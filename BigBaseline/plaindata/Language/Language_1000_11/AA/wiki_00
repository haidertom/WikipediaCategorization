{"id": "4051786", "url": "https://en.wikipedia.org/wiki?curid=4051786", "title": "Anglophone pronunciation of foreign languages", "text": "Anglophone pronunciation of foreign languages\n\nThe following is a list of common non-native pronunciations that English speakers make when trying to speak foreign languages. Many of these are due to transfer of phonological rules from English to the new language as well as differences in grammar and syntax that they encounter.\n\nThis article uses International Phonetic Alphabet pronunciation. See and IPA chart for English for an introduction.\n\n\n\n\n\n\n\n"}
{"id": "46259914", "url": "https://en.wikipedia.org/wiki?curid=46259914", "title": "Bergen Corpus of London Teenage Language", "text": "Bergen Corpus of London Teenage Language\n\nThe Bergen Corpus of London Teenage Language (COLT) is a data set of samples of spoken English that was compiled in 1993 from tape recorded and transcribed conversations by teens between the ages of 13 and 17 in London schools. This corpus, which has been tagged for part of speech using the CLAWS 6 tagset, is one of the linguistic research projects housed at the University of Bergen in Norway. Linguistic analysis based on this corpus material has appeared in the book \"Trends in Teenage Talk\" and later journal articles.\n"}
{"id": "38357394", "url": "https://en.wikipedia.org/wiki?curid=38357394", "title": "Budya language", "text": "Budya language\n\nBudya is a minor Bantu language. It is listed among Luban languages in Maho (2009).\n\nShona (Korekore) has a dialect of the same name (Budya/Budjga) in Zimbabwe.\n"}
{"id": "3852913", "url": "https://en.wikipedia.org/wiki?curid=3852913", "title": "CHILDES", "text": "CHILDES\n\nThe Child Language Data Exchange System (CHILDES) is a corpus established in 1984 by Brian MacWhinney and Catherine Snow to serve as a central repository for first language acquisition data. Its earliest transcripts date from the 1960s, and it now has contents (transcripts, audio, and video) in 26 languages from 130 different corpora, all of which are publicly available worldwide. Recently, CHILDES has been made into a component of the larger corpus TalkBank, which also includes language data from aphasics, second language acquisition, conversation analysis, and classroom language learning. CHILDES is mainly used for analyzing the language of young children and the child directed speech of adults.\n\nDuring the early 1990s, as computational resources capable of easily manipulating the data volumes found in CHILDES became commonly available, there was a significant increase in the number of studies of child language acquisition that made use of it. CHILDES is currently directed and maintained by Brian MacWhinney at Carnegie Mellon University.\n\nThere are a variety of languages and ages represented in the CHILDES transcripts. The majority of the transcripts are from spontaneous interactions and conversations. The transcriptions are coded in the CHAT (Codes for the Human Analysis of Transcripts) transcription format, which provides a standardized format for producing conversational transcripts. This system can be used to transcribe conversations with any type of language learner: children, second-language learners, and recovering aphasics. In addition to discourse level transcription, the CHAT system also has options for phonological and morphological analysis. The CLAN program was developed by Leonid Spektor and aids in transcription and analysis of the child language data.\n\nTo date, over 4500 published studies cite CHILDES. CHILDES reports this number in their manuals and Google Scholar contains 5451 citations as of July 2017.\n\n"}
{"id": "160987", "url": "https://en.wikipedia.org/wiki?curid=160987", "title": "CJK characters", "text": "CJK characters\n\nIn internationalization, CJK is a collective term for the Chinese, Japanese, and Korean languages, all of which include Chinese characters and derivatives (collectively, CJK characters) in their writing systems. Occasionally, Vietnamese is included, making the abbreviation CJKV, since Vietnamese historically used Chinese characters as well. Collectively, the CJKV characters often include \"hànzì\" in Chinese, \"kanji\", \"kana\" in Japanese, \"hanja\", \"hangul\" in Korean, and \"hán tự\" or \"chữ nôm\" in Vietnamese.\n\nChinese is written almost exclusively in Chinese characters. It requires over 3,000 characters for general literacy, but up to 40,000 characters for reasonably complete coverage. Japanese uses fewer characters — general literacy in Japanese can be expected with 1,945 characters. The use of Chinese characters in Korea is becoming increasingly rare, although idiosyncratic use of Chinese characters in proper names requires knowledge (and therefore availability) of many more characters. However, even today, students in South Korea are taught 1,800 characters.\n\nOther scripts used for these languages, such as bopomofo and the Latin-based pinyin for Chinese, hiragana and katakana for Japanese, and hangul for Korean, are not strictly \"CJK characters\", although CJK character sets almost invariably include them as necessary for full coverage of the target languages.\n\nUntil the early 20th century, Literary Chinese was the written language of government and scholarship in Vietnam. Popular literature in Vietnamese was written in the \"chữ Nôm\" script, consisting of borrowed Chinese characters together with many characters created locally. By the end of the 1920s, both scripts had been replaced by writing in Vietnamese using the Latin-based Vietnamese alphabet.\n\nThe sinologist Carl Leban (1971) produced an early survey of CJK encoding systems.\n\nThe number of characters required for complete coverage of all these languages' needs cannot fit in the 256-character code space of 8-bit character encodings, requiring at least a 16-bit fixed width encoding or multi-byte variable-length encodings. The 16-bit fixed width encodings, such as those from Unicode up to and including version 2.0, are now deprecated due to the requirement to encode more characters than a 16-bit encoding can accommodate—Unicode 5.0 has some 70,000 Han characters—and the requirement by the Chinese government that software in China support the GB 18030 character set.\n\nAlthough CJK encodings have common character sets, the encodings often used to represent them have been developed separately by different East Asian governments and software companies, and are mutually incompatible. Unicode has attempted, with some controversy, to unify the character sets in a process known as Han unification.\n\nCJK character encodings should consist minimally of Han characters plus language-specific phonetic scripts such as pinyin, bopomofo, hiragana, katakana and hangul.\n\nCJK character encodings include:\n\nThe CJK character sets take up the bulk of the assigned Unicode code space. There is much controversy among Japanese experts of Chinese characters about the desirability and technical merit of the Han unification process used to map multiple Chinese and Japanese character sets into a single set of unified characters.\n\nAll three languages can be written both left-to-right and top-to-bottom (right-to-left and top-to-bottom in ancient documents), but are usually considered left-to-right scripts when discussing encoding issues.\n\nLibraries cooperated on encoding standards for JACKPHY characters in the early 1980s. According to Ken Lunde, the abbreviation \"CJK\" was a registered trademark of Research Libraries Group (which merged with OCLC in 2006). The trademark owned by OCLC between 1987 and 2009 has now expired.\n\n\n\n"}
{"id": "17220101", "url": "https://en.wikipedia.org/wiki?curid=17220101", "title": "Cognitive and linguistic theories of composition", "text": "Cognitive and linguistic theories of composition\n\nCognitive science and linguistic theory have played an important role in providing empirical research into the writing process and serving the teaching of composition. As composition theories, there is some dispute concerning the appropriateness of tying these two schools of thought together into one theory of composition. However, their empirical basis for research and ties to the process theory of composition and cognitive science can be thought to warrant some connection.\n\nThe cognitive theory of composition (hereafter referred to as “cognitive theory”) can trace its roots to psychology and cognitive science. Lev Vygotsky's and Jean Piaget's contributions to the theories of cognitive development and developmental psychology could be found in early work linking these sciences with composition theory (see Ann E. Berthoff). Linda Flower and John Hayes published “A Cognitive Process Theory of Writing” in 1981, providing the groundwork for further research into how thought processes influence the writing process.\n\nLinguistic theories of composition found their roots in the debate surrounding grammar's importance in composition pedagogy. Scholars, such as Janet Emig, Patrick Hartwell, Martha J. Kolln, Robert Funk, Stephen Witte, and Lester Faigley continued this line of thought around the same time that a cognitive theory of composition was being developed by Flower and Hayes. These scholars, like scholars researching cognitive-oriented composition theory, focused on research providing insight into the writing process, but were also committed to providing pedagogical advancements addressing deficiencies, trends, and insights gained from their linguistic research.\n\nA cognitive theory is focused on gaining insight into the writing process through the writer’s thought processes. Composition theorists have attacked the problem of accessing writers’ thoughts in various ways. Flower and Hayes’ essay, “A Cognitive Process Theory of Writing” sought to outline the writer’s choice-making throughout the writing process, and how those choices constrained or influenced other choices down the line. Other research has focused on capturing the cognitive processes of writers during the writing process through note-taking or speaking aloud, while some early research by Birdwell, Nancrow, and Ross was done with computers to record writers’ keystrokes during the writing process.\n\nLinguistic composition theory has traditionally focused on sentence and paragraph-level composition, with the goal of providing instructors insights into the way students write at various proficiency levels. Stephen Witte and Lester Faigley utilized detailed syntactic analysis to redefine the importance of cohesion and coherence in judging writing quality. Paul Rodgers and Richard Braddock focused on paragraph structure, in separate studies, in order to dispel common misjudgments about the importance of traditional paragraph structure.\n\nApplied linguistics, specifically EFL/ESL studies, has played a large role in development linguistic theories of composition. Liz Hamp-Lyons’ research in ESL/EFL writing assessment is valuable in informing ESL composition pedagogy. Paul Kei Matsuda, has illustrated the deficiency in ESL composition research, and recent compilations by Matsuda and others have attempted to bridge the gap between ESL instruction and composition theory by presenting pedagogical, theoretical, and assessment frameworks in the ESL composition classroom.\n\nCognitive and linguistic theories of composition are heavily tied to process theory. Cognitive and linguistic theories have been instrumental in providing respected empirical research to the field of composition theory, but tend to stay away from making pedagogical suggestions. Instead, research in these fields is typically intended to inform process theory by providing data analysis regarding the writing process, and by bringing scientific research to the field.\n"}
{"id": "50937447", "url": "https://en.wikipedia.org/wiki?curid=50937447", "title": "Comparison of computer-assisted translation tools", "text": "Comparison of computer-assisted translation tools\n\nA number of computer-assisted translation software and websites exists for various platforms and access types. The list below includes only some of the existent and available software and website platforms.\n\nAccording to a 2006 survey undertaken by Imperial College of 874 translation professionals from 54 countries, primary tool usage was reported as follows: Trados (35%), Wordfast (17%), Déjà Vu (16%), SDL Trados 2006 (15%), SDLX (4%), STAR Transit (3%), OmegaT (3%), others (7%).\n"}
{"id": "35488854", "url": "https://en.wikipedia.org/wiki?curid=35488854", "title": "Complete Feedback", "text": "Complete Feedback\n\nComplete Feedback is one of Charles Hockett's 16 Design features of language which states that speakers are able to hear what they are saying. Through their auditory channels they are able to receive feedback on what they are vocalizing.\n"}
{"id": "40965300", "url": "https://en.wikipedia.org/wiki?curid=40965300", "title": "Concatenation theory", "text": "Concatenation theory\n\nConcatenation theory, also called string theory, character-string theory, or theoretical syntax, studies character strings over finite alphabets of characters, signs, symbols, or marks. String theory is foundational for formal linguistics, computer science, logic, and metamathematics especially proof theory. A generative grammar can be seen as a recursive definition in string theory.\n\nThe most basic operation on strings is concatenation; connect two strings to form a longer string whose length is the sum of the lengths of those two strings. ABCDE is the concatenation of AB with CDE, in symbols ABCDE = AB ^ CDE. Strings, and concatenation of strings can be treated as an algebraic system with some properties resembling those of the addition of integers; in modern mathematics, this system is called a free monoid.\n\nIn 1956 Alonzo Church wrote: \"Like any branch of mathematics, theoretical syntax may, and ultimately must, be studied by the axiomatic method\". Church was evidently unaware that string theory already had two axiomatizations from the 1930s: one by and one by Alfred Tarski. Coincidentally, the first English presentation of Tarski’s 1933 axiomatic foundations of string theory appeared in 1956 – the same year that Church called for such axiomatizations. As Tarski himself noted using other terminology, serious difficulties arise if strings are construed as tokens rather than types in the sense of Pierce's type-token distinction, not to be confused with similar distinctions underlying other type-token distinctions.\n"}
{"id": "30011719", "url": "https://en.wikipedia.org/wiki?curid=30011719", "title": "Consorzio ICoN", "text": "Consorzio ICoN\n\nThe Consorzio ICoN is an interuniversity consortium for Italian Studies established in 1999. It consists of 21 Italian universities and focuses on philology and cultural studies. The consortium is based and administrated at the University of Pisa and is supported by the Italian Ministry of University and Research (\"Ministero dell'Università e della Ricerca\"). It aims at diffusing Italian language, culture and literature.\n\nThe universities forming the consortium are\n\n\nThe University of Pisa, in collaboration with the consortium, offers a bachelor's degree program in Italian philology and cultural studies (Corso di laurea triennale in \"Lingua e cultura italiana per stranieri\") for foreigners and expatriates, based on distance education and e-learning. The program refers to the bachelor's degree class L-10 (literary studies) and offers four majors in\n\n\nExams are carried out at institutions in the country of residence (partner universities, Italian embassies). The title will be issued by the administrative university, actually Pisa, mentioning all participating universities. As Italy is part of European Higher Education Area, the program has a value of 180 ECTS points and permits to participate in a Master's degree program.\n\nThe ICoN consortium organizes three executive master's degrees (60 ECTS) in the field of Italian studies. They consist of phases of attendance, distance education and e-learning. The offer includes\n\n\nThe consortium ICoN also offers language courses and programs in written Italian at distinct levels. For native English speakers special packages have been designed in collaboration with the National Italian American Foundation and the University of California's department of Italian. The courses have been awarded with the European Commission's \"European Language Label\".\n\n\n"}
{"id": "6867", "url": "https://en.wikipedia.org/wiki?curid=6867", "title": "Context-free language", "text": "Context-free language\n\nIn formal language theory, a context-free language (CFL) is a language generated by a context-free grammar (CFG).\n\nContext-free languages have many applications in programming languages, in particular, most arithmetic expressions are generated by context-free grammars.\n\nDifferent context-free grammars can generate the same context-free language. Intrinsic properties of the language can be distinguished from extrinsic properties of a particular grammar by comparing multiple grammars that describe the language.\n\nThe set of all context-free languages is identical to the set of languages accepted by pushdown automata, which makes these languages amenable to parsing. Further, for a given CFG, there is a direct way to produce a pushdown automaton for the grammar (and thereby the corresponding language), though going the other way (producing a grammar given an automaton) is not as direct.\n\nA model context-free language is formula_1, the language of all non-empty even-length strings, the entire first halves of which are 's, and the entire second halves of which are 's. is generated by the grammar formula_2.\nThis language is not regular.\nIt is accepted by the pushdown automaton formula_3 where formula_4 is defined as follows:\n\nUnambiguous CFLs are a proper subset of all CFLs: there are inherently ambiguous CFLs. An example of an inherently ambiguous CFL is the union of formula_6 with formula_7. This set is context-free, since the union of two context-free languages is always context-free. But there is no way to unambiguously parse strings in the (non-context-free) subset formula_8 which is the intersection of these two languages.\n\nThe language of all properly matched parentheses is generated by the grammar formula_9.\n\nThe context-free nature of the language makes it simple to parse with a pushdown automaton.\n\nDetermining an instance of the membership problem; i.e. given a string formula_10, determine whether formula_11 where formula_12 is the language generated by a given grammar formula_13; is also known as \"recognition\". Context-free recognition for Chomsky normal form grammars was shown by Leslie G. Valiant to be reducible to boolean matrix multiplication, thus inheriting its complexity upper bound of \"O\"(\"n\").\nConversely, Lillian Lee has shown \"O\"(\"n\") boolean matrix multiplication to be reducible to \"O\"(\"n\") CFG parsing, thus establishing some kind of lower bound for the latter.\n\nPractical uses of context-free languages require also to produce a derivation tree that exhibits the structure that the grammar associates with the given string. The process of producing this tree is called \"parsing\". Known parsers have a time complexity that is cubic in the size of the string that is parsed.\n\nFormally, the set of all context-free languages is identical to the set of languages accepted by pushdown automata (PDA). Parser algorithms for context-free languages include the CYK algorithm and Earley's Algorithm.\n\nA special subclass of context-free languages are the deterministic context-free languages which are defined as the set of languages accepted by a deterministic pushdown automaton and can be parsed by a LR(k) parser.\n\nSee also parsing expression grammar as an alternative approach to grammar and parser.\n\nContext-free languages are closed under the following operations. That is, if \"L\" and \"P\" are context-free languages, the following languages are context-free as well:\n\nThe context-free languages are not closed under intersection. This can be seen by taking the languages formula_22 and formula_23, which are both context-free. Their intersection is formula_24, which can be shown to be non-context-free by the pumping lemma for context-free languages. As a consequence, context-free languages cannot be closed under complementation, as for any languages \"A\" and \"B\", their intersection can be expressed by union and complement: formula_25. In particular, context-free language cannot be closed under difference, since complement can be expressed by difference: formula_26. \n\nHowever, if \"L\" is a context-free language and \"D\" is a regular language then both their intersection formula_27 and their difference formula_28 are context-free languages.\n\nIn formal language theory, questions about regular languages are usually decidable, but ones about context-free languages are often not. It is decidable whether such a language is finite, but not whether it contains every possible string, is regular, is unambiguous, or is equivalent to a language with a different grammar.\n\nThe following problems are undecidable for arbitrarily given context-free grammars A and B:\n\nThe following problems are \"decidable\" for arbitrary context-free languages:\n\nAccording to Hopcroft, Motwani, Ullman (2003), \nmany of the fundamental closure and (un)decidability properties of context-free languages were shown in the 1961 paper of Bar-Hillel, Perles, and Shamir\n\nThe set formula_8 is a context-sensitive language, but there does not exist a context-free grammar generating this language. So there exist context-sensitive languages which are not context-free. To prove that a given language is not context-free, one may employ the pumping lemma for context-free languages or a number of other methods, such as Ogden's lemma or Parikh's theorem.\n\n"}
{"id": "54396537", "url": "https://en.wikipedia.org/wiki?curid=54396537", "title": "Developmental language disorder", "text": "Developmental language disorder\n\nDevelopmental language disorder (DLD) is identified when a child has problems with language development that continue into school age and beyond. The language problems have a significant impact on everyday social interactions or educational progress, and occur in the absence of autism spectrum disorder, intellectual disability or a known biomedical condition. The most obvious problems are difficulties in using words and sentences to express meanings, but for many children, understanding of language (receptive language) is also a challenge, although this may not be evident unless the child is given a formal assessment.\n\nThe term developmental language disorder (DLD) was endorsed in a consensus study involving a panel of experts (CATALISE Consortium) in 2017... The study was conducted in response to concerns that a wide range of terminology was used in this area, with the consequence that there was poor communication, lack of public recognition, and in some cases children were denied access to services. Developmental language disorder is a subset of language disorder, which is itself a subset of the broader category of speech, language and communication needs (SLCN).\n\nThe terminology for children’s language disorders has been extremely wide-ranging and confusing, with many labels that have overlapping but not necessarily identical meanings. In part this confusion reflected uncertainty about the boundaries of DLD, and the existence of different subtypes. Historically, the terms ‘’developmental dysphasia’’ or ‘’developmental aphasia’’ were used to describe children with the clinical picture of DLD. These terms have, however, largely been abandoned, as they suggest parallels with adult acquired aphasia. This is misleading, as DLD is not caused by brain damage.\n\nAlthough the term DLD has been used for many years, it has been less common than the term Specific language impairment (SLI), which has been widely adopted, especially in North America. The definition of SLI overlaps with DLD, but was rejected by the CATALISE panel because it was seen as overly restrictive in implying that the child had relatively pure problems with language in the absence of any other impairments. Children with such selective problems are relatively rare, and there is no evidence that they respond differently to intervention, or have different causal factors, from other children with language problems.\n\nIn the UK education system the term Speech, Language and Communication Needs (SLCN) is widely used, but this is far broader than DLD, and includes children with speech, language and social communication difficulties arising from a wide range of causes.\n\nThe question of whether to refer to children's language problems as ‘disorder’ was a topic of debate among the CATALISE consortium, but the conclusion was that ‘disorder’ conveyed the serious nature and potential consequences of persistent language deficits. It is also parallel with other neurodevelopmental conditions and consistent with diagnostic frameworks such as DSM5 and ICD-11. Where there are milder or more transient difficulties, language difficulties may be a more appropriate term.\n\nDLD can affect a range of areas of language and the degree of impairment in different areas of language can vary from child to child. However, although there have been attempts to define different subtypes, these have not generally resulted in robust categories. The recommendation of the CATALISE panel was that the specific areas of impairment should be assessed and documented for individual children, while recognizing that different children might have different combinations of problems. The areas which can be affected are:\n\nSpeech is the act of articulating sounds, and this can be impaired for all kinds of reasons – a structural problem such as cleft lip and cleft palate, a neurological problem affecting motor control of the speech apparatus Dysarthria, or inability to perceive distinctions between sounds because of Hearing loss. Some distortions of speech sounds, such as a Lisp, are commonly seen in young children. These misarticulations should not be confused with language problems, which involve the ability to select and combine linguistic elements to express meanings, and the ability to comprehend meanings. \nAlthough speech disorders can be distinguished from language disorders, they can also co-occur. When a child fails to produce distinctions between speech sounds for no obvious reason, this is typically regarded as a language problem affecting the learning of phonological contrasts. The classification of and terminology for disorders of speech sound production is a subject of considerable debate. In practice, even for those with specialist skills, it is not always easy to distinguish between phonological disorders and other types of speech production problem.\nSpeech sound disorder (SSD) is any problem with speech production arising from any cause. \nSpeech Sound Disorders of unknown cause that are not accompanied by other language problems are a relatively common reason for young children to be referred to speech-language therapy (speech-language pathology). These often resolve by around 4–5 years of age with specialist intervention, and so would not meet criteria for DLD. Where such problems continue beyond 5 years of age, they are usually accompanied by problems in broader language domains and have a poorer prognosis, so a diagnosis of DLD with SSD is then appropriate.\n\nDLD often co-occurs with milder neurodevelopmental disorders of unknown origin, such as attention-deficit hyperactivity disorder, developmental dyslexia or developmental co-ordination disorder. These do not preclude a diagnosis of DLD, but should be noted as co-occurring conditions.\n\nIt is generally accepted that DLD is strongly influenced by genetic factors. The best evidence comes from the Twin study method. Two twins growing up together are exposed to the same home environment, yet may differ radically in their language skills. Such different outcomes are, however, much more common in fraternal (non-identical) twins, who are genetically different. Identical twins share the same genes and tend to be much more similar in language ability. There can be some variation in the severity and persistence of DLD in identical twins, indicating that non-genetic factors affect the course of disorder, but it is unusual to find a child with DLD who has an identical twin with typical language.\n\nThere was considerable excitement when a large, multigenerational family with a high rate of DLD were found to have a mutation of the FOXP2 gene just in the affected family members. However, subsequent studies have found that, though DLD runs in families, it is not usually caused by a mutation in FOXP2 or another specific gene. Current evidence suggests that there are many different genes that can influence language learning, and DLD results when a child inherits a particularly detrimental combination of risk factors, each of which may have only a small effect. Nevertheless, study of the mode of action of the FOXP2 gene has helped identify other common genetic variants involved in the same neural pathways that may play a part in causing DLD.\n\nLanguage disorders are associated with aspects of home environment, and it is often assumed that this is a causal link, with poor language stimulation leading to weak language skills. Twin studies, however, show that two children in the same home environment can have very different language outcomes, suggesting we should consider other explanations for the link. Children with DLD often grow up into adults who have relatively low educational attainments, and their children may share a genetic risk for language disorder.\n\nOne non-genetic factor that is known to have a specific impact on language development is being a younger sibling in a large family.\n\nIt has long been noted that males are more affected by DLD than females, with a sex ratio of affected males: females around 3 or 4:1 However, the sex difference is much less striking in epidemiological samples, suggesting that similar problems may exist in females but are less likely to be detected. The reason for the sex difference is not well understood.\n\nPoor motor skills are commonly found in children with DLD.\n\nBrain scans do not usually reveal any obvious abnormalities in children with DLD, although quantitative comparisons have found differences in brain size or relative proportions of white or grey matter in specific regions. In some cases, unusual brain gyri are found. To date, no consistent 'neural signature' for DLD has been found, although some studies have noted evidence for involvement of subcortical systems. Differences in the brains of children with DLD vs typically developing children are subtle and may overlap with atypical patterns seen in other neurodevelopmental disorders.\n\nDLD is defined purely in behavioural terms: there is no biological test. There are three points that need to be met for a diagnosis of DLD:\nFor research and epidemiological purposes, specific cutoffs on language assessments have been used to document the first criterion. Tomblin et al. proposed the EpiSLI criterion, based on five composite scores representing performance in three domains of language (vocabulary, grammar, and narration) and two modalities (comprehension and production). Children scoring in the lowest 10% on two or more composite scores are identified as having language disorder.\n\nThe second criterion, persistence of language problems, can be difficult to judge in a young child, but longitudinal studies have shown that difficulties are less likely to resolve for children who have poor language comprehension, rather than difficulties confined to expressive language. In addition, children with isolated difficulties in just one of the areas noted under 'subtypes' tend to make better progress than those whose language is impaired in several areas.\n\nThe third criterion specifies that DLD is used for children whose language disorder is not part of another biomedical condition, such as a genetic syndrome, a sensorineural hearing loss, neurological disease, Autism Spectrum Disorder or Intellectual Disability – these were termed 'differentiating conditions' by the CATALISE panel. Language disorders occurring with these conditions need to be assessed and children offered appropriate intervention, but a terminological distinction is made so that these cases would be diagnosed as Language Disorder associated with <mark>___</mark>, with the main diagnosis being specified: e.g. \"Language Disorder associated with Autism Spectrum Disorder.\" The reasoning behind these diagnostic distinctions is discussed further by Bishop (2017).\n\nAssessment will usually include an interview with the child’s caregiver, observation of the child in an unstructured setting, a hearing test, and standardized tests of language. There is a wide range of language assessments in English. Some are restricted for use by experts in speech-language pathology: speech and language therapists (SaLTs/SLTs) in the UK, speech-language pathologists (SLPs) in the US and Australia. A commonly used test battery for diagnosis of DLD is the Clinical Evaluation of Language Fundamentals (CELF). \nAssessments that can be completed by a parent or teacher can be useful to identify children who may require more in-depth evaluation. The Children’s Communication Checklist (CCC–2) is a parent questionnaire suitable for assessing everyday use of language in children aged 4 years and above who can speak in sentences. \nInformal assessments, such as language samples, are often used by speech-language therapists/pathologists to complement formal testing and give an indication of the child's language in a more naturalistic context. A language sample may be of a conversation or narrative retell. In a narrative language sample, an adult may tell the child a story using a wordless picture book (e.g. Frog Where Are You?, Mayer, 1969), then ask the child to use the pictures and tell the story back. Language samples can be transcribed using computer software such as the Systematic Analysis of Language Software, and then analyzed for a range of features: e.g., the grammatical complexity of the child's utterances, whether the child introduces characters to their story or jumps right in, whether the events follow a logical order, and whether the narrative includes a main idea or theme and supporting details.\n\nTreatment is usually carried out by speech and language therapists/pathologists, who use a wide range of techniques to stimulate language learning. In the past, there was a vogue for drilling children in grammatical exercises, using imitation and elicitation, but such methods fell into disuse when it became apparent that there was little generalisation to everyday situations. Contemporary approaches to enhancing development of language structure, for younger children at least, are more likely to adopt 'milieu' methods, in which the intervention is interwoven into natural episodes of communication, and the therapist builds on the child's utterances, rather than dictating what will be talked about. Interventions for older children, may be more explicit, telling the children what areas are being targeted and giving explanations regarding the rules and structures they are learning, often with visual supports.\n\nIn addition, there has been a move away from a focus solely on grammar and phonology toward interventions that develop children's social use of language, often working in small groups that may include typically developing as well as language-impaired peers.\n\nAnother way in contemporary remediation differ from the past is that parents are more likely to be directly involved, but this approach is largely used with preschool children, rather than those whose problems persist into school age.,\n\nFor school-aged children, teachers are increasingly involved in intervention, either in collaboration with speech and language therapists/pathologists, or as the main agents of delivery of the intervention. Evidence for the benefits of a collaborative approach is emerging, but the benefits of asking education staff to be the main deliverers of SLT intervention (the “consultative” approach) are unclear. When SLT intervention is delivered indirectly by trained SLT assistants, however, there are indications that this can be effective.\n\nA radically different approach has been developed by Tallal and colleagues, who devised a computer-based intervention, FastForWord, that involves prolonged and intensive training on specific components of language and auditory processing. The theory underlying FastForword maintains that language difficulties are caused by a failure to make fine-grained auditory discriminations in the temporal dimension, and the computerised training materials are designed to sharpen perceptual acuity. However, a systematic review of clinical trials assessing FastForWord reported no significant gains relative to a control group.\n\nIn this field, Randomized controlled trial methodology has not been widely used, and this makes it difficult to assess clinical efficacy with confidence. Children's language will tend to improve over time, and without controlled studies, it can be hard to know how much of observed change is down to a specific treatment. There is, however, increasing evidence that direct 1:1 intervention with an SLT/P can be effective for improving vocabulary and expressive language. There have been few studies of interventions that target receptive language, though some positive outcomes have been reported.,\n\nLongitudinal studies indicate that problems are largely resolved by 5 years of age in around 40% of 4-year-olds with early language delays who have no other presenting risk factors. However, for children who still have significant language difficulties at school entry, reading problems are common, even for children who receive specialist help, and educational attainments are typically poor. Poor outcomes are most common in cases where comprehension as well as expressive language is affected. There is also evidence that scores on tests of nonverbal ability of children with DLD decrease over the course of development.\n\nDLD is associated with an elevated risk of social, emotional and mental health concerns. For instance, in a UK survey, 64% of a sample of 11-year-olds with DLD scored above a clinical threshold on a questionnaire for psychiatric difficulties, and 36% were regularly bullied, compared with 12% of comparison children. In the longer-term, studies of adult outcomes of children with DLD have found elevated rates of unemployment, social isolation and psychiatric disorder among those with early comprehension difficulties. However, better outcomes are found for children who have milder difficulties and do not require special educational provision.\n\nEpidemiological surveys, in the US and the UK converge in estimating the prevalence of DLD in 5-year-olds at around 7 percent.\n\nMuch research has focused on trying to identify what makes language learning so hard for some children. A major divide is between theories that attribute the difficulties to a low-level problem with auditory temporal processing, and those that propose there is a deficit in a specialised language-learning system.. Other accounts emphasise deficits in specific aspects of learning and memory.. It can be difficult to choose between theories because they do not always make distinctive predictions, and there is considerable heterogeneity among children with DLD. It has also been suggested that DLD may only arise when more than one underlying deficit is present.\n\n\n\n"}
{"id": "35643436", "url": "https://en.wikipedia.org/wiki?curid=35643436", "title": "Dhalandji language", "text": "Dhalandji language\n\nDhalandji of Thalanyji (also spelt Dhalanyji, Thalantji) and Binigura or Pinikura (also spelt Pinigura), are two closely related languages from the Pilbara region of Western Australia. They are part of the Kanyara subgroup of the Pama–Nyungan language fanily.\n"}
{"id": "1454375", "url": "https://en.wikipedia.org/wiki?curid=1454375", "title": "Dhikr", "text": "Dhikr\n\nDhikr (also \"Zikr, Zekr, Zikir, Jikir\", and variants; ; plural \"aḏkār\" , meaning \"mentioning\")\nare devotional acts in Islam in which short phrases or prayers are repeatedly recited silently within the mind or aloud. It can be counted on a set of prayer beads (\"Misbaha\" ) or in ones head. A person who recites the Dhikr is called a \"ḏākir\" ( ).\n\"Tasbih\" () is a form of dhikr that involves the repetitive utterances of short sentences glorifying God.\nThe content of the prayers includes the names of God, or a \"duʿāʾ\" (prayer of supplication) taken from the hadith or the Quran.\n\nThere are several verses in the Quran that emphasize the importance of remembering the will of God by saying phrases such as \"God willing,\" \"God knows best,\" and \"If it is your will.' This is the basis for dhikr. Sura 18 (Al-Kahf), ayah 24 states a person who forgets to say, \"God Willing,\" should immediately remember God by saying, \"May my Lord guide me to do better next time.\" Other verses include sura 33 (Al-Ahzab), ayah 41, \"O ye who believe! Celebrate the praises of Allah, and do this often,\" and sura 13 (Ar-Ra'd), ayah 28, \"They are the ones whose hearts rejoice in remembering God. Absolutely, by remembering God, the hearts rejoice.\" Muhammad said, 'The best [dhikr] is \"La ilaha illa’llah\" (\"there is no God but God\"), and the best supplicatory prayer is \"Al-hamdu li’llah\" (\"praise be to God\").\n\nMuslims believe dhikr is one of the best ways to enter the higher level of Heaven and to glorify the Oneness of Allah.\n\nTo Sufis, dhikr is seen as a way to gain spiritual enlightenment and achieve union (\"visal\") or annihilation (\"fana\") in God. All Muslim sects endorse individual rosaries as a method of meditation, the goal of which is to obtain a feeling of peace, separation from worldly values (dunya), and, in general, strengthen Iman (faith).\n\nThere are several phrases that are usually read when remembering Allah. Here are a few:\n\n\nSome of these can be said together.e.g- \n\nReciting the Quran sincerely is also considered a kind of Dhikr. \ne.g.- \n\nIt is mentioned in hadith that where people are oblivious to dhikir, remembrance of Allah is like being steadfast in jihad when others are running away (Targhib, p. 193, vol. 3 ref. Bazar and Tibrani).\n\nFollowers of Sufism often engage in ritualized dhikr ceremonies, the details of which sometimes vary between Sufi orders or \"tariqah\". Each order, or lineage within an order, has one or more forms for group dhikr, the liturgy of which may include recitation, singing, music, dance, costumes, incense, \"muraqaba\" (meditation), ecstasy, and trance. Though the extent, usage and acceptability of many of these elements vary from order to order - with many condemning the usage of instruments (considered unlawful by most scholars) and intentional loss of control. In addition, costumes are quite uncommon and is almost exclusively unique to the Mevlavi order in Turkey - which is an official cultural \"heritage\" of the secular Turkish state. In Sufism, group dhikr does not necessarily entail all of these forms.\n\nThe most common forms of Sufi group dhikr consist in the recital of particular litanies (e.g. Hizb al-Bahr of the Shadhilis), a composition of Quranic phrases and Prophetic supplications (e.g. Wird al-Latif of the Ba `Alawis), or a liturgical repetition of various formula and prayers (e.g. al-Wadhifa of the Tijanis ). All of these forms are referred to as a \"hizb\" (\"pl.\" \"ahzab\") or a \"wird\" (\"pl.\" \"awrad\"). This terminological usage is important as some critics often mistakenly believe that the word hizb only refers to a portion of the Quran. In addition, many recite extended prayers upon Muhammad (known as durood) of which the Dala'il al-Khayrat is perhaps the most popular. Though common to almost all Sufi orders, some (such as the Naqsbandis) prefer to perform their dhikr silently - even in group settings. In addition, most gatherings are held on Thursday or Sunday nights as part of the institutional practices of the tariqah (since Thursday is the night marks the entrance of the Muslim \"holy\" day of Friday and Sundays are a convenient congregational time in most contemporary societies) - though people who don't live near their official zawiya gather whenever is convenient for the most people.\n\nAnother type of group dhikr ceremony that is most commonly performed in Arabic countries is called the haḍra (\"lit\". presence). The haḍra is a communal gathering for dhikr and its associated liturgical rituals, prayers, and song recitals, performing both in private or public. Though the haḍra is popular (in part because of the controversy surrounding it), it is mostly practiced in North Africa, the Middle-East and Turkey. In Turkey this ceremony is called \"Zikr-i Kiyam\" (Standing dhikr) and \"imara\" in Algeria and Morocco. In places like Syria where Sufis are a visible part of the fabric and psyche of society, each order typically has their private gathering on one day and will participate in a public haḍra at a central location to which both the affiliated and unaffiliated alike are invited as an expression of unity. Similar public ceremonies occur in Turkey, Egypt, Algeria and Morocco.\n\nFor those who perform it, the haḍra marks the climax of the Sufi's gathering regardless of any teaching or formal structure - it often follows a formal teaching session as a way of internalizing the lessons. Musically, the structure of the haḍra includes several secular Arab genres (each of which expresses a different emotion) and can last for hours. It is directed by the sheikh of the tariqa or one of his representatives; monitoring the intensity, depth and duration of the phases of the haḍra, the sheikh aims to draw the circle into deep awareness of God and away from the participants own individuatedness. The dhikr ceremonies may have a ritually determined length or may last as long as the Sheikh deems his murids require. The haḍra section consists of the ostinato-like repetition of the name of God over which the soloist performs a richly ornamented song. In many haḍras, this repetition proceeds from the chest and has the effect of a percussion instrument, with the participants bending forward while exhaling and stand straight while inhaling so that both the movement and sound contribute to the overall rhythm. The climax is usually reached through cries of \"Allah! Allah!\" or \"hu hu\" (which is either the pronoun \"he\" or the last vowel on the word \"Allah\" depending on the method) while the participants are moving up and down. Universally, the haḍra is almost always followed by Quranic recital in the tarteel style - which according to al-Junayd al-Baghdadi, was a prophetic instruction received through a dream.\n\nMore common than the haḍra is the sama` (\"lit\". audition), a type of group ceremony that consist mostly of the audition of spiritual poetry and Quranic recitation in an emotionally charged manner; and thus is not dhikr is the technical sense the word implies. However, the same debate over certain matters of decorum apply as exists with the haḍra. Even though group dhikr is popular and makes up the spiritual life of most Sufi adherents, other more private forms of dhikr are performed more routinely - usually consisting of the order's \"wird\" (daily litany) - which adherents usually recite privately, even if gathered together. So although group dhikr is seen as a hallmark of Sufism, the Sufis themselves practice the same private forms of worship that other Muslims practice, though usually more frequently and methodically; group dhikr is a less frequent occurrence and is not the end-all-and-be-all of Sufism, as some Sufi orders do not even perform it.\n\nDhikr takes on a wide range and various layers of meaning. In some Sufi orders it is instituted as a ceremonial activity. In \"tasawwuf\" (Islamic mysticism or Sufism) dhikr is most likely the most frequent form of prayer. Among the orders of Muslims that practice dhikr, there are some who advocate silent, individual prayer, while others join together in an outward, group expression of their love for God. There are also a number of hadiths that give emphasis to remembrance of God.\n\nDhikr is given great importance by some Sufi writers, among them is Najm-al-Din Razi who wrote about dhikr in the context of what it combats. In contrast to the virtues of remembrance, Razi uses the perils of forgetfulness to show the importance of dhikr. The soul and the world are veils that make people forget God. The Naqshbandi Haqqani Sufi Order of America says this about dhikr: \n\nThere are some Sufi orders, such as the Shadhili, that perform a ritualized form of dhikr in groups termed \"haḍra\" (\"lit\". presence) - the details of which are discussed below. Another method of dhikr, but which is most commonly associated with Sufism, is the repetition of the Arabic name \"Allah Hu\". Sufi orders have similar practices - some with similar visualizations and others choosing to focus only on the attachment of their heart to the One they are invoking. Though this is associated almost exclusively with Sufism in modern times, many of the Quranic exegesis of the past approved of the practice (e.e. Fakhr al-Din al-Razi in his \"Mafatih al-Ghayb\"), which confirms that it has a basis in orthodoxy.\n\nKnown also as \"Tasbih\", these are usually \"Misbaha\" (prayer beads) upon a string, 99 or 100 in number, which correspond to the names of God in Islam and other recitations. The beads are used to keep track of the number of recitations that make up the dhikr.\n\nWhen the dhikr involves the repetition of particular phrases a specific number of times, the beads are used to keep track so that the person performing dhikr can turn all of their focus on what is actually being said - as it can become difficult to concentrate simultaneously on the number and phrasing when one is doing so a substantial number of times.\n\nIn the United States, Muslim inmates are allowed to utilize prayer beads for therapeutic effects. In Alameen v. Coughlin, 892 F. Supp. 440 (E.D.N.Y 1995), Imam Hamzah S. Alameen, a/k/a Gilbert Henry, and Robert Golden brought suit against Thomas A. Coughlin III, etc., et alia (Head of the Department of Corrections) in the State of New York pursuant to 28 USC @ 1983. The plaintiffs argued that prisoners have a First Amendment Constitutional right to pursue Islamic healing therapy called KASM (قاسَمَهُ | qaasama | taking an oath ) which uses prayer beads. The rosary of oaths, which Alameen developed, was used to successfully rehabilitate inmates suffering from co-occurring mental health challenges and substance abuse issues during the 1990s. All people, including Muslims and Catholics, were allowed to use prayer beads inside prisons, lest their freedom of religion be violated when the prison administration forbade their possession as contraband in the penal system. The practice of carrying prayer beads became controversial when gang-members began carrying specific colors of prayer beads to identify themselves.\n\n\n\n\n"}
{"id": "13698825", "url": "https://en.wikipedia.org/wiki?curid=13698825", "title": "Dialog act", "text": "Dialog act\n\nIn linguistics and in particular in natural language understanding, a dialog act is an utterance, in the context of a conversational dialog, that serves a function in the dialog. Types of dialog acts include a question, a statement, or a request for action. Dialog acts are a type of speech act. \n\nDialog act recognition, also known as spoken utterance classification, is an important part of spoken language understanding. AI inference models or statistical models are used to recognize and classify dialog acts.\n\nA dialog system typically includes a taxonomy of dialog types or \"tags\" that classify the different functions dialog acts can play. One study had 42 types of dialog act in their taxonomy. Examples of types in this study include \"STATEMENT\", \"OPINION\", \"AGREEMENT/ACCEPT\", and \"YES-NO-QUESTION\". \n\nThe research on dialog acts have increased since 1999, after spoken dialog systems became commercial reality.\n"}
{"id": "9785037", "url": "https://en.wikipedia.org/wiki?curid=9785037", "title": "Dictated but not read", "text": "Dictated but not read\n\n\"Dictated but not read\" is a phrase used at the end of a text to warn that the written material has not been personally written or verified by the author. The material may have been dictated to a secretary when the author had no time to proofread or edit it. \n\nThis practice is more common within the medical community, though its appropriateness is still debated.\n\nThe phrase is used to indicate a need for extra care in reading the document so annotated. It may be intended as a disclaimer to limit legal liability.\n\nIt may be used at the end of an article to warn the reader that the written material has not been personally written by the author, who likely dictated it to a secretary, but they did not have the time to write it themselves. Very busy people may be expected to sign off their article with such notation. However, it may be regarded as disrespectful, especially when the writer is deemed not busy.\n\nIt is commonly used to sign off on correspondence where formality takes a backseat to speedy communications, or where such correspondence is routine. When this is not the case, it may be a discourtesy to the recipient of the letter.\n"}
{"id": "599351", "url": "https://en.wikipedia.org/wiki?curid=599351", "title": "Ems Ukaz", "text": "Ems Ukaz\n\nThe Ems Ukaz, or \"Ems Ukase\" (, \"Emskiy ukaz\"; , \"Ems’kyy ukaz\"), was a secret decree (\"ukaz\") of Tsar Alexander II of Russia issued in 1876, banning the use of the Ukrainian language in print, with the exception of reprinting of old documents. The ukaz also forbade the import of Ukrainian publications and the staging of plays or lectures in Ukrainian. It was named after the city of Bad Ems, Germany, where it was promulgated.\n\nIn the 1860s, a decade and a half after the Imperial Russian government had broken up the Brotherhood of Sts Cyril and Methodius in Kiev (March 1847), and exiled or arrested its founder Nikolay Kostomarov and other prominent figures, Ukrainian intellectuals were gaining further awareness of their cultural background. \"Hromada\" cultural associations (named after the traditional village assembly) started in a number of cities, and Sunday schools started in the cities and towns (the Russian Imperial administration had neglected education). The new cultural movement was partly driven by publications in both Russian and Ukrainian, including journals (such as Kostomarov's \"Osnova\", 1861–62, and Hlibov's \"Chernyhosvs’kyy Lystok\", 1861–63), historical and folkloristic monographs (Kostomarov's biography of the Cossack hetman Bohdan Khmelnytsky, Kulish's two-volume folklore collection \"Zapiski o Yuzhnoy Rusi\", \"Notes on Southern Rus\"', 1856–57), and elementary primers (Kulish's \"Hramatka\", 1857, 1861, Shevchenko's \"Bukvar Yuzhnoruskiy\", 1861). In \"Osnova\", Kostomarov published his influential article \"Dve russkiye narodnosti\" (\"Two Russian Nationalities\").\n\nAlthough Ukrainianism had been considered popular and somewhat chic in Russian cultural circles, a debate began at the time over its relation to the ideology of Russian Pan-Slavism—epitomized by a quotation of Pushkin: \"will not all the Slavic streams merge into the Russian sea?\"—and a rhetoric of criticism emerged. Conservative Russians called the Ukrainian movement a \"Polish intrigue\", while Polish commentators had been complaining that Ukrainianism had been used as a weapon against Polish culture in right-bank Ukraine.\n\nAfter the 1861 emancipation of the serfs in the Russian Empire, many landowners were unhappy with the loss of their serfs, while peasants were generally displeased with the terms of the emancipation. In this atmosphere of discontent, increasing reports reached the imperial government that Ukrainian leaders were plotting to separate from Russia. The 1863 January Uprising in Poland raised tensions around the issue of ethnic separatism in general even further. Several Ukrainian activists were arrested, Sunday schools and hromadas were closed and their publication activities were suspended.\n\nA new Ukrainian translation by Pylyp Morachevskyi of parts of the New Testament was vetted and passed by the Imperial Academy of Sciences, but rejected by the Holy Synod of the Russian Orthodox church, because it was considered politically suspect. In response, Interior Minister Count Pyotr Valuyev issued a decree through an internal document circulated to the censors on 18 July 1863, known as Valuyev's Circular. The Circular implemented a policy based on his opinion that \"the Ukrainian language never existed, does not exist, and shall never exist\". It banned the publication of secular and religious books (apart from \"belles-lettres\"), on the premise that not only is the content of such publications potentially questionable, but their very existence implied the anti-imperial idea that a Ukrainian nation could exist.\n\nIn the 1870s, the Kiev Hromada and the South-Western Branch of the Imperial Russian Geographic Society began to publish important works in Kiev, in Russian, about Ukrainian ethnography. Authors included Mykhailo Drahomanov, Volodymyr Antonovych, Ivan Rudchenko, and Pavlo Chubynsky. They held an Archaeological Congress in 1874, and published in the Russian-language paper \"Kievskiy telegraf\".\n\nA member of the Geographic Society, Mikhail Yuzefovich, sent two letters to St Petersburg warning of separatist activity. Tsar Alexander II appointed an Imperial Commission on Ukrainophile Propaganda in the Southern Provinces of Russia, which found evidence of a danger to the state, and recommended extending the scope of the Valuyev decree. While enjoying a spa in Bad Ems, Germany, in May 1876, the Tsar signed what would come to be called the \"Ems Ukaz\", extending the publication ban to apply to all books and song lyrics in the \"Little Russian dialect\", and to prohibit the importation of such materials. Public lectures, plays, and song performances in Ukrainian were forbidden, suspect teachers removed from teaching, and presumably dangerous organizations and newspapers shut down.\n\nThe ukaz coincided with other actions against Ukrainian culture. Drahomanov and fellow activist Mykola Ziber were sacked from their posts at Kiev's University of St Vladimir, and emigrated along with other cultural leaders such as Fedir Vovk and Serhiy Podolynsky. The situation was exposed by professor Mykhailo Drahomanov at the 1878 Paris International Literary Congress.\n\nIn 1881, the new Tsar Alexander III amended the ukaz. Ukrainian lyrics and dictionaries would be allowed, but the \"Kulishivka\" Ukrainian alphabet was still prohibited, and such publications would have to employ Russian orthography (disparagingly called the \"Yaryzhka\" by some Ukrainians, after the Russian letter yery, ы). Performance of Ukrainian plays and humorous songs could be approved by local authorities, but Ukrainian-only theatres and troupes could not be established.\n\nMany illegal performances and publications were delivered through ingenuity and bribery, but Ukrainian cultural development practically ceased.\n\nAfter the Russian Revolution of 1905, the Imperial Academy of Sciences recommended that the ukaz's restrictions be lifted. Ukrainian-language newspapers began publication, \"Prosvita\" (‘Enlightenment’) educational societies were formed, some university professors lectured in Ukrainian, and the Orthodox bishop of the Podolia vicariate, Parfeniy Levytsky, allowed the language to be used in services and church schools there.\n\nIn 1910, concerned about potential revolutionary activity, Interior Minister Pyotr Stolypin restored the ukaz's restrictions and shut down the Prosvita societies and Ukrainian-language publications. Russian-language press and intellectuals launched a campaign against the idea of Ukrainian autonomy or separatism.\n\nThus, self-aware Ukrainians remained a small intelligentsia in Dnieper Ukraine, out of touch with a much larger rural population who lacked the opportunity for a cultural education. Russian imperial ideology dominated the schools and the army, and the Russian language was the only one used for official business in the urban workplace, government offices, and public services. In the meantime, Ukrainian self-identity would grow in Austro-Hungarian Galicia, out of reach of Russian imperial authorities.\n\nThe ukaz was never cancelled, but became void along with all other imperial Russian laws in the February Revolution of 1917–18. After the Revolution, Ukrainian language, education and culture was allowed to flower in the Ukrainian National Republic, the Hetmanate, and under the policies of Soviet Ukraine before 1931.\n\nExcerpts from the Ukaz:\n\n\n"}
{"id": "53445822", "url": "https://en.wikipedia.org/wiki?curid=53445822", "title": "English surnames of Norman origin", "text": "English surnames of Norman origin\n\nSome family names contain clues as to their origin, like English surnames of Norman Origin. William, Duke of Normandy, successfully invaded England in 1066, and this invasion left a lasting legacy in the English language, in general, and in surnames, in particular. \n\nAccording to Christopher Daniell, in \"From Norman Conquest to Magna Carta\", 1140 marked what might be the first recorded use of a modern surname, inherited by multiple generations. The sons of a Norman named Robert used a modern inheritable surname, \"FitzGerald\", in honour of an earlier relative, named \"Gerald\".\n\nAccording to Joslin Fiennes's \"Origins of English surnames\" modern surnames were not used until the fourteenth century:\nBeginning in the late 1500s and peaking in the wake of the Edict of Fontainebleau (1685), French Protestant refugees from France, the Huguenots, brought surnames like Dubarry, Duhamel and Dupuy, from Normandy, into the English namespace, when the historical record shows these names had not been present prior to the fifteenth century.\n\n"}
{"id": "13989289", "url": "https://en.wikipedia.org/wiki?curid=13989289", "title": "Etymologicum Magnum", "text": "Etymologicum Magnum\n\nEtymologicum Magnum (, \"Ἐtymologikὸn Mέga\") (standard abbreviation EM, or Etym. M. in older literature) is the traditional title of a Greek lexical encyclopedia compiled at Constantinople by an unknown lexicographer around 1150 AD. It is the largest Byzantine lexicon and draws on many earlier grammatical, lexical and rhetorical works. Its main sources were two previous \"etymologica\", the so-called \"Etymologicum Genuinum\" and the \"Etymologicum Gudianum\". Other sources include Stephanus of Byzantium, the \"Epitome\" of Diogenianus, the so-called \"Lexicon\" Αἱμωδεῖν (\"Haimōdeῖn\"), Eulogius’ Ἀπορίαι καὶ λύσεις (\"Ἀporίai kaὶ lύseis\"), George Choeroboscus’ \"Epimerismi ad Psalmos\", the \"Etymologicon\" of Orion of Thebes, and collections of \"scholia\". The compiler of the \"Etymologicum Magnum\" was not a mere copyist; rather he amalgamated, reorganised, augmented and freely modified his source material to create a new and individual work.\n\nThe \"editio princeps\" of the \"Etymologicum Magnum\" was published by Zacharias Kallierges and Nikolaos Vlastos under the patronage of Anna Notaras at Venice in 1499. The typeface was designed and cut by Kallierges, modeled on his own handwriting. The decorative initial letters and headpieces are patterned on the decorations of the Byzantine manuscript tradition, and the woodcut borders incorporate elaborate arabesque designs, usually colored white on red, but also white on gold. The decorations of the Kallierges edition had a great influence in printing, especially on Greek liturgical books.\n\nThe most recent complete edition is by Thomas Gaisford (Oxford 1848). A new (uncompleted) edition is in preparation by F. Lasserre and N. Livadaras (under the title \"Etymologicum Magnum Auctum\").\n\n\n"}
{"id": "58617", "url": "https://en.wikipedia.org/wiki?curid=58617", "title": "Fact", "text": "Fact\n\nA fact is something that is consistent with objective reality or that can be proven with evidence. The usual test for a statement of fact is verifiability — that is whether it can be demonstrated to correspond to experience. Standard reference works are often used to check facts. Scientific facts are verified by repeatable careful observation or measurement by experiments or other means.\n\nThe word \"fact\" derives from the Latin \"factum\", and was first used in English with the same meaning: \"a thing done or performed\" a meaning now obsolete. The common usage of \"something that has really occurred or is the case\" dates from the middle of the sixteenth century.\n\nFact is sometimes used synonymously with \"truth\", as distinct from opinions, falsehoods, or matters of taste. This use is found in such phrases as, \"It is a fact that the cup is blue\" or \"Matter of fact\", and \"... not history, nor fact, but imagination.\" Filmmaker Werner Herzog distinguishes between the two, claiming that \"Fact creates norms, and truth illumination.\"\n\nFact also indicates a \"matter under discussion\" deemed to be true or correct, such as to emphasize a point or prove a disputed issue; (e.g., \"... the \"fact\" of the matter is ...\").\n\nAlternatively, \"fact\" may also indicate an \"allegation or stipulation\" of something that may or may not be a \"true fact\", (e.g., \"the author's facts are not trustworthy\"). This alternate usage, although contested by some, has a long history in standard English.\n\nFact may also indicate findings derived through a \"process of evaluation\", including review of testimony, direct observation, or otherwise; as distinguishable from matters of inference or speculation. This use is reflected in the terms \"fact-find\" and \"fact-finder\" (e.g., \"set up a fact-finding commission\").\n\nFacts may be checked by reason, experiment, personal experience, or may be argued from authority. Roger Bacon wrote \"If in other sciences we should arrive at certainty without doubt and truth without error, it behooves us to place the foundations of knowledge in mathematics.\"\n\nIn philosophy, the concept \"fact\" is considered in epistemology and ontology. Questions of objectivity and truth are closely associated with questions of fact. A \"fact\" can be defined as something that is the case—that is, a state of affairs.\n\nFacts may be understood as information that makes a true sentence true. Facts may also be understood as those things to which a true sentence refers. The statement \"Jupiter is the largest planet in the solar system\" is \"about\" the fact Jupiter is the largest planet in the solar system.\n\nPascal Engel's version of the correspondence theory of truth explains that what makes a sentence true is that it \"corresponds\" to a fact.\nThis theory presupposes the existence of an objective world.\n\nThe Slingshot argument claims to show that all true statements stand for the same thing - the truth value \"true\". If this argument holds, and facts are taken to be what true statements stand for, then we reach the counter-intuitive conclusion that there is only one fact - \"the truth\".\n\nAny non-trivial true statement about reality is necessarily an abstraction composed of a complex of objects and properties or relations. For example, the fact described by the true statement \"Paris is the capital city of France\" implies that there is such a place as Paris, there is such a place as France, there are such things as capital cities, as well as that France has a government, that the government of France has the power to define its capital city, and that the French government has chosen Paris to be the capital, that there is such a thing as a \"place\" or a \"government\", and so on. The verifiable accuracy of all of these assertions, if facts themselves, may coincide to create the fact that Paris is the capital of France.\n\nDifficulties arise, however, in attempting to identify the constituent parts of negative, modal, disjunctive, or moral facts.\n\nMoral philosophers since David Hume have debated whether values are objective, and thus factual. In \"A Treatise of Human Nature\" Hume pointed out there is no obvious way for a series of statements about what \"ought\" to be the case to be derived from a series of statements of what \"is\" the case. Those who insist there is a logical gulf between facts and values, such that it is fallacious to attempt to derive values from facts, include G. E. Moore, who called attempting to do so the naturalistic fallacy.\n\nFactuality—what has occurred—can also be contrasted with counterfactuality:\nwhat \"might have\" occurred, but did not. A counterfactual conditional or subjunctive conditional is a conditional (or \"if-then\") statement indicating what \"would be\" the case if events had been other than they were. For example, \"If Alexander had lived, his empire would have been greater than Rome.\" This contrasts with an indicative conditional, which indicates what \"is\" (in fact) the case if its antecedent \"is\" (in fact) true—for example, \"If you drink this, it will make you well.\"\n\nSuch sentences are important to modal logic, especially since the development of possible world semantics.\n\nIn science, a \"fact\" is a repeatable careful observation or measurement (by experimentation or other means), also called empirical evidence. Facts are central to building scientific theories. Various forms of observation and measurement lead to fundamental questions about the scientific method, and the scope and validity of scientific reasoning.\n\nIn the most basic sense, a scientific \"fact\" is an objective and verifiable observation, in contrast with a \"hypothesis\" or \"theory\", which is intended to explain or interpret facts.\n\nVarious scholars have offered significant refinements to this basic formulation. Scientists are careful to distinguish between: 1) \"states of affairs\" in the external world and 2) \"assertions\" of fact that may be considered relevant in scientific analysis. The term is used in both senses in the philosophy of science.\n\nScholars and clinical researchers in both the social and natural sciences have written about numerous questions and theories that arise in the attempt to clarify the fundamental nature of scientific fact. Pertinent issues raised by this inquiry include:\n\nConsistent with the idea of confirmation holism, some scholars assert \"fact\" to be necessarily \"theory-laden\" to some degree. Thomas Kuhn points out that knowing what facts to measure, and how to measure them, requires the use of other theories. For example, the age of fossils is based on radiometric dating, which is justified by reasoning that radioactive decay follows a Poisson process rather than a Bernoulli process. Similarly, Percy Williams Bridgman is credited with the methodological position known as operationalism, which asserts that all observations are not only influenced, but necessarily defined by the means and assumptions used to measure them.\n\nApart from the fundamental inquiry into the nature of scientific fact, there remain the practical and social considerations of how fact is investigated, established, and substantiated through the proper application of the scientific method. Scientific facts are generally believed independent of the observer: no matter who performs a scientific experiment, all observers agree on the outcome.\nIn addition to these considerations, there are the social and institutional measures, such as peer review and accreditation, that are intended to promote \"factual accuracy\" (among other interests) in scientific study.\n\nA common rhetorical cliché states, \"History is written by the winners.\" This phrase suggests but does not examine the use of facts in the writing of history.\n\nE. H. Carr in his 1961 volume \"What is History?\" argues that the inherent biases from the gathering of facts makes the objective truth of any historical perspective idealistic and impossible. Facts are, \"like fish in the Ocean,\" of which we may only happen to catch a few, only an indication of what is below the surface. Even a dragnet cannot tell us for certain what it would be like to live below the Ocean's surface. Even if we do not discard any facts (or fish) presented, we will always miss the majority; the site of our fishing, the methods undertaken, the weather and even luck play a vital role in what we will catch. Additionally, the composition of history is inevitably made up by the compilation of many different biases of fact finding - all compounded over time. He concludes that for a historian to attempt a more objective method, one must accept that history can only aspire to a conversation of the present with the past - and that one's methods of fact gathering should be openly examined. Historical truth and facts therefore change over time, and reflect only the present consensus (if that).\n\nIn most common law jurisdictions, the general concept and analysis of fact reflects fundamental principles of jurisprudence, and is supported by several well-established standards. Matters of fact have various formal definitions under common law jurisdictions.\n\nThese include:\n\n\n\nA party to a civil suit generally must clearly state all relevant allegations of fact that form the basis of a claim. The requisite level of precision and particularity of these allegations varies, depending on the rules of civil procedure and jurisdiction. Parties who face uncertainties regarding facts and circumstances attendant to their side in a dispute may sometimes invoke alternative pleading. In this situation, a party may plead separate sets of facts that (when considered together) may be contradictory or mutually exclusive. This (seemingly) logically-inconsistent presentation of facts may be necessary as a safeguard against contingencies (such as \"res judicata\") that would otherwise preclude presenting a claim or defense that depends on a particular interpretation of the underlying facts.\n\n"}
{"id": "47665171", "url": "https://en.wikipedia.org/wiki?curid=47665171", "title": "Feminist language reform", "text": "Feminist language reform\n\nFeminist language reform or feminist language planning refers to the effort, often of political and grassroots movements, to change how language is used to gender people, activities and ideas on an individual and societal level. This initiative has been adopted in countries such as Sweden, Switzerland and Australia, and has been tentatively linked to higher gender equality.\n\nLinguistic activism and feminist authorship stemming from second wave feminism in the 1960s and 70s began to draw attention to gender bias in language, including \"the uncovering of the gendered nature of many linguistic rules and norms\". Scholarship such as Dennis Baron's \"Grammar and Gender\" and Anne Bodine's \"Androcentrism in Prescriptive Grammar\" uncovered historical male regulation to promote male-centric language such as the use of \"he\" as a generic pronoun.\n\nExposition and analysis of sexism in language through a grassroots feminist linguistics movement continued throughout the 80's and 90's, including study across languages and speech communities such as Germany and France. Study and documentation of gendered language has since spread to cover over 30 languages.\n\nFeminist language planning has more recently been instituted centrally in countries such as Sweden, Switzerland and Australia, with mixed results.\n\nSweden have made strides towards shifting their language to fit a less misogynistic society. In the Swedish language, there has never been a word for the female genitalia or even a translation of the word “vagina”, even though the word \"snopp\" translates to “penis” and has been used as such since the 1960s. Through history, there have been many slang terms used for the woman’s genitalia, including words such as \"fitta\" translated to “cunt”, \"där nere\" translated to “down-there”, and even \"mus\" translated to “mouse”. In the 1990s, Swedish media started to bring the absence of such a word to light. It wasn’t until the early 2000s did the feminists and activists start using the word \"snippa\" to be identified with the female genitalia. \"Snippa\"’s origins can be traced back to many different Swedish dialects. It’s popular definition “refers to something small and/or narrow, for example a small pike or a narrow boat”. In regards to genitalia, “it might have been used to refer to female genitalia of cows and pigs in the early twentieth century”. Since the popularization of using the word \"Snippa,\" the Swedish Academy added the word to the 2006 Swedish Language Dictionary.\n\nSome language reformers directly work with identifying and changing sexist undertones and patriarchal vocabulary through a method called “linguistic disruption”. An example: In the United States, the word “herstory” became popularized “to refer to history which is not only about men”. Sweden has also showed efforts in language planning regarding changing misogynistic undertones in their vocabulary. The Swedish Association for Sexuality Education has promoted the word \"slidkrans\" to replace the word for “hymen”, \"mödomshinna.\" “The new word, \"slidkrans\", is made up of the two parts \"slid\", translating to “vaginal” and \"krans\", translating to “garland”. It lacks the connotations of the ideology of virginity and honour attached to mödomshinna.”\n\nAdditionally, Sweden has also shown efforts in accepting more of a non-gender binary identity by creating the gender-neutral pronoun \"hen,\" which has been used by feminists and the LGBT community. Feminist language reform regarding gender is not of recent efforts. Early feminist language reformists have been fighting the male-dominant approach to language and raising awareness to the public about the gendered structure of the society’s language.\n\nAustralia has been identified as a nation that officially promotes the feminist influence to its public bureaucracy by implementing feminist language reform across many institutions. Since this planned social shift, Australia has seen changes in political and government leadership that aim to interfere with this reform, such as a shift towards a conservative-leaning government. There are shifts that come from such movements that support them as well, such as the gender-neutral pronoun “they” being more widely accepted.\n\nThe ongoing feminist movement acknowledges language as a “powerful instrument of patriarchy”. The goals set for linguistic reform aim to achieve linguistic equality of the sexes. A study of Australian newspapers from 1992 and 1996 found that the word “chairman” was used to describe all people holding the position, including women. This is an example of a linguistic issue that feminist’s seek to reform. Occupational nomenclature reflects gender bias when “professional nomenclature used in employment-related contexts displays bias in favour of men leading to women’s invisibility in this area.” The invisibility of women is a linguistic feminist issue because when encountering sentences predominantly using male pronouns, listeners are more likely to think of men before women and therefore women get overlooked. Positions are gendered to be male and the “continuing, frequent use reflects the fact that far more men than women continue to occupy this position.” This study further investigated and found instances of female professionals being specified as women while men would just be titled with the profession itself, for example “female judge,” “woman engineer,” and “woman politician.”\n\nSwitzerland has attempted to implement feminist language reform both formally and informally. However, changes in Switzerland have proven to be complicated due to the fact that Switzerland is a multilingual country (with the major languages being German, French, and Italian). The Bulletin Suisse de Linguistique Appliquée (Swiss Bulletin of Applied Linguistics) addressed this issue in 2000 when it created a special issue dedicated to the feminization of language in Switzerland. The bulletin attempted to critique language in Switzerland by creating a composite image of all the languages in Switzerland and how they interact with gender.\n\nThe most commonly spoken language in Switzerland is German. German is a gendered language. This has concerned some language activists due to the fact that many important societal position such as judge and professor possess the gender of male and are often referred to as he/him. Activists worry that the gendering of those words discourage women from entering those fields. This facet of the German language is particularly important in Switzerland because it was historically used as a justification to restrict women’s right to vote and pass the bar.\n\nVarious attempts to implement feminist language reform have been undertaken in German speaking Switzerland. The government and other organizations have attempted to implement language feminization in the realms of policy making, teaching, advertising, etc. Language feminization refers to when in writing or talking traditional male words are feminized by either using the feminine variant of the word or adding a feminine suffix. However, these attempts have had only limited success. For example, private Swiss radio and television broadcasts still generally use the generic-masculine form of words.\n\nThe second most commonly spoken language in Switzerland is French which is also a gendered language. The French language raises similar concerns to that of the German language. This is because many nouns (especially those of professions) are gendered. To address these concerns, the Swiss government has created a guide on the non-sexist use of the French language. However, these attempts at change have been met with little success. This is due to the fact that Switzerland has limited influence over the French language. Meanwhile, France and specifically the government backed Académie Française (French Academy) (the French council for matters relating to the French language) has resisted feminist language reform.\n\nThe main focus of Feminist Language Reform is to acknowledge the often unconscious ways that language both silences and emphasizes gender in negative ways. In some languages it is clear with gendered nouns how some words are gendered to associate those words with maleness of femaleness. Feminist Philosophers argue that English, a non gendered language, still has the need for Language Reform.\n\nPrevious language reform attempts to avoid sexist words or phrases were addressed in a symptomatic manner. Often in the workplace, employees were given pamphlets with lists of words to avoid or preferred words to use. Many modern day feminists argue that this is ineffective because it does not address the root of the problem or make the large scale changes to the language that they feel are necessary.\n\nA major part of the theory focuses on when words or phrases make one gender, typically women, subjugated or invisible compared to the other. The most popular examples are the pronoun “he” or the word “man”. Feminist Language Philosophers argue that these words participate in making women invisible by having them being used to refer to men and also women. The fact that the pronouns or words for the male gender can be also used to refer to the female gender shows how maleness is dominant and femaleness is subjugated.\n\nFeminist Language Theory also focuses on when words or phrases emphasize a break in gender norms. Clear examples of this are words like Lady Doctor or Manageress. These are positions of power that are typically held by men. Therefore, when a woman holds them, they need a new title to emphasize their break of social norm. It also goes both ways, with terms like male nurse referring to a man in a typically feminine role. Feminist Language Reform seeks to remove words like this because they help to sustain unhealthy gender norms.\n\nSome modern feminists, like Sergio Bolaños Cuellar, argue that feminist language reforms needs to reverse the generic masculine forms and create a generic feminine form with words like he or man being replaced with she or woman.\n\nCases of feminist language planning have taken a largely sociolinguistic approach in which the goal is to enact social change through the reform of language and language use. This approach to language planning is divided into four stages:\n\n\n\n"}
{"id": "6503287", "url": "https://en.wikipedia.org/wiki?curid=6503287", "title": "Fix-up", "text": "Fix-up\n\nA fix-up (or fixup) is a novel created from several short fiction stories that may or may not have been initially related or previously published. The stories may be edited for consistency, and sometimes new connecting material, such as a frame story or other interstitial narration, is written for the new work. The term was coined by the science fiction writer A. E. van Vogt, who published several fix-ups of his own, including \"The Voyage of the Space Beagle\", but the practice (if not the term) exists outside of science fiction. The use of the term in science fiction criticism was popularised by the first (1979) edition of the \"Encyclopedia of Science Fiction\", edited by Peter Nicholls, which credited Van Vogt with the creation of the term.\nThe name comes from the modifications that the author needs to make in the original texts to make them fit together as though they were a novel. Foreshadowing of events from the later stories may be jammed into an early chapter of the fix-up, and character development may be interleaved throughout the book. Contradictions and inconsistencies between episodes are usually worked out.\n\nSome fix-ups in their final form are more of a short story cycle or composite novel rather than a traditional novel with a single main plotline. Examples are Ray Bradbury's \"The Martian Chronicles\" and Isaac Asimov's \"I, Robot\", both of which read as a series of short stories which may share plot threads and characters but which still act as self-contained stories. By contrast, van Vogt's \"The Weapon Shops of Isher\" is structured like a continuous novel although it incorporates material from three previous Van Vogt short stories.\n\nFix-ups became an accepted practice in the 1950s, when science fiction and fantasy—once published only in magazines—began appearing in book form. Large book publishers like Doubleday and Simon & Schuster entered the market, greatly increasing demand for fiction. Authors created new manuscripts from old stories to sell to publishers. Algis Budrys in 1965 described fixups as a consequence of the lack of good supply during the \"bad years for quality\" of the mid-1950s, although citing \"The Martian Chronicles\" and Clifford D. Simak's \"City\" as among exceptions.\n\n\n\n\n \n"}
{"id": "37125418", "url": "https://en.wikipedia.org/wiki?curid=37125418", "title": "Hopi time controversy", "text": "Hopi time controversy\n\nThe Hopi time controversy is the academic debate about how the Hopi language grammaticalizes the concept of time, and about whether the differences between the ways the English and Hopi languages describe time are an example of linguistic relativity or not. In popular discourse the debate is often framed as a question about whether the Hopi \"had a concept of time\", despite it now being well established that they do.\n\nThe debate originated in the 1940s when American linguist Benjamin Lee Whorf argued that the Hopi conceptualized time differently from the Standard Average European speaker, and that this difference correlated with grammatical differences between the languages. Whorf argued that Hopi has \"no words, grammatical forms, construction or expressions that refer directly to what we call 'time'\", and concluded that the Hopi had \"no general notion or intuition of time as a smooth flowing continuum in which everything in the universe proceeds at equal rate, out of a future, through the present, into a past\". Whorf used the Hopi concept of time as a primary example of his concept of linguistic relativity, which posits that the way in which individual languages encode information about the world, influences and correlates with the cultural world view of the speakers. Whorf's relativist views fell out of favor in linguistics and anthropology in the 1960s, but Whorf's statement lived on in the popular literature often in the form of an urban myth that \"the Hopi have no concept of time\". In 1983 linguist Ekkehart Malotki published a 600-page study of the grammar of time in the Hopi language, concluding that he had finally refuted Whorf's claims about the language. Malotki's treatise gave hundreds of examples of Hopi words and grammatical forms referring to temporal relations. Malotki's central claim was that the Hopi do indeed conceptualize time as structured in terms of an ego-centered spatial progression from past, through present into the future. He also demonstrated that the Hopi language grammaticalizes tense using a distinction between future and non-future tenses, as opposed to the English tense system, which is usually analyzed as being based on a past/non-past distinction. Many took Malotki's work as a definitive refutation of the linguistic relativity hypothesis. Linguist and specialist in the linguistic typology of tense Bernard Comrie concluded that \"Malotki's presentation and argumentation are devastating\". Psychologist Steven Pinker, a well-known critic of Whorf and the concept of linguistic relativity, accepted Malotki's claims as having demonstrated Whorf's complete ineptitude as a linguist.\n\nSubsequently the study of linguistic relativity was revived using new approaches in the 1990s, and Malotki's study came under criticism from relativist linguists and anthropologists, who did not consider that the study invalidated Whorf's claims. The main issue of contention is the interpretation of Whorf's original claims about Hopi, and what exactly it was that he was claiming made Hopi different from what Whorf called \"Standard Average European\" languages. Some consider that the Hopi language may be best described as a tenseless language, and that the distinction between non-future and future posited by Malotki may be better understood as a distinction between \"realis\" and \"irrealis\" moods. Regardless of exactly how the Hopi concept of time is best analyzed, most specialists agree with Malotki that all humans conceptualize time by an analogy with space, although some recent studies have also questioned this.\n\nThe Hopi language is a Native American language of the Uto-Aztecan language family, which is spoken by some 5,000 Hopi people in the Hopi Reservation in Northeastern Arizona, US.\n\nIn the large \"\" there is no word exactly corresponding to the English noun \"time\". Hopi employs different words to refer to \"a duration of time\" (\"pàasa\"' \"for that long\"), to a point in time (\"pàasat\" \"at that time\"), and time as measured by a clock (\"pahàntawa\"), as an occasion to do something (\"hisat\" or \"qeni\"), a turn or the appropriate time for doing something (\"qeniptsi\" (noun)), and to have time for something (\"aw nánaptsiwta\" (verb)).\n\nTime reference can be marked on verbs using the suffix \"-ni\"\n\nThe -ni suffix is also used in the word \"naatoniqa\" which means \"that which will happen yet\" in reference to the future. This word is formed from the adverb \"naato\" \"yet\", the \"-ni\" suffix and the clitic -qa that forms a relative clause with the meaning \"that which...\".\n\nThe -\"ni\" suffix is also obligatory on the main verb in conditional clauses:\n\nThe suffix is also used in conditional clauses referring to a past context then often combined with the particle \"as\" that carries past tense or counterfactual meaning, or describes unachieved intent:\n\nThe suffix \"-ngwu\" describes actions taking place habitually or as a general rule.\n\nBenjamin Lee Whorf (1897–1941), a fire prevention engineer by profession, studied Native American linguistics from an early age. He corresponded with many of the greatest scholars of his time, such as Alfred Tozzer at Harvard and Herbert Spinden of the American Museum of Natural History. They were impressed with his work on the linguistics of the Nahuatl language and encouraged him to participate professionally and to undertake field research in Mexico. In 1931 Edward Sapir, the foremost expert on Native American languages, started teaching at Yale, close to where Whorf lived, and Whorf signed up for graduate-level classes with Sapir, becoming one of his most respected students. Whorf took a special interest in the Hopi language and started working with Ernest Naquayouma, a speaker of Hopi from Toreva village on the Second Mesa of the Hopi Reservation in Arizona, who was living in the Manhattan borough of New York City. At this time it was common for linguists to base their descriptions of a language on data from a single speaker. Whorf credited Naquayouma as the source of most of his information on the Hopi language, although in 1938 he took a short field trip to the village of Mishongnovi on the Second Mesa, collecting some additional data.\n\nWhorf published several articles on Hopi grammar, focusing particularly on the ways in which the grammatical categories of Hopi encoded information about events and processes, and how this correlated with aspects of Hopi culture and behavior. After his death his full sketch of Hopi grammar was published by his friend the linguist Harry Hoijer, and some essays on Native American linguistics, many of which had been previously published in academic journals, were published in 1956 in the anthology \"Language, Thought, and Reality\" by his friend psychologist John Bissell Carroll.\n\nWhorf's most frequently cited statement regarding Hopi time is the strongly worded introduction of his 1936 paper \"An American Indian model of the Universe\", which was first published posthumously in Carroll's edited volume. Here he writes that\n\nWhorf argues that in Hopi units of time are not represented by nouns, but by adverbs or verbs. Whorf argues that all Hopi nouns include the notion of a boundary or outline, and that consequently the Hopi language does not refer to abstract concepts with nouns. This, Whorf argues, is encoded in Hopi grammar, which does not allow durations of time to be counted in the same way objects are. So instead of saying, for example, \"three days\", Hopi would say the equivalent of \"on the third day\", using ordinal numbers. Whorf argues that the Hopi do not consider the process of time passing to produce another new day, but merely as bringing back the daylight aspect of the world.\n\nWhorf gives slightly different analyses of the grammatical encoding of time in Hopi in his different writings. His first published writing on Hopi grammar was the paper \"The punctual and segmentative aspects of verbs in Hopi\", published in 1936 in \"Language\", the journal of the Linguistic Society of America. Here Whorf analyzed Hopi as having a tense system with a distinction between three tenses: one used for past or present events (which Whorf calls the \"Factual\" tense or \"present-past\"); one for future events; and one for events that are generally or universally true (here called \"usitative\"). This analysis was repeated in a 1937 letter to J. B. Carroll, who later published it as part of his selected writings under the title \"Discussion of Hopi Linguistics\".\n\nIn the 1938 paper \"Some verbal categories of Hopi\", also published in \"Language\", Whorf abandoned the word \"tense\" in the description of Hopi and described the distinction previously called \"tense\" with the label \"assertions\". Whorf described assertions as a system of categories that describe the speaker's claim of epistemic validity of his own statement. The three \"assertions\" of Hopi described by Whorf are the \"Reportive\", \"Expective\" and \"Nomic\" forms of the Hopi verb. Whorf acknowledges that these \"translate more or less [as] the English tenses\", but maintains that these forms do not refer to time or duration, but rather to the speaker's claim of the validity of the statement. The reportive form is unmarked, whereas the expective form is marked with the verbal suffix \"-ni\", and the nomic form with the suffix \"-ŋʷi\". In Whorf's analysis, by using the reportive form the speaker claims that the event has in fact occurred or is still occurring, whereas by using the expective form the speaker describes an expectation of a future event. Whorf says that the expective can be used to describe events in the past, giving the meaning of \"was going to\" or \"would\".\n\nIn the 1940 article \"Science and Linguistics\", Whorf gave the same three-way classification based on the speaker's assertion of the validity of his statement: \"The timeless Hopi verb does not distinguish between the present, past and future of the event itself but must always indicate what type of validity the intends the statement to have: a. report of an event .. b. expectation of an event ..; generalization or law about events.\"\n\nIn his full sketch of Hopi grammar published posthumously in 1946, Whorf also described how adverbial particles contributed to the linguistic description of time in Hopi. He posited two subclasses of adverbs called \"temporals\" and \"tensors\", which were used in sentences to locate events in time. A central claim in Whorf's work on linguistic relativity was that for the Hopi units of time were not considered objects that can be counted like most of the comparable English words that are described by nouns (\"a day\", \"an hour\" etc.). He argued that only the Hopi word for \"year\" was a noun, the words for days and nights were ambivalent between noun and verbs, but that all other cyclic events and periods were described by adverbial particles used as modifiers for the sentence \nIn his interpretation of Hopi time Whorf was influenced by Einstein's theory of relativity, which was developed in the first decades of the century and impacted the general Zeitgeist. Whorf, an engineer by profession, in fact made occasional reference to physical relativity, and he adopted the term \"linguistic relativity,\" reflecting the general concept of the different but equally valid interpretations of some aspects of physical reality by different observers due to differences in their (for Einstein) physical circumstances or (for Whorf) their psychological-linguistic circumstances.\n\nThe most salient points involve the concepts of \"simultaneity\" and \"spacetime\". In his 1905 Special Relativity paper, Einstein maintained that two given events can legitimately be called simultaneous if and only if they take place at the same point in time and in the same point in space. No two events which take place at a spatial distance from one another can legitimately be declared to be simultaneous in any absolute sense, for the judgement of simultaneity or non-simultaneity will depend on the physical circumstances (to be exact: the relative motion) of the observers. This difference is no artifact; each of the observers is correct (and is wrong only to the extent he or she insists that another observer is incorrect).\n\nHermann Minkowski, in his seminal 1908 address to the Congress of German Physicists, translated Einstein's 1905 mathematical equations into geometric terms. Minkowski famously declared:\n\n\"Henceforth space by itself, and time by itself, are doomed to fade away into mere shadows, and only a kind of union of the two will preserve an independent reality.\"\n\nSpatial distance and temporal distance between any two events was now replaced by a single absolute distance in spacetime.\n\nHeynick points to several passages in Whorf's writings on the Hopis which parallel Einsteinian concepts such as:\n\n\"time varies with each observer and does not permit of simultaneity\" (1940)\n\n\"The Hopi metaphysics does not raise the question whether the things at a distant village exist at the same moment as those in one's own village, for it ... says that any 'events' in the distant village can be compared to any events in one's own village only by an interval of magnitude that has both time and space forms in it.\" (c.1936) \n\nThe concept of a \"simultaneous now\" throughout the cosmos was formulated by Aristotle, Newton, and most succinctly in John Locke's \"Essay Concerning Human Understanding\" (1690):\n\n\"For this moment is common to all things that are now in being ... they all exist in the same moment of time.\"\n\nWhorf saw this notion as derived from the Standard Average European languages in which these thinkers thought: \"Newtonian space, time, and matter are no intuitions. They are recepts from culture and language. That is where Newton got them.\"\n\nHeynick, who claimed no personal knowledge of the Hopi language, posits alternative weaker and stronger interpretations of the influence of Einsteinian relativity on Whorf's analysis of the Hopi language and the Hopi concept of time. In the weaker version, the (then) new questioning of the nature of time and space brought about by the Einsteinian revolution in physics enabled Whorf to approach the Hopis and their language unburdened by traditional Western concepts and presumptions. The stronger version is that Whorf under the influence of Einstein tended inadvertently to \"read into\" his linguistic and cultural data relativistic concepts where they perhaps were not.\n\nWhorf died in 1941, but his ideas took on their own life in academia and in the popular discourse on Native Americans. In 1958 Stuart Chase—an economist and engineer at MIT who had followed Whorf's ideas with great interest, but whom Whorf himself considered utterly incompetent and incapable of understanding the nuances of his ideas—published \"Some things worth knowing: a generalist's guide to useful knowledge\". Here he repeated Whorf's claim about Hopi time, but arguing that because of the Hopi view of time as a process, they were better able to understand the concept of time as a fourth dimension. Similarly, even scientists were intrigued by the thought that the idea of spatio-temporal unity that had taken Albert Einstein seven years to ponder, was readily available to the Hopi, simply because of the grammar of their language.\n\nIn 1964 John Greenway published a humorous portrait of American culture, \"The Inevitable Americans\", in which he wrote: \"You have a watch, because Americans are obsessed with time. If you were a Hopi Indian, you would have none, the Hopi have no concept of time\". And even the 1971 ethnography of the Hopi by Euler and Dobyns claimed that \"The English concept of time is nearly incomprehensible to the Hopi\". The myth quickly became a staple element of New Age conceptualizations of the Hopi.\n\nIn 1959 philosopher Max Black published a critique of Whorf's arguments in which he argued that the principle of linguistic relativity was obviously wrong because translation between languages is always possible, even when there are no exact correspondences between the single words or concepts in the two languages.\n\nGerman linguist and philosopher Helmut Gipper had studied with the neo-Humboldtian linguist Leo Weisgerber and had a basically Kantian understanding of the relation between language and thought. Immanuel Kant considered the categories of time and space to be universals underlying all human thinking. Whorf's argument that the Hopi do not conceive of time and space as speakers of Indo-European languages do clashed with this basic understanding of cognition. Gipper went to the Hopi reservation to collect data for a general critique of Whorf's principle of linguistic relativity published in 1972. His critique included a refutation of Whorf's Hopi arguments. Gipper showed that the Hopi could refer to time, by juxtaposing Hopi phrases with their German equivalents that used words referring to units of time and to distinctions between past and present. Gipper also argued that several time intervals were described by nouns, and that these nouns could take the role of syntactic subject or object, in contradiction of Whorf's explicit statement. He argues that Whorf's assertion that intervals of time are not counted in the same way as objects is \"questionable\".\n\nEkkehart Malotki studied with Gipper at the Westfälische Wilhelms-Universität at Münster and his work was a continuation of his mentor's, spurred on by the frequent claims in the popular literature that \"the Hopi have no concept of time\". Malotki conducted four years of research on the Third Mesa, studying Hopi spatial and temporal reference. He published two large volumes, one in German, \"Hopi-Raum\" [Hopi space] and one in English, \"Hopi Time\". For Malotki it was imperative to demonstrate two facts in contradiction of Whorf's claims: 1. that the Hopi language has an abundance of terms, words and constructions that refer to time. 2. that the Hopi do cognitively conceptualize time in analogy with physical space, using spatial metaphors to describe durations and units of time. He also wanted to demonstrate that Whorf misanalyzed several particularities regarding specific Hopi words and expressions. Malotki states that a main goal is to present \"actual Hopi language data\", since when he was writing very little textual data in Hopi had been published, and Whorf's publications were largely without text examples.\n\nMost of \"Hopi Time\" is dedicated to the detailed description of the Hopi usage of words and constructions related to time. Malotki describes in detail the usage of a large amount of linguistic material: temporal adverbs, time units, time counting practices such as the Hopi calendar, the way that days are counted and time is measured.\n\nThe first part of the book describes \"spatio-temporal metaphors\"; in it he shows several deictic adverbs that are used both to reference distance in space and in time, such as the word \"ep\" that means both \"there\" and \"then\". In the second chapter he describes the way in which the Hopi talk about units of time. He argues that in some contexts, specifically those of the ceremonial cycle, the Hopi do count days, using compound words such as \"payistala\" \"the third day (of a ceremony)\" composed of the morphemes \"paayo\" \"three\", \"s\" \"times\" and \"taala\"' \"day/light\", meaning literally \"three-times-day\". He also shows that the Hopi reckon time through the movement of the sun, having distinct words for the different degrees of light during the dawn and dusk periods. He also notes that the feeling of time passing can be described by saying \"the sun moves slowly/quickly\". Parts 3, 4, 5, and 6 describe Hopi time-keeping practices using the sun relative to the horizon, using the stars, the ceremonial calendar and the use of time-keeping devices such as knotted strings or notched sticks with a mark or knot for every day, sun-hole alignment and shadow observation. The eighth chapter describes the temporal particles that Whorf defined as temporals and tensors. He argues that Whorf's descriptions are vague and alienating.\n\nThe concept of Hopi tense is covered in the last part of chapter 9, titled \"miscellaneous\", and in the conclusion. Malotki follows Gipper in arguing that time is a natural category and that it is naturally experienced in terms of past, present and future, even though many languages do not necessarily grammaticalize all of these distinctions. He analyzes the Hopi \"-ni\" suffix as marking the future tense. He argues that since there is no grammatical distinction between past and present, Hopi has a future-nonfuture tense system. Malotki distinguishes between primary and secondary functions of the -ni suffix, arguing that its primary function is temporal reference and that its many modal functions such as imperative, hortative and desiderative are of secondary importance. Malotki does admit that the English and Hopi systems of tense are different since the English system distinguishes past from non-past, whereas Hopi distinguishes future from non-future.\n\nSubsequent descriptions of Hopi grammar have maintained Malotki's distinction between an unmarked non-future tense and a future tense marked with the -\"ni\" suffix, and a habitual aspect marked by the suffix -\"ngwu\". The review by Bernard Comrie, a well-known authority on the linguistic typology of tense and aspect, accepts that Malotki's work demonstrates that the Hopi do have a concept of time and that it is devastating for Whorf's strong claims. But Comrie also notes that Malotki's \"Claim that Hopi has a tense system based on the opposition of future and non-future ... strikes me as questionable: given the wide range of modal uses of the so-called future, it is at least plausible that this is a modal rather than temporal distinction, with the result that Hopi would have no tense distinction.\"\n\nLinguists and psychologists who work in the universalist tradition such as Steven Pinker and John McWhorter, have seen Malotki's study as being the final proof that Whorf was an inept linguist and had no significant knowledge or understanding of the Hopi language. This interpretation has been criticized by relativist scholars as unfounded and based on a lack of knowledge of Whorf's work.\n\nIn spite of Malotki's refutation, the myth that \"the Hopi have no concept of time\" lived on in the popular literature. For example, in her 1989 novel \"Sexing the Cherry\", Jeanette Winterson wrote of the Hopi: \"...their language has no grammar in the way we recognize it. And most bizarre of all, they have no tenses for past, present and future. They do not sense time in that way. For them time is one.\" And the myth continues to be an integral part of New Age thinking that draws on stereotypical depictions of \"timeless Hopi culture\".\n\nSome linguists working on Universals of semantics, such as Anna Wierzbicka and Cliff Goddard, argue that there is a Natural Semantic Metalanguage that has a basic vocabulary of semantic \"primes\" including concepts such as . They have argued that Malotki's data show that the Hopi share these primes with English and all other languages, even though it is also clear that the precise way in which these concepts fit into the larger pattern of culture and language practices is different in each language, as illustrated by the differences between Hopi and English.\n\nMalotki's work has been criticized by relativist scholars for failing to engage with Whorf's actual argument. John A. Lucy argues that Malotki's critique misses the fact that Whorf's point was exactly that the way in which the Hopi language grammatically structurates the representation of time leads to a different conception of time than the English one, not that they do not have one. Lucy notes that when Whorf makes his strong claim about what it is that Hopi lacks, he consistently puts the word \"time\" in scare quotes, and uses the qualifier \"what we call\". Lucy and others take this as evidence that Whorf was implying specifically that what the Hopi lacked was a concept that corresponds entirely to that denoted by the English word, i.e. he was making a point of showing that the concepts of time were different. Malotki himself acknowledges that the conceptualizations are different, but because he ignores Whorf's use of scare quotes, takes Whorf to be arguing that the Hopi have no concept of time at all.\n\nIn 1991 Penny Lee published a comparison of Malotki and Whorf's analyses of the adverbial word class that Whorf had called \"tensors\". She argues that Whorf's analysis captured aspects of Hopi grammar that were not captured by simply describing tensors as falling within the class of temporal adverbs.\n\nIn 2006 anthropologist David Dinwoodie published a severe critique of Malotki's work, questioning his methods and his presentation of data as well as his analysis. Dinwoodie argues that Malotki fails to adequately support his claim of having demonstrated that the Hopi have a concept of time \"as we know it\". He provides ethnographic examples of how some Hopi speakers explain the way they experience the difference between a traditional Hopi way of experiencing time as tied closely to cycles of ritual and natural events, and the Anglo-American concept of clock-time or school-time.\n\nSparked by the Hopi debate about time a number of studies about how different languages grammaticalize tense and conceptualize time have been carried out. Some of these studies in psycholinguistics and cognitive linguistics have found some evidence that there may be significant differences in how speakers of different languages conceptualize time, although not necessarily in the way Whorf claimed for the Hopi. Specifically, it has been shown that some cultural groups conceptualize the flow of time in a direction opposite to what is usual for speakers of English and other Indo-European languages, i.e. that the future is in front of the speaker and the past behind. It has also been found that not all languages have a grammatical category of tense: some instead use combinations of adverbs and grammatical aspect to locate events in time.\n"}
{"id": "16571023", "url": "https://en.wikipedia.org/wiki?curid=16571023", "title": "Innateness hypothesis", "text": "Innateness hypothesis\n\nThe innateness hypothesis is an expression coined by Hilary Putnam to refer to a linguistic theory of language acquisition which holds that at least some knowledge about language exists in humans at birth. Putnam used the expression \"the innateness hypothesis\" to target linguistic nativism and specifically the views of Noam Chomsky. Facts about the complexity of human language systems, the universality of language acquisition, the facility that children demonstrate in acquiring these systems, and the comparative performance of adults in attempting the same task are all commonly invoked in support. However, the validity of Chomsky's approach is still debated. Empiricists advocate that language is entirely learned. Some have criticized Chomsky's work, pinpointing problems with his theories while others have proposed new theories to account for language acquisition (with specific differences in terms of language acquisition per se compared to second language acquisition).\n\nLinguistic nativism is the theory that humans are born with some knowledge of language. One acquires a language not entirely through learning.\n\nHuman language is complicated and is said to form one of the most complex areas of human cognition. However, despite its complexity, children are able to accurately acquire a language within a short period of time. Moreover, research has shown that language acquisition among children (including the blind and the deaf) occurs in ordered developmental stages.\nThis highlights the possibility of humans having an innate language acquisition ability. According to Noam Chomsky, \"The speed and precision of vocabulary acquisition leaves no real alternative to the conclusion that the child somehow has the concepts available before experience with language and is basically learning labels for concepts that are already a part of his or her conceptual apparatus.\" Chomsky's view that the human faculty of language is innate is also affirmed by Steven Pinker. Moreover, in his work, The Language Instinct, Pinker argued that language in humans is a biological adaptation—language is hard-wired into our minds by evolution. Furthermore, in contrast to children's ease in language acquisition, having passed the critical age for language acquisition the complexity of a language often makes it challenging for adult learners to pick up a second language. More often than not, unlike children, adults are unable to acquire native-like proficiency.\nHence, with this idea in mind, nativists advocate that the fundamentals of language and grammar are innate rather than acquired through learning. The innateness hypothesis supports language nativism and several reasons and concepts have been proposed to support and explain this hypothesis. In his work, Chomsky introduced the idea of a language acquisition device (LAD) to account for the competence of humans in acquiring a language. The universal grammar (UG) that is also often credited to Chomsky was later introduced.\n\nAccording to Chomsky, humans are born with a set of language learning tools referred to as the LAD. The LAD is an abstract part of the human mind which houses the ability for humans to acquire and produce language. Chomsky expressed that children are able to derive rules of a language through hypothesis testing because they are equipped with a LAD. The LAD then transforms these rules into basic grammar. Hence, according to Chomsky, the LAD explains why children seem to have the innate ability to acquire a language and accounts for why no explicit teaching is required for a child to acquire a language.\n\nIn his argument for the existence of a LAD, Chomsky proposed that for a child to acquire a language, sufficient innate language-specific knowledge is needed. These constraints were later termed as universal grammar (UG). In this theory, it is suggested that all humans have a set of limited rules for grammar that are universal to all natural human languages. These rules are genetically wired into our brains and they can be altered in correspondence to the language children are exposed to. In other words, under this theory, language acquisition is seen as a process of filtering through the set of possible grammatical structures in natural languages pre-programmed in one's mind and this is guided by the language input in one's environment. Chomsky later introduced generative grammar. He argued that \"properties of a generative grammar arise from an \"innate\" universal grammar\". This theory of generative grammar describes a set of rules that are used to order words correctly in order to form grammatically-sound sentences. It also attempts to describe a speaker's innate grammatical knowledge.\n\nOne of the most significant arguments generative grammarians had for language nativism is the poverty of the stimulus argument. Since 1980, the poverty of stimulus became increasingly integrated into the theory of generative grammar. In this argument, Noam Chomsky put forth that the amount of input a child receives during language acquisition is insufficient to account for the linguistic output. To be exact, he said that, \"the native speaker has acquired a grammar on the basis of very restricted and degenerate evidence\". Similarly, in his paper, Pinker concludes that humans have a system that is more sophisticated than what they are being exposed to.\n\nIn their article, Pullum and Scholz summarised the properties of a child's environment. They identified properties of positivity, degeneracy, incompleteness and idiosyncrasy. Under positivity, they assert that children are only exposed to positive linguistic data. Moreover, there is lack in negative data that aids a child in identifying ungrammatical sentences that are unacceptable in the language. It is also claimed that children are unable to acquire a language with positive evidence alone. In addition, under degeneracy, it is stated that children are often exposed to linguistic data that are erroneous. This is supported by Zohari that states that in adult speech, erroneous utterances that include speech slips, ungrammatical sentences, incomplete sentences etc. are often observed. Furthermore, the linguistic data each child is exposed to is different (i.e. idiosyncrasy) and there are many utterances that a child might not have heard (i.e. incompleteness). However, despite the properties mentioned above, children would eventually be able to deliver a linguistic output that is similar to the target language within a relatively short amount of time. In contrast, when placed in certain environments, other organisms are unable to attain the language mastery humans have reached. From the nativists' point of view, all of these highlight that babies are hard-wired with a UG and thus support the innateness hypothesis.\n\nHowever, it is important to note that the argument that the poverty of stimulus supports the innateness hypothesis remains very controversial. For example, in one of the latest work against the poverty of stimulus argument, Fiona Cowie wrote in her paper that the Poverty of Stimulus argument fails \"on both empirical and conceptual grounds to support nativism\".\n\nThe critical period hypothesis by Linguist Eric Lenneberg states that full native competence in acquiring a language can only be achieved during an optimal period. This hypothesis supports the innateness hypothesis about the biological innateness of linguistic competence. Lenneberg expressed that age plays a salient role in the ability to acquire language. According to him, a child before the age of two will not sufficiently acquire language, while development of full native competence in a language must occur before the onset of puberty. This suggests that language is innate that occurs through development instead of feedback from the environment. As a result, should a child not hear any language during this period, the child would not be able to learn nor be able to speak. This hypothesis is also said to explain why adults do not acquire languages as well as children.\n\nEvidence for the critical period hypothesis can be seen in the case of Genie. When discovered, she was without language. Genie's subsequent language acquisition process was studied, whereby her linguistic performance, cognitive and emotional development was deemed abnormal. Genie was said to have right-hemisphere language, resembling other cases where language was acquired outside of the \"critical period\". This would lend support to Lenneberg's hypothesis. Moreover, some saw the case of Genie as a support to the innateness hypothesis. When the LAD is not triggered during the critical period, the natural process of language acquisition cannot be reached. However, Genie's case is complex and controversial. It has been argued that it does not support linguistic innateness. Some have asserted that there is at least a possible degree of first language acquisition beyond the critical period. Moreover, the emotional and cognitive deprivation may have also played a part in Genie's linguistic and cognitive difficulties.\n\nThe development of the Nicaraguan sign language by students in a school for the deaf also lends evidence to the hypothesis. Initially a pidgin sign language with simple grammar, there were large grammatical differences and variations across signers. Eventually, the pidgin became a full-fledged language (like a creole) as younger signers developed a significantly more grammatically structured and regular system such as specific grammatical structures Often, the differences in abilities between the younger and older students to use sign language are said to suggest evidence for a critical period. The spontaneity of the development of NSL also shows that there is an innate element to the process of language learning.\n\nNonetheless, the critical period hypothesis in relation to language acquisition is also widely debated. Other research has also indicated that any age effects depend largely on the opportunities for learning, learning situations and how significant the initial exposure is.\n\nEmpiricism is the theory that all knowledge is based on experience derived from the senses. Empiricists only study observable behaviour instead of unobservable mental representations, states and processes. They claim that sense and experience is the ultimate source of all concepts and knowledge. On the other hand, linguistic empiricism is a perspective where language is entirely learned. These data-driven theorists also support that children do not have linguistically-specific knowledge at birth. Language and grammar are only learned through exposure and accumulated experience. This is also called the \"nurture\" perspective as opposed to the \"nature\" perspective (linguistic nativism).\n\nAgainst Chomsky's Innateness Hypothesis, philosopher John Locke insisted that our knowledge, including language, cannot be innate. Instead, all ideas are derived from experience. Geoffrey Sampson also showed the same stand by stating that \"Our languages are not inborn but are learned wholly with experience.\" Empiricists have criticised concepts like generative grammar that support linguistic nativism. In fact, some would argue that \"language structure\" is created through language use. Moreover, they assert that theories like the LAD are unsupported by empirical evidence.\n\nContrastive analyses about the innateness hypothesis have been done by Jacek Fisiak in 1980. According to Fisiak's analysis, Putnam, Hiż and Goodman criticized Chomsky's innate hypothesis by stating that:\n\nIt is hard to explain what it is for someone to have an innate concept since empirical evidence to support this theory is hard to find. In other words, there is no way to falsify the theory unless empirical evidence is found.\n\nOver the years, many theories that are against language innateness have been developed to account for language acquisition. Many have championed that human beings learn language through experience with some leaning towards children being equipped with learning mechanisms while others suggesting that social situations or cognitive capacities can account for language learning.\n\nBates and Elman summarised a research conducted by Saffran, Aslin and Newport that supports that learning is \"a purely inductive, statistically driven process\". In the research, it was found that 8 month old infants were able to use simple statistics to identify word boundaries in speech. The results of the research highlight that language acquisition is a process of learning through statistical means. Moreover, it raises the possibility that infants possess experience-dependent mechanisms that allow for word segmentation and acquisition of other aspects of language. As a result, Bates and Elman found that this contradicts the extensive view that human beings are unable and cannot utilize generalized statistical procedures for language acquisition. This is empirical evidence for linguistic empiricism, thereby going against the innateness hypothesis.\n\nMichael Tomasello's findings highlight the significance of a usage-based theory of language acquisition and indicates that there is a relation between cognitive and social skills with linguistic competence. This shows the importance of the role of experience in language acquisition. By empirically studying the developmental stages of child language acquisition, he argues that children have specific cognitive capacities at birth that promote growth in linguistic competence and specific interpersonal abilities that aid language learning. However, he emphasised that this does not prove that language is innate. In addition, his experiments indicate that children's awareness and understanding of the intentional communicative cues displayed by others is a salient social cognitive skill that determines their ability to learn words. Tomasello also stated that young children's initial multi-word productions are very concrete as they are based on specific words and phrases instead of innate and abstract linguistic categories. Hence, this would explain why grammar development is progressive and word-specific.\n\nGeoffrey Sampson also supports that the \"richness of the environment\" plays a role in language acquisition. For example, Sampson observed that not only human beings but all species are capable of recognizing speech. This ability indicates that a child is equipped with the capacity for normalisation which plays a fundamental role in acquiring the phonology of a language. Therefore, he contends that a child is born with the ability to learn and this is through testing and guessing instead of the innate ability that nativists support.\n\n"}
{"id": "15729796", "url": "https://en.wikipedia.org/wiki?curid=15729796", "title": "Institute of the Peoples of the North", "text": "Institute of the Peoples of the North\n\nThe Institute of the Peoples of the North () is a research and later educationary institute based in Saint Petersburg. Its objective is to examine topics related to the northern minorities in the Soviet Union, and to prepare teachers for the northern boarding schools. One of the central figures involved in the research institute was Vladimir Bogoraz.\n\nThe institute was founded in 1930, as four years previously it had become possible to study the languages of the northern peoples in their own right at the Institute for Eastern Studies at Leningrad State University. By the end of 1929, the institute's teachers had joined forces to create the Unified Northern Alphabet () for use by the linguistic minorities living in the north of the Soviet Union. The alphabet consisted of 32 Latin-based letters, some of which were equipped with diacritics. For practical reasons, i.e., typographical reasons, a move to rid the alphabet of graphemes using diacritics was made and one year later a new version was ready. On December 13, 1930, the Presidium of the Scientific Investigation Association at the institute presented a version of the Unified Northern Alphabet to the Scientific Council of the USSR’s Central Committee on Alphabet Adaptation (). The same body discussed the draft again on December 18 and it was approved on February 23, 1931. The scientific section of Narkompros approved the draft in May the same year. \n\nThe alphabet consisted of 39 letters: 29 consonants and 10 vowels. In addition, some letters were marked with diacritics to show palatalization, length and aspiration.\n\nAn intensive and systematic publishing campaign was launched immediately after the alphabet had been formally approved. From 1939 to 1949, approximately 300 experts were employed by the institute.\n\n\"The finalisation of principles for creation of a literary public institution for the peoples of the north\" came at the first pan-Russian conference. Delegates to the conference (which was held at the INS ni Leningrad) were representatives for Narkompros, Komitet Severa v/Presidium VCIK, CK Novogo Alfavita SSSR i RSFSR, and the publisher Učpedgiz. In the work conducted at the conference, there were participants from the national northern okrugs, for the local Northern Committees, for CK VLKSM, for the soviet Academy of Sciences, for the Historical-linguistic institute in Leningrad, and for the Northern department at the Leningrad Herzen Pedagogical Institute. The preparation work was done at INS.\n\nThe conference decided to create orthographies for a total of 16 languages and to have books available for the 15th anniversary of the revolution:\n\n\nVarious books, including primers and math textbooks, were published using this alphabet. The first work published using the new orthography was a book on terminology specific to these areas.\n\nThe institute was run in its original form from 1930 until 1941. Between 1942 and 1945, the institute was located in Omsk, after which it moved back to Leningrad as a part of the Faculty of Oriental Studies at Leningrad State University. Since 1948, the institute has been a part of the Herzen University, to which it still belongs today.\n\n"}
{"id": "1737517", "url": "https://en.wikipedia.org/wiki?curid=1737517", "title": "Language planning", "text": "Language planning\n\nLanguage planning (also known as language engineering) is a deliberate effort to influence the function, structure, or acquisition of languages or language variety within a speech community. It is often associated with government planning, but is also used by a variety of non-governmental organizations, such as grass-roots organizations, and individuals. Goals of such planning vary. Better communication through assimilation of a single dominant language can bring economic benefits to minorities but is also perceived to facilitate their political domination. It involves the establishment of language regulators, such as formal or informal agencies, committees, societies or academies, to design or develop new structures to meet contemporary needs.\n\nFour overarching language ideologies motivate decision making in language planning. The first, linguistic assimilation, is the belief that every member of a society, irrespective of their native language, should learn and use the dominant language of the society in which they live. An example is the English-only movement of some residents of the United States.\n\nIn contrast is the second ideology, linguistic pluralism - the recognition and support of multiple languages within one society. Examples include the coexistence of French, German, Italian, and Romansh in Switzerland; and the shared official status of English, Malay, Tamil, and Mandarin Chinese in Singapore. The coexistence of many languages may not necessarily arise from a conscious language ideology, but rather related to the relative efficiency in communication of a common language.\n\nThe third ideology, vernacularization, denotes the restoration and development of an indigenous language, along with its adoption by the state as an official language. Examples include Hebrew in the state of Israel and Quechua in Peru.\n\nThe final ideology, internationalization, is the adoption of a non-indigenous language as a means of wider communication, as an official language or in a particular domain, such as the use of English in India, Singapore, the Philippines, Papua New Guinea, and South Africa.\n\nEleven language planning goals have been recognized (Nahir 2003):\n\nLanguage planning has been divided into three types:\n\nStatus planning is the allocation or reallocation of a language or variety to functional domains within a society, thus affecting the status, or standing, of a language.\n\nLanguage status is a concept distinct from, though intertwined with, language prestige and language function. Strictly speaking, language status is the position or standing of a language vis-à-vis other languages. A language garners status according to the fulfillment of four attributes, described in 1968 by two different authors, Heinz Kloss and William Stewart. Both Kloss and Stewart stipulated four qualities of a language that determine its status. Their respective frameworks differ slightly, but they emphasize four common attributes:\n\nTogether, origin, degree of standardization, juridical status, and vitality express a language's status.\n\nWilliam Stewart outlines ten functional domains in language planning: \n\nRobert Cooper, in reviewing Stewart's list, makes several additions. First, he creates three sub-types of official functions: statutory, working, and symbolic. A statutory language is a language that a government has declared official by law. A working language is a language that a government uses as a medium for daily activities, and a symbolic language is a language that is a symbol of the state. Cooper also adds two functional domains to Stewart's list: mass media and work.\n\nCorpus planning refers to the prescriptive intervention in the forms of a language, whereby planning decisions are made to engineer changes in the structure of the language. Corpus planning activities often arise as the result of beliefs about the adequacy of the form of a language to serve desired functions. Unlike status planning, which is primarily undertaken by administrators and politicians, corpus planning generally is performed by individuals with greater linguistic expertise. There are three traditionally recognized types of corpus planning: graphization, standardization, and modernization.\n\nGraphization refers to development, selection and modification of scripts and orthographic conventions for a language. The use of writing in a speech community can have lasting sociocultural effects, which include easier transmission of material through generations, communication with larger numbers of people, and a standard against which varieties of spoken language are often compared. Linguist Charles A. Ferguson made two key observations about the results of adopting a writing system. First, the use of writing adds another variety of the language to the community's repertory. Although written language is often viewed as secondary to spoken language, the vocabulary, grammatical structures and phonological structures of a language often adopt characteristics in the written form that are distinct from the spoken variety. Second, the use of writing often leads to a folk belief that the written language is the 'real' language, and speech is a corruption of it. Written language is viewed as more conservative, while the spoken variety is more susceptible to language change. Isolated relic areas of the spoken language may be less innovative than the written form, or the written language may have been based on a divergent variety of the spoken language.\n\nIn establishing a writing system for a language, corpus planners have the option of using an existing system or creating a new one. The Ainu of Japan chose to adopt the Japanese language's katakana syllabary as the writing system for the Ainu language. Katakana is designed for a language with a basic CV syllable structure, but Ainu contains many CVC syllables that cannot easily be adapted to this syllabary. As a result, Ainu uses a modified katakana system, in which syllable-final codas are consonants by a subscript version of a katakana symbol that begins with the desired consonant.\n\nAn example on a created script includes the development of the Armenian script in 405 AD by St. Mesrop Mashtots. Though the script was modeled after the Greek alphabet, the original script distinguished Armenian from the Greek and Syriac alphabets of the neighboring peoples. Similarly, in the early 19th century, Sequoyah (Cherokee) created an orthography for written Cherokee in the Southeast of the present-day United States. It uses some Latin characters but also introduces new ones.\n\nThe process of Standardization often involves one variety of a language taking precedence over other social and regional dialects of a language. Another approach, where dialects are mutually intelligible, is to introduce a poly-phonemic written form that is intended to represent all dialects of a language adequately but with no standard spoken form. If one variety of a language is chosen, that variety comes to be understood as supra-dialectal and the 'best' form of the language.\n\nThe choice of which language takes precedence has important societal consequences, as it confers privilege upon speakers whose spoken and written dialect conforms closest to the chosen standard. The standard that is chosen as the norm is generally spoken by the most powerful social group within the society, and is imposed upon the less powerful groups as the form to emulate. This often reinforces the dominance of the powerful social group and makes the standard norm necessary for socioeconomic mobility. In practice, standardization generally entails increasing the uniformity of the norm, as well as the codification of the norm.\n\nThe history of English provides an example of standardization occurring over an extended time period, without formally recognized language planning. The standardization process began when William Caxton introduced the printing press in England in 1476. This was accompanied by the adoption of the south-east Midlands variety of English, spoken in London, as the print language. Because of the dialect's use for administrative, government, business, and literary purposes, this variety became entrenched as the prestigious variety of English. After the creation of grammars and dictionaries in the 18th century, the rise of print capitalism, industrialization, urbanization, and mass education led to the dissemination of this dialect as the standard norm for the English language.\n\nModernization is a form of language planning that occurs when a language needs to expand its resources to meet functions. Modernization often occurs when a language undergoes a shift in status, such as when a country gains independence from a colonial power or when there is a change in the language education policy. The most significant force in modernization is the expansion of the lexicon, which allows the language to discuss topics in modern semantic domains. Language planners generally focus on creating new lists and glossaries to describe new technical terms, but it is also necessary to ensure that the new terms are consistently used by the appropriate sectors within society. While some languages, such as Japanese and Hungarian, have experienced rapid lexical expansion to meet the demands of modernization, other languages, such as Hindi and Arabic, have failed to do so. Rapid lexical expansion is aided by the use of new terms in textbooks and professional publications, as well as frequent use among specialists. Issues of linguistic purism often play a significant role in lexical expansion, but technical vocabulary can be effective within a language, regardless of whether it comes from the language's own process of word formation or from extensive borrowing from another language. While Hungarian has almost exclusively used language-internal processes to create new lexical items, Japanese has borrowed extensively from English to derive new words as part of its modernization.\n\nAcquisition planning is a type of language planning in which a national, state or local government system aims to influence aspects of language, such as language status, distribution and literacy through education. Acquisition planning can also be used by non-governmental organizations, but it is more commonly associated with government planning.\n\nFrequently, acquisition planning is integrated into a larger language planning process in which the statuses of languages are evaluated, corpuses are revised and the changes are finally introduced to society on a national, state or local level through education systems, ranging from primary schools to universities. This process of change can entail a variety of modifications, such as an alteration in student textbook formatting, a change in methods of teaching an official language or the development of a bilingual language program, only to name a few. For example, if a government decides to raise the status level of a certain language or change its level of prestige, it can establish a law that requires teachers to teach only in this language or that textbooks are written using only this language's script. This, in turn, would support the elevation of the language's status or could increase its prestige. In this way, acquisition planning is often used to promote language revitalization, which can change a language's status or reverse a language shift, or to promote linguistic purism. In a case where a government revises a corpus, new dictionaries and educational materials will need to be revised in schools in order to maintain effective language acquisition.\n\nThe education ministry or education sector of government is typically in charge of making national language acquisition decisions based on state and local evaluation reports. The responsibilities of education sectors vary by country; Robert B. Kaplan and Richard B. Baldauf describe the sectors' six principal goals:\n\n\nAlthough acquisition planning can be useful to governments, there are several problems that must be considered. Even with a solid evaluation and assessment system, the effects of planning methods can never be certain; governments must consider the effects on other aspects of state planning, such as economic and political planning. Some proposed acquisition changes could also be too drastic or instituted too suddenly without proper planning and organization. Acquisition planning can also be financially draining, so adequate planning and awareness of financial resources is essential. It is important therefore that government goals, such as those described above, be organized and planned carefully.\n\nThere is also a growing concern over the treatment of multilingualism in education, especially in many countries that were once colonized. Deciding on which language of instruction would be most beneficial to effective communication on the local and state level is a task requiring thoughtful planning and is surrounded by debate. Some states prefer instruction only in the official language, but some aim to foster linguistic and thus social diversity by encouraging teaching in several (native) languages. One reason some states prefer a single language of instruction is that it supports national unity and homogeneity. Some states prefer incorporating different languages in order to help students learn better by giving them diverse perspectives.\n\nIn addition to the education sector, there are non-governmental sectors or organizations that have a significant effect on language acquisition, such as the Académie française of France or the Real Academia Española of Spain. These organizations often create their own dictionaries and grammar books, thus affecting the materials which students are exposed to in schools. Although these organizations do not hold official power, they influence government planning decisions, such as with educational materials, affecting acquisition.\n\nBefore the partition of Ireland, a movement began which aimed at the restoration of Irish, as the nation's primary language, based on a widespread sentiment for Irish nationalism and cultural identity. During and after colonisation, Irish had competed with English and Scots; the movement to restore the language gained momentum after the Irish War of Independence. The Gaelic League was created to promote the acquisition of Irish in schools, thus \"de-Anglicizing\" Ireland. Immediately after Ireland gained independence in 1922, the League declared that Irish must be the language of instruction for at least one hour in primary schools nationwide. Irish-speaking teachers were recruited, and preparatory colleges were established to train new ones.\n\nThe program implementation was mostly left to the individual schools, which did not consistently carry it out. Additionally, educating a generation is a long process, for which the League was not prepared. There was no consensus as to how the Irish language should be reinstituted; the League and schools did not develop a system assessment plan to monitor progress. As a result, the movement lost strength, and the number of native Irish speakers has been in steady decline.\n\nPeru's history of language planning begins in the 16th century with Spanish colonization. When the Spanish first arrived in Peru, Quechua served as a language of wider communication, a lingua franca, between Spaniards and Peruvian natives. As the years passed, Spaniards asserted the superiority of the Spanish language; as a result, Spanish gained prestige, taking over as a language of wider communication and the dominant language of Peru. In 1975, under the leadership of President Juan Velasco Alvarado, the revolutionary government of Peru declared Quechua an official language of the Peruvian state, \"coequal with Spanish.\" Four years later, the law was reversed. Peru's 1979 constitution declares Spanish the only official language of the state; Quechua and Aymara are relegated to \"official use zones,\" equivalent to Stewart's provincial function described above. Quechua has officially remained a provincial language since 1979. Today, Quechua also serves a limited international function throughout South America in Argentina, Bolivia, Brazil, Chile, Colombia, and Ecuador; communities of Quechua speakers outside Peru enable communication in Quechua across borders. Still, because of Quechua's low status, Spanish is almost always used as the lingua franca instead. Recently, Quechua has also gained ground in the academic world, both as a school subject and a topic of literary interest.\n\nThe three main types of corpus planning are all evident in the development of Quechua languages in Peru since the colonial era. Graphization has been in process since the arrival of the Spanish in the region, when the Spanish imperialists attempted to describe the exotic sounds of the language to Europeans.\n\nWhen Quechua was made an official language in Peru in 1975, the introduction of the language into the education and government domains made it essential to have a standard written language. The task of adopting a writing system proved to be a point of contention among Peruvian linguists. Although most agreed to use the Latin alphabet, linguists disagreed about how to represent the phonological system of Quechua, particularly in regards to the vowel system. Representatives from the Peruvian Academy of the Quechua language and the Summer Institute of Linguistics wanted to represent allophones of the vowels /i/ and /u/ with separate letters <e> and <o>, which creates an apparent five-vowel system. They argued that this makes the language easier to learn for people who are already familiar with written Spanish. However, other Peruvian linguists argued that a three-vowel system was more faithful to the phonology of Quechua. After several years of debate and disagreement, in 1985 Peruvian linguists proposed the Pan-Quechua alphabet as an accurate representation of the language, and this was adopted in intercultural bilingual education programs and textbooks. However, the Peruvian Academy and the SIL both refused to adopt it and continued to propose new alphabets, leaving the issue unsettled. For more information, see Quechua writing system and Quechuan and Aymaran spelling shift. Another of the primary issues disagreements was about how to reflect the phonological differences apparent in different dialects of Quechua. For example, some distinct dialects utilize aspirated and glottalized versions of the voiceless uvular stop /q/, while others do not and some language planners found it important to reflect these dialectal differences.\n\nThe search for a unified alphabet reflects the process of standardization. Unlike other cases of standardization, in Quechua this has been applied only to the written language, not to the spoken language, and no attempt was made to change the spoken language of native speakers, which varied by regions. Rather, standardization was required in order to create a uniform writing system to provide education to Quechua speakers in their native language.\n\nLanguage planners in Peru have proposed several varieties to serve as the supradialectal spoken norm. Some saw Qusqu-Qullaw as the natural choice for a standard norm, as it is recognized to be the variety closest to that spoken by the Incas. Others argued that Ayacucho Quechua is a better option, as the language is more conservative and similar to the proto-language, while Qusqu-Qullaw has been influenced by contact with the Aymara language.\n\nRodolfo Cerrón-Palomino proposed a standard literary norm, Southern Quechua that combines features of both these dialects. This norm has been accepted by many institutions in Peru.\n\nLexical modernization has also been critical to the development of Quechua. Language planners have attempted to create new Quechua words primarily through Quechua morphemes, which are combined in new ways to give new meanings. In general, loanwords from other languages are considered only when there are no possibilities to develop the word through existing Quechua structures. If loanwords are adopted into the language, linguists attempt to phonologically adapt the word to match typical Quechua pronunciation norms.\n\nSince Quechua is no longer an official language of Peru, Quechua literacy is not consistently encouraged in schools. Peru's education system is instead primarily based on Spanish, the nation's official language. Despite its low prestige, Quechua is still spoken by millions of indigenous Peruvians, a large portion of whom are bilingual in Quechua and Spanish. There is a desire to preserve the uniqueness of Quechua as a language with its own attributes and representations of culture. Some argue that promoting a diverse literacy program gives students diverse perspectives on life, which could only enhance their educational experience. Before 1975, Peru had bilingual education programs, but Quechua was not taught as a subject in primary and secondary schools. After the 1975 education reform, Quechua and Spanish both had standing in bilingual programs, but only in restricted speech communities. These experimental programs were then canceled due to a change in government planning, but again reinstated in 1996. Even with national intercultural bilingual education programs, teachers at local schools and members of the community often prefer using Spanish, destabilizing support for bilingual education. This underscores the importance of community support as a goal for the education sector as mentioned earlier. Some believe that due to Spanish's higher national prestige, it is more socially and economically beneficial to learn and speak Spanish. It is debatable whether these education programs will benefit education or raise the status of Quechua.\n\n\n\n\n"}
{"id": "18077", "url": "https://en.wikipedia.org/wiki?curid=18077", "title": "Lexicon", "text": "Lexicon\n\nA lexicon, word-hoard, wordbook, or word-stock is the vocabulary of a person, language, or branch of knowledge (such as nautical or medical). In linguistics, a lexicon is a language's inventory of lexemes. The word \"lexicon\" derives from the Greek (\"lexicon\"), neuter of (\"lexikos\") meaning \"of or for words.\"\n\nLinguistic theories generally regard human languages as consisting of two parts: a lexicon, essentially a catalogue of a language's words (its wordstock); and a grammar, a system of rules which allow for the combination of those words into meaningful sentences. The lexicon is also thought to include bound morphemes, which cannot stand alone as words (such as most affixes). In some analyses, compound words and certain classes of idiomatic expressions and other collocations are also considered to be part of the lexicon. Dictionaries represent attempts at listing, in alphabetical order, the lexicon of a given language; usually, however, bound morphemes are not included.\n\nItems in the lexicon are called lexemes, or lexical items, or word forms. Lexemes are not atomic elements but contain both phonological and morphological components. When describing the lexicon, a reductionist approach is used, trying to remain general while using a minimal description. To describe the size of a lexicon, lexemes are grouped into lemmas. A lemma is a group of lexemes generated by inflectional morphology. Lemmas are represented in dictionaries by headwords which list the citation forms and any irregular forms, since these must be learned to use the words correctly. Lexemes derived from a word by derivational morphology are considered new lemmas. The lexicon is also organized according to open and closed categories. Closed categories, such as determiners or pronouns, are rarely given new lexemes; their function is primarily syntactic. Open categories, such as nouns and verbs, have highly active generation mechanisms and their lexemes are more semantic in nature.\n\nA central role of the lexicon is the documenting of established \"lexical norms and conventions\". Lexicalization is the process in which new words, having gained widespread usage, enter the lexicon. Since lexicalization may modify lexemes phonologically and morphologically, it is possible that a single etymological source may be inserted into a single lexicon in two or more forms. These pairs, called a doublet, are often close semantically. Two examples are \"aptitude\" versus \"attitude\" and \"employ\" versus \"imply\".\n\nThe mechanisms, not mutually exclusive, are:\n\nNeologisms are new lexeme candidates which, if they gain wide usage over time, become part of a language's lexicon. Neologisms are often introduced by children who produce erroneous forms by mistake. Another common source is slang and activities such as advertising and branding.\n\nThere are two types of borrowings (neologisms based on external sources) that retain the sound of the source language material:\n\nThe following are examples of external lexical expansion using the source language lexical item as the basic material for the neologization, listed in decreasing order of phonetic resemblance to the original lexical item (in the source language):\n\nThe following are examples of simultaneous external and internal lexical expansion using target language lexical items as the basic material for the neologization but still resembling the sound of the lexical item in the source language:\n\nAnother mechanism involves generative devices that combine morphemes according to a language's rules. For example, the suffix \"-able\" is usually only added to transitive verbs, as in \"readable\" but not \"cryable\".\n\nA compound word is a lexeme composed of several established lexemes, whose semantics is not the sum of that of their constituents. They can be interpreted through analogy, common sense and, most commonly, context. Compound words can have simple or complex morphological structures. Usually only the head requires inflection for agreement. Compounding may result in lexemes of unwieldy proportion. This is compensated by mechanisms that reduce the length of words. A similar phenomenon has been recently shown to feature in social media also where hashtags compound to form longer-sized hashtags that are at times more popular than the individual constituent hashtags forming the compound. Compounding is the most common of word formation strategies cross-linguistically. \n\nComparative historical linguistics studies the evolutions languages and takes a diachronic view of the lexicon. The evolution of lexicons in different languages occurs through parallel mechanism. Over time historical forces work to shape the lexicon, making it simpler to acquire and often creating an illusion of great regularity in language.\n\nThe term \"lexicon\" is generally used in the context of single language. Therefore, multi-lingual speakers are generally thought to have multiple lexicons. Speakers of language variants (Brazilian Portuguese and European Portuguese, for example) may be considered to possess a single lexicon. Thus a \"cash dispenser\" (British English) as well as an automatic teller machine or ATM in American English would be understood by both American and British speakers, despite each group using different dialects.\n\nWhen linguists study a lexicon, they consider such things as what constitutes a word; the word/concept relationship; lexical access and lexical access failure; how a word's phonology, syntax, and meaning intersect; the morphology-word relationship; vocabulary structure within a given language; language use (pragmatics); language acquisition; the history and evolution of words (etymology); and the relationships between words, often studied within philosophy of language.\n\nVarious models of how lexicons are organized and how words are retrieved have been proposed in psycholinguistics, neurolinguistics and computational linguistics.\n\n\n"}
{"id": "39928510", "url": "https://en.wikipedia.org/wiki?curid=39928510", "title": "LinguaSys", "text": "LinguaSys\n\nLinguaSys, Inc. was a company headquartered in Boca Raton, Florida. LinguaSys provided multilingual human language software and services to financial, banking, hospitality, Customer Relations Management, technology, forensics and telecommunications blue chip enterprises, and the government and military.\n\nLinguaSys was co-founded by Chief Executive Officer Brian Garr in Boca Raton, Florida, USA; Chief Technology Officer Vadim Berman in Melbourne, Australia; and Vice President of Development and Architecture Can Unal in Darmstadt, Germany in 2010.\n\nCEO Brian Garr was formerly CTO of Globalink from 1995–1998 and is a recipient of the Smithsonian Institute's \"Heroes in Technology\" award for his work in Machine Translation.\n\nBillionaire Mark Cuban began investing in LinguaSys, Inc., in 2012.\n\nAlso in 2012, LinguaSys partnered with Salesforce.com, adding multilingual text analytics abilities to the company's social marketing services.\n\nIn 2014, LinguaSys made their technology available in a public cloud.\n\nIn 2015, LinguaSys added NLUI Server, which enables building Siri-like natural language applications rapidly in a variety of languages, to the products available in the public cloud.\n\nIn August 2015, LinguaSys was acquired by Aspect Software.\n\nLinguaSys uses interlingual natural language processing software to provide multilingual text, sentiment, relevance and conceptual understanding and analysis. LinguaSys trademarked its proprietary interlingual technology called Carabao Linguistic Virtual Machine. LinguaSys' multilingual software solutions are customized by clients and used via SaaS and behind the firewall. LinguaSys is an IBM Business Partner.\n\nLinguaSys' multilingual technology is used on enterprise servers and consumer smartphones.\n\nLinguaSys has developed an app \"TGPhoto\" which allows the user to snap a photo of some text and show a translation to one of fifty languages. The software works on Android, and Blackberry smartphones.\n"}
{"id": "55402", "url": "https://en.wikipedia.org/wiki?curid=55402", "title": "Linguistic description", "text": "Linguistic description\n\nIn the study of language, description or descriptive linguistics is the work of objectively analyzing and describing how language is actually used (or how it was used in the past) by a group of people in a speech community.\n\nAll academic research in linguistics is descriptive; like all other scientific disciplines, its aim is to describe the reality as it is, without the bias of preconceived ideas about how it ought to be. Modern descriptive linguistics is based on a structural approach to language, as exemplified in the work of Leonard Bloomfield and others.\n\nLinguistic description is often contrasted with linguistic prescription, which is found especially in education and in publishing. Prescription seeks to define standard language forms and give advice on effective language use, and can be thought of as a presentation of the fruits of descriptive research in a learnable form, though it also draws on more subjective aspects of language aesthetics. Prescription and description are complementary, but have different priorities and sometimes are seen to be in conflict. Description is sometimes distinguished from \"descriptivism\", which is then defined as the belief that description is more significant or important to teach, study, and practice than prescription.\n\nAs English-linguist Larry Andrews describes it, descriptive grammar is the linguistic approach that studies what a language is like, as opposed to prescriptive, which declares what a language should be like. In other words, descriptive grammarians focus analysis on how all sorts of people in all sorts of environments, usually in more casual, everyday settings, communicate, while prescriptive grammarians focus on the grammatical rules and structures predetermined by linguistic registers and figures of power for those who are under the control of said authorities to use. An example Andrews uses in his book is \"fewer than\" vs \"less than\". A descriptive grammarian would state that both statements are correct, as long as the receiver of the message can understand the meaning behind the statement. A prescriptive grammarian, on the other hand, would analyze the rules and conventions behind the statements made and determine which statement is correct according to those rules. Andrews also believes that although the majority of linguists would be descriptive grammarians, the majority of public school teachers tend to be prescriptive.\n\nAccurate description of real speech is a difficult problem, and linguists have often been reduced to approximations. Almost all linguistic theory has its origin in practical problems of descriptive linguistics. Phonology (and its theoretical developments, such as the phoneme) deals with the function and interpretation of sound in language. Syntax has developed to describe the rules concerning how words relate to each other in order to form sentences. Lexicology collects \"words\" and their derivations and transformations: it has not given rise to much generalized theory.\n\nAn extreme \"mentalist\" viewpoint denies that the linguistic description of a language can be done by anyone but a competent speaker. Such speakers have internalized something called \"linguistic competence\", which gives them the ability to extrapolate correctly from their experience new but correct expressions, and to reject expressions which do not convey meaning in the way the speaker intends. For example, an expression could be ambiguous, possibly leading to several different interpretations by the listener. Depending on the speaker's intent, ambiguity can be desirable (as in jokes and other humor) or not. \n\nA linguistic description is considered descriptively adequate if it achieves one or more of the following goals of descriptive linguistics:\n\n\n"}
{"id": "489576", "url": "https://en.wikipedia.org/wiki?curid=489576", "title": "Láadan", "text": "Láadan\n\nLáadan is a feminist constructed language created by Suzette Haden Elgin in 1982 to test the Sapir–Whorf hypothesis, specifically to determine if development of a language aimed at expressing the views of women would shape a culture; a subsidiary hypothesis was that Western natural languages may be better suited for expressing the views of men than women. The language was included in her science fiction \"Native Tongue\" series. Láadan contains a number of words that are used to make unambiguous statements that include how one feels about what one is saying. According to Elgin, this is designed to counter male-centered language's limitations on women, who are forced to respond \"I know I said that, but I meant this\".\n\nLáadan is a tonal language. It utilises two distinct tones:\nThe word \"Láadan\" has three syllables: \"lá-\" with the short vowel /a/ plus high tone; \"-a\" with the short vowel /a/ and no tone; and \"-dan\".\n\nLáadan does not allow any double [i.e. long] phonemes. Whenever two identical short vowels would occur side by side in a single morpheme, one of them has to be marked for high tone. When adding an affix would result in two identical vowels side by side, an epenthetic /h/ is inserted to prevent the forbidden sequence. The language will allow either \"máa\" or \"maá,\" but not \"maa\". These combinations can be described as:\n(Some people analyze these tone sequences as tonemic as well, for a total of four tones.)\n\nElgin prefers an analysis of the language as having no long vowels and a single tone, the high tone (distinguished from \"neutral, baseline pitch\"), but she acknowledges that linguists using other formalisms would be justified in saying that there are two tones, high and low (or unmarked or mid).\n\nLáadan has five vowels:\n\nLáadan lacks the consonants . However, it uses \"b\", \"d\", \"sh\" (), \"m\", \"n\", \"l\", \"r\", \"w\", \"y\" (), \"h\" with the same phonetic value as English. In addition to these, three digraphs require further explanation:\n\nMost Láadan sentences contain three particles:\n\nLáadan is a verb–subject–object (VSO) language. Verbs and adjectives are interchangeable. There are no articles, and the object is marked by the \"-th\" or \"-eth\" suffix. The plural number is shown only by the \"me-\" prefix to the verb. The particle \"ra\" following a verb makes it negative. Separate clauses are joined by the particle \"hé\".\n\nLáadan has an agglutinative morphology, and uses a number of affixes to indicate various feelings and moods that many natural languages can only indicate by tone of voice, body language or circumlocution.\n\nThe \"speech-act\" particle, at the beginning of a sentence, can also carry several suffixes, which expand on the overall state of the sentence. For example, \"bíi\" begins a statement, but \"bíide\" begins a statement that is part of a narrative; \"bóoth\" begins a request made in pain; \"báada\" begins a question that is meant in jest.\n\nPronouns in Láadan are built up from a number of constituent parts. The consonant \"l\" marks the first person, \"n\" the second person and \"b\" the third person. Usually, these are followed by the vowel \"e\". However, the vowel \"a\" is used to designate someone who is loved (\"lhe-\" is prefixed to describe someone who is despised). The suffix \"-zh\" is used to mark a plural pronoun for numbers up to four, and \"-n\" for numbers beyond that. Therefore, \"lazh\" means \"we, several beloved\", and \"lheben\" means \"they, many despised\".\n\n\n\n"}
{"id": "31689940", "url": "https://en.wikipedia.org/wiki?curid=31689940", "title": "Mawa language (Nigeria)", "text": "Mawa language (Nigeria)\n\nMawa is an extinct and unattested language of Nigeria. It was apparently different from a language of Chad also known as Mawa, and so is unclassified.\n"}
{"id": "4153402", "url": "https://en.wikipedia.org/wiki?curid=4153402", "title": "Meaning (semiotics)", "text": "Meaning (semiotics)\n\nIn semiotics, the meaning of a sign is its place in a sign relation, in other words, the set of roles that it occupies within a given sign relation. \n\nThis statement holds whether \"sign\" is taken to mean a \"sign type\" or a \"sign token\". Defined in these global terms, the meaning of a sign is not in general analyzable with full exactness into completely localized terms, but aspects of its meaning can be given approximate analyses, and special cases of sign relations frequently admit of more local analyses.\n\nTwo aspects of meaning that may be given approximate analyses are the \"connotative relation\" and the \"denotative relation\". The connotative relation is the relation between signs and their interpretant signs. The denotative relation is the relation between signs and objects. An arbitrary association exists between the \"signified\" and the \"signifier.\"\nFor example, a US salesperson doing business in Japan might interpret silence following an offer as rejection, while to Japanese negotiators silence means the offer is being considered. This difference in interpretations represents a difference in: semiotics\n\nThe triadic (three part) model of the sign separates the meaning of a sign into three distinct components:\n\n1.The representamen, which is the medium, or ‘sign vehicle’, through which the sign is represented. For example, this could be written/spoken words, a photograph, or a painting.\n\n2.The interpretant, or what is meant by the sign \n\n3. The object, or that to which the sign refers \n\nTogether, these three components generate semiosis. For example, an exclamation mark can be broken down into these components. The representamen is the exclamation mark itself, the interpretant is the idea of excitement or an elevated volume of speech, and the object is the actual excitement or elevated volume of speech to which it refers.\nWhile it might appear that the latter two are the same, the subtle difference lies in the fact that the interpretant refers to the idea of something, and the object is the thing itself.\n\nThe representamen component of the sign can be further broken down into three categories, which are icon, index, and symbol. These denote the degree of abstraction from the object to which they refer. A symbol, which is the most abstract, does not resemble or bear any physical relation to the thing that it represents in any way. For example, a peace sign has no relation to peace aside from its social construction as a symbol that represents it. An icon is slightly less abstract, and resembles to some degree the thing that it represents, and bears some physical likeness to it. A good example of this would be a painted portrait. An index is the least arbitrary category of representamen, and has a definite physical tie to that which it represents. This could be something like a weather vane blowing in the wind indicating that it is windy out, or smoke, which indicates a fire.\n\nThe triadic model of the sign was proposed by Charles Peirce. In contradistinction to Ferdinand de Saussure's dyadic model, which assumed no material referent, Peirce's model assumes that in order for a sign to be meaningful, it must refer to something external and cannot be self-contained, as it is for Saussure. Thus, Peirce's model includes the addition of an 'object'. The ‘representamen’ and ‘interpretant’ components of the triadic model are comparable to Saussure’s dyadic model of the sign, which breaks down into signifier and signified.\n\n\n"}
{"id": "15184165", "url": "https://en.wikipedia.org/wiki?curid=15184165", "title": "Metaphor in philosophy", "text": "Metaphor in philosophy\n\nMetaphor, the description of one thing as something else, has become of interest in recent decades to both analytic philosophy and continental philosophy, but for different reasons.\n\nIn the Anglo-American tradition of analytic philosophy (in particular, in the philosophy of language), metaphor has attracted interest because it does not conform to accepted truth-conditional semantics, the conditions which determine whether or not a statement is true. Taken literally, the statement \"Juliet is the sun\" (from \"Romeo and Juliet\") is false, if not nonsensical, yet, taken metaphorically, it is meaningful and may be true, but in a sense which is far from clear. The comparison theory of metaphor asserts that one can express the truth value of a metaphor by listing all the respects in which the two terms are alike or similar; for example: Juliet is \"like\" the sun because she shares with it qualities such as radiance, brilliance, the fact that she makes the day and that she gets up every morning. However, this results in re-casting metaphor as simile. Because it can only explain the truth of metaphor by in effect losing metaphor, the comparison theory is rarely defended.\n\nIn contrast, two leading theorists emphasize the fact that truth conditions cannot be specified for a metaphor. Max Black maintains that metaphors are too open-ended to be able to function as referring expressions, and so cannot be expressions which have truth conditions . If metaphors are used in contexts where precise terminology is expected (for example, in a scientific theory), then their role, Black argues, is purely heuristic, that is, they are means to an end or ways of assisting understanding, rather than being terms which can be tested for truth or falsity . Donald Davidson also thinks it a mistake to look for the truth conditions of a metaphor, since, in his words, \"much of what we are caused to notice [in a metaphor] is not propositional in character\", that is to say, metaphor is a prompt to thought which cannot be reduced to or contained by a series of truth conditions . What metaphor does, Davidson maintains, is make us see one thing as something else by \"making [a] literal statement that inspires or prompts the insight\" . Seeing one thing as something else is not the recognition of some truth or fact, and so \"the attempt to give literal expression to the content of the metaphor is simply misguided\".\n\nMax Black develops the idea that metaphor actually creates insight or new meaning . His interactionist theory asserts that at the heart of a metaphor is the interaction between its two subject terms, where the interaction provides the condition for a meaning which neither of the subject terms possesses independently of the metaphorical context. The primary subject in a metaphor, he claims, is coloured by a set of \"associated implications\" normally predicated of the secondary subject . From the number of possible meanings which could result, the primary subject sieves the qualities predicable of the secondary subject, letting through only those that fit. The interaction, as a process, brings into being what Black terms an \"implication-complex\", a system of associated implications shared by the linguistic community as well as an impulse of free meaning, free in that it is meaning which was unavailable prior to the metaphor's introduction.\n\nIn a different, naturalist, approach, some English-speaking philosophers close to cognitive science, such as Lakoff, have made metaphor the central aspect of human rationality.\n\nWhereas analytic philosophy examines metaphor within the philosophy of language, continental philosophy assigns much wider significance to metaphor. This is because the climate within continental thought has been more favourable to the propagation of new branches of enquiry from nineteenth century German philosophy. Although Kant and Hegel sit quite happily on both analytic and continental curricula, it is only the latter which has seriously addressed the need to rethink how the world appears to us and how it is made manifest to us in the light of their metaphysics. Metaphor has proven to be extremely important for this rethinking because it is the process of conceptual borrowing or reassignment which revises our perception of the world.\n\nThe major shift which occurs in Kantian continental philosophy, according to Cazeaux, is the departure 'from dualistic thought, i.e. thinking which remains within the boundaries created by oppositions, such as mind—body and subjective—objective' . The turn away from dualistic thought is made by Kant on account of his representing experience as the subjective determination of an objective world, thereby placing in a relationship terms which normally stand as opposites in a dualism. As a result of this shift, without conventional dualisms to fall back upon, the process of conceptual borrowing and cross-referral presented by metaphor becomes central as the means by which the textures and complexities of experience can be articulated. Theses to this effect, but with significant differences, can be found in Kierkegaard, Nietzsche, Heidegger, Merleau-Ponty, Bachelard, Paul Ricoeur, and Derrida.\n\nTo give two examples. According to Nietzsche, we are in metaphor or we are metaphor: our being is not derived from a Platonic, eternal essence or from a Cartesian thinking substance but (in as much as there is a way of being we can call ours) is emergent from tensional interactions between competing drives or perspectives . We customarily hold truth to be a relation of correspondence between knowledge and reality but, Nietzsche declares, it is in fact ‘a movable host of metaphors, metonymies, and anthropomorphisms’ due to the fundamentally metaphorical nature of concept-formation, a series of creative leaps from nerve stimulus to retinal image (first metaphor) to sound as signifier (second metaphor) . Our categories, and the judgments we form with them, can never correspond to things in themselves because they are formed through a series of transformations which ensures that ‘there is no causality, no correctness, and no expression’ connecting the first stage (the stimulus) with the last (the concept) .\n\nFor Ricoeur, metaphor is also ‘living’ – hence the title of his book, \"La Métaphore vive\" (translated into English as \"The Rule of Metaphor\" ) – but in a different sense from Nietzsche . Metaphor is living, Ricoeur claims, in that it is the principle which revives our perception of the world and through which we become aware of our creative capacity for seeing the world anew. This process, he thinks, is both paradoxical and Kantian in nature: paradoxical in that the creative combination of terms in a metaphor nevertheless produces meaning which has the character of a discovery (how can something be both a creation and a discovery?), and Kantian because the paradox mirrors Kant’s theory of experience in which the subjective application of concepts nevertheless yields perception of an objective world. The tension between the subjective, creative and the objective, discovery aspects of a metaphor, Ricoeur argues, proceeds ‘from the very structures of the mind, which it is the task of [Kant’s] transcendental philosophy to articulate’ . Unfortunately, the part of Kant’s philosophy which Ricoeur appeals to is highly problematic: the schema or schematism, the operation which Kant dismisses as ‘an art concealed in the depths of the human soul' . Ricoeur’s Kantianism is considered at length by Cazeaux and Stellardi , with the former providing an account of how the schematism might afford a coherent explanation of metaphor.\n\nAnother reason for the attention paid by continental philosophy to metaphor is the questioning of boundaries – between subject areas and between the wider concepts of ethics, epistemology and aesthetics – which has occurred within postmodernism. Principal concerns in these debates are the status of knowledge and the way in which the concepts of truth and objectivity are understood. Philosophy has been under attack on this score with its history of ‘universal truths’, e.g. Descartes’s cogito, Kant’s table of categories, and Hegel’s Absolute Consciousness. The main arguments against this universalism invoke metaphor on two related accounts: (1) the fact that key epistemological concepts have metaphors at their root, for example, “mirroring”, “correspondence”, “sense data”, is taken as evidence of the contingent, communal, subjective basis of knowledge, and (2) because metaphor (as a form of dislocated or dislocating predication) works by testing the appropriate with the inappropriate, it is seen as a means of challenging the boundaries whereby one subject defines itself in relation to another.\n\n\n\n"}
{"id": "31782815", "url": "https://en.wikipedia.org/wiki?curid=31782815", "title": "Nomen à clef", "text": "Nomen à clef\n\nIn romance languages, nomen à clef or nomen à clé (, French for \"name with a key\"), is a name describing a real person, behind a façade of fiction. \"Key\" in this context means a table one can use to swap out the names. \nIt is the nomenclature complement of the roman à clef.\n\n"}
{"id": "1743222", "url": "https://en.wikipedia.org/wiki?curid=1743222", "title": "Norito", "text": "Norito\n\nThere is no single accepted universally accepted theory to explain the meaning of the term. One theory derives \"norito\" from \"noru\" (宣る, 'to declare'; cf. the verbs \"inoru\" 'to pray' and \"norou\" 'to curse') - combined with the suffix \"-to\". A variant term, \"notto\", is derived from a combination of \"norito\" with \"koto\", 'word'.\n\nThere are various known ways of writing the word in kanji: aside from 祝詞 (currently the standard), 詔戸言, 詔刀言, and 諄辞 are also attested.\n\nOne recent writer summed up the original meaning of \"norito\" as \"a general term meaning magic by means of words.\"\n\nThe first written documentation of \"norito\" dates to 712 CE in the \"Kojiki\" and 720 CE in the \"Nihongi\".\n\nThe Engishiki, a compilation of laws and minute regulation presented by the court compiled in 927 CE, preserves twenty-seven representative forms of \"norito\".\n\n\"Norito\" were (and still are) traditionally written in a variety of \"man'yōgana\" where particles and suffixes are written in a smaller script than the main body of the text. This style of writing, used in imperial edicts (宣命 \"senmyō\") preserved in the \"Shoku Nihongi\" and other texts dating from the 8th century (Nara period), is known as \"senmyōgaki\".\n\n"}
{"id": "18894210", "url": "https://en.wikipedia.org/wiki?curid=18894210", "title": "Open-ended question", "text": "Open-ended question\n\nAn open-ended question cannot be answered with a \"yes\" or \"no\" response, or with a static response. Open-ended questions are phrased as a statement which requires a response. The response can be compared to information that is already known to the questioner.\n\nExamples of open-ended questions:\n\nThe received wisdom in education is that open questions are broadly speaking ‘good’ questions. They invite students to give longer responses that demonstrate their understanding. They are preferable to closed questions (i.e. one that demands a yes/no answer) because they are better for discussions or enquiries, whereas closed questions are only good for knowledge testing. \n\nPeter Worley argues that this is a false assumption. This is based on Worley’s central arguments that there are two different kinds of open and closed questions: grammatical and conceptual. He argues that educational practitioners should be aiming for questions that are “grammatically closed, but conceptually open”. For example, in standard parlance, ‘is it ever right to lie?’ would be regarded as a closed question: it elicits a yes/no response. Significantly, however, it is conceptually open. Any initial yes/no answer to it can be ‘opened up’ by the questioner (‘why do you think that?,’ ‘Could there be an instance where that’s not the case?), inviting elaboration and enquiry. \n\nThis grammatically closed but cognitively open style of questioning, Worley argues, “gives [educators] the best of both worlds: the focus and specificity of a closed question (this, after all, is why teachers use them) and the inviting, elaborating character of an open question”. Closed questions, simply require ‘opening up’ strategies to ensure that conceptually open questions can fulfil their educational potential. \n\nWorley's structural and semantic distinction between open and closed questions is integral to his pedagogical invention 'Open Questioning Mindset', or OQM. OQM refers to the development, in educators, of an open attitude towards the process of learning and the questioning at the heart of that process. It is a mind-set that is applicable to all subject areas and all pedagogical environments. Teachers who develop an Open Questioning Mindset listen openly for the cognitive content of student’s contributions and looks for ways to use what is given for learning opportunities, whether right, wrong, relevant or apparently irrelevant. OQM encourages a style of pedagogy that values genuine enquiry in the classroom. It provides teachers with the tools to move beyond what Worley calls ‘guess what’s in my head’ teaching, that relies on closed and leading questions..\n\n"}
{"id": "4574535", "url": "https://en.wikipedia.org/wiki?curid=4574535", "title": "Paremiology", "text": "Paremiology\n\nParemiology () is the collection and study of proverbs.\n\nParemiology can be dated back as far as Aristotle. Paremiography, on the other hand, is the collection of proverbs. The proverb scholar Wolfgang Mieder defines the term \"proverb\" as follows:\n\nAs well as actual proverbs, the following may be considered proverbial phrases:\n\nTypical stylistic features of proverbs (as Shirley Arora points out in her article, \"The Perception of Proverbiality\" (1984)) are:\n\n\nIn some languages, assonance, the repetition of a vowel, is also exploited in forming artistic proverbs, such as the following extreme example from Oromo, of Ethiopia.\nSimilarly, from Tajik:\nNotice that in all of these cases of complete assonance, the vowel is , the most common vowel in human languages.\n\nAlso in Amharic, complete assonance is not infrequent when verbs are in the 3rd person masculine singular, past tense. The vowel <ä> is the most frequent vowel in the language.\n\nInternal features that can be found quite frequently include:\n\nTo make the respective statement more general most proverbs are based on a metaphor. Further typical features of the proverb are its shortness and the fact that its author is generally unknown.\nIn the article \"Tensions in Proverbs: More Light on International Understanding\", Joseph Raymond comments on what common Russian proverbs from the 18th and 19th centuries portray: Potent antiauthoritarian proverbs reflected tensions between the Russian people and the Czar. The rollickingly malicious undertone of these folk verbalizations constitutes what might be labeled a \"paremiological revolt\". To avoid openly criticizing a given authority or cultural pattern, folk take recourse to proverbial expressions which voice personal tensions in a tone of generalized consent. Proverbs that speak to the political disgruntlement include: \"When the Czar spits into the soup dish, it fairly bursts with pride\"; \"If the Czar be a rhymester, woe be to the poets\"; and \"The hen of the Czarina herself does not lay swan's eggs\". While none of these proverbs state directly, \"I hate the Czar and detest my situation\" (which would have been incredibly dangerous), they do get their points across.\n\nProverbs are found in many parts of the world, but some areas seem to have richer stores of proverbs than others (such as West Africa), while others have hardly any (North and South America) (Mieder 2004b:108,109).\n\nProverbs are used by speakers for a variety of purposes. Sometimes they are used as a way of saying something gently, in a veiled way (Obeng 1996). Other times, they are used to carry more weight in a discussion, a weak person is able to enlist the tradition of the ancestors to support his position, or even to argue a legal case. Proverbs can also be used to simply make a conversation/discussion more lively. In many parts of the world, the use of proverbs is a mark of being a good orator.\n\nThe study of proverbs has application in a number of fields. Clearly, those who study folklore and literature are interested in them, but scholars from a variety of fields have found ways to profitably incorporate the study proverbs. For example, they have been used to study abstract reasoning of children, acculturation of immigrants, intelligence, the differing mental processes in mental illness, cultural themes, etc. Proverbs have also been incorporated into the strategies of social workers, teachers, preachers, and even politicians. (For the deliberate use of proverbs as a propaganda tool by Nazis, see Mieder 1982.)\n\nThere are collections of sayings that offer instructions on how to play certain games, such as dominoes (Borajo \"et al.\" 1990) and the Oriental board game go (Mitchell 2001). However, these are not prototypical proverbs in that their application is limited to one domain.\n\nOne of the most important developments in the study of proverbs (as in folklore scholarship more generally) was the shift to more ethnographic approaches in the 1960s. This approach attempted to explain proverb use in relation to the context of a speech event, rather than only in terms of the content and meaning of the proverb.\n\nAnother important development in scholarship on proverbs has been applying methods from cognitive science to understand the uses and effects of proverbs and proverbial metaphors in social relations.\n\n"}
{"id": "24342055", "url": "https://en.wikipedia.org/wiki?curid=24342055", "title": "Peeters directive", "text": "Peeters directive\n\nThe Peeters directive (, ), officially Circular BA 97/22 of 16 December 1997 concerning the use of languages in municipal councils of the Dutch language area, is a \"circulaire\" of the Flemish government regulating the use of languages in municipal councils in the Flemish Region (Belgium), where the sole official language is Dutch. The directive is more in particular aimed at the municipalities with language facilities bordering the Brussels Capital-Region. It stipulates that each and every time French-speakers deal with the government, they must explicitly ask for their documents to be in French.\n\nThe circular caused national political commotion and reflects the conflicting perception of language facilities in Dutch and French-speaking public opinion. The non-appointment of three mayors of municipalities with language facilities — refused by the Flemish government because they repeatedly ignored the Peeters (and Keulen) directives — was a highly mediatised issue during the 2007–2008 Belgian government formation. It attracted international attention when the mayors took their case to the Congress of Local and Regional Authorities of the Council of Europe.\n\nWith the territoriality principle as the basic guideline of Belgian language politics, the language law of 28 June 1932 divided the country in the Dutch-speaking region, the French-speaking region and the German-speaking region. Brussels received a bilingual Dutch-French status. The law further stipulated that municipalities along the language border and around Brussels had to ensure a bilingual service when the minority language population exceeded 30% (so-called language facilities) and that the language of administration would be changed when this \"minority\" exceeded 50%. In order to estimate the number of speakers of each language, a decennial language census was established, of which the results were often contested by the Flemish.\n\nThe consensus in contemporary historical and political literature is that the results of the language census have to be interpreted with caution. The questions were alternatively on \"known\" languages or on the \"usual\" language, the most often spoken. Some considered this to refer to their mother tongue, while for others it referred to the prestigious and ubiquitous language that was French. Moreover, the censuses of 1920 and 1947 were performed in a post-war climate. Dutch, being closely related with German, was discredited due to collaborationism of certain wings of the Flemish Movement with the German occupation. French on the other hand enjoyed the status of the language of victory. Finally, given that the results had political consequences, inviting for manipulation in some cases, the census had more of a referendum on the language status of the municipality than of a sociological inquiry. In the 1947 census, more than 30% declared to speak French \"exclusively or most frequently\" in Wemmel, Kraainem, Drogenbos and Linkebeek, which meant that the French-speaking population of these municipalities received language facilities, whereby citizens can request to communicate with the municipal services in the language of their choice, while the official language remained the same.\n\nThe language laws of 1962-63, constitutionally entrenched in 1970, abolished the language census and fixed the language border between the language areas. All Belgian municipalities belong to one of these territories. Some municipalities went from one region to another, while others retained or were given a system of language facilities. Wezembeek-Oppem and Sint-Genesius-Rode became municipalities with language facilities. The last census in 1947 showed that the French minority in these towns was 18% and 16% respectively, but that 35% and 27% spoke French most frequently.\n\nAccording to art. 7 of the 1966 law on the use of languages in the administration, the six municipalities situated in the Brussels periphery, namely Drogenbos, Kraainem, Linkebeek, Sint-Genesius-Rode, Wemmel and Wezembeek-Oppem, enjoy a \"special treatment\" and are called \"rim municipalities\". As part of the wider Frenchification of Brussels and a process of urbanisation, these formerly Dutch-speaking municipalities became majority French-speaking in the second half of the 20th century. This phenomenon, known in Flanders as the \"oil slick\", is, together with the future of Brussels, one of the most controversial topics in all of Belgian politics. All other municipalities with facilities, except for those in the German language area, plus Malmedy and Waimes, are grouped together as \"language border municipalities\" (art. 8).\n\nAccording to a 1986 ruling of the Constitutional Court, the division in language regions entails \"a restriction on the ability of legislators to regulate the use of languages and so forms the constitutional guarantee of the priority of the language of the unilingual area\". The 1988 revision of the constitution (art. 129, §1) confirms that the parliaments of the French Community and the Flemish Community determine through decrees, each for their respective territory, the use of languages in administrative matters, the education system, for social contacts between the employer and his employees, and for official documents in business. However, the constitution (art. 129, §2) makes an exception for municipalities with language facilities, stating that in those municipalities the law on the use of languages for situations listed in §1 can only be changed by a law adopted by a majority in both language groups.\n\nThe Standing Commission for Linguistic Supervision is a federal institution responsible for collecting and reporting language complaints. It can give its opinion to the responsible public authorities, but its opinions are not binding. In its recommendations 26.125A, 26.033 and 23.062 (all published in 1994), the agency argued that language facilities should not lead to a generalised system of bilingualism of public services in which both languages would hold equal status. Only the regional governments can provide a supreme binding political interpretation for the language laws and the application of language facilities, which can only be annulled by the Council of State.\n\nAs a general rule, the federal government communicates with citizens in the language of the region, not in their individual language. Only in municipalities with facilities, another language can be used when so requested.\n\nThe Peeters directive's recommendations for municipalities with language facilities bordering the Brussels Capital-Region and the language border, where to some extent the French-speaking population has the right to relate with the local and federal administration in French, have triggered political commotion. It stipulates these facilities, being \"an exception to the rule of unilingualism of the official language areas\", should be interpreted \"strictly\", considering their \"exceptional\" and \"temporary\" character.\n\nThe directive argues language facilities have an \"integrative function\", meaning that, \"per definition\", \"for the concerned individual\", they have an \"extinguishing character\". It reads further: \"The interpretation of language facilities has to take into account the possibility that a French-speaking inhabitant, who previously made use of these facilities, meanwhile knows the language of the region well enough and consequently no longer wishes to invoke the facilities\". In this sense, facilities are temporary in character, and because they are temporary, they have to be applied \"restrictively\", implying that French-speakers have to make a new request each and every time they wish to use French in official affairs. The directive claims the \"spirit in which the language laws of 1962-63 were established\" is reflected in the end report of the Harmel Centre:\n\nAccording to the directive, this quote clearly shows that the language facilities were intended to ease the transition of the minority language inhabitants to the Community to which their municipality would belong from that moment onwards.\n\nThe most important rule introduced by the Peeters directive is that all official documents have to be sent to the citizens in Dutch. Afterwards, French-speakers can request a French translation for each separate document, on their own initiative. As for the application of documents in the town hall, all these documents have to be issued in Dutch in the municipalities along the language border, after which a translation can be requested. For the \"rim municipalities\" (those bordering Brussels), a French translation can be requested beforehand. Such a restrictive meaning went against the existing practice, whereby citizens had to declare their preferred language only once.\n\nAnother issue is that the Peeters directive stipulates that the language of administration and local public services should at all times be Dutch, the only official language of the concerned municipalities. It is obligatory to speak Dutch in meetings of the municipal council and the Board of Mayor and Aldermen.\n\nOn the initiative of the municipality of Linkebeek, the Constitutional Court of Belgium was asked for an opinion on the constitutionality of article 23 of the law of 18 July 1966 that stipulates that the internal language of administration in the rim municipalities has to be Dutch. In its ruling 98/26 of 10 March 1998, the Court ruled this was not in violation with articles 10 and 11 of the Constitution of Belgium and that the mayor and aldermen do indeed not have the right to speak in another language than Dutch during council meetings. The Court further specified that the language facilities do not alter the principle of Dutch unilingualism of the concerned municipalities and that the Constitution guarantees the primacy of Dutch.\n\nOn 27 February 1998, the French Community of Belgium and the Walloon Region, together with a French-speaking inhabitant of one of the concerned rim municipalities, challenged the legitimacy of the directive before the Council of State. On 27 March 2001, the court argued that two first plaintiffs did not have any powers within the territory of the Flemish Region, and dismissed the appeal on those grounds. The case of the French-speaking inhabitant was forwarded to a Dutch-speaking chamber (since the other two plaintiffs were removed from the case, the competetent chamber changed) and debates were reopened. On 25 February 1998, the municipality of Kraainem (in the periphery of Brussels, with a French-speaking majority) had initiated another case, also requesting annulment of the directive. On 28 May, Wemmel and Wezembeek-Oppem filed for intervention, joined by Drogenbos on 28 July 2008. The municipalities (and a number of French-speaking inhabitants) claimed that the directive introduced new rules, and thus conflicted with art. 129, §2 of the Constitution.\n\nOn 23 December 2004, the Council of State decided not to nullify the directive. It argued that although the directive may have changed existing practice, it did not change the legal situation and was only to reverse the habit of municipal administrations of addressing a citizen in French without an explicit repeated request, and that the directive did not impede the use of French when wished. The court followed ruling 98/26 of the Constitutional Court, stating that the interpretation of the language law had to match the priority of Dutch; that the interpretation of the language facilities put forward by the plaintiffs did thus not apply, but would on the contrary lead to \"a factual state of bilinguism whereby the language preference would even be stocked in files\".\n\nThe Court's decision was received with derision by the French-speaking political parties. In a reaction of 13 January 2005, the Front Démocratique des Francophones (FDF) wrote:\n\nOn 25 January 2005, the parliament of the French Community of Belgium ratified a \"Resolution aimed to reaffirm the unswerving link between the French Community and the French-speakers of the [Brussels] periphery and Voeren\":\n\nOn 13 October 2003, the municipality of Wezembeek-Oppem summoned the Flemish Region for its decision of 13 August 2003 to nullify its decision of 21 January 2001 to send out invitation letters for the 2003 federal elections in French to those who it assumed were French-speaking. According to the Peeters directive, these had to be issued in Dutch first after which a French translation could be requested. On 19 July 2008, the Council of State referred back to its rulings of 23 December 2004 and ruled that the Peeters directive was the only correct interpretation of the language law concerning the six rim municipalities. It argued only the Flemish government was in place of interpreting the law, that the interpretation of the Peeters directive was in conformity with the general principles of the law and that no other interpretation held legal authority. The Court refuted the argument of the plaintiff that the advice of the Standing Commission for Linguistic Supervision (to stock the language preference of citizens and directly addressing them in that language, which was explicitly forbidden by the Keulen directive) should be followed, arguing the Commission had no legal authority. The Court repeated that the interpretation put forward by the municipality of Wezembeek-Oppem would in practice result in a situation of bilingualism that would be in contradiction with the priority of Dutch and the fundamental Dutch unilingualism of these municipalities.\n\nOn 16 December 1997 the directive was sent to the governors of the five Flemish provinces by the then Flemish minister of Internal Affairs, Leo Peeters. It was amended by the Martens directive of 5 May 1998 that prescribed a similar arrangement for the social services. Both directives were reconfirmed and specified by the Keulen directive of 8 July 2005, which was not well received by the French-speaking press and politicians.\n\nThe municipal councils of Sint-Genesius-Rode, Linkebeek, Wezembeek-Oppem and Kraainem sent out convocation letters for the 2006 provincial and municipal elections in French to the citizens of which they assumed were French-speaking. This was contrary to the Peeters directive ordering municipalities to send out documents in Dutch first, after which a French translation can be requested and the Keulen directive, prohibiting the stocking of language preference. In Flanders (contrary to Wallonia), mayors are not directly elected. Instead, after the elections, the town council nominates a candidate-mayor, who then has to be appointed by the Flemish Minister of the Interior. Marino Keulen, then minister, delayed the appointment of the four proposed mayors because they did not apply language legislation. Three of the four mayors repeated their actions for the 2007 federal elections. On 14 November 2007, the appointment of Arnold d'Oreye de Lantremange (FDF, for Kraainem), François van Hoobrouck d'Aspre (UF, for Wezembeek-Oppem) and Damien Thiéry (FDF, for Linkebeek) was officially rejected. The mayor of Sint-Genesius-Rode, Myriam Delacroix-Rolin (CDH), was appointed since she applied the language laws.\n\nInstead of challenging their non-appointment before the Council of State, the three mayors chose to bring it before the Congress of Local and Regional Authorities of the Council of Europe. On 13 and 14 May 2008, the Congress sent a fact-finding mission to Belgium to look into the situation. The delegation was led by a Frenchman and consisted further of a Serbian representative, a German expert, and two other French members of the Congress. The Council of Europe can make recommendations to its 47 member states, but it cannot impose sanctions on them for non-compliance and its conclusions are not legally binding. The mayors allowed that French was spoken during council meetings and refused to apply the recommendations of the Flemish directives. This went against the stipulations of language laws and lead to their non-appointment. Michel Guégan, president of the delegation, found that the sanction of non-appointment was disproportionate to the infractions. According to him, it hindered the normal functioning of the municipality. He also questioned why the regional authority had to appoint \"democratically elected mayors\". He also said that in towns with French-speaking majorities, participation of the inhabitants in local politics is complicated when the official language of administration is Dutch. The decisions of the delegation were considered ridiculous in Flanders. The Flemish Interior Minister, Marino Keulen, said they were \"absurd\" because they did not take into account the language legislation, the grounds on which their nomination was refused. In the European Parliament, Frieda Brepoels (N-VA) decounced \"the arrogance and thoughtlessness\" of the delegation. The Flemish government ignored the resolutions of the fact-finding mission, Keulen saying the acting mayors should take their case to the Council of State rather than to the Council of Europe. On 2 December 2008, the Congress voting a resolution on the issue. Of all 46 members entitled to vote, 16 were present: 14 voted in favour, the only Flemish representative voted against, and the only Dutch member abstained from voting. In the adopted resolution, the Congress urged the Belgian state to appoint the mayors and to review the language legislation in the concerned municipalities.\n\nMinister Keulen \"took notice\" of the Congress's recommendations but stressed that only the Council of State was competent to undo his decision. For the 2009 regional elections, the three acting mayors sent out French documents again. Sint-Genesius-Rode sent out convocation letters in Dutch to all citizens, accompanied by a French translation for those considered to be French-speaking.\n\nAs of February 2010, the three acting mayors are still not appointed and the Peeters, Martens and Keulen directives are still in force.\n"}
{"id": "35063433", "url": "https://en.wikipedia.org/wiki?curid=35063433", "title": "Phonological dyslexia", "text": "Phonological dyslexia\n\nPhonological dyslexia is a reading disability that is a form of alexia (acquired dyslexia), resulting from brain injury, stroke, or progressive illness and that affects previously acquired reading abilities. The major distinguishing symptom of acquired phonological dyslexia is that a selective impairment of the ability to read pronounceable non-words occurs although the ability to read familiar words is not affected. It has also been found that the ability to read non-words can be improved if the non-words belong to a family of pseudohomophones.\n\nIndividuals who suffer from phonological dyslexia have the opposite problem to surface dyslexics. These individuals are able to read using the whole word method. However, they struggle when it comes to sounding words out. Phonological dyslexics are able to read familiar words, but have difficulties when it comes to unfamiliar words or non-words that are pronounceable. Several studies have found that many phonological dyslexics have a good reading ability if the individual has developed a large vocabulary prior to suffering from brain damage. These individuals seem to stop developing their vocabulary post-brain damage, which affects their reading capacity.\n\nPhonological dyslexia is a reading disorder in which the patient has impaired reading of nonwords. The symptoms of phonological dyslexia are very similar to those of deep dyslexia. The major difference between these two dyslexias is that phonological dyslexics do not make semantic errors associated with deep dyslexia. Beauvois and Dérouesné (1979) studied the first case of phonological dyslexia and came up with this term. The problem people with phonological dyslexia have is that they are able to read words using the whole word method; however, they are not able to sound words out. This means that they are able to read familiar words, but have difficulties reading new words.\n\nInitially it was believed that the factor causing phonological dyslexia was lexicality; however, other factors such as imageability and concreteness also play a critical role in reading. A study done by Crisp and Lambon Ralph concluded that imageability has a significant effect on phonological dyslexia. The study found that eleven out of the twelve patients had more accuracy when reading words with high imageability. In that study, the patient who was the exception was the least severely damaged, contributing to a view of phonological dyslexia and deep dyslexia as points on a continuum rather than discrete disorders.\n\nSeveral studies have found that different levels of brain damage can lead to the occurrence of varying forms of non-word reading disorders. It has been found that during certain tasks, dyslexics had activated one of two regions of the brain: the Broca's area, which is responsible for speech, or the Wernicke's area, which is responsible for forming and understanding. Both areas were seldom active together. This study has led to the conclusion that there exist neural connection breakdowns between the language centers that may be causing dyslexia.\n\nAn investigation conducted by Harley, T. A., and O'Mara, D.A. (2006) found that hyphenation significantly improved a participant`s reading ability. The subject suffered from phonological dyslexia that was due to a deficiency in graphemic parsing. The study suggested that hyphenation might be generally useful as a strategy to assist phonological dyslexics.\n\nA study was done by Beauvois and Dérouesné on a 64-year-old man. The individual is described as right-handed, a retiree, and having formerly been an agricultural machinery representative. The individual had had surgery for a left parieto-occipital angioma. Scans showed a lesion at the left angular gyrus, the posterior part of the second temporal convolution, the inferior longitudinal fasciculus, the geniculostriate fibres and tapetum. The patient was also found to be suffering from neurological defects such as right inferior quadrantanopia, mild memory deficit, mild calculation impairment, minimal constructional apraxia, and astereognosia. It was found that the patient did not suffer from motor or sensory defects. He had been obliged to retire as the phonological dyslexia disrupted his ability to work. He had previously enjoyed reading, but was now unable to read his own or other pieces of writing. The diagnosis was confirmed with the Alouette reading test, which concluded that the patient suffered from a reading disability. He was found to have the reading ability of a 6-year-old child, which is considered to be the lowest reading level. The level of reading was not determined from the speed, rather from the fact that the patient was not able to read more than 62 of the stimuli presented in three minutes, while 40% of the represented stimuli were either read incorrectly or left unread. The reading errors included adjectives, possessive adjectives, conjunctions and verbs.\n\nPatients with phonological dyslexia have problem reading non-words and unfamiliar words. According to the dual route model, patients with phonological dyslexia use route 2 or 3 that have intact orthographic input lexicon which allow them to pronounce familiar words whether regular or irregular. However due to phonological dyslexia they are unable to use grapheme-phoneme conversion (Route 1), as route 1 is impaired, thus patients find it difficult to pronounce unfamiliar words and non-words. \n\n\n\n"}
{"id": "1623045", "url": "https://en.wikipedia.org/wiki?curid=1623045", "title": "Registry of Interpreters for the Deaf", "text": "Registry of Interpreters for the Deaf\n\nThe Registry of Interpreters for the Deaf, Inc (RID) is a non-profit organization, founded in 1964 and incorporated in 1972, that seeks to uphold standards, ethics, and professionalism for American Sign Language interpreters. RID is the only organization in the United States that credentials both d/Deaf and Hearing interpreters to provide services in a wide range of settings, as well as test and certify interpreters for legal work. The RID Board is committed to the \"4 R's\" which are: Roots, Respect, Relevance and Results. As of 2014 there were over 15,000 members and 58 affiliate chapters. \n\nSince August 2004, RID has been building stronger ties with the National Association of the Deaf (NAD), including a joint Code of Professional Ethics and the merging of their respective certification programs. They jointly developed the National Interpreter Certification test (NIC), which was adopted in 2005.\n\nRID is headquartered in Alexandria, Virginia, with a roughly $3,000,000 annual budget and around 20 employees. The association's operations are led by an executive director (currently vacant) and governed by an eleven-member board of directors. \n\nRID is governed by an eleven-member board of directors elected directly by the voting membership for a two-year term. Voting rights are determined by being a member in good standing of both RID (in the certified or associate category) and a sanctioned affiliate chapter. The board is made up of the following positions: \nFollowing the expiration of the president's term, they serve an ex officio non-voting term on the board of directors as Immediate Past President. \n\nThe Executive Board consists of the President, Vice President, Secretary, Treasurer, Member-at-Large, and Deaf Member-at-Large, and is elected on odd years for two-year terms. The regional representative positions are elected on even years for two-year terms. \n\nTo run for election to the Executive Board, members must collect 25 nomination signatures from voting members with at least one from each region of RID. Regional representative candidates must collect 25 nomination signatures from within their region. All positions except the Member-at Large require the candidate to be certified member of RID for four consecutive years prior to candidacy. Member-at-Large requires either associate or certified membership in RID for four consecutive years prior to candidacy. Additionally, regional representative candidates must have resided in their region at least two years prior to candidacy. If there are more than one candidates, an election is held via on-line balloting. p\n\nThe 2007–2018 board of directors are as follows:\n\nRID operations are conducted by a paid staff led by an Executive Director. Since 2014, RID has not had a permanent Executive Director following the departure of Shane Feldman. The board contracted with Anna Witter-Merithew who served as Interim Executive Director until August 2017. Since that time, the board has served as Executive Director through President Melvin Walker while continuing a permanent Executive Director search.\n\nAs part of their push to improve the ethical behavior of practitioners in the field, RID revised and updated existing guidelines from the Code of Ethics. In 2005, the Code of Professional Conduct was adopted as the newest set of principles interpreters should adhere to. Certified interpreters have an especially strong duty to follow the principles laid out by RID, for the integrity of the work, the well being of the stakeholders, and to avoid causing harm.\n\nThe tenets from the current Code of Professional Conduct are:\n\n\nRID has a national certification system with three key components: \n\n\nIn previous incarnations of the NTS, the following certifications were given to interpreters meeting the testing criteria (All credentials awarded by the Registry of Interpreters for the Deaf will remain valid as long as the holder of said certification(s) maintains their membership and maintenance program.):\n\nPreviously offered certificates:\n\n\nCurrently offered certificates:\n\n\nRID granted certified membership to holders of the defunct NAD certification at levels III, IV and V as well as those who pass the Educational Interpreter Performance Assessment (EIPA) at proficiency level 4.0 with a passing score on the EIPA written exam. The certifications for these members are listed as:\nNo new certified member status is being granted for any of these categories. \n\nAs of July 2005, a new certification test, developed with the NAD, was implemented and the CI and CT tests began to be phased out. The new generalist certification for hearing interpreters is the NAD-RID National Interpreter Certification (NIC). In 2015 NAD decided to withdraw its involvement from the NIC resulting its name being removed from the test. \n\nRID formed a limited liability company called the Center for Assessment of Sign Language Interpretation (CASLI) in 2015 to carry out all testing functions. CASLI is a wholly owned subsidiary, supported operationally by RID headquarters staff and governed by a Managing Board that reports to the RID Board of Directors. As of 2017, the Board of Managers consisted of: \n\nIn 2017, CASLI's operations began direct supervision by Star Grieser, CDI who reports to the RID Deputy Director. \n\nCASLI's formation began a clearer philosophical and practical split of certification from professional testing. Under this new scheme, CASLI is granted greater autonomy to design, prepare and conduct generalist testing for both Deaf and hearing interpreters. RID retains the function of certifying interpreters based on their testing results and other certification criteria. As such, the EPS and CMP systems remain under RID's direct control. \n\n\n"}
{"id": "42312430", "url": "https://en.wikipedia.org/wiki?curid=42312430", "title": "Sakshi (Witness)", "text": "Sakshi (Witness)\n\nSakshi or Sākṣī (Sanskrit: साक्षी) means – 'observer', 'eyewitness' or the 'Supreme Being' the one that lends its shine - \" Chitchhaya\"- to the \"ego\" part of the subtle body - which consists of the everchanging Mind, the decision making Intellect, the Memory & the Illusory Ego ! In Hindu philosophy, the word, \"Sākṣī\" or 'witness' refers to the 'Pure Awareness' that witnesses the world but does not get affected or involved. \"Sakshi\" is beyond time, space and the triad of experiencer, experiencing and experienced; \"sakshi\" witnesses all thoughts, words and deeds without interfering with them or being affected by them, other than \"sakshi\" there is nothing else in the entire universe.\n\nWith regard to the word, साक्षी (\"sākṣī\"), used in the following verse from Shvetashvatara Upanishad,\n\nPanini states that the same indicates a direct seer or eyewitness (Panini Sutras V.ii.91), Sakshi means Ishvara, the चेता (cetā), the sole Self-consciousness, who is the witness of all, who gives consciousness to every human being, thereby making each rational and discriminatory.\n\nVedanta speaks of mind (\"chitta\") or \"antahkarana\" ('internal instrument'), and matter as the subtle and gross forms of one and the same reality; being the subtle aspect of matter, mind is not a tangible reality. The field of mind (\"Chittakasha\") involves the duality of the seer and the seen, the observer (\"drg\") and the observed (\"drshya\"), which duality is overcome in the field of pure Consciousness. \"Drg-drshya-Viveka\" tells us:-\n\n\"Sakshi\", the Atman, the unchangeable eternal Reality, is the Pure Consciousness and knowledge, in which regard Sankara explains that knowledge does not destroy or create, it only illumines, that the senses (\"indriyas\") are not the mind, the mind uses them as an implement.\n\nThe Varaha Upanishad (IV) refers to the \"Bhumika\" ('stage of development of wisdom') which is of the form of \"pranava\" (\"Aum\" or \"Om\") as formed of or divided into – \"akāra\", \"ukāra\", \"makāra\" and \"ardhmātra\", which is on account of the difference of \"sthula\" ('gross'), \"sukshama\" ('subtle'), \"bija\" ('seed' or 'causal') and \"sakshi\" ('witness') whose \"avasthas\" ('states') are – 'waking', 'dreaming', 'dream-less sleep' and 'turiya'. \"Sakshi\" which is 'turiya' is the essence.\n\nThe faculty which perceives the individual personality is \"Sakshi\" or 'Witness' or the higher 'Ego'. Mind (\"manas\"), Ego (\"ahankara\") and \"Sakshi\", all perform different functions but that difference of functions does not mean difference in nature or essence. Indian Philosophy discovered the concept of \"Sakshi\", the ultimate Observer, or Witness behind the sense of individuality, or the ego; the \"Sakshi\" is the timeless Being which witnesses all this ceaseless flow and change in the world of thought and things.\n"}
{"id": "162986", "url": "https://en.wikipedia.org/wiki?curid=162986", "title": "Second language", "text": "Second language\n\nA person’s second language or L2 is a language that is not the native language/first language/L1 of the speaker, but is learned by the speaker after his/her native language (usually a foreign language, see below). Additionally, a person’s second language can be explained as the second language in the country the speaker lives in and they may be both used in daily life. For example, Canada has two official languages (English and French) and some citizens speak and use both of them.<br>\nA person’s dominant language, which is the language the speaker uses most or is most comfortable with, is not necessarily to be his/her first language. The second language can also be the dominant one. For example, the Canadian census defines first language for its purposes as \"the first language learned in childhood and still spoken\", recognizing that for some, the earliest language may be lost, a process known as language attrition. This can happen when young children move, with or without their family (because of immigration or international adoption), to a new language environment.<br>\n\nThe distinction between acquiring and learning was made by Stephen Krashen (1982) as part of his Monitor Theory. According to Krashen, the \"acquisition\" of a language is a natural process; whereas \"learning\" a language is a conscious one. In the former, the student needs to partake in natural communicative situations. In the latter, error correction is present, as is the study of grammatical rules isolated from natural language. Not all educators in second language agree to this distinction; however, the study of how a second language is \"learned/acquired\" is referred to as \"second-language acquisition\" (SLA).\n\nResearch in SLA \"...focuses on the developing knowledge and use of a language by children and adults who already know at least one other language... [and] a knowledge of second-language acquisition may help educational policy makers set more realistic goals for programmes for both foreign language courses and the learning of the majority language by minority language children and adults.\" (Spada & Lightbown, p. 115).\n\nSLA has been influenced by both linguistic and psychological theories. One of the dominant linguistic theories hypothesizes that a \"device\" or \"module\" of sorts in the brain contains innate knowledge. Many psychological theories, on the other hand, hypothesize that cognitive mechanisms, responsible for much of human learning, process language.\n\nOther dominant theories and points of research include 2nd language acquisition studies (which examine if L1 findings can be transferred to L2 learning), verbal behaviour (the view that constructed linguistic stimuli can create a desired speech response), morpheme studies, behaviourism, error analysis, stages and order of acquisition, structuralism (approach that looks at how the basic units of language relate to each other according to their common characteristics), 1st language acquisition studies, contrastive analysis (approach where languages were examined in terms of differences and similarities) and inter-language (which describes L2 learners’ language as a rule-governed, dynamic system) (Mitchell, Myles, 2004). \nThese theories have all influenced second-language teaching and pedagogy. There are many different methods of second-language teaching, many of which stem directly from a particular theory. Common methods are the grammar-translation method, the direct method, the audio-lingual method (clearly influenced by audio-lingual research and the behaviourist approach), the Silent Way, Suggestopedia, community language learning, the Total Physical Response method, and the communicative approach (highly influenced by Krashen’s theories) (Doggett, 1994). Some of these approaches are more popular than others, and are viewed to be more effective. Most language teachers do not use one singular style, but will use a mix in their teaching. This provides a more balanced approach to teaching and helps students of a variety of learning styles succeed.\n\nThe defining difference between a first language (L1) and a second language (L2) is the age the person learned the language. For example, linguist Eric Lenneberg used \"second language\" to mean a language consciously acquired or used by its speaker after puberty. In most cases, people never achieve the same level of fluency and comprehension in their second languages as in their first language. These views are closely associated with the critical period hypothesis.\n\nIn acquiring an L2, Hyltenstam (1992) found that around the age of six or seven seemed to be a cut-off point for bilinguals to achieve native-like proficiency. After that age, L2 learners could get \"near-native-like-ness\" but their language would, while consisting of few actual errors, have enough errors to set them apart from the L1 group. The inability of some subjects to achieve native-like proficiency must be seen in relation to the \"age of onset\" (AO). Later, Hyltenstam & Abrahamsson (2003) modified their age cut-offs to argue that after childhood, in general, it becomes more and more difficult to acquire native-like-ness, but that there is no cut-off point in particular.<br>\n\nAs we are learning more and more about the brain, there is a hypothesis that when a child is going through puberty, that is the time that accents \"start\". Before a child goes through puberty, the chemical processes in the brain are more geared towards language and social communication. Whereas after puberty, the ability for learning a language without an accent has been rerouted to function in another area of the brain—most likely in the frontal lobe area promoting cognitive functions, or in the neural system of hormone allocated for reproduction and sexual organ growth.\n\nAs far as the relationship between age and eventual attainment in SLA is concerned, Krashen, Long, and Scarcella, say that people who encounter foreign language in early age, begin natural exposure to second languages and obtain better proficiency than those who learn the second language as an adult. However, when it comes to the relationship between age and rate SLA, “Adults proceed through early stages of syntactic and morphological development faster than children (where time and exposure are held constant)” (Krashen, Long, Scarcella 573). Also, “older children acquire faster than younger children do (again, in early stages of morphological and syntactic development where time and exposure are held constant)” (573). In other words, adults and older children are fast learners when it comes to the initial stage of foreign language education.\n\nGauthier and Genesee (2011) have done a research which mainly focuses on the second language acquisition of internationally adopted children and results show that early experiences of one language of children can affect their ability to acquire a second language, and usually children learn their second language slower and weaker even during the critical period.<br>\n\nAs for the fluency, it is better to do foreign language education at an early age, but being exposed to a foreign language since an early age causes a “weak identification” (Billiet, Maddens and Beerten 241). Such issue leads to a \"double sense of national belonging,\" that makes one not sure of where he or she belongs to because according to Brian A. Jacob, multicultural education affects students' \"relations, attitudes, and behaviors\" (Jacob 364). And as children learn more and more foreign languages, children start to adapt, and get absorbed into the foreign culture that they “undertake to describe themselves in ways that engage with representations others have made” (Pratt 35). Due to such factors, learning foreign languages at an early age may incur one’s perspective of his or her native country.\nAcquiring a second language can be a lifelong learning process for many. Despite persistent efforts, most learners of a second language will never become fully \"native-like\" in it, although with practice considerable fluency can be achieved. However, children by around the age of 5 have more or less mastered their first language with the exception of vocabulary and a few grammatical structures, and the process is relatively very fast because language is a very complex skill. Moreover, if children start to learn a second language when they are 7 years old or younger, they will also be fully fluent with their second language in a faster speed comparing to the speed of learning by adults who start to learn a second language later in their life. <br>\n\nIn the first language, children do not respond to systematic correction. Furthermore, children who have limited input still acquire the first language, which is a significant difference between input and output. Children are exposed to a language environment of errors and lack of correction but they end up having the capacity to figure out the grammatical rules. Error correction does not seem to have a direct influence on learning a second language. Instruction may affect the rate of learning, but the stages remain the same. Adolescents and adults who know the rule are faster than those who do not. <br>\n\nIn the learning of a second language the correction of errors remains a controversial topic with many differing schools of thought. Throughout the last century much advancement has been made in research on the correction of students’ errors. In the 1950s and 60s the viewpoint of the day was that all errors must be corrected at all costs. Little thought went to students’ feelings or self-esteem in regards to this constant correction (Russell, 2009).\n\nIn the 1970s Dulay and Burt’s studies showed that learners acquire grammar forms and structures in a pre-determined, inalterable order, and that teaching or correcting styles would not change this (Russell, 2009).\n\nIn this same decade Terrell (1977) did studies that showed that there were more factors to be considered in the classroom than the cognitive processing of the students (Russell, 2009). He contested that the affective side of students and their self-esteem were equally important to the teaching process (Russell, 2009).\n\nA few years later in the 1980s, the strict grammar and corrective approach of the 1950s became obsolete. Researchers asserted that correction was often unnecessary and that instead of furthering students’ learning it was hindering them (Russell, 2009). The main concern at this time was relieving student stress and creating a warm environment for them. Stephen Krashen was a big proponent in this hands-off approach to error correction (Russell, 2009).\n\nThe 1990s brought back the familiar idea that explicit grammar instruction and error correction was indeed useful for the SLA process. At this time, more research started to be undertaken to determine exactly which kinds of corrections are the most useful for students. In 1998, Lyster concluded that “recasts” (when the teacher repeats a student’s incorrect utterance with the correct version) are not always the most useful because students do not notice the correction (Russell, 2009). His studies in 2002 showed that students learn better when teachers help students recognize and correct their own errors (Russell, 2009). Mackey, Gas and McDonough had similar findings in 2000 and attributed the success of this method to the student’s active participation in the corrective processes.\n\nAccording to Noam Chomsky, children will bridge the gap between input and output by their innate grammar because the input (utterances they hear) is so poor but all children end up having complete knowledge of grammar. Chomsky calls it the Poverty of Stimulus. And second language learners can do this by applying the rules they learn to the sentence-construction, for example. So learners in both their native and second language have knowledge that goes beyond what they have received, so that people can make correct utterances (phrases, sentences, questions, etc) that they have never learned or heard before.<br>\n\nBilingualism has been an advantage to today's world and being bilingual gives the opportunity to understand and communicate with people with different cultural backgrounds. However, a study done by Optiz and Degner in 2012 shows that sequential bilinguals (i.e. learn their L2 after L1) often relate themselves to the emotions more when they perceive these emotions by their first language/native language/L1, but feel less emotional when by their second language even though they know the meaning of words clearly. The emotional distinction between L1 and L2 indicates that the \"effective valence\" of words is processed less immediate in L2 because of the delayed vocabulary/lexical access to these two languages.<br>\n\nSuccess in language learning can be measured in two ways: likelihood and quality. First language learners \"will\" be successful in both measurements. It is inevitable that all people will learn a first language and with few exceptions, they will be fully successful. For second language learners, success is not guaranteed. For one, learners may become fossilized or \"stuck\" as it were with ungrammatical items. (Fossilization occurs when language errors become a permanent feature. See Canale & Swain (1980), Johnson (1992), Selinker (1972), and Selinker and Lamendella (1978).) The difference between learners may be significant. As noted elsewhere, L2 learners rarely achieve complete \"native-like\" control of the second language. <br>\nFor L2 pronounciation, there are two principles that haven been put forth by Levis (2005). The first is nativeness which means the speakers' ability to approximately reach the speaking pattern of the second language of speakers; and the second, understanding, refers to the speaker's ability to make themselves understood.\nBeing successful in learning a second language can seem like a daunting task. Research has been done to look into why some students are more successful than others. Stern (1975), Rubin (1975) and Reiss (1985) are just a few of the researchers who have dedicated time to this subject. They have worked to determine what qualities make a \"good language learner\" (Mollica, Neussel, 1997). Some of their common findings are that a good language learner uses positive learning strategies, is an active learner who is constantly searching for meaning. Also a good language learner demonstrates a willingness to practice and use the language in real communication. He also monitors himself and his learning, has a strong drive to communicate, and has a good ear and good listening skills (Mollica, Neussel, 1997).<br>\n\nÖzgür and Griffiths have designed an experiment in 2013 about the relationship between different motivations and second language acquisition. They have looked at four types of motivations—intrinsic (inner feelings of learner), extrinsic (reward from outside), integrative (attitude towards learning), and instrumental (practical needs). According to the test results, the intrinsic part has been the main motivation for these student who learn English as their second language. However, students report themselves being strongly instrumentally motivated. In conclusion, learning a second language and being successful depend on every individual.<br>\n\nIn pedagogy and sociolinguistics, a distinction is made between second language and foreign language, the latter is being learned for use in an area where that language is originally from another country and not spoken in the native country of the speakers. And in other words, foreign language is used from the perspective of countries; the second language is used from the perspective of individuals.\n\nFor example, arguably, English in countries such as India, Pakistan, Bangladesh, the Philippines, the Nordic countries and the Netherlands can be considered a second language for many of its speakers, because they learn it young and use it regularly; indeed in southern Asia it is the official language of the courts, government and business. The same can be said for French in Algeria, Morocco and Tunisia, although French is nominally not an official language in any of these Arabic-speaking countries. In practice, French is widely used in a variety of contexts in these countries, and public signs are normally printed in both Arabic and French. A similar phenomenon exists in post-Soviet states such as the Ukraine, Uzbekistan, Kyrgyzstan and Kazakhstan, where Russian can be considered a second language, and there are large Russophone communities there.\n\nHowever, in China (with the exception perhaps of Hong Kong), English must be considered a foreign language due to the lack of opportunities for use, such as historical links, media, conversation between people, and similar vocabulary. Likewise, French would be considered a foreign language in Romania and Moldova. This is despite Romanian and French being Romance languages (unlike Chinese and English, which come from two different language families: Sino-Tibetan and Indo-European). This is also despite Romania and Moldova being the only two countries in the world where Romanian is an official language at the national level, Romania's historical links to France, and both Romanian-speaking countries' membership in the Francophonie.\nPsychological studies have found that speaking two or more languages is good for people's cognitive process and the differences between brains of bilinguals and single language speakers usually provides some mental benefits, according to an article on The Telegraph in 2013. Including but not limited to these: <br>\nBecoming smarter<br>\nSpeaking a second language improves the functions of the brain by thinking and using the different language systems.<br>\nBuilding multitasking skills<br>\nAccording to a study from the Pennsylvania State University, \"juggling language can make better brains\". Because multilingual people are usually good at switching between different language systems, they can be good multitaskers as well. <br>\nImproving memory<br>\nThe vocabulary capacity for a high school graduate student is about 45000 words, according to Nagy and Anderson (1984), and being a bilingual will double this number because learning a language involves memorizing rules and vocabulary.<br>\nSee more in references.<br>\nGeorge H. J. Weber, a Swiss businessman and independent scholar, founder of the Andaman Association and creator of the encyclopedic andaman.org Web site, made a report in December 1997 about the number of secondary speakers of the world's leading languages. Weber used the Fischer Weltalmanach of 1986 as his only source for the L2-speakers data, in preparing the data in the following table. These numbers are here compared with those referred to by Ethnologue, a popular source in the linguistics field. See below Table 1.\n\nCollecting the number of second language speakers of every language is extremely difficult and even the best estimates contain the guess work. Data below updated June 2013 from Ethnologue.com See below Table 2&3.\n\n\n"}
{"id": "3221635", "url": "https://en.wikipedia.org/wiki?curid=3221635", "title": "True name", "text": "True name\n\nA true name is a name of a thing or being that expresses, or is somehow identical to, its true nature. The notion that language, or some specific sacred language, refers to things by their true names has been central to philosophical study as well as various traditions of magic, religious invocation and mysticism (mantras) since antiquity.\n\nThe true name of the Egyptian sun god Ra was revealed to Isis through an elaborate trick. This gave Isis complete power over Ra and allowed her to put her son Horus on the throne.\n\nSocrates in Plato's \"Cratylus\" considers, without taking a position, the possibility whether names are \"conventional\" or \"natural\" (\"true name\" [τῇ ἀληθείᾳ ὄνομα]), that is, whether language is a system of arbitrary signs or whether words have an intrinsic relation to the things they signify (this anti-conventionalist position is called Cratylism).\n\nHellenistic Judaism emphasized the divine nature of \"logos\", later adopted by the Gospel of John. The true name of God plays a central role in Kabbalism (see Gematria, Temurah, YHWH [the tetragrammaton]) and to some extent in Sufism (see 100th name of God).\nThe ancient Jews considered God's true name so potent that its invocation conferred upon the speaker tremendous power over His creations. To prevent abuse of this power, as well as to avoid blasphemy, the name of God was always taboo, and increasingly disused so that by the time of Jesus their High Priest was supposedly the only individual who spoke it aloud — and then only in the Holy of Holies upon the Day of Atonement.\n\nAlso in a Biblical context, in the tale of Jacob's nocturnal wrestling with an anonymous angel, the angel refuses to reveal his own name to Jacob even after the angel's submission at dawn. Thereafter Jacob obtains a new name which signifies his successful struggle to God and man, and names the place to commemorate his surviving an encounter with the Divine.\n\nContemporary pre-industrial peoples guard secret names which are only used in solemn rituals. These names are never mentioned and kept from general knowledge.\n\nIn Jewish tradition, when several children have died in a family the next that is born has no name given to it, but is referred to as \"Alter\" (, literally \"old\"), or \"Alterke\", the view being that the Angel of Death, not knowing the name of the child, will not be able to seize it. When such a child attains the marriageable age, a new name, generally that of one of the Patriarchs, is given to it. \n\nWhen captured by Polyphemus, Homer's Odysseus is careful not to reveal his name; when asked for it, Odysseus tells the giant that he is \"Οὖτις\", which means \"nobody\". But later, having escaped after blinding Polyphemus and thinking himself beyond Polyphemus' power, Odysseus boastfully reveals his real name, an act of hubris that was to cause enormous problems later. Knowing his name, Polyphemus was able to call upon Odysseus the revenge of his father, the god Poseidon. Many later episodes of the Odyssey depict Odysseus facing the relentless hostility of Poseidon - which he could have avoided had he persisted in keeping his real name secret. \nAccording to practises in folklore, referred to as 'the Law of Names'; knowledge of a true name allows one to affect another person or being magically. It is stated that knowing someone's, or something's, true name therefore gives the person (who knows the true name) power over them. This effect is used in many tales, such as in the German fairytale of \"Rumpelstiltskin\": within Rumpelstiltskin and all its variants, the girl can free herself from the power of a supernatural helper who demands her child by learning its name.\n\nA legend of Saint Olaf recounts how a troll built a church for the saint at a fantastic speed and price, but the saint was able to free himself by learning the troll's name during a walk in the woods. Similarly, the belief that children who were not baptised at birth were in particular danger of having the fairies kidnap them and leave changelings in their place may stem from their unnamed state. In the Scandinavian variants of the ballad \"Earl Brand\", the hero can defeat all his enemies until the heroine, running away with him, pleads with him by name to spare her youngest brother.\n\nIn Scandinavian beliefs, more magical beasts, such as the Nix, could be defeated by calling their name. For the same reason significant objects in Germanic mythology, which were considered to have some kind of intrinsic personality, had their own names too, for example the legendary Sword Balmung.\n\nMedieval beliefs about witchcraft indicated that the Devil baptized witches with a new, secret name.\n\nIn the folklore of Northern England, there was the belief that a boggart should never be named, for when the boggart was given a name, it would not be reasoned with nor persuaded, but would become uncontrollable and destructive.\n\nGiacomo Puccini used a similar theme in the opera Turandot. The plot turns on whether or not Princess Turandot could learn the name of her unwanted suitor. If she does, she could execute him; if she doesn't, she would have to marry him.\n\nThe term \"true name\" is sometimes used in cryptography and computer security to refer to a name that is assumed to uniquely identify a principal in a global namespace (for example, an X.500 or X.509 Distinguished name). This usage is often critical, with the implication that use of true names is difficult to enforce and unwise to rely on. \n\nIn fantasy where magic works by evoking true names, characters often go to great lengths to conceal their true names. In some settings, such as Ursula K. Le Guin's \"Earthsea\", this is true for all beings. In others, as in Larry Niven's \"The Magic Goes Away\", it applies only to those of magical inclination, as where a wizard is revived from the dead only by another who found his name, and even then only with great difficulty. Finding a true name may require arcane procedures. In \"Earthsea\", a wizard must listen for and give the hero his true name; this is performed in both Le Guin's \"A Wizard of Earthsea\" and \"The Tombs of Atuan\".\n\n\nA character remembering their true name may be an important means of maintaining mastery of their own life. In Hayao Miyazaki's movie \"Spirited Away\", the witch who runs the bathhouse, Yubaba, ensures loyalty by stealing the names of her subjects. For example, one of the witch's most loyal subjects, the spirit of the Kohaku River, has his name taken and is given a slave name: Haku. He forgets his name, and it is in this way 'taken' from him; he warns Chihiro Ogino against the dangers of forgetting her own name. She frees him when she recognises him and he then remembers and 'takes back' his name and is freed from the clutches of the witch.\n\nIn the cyberpunk genre following Vernor Vinge's 1981 \"True Names\" and the work of William Gibson, much of the plot involved interactions between people's virtual selves in cyberspace. Learning a fellow hacker's real-world name (i.e., their \"true name\") could allow you to turn them in to the government or otherwise blackmail them, conveying a kind of power that could be considered analogous to the equivalent concept of myth and legend.\n\n"}
{"id": "11270807", "url": "https://en.wikipedia.org/wiki?curid=11270807", "title": "Truth in Translation", "text": "Truth in Translation\n\nTruth in Translation is a stage play conceived and directed by Michael Lessac, with music by Hugh Masekela. It tells the story of the interpreters at South Africa's Truth and Reconciliation Commission. \n\nThe play was written in a collaboration between the interpreters who worked at the TRC, writer Paavo Tom Tammi and the company of South African actors. It premiered in Rwanda, has toured South Africa and is touring to international conflict zones such as Northern Ireland, Sierra Leone, the Balkans, Jerusalem/Ramallah, Sri Lanka, Peru, and Indonesia/Timor to tell the story of the South African experience. The project includes workshops with audiences, exhibitions (The Forgiveness Project and Jillian Edelstein's \"Truth and Lies\") and filming of the interaction between audiences and the company, and attempts to provoke a global dialogue around notions of healing and reconciliation.\n\n"}
{"id": "100824", "url": "https://en.wikipedia.org/wiki?curid=100824", "title": "Uncial script", "text": "Uncial script\n\nUncial is a majuscule script (written entirely in capital letters) commonly used from the 4th to 8th centuries AD by Latin and Greek scribes. Uncial letters were used to write Greek, Latin, and Gothic.\n\nEarly uncial script is likely to have developed from late Old Roman cursive. Early forms are characterized by broad single stroke letters using simple round forms taking advantage of the new parchment and vellum surfaces, as opposed to the angular, multiple stroke letters, which are more suited for rougher surfaces, such as papyrus. In the oldest examples of uncial, such as the fragment of \"De bellis macedonicis\" in the British Library, of the late 1st-early 2nd century, all of the letters are disconnected from one another, and word separation is typically not used. Word separation, however, is characteristic of later uncial usage.\n\nAs the script evolved over the centuries, the characters became more complex. Specifically, around AD 600, flourishes and exaggerations of the basic strokes began to appear in more manuscripts. Ascenders and descenders were the first major alterations, followed by twists of the tool in the basic stroke and overlapping. By the time the more compact minuscule scripts arose circa AD 800, some of the evolved uncial styles formed the basis for these simplified, smaller scripts. Uncial was still used, particularly for copies of the Bible, tapering off until around the 10th century. There are over 500 surviving copies of uncial script, by far the largest number prior to the Carolingian Renaissance.\n\nIn general, there are some common features of uncial script:\n\n\nIn later uncial scripts, the letters are sometimes drawn haphazardly; for example, runs together at the baseline, bows (for example in , , ) do not entirely curve in to touch their stems, and the script is generally not written as cleanly as previously.\n\nDue to its extremely widespread use, in Byzantine, African, Italian, French, Spanish, and \"insular\" (Irish, British and English) centres, there were many slightly different styles in use:\n\n\nThere is some doubt about the original meaning of the word. \"Uncial\" itself probably comes from St. Jerome's preface to the Book of Job, where it is found in the form \"uncialibus\", but it is possible that this is a misreading of \"inicialibus\" (though this makes little sense in the context), and Jerome may have been referring to the larger initial letters found at the beginning of paragraphs.\n\nIn classical Latin \"uncialis\" could mean both \"inch-high\" and \"weighing an ounce\", and it is possible that Jerome was punning on this; he may conceivably also have been playing with the other meaning of \"codex\", \"block of wood\".\n\nThe term \"uncial\" in the sense of describing this script was first used by Jean Mabillon in the early 18th century. Thereafter his definition was refined by Scipione Maffei, who used to refer to this script as distinct from Roman square capitals.\n\nThe word, \"uncial\", is also sometimes used to refer to manuscripts that have been scribed in uncial, especially when differentiating from those penned with minuscule. Some of the most noteworthy Greek uncials are:\n\nThe Petropolitanus is considered by some to contain optimum uncial style. It is also an example of how large the characters were getting.\n\nFor further details on these manuscripts, see Guglielmo Cavallo \"Ricerche sulla Maiuscola Biblica\" (Florence, 1967).\n\nModern calligraphy usually teaches a form of evolved Latin-based uncial hand that would probably be best compared to the later 7th to 10th century examples, though admittedly, the variations in Latin uncial are much wider and less rigid than Greek. Modern uncial has borrowed heavily from some of the conventions found in more cursive scripts, using flourishes, variable width strokes, and on occasion, even center axis tilt.\n\nIn a way comparable to the continued widespread use of the blackletter typefaces for written German until well into the 20th century, Gaelic letterforms, which are similar to uncial letterforms, were conventionally used for typography in Irish until the 1950s. The script is still widely used in this way for titles of documents, inscriptions on monuments and other 'official' uses. Strictly speaking, the Gaelic script is insular, not uncial. Uncial Greek (commonly called \"Byzantine lettering\" by Greeks themselves) is commonly used by the Greek Orthodox Church and various institutions and individuals in Greece to this day. The Modern Greek State has also used uncial script on several occasions in official capacity (such as on seals, government documents etc.) as did many of the Greek provisional governments during the Greek War of Independence. The height of uncial usage by the Modern Greek State was during the Greek military junta of 1967–74, when even Greek Drachma coins had uncial lettering on them. Since the Metapolitefsi, the Greek State has stopped using uncial script.\n\nThe term \"half-uncial\" or \"semi-uncial\" was first deployed by Scipione Maffei, \"Istoria diplomatica\" (Mantua, 1727); he used it to distinguish what seemed like a cut-down version of uncial in the famous \"Codex Basilicanus\" of Hilary, which contains sections in each of the two types of script. The terminology was continued in the mid-18th century by René Prosper Tassin and Charles François Toustain. Despite the common and well-fixed usage, half-uncial is a poor name to the extent that it suggests some organic debt to regular uncial, though both types share features inherited from their ancient source. See now: L. E. Boyle, \"'Basilicanus' of Hilary Revisited,\" in \"Integral Palaeography\", with an introduction by F. Troncarelli (Turnhout, 2001), 105-17.\n\nLike uncial, half-uncial derived from Roman cursive, but now of a later, evolved type. It was first used around the 3rd century and remained in use until the end of the 8th century. The early forms of half-uncial were used for pagan authors and Roman legal writing, while in the 6th century the script came to be used in Africa and Europe (but not as often in insular centres) to transcribe Christian texts.\n\nSome general forms of half-uncial letters are:\n\nHalf-uncial was brought to Ireland in the 5th century, and was then carried to England. There, it was used up to the 8th century, and developed into the insular script after the 8th century.\n\n\n"}
{"id": "28820961", "url": "https://en.wikipedia.org/wiki?curid=28820961", "title": "Union Nationale des Experts Traducteurs Interprètes près les Cours d'Appel", "text": "Union Nationale des Experts Traducteurs Interprètes près les Cours d'Appel\n\nThe Union Nationale des Experts Traducteurs Interprètes près les Cours d'Appel is a member organization of the International Federation of Translators.\n\nExperts-traducteurs are professional translators chosen by a jury on application to the Cour d'Appel (Appellate Court) of their home region in France. They have to show the jury, on request, that they have been working for a minimum of three years and that the result of their work corresponds exactly to the original text. They are then listed on a document tended by the regional Cour d'Appel as a regional expert translator/interpreter. They are regularly checked by police officers on their personal acquaintances and life style to ensure loyalty, lawfulness and impartiality. Translators listed at the Cour d'Appel can, after another three years, file a new application at the jury of the Cour de Cassation in Paris to be listed as a national expert translator.\n\n"}
{"id": "15138256", "url": "https://en.wikipedia.org/wiki?curid=15138256", "title": "United Nations Multilingual Terminology Database", "text": "United Nations Multilingual Terminology Database\n\nThe United Nations Multilingual Terminology Database (UNTERM) is a linguistic tool which translates terminology and nomenclature used within the United Nations (UN) in the six official languages of the UN (Arabic, Chinese, English, French, Russian and Spanish). The database contains more than 85,000 words and is updated daily.\n\nThe database is maintained by Terminology and Reference Section, Documentation Division, Department of General Assembly and Conference Management, with its headquarters in New York City. The database has been put on the Internet in order to facilitate the understanding of the work of the UN by the public who do not have access to the intranet of the UN Secretariat. \n\n"}
{"id": "325480", "url": "https://en.wikipedia.org/wiki?curid=325480", "title": "Whistling", "text": "Whistling\n\nWhistling without the use of an artificial whistle is achieved by creating a small opening with one's lips and then blowing or sucking air through the hole. The air is moderated by the lips, curled tongue, teeth or fingers (placed over the mouth) to create turbulence, and the curled tongue acts as a resonant chamber to enhance the resulting sound by acting as a type of Helmholtz resonator.\n\nPucker whistling is the most common form in much Western music. Typically, the tongue tip is lowered, often placed behind the lower teeth, and pitch altered by varying the position of the tongue. Although varying the degree of pucker will change the pitch of a pucker whistle, expert pucker whistlers will generally only make small variations to the degree of pucker, due to its tendency to affect purity of tone. Pucker whistling can be done by either only blowing out or blowing in and out alternately. In the 'only blow out' method, a consistent tone is achieved, but a negligible pause has to be taken to breathe in. In the alternating method there is no problem of breathlessness or interruption as breath is taken when one whistles breathing in, but a disadvantage is that many times, the consistency of tone is not maintained, and it fluctuates.\n\nMany expert musical palatal whistlers will substantially alter the position of the tongue to ensure a good quality tone. Venetian gondoliers are famous for moving the tongue while they whistle in a way that can look like singing. A good example of a palatal whistler is Luke Janssen, winner of the 2009 world whistling competition.\nFinger whistling is harder to control but achieves a piercing volume. In Boito's opera \"Mefistofele\" the title character uses it to express his defiance of the Almighty.\n\nWhistling can also be produced by blowing air through enclosed, cupped hands or through an external instrument, such as a whistle or even a blade of grass or leaf.\n\nOne of the most well known whistling competitions is the International Whistlers Convention (IWC). Since 1973, this annual event takes place in Louisburg, North Carolina. The awards go to whistlers ranging from international male and female, teenage male and female, and even grandchildren. It has been customary for the Governor of the State of North Carolina to sign a declaration declaring the week of the IWC as \"Happy Whistlers Week,\" for citizens and visitors to honor the art of whistling and to participate in the scheduled events.\n\nAccording to Guinness World Records, the highest pitch human whistle ever recorded was measured at 4,186 Hz, which corresponds to a C8 musical note. This was done by Michael Stuart in Richmond, Virginia, on January 11, 2016. The lowest pitch whistle ever recorded was measured at 174.6 Hz, which corresponds to a F3 musical note. This was accomplished by Jennifer Davies of Dachau, Germany on November 6, 2005. The most people whistling simultaneously was 853, which was organized at the Spring Harvest event at Minehead, UK on April 11, 2014.\n\nOn La Gomera, one of Spain's Canary Islands, a traditional whistled language named \"Silbo Gomero\" is still used. At least nine separate whistling sounds are used to produce usually four vowels and five consonants, allowing this language to convey unlimited words. This language allowed people (e.g. shepherds) to communicate over long distances in the island, when other communication means were not available. It is now taught in school so that it is not lost among the younger generation. Another group of whistlers were the Mazateco Indians of Oaxaca, Mexico. Their whistling aided in conveying messages over far distances, but was also used in close quarters as a unique form of communication with a variety of tones.\n\nWhistling can be used to control trained animals such as dogs. A Shepherd's whistle is often used instead.\n\nWhistling has long been used as a specialized communication between laborers. For example, whistling in theatre, particularly on-stage, is used by flymen (i.e. members of a fly crew) to cue the lowering or raising of a batten pipe or flat. This method of communication became popular before the invention of electronic means of communication, and is still in use, primarily in older \"hemp\" houses during the set and strike of a show.\n\nThe range of pucker whistlers varies from about one to three octaves. Agnes Woodward classifies by analogy to voice types: soprano (c\"-c\"\"), mezzo (a-g'\") and alto (e or d-g\")\n\nMany performers (also known as siffleurs) on the music hall and Vaudeville circuits were professional whistlers, the most famous of which were Ronnie Ronalde and Fred Lowery. The term \"puccalo\" or \"puccolo\" was coined by Ron McCroby to refer to highly skilled jazz whistling.\n\nWhistling is featured in a number of television themes, such as \"Lassie\", \"The Andy Griffith Show\" and Mark Snow's title theme for \"The X-Files\".\nIt also prominently features in the score of the movie \"Twisted Nerve\", composed by Bernard Herrmann, which was later used in Quentin Tarantino's \"Kill Bill\".\n\nProminent in classic songs such as Bobby McFerrin's \"Don't Worry, Be Happy\" and Scorpions' \"Wind of Change\", whistling has also been integrated in many contemporary pop hits such as Flo Rida's \"Whistle\", Selena Gomez's \"Kill Em With Kindness\", Florida Georgia Line's \"Sun Daze\", Foster the People's \"Pumped Up Kicks\", Maroon 5's \"Moves Like Jagger\", Edward Sharpe and the Magnetic Zeros' \"Home\", OneRepublic's \"Good Life\", Adam Lambert's \"Ghost Town\", Kanye West's \"All Day\", Peter Bjorn and John's \"Young Folks\" and The Seekers \"Georgy Girl\".\n\nWhistling is often used by spectators at sporting events to express either enthusiasm or disapprobation. In the United States and Canada, whistling is used much like applause, to express approval or appreciation for the efforts of a team or a player, such as a starting pitcher in baseball who is taken out of the game after having pitched well. In much of the rest of the world, especially Europe and South America, whistling is used to express displeasure with the action or disagreement with an official's decision, like booing. This whistling is often loud and cacophonous, using finger whistling.\n\nIn many cultures, whistling or making whistling noises at night is thought to attract bad luck, bad things, or evil spirits.\n\nIn the UK there is a superstitious belief in the \"Seven Whistlers\" which are seven mysterious birds or spirits who call out to foretell death or a great calamity. In the 19th century, large groups of coal miners were known to have refused to enter the mines for one day after hearing this spectral whistling. The Seven Whistlers have been mentioned in literature such as \"The Faerie Queene\" by Edmund Spenser, as bearing an omen of death. William Wordsworth included fear of the Seven Whistlers in his poem, \"Though Narrow Be That Old Man's Cares\". The superstition has been reported in the Midland Counties of England but also in Lancashire, Essex, Kent, and even in other places such as North Wales and Portugal.\n\nIn Russian and other Slavic cultures, and also in Romania and the Baltic states, whistling indoors is superstitiously believed to bring poverty (\"whistling money away\"), whereas whistling outdoors is considered normal. In Estonia it is also widely believed that whistling indoors may bring bad luck and therefore set the house on fire.\n\nWhistling on board a sailing ship is thought to encourage the wind strength to increase. This is regularly alluded to in the Aubrey-Maturin books by Patrick O'Brian.\n\nTheater practice has plenty of superstitions: one of them is against whistling. A popular explanation is that traditionally sailors, skilled in rigging and accustomed to the boatswain's pipe, were often used as stage technicians, working with the complicated rope systems associated with flying. An errant whistle might cause a cue to come early or a \"sailor's ghost\" to drop a set-piece on top of an actor. An offstage whistle audible to the audience in the middle of a performance might also be considered bad luck.\n\nTranscendental whistling (\"chángxiào\" 長嘯) was an ancient Chinese Daoist technique of resounding breath yoga, and skillful whistlers supposedly could summon supernatural beings, wild animals, and weather phenomena.\n\n\n"}
