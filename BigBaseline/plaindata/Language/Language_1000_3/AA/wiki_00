{"id": "16911546", "url": "https://en.wikipedia.org/wiki?curid=16911546", "title": "Aka-Kol language", "text": "Aka-Kol language\n\nThe Kol language, Aka-Kol, is an extinct Great Andamanese language, of the Central group. It was spoken in the southeast section of Middle Andaman.\n\nThe Kol were one of the indigenous peoples of the Andaman Islands, one of the ten or so Great Andamanese tribes identified by British colonials in the 1860s. Their language was closely related to the other Great Andamanese languages. They were extinct as a distinct people by 1921.\n\nThe Great Andamanese languages are agglutinative languages, with an extensive prefix and suffix system. They have a distinctive noun class system based largely on body parts, in which every noun and adjective may take a prefix according to which body part it is associated with (on the basis of shape, or functional association). Thus, for instance, the *aka- at the beginning of the language names is a prefix for objects related to the tongue. An adjectival example can be given by the various forms of \"yop\", \"pliable, soft\", in Aka-Bea: \nSimilarly, \"beri-nga\" \"good\" yields:\n\nThe prefixes are,\n\nBody parts are inalienably possessed, requiring a possessive adjective prefix to complete them, so one cannot say \"head\" alone, but only \"my, or his, or your, etc. head\".\n\nThe basic pronouns are almost identical throughout the Great Andamanese languages; Aka-Bea will serve as a representative example (pronouns given in their basic prefixal forms):\n'This' and 'that' are distinguished as \"k-\" and \"t-\". \n\nJudging from the available sources, the Andamanese languages have only two cardinal numbers — one and two — and their entire numerical lexicon is one, two, one more, some more, and all.\n"}
{"id": "4503405", "url": "https://en.wikipedia.org/wiki?curid=4503405", "title": "American Speech–Language–Hearing Association", "text": "American Speech–Language–Hearing Association\n\nThe American Speech–Language–Hearing Association (ASHA) is a professional association for speech–language pathologists, audiologists, and speech, language, and hearing scientists in the United States and internationally. It has more than 197,856 members and affiliates.\n\nThe mission of the American Speech–Language–Hearing Association is to promote the interests of and provide the highest quality services for professionals in audiology, speech–language pathology, and speech and hearing science, and to advocate for people with communication disabilities.\n\nThe association's national office is located at 2200 Research Boulevard, Rockville, Maryland. The organization also has an office on Capitol Hill.\n\nArlene Pietranton is currently serving as the association's executive director.\nASHA was founded in 1925 as the American Academy of Speech Correction. The current name was adopted in 1978.\n\nThe 2014 ASHA conference was held in Orlando, Florida from November 20–22.\n\nThe 2017 ASHA conference will be held in Los Angeles, California from November 9–11.\n\nThe Council for Academic Accreditation in Audiology and Speech-Language Pathology (CAA) is the accreditation unit of the ASHA. Founded over 100 years ago by American universities and secondary schools, CAA established standards for graduate program accreditation that meet entry-level preparation in the speech and hearing field. Accreditation is available for graduate programs with a master's degree in Speech-Language Pathology or clinical doctoral program in audiology.\n\nProfessionals of Communication Sciences and Disorders (CSD) can become members of ASHA. These professionals include audiologists, speech-language pathologists, and speech-language-hearing scientists. As of December 31, 2017, there are more than 197,856 members and affiliates of ASHA. Opportunities ASHA membership brings include access to publications associated with ASHA, to continuing education programs through ASHA, to a platform to network with other CSD professionals, to career-building tools, and to money-saving programs.\n\nASHA sponsors special interest groups (SIGS) within the organization as a means of promoting community and learning in more specialized topics. As of 2016, ASHA has 19 established Special Interest Groups (SIG). These have been added through the years. ASHA members can be a SIG Affiliate of any number of SIGS, with each affiliation requiring nominal yearly dues. The 19 SIGS are:\n\n"}
{"id": "1107192", "url": "https://en.wikipedia.org/wiki?curid=1107192", "title": "Anthon Transcript", "text": "Anthon Transcript\n\nThe \"Anthon Transcript\" (often identified with the \"Caractors document\") is a small piece of paper on which Joseph Smith wrote several lines of characters. According to Smith, these characters were from the golden plates (the ancient record from which Smith claims to have translated the Book of Mormon) and represent the reformed Egyptian writing that was on the plates. In 1828, this paper was delivered to Charles Anthon, a well-known classical scholar of Columbia College, Columbia University, for an expert opinion on the authenticity of the characters and the translation. Some adherents to the Book of Mormon claim that Anthon attested to the characters' authenticity in writing to Martin Harris but then ripped up his certification after hearing the story of Smith and the plates. Critics of Smith claim that Anthon believed any idea of reformed Egyptian was a hoax all along and that Harris was being deceived.\n\nBelievers claim that the incident between Harris and Anthon fulfilled a biblical prophecy made by Isaiah, as Anthon is reported to have said to Harris, through Smith's telling of events, \"I cannot read a sealed book.\"\n\nIn 1980, Mark Hofmann created and sold a forgery of the Anthon Transcript to leaders of The Church of Jesus Christ of Latter-day Saints (LDS Church), which was revealed to be fraudulent when Hofmann's crimes were investigated.\n\nIn 1838, Smith related an account based on Harris's version of the meeting. Smith wrote that Anthon \"stated that the translation was correct, more so than any he had before seen translated from the Egyptian. [Harris] then showed him those not yet translated, and said they were Egyptian, Chaldaic, Assyriac, and Arabic\"; and that they were \"true characters.\" According to Harris, Anthon wrote Harris a letter of authenticity declaring the fragment to contain true Egyptian characters. Anthon was also reported to have confirmed the translation of these characters as correct. When informed that an angel of God had revealed the characters to Smith, Anthon reportedly tore up the authentication stating that there was no such thing as angels and asked Harris to bring the plates to him for translation. Harris then went to Dr. Samuel L. Mitchill, who sanctioned what Anthon said.\n\nIn 1834, Anthon stated in a letter that, \"The whole story about my having pronounced the Mormonite inscription to be 'reformed Egyptian hieroglyphics' is perfectly false ... I soon came to the conclusion that it was all a trick, perhaps a hoax ... [Harris] requested an opinion from me in writing, which of course I declined giving.\" Anthon stated in the letter that the story of his supposed authentication was false, that Anthon had identified the writings as a hoax, and that he had told Harris that the writings were part of \"a scheme to cheat the farmer [Harris] of his money\".\n\nAnthon gave a second account in 1841 that contradicted his 1834 account as to whether or not he gave Harris a written opinion about the document: \"[Harris] requested me to give him my opinion in writing about the paper which he had shown to me. I did so without hesitation, partly for the man's sake, and partly to let the individual 'behind the curtain' see that his trick was discovered. The import of what I wrote was, as far as I can now recollect, simply this, that the marks in the paper appeared to be merely an imitation of various alphabetical characters, and had, in my opinion, no meaning at all connected with them.\" In both accounts, Anthon maintained that he told Harris that Harris was the victim of a fraud. Pomeroy Tucker, a contemporary of Harris and Smith, wrote in 1867 that all the scholars whom Harris visited \"were understood to have scouted the whole pretense as too depraved for serious attention, while commiserating the applicant as the victim of fanaticism or insanity.\"\n\nThe Community of Christ purchased the handwritten slip of paper known as the Anthon Transcript, or the Caractors document from the heirs of David Whitmer. Whitmer, who once owned the document, stated that it was this slip of paper that Harris showed to Anthon. Both Mormon apologists and critics, however, claim that it is not certain that the document is the original, since Anthon had mentioned that the characters on the slip he saw were arranged in vertical columns and ended in a \"rude delineation of a circle divided into various compartments, decked with various strange marks, and evidently copied after the Aztec calendar given by Humboldt,\" (1834) or \"a rude representation of the Mexican zodiac\" (1841). Recent scholarship, including handwriting analysis, suggests the \"Caractors\" document was written by David Whitmer's brother John Whitmer in or after 1829 and therefore would not have been available to show Anthon or others in 1828. The symbols on the document were published twice in 1844, after Smith's death, as characters that had been copied from the gold plates, one of them in the December 21 issue of \"The Prophet\". In 1956 a request for review of the Caractors Document was made to three recognized Egyptologists, Sir Alan Gardiner, William C.. Hayes, and John A. Wilson. Gardiner replied that he saw no resemblance with \"any form of Egyptian writing.\" Hayes stated that it might be an inaccurate copy of something in hieratic script and that \"some groups look like hieratic numerals\", adding that \"I imagine, however, that the inscription bears a superficial resemblance to other scripts, both ancient and modern, of which I have no knowledge.\" Wilson gave the most detailed reply, saying that \"This is not Egyptian writing, as known to the Egyptologist. It obviously is not hieroglyphic, nor the \"cursive hieroglyphic\" as used in the Book of the Dead. It is not Coptic, which took over Greek characters to write Egyptian. Nor does it belong to one of the cursive stages of ancient Egyptian writing: hieratic, abnormal hieratic, or demotic.\"\n\nThe document is portrayed in the 2004 film \"The Work and the Glory\".\n\n"}
{"id": "160987", "url": "https://en.wikipedia.org/wiki?curid=160987", "title": "CJK characters", "text": "CJK characters\n\nIn internationalization, CJK is a collective term for the Chinese, Japanese, and Korean languages, all of which include Chinese characters and derivatives (collectively, CJK characters) in their writing systems. Occasionally, Vietnamese is included, making the abbreviation CJKV, since Vietnamese historically used Chinese characters as well. Collectively, the CJKV characters often include \"hànzì\" in Chinese, \"kanji\", \"kana\" in Japanese, \"hanja\", \"hangul\" in Korean, and \"hán tự\" or \"chữ nôm\" in Vietnamese.\n\nChinese is written almost exclusively in Chinese characters. It requires over 3,000 characters for general literacy, but up to 40,000 characters for reasonably complete coverage. Japanese uses fewer characters — general literacy in Japanese can be expected with 1,945 characters. The use of Chinese characters in Korea is becoming increasingly rare, although idiosyncratic use of Chinese characters in proper names requires knowledge (and therefore availability) of many more characters. However, even today, students in South Korea are taught 1,800 characters.\n\nOther scripts used for these languages, such as bopomofo and the Latin-based pinyin for Chinese, hiragana and katakana for Japanese, and hangul for Korean, are not strictly \"CJK characters\", although CJK character sets almost invariably include them as necessary for full coverage of the target languages.\n\nUntil the early 20th century, Literary Chinese was the written language of government and scholarship in Vietnam. Popular literature in Vietnamese was written in the \"chữ Nôm\" script, consisting of borrowed Chinese characters together with many characters created locally. By the end of the 1920s, both scripts had been replaced by writing in Vietnamese using the Latin-based Vietnamese alphabet.\n\nThe sinologist Carl Leban (1971) produced an early survey of CJK encoding systems.\n\nThe number of characters required for complete coverage of all these languages' needs cannot fit in the 256-character code space of 8-bit character encodings, requiring at least a 16-bit fixed width encoding or multi-byte variable-length encodings. The 16-bit fixed width encodings, such as those from Unicode up to and including version 2.0, are now deprecated due to the requirement to encode more characters than a 16-bit encoding can accommodate—Unicode 5.0 has some 70,000 Han characters—and the requirement by the Chinese government that software in China support the GB 18030 character set.\n\nAlthough CJK encodings have common character sets, the encodings often used to represent them have been developed separately by different East Asian governments and software companies, and are mutually incompatible. Unicode has attempted, with some controversy, to unify the character sets in a process known as Han unification.\n\nCJK character encodings should consist minimally of Han characters plus language-specific phonetic scripts such as pinyin, bopomofo, hiragana, katakana and hangul.\n\nCJK character encodings include:\n\nThe CJK character sets take up the bulk of the assigned Unicode code space. There is much controversy among Japanese experts of Chinese characters about the desirability and technical merit of the Han unification process used to map multiple Chinese and Japanese character sets into a single set of unified characters.\n\nAll three languages can be written both left-to-right and top-to-bottom (right-to-left and top-to-bottom in ancient documents), but are usually considered left-to-right scripts when discussing encoding issues.\n\nLibraries cooperated on encoding standards for JACKPHY characters in the early 1980s. According to Ken Lunde, the abbreviation \"CJK\" was a registered trademark of Research Libraries Group (which merged with OCLC in 2006). The trademark owned by OCLC between 1987 and 2009 has now expired.\n\n\n\n"}
{"id": "33204986", "url": "https://en.wikipedia.org/wiki?curid=33204986", "title": "Central Savinja dialect", "text": "Central Savinja dialect\n\nThe Central Savinja dialect (\"srednjesavinjsko narečje\", \"srednja savinjščina\") is a Slovene dialect in the Styrian dialect group. It is spoken in the central Savinja Valley in the basins of the Bolska, Paka, and Hudinja rivers east of the Upper Savinja dialect and west of the Central Styrian dialect, south of the Mežica and South Pohorje dialects, and north of the Eastern Upper Carniolan, Zagorje-Trbovlje, and Laško subdialects. It includes the settlements of Trojane, Špitalič, Vransko, Topolšica, Šoštanj, Velenje, Frankolovo, Vojnik, and Celje.\n\nThe Central Savinja dialect has preserved accented short vowels. It does not have the change \"u\" > \"ü\" nor \"a\" > \"ɔ\", the diphthongs \"ou\" and \"ei\" have monophthongized but \"ie\" and \"uo\" are pronounced, and there is limited akanye. Vocalic \"r\" has developed into \"ar\" and vocalic \"l\" into \"aw\". The feminine singular instrumental ending for nouns and adjectives is \"-oj/-uj\" (in contrast to standard \"o\").\n"}
{"id": "55750276", "url": "https://en.wikipedia.org/wiki?curid=55750276", "title": "Confusion network", "text": "Confusion network\n\nA confusion network is a natural language processing method that combines outputs from multiple machine translation systems. The defining characteristic of confusion networks is that they allow multiple ambiguous inputs, deferring committal translation decisions until later stages of processing. This approach is used in the open source machine translation software Moses and the proprietary translation API in IBM Bluemix Watson.\n"}
{"id": "22414061", "url": "https://en.wikipedia.org/wiki?curid=22414061", "title": "Conversational constraints theory", "text": "Conversational constraints theory\n\nConversational Constraints Theory, developed in Min-Sun Kim, attempts to explain how and why certain conversational strategies differ across various cultures and the effects of these differences. It is embedded in the Social Science communication approach which is based upon how culture influences communication. There are five universal conversational constraints: 1) clarity, 2) minimizing imposition, 3) consideration for the other’s feelings, 4) risking negative evaluation by the receiver, and 5) effectiveness. These five constraints pivot on the notion of if a culture is more social relational (collectivistic cultures), or task oriented (individualistic cultures). The social relational approach focuses on having more concern for the receiver’s feelings, holding more importance upon saving face for the other person than being concise. When constructing messages, the social relational approach takes into account how their words and actions will affect the listener’s feelings. The task oriented approach emphasizes concern for clarity over feelings. It places higher value on the degree to which the message is communicated explicitly in its truest form. Cultures have specific manners and behaviors that pertain to conversational style. These behaviors can be preferred by some cultures, and offensive to others. Conversational Constraints Theory seeks to explain why these certain tactics work in some cultures but not in others. It is influenced by the customs, rules, and norms of that culture. The central focus of Conversational Constraints Theory is not necessarily what is said, but how it is said. Conversations are typically goal-oriented and require coordination between both communicators, and messages are developed built upon various constraints, personal or cultural, in order to pursue any kind of interaction. Kim discusses the need for approval, need for dominance, and gender roles to analyze conversational constraints. The more approval a person needs, thus more feminine, the more they view minimizing imposition and being concerned with the hearer’s feelings as being important. The more dominant, thus more masculine, the more they view message clarity and directness as being important.\n\nConcern for effectiveness is a constraint that is universally important amongst most all cultures. It is focused on the influence that the message has on the receiver and to what extent. Effectiveness explains the capability of how well the content of the message is conveyed to the listener, and if the style of verbal deliverance is soft or punctual. Effectiveness pertains to the potency of the message, if it is strong or weak, powerful or ineffective, weighty or superficial. Collectivistic cultures tend to use effectiveness within their conversations as more diffused and watered-down so as to lessen negativity and offense. This aspect of effectiveness has more ease and cushion in how the message is spoken, and is structured in a way that will minimize dissonance at all costs. On the other hand, individualistic cultures maximize the punctuality of effectiveness in delivering the message. The tone of their message focuses on directness, frankness, and being straightforward with their listener, and intend on being bluntly honest in order to be effective. Individualistic cultures are not generally concerned with the listener’s feelings if that sacrifices the effectiveness of the message.\n\n“Clarity is defined as the likelihood of an utterance making one’s intention clear and explicit.” Clarity is an important part of conversation because in order for a conversation to flow properly, the communication needs to be clear and precise. A person trying to communicate a specific message explicitly uses direct imperatives to ensure that the proper message is carried to the hearer. If a person is attempting to use the hint strategy, the message will be less clear because the intent is not communicated explicitly, therefore is not derivable from the literal meaning of the utterances.\nKim proposes that task-oriented constraints emphasize a concern for clarity. For example, task-oriented constraints measure the degree to which the intentions of messages are communicated explicitly. When comparing collectivistic cultures to individualistic cultures, the members of individualistic cultures consider clarity as more significant than members of collectivistic when aspiring goals. Further, members of individualistic cultures have thresholds and exploit more attention for clarity than members of collectivistic cultures. Individuals who display independent and interdependent self-construals present different views on the importance of clarity. For instance, individuals who exhibit independent self-construals perceive clarity as significant in pursuing goals more than individuals who stimulate interdependent self-construals. Individuals who display both independent and interdependent self-construals focus more on relational and clarity restraints. On the other hand, individuals who do not exercise independent or interdependent self-construals do not visualize clarity and relational constraints imperative. To help further explain conversational constraints, Kim uses the need for approval, need for dominance, and gender roles. The need for dominance and gender roles apply to the clarity of a conversational constraint. For instance, the more dominance an individual possesses to be, the more emphasis he or she places on clarity. Also, the importance on clarity is exhibited through to need to be more masculine. These different displays of clarity provide evidence for Kim’s conversational constraints.\n\nWhen communicating with another person, individuals take into account the listener’s feelings. People acknowledge how their intended action is going to affect the feelings of the other person. The concern the speaker displays for the hearer relates to what the speaker feels is necessary in order to help the hearer maintain positive self images. Positive face, identity goals, and “concern with support” are three labels that help determine the degree to which a strategy shows consideration for the hearer’s feelings. When a person requests an explicit action, it possesses a higher chance of hurting the listener’s feelings. On the other hand, communicating with a hint sends a more implicit message, thus, delivering the message successfully. Compared to task-oriented constraints, social relational constraints stress concern for others by withdrawing from injuring the hearer’s feelings. They are strongly concerned with how their communication may affect the hearer’s and reflect on their concern to successfully accomplish these communicative goals. Some of these communicative goals affect the hearer’s still, thus, threatening their autonomy. It has been found that “collectivism influences the importance members of cultures place on relational concerns in conversation” (Kim, 1995). Therefore, members of this culture place more emphasis on face-supporting behaviors, such as avoiding harming the other’s feelings than when members are pursuing goals. Compared to members of individualistic cultures, these members “have higher thresholds for face support and select strategies to maximize face support” (Kim, 1995). Individuals who highlight interdependent self-construals want to avoid face loss as much as possible and want to feel welcomed by particular social groups. These individuals see avoiding hurt feelings as more significant than individuals who use independent self-construals. Individuals who are more feminine and need more approval than others tend to put more focus on the concern for others than more dominant individuals.\n\nAn element that is an essential component within the Conversational Constraints Theory emphasizes the role of minimizing imposition. The theory discusses cross-cultural differences that have been observed when studying communicative strategies in different cultures. For instance, members within collectivistic cultures view face-supporting behavior. One way this is done is through minimizing imposition as an important component when a member is in pursuit of a goal. There is ample reason to believe that individualistic cultures, on the other hand, do not consider face-supporting behaviors to be as important to goal oriented behavior. Conversational Constraints Theory suggests that feminine individuals place more value on minimizing their imposition. In contrast, individuals that are masculine tend to place less value on minimizing their imposition. In addition, the theory also reports that the more an individual requires approval within a given context, the higher the amount of importance they will place on minimizing their imposition. This occurs when the individuals are minimizing their imposition on hearers in a social-relational conversational constraint. In addition, this can occur in a task-oriented conversational constraint. Returning to the issue of research about conversational constraints across different cultures, researchers have noted specific concerns which are to be addressed.\n\nThere have been concerns found in recent studies about conversational constraints across different cultures. Current research suggests that the concern for avoiding negative evaluation by the hearer is only one of the three concerns that were observed in research studies. In most instances, this particular conversational constraint occurs when a speaker within a conversation makes an attempt to avoid negative evaluation from the individual that is hearing the speaker’s message. The concern for avoiding negative evaluation by the hearer in a conversation explains a plausible reason that explains why individuals attempt to conduct their behavior in ways that will avoid devaluation from others within a conversation. For example, a person might try to make a good first impression to seek approval in an interview by using strategies to avoid negative evaluation from the individual who is conducting the interview. Among the various cultures that conversational constraints have been studied, individualistic cultures have been shown to have differences in comparison to other types of cultures. Individualistic cultures are more focused on the amount of clarity within a conversational constraint and less concerned with avoiding negative evaluation from the hearer. In contrast, collectivistic cultures are more concerned with behaviors that include avoiding negative evaluation from the hearer, and minimizing imposition because these constraints are considered face-supporting behavior.\n\n"}
{"id": "19107318", "url": "https://en.wikipedia.org/wiki?curid=19107318", "title": "Crazy English (film)", "text": "Crazy English (film)\n\nCrazy English is a 1999 Chinese documentary directed by Zhang Yuan. The film premiered along with Zhang's \"Seventeen Years\" at the 1999 Locarno International Film Festival. It established Zhang's position as a \"legitimate\" director after years of working independently from, and often at odds with, the Chinese authorities.\n\nIn contrast to earlier films, like \"East Palace, West Palace\" (1997), \"Crazy English\" was produced with the cooperation of the state-owned Xi'an Film Studio, which enjoys a \"presented by\" billing in the film's credits.\n\nThe film follows one of the People's Republic of China's most popular motivational speakers, Li Yang, the founder of \"Crazy English\". Li is known for his stadium-sized presentations where he exhorts his audiences to engage in mass recitations of English phrases and idioms, often with a strong nationalist bent: \"Conquer English to Make China Stronger!\". Li, however, has also courted controversy. Despite the fact that he teaches a foreign language, Li has never left China, a fact not revealed in the film until the end. Other common criticisms, including accusations that Li Yang is a \"nationalist huckster\" and that his methods do not actually improve English-speaking ability, receive a much more subtle presentation in Zhang's film.\n\nThe film follows Li on his tours throughout China with a few interspersed interviews. Zhang Yuan has described the film as a combination of Leni Riefenstahl's \"Triumph of the Will\" and Robert Zemeckis' \"Forrest Gump\".\n\nThe seeds for \"Crazy English\" first arose when Li Yang's manager asked to meet with Zhang Yuan at a bar in Beijing's Sanlitun neighborhood. At the time Zhang Yuan had not even heard of Li Yang or his \"Crazy English\" programs. After meeting with the manager, Zhang was sufficiently intrigued by the idea of a documentary about Li to arrange for an actual meeting with the motivational speaker.\n\nOnce the two men met, Zhang Yuan \"immediately\" decided to make the film. Though made with the assent of official authorities, the filmmakers were nevertheless forced to make certain cuts before being allowed a limited release for their documentary. Zhang has noted that his own opinions of Li Yang vary dramatically from admiration to disgust. One critic also noticed Zhang's ambivalence in the film and noted that the film seems to shift from appreciation or amusement at Li Yang's methodologies to one darker in tone, as Li Yang's mass rallies begin to resemble Mao-era Red Guard rallies or even Hitler's Nuremberg Rally.\n\nDespite of its official approval, \"Crazy English\" received only a limited release in select cities within China. Zhang Yuan has stated that the film's reception within China was difficult to read, given the mass adoration (and criticism) that Li Yang often elicits.\n\nWhile China remained ambivalent, the west also responded to \"Crazy English\" with mixed reactions. At least one critic felt that the film was too long and better suited for television than film. On the other hand, the film journal \"Senses of Cinema\" showered praise on \"Crazy English\", saying, \"This is a fascinating film - for China watchers, for educators and for fans of the documentary film - and is an absolute must for festival patrons.\"\n\nAs for the film's subject, Li Yang was reportedly less than pleased by the film's portrayal of him as a demagogue, and he has gone on to say that the film was \"not a real documentary\" accusing Zhang of manipulating the film to appeal to Western audiences.\n\n\n"}
{"id": "10374", "url": "https://en.wikipedia.org/wiki?curid=10374", "title": "Essay", "text": "Essay\n\nAn essay is, generally, a piece of writing that gives the author's own argument — but the definition is vague, overlapping with those of a paper, an article, a pamphlet, and a short story. Essays have traditionally been sub-classified as formal and informal. Formal essays are characterized by \"serious purpose, dignity, logical organization, length,\" whereas the informal essay is characterized by \"the personal element (self-revelation, individual tastes and experiences, confidential manner), humor, graceful style, rambling structure, unconventionality or novelty of theme,\" etc.\n\nEssays are commonly used as literary criticism, political manifestos, learned arguments, observations of daily life, recollections, and reflections of the author. Almost all modern essays are written in prose, but works in verse have been dubbed essays (e.g., Alexander Pope's \"An Essay on Criticism\" and \"An Essay on Man\"). While brevity usually defines an essay, voluminous works like John Locke's \"An Essay Concerning Human Understanding\" and Thomas Malthus's \"An Essay on the Principle of Population\" are counterexamples.\n\nIn some countries (e.g., the United States and Canada), essays have become a major part of formal education. Secondary students are taught structured essay formats to improve their writing skills; admission essays are often used by universities in selecting applicants, and in the humanities and social sciences essays are often used as a way of assessing the performance of students during final exams.\n\nThe concept of an \"essay\" has been extended to other media beyond writing. A film essay is a movie that often incorporates documentary filmmaking styles and focuses more on the evolution of a theme or idea. A photographic essay covers a topic with a linked series of photographs that may have accompanying text or captions.\n\nAn essay has been defined in a variety of ways. One definition is a \"prose composition with a focused subject of discussion\" or a \"long, systematic discourse\".\nIt is difficult to define the genre into which essays fall. Aldous Huxley, a leading essayist, gives guidance on the subject. He notes that \"the essay is a literary device for saying almost everything about almost anything\", and adds that \"by tradition, almost by definition, the essay is a short piece\". Furthermore, Huxley argues that \"essays belong to a literary species whose extreme variability can be studied most effectively within a three-poled frame of reference\". \nThese three poles (or worlds in which the essay may exist) are:\nHuxley adds that the most satisfying essays \"...make the best not of one, not of two, but of all the three worlds in which it is possible for the essay to exist.\"\n\nThe word \"essay\" derives from the French infinitive \"essayer\", \"to try\" or \"to attempt\". In English \"essay\" first meant \"a trial\" or \"an attempt\", and this is still an alternative meaning. The Frenchman Michel de Montaigne (1533–1592) was the first author to describe his work as essays; he used the term to characterize these as \"attempts\" to put his thoughts into writing, and his essays grew out of his commonplacing. Inspired in particular by the works of Plutarch, a translation of whose \"Œuvres Morales\" (\"Moral works\") into French had just been published by Jacques Amyot, Montaigne began to compose his essays in 1572; the first edition, entitled \"Essais\", was published in two volumes in 1580. For the rest of his life, he continued revising previously published essays and composing new ones. Francis Bacon's essays, published in book form in 1597, 1612, and 1625, were the first works in English that described themselves as \"essays\". Ben Jonson first used the word \"essayist\" in English in 1609, according to the \"Oxford English Dictionary\".\n\nEnglish essayists included Robert Burton (1577–1641) and Sir Thomas Browne (1605–1682). In France, Michel de Montaigne's three volume \"Essais\" in the mid 1500s contain over 100 examples widely regarded as the predecessor of the modern essay. In Italy, Baldassare Castiglione wrote about courtly manners in his essay \"Il Cortigiano\". In the 17th century, the Jesuit Baltasar Gracián wrote about the theme of wisdom. During the Age of Enlightenment, essays were a favored tool of polemicists who aimed at convincing readers of their position; they also featured heavily in the rise of periodical literature, as seen in the works of Joseph Addison, Richard Steele and Samuel Johnson. In the 18th and 19th centuries, Edmund Burke and Samuel Taylor Coleridge wrote essays for the general public. The early 19th century, in particular, saw a proliferation of great essayists in English – William Hazlitt, Charles Lamb, Leigh Hunt and Thomas de Quincey all penned numerous essays on diverse subjects. In the 20th century, a number of essayists tried to explain the new movements in art and culture by using essays (e.g., T.S. Eliot). Whereas some essayists used essays for strident political themes, Robert Louis Stevenson and Willa Cather wrote lighter essays. Virginia Woolf, Edmund Wilson, and Charles du Bos wrote literary criticism essays.\n\nAs with the novel, essays existed in Japan several centuries before they developed in Europe with a genre of essays known as \"zuihitsu\" — loosely connected essays and fragmented ideas. Zuihitsu have existed since almost the beginnings of Japanese literature. Many of the most noted early works of Japanese literature are in this genre. Notable examples include \"The Pillow Book\" (c. 1000), by court lady Sei Shōnagon, and \"Tsurezuregusa\" (1330), by particularly renowned Japanese Buddhist monk Yoshida Kenkō. Kenkō described his short writings similarly to Montaigne, referring to them as \"nonsensical thoughts\" written in \"idle hours\". Another noteworthy difference from Europe is that women have traditionally written in Japan, though the more formal, Chinese-influenced writings of male writers were more prized at the time.\n\nThis section describes the different forms and styles of essay writing. These forms and styles are used by an array of authors, including university students and professional essayists.\n\nThe defining features of a \"cause and effect\" essay are causal chains that connect from a cause to an effect, careful language, and chronological or emphatic order. A writer using this rhetorical method must consider the subject, determine the purpose, consider the audience, think critically about different causes or consequences, consider a thesis statement, arrange the parts, consider the language, and decide on a conclusion.\n\nClassification is the categorization of objects into a larger whole while division is the breaking of a larger whole into smaller parts.\n\nCompare and contrast essays are characterized by a basis for comparison, points of comparison, and analogies. It is grouped by the object (chunking) or by point (sequential). The comparison highlights the similarities between two or more similar objects while contrasting highlights the differences between two or more objects. When writing a compare/contrast essay, writers need to determine their purpose, consider their audience, consider the basis and points of comparison, consider their thesis statement, arrange and develop the comparison, and reach a conclusion. Compare and contrast is arranged emphatically.\n\nExpository essay is used to inform, describe or explain a topic, using important facts and teaching reader about the topic. Mostly written in third-person, using \"it\", \"he\", \"she\", \"they\". Expository essay uses formal language to discuss someone or something. Examples of expository essays are: a medical or biological condition, social or technological process, life or character of a famous person. Writing of expository essay often consists of following next steps: organizing thoughts (brainstorming), researching a topic, developing a thesis statement, writing the introduction, writing the body of essay, writing the conclusion. Expository essays are often assigned as a part of SAT and other standardized testings or as a homework for high school and college students.\n\nDescriptive writing is characterized by sensory details, which appeal to the physical senses, and details that appeal to a reader's emotional, physical, or intellectual sensibilities. Determining the purpose, considering the audience, creating a dominant impression, using descriptive language, and organizing the description are the rhetorical choices to consider when using a description. A description is usually arranged spatially but can also be chronological or emphatic. The focus of a description is the scene. Description uses tools such as denotative language, connotative language, figurative language, metaphor, and simile to arrive at a dominant impression. One university essay guide states that \"descriptive writing says what happened or what another author has discussed; it provides an account of the topic\".\nLyric essays are an important form of descriptive essays.\n\nIn the dialectic form of the essay, which is commonly used in philosophy, the writer makes a thesis and argument, then objects to their own argument (with a counterargument), but then counters the counterargument with a final and novel argument. This form benefits from presenting a broader perspective while countering a possible flaw that some may present. This type is sometimes called an ethics paper.\n\nAn exemplification essay is characterized by a generalization and relevant, representative, and believable examples including anecdotes. Writers need to consider their subject, determine their purpose, consider their audience, decide on specific examples, and arrange all the parts together when writing an exemplification essay.\nAn essayist writes a \"familiar essay\" if speaking to a single reader, writing about both themselves, and about particular subjects. Anne Fadiman notes that \"the genre's heyday was the early nineteenth century,\" and that its greatest exponent was Charles Lamb. She also suggests that while critical essays have more brain than the heart, and personal essays have more heart than brain, familiar essays have equal measures of both.\n\nA history essay sometimes referred to as a thesis essay describes an argument or claim about one or more historical events and supports that claim with evidence, arguments, and references. The text makes it clear to the reader why the argument or claim is as such.\n\nA narrative uses tools such as flashbacks, flash-forwards, and transitions that often build to a climax. The focus of a narrative is the plot. When creating a narrative, authors must determine their purpose, consider their audience, establish their point of view, use dialogue, and organize the narrative. A narrative is usually arranged chronologically.\n\nAn argumentative essay is a critical piece of writing, aimed at presenting objective analysis of the subject matter, narrowed down to a single topic. The main idea of all the criticism is to provide an opinion either of positive or negative implication. As such, a critical essay requires research and analysis, strong internal logic and sharp structure. Its structure normally builds around introduction with a topic's relevance and a thesis statement, body paragraphs with arguments linking back to the main thesis, and conclusion. In addition, an argumentative essay may include a refutation section where conflicting ideas are acknowledged, described, and criticized. Each argument of argumentative essay should be supported with sufficient evidence, relevant to the point.\n\nA process essay is used for an explanation of making or breaking something. Often, it is written in chronological order or numerical order to show step-by-step processes. It has all the qualities of a technical document with the only difference is that it is often written in descriptive mood, while a technical document is mostly in imperative mood.\n\nAn economic essay can start with a thesis, or it can start with a theme. It can take a narrative course and a descriptive course. It can even become an argumentative essay if the author feels the need. After the introduction, the author has to do his/her best to expose the economic matter at hand, to analyze it, evaluate it, and draw a conclusion. If the essay takes more of a narrative form then the author has to expose each aspect of the economic puzzle in a way that makes it clear and understandable for the reader\n\nA \"reflective essay\" is an analytical piece of writing in which the writer describes a real or imaginary scene, event, interaction, passing thought, memory, or form — adding a personal reflection on the meaning of the topic in the author's life. Thus, the focus is not merely descriptive. The writer doesn’t just describe the situation, but revisits the scene with more detail and emotion to examine what went well, or reveal a need for additional learning — and may relate what transpired to the rest of the author's life.\n\nThe logical progression and organizational structure of an essay can take many forms. Understanding how the movement of thought is managed through an essay has a profound impact on its overall cogency and ability to impress. A number of alternative logical structures for essays have been visualized as diagrams, making them easy to implement or adapt in the construction of an argument.\n\nIn countries like the United States and the United Kingdom, essays have become a major part of a formal education in the form of free response questions. Secondary students in these countries are taught structured essay formats to improve their writing skills, and essays are often used by universities in these countries in selecting applicants (\"see\" admissions essay). In both secondary and tertiary education, essays are used to judge the mastery and comprehension of the material. Students are asked to explain, comment on, or assess a topic of study in the form of an essay. In some courses, university students must complete one or more essays over several weeks or months. In addition, in fields such as the humanities and social sciences, mid-term and end of term examinations often require students to write a short essay in two or three hours.\n\nIn these countries, so-called academic essays also called \"papers\", are usually more formal than literary ones. They may still allow the presentation of the writer's own views, but this is done in a logical and factual manner, with the use of the first person often discouraged. Longer academic essays (often with a word limit of between 2,000 and 5,000 words) are often more discursive. They sometimes begin with a short summary analysis of what has previously been written on a topic, which is often called a literature review.\n\nLonger essays may also contain an introductory page that defines words and phrases of the essay's topic. Most academic institutions require that all substantial facts, quotations, and other supporting material in an essay be referenced in a bibliography or works cited page at the end of the text. This scholarly convention helps others (whether teachers or fellow scholars) to understand the basis of facts and quotations the author uses to support the essay's argument and helps readers evaluate to what extent the argument is supported by evidence, and to evaluate the quality of that evidence. The academic essay tests the student's ability to present their thoughts in an organized way and is designed to test their intellectual capabilities.\n\nOne of the challenges facing universities is that in some cases, students may submit essays purchased from an essay mill (or \"paper mill\") as their own work. An \"essay mill\" is a ghostwriting service that sells pre-written essays to university and college students. Since plagiarism is a form of academic dishonesty or academic fraud, universities and colleges may investigate papers they suspect are from an essay mill by using plagiarism detection software, which compares essays against a database of known mill essays and by orally testing students on the contents of their papers.\n\nEssays often appear in magazines, especially magazines with an intellectual bent, such as \"The Atlantic\" and \"Harpers\". Magazine and newspaper essays use many of the essay types described in the section on forms and styles (e.g., descriptive essays, narrative essays, etc.). Some newspapers also print essays in the op-ed section.\nEmployment essays detailing experience in a certain occupational field are required when applying for some jobs, especially government jobs in the United States. Essays known as Knowledge Skills and Executive Core Qualifications are required when applying to certain US federal government positions.\n\nA KSA, or \"Knowledge, Skills, and Abilities,\" is a series of narrative statements that are required when applying to Federal government job openings in the United States. KSAs are used along with resumes to determine who the best applicants are when several candidates qualify for a job. The knowledge, skills, and abilities necessary for the successful performance of a position are contained on each job vacancy announcement. KSAs are brief and focused essays about one's career and educational background that presumably qualify one to perform the duties of the position being applied for.\n\nAn Executive Core Qualification, or ECQ, is a narrative statement that is required when applying to Senior Executive Service positions within the US Federal government. Like the KSAs, ECQs are used along with resumes to determine who the best applicants are when several candidates qualify for a job. The Office of Personnel Management has established five executive core qualifications that all applicants seeking to enter the Senior Executive Service must demonstrate.\n\nA film essay (or \"cinematic essay\") consists of the evolution of a theme or an idea rather than a plot per se, or the film literally being a cinematic accompaniment to a narrator reading an essay. From another perspective, an essay film could be defined as a documentary film visual basis combined with a form of commentary that contains elements of self-portrait (rather than autobiography), where the signature (rather than the life story) of the filmmaker is apparent. The cinematic essay often blends documentary, fiction, and experimental film making using tones and editing styles.\n\nThe genre is not well-defined but might include propaganda works of early Soviet parliamentarians like Dziga Vertov, present-day filmmakers including Chris Marker, Michael Moore (\"Roger & Me\" (1989), \"Bowling for Columbine\" (2002) and \"Fahrenheit 9/11\" (2004)), Errol Morris (\"The Thin Blue Line\" (1988)), Morgan Spurlock (\"Supersize Me: A Film of Epic Portions\") and Agnès Varda. Jean-Luc Godard describes his recent work as \"film-essays\". Two filmmakers whose work was the antecedent to the cinematic essay include Georges Méliès and Bertolt Brecht. Méliès made a short film (\"The Coronation of Edward VII\" (1902)) about the 1902 coronation of King Edward VII, which mixes actual footage with shots of a recreation of the event. Brecht was a playwright who experimented with film and incorporated film projections into some of his plays. Orson Welles made an essay film in his own pioneering style, released in 1974, called \"F for Fake\", which dealt specifically with art forger Elmyr de Hory and with the themes of deception, \"fakery,\" and authenticity in general. These are often published online on video hosting services.\n\nDavid Winks Gray's article \"The essay film in action\" states that the \"essay film became an identifiable form of filmmaking in the 1950s and '60s\". He states that since that time, essay films have tended to be \"on the margins\" of the filmmaking the world. Essay films have a \"peculiar searching, questioning tone ... between documentary and fiction\" but without \"fitting comfortably\" into either genre. Gray notes that just like written essays, essay films \"tend to marry the personal voice of a guiding narrator (often the director) with a wide swath of other voices\". The University of Wisconsin Cinematheque website echoes some of Gray's comments; it calls a film essay an \"intimate and allusive\" genre that \"catches filmmakers in a pensive mood, ruminating on the margins between fiction and documentary\" in a manner that is \"refreshingly inventive, playful, and idiosyncratic\".\n\nIn the realm of music, composer Samuel Barber wrote a set of \"Essays for Orchestra,\" relying on the form and content of the music to guide the listener's ear, rather than any extra-musical plot or story.\n\nA photographic essay strives to cover a topic with a linked series of photographs. Photo essays range from purely photographic works to photographs with captions or small notes to full-text essays with a few or many accompanying photographs. Photo essays can be sequential in nature, intended to be viewed in a particular order — or they may consist of non-ordered photographs viewed all at once or in an order that the viewer chooses. All photo essays are collections of photographs, but not all collections of photographs are photo essays. Photo essays often address a certain issue or attempt to capture the character of places and events.\nIn the visual arts, an essay is a preliminary drawing or sketch that forms a basis for a final painting or sculpture, made as a test of the work's composition (this meaning of the term, like several of those following, comes from the word \"essay\"'s meaning of \"attempt\" or \"trial\").\n\n\n\n"}
{"id": "184421", "url": "https://en.wikipedia.org/wiki?curid=184421", "title": "FOXP2", "text": "FOXP2\n\nForkhead box protein P2 (FOXP2) is a protein that, in humans, is encoded by the \"FOXP2\" gene, also known as \"CAGH44\", \"SPCH1\" or \"TNRC10\", and is required for proper development of speech and language. The gene is shared with many vertebrates, where it generally plays a role in communication (for instance, the development of bird song).\n\nInitially identified as the genetic factor of speech disorder in KE family, \"FOXP2\" is the first gene discovered associated with speech and language. The gene is located on chromosome 7 (7q31, at the \"SPCH1\" locus) and is expressed in fetal and adult brain, heart, lung and gut. \"FOXP2\" orthologs have also been identified in other mammals for which complete genome data are available. The \"FOXP2\" protein contains a forkhead-box DNA-binding domain, making it a member of the FOX group of transcription factors, involved in regulation of gene expression. In addition to this characteristic forkhead-box domain, the protein contains a polyglutamine tract, a zinc finger and a leucine zipper. The gene is more active in females than in males, to which could be attributed better language learning in females.\n\nIn humans, mutations of \"FOXP2\" cause a severe speech and language disorder. Versions of \"FOXP2\" exist in similar forms in distantly related vertebrates; functional studies of the gene in mice and in songbirds indicate that it is important for modulating plasticity of neural circuits. Outside the brain \"FOXP2\" has also been implicated in development of other tissues such as the lung and gut.\n\n\"FOXP2\" is popularly dubbed the \"language gene\", but this is only partly correct since there are other genes involved in language development. It directly regulates a number of other genes, including \"CNTNAP2\", \"CTBP1\", and \"SRPX2\".\n\nTwo amino acid substitutions distinguish the human \"FOXP2\" protein from that found in chimpanzees, but only one of these changes is unique to humans. Evidence from genetically manipulated mice and human neuronal cell models suggests that these changes affect the neural functions of \"FOXP2\".\n\n\"FOXP2\" and its gene were discovered as a result of investigations on an English family known as the KE family, half of whom (fifteen individuals across three generations) suffered from a speech and language disorder called developmental verbal dyspraxia. Their case was studied at the Institute of Child Health of University College London. In 1990 Myrna Gopnik, Professor of Linguistics at McGill University, reported that the disorder-affected KE family had severe speech impediment with incomprehensible talk, largely characterized by grammatical deficits. She hypothesized that the basis was not of learning or cognitive disability, but due to genetic factors affecting mainly grammatical ability. (Her hypothesis led to a popularised existence of \"grammar gene\" and a controversial notion of grammar-specific disorder.) In 1995, the University of Oxford and the Institute of Child Health researchers found that the disorder was purely genetic. Remarkably, the inheritance of the disorder from one generation to the next was consistent with autosomal dominant inheritance, i.e., mutation of only a single gene on an autosome (non-sex chromosome) acting in a dominant fashion. This is one of the few known examples of Mendelian (monogenic) inheritance for a disorder affecting speech and language skills, which typically have a complex basis involving multiple genetic risk factors.\n\nIn 1998, Oxford University geneticists Simon Fisher, Anthony Monaco, Cecilia S. L. Lai, Jane A. Hurst, and Faraneh Vargha-Khadem identified an autosomal dominant monogenic inheritance that is localized on a small region of chromosome 7 from DNA samples taken from the affected and unaffected members. The chromosomal region (locus) contained 70 genes. The locus was given the official name \"SPCH1\" (for speech-and-language-disorder-1) by the Human Genome Nomenclature committee. Mapping and sequencing of the chromosomal region was performed with the aid of bacterial artificial chromosome clones. Around this time, the researchers identified an individual who was unrelated to the KE family, but had a similar type of speech and language disorder. In this case the child, known as CS, carried a chromosomal rearrangement (a translocation) in which part of chromosome 7 had become exchanged with part of chromosome 5. The site of breakage of chromosome 7 was located within the SPCH1 region.\n\nIn 2001, the team identified in CS that the mutation is in the middle of a protein-coding gene. Using a combination of bioinformatics and RNA analyses, they discovered that the gene codes for a novel protein belonging to the forkhead-box (FOX) group of transcription factors. As such, it was assigned with the official name of FOXP2. When the researchers sequenced the \"FOXP2\" gene in the KE family, they found a heterozygous point mutation shared by all the affected individuals, but not in unaffected members of the family and other people. This mutation is due to an amino-acid substitution that inhibits the DNA-binding domain of the \"FOXP2\" protein. Further screening of the gene identified multiple additional cases of \"FOXP2\" disruption, including different point mutations and chromosomal rearrangements, providing evidence that damage to one copy of this gene is sufficient to derail speech and language development.\n\n\"FOXP2\" is required for proper brain and lung development. Knockout mice with only one functional copy of the \"FOXP2\" gene have significantly reduced vocalizations as pups. Knockout mice with no functional copies of \"FOXP2\" are runted, display abnormalities in brain regions such as the Purkinje layer, and die an average of 21 days after birth from inadequate lung development.\n\n\"FOXP2\" is expressed in many areas of the brain including the basal ganglia and inferior frontal cortex where it is essential for brain maturation and speech and language development.\n\nA knockout mouse model has been used to examine \"FOXP2\"'s role in brain development and how mutations in the two copies of \"FOXP2\" affect vocalization. Mutations in one copy result in reduced speech while abnormalities in both copies cause major brain and lung developmental issues.\n\nThe expression of \"FOXP2\" is subject to post-transcriptional regulation, particularly micro RNA, which binds to multiple miRNA binding-sites in the neocortex, causing the repression of FOXP2 3’UTR.\n\nThere are several abnormalities linked to \"FOXP2\". The most common mutation results in severe speech impairment known as developmental verbal dyspraxia (DVD) which is caused by a translocation in the 7q31.2 region [t(5;7)(q22;q31.2)]. A missense mutation causing an arginine-to-histidine substitution (R553H) in the DNA-binding domain is thought to be the abnormality in KE. A heterozygous nonsense mutation, R328X variant, produces a truncated protein involved in speech and language difficulties in one KE individual and two of their close family members. R553H and R328X mutations also affected nuclear localization, DNA-binding, and the transactivation (increased gene expression) properties of \"FOXP2\". Although DVD associated with \"FOXP2\" disruptions are thought to be rare (~2% by one estimate), genetic links from \"FOXP2\" to disease usually relate to speech or language problems. \n\nSeveral cases of developmental verbal dyspraxia in humans have been linked to mutations in the \"FOXP2\" gene. Such individuals have little or no cognitive handicap but are unable to correctly perform the coordinated movements required for speech. fMRI analysis of these individuals performing silent verb generation and spoken word repetition tasks showed underactivation of Broca's area and the putamen, brain centers thought to be involved in language tasks. Because of this, \"FOXP2\" has been dubbed the \"language gene\". People with this mutation also experience symptoms not related to language (not surprisingly, as \"FOXP2\" is known to affect development in other parts of the body as well). Scientists have also looked for associations between \"FOXP2\" and autism, and both positive and negative findings have been reported.\n\nThere is some evidence that the linguistic impairments associated with a mutation of the \"FOXP2\" gene are not simply the result of a fundamental deficit in motor control. For examples, the impairments include difficulties in comprehension. Brain imaging of affected individuals indicates functional abnormalities in language-related cortical and basal/ganglia regions, demonstrating that the problems extend beyond the motor system.\n\nThe \"FOXP2\" gene is highly conserved in mammals. The human gene differs from that in non-human primates by the substitution of two amino acids, a threonine to asparagine substitution at position 303 (T303N) and an asparagine to serine substitution at position 325 (N325S). In mice it differs from that of humans by three substitutions, and in zebra finch by seven amino acids. One of the two amino acid differences between human and chimps also arose independently in carnivores and bats. Similar \"FOXP2\" proteins can be found in songbirds, fish, and reptiles such as alligators.\n\nDNA sampling from \"Homo neanderthalensis\" bones indicates that their \"FOXP2\" gene is a little different, though largely similar to those of \"Homo sapiens\" (i.e. humans). \n\nThe \"FOXP2\" gene showed indications of recent positive selection. Some researchers have speculated that positive selection is crucial for the evolution of language in humans. Others, however, have been unable to find a clear association between species with learned vocalizations and similar mutations in \"FOXP2\". Recent data from a large sample of globally distributed genomes showed no evidence of positive selection, suggesting that the original signal of positive selection may be driven by sample composition. Insertion of both human mutations into mice, whose version of \"FOXP2\" otherwise differs from the human and chimpanzee versions in only one additional base pair, causes changes in vocalizations as well as other behavioral changes, such as a reduction in exploratory tendencies, and a decrease in maze learning time. A reduction in dopamine levels and changes in the morphology of certain nerve cells are also observed.\n\nHowever, \"FOXP2\" is extremely diverse in echolocating bats. Twenty-two sequences of non-bat eutherian mammals revealed a total number of 20 nonsynonymous mutations in contrast to half that number of bat sequences, which showed 44 nonsynonymous mutations. All cetaceans share three amino acid substitutions, but no differences were found between echolocating toothed whales and non-echolocating baleen cetaceans. Within bats, however, amino acid variation correlated with different echolocating types.\n\n\"FOXP2\" interacts with a regulatory gene \"CTBP1\". It also downregulates \"CNTNAP2\" gene, a member of the neurexin family found in neurons. The target gene is associated with common forms of language impairment. It regulates the repeat-containing protein X-linked 2 (\"SRPX2\"), which is an epilepsy and language-associated gene in humans, and sound-controlling gene in mice.\n\nIn a mouse \"FOXP2\" knockout study, loss of both copies of the gene caused severe motor impairment related to cerebellar abnormalities and lack of ultrasonic vocalisations normally elicited when pups are removed from their mothers. These vocalizations have important communicative roles in mother-offspring interactions. Loss of one copy was associated with impairment of ultrasonic vocalisations and a modest developmental delay. Male mice on encountering female mice produce complex ultrasonic vocalisations that have characteristics of song. Mice that have the R552H point mutation carried by the KE family show cerebellar reduction and abnormal synaptic plasticity in striatal and cerebellar circuits.\n\nIn songbirds, \"FOXP2\" most likely regulates genes involved in neuroplasticity.\nGene knockdown of \"FOXP2\" in Area X of the basal ganglia in songbirds results in incomplete and inaccurate song imitation. Overexpression of FoxP2 was accomplished through injection of adeno-associated virus serotype 1 (AAV1) into Area X of the brain. This overexpression produced similar effects to that of knockdown; juvenile zebra finch birds were unable to accurately imitate their tutors. Similarly, in adult canaries higher \"FOXP2\" levels also correlate with song changes.\n\nLevels of \"FOXP2\" in adult zebra finches are significantly higher when males direct their song to females than when they sing song in other contexts. “Directed” singing refers to when a male is singing to a female usually for a courtship display. “Undirected” singing occurs when for example, a male sings when other males are present or is alone. Studies have found that FoxP2 levels vary depending on the social context. When the birds were singing undirected song, there was a decrease of FoxP2 expression in Area X. This downregulation was not observed and FoxP2 levels remained stable in birds singing directed song.\n\nDifferences between song-learning and non-song-learning birds have been shown to be caused by differences in \"FOXP2\" gene expression, rather than differences in the amino acid sequence of the \"FOXP2\" protein.\n\n\"FOXP2\" also has possible implications in the development of bat echolocation.\n\n\n"}
{"id": "11964", "url": "https://en.wikipedia.org/wiki?curid=11964", "title": "Genus–differentia definition", "text": "Genus–differentia definition\n\nA genus–differentia definition is a type of intensional definition, and it is composed of two parts:\n\nFor example, consider these two definitions:\nThose definitions can be expressed as one genus and two \"differentiae\":\n\nThe process of producing new definitions by \"extending\" existing definitions is commonly known as differentiation (and also as derivation). The reverse process, by which just part of an existing definition is used itself as a new definition, is called abstraction; the new definition is called \"an abstraction\" and it is said to have been \"abstracted away from\" the existing definition.\n\nFor instance, consider the following:\nA part of that definition may be singled out (using parentheses here):\nand with that part, an abstraction may be formed:\nThen, the definition of \"a square\" may be recast with that abstraction as its genus:\n\nSimilarly, the definition of \"a square\" may be rearranged and another portion singled out:\nleading to the following abstraction:\nThen, the definition of \"a square\" may be recast with that abstraction as its genus:\n\nIn fact, the definition of \"a square\" may be recast in terms of both of the abstractions, where one acts as the genus and the other acts as the differentia:\nHence, abstraction is crucial in simplifying definitions.\n\nWhen multiple definitions could serve equally well, then all such definitions apply simultaneously. Thus, \"a square\" is a member of both the genus \"[a] rectangle\" and the genus \"[a] rhombus\". In such a case, it is notationally convenient to consolidate the definitions into one definition that is expressed with multiple genera (and possibly no differentia, as in the following):\nor completely equivalently:\n\nMore generally, a collection of formula_1 equivalent definitions (each of which is expressed with one unique genus) can be recast as one definition that is expressed with formula_2 genera. Thus, the following:\ncould be recast as:\n\nA genus of a definition provides a means by which to specify an \"is-a relationship\":\nThe non-genus portion of the differentia of a definition provides a means by which to specify a \"has-a relationship\":\n\nWhen a system of definitions is constructed with genera and differentiae, the definitions can be thought of as nodes forming a hierarchy or—more generally—a directed acyclic graph; a node that has no predecessor is \"a most general definition\"; each node along a directed path is \"more differentiated (or \"more derived) than any one of its predecessors, and a node with no successor is \"a most differentiated\" (or \"a most derived\") definition.\n\nWhen a definition, \"S\", is the tail of each of its successors (that is, \"S\" has at least one successor and each direct successor of \"S\" is a most differentiated definition), then \"S\" is often called \"the species of each of its successors, and each direct successor of \"S\" is often called \"an individual (or \"an entity\") of the species \"S\"; that is, the genus of an individual is synonymously called \"the species\" of that individual. Furthermore, the differentia of an individual is synonymously called \"the identity\" of that individual. For instance, consider the following definition:\nIn this case:\n\nAs in that example, the identity itself (or some part of it) is often used to refer to the entire individual, a phenomenon that is known in linguistics as a \"pars pro toto synecdoche\".\n"}
{"id": "11709017", "url": "https://en.wikipedia.org/wiki?curid=11709017", "title": "Global language system", "text": "Global language system\n\nThe global language system is the \"ingenious pattern of connections between language groups\". Dutch sociologist Abram de Swaan developed this theory in 2001 in his book \"Words of the World: The Global Language System\" and according to him, \"the multilingual connections between language groups do not occur haphazardly, but, on the contrary, they constitute a surprisingly strong and efficient network that ties together – directly or indirectly – the six billion inhabitants of the earth.\" The global language system draws upon the world system theory to account for the relationships between the world's languages and divides them into a hierarchy consisting of four levels, namely the peripheral, central, supercentral and hypercentral languages.\n\nAccording to de Swaan, the global language system has been constantly evolving since the time period of the early 'military-agrarian' regimes. Under these regimes, the rulers imposed their own language and so the first 'central' languages emerged, linking the peripheral languages of the agrarian communities via bilingual speakers to the language of the conquerors. Then was the formation of empires, which resulted in the next stage of integration of the world language system.\n\nFirstly, Latin emerged from Rome. Under the rule of the Roman Empire, under which an extensive group of states were ruled by, the usage of Latin stretched along the Mediterranean coast, the southern half of Europe, and more sparsely to the North and then into the Germanic and Celtic lands. Thus, Latin evolved to become a central language in Europe from 27 BC to 476 AD.\n\nSecondly, there was the widespread usage of the pre-classical version of Han Chinese in contemporary China due to the unification of China in 221 BC by Qin Shi Huang.\n\nThirdly, Sanskrit started to become widely spoken in South Asia from the widespread teaching of Hinduism and Buddhism in South Asian countries.\n\nFourthly, the expansion of the Arabic empire also led to the increased usage of Arabic as a language in the Afro-Eurasian land mass.\n\nMilitary conquests of preceding centuries generally determine the distribution of languages today.\nSupercentral languages spread by land and sea. Land-bound languages spread via marching empires: German, Russian, Arabic, Hindi, Chinese and Japanese. However, when the conquerors were defeated and were forced to move out of the territory, the spread of the languages receded. As a result, some of these languages are currently barely supercentral languages and are instead confined to their remaining state territories, as is evident from German, Russian and Japanese.\n\nOn the other hand, sea-bound languages spread by conquests overseas: English, French, Portuguese, Spanish. Consequently, these languages became widespread in areas settled by European colonisers and relegated the indigenous people and their languages to peripheral positions.\n\nBesides, the world-systems theory also allowed the global language system to expand further. It focuses on the existence of the core, semi-peripheral and peripheral nations. The core countries are the most economically powerful and the wealthiest countries. Besides, they also have a strong governmental system in the country, which oversees the bureaucracies in the governmental departments. There is also the prevalent existence of the bourgeois, and core nations have significant influence over the non-core, smaller nations. Historically, the core countries were found in northwestern Europe and include countries such as England, France and the Netherlands. They were the dominant countries that had colonized many other nations from the early 15th century to the early 19th century.\n\nThen is the existence of the periphery countries, the countries with the slowest economic growth. They also have relatively weak governments and a poor social structure and often depend on primary industries as the main source of economic activity for the country.\n\nThe extracting and exporting of raw materials from the peripheral nations to core nations is the activity bringing about the most economic benefits to the country. Much of the population that is poor and uneducated, and the countries are also extensively influenced by core nations and the multinational corporations found there. Historically, peripheral nations were found outside Europe, the continent of colonial masters. Many countries in Latin America were peripheral nations during the period of colonization, and today peripheral countries are in sub-Saharan Africa.\n\nLastly, the presence of the semiperiphery countries, those in between the core and the periphery. They tend to be those which started out as peripheral nations and are currently moving towards industrialization and the development of more diversified labour markets and economies. They can as well come about from declining core countries. They are not dominant players in the international trade market. As compared to the peripheral nations, semi-peripheries are not as susceptible to manipulation by the core countries. However, most of these nations have economic or political relations with the core. Semi-peripheries also tend to exert influence and control over peripheries and can serve to be a buffer between the core and peripheral nations and ease political tensions. Historically, Spain and Portugal were semi-peripheral nations after they fell from their dominant core positions. As they still maintained a certain level of influence and dominance in Latin America over their colonies, they could still maintain their semi-peripheral position.\n\nAccording to Immanuel Wallerstein, one of the most well-known theorists who developed the world-systems approach, a core nation is dominant over the non-core nations from its economic and trade dominance. The abundance of cheap and unskilled labour in the peripheral nations makes many large multinational corporations (MNCs), from core countries, often outsource their production to the peripheral countries to cut costs, by employing cheap labour. Hence, the languages from the core countries could penetrate into the peripheries from the setting up of the foreign MNCs in the peripheries. A significant percentage of the population living in the core countries had also migrated to the core countries in search of jobs with higher wages.\n\nThe gradual expansion of the population of migrants makes the language used in their home countries be brought into the core countries, thus allowing for further integration and expansion of the world language system. The semi-peripheries also maintain economic and financial trade with the peripheries and core countries. That allows for the penetration of languages used in the semi-peripheries into the core and peripheral nations, with the flow of migrants moving out of the semi-peripheral nations to the core and periphery for trade purposes.\n\nThus, the global language system examines rivalries and accommodations using a global perspective and establishes that the linguistic dimension of the world system goes hand in hand with the political, economic, cultural and ecological aspects. Specifically, the present global constellation of languages is the product of prior conquest and domination and of ongoing relations of power and exchange.\n\nformula_1 is the communicative value of a language \"i\", its potential to connect a speaker with other speakers of a constellation or subconstellation, \"S\". It is defined as follows:\n\nformula_2\n\nThe prevalence formula_3 of language \"i\", means the number of competent speakers in \"i\", formula_4, divided by all the speakers, formula_5 of constellation \"S\". Centrality, formula_6 is the number of multilingual speakers formula_7 who speak language \"i\" divided by all the multilingual speakers in constellation \"S\", formula_8.\n\nThus, the Q-value or communication value is the product of the prevalence formula_3 and the centrality formula_6 of language \"i\" in constellation \"S\".\n\nConsequently, a peripheral language has a low Q-value and the Q-values increase along the sociology classification of languages, with the Q-value of the hypercentral language being the highest.\n\nDe Swaan has been calculating the Q-values of the official European Union(EU) languages since 1957 to explain the acquisition of languages by EU citizens in different phases.\n\nIn 1970, when there were only four language constellations, Q-value decreased in the order of French, German, Italian, Dutch. In 1975, the European Commission enlarged to include Britain, Denmark and Ireland. English had the highest Q-value followed by French and German.\nIn the following years, the European Commission grew, with the addition of countries like Austria, Finland and Sweden. Q-value of English still remained the highest, but French and German swapped places.\n\nIn EU23, which refers to the 23 official languages spoken in the European Union, the Q-values for English, German and French were 0.194, 0.045 and 0.036 respectively.\n\nDe Swaan likens the global language system to contemporary political macrosociology and states that language constellations are a social phenomenon, which can be understood by using social science theories. In his theory, de Swaan uses the Political Sociology of Language and Political Economy of Language to explain the rivalry and accommodation between language groups.\n\nThis theoretical perspective centres on the interconnections among the state, nation and citizenship. Accordingly, bilingual elite groups try to take control of the opportunities for mediation between the monolingual group and the state. Subsequently, they use the official language to dominate the sectors of government and administration and the higher levels of employment. It assumes that both the established and outsider groups are able to communicate in a shared vernacular, but the latter groups lack the literacy skills that could allow them to learn the written form of the central or supercentral language, which would, in turn allow, them to move up the social ladder.\n\nThis perspective centres on the inclinations that people have towards learning one language over the other. The presumption is that if given a chance, people will learn the language that gives them more communication advantage. In other words, a higher Q-Value. Certain languages such as English or Chinese have high Q-values since they are spoken in many countries across the globe and would thus be more economically useful than to less spoken languages, such as Romanian or Hungarian.\n\nFrom an economic perspective, languages are ‘hypercollective’ goods since they exhibit properties of collective goods and produce external network effects. Thus, the more speakers a language has, the higher its communication value for each speaker. The hypercollective nature and Q-Value of languages thus help to explain the dilemma that a speaker of a peripheral language faces when deciding whether to learn the central or hypercentral language. The hypercollective nature and Q-value also help to explain the accelerating spread and abandonment of various languages. In that sense, when people feel that a language is gaining new speakers, they would assign a greater Q-value to this language and abandon their own native language in place of a more central language. The hypercollective nature and Q-value also explain, in an economic sense, the ethnic and cultural movements for language conservation.\n\nSpecifically, a minimal Q-value of a language is guaranteed when there is a critical mass of speakers committed to protecting it, thus preventing the language from being forsaken.\n\nThe global language system theorises that language groups are engaged in unequal competition on different levels globally. Using the notions of a periphery, semi-periphery and a core, which are concepts of the world system theory, de Swaan relates them to the four levels present in the hierarchy of the global language system: peripheral, central, supercentral and hypercentral.\n\nDe Swaan also argues that the greater the range of potential uses and users of a language, the higher the tendency of an individual to move up the hierarchy in the global language system and learn a more \"central\" language. Thus, de Swaan views the learning of second languages as proceeding up rather than down the hierarchy, in the sense that they learn a language that is on the next level up. For instance, speakers of Catalan, a peripheral language, have to learn Spanish, a central language to function in their own society, Spain. Meanwhile, speakers of Persian, a central language, have to learn Arabic, a supercentral language, to function in their region. On the other hand, speakers of a supercentral language have to learn the hypercentral language to function globally, as is evident from the huge number of non-native English speakers.\n\nAccording to de Swaan, languages exist in \"constellations\" and the global language system comprises a sociological classification of languages based on their social role for their speakers. The world's languages and multilinguals are connected in a strongly ordered, hierarchical pattern. There are thousands of peripheral or minority languages in the world, each of which are connected to one of a hundred central languages. The connections and patterns between each language is what makes up the global language system. The four levels of language are the peripheral, central, supercentral and hypercentral languages.\n\nAt the lowest level, peripheral languages, or minority languages, form the majority of languages spoken in the world; 98% of the world's languages are peripheral languages and spoken by less than 10% of the world’s population. Unlike central languages, these are \"languages of conversation and narration rather than reading and writing, of memory and remembrance rather than record\". They are used by native speakers within a particular area and are in danger of becoming extinct with increasing globalisation, which sees more and more speakers of peripheral languages acquiring more central languages in order to communicate with others.\n\nThe next level constitutes about 100 central languages, spoken by 95% of the world's population and generally used in education, media and administration. Typically, they are the 'national' and official languages of the ruling state. These are the languages of record, and much of what has been said and written in those languages is saved in newspaper reports, minutes and proceedings, stored in archives, included in history books, collections of the 'classics', of folk talks and folk ways, increasingly recorded on electronic media and thus conserved for posterity.\n\nMany speakers of central languages are multilingual because they are either native speakers of a peripheral language and have acquired the central language, or they are native speakers of the central language and have learned a supercentral language.\n\nAt the second highest level, 13 supercentral languages are very widely spoken languages that serve as connectors between speakers of central languages: Arabic, Chinese, English, French, German, Hindi, Japanese, Malay, Portuguese, Russian, Spanish, Swahili and Turkish.\n\nThese languages often have colonial traces and \"were once imposed by a colonial power and after independence continued to be used in politics, administration, law, big business, technology and higher education\".\n\nAt the highest level is the language that connects speakers of the supercentral languages. Today, English is the only example of a hypercentral language as the standard for science, literature, business, and law, as well as being the most widely spoken second language.\n\nAccording to David Graddol (1997), in his book titled \"The Future of English\", the languages of the world comprise a \"hierarchical pyramid\", as follows:\n\n\nThe global language system is also seen in the international translation process as explained by Johan Heilbron, a historical sociologist: \"translations and the manifold activities these imply are embedded in and dependent on a world system of translation, including both the source and the target cultures\".\n\nThe hierarchical relationship between global languages is reflected in the global system for translations. The more \"central\" a language, the greater is its capability to function as a bridge or vehicular language to facilitate communication between peripheral and semi-central languages.\n\nHeilbron's version of the global system of language in translations has four levels:\n\nLevel 1: Hypercentral position — \nEnglish currently holds the largest market share of the global market for translations; 55–60% of all book translations are from English. It strongly dominates the hierarchical nature of book translation system.\n\nLevel 2: Central position — \nGerman and French each hold 10% of the global translation market.\n\nLevel 3: Semi-central position — \nThere are 7 or 8 languages \"neither very central on a global level nor very peripheral\", making up 1 to 3% of the world market (like Spanish, Italian and Russian).\n\nLevel 4: Peripheral position — \nLanguages from which \"less than 1% of the book translations worldwide are made\", including Chinese, Japanese and Arabic. Despite having large populations of speakers, \"their role in the translation economy is peripheral as compared to more central languages\".\n\nAccording to the Google Scholar website, de Swaan's book, \"Words of the world: The global language system\", has been cited by 546 other papers, as of 16 October 2014.\n\nHowever, there have also been several concerns regarding the global language system:\n\nVan Parijs (2004) claimed that 'frequency' or likelihood of contact is adequate as an indicator of language learning and language spread. However, de Swaan (2007) argued that it alone is not sufficient. Rather, the Q-value, which comprises both frequency (better known as prevalence) and 'centrality', helps to explain the spread of (super)central languages, especially former colonial languages in newly independent countries where in which only the elite minority spoke the language initially. Frequency alone would not be able to explain the spread of such languages, but Q-value, which includes centrality, would be able to.\n\nIn another paper, Cook and Li (2009) examined the ways to categorise language users into various groups. They suggested two theories: one by Siegel (2006) who used 'sociolinguistic settings', which is based on the notion of dominant language, and another one by de Swaan (2001) that used the concept of hierarchy in the global language system. According to them, de Swaan's hierarchy is more appropriate, as it does not imply dominance in power terms. Rather, de Swaan's applies the concepts of geography and function to group languages and hence language users according to the global language system. De Swaan (2001) views the acquisition of second languages (L2) as typically going up the hierarchy.\n\nHowever, Cook and Li argues that this analysis is not adequate in accounting for the many groups of L2 users to whom the two areas of territory and function hardly apply. The two areas of territory and function can be associated respectively with the prevalence and centrality of the Q-value. This group of L2 users typically doez not acquire an L2 going up the hierarchy, such as users in an intercultural marriage or users who come from a particular cultural or ethnic group and wish to learn its language for identity purposes. Thus, Cook and Li argue that de Swaan's theory, though highly relevant, still has its drawbacks in that the concept behind Q-value is insufficient in accounting for some L2 users.\n\nThere is disagreement as to which languages should be considered more central. The theory states that a language is central if it connects speakers of \"a series of central languages\". Robert Phillipson questioned why Japanese is included as one of the supercentral languages but Bengali, which has more speakers, is not on the list.\n\nMichael Morris argued that while it is clear that there is language hierarchy from the \"ongoing interstate competition and power politics\", there is little evidence provided that shows that the \"global language interaction is so intense and systematic that it constitutes a global language system, and that the entire system is held together by one global language, English\". He claimed that de Swaan's case studies demonstrated that hierarchy in different regions of the world but did not show the existence of a system within a region or across regions. The global language system is supposed to be part of the international system but is \"notoriously vague and lacking in operational importance\" and therefore cannot be shown to exist. However, Morris believes that this lack of evidence could be from the lack of global language data and not negligence on de Swaan's part. Morris also believes that any theory on a global system, if later proved, would be much more complex than what is proposed by de Swaan. Questions on how the hypercentral language English holds together the system must also be answered by such a global language system.\n\nRobert Phillipson states that the theory is based on selective theoretical foundations. He claimed that there is a lack of consideration about the effects of globalization, which is especially important when the theory is about a global system: \"De Swaan nods occasionally in the direction of linguistic and cultural capital, but does not link this to class or linguistically defined social stratification (linguicism) or linguistic inequality\" and that \"key concepts in the sociology of language, language maintenance and shift, and language spread are scarcely mentioned\".\n\nOn the other hand, de Swaan's work in the field of sociolinguistics has been noted by other scholars to be focused on \"issues of economic and political sociology\" and \"politic and economic patterns\", which may explain why he makes only 'cautious references to socio-linguistic parameters\".\n\n"}
{"id": "8753001", "url": "https://en.wikipedia.org/wiki?curid=8753001", "title": "Glossophilia", "text": "Glossophilia\n\nGlossophilia is a love of language, be it foreign or native. The term refers to people with a love for language and the structure of language. Glossophiles also dedicate themselves to the learning of foreign languages and intensely study as many languages as possible. It is not uncommon for glossophiles to be proficient in many languages.\n\n\n"}
{"id": "31107318", "url": "https://en.wikipedia.org/wiki?curid=31107318", "title": "Good language learner studies", "text": "Good language learner studies\n\nThe good language learner (GLL) studies are a group of academic studies in the area of second language acquisition that deal with the strategies that good language learners exhibit. The rationale for the studies was that there is more benefit from studying the habits of successful language learners than there is from studying learners who fossilize at an early stage or stop studying altogether. It was thought that if the strategies of successful learners could be found, then that knowledge could help learners who were not getting such good results.\n\nThe original studies were made in the 1970s, but petered out in the 1980s as researchers concentrated on individual learning strategies. However, some research on the topic has also been carried out in more recent years. The main body of GLL research investigated language learning in classroom situations. It found that good language learners could not be distinguished on the basis of observable behavior alone, although personality did seem to have an effect. It also found that teachers did not treat these learners differently from other students, although they could distinguish good language learners from learners who were not so effective.\n\nThe first studies in the good language learner tradition were made by Joan Rubin and David Stern, both of which were completed in 1975. Both of these studies proposed similar lists of strategies that good language learners use. On the basis of this, a large-scale study was performed at the Ontario Institute for Studies in Education (OISE) which investigated 34 language learners with good learning habits. This study found a list of six different strategies, which were similar to those proposed by Rubin and Stern:\n\n\nIn spite of the flurry of interest in the GLL in the mid to late 70s, in the 80s and 90s interest moved more in the direction of socio/cultural influences and individual differences, as well as developing the concept of communicative competence into a communicative approach to language teaching.\n\nIn the new millennium, Norton and Toohey re-visited the GLL. Their new perspective emphasized the influence of situation, investment and identity on successful language learning.\n\nSeven years later, Griffiths, harking back to Joan Rubin's original title, published \"Lessons from Good Language Learners\". Whereas the early work in the GLL field had tended to emphasize the role of strategies, Griffiths' work took a broader view and presented the GLL as a highly complex being involving many different variables, including motivation, age, style, personality, gender, metacognition, autonomy, beliefs, culture and aptitude. In addition, the target variables (including grammar, vocabulary, pronunciation, function and skills) and some of the situational factors (including method and error correction practices) which learners must manage if they are to be successful were discussed.\n\n\n"}
{"id": "39356537", "url": "https://en.wikipedia.org/wiki?curid=39356537", "title": "Hockett's design features", "text": "Hockett's design features\n\nIn the 1960s, linguistic anthropologist Charles F. Hockett defined a set of features that characterize human language and set it apart from animal communication. He called these characteristics the design features of language. Hockett originally believed there to be 13 design features. While primate communication utilizes the first 9 features, the final 4 features (displacement, productivity, cultural transmission, and duality) are reserved for humans. Hockett later added prevarication, reflexiveness, and learnability to the list as uniquely human characteristics. He asserted that even the most basic human languages possess these 16 features.\n\nCharles Hockett was an American linguist and anthropologist, who lived from 1916 to 2000. Hockett graduated from Yale in 1939, and later taught at both Cornell and Rice. Hockett made significant contributions to structural linguistics, as well as the study of Native American, Chinese, and Fijian languages. His work focused on detailed linguistic analysis, particularly morphology and phonology, and on the concepts and tools that facilitated such analysis.\nUp until the 1950s, language was largely viewed as a social-behavioral phenomenon. Hockett was challenged in this belief by Noam Chomsky, who suggested that language is biologically-based and innately learned. He believed that humans share a universal grammar that ties all languages together. Hockett staunchly opposed this \"Chomskyan\" concept of the nature of language. However, Hockett is most famous for defining what he called the design features of language, which demonstrate his beliefs about the commonalities between human languages.\n\nVocal-auditory channel.\nRefers to the idea that speaking/hearing is the mode humans use for language. When Hockett first defined this feature, it did not take sign language into account, which reflects the ideology of orality that was prevalent during the time (See, for instance, the argumentation of Christin, 1995) . This feature has since been modified to include other channels of language, such as tactile-visual or chemical-olfactory.\n\nBroadcast transmission and directional reception\nWhen humans speak, sounds are transmitted in all directions; however, listeners perceive the direction from which the sounds are coming. Similarly, signers broadcast to potentially anyone within the line of sight, while those watching see who is signing. This is characteristic of most forms of human and animal communication.\n\nTransitoriness\nAlso called rapid fading, transitoriness refers to the idea of temporary quality of language. Language sounds exist for only a brief period of time, after which they are no longer perceived. Sound waves quickly disappear once a speaker stops speaking. This is also true of signs. In contrast, other forms of communication such as writing and Inka khipus (knot-tying) are more permanent.\n\nInterchangeability\nRefers to the idea that humans can give and receive identical linguistic signals; humans are not limited in the types of messages they can say/hear. One can say \"I am a boy\" even if one is a girl. This is not to be confused with lying (prevarication). The importance is that a speaker can physically create any and all messages regardless of their truth or relation to the speaker. In other words, anything that one can hear, one can also say.\n\nNot all species possess this feature. For example, in order to communicate their status, queen ants produce chemical scents that no other ants can produce (see animal communication below).\n\nTotal feedback\nSpeakers of a language can hear their own speech and can control and modify what they are saying as they say it. Similarly, signers see, feel, and control their signing.\n\nSpecialization\nThe purpose of linguistic signals is communication and not some other biological function. When humans speak or sign, it is generally intentional.\n\nAn example of \"non\"-specialized communication is dog panting. When a dog pants, it often communicates to its owner that it is hot or thirsty; however, the dog pants in order to cool itself off. This is a biological function, and the communication is a secondary matter.\n\nSemanticity\nSpecific sound signals are directly tied to certain meanings.\n\nArbitrariness ** languages are generally made up of both arbitrary and iconic symbols. In spoken languages this takes the form of onomatopoeias. In English \"murmur\", in Mandarin \"māo\" (cat). In ASL \"cup\", \"me\" \"up/down\", etc. \nThere is no intrinsic or logical connection between a sound form (signal) and its meaning. Whatever name a human language attributes an object is purely arbitrary. The word \"car\" is nothing like an actual car. Spoken words are really nothing like the objects they represent. This is further demonstrated by the fact that different languages attribute very different names to the same object.\n\nSigned languages are transmitted visually and this allows for a certain degree of iconicity. For example, in the ASL sign HOUSE, the hands are flat and touch in a way that resembles the roof and walls of a house. However, many other signs are not iconic, and the relationship between form and meaning is arbitrary. Thus, while Hockett did not account for the possibility of non-arbitrary form-meaning relationships, the principle still generally applies. \n\nDiscreteness\nLinguistic representations can be broken down into small discrete units which combine with each other in rule-governed ways. They are perceived categorically, not continuously. For example, English marks number with the plural morpheme /s/, which can be added to the end of any noun. The plural morpheme is perceived categorically, not continuously: we cannot express smaller or larger quantities by varying how loudly we pronounce the /s/. \n\nDisplacement\nRefers to the idea that humans can talk about things that are not physically present or that do not even exist. Speakers can talk about the past and the future, and can express hopes and dreams. A human's speech is not limited to here and now. Displacement is one of the features that separates human language from other forms of primate communication.\n\nProductivity\nRefers to the idea that language-users can create and understand novel utterances. Humans are able to produce an unlimited amount of utterances. Also related to productivity is the concept of grammatical patterning, which facilitates the use and comprehension of language. Language is not stagnant, but is constantly changing. New idioms are created all the time and the meaning of signals can vary depending on the context and situation.\n\nTraditional transmission\nAlso called cultural transmission. While humans are born with innate language capabilities, language is learned after birth in a social setting. Children learn how to speak by interacting with experienced language users. Language and culture are woven together.\n\nDuality of patterning\nMeaningful messages are made up of distinct smaller meaningful units (words and morphemes) which themselves are made up of distinct smaller, meaningless units (phonemes).\n\nPrevarication\nPrevarication is the ability to lie or deceive. When using language, humans can make false or meaningless statements.\n\nReflexiveness\nHumans can use language to talk about language.\n\nLearnability\nLanguage is teachable and learnable. In the same way as a speaker learns their first language, the speaker is able to learn other languages. It is worth noting that young children learn language with competence and ease; however, language acquisition is constrained by a critical period such that it becomes more difficult once children pass a certain age.\n\nHockett distinguished language from communication. While almost all animals communicate in some way, a communication system is only considered language if it possesses \"all\" of the above characteristics. Some animal communication systems are impressively sophisticated.\n\nAnts make use of the chemical-olfactory channel of communication. Ants produce chemicals called pheromones, which are released through body glands and received by the tips of the antenna. Ants can produce up to twenty different pheromone scents, each a unique signal used to communicate things such as the location of food and danger, or even the need to defend or relocate the colony. When an ant is killed, it releases a pheromone that alerts others of potential danger. Pheromones also help ants distinguish family members from strangers. The queen ant has special pheromones which she uses to signal her status, orchestrate work, and let the colony know when they need to raise princesses or drones.\nAnts will even engage in warfare to protect the colony or a food source. This warfare involves tactics that resemble human warfare. Marauder ants will capture and hold down an enemy while another ant crushes it. Ants are loyal to their colony to the death; however, the queen will kill her own in order to be the last one standing. This level of \"planning\" among an animal species requires an intricate communication.\n\nBird communication demonstrates many features, including the vocal-auditory channel, broadcast transmission/directional reception, rapid fading, semanticity, and arbitrariness. Bird communication is divided into songs and calls. Songs are used primarily to attract mates, while calls are used to alert of food and danger and coordinate movement with the flock. Calls are acoustically simple, while songs are longer and more complex. Bird communication is both discrete and non-discrete. Birds use syntax to arrange their songs, where musical notes act as phonemes. The order of the notes is important to the meaning of the song, thus indicating that discreteness exists. Bird communication is also continuous in the sense that it utilizes duration and frequency. However, the fact that birds have \"phonemes\" does not necessarily mean that they can combine them in an infinite way. Birds have a limited number of songs that they can produce. The male indigo bunting only has one song, while the brown thrasher can sing over 2000 songs. Birds even have unique dialects, depending on where they are from.\n\nHoneybee communication is distinct from other forms of animal communication. Rather than vocal-auditory, bees use the space-movement channel to communicate. Honeybees use two kinds of dances to communicate—the round dance and the waggle dance. They use the round dance to communicate that food is 50–75 meters from the hive. They use the waggle dance when it is farther than this. To do the waggle dance, a bee moves in a zig-zag line and then does a loop back to the beginning of the line, forming a figure-eight. The direction of the line points to the food. The speed of the dance indicates the distance to the food. In this way, bee dancing is also continuous, rather than discrete. Their communication is also not arbitrary. They move in a direction and pattern that physically points out where food is located.\n\nHoneybee dancing also demonstrates displacement, which is generally considered a human characteristic. Most animals will only give a food-found call in the physical presence of food, yet bees can talk about food that is over 100 meters away.\n\n\n"}
{"id": "52945567", "url": "https://en.wikipedia.org/wiki?curid=52945567", "title": "IHunch", "text": "IHunch\n\niHunch is a term used to describe the common spinal problem of an excessively kyphotic (hunched) thoracic spine driving neck pain and cervicogenic headache. Other terms include iPosture, forward head posture, poking chin posture, computer neck, text neck and dowager’s hump.\n\nIndications are that the prevalence of upper back and neck pain has increased dramatically in the decade leading up to 2016. This increase has been attributed to the corresponding widespread adoption of laptop computers, tablets, smartphones and other small portable digital devices.\n\nBecause their screens do not separate from their keyboards these small devices cannot be set up ergonomically correctly (unless an extra screen or extra keyboard is added). They are unlike personal desk top computers (PCs) in this respect. Most commonly, the user hunches to operate them, often for many hours a day.\n\nHunching increases the effective load on the neck up to several times more than does erect posture, due to increasing moment arm. Local pain, cervicogenic headache and referred pain extending down the arms can arise from the sustained muscle strain, cervical facet joint (or apophyseal, or zygapophyseal joint) compression and diminution of the cervical foraminal nerve exits.\n\nA hunched posture also sends out a body language message of submission and lower self-confidence, with some research indicating it can actually promote these in the person holding it. A comprehensive view of the research and concepts is found in Dr Amy Cuddy’s book ‘Presence’ (2015).\n\nTreatment may include analgesic and/or anti-inflammatory medications, regular breaks while using the small devices, muscle strengthening and stretching, massage, spinal manipulation and mobilsation, posture instruction and spinal fulcrums. Biomechanical analysis suggests a combination of approaches is best and gives more lasting results.\n\nIn a neck with perfect posture (as seen for instance in young children) the head is balanced above the shoulders. In this position the load on each vertebra of the cervical spine is spread evenly between the two facet (apophyseal) joints at the back and the intervertebral disc and vertebral body at the front.\n\nThe iHunch is characterised by a posture with the head sitting somewhat forward of the shoulders (i.e., the ear lobe is anterior to a vertical line through the point of the shoulder (acromion process)). This can be very marked, with the back of the skull positioned anterior to the breastbone (sternum). The chin is poked forward.\n\nWhen the patient is asked to look up at the ceiling, the hunched-forward upper thoracic curve does not change as viewed from the side. Rather, the lower cervical spine ‘hinges’ backward at C5/6/7, a movement pattern known as ‘swan-necking'.\n\nThis indicates that the upper back vertebrae have frozen in their habitual flexed positions, with the surrounding collagen of the ligaments, joint capsules and fascia shortening to reinforce this hypomobility. (This is the dowager’s hump of the elderly of earlier generations, now observable in modern (2016) late teenagers.)\n\nSymptoms include overuse muscle pain and fatigue along the back of the neck and reaching down to the mid-back, often starting with the upper trapezius muscle bellies between the shoulders and neck. Cervicogenic headache from the joints and muscle attachments at the top of the neck is common.\n\nThe compressive load on the cervical facet joints predisposes to acute joint locking episodes, with pain and movement loss. In older patients with already diminished cervical foramina spaces and/or osteophytes, nerve root irritation and impingement can trigger referred pain down the arm(s).\n\nThe human spine is well suited to erect upright posture, with the increased heart rate from movement shunting a good blood supply to the muscles. This is clearly not the\ncase for vast numbers of sedentary humans spending many hours daily bent over laptops, tablets, smartphones and similar. A biomechanical assessment of thoracic hunching shows the abnormal spinal loading and other effects which plausibly account for the recent steep rise in thoracic and cervical pain in step with the ubiquitous adoption of the small IT devices.\n\nHunching has always caused problems, for instance in occupational groups like dentists, surgeons, hairdressers, nurses, chefs, teachers, computer workers and students. Some rheumatoid conditions like ankylosing spondylitis and neurodegenerative conditions like Parkinson's Disease cause characteristic excessive thoracic kyphosis. What has changed is the amount of hunching in society generally, and especially with the technologically adept young.\n\nThe first laptop was produced in 1981 but it took more than a decade of development for the designs to approach current (2016) levels of portability and capacity, and hence uptake. Apple produced the first smartphone (the iPhone) in 2007 and the first tablet (the iPad) in 2010. In 2015 there were 4.43 billion mobile phone (cellphone) users in the world, of which 2.6 billion had smartphones. In the US, 45% owned a tablet computer in 2014 and 92% owned a mobile phone; for younger adults aged 18–29, only 2% didn’t own a mobile phone and 50% had tablets.\n\nA large Finnish cross-sectional study on school-age adolescents published in 2012 concluded that more than two hours a day spent on computers was associated with a moderate/severe increase in musculoskeletal pain. In the following year, the average UK 18-24 year-old spent 8.83 hours a day in front of a PC, laptop or tablet. Neck pain per se has been a large problem for a long time, and surveyed repeatedly. A composite review of studies with good methodology by Fejer et al published in 2006 found that point prevalence (in pain right now) of neck pain in the adult (15–75 years) population ranged from 5.9% to 22.2%, with one study of the elderly (65+ years) finding 38.7% were in pain when surveyed. Generally, more urban populations had more neck pain, e.g. 22.2% of a large 1998 Canadian study had neck pain when surveyed.\n\nBased on these surveys of neck pain prevalence, and adding to them the prevalence of thoracic pain and cervicogenic headache, it is reasonable to estimate that around one adult in six (15%) probably has pain in any, some or all of those areas right now. However the published epidemiological papers draw on raw data from surveys done at least 10 years ago, and there are indications that the numbers have been rising dramatically since then – as rapidly as the adoption of laptops, tablets and smartphones. This is reflected in the recent rise in the number of popular articles, news items and media discussions about the problem.\n\nThe iHunch is a multi-factorial problem.\n\n\nNeck pain generally has been treated with a profusion of approaches and modalities, including nonsteroidal anti-inflammatory drugs (NSAIDs) such as ibuprofen; pain relief medications (analgesics) such as acetaminophen; low dose tricyclic antidepressants such as amytriptyline for chronic problems; Physical therapy (a.k.a. physiotherapy in British-derived cultures) which utilises a wide range of techniques and modalities; spinal manipulation from osteopaths, chiropractors, manipulating physiotherapists and doctors; massage; muscle strengthening programmes including gyms and Pilates; postural approaches such as the Feldenkrais Method and the Alexander Technique; stretching approaches such as yoga; ergonomic approaches including setting up desk top computers correctly and frequent breaks; acupuncture; and surgery for severe structural problems such as osteophytic impingement on the cervical nerve roots and cervical disc herniation.\n\nA biomechanical analysis of the iHunch indicates its standard, logical development from much flexed activity and its multi-factorial character. (See Pathogenesis)\n\nA composite approach which covers each component of the problem is therefore likely to be most successful and lasting. Most of the general treatment approaches to neck pain cover only one aspect. A logical response should include as a minimum:\n\n\n"}
{"id": "27347921", "url": "https://en.wikipedia.org/wiki?curid=27347921", "title": "International Society for Augmentative and Alternative Communication", "text": "International Society for Augmentative and Alternative Communication\n\nThe International Society for Augmentative and Alternative Communication (ISAAC) was founded in May 1983 in East Lansing, Michigan, United States. Its stated purpose is to improve the communication abilities and quality of life of individuals with complex communication needs who use augmentative and alternative communication (AAC). ISAAC provides information about AAC services, policies and activities around the world thorough various publications and their website. The society publishes a journal and various other publications, organizes biennial conferences, promotes research on AAC use and AAC development as well as implements various projects.\n\nISAAC works to promote augmentative and alternative communication as a known and valued way of communicating worldwide. The society’s vision \"is that AAC will be recognized, valued and used throughout the world\" and the society's mission \"is to promote the best possible communication for people with complex needs\". The society encourages research and scholarship as well as works to improve service delivery.\n\nISAAC has more than 3700 members from over 60 different countries. Members include professionals, AAC users and their families and friends. The society is recognized as a nongovernmental organization in consultative status with the United Nations Economic and Social Council.\n\nNational chapters of ISAAC are located in many different countries. Chapters exist in Australia, Canada, Denmark, Finland, French-speaking countries and regions, German-speaking countries and regions, India, Ireland, Israel, Italy, Netherlands and Flanders, Norway, Sweden, United Kingdom and United States of America. Each chapter has a wide variety of members. For example, members of the Communication Matters, UK chapter, include: AAC users, families of AAC users, professionals working with AAC users, researchers and academics.\n\n ISAAC has publications including the Augmentative and Alternative Communication (AAC), which is the society’s official journal. The society also has affiliated publications such as AGOSCI in Focus (formerly known as Australian Group of Severe Communication Impairment).\n\nISAAC organizes biennial conferences. Each conference includes the sharing of breakthroughs and scientific papers, demonstrations of AAC devices, AAC users' experiences, and social activities. A variety of people attend including professionals and therapists as well as children and adults with complex communication needs and their families. Other conferences and courses are also organized by the society.\n\nISAAC has implemented 3 projects to help support the organization’s vision and meet the society’s mission. These projects are the BUILD, LEAD and READ projects.\n\n"}
{"id": "17524", "url": "https://en.wikipedia.org/wiki?curid=17524", "title": "Language", "text": "Language\n\nLanguage is a system that consists of the development, acquisition, maintenance and use of complex systems of communication, particularly the human ability to do so; and a language is any specific example of such a system.\n\nThe scientific study of language is called linguistics. Questions concerning the philosophy of language, such as whether words can represent experience, have been debated at least since Gorgias and Plato in ancient Greece. Thinkers such as Rousseau have argued that language originated from emotions while others like Kant have held that it originated from rational and logical thought. 20th-century philosophers such as Wittgenstein argued that philosophy is really the study of language. Major figures in linguistics include Ferdinand de Saussure and Noam Chomsky.\n\nEstimates of the number of human languages in the world vary between 5,000 and 7,000. However, any precise estimate depends on a partly arbitrary distinction between languages and dialects. Natural languages are spoken or signed, but any language can be encoded into secondary media using auditory, visual, or tactile stimuli – for example, in whistling, signed, or braille. This is because human language is modality-independent. Depending on philosophical perspectives regarding the definition of language and meaning, when used as a general concept, \"language\" may refer to the cognitive ability to learn and use systems of complex communication, or to describe the set of rules that makes up these systems, or the set of utterances that can be produced from those rules. All languages rely on the process of semiosis to relate signs to particular meanings. Oral, manual and tactile languages contain a phonological system that governs how symbols are used to form sequences known as words or morphemes, and a syntactic system that governs how words and morphemes are combined to form phrases and utterances.\n\nHuman language has the properties of productivity and displacement, and relies entirely on social convention and learning. Its complex structure affords a much wider range of expressions than any known system of animal communication. Language is thought to have originated when early hominins started gradually changing their primate communication systems, acquiring the ability to form a theory of other minds and a shared intentionality. This development is sometimes thought to have coincided with an increase in brain volume, and many linguists see the structures of language as having evolved to serve specific communicative and social functions. Language is processed in many different locations in the human brain, but especially in Broca's and Wernicke's areas. Humans acquire language through social interaction in early childhood, and children generally speak fluently by approximately three years old. The use of language is deeply entrenched in human culture. Therefore, in addition to its strictly communicative uses, language also has many social and cultural uses, such as signifying group identity, social stratification, as well as social grooming and entertainment.\n\nLanguages evolve and diversify over time, and the history of their evolution can be reconstructed by comparing modern languages to determine which traits their ancestral languages must have had in order for the later developmental stages to occur. A group of languages that descend from a common ancestor is known as a language family. The Indo-European family is the most widely spoken and includes languages as diverse as English, Russian and Hindi; the Sino-Tibetan family includes Mandarin, Bodo and the other Chinese languages, and Tibetan; the Afro-Asiatic family includes Arabic, Somali, and Hebrew; the Bantu languages include Swahili, and Zulu, and hundreds of other languages spoken throughout Africa; and the Malayo-Polynesian languages include Indonesian, Malay, Tagalog, and hundreds of other languages spoken throughout the Pacific. The languages of the Dravidian family, spoken mostly in Southern India, include Tamil Telugu and Kannada. Academic consensus holds that between 50% and 90% of languages spoken at the beginning of the 21st century will probably have become extinct by the year 2100.\n\nThe English word \"language\" derives ultimately from Proto-Indo-European \"\" \"tongue, speech, language\" through Latin \"lingua\", \"language; tongue\", and Old French \"language\". The word is sometimes used to refer to codes, ciphers, and other kinds of artificially constructed communication systems such as formally defined computer languages used for computer programming. Unlike conventional human languages, a formal language in this sense is a system of signs for encoding and decoding information. This article specifically concerns the properties of natural human language as it is studied in the discipline of linguistics.\n\nAs an object of linguistic study, \"language\" has two primary meanings: an abstract concept, and a specific linguistic system, e.g. \"French\". The Swiss linguist Ferdinand de Saussure, who defined the modern discipline of linguistics, first explicitly formulated the distinction using the French word \"langage\" for language as a concept, \"langue\" as a specific instance of a language system, and \"parole\" for the concrete usage of speech in a particular language.\n\nWhen speaking of language as a general concept, definitions can be used which stress different aspects of the phenomenon. These definitions also entail different approaches and understandings of language, and they also inform different and often incompatible schools of linguistic theory. Debates about the nature and origin of language go back to the ancient world. Greek philosophers such as Gorgias and Plato debated the relation between words, concepts and reality. Gorgias argued that language could represent neither the objective experience nor human experience, and that communication and truth were therefore impossible. Plato maintained that communication is possible because language represents ideas and concepts that exist independently of, and prior to, language.\n\nDuring the Enlightenment and its debates about human origins, it became fashionable to speculate about the origin of language. Thinkers such as Rousseau and Herder argued that language had originated in the instinctive expression of emotions, and that it was originally closer to music and poetry than to the logical expression of rational thought. Rationalist philosophers such as Kant and Descartes held the opposite view. Around the turn of the 20th century, thinkers began to wonder about the role of language in shaping our experiences of the world – asking whether language simply reflects the objective structure of the world, or whether it creates concepts that it in turn imposes on our experience of the objective world. This led to the question of whether philosophical problems are really firstly linguistic problems. The resurgence of the view that language plays a significant role in the creation and circulation of concepts, and that the study of philosophy is essentially the study of language, is associated with what has been called the linguistic turn and philosophers such as Wittgenstein in 20th-century philosophy. These debates about language in relation to meaning and reference, cognition and consciousness remain active today.\n\nOne definition sees language primarily as the mental faculty that allows humans to undertake linguistic behaviour: to learn languages and to produce and understand utterances. This definition stresses the universality of language to all humans, and it emphasizes the biological basis for the human capacity for language as a unique development of the human brain. Proponents of the view that the drive to language acquisition is innate in humans argue that this is supported by the fact that all cognitively normal children raised in an environment where language is accessible will acquire language without formal instruction. Languages may even develop spontaneously in environments where people live or grow up together without a common language; for example, creole languages and spontaneously developed sign languages such as Nicaraguan Sign Language. This view, which can be traced back to the philosophers Kant and Descartes, understands language to be largely innate, for example, in Chomsky's theory of Universal Grammar, or American philosopher Jerry Fodor's extreme innatist theory. These kinds of definitions are often applied in studies of language within a cognitive science framework and in neurolinguistics.\n\nAnother definition sees language as a formal system of signs governed by grammatical rules of combination to communicate meaning. This definition stresses that human languages can be described as closed structural systems consisting of rules that relate particular signs to particular meanings. This structuralist view of language was first introduced by Ferdinand de Saussure, and his structuralism remains foundational for many approaches to language.\n\nSome proponents of Saussure's view of language have advocated a formal approach which studies language structure by identifying its basic elements and then by presenting a formal account of the rules according to which the elements combine in order to form words and sentences. The main proponent of such a theory is Noam Chomsky, the originator of the generative theory of grammar, who has defined language as the construction of sentences that can be generated using transformational grammars. Chomsky considers these rules to be an innate feature of the human mind and to constitute the rudiments of what language is. By way of contrast, such transformational grammars are also commonly used to provide formal definitions of language are commonly used in formal logic, in formal theories of grammar, and in applied computational linguistics. In the philosophy of language, the view of linguistic meaning as residing in the logical relations between propositions and reality was developed by philosophers such as Alfred Tarski, Bertrand Russell, and other formal logicians.\n\nYet another definition sees language as a system of communication that enables humans to exchange verbal or symbolic utterances. This definition stresses the social functions of language and the fact that humans use it to express themselves and to manipulate objects in their environment. Functional theories of grammar explain grammatical structures by their communicative functions, and understand the grammatical structures of language to be the result of an adaptive process by which grammar was \"tailored\" to serve the communicative needs of its users.\n\nThis view of language is associated with the study of language in pragmatic, cognitive, and interactive frameworks, as well as in sociolinguistics and linguistic anthropology. Functionalist theories tend to study grammar as dynamic phenomena, as structures that are always in the process of changing as they are employed by their speakers. This view places importance on the study of linguistic typology, or the classification of languages according to structural features, as it can be shown that processes of grammaticalization tend to follow trajectories that are partly dependent on typology. In the philosophy of language, the view of pragmatics as being central to language and meaning is often associated with Wittgenstein's later works and with ordinary language philosophers such as J.L. Austin, Paul Grice, John Searle, and W.O. Quine.\n\nA number of features, many of which were described by Charles Hockett and called design features set human language apart from other known systems of communication, such as those used by non-human animals.\n\nCommunication systems used by other animals such as bees or apes are closed systems that consist of a finite, usually very limited, number of possible ideas that can be expressed. In contrast, human language is open-ended and productive, meaning that it allows humans to produce a vast range of utterances from a finite set of elements, and to create new words and sentences. This is possible because human language is based on a dual code, in which a finite number of elements which are meaningless in themselves (e.g. sounds, letters or gestures) can be combined to form an infinite number of larger units of meaning (words and sentences). However, one study has demonstrated that an Australian bird, the chestnut-crowned babbler, is capable of using the same acoustic elements in different arrangements to create two functionally distinct vocalizations. Additionally, pied babblers have demonstrated the ability to generate two functionally distinct vocalisations composed of the same sound type, which can only be distinguished by the number of repeated elements.\n\nSeveral species of animals have proved to be able to acquire forms of communication through social learning: for instance a bonobo named Kanzi learned to express itself using a set of symbolic lexigrams. Similarly, many species of birds and whales learn their songs by imitating other members of their species. However, while some animals may acquire large numbers of words and symbols, none have been able to learn as many different signs as are generally known by an average 4 year old human, nor have any acquired anything resembling the complex grammar of human language.\n\nHuman languages also differ from animal communication systems in that they employ grammatical and semantic categories, such as noun and verb, present and past, which may be used to express exceedingly complex meanings. Human language is also unique in having the property of recursivity: for example, a noun phrase can contain another noun phrase (as in \"<nowiki>the chimpanzee]'s lips]</nowiki>\") or a clause can contain another clause (as in \"<nowiki>[I see [the dog is running</nowiki>\"). Human language is also the only known natural communication system whose adaptability may be referred to as \"modality independent\". This means that it can be used not only for communication through one channel or medium, but through several. For example, spoken language uses the auditive modality, whereas sign languages and writing use the visual modality, and braille writing uses the tactile modality.\n\nHuman language is also unique in being able to refer to abstract concepts and to imagined or hypothetical events as well as events that took place in the past or may happen in the future. This ability to refer to events that are not at the same time or place as the speech event is called \"displacement\", and while some animal communication systems can use displacement (such as the communication of bees that can communicate the location of sources of nectar that are out of sight), the degree to which it is used in human language is also considered unique.\n\nTheories about the origin of language differ in regard to their basic assumptions about what language is. Some theories are based on the idea that language is so complex that one cannot imagine it simply appearing from nothing in its final form, but that it must have evolved from earlier pre-linguistic systems among our pre-human ancestors. These theories can be called continuity-based theories. The opposite viewpoint is that language is such a unique human trait that it cannot be compared to anything found among non-humans and that it must therefore have appeared suddenly in the transition from pre-hominids to early man. These theories can be defined as discontinuity-based. Similarly, theories based on the generative view of language pioneered by Noam Chomsky see language mostly as an innate faculty that is largely genetically encoded, whereas functionalist theories see it as a system that is largely cultural, learned through social interaction.\n\nChomsky is one prominent proponent of a discontinuity-based theory of human language origins. He suggests that for scholars interested in the nature of language, \"talk about the evolution of the language capacity is beside the point.\" Chomsky proposes that perhaps \"some random mutation took place [...] and it reorganized the brain, implanting a language organ in an otherwise primate brain.\" Though cautioning against taking this story literally, Chomsky insists that \"it may be closer to reality than many other fairy tales that are told about evolutionary processes, including language.\"\n\nContinuity-based theories are held by a majority of scholars, but they vary in how they envision this development. Those who see language as being mostly innate, for example psychologist Steven Pinker, hold the precedents to be animal cognition, whereas those who see language as a socially learned tool of communication, such as psychologist Michael Tomasello, see it as having developed from animal communication in primates: either gestural or vocal communication to assist in cooperation. Other continuity-based models see language as having developed from music, a view already espoused by Rousseau, Herder, Humboldt, and Charles Darwin. A prominent proponent of this view is archaeologist Steven Mithen. Stephen Anderson states that the age of spoken languages is estimated at 60,000 to 100,000 years and that: Researchers on the evolutionary origin of language generally find it plausible to suggest that language was invented only once, and that all modern spoken languages are thus in some way related, even if that relation can no longer be recovered ... because of limitations on the methods available for reconstruction.\n\nBecause language emerged in the early prehistory of man, before the existence of any written records, its early development has left no historical traces, and it is believed that no comparable processes can be observed today. Theories that stress continuity often look at animals to see if, for example, primates display any traits that can be seen as analogous to what pre-human language must have been like. And early human fossils can be inspected for traces of physical adaptation to language use or pre-linguistic forms of symbolic behaviour. Among the signs in human fossils that may suggest linguistic abilities are: the size of the brain relative to body mass, the presence of a larynx capable of advanced sound production and the nature of tools and other manufactured artifacts.\n\nIt was mostly undisputed that pre-human australopithecines did not have communication systems significantly different from those found in great apes in general. However, a 2017 study on Ardipithecus ramidus challenges this belief. Scholarly opinions vary as to the developments since the appearance of the genus \"Homo\" some 2.5 million years ago. Some scholars assume the development of primitive language-like systems (proto-language) as early as \"Homo habilis\" (2.3 million years ago) while others place the development of primitive symbolic communication only with \"Homo erectus\" (1.8 million years ago) or \"Homo heidelbergensis\" (0.6 million years ago), and the development of language proper with Anatomically Modern \"Homo sapiens\" with the Upper Paleolithic revolution less than 100,000 years ago.\n\nThe study of language, linguistics, has been developing into a science since the first grammatical descriptions of particular languages in India more than 2000 years ago, after the development of the Brahmi script. Modern linguistics is a science that concerns itself with all aspects of language, examining it from all of the theoretical viewpoints described above.\n\nThe academic study of language is conducted within many different disciplinary areas and from different theoretical angles, all of which inform modern approaches to linguistics. For example, descriptive linguistics examines the grammar of single languages, theoretical linguistics develops theories on how best to conceptualize and define the nature of language based on data from the various extant human languages, sociolinguistics studies how languages are used for social purposes informing in turn the study of the social functions of language and grammatical description, neurolinguistics studies how language is processed in the human brain and allows the experimental testing of theories, computational linguistics builds on theoretical and descriptive linguistics to construct computational models of language often aimed at processing natural language or at testing linguistic hypotheses, and historical linguistics relies on grammatical and lexical descriptions of languages to trace their individual histories and reconstruct trees of language families by using the comparative method.\n\nThe formal study of language is often considered to have started in India with Pāṇini, the 5th century BC grammarian who formulated 3,959 rules of Sanskrit morphology. However, Sumerian scribes already studied the differences between Sumerian and Akkadian grammar around 1900 BC. Subsequent grammatical traditions developed in all of the ancient cultures that adopted writing.\n\nIn the 17th century AD, the French Port-Royal Grammarians developed the idea that the grammars of all languages were a reflection of the universal basics of thought, and therefore that grammar was universal. In the 18th century, the first use of the comparative method by British philologist and expert on ancient India William Jones sparked the rise of comparative linguistics. The scientific study of language was broadened from Indo-European to language in general by Wilhelm von Humboldt. Early in the 20th century, Ferdinand de Saussure introduced the idea of language as a static system of interconnected units, defined through the oppositions between them.\n\nBy introducing a distinction between diachronic and synchronic analyses of language, he laid the foundation of the modern discipline of linguistics. Saussure also introduced several basic dimensions of linguistic analysis that are still fundamental in many contemporary linguistic theories, such as the distinctions between syntagm and paradigm, and the Langue-parole distinction, distinguishing language as an abstract system (\"langue\"), from language as a concrete manifestation of this system (\"parole\").\n\nIn the 1960s, Noam Chomsky formulated the generative theory of language. According to this theory, the most basic form of language is a set of syntactic rules that is universal for all humans and which underlies the grammars of all human languages. This set of rules is called Universal Grammar; for Chomsky, describing it is the primary objective of the discipline of linguistics. Thus, he considered that the grammars of individual languages are only of importance to linguistics insofar as they allow us to deduce the universal underlying rules from which the observable linguistic variability is generated.\n\nIn opposition to the formal theories of the generative school, functional theories of language propose that since language is fundamentally a tool, its structures are best analyzed and understood by reference to their functions. Formal theories of grammar seek to define the different elements of language and describe the way they relate to each other as systems of formal rules or operations, while functional theories seek to define the functions performed by language and then relate them to the linguistic elements that carry them out. The framework of cognitive linguistics interprets language in terms of the concepts (which are sometimes universal, and sometimes specific to a particular language) which underlie its forms. Cognitive linguistics is primarily concerned with how the mind creates meaning through language.\n\nSpeaking is the default modality for language in all cultures. The production of spoken language depends on sophisticated capacities for controlling the lips, tongue and other components of the vocal apparatus, the ability to acoustically decode speech sounds, and the neurological apparatus required for acquiring and producing language. The study of the genetic bases for human language is at an early stage: the only gene that has definitely been implicated in language production is FOXP2, which may cause a kind of congenital language disorder if affected by mutations.\n\n The brain is the coordinating center of all linguistic activity; it controls both the production of linguistic cognition and of meaning and the mechanics of speech production. Nonetheless, our knowledge of the neurological bases for language is quite limited, though it has advanced considerably with the use of modern imaging techniques. The discipline of linguistics dedicated to studying the neurological aspects of language is called neurolinguistics.\n\nEarly work in neurolinguistics involved the study of language in people with brain lesions, to see how lesions in specific areas affect language and speech. In this way, neuroscientists in the 19th century discovered that two areas in the brain are crucially implicated in language processing. The first area is Wernicke's area, which is in the posterior section of the superior temporal gyrus in the dominant cerebral hemisphere. People with a lesion in this area of the brain develop receptive aphasia, a condition in which there is a major impairment of language comprehension, while speech retains a natural-sounding rhythm and a relatively normal sentence structure. The second area is Broca's area, in the posterior inferior frontal gyrus of the dominant hemisphere. People with a lesion to this area develop expressive aphasia, meaning that they know what they want to say, they just cannot get it out. They are typically able to understand what is being said to them, but unable to speak fluently. Other symptoms that may be present in expressive aphasia include problems with fluency, articulation, word-finding, word repetition, and producing and comprehending complex grammatical sentences, both orally and in writing. Those with this aphasia also exhibit ungrammatical speech and show inability to use syntactic information to determine the meaning of sentences. Both expressive and receptive aphasia also affect the use of sign language, in analogous ways to how they affect speech, with expressive aphasia causing signers to sign slowly and with incorrect grammar, whereas a signer with receptive aphasia will sign fluently, but make little sense to others and have difficulties comprehending others' signs. This shows that the impairment is specific to the ability to use language, not to the physiology used for speech production.\n\nWith technological advances in the late 20th century, neurolinguists have also incorporated non-invasive techniques such as functional magnetic resonance imaging (fMRI) and electrophysiology to study language processing in individuals without impairments.\n\nSpoken language relies on human physical ability to produce sound, which is a longitudinal wave propagated through the air at a frequency capable of vibrating the ear drum. This ability depends on the physiology of the human speech organs. These organs consist of the lungs, the voice box (larynx), and the upper vocal tract – the throat, the mouth, and the nose. By controlling the different parts of the speech apparatus, the airstream can be manipulated to produce different speech sounds.\n\nThe sound of speech can be analyzed into a combination of segmental and suprasegmental elements. The segmental elements are those that follow each other in sequences, which are usually represented by distinct letters in alphabetic scripts, such as the Roman script. In free flowing speech, there are no clear boundaries between one segment and the next, nor usually are there any audible pauses between words. Segments therefore are distinguished by their distinct sounds which are a result of their different articulations, and they can be either vowels or consonants. Suprasegmental phenomena encompass such elements as stress, phonation type, voice timbre, and prosody or intonation, all of which may have effects across multiple segments.\n\nConsonants and vowel segments combine to form syllables, which in turn combine to form utterances; these can be distinguished phonetically as the space between two inhalations. Acoustically, these different segments are characterized by different formant structures, that are visible in a spectrogram of the recorded sound wave (See illustration of Spectrogram of the formant structures of three English vowels). Formants are the amplitude peaks in the frequency spectrum of a specific sound.\n\nVowels are those sounds that have no audible friction caused by the narrowing or obstruction of some part of the upper vocal tract. They vary in quality according to the degree of lip aperture and the placement of the tongue within the oral cavity. Vowels are called \"close\" when the lips are relatively closed, as in the pronunciation of the vowel (English \"ee\"), or \"open\" when the lips are relatively open, as in the vowel (English \"ah\"). If the tongue is located towards the back of the mouth, the quality changes, creating vowels such as (English \"oo\"). The quality also changes depending on whether the lips are rounded as opposed to unrounded, creating distinctions such as that between (unrounded front vowel such as English \"ee\") and (rounded front vowel such as German \"ü\").\n\nConsonants are those sounds that have audible friction or closure at some point within the upper vocal tract. Consonant sounds vary by place of articulation, i.e. the place in the vocal tract where the airflow is obstructed, commonly at the lips, teeth, alveolar ridge, palate, velum, uvula, or glottis. Each place of articulation produces a different set of consonant sounds, which are further distinguished by manner of articulation, or the kind of friction, whether full closure, in which case the consonant is called \"occlusive\" or \"stop\", or different degrees of aperture creating \"fricatives\" and \"approximants\". Consonants can also be either \"voiced or unvoiced\", depending on whether the vocal cords are set in vibration by airflow during the production of the sound. Voicing is what separates English in \"bus\" (unvoiced sibilant) from in \"buzz\" (voiced sibilant).\n\nSome speech sounds, both vowels and consonants, involve release of air flow through the nasal cavity, and these are called \"nasals\" or \"nasalized\" sounds. Other sounds are defined by the way the tongue moves within the mouth: such as the l-sounds (called \"laterals\", because the air flows along both sides of the tongue), and the r-sounds (called \"rhotics\") that are characterized by how the tongue is positioned relative to the air stream.\n\nBy using these speech organs, humans can produce hundreds of distinct sounds: some appear very often in the world's languages, whereas others are much more common in certain language families, language areas, or even specific to a single language.\n\nWhen described as a system of symbolic communication, language is traditionally seen as consisting of three parts: signs, meanings, and a code connecting signs with their meanings. The study of the process of semiosis, how signs and meanings are combined, used, and interpreted is called semiotics. Signs can be composed of sounds, gestures, letters, or symbols, depending on whether the language is spoken, signed, or written, and they can be combined into complex signs, such as words and phrases. When used in communication, a sign is encoded and transmitted by a sender through a channel to a receiver who decodes it.\nSome of the properties that define human language as opposed to other communication systems are: the arbitrariness of the linguistic sign, meaning that there is no predictable connection between a linguistic sign and its meaning; the duality of the linguistic system, meaning that linguistic structures are built by combining elements into larger structures that can be seen as layered, e.g. how sounds build words and words build phrases; the discreteness of the elements of language, meaning that the elements out of which linguistic signs are constructed are discrete units, e.g. sounds and words, that can be distinguished from each other and rearranged in different patterns; and the productivity of the linguistic system, meaning that the finite number of linguistic elements can be combined into a theoretically infinite number of combinations.\n\nThe rules by which signs can be combined to form words and phrases are called syntax or grammar. The meaning that is connected to individual signs, morphemes, words, phrases, and texts is called semantics. The division of language into separate but connected systems of sign and meaning goes back to the first linguistic studies of de Saussure and is now used in almost all branches of linguistics.\n\nLanguages express meaning by relating a sign form to a meaning, or its content. Sign forms must be something that can be perceived, for example, in sounds, images, or gestures, and then related to a specific meaning by social convention. Because the basic relation of meaning for most linguistic signs is based on social convention, linguistic signs can be considered arbitrary, in the sense that the convention is established socially and historically, rather than by means of a natural relation between a specific sign form and its meaning.\n\nThus, languages must have a vocabulary of signs related to specific meaning. The English sign \"dog\" denotes, for example, a member of the species \"Canis familiaris\". In a language, the array of arbitrary signs connected to specific meanings is called the lexicon, and a single sign connected to a meaning is called a lexeme. Not all meanings in a language are represented by single words. Often, semantic concepts are embedded in the morphology or syntax of the language in the form of grammatical categories.\n\nAll languages contain the semantic structure of predication: a structure that predicates a property, state, or action. Traditionally, semantics has been understood to be the study of how speakers and interpreters assign truth values to statements, so that meaning is understood to be the process by which a predicate can be said to be true or false about an entity, e.g. \"<nowiki>[x [is y]]\" or \"[x [does y]]</nowiki>\". Recently, this model of semantics has been complemented with more dynamic models of meaning that incorporate shared knowledge about the context in which a sign is interpreted into the production of meaning. Such models of meaning are explored in the field of pragmatics.\n\nDepending on modality, language structure can be based on systems of sounds (speech), gestures (sign languages), or graphic or tactile symbols (writing). The ways in which languages use sounds or signs to construct meaning are studied in phonology. The study of how humans produce and perceive vocal sounds is called phonetics. In spoken language, meaning is produced when sounds become part of a system in which some sounds can contribute to expressing meaning and others do not. In any given language, only a limited number of the many distinct sounds that can be created by the human vocal apparatus contribute to constructing meaning.\n\nSounds as part of a linguistic system are called phonemes. Phonemes are abstract units of sound, defined as the smallest units in a language that can serve to distinguish between the meaning of a pair of minimally different words, a so-called minimal pair. In English, for example, the words \"bat\" and \"pat\" form a minimal pair, in which the distinction between and differentiates the two words, which have different meanings. However, each language contrasts sounds in different ways. For example, in a language that does not distinguish between voiced and unvoiced consonants, the sounds and (if they both occur) could be considered a single phoneme, and consequently, the two pronunciations would have the same meaning. Similarly, the English language does not distinguish phonemically between aspirated and non-aspirated pronunciations of consonants, as many other languages like Korean and Hindi do: the unaspirated in \"spin\" and the aspirated in \"pin\" are considered to be merely different ways of pronouncing the same phoneme (such variants of a single phoneme are called allophones), whereas in Mandarin Chinese, the same difference in pronunciation distinguishes between the words 'crouch' and 'eight' (the accent above the á means that the vowel is pronounced with a high tone).\n\nAll spoken languages have phonemes of at least two different categories, vowels and consonants, that can be combined to form syllables. As well as segments such as consonants and vowels, some languages also use sound in other ways to convey meaning. Many languages, for example, use stress, pitch, duration, and tone to distinguish meaning. Because these phenomena operate outside of the level of single segments, they are called suprasegmental. Some languages have only a few phonemes, for example, Rotokas and Pirahã language with 11 and 10 phonemes respectively, whereas languages like Taa may have as many as 141 phonemes. In sign languages, the equivalent to phonemes (formerly called cheremes) are defined by the basic elements of gestures, such as hand shape, orientation, location, and motion, which correspond to manners of articulation in spoken language.\n\nWriting systems represent language using visual symbols, which may or may not correspond to the sounds of spoken language. The Latin alphabet (and those on which it is based or that have been derived from it) was originally based on the representation of single sounds, so that words were constructed from letters that generally denote a single consonant or vowel in the structure of the word. In syllabic scripts, such as the Inuktitut syllabary, each sign represents a whole syllable. In logographic scripts, each sign represents an entire word, and will generally bear no relation to the sound of that word in spoken language.\n\nBecause all languages have a very large number of words, no purely logographic scripts are known to exist. Written language represents the way spoken sounds and words follow one after another by arranging symbols according to a pattern that follows a certain direction. The direction used in a writing system is entirely arbitrary and established by convention. Some writing systems use the horizontal axis (left to right as the Latin script or right to left as the Arabic script), while others such as traditional Chinese writing use the vertical dimension (from top to bottom). A few writing systems use opposite directions for alternating lines, and others, such as the ancient Maya script, can be written in either direction and rely on graphic cues to show the reader the direction of reading.\n\nIn order to represent the sounds of the world's languages in writing, linguists have developed the International Phonetic Alphabet, designed to represent all of the discrete sounds that are known to contribute to meaning in human languages.\n\nGrammar is the study of how meaningful elements called \"morphemes\" within a language can be combined into utterances. Morphemes can either be \"free\" or \"bound\". If they are free to be moved around within an utterance, they are usually called \"words\", and if they are bound to other words or morphemes, they are called affixes. The way in which meaningful elements can be combined within a language is governed by rules. The rules for the internal structure of words are called morphology. The rules of the internal structure of phrases and sentences are called \"syntax\".\n\nGrammar can be described as a system of categories and a set of rules that determine how categories combine to form different aspects of meaning. Languages differ widely in whether they are encoded through the use of categories or lexical units. However, several categories are so common as to be nearly universal. Such universal categories include the encoding of the grammatical relations of participants and predicates by grammatically distinguishing between their relations to a predicate, the encoding of temporal and spatial relations on predicates, and a system of grammatical person governing reference to and distinction between speakers and addressees and those about whom they are speaking.\n\nLanguages organize their parts of speech into classes according to their functions and positions relative to other parts. All languages, for instance, make a basic distinction between a group of words that prototypically denotes things and concepts and a group of words that prototypically denotes actions and events. The first group, which includes English words such as \"dog\" and \"song\", are usually called nouns. The second, which includes \"run\" and \"sing\", are called verbs. Another common category is the adjective: words that describe properties or qualities of nouns, such as \"red\" or \"big\". Word classes can be \"open\" if new words can continuously be added to the class, or relatively \"closed\" if there is a fixed number of words in a class. In English, the class of pronouns is closed, whereas the class of adjectives is open, since an infinite number of adjectives can be constructed from verbs (e.g. \"saddened\") or nouns (e.g. with the -like suffix, as in \"noun-like\"). In other languages such as Korean, the situation is the opposite, and new pronouns can be constructed, whereas the number of adjectives is fixed.\n\nWord classes also carry out differing functions in grammar. Prototypically, verbs are used to construct predicates, while nouns are used as arguments of predicates. In a sentence such as \"Sally runs\", the predicate is \"runs\", because it is the word that predicates a specific state about its argument \"Sally\". Some verbs such as \"curse\" can take two arguments, e.g. \"Sally cursed John\". A predicate that can only take a single argument is called \"intransitive\", while a predicate that can take two arguments is called \"transitive\".\n\nMany other word classes exist in different languages, such as conjunctions like \"and\" that serve to join two sentences, articles that introduce a noun, interjections such as \"wow!\", or ideophones like \"splash\" that mimic the sound of some event. Some languages have positionals that describe the spatial position of an event or entity. Many languages have classifiers that identify countable nouns as belonging to a particular type or having a particular shape. For instance, in Japanese, the general noun classifier for humans is \"nin\" (人), and it is used for counting humans, whatever they are called:\n\nFor trees, it would be:\n\nIn linguistics, the study of the internal structure of complex words and the processes by which words are formed is called morphology. In most languages, it is possible to construct complex words that are built of several morphemes. For instance, the English word \"unexpected\" can be analyzed as being composed of the three morphemes \"un-\", \"expect\" and \"-ed\".\n\nMorphemes can be classified according to whether they are independent morphemes, so-called roots, or whether they can only co-occur attached to other morphemes. These bound morphemes or affixes can be classified according to their position in relation to the root: \"prefixes\" precede the root, suffixes follow the root, and infixes are inserted in the middle of a root. Affixes serve to modify or elaborate the meaning of the root. Some languages change the meaning of words by changing the phonological structure of a word, for example, the English word \"run\", which in the past tense is \"ran\". This process is called \"ablaut\". Furthermore, morphology distinguishes between the process of inflection, which modifies or elaborates on a word, and the process of derivation, which creates a new word from an existing one. In English, the verb \"sing\" has the inflectional forms \"singing\" and \"sung\", which are both verbs, and the derivational form \"singer\", which is a noun derived from the verb with the agentive suffix \"-er\".\n\nLanguages differ widely in how much they rely on morphological processes of word formation. In some languages, for example, Chinese, there are no morphological processes, and all grammatical information is encoded syntactically by forming strings of single words. This type of morpho-syntax is often called isolating, or analytic, because there is almost a full correspondence between a single word and a single aspect of meaning. Most languages have words consisting of several morphemes, but they vary in the degree to which morphemes are discrete units. In many languages, notably in most Indo-European languages, single morphemes may have several distinct meanings that cannot be analyzed into smaller segments. For example, in Latin, the word \"bonus\", or \"good\", consists of the root \"bon-\", meaning \"good\", and the suffix -\"us\", which indicates masculine gender, singular number, and nominative case. These languages are called \"fusional languages\", because several meanings may be fused into a single morpheme. The opposite of fusional languages are agglutinative languages which construct words by stringing morphemes together in chains, but with each morpheme as a discrete semantic unit. An example of such a language is Turkish, where for example, the word \"evlerinizden\", or \"from your houses\", consists of the morphemes, \"ev-ler-iniz-den\" with the meanings \"house-plural-your-from\". The languages that rely on morphology to the greatest extent are traditionally called polysynthetic languages. They may express the equivalent of an entire English sentence in a single word. For example, in Persian the single word \"nafahmidamesh\" means \"I didn't understand it\" consisting of morphemes \"na-fahm-id-am-esh\" with the meanings, \"negation.understand.past.I.it\". As another example with more complexity, in the Yupik word \"tuntussuqatarniksatengqiggtuq\", which means \"He had not yet said again that he was going to hunt reindeer\", the word consists of the morphemes \"tuntu-ssur-qatar-ni-ksaite-ngqiggte-uq\" with the meanings, \"reindeer-hunt-future-say-negation-again-third.person.singular.indicative\", and except for the morpheme \"tuntu\" (\"reindeer\") none of the other morphemes can appear in isolation.\n\nMany languages use morphology to cross-reference words within a sentence. This is sometimes called \"agreement\". For example, in many Indo-European languages, adjectives must cross-reference the noun they modify in terms of number, case, and gender, so that the Latin adjective \"bonus\", or \"good\", is inflected to agree with a noun that is masculine gender, singular number, and nominative case. In many polysynthetic languages, verbs cross-reference their subjects and objects. In these types of languages, a single verb may include information that would require an entire sentence in English. For example, in the Basque phrase \"ikusi nauzu\", or \"you saw me\", the past tense auxiliary verb \"n-au-zu\" (similar to English \"do\") agrees with both the subject (you) expressed by the \"n\"- prefix, and with the object (me) expressed by the – \"zu\" suffix. The sentence could be directly transliterated as \"see you-did-me\"\n\nAnother way in which languages convey meaning is through the order of words within a sentence. The grammatical rules for how to produce new sentences from words that are already known is called syntax. The syntactical rules of a language determine why a sentence in English such as \"I love you\" is meaningful, but \"*love you I\" is not. Syntactical rules determine how word order and sentence structure is constrained, and how those constraints contribute to meaning. For example, in English, the two sentences \"the slaves were cursing the master\" and \"the master was cursing the slaves\" mean different things, because the role of the grammatical subject is encoded by the noun being in front of the verb, and the role of object is encoded by the noun appearing after the verb. Conversely, in Latin, both \"Dominus servos vituperabat\" and \"Servos vituperabat dominus\" mean \"the master was reprimanding the slaves\", because \"servos\", or \"slaves\", is in the accusative case, showing that they are the grammatical object of the sentence, and \"dominus\", or \"master\", is in the nominative case, showing that he is the subject.\n\nLatin uses morphology to express the distinction between subject and object, whereas English uses word order. Another example of how syntactic rules contribute to meaning is the rule of inverse word order in questions, which exists in many languages. This rule explains why when in English, the phrase \"John is talking to Lucy\" is turned into a question, it becomes \"Who is John talking to?\", and not \"John is talking to who?\". The latter example may be used as a way of placing special emphasis on \"who\", thereby slightly altering the meaning of the question. Syntax also includes the rules for how complex sentences are structured by grouping words together in units, called phrases, that can occupy different places in a larger syntactic structure. Sentences can be described as consisting of phrases connected in a tree structure, connecting the phrases to each other at different levels. To the right is a graphic representation of the syntactic analysis of the English sentence \"the cat sat on the mat\". The sentence is analyzed as being constituted by a noun phrase, a verb, and a prepositional phrase; the prepositional phrase is further divided into a preposition and a noun phrase, and the noun phrases consist of an article and a noun.\n\nThe reason sentences can be seen as being composed of phrases is because each phrase would be moved around as a single element if syntactic operations were carried out. For example, \"the cat\" is one phrase, and \"on the mat\" is another, because they would be treated as single units if a decision was made to emphasize the location by moving forward the prepositional phrase: \"[And] on the mat, the cat sat\". There are many different formalist and functionalist frameworks that propose theories for describing syntactic structures, based on different assumptions about what language is and how it should be described. Each of them would analyze a sentence such as this in a different manner.\n\nLanguages can be classified in relation to their grammatical types. Languages that belong to different families nonetheless often have features in common, and these shared features tend to correlate. For example, languages can be classified on the basis of their basic word order, the relative order of the verb, and its constituents in a normal indicative sentence. In English, the basic order is SVO: \"The snake(S) bit(V) the man(O)\", whereas for example, the corresponding sentence in the Australian language Gamilaraay would be \"d̪uyugu n̪ama d̪ayn yiːy\" (snake man bit), SOV. Word order type is relevant as a typological parameter, because basic word order type corresponds with other syntactic parameters, such as the relative order of nouns and adjectives, or of the use of prepositions or postpositions. Such correlations are called implicational universals. For example, most (but not all) languages that are of the SOV type have postpositions rather than prepositions, and have adjectives before nouns.\n\nAll languages structure sentences into Subject, Verb, and Object, but languages differ in the way they classify the relations between actors and actions. English uses the nominative-accusative word typology: in English transitive clauses, the subjects of both intransitive sentences (\"I run\") and transitive sentences (\"I love you\") are treated in the same way, shown here by the nominative pronoun \"I\". Some languages, called ergative, Gamilaraay among them, distinguish instead between Agents and Patients. In ergative languages, the single participant in an intransitive sentence, such as \"I run\", is treated the same as the patient in a transitive sentence, giving the equivalent of \"me run\". Only in transitive sentences would the equivalent of the pronoun \"I\" be used. In this way the semantic roles can map onto the grammatical relations in different ways, grouping an intransitive subject either with Agents (accusative type) or Patients (ergative type) or even making each of the three roles differently, which is called the tripartite type.\n\nThe shared features of languages which belong to the same typological class type may have arisen completely independently. Their co-occurrence might be due to universal laws governing the structure of natural languages, \"language universals\", or they might be the result of languages evolving convergent solutions to the recurring communicative problems that humans use language to solve.\n\nWhile humans have the ability to learn any language, they only do so if they grow up in an environment in which language exists and is used by others. Language is therefore dependent on communities of speakers in which children learn language from their elders and peers and themselves transmit language to their own children. Languages are used by those who speak them to communicate and to solve a plethora of social tasks. Many aspects of language use can be seen to be adapted specifically to these purposes. Due to the way in which language is transmitted between generations and within communities, language perpetually changes, diversifying into new languages or converging due to language contact. The process is similar to the process of evolution, where the process of descent with modification leads to the formation of a phylogenetic tree.\n\nHowever, languages differ from biological organisms in that they readily incorporate elements from other languages through the process of diffusion, as speakers of different languages come into contact. Humans also frequently speak more than one language, acquiring their first language or languages as children, or learning new languages as they grow up. Because of the increased language contact in the globalizing world, many small languages are becoming endangered as their speakers shift to other languages that afford the possibility to participate in larger and more influential speech communities.\n\nThe semantic study of meaning assumes that meaning is in a relation between signs and meanings that are firmly established through social convention. However, semantics does not study the way in which social conventions are made and affect language. Rather, when studying the way in which words and signs are used, it is often the case that words have different meanings, depending on the social context of use. An important example of this is the process called deixis, which describes the way in which certain words refer to entities through their relation between a specific point in time and space when the word is uttered. Such words are, for example, the word, \"I\" (which designates the person speaking), \"now\" (which designates the moment of speaking), and \"here\" (which designates the position of speaking). Signs also change their meanings over time, as the conventions governing their usage gradually change. The study of how the meaning of linguistic expressions changes depending on context is called pragmatics. Deixis is an important part of the way that we use language to point out entities in the world. Pragmatics is concerned with the ways in which language use is patterned and how these patterns contribute to meaning. For example, in all languages, linguistic expressions can be used not just to transmit information, but to perform actions. Certain actions are made only through language, but nonetheless have tangible effects, e.g. the act of \"naming\", which creates a new name for some entity, or the act of \"pronouncing someone man and wife\", which creates a social contract of marriage. These types of acts are called speech acts, although they can also be carried out through writing or hand signing.\n\nThe form of linguistic expression often does not correspond to the meaning that it actually has in a social context. For example, if at a dinner table a person asks, \"Can you reach the salt?\", that is, in fact, not a question about the length of the arms of the one being addressed, but a request to pass the salt across the table. This meaning is implied by the context in which it is spoken; these kinds of effects of meaning are called conversational implicatures. These social rules for which ways of using language are considered appropriate in certain situations and how utterances are to be understood in relation to their context vary between communities, and learning them is a large part of acquiring communicative competence in a language.\n\nAll healthy, normally developing human beings learn to use language. Children acquire the language or languages used around them: whichever languages they receive sufficient exposure to during childhood. The development is essentially the same for children acquiring sign or oral languages. This learning process is referred to as first-language acquisition, since unlike many other kinds of learning, it requires no direct teaching or specialized study. In \"The Descent of Man\", naturalist Charles Darwin called this process \"an instinctive tendency to acquire an art\".\n\nFirst language acquisition proceeds in a fairly regular sequence, though there is a wide degree of variation in the timing of particular stages among normally developing infants. From birth, newborns respond more readily to human speech than to other sounds. Around one month of age, babies appear to be able to distinguish between different speech sounds. Around six months of age, a child will begin babbling, producing the speech sounds or handshapes of the languages used around them. Words appear around the age of 12 to 18 months; the average vocabulary of an eighteen-month-old child is around 50 words. A child's first utterances are holophrases (literally \"whole-sentences\"), utterances that use just one word to communicate some idea. Several months after a child begins producing words, he or she will produce two-word utterances, and within a few more months will begin to produce telegraphic speech, or short sentences that are less grammatically complex than adult speech, but that do show regular syntactic structure. From roughly the age of three to five years, a child's ability to speak or sign is refined to the point that it resembles adult language. Studies published in 2013 have indicated that unborn fetuses are capable of language acquisition to some degree.\n\nAcquisition of second and additional languages can come at any age, through exposure in daily life or courses. Children learning a second language are more likely to achieve native-like fluency than adults, but in general, it is very rare for someone speaking a second language to pass completely for a native speaker. An important difference between first language acquisition and additional language acquisition is that the process of additional language acquisition is influenced by languages that the learner already knows.\n\nLanguages, understood as the particular set of speech norms of a particular community, are also a part of the larger culture of the community that speaks them. Languages differ not only in pronunciation, vocabulary, and grammar, but also through having different \"cultures of speaking.\" Humans use language as a way of signalling identity with one cultural group as well as difference from others. Even among speakers of one language, several different ways of using the language exist, and each is used to signal affiliation with particular subgroups within a larger culture. Linguists and anthropologists, particularly sociolinguists, ethnolinguists, and linguistic anthropologists have specialized in studying how ways of speaking vary between speech communities.\n\nLinguists use the term \"varieties\" to refer to the different ways of speaking a language. This term includes geographically or socioculturally defined dialects as well as the jargons or styles of subcultures. Linguistic anthropologists and sociologists of language define communicative style as the ways that language is used and understood within a particular culture.\n\nBecause norms for language use are shared by members of a specific group, communicative style also becomes a way of displaying and constructing group identity. Linguistic differences may become salient markers of divisions between social groups, for example, speaking a language with a particular accent may imply membership of an ethnic minority or social class, one's area of origin, or status as a second language speaker. These kinds of differences are not part of the linguistic system, but are an important part of how people use language as a social tool for constructing groups.\n\nHowever, many languages also have grammatical conventions that signal the social position of the speaker in relation to others through the use of registers that are related to social hierarchies or divisions. In many languages, there are stylistic or even grammatical differences between the ways men and women speak, between age groups, or between social classes, just as some languages employ different words depending on who is listening. For example, in the Australian language Dyirbal, a married man must use a special set of words to refer to everyday items when speaking in the presence of his mother-in-law. Some cultures, for example, have elaborate systems of \"social deixis\", or systems of signalling social distance through linguistic means. In English, social deixis is shown mostly through distinguishing between addressing some people by first name and others by surname, and in titles such as \"Mrs.\", \"boy\", \"Doctor\", or \"Your Honor\", but in other languages, such systems may be highly complex and codified in the entire grammar and vocabulary of the language. For instance, in languages of east Asia such as Thai, Burmese, and Javanese, different words are used according to whether a speaker is addressing someone of higher or lower rank than oneself in a ranking system with animals and children ranking the lowest and gods and members of royalty as the highest.\n\nThroughout history a number of different ways of representing language in graphic media have been invented. These are called writing systems.\n\nThe use of writing has made language even more useful to humans. It makes it possible to store large amounts of information outside of the human body and retrieve it again, and it allows communication across distances that would otherwise be impossible. Many languages conventionally employ different genres, styles, and registers in written and spoken language, and in some communities, writing traditionally takes place in an entirely different language than the one spoken. There is some evidence that the use of writing also has effects on the cognitive development of humans, perhaps because acquiring literacy generally requires explicit and formal education.\n\nThe invention of the first writing systems is roughly contemporary with the beginning of the Bronze Age in the late 4th millennium BC. The Sumerian archaic cuneiform script and the Egyptian hieroglyphs are generally considered to be the earliest writing systems, both emerging out of their ancestral proto-literate symbol systems from 3400–3200 BC with the earliest coherent texts from about 2600 BC. It is generally agreed that Sumerian writing was an independent invention; however, it is debated whether Egyptian writing was developed completely independently of Sumerian, or was a case of cultural diffusion. A similar debate exists for the Chinese script, which developed around 1200 BC. The pre-Columbian Mesoamerican writing systems (including among others Olmec and Maya scripts) are generally believed to have had independent origins.\n\nAll languages change as speakers adopt or invent new ways of speaking and pass them on to other members of their speech community. Language change happens at all levels from the phonological level to the levels of vocabulary, morphology, syntax, and discourse. Even though language change is often initially evaluated negatively by speakers of the language who often consider changes to be \"decay\" or a sign of slipping norms of language usage, it is natural and inevitable.\n\nChanges may affect specific sounds or the entire phonological system. Sound change can consist of the replacement of one speech sound or phonetic feature by another, the complete loss of the affected sound, or even the introduction of a new sound in a place where there had been none. Sound changes can be \"conditioned\" in which case a sound is changed only if it occurs in the vicinity of certain other sounds. Sound change is usually assumed to be \"regular\", which means that it is expected to apply mechanically whenever its structural conditions are met, irrespective of any non-phonological factors. On the other hand, sound changes can sometimes be \"sporadic\", affecting only one particular word or a few words, without any seeming regularity. Sometimes a simple change triggers a chain shift in which the entire phonological system is affected. This happened in the Germanic languages when the sound change known as Grimm's law affected all the stop consonants in the system. The original consonant * became /b/ in the Germanic languages, the previous * in turn became /p/, and the previous * became /f/. The same process applied to all stop consonants and explains why Italic languages such as Latin have \"p\" in words like pater\" and pisces\", whereas Germanic languages, like English, have father\" and fish\".\n\nAnother example is the Great Vowel Shift in English, which is the reason that the spelling of English vowels do not correspond well to their current pronunciation. This is because the vowel shift brought the already established orthography out of synchronization with pronunciation. Another source of sound change is the erosion of words as pronunciation gradually becomes increasingly indistinct and shortens words, leaving out syllables or sounds. This kind of change caused Latin \"mea domina\" to eventually become the French \"madame\" and American English \"ma'am\".\n\nChange also happens in the grammar of languages as discourse patterns such as idioms or particular constructions become grammaticalized. This frequently happens when words or morphemes erode and the grammatical system is unconsciously rearranged to compensate for the lost element. For example, in some varieties of Caribbean Spanish the final /s/ has eroded away. Since Standard Spanish uses final /s/ in the morpheme marking the second person subject \"you\" in verbs, the Caribbean varieties now have to express the second person using the pronoun \"tú\". This means that the sentence \"what's your name\" is \"¿como te llamas?\" in Standard Spanish, but in Caribbean Spanish. The simple sound change has affected both morphology and syntax. Another common cause of grammatical change is the gradual petrification of idioms into new grammatical forms, for example, the way the English \"going to\" construction lost its aspect of movement and in some varieties of English has almost become a full-fledged future tense (e.g. \"I'm gonna\").\n\nLanguage change may be motivated by \"language internal\" factors, such as changes in pronunciation motivated by certain sounds being difficult to distinguish aurally or to produce, or through patterns of change that cause some rare types of constructions to drift towards more common types. Other causes of language change are social, such as when certain pronunciations become emblematic of membership in certain groups, such as social classes, or with ideologies, and therefore are adopted by those who wish to identify with those groups or ideas. In this way, issues of identity and politics can have profound effects on language structure.\n\nOne important source of language change is contact and resulting diffusion of linguistic traits between languages. Language contact occurs when speakers of two or more languages or varieties interact on a regular basis. Multilingualism is likely to have been the norm throughout human history and most people in the modern world are multilingual. Before the rise of the concept of the ethno-national state, monolingualism was characteristic mainly of populations inhabiting small islands. But with the ideology that made one people, one state, and one language the most desirable political arrangement, monolingualism started to spread throughout the world. Nonetheless, there are only 250 countries in the world corresponding to some 6000 languages, which means that most countries are multilingual and most languages therefore exist in close contact with other languages.\n\nWhen speakers of different languages interact closely, it is typical for their languages to influence each other. Through sustained language contact over long periods, linguistic traits diffuse between languages, and languages belonging to different families may converge to become more similar. In areas where many languages are in close contact, this may lead to the formation of language areas in which unrelated languages share a number of linguistic features. A number of such language areas have been documented, among them, the Balkan language area, the Mesoamerican language area, and the Ethiopian language area. Also, larger areas such as South Asia, Europe, and Southeast Asia have sometimes been considered language areas, because of widespread diffusion of specific areal features.\n\nLanguage contact may also lead to a variety of other linguistic phenomena, including language convergence, borrowing, and relexification (replacement of much of the native vocabulary with that of another language). In situations of extreme and sustained language contact, it may lead to the formation of new mixed languages that cannot be considered to belong to a single language family. One type of mixed language called pidgins occurs when adult speakers of two different languages interact on a regular basis, but in a situation where neither group learns to speak the language of the other group fluently. In such a case, they will often construct a communication form that has traits of both languages, but which has a simplified grammatical and phonological structure. The language comes to contain mostly the grammatical and phonological categories that exist in both languages. Pidgin languages are defined by not having any native speakers, but only being spoken by people who have another language as their first language. But if a Pidgin language becomes the main language of a speech community, then eventually children will grow up learning the pidgin as their first language. As the generation of child learners grow up, the pidgin will often be seen to change its structure and acquire a greater degree of complexity. This type of language is generally called a creole language. An example of such mixed languages is Tok Pisin, the official language of Papua New-Guinea, which originally arose as a Pidgin based on English and Austronesian languages; others are Kreyòl ayisyen, the French-based creole language spoken in Haiti, and Michif, a mixed language of Canada, based on the Native American language Cree and French.\n\n\"SIL Ethnologue\" defines a \"living language\" as \"one that has at least one speaker for whom it is their first language\". The exact number of known living languages varies from 6,000 to 7,000, depending on the precision of one's definition of \"language\", and in particular, on how one defines the distinction between languages and dialects. As of 2016, \"Ethnologue\" cataloged 7,097 living human languages. The \"Ethnologue\" establishes linguistic groups based on studies of mutual intelligibility, and therefore often includes more categories than more conservative classifications. For example, the Danish language that most scholars consider a single language with several dialects is classified as two distinct languages (Danish and Jutish) by the \"Ethnologue\".\n\nAccording to the \"Ethnologue\", 389 languages (nearly 6%) have more than a million speakers. These languages together account for 94% of the world's population, whereas 94% of the world's languages account for the remaining 6% of the global population. To the right is a table of the world's 10 most spoken languages with population estimates from the \"Ethnologue\" (2009 figures).\n\nThere is no clear distinction between a language and a dialect, notwithstanding a famous aphorism attributed to linguist Max Weinreich that \"a language is a dialect with an army and navy\". For example, national boundaries frequently override linguistic difference in determining whether two linguistic varieties are languages or dialects. Hakka, Cantonese and Mandarin are, for example, often classified as \"dialects\" of Chinese, even though they are more different from each other than Swedish is from Norwegian. Before the Yugoslav civil war, Serbo-Croatian was considered a single language with two dialects, but now Croatian and Serbian are considered different languages and employ different writing systems. In other words, the distinction may hinge on political considerations as much as on cultural differences, distinctive writing systems, or degree of mutual intelligibility.\n\nThe world's languages can be grouped into language families consisting of languages that can be shown to have common ancestry. Linguists recognize many hundreds of language families, although some of them can possibly be grouped into larger units as more evidence becomes available and in-depth studies are carried out. At present, there are also dozens of language isolates: languages that cannot be shown to be related to any other languages in the world. Among them are Basque, spoken in Europe, Zuni of New Mexico, Purépecha of Mexico, Ainu of Japan, Burushaski of Pakistan, and many others.\n\nThe language family of the world that has the most speakers is the Indo-European languages, spoken by 46% of the world's population. This family includes major world languages like English, Spanish, Russian, and Hindustani (Hindi/Urdu). The Indo-European family achieved prevalence first during the Eurasian Migration Period (c. 400–800 AD), and subsequently through the European colonial expansion, which brought the Indo-European languages to a politically and often numerically dominant position in the Americas and much of Africa. The Sino-Tibetan languages are spoken by 20% of the world's population and include many of the languages of East Asia, including Hakka, Mandarin Chinese, Cantonese, and hundreds of smaller languages.\n\nAfrica is home to a large number of language families, the largest of which is the Niger-Congo language family, which includes such languages as Swahili, Shona, and Yoruba. Speakers of the Niger-Congo languages account for 6.9% of the world's population. A similar number of people speak the Afroasiatic languages, which include the populous Semitic languages such as Arabic, Hebrew language, and the languages of the Sahara region, such as the Berber languages and Hausa.\n\nThe Austronesian languages are spoken by 5.5% of the world's population and stretch from Madagascar to maritime Southeast Asia all the way to Oceania. It includes such languages as Malagasy, Māori, Samoan, and many of the indigenous languages of Indonesia and Taiwan. The Austronesian languages are considered to have originated in Taiwan around 3000 BC and spread through the Oceanic region through island-hopping, based on an advanced nautical technology. Other populous language families are the Dravidian languages of South Asia (among them Kannada Tamil and Telugu), the Turkic languages of Central Asia (such as Turkish), the Austroasiatic (among them Khmer), and Tai–Kadai languages of Southeast Asia (including Thai).\n\nThe areas of the world in which there is the greatest linguistic diversity, such as the Americas, Papua New Guinea, West Africa, and South-Asia, contain hundreds of small language families. These areas together account for the majority of the world's languages, though not the majority of speakers. In the Americas, some of the largest language families include the Quechumaran, Arawak, and Tupi-Guarani families of South America, the Uto-Aztecan, Oto-Manguean, and Mayan of Mesoamerica, and the Na-Dene, Iroquoian, and Algonquian language families of North America. In Australia, most indigenous languages belong to the Pama-Nyungan family, whereas New Guinea is home to a large number of small families and isolates, as well as a number of Austronesian languages.\n\nLanguage endangerment occurs when a language is at risk of falling out of use as its speakers die out or shift to speaking another language. Language loss occurs when the language has no more native speakers, and becomes a \"dead language\". If eventually no one speaks the language at all, it becomes an \"extinct language\". While languages have always gone extinct throughout human history, they have been disappearing at an accelerated rate in the 20th and 21st centuries due to the processes of globalization and neo-colonialism, where the economically powerful languages dominate other languages.\n\nThe more commonly spoken languages dominate the less commonly spoken languages, so the less commonly spoken languages eventually disappear from populations. The total number of languages in the world is not known. Estimates vary depending on many factors. The consensus is that there are between 6,000 and 7,000 languages spoken as of 2010, and that between 50–90% of those will have become extinct by the year 2100. The top 20 languages, those spoken by more than 50 million speakers each, are spoken by 50% of the world's population, whereas many of the other languages are spoken by small communities, most of them with less than 10,000 speakers.\n\nThe United Nations Educational, Scientific and Cultural Organization (UNESCO) operates with five levels of language endangerment: \"safe\", \"vulnerable\" (not spoken by children outside the home), \"definitely endangered\" (not spoken by children), \"severely endangered\" (only spoken by the oldest generations), and \"critically endangered\" (spoken by few members of the oldest generation, often semi-speakers). Notwithstanding claims that the world would be better off if most adopted a single common \"lingua franca\", such as English or Esperanto, there is a consensus that the loss of languages harms the cultural diversity of the world. It is a common belief, going back to the biblical narrative of the tower of Babel in the Old Testament, that linguistic diversity causes political conflict, but this is contradicted by the fact that many of the world's major episodes of violence have taken place in situations with low linguistic diversity, such as the Yugoslav and American Civil War, or the genocide of Rwanda, whereas many of the most stable political units have been highly multilingual.\n\nMany projects aim to prevent or slow this loss by revitalizing endangered languages and promoting education and literacy in minority languages. Across the world, many countries have enacted specific legislation to protect and stabilize the language of indigenous speech communities. A minority of linguists have argued that language loss is a natural process that should not be counteracted, and that documenting endangered languages for posterity is sufficient.\n\n"}
{"id": "221917", "url": "https://en.wikipedia.org/wiki?curid=221917", "title": "Language code", "text": "Language code\n\nA language code is a code that assigns letters or numbers as identifiers or classifiers for languages. These codes may be used to organize library collections or presentations of data, to choose the correct localizations and translations in computing, and as a shorthand designation for longer forms of language-name.\n\nLanguage code schemes attempt to classify the complex world of human languages, dialects, and variants. Most schemes make some compromises between being general and being complete enough to support specific dialects.\n\nFor example, most people in Central America and South America speak Spanish. Spanish spoken in Mexico will be slightly different from Spanish spoken in Peru. Different regions of Mexico will have slightly different dialects and accents of Spanish. A language code scheme might group these all as \"Spanish\" for choosing a keyboard layout, most as \"Spanish\" for general usage, or separate each dialect to allow region-specific idioms.\n\nSome common language code schemes include:\n\n\n"}
{"id": "373867", "url": "https://en.wikipedia.org/wiki?curid=373867", "title": "Language policy", "text": "Language policy\n\nMany countries have a language policy designed to favor or discourage the use of a particular language or set of languages. Although nations historically have used language policies most often to promote one official language at the expense of others, many countries now have policies designed to protect and promote \nregional and ethnic languages whose viability is threatened. Indeed, whilst the existence of linguistic minorities within their jurisdiction has often been considered to be a potential threat to internal cohesion, States also understand that providing language rights to minorities may be more in their long term interest, as a means of gaining citizens' trust in the central government.\n\nLanguage policy is what a government does either officially through legislation, court decisions or policy to determine how languages are used, cultivate language skills needed to meet national priorities or to establish the rights of individuals or groups to use and maintain languages. The scope of language policy varies in practice from State to State. This may be explained by the fact that language policy is often based on contingent historical reasons. Likewise, States also differ as to the degree of explicitness with which they implement a given language policy. The French Toubon law is a good example of explicit language policy. The same may be said for the Charter of the French Language in Quebec.\n\nThe preservation of cultural and linguistic diversity in today's world is a major concern to many scientists, artists, writers, politicians, leaders of linguistic communities, and defenders of linguistic human rights. More than half of the 6000 languages currently spoken in the world are estimated to be in danger of disappearing during the 21st century. Many factors affect the existence and usage of any given human language, including the size of the native speaking population, its use in formal communication, and the geographical dispersion and the socio-economic weight of its speakers. National language policies can either mitigate or exacerbate the effects of some of these factors.\n\nFor example, according to Ghil'ad Zuckermann, \"Native tongue title and language rights should be promoted. The government ought to define Aboriginal and Torres Strait Islander vernaculars as official languages of Australia. We must change the linguistic landscape of Whyalla and elsewhere. Signs should be in both English and the local indigenous language. We ought to acknowledge intellectual property of indigenous knowledge including language, music and dance.\"\n\nThere are many ways in which language policies can be categorized. It was elaborated by Université Laval sociolinguist Jacques Leclerc for the French-language Web site \"L'aménagement linguistique dans le monde\" put on line by the CIRAL in 1999. The collecting, translating and classifying of language policies started in 1988 and culminated in the publishing of \"Recueil des législations linguistiques dans le monde\" (vol. I to VI) at Presses de l'Université Laval in 1994. The work, containing some 470 language laws, and the research leading to publication, were subsidised by the Office québécois de la langue française. In April 2008, the Web site presented the linguistic portrait and language policies in 354 States or autonomous territories in 194 recognised countries.\n\n\nDirections of language policies:\n\n\nSome case studies:\n\n\n"}
{"id": "13503257", "url": "https://en.wikipedia.org/wiki?curid=13503257", "title": "Language survey", "text": "Language survey\n\nA language survey is conducted around the world for a variety of reasons.\n\n\nMethods used in language surveys depend on the questions that the survey is trying to answer. Methods used include collecting word lists (Bender 1971), playing recorded texts to assess comprehension (Casad 1974), sentence repetition tests (Radloff 1991), questionnaires (Hochstetler and Tillinghast 1996), group and individual interviews, retelling of stories (McKinnies and Priestly 2004), direct observation (Cooper and Carpenter 1976), and even internet surveys (tafesilafai.org).\n\nAs with any form of research, the methods used depend on the questions that the researchers are trying to answer. Also, the reliability of the results varies according to the method and the rigor with which it is applied, proper sampling technique, etc.\n\nThe results of language surveys are use for a variety of purposes. One of the most common is in making decisions for implementing educational programs. The results have also been used for making decision for language development work (Holbrook, 2001). And of course, academics are always interested in the results of any language survey.\n\nSurveys have also been conducted by ethnic associations (Saskatchewan 1991), government agencies (Statistics Canada 1993), NGO's (Toba, et al. 2002), foundations (Pew Hispanic Center 2004), etc. Often such groups work together (Clifton 2002). Some large and notable surveys include the Language Survey of India which was begun by George Abraham Grierson late in the 19th century (Sociolinguistics research in India) and the Survey of Language Use and Language Teaching in East Africa, sponsored by the Ford Foundation from the 1960s. Both resulted in a number of volumes describing locations of languages, patterns of multilingualism, language classification, and also included descriptions of languages, such as \"Language in Ethiopia\" (Bender, Bowen, Cooper, and Ferguson 1976). The single agency conducting the most language surveys around the world is SIL International (Summer Institute of Linguistics). The results of many of their surveys are posted on the web: http://www.sil.org/silesr.\n\nSurveys have usually been conducted among spoken languages. However, surveys have also been done among users of sign languages (Vasishta, Woodward, and Wilson 1978, Woodward 1991, 1993, 1996, Parkhurst & Parkhurst 1998, Al-Fityani & Padden 2008). As with surveys among spoken languages, surveys among sign languages have studied multilingualism, attitudes about various languages both spoken and signed (Ciupek-Reed 2012), differences and similarities between signed varieties (Aldersson and McEntee-Atalianis 2007, Bickford 1991, 2005, Parks 2011), and assessing the vitality of signed languages, and initial descriptions of undocumented sign languages.\n\n\n\n"}
{"id": "15779916", "url": "https://en.wikipedia.org/wiki?curid=15779916", "title": "Languages of Norfolk Island", "text": "Languages of Norfolk Island\n\nThere are two official languages of Norfolk Island, English and Norfuk. English, due to the influence of Great Britain and Australia, the two colonial powers who administered Norfolk Island, is the dominant language of the pair. Norfuk, a creole language based on English and Tahitian and brought to the island by the descendants of the Bounty mutineers from Pitcairn Island was spoken by 580 persons according to the 1989 census. It is closely related to Pitkern spoken on Pitcairn Island.\n\n"}
{"id": "632392", "url": "https://en.wikipedia.org/wiki?curid=632392", "title": "Liner notes", "text": "Liner notes\n\nLiner notes (also sleeve notes or album notes) are the writings found on the sleeves of LP record albums and in booklets which come inserted into the compact disc jewel case or the equivalent packaging for vinyl records and cassettes.\n\nLiner notes are descended from the notes of text that were printed on the inner sleeve used to protect a traditional 12-inch vinyl record, i.e., long playing or gramophone record album. The term descends from the name \"record liner\" or \"album liner\". Album liner notes survived format changes from vinyl LP to cassette to CD.\n\nSuch notes often contained a mix of factual and anecdotal material, and occasionally a discography for the artist or the issuing record label. Liner notes were also an occasion for thoughtful signed essays on the artist by another party, often a sympathetic music journalist, a custom that has largely died out. However, the liner note \"essay\" has survived in retrospective compilations, particularly in box sets. It is also a tradition in Japan especially for foreign artist releases in Japan. Many CD liner notes include complete song lyrics for the album.\n\nLiner notes now usually include information about the musician, lyrics, a personnel list, and other credits to people the musicians want to thank and people or companies involved in the production of the music. They also can give details on the extent of each musical piece, and sometimes place them in historical or social context. Liner notes for classical music recordings often provide information in several languages; if the piece includes vocal parts, they will often include a libretto, possibly also translated into several languages.\n\nLiner notes sometimes provide metadata that can help when cataloguing private or public collections of sound recordings. However, the information provided on liner notes varies considerably depending on the studio or label which produced the record.\n\nIncreasingly and due to the rise of digital downloads, a digital booklet is being introduced to compensate for the lack of a physical booklet. Apple Inc. also introduced iTunes LP which features interactive menus instead of simple pages.\n\nA Grammy Award for Best Album Notes has been given annually since 1964.\n\n\n\n"}
{"id": "40621603", "url": "https://en.wikipedia.org/wiki?curid=40621603", "title": "Linguistic intelligence", "text": "Linguistic intelligence\n\nLinguistic Intelligence is a part of Howard Gardner's multiple intelligence theory that deals with individuals' ability to understand both spoken and written language, as well as their ability to speak and write themselves. In a practical sense, linguistic intelligence is the extent to which an individual can use language, both written and verbal, to achieve goals. In addition to this, high linguistic intelligence has been linked to improved problem solving, as well as to increased abstract reasoning.\n\nIn many cases, only the verbal aspects are taken into consideration. This is usually referred to as verbal intelligence or verbal fluency, and is commonly a reflection of an individual's overall linguistic intelligence.\n\nIn order to understand linguistic intelligence, it is important to understand the mechanisms that control speech and language. These mechanisms can be broken down into four major groups: speech generation (talking), speech comprehension (hearing), writing generation (writing), and writing comprehension (reading).\n\nSpeech production is process by which a thought in the brain is converted into an understandable auditory form. This is a multistage mechanism that involves many different areas of the brain. The first stage is planning, where the brain constructs words and sentences that turn the thought into an understandable form. This occurs primarily in the inferior frontal cortex, specifically in an area known as Broca's area. Next, the brain must plan how to physically create the sounds necessary for speech by linking the planned speech with known sounds, or phonemes. While the location of these associations is not known, it is known that the supplementary motor area plays a key role in this step. Finally, the brain must signal for the words to actually be spoken. This is carried out by the premotor cortex and the motor cortex.\nIn most cases, speech production is controlled by the left hemisphere. In a series of studies, Wilder Penfield, among others, probed the brains of both right-handed (generally left-hemisphere dominant) and left-handed (generally right-hemisphere dominant) patients. They discovered that, regardless of handedness, the left hemisphere was almost always the speech controlling side. However, it has been discovered that in cases of neural stress (hemorrhage, stroke, etc.) the right hemisphere has the ability to take control of speech functions.\n\nVerbal Comprehension is a fairly complex process, and it is not fully understood. From various studies and experiments, it has been found that the superior temporal sulcus activates when hearing human speech, and that speech processing seems to occur within Wernicke's area.\n\nHearing plays an important part in both speech generation and comprehension. When speaking, the person can hear their speech, and the brain uses what it hears as a feedback mechanism to fix speech errors. If a single feedback correction occurs multiple times, the brain will begin to incorporate the correction to all future speech, making it a feed forward mechanism. This is apparent in some deaf people. Deafness, as well as other, smaller deficiencies in hearing, can greatly affect one's ability to comprehend spoken language, as well as to speak it. However, if the person loses hearing ability later in life, most can still maintain a normal level of verbal intelligence. This is thought to be because of the brain's feed forward mechanism still helping to fix speech errors, even in the absence of auditory feedback.\n\nGeneration of written language is thought to be closely related to speech generation, relying on Broca's area for early processing and on the inferior frontal gyrus for semantic processing. However, writing differs in two major ways. First, instead of relating the thought to sounds, the brain must relate the thought to symbols or letters, and second, the motor cortex activates a different set of muscles to write, than when speaking.\n\nWritten comprehension, similar to spoken comprehension, seems to occur primarily in Wernicke's area. However, instead of using the auditory system to gain language input, written comprehension relies on the visual system.\n\nWhile the capabilities of the physical structures used are large factors in determining linguistic intelligence, there have been several genes that have been linked to individual linguistic ability. The NRXN1 gene has been linked to general language ability, and mutations of this gene has been shown to cause major issues to overall linguistic intelligence. The CNTNAP2 gene is believed to affect language development and performance, and mutations in this gene is thought to be involved in autism spectrum disorders. PCDH11 has been linked to language capacity, and it is believed to be one of the factors that accounts for the variation in linguistic intelligence.\n\nIn general, it is difficult to test for linguistic intelligence as a whole, therefore verbal intelligence is often measured instead. This is done using various types of verbal fluency tests.\n\n\nIn one series of tests, it was shown that when children were given verbal fluency tests, a larger portion of their cortex activated compared to adults, as well as activation of both the left and right hemispheres. This is most likely due to the high plasticity of newly developing brains.\n\nRecently, a study was done showing that verbal fluency test results can differ depending on the mental focus of the subject. In this study, mental focus on physical speech production mechanisms caused speech production times to suffer, whereas mental focus on auditory feedback improved these times.\n\nSince linguistic intelligence is based on several complex skills, there are many disorders and injuries that can affect an individual's linguistic intelligence.\n\nDamage and injury in the brain can severely lower one's ability to communicate, and therefore lower one's linguistic intelligence. Common forms of major damage are strokes, concussions, brain tumors, viral/bacterial damage, and drug-related damage. The three major linguistic disorders that result from these injuries are aphasia, alexia, and agraphia. Aphasia is the inability to speak, and can be caused by damage to Broca's area or the motor cortex. Alexia is the inability to read, which can arise from damage to Wernicke's area, among other places. Agraphia is the inability to write which can also arise from damage to Broca's area or the motor cortex. In addition, damage to large areas of the brain can result in any combinations of these disorders, as well as a loss of other abilities.\n\nThere are several disorders that primarily affect only language skills. Three major pure language disorders are Developmental verbal dyspraxia, specific language impairment, and stuttering. Developmental verbal dyspraxia (DVD) is a disorder where children have errors in consonant and vowel production. Specific language impairment (SLI) is a disorder where the patient has a lack of language acquisition skills, despite a seemingly normal intelligence level in other areas. Stuttering is a fairly common disorder where speech flow is interrupted by involuntary repetitions of syllables.\n\nSome disorders cause a wide array of effects, and language impairment is merely one of many possible symptoms. The two major disorders of this type are autism spectrum disorder and epilepsy. Autism and other autism spectrum disorders (ASD) are disorders in which the patient suffers from decreased social skills and lowered mental flexibility. As a result, many patients suffering from ASDs also have language problems, arising from both the lack of social interaction and lowered mental flexibility. Epilepsy is a disorder where electrical malfunctions or mis-communications in the brain cause seizures, leading to muscle spasms and activation of other organs and systems of the body. Over time, epilepsy can lead to cognitive and behavioral decay. This mental decay can eventually lead to a loss of language and communication skills.\n\n"}
{"id": "1723892", "url": "https://en.wikipedia.org/wiki?curid=1723892", "title": "Linguistic philosophy", "text": "Linguistic philosophy\n\nLinguistic philosophy is the view that philosophical problems are problems which may be solved (or dissolved) either by reforming language, or by understanding more about the language we presently use. The former position is that of ideal language philosophy, the latter the position of ordinary language philosophy.\n\n\n"}
{"id": "22760983", "url": "https://en.wikipedia.org/wiki?curid=22760983", "title": "Linguistics", "text": "Linguistics\n\nLinguistics is the scientific study of language, and it involves an analysis of language form, language meaning, and language in context. The earliest activities in the documentation and description of language have been attributed to the 6th century BC Indian grammarian Pāṇini who wrote a formal description of the Sanskrit language in his \"\".\n\nLinguists traditionally analyse human language by observing an interplay between sound and meaning. Phonetics is the study of speech and non-speech sounds, and delves into their acoustic and articulatory properties. The study of language meaning, on the other hand, deals with how languages encode relations between entities, properties, and other aspects of the world to convey, process, and assign meaning, as well as manage and resolve ambiguity. While the study of semantics typically concerns itself with truth conditions, pragmatics deals with how situational context influences the production of meaning.\n\nGrammar is a system of rules which governs the production and use of utterances in a given language. These rules apply to sound as well as meaning, and include componential subsets of rules, such as those pertaining to phonology (the organisation of phonetic sound systems), morphology (the formation and composition of words), and syntax (the formation and composition of phrases and sentences). Modern theories that deal with the principles of grammar are largely based within Noam Chomsky's framework of generative linguistics.\n\nIn the early 20th century, Ferdinand de Saussure distinguished between the notions of \"langue\" and \"parole\" in his formulation of structural linguistics. According to him, \"parole\" is the specific utterance of speech, whereas langue refers to an abstract phenomenon that theoretically defines the principles and system of rules that govern a language. This distinction resembles the one made by Noam Chomsky between competence and performance in his theory of transformative or generative grammar. According to Chomsky, competence is an individual's innate capacity and potential for language (like in Saussure's \"langue\"), while performance is the specific way in which it is used by individuals, groups, and communities (i.e., \"parole\", in Saussurean terms).\n\nThe study of \"parole\" (which manifests through cultural discourses and dialects) is the domain of sociolinguistics, the sub-discipline that comprises the study of a complex system of linguistic facets within a certain speech community (governed by its own set of grammatical rules and laws). Discourse analysis further examines the structure of texts and conversations emerging out of a speech community's usage of language. This is done through the collection of linguistic data, or through the formal discipline of corpus linguistics, which takes naturally occurring texts and studies the variation of grammatical and other features based on such corpora (or corpus data).\n\nStylistics also involves the study of written, signed, or spoken discourse through varying speech communities, genres, and editorial or narrative formats in the mass media. In the 1960s, Jacques Derrida, for instance, further distinguished between speech and writing, by proposing that written language be studied as a linguistic medium of communication in itself. Palaeography is therefore the discipline that studies the evolution of written scripts (as signs and symbols) in language. The formal study of language also led to the growth of fields like psycholinguistics, which explores the representation and function of language in the mind; neurolinguistics, which studies language processing in the brain; biolinguistics, which studies the biology and evolution of language; and language acquisition, which investigates how children and adults acquire the knowledge of one or more languages.\n\nLinguistics also deals with the social, cultural, historical and political factors that influence language, through which linguistic and language-based context is often determined. Research on language through the sub-branches of historical and evolutionary linguistics also focus on how languages change and grow, particularly over an extended period of time.\n\nLanguage documentation combines anthropological inquiry (into the history and culture of language) with linguistic inquiry, in order to describe languages and their grammars. Lexicography involves the documentation of words that form a vocabulary. Such a documentation of a linguistic vocabulary from a particular language is usually compiled in a dictionary. Computational linguistics is concerned with the statistical or rule-based modeling of natural language from a computational perspective. Specific knowledge of language is applied by speakers during the act of translation and interpretation, as well as in language education – the teaching of a second or foreign language. Policy makers work with governments to implement new plans in education and teaching which are based on linguistic research.\n\nRelated areas of study also includes the disciplines of semiotics (the study of direct and indirect language through signs and symbols), literary criticism (the historical and ideological analysis of literature, cinema, art, or published material), translation (the conversion and documentation of meaning in written/spoken text from one language or dialect onto another), and speech-language pathology (a corrective method to cure phonetic disabilities and dis-functions at the cognitive level).\n\nBefore the 20th century, the term \"philology\", first attested in 1716, was commonly used to refer to the study of language, which was then predominantly historical in focus. Since Ferdinand de Saussure's insistence on the importance of synchronic analysis, however, this focus has shifted and the term \"philology\" is now generally used for the \"study of a language's grammar, history, and literary tradition\", especially in the United States (where philology has never been very popularly considered as the \"science of language\").\n\nAlthough the term \"linguist\" in the sense of \"a student of language\" dates from 1641, the term \"linguistics\" is first attested in 1847. It is now the usual term in English for the scientific study of language, though \"linguistic science\" is sometimes used.\n\nLinguistics is a multi-disciplinary field of research that combines tools from natural sciences, social sciences, and the humanities. Many linguists, such as David Crystal, conceptualize the field as being primarily scientific. The term \"linguist\" applies to someone who studies language or is a researcher within the field, or to someone who uses the tools of the discipline to describe and analyse specific languages.\n\nWhile some theories on linguistics focus on the different varieties that language produces, among different sections of society, others focus on the universal properties that are common to all human languages. The theory of variation therefore would elaborate on the different usages of popular languages like French and English across the globe, as well as its smaller dialects and regional permutations within their national boundaries. The theory of variation looks at the cultural stages that a particular language undergoes, and these include the following.\n\nThe pidgin stage in a language is a stage when communication occurs through a grammatically simplified means, developing between two or more groups that do not have a language in common. Typically, it is a mixture of languages at the stage when there occurs a mixing between a primary language with other language elements.\n\nA creole stage in language occurs when there is a stable natural language developed from a mixture of different languages. It is a stage that occurs after a language undergoes its pidgin stage. At the creole stage, a language is a complete language, used in a community and acquired by children as their native language.\n\nA dialect is a variety of language that is characteristic of a particular group among the language speakers. The group of people who are the speakers of a dialect are usually bound to each other by social identity. This is what differentiates a dialect from a register or a discourse, where in the latter case, cultural identity does not always play a role. Dialects are speech varieties that have their own grammatical and phonological rules, linguistic features, and stylistic aspects, but have not been given an official status as a language. Dialects often move on to gain the status of a language due to political and social reasons. Differentiation amongst dialects (and subsequently, languages too) is based upon the use of grammatical rules, syntactic rules, and stylistic features, though not always on lexical use or vocabulary. The popular saying that \"a language is a dialect with an army and navy\" is attributed as a definition formulated by Max Weinreich.\n\nUniversal grammar takes into account general formal structures and features that are common to all dialects and languages, and the template of which pre-exists in the mind of an infant child. This idea is based on the theory of generative grammar and the formal school of linguistics, whose proponents include Noam Chomsky and those who follow his theory and work.\n\n\"We may as individuals be rather fond of our own dialect. This should not make us think, though, that it is actually any better than any other dialect. Dialects are not good or bad, nice or nasty, right or wrong – they are just different from one another, and it is the mark of a civilised society that it tolerates different dialects just as it tolerates different races, religions and sexes.\"\n\nDiscourse is language as social practice (Baynham, 1995) and is a multilayered concept. As a social practice, discourse embodies different ideologies through written and spoken texts. Discourse analysis can examine or expose these ideologies. Discourse influences genre, which is chosen in response to different situations and finally, at micro level, discourse influences language as text (spoken or written) at the phonological or lexico-grammatical level. Grammar and discourse are linked as parts of a system. A particular discourse becomes a language variety when it is used in this way for a particular purpose, and is referred to as a register. There may be certain lexical additions (new words) that are brought into play because of the expertise of the community of people within a certain domain of specialization. Registers and discourses therefore differentiate themselves through the use of vocabulary, and at times through the use of style too. People in the medical fraternity, for example, may use some medical terminology in their communication that is specialized to the field of medicine. This is often referred to as being part of the \"medical discourse\", and so on.\n\nWhen a dialect is documented sufficiently through the linguistic description of its grammar, which has emerged through the consensual laws from within its community, it gains political and national recognition through a country or region's policies. That is the stage when a language is considered a standard variety, one whose grammatical laws have now stabilised from within the consent of speech community participants, after sufficient evolution, improvisation, correction, and growth. The English language, besides perhaps the French language, may be examples of languages that have arrived at a stage where they are said to have become standard varieties.\n\nThe study of a language's universal properties, on the other hand, include some of the following concepts.\n\nThe lexicon is a catalogue of words and terms that are stored in a speaker's mind. The lexicon consists of words and bound morphemes, which are parts of words that can't stand alone, like affixes. In some analyses, compound words and certain classes of idiomatic expressions and other collocations are also considered to be part of the lexicon. Dictionaries represent attempts at listing, in alphabetical order, the lexicon of a given language; usually, however, bound morphemes are not included. Lexicography, closely linked with the domain of semantics, is the science of mapping the words into an encyclopedia or a dictionary. The creation and addition of new words (into the lexicon) is called coining or neologization, and the new words are called neologisms.\n\nIt is often believed that a speaker's capacity for language lies in the quantity of words stored in the lexicon. However, this is often considered a myth by linguists. The capacity for the use of language is considered by many linguists to lie primarily in the domain of grammar, and to be linked with competence, rather than with the growth of vocabulary. Even a very small lexicon is theoretically capable of producing an infinite number of sentences.\n\nAs constructed popularly through the Sapir–Whorf hypothesis, relativists believe that the structure of a particular language is capable of influencing the cognitive patterns through which a person shapes his or her world view. Universalists believe that there are commonalities between human perception as there is in the human capacity for language, while relativists believe that this varies from language to language and person to person. While the Sapir–Whorf hypothesis is an elaboration of this idea expressed through the writings of American linguists Edward Sapir and Benjamin Lee Whorf, it was Sapir's student Harry Hoijer who termed it thus. The 20th century German linguist Leo Weisgerber also wrote extensively about the theory of relativity. Relativists argue for the case of differentiation at the level of cognition and in semantic domains. The emergence of cognitive linguistics in the 1980s also revived an interest in linguistic relativity. Thinkers like George Lakoff have argued that language reflects different cultural metaphors, while the French philosopher of language Jacques Derrida's writings have been seen to be closely associated with the relativist movement in linguistics, especially through deconstruction and was even heavily criticized in the media at the time of his death for his theory of relativism.\n\nLinguistic structures are pairings of meaning and form. Any particular pairing of meaning and form is a Saussurean sign. For instance, the meaning \"cat\" is represented worldwide with a wide variety of different sound patterns (in oral languages), movements of the hands and face (in sign languages), and written symbols (in written languages). Linguistic patterns have proven their importance for the knowledge engineering field especially with the ever-increasing amount of available data.\n\nLinguists focusing on structure attempt to understand the rules regarding language use that native speakers know (not always consciously). All linguistic structures can be broken down into component parts that are combined according to (sub)conscious rules, over multiple levels of analysis. For instance, consider the structure of the word \"tenth\" on two different levels of analysis. On the level of internal word structure (known as morphology), the word \"tenth\" is made up of one linguistic form indicating a number and another form indicating ordinality. The rule governing the combination of these forms ensures that the ordinality marker \"th\" follows the number \"ten.\" On the level of sound structure (known as phonology), structural analysis shows that the \"n\" sound in \"tenth\" is made differently from the \"n\" sound in \"ten\" spoken alone. Although most speakers of English are consciously aware of the rules governing internal structure of the word pieces of \"tenth\", they are less often aware of the rule governing its sound structure. Linguists focused on structure find and analyze rules such as these, which govern how native speakers use language.\n\nLinguistics has many sub-fields concerned with particular aspects of linguistic structure. The theory that elucidates on these, as propounded by Noam Chomsky, is known as generative theory or universal grammar. These sub-fields range from those focused primarily on form to those focused primarily on meaning. They also run the gamut of level of analysis of language, from individual sounds, to words, to phrases, up to cultural discourse.\n\nSub-fields that focus on a grammatical study of language include the following.\n\n\nStylistics is the study and interpretation of texts for aspects of their linguistic and tonal style. Stylistic analysis entails the analysis of description of particular dialects and registers used by speech communities. Stylistic features include rhetoric, diction, stress, satire, irony, dialogue, and other forms of phonetic variations. Stylistic analysis can also include the study of language in canonical works of literature, popular fiction, news, advertisements, and other forms of communication in popular culture as well. It is usually seen as a variation in communication that changes from speaker to speaker and community to community. In short, Stylistics is the interpretation of text.\n\nOne major debate in linguistics concerns the very nature of language and how it should be understood. Some linguists hypothesize that there is a module in the human brain that allows people to undertake linguistic behaviour, which is part of the formalist approach. This \"universal grammar\" is considered to guide children when they learn language and to constrain what sentences are considered grammatical in any human language. Proponents of this view, which is predominant in those schools of linguistics that are based on the generative theory of Noam Chomsky, do not necessarily consider that language evolved for communication in particular. They consider instead that it has more to do with the process of structuring human thought (see also formal grammar).\n\nAnother group of linguists, by contrast, use the term \"language\" to refer to a communication system that developed to support cooperative activity and extend cooperative networks. Such theories of grammar, called \"functional\", view language as a tool that emerged and is adapted to the communicative needs of its users, and the role of cultural evolutionary processes are often emphasized over that of biological evolution.\n\nLinguistics is primarily descriptive. Linguists describe and explain features of language without making subjective judgments on whether a particular feature or usage is \"good\" or \"bad\". This is analogous to practice in other sciences: a zoologist studies the animal kingdom without making subjective judgments on whether a particular species is \"better\" or \"worse\" than another.\n\nPrescription, on the other hand, is an attempt to promote particular linguistic usages over others, often favouring a particular dialect or \"acrolect\". This may have the aim of establishing a linguistic standard, which can aid communication over large geographical areas. It may also, however, be an attempt by speakers of one language or dialect to exert influence over speakers of other languages or dialects (see Linguistic imperialism). An extreme version of prescriptivism can be found among censors, who attempt to eradicate words and structures that they consider to be destructive to society. Prescription, however, may be practised appropriately in the teaching of language, like in ELT, where certain fundamental grammatical rules and lexical terms need to be introduced to a second-language speaker who is attempting to acquire the language.\n\nThe objective of describing languages is often to uncover cultural knowledge about communities. The use of anthropological methods of investigation on linguistic sources leads to the discovery of certain cultural traits among a speech community through its linguistic features. It is also widely used as a tool in language documentation, with an endeavour to curate endangered languages. However, now, linguistic inquiry uses the anthropological method to understand cognitive, historical, sociolinguistic and historical processes that languages undergo as they change and evolve, as well as general anthropological inquiry uses the linguistic method to excavate into culture. In all aspects, anthropological inquiry usually uncovers the different variations and relativities that underlie the usage of language.\n\nMost contemporary linguists work under the assumption that spoken data and signed data are more fundamental than written data. This is because\n\nNonetheless, linguists agree that the study of written language can be worthwhile and valuable. For research that relies on corpus linguistics and computational linguistics, written language is often much more convenient for processing large amounts of linguistic data. Large corpora of spoken language are difficult to create and hard to find, and are typically transcribed and written. In addition, linguists have turned to text-based discourse occurring in various formats of computer-mediated communication as a viable site for linguistic inquiry.\n\nThe study of writing systems themselves, graphemics, is, in any case, considered a branch of linguistics.\n\nBefore the 20th century, linguists analysed language on a diachronic plane, which was historical in focus. This meant that they would compare linguistic features and try to analyse language from the point of view of how it had changed between then and later. However, with Saussurean linguistics in the 20th century, the focus shifted to a more synchronic approach, where the study was more geared towards analysis and comparison between different language variations, which existed at the same given point of time.\n\nAt another level, the syntagmatic plane of linguistic analysis entails the comparison between the way words are sequenced, within the syntax of a sentence. For example, the article \"the\" is followed by a noun, because of the syntagmatic relation between the words. The paradigmatic plane on the other hand, focuses on an analysis that is based on the paradigms or concepts that are embedded in a given text. In this case, words of the same type or class may be replaced in the text with each other to achieve the same conceptual understanding.\n\nThe formal study of language began in India with Pāṇini, the 6th century BC grammarian who formulated 3,959 rules of Sanskrit morphology. Pāṇini's systematic classification of the sounds of Sanskrit into consonants and vowels, and word classes, such as nouns and verbs, was the first known instance of its kind. In the Middle East, Sibawayh, a non-Arab, made a detailed description of Arabic in AD 760 in his monumental work, \"Al-kitab fi al-nahw\" (, \"The Book on Grammar\"), the first known author to distinguish between sounds and phonemes (sounds as units of a linguistic system). Western interest in the study of languages began somewhat later than in the East, but the grammarians of the classical languages did not use the same methods or reach the same conclusions as their contemporaries in the Indic world. Early interest in language in the West was a part of philosophy, not of grammatical description. The first insights into semantic theory were made by Plato in his \"Cratylus\" dialogue, where he argues that words denote concepts that are eternal and exist in the world of ideas. This work is the first to use the word etymology to describe the history of a word's meaning. Around 280 BC, one of Alexander the Great's successors founded a university (see Musaeum) in Alexandria, where a school of philologists studied the ancient texts in and taught Greek to speakers of other languages. While this school was the first to use the word \"grammar\" in its modern sense, Plato had used the word in its original meaning as \"téchnē grammatikḗ\" (), the \"art of writing\", which is also the title of one of the most important works of the Alexandrine school by Dionysius Thrax. Throughout the Middle Ages, the study of language was subsumed under the topic of philology, the study of ancient languages and texts, practised by such educators as Roger Ascham, Wolfgang Ratke, and John Amos Comenius.\n\nIn the 18th century, the first use of the comparative method by William Jones sparked the rise of comparative linguistics. Bloomfield attributes \"the first great scientific linguistic work of the world\" to Jacob Grimm, who wrote \"Deutsche Grammatik\". It was soon followed by other authors writing similar comparative studies on other language groups of Europe. The study of language was broadened from Indo-European to language in general by Wilhelm von Humboldt, of whom Bloomfield asserts:\n\nThis study received its foundation at the hands of the Prussian statesman and scholar Wilhelm von Humboldt (1767–1835), especially in the first volume of his work on Kavi, the literary language of Java, entitled \"Über die Verschiedenheit des menschlichen Sprachbaues und ihren Einfluß auf die geistige Entwickelung des Menschengeschlechts\" (\"On the Variety of the Structure of Human Language and its Influence upon the Mental Development of the Human Race\").\n\nEarly in the 20th century, Saussure introduced the idea of language as a static system of interconnected units, defined through the oppositions between them. By introducing a distinction between diachronic and synchronic analyses of language, he laid the foundation of the modern discipline of linguistics. Saussure also introduced several basic dimensions of linguistic analysis that are still foundational in many contemporary linguistic theories, such as the distinctions between syntagm and paradigm, and the langue- parole distinction, distinguishing language as an abstract system (\"langue\") from language as a concrete manifestation of this system (\"parole\"). Substantial additional contributions following Saussure's definition of a structural approach to language came from The Prague school, Leonard Bloomfield, Charles F. Hockett, Louis Hjelmslev, Émile Benveniste and Roman Jakobson.\n\nDuring the last half of the 20th century, following the work of Noam Chomsky, linguistics was dominated by the generativist school. While formulated by Chomsky in part as a way to explain how human beings acquire language and the biological constraints on this acquisition, in practice it has largely been concerned with giving formal accounts of specific phenomena in natural languages. Generative theory is modularist and formalist in character. Chomsky built on earlier work of Zellig Harris to formulate the generative theory of language. According to this theory the most basic form of language is a set of syntactic rules universal for all humans and underlying the grammars of all human languages. This set of rules is called Universal Grammar, and for Chomsky describing it is the primary objective of the discipline of linguistics. For this reason the grammars of individual languages are of importance to linguistics only in so far as they allow us to discern the universal underlying rules from which the observable linguistic variability is generated.\n\nIn the classic formalization of generative grammars first proposed by Noam Chomsky in the 1950s, a grammar \"G\" consists of the following components:\n\nA formal description of language attempts to replicate a speaker's knowledge of the rules of their language, and the aim is to produce a set of rules that is minimally sufficient to successfully model valid linguistic forms.\n\nFunctional theories of language propose that since language is fundamentally a tool, it is reasonable to assume that its structures are best analysed and understood with reference to the functions they carry out. Functional theories of grammar differ from formal theories of grammar, in that the latter seek to define the different elements of language and describe the way they relate to each other as systems of formal rules or operations, whereas the former defines the functions performed by language and then relates these functions to the linguistic elements that carry them out. This means that functional theories of grammar tend to pay attention to the way language is actually used, and not just to the formal relations between linguistic elements.\n\nFunctional theories describe language in term of the functions existing at all levels of language.\n\nCognitive linguistics emerged as a reaction to generativist theory in the 1970s and 1980s. Led by theorists like Ronald Langacker and George Lakoff, cognitive linguists propose that language is an emergent property of basic, general-purpose cognitive processes. In contrast to the generativist school of linguistics, cognitive linguistics is non-modularist and functionalist in character. Important developments in cognitive linguistics include cognitive grammar, frame semantics, and conceptual metaphor, all of which are based on the idea that form–function correspondences based on representations derived from embodied experience constitute the basic units of language.\n\nCognitive linguistics interprets language in terms of concepts (sometimes universal, sometimes specific to a particular tongue) that underlie its form. It is thus closely associated with semantics but is distinct from psycholinguistics, which draws upon empirical findings from cognitive psychology in order to explain the mental processes that underlie the acquisition, storage, production and understanding of speech and writing. Unlike generative theory, cognitive linguistics denies that there is an \"autonomous linguistic faculty\" in the mind; it understands grammar in terms of \"conceptualization\"; and claims that knowledge of language arises out of \"language use\". Because of its conviction that knowledge of language is learned through use, cognitive linguistics is sometimes considered to be a functional approach, but it differs from other functional approaches in that it is primarily concerned with how the mind creates meaning through language, and not with the use of language as a tool of communication.\n\nHistorical linguists study the history of specific languages as well as general characteristics of language change. The study of language change is also referred to as \"diachronic linguistics\" (the study of how one particular language has changed over time), which can be distinguished from \"synchronic linguistics\" (the comparative study of more than one language at a given moment in time without regard to previous stages). Historical linguistics was among the first sub-disciplines to emerge in linguistics, and was the most widely practised form of linguistics in the late 19th century. However, there was a shift to the synchronic approach in the early twentieth century with Saussure, and became more predominant in western linguistics with the work of Noam Chomsky.\n\nEcolinguistics explores the role of language in the life-sustaining interactions of humans, other species and the physical environment. The first aim is to develop linguistic theories which see humans not only as part of society, but also as part of the larger ecosystems that life depends on. The second aim is to show how linguistics can be used to address key ecological issues, from climate change and biodiversity loss to environmental justice.\n\nSociolinguistics is the study of how language is shaped by social factors. This sub-discipline focuses on the synchronic approach of linguistics, and looks at how a language in general, or a set of languages, display variation and varieties at a given point in time. The study of language variation and the different varieties of language through dialects, registers, and ideolects can be tackled through a study of style, as well as through analysis of discourse. Sociolinguists research on both style and discourse in language, and also study the theoretical factors that are at play between language and society.\n\nDevelopmental linguistics is the study of the development of linguistic ability in individuals, particularly the acquisition of language in childhood. Some of the questions that developmental linguistics looks into is how children acquire different languages, how adults can acquire a second language, and what the process of language acquisition is.\n\nNeurolinguistics is the study of the structures in the human brain that underlie grammar and communication. Researchers are drawn to the field from a variety of backgrounds, bringing along a variety of experimental techniques as well as widely varying theoretical perspectives. Much work in neurolinguistics is informed by models in psycholinguistics and theoretical linguistics, and is focused on investigating how the brain can implement the processes that theoretical and psycholinguistics propose are necessary in producing and comprehending language. Neurolinguists study the physiological mechanisms by which the brain processes information related to language, and evaluate linguistic and psycholinguistic theories, using aphasiology, brain imaging, electrophysiology, and computer modelling. Amongst the structures of the brain involved in the mechanisms of neurolinguistics, the cerebellum which contains the highest numbers of neurons has a major role in terms of predictions required to produce language.\n\nLinguists are largely concerned with finding and describing the generalities and varieties both within particular languages and among all languages. Applied linguistics takes the results of those findings and \"applies\" them to other areas. Linguistic research is commonly applied to areas such as language education, lexicography, translation, language planning, which involves governmental policy implementation related to language use, and natural language processing. \"Applied linguistics\" has been argued to be something of a misnomer. Applied linguists actually focus on making sense of and engineering solutions for real-world linguistic problems, and not literally \"applying\" existing technical knowledge from linguistics. Moreover, they commonly apply technical knowledge from multiple sources, such as sociology (e.g., conversation analysis) and anthropology. (Constructed language fits under Applied linguistics.)\n\nToday, computers are widely used in many areas of applied linguistics. Speech synthesis and speech recognition use phonetic and phonemic knowledge to provide voice interfaces to computers. Applications of computational linguistics in machine translation, computer-assisted translation, and natural language processing are areas of applied linguistics that have come to the forefront. Their influence has had an effect on theories of syntax and semantics, as modelling syntactic and semantic theories on computers constraints.\n\nLinguistic analysis is a sub-discipline of applied linguistics used by many governments to verify the claimed nationality of people seeking asylum who do not hold the necessary documentation to prove their claim. This often takes the form of an interview by personnel in an immigration department. Depending on the country, this interview is conducted either in the asylum seeker's native language through an interpreter or in an international \"lingua franca\" like English. Australia uses the former method, while Germany employs the latter; the Netherlands uses either method depending on the languages involved. Tape recordings of the interview then undergo language analysis, which can be done either by private contractors or within a department of the government. In this analysis, linguistic features of the asylum seeker are used by analysts to make a determination about the speaker's nationality. The reported findings of the linguistic analysis can play a critical role in the government's decision on the refugee status of the asylum seeker.\n\nWithin the broad discipline of linguistics, various emerging sub-disciplines focus on a more detailed description and analysis of language, and are often organized on the basis of the school of thought and theoretical approach that they pre-suppose, or the external factors that influence them.\n\nSemiotics is the study of sign processes (semiosis), or signification and communication, signs, and symbols, both individually and grouped into sign systems, including the study of how meaning is constructed and understood. Semioticians often do not restrict themselves to linguistic communication when studying the use of signs but extend the meaning of \"sign\" to cover all kinds of cultural symbols. Nonetheless, semiotic disciplines closely related to linguistics are literary studies, discourse analysis, text linguistics, and philosophy of language. Semiotics, within the linguistics paradigm, is the study of the relationship between language and culture. Historically, Edward Sapir and Ferdinand De Saussure's structuralist theories influenced the study of signs extensively until the late part of the 20th century, but later, post-modern and post-structural thought, through language philosophers including Jacques Derrida, Mikhail Bakhtin, Michel Foucault, and others, have also been a considerable influence on the discipline in the late part of the 20th century and early 21st century. These theories emphasize the role of language variation, and the idea of subjective usage, depending on external elements like social and cultural factors, rather than merely on the interplay of formal elements.\n\nSince the inception of the discipline of linguistics, linguists have been concerned with describing and analysing previously undocumented languages. Starting with Franz Boas in the early 1900s, this became the main focus of American linguistics until the rise of formal structural linguistics in the mid-20th century. This focus on language documentation was partly motivated by a concern to document the rapidly disappearing languages of indigenous peoples. The ethnographic dimension of the Boasian approach to language description played a role in the development of disciplines such as sociolinguistics, anthropological linguistics, and linguistic anthropology, which investigate the relations between language, culture, and society.\n\nThe emphasis on linguistic description and documentation has also gained prominence outside North America, with the documentation of rapidly dying indigenous languages becoming a primary focus in many university programmes in linguistics. Language description is a work-intensive endeavour, usually requiring years of field work in the language concerned, so as to equip the linguist to write a sufficiently accurate reference grammar. Further, the task of documentation requires the linguist to collect a substantial corpus in the language in question, consisting of texts and recordings, both sound and video, which can be stored in an accessible format within open repositories, and used for further research.\n\nThe sub-field of translation includes the translation of written and spoken texts across mediums, from digital to print and spoken. To translate literally means to transmute the meaning from one language into another. Translators are often employed by organizations, such as travel agencies as well as governmental embassies to facilitate communication between two speakers who do not know each other's language. Translators are also employed to work within computational linguistics setups like Google Translate for example, which is an automated, programmed facility to translate words and phrases between any two or more given languages. Translation is also conducted by publishing houses, which convert works of writing from one language to another in order to reach varied audiences. Academic Translators, specialize and semi specialize on various other disciplines such as; Technology, Science, Law, Economics etc.\n\nBiolinguistics is the study of the biology and evolution of language. It is a highly interdisciplinary field, including linguists, biologists, neuroscientists, psychologists, mathematicians, and others. By shifting the focus of investigation in linguistics to a comprehensive scheme that embraces natural sciences, it seeks to yield a framework by which the fundamentals of the faculty of language are understood.\n\nClinical linguistics is the application of linguistic theory to the fields of Speech-Language Pathology. Speech language pathologists work on corrective measures to cure communication disorders and swallowing disorders\n\nChaika (1990) showed that people with schizophrenia who display speech disorders, like rhyming inappropriately, have attentional dysfunction, as when a patient, shown a colour chip and then asked to identify it, responded \"looks like clay. Sounds like gray. Take you for a roll in the hay. Heyday, May Day.\" The color chip was actually clay-colored, so his first response was correct.'\n\nHowever, most people suppress or ignore words which rhyme with what they've said unless they are deliberately producing a pun, poem or rap. Even then, the speaker shows connection between words chosen for rhyme and an overall meaning in discourse. People with schizophrenia with speech dysfunction show no such relation between rhyme and reason. Some even produce stretches of gibberish combined with recognizable words.\n\nComputational linguistics is the study of linguistic issues in a way that is \"computationally responsible\", i.e., taking careful note of computational consideration of algorithmic specification and computational complexity, so that the linguistic theories devised can be shown to exhibit certain desirable computational properties and their implementations. Computational linguists also work on computer language and software development.\n\nEvolutionary linguistics is the interdisciplinary study of the emergence of the language faculty through human evolution, and also the application of evolutionary theory to the study of cultural evolution among different languages. It is also a study of the dispersal of various languages across the globe, through movements among ancient communities.\n\nForensic linguistics is the application of linguistic analysis to forensics. Forensic analysis investigates on the style, language, lexical use, and other linguistic and grammatical features used in the legal context to provide evidence in courts of law. Forensic linguists have also contributed expertise in criminal cases.\n\n\n"}
{"id": "18456", "url": "https://en.wikipedia.org/wiki?curid=18456", "title": "Literacy", "text": "Literacy\n\nLiteracy is traditionally defined as the ability to read and write. In the modern world, this is one way of interpreting literacy. A more broad interpretation is literacy as knowledge and competence in a specific area. The concept of literacy has evolved in meaning. The modern term's meaning has been expanded to include the ability to use language, numbers, images, computers, and other basic means to understand, communicate, gain useful knowledge, solve mathematical problems and use the dominant symbol systems of a culture. The concept of literacy is expanding across OECD countries to include skills to access knowledge through technology and ability to assess complex contexts. A person who travels and resides in a foreign country but is unable to read or write in the language of the host country would also be regarded by the locals as illiterate.\n\nThe key to literacy is reading development, a progression of skills that begins with the ability to understand spoken words and decode written words, and culminates in the deep understanding of text. Reading development involves a range of complex language underpinnings including awareness of speech sounds (phonology), spelling patterns (orthography), word meaning (semantics), grammar (syntax) and patterns of word formation (morphology), all of which provide a necessary platform for reading fluency and comprehension.\n\nOnce these skills are acquired, the reader can attain full language literacy, which includes the abilities to apply to printed material critical analysis, inference and synthesis; to write with accuracy and coherence; and to use information and insights from text as the basis for informed decisions and creative thought. The inability to do so is called illiteracy or analphabetism.\n\nThe United Nations Educational, Scientific and Cultural Organization (UNESCO) defines literacy as the \"ability to identify, understand, interpret, create, communicate and compute, using printed and written materials associated with varying contexts. Literacy involves a continuum of learning in enabling individuals to achieve their goals, to develop their knowledge and potential, and to participate fully in their community and wider society\".\n\nLiteracy is emerged with the development of numeracy and computational devices as early as 8,000 BCE. Script developed independently at least five times in human history Mesopotamia, Egypt, the Indus civilization, lowland Mesoamerica, and China. \nThe earliest forms of written communication originated in Serbia (Vinča culture), followed by Sumer, located in southern Mesopotamia about 3500-3000 BCE. During this era, literacy was \"a largely functional matter, propelled by the need to manage the new quantities of information and the new type of governance created by trade and large scale production\". Writing systems in Mesopotamia first emerged from a recording system in which people used impressed token markings to manage trade and agricultural production. The token system served as a precursor to early cuneiform writing once people began recording information on clay tablets. Proto-cuneiform texts exhibit not only numerical signs, but also ideograms depicting objects being counted.\n\nEgyptian hieroglyphs emerged from 3300-3100 BCE and depicted royal iconography that emphasized power amongst other elites. The Egyptian hieroglyphic writing system was the first notation system to have phonetic values.\n\nWriting in lowland Mesoamerica was first put into practice by the Olmec and Zapotec civilizations in 900-400 BCE. These civilizations used glyphic writing and bar-and-dot numerical notation systems for purposes related to royal iconography and calendar systems.\n\nThe earliest written notations in China date back to the Shang Dynasty in 1200 BCE. These systematic notations were found inscribed on bones and recorded sacrifices made, tributes received, and animals hunted, which were activities of the elite. These oracle-bone inscriptions were the early ancestors of modern Chinese script and contained logosyllabic script and numerals.\n\nIndus script is largely pictorial and has not been deciphered yet. It may or may not include abstract signs. It is thought that they wrote from right to left and that the script is thought to be logographic. Because it has not been deciphered, linguists disagree on whether it is a complete and independent writing system; however, it is genuinely thought to be an independent writing system that emerged in the Harappa culture.\n\nThese examples indicate that early acts of literacy were closely tied to power and chiefly used for management practices, and probably less than 1% of the population was literate, as it was confined to a very small ruling elite.\n\nAccording to social anthropologist Jack Goody, there are two interpretations that regard the origin of the alphabet. Many classical scholars, such as historian Ignace Gelb, credit the Ancient Greeks for creating the first alphabetic system (c. 750 BCE) that used distinctive signs for consonants and vowels. But Goody contests, \"The importance of Greek culture of the subsequent history of Western Europe has led to an over-emphasis, by classicists and others, on the addition of specific vowel signs to the set of consonantal ones that had been developed earlier in Western Asia\".\n\nThus, many scholars argue that the ancient Semitic-speaking peoples of northern Canaan (modern-day Syria) invented the consonantal alphabet as early as 1500 BCE. Much of this theory's development is credited to English archeologist Flinders Petrie, who, in 1905, came across a series of Canaanite inscriptions located in the turquoise mines of Serabit el-Khadem. Ten years later, English Egyptologist Alan Gardiner reasoned that these letters contain an alphabet, as well as references to the Canaanite goddess Asherah. In 1948, William F. Albright deciphered the text using additional evidence that had been discovered subsequent to Goody's findings. This included a series of inscriptions from Ugarit, discovered in 1929 by French archaeologist Claude F. A. Schaeffer. Some of these inscriptions were mythological texts (written in an early Canaanite dialect) that consisted of a 32-letter cuneiform consonantal alphabet.\n\nAnother significant discovery was made in 1953 when three arrowheads were uncovered, each containing identical Canaanite inscriptions from twelfth century BCE. According to Frank Moore Cross, these inscriptions consisted of alphabetic signs that originated during the transitional development from pictographic script to a linear alphabet. Moreover, he asserts, \"These inscriptions also provided clues to extend the decipherment of earlier and later alphabetic texts\".\n\nThe consonantal system of the Canaanite script inspired alphabetical developments in subsequent systems. During the Late Bronze Age, successor alphabets appeared throughout the Mediterranean region and were employed for Phoenician, Hebrew and Aramaic.\n\nAccording to Goody, these cuneiform scripts may have influenced the development of the Greek alphabet several centuries later. Historically, the Greeks contended that their writing system was modeled after the Phoenicians. However, many Semitic scholars now believe that Ancient Greek is more consistent with an early form Canaanite that was used c. 1100 BCE. While the earliest Greek inscriptions are dated c. eighth century BCE, epigraphical comparisons to Proto-Canaanite suggest that the Greeks may have adopted the consonantal alphabet as early as 1100 BCE, and later \"added in five characters to represent vowels\".\n\nPhoenician, which is considered to contain the first \"linear alphabet\", rapidly spread to the Mediterranean port cities in northern Canaan. Some archeologists believe that Phoenician scripture had some influence on the developments of the Hebrew and Aramaic alphabets based on the fact that these languages evolved during the same time period, share similar features, and are commonly categorized into the same language group.\n\nWhen the Israelites migrated to Canaan between 1200 and 1001 BCE, they also adopted a variation of the Canaanite alphabet. Baruch ben Neriah, Jeremiah's scribe, used this alphabet to create the later scripts of the Old Testament. The Early Hebrew alphabet was prominent in the Mediterranean region until Chaldean Babylonian rulers exiled the Jews to Babylon in the sixth century BCE. It was then that the new script (\"Square Hebrew\") emerged and the older one rapidly died out.\n\nThe Aramaic alphabet also emerged sometime between 1200 and 1001 BCE. As the Bronze Age collapsed, the Aramaeans moved into Canaan and Phoenician territories and adopted their scripts. Although early evidence of this writing is scarce, archeologists have uncovered a wide range of later Aramaic texts, written as early as the seventh century BCE. Due to its longevity and prevalence in the region, Achaemenid rulers would come to adopt it as a \"diplomatic language\". The modern Aramaic alphabet rapidly spread east to the Kingdom of Nabataea, then to Sinai and the Arabian Peninsula, eventually making its way to Africa. Aramaic merchants carried older variations of the language as far as India, where it later influenced the development of Brahmi scripture. It also led to the developments of Arabic, Pahlavi (an Iranian adaptation), \"as well as for a range of alphabets used by early Turkish and Mongol tribes in Siberia, Mongolia and Turkestan\". Literacy at this period spread with the merchant classes and may have grown to number 15-20% of the total population.\n\nThe Aramaic language would die out with the spread of Islam and with it, its influence of Arabic.\n\nUntil recently it was thought that the majority of people were illiterate in ancient times. However, recent work challenges this perception. Anthony DiRenzo asserts that Roman society was \"a civilization based on the book and the register\", and \"no one, either free or slave, could afford to be illiterate\". Similarly Dupont points out, \"The written word was all around them, in both public and private life: laws, calendars, regulations at shrines, and funeral epitaphs were engraved in stone or bronze. The Republic amassed huge archives of reports on every aspect of public life\". The imperial civilian administration produced masses of documentation used in judicial, fiscal and administrative matters as did the municipalities. The army kept extensive records relating to supply and duty rosters and submitted reports. Merchants, shippers, and landowners (and their personal staffs) especially of the larger enterprises must have been literate. \n\nIn the late fourth century the Desert Father Pachomius would expect literacy of a candidate for admission to his monasteries:\nthey shall give him twenty Psalms or two of the Apostles' epistles or some other part of Scripture. And if he is illiterate he shall go at the first, third and sixth hours to someone who can teach and has been appointed for him. He shall stand before him and learn very studiously and with all gratitude. The fundamentals of a syllable, the verbs and nouns shall all be written for him and even if he does not want to he shall be compelled to read.\n\nIn the course of the 4th and 5th century the Churches made efforts to ensure a better clergy in particular among the bishops who were expected to have a classical education, which was the hallmark of an socially acceptable person in higher society (and possession of which allayed the fears of the pagan elite that their cultural inheritance would be destroyed). Even after the remnants of the Western Roman Empire fell in the 470s literacy continued to be a distinguishing mark of the elite as communications skills were still important in political and Church life (bishops were largely drawn from the senatorial class) in a new cultural synthesis that made \"Christianity the Roman religion,\" . However, these skills were less in needed than previously in the absence of the large imperial administrative apparatus whose middle and top echelons the elite had dominated as if by right. Even so, in pre-modern times it is unlikely that literacy was found in more than about 30-40% of the population. The highest percentage of literacy during the Dark Ages was among the clergy and monks who supplied much of the staff needed to administer the states of western Europe. \n\nPost-Antiquity illiteracy was made much worse due to a lack of suitable writing medium. When the Western Roman Empire collapsed, the import of papyrus to Europe ceased. Since papyrus perishes easily and does not last well in the wetter or damper European climate, the alternative was parchment which was expensive and accessible only by the Church and upper layers of the society. Once paper was introduced into Europe in the 11th century in Spain. Its use spread north slowly over the next four centuries. Increased literacy saw a resurgence because of its use. By the 15th century paper had largely replaced parchment except for many luxury manuscripts (some of which used paper). \n\nThe Reformation stressed the importance of literacy and being able to read the Bible. The Protestant countries were the first to attain full literacy; Scandinavian countries were fully literate in the early 17th century. The Church demanded literacy as the pre-requisite for marriage in Sweden, this further propagating full literacy.\n\nLiteracy data published by UNESCO displays that since 1950, the adult literacy rate at the world level has increased by 5 percentage points every decade on average, from 55.7 per cent in 1950 to 86.2 per cent in 2015. However, for four decades, the population growth was so rapid that the number of illiterate adults kept increasing, rising from 700 million in 1950 to 878 million in 1990. Since then, the number has fallen markedly to 745 million in 2015, although it remains higher than in 1950 despite decades of universal education policies, literacy interventions and the spread of print material and information and communications technology (ICT). However, these trends have been far from uniform across regions.\n\nAvailable global data indicates significant variations in literacy rates between world regions. North America, Europe, West Asia, and Central Asia have achieved almost full adult literacy (individuals at or over the age of 15) for both men and women. Most countries in East Asia and the Pacific, as well as Latin America and the Caribbean, are above a 90% literacy rate for adults. Illiteracy persists to a greater extent in other regions: 2013 UNESCO Institute for Statistics (UIS) data indicates adult literacy rates of only, 67.55% in South Asia and North Africa, 59.76% in Sub-Saharan Africa.\n\nIn much of the world, high youth literacy rates suggest that illiteracy will become less and less common as younger generations with higher educational attainment levels replace older ones. However, in sub-Saharan Africa and South Asia, where the vast majority of the world's illiterate youth live, lower school enrollment implies that illiteracy will persist to a greater degree. According to 2013 UIS data, the youth literacy rate (individuals ages 15 to 24) is 84.03% in South Asia and North Africa, and 70.06% in Sub-Saharan Africa.\n\nThat being said, literacy has rapidly spread in several regions in the last twenty-five years (see image).\n\nOn a worldwide scale, illiteracy disproportionately impacts women. According to 2015 UIS data collected by the UNESCO Institute for Statistics, about two-thirds (63%) of the world's illiterate adults are women. This disparity was even starker in previous decades: from 1970 to 2000, the global gender gap in literacy would decrease by roughly 50%. In recent years, however, this progress has stagnated, with the remaining gender gap holding almost constant over the last two decades. In general, the gender gap in literacy is not as pronounced as the regional gap; that is, differences between countries in overall literacy are often larger than gender differences within countries. However, the gap between men and women would narrow from 1990 onwards, after the increase of male adult literacy rates at 80 per cent (see image).\n\nSub-Saharan Africa, the region with the lowest overall literacy rates, also features the widest gender gap: just 52% of adult females are literate, and 68% among adult men. Similar gender disparity persists in two other regions, North Africa (86% adult male literacy, 70% adult female literacy) and South Asia (77% adult male literacy, 58% adult female literacy).\n\nThe 1990 World Conference on Education for All, held in Jomtien, Thailand, would bring attention to the literacy gender gap and prompt many developing countries to prioritize women's literacy. In the past decade, global development agendas would increasingly address the issue of female literacy. For example, UN Secretary-General Ban Ki-moon would center his 2010 International Literacy Day speech around the theme \"Empowering Women Through Literacy Empowers Us All,\" emphasizing the broad societal progress that higher female literacy rates could promote.\n\nIn many contexts, female illiteracy co-exists with other aspects of gender inequality. Martha Nussbaum, for example, make illiterate women more vulnerable to becoming trapped in an abusive marriage, given that illiteracy limits their employment opportunities and worsens their intra-household bargaining position. Moreover, Nussbaum links literacy to the potential for women to effectively communicate and collaborate with one another in order \"to participate in a larger movement for political change.\"\n\nSocial barriers prevent expanding literacy skills among women and girls. Making literacy classes available can be ineffective when it conflicts with the use of the valuable limited time of women and girls. School age girls, in many contexts, face stronger expectations than their male counterparts to perform household work and care after younger siblings. Generational dynamics can also perpetuate these disparities: illiterate parents may not readily appreciate the value of literacy for their daughters, particularly in traditional, rural societies with expectations that girls will remain at home.\n\nA 2015 World Bank and the International Center for Research on Women review of academic literature would conclude that child marriage, which predominantly impacts girls, tends to reduce literacy levels. A 2008 analysis of the issue in Bangladesh found that for every additional year of delay in a girl's marriage, her likelihood of literacy would increase by 5.6 percent. Similarly, a 2014 study found that in sub-Saharan Africa, marrying early would significantly decrease a girl's probability of literacy, holding other variables constant. A 2015 review of the child marriage literature therefore would recommend marriage postponement as part of a strategy to increase educational attainment levels, including female literacy in particular.\n\nWhile women and girls comprise the majority of the global illiterate population, in many developed countries a literacy gender gap exists in the opposite direction. Data from the Programme for International Student Assessment (PISA) has consistently indicated the literacy underachievement of boys within member countries of the Organisation for Economic Co-operation and Development (OECD). In view of such findings, many education specialists have recommended changes in classroom practices to better accommodate boys' learning styles, and to remove any gender stereotypes that may create a perception of reading and writing as feminine activities.\n\nMany policy analysts consider literacy rates as a crucial measure of the value of a region's human capital. For example, literate people can be more easily trained than illiterate people, and generally have a higher socioeconomic status; thus they enjoy better health and employment prospects. The international community has come to consider literacy as a key facilitator and goal of development. In regard to the Sustainable Development Goals adopted by the UN in 2015, the UNESCO Institute for Lifelong Learning has declared the \"central role of literacy in responding to sustainable development challenges such as health, social equality, economic empowerment and environmental sustainability.\"\n\nIlliterate people are generally less knowledgeable about hygiene and nutritional practices, an unawareness which can exacerbate a wide range of health issues. Within developing countries in particular, literacy rates also have implications for child mortality; in these contexts, children of literate mothers are 50% more likely to live past age 5 than children of illiterate mothers. Public health research has thus increasingly concerned itself with the potential for literacy skills to allow women to more successfully access health care systems, and thereby facilitate gains in child health.\n\nFor example, a 2014 descriptive research survey project correlates literacy levels with the socioeconomic status of women in Oyo State, Nigeria. The study claims that developing literacy in this area will bring \"economic empowerment and will encourage rural women to practice hygiene, which will in turn lead to the reduction of birth and death rates.\"\n\nLiteracy can increase job opportunities and access to higher education. In 2009, the National Adult Literacy agency (NALA) in Ireland commissioned a cost benefit analysis of adult literacy training. This concluded that there were economic gains for the individuals, the companies they worked for, and the Exchequer, as well as the economy and the country as a whole—for example, increased GDP. Korotayev and coauthors have revealed a rather significant correlation between the level of literacy in the early 19th century and successful modernization and economic breakthroughs in the late 20th century, as \"literate people could be characterized by a greater innovative-activity level, which provides opportunities for modernization, development, and economic growth\".\n\nWhile informal learning within the home can play an important role in literacy development, gains in childhood literacy often occur in primary school settings. Continuing the global expansion of public education is thus a frequent focus of literacy advocates. These kinds of broad improvements in education often require centralized efforts undertaken by national governments; alternatively, local literacy projects implemented by NGOs can play an important role, particularly in rural contexts.\n\nFunding for both youth and adult literacy programs often comes from large international development organizations. USAID, for example, steered donors like the Bill and Melinda Gates Foundation and the Global Partnership for Education toward the issue of childhood literacy by developing the Early Grade Reading Assessment. Advocacy groups like the National Institute of Adult Continuing Education have frequently called upon international organizations such as UNESCO, the International Labour Organization, the World Health Organization, and the World Bank to prioritize support for adult women's literacy. Efforts to increase adult literacy often encompass other development priorities as well; for example, initiatives in Ethiopia, Morocco, and India have combined adult literacy programs with vocational skills trainings in order to encourage enrollment and address the complex needs of women and other marginalized groups who lack economic opportunity.\n\nIn 2013, the UNESCO Institute for Lifelong Learning published a set of case studies on programs that successfully improved female literacy rates. The report features countries from a variety of regions and of differing income levels, reflecting the general global consensus on \"the need to empower women through the acquisition of literacy skills.\" Part of the impetus for UNESCO's focus on literacy is a broader effort to respond to globalization and \"the shift towards knowledge-based societies\" that it has produced. While globalization presents emerging challenges, it also provides new opportunities: many education and development specialists are hopeful that new information and communications technologies (ICTs) will have the potential to expand literacy learning opportunities for children and adults, even those in countries that have historically struggled to improve literacy rates through more conventional means.\n\nThe Human Development Index, produced by the United Nations Development Programme (UNDP), uses education as one of its three indicators; originally, adult literacy represented two-thirds of this education index weight. In 2010, however, the UNDP replaced the adult literacy measure with mean years of schooling. A 2011 UNDP research paper framed this change as a way to \"ensure current relevance,\" arguing that gains in global literacy already achieved between 1970 and 2010 meant that literacy would be \"unlikely to be as informative of the future.\" Other scholars, however, have since warned against overlooking the importance of literacy as an indicator and a goal for development, particularly for marginalized groups such as women and rural populations.\n\nUnlike medieval times, when reading and writing skills were restricted to a few elites and the clergy, these literacy skills are now expected from every member of a society. Literacy is a human right essential for lifelong learning and social change. As supported by the 1996 Report of the International Commission on Education for the Twenty-First Century, and the 1997 Hamburg Declaration: ‘Literacy, broadly conceived as the basic knowledge and skills needed by all in a rapidly changing world, is a fundamental human right. (...) There are millions, the majority of whom are women, who lack opportunities to learn or who have insufficient skills to be able to assert this right. The challenge is to enable them to do so. This will often imply the creation of preconditions for learning through awareness raising and empowerment. Literacy is also a catalyst for participation in social, cultural, political and economic activities, and for learning throughout life’.\n\nThe public library has long been a force promoting literacy in many countries. In the U.S. context, the American Library Association promotes literacy through the work of the Office for Literacy and Outreach Services. This committee's charge includes ensuring equitable access to information and advocating for adult new and non-readers. The Public Library Association recognizes the importance of early childhood in the role of literacy development and created, in collaboration with the Association for Library Service to Children, Every Child Ready to Read @your library in order to inform and support parents and caregivers in their efforts to raise children who become literate adults. The release of the National Assessment of Adult Literacy (NAAL) report in 2005 revealed that approximately 14% of U.S. adults function at the lowest level of literacy; 29% of adults function at the basic functional literacy level and cannot help their children with homework beyond the first few grades. The lack of reading skills hinders adults from reaching their full potential. They might have difficulty getting and maintaining a job, providing for their families, or even reading a story to their children. For adults, the library might be the only source of a literacy program.\n\nDia! Which stand for Diversity in Action and is also known as \"El Dia de los Ninos/El dia de los libros (Children's Day/Book Day)\" is a program which celebrates the importance of reading to children from all cultural and linguistic backgrounds. Dia! is celebrated every year on 30 April in schools, libraries, and homes and this website provides tools and programs to encourage reading in children. Parents, caregivers, and educators can even start a book club.\n\nThis community literacy program was initiated in 1992 by the Orange County Public Library in California. The mission of READ/Orange County is to \"create a more literate community by providing diversified services of the highest quality to all who seek them.\" Potential tutors train during an extensive 23-hour tutor training workshop in which they learn the philosophy, techniques and tools they will need to work with adult learns. After the training, the tutors invest at least 50 hours a year to tutoring their student.The organization builds on people's experience as well as education rather than trying to make up for what has not been learned. The program seeks to equip students with skills to continue learning in the future. The guiding philosophy is that an adult who learns to read creates a ripple effect in the community. The person becomes an example to children and grandchildren and can better serve the community.\n\nLocated in Boulder, Colorado, the program recognized the difficulty that students had in obtaining child care while attending tutoring sessions, and joined with the University of Colorado to provide reading buddies to the children of students. Reading Buddies matches children of adult literacy students with college students who meet with them once a week throughout the semester for an hour and a half. The college students receive course credit to try to enhance the quality and reliability of their time. Each Reading Buddies session focuses primarily on the college student reading aloud with the child. The goal is to help the child gain interest in books and feel comfortable reading aloud. Time is also spent on word games, writing letters, or searching for books in the library. Throughout the semester the pair work on writing and illustrating a book together. The college student's grade is partly dependent on the completion of the book. Although Reading Buddies began primarily as an answer to the lack of child care for literacy students, it has evolved into another aspect of the program. Participating children show marked improvement in their reading and writing skills throughout the semester.\n\nApproximately 120,000 adults in Hillsborough County are illiterate or read below the fourth-grade level. Working since 1986, the HLC is \"committed to improving literacy by empowering adults through education\". Sponsored by the statewide Florida Literacy Coalition, HLC strives to improve the literacy ability of adults in Hillsborough County, Florida. The HLC provides tutoring for English for speakers of other languages (ESOL). Through one-on-one tutoring, the organization works to help adult students reach at least the fifth-grade level.\n\nTraditionally, literacy is the ability to use written language actively and passively; one definition of literacy is the ability to \"read, write, spell, listen, and speak\". Since the 1980s, some have argued that literacy is ideological, which means that literacy always exists in a context, in tandem with the values associated with that context. Prior work viewed literacy as existing autonomously.\n\nSome have argued that the definition of literacy should be expanded. For example, in the United States, the National Council of Teachers of English and the International Reading Association have added \"visually representing\" to the traditional list of competencies. Similarly, in Scotland, literacy has been defined as: \"The ability to read, write and use numeracy, to handle information, to express ideas and opinions, to make decisions and solve problems, as family members, workers, citizens and lifelong learners\". It is argued that literacy includes the cultural, political, and historical contexts of the community in which communication takes place.\n\nA basic literacy standard in many places is the ability to read the newspaper. Increasingly, communication in commerce and in general requires the ability to use computers and other digital technologies. Since the 1990s, when the Internet came into wide use in the United States, some have asserted that the definition of literacy should include the ability to use tools such as web browsers, word processing programs, and text messages. Similar expanded skill sets have been called multimedia literacy, computer literacy, information literacy, and technological literacy. Some scholars propose the idea multiliteracies which includes Functional Literacy, Critical Literacy, and Rhetorical Literacy.\n\n\"Arts literacy\" programs exist in some places in the United States. Visual literacy also includes the ability to understand visual forms of communication such as body language, pictures, maps, and video. Evolving definitions of literacy often include all the symbol systems relevant to a particular community.\n\nOther genres under study by academia include critical literacy, media literacy, ecological literacy and health literacy With the increasing emphasis on evidence-based decision making, and the use of statistical graphics and information, statistical literacy is becoming a very important aspect of literacy in general. The International Statistical Literacy Project is dedicated to the promotion of statistical literacy among all members of society.\n\nGiven that a large part of the benefits of literacy can be obtained by having access to a literate person in the household, some recent literature in economics, starting with the work of Kaushik Basu and James Foster, distinguishes between a \"proximate illiterate\" and an \"isolated illiterate\". The former refers to an illiterate person who lives in a household with literates and the latter to an illiterate who lives in a household of all illiterates. What is of concern is that many people in poor nations are not just illiterates but isolated illiterates.\n\nTeaching English literacy in the United States is dominated by a focus on a set of discrete decoding skills. From this perspective, literacy—or, rather, reading—comprises a number of subskills that can be taught to students. These skill sets include phonological awareness, phonics (decoding), fluency, comprehension, and vocabulary. Mastering each of these subskills is necessary for students to become proficient readers.\n\nFrom this same perspective, readers of alphabetic languages must understand the alphabetic principle to master basic reading skills. For this purpose a writing system is \"alphabetic\" if it uses symbols to represent individual language sounds, though the degree of correspondence between letters and sounds varies between alphabetic languages. Syllabic writing systems (such as Japanese kana) use a symbol to represent a single syllable, and logographic writing systems (such as Chinese) use a symbol to represent a morpheme.\n\nThere are any number of approaches to teaching literacy; each is shaped by its informing assumptions about what literacy is and how it is best learned by students. Phonics instruction, for example, focuses on reading at the level of the word. It teaches readers to observe and interpret the letters or groups of letters that make up words. A common method of teaching phonics is synthetic phonics, in which a novice reader pronounces each individual sound and \"blends\" them to pronounce the whole word. Another approach is embedded phonics instruction, used more often in whole language reading instruction, in which novice readers learn about the individual letters in words on a just-in-time, just-in-place basis that is tailored to meet each student's reading and writing learning needs. That is, teachers provide phonics instruction opportunistically, within the context of stories or student writing that feature many instances of a particular letter or group of letters. Embedded instruction combines letter-sound knowledge with the use of meaningful context to read new and difficult words. Techniques such as directed listening and thinking activities can be used to aid children in learning how to read and reading comprehension.\n\nIn a 2012 proposal, it has been claimed that reading can be acquired naturally if print is constantly available at an early age in the same manner as spoken language. If an appropriate form of written text is made available before formal schooling begins, reading should be learned inductively, emerge naturally, and with no significant negative consequences. This proposal challenges the commonly held belief that written language requires formal instruction and schooling. Its success would change current views of literacy and schooling. Using developments in behavioral science and technology, an interactive system (Technology Assisted Reading Acquisition, TARA) would enable young pre-literate children to accurately perceive and learn properties of written language by simple exposure to the written form.\n\nIn Australia a number of State governments have introduced Reading Challenges to improve literacy. The Premier's Reading Challenge in South Australia, launched by Premier Mike Rann has one of the highest participation rates in the world for reading challenges. It has been embraced by more than 95% of public, private and religious schools.\n\nPrograms have been implemented in regions that have an ongoing conflict or in a post-conflict stage. The Norwegian Refugee Council Pack program has been used in 13 post-conflict countries since 2003. The program organizers believe that daily routines and other wise predictable activities help the transition from war to peace. Learners can select one area in vocational training for a year-long period. They complete required courses in agriculture, life skills, literacy and numeracy. Results have shown that active participation and management of the members of the program are important to the success of the program. These programs share the use of integrated basic education, e.g. literacy, numeracy, scientific knowledge, local history and culture, native and mainstream language skills, and apprenticeships.\n\nAlthough there is considerable awareness that language deficiencies (lacking proficiency) are disadvantageous to immigrants settling in a new country, there appears to be a lack of pedagogical approaches that address the instruction of literacy to migrant English language learners (ELLs). Harvard scholar Catherine Snow (2001) called for a gap to be addresses: \"The TESOL field needs a concerted research effort to inform literacy instruction for such children ... to determine when to start literacy instruction and how to adapt it to the LS reader's needs\". The scenario becomes more complex when there is no choice in such decisions as in the case of the current migration trends with citizens from the Middle East and Africa being relocated to English majority nations due to various political or social reasons. Recent developments to address the gap in teaching literacy to second or foreign language learners has been ongoing and promising results have been shown by Pearson and Pellerine (2010) which integrates Teaching for Understanding, a curricular framework from the Harvard Graduate School of Education. A series of pilot projects had been carried out in the Middle East and Africa (see Patil, 2016). In this work significant interest from the learners perspective have been noticed through the integration of visual arts as springboards for literacy oriented instruction. In one case migrant women had been provided with cameras and a walking tour of their local village was provided to the instructor as the women photographed their tour focusing on places and activities that would later be used for writings about their daily life. In essence a narrative of life. Other primers for writing activities include: painting, sketching, and other craft projects (e.g. gluing activities).\n\nA series of pilot studies were carried out to investigate alternatives to instructing literacy to migrant ELLs, starting from simple trials aiming to test the teaching of photography to participants with no prior photography background, to isolating painting and sketching activities that could later be integrated into a larger pedagogical initiative. In efforts to develop alternative approaches for literacy instruction utilising visual arts, work was carried out with Afghan labourers, Bangladeshi tailors, Emirati media students, internal Ethiopian migrants (both labourers and university students), and a street child.\nIt should be pointed out that in such challenging contexts sometimes the teaching of literacy may have unforeseen barriers. The \"EL Gazette\" reported that in the trials carried out in Ethiopia, for example, it was found that all ten of the participants had problems with vision. In order to overcome this, or to avoid such challenges, preliminary health checks can help inform pre-teaching in order to better assist in the teaching/learning of literacy.\n\nIn a visual arts approach to literacy instruction a benefit can be the inclusion of both a traditional literacy approach (reading and writing) while at the same time addressing 21st Century digital literacy instruction through the inclusion of digital cameras and posting images onto the web. Many scholars feel that the inclusion of digital literacy is necessary to include under the traditional umbrella of literacy instruction specifically when engaging second language learners. (Also see: Digital literacy.) \n\nOther ways in which visual arts have been integrated into literacy instruction for migrant populations include integrating aspects of visual art with the blending of core curricular goals.\n\nA more pressing challenge in education is the instruction of literacy to Migrant English Language Learners (MELLs), a term coined by Pellerine. It is not just limited to English. “Due to the growing share of immigrants in many Western societies, there has been increasing concern for the degree to which immigrants acquire language that is spoken in the destination country” (Tubergen 2006). Remembering that teaching literacy to a native in their L1 can be challenging, and the challenge becomes more cognitively demanding when in a second language (L2), the task can become considerably more difficult when confronted with a migrant who has made a sudden change (migrated) and requires the second language upon arrival in the country of destination. In many instances a migrant will not have the opportunity, for many obvious reasons, to start school again at grade one and acquire the language naturally. In these situations alternative interventions need to take place.\n\nIn working with illiterate people (and individuals with low-proficiency in an L2) following the composition of some artifact like in taking a photo, sketching an event, or painting an image, a stage of orality has been seen as an effective way to understand the intention of the learner.\n\nIn the accompanying image from left to right a) an image taken during a phototour of the participant's village. This image is of the individual at her shop, and this is one of her products that she sells, dung for cooking fuel. The image helps the interlocutor understand the realities of the participants daily life and most importantly it allows the participant the opportunity to select what they feel is important to them. b) This is an image of a student explaining and elaborating the series of milestones in her life to a group. In this image the student had a very basic ability and with some help was able to write brief captions under the images. While she speaks a recording of her story takes place to understand her story and to help develop it in the L2. The third image is of a painting that had been used with a composite in Photoshop. With further training participants can learn how to blend images they would like to therefore introducing elements of digital literacies, beneficial in many spheres of life in the 21st century.\n\nIn the following image (see right) you can see two samples 1) One in Ethiopia from stencil to more developed composition based on a village tour, photography, and paintings. 2) In the Middle East at a tailor's shop focusing English for Specific Purposes (ESP) and in this example the writing has evolved from photography, sketching, and in situ exposure for the instructor (much like the village tour in sample one).\n\nFrom the work based in Ethiopia, participants were asked to rate preference of activity, on a scale of 1-10. The survey prompt was: On a scale of 1 - 10 how would you rate photography as an activity that helped you get inspiration for your writing activities (think of enjoyment and usefulness). The following activities were rated, in order of preference - activities used as primers for writing:\n\n\nMore research would need to be conducted to confirm such trends.\n\nIn bringing work together from students in culminating projects, authorship programs have been successful in bringing student work together in book format. Such artifacts can be used to both document learning, but more importantly reinforce language and content goals.\n\nThe culmination of such writings, into books can evoke both intrinsic and extrinsic motivation. Form feedback by students involved in such initiatives the responses have indicated that the healthy pressures of collective and collaborative work was beneficial.\n\nTeaching people to read and write, in a traditional sense of the meaning (literacy) is a very complex task in a native language. To do this in a second language becomes increasingly more complex, and in the case of migrants relocating to another country there can be legal and policy driven boundaries that prohibit the naturalization and acquisition of citizen ship based on language proficiency. In Canada for example despite a debate, language tests are required years after settling into Canada. Similar exists globally, see:, and for example.\n\nThe \"EL Gazette\" reviewed Pellerine's work with migrant English language learners and commented: \"Handing English language learners a sponge and some paint and asking them to ‘paint what comes’ might not appear like a promising teaching method for a foreign language. But Canadian EL instructor and photographer Steve Pellerine has found that the technique, along with others based around the visual arts, has helped some of his most challenging groups to learn\". Visual arts have been viewed as an effective way to approach literacy instruction - the art being primers for subsequent literacy tasks within a scaffolded curricular design, such at Teaching for Understanding (TfU) or Understanding by Design (UbD).\n\nNearly one in ten young adult women has poor reading and writing skills in the UK in the 21st century. This seriously damages their employent prospects and many are trapped in poverty. Lack of reading skill is a social stigma and women tend to hide their difficulty rather than seeking help. Girls on average do better than boys at English in school. A quarter of British adults would struggle to read a bus timetable. \n\nLiteracy is first documented in the area of modern England on 24 September 54 BCE, on which day Julius Caesar and Quintus Cicero wrote to Cicero \"from the nearest shores of Britain\". Literacy was widespread under Roman rule, but became very rare, limited almost entirely to churchmen, after the fall of the Western Roman Empire. In 12th and 13th century England, the ability to recite a particular passage from the Bible in Latin entitled a common law defendant to the so-called benefit of clergy—i.e., trial before an ecclesiastical court, where sentences were more lenient, instead of a secular one, where hanging was a likely sentence. Thus literate lay defendants often claimed the right to benefit of clergy, while an illiterate person who had memorized the psalm used as the literacy test, Psalm 51 (\"O God, have mercy upon me...\"), could also claim benefit of clergy. Despite lacking a system of free and compulsory primary schooling, England managed to reach near universal literacy in the nineteenth century as a result of shared, informal learning systems such as family members, fellow workers, and/or benevolent employers, to name a few. Even with near universal literacy rates, the gap between male and female literacy rates continued to persist until the early twentieth century. Many female readers in the West during the nineteenth century were able to read, but unable to write.\n\nFormal higher education in the arts and sciences in Wales, from the Dark Ages to the 18th century, was the preserve of the wealthy and the clergy. As in England, Welsh history and archaeological finds dating back to the Bronze Age reveal not only reading and writing, but also alchemy, botany, advanced maths and science. Following the Roman occupation and the conquest by the English, education in Wales was at a very low ebb in the early modern period; in particular, formal education was only available in English while the majority of the population spoke only Welsh. The first modern grammar schools were established in Welsh towns such as Ruthin, Brecon, and Cowbridge. One of the first modern national education methods to use the native Welsh language was started by Griffith Jones in 1731. Jones was the rector of Llanddowror from 1716 and remained there for the rest of his life. He organized and introduced a Welsh medium circulating school system, which was attractive and effective for Welsh speakers, while also teaching them English, which gave them access to broader educational sources. The circulating schools may have taught half the country's population to read. Literacy rates in Wales by the mid-18th century were one of the highest.\nThe ability to read did not necessarily imply the ability to write. The 1686 church law (\"kyrkolagen\") of the Kingdom of Sweden (which at the time included all of modern Sweden, Finland, Latvia and Estonia) enforced literacy on the people, and by 1800 the ability to read was close to 100%. This was directly dependent on the need to read religious texts in the Lutheran faith in Sweden and Finland. As a result, literacy in these countries was inclined towards reading, specifically. But as late as the 19th century, many Swedes, especially women, could not write. The exception to this rule were the men and women of Iceland who achieved widespread literacy without formal schooling, libraries, or printed books via informal tuition by religious leaders and peasant teachers. That said, the situation in England was far worse than in Scandinavia, France, and Prussia: as late as 1841, 33% of all Englishmen and 44% of Englishwomen signed marriage certificates with their mark as they were unable to write (government-financed public education was not available in England until 1870 and, even then, on a limited basis).\n\nHistorian Ernest Gellner argues that Continental European countries were far more successful in implementing educational reform precisely because their governments were more willing to invest in the population as a whole. Government oversight allowed countries to standardize curriculum and secure funding through legislation thus enabling educational programs to have a broader reach.\n\nAlthough the present-day concepts of literacy have much to do with the 15th-century invention of the movable type printing press, it was not until the Industrial Revolution of the mid-19th century that paper and books became affordable to all classes of industrialized society. Until then, only a small percentage of the population were literate as only wealthy individuals and institutions could afford the materials. Even , the cost of paper and books is a barrier to universal literacy in some less-industrialized nations.\n\nOn the other hand, historian Harvey Graff argues that the introduction of mass schooling was in part an effort to control the type of literacy that the working class had access to. According to Graff, literacy learning was increasing outside of formal settings (such as schools) and this uncontrolled, potentially critical reading could lead to increased radicalization of the populace. In his view, mass schooling was meant to temper and control literacy, not spread it. Graff also points out, using the example of Sweden, that mass literacy can be achieved without formal schooling or instruction in writing.\n\nResearch on the literacy rates of Canadians in the colonial days rested largely on examinations of the proportion of signatures to marks on parish acts (birth, baptismal, and marriage registrations). Although some researchers have concluded that signature counts drawn from marriage registers in nineteenth century France corresponded closely with literacy tests given to military conscripts, others regard this methodology as a \"relatively unimaginative treatment of the complex practices and events that might be described as literacy\" (Curtis, 2007, p. 1-2). But censuses (dating back to 1666) and official records of New France offer few clues of their own on the population's levels of literacy, therefore leaving few options in terms of materials from which to draw literary rate estimates.\n\nIn his research of literacy rates of males and females in New France, Trudel found that in 1663, of 1,224 persons in New France who were of marriageable age, 59% of grooms and 46% of brides wrote their name; however, of the 3,000-plus colony inhabitants, less than 40% were native born. Signature rates were therefore likely more reflective of rates of literacy among French immigrants. Magnuson's (1985) research revealed a trend: signature rates for the period of 1680–1699 were 42% for males, 30% for females; in 1657-1715, they were 45% for males and 43% for females; in 1745-1754, they were higher for females than for males. He believed that this upward trend in rates of females’ ability to sign documents was largely attributed to the larger number of female religious orders, and to the proportionately more active role of women in health and education, while the roles of male religious orders were largely to serve as parish priests, missionaries, military chaplains and explorers. 1752 marked the date that Canada's first newspaper—the \"Halifax Gazette\"—began publication.\n\nThe end of the Seven Years' War in 1763 allowed two Philadelphia printers to come to Québec City and to begin printing a bilingual \"Quebec Gazette\" in 1764, while in 1785 Fleury Mesplet started publication of the \"Montreal Gazette\", which is now the oldest continuing newspaper in the country.\n\nIn the 19th century, everything about print changed, and literature in its many forms became much more available. But educating the Canadian population in reading and writing was nevertheless a huge challenge. Concerned about the strong French Canadian presence in the colony, the British authorities repeatedly tried to help establish schools that were outside the control of religious authorities, but these efforts were largely undermined by the Catholic Church and later the Anglican clergy.\n\nFrom the early 1820s in Lower Canada, classical college curriculum, which was monopolized by the Church, was also subject to growing liberal and lay criticism, arguing it was fit first and foremost to produce priests, when Lower Canadians needed to be able to compete effectively with foreign industry and commerce and with the immigrants who were monopolizing trade (Curtis, 1985). Liberal and lay attempts to promote parish schools generated a reaction from the Catholic and later the Anglican clergy in which the dangers of popular literacy figured centrally. Both churches shared an opposition to any educational plan that encouraged lay reading of the Bible, and spokesmen for both warned of the evil and demoralizing tendencies of unregulated reading in general. Granted the power to organize parish schooling through the Vestry School Act of 1824, the Catholic clergy did nothing effective.\n\nDespite this, the invention of the printing press had laid the foundation for the modern era and universal social literacy, and so it is that with time, \"technologically, literacy had passed from the hands of an elite to the populace at large. Historical factors and sociopolitical conditions, however, have determined the extent to which universal social literacy has come to pass\".\n\nIn 1871 only about half of French Canadian men in Canada self-reported that they were literate, whereas 90 percent of other Canadian men said they could read and write, but information from the Canadian Families Project sample of the 1901 Census of Canada indicated that literacy rates for French Canadians and other Canadians increased, as measured by the ability of men between the ages of 16 and 65 to answer literacy questions. Compulsory attendance in schools was legislated in the late 19th century in all provinces but Quebec, but by then, a change in parental attitudes towards educating the new generation meant that many children were already attending regularly. Unlike the emphasis of school promoters on character formation, the shaping of values, the inculcation of political and social attitudes, and proper behaviour, many parents supported schooling because they wanted their children to learn to read, write, and do arithmetic. Efforts were made to exert power and religious, moral, economic/professional, and social/cultural influence over children who were learning to read by dictating the contents of their school readers accordingly. But educators broke from these spheres of influence and also taught literature from a more child-centred perspective: for the pleasure of it.\n\nEducational change in Québec began as a result of a major commission of inquiry at the start of what came to be called the \"Quiet Revolution\" in the early 1960s. In response to the resulting recommendations, the Québec government revamped the school system in an attempt to enhance the francophone population's general educational level and to produce a better-qualified labour force. Catholic Church leadership was rejected in favour of government administration and vastly increased budgets were given to school boards across the province.\n\nWith time, and with continuing inquiry into the literacy achievement levels of Canadians, the definition of literacy moved from a dichotomous one (either a person could, or couldn’t write his or her name, or was literate or illiterate), to ones that considered its multidimensionality, along with the qualitative and quantitative aspects of literacy. In the 1970s, organizations like the Canadian Association for Adult Education (CAAE) believed that one had to complete the 8th grade to achieve functional literacy. Examination of 1976 census data, for example, found that 4,376,655, or 28.4% of Canadians 15 years of age and over reported a level of schooling of less than grade 9 and were thus deemed not functionally literate. But in 1991, UNESCO formally acknowledged Canada's findings that assessment of educational attainment as proxy measure of literacy was not as reliable as was direct assessment. This dissatisfaction manifested itself in the development of actual proficiency tests that measure reading literacy more directly.\n\nCanada conducted its first literacy survey in 1987 which discovered that there were more than five million functionally illiterate adults in Canada, or 24 per cent of the adult population. Statistics Canada then conducted three national and international literacy surveys of the adult population — the first one in 1989 commissioned by the Human Resources and Skills Development Canada (HRSDC) department.\n\nThis first survey was called the \"Literacy Skills Used in Daily Activities\" (LSUDA) survey, and was modeled on the 1985 U.S. survey of young adults (YALS). It represented a first attempt in Canada to produce skill measures deemed comparable across languages. Literacy, for the first time, was measured on a continuum of skills. The survey found that 16% of Canadians had literacy skills too limited to deal with most of the printed material encountered in daily life whereas 22% were considered \"narrow\" readers.\n\nIn 1994-95, Canada participated in the first multi-country, multi-language assessment of adult literacy, the International Adult Literacy Survey (IALS). A stratified multi-stage probability sample design was used to select the sample from the Census Frame. The sample was designed to yield separate samples for the two Canadian official languages, English and French, and participants were measured on the dimensions of prose literacy, document literacy and quantitative literacy. The survey found that 42.2%, 43% and 42.2% of Canadians between the ages of 16 and 65 scored at the lowest two levels of Prose Literacy, Document Literacy and Quantitative Literacy, respectively. The survey presented many important correlations, among which was a strong plausible link between literacy and a country's economic potential.\n\nIn 2003, Canada participated in the Adult Literacy and Life Skills Survey (ALL). This survey contained identical measures for assessing the prose and document literacy proficiencies, allowing for comparisons between survey results on these two measures and found that 41.9% and 42.6% of Canadians between the ages of 16 and 65 scored at the lowest two levels of Prose Literacy and document literacy respectively. Further, Canadians’ mean scores also improved on both the prose and the document literacy scales. Energy production:36%, transportation: 24%, homes and businesses: 12%, industry: 11%, agriculture: 10%, and waste: 7%.\n\nThe OECD's Programme for the International Assessment of Adult Competencies (PIAAC) is expected to produce new comparative skill profiles in late 2013.\n\nIn the last 40 years, the rate of illiteracy in Mexico has been steadily decreasing. In the 1960s, because the majority of the residents of the federal capital were illiterate, the planners of the Mexico City Metro designed a system of unique icons to identify each station in the system in addition to its formal name. However, The INEGI´s census data of 1970 showed a national average illiteracy rate of 25.8%; the last census data puts the national average at 6.9%. Mexico still has a gender educational bias. The illiteracy rate for women in the last census was 8.1% compared with 5.6% for men. Rates differ across regions and states. Chiapas, Guerrero and Oaxaca, the states with the highest poverty rate, had greater than 15% illiteracy in 2010(17.8%, 16.7% and 16.3 respectively). In contrast, the illiteracy rates in the Federal District (D.F. / Mexico City) and in some northern states like Nuevo León, Baja California, and Coahuila were below 3% in the 2010 census (2.1%, 2.2%, 2.6% and 2.6% respectively).\n\nBefore the 20th century white illiteracy was not uncommon and many of the slave states made it illegal to teach slaves to read. By 1900 the situation had improved somewhat, but 44% of black people remained illiterate. There were significant improvements for African American and other races in the early 20th century as the descendants of former slaves, who had had no educational opportunities, grew up in the post Civil War period and often had some chance to obtain a basic education. The gap in illiteracy between white and black adults continued to narrow through the 20th century, and in 1979 the rates were about the same.\n\nFull prose proficiency, as measured by the ability to process complex and challenging material such as would be encountered in everyday life, is achieved by about 13% of the general, 17% of the white, and 2% of the African American population. However 86% of the general population had basic or higher prose proficiency as of 2003, with a decrease distributed across all groups in the full proficiency group vs. 1992 of more than 10% consistent with trends, observed results in the SAT reading score to the present (2015).\n\nBefore colonization, oral storytelling and communication composed most if not all Native American literacy. Native people communicated and retained their histories verbally—it was not until the beginning of American Indian boarding schools that reading and writing forms of literacy were forced onto Native Americans. While literacy rates of English increased, forced assimilation exposed Native children to physical and sexual abuse, unsanitary living conditions, and even death. Many students ran away in an attempt to hold on to their cultural identity and literary traditions that were relevant to their community. While these formalized forms of literacy prepared Native youth to exist in the changing society, they destroyed all traces of their cultural literacy. Native children would return to their families unable to communicate with them due to the loss of their indigenous language. In the 20th and 21st century, there is still a struggle to learn and maintain cultural language. But education initiatives and programs have increased overall—according to the 2010 census, 86 percent of the overall population of Native Americans and Alaska Natives have high school diplomas, and 28 percent have a bachelor's degree or higher.\n\nIn 1964 in Brazil, Paulo Freire was arrested and exiled for teaching peasants to read. Since democracy returned to Brazil, however, there has been a steady increase in the percentage of literate people. Educators with the Axé project within the city of Salvador, Bahía attempt to improve literacy rates among urban youth, especially youth living on the streets, through the use of music and dances of the local culture. They are encouraged to continue their education and become professionals.\n\nThe literacy rates in Africa vary significantly between countries. The highest registered literacy rate in the region is in Equatorial Guinea and Libya (both 94.2%), while the lowest literacy rate is in South Sudan (27%). Poorer youth in sub-Saharan Africa have fewer educational opportunities to become literate compared with wealthier families. They often must leave school because of being needed at home to farm or care for siblings.\nIn sub-Saharan Africa, the rate of literacy has not improved enough to compensate for the effects of demographic growth. As a result, the number of illiterate adults has risen by 27% over the last 20 years, reaching 169 million in 2010. Thus, out of the 775 million illiterate adults in the world in 2010, more than one fifth were in sub- Saharan Africa – in other words, 20% of the adult population. The countries with the lowest levels of literacy in the world are also concentrated in this region. These include Niger (28.7%), Burkina Faso (28.7%), Mali (33.4%), Chad (35.4%) and Ethiopia (39%), where adult literacy rates are well below 50%. There are, however, certain exceptions, like Equatorial Guinea, with a literacy rate of 94%.\n\nThe literacy rate of Algeria is around 70%: education is compulsory and free in Algeria up to age of 17.\n\nBotswana has among the highest literacy rates in the developing world with around 85% of its population being literate.\n\nBurkina Faso has a very low literacy rate of 28.7%. The government defines literacy as anyone at least 15 years of age and up who can read and write. To improve the literacy rate, the government has received at least 80 volunteer teachers. A severe lack of primary school teachers causes problems for any attempt to improve the literacy rate and school enrollment.\n\nEgypt has a relatively high literacy rate. The adult literacy rate in 2010 was estimated at 72%.\nEducation is compulsory from ages 6 to 15 and free for all children to attend. 93% of children enter primary school today, compared with 87% in 1994.\n\nDjibouti has an estimated literacy rate of 70%.\n\nAccording to the Ministry of Information of Eritrea, the nation has an estimated literacy rate of 80%.\n\nThe Ethiopians are among the first literate people in the world, having written, read, and created manuscripts in their ancient language of Ge'ez (Amharic) since the second century CE. All boys learned to read the Psalms around the age of 7. National literacy campaign introduced in 1978 increased literacy rates to between 37% (unofficial) and 63% (official) by 1984.\n\nGuinea has a literacy rate of 41%. The Guinea government defines literacy as anyone who can read or write who is at least 15 years old. Guinea was the first to use the Literacy, Conflict Resolution, and Peacebuilding project. This project was developed to increase agriculture production, develop key skills, resolve conflict, improve literacy, and numeracy skills. The LCRP worked within refugee camps near the border of Sierra Leone, however this project only lasted from 1999 to 2001. There are several other international projects working within the country that have similar goals.\n\nThe literacy rate in Kenya among people below 20 years of age is over 70%, as the first 8 years of primary school are provided tuition-free by the government. In January 2008, the government began offering a restricted program of free secondary education. Literacy is much higher among the young than the old population, with the total being about 53% for the country. Most of this literacy, however, is elementary—not secondary or advanced.\n\nMali has one of the lowest literacy rates in the world, at 33.4%, with males having a 43.1% literacy rate and females having a 24.6% literacy rate. The government defines literacy as anyone who is at least 15 and over who can read or write. The government of Mali and international organizations in recent years has taken steps to improve the literacy rate. The government recognized the slow progress in literacy rates and began created ministries for basic education and literacy for their national languages in 2007. To also improve literacy the government planned to increase its education budget by 3%, when this was purposed it was at 35% in 2007. The lack of literate adults causes the programs to be slowed. The programs need qualified female trainers is a major problem because most men refuse to send female family members to be trained under male teachers.\n\nFree education in Mauritius didn't proceed beyond the primary level until 1976, so many women now in their 50s or older left school at age 12. The younger generation (below 50) are however extremely well educated with very high educational expectations placed upon pupils. Education is today free from pre-primary to tertiary (only admission fees remain at University level). Most professional people have at least a bachelor's degree. Mauritian students consistently rank top in the world each year for the Cambridge International O Level, International A and AS level examinations. Most Mauritian children, even at primary level, attend tuition after school and at weekends to cope with the highly competitive public school system where admission to prestigious public colleges (secondary) and most sought after university courses depend on merit based academic performance.\n\nThe adult literacy rate was estimated at 89.8% in 2011. Male literacy was 92.3% and Female literacy 87.3%.\n\nNiger has an extremely low literacy rate at 28.7%. However, the gender gap between males and females is a major problem for the country, men have a literacy rate of 42.9% and women a literacy rate of 15.1%. The Nigerien government defines literacy as anyone who can read or write over the age of 15. The Niass Tijaniyya, a predominate group of the Sufi brotherhoods, has started anti-poverty, empowerment, and literacy campaigns. The women in Kiota had not attempted to improve their education, or economic standing. Saida Oumul Khadiri Niass, known as Maman, through talking to men and women throughout the community changed the community's beliefs on appropriate behavior for women because the community recognized she was married to a leader of the Niass Tijaniyya. Maman's efforts has allowed women in Kiota to own small businesses, sell in the market place, attend literacy classes, and organize small associations that can give micro loans. Maman personally teaches children in and around Kiota, with special attention to girls. Maman has her students require instructor permission to allow the girls' parents to marry their daughters early. This increases the amount of education these girls receive, as well as delaying marriage, pregnancy, and having children.\n\nSenegal has a literacy rate of 49.7%; the government defines literacy as anyone who is at least 15 years of age and over who can read and write. However, many students do not attend school long enough to be considered literate. The government did not begin actively attempting to improve the literacy rate until 1971 when it gave the responsibility to Department for Vocational Training at the Secretariat for Youth and Sports. This department and subsequent following departments had no clear policy on literacy until the Department of Literacy and Basic Education was formed in 1986. The government of Senegal relies heavily on funding from the World Bank to fund its school system.\n\nThere is no reliable data on the nationwide literacy rate in Somalia. A 2013 FSNAU survey indicates considerable differences per region, with the autonomous northeastern Puntland region having the highest registered literacy rate at 72%.\n\nThe Sierra Leone government defines literacy as anyone over the age of 15 who can read and write in English, Mende, Temne, or Arabic. Official statics put the literacy rate at 43.3%. Sierra Leone was the second country to use the Literacy, Conflict Resolution and Peacebuilding project. However, due to fighting near the city where the project was centered causing the project to be delayed until an arms amnesty was in place.\n\nUganda has a literacy rate of 66.8%.\n\nZimbabwe has a high literacy rate of 86.5% (2016 est.).\n\n Afghanistan has one of the lowest literacy rates in the world at 28.1% with males having a literacy rate of 43.1% and females with a literacy rate of 12.6%. The Afghan government considers someone literate if they are 15 years of age or older, and if they can read and write. To improve the literacy rate U.S. military trainers have been teaching Afghan Army recruits how to read before teaching to fire a weapon. U.S. commanders in the region estimate that as many as 65% of recruits may be illiterate.\n\nThe PRC conducts standardized testing to assess proficiency in Standard Chinese, known as \"putonghua,\" but it is primarily for foreigners or those needing to demonstrate professional proficiency in the Beijing dialect. Literacy in languages like Chinese can be assessed by reading comprehension tests, just as in other languages, but historically has often been graded on the number of Chinese characters introduced during the speaker's schooling, with a few thousand considered the minimum for practical literacy. Social science surveys in China have repeatedly found that just more than half the population of China is conversant in spoken putonghua.\n\nLiteracy is defined by the Registrar General and Census Commissioner of India, as \"[the ability of] a person aged 7 years and above [to]... both write and read with understanding in any language.\" According to the 2011 census, 74.04 percent.\n\nLaos has the lowest level of adult literacy in all of Southeast Asia other than East Timor.\n\nObstacles to literacy vary by country and culture as writing systems, quality of education, availability of written material, competition from other sources (television, video games, cell phones, and family work obligations), and culture all influence literacy levels. In Laos, which has a phonetic alphabet, reading is relatively easy to learn—especially compared to English, where spelling and pronunciation rules are filled with exceptions, and Chinese, with thousands of symbols to be memorized. But a lack of books and other written materials has hindered functional literacy in Laos, where many children and adults read so haltingly that the skill is hardly beneficial.\n\nA literacy project in Laos addresses this by using what it calls \"books that make literacy fun!\" The project, Big Brother Mouse, publishes colorful, easy-to-read books, then delivers them by holding book parties at rural schools. Some of the books are modeled on successful western books by authors such as Dr. Seuss; the most popular, however, are traditional Lao fairy tales. Two popular collections of folktales were written by Siphone Vouthisakdee, who comes from a village where only five children finished primary school.\n\nBig Brother Mouse has also created village reading rooms, and published books for adult readers about subjects such as Buddhism, health, and baby care.\n\nIn Pakistan, the National Commission for Human Development (NCHD) aims to bring literacy to adults, especially women.\nISLAMABAD - UNESCO Islamabad Director Kozue Kay Nagata has said, \"Illiteracy in Pakistan has fallen over two decades, thanks to the government and people of Pakistan for their efforts working toward meeting the Millennium Development Goals\". \"Today, 70 percent of Pakistani youths can read and write. In 20 years, illiterate population has been reduced significantly\", she said while speaking at a function held in connection with International Literacy Day.\n\nHowever, she also emphasised on the need to do more to improve literacy in the country and said, \"The proportion of population in Pakistan lacking basic reading and writing is too high. This is a serious obstacle for individual fulfillment, to the development of societies, and to mutual understanding between peoples.\" Referring to the recent national survey carried out by the Ministry of Education, Trainings and Standards in Higher Education with support of UNESCO, UNICEF, and provincial and areas departments of education, Nagata pointed out that, in Pakistan, although primary school survival rate is 70 percent, gender gap still exists with only 68 percent of girls’ survival rate compared to 71 percent for boys. Specifically in the case of Punjab, she said, primary school survival rate today is better with 76 percent, but not without a gender gap of 8 percent points with 72 percent girls’ survival rate compared to 80 percent for boys. She also pointed out that average per student spending in primary level (age 5-9) was better in Punjab: Rs 6,998, compared to the national average. In Balochistan, although almost the same amount (Rs 6,985) as in Punjab is spent per child, the primary school survival rate is only 53 percent. Girls’ survival rate is slightly better with 54 percent than that of boys which is 52 percent. Literate Pakistan Foundation, a non-profit organization, which was established in 2003, is a case study, which brings to light the solutions for removing this menace from its roots. It works to improve rate of literacy in Pakistan.\n\nThe data of the survey shows that in Khyber Pakhtunkhwa, primary school survival rate is 67 percent which is lower than the national average of 70 percent. Furthermore, gender gap also exists with only 65 percent of girls’ survival rate compared to that of boys which is 68 percent. Per-student education expenditure in primary level (age 5-9) in Khyber Pakhtunkhwa is Rs 8,638. In Sindh, primary school survival rate is 63percent, with a gender gap of only 67 percent of girls’ survival rate compared to 60 percent for boys. Per student education expenditure in primary level (age 5-9) in Sindh is Rs 5,019. Nagata made reference to the survey report and mentioned that the most common reason in Pakistan for children (both boys and girls) of age 10 to 18 years leaving school before completing primary grade is \"the child not willing to go to school\", which may be related to quality and learning outcome. She said, however, and sadly, for the girls living in rural communities the second highest reason for dropout is \"parents did not allow\" which might be related to prejudice and cultural norm against girls.\n\nEarly Filipinos devised and used their own system of writings from 300 BC, which derived from the Brahmic family of scripts of Ancient India. Baybayin became the most widespread of these derived scripts by the 11th century.\n\nEarly chroniclers, who came during the first Spanish expeditions to the islands, noted the proficiency of some of the natives, especially the chieftain and local kings, in Sanskrit, Old Javanese, Old Malay, and several other languages.\n\nDuring the Spanish colonization of the islands, reading materials were destroyed to a far much less extent compared to the Spanish colonization of the Americas. Education and literacy was introduced only to the Peninsulares and remained a privilege until the Americans came.\n\nThe Americans introduced the public schools system to the country which drove literacy rates up. English became the lingua franca in the Philippines. It was only during a brief period in the Japanese occupation of the Philippines that the Japanese were able to teach their language in the Philippines and teach the children their written language.\n\nAfter World War II, the Philippines had the highest literacy rates in Asia. It nearly achieved universal literacy once again in the 1980s and 1990s. Ever since then, the literacy rate has plummeted only to start regaining a few percentage years back.\n\nThe DepEd, CHED, and other academic institutions encourage children to improve literacy skills and knowledge. The government has a program of literacy teaching starting in kindergarten. New reforms are being brought in shifting to a K-12 system which will teach children their regional languages before English, as opposed to the ten-year basic education program which teaches English and Filipino, the country's two official languages, from Grade 1.\n\nWith a literacy rate of 92.5%, Sri Lanka has one of the most literate populations amongst developing nations. Its youth literacy rate stands at 98%, computer literacy rate at 35%, and primary school enrollment rate at over 99%. An education system which dictates 9 years of compulsory schooling for every child is in place. The free education system established in 1945, is a result of the initiative of C. W. W. Kannangara and A. Ratnayake. It is one of the few countries in the world that provide universal free education from primary to tertiary stage.\n\nApproximately 56% of Australians aged 15 to 74 achieve Level 3 literacy or above Australian Bureau of Statistics 2011-2012 and 83% of five-year-olds are on track to develop good language and cognitive skills Australian Early Development Census 2012 summary report. In 2012-2013, Australia had 1515 public library service points, lending almost 174 million items to 10 million members of Australian public library services, at an average per capita cost of just under AU$45 Australian Public Library Statistics 2012-2013.\n\n\n\n"}
{"id": "227277", "url": "https://en.wikipedia.org/wiki?curid=227277", "title": "Meaningless statement", "text": "Meaningless statement\n\nA meaningless statement posits nothing of substance with which one could agree or disagree. In the context of logical arguments, the inclusion of a meaningless statement in the premises will undermine the validity of the argument since that premise can neither be true nor false.\n\nThere are many classes of meaningless statement:\n\n\n"}
{"id": "1419264", "url": "https://en.wikipedia.org/wiki?curid=1419264", "title": "Modistae", "text": "Modistae\n\nThe Modistae (Latin for \"Modists\"), also known as the speculative grammarians, were the members of a school of grammarian philosophy known as Modism or speculative grammar, active in northern France, Germany, England, and Denmark in the 13th and 14th centuries. Their influence was felt much less in the southern part of Europe, where the somewhat opposing tradition of the so-called \"pedagogical grammar\" never lost its preponderance. \nWilliam of Conches, Peter Helias, and Ralph of Beauvais, also referred to as speculative grammarians predate the Modist movement proper.\n\nThe Modist philosophy was first developed by Martin of Dacia (died 1304) and his colleagues in the mid-13th century, though it would rise to prominence only after its systematization by Thomas of Erfurt decades later, in his treatise \"De modis significandi seu grammatica speculativa\", probably written in the first decade of the 14th century. Until the early twentieth-century this work was assumed to have been authored by John Duns Scotus. Widely reproduced and commented upon in the Middle Ages, it remains the most complete textbook of Modist speculative grammar. The mistaken authorship arose out of the natural affinity of Erfurt's speculative grammar with Scotus's metaphysics.\n\nThe philosophy of the Modistae, as indicated by their name, was based on a theory of 'modes' of meaning in language which was tripartite: modes of being (\"modi essendi\"), modes of understanding (\"modi intelligendi\"), and modes of signifying (\"modi significandi\"). To the Modistae, the various parts of speech were viewed as representing reality in terms of these modes. The \"modi essendi\" are objectively existent qualities in an object of understanding, the \"modi intelligendi\" the understanding's means of representing the \"modi essendi\", and the \"modi significandi\" grammar's means of representing the \"modi intelligendi\" in language. This corresponds to Aristotle's tripartite semantic theory of \"words\" representing \"concepts\" which represent \"objects\".\n\nOpposing nominalism, they assumed that the analysis of the grammar of ordinary language was the key to metaphysics. For the Modistae, grammatical forms, the \"modi significandi\" of verbs, nouns, and adjectives, comprise the deep ontological structure of language, which objectively reflects reality. Their work predicted the concept of universal grammar, suggesting that universal grammatical rules may be extracted from all living languages. Roger Bacon may have given the movement inspiration with his observation that all languages are built upon a common grammar, a shared foundation of ontologically anchored linguistic structures. He argued grammar is substantially the same in all languages, even though it may undergo accidental variations between languages.\n\nThere are parallels between speculative grammar and phenomenology, a fact that was picked up early on by Martin Heidegger, who wrote his first book, \"Die Kategorien-und Bedeutungslehre des Duns Scotus\", on Thomas of Erfurt's treatise (at that time still mistakenly attributed to Duns Scotus).\n\n\n\n\n"}
{"id": "2324604", "url": "https://en.wikipedia.org/wiki?curid=2324604", "title": "Monguor language", "text": "Monguor language\n\nThe Monguor language (; also written Mongour and Mongor) is a Mongolic language of its Shirongolic branch and is part of the Gansu–Qinghai sprachbund. There are several dialects, mostly spoken by the Monguor people. A written script was devised for Huzhu Monguor (Mongghul) in the late 20th century, but has been little used. A division into two languages, namely Mongghul in Huzhu Tu Autonomous County and Mangghuer in Minhe Hui and Tu Autonomous County, is considered necessary by some linguists. While Mongghul was under strong influence from Tibetan, the same holds for Mangghuer and Chinese, and local dialects of Chinese such as Gangou were in turn influenced by Monguor.\n\nMonguor has five vowels: /a, e, i, o, u/.\n\nMongolian numerals such as the following are only in use in the Mongghul dialect, while Mangghuer speakers have switched to counting in Chinese. Note that while the Mongolian script has only \"arban\" for 'ten', Middle Mongolian *\"harpa/n\" including *\"h\" can be reconstructed from the scripts.\nE. Gaspardone\nBulletin de l'Ecole française d'Extrême-Orient Année 1933 Volume 33 Numéro 1 p. 1014\nhttp://www.persee.fr/doc/befeo_0336-1519_1933_num_33_1_4683\n\n"}
{"id": "31507057", "url": "https://en.wikipedia.org/wiki?curid=31507057", "title": "Online speech therapy", "text": "Online speech therapy\n\nOnline speech therapy or telepractice is the use of technology to provide speech therapy via high speed internet, webcam, headset with microphone or any other form of communication. Online therapy is a clinical arrangement where the patient and a speech-language certified pathologist communicate and interact face-to-face over the Internet. The session involves a suite of therapeutic exercises including listening, speaking, reading and writing. The recorded videos are assessed by the pathologist to generate an activity report for evaluating progress and usage.\n\nTelepractice is a method of reaching students and individuals in any distant location. Telepractice is defined by the American Speech–Language–Hearing Association (ASHA) as the use of technology to provide speech therapy services to remote regions. Janet Brown, the Director of Healthcare services in SLP at ASHA has stated \"research shows that with telepractice a speech-language pathologist can provide speech therapy services, with the same results, as being there in person.\"\n\nAssessment for online speech therapy consists of an informal oral exam by a licensed trained professional through video conferencing or a web application. Patients are initially screened for communication disorders with diagnosis and consultation for provision counseling including cognitive aspects of communication, syntax, hypophonia and upper aerodigestive functions. The therapist and patient communicate via telecommunication technology where they can interact in real time. Therapy may cover speech sound production, fluency, language, cognition and written language.\n\nThe therapists create an assessment document or report that is updated after every session. The document is reported to the parents or the referral source in compliance with HIPAA and FERPA. The Health Insurance Portability and Accountability Act also known as HIPAA is a federal law that protects patient medical records. HIPAA specifically protects “individually identifiable health information.” The Family Educational Rights and Privacy Act known as FERPA is a federal law that protects student education records. FERPA gives parents certain rights with respect to their children’s education records until they turn 18 or transfer to a school higher than the high school level, thus making them “eligible students.” Clinical departments in Universities also offer speech and language therapy services where they keep recorded video of sessions between clinicians and patients secured through password security services.\n\nOnline speech therapy courses are offered by professional associations, Universities and cyber schools for treatment of communication disorders. The minimum eligibility for an online speech therapy course is a bachelor's degree for Master's entry-level field and master's degree for CScD offered by professional associations and Universities in the United States. The speech therapist course is not available for Bachelors or under graduate degree level in the United States. The pathologists are required to attain a minimum of 400 clinical hours to complete the course. In Asian countries, the course is open for Bachelors level degree program offered by Universities.\n\nSpeech Pathologist are also required to complete 400 hours clinical hours and pass the KASA exams in the United States.\n"}
{"id": "44364067", "url": "https://en.wikipedia.org/wiki?curid=44364067", "title": "Paradigm case argument", "text": "Paradigm case argument\n\nIn analytic philosophy, the paradigm case argument is an argument which is applied as a rebuttal to the claim that certain concepts, such as free will or knowledge, are meaningless. The paradigm case argument is that if a term, such as \"knowledge\", is regularly applied to some cases and not to others, then that term (and the concept it refers to) cannot truly be undefined, as it clearly has some kind of definition in practice. The argument is so named because it often takes the form of pointing out a \"paradigm case\"—a case which unambiguously falls under the common definition of the term, and so can be taken as a definite instance of the supposedly non-existent concept. This argument was commonly applied during the flourishing of linguistic philosophy.\n"}
{"id": "2691458", "url": "https://en.wikipedia.org/wiki?curid=2691458", "title": "Poverty of the stimulus", "text": "Poverty of the stimulus\n\nPoverty of the stimulus (POS) is the argument from linguistics that children are not exposed to rich enough data within their linguistic environments to acquire every feature of their language. This is considered evidence contrary to the empiricist idea that language is learned solely through experience. The claim is that the sentences children hear while learning a language do not contain the information needed to home in on the grammar of the language.\n\nThe POS is often used as evidence for universal grammar. This is the idea that all languages conform to the same structural principles, which define the space of possible languages.\n\nBoth poverty of the stimulus and universal grammar are terms that can be credited to Noam Chomsky. Chomsky coined the term \"poverty of the stimulus\" in 1980, however he had argued for the idea since his 1959 review of B.F. Skinner's Verbal Behavior. The POS is also related to Nelson Goodman's new riddle of induction.\n\nAn argument from the poverty of the stimulus generally takes the following structure:\n\n\nChomsky coined the term \"poverty of the stimulus\" in 1980. This idea is closely related to what Chomsky calls \"Plato's Problem\". He outlined this philosophical approach in the first chapter of the \"Knowledge of Language\" in 1986. Plato's Problem traces back to \"Meno\", a Socratic dialogue. In Meno, Socrates unearths knowledge of geometry concepts from a servant who was never explicitly taught them. Plato's Problem directly parallels the idea of the innateness of language, universal grammar, and more specifically the poverty of the stimulus argument because it reveals that people's knowledge is richer than what they are exposed to. Chomsky illustrates that humans are not exposed to all structures of their language, yet they fully achieve knowledge of these structures.\n\nLinguistic nativism is the theory that humans are born with some knowledge of language. One acquires a language not entirely through experience. According to Noam Chomsky, \"The speed and precision of vocabulary acquisition leaves no real alternative to the conclusion that the child somehow has the concepts available before experience with language and is basically learning labels for concepts that are already a part of his or her conceptual apparatus.\" Chomsky's view that the humans possess an innate faculty of language is shared by Steven Pinker. One of the most significant arguments generative grammarians have for linguistic nativism is the poverty of the stimulus argument.\n\nPullum and Scholz frame the poverty of the stimulus argument by examining all of the ways that the input is insufficient for language acquisition. First, children are exposed only to positive evidence. They do not receive explicit correction or instruction about what is not possible in the language. Second, the input that children receive is degenerate in terms of scope and quality. Degeneracy of scope means that the input does not contain information about the full extent of any grammatical rules. Degeneracy of quality means that children are exposed to speech errors, utterances by nonnative speakers, and false starts, potentially obscuring the grammatical structure of the language. Furthermore, the linguistic data each child is exposed to is different and so the basis for learning is idiosyncratic. However, despite these insufficiencies, children eventually acquire the grammar of the language they are exposed to. Further, other organisms in the same environment do not. From the nativists' point of view, the insufficiency of the input leads to the conclusion that humans are hard-wired with a UG and thus support the innateness hypothesis.\n\nHowever, the argument that the poverty of stimulus supports the innateness hypothesis remains controversial. For example, Fiona Cowie claims that the Poverty of Stimulus argument fails \"on both empirical and conceptual grounds to support nativism\".\n\nAn overarching theme in examples provided as evidence for the poverty of the stimulus is that children acquire grammatical rules based on evidence that is consistent with multiple generalizations. And since children are not instructed in the grammar of their language, the gap must be filled in by properties of the learner.\n\nIn general, pronouns can refer to any prominent individual in the discourse context. However, a pronoun cannot find its antecedent in certain structural positions, as defined by the Binding Theory. For example, the pronoun \"he\" can refer to the Ninja Turtle in (1) but not (2), above. Given that speech to children does not indicate what interpretations are impossible, the input is equally consistent with a grammar that allows coreference between \"he\" and \"the Ninja Turtle\" in (2) and one that does not. But, since all speakers of English recognize that (2) does not allow this coreference, this aspect of the grammar must come from some property internal to the learner.\n\nThe sentences in (1) and (2) illustrate the active-passive alternation in English. The Noun Phrase after the verb in the active (1) is the subject in the passive (2). Data like (2) would be compatible with a passive rule stated in terms of linear order (move the 1st NP after the verb) or syntactic structure (move the highest NP after the verb). The data in (3-5) illustrate that the actual rule is formulated in terms of structure. If it were stated in terms of linear order, then (4) would be ungrammatical and (5) would be grammatical. But the opposite is true. However, children may not be exposed to sentences like (3-5) as evidence in favor of the correct grammar. Thus, the fact that all adult speakers agree that (4) is grammatical and (5) is not suggests that the linear rule was never even considered and that children are predisposed to a structure based grammatical system.\n\nThe English word \"one\" can refer back to a previously mentioned property in the discourse. For example in (1), \"one\" can mean \"ball\". \nIn (2), one is interpreted as \"red ball.\" However, even if a speaker intends (2) in this way, it would be difficult to distinguish that interpretation from one in which \"one\" simply meant \"ball\". This is because when a speaker refers to a red ball, they are also referring to a ball since the set of red balls is a subset of balls in general. 18-month-olds, like adults, show that they believe 'one' refers to 'red ball' and not 'ball'. The evidence available to children is systematically ambiguous between a grammar in which \"one\" refers back to Nouns and one in which \"one\" refers back to noun phrases. Despite this ambiguity, children learn the more narrow interpretation, suggesting that some property other than the input is responsible for their interpretations.\n\nIn Wh-questions, the Wh-word at the beginning of the sentence (the filler) is related to a position later in the sentence (the gap). This relation can hold over an unbounded distance, as in (1). However, there are restrictions on the gap positions that a filler can be related to. These restrictions are called syntactic islands (2). Because questions with islands are ungrammatical, they are not included in the speech that children hear—but neither are grammatical Wh-questions that span multiple clauses. Because the speech children are exposed to is consistent with grammars which have island constraints and grammars which don't, something internal to the child must contribute this knowledge.\n\nBergelson & Idsardi (2009) presented adults with words drawn from an artificial language. The words contained 3 CV syllables. If the last vowel was long, then it bore stress. Otherwise, stress fell on the first syllable. This pattern is consistent with two grammars. In one grammar, a long vowel bears stress if it is the last segment in the word. This is a rule based on absolute finality. In the other grammar, a long vowel bears stress only if it is the last vowel in the word (i.e., even if it is not the last segment of the word). This is a rule based on relative finality. In natural languages stress rules make reference to relative finality but not to absolute finality. After being exposed to these words, participants were then tested to see whether they thought that a word with a long vowel in a closed syllable (CVVC) would bear stress. If it did, then that would be consistent with the relative-final grammar, but not with the absolute-final grammar. English-speaking adults (tested through computer software) were more likely to accept the words from the relative-final grammar than from the absolute-final grammar. Since the data they were exposed to was equally consistent with both grammars, and since neither rule is a rule of English, the source of this decision must have come from the participants, not from any aspect of their experience. In addition, eighth-month-old children (tested via the Headturn Preference Procedure) were found to have the same preference as adults. Given that this preference could not have come from their exposure to either the artificial language or to their native language, the researchers concluded that human language acquisition mechanisms are \"hardwired\" to lead infants towards certain generalizations, consistent with the argument for the poverty of the stimulus.\n\nHalle (1978) argues that the morphophonological rule governing the English plural produces forms that are consistent with two grammars. In one grammar, the plural is pronounced as [s] if it follows one of the sounds [p, t, k, f, 𝝷]; otherwise it is pronounced as [z]. In the other grammar, the plural is pronounced as [s] if it follows a voiceless consonant. These rules are exactly equal in their coverage of English since the set of consonants that triggers the [s] pronunciation is identical in the two cases. However, Halle also observes that English speakers consistently pluralize the German name \"Bach\" (pronounced \"/bax/\") as \"/baxs/\", despite not having any experience with the \"/x/\" sound, which is nonexistent in English. Since there is \"no indication\" that speakers could have acquired this knowledge, Halle argues that the tendency to build rules in terms of natural classes comes from a factor internal to the child and not from their experience.\n\nThe poverty of the stimulus also applies in the domain of word learning. When learning a new word, children are exposed to examples of the word's referent, but not to the full extent of the category. For example, in learning the word \"dog\", a child might see a German Shepherd, a Great Dane and a Poodle. How do they know to extend this category to include Dachshunds and Bulldogs? The situations in which the word is used cannot provide the relevant information. Thus, something internal to learners must shape the way that they generalize. This problem is closely related to Quine's gavagai problem.\n\nIn other cases, words refer to aspects of the world that cannot be observed directly. For example Lila Gleitman poses a POS argument with respect to verbs that label mental states. She observes that a learner cannot see inside another person's mind, and so an utterance of \"Kim thinks that it is raining\" is likely to occur in the same kinds of contexts as \"Kim wonders if it is raining\" or even \"Kim wants it to rain\". If no aspect of the context can determine whether a mental state verb refers to thinkings, wanting or wonderings, then some aspect of children's minds must direct their attention to other cues. Thus, our ability to learn these word meanings must be shaped by factors internal to the child and not simply from the conditions of their use.\n\nSome researchers argue that the poverty of the stimulus argument, which supports nativist theorizing, does not disprove the hypothesis that language is learned entirely from external sources. Some argue that nativist views reflect a failure to imagine how the input could support specific grammatical conclusions in the absence of innate structure. Other areas of criticism range from discussions about whether the poverty of the stimulus can be solved not through innate linguistic knowledge, but from other capacities like social cognition or statistical learning.\n\nThe empiricist views suggest that language can be learned with mental processes originally meant for other modes of cognition, and that there need not be a concept of innateness in order to account for the difference between the input a child receives versus the language they develop. Natural languages display statistical cues that children are able to learn from. Some argue that the ability to learn by statistical pattern matching can solve problems that nativists argue require innate knowledge.\n\nSome researchers also argue that the POS problem can be overcome through implicit negative evidence or indirect negative evidence.\n\n\n"}
{"id": "17640957", "url": "https://en.wikipedia.org/wiki?curid=17640957", "title": "Processability theory", "text": "Processability theory\n\nProcessability theory is a theory and a model of second language acquisition developed by Manfred Pienemann that touches the linguistic structures that surface in the learning of a second language. The theory has been used as a framework by several scientists from Europe and Australia.\n\nProcessability theory is part of the cognitive approach to second language acquisition that attempts to increase understanding of the ways L2 learners restructure their interlanguage knowledge systems to be in greater conformity to L2 structures. Processability theory states that learners restructure their L2 knowledge systems in an order of which they are capable at their stage of development. For instance, in order to acquire the correct morphological and syntactic forms for English questions, learners must transform declarative English sentences. They do so by a series of stages, consistent across learners. Clahsen proposed that certain processing principles determine this order of restructuring. Specifically, he stated that learners first, maintain declarative word order while changing other aspects of the utterances, second, move words to the beginning and end of sentences, and third, move elements within main clauses before subordinate clauses.\n\nProcessability Theory is now a mature theory of grammatical development of learners' interlanguage. It is cognitively founded (hence applicable to any language), formal and explicit (hence empirically testable), and extended, having not only formulated and tested hypotheses about morphology, syntax and discourse-pragmatics, but having also paved the way for further developments at the interface between grammar and the lexicon and other important modules in SLA.\n\nAmong the most important SLA theories recently discussed in Van Patten (2007), no other can accommodate such a variety of phenomena or seems able to offer the basis for so many new directions. Ten years have gone by since Pienemann’s first book-length publication on PT in 1998; and before that, it took almost two decades to mould into PT the initial intuition by the ZISA team that the staged development of German word order could be explained by psycholinguistic constraints universally applicable to all languages (Pienemann 1981; Clahsen, Meisel & Pienemann 1983). In these three decades, the whole field of SLA has grown exponentially. PT has paralleled this growth, and widened its scope in several directions. First, ZISA’s intuitions have been applied to English (Pienemann & Johnston 1984; Pienemann, Johnston & Brindley 1988, Pienemann 1989), then PT has expanded its typological validation from German and English to different languages, such as Swedish and other Scandinavian languages (Håkansson 1997, Glahn et al. 2001), Arabic (e.g., Mansouri 1995; 2005), Italian (e.g. Di Biase & Kawaguchi 2002; Di Biase 2007; Bettoni, Di Biase & Nuzzo 2009), French (Ågren 2009), Chinese (e.g. Zhang 2004, 2005), and Japanese (e.g. Di Biase & Kawaguchi 2002, 2005).\n\nSecondly, PT’s framework has been substantially widened by including Bresnan’s (2001) Lexical Mapping Theory, and thus adding a discourse pragmatically motivated syntactic component (Pienemann, Di Biase & Kawaguchi 2005) to its first syntactically motivated morphological module. Thirdly, developmentally-moderated transfer from L1 (e.g., Pienemann, Di Biase, Kawaguchi & Håkansson 2005a; Pienemann, Di Biase, Kawaguchi & Håkansson 2005b). Fourthly, PT’s plausibility has been tested in language situations other than L2 ones, such as monolingual and bilingual language acquisition (e.g., Håkansson 2001, 2005; ItaniAdams 2006), among children with Specific Language Impairment (e.g., Håkansson 2001; 2005), and in the origins of creole languages (Plag 2008a, 2008b).\n\nFinally, the range of the original applications of PT to language testing and language teaching has also expanded over the years, involving several new ways of testing and teaching situations (e.g., Iwasaki 2004, 2008, ask Bruno; Pienemann & Keßler 2007), and new languages (e.g. Di Biase 2008; Yamaguchi 2009). Ensuing publications in all these PT strands during such a long period of growth have had their own agendas and purposes. Furthermore, not only PT itself but also its feeder disciplines have developed in new directions, crucially among them psycholinguistics for language production and theoretical linguistics for language knowlwedge. As a consequence, it is not surprising that readers unfamiliar with PT's history may at times be confused by differences in the presentation of the theory, its use of terminology, and reliance on its theoretical bases.\n"}
{"id": "57631881", "url": "https://en.wikipedia.org/wiki?curid=57631881", "title": "Share of throat", "text": "Share of throat\n\nShare of throat is a beverage industry term that refers to the proportion of the world's beverage consumption produced by a single company. The term was originally coined by Coca-Cola as \"throat share\", in order to measure how much of the world's beverages were theirs, but is now more commonly referred to as \"share of throat\".\n"}
{"id": "4887910", "url": "https://en.wikipedia.org/wiki?curid=4887910", "title": "Speech and language pathology in school settings", "text": "Speech and language pathology in school settings\n\nSpeech-language pathology, also known as \"communication sciences and disorders\" in the United States, is a fast-growing profession that, according to the Bureau of Labor Statistics, offers about 120,000 jobs in the United States alone. The American Speech-Language-Hearing Association (ASHA) has 166,000 members, who are audiologists, speech-language pathologists, speech, language, and hearing scientists, and speech language pathology assistants. To begin practice in most areas of the United States, a prospective therapist must have an undergraduate degree (preferably in some area of communications) and a graduate degree (with two externships; usually about 2 to 2 1/2 years) in speech pathology. A 9-month, supervised clinical fellowship year is then completed, after which the Certificate of Clinical Competence (CCC) in speech pathology from the American Speech-Language-Hearing Association (ASHA) is granted. In order to be certified clinically competent the Praxis exam must be passed. In some areas the master's degree is not required. In some areas additional requirements must be met: an additional certification from ASHA in school speech pathology and audiology, certification in special education instruction, and/or and must have passed any other federal or state examinations for licensure and certification. To retain the ASHA license a minimum amount of continuing education must be completed. A doctorate is not currently required (as of June 2011), but that may change, as it has for many other areas of therapy. Speech-language pathology overlaps with many educational disciplines, such as communication sciences, linguistics, special education, and health care. This article will explore some of the fundamental elements of speech-language pathology, looking at the career in an educational setting.\n\nSpeech-Language Pathologists (SLP) are professionals who assess and diagnose individuals with speech, language, cognitive, and swallowing disorders. SLPs are informally referred to as \"speech therapist\"s. SLPs may also conduct research in the field, run a private practice, or work with large companies to improve employee-customer communication (American Speech-Language-Hearing Association). This article will focus on the aspects of speech-language pathology as practiced with young children in a school setting.\n\nFor most people, the terms \"speech\", \"language\", and \"communication\" have nearly the same definition. However, in the realm of speech-language pathology, there are important distinctions to be made.\n\nSpeech is the spoken production of language and the process through which sounds are produced. Several parts of the body work together to produce sound waves, and this motor production of speech is called articulation. The parts of the vocal tract involved with speech include the lips, tongue, teeth, throat, vocal folds, and lungs. Speech disorders affect the physical mechanisms of communication and cause problems with articulation or phonology. Examples of speech disorders include stuttering, lisping, and voice disorders.\n\nLanguage is a system used to represent thoughts and ideas. Language is made up of several rules that explain what words mean, how to make new words, and how to put words together to form sentences. A community must share the same language in order to attach meaning to utterances. The method of delivery of language may be visual (e.g., American Sign Language), auditory (e.g., English), and/or written. Humans are the only creatures innately capable of using language to discuss an endless number of topics. Language disorders can be developmental or acquired (e.g., specific language impairment and aphasia, respectively).\n\nCommunication is the exchange of information and ideas through the use of speech and language. The transfer of information is often spoken, but may also be implied through body language or contextual cues such as intonation or hesitation. Usually, communication is a four-step process:\n\n\nIf a problem occurs at any step of the process, the message might not be communicated. Without the ability to communicate through speech and language, we would not be able to tell a doctor that we have a stomach ache, choose food from a menu, or say “I love you” to our children. Communication is a most basic component of human nature and it develops before we are even conscious of it.\n\nPHAGIA & SWALLOWING\nThe process of grasping, biting, sucking, mucose making, swallowing and routine eating ability. Dysphagia can effect in many aspect of life. Dysphagia accurs in developments disorder and acquired brain and buccofacial anomalies or disease.\n\nSpeech-Language Pathologists (SLPs) have several options when seeking employment. One of the most popular is to secure a school-based position through an agency that specializes in this area. One of the largest and most respected agencies is Therapy Source, a nationwide organization founded in 2001, and based out of Plymouth Meeting, PA.\n\nEvery child develops at a different rate, but most go through the same stages. Listed below are the average ages of some important language and comprehension milestones as developed by the American Speech-Language-Hearing Association. Please note that like with any developmental timeline, these stages may be quite varied and perhaps met in a different order. A child who accomplishes these milestones differently may not necessarily have a developmental delay or speech disorder (and a child who hits these stages early is not necessarily a prodigy!).\n\n\nProblems can arise at any stage of development, as well as much later in life. They can be the result of a congenital defect, a developmental disorder, or an injury. If a problem is suspected, an assessment should be made by an SLP who can diagnose and treat communication disorders.\n\nIn a school setting, children are often screened when they start kindergarten. This process involves a rapid assessment to determine which children need further testing, diagnosis, or treatment. Often, a screening is a sort of informal interview between an SLP and a child or group of children. The child may be asked to give their name, count, pronounce the names of pictured objects, and answer open-ended questions. The purpose of these tasks is to elicit a brief language sample from the child which the SLP will use to evaluate articulation, fluency, and other aspects of speech. Screenings usually last about five minutes (Oyer 10).\n\nAfter a screening is done, an individual diagnosis must be made. This involves a one-on-one evaluation which may last two hours or more. If an individual has been referred for testing, either by a doctor, teacher, or other professional, the screening process is skipped and testing starts here. This session allows the SLP to gather information that will help in the diagnosis of a speech or language problem, as well as provide insight to possible causes, goals and objectives for therapy, and which techniques will work best for that individual. Individual evaluations often include the following components:\n\n\nAfter this evaluation, the SLP will review the results and information gathered and determine whether the individual would benefit from speech therapy. Goals and objectives of therapy are outlined and a specific treatment plan is created, drawing on the strengths and weaknesses and unique situation of that individual (Oyer 11).\n\nDisorders that affect children may affect adults differently, or even not at all. As the body grows and develops, the types of disorders that affect an individual change. Children typically exhibit developmental language disorders, but may also experience problems due to illness or injury.\n\nIn developing children, language disorders are often related to congenital disabilities or neurological or physiological results of childhood illness. These seemingly unrelated problems can seriously affect speech and language development. Children that have cognitive impairments are often delayed in development of communication skills. Different genetic syndromes that often cause cognitive impairment, such as Down syndrome or Williams syndrome, often affect different areas of speech. Children with autism tend to have difficulty communicating and expressing their emotions or desires. Sometimes this is due to specific problems with articulation or semantics, but often it is an issue of neurological development directly related to autism. Brain injuries, tumors, or seizures in children can also cause loss of language skills. Children with attention deficit hyperactivity disorder (ADHD) commonly have learning difficulties which also affect their language development. Emotional disturbances early in childhood can also affect the growth of basic communicative skills. Perhaps more obvious are the developmental and communicative consequences of childhood hearing loss (Boone 200-05).\n\nSome disorders commonly diagnosed in children:\n\nSome children have language development deficits that cannot be linked to neurological, intellectual, social, or motor causes. The child’s language skills grow much more slowly than those of typically developing children. While other children are speaking in complete sentences, using conjugated verb forms, the SLI child’s speech sounds telegraphic- lacking grammatical and functional morphemes (e.g., \"He go store\". rather than \"He goes to the store\".) Their vocabulary remains relatively small while other children are adding new words every day. The SLI child often produces short sentences in order to avoid embarrassment and may have problems understanding complex or figurative structures (such as metaphors or multi-clausal sentences). Problems due to SLI can also lead to learning disabilities as the child fails to understand information being presented in science, language arts, or math classes. Studies suggest that the cause of SLI is a biological difference in brain anatomy and development (Boone 204). Treatment objectives generally focus on vocabulary development, verb morphology, memory and recall, and narrative skills (Goffman 154).\n\nAn articulation disorder may be diagnosed when a child has difficulty producing phonemes, or speech sounds, correctly. When classifying a sound, speech pathologists refer to the manner of articulation, the place of articulation, and voicing. A speech sound disorder may include one or more errors of place, manner, or voicing of the phoneme.\n\nDifferent types of articulation disorders include:\n\n\nThe phonemes that present the greatest challenge for children include /l/ as in \"pull\", /r/ as in \"mirror\", /ʃ/ (\"sh\") as in \"shut\", /tʃ/ (\"ch\") as in \"church\", /dʒ/ (\"j\") as in \"fudge\", /z/ as in \"zoo\", /ʒ/ (\"zh\") as in \"measure\", /θ/ (\"th\") as in \"math\" and /ð/ (\"th\") as in \"this\" (Boone 112).\n\nArticulation disorders may be attributed to a variety of causes. A child with hearing loss may not be able to hear certain phonemes pronounced at certain frequencies, or hear the error in their own production of sounds. Oral-motor problems may also be at fault, such as \"developmental verbal dyspraxia\" (a problem with coordination of speech muscles) or \"dysarthria\" (abnormal facial muscle tone, often due to neurological problems such as cerebral palsy). Abnormalities in the structure of the mouth and other speech muscles can cause problems with articulation; cleft palate, tongue thrust, and dental-orthodontia abnormalities are some common examples. Finally, it is difficult for children to hear and produce all of the different phonemes of a given language. Development is slow, and may take up to seven years. Sometimes, as children grow, articulation problems fade and disappear without treatment. Often, however, therapy is necessary. Treatment therapies may target semantic differences related to phonemic differences (e.g., teaching a child the difference between \"toe\" and \"toad\", underlining the importance of the final consonant), physical-motor differences (e.g., using a mirror to show a child the correct tongue placement for a particular sound), or behavior-modification techniques (e.g., repetitive production through prompts and fun learning games). Support and reinforcement of therapy practices, both in the classroom and at home, are crucial to the success of articulation disorder treatment (Boone 122-24, 259-62, 274-76).\n\nIt is necessary to note the difference between articulation disorders and dialectical variations. There are several dialects of English spoken in the United States, influenced by socioeconomic status, geographic isolation, and other languages either brought to the U.S. by settlers or indigenous languages of the Native Americans. These social dialects are rule-governed and are not to be considered lesser than, but simply different from standard English. Examples of dialectical features that may be mistaken for articulation disorders include the 'r-lessness' of New York City speech in words like floor, here, and paper as well as the reduction of consonant clusters in African-American Vernacular English (AAVE). If a word ends with two or more consonants such as in \"cold\", and is followed by another word that begins with a consonant such as \"cuts\", \"cold\" is shortened to \"col\", producing \"col cuts\". These features alone should not be treated as articulation disorders to be 'cured' by speech therapy. However, it is possible for a child with a dialectal variation to also have a communication disorder. It is important for a speech pathologist to be able to tell the difference (Oyer 170).\n\nChildren may experience problems with their voice due to misuse or abnormalities in the vocal mechanisms. There are two types of voice disorders: those of phonation, and those of resonance. Both types can be the result of either abuse or physical structure. Voice disorders are among the most successfully treated speech and language problems because they can be solved with surgery or reconditioning of the voice (Boone 286).\n\nA phonation disorder is a problem with pitch, loudness, or intensity that originates in the vocal folds of the larynx. Phonation disorders may be \"functional\", caused by continuous yelling or throat clearing, excessive smoking, or speaking at an abnormally low frequency or pitch. The results may be an increased size or thickening of the vocal folds, lesions or polyps on the vocal folds, or problems with elasticity of the larynx. In these cases, the treatment involves resting the voice and learning to speak at optimal pitches and volumes, as well as eliminating external causes such as smoking. Phonation disorders may also be \"organic\", due to viral growths, cancer, paralysis of laryngeal nerves, surgical intubation, or external traumas such as being hit in the throat with a baseball. These problems may require surgical removal of growths or reconstruction of the larynx, accompanied by voice therapy (Boone 287-96).\n\nA resonance disorder occurs when any part of the vocal tract is altered or dysfunctional.\n\nIn the case of an \"oral\" resonance disorder, the tongue sits too high in the front or back of the mouth. When the tongue is too far forward in the mouth, a type of ‘baby voice’ occurs, and a lisp may also result. Treatment involves practicing back vowels such as /a/ in \"father\", /o/ in \"boat\", and /u/ in \"spoon\", accompanied by back consonants like /k/ in \"broke\" and /g/ in \"bog\". When the tongue sits toward the back of the mouth, the voice sounds dull, and problems with articulation at the front of the mouth may also occur. Treatment focuses on front consonants such as /w/ in \"where\" or \"work\", /p/ in \"pink\", /b/ in \"ball\", /f/ in \"laugh\", /v/ in \"leave\", /l/ in \"mail\", and /th/ in \"with\" or \"bath\" coupled with high-front vowels like /i/ in \"wheat\", /I/ in \"fit\", /e/ in \"pay\", /E/ in \"bet\", and /ae/ in \"slat\". This type of resonance disorder is commonly seen in children with severe hearing impairment.\n\n\"Nasal\" resonance disorders occur when the space between the oral and nasal cavities remains open or closed, producing a \"hypernasal\" or \"denasal\" resonance. Causes of hypernasality include paralysis of the velum, a short velum, or a cleft palate which allows air to escape to the nasal cavity. The speech of actor James Stewart is a recognizable example of hypernasality (although in this case, there was no structural problem; rather, he employed the highly nasal voice as part of his character). Denasality is often caused by a structural blockage which doesn’t allow air to pass between the oral and nasal cavities. A child experiencing denasality may sound like they have a bad cold. If a structural problem is to blame, surgery is the most common treatment. After surgery, or if there is no structural cause, voice therapy is often given, involving massive amounts of practice (Boone 305-12).\n\nAs a child’s language and vocabulary grows, they may struggle to locate a particular word or sound. Normal dysfluency occurs in developing children as a repetition of whole words or phrases while the child searches for a particular thought or word. Around age three-and-a-half, children may compulsively repeat words or phrases. This tends to fade by the time the child is five. Stuttering, in contrast, results in repeated or prolonged speech sounds or syllables. Often, involuntary blocks in fluency will be accompanied by muscle tension due to frustration. The mouth may tighten up or the eyes may blink rapidly. A child may become so embarrassed by stuttering that they talk as little as possible to avoid the struggle. This may have serious academic and social implications. The cause of stuttering is unknown, yet widely debated. Most theories suggest emotional, psychological, or neurological origins. Psychological treatment aims at improving the self-image of the child and the child’s attitude toward the problem, while other therapies attempt to increase fluency by modifying the rhythm and rate of speech (Boone 316-29, 335-38).\n\nAccording to the National Institutes of Health, it is estimated that, in the United States,\n\n\nAccording to the United States Department of Education, speech, language, and hearing impairments account for 20.1 percent of all Special Education students in the United States.\n\nCommunication skills play an important part in life’s experiences. In elementary school, children are developing language and learning to read and write. In order for a child to learn, he has to communicate and interact with his peers and adults. Spoken language is the basis for written language. As a child grows and develops, the two types of language interact and build upon each other to improve literacy and language. This process continues throughout a person’s life. If a child has a communication disorder, they are often delayed in other areas, such as reading and math. The child may be very bright but unable to express themselves correctly, and the learning process can be affected negatively.\n\nSpeech therapy can help children learn to communicate effectively with others and learn to solve problems and make decisions independently. Communication with peers and educators is an essential part of a fulfilling educational experience.\nAlso, children who are able to overcome communication disorders feel a great sense of pride and confidence. Children who stutter may be withdrawn socially, but with the help of therapy and improved confidence, they can enjoy a fully active social life (\"ASHA\").\n\n\n\n\n"}
{"id": "38523090", "url": "https://en.wikipedia.org/wiki?curid=38523090", "title": "Statistical learning in language acquisition", "text": "Statistical learning in language acquisition\n\nStatistical learning is the ability for humans and other animals to extract statistical regularities from the world around them to learn about the environment. Although statistical learning is now thought to be a generalized learning mechanism, the phenomenon was first identified in human infant language acquisition.\n\nThe earliest evidence for these statistics learning abilities comes from a study by Jenny Saffran, Richard Aslin, and Elissa Newport, in which 8-month-old infants were presented with nonsense streams of monotone speech. Each stream was composed of four three-syllable “pseudowords” that were repeated randomly. After exposure to the speech streams for two minutes, infants reacted differently to hearing “pseudowords” as opposed to “nonwords” from the speech stream, where nonwords were composed of the same syllables that the infants had been exposed to, but in a different order. This suggests that infants are able to learn statistical relationships between syllables even with very limited exposure to a language. That is, infants learn which syllables are always paired together and which ones only occur together relatively rarely, suggesting that they are parts of two different units. This method of learning is thought to be one way that children learn which groups of syllables form individual words.\n\nSince the initial discovery of the role of statistical learning in lexical acquisition, the same mechanism has been proposed for elements of phonological acquisition, and syntactical acquisition, as well as in non-linguistic domains. Further research has also indicated that statistical learning is likely a domain-general and even species-general learning mechanism, occurring for visual as well as auditory information, and in both primates and non-primates.\n\nThe role of statistical learning in language acquisition has been particularly well documented in the area of lexical acquisition. One important contribution to infants' understanding of segmenting words from a continuous stream of speech is their ability to recognize statistical regularities of the speech heard in their environments. Although many factors play an important role, this specific mechanism is powerful and can operate over a short time scale.\n\nIt is a well-established finding that, unlike written language, spoken language does not have any clear boundaries between words; spoken language is a continuous stream of sound rather than individual words with silences between them. This lack of segmentation between linguistic units presents a problem for young children learning language, who must be able to pick out individual units from the continuous speech streams that they hear. One proposed method of how children are able to solve this problem is that they are attentive to the statistical regularities of the world around them. For example, in the phrase \"pretty baby,\" children are more likely to hear the sounds \"pre\" and \"ty\" heard together during the entirety of the lexical input around them than they are to hear the sounds \"ty\" and \"ba\" together. In an artificial grammar learning study with adult participants, Saffran, Newport, and Aslin found that participants were able to locate word boundaries based only on transitional probabilities, suggesting that adults are capable of using statistical regularities in a language-learning task. This is a robust finding that has been widely replicated.\n\nTo determine if young children have these same abilities Saffran Aslin and Newport exposed 8-month-old infants to an artificial grammar. The grammar was composed of four words, each composed of three nonsense syllables. During the experiment, infants heard a continuous speech stream of these words . Importantly, the speech was presented in a monotone with no cues (such as pauses, intonation, etc.) to word boundaries other than the statistical probabilities. Within a word, the transitional probability of two syllable pairs was 1.0: in the word \"bidaku\", for example, the probability of hearing the syllable \"da\" immediately after the syllable \"bi\" was 100%. Between words, however, the transitional probability of hearing a syllable pair was much lower: After any given word (e.g., \"bidaku\") was presented, one of three words could follow (in this case, \"padoti\", \"golabu\", or \"tupiro\"), so the likelihood of hearing any given syllable after \"ku\" was only 33%.\n\nTo determine if infants were picking up on the statistical information, each infant was presented with multiple presentations of either a word from the artificial grammar or a nonword made up of the same syllables but presented in a random order. Infants who were presented with nonwords during the test phase listened significantly longer to these words than infants who were presented with words from the artificial grammar, showing a novelty preference for these new nonwords. However, the implementation of the test could also be due to infants learning serial-order information and not to actually learning transitional probabilities between words. That is, at test, infants heard strings such as \"dapiku\" and \"tilado\" that were never presented during learning; they could simply have learned that the syllable \"ku\" never followed the syllable \"pi\".\n\nTo look more closely at this issue, Saffran Aslin and Newport conducted another study in which infants underwent the same training with the artificial grammar but then were presented with either words or part-words rather than words or nonwords. The part-words were syllable sequences composed of the last syllable from one word and the first two syllables from another (such as \"kupado\"). Because the part-words had been heard during the time when children were listening to the artificial grammar, preferential listening to these part-words would indicate that children were learning not only serial-order information, but also the statistical likelihood of hearing particular syllable sequences. Again, infants showed greater listening times to the novel (part-) words, indicating that 8-month-old infants were able to extract these statistical regularities from a continuous speech stream.\n\nThis result has been the impetus for much more research on the role of statistical learning in lexical acquisition and other areas (see ). In a follow-up to the original report, Aslin, Saffran, and Newport found that even when words and part words occurred equally often in the speech stream, but with different transitional probabilities between syllables of words and part words, infants were still able to detect the statistical regularities and still preferred to listen to the novel part-words over the familiarized words. This finding provides stronger evidence that infants are able to pick up transitional probabilities from the speech they hear, rather than just being aware of frequencies of individual syllable sequences.\n\nAnother follow-up study examined the extent to which the statistical information learned during this type of artificial grammar learning feeds into knowledge that infants may already have about their native language. Infants preferred to listen to words over part-words, whereas there was no significant difference in the nonsense frame condition. This finding suggests that even pre-linguistic infants are able to integrate the statistical cues they learn in a laboratory into their previously-acquired knowledge of a language. In other words, once infants have acquired some linguistic knowledge, they incorporate newly acquired information into that previously-acquired learning.\n\nA related finding indicates that slightly older infants can acquire both lexical and grammatical regularities from a single set of input, suggesting that they are able to use outputs of one type of statistical learning (cues that lead to the discovery of word boundaries) as input to a second type (cues that lead to the discovery of syntactical regularities. At test, 12-month-olds preferred to listen to sentences that had the same grammatical structure as the artificial language they had been tested on rather than sentences that had a different (ungrammatical) structure. Because learning grammatical regularities requires infants to be able to determine boundaries between individual words, this indicates that infants who are still quite young are able to acquire multiple levels of language knowledge (both lexical and syntactical) simultaneously, indicating that statistical learning is a powerful mechanism at play in language learning.\n\nDespite the large role that statistical learning appears to play in lexical acquisition, it is likely not the only mechanism by which infants learn to segment words. Statistical learning studies are generally conducted with artificial grammars that have no cues to word boundary information other than transitional probabilities between words. Real speech, though, has many different types of cues to word boundaries, including prosodic and phonotactic information.\n\nTogether, the findings from these studies of statistical learning in language acquisition indicate that statistical properties of the language are a strong cue in helping infants learn their first language.\n\nThere is much evidence that statistical learning is an important component of both discovering which phonemes are important for a given language and which contrasts within phonemes are important. Having this knowledge is important for aspects of both speech perception and speech production.\n\nSince the discovery of infants’ statistical learning abilities in word learning, the same general mechanism has also been studied in other facets of language learning. For example, it is well-established that infants can discriminate between phonemes of many different languages but eventually become unable to discriminate between phonemes that do not appear in their native language; however, it was not clear how this decrease in discriminatory ability came about. Maye et al. suggested that the mechanism responsible might be a statistical learning mechanism in which infants track the distributional regularities of the sounds in their native language. To test this idea, Maye et al. exposed 6- and 8-month-old infants to a continuum of speech sounds that varied on the degree to which they were voiced. The distribution that the infants heard was either bimodal, with sounds from both ends of the voicing continuum heard most often, or unimodal, with sounds from the middle of the distribution heard most often. The results indicated that infants from both age groups were sensitive to the distribution of phonemes. At test, infants heard either non-alternating (repeated exemplars of tokens 3 or 6 from an 8-token continuum) or alternating (exemplars of tokens 1 and 8) exposures to specific phonemes on the continuum. Infants exposed to the bimodal distribution listened longer to the alternating trials than the non-alternating trials while there was no difference in listening times for infants exposed to the unimodal distribution. This finding indicates that infants exposed the bimodal distribution were better able to discriminate sounds from the two ends of the distribution than were infants in the unimodal condition, regardless of age. This type of statistical learning differs from that used in lexical acquisition, as it requires infants to track frequencies rather than transitional probabilities, and has been named “distributional learning.”\n\nDistributional learning has also been found to help infants contrast two phonemes that they initially have difficulty in discriminating between. Maye, Weiss, and Aslin found that infants who were exposed to a bimodal distribution of a non-native contrast that was initially difficult to discriminate were better able to discriminate the contrast than infants exposed to a unimodal distribution of the same contrast. Maye et al. also found that infants were able to abstract features of a contrast (i.e., voicing onset time) and generalize that feature to the same type of contrast at a different place of articulation, a finding that has not been found in adults.\n\nIn a review of the role of distributional learning on phonological acquisition, Werker et al. note that distributional learning cannot be the only mechanism by which phonetic categories are acquired. However, it does seem clear that this type of statistical learning mechanism can play a role in this skill, although research is ongoing.\n\nA related finding regarding statistical cues to phonological acquisition is a phenomenon known as the perceptual magnet effect. In this effect, a prototypical phoneme of a person’s native language acts as a “magnet” for similar phonemes, which are perceived as belonging to the same category as the prototypical phoneme. In the original test of this effect, adult participants were asked to indicate if a given exemplar of a particular phoneme differed from a referent phoneme. If the referent phoneme is a non-prototypical phoneme for that language, both adults and 6-month-old infants show less generalization to other sounds than they do for prototypical phonemes, even if the subjective distance between the sounds is the same. That is, adults and infants are both more likely to notice that a particular phoneme differs from the referent phoneme if that referent phoneme is a non-prototypical exemplar than if it is a prototypical exemplar. The prototypes themselves are apparently discovered through a distributional learning process, in which infants are sensitive to the frequencies with which certain sounds occur and treat those that occur most often as the prototypical phonemes of their language.\n\nA statistical learning device has also been proposed as a component of syntactical acquisition for young children. Early evidence for this mechanism came largely from studies of computer modeling or analyses of natural language corpora. These early studies focused largely on distributional information specifically rather than statistical learning mechanisms generally. Specifically, in these early papers it was proposed that children created templates of possible sentence structures involving unnamed categories of word types (i.e., nouns or verbs, although children would not put these labels on their categories). Children were thought to learn which words belonged to the same categories by tracking the similar contexts in which words of the same category appeared.\n\nLater studies expanded these results by looking at the actual behavior of children or adults who had been exposed to artificial grammars. These later studies also considered the role of statistical learning more broadly than the earlier studies, placing their results in the context of the statistical learning mechanisms thought to be involved with other aspects of language learning, such as lexical acquisition.\n\nEvidence from a series of four experiments conducted by Gomez and Gerken suggests that children are able to generalize grammatical structures with less than two minutes of exposure to an artificial grammar. In the first experiment, 11-12 month-old infants were trained on an artificial grammar composed of nonsense words with a set grammatical structure. At test, infants heard both novel grammatical and ungrammatical sentences. Infants oriented longer towards the grammatical sentences, in line with previous research that suggests that infants generally orient for a longer amount of time to natural instances of language rather than altered instances of language e.g.. (This familiarity preference differs from the novelty preference generally found in word-learning studies, due to the differences between lexical acquisition and syntactical acquisition.) This finding indicates that young children are sensitive to the grammatical structure of language even after minimal exposure. Gomez and Gerken also found that this sensitivity is evident when ungrammatical transitions are located in the middle of the sentence (unlike in the first experiment, in which all the errors occurred at the beginning and end of the sentences), that the results could not be due to an innate preference for the grammatical sentences caused by something other than grammar, and that children are able to generalize the grammatical rules to new vocabulary.\n\nTogether these studies suggest that infants are able to extract a substantial amount of syntactic knowledge even from limited exposure to a language. Children apparently detected grammatical anomalies whether the grammatical violation in the test sentences occurred at the end or in the middle of the sentence. Additionally, even when the individual words of the grammar were changed, infants were still able to discriminate between grammatical and ungrammatical strings during the test phase. This generalization indicates that infants were not learning vocabulary-specific grammatical structures, but abstracting the general rules of that grammar and applying those rules to novel vocabulary. Furthermore, in all four experiments, the test of grammatical structures occurred five minutes after the initial exposure to the artificial grammar had ended, suggesting that the infants were able to maintain the grammatical abstractions they had learned even after a short delay.\n\nIn a similar study, Saffran found that adults and older children (first and second grade children) were also sensitive to syntactical information after exposure to an artificial language which had no cues to phrase structure other than the statistical regularities that were present. Both adults and children were able to pick out sentences that were ungrammatical at a rate greater than chance, even under an “incidental” exposure condition in which participants’ primary goal was to complete a different task while hearing the language.\n\nAlthough the number of studies dealing with statistical learning of syntactical information is limited, the available evidence does indicate that the statistical learning mechanisms are likely a contributing factor to children’s ability to learn their language.\n\nMuch of the early work using statistical learning paradigms focused on the ability for children or adults to learn a single language, consistent with the process of language acquisition for monolingual speakers or learners. However, it is estimated that approximately 60-75% of people in the world are bilingual. More recently, researchers have begun looking at the role of statistical learning for those who speak more than one language. Although there are no reviews on this topic yet, Weiss, Gerfen, and Mitchel examined how hearing input from multiple artificial languages simultaneously can affect the ability to learn either or both languages. Over four experiments, Weiss et al. found that, after exposure to two artificial languages, adult learners are capable of determining word boundaries in both languages when each language is spoken by a different speaker. However, when the two languages were spoken by the same speaker, participants were able learn both languages only when they were “congruent”—when the word boundaries of one language matched the word boundaries of the other. When the languages were incongruent—a syllable that appeared in the middle of a word in one language appeared at the end of the word in the other language—and spoken by a single speaker, participants were able to learn, at best, one of the two languages. A final experiment showed that the inability to learn incongruent languages spoken in the same voice was not due to syllable overlap between the languages but due to differing word boundaries.\n\nSimilar work replicates the finding that learners are able to learn two sets of statistical representations when an additional cue is present (two different male voices in this case). In their paradigm, the two languages were presented consecutively, rather than interleaved as in Weiss et al.’s paradigm, and participants did learn the first artificial language to which they had been exposed better than the second, although participants’ performance was above chance for both languages.\n\nWhile statistical learning improves and strengthens multilingualism, it appears that the inverse is not true. In a study by Yim and Rudoy it was found that both monolingual and bilingual children perform statistical learning tasks equally well.\n\nAntovich and Graf Estes found that 14 month old bilingual children are better than monolinguals at segmenting two different artificial languages using transitional probability cues. They suggest that a bilingual environment in early childhood trains children to rely on statistical regularities to segment the speech flow and access two lexical systems.\n\nA statistical learning mechanism has also been proposed for learning the meaning of words. Specifically, Yu and Smith conducted a pair of studies in which adults were exposed to pictures of objects and heard nonsense words. Each nonsense word was paired with a particular object. There were 18 total word-referent pairs, and each participant was presented with either 2, 3, or 4 objects at a time, depending on the condition, and heard the nonsense word associated with one of those objects. Each word-referent pair was presented 6 times over the course of the training trials; after the completion of the training trials, participants completed a forced-alternative test in which they were asked to choose the correct referent that matched a nonsense word they were given. Participants were able to choose the correct item more often than would happen by chance, indicating, according to the authors, that they were using statistical learning mechanisms to track co-occurrence probabilities across training trials.\n\nAn alternative hypothesis is that learners in this type of task may be using a “propose-but-verify” mechanism rather than a statistical learning mechanism. Medina et al. and Trueswell et al. argue that, because Yu and Smith only tracked knowledge at the end of the training, rather than tracking knowledge on a trial-by-trial basis, it is impossible to know if participants were truly updating statistical probabilities of co-occurrence (and therefore maintaining multiple hypotheses simultaneously), or if, instead, they were forming a single hypothesis and checking it on the next trial. For example, if a participant is presented with a picture of a dog and a picture of a shoe, and hears the nonsense word \"vash\" she might hypothesize that \"vash\" refers to the dog. On a future trial, she may see a picture of a shoe and a picture of a door and again hear the word \"vash\". If statistical learning is the mechanism by which word-referent mappings are learned, then the participant would be more likely to select the picture of the shoe than the door, as shoe would have appeared in conjunction with the word \"vash\" 100% of the time. However, if participants are simply forming a single hypothesis, they may fail to remember the context of the previous presentation of \"vash\" (especially if, as in the experimental conditions, there are multiple trials with other words in between the two presentations of \"vash\") and therefore be at chance in this second trial. According to this proposed mechanism of word learning, if the participant had correctly guessed that \"vash\" referred to the shoe in the first trial, her hypothesis would be confirmed in the subsequent trial.\n\nTo distinguish between these two possibilities, Trueswell et al. conducted a series of experiments similar to those conducted by Yu and Smith except that participants were asked to indicate their choice of the word-referent mapping on each trial, and only a single object name was presented on each trial (with varying numbers of objects). Participants would therefore have been at chance when they are forced to make a choice in their first trial. The results from the subsequent trials indicate that participants were not using a statistical learning mechanism in these experiments, but instead were using a propose-and-verify mechanism, holding only one potential hypothesis in mind at a time. Specifically, if participants had chosen an incorrect word-referent mapping in an initial presentation of a nonsense word (from a display of five possible choices), their likelihood of choosing the correct word-referent mapping in the next trial of that word was still at chance, or 20%. If, though, the participant had chosen the correct word-referent mapping on an initial presentation of a nonsense word, the likelihood of choosing the correct word-referent mapping on the subsequent presentation of that word was approximately 50%. These results were also replicated in a condition where participants were choosing between only two alternatives. These results suggest that participants did not remember the surrounding context of individual presentations and were therefore not using statistical cues to determine the word-referent mappings. Instead, participants make a hypothesis regarding a word-referent mapping and, on the next presentation of that word, either confirm or reject the hypothesis accordingly.\n\nOverall, these results, along with similar results from Medina et al., indicate that word meanings may not be learned through a statistical learning mechanism in these experiments, which ask participants to hypothesize a mapping even on the first occurrence (i.e., not cross-situationally). However, when the propose-but-verify mechanism has been compared to a statistical learning mechanism, the former was unable to reproduce individual learning trajectories nor fit as well as the latter.\n\nAdditionally, statistical learning by itself cannot account even for those aspects of language acquisition for which it has been shown to play a large role. For example, Kuhl, Tsao, and Liu found that young English-learning infants who spent time in a laboratory session with a native Mandarin speaker were able to distinguish between phonemes that occur in Mandarin but not in English, unlike infants who were in a control condition. Infants in this control condition came to the lab as often as infants in the experimental condition, but were exposed only to English; when tested at a later date, they were unable to distinguish the Mandarin phonemes. In a second experiment, the authors presented infants with audio or audiovisual recordings of Mandarin speakers and tested the infants’ ability to distinguish between the Mandarin phonemes. In this condition, infants failed to distinguish the foreign language phonemes. This finding indicates that social interaction is a necessary component of language learning and that, even if infants are presented with the raw data of hearing a language, they are unable to take advantage of the statistical cues present in that data if they are not also experiencing the social interaction.\n\nAlthough the phenomenon of statistical learning was first discovered in the context of language acquisition and there is much evidence of its role in that purpose, work since the original discovery has suggested that statistical learning may be a domain general skill and is likely not unique to humans. For example, Saffran, Johnson, Aslin, and Newport found that both adults and infants were able to learn statistical probabilities of “words” created by playing different musical tones (i.e., participants heard the musical notes D, E, and F presented together during training and were able to recognize those notes as a unit at test as compared to three notes that had not been presented together). In non-auditory domains, there is evidence that humans are able to learn statistical visual information whether that information is presented across space, e.g., or time, e.g.. Evidence of statistical learning has also been found in other primates, e.g., and some limited statistical learning abilities have been found even in non-primates like rats. Together these findings suggest that statistical learning may be a generalized learning mechanism that happens to be utilized in language acquisition, rather than a mechanism that is unique to the human infant’s ability to learn his or her language(s).\n\nFurther evidence for domain general statistical learning was suggested in a study run through the University of Cornell Department of Psychology concerning visual statistical learning in infancy. Researchers in this study questioned whether domain generality of statistical learning in infancy would be seen using visual information. After first viewing images in statistically predictable patterns, infants were then exposed to the same familiar patterns in addition to novel sequences of the same identical stimulus components. Interest in the visuals was measured by the amount of time the child looked at the stimuli in which the researchers named “looking time.” All ages of infant participants showed more interest in the novel sequence relative to the familiar sequence. In demonstrating a preference for the novel sequences (which violated the transitional probability that defined the grouping of the original stimuli) the results of the study support the likelihood of domain general statistical learning in infancy.\n"}
{"id": "35740951", "url": "https://en.wikipedia.org/wiki?curid=35740951", "title": "Syntactic bootstrapping", "text": "Syntactic bootstrapping\n\nSyntactic bootstrapping is a theory in developmental psycholinguistics and language acquistion which proposes that children learn word meanings by recognizing syntactic categories (such as nouns, adjectives, etc.) and the structure of their language. It is proposed that children have innate knowledge of the links between syntactic and semantic categories and can use these observations to make inferences about word meaning. Learning words in one's native language can be challenging because the extralinguistic context of use does not give specific enough information about word meanings. Therefore, in addition to extralinguistic cues, conclusions about syntactic categories are made which then lead to inferences about a word's meaning. This theory aims to explain the acquisition of lexical categories such as verbs, nouns, etc. and functional categories such as case markers, determiners, etc.\n\nOne of the earliest demonstrations of the existence of syntactic bootstrapping is an experiment done by Roger Brown at Harvard University in 1957. In his research, Brown demonstrated that preschool-aged children could use their knowledge of different parts of speech to distinguish the meaning of nonsense words in English. The results of Brown’s experiment provided the first evidence showing that children could use syntax to infer meaning for newly encountered words and that they acquired grammar and semantics simultaneously. Brown's experiment was the beginning of the framework needed in order for the theory to thrive.\n\nThis led developmental psycholinguists like Lila Gleitman, who coined the term syntactic bootstrapping in 1990, to argue that syntax was pivotal for language learning, as it also gives a learner clues about semantics. According to Gleitman's hypothesis, verbs are learned with a delay compared to other parts of speech because the linguistic information that supports their acquisition is not available during the early stages of language acquisition. The acquisition of verb meaning in children is pivotal to their language development. Syntactic bootstrapping seeks to explain how children acquire these words.\n\nThe syntactic bootstrapping hypothesis is based on the idea that there are universal/innate links between syntactic categories and semantic categories. Learners can therefore use their observations about the syntactic categories of novel words to make inferences about their meanings. This hypothesis is intended to solve the problem that the extralinguistic context is uninformative by itself to make conclusions about a novel word's meaning.\n\nFor example, a child hears the sentence, “The cat meeped the bird.” If the child is familiar with the way arguments of verbs interact with the verb, he will infer that \"the cat\" is the agent and that \"the bird\" is the patient. Then, he can use these syntactic observations to infer that \"meep\" is a behaviour that the cat is doing to the bird.\n\nChildren's ability to identify syntactic categories may be supported by Prosodic bootstrapping. Prosodic bootstrapping is the hypothesis that children use prosodic cues, such as intonation and stress, to identify word boundaries.\n\nLandau and Gleitman (1985) found when studying the acquisition of the verbs \"look\" and \"see\" by blind children that contextual clues appeared to be insufficient to explain their ability to differentiate these verbs \".\" They considered the possibility that perceptual verbs might be used more by the blind child's mother when talking about nearby objects, since the child had to touch objects to perceive them. An analysis of the mother's utterances however, found this not to be the case.\n\nThe solution investigated by Gleitman et al. was that syntactic categories (referred to as 'Sentence Frames' by Gleitman), narrow down the contexts in which verbs are present, allowing children to learn their specific meanings in isolation. This narrowing provided evidence for their original hypothesis. When utterances that selected for \"perception verbs only\" were analyzed, the mother's use of the verbs \"look\" and \"see\" for nearby objects increased significantly. Gleitman concluded that a narrowing of contexts, \"then\" contextual support were required for the blind children to learn verbs (in which they had no direct experience). By proxy, since there are many verbs that sighted children do not have direct experience with, they must use the same mechanism as well.\n\nWaxman and Booth (2001) found that children who heard nouns focused on the object categories and children who focused on adjectives focused on an object's properties and categories. This shows that children are sensitive to different syntactic categories and can use their observations of syntax to infer word meaning.\n\nIn Roger Brown’s 1957 experiment, children between the ages of three and five were shown various pictures depicting nonsense words that represented either singular nouns, mass nouns, count nouns or verbs. When the novel words were positioned in a question format, the children were able to use the placement of the novel word in the sentence to draw conclusions focus on different aspects of the image shown and adjusted their answer. For example, when Brown wanted the child to identify a mass noun, he would ask the children \"do you see any sib\", and the child would point at the pictured mass noun or noun indicating quantity. \n\nWhen children made guesses, they were correct more than half of the time. This shows that children are sensitive to the syntactic position of words, and can correctly associate a novel word with its syntactic category.\n\nHarrigan, Hacquard, and Lidz (2016) —Found that children's interpretation of a new attitude verb depended on the syntactic frame in which it was introduced. In the experiment, children who heard the word 'hope' presented in the same syntactic frame as 'want' (i.e. followed by an infinitival verb) connected the new verb 'hope' with a meaning of desire. On the other hand, those that heard 'hope' presented in the same frame as 'think' (i.e. followed by a finite verb) made no such association between desire and the new verb, instead of associating the novel verb with belief. This provides evidence that children use syntax to some extent in learning the meaning behind these sorts of abstract verbs.\nPapafragou, Cassidy, Gleitman (2007) —Participants were asked to identify verbs within the context of a video. Papafragou et al. had children watch 12 videotaped stories. 4 stories about the subject's desires and 8 stories that varied in the subject's beliefs and the framing of a novel verb. At the end of the tape, they would hear a sentence describing the scene but the sentence's verb was replaced with a novel word. Children were asked to respond with what they thought the word meant. Their responses were categorized 4 ways: Action, Belief, Desire, and Other. They found that action words were easily interpreted by children. However, false belief scenes with the complementizer phrase caused for children to respond with belief words more often. Results showed that participants in the experiment identified the verb most accurately when they could use both the video and sentence contexts. When it comes to attitude verbs, children are sensitive to the syntactic framing of the verb in question.\nWellwood, Gagliardi, and Lidz (2016) — showed that four-year-olds can understand the difference between a quantitative or qualitative word, based on its syntactic position within a sentence. In “Gleebest of the cows are by the barn,” the novel word “gleebest” is in a determiner position, and is inferred to mean “most” or “many.” In “the gleebest cows are by the barn,” “gleebest” is in an adjective position, and children infer it to mean “spotty” or another quality. These results are significant because they show children using syntax to understand word meanings.\n\nIn the Gillette et al. (1999) study—, the researchers tested adults to see what difficulties they would face when asked to identify a word from a muted, videotaped scene. They found that adults had trouble identifying the word, especially verbs, when they could only refer to the scene. Their performance increased once they were given the syntactic context for the mystery word. These results indicate that word learning is aided by the presence of syntactic context.\n\nGillette et al. (1999) performed experiments which found that participants who were provided both environmental and syntactic contexts were better able to infer what muted word was uttered at a particular point in a video than when only the environmental context was provided. In the experiment, participants were shown muted videos of a mother and infant playing. At a particular point in the video, a beep would sound and participants had to guess what word the beep stood for. It was always a verb or noun. Experimental results showed that participants were correct on identifying nouns more often than verbs. This shows that certain contexts are conducive to learning certain categories of words, like nouns, while the same context is not conducive to learning other categories, like verbs. However, when the scene was paired with a sentence containing all novel words, but the same syntactic structure as the original sentence, adults were better able to guess the verb. This shows that syntactic context is useful in the acquisition of verbs.\n\nAn early demonstration by Naigles (1990) of syntactic bootstrapping involved showing 2-year-olds a video of a duck using its left hand to push a rabbit down into a squatting position while both the animals wave their right arms in circles.\n\nDuring the video, children are presented with one of the following two descriptions:\n\nChildren were then presented two distinct follow-up videos.\n\nWhen instructed to \"find kradding\", children looked to the video that illustrated the utterance they heard during the initial video. Children who heard utterance A interpreted \"kradding\" to mean the act of the duck pushing on the rabbit, while children who heard utterance B assumed \"kradding\" was the action of arm waving. This indicates that children arrive at interpretations of a novel verb based on the utterance context and the syntactic structure in which it was embedded.\n\nIn 1990, Lila Gleitman took this idea further by examining the acquisition of verbs in more detail. In her study, she found that children could differentiate between verbs that take one or more arguments and that this knowledge was used to help them narrow down the potential meanings for the verb in question. This discovery explains how children can learn the meaning of verbs that cannot be observed, like ‘think’.\n\nIn later studies, this was exemplified by Fisher as she proposed that children can use the number of noun phrases in a sentence as evidence about a verb's meaning. She argues that children expect the noun phrases in a sentence to map one-to-one with participant roles in the event described by that sentence. For example, if a toddler hears a sentence that contains two noun phrases, she can infer that that sentence describes an event with two participants. This constrains the meaning that the verb in that sentence can have. Fisher presented 3 and 5 year old children a video in which one participant caused a second participant to move. Children who heard that scene described by a transitive clause containing a novel verb, associated the subject of the verb with the agent. Children who heard the scene described by an intransitive clause associated the subject with either the agent or the patient. This shows that children make different inferences about meaning depending on the transitivity of the sentence.\n\nAcquiring the meaning of attitude verbs, which refer to an individual’s mental state, provides a challenge for word learners since these verbs do not correlate with any physical aspects of the environment. Words such as 'think' and 'want' do not have physically observable qualities. Thus, there must be something deeper going on that enables children to learn these verbs referring to abstract mental concepts, such as syntactic frames as described in a study above by Harrigan, Hacquard, and Lidz. Because children have no initial idea about the meaning or usage of the words, syntactic bootstrapping aids them in figuring out when verbs refer to mental concepts. If a child hears the statement, \"Matt thinks his grandmother is under the covers,\" three- to four-year-old children will understand that the sentence is about Matt's belief. Children will understand from the syntactic frame in which it was uttered that the verb for mental state, \"thinks\", refers to Matt's beliefs and not to his grandmother's. In addition, Gillette et al. (1999) show that mental state verbs cannot easily be identified when only visual context is available and that these verbs showed the greatest improvement when syntactic context was provided.\n\nThe acquisition of nouns is related to the acquisition of the mass/count contrast. In 1969, Willard Van Orman Quine claimed that children cannot learn new nouns unless they have already acquired this semantic distinction. Otherwise, the word “apples” might refer to the individual objects in a pile or the pile itself, and the child would have no way to know without already understanding the difference between a mass and a count noun. Nancy N. Soja argues that Quine is mistaken, and that children can learn new nouns without fully understanding the mass/count distinction. She found in her study that 2-year old children were able to learn new nouns (some mass, some count nouns) from inferring meaning from the syntactic structure of the sentence the words were introduced in.\n\nIn a 2010 study, Syrett and Lidz show that children learn the meaning of novel gradable adjectives on the basis of the adverbs that modify them. Gradable adjectives have a scale associated with them: for example, the adjective “large” places the noun that it modifies on a size scale, while the adjective “expensive” places the noun that is modifiers on a price scale. In addition, gradable adjectives (GA's) subdivide into two classes: relative and maximal GA’s.\n\nRelative GA’s are words like “big” in (5), and require a reference point: a big mouse is not the same size as a big elephant. As shown in (6) and (7), while relative GAs can be modified by the adverb \"very\" they cannot be modified by the adverb \"completely\".\n\nMaximal GA’s are words like, “full” in (8); they operate on a close-ended scale. As shown in (9) and (10), while relative GAs cannot be modified by the adverb \"very\" they can be modified by the adverb \"completely\".\n\nIn the 2010 study, Syrett and Lidz showed children pictures of objects that could be described in terms of both relative and maximal GA’s. For example, a picture of a container that could be described as both \"tall\" (a relative GA) and \"clear\" (a maximal GA).\n\nWhen showing these objects to the children, the novel adjective used to describe them was prefaced with either adverb \"very\" (which usually modifies relative GA’s) or the adverb \"completely\" (which modifies maximal GA’s). As a control, in some contexts, no adverb was present. When the novel adjective was presented with the adverb \"very\", the children assigned a relative GA meaning to it, and when it was presented with adverb \"completely\", a maximal GA. When no adverb was present, the children were unable to assign a meaning to the adjective. This shows that, in order for children to learn the meaning of a new adjective, they depend on grammatical information provide by adverbs about the semantic class of the novel adjective.\n\nAn experiment by Wellwood, Gagliardi, and Lidz (2016) showed that four-year-olds associate unknown words with a quality meaning when they are presented with adjective syntax, and with a quantitative meaning when they are presented with determiner syntax. For example, in \"Gleebest of the cows are by the barn,\" \"gleebest\" would be interpreted as \"many\" or \"four,\" a quantity. Yet children associate the same unknown word with a quality interpretation when the word is presented in an adjective position. In the sentence \"The gleebest cows are by the barn,\" \"gleebest\" would be interpreted as \"striped\" or \"purple,\" a quality. This shows that children use syntax to identify whether a word is an adjective or a determiner, and use that category information to infer aspects of the word's meaning.\n\nThere is a basic contrast between lexical categories (which include open-class items such as verbs, nouns, and adjectives), and functional categories (which include closed-class items such auxiliary verbs, case markers, complementizers, conjunctions and determiners. The acquisition functional categories has been studied significantly less than the lexical class, so much remains unknown. A 1998 study led by Rushen Shi shows that, at a very young age, Mandarin and Turkish learners use phonological, acoustic and distributional cues to distinguish between words that are lexical categories from words that are functional categories. 11 to 20-month old children were observed speaking with their mothers to evaluate whether speech directed at the children contained clues that they could then use to categorize words as \"lexical\" or \"function\". Compared to as lexical category words, functional category words were found to have the following properties:\n\n\nSteven Pinker presents his theory of semantic bootstrapping, which hypothesizes that children use the meaning of words to start to learn the syntax of their language. Gleitman (1990) counters Pinker’s ideas by asserting that context is insufficient to supply word meaning, as a single context can allow for multiple interpretations of an uttered sentence. She explains that simply observing objects and events in the world does not provide sufficient information to infer the meanings of words and sentences. Pinker, however, argues that semantic bootstrapping and syntactic bootstrapping aren't conflicting ideas, and that semantic bootstrapping makes no claims about learning word meanings. He argues that since semantic bootstrapping is a hypothesis about how children acquire syntax, while syntactic bootstrapping is a hypothesis about how children acquire word meanings, the opposition between the two theories does not necessarily exist.\n\nPinker agrees that syntactic categories are in fact used by children to learn semantics and accepts syntactic bootstrapping, but argues that Gleitman applies the hypothesis too broadly, and that is insufficient evidence to account for all of Gleitman's claims. Pinker argues that while children can use syntax to learn certain semantic properties within a single frame, like the number of arguments a verb takes or the types of arguments such as agent and patient, there are serious problems with the argument that children pick up on these semantic properties from the syntax when a verb is found in a wide range of syntactic frames. Pinker uses the verb \"sew\" as an example:\n\nPinker argues that the syntax provides information about possible verb frames, but does not help a learner \"zoom in\" on a verb's meaning after hearing it in multiple frames. According to Pinker, the frames presented above for \"sew\" can do nothing for learners other than clue them into the fact that \"sewing\" is some sort of activity. Furthermore, Pinker disagrees with Gleitman's claim that the ambiguities in the situations where a word is used could only be solved by using information about how the word behaves syntactically.\n\nWith all of the studies above supporting or challenging syntactic bootstrapping, how does the theory hold up cross linguistically?\n\nTwo studies focusing on French and German were determining the use of syntactic contexts to classify novel words as nouns or verbs. The German study found that children between 14 and 16 months could use determiners to classify a novel word as a noun, however, they could not show the same ability mapping pronoun environments to verbs. Overall, this exemplifies their ability to determine the categories of function words and shows a sensitivity to syntactic framing. Following this conclusion, Christophe et al. found that children can use this ability along with Prosodic bootstrapping to infer the syntactic category of the neighboring content words; as at 23 months they can classify novel nouns as well as verbs based on their surrounding syntactic envionrment. These studies follow the Syntactic Bootstrapping model of language acquisition, however, the determiner/noun and pronoun/verb environments are also found in English, som, how well does this theory apply to a Language structurally different from English?\n\nLee and Naigles (2005) looked into how Mandarin children use the transitive versus intransitive environments to infer meaning in a language that allows the noun phrase (subject or object) argument to go unpronounced. Following Fisher’s studies where children use the number of NP’s to make conclusions about the causation in the sentence; 1 NP is an intransitive sentence and involves only the agent while 2 NP’s is a transitive environment and involves an action being taken upon something or someone. \n\nThe environment above was presented in the study and then altered to test the change of interpretation the Mandarin children might have. Due to the pervasive ellipsis in Mandarin, the number of NP’s in a phrase is a weaker clue in mapping causation or non-causation of a verb. Presented with an elided transitive environment \"The dog brings,\" the children determined the sentence to be intransitive, meaning they changed their interpretation of the verb based on the number of noun phrases presented. This was shown as the children used toys to act out the scenario they heard; if their interpretation were to be independent of the number of NP's they would have shown the dog bringing the lion, however, they showed the dog going on its own, showing their interpretation of the verb to be non-causative. This follows the syntactic bootstrapping theory as their mapping of verb meaning relied on the syntactic frame and content in the sentence. However, it poses another question about how Mandarin children can go on to map transitive or intransitive environments properly during their development.\n\nA few studies have begun to look at how children learning languages with different word orders represent syntactic structures which are required for children to map word meanings or categories using syntactic bootstrapping. For example, the research on the acquisition of verbs presents English children as using information about the subject and objects to determine if the verb is causative or non-causative, however, will this ability change in a language which has the object occurring before the verb. One could assume this to be a difficult task if both an English child and child leaning an SOV language have the same mental representation of syntactic structure. To address this, a Gervain, et al., looked at an infant’s mental representation of Japanese, which is a complement – head language with an object-verb (OV) word order, and Italian, which like English, is head-complement and therefore has a verb-object (VO) word order. They found that 8-month-olds have a general knowledge of word order specific to their language preceding their acquisition of lexical items or syntactic categories. Their attuning of structural relations of syntactic categories (verbs, nouns, etc.) within their language allows them to then apply this knowledge later in their development, possibly allowing for language-specific syntactic bootstrapping.\n\n"}
{"id": "26860", "url": "https://en.wikipedia.org/wiki?curid=26860", "title": "Syntax", "text": "Syntax\n\nIn linguistics, syntax () is the set of rules, principles, and processes that govern the structure of sentences in a given language, usually including word order. The term \"syntax\" is also used to refer to the study of such principles and processes. The goal of many syntacticians is to discover the syntactic rules common to all languages.\n\nIn mathematics, \"syntax\" refers to the rules governing the notation of mathematical systems, such as formal languages used in logic. (See logical syntax.)\n\nThe word \"syntax\" comes from Ancient Greek: \"coordination\", which consists of \"syn\", \"together\", and \"táxis\", \"an ordering\".\n\nA basic feature of a language's syntax is the sequence in which the subject (S), verb (V), and object (O) usually appear in sentences. Over 85% of languages usually place the subject first, either in the sequence SVO or the sequence SOV. The other possible sequences are VSO, VOS, OVS, and OSV, the last three of which are rare.\n\nWorks on grammar were written long before modern syntax came about; in Ancient India, the \"Aṣṭādhyāyī\" of Pāṇini (c. 4th century BC) is often cited as an example of a premodern work that approaches the sophistication of a modern syntactic theory. In the West, the school of thought that came to be known as \"traditional grammar\" began with the work of Dionysius Thrax.\n\nFor centuries, work in syntax was dominated by a framework known as , first expounded in 1660 by Antoine Arnauld in a book of the same title. This system took as its basic premise the assumption that language is a direct reflection of thought processes and therefore there is a single, most natural way to express a thought.\n\nHowever, in the 19th century, with the development of historical-comparative linguistics, linguists began to realize the sheer diversity of human language and to question fundamental assumptions about the relationship between language and logic. It became apparent that there was no such thing as the most natural way to express a thought, and therefore logic could no longer be relied upon as a basis for studying the structure of language.\n\nThe Port-Royal grammar modeled the study of syntax upon that of logic. (Indeed, large parts of the Port-Royal Logic were copied or adapted from the \"Grammaire générale\".) Syntactic categories were identified with logical ones, and all sentences were analyzed in terms of \"subject – copula – predicate\". Initially, this view was adopted even by the early comparative linguists such as Franz Bopp.\n\nThe central role of syntax within theoretical linguistics became clear only in the 20th century, which could reasonably be called the \"century of syntactic theory\" as far as linguistics is concerned. (For a detailed and critical survey of the history of syntax in the last two centuries, see the monumental work by Giorgio Graffi (2001).)\n\nThere are a number of theoretical approaches to the discipline of syntax. One school of thought, founded in the works of Derek Bickerton, sees syntax as a branch of biology, since it conceives of syntax as the study of linguistic knowledge as embodied in the human mind. Other linguists (e.g., Gerald Gazdar) take a more Platonistic view, since they regard syntax to be the study of an abstract formal system. Yet others (e.g., Joseph Greenberg) consider syntax a taxonomical device to reach broad generalizations across languages.\n\nThe hypothesis of generative grammar is that language is a structure of the human mind. The goal of generative grammar is to make a complete model of this inner language (known as \"i-language\"). This model could be used to describe all human language and to predict the grammaticality of any given utterance (that is, to predict whether the utterance would sound correct to native speakers of the language). This approach to language was pioneered by Noam Chomsky. Most generative theories (although not all of them) assume that syntax is based upon the constituent structure of sentences. Generative grammars are among the theories that focus primarily on the form of a sentence, rather than its communicative function.\n\nAmong the many generative theories of linguistics, the Chomskyan theories are:\n\nOther theories that find their origin in the generative paradigm are:\n\nDependency grammar is an approach to sentence structure where syntactic units are arranged according to the dependency relation, as opposed to the constituency relation of phrase structure grammars. Dependencies are directed links between words. The (finite) verb is seen as the root of all clause structure and all the other words in the clause are either directly or indirectly dependent on this root. Some prominent dependency-based theories of syntax are:\n\n\nLucien Tesnière (1893–1954) is widely seen as the father of modern dependency-based theories of syntax and grammar. He argued vehemently against the binary division of the clause into subject and predicate that is associated with the grammars of his day (S → NP VP) and which remains at the core of most phrase structure grammars. In the place of this division, he positioned the verb as the root of all clause structure.\n\nCategorial grammar is an approach that attributes the syntactic structure not to rules of grammar, but to the properties of the syntactic categories themselves. For example, rather than asserting that sentences are constructed by a rule that combines a noun phrase (NP) and a verb phrase (VP) (e.g., the phrase structure rule S → NP VP), in categorial grammar, such principles are embedded in the category of the head word itself. So the syntactic category for an intransitive verb is a complex formula representing the fact that the verb acts as a function word requiring an NP as an input and produces a sentence level structure as an output. This complex category is notated as (NP\\S) instead of V. NP\\S is read as \"a category that searches to the left (indicated by \\) for an NP (the element on the left) and outputs a sentence (the element on the right).\" The category of transitive verb is defined as an element that requires two NPs (its subject and its direct object) to form a sentence. This is notated as (NP/(NP\\S)) which means \"a category that searches to the right (indicated by /) for an NP (the object), and generates a function (equivalent to the VP) which is (NP\\S), which in turn represents a function that searches to the left for an NP and produces a sentence.\"\n\nTree-adjoining grammar is a categorial grammar that adds in partial tree structures to the categories.\n\nTheoretical approaches to syntax that are based upon probability theory are known as stochastic grammars. One common implementation of such an approach makes use of a neural network or connectionism.\n\nFunctionalist theories, although focused upon form, are driven by explanation based upon the function of a sentence (i.e., its communicative function). Some typical functionalist theories include:\n\n\n\n"}
{"id": "17729828", "url": "https://en.wikipedia.org/wiki?curid=17729828", "title": "Terminology (disambiguation)", "text": "Terminology (disambiguation)\n\nTerminology is the study of terms and their use.\n\nTerminology may also refer to:\n\n\n"}
{"id": "9246933", "url": "https://en.wikipedia.org/wiki?curid=9246933", "title": "Text Services Framework", "text": "Text Services Framework\n\nThe Text Services Framework (TSF) is a COM framework and API in Windows XP and later Windows operating systems that supports advanced text input and text processing. The Text Services Framework is designed to offer advanced language and word processing features to applications. It supports features such as multilingual support, keyboard drivers, handwriting recognition, speech recognition, as well as spell checking and other text and natural language processing functions. It is also downloadable for older Windows operating systems.\n\nThe Language Bar is the core user interface for Text Services Framework. The language bar enables text services to add UI elements to the toolbar and enables these elements when an application has focus. From the Language Bar, users can select the input language, and control keyboard input, handwriting recognition and speech recognition.\n\nThe language bar also provides a direct means to switch between installed languages, even when a non-TSF-enabled application has focus.\n\nStarting with Windows XP Tablet PC Edition 2005 and Windows Vista, the RichEdit control supports the Text Services Framework. Windows Speech Recognition in Windows Vista is also implemented using the Text Services Framework.\n\n\n"}
{"id": "155023", "url": "https://en.wikipedia.org/wiki?curid=155023", "title": "Textual criticism", "text": "Textual criticism\n\nTextual criticism is a branch of textual scholarship, philology, and literary criticism that is concerned with the identification of textual variants in either manuscripts or printed books. Scribes can make alterations when copying manuscripts by hand. Given a manuscript copy, several or many copies, but not the original document, the textual critic might seek to reconstruct the original text (urtext, archetype or autograph) as closely as possible. The same processes can be used to attempt to reconstruct intermediate versions, or recensions, of a document's transcription history. The objective of the textual critic's work is a better understanding of the creation and historical transmission of texts. This understanding may lead to the production of a \"critical edition\" containing a scholarly curated text.\n\nThere are many approaches to textual criticism, notably eclecticism, stemmatics, and copy-text editing. Quantitative techniques are also used to determine the relationships between witnesses to a text, with methods from evolutionary biology (phylogenetics) appearing effective on a range of traditions.\n\nIn some domains (religious and classical text editing) the phrase \"lower criticism\" is used to describe the contrast between textual criticism and \"higher criticism\", which is the endeavor to establish the authorship, date, and place of composition of the original text.\n\nTextual criticism has been practiced for over two thousand years. Early textual critics, especially the librarians of Hellenistic Alexandria in the last two centuries BC, were concerned with preserving the works of antiquity, and this continued through the medieval period into early modern times and the invention of the printing press. Textual criticism was an important aspect of the work of many Renaissance Humanists, such as Desiderius Erasmus, who edited the Greek New Testament, creating the \"Textus Receptus\". In Italy, scholars such as Petrarch and Poggio Bracciolini collected and edited many Latin manuscripts, while a new spirit of critical enquiry was boosted by the attention to textual states, for example in the work of Lorenzo Valla on the purported Donation of Constantine.\n\nMany ancient works, such as the Bible and the Greek tragedies, survive in hundreds of copies, and the relationship of each copy to the original may be unclear. Textual scholars have debated for centuries which sources are most closely derived from the original, hence which readings in those sources are correct. Although biblical books that are letters, like Greek plays, presumably had one original, the question of whether some biblical books, like the Gospels, ever had just one original has been discussed. Interest in applying textual criticism to the Quran has also developed after the discovery of the Sana'a manuscripts in 1972, which possibly date back to the 7–8th centuries.\n\nIn the English language, the works of Shakespeare have been a particularly fertile ground for textual criticism—both because the texts, as transmitted, contain a considerable amount of variation, and because the effort and expense of producing superior editions of his works have always been widely viewed as worthwhile.\nThe principles of textual criticism, although originally developed and refined for works of antiquity and the Bible, and, for Anglo-American Copy-Text editing, Shakespeare,\nhave been applied to many works, from (near-)contemporary texts to the earliest known written documents. Ranging from ancient Mesopotamia and Egypt to the twentieth century, textual criticism covers a period of about five millennia.\n\nThe basic problem, as described by Paul Maas, is as follows:\nMaas comments further that \"A dictation revised by the author must be regarded as equivalent to an autograph manuscript\". The lack of autograph manuscripts applies to many cultures other than Greek and Roman. In such a situation, a key objective becomes the identification of the first \"exemplar\" before any split in the tradition. That exemplar is known as the \"archetype\". \"If we succeed in establishing the text of [the archetype], the \"constitutio\" (reconstruction of the original) is considerably advanced.\n\nThe textual critic's ultimate objective is the production of a \"critical edition\". This contains the text that the author has determined most closely approximates the original, and is accompanied by an \"apparatus criticus\" or critical apparatus. The critical apparatus presents the author's work in three parts: first, a list or description of the evidence that the editor used (names of manuscripts, or abbreviations called sigla); second, the editor's analysis of that evidence (sometimes a simple likelihood rating),; and third, a record of rejected variants of the text (often in order of preference).\n\nBefore mechanical printing, literature was copied by hand, and many variations were introduced by copyists. The age of printing made the scribal profession effectively redundant. Printed editions, while less susceptible to the proliferation of variations likely to arise during manual transmission, are nonetheless not immune to introducing variations from an author's autograph. Instead of a scribe miscopying his source, a compositor or a printing shop may read or typeset a work in a way that differs from the autograph. Since each scribe or printer commits different errors, reconstruction of the lost original is often aided by a selection of readings taken from many sources. An edited text that draws from multiple sources is said to be \"eclectic\". In contrast to this approach, some textual critics prefer to identify the single best surviving text, and not to combine readings from multiple sources.\n\nWhen comparing different documents, or \"witnesses\", of a single, original text, the observed differences are called \"variant readings\", or simply \"variants\" or \"readings\". It is not always apparent which single variant represents the author's original work. The process of textual criticism seeks to explain how each variant may have entered the text, either by accident (duplication or omission) or intention (harmonization or censorship), as scribes or supervisors transmitted the original author's text by copying it. The textual critic's task, therefore, is to sort through the variants, eliminating those most likely to be \"un\"-original, hence establishing a \"critical text\", or critical edition, that is intended to best approximate the original. At the same time, the critical text should document variant readings, so the relation of extant witnesses to the reconstructed original is apparent to a reader of the critical edition. In establishing the critical text, the textual critic considers both \"external\" evidence (the age, provenance, and affiliation of each witness) and \"internal\" or \"physical\" considerations (what the author and scribes, or printers, were likely to have done).\n\nThe collation of all known variants of a text is referred to as a variorum, namely a work of textual criticism whereby all variations and emendations are set side by side so that a reader can track how textual decisions have been made in the preparation of a text for publication. The Bible and the works of William Shakespeare have often been the subjects of variorum editions, although the same techniques have been applied with less frequency to many other works, such as Walt Whitman's Leaves of Grass,\nand the prose writings of Edward Fitzgerald.\n\nEclecticism refers to the practice of consulting a wide diversity of witnesses to a particular original. The practice is based on the principle that the more independent transmission histories there are, the less likely they will be to reproduce the same errors. What one omits, the others may retain; what one adds, the others are unlikely to add. Eclecticism allows inferences to be drawn regarding the original text, based on the evidence of contrasts between witnesses.\n\nEclectic readings also normally give an impression of the number of witnesses to each available reading. Although a reading supported by the majority of witnesses is frequently preferred, this does not follow automatically. For example, a second edition of a Shakespeare play may include an addition alluding to an event known to have happened between the two editions. Although nearly all subsequent manuscripts may have included the addition, textual critics may reconstruct the original without the addition.\n\nThe result of the process is a text with readings drawn from many witnesses. It is not a copy of any particular manuscript, and may deviate from the majority of existing manuscripts. In a purely eclectic approach, no single witness is theoretically favored. Instead, the critic forms opinions about individual witnesses, relying on both external and internal evidence.\n\nSince the mid-19th century, eclecticism, in which there is no \"a priori\" bias to a single manuscript, has been the dominant method of editing the Greek text of the New Testament (currently, the United Bible Society, 5th ed. and Nestle-Aland, 28th ed.). Even so, the oldest manuscripts, being of the Alexandrian text-type, are the most favored, and the critical text has an Alexandrian disposition.\n\nExternal evidence is evidence of each physical witness, its date, source, and relationship to other known witnesses. Critics will often prefer the readings supported by the oldest witnesses. Since errors tend to accumulate, older manuscripts should have fewer errors. Readings supported by a majority of witnesses are also usually preferred, since these are less likely to reflect accidents or individual biases. For the same reasons, the most geographically diverse witnesses are preferred. Some manuscripts show evidence that particular care was taken in their composition, for example, by including alternative readings in their margins, demonstrating that more than one prior copy (exemplar) was consulted in producing the current one. Other factors being equal, these are the \"best\" witnesses. The role of the textual critic is necessary when these basic criteria are in conflict. For instance, there will typically be fewer early copies, and a larger number of later copies. The textual critic will attempt to balance these criteria, to determine the original text.\n\nThere are many other more sophisticated considerations. For example, readings that depart from the known practice of a scribe or a given period may be deemed more reliable, since a scribe is unlikely on his own initiative to have departed from the usual practice.\n\nInternal evidence is evidence that comes from the text itself, independent of the physical characteristics of the document. Various considerations can be used to decide which reading is the most likely to be original. Sometimes these considerations can be in conflict.\n\nTwo common considerations have the Latin names \"lectio brevior\" (shorter reading) and \"lectio difficilior\" (more difficult reading). The first is the general observation that scribes tended to add words, for clarification or out of habit, more often than they removed them. The second, \"lectio difficilior potior\" (the harder reading is stronger), recognizes the tendency for harmonization—resolving apparent inconsistencies in the text. Applying this principle leads to taking the more difficult (unharmonized) reading as being more likely to be the original. Such cases also include scribes simplifying and smoothing texts they did not fully understand.\n\nAnother scribal tendency is called homoioteleuton, meaning \"same endings\". Homoioteleuton occurs when two words/phrases/lines end with the same sequence of letters. The scribe, having finished copying the first, skips to the second, omitting all intervening words. \"Homeoarchy\" refers to eye-skip when the \"beginnings\" of two lines are similar.\n\nThe critic may also examine the other writings of the author to decide what words and grammatical constructions match his style. The evaluation of internal evidence also provides the critic with information that helps him evaluate the reliability of individual manuscripts. Thus, the consideration of internal and external evidence is related.\n\nAfter considering all relevant factors, the textual critic seeks the reading that best explains how the other readings would arise. That reading is then the most likely candidate to have been original.\n\nVarious scholars have developed guidelines, or \"canons\" of textual criticism, to guide the exercise of the critic's judgment in determining the best readings of a text. One of the earliest was Johann Albrecht Bengel (1687–1752), who in 1734 produced an edition of the Greek New Testament. In his commentary, he established the rule \"Proclivi scriptioni praestat ardua\", (\"the harder reading is to be preferred\").\n\nJohann Jakob Griesbach (1745–1812) published several editions of the New Testament. In his 1796 edition, he established fifteen critical rules. Among them was a variant of Bengel's rule, \"Lectio difficilior potior\", \"the harder reading is better.\" Another was \"Lectio brevior praeferenda\", \"the shorter reading is better\", based on the idea that scribes were more likely to add than to delete. This rule cannot be applied uncritically, as scribes may omit material inadvertently.\n\nBrooke Foss Westcott (1825–1901) and Fenton Hort (1828–1892) published an edition of the New Testament in Greek in 1881. They proposed nine critical rules, including a version of Bengel's rule, \"The reading is less likely to be original that shows a disposition to smooth away difficulties.\" They also argued that \"Readings are approved or rejected by reason of the quality, and not the number, of their supporting witnesses\", and that \"The reading is to be preferred that most fitly explains the existence of the others.\"\n\nMany of these rules, although originally developed for biblical textual criticism, have wide applicability to any text susceptible to errors of transmission.\n\nSince the canons of criticism are highly susceptible to interpretation, and at times even contradict each other, they may be employed to justify a result that fits the textual critic's aesthetic or theological agenda. Starting in the 19th century, scholars sought more rigorous methods to guide editorial judgment. Stemmatics and copy-text editing – while both eclectic, in that they permit the editor to select readings from multiple sources – sought to reduce subjectivity by establishing one or a few witnesses presumably as being favored by \"objective\" criteria. The citing of sources used, and alternate readings, and the use of original text and images helps readers and other critics determine to an extent the depth of research of the critic, and to independently verify their work.\n\nStemmatics or stemmatology is a rigorous approach to textual criticism. Karl Lachmann (1793–1851) greatly contributed to making this method famous, even though he did not invent it. The method takes its name from the word \"stemma\". The Ancient Greek word στέμματα and its loanword in classical Latin \"stemmata\" may refer to \"family trees\". This specific meaning shows the relationships of the surviving witnesses (the first known example of such a stemma, albeit with the name, dates from 1827).<ref>Collín, H. S. and C. J. Schlyter (eds), \"Corpus iuris Sueo-Gotorum antiqui: Samling af Sweriges gamla lagar, på Kongl. Maj:ts. nådigste befallning\", 13 vols (Stockholm: Haeggström, 1827–77), vol. 1, table 3; the volume is available at but the scan unfortunately omits the stemma. William Robins, `Editing and Evolution', \"Literature Compass\" 4 (2007): 89–120, at pp. 93–94, \n"}
{"id": "167550", "url": "https://en.wikipedia.org/wiki?curid=167550", "title": "Transcription (linguistics)", "text": "Transcription (linguistics)\n\nTranscription in the linguistic sense is the systematic representation of language in written form. The source can either be utterances (\"speech\" or \"sign language\") or preexisting text in another writing system.\n\nTranscription should not be confused with translation, which means representing the meaning of a source language text in a target language (e.g. \"Los Angeles\" into \"City of Angels\") or with transliteration which means representing the spelling of a text from one script to another (e.g. \"Jalapeño\", which preserves the Ñ from Spanish despite the diacritic having no use in English).\n\nIn the academic discipline of linguistics, transcription is an essential part of the methodologies of (among others) phonetics, conversation analysis, dialectology and sociolinguistics. It also plays an important role for several subfields of speech technology. Common examples for transcriptions outside academia are the proceedings of a court hearing such as a criminal trial (by a court reporter) or a physician's recorded voice notes (medical transcription). This article focuses on transcription in linguistics.\n\nBroadly speaking, there are two possible approaches to linguistic transcription. Phonetic transcription focuses on phonetic and phonological properties of spoken language. Systems for phonetic transcription thus furnish rules for mapping individual sounds or phones to written symbols. Systems for orthographic transcription, by contrast, consist of rules for mapping spoken words onto written forms as prescribed by the orthography of a given language. Phonetic transcription operates with specially defined character sets, usually the International Phonetic Alphabet.\n\nWhich type of transcription is chosen depends mostly on the research interests pursued. Since phonetic transcription strictly foregrounds the phonetic nature of language, it is most useful for phonetic or phonological analyses. Orthographic transcription, on the other hand, has a morphological and a lexical component alongside the phonetic component (which aspect is represented to which degree depends on the language and orthography in question). It is thus more convenient wherever meaning-related aspects of spoken language are investigated. Phonetic transcription is doubtlessly more systematic in a scientific sense, but it is also harder to learn, more time-consuming to carry out and less widely applicable than orthographic transcription.\n\nMapping spoken language onto written symbols is not as straightforward a process as may seem at first glance. Written language is an idealisation, made up of a limited set of clearly distinct and discrete symbols. Spoken language, on the other hand, is a continuous (as opposed to discrete) phenomenon, made up of a potentially unlimited number of components. There is no predetermined system for distinguishing and classifying these components and, consequently, no preset way of mapping these components onto written symbols.\n\nLiterature is relatively consistent in pointing out the nonneutrality of transcription practices. There is not and cannot be a neutral transcription system. Knowledge of social culture enters directly into the making of a transcript. They are captured in the texture of the transcript (Baker, 2005).\n\nTranscription systems are sets of rules which define how spoken language is to be represented in written symbols. Most phonetic transcription systems are based on the International Phonetic Alphabet or, especially in speech technology, on its derivative SAMPA.\nExamples for orthographic transcription systems (all from the field of conversation analysis or related fields) are:\n\nArguably the first system of its kind, originally sketched in (Sacks et al. 1978), later adapted for the use in computer readable corpora as \"CA-CHAT\" by (MacWhinney 2000). The field of Conversation Analysis itself includes a number of distinct approaches to transcription and sets of transcription conventions. These include, among others, Jefferson Notation. To analyze conversation, recorded data is typically transcribed into a written form that is agreeable to analysts. There are two common approaches. The first, called narrow transcription, captures the details of conversational interaction such as which particular words are stressed, which words are spoken with increased loudness, points at which the turns-at-talk overlap, how particular words are articulated, and so on. If such detail is less important, perhaps because the analyst is more concerned with the overall gross structure of the conversation or the relative distribution of turns-at-talk amongst the participants, then a second type of transcription known as broad transcription may be sufficient (Williamson, 2009).\n\nThe Jefferson Notation System is a set of symbols, developed by Gail Jefferson, which is used for transcribing talk. Having had some previous experience in transcribing when she was hired in 1963 as a clerk typist at the UCLA Department of Public Health to transcribe sensitivity-training sessions for prison guards, Jefferson began transcribing some of the recordings that served as the materials out of which Harvey Sacks’ earliest lectures were developed. Over four decades, for the majority of which she held no university position and was unsalaried, Jefferson's research into talk-in-interaction has set the standard for what became known as Conversation Analysis (CA). Her work has greatly influenced the sociological study of interaction, but also disciplines beyond, especially linguistics, communication, and anthropology. This system is employed universally by those working from the CA perspective and is regarded as having become a near-globalized set of instructions for transcription.\n\nA system described in (DuBois et al. 1992), used for transcription of the Santa Barbara Corpus of Spoken American English (SBCSAE), later developed further into \"DT2\".\n\nTranscription was originally a process carried out manually, i.e. with pencil and paper, using an analogue sound recording stored on, e.g., a Compact Cassette. Nowadays, most transcription is done on computers. Recordings are usually digital audio or video files, and transcriptions are electronic documents. Specialized computer software exists to assist the transcriber in efficiently creating a digital transcription from a digital recording. Among the most widely used transcription tools in linguistic research are:\n\nOther transcription software is developed for commercial sale.\n\n\n\n"}
{"id": "22618868", "url": "https://en.wikipedia.org/wiki?curid=22618868", "title": "Velleity", "text": "Velleity\n\nVelleity is the lowest degree of volition, a slight wish or tendency.\n\nThe marketer Matt Bailey described it as \"a desire to see something done, but not enough desire to make it happen\".\n\nMatt Bailey expressed an attempt \"to bring it back, as it has more relevance now than ever.\" He writes that:\n\nFriedrich Nietzsche describes the velleity of an artist as a \"desire to \"be\" 'what he is able to represent, conceive, and express'...\" Nietzsche championed the will to power, which can be encapsulated as starting with velleity, in his free-will theorem.\n\nKeith David Wyma refers frequently to the \"concept of velleity\", citing Thomas Aquinas as a pioneer of introducing the idea into philosophy.\n\nPsychologist Avi Sion writes, \"\"Many psychological concepts may only be defined and explained with reference to velleity\".\" (\"Emphasis in original\".) An example he cites is that \"an ordinarily desirable object can only properly be called 'interesting' or 'tempting' to that agent at that time, if he manifests some velleity...\"\nHe distinguishes between the two types of velleity - \"\"to do\" something and one \"not to do\" something...\" Furthermore, he asserts, \"The concept of velleity is also important because it enables us to understand the co-existence of conflicting values.\" A person could thus have \"double velleity\" or \"a mix of velleity for something and a volition for its opposite: the latter dominates, of course, but that does not erase the fact of velleity.\"\n\nKathy Kolbe also lists velleity as a \"key concept of conation.\"\n\n"}
{"id": "2892491", "url": "https://en.wikipedia.org/wiki?curid=2892491", "title": "Visual language", "text": "Visual language\n\nThe visual language is a system of communication using visual elements. Speech as a means of communication cannot strictly be separated from the whole of human communicative activity which includes the visual and the term 'language' in relation to vision is an extension of its use to describe the perception, comprehension and production of visible signs.\n\nAn image which dramatizes and communicates an idea presupposes the use of a visual language. Just as people can 'verbalize' their thinking, they can 'visualize' it. A diagram, a map, and a painting are all examples of uses of visual language. Its structural units include line, shape, colour, form, motion, texture, pattern, direction, orientation, scale, angle, space and proportion.\n\nThe elements in an image represent concepts in a spatial context, rather than the linear form used for words. Speech and visual communication are parallel and often interdependent means by which humans exchange information.\n\nVisual units in the form of lines and marks are constructed into meaningful shapes and structures or signs. Different areas of the cortex respond to different elements such as colour and form. Semir Zeki has shown the responses in the brain to the paintings of Michelangelo, Rembrandt, Vermeer, Magritte, Malevich and Picasso.\n\nWhat we have in our minds in a waking state and what we imagine in dreams is very much of the same nature. Dream images might be with or without spoken words, other sounds or colours. In the waking state there is usually, in the foreground, the buzz of immediate perception, feeling, mood and as well as fleeting memory images. In a mental state between dreaming and being fully awake is a state known as 'day dreaming' or a meditative state, during which \"the things we see in the sky when the clouds are drifting, the centaurs and stags, antelopes and wolves\" are projected from the imagination. Rudolf Arnheim has attempted to answer the question: what does a mental image look like? In Greek philosophy, the School of Leucippus and Democritus believed that a replica of an object enters the eye and remains in the soul as a memory as a complete image. Berkeley explained that parts, for example, a leg rather than the complete body, can be brought visually to the mind. Arnheim considers the psychologist, Edward B. Titchener's account to be the breakthrough in understanding something of how the vague incomplete quality of the image is 'impressionistic' and carries meaning as well as form.\n\nAbstract art has shown that the qualities of line and shape, proportion and colour convey meaning directly without the use of words or pictorial representation. Wassily Kandinsky showed how drawn lines and marks can be expressive without any association with a representational image. From the most ancient cultures and throughout history visual language has been used to encode meaning: \"The Bronze Age Badger Stone on Ilkly Moor is covered in circles, lines, hollow cups,winged figures, a spread hand, an ancient swastika, an embryo, a shooting star? … It's a story-telling rock, a message from a world before (written) words.\" Richard Gregory suggests that, \"Perhaps the ability to respond to absent imaginary situations,\" as our early ancestors did with paintings on rock, \"represents an essential step towards the development of abstract thought.\"\n\nThe sense of sight operates selectively. Perception is not a passive recording of all that is in front of the eyes, but is a continuous judgement of scale and colour relationships, and includes making categories of forms to classify images and shapes in the world. Children of six to twelve months are to be able through experience and learning to discriminate between circles, squares and triangles.The child from this age onwards learns to classify objects, abstracting essential qualities and comparing them to other similar objects. Before objects can be perceived and identified the child must be able to classify the different shapes and sizes that a single object may appear to have when it is seen in varying surroundings and from different aspects.\n\nThe perception of a shape requires the grasping of the essential structural features, to produce a \"whole\" or \"gestalt\". The theory of the \"gestalt\" was proposed by Christian von Ehrenfels in 1890. He pointed out that a melody is still recognisable when played in different keys and argued that the whole is not simply the sum of its parts but a total structure. Max Wertheimer researched von Ehrenfels' idea, and in his \"Theory of Form\" (1923) – nicknamed \"the dot essay\" because it was illustrated with abstract patterns of dots and lines – he concluded that the perceiving eye tends to bring together elements that look alike (similarity groupings) and will complete an incomplete form (object hypothesis). An array of random dots tends to form configurations (constellations). All these innate abilities demonstrate how the eye and the mind are seeking pattern and simple whole shapes. When we look at more complex visual images such as paintings we can see that art has been a continuous attempt to \"notate\" visual information.\n\nThought processes are diffused and interconnected and are cognitive at a sensory level. The mind thinks at its deepest level in sense material, and the two hemispheres of the brain deal with different kinds of thought. The brain is divided into two hemispheres and a thick bundle of nerve fibres enable these two halves to communicate with each other. In most people the ability to organize and produce speech is predominantly located in the left side. Appreciating spatial perceptions depends more on the right hemisphere, although there is a left hemisphere contribution. In an attempt to understand how designers solve problems, L. Bruce Archer proposed \"that the way designers (and everybody else, for that matter) form images in their mind's eye, manipulating and evaluating ideas before, during and after externalising them, constitutes a cognitive system comparable with but different from, the verbal language system. Indeed we believe that human beings have an innate capacity for cognitive modelling, and its expression through sketching, drawing, construction, acting out and so on, that is fundamental to human thought.\"\n\nThe visual language begins to develop in babies as the eye and brain become able to focus, and be able to recognize patterns. Children's drawings show a process of increasing perceptual awareness and range of elements to express personal experience and ideas. The development of the visual aspect of language communication in education has been referred to as graphicacy, as a parallel discipline to literacy and numeracy. The ability to think and communicate in visual terms is part of, and of equal importance in the learning process, with that of literacy and numeracy. The visual artist, as Michael Twyman has pointed out, has developed the ability to handle the visual language to communicate ideas. This includes both the understanding and conception and the production of concepts in a visual form.\n\n\n\n"}
{"id": "6872117", "url": "https://en.wikipedia.org/wiki?curid=6872117", "title": "World Englishes", "text": "World Englishes\n\nWorld Englishes is a term for emerging localized or indigenized varieties of English, especially varieties that have developed in territories influenced by the United Kingdom or the United States. The study of World Englishes consists of identifying varieties of English used in diverse sociolinguistic contexts globally and analyzing how sociolinguistic histories, multicultural backgrounds and contexts of function influence the use of English in different regions of the world.\n\nThe issue of World Englishes was first raised in 1978 to examine concepts of regional Englishes globally. Pragmatic factors such as appropriateness, comprehensibility and interpretability justified the use of English as an international and intra-national language. In 1988, at a Teachers of English to Speakers of Other Languages (TESOL) conference in Honolulu, Hawaii, the International Committee of the Study of World Englishes (ICWE) was formed. In 1992, the ICWE formally launched the International Association for World Englishes (IAWE) at a conference of \"World Englishes Today\", at the University of Illinois, USA. There is now an academic journal devoted to the study of this topic, titled \"World Englishes\".\n\nCurrently, there are approximately 75 territories where English is spoken either as a first language (L1) or as an unofficial or institutionalized second language (L2) in fields such as government, law and education. It is difficult to establish the total number of Englishes in the world, as new varieties of English are constantly being developed and discovered.\n\nThe notions of World English and World Englishes are far from similar, although the terms are often mistakenly used interchangeably. \"World English\" refers to the English language as a lingua franca used in business, trade, diplomacy and other spheres of global activity, while \"World Englishes\" refers to the different varieties of English and English-based creoles developed in different regions of the world. Alternatively, the term \"Global Englishes\" has been used by scholars in the field to emphasise the more recent spread of English due to globalization, which has resulted in increased usage of English as a lingua franca.\n\nEnglish is a West Germanic language that originated from the Anglo-Frisian dialects brought by Germanic invaders into Britain. Initially, Old English was a diverse group of dialects, reflecting the varied origins of the Anglo-Saxon kingdoms of England. Eventually, one of these dialects, Late West Saxon, came to dominate.\n\nThe original Old English language was then influenced by two further waves of invasion: the first by speakers of the Scandinavian branch of the Germanic language family, who conquered and colonized parts of Britain in the 8th and 9th centuries; the second by the Normans in the 11th century, who spoke Old Norman and ultimately developed a Norman variety called Anglo-Norman. For two centuries after the Norman Conquest, French became the language of everyday life among the upper classes in England. Although the language of the masses remained English, the bilingual character of England in this period was thus formed.\n\nDuring the Middle English period, France and England experienced a process of separation. This period of conflicting interests and feelings of resentment was later termed the Hundred Years' War. By the beginning of the 14th century, English had regained universal use and become the principal tongue of all England, but not without having undergone significant change.\n\nDuring the Renaissance, patriotic feelings regarding English brought about the recognition of English as the national language of England. The language was advocated as acceptable for learned and literary use. With the Great Vowel Shift, the language in this period matured to a standard and differed significantly from the Middle English period, becoming recognizably \"modern\".\n\nBy the 18th century, three main forces were driving the direction of the English language: (1) to reduce the language to rule and effect a standard of correct usage; (2) to refine the language by removing supposed defects and introducing certain improvements; and (3) to fix English permanently in the desired form. This desire for system and regularity in the language contrasted with the individualism and spirit of independence characterized by the previous age.\n\nBy the 19th century, the expansion of the British Empire, as well as global trade, had led to the spread of English around the world. The rising importance of some of England's larger colonies and former colonies, such as the rapidly developing United States, enhanced the value of the English varieties spoken in these regions, encouraging the belief, among the local populations, that their distinct varieties of English should be granted equal standing with the standard of Great Britain.\n\nThe first diaspora involved relatively large-scale migrations of mother-tongue English speakers from England, Scotland and Ireland predominantly to North America and the Caribbean, Australia, South Africa and New Zealand. Over time, their own English dialects developed into modern American, Canadian, West Indian, South African, Australian, and New Zealand Englishes. In contrast to the English of Great Britain, the varieties spoken in modern North America and Caribbean, South Africa, Australia, and New Zealand have been modified in response to the changed and changing sociolinguistic contexts of the migrants, for example being in contact with indigenous Native American, Khoisan and Bantu, Aboriginal or Maori populations in the colonies.\n\nThe second diaspora was the result of the colonization of Asia and Africa, which led to the development of 'New Englishes', the second-language varieties of English. In colonial Africa, the history of English is distinct between West and East Africa. English in West Africa began with trade. particularly the slave trade. English soon gained official status in what are today Gambia, Sierra Leone, Ghana, Nigeria and Cameroon, and some of the pidgin and creoles which developed from English contact, including Krio (Sierra Leone) and Cameroon Pidgin, have large numbers of speakers now.\n\nAs for East Africa, extensive British settlements were established in what are now Kenya, Uganda, Tanzania, Malawi, Zambia and Zimbabwe, where English became a crucial language of the government, education and the law. From the early 1960s, the six countries achieved independence in succession; but English remained the official language and had large numbers of second language speakers in Uganda, Zambia, Zimbabwe and Malawi (along with Chewa).\n\nEnglish was formally introduced to the sub-continent of South Asia (India, Bangladesh, Pakistan, Sri Lanka, Nepal and Bhutan) during the second half of the eighteenth century. In India, English was given status through the implementation of Macaulay 'Minute' of 1835, which proposed the introduction of an English educational system in India. Over time, the process of 'Indianisation' led to the development of a distinctive national character of English in the Indian sub-continent.\n\nBritish influence in South-East Asia and the South Pacific began in the late eighteenth century, involving primarily the territories now known as Singapore, Malaysia and Hong Kong. Papua New Guinea, also a British protectorate, exemplified the English-based pidgin - Tok Pisin.\n\nThe Americans came late in South-East Asia but their influence spread like wildfire as their reforms on education in the Philippines progressed in their less than half a century colonization of the islands. English has been taught since the American period and is one of the official languages of the Philippines. Ever since English became the official language, a localized variety gradually emerged - Philippine English. Lately, linguist Wilkinson Daniel Wong Gonzales argued that this variety has in itself more varieties, suggesting that we move towards Philippine Englishes paradigm to progress further in Schneider's dynamic model after gathering evidences of such happening.\n\nNowadays, English is also learnt in other countries in neighbouring areas, most notably in Taiwan, Japan and Korea, with the latter two having begun to consider the possibility of making English their official second language.\n\nThe spread of English around the world is often discussed in terms of three distinct groups of users, where English is used respectively as:\n\n\n The most influential model of the spread of English is Braj Kachru's model of World Englishes. In this model the diffusion of English is captured in terms of three Concentric Circles of the language: The Inner Circle, the Outer Circle, and the Expanding Circle.\n\nThe Inner Circle refers to English as it originally took shape and was spread across the world in the first diaspora. In this transplantation of English, speakers from England carried the language to Australia, New Zealand and North America. The Inner Circle thus represents the traditional historical and sociolinguistic bases of English in regions where it is now used as a primary language: the United Kingdom, the United States, Australia, New Zealand, Ireland, anglophone Canada and South Africa, and some of the Caribbean territories. English is the native language or mother tongue of most people in these countries. The total number of English speakers in the inner circle is as high as 380 million, of whom some 120 million are outside the United States.\n\nThe Outer Circle of English was produced by the second diaspora of English, which spread the language through imperial expansion by Great Britain in Asia and Africa. In these regions, English is not the native tongue, but serves as a useful lingua franca between ethnic and language groups. Higher education, the legislature and judiciary, national commerce and so on may all be carried out predominantly in English. This circle includes India, Nigeria, Bangladesh, Pakistan, Malaysia, Tanzania, Kenya, non-Anglophone South Africa, the Philippines (colonized by the US) and others. The total number of English speakers in the outer circle is estimated to range from 150 million to 300 million. Singapore, while in the Outer Circle, may be drifting into the Inner Circle as English becomes more often used as a home language (see Languages of Singapore), much as Ireland did earlier. Countries where most people speak an English-based creole and retain standard English for official purposes, such as Jamaica and Papua New Guinea, are also in the Outer Circle.\n\nFinally, the Expanding Circle encompasses countries where English plays no historical or governmental role, but where it is nevertheless widely used as a medium of international communication. This includes much of the rest of the world's population not categorized above, including territories such as China, Russia, Japan, non-Anglophone Europe (especially the Netherlands and Nordic countries), South Korea, Egypt and Indonesia. The total in this expanding circle is the most difficult to estimate, especially because English may be employed for specific, limited purposes, usually in a business context. The estimates of these users range from 100 million to one billion.\n\nThe inner circle (UK, US etc.) is 'norm-providing'; that means that English language norms are developed in these countries. The outer circle (mainly New Commonwealth countries) is 'norm-developing'. The expanding circle (which includes much of the rest of the world) is 'norm-dependent', because it relies on the standards set by native speakers in the inner circle.\n\nEdgar Werner Schneider tries to avoid a purely geographical and historical approach evident in the 'circles' models and incorporates sociolinguistic concepts pertaining to acts of identity.\nHe outlines five characteristic stages in the spread of English:\n\nPhase 1 - Foundation: This is the initial stage of the introduction of English to a new territory over an extended period of time. Two linguistic processes are operative at this stage: (a) language contact between English and indigenous languages; (b) contact between different dialects of English of the settlers which eventually results in a new stable dialect (see koiné). At this stage, bilingualism is marginal. A few members of the local populace may play an important role as interpreters, translators and guides. Borrowings are limited to lexical items; with local place names and terms for local fauna and flora being adopted by the English.\n\nPhase 2 - Exonormative stabilization: At this stage, the settler communities tend to stabilize politically under British rule. English increases in prominence and though the colloquial English is a colonial koiné, the speakers look to England for their formal norms. Local vocabulary continues to be adopted. Bilingualism increases amongst the indigenous population through education and increased contacts with English settlers. Knowledge of English becomes an asset, and a new indigenous elite develops.\n\nPhase 3 - Nativisation: According to Schneider, this is the stage at which a transition occurs as the English settler population starts to accept a new identity based on present and local realities, rather than sole allegiance to their 'mother country'. By this time, the indigenous strand has also stabilized an L2 system that is a synthesis of substrate effects, interlanguage processes and features adopted from the settlers' koiné English. Neologisms stabilize as English is made to adapt to local sociopolitical and cultural practices.\n\nPhase 4 - Endonormative stabilization: This stage is characterized by the gradual acceptance of local norms, supported by a new locally rooted linguistic self-confidence. By this time political events have made it clear that the settler and indigenous strands are inextricably bound in a sense of nationhood independent of Britain. Acceptance of local English(es) expresses this new identity. National dictionaries are enthusiastically supported, at least for new lexis (and not always for localized grammar). Literary creativity in local English begins to flourish.\n\nPhase 5 - Differentiation: At this stage there is a change in the dynamics of identity as the young nation sees itself as less defined by its differences from the former colonial power as a composite of subgroups defined on regional, social and ethnic lines. Coupled with the simple effects of time in effecting language change (with the aid of social differentiation) the new English koiné starts to show greater differentiation.\n\nThe oldest map of the spread of English is Strevens's world map of English. His world map, even predating that of Kachru's three circles, showed that since American English became a separate variety from British English, all subsequent Englishes have had affinities with either one or the other.\n\nMcArthur's \"wheel model\" has an idealized central variety called \"World Standard English,\" which is best represented by \"written international English.\" The next circle is made of regional standards or standards that are emerging. Finally, the outer layer consists of localized varieties which may have similarities with the regional standards or emerging standards.\n\nAlthough the model is neat, it raises several problems. Firstly, the three different types of English — ENL, ESL and EFL, are conflated in the second circle. Secondly, the multitude of Englishes in Europe are also missing in this layer. Finally, the outside layer includes pidgins, creoles and L2 Englishes. Most scholars would argue that English pidgins and creoles do not belong to one family: rather they have overlapping multiple memberships.\n\nManfred Görlach's and McArthur's models are reasonably similar. Both exclude English varieties in Europe. As Görlach does not include EFLs at all, his model is more consistent, though less comprehensive. Outside the circle are mixed varieties (pidgins, creoles and mixed languages involving English), which are better categorized as having partial membership.\n\nIn Modiano's model of English, the center consists of users of English as an International Language, with a core set of features which are comprehensible to the majority of native and competent non-native speakers of English. The second circle consists of features which may become internationally common or may fall into obscurity. Finally, the outer area consists of five groups (American English, British English, other major varieties, local varieties, foreign varieties) each with features peculiar to their own speech community and which are unlikely to be understood by most members of the other four groups.\n\nThe World Englishes paradigm is not static, and neither are rapidly changing realities of language use worldwide. The use of English in the Outer and Expanding Circle societies (refer to Kachru's Three Circles of English) continues its rapid spread, while at the same time new patterns of language contact and variety differentiation emerge. The different varieties range from English in the Inner circle societies such as the United States, Canada, South Africa, Australia and New Zealand, to the Outer circle post-colonial societies of Asia and Africa.\nThe World Englishes initiative, in recognizing and describing the New Englishes of the Caribbean, Africa and Asia, has been partly motivated by a consideration of the local linguistic factors and partly by a consideration of the wider cultural and political contexts of language acquisition and use. This, in turn, has involved the creative rewriting of discourses towards a recognition of pluralism and multiple possibilities for scholarship. The notion of varieties in this context is similarly dynamic, as new contexts, new realities, new discourses, and new varieties continue to emerge.\n\nThe terms \"language\" and \"dialect\" are not easily defined concepts. It is often suggested that languages are autonomous, while dialects are heteronomous. It is also said that dialects, in contrast with languages, are mutually intelligible, though this is not always the case. Dialects are characteristically spoken, do not have a codified form and are used only in certain domains.\nIn order to avoid the difficult dialect-language distinction, linguists tend to prefer a more neutral term, \"variety\", which covers both concepts and is not clouded by popular usage. This term is generally used when discussing World Englishes.\n\nTwo scenarios have been advanced about English's future status as the major world language: it will ultimately fragment into a large number of mutually unintelligible varieties (in effect, languages), or it will converge so that differences across groups of speakers are largely eliminated.\n\nIf English is, numerically speaking, the language of 'others', then the center of gravity of the language is almost certain to shift in the direction of the 'others'. In the words of Widdowson, there is likely to be a paradigm shift from one of language distribution to one of language spread:\nIn this new paradigm, English spreads and adapts according to the linguistic and cultural preferences of its users in the Outer and Expanding circles (refer to Kachru's Three Circles of English). However, if English is genuinely to become the language of 'others', then the 'others' have to be accorded – or perhaps more likely, accord themselves – at least the same English language rights as those claimed by mother-tongue speakers.\n\nThe other potential shift in the linguistic center of gravity is that English could lose its international role altogether, or come to share it with a number of equals. Although this would not happen mainly as a result of native-speaker resistance to the spread of non-native speaker Englishes and the consequent abandoning of English by large numbers of non-native speakers, the latter could play a part.\n\nAs evidence that English may eventually give way to another language (or languages) as the world's lingua franca, David Crystal cites Internet data:\n\nOn the other hand, there are at least 1500 languages present on the internet now and that figure is likely to increase. Nevertheless, Crystal predicts that English will retain its dominant presence.\n\n"}
{"id": "3032466", "url": "https://en.wikipedia.org/wiki?curid=3032466", "title": "Writing circle", "text": "Writing circle\n\nA writing circle is a group of like-minded writers needing support for their work, either through writing peer critiques, workshops or classes, or just encouragement. There are many different types of writing circles or writing groups based on location, style of writing, or format. Normally, the goal of a writing circle is to improve one's own craft by listening to the works and suggestions of others in the group. It also builds a sense of community, and allows new writers to become accustomed to sharing their work. Writing circles can be helpful inside and outside of the classroom.\n\nA writing circle brings writers from different walks of life together in one place to discuss their work in a workshop style setting. Writers will be able to give feedback and hear suggestions from fellow writers. It can build community in a classroom and help students gain public speaking cleans. This workshop method could be used for any genre of writing (creative prose, poetry, etc.).\n\nWriting circles can build a sense of community and help writers become more confident in their own work. They teach writers how give and receive constructive criticism enable them to learn from one another's mistakes and successes and appreciate different opinions and views. In some cases writing circles can be used a form of group therapy (Writing for healing).\n\n\n\n"}
