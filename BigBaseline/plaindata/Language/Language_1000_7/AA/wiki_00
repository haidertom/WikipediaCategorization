{"id": "406551", "url": "https://en.wikipedia.org/wiki?curid=406551", "title": "Applied linguistics", "text": "Applied linguistics\n\nApplied linguistics is an interdisciplinary field of linguistics which identifies, investigates, and offers solutions to language-related real-life problems. Some of the academic fields related to applied linguistics are education, psychology, communication research, anthropology, and sociology.\n\nApplied linguistics is an interdisciplinary field of linguistics. Major branches of applied linguistics include bilingualism and multilingualism, conversation analysis, contrastive linguistics, sign linguistics, language assessment, literacies, discourse analysis, language pedagogy, second language acquisition, language planning and policy, interlinguistics, stylistics, pragmatics, forensic linguistics and translation.\n\nMajor journals of the field include \"Annual Review of Applied Linguistics\", \"Applied Linguistics\", \"Journal of Applied Linguistics\", \"International Review of Applied Linguistics\", \"International Journal of Applied Linguistics\", \"European Journal of Applied Linguistics\", \"Issues in Applied Linguistics\", \"Language Learning\", \"Language and Education, TESOL Quarterly\", and \"Linguistics and Education\".\n\nThe tradition of applied linguistics established itself in part as a response to the narrowing of focus in linguistics with the advent in the late 1950s of generative linguistics, and has always maintained a socially-accountable role, demonstrated by its central interest in language problems.\n\nAlthough the field of applied linguistics started from Europe and the United States, the field rapidly flourished in the international context.\n\nApplied linguistics first concerned itself with principles and practices on the basis of linguistics. In the early days, applied linguistics was thought as “linguistics-applied” at least from the outside of the field. In the 1960s, however, applied linguistics was expanded to include language assessment, language policy, and second language acquisition. As early as the 1970s, applied linguistics became a problem-driven field rather than theoretical linguistics, including the solution of language-related problems in the real world. By the 1990s, applied linguistics had broadened including critical studies and multilingualism. Research in applied linguistics was shifted to \"the theoretical and empirical investigation of real world problems in which language is a central issue.\"\n\nIn the United States, applied linguistics also began narrowly as the application of insights from structural linguistics—first to the teaching of English in schools and subsequently to second and foreign language teaching. The \"linguistics applied\" approach to language teaching was promulgated most strenuously by Leonard Bloomfield, who developed the foundation for the Army Specialized Training Program, and by Charles C. Fries, who established the English Language Institute (ELI) at the University of Michigan in 1941. In 1946, Applied linguistics became a recognized field of studies in the aforementioned university. In 1948, the Research Club at Michigan established \"Language Learning: A Journal of Applied Linguistics\", the first journal to bear the term \"applied linguistics.\" In the late 1960s, applied linguistics began to establish its own identity as an interdisciplinary field of linguistics concerned with real-world language issues. The new identity was solidified by the creation of the American Association for Applied Linguistics in 1977.\n\nThe International Association of Applied Linguistics was founded in France in 1964, where it is better known as Association Internationale de Linguistique Appliquée, or AILA. AILA has affiliates in more than thirty countries, some of which are listed below.\n\nAustralia\nAustralian applied linguistics took as its target the applied linguistics of mother tongue teaching and teaching English to immigrants. The Australia tradition shows a strong influence of continental Europe and of the USA, rather than of Britain. Applied Linguistics Association of Australia (ALAA) was established at a national congress of applied linguists held in August 1976. ALAA holds a joint annual conference in collaboration with the Association for Applied Linguistics in New Zealand (ALANZ).\n\nCanada\nThe Canadian Association of Applied Linguistics / L’Association canadienne de linguistique appliquée (CAAL/ACLA), is an officially bilingual (English and French) scholarly association with approximately 200 members. They produce the \"Canadian Journal of Applied Linguistics\" and hold an annual conference.\n\nIreland\nThe Irish Association for Applied Linguistics/Cumann na Teangeolaíochta Feidhmí (IRAAL) was founded in 1975. They produce the journal \"Teanga\", the Irish word for 'language'.\n\nJapan\nIn 1982, the Japan Association of Applied Linguistics (JAAL) was established in the Japan Association of College English Teachers (JACET) in order to engage in activities on a more international scale. In 1984, JAAL became an affiliate of the International Association of Applied Linguistics (AILA).\n\nNew Zealand\nThe Applied Linguistics Association of New Zealand (ALANZ) produces the journal \"New Zealand Studies in Applied Linguistics\" and has been collaborating with the Applied Linguistics Association of Australia in a combined annual conference since 2010, with the Association for Language Testing and Assessment of Australia and New Zealand (ALTAANZ) later joining the now three-way conference collaboration. \n\nSouth Africa\nThe Southern African Applied Linguistics Association (SAALA) was founded in 1980. There are currently four publications associated with SAALA including the \"Southern African Linguistics and Applied Language Studies Journal\" (SAJALS).\n\nUnited Kingdom\nThe British Association for Applied Linguistics (BAAL) was established in 1967. Its mission is \"the advancement of education by fostering and promoting, by any lawful charitable means, the study of language use, language acquisition and language teaching and the fostering of interdisciplinary collaboration in this study [...]\". BAAL hosts an annual conference, as well as many additional smaller conferences and events organised by its Special Interest Groups (SIGs). \n\nUnited States\nThe American Association for Applied Linguistics (AAAL) was founded in 1977. AAAL holds an annual conference, usually in March or April, in the United States or Canada.\n\n\n"}
{"id": "3368303", "url": "https://en.wikipedia.org/wiki?curid=3368303", "title": "Chunking (writing)", "text": "Chunking (writing)\n\nChunking is a method of presenting information which splits concepts into small pieces or \"chunks\" of information to make reading and understanding faster and easier. Chunking is especially useful for material presented on the web because readers tend to scan for specific information on a web page rather than read the page sequentially.\n\nChunked content usually contains:\n\n\nThe bite, snack and meal is a popular phrase for a specific means of chunking content.\n\n"}
{"id": "20765789", "url": "https://en.wikipedia.org/wiki?curid=20765789", "title": "Competition model", "text": "Competition model\n\nThe competition model is a psycholinguistic theory of language acquisition and sentence processing, developed by Elizabeth Bates and Brian MacWhinney (1981).\n\nThe model suggests that the meaning of language is interpreted by comparing a number of linguistic 'cues' (signaling specific functions) within a sentence, and that language is learned through the competition of basic cognitive mechanisms inside a rich linguistic environment.\n\nIt is an emergentist theory of language acquisition and processing, serving as an alternative to strict innatist and empiricist theories.\n\nAccording to the competition model, competitive cognitive processes operate on a phylogenetic, ontogenetic, and synchronic scale, allowing language acquisition to take place across a wide variety of chronological periods.\n\nIn its original instantiation, the competition model was proposed as a theory of cross-linguistic sentence processing.\n\nThe competition model suggests that people interpret the meaning of a sentence by taking into account various linguistic cues contained in the sentence context ('cotext'), such as word order, morphology, and semantic characteristics (e.g., animacy), to compute a probabilistic value for each interpretation, eventually choosing the interpretation with the highest likelihood. According to the model, cue weights are learned inductively on the basis of a 'constrained set of sentence types' and 'limited predictions of sentence meaning' for each language.\n\nBecause different languages use different cues to signal meanings, the competition model maintains that cue weights will differ between languages, and users of a given language will use the cue weights associated with that language, to guide their interpretation of sentences.\n\nThus, when people learn other languages, they must learn which cues are important in which languages, in order to successfully interpret sentences in any language.\n\nMore recently, the competition model has been developed into a unified theory of first and second language acquisition.\n\nIts scope has been expanded to account for a number of psycholinguistic processes involved in language acquisition, including arenas, cues, storage, chunking, codes, and resonance.\n\nThe expanded version of the competition model posits that each of these cognitive mechanisms controls the activation of representations in the target language – and in the native language, as for L2 learners – which compete in the mind of the learner during acquisition and usage of the language.\n\nAs in the original version of the model, the weights of the competing representations are computed and adjusted in real-time, based on the learner's experience with the target language.\n\nThus, the model infers that as the extensiveness of learners' exposure to the target language increases, they will gain an increasingly complete and nuanced understanding of the meaning of sentences in the target language.\n\nBy definition, the competition model is an emergentist theory of language acquisition.\n\nRather than viewing language acquisition as a process that is based on innate, language-specific mechanisms (e.g., Chomsky's concepts of the language acquisition device and universal grammar), or rather as completely dependent upon one's experience with language or on the influence of the environment, the competition model views language acquisition as a process consisting of a series of competitive cognitive processes that act upon an analog linguistic signal.\n\nBy applying general cognitive processes to the language stimulus in the presence of a rich and stimulating environment, we are able to connect intrinsically meaningless symbols (words and sentences) to their referents, which allows us to infer meaning.\n\nThus, in addition to relying on traditional mechanisms of human information processing, the competition model posits that language acquisition must be embodied and situated in order for learners to derive meaning from language.\n\nIn this sense, the competition model follows many of the principles of situated cognition, situated learning, and legitimate peripheral participation.\n\nOn the synchronic time scale of online language processing, the competition model hypothesizes that utterances provide cues that adjudicate the competition between alternative interpretations. It views language processing as a series of competitions between lexical items, phonological forms, and syntactic patterns. Studies based on the Competition Model have shown that learning of language forms relies on the accurate recording of many exposures to words and patterns in different contexts. If a pattern is reliably present in adult language input, children acquire it quickly. Rare and unreliable language patterns are learned late and are relatively weaker, even in adults.\n\nOn the ontogenetic time scale, the competition model posits that language emergence can be examined in at least two ways. One methodology uses neural network models to simulate the acquisition of detailed grammatical structures. Competition model researchers have constructed connectionist models for the acquisition of morphology, syntax, and lexicon in several languages, including English, German, and Hungarian. More recently, the ontogenetic emergence of language has been examined from a biological viewpoint, using data on language processing from children with early focal lesions. The results of studies of these children using reaction time methodologies and neuropsychological tests indicate that, although they have completely normal functional use of language, detailed aspects of processing are slower in some cases. Using functional magnetic resonance imaging technology, areas of neurological activation involved in specific linguistic tasks have been pinpointed in these children. These results have allowed researchers to evaluate a series of hypotheses regarding sensitive periods for the emergence of language in the brain.\n\nOn the phylogenetic time scale, researchers working within the framework of the competition model have begun to examine the ways in which language originally emerged through competitive Darwinian processes. Research on cognitive perspective taking, competition, and brain mechanisms suggests that the most likely account of the origin of language is one grounded on language as a medium of social interaction. In this sense, the elaboration of an emergent account of perspective taking suggests a Vygotskyan approach to language evolution.\n\nOn the level of mental model construction, the communicative functions of language postulated by the competition model have been related to the process of perspective taking. This process allows the human mind to construct an ongoing cognitive simulation of the meaning of an utterance coded in linguistic abstractions, through the use of perceptual realities derived from one's embodied experience. The perspective taking approach views the forms of grammar as emerging from repeated acts of perspective taking and perspective switching during online language comprehension. Grammatical devices such as pronouns, case, voice, and attachment can all be seen as ways of expressing shifts in a basically ego-centered perspective. One major goal in this line of research is to better understand the brain mechanisms underlying perspective shifting during language comprehension.\n\nIn addition to accounting for the acquisition of a first language by children, the competition model accounts for the learning of second languages. In its conceptualization, the model's creators used linguistic data from 18 different languages to elaborate the parameters and mechanisms of the model. \n\nEmpirical studies conducted within the competition model framework have supported the predictions of a connectionist perspective, emphasizing the role of transfer and interference in second language learning.\n\nAlthough first and second language acquisition share many features in common, they also differ because of a series of four risk factors (\"entrenchment\", \"transfer\", \"over analysis\", and \"social isolation\") which the adult second language learner faces. Fortunately, a determined adult second language learner can also rely on a series of protective factors to compensate for these disadvantages. \n\nThese compensatory factors include \"resonance\", working to connect new L2 forms; \"decoupling\", operating to bind together L2 as separate from L1; \"chunking\", reducing the effects of overanalysis; and \"participation\", countering the tendency to social isolation.\n\n\n"}
{"id": "13477931", "url": "https://en.wikipedia.org/wiki?curid=13477931", "title": "Computer Russification", "text": "Computer Russification\n\nIn computing, Russification involves the localization of computers and software, allowing the user interface of a computer and its software to communicate in the Russian language using Cyrillic script.\n\nProblems associated with Russification before the advent of Unicode included the absence of a single character-encoding standard for Cyrillic (see Cyrillic script#Computer encoding).\n\nThe first official Russification of MS-DOS was carried out for MS-DOS 4.01 in 1989/1990, released on . In Microsoft, the Russification project manager and one of its main developers was Nikolai Lyubovny (Николай Любовный). A Russian version of MS-DOS 5.0 was also developed in 1991, released on . Based on an initiative of Microsoft Germany in March 1991, derivates of the Russian MS-DOS 5.0 drivers used for keyboard, display and printer localization support (DISPLAY.SYS, EGA.CPI, EGA2.CPI, KEYB.COM, KEYBOARD.SYS, MSPRINT.SYS, COUNTRY.SYS, ALPHA.EXE) could also be purchased separately (with English messages) as part of Microsoft's \"AlphabetPlus\" kit. This enabled English issues of MS-DOS 3.3, 4.01 and 5.0 to be set up for Eastern European countries like Czechoslovakia, Poland, Hungary, Yugoslavia, Romania and Bulgaria.\n\nA comprehensive instruction set for computer Russification is maintained by Paul Gorodyansky. It is mirrored in many places and recommended by the U.S. Library of Congress.\n\n\n"}
{"id": "8886", "url": "https://en.wikipedia.org/wiki?curid=8886", "title": "Deconstruction", "text": "Deconstruction\n\nDeconstruction is a critique of the relationship between text and meaning originated by the philosopher Jacques Derrida. Derrida's approach consisted in conducting readings of texts with an ear to what runs counter to the intended meaning or structural unity of a particular text. The purpose of deconstruction is to show that the usage of language in a given text, and language as a whole, are irreducibly complex, unstable, or impossible. Throughout his readings, Derrida hoped to show deconstruction at work.\n\nMany debates in continental philosophy surrounding ontology, epistemology, ethics, aesthetics, hermeneutics, and philosophy of language refer to Derrida's observations. Since the 1980s, these observations inspired a range of theoretical enterprises in the humanities, including the disciplines of law anthropology, historiography, linguistics, sociolinguistics, psychoanalysis, LGBT studies, and the feminist school of thought. Deconstruction also inspired deconstructivism in architecture and remains important within art, music, and literary criticism.\n\nWhile common in continental Europe (and wherever Continental philosophy is in the mainstream), deconstruction is not adopted or accepted by most philosophy departments in universities where analytic philosophy is predominant.\n\nJacques Derrida's 1967 book \"Of Grammatology\" introduced the majority of ideas influential within deconstruction. Derrida published a number of other works directly relevant to the concept of deconstruction. Books showing deconstruction in action or defining it more completely include \"Différance\", \"Speech and Phenomena\", and \"Writing and Difference\".\n\nAccording to Derrida and taking inspiration from the work of Ferdinand de Saussure, language as a system of signs and words only has meaning because of the contrast between these signs. As Rorty contends, \"words have meaning only because of contrast-effects with other words...no word can acquire meaning in the way in which philosophers from Aristotle to Bertrand Russell have hoped it might—by being the unmediated expression of something non-linguistic (e.g., an emotion, a sense-datum, a physical object, an idea, a Platonic Form)\". As a consequence, meaning is never present, but rather is deferred to other signs. Derrida refers to the—in this view, mistaken—belief that there is a self-sufficient, non-deferred meaning as metaphysics of presence. A concept, then, must be understood in the context of its opposite, such as being/nothingness, normal/abnormal, speech/writing, etc.\n\nFurther, Derrida contends that \"in a classical philosophical opposition we are not dealing with the peaceful coexistence of a vis-a-vis, but rather with a violent hierarchy. One of the two terms governs the other (axiologically, logically, etc.), or has the upper hand\": signified over signifier; intelligible over sensible; speech over writing; activity over passivity, etc. The first task of deconstruction would be to find and overturn these oppositions inside a text or a corpus of texts; but the final objective of deconstruction is not to surpass all oppositions, because it is assumed they are structurally necessary to produce sense. The oppositions simply cannot be suspended once and for all. The hierarchy of dual oppositions always reestablishes itself. Deconstruction only points to the necessity of an unending analysis that can make explicit the decisions and arbitrary violence intrinsic to all texts.\n\nFinally, Derrida argues that it is not enough to expose and deconstruct the way oppositions work and then stop there in a nihilistic or cynical position, \"thereby preventing any means of intervening in the field effectively\". To be effective, deconstruction needs to create new terms, not to synthesize the concepts in opposition, but to mark their difference and eternal interplay. This explains why Derrida always proposes new terms in his deconstruction, not as a free play but as a pure necessity of analysis, to better mark the intervals. Derrida called undecidables—that is, unities of simulacrum—\"false\" verbal properties (nominal or semantic) that can no longer be included within philosophical (binary) opposition, but which, however, inhabit philosophical oppositions—resisting and organizing it—without ever constituting a third term, without ever leaving room for a solution in the form of Hegelian dialectics (e.g., différance, archi-writing, pharmakon, supplement, hymen, gram, spacing).\n\nDerrida's theories on deconstruction were themselves influenced by the work of linguists such as Ferdinand de Saussure (whose writings on semiotics also became a cornerstone of structuralist theory in the mid-20th century) and literary theorists such as Roland Barthes (whose works were an investigation of the logical ends of structuralist thought). Derrida's views on deconstruction stood in opposition to the theories of structuralists such as psychoanalytic theorist Jacques Lacan, and linguist Claude Lévi-Strauss. However, Derrida resisted attempts to label his work as \"post-structuralist\".\n\nIn order to understand Derrida's motivation, one must refer to Nietzsche's philosophy.\n\nNietzsche's project began with Orpheus, the man underground. This foil to Platonic light was deliberately and self-consciously lauded in \"Daybreak\", when Nietzsche announces, albeit retrospectively, \"In this work you will discover a subterranean man at work\", and then goes on to map the project of unreason: \"All things that live long are gradually so saturated with reason that their origin in unreason thereby becomes improbable. Does not almost every precise history of an origination impress our feelings as paradoxical and wantonly offensive? Does the good historian not, at bottom, constantly contradict?\".\n\nNietzsche's point in \"Daybreak\" is that standing at the end of modern history, modern thinkers know too much to be deceived by the illusion of reason any more. Reason, logic, philosophy and science are no longer solely sufficient as the royal roads to truth. And so Nietzsche decides to throw it in our faces, and uncover the truth of Plato, that he—unlike Orpheus—just happened to discover his true love in the light instead of in the dark. This being merely one historical event amongst many, Nietzsche proposes that we revisualize the history of the West as the history of a series of political moves, that is, a manifestation of the will to power, that at bottom have no greater or lesser claim to truth in any noumenal (absolute) sense. By calling our attention to the fact that he has assumed the role of Orpheus, the man underground, in dialectical opposition to Plato, Nietzsche hopes to sensitize us to the political and cultural context, and the political influences that impact authorship. For example, the political influences that led one author to choose philosophy over poetry (or at least \"portray\" himself as having made such a choice), and another to make a different choice.\n\nThe problem with Nietzsche, as Derrida sees it, is that he did not go far enough. That he missed the fact that this will to power is itself but a manifestation of the operation of writing. And so Derrida wishes to help us step beyond Nietzsche's penultimate revaluation of all western values, to the ultimate, which is the final appreciation of \"the role of writing in the production of knowledge\".\n\nDerrida approaches all texts as constructed around elemental oppositions which all discourse has to articulate if it intends to make any sense whatsoever. This is so because identity is viewed in non-essentialist terms as a construct, and because constructs only produce meaning through the interplay of difference inside a \"system of distinct signs\". This approach to text is influenced by the semiology of Ferdinand de Saussure.\n\nSaussure is considered one of the fathers of structuralism when he explained that terms get their meaning in reciprocal determination with other terms inside language:\n\nIn language there are only differences. Even more important: a difference generally implies positive terms between which the difference is set up; but in language there are only differences without positive terms. Whether we take the signified or the signifier, language has neither ideas nor sounds that existed before the linguistic system, but only conceptual and phonic differences that have issued from the system. The idea or phonic substance that a sign contains is of less importance than the other signs that surround it. [...] A linguistic system is a series of differences of sound combined with a series of differences of ideas; but the pairing of a certain number of acoustical signs with as many cuts made from the mass thought engenders a system of values.\n\nSaussure explicitly suggested that linguistics was only a branch of a more general semiology, a science of signs in general, human codes being only one part. Nevertheless, in the end, as Derrida pointed out, Saussure made linguistics \"the regulatory model\", and \"for essential, and essentially metaphysical, reasons had to privilege speech, and everything that links the sign to phone\". Derrida will prefer to follow the more \"fruitful paths (formalization)\" of a general semiotics without falling into what he considered \"a hierarchizing teleology\" privileging linguistics, and to speak of \"mark\" rather than of language, not as something restricted to mankind, but as prelinguistic, as the pure possibility of language, working everywhere there is a relation to something else.\n\nDerrida's original use of the word \"deconstruction\" was a translation of \"Destruktion\", a concept from the work of Martin Heidegger that Derrida sought to apply to textual reading. Heidegger's term referred to a process of exploring the categories and concepts that tradition has imposed on a word, and the history behind them.\n\nDerrida's concerns flow from a consideration of several issues:\n\n\nTo this end, Derrida follows a long line of modern philosophers, who look backwards to Plato and his influence on the Western metaphysical tradition. Like Nietzsche, Derrida suspects Plato of dissimulation in the service of a political project, namely the education, through critical reflections, of a class of citizens more strategically positioned to influence the polis. However, like Nietzsche, Derrida is not satisfied merely with such a political interpretation of Plato, because of the particular dilemma modern humans find themselves in. His Platonic reflections are inseparably part of his critique of modernity, hence the attempt to be something beyond the modern, because of this Nietzschian sense that the modern has lost its way and become mired in nihilism.\n\nDifférance is the observation that the meanings of words come from their synchrony with other words within the language and their diachrony between contemporary and historical definitions of a word. Understanding language, according to Derrida, requires an understanding of both viewpoints of linguistic analysis. The focus on diachrony has led to accusations against Derrida of engaging in the etymological fallacy.\n\nThere is one statement by Derrida—in an essay on Rousseau in \"Of Grammatology\"—which has been of great interest to his opponents. It is the assertion that \"there is no outside-text\" (\"il n'y a pas de hors-texte\"), which is often mistranslated as \"there is nothing outside of the text\". The mistranslation is often used to suggest Derrida believes that nothing exists but words. Michel Foucault, for instance, famously misattributed to Derrida the very different phrase \"Il n'y a rien en dehors du texte\" for this purpose. According to Derrida, his statement simply refers to the unavoidability of context that is at the heart of différance.\n\nFor example, the word \"house\" derives its meaning more as a function of how it differs from \"shed\", \"mansion\", \"hotel\", \"building\", etc. (Form of Content, that Louis Hjelmslev distinguished from Form of Expression) than how the word \"house\" may be tied to a certain image of a traditional house (i.e., the relationship between signified and signifier), with each term being established in reciprocal determination with the other terms than by an ostensive description or definition: when can we talk about a \"house\" or a \"mansion\" or a \"shed\"? The same can be said about verbs, in all the languages in the world: when should we stop saying \"walk\" and start saying \"run\"? The same happens, of course, with adjectives: when must we stop saying \"yellow\" and start saying \"orange\", or exchange \"past\" for \"present\"? Not only are the topological differences between the words relevant here, but the differentials between what is signified is also covered by différance.\n\nThus, complete meaning is always \"differential\" and \"postponed\" in language; there is never a moment when meaning is complete and total. A simple example would consist of looking up a given word in a dictionary, then proceeding to look up the words found in that word's definition, etc., also comparing with older dictionaries. Such a process would never end.\n\nDerrida describes the task of deconstruction as the identification of metaphysics of presence, or \"logocentrism\" in western philosophy. Metaphysics of presence is the desire for immediate access to meaning, the privileging of presence over absence. This means that there is an assumed bias in certain binary oppositions where one side is placed in a position over another, such as good over bad, speech over the written word, male over female. Derrida writes, \"Without a doubt, Aristotle thinks of time on the basis of ousia as parousia, on the basis of the now, the point, etc. And yet an entire reading could be organized that would repeat in Aristotle's text both this limitation and its opposite\". To Derrida, the central bias of logocentrism was the now being placed as more important than the future or past. This argument is largely based on the earlier work of Heidegger, who, in \"Being and Time\", claimed that the theoretical attitude of pure presence is parasitical upon a more originary involvement with the world in concepts such as ready-to-hand and being-with.\n\nIn the deconstruction procedure, one of the main concerns of Derrida is to not collapse into Hegel's dialectic, where these oppositions would be reduced to contradictions in a dialectic that has the purpose of resolving it into a synthesis. The presence of Hegelian dialectics was enormous in the intellectual life of France during the second half of the 20th century, with the influence of Kojève and Hyppolite, but also with the impact of dialectics based on contradiction developed by Marxists, and including the existentialism of Sartre, etc. This explains Derrida's concern to always distinguish his procedure from Hegel's, since Hegelianism believes binary oppositions would produce a synthesis, while Derrida saw binary oppositions as incapable of collapsing into a synthesis free from the original contradiction.\n\nThere have been problems defining deconstruction. Derrida claimed that all of his essays were attempts to define what deconstruction is, and that deconstruction is necessarily complicated and difficult to explain since it actively criticises the very language needed to explain it.\n\nDerrida has been more forthcoming with negative (apophatic) than with positive descriptions of deconstruction. When asked by Toshihiko Izutsu some preliminary considerations on how to translate \"deconstruction\" in Japanese, in order to at least prevent using a Japanese term contrary to deconstruction's actual meaning, Derrida began his response by saying that such a question amounts to \"what deconstruction is not, or rather \"ought\" not to be\".\n\nDerrida states that deconstruction is not an analysis, a critique, or a method in the traditional sense that philosophy understands these terms. In these negative descriptions of deconstruction, Derrida is seeking to \"multiply the cautionary indicators and put aside all the traditional philosophical concepts\". This does not mean that deconstruction has absolutely nothing in common with an analysis, a critique, or a method, because while Derrida distances deconstruction from these terms, he reaffirms \"the necessity of returning to them, at least under erasure\". Derrida's necessity of returning to a term under erasure means that even though these terms are problematic we must use them until they can be effectively reformulated or replaced. The relevance of the tradition of negative theology to Derrida's preference for negative descriptions of deconstruction is the notion that a positive description of deconstruction would over-determine the idea of deconstruction and would close off the openness that Derrida wishes to preserve for deconstruction. If Derrida were to positively define deconstruction—as, for example, a critique—then this would make the concept of critique immune to itself being deconstructed. Some new philosophy beyond deconstruction would then be required in order to encompass the notion of critique.\n\nDerrida states that \"Deconstruction is not a method, and cannot be transformed into one\". This is because deconstruction is not a mechanical operation. Derrida warns against considering deconstruction as a mechanical operation, when he states that \"It is true that in certain circles (university or cultural, especially in the United States) the technical and methodological \"metaphor\" that seems necessarily attached to the very word 'deconstruction' has been able to seduce or lead astray\". Commentator Richard Beardsworth explains that\n\nDerrida is careful to avoid this term [method] because it carries connotations of a procedural form of judgement. A thinker with a method has already decided \"how\" to proceed, is unable to give him or herself up to the matter of thought in hand, is a functionary of the criteria which structure his or her conceptual gestures. For Derrida [...] this is irresponsibility itself. Thus, to talk of a method in relation to deconstruction, especially regarding its ethico-political implications, would appear to go directly against the current of Derrida's philosophical adventure.\n\nBeardsworth here explains that it would be irresponsible to undertake a deconstruction with a complete set of rules that need only be applied as a method to the object of deconstruction, because this understanding would reduce deconstruction to a thesis of the reader that the text is then made to fit. This would be an irresponsible act of reading, because it becomes a prejudicial procedure that only finds what it sets out to find.\n\nDerrida states that deconstruction is not a critique in the Kantian sense. This is because Kant defines the term critique as the opposite of dogmatism. For Derrida, it is not possible to escape the dogmatic baggage of the language we use in order to perform a pure critique in the Kantian sense. Language is dogmatic because it is inescapably metaphysical. Derrida argues that language is inescapably metaphysical because it is made up of signifiers that only refer to that which transcends them—the signified. In addition, Derrida asks rhetorically \"Is not the idea of knowledge and of the acquisition of knowledge in itself metaphysical?\" By this, Derrida means that all claims to know something necessarily involve an assertion of the metaphysical type that something \"is\" the case somewhere. For Derrida the concept of neutrality is suspect and dogmatism is therefore involved in everything to a certain degree. Deconstruction can challenge a particular dogmatism and hence desediment dogmatism in general, but it cannot escape all dogmatism all at once.\n\nDerrida states that deconstruction is not an analysis in the traditional sense. This is because the possibility of analysis is predicated on the possibility of breaking up the text being analysed into elemental component parts. Derrida argues that there are no self-sufficient units of meaning in a text, because individual words or sentences in a text can only be properly understood in terms of how they fit into the larger structure of the text and language itself. For more on Derrida's theory of meaning see the article on différance.\n\nDerrida states that his use of the word deconstruction first took place in a context in which \"structuralism was dominant\" and deconstruction's meaning is within this context. Derrida states that deconstruction is an \"antistructuralist gesture\" because \"[s]tructures were to be undone, decomposed, desedimented\". At the same time, deconstruction is also a \"structuralist gesture\" because it is concerned with the structure of texts. So, deconstruction involves \"a certain attention to structures\" and tries to \"understand how an 'ensemble' was constituted\". As both a structuralist and an antistructuralist gesture, deconstruction is tied up with what Derrida calls the \"structural problematic\". The structural problematic for Derrida is the tension between genesis, that which is \"in the essential mode of creation or movement\", and structure: \"systems, or complexes, or static configurations\". An example of genesis would be the sensory ideas from which knowledge is then derived in the empirical epistemology. An example of structure would be a binary opposition such as good and evil where the meaning of each element is established, at least partly, through its relationship to the other element.\n\nIt is for this reason that Derrida distances his use of the term deconstruction from post-structuralism, a term that would suggest that philosophy could simply go beyond structuralism. Derrida states that \"the motif of deconstruction has been associated with 'post-structuralism, but that this term was \"a word unknown in France until its 'return' from the United States\". In his deconstruction of Husserl, Derrida actually argues the contamination of pure origins by the structures of language and temporality. Manfred Frank has even referred to Derrida's work as \"Neostructuralism\".\n\nThe popularity of the term deconstruction, combined with the technical difficulty of Derrida's primary material on deconstruction and his reluctance to elaborate his understanding of the term, has meant that many secondary sources have attempted to give a more straightforward explanation than Derrida himself ever attempted. Secondary definitions are therefore an interpretation of deconstruction by the person offering them rather than a summary of Derrida's actual position.\n\n\nA survey of the secondary literature reveals a wide range of heterogeneous arguments. Particularly problematic are the attempts to give neat introductions to deconstruction by people trained in literary criticism who sometimes have little or no expertise in the relevant areas of philosophy that Derrida is working in. These secondary works (e.g. \"Deconstruction for Beginners\" and \"Deconstructions: A User's Guide\") have attempted to explain deconstruction while being academically criticized as too far removed from the original texts and Derrida's actual position.\n\nDerrida's observations have greatly influenced literary criticism and post-structuralism.\n\nDerrida's method consisted of demonstrating all the forms and varieties of the originary complexity of semiotics, and their multiple consequences in many fields. His way of achieving this was by conducting thorough, careful, sensitive, and yet transformational readings of philosophical and literary texts, with an ear to what in those texts runs counter to their apparent systematicity (structural unity) or intended sense (authorial genesis). By demonstrating the aporias and ellipses of thought, Derrida hoped to show the infinitely subtle ways that this originary complexity, which by definition cannot ever be completely known, works its structuring and destructuring effects.\n\nDeconstruction denotes the pursuing of the meaning of a text to the point of exposing the supposed contradictions and internal oppositions upon which it is founded—supposedly showing that those foundations are irreducibly complex, unstable, or impossible. It is an approach that may be deployed in philosophy, in literary analysis, and even in the analysis of scientific writings. Deconstruction generally tries to demonstrate that any text is not a discrete whole but contains several irreconcilable and contradictory meanings; that any text therefore has more than one interpretation; that the text itself links these interpretations inextricably; that the incompatibility of these interpretations is irreducible; and thus that an interpretative reading cannot go beyond a certain point. Derrida refers to this point as an \"aporia\" in the text; thus, deconstructive reading is termed \"aporetic.\" He insists that meaning is made possible by the relations of a word to other words within the network of structures that language is.\n\nDerrida initially resisted granting to his approach the overarching name \"deconstruction\", on the grounds that it was a precise technical term that could not be used to characterize his work generally. Nevertheless, he eventually accepted that the term had come into common use to refer to his textual approach, and Derrida himself increasingly began to use the term in this more general way.\n\nDerrida's deconstruction strategy is also used by postmodernists to locate meaning in a text rather than discover meaning due to the position that it has multiple readings. There is a focus on the deconstruction that denotes the tearing apart of a text to find arbitrary hierarchies and presuppositions for the purpose of tracing contradictions that shadow a text's coherence. Here, the meaning of a text does not reside with the author or the author's intentions because it is dependent on the interaction between reader and text. Even the process of translation is also seen as transformative since it \"modifies the original even as it modifies the translating language.\"\n\nDerrida's lecture at Johns Hopkins University, \"Structure, Sign, and Play in the Human Sciences\", often appears in collections as a manifesto against structuralism. Derrida's essay was one of the earliest to propose some theoretical limitations to structuralism, and to attempt to theorize on terms that were clearly no longer structuralist. Structuralism viewed language as a number of signs, composed of a signified (the meaning) and a signifier (the word itself). Derrida proposed that signs always referred to other signs, existing only in relation to each other, and there was therefore no ultimate foundation or centre. This is the basis of différance.\n\nBetween the late 1960s and the early 1980s, many thinkers were influenced by deconstruction, including Paul de Man, Geoffrey Hartman, and J. Hillis Miller. This group came to be known as the Yale school and was especially influential in literary criticism. Derrida and Hillis Miller were subsequently affiliated with the University of California, Irvine.\n\nMiller has described deconstruction this way: \"Deconstruction is not a dismantling of the structure of a text, but a demonstration that it has already dismantled itself. Its apparently solid ground is no rock, but thin air.\"\n\nArguing that law and politics cannot be separated, the founders of the \"Critical Legal Studies Movement\" found it necessary to criticize the absence of the recognition of this inseparability at the level of theory. To demonstrate the indeterminacy of legal doctrine, these scholars often adopt a method, such as structuralism in linguistics, or deconstruction in Continental philosophy, to make explicit the deep structure of categories and tensions at work in legal texts and talk. The aim was to deconstruct the tensions and procedures by which they are constructed, expressed, and deployed.\n\nFor example, Duncan Kennedy, in explicit reference to semiotics and deconstruction procedures, maintains that various legal doctrines are constructed around the binary pairs of opposed concepts, each of which has a claim upon intuitive and formal forms of reasoning that must be made explicit in their meaning and relative value, and criticized. Self and other, private and public, subjective and objective, freedom and control are examples of such pairs demonstrating the influence of opposing concepts on the development of legal doctrines throughout history.\n\nDeconstructive readings of history and sources have changed the entire discipline of history. In \"Deconstructing History\", Alun Munslow examines history in what he argues is a postmodern age. He provides an introduction to the debates and issues of postmodernist history. He also surveys the latest research into the relationship between the past, history, and historical practice, as well as articulating his own theoretical challenges.\n\nJean-Luc Nancy argues, in his 1982 book \"The Inoperative Community\", for an understanding of community and society that is undeconstructable because it is prior to conceptualisation. Nancy's work is an important development of deconstruction because it takes the challenge of deconstruction seriously and attempts to develop an understanding of political terms that is undeconstructable and therefore suitable for a philosophy after Derrida.\n\nSimon Critchley, an English philosopher, argues, in his 1992 book \"The Ethics of Deconstruction\", that Derrida's deconstruction is an intrinsically ethical practice. Critchley argues that deconstruction involves an openness to the Other that makes it ethical in the Levinasian understanding of the term.\n\nJacques Derrida has had a great influence on contemporary political theory and political philosophy. Derrida's thinking has inspired Slavoj Zizek, Richard Rorty, Ernesto Laclau, Judith Butler and many more contemporary theorists who have developed a deconstructive approach to politics. Because deconstruction examines the internal logic of any given text or discourse it has helped many authors to analyse the contradictions inherent in all schools of thought; and, as such, it has proved revolutionary in political analysis, particularly ideology critiques.\n\nRichard Beardsworth, developing from Critchley's \"Ethics of Deconstruction\", argues, in his 1996 \"Derrida and the Political\", that deconstruction is an intrinsically political practice. He further argues that the future of deconstruction faces a perhaps undecidable choice between a theological approach and a technological approach, represented first of all by the work of Bernard Stiegler.\n\nDerrida was involved in a number of high-profile disagreements with prominent philosophers, including Michel Foucault, John Searle, Willard Van Orman Quine, Peter Kreeft, and Jürgen Habermas. Most of the criticism of deconstruction were first articulated by these philosophers and repeated elsewhere.\n\nIn the early 1970s, Searle had a brief exchange with Jacques Derrida regarding speech-act theory. The exchange was characterized by a degree of mutual hostility between the philosophers, each of whom accused the other of having misunderstood his basic points. Searle was particularly hostile to Derrida's deconstructionist framework and much later refused to let his response to Derrida be printed along with Derrida's papers in the 1988 collection \"Limited Inc\". Searle did not consider Derrida's approach to be legitimate philosophy, or even intelligible writing, and argued that he did not want to legitimize the deconstructionist point of view by paying any attention to it. Consequently, some critics have considered the exchange to be a series of elaborate misunderstandings rather than a debate, while others have seen either Derrida or Searle gaining the upper hand. The level of hostility can be seen from Searle's statement that \"It would be a mistake to regard Derrida's discussion of Austin as a confrontation between two prominent philosophical traditions\", to which Derrida replied that that sentence was \"the only sentence of the 'reply' to which I can subscribe\". Commentators have frequently interpreted the exchange as a prominent example of a confrontation between analytic and Continental philosophies.\n\nThe debate began in 1972, when, in his paper \"Signature Event Context\", Derrida analyzed J. L. Austin's theory of the illocutionary act. While sympathetic to Austin's departure from a purely denotational account of language to one that includes \"force\", Derrida was sceptical of the framework of normativity employed by Austin. Derrida argued that Austin had missed the fact that any speech event is framed by a \"structure of absence\" (the words that are left unsaid due to contextual constraints) and by \"iterability\" (the constraints on what can be said, imposed by what has been said in the past). Derrida argued that the focus on intentionality in speech-act theory was misguided because intentionality is restricted to that which is already established as a possible intention. He also took issue with the way Austin had excluded the study of fiction, non-serious, or \"parasitic\" speech, wondering whether this exclusion was because Austin had considered these speech genres as governed by different structures of meaning, or hadn't considered them due to a lack of interest. In his brief reply to Derrida, \"Reiterating the Differences: A Reply to Derrida\", Searle argued that Derrida's critique was unwarranted because it assumed that Austin's theory attempted to give a full account of language and meaning when its aim was much narrower. Searle considered the omission of parasitic discourse forms to be justified by the narrow scope of Austin's inquiry. Searle agreed with Derrida's proposal that intentionality presupposes iterability, but did not apply the same concept of intentionality used by Derrida, being unable or unwilling to engage with the continental conceptual apparatus. This, in turn, caused Derrida to criticize Searle for not being sufficiently familiar with phenomenological perspectives on intentionality. Searle also argued that Derrida's disagreement with Austin turned on Derrida's having misunderstood Austin's type–token distinction and having failed to understand Austin's concept of failure in relation to performativity. Some critics have suggested that Searle, by being so grounded in the analytical tradition that he was unable to engage with Derrida's continental phenomenological tradition, was at fault for the unsuccessful nature of the exchange.\n\nDerrida, in his response to Searle ( in \"Limited Inc\"), ridiculed Searle's positions. Claiming that a clear sender of Searle's message could not be established, Derrida suggested that Searle had formed with Austin a \"société à responsabilité limitée\" (a \"limited liability company\") due to the ways in which the ambiguities of authorship within Searle's reply circumvented the very speech act of his reply. Searle did not reply. Later in 1988, Derrida tried to review his position and his critiques of Austin and Searle, reiterating that he found the constant appeal to \"normality\" in the analytical tradition to be problematic.\n\nIn the debate, Derrida praised Austin's work, but argued that Austin is wrong to banish what Austin calls \"infelicities\" from the \"normal\" operation of language. One \"infelicity\", for instance, occurs when it cannot be known whether a given speech act is \"sincere\" or \"merely citational\" (and therefore possibly ironic). Derrida argues that every iteration is necessarily \"citational\", due to the graphematic nature of speech and writing, and that language could not work at all without the ever-present and ineradicable possibility of such alternate readings. Derrida takes Searle to task for attempting to get around this issue by grounding final authority in the speaker's inaccessible \"intention\". Derrida argues that intention cannot possibly govern how an iteration signifies, once it becomes hearable or readable. All speech acts borrow from a language whose significance is determined by historical-linguistic context, and by the alternate possibilities that this context makes possible. This significance, Derrida argues, cannot be altered or governed by the whims of intention.\n\nDerrida argued against the constant appeal to \"normality\" in the analytical tradition of which Austin and Searle were paradigmatic examples.\n\nDerrida argued that it was problematic to establish the relation between \"nonfiction or standard discourse\" and \"fiction,\" defined as its \"parasite, \"for part of the most originary essence of the latter is to allow fiction, the simulacrum, parasitism, to take place—and in so doing to \"de-essentialize\" itself as it were\".\nHe would finally argue that the indispensable question would then become:\nIn 1995, Searle gave a brief reply to Derrida in \"The Construction of Social Reality\". He called Derrida's conclusion \"preposterous\" and stated that \"Derrida, as far as I can tell, does not have an argument. He simply declares that there is nothing outside of texts...\" Searle's reference here is not to anything forwarded in the debate, but to a mistranslation of the phrase \"\"il n'y a pas dehors du texte\",\" (\"There is no outside-text\") which appears in Derrida's \"Of Grammatology\".\n\nIn \"The Philosophical Discourse of Modernity\", Jürgen Habermas criticized what he considered Derrida's opposition to rational discourse.\n\nFurther, in an essay on religion and religious language, Habermas criticized Derrida's insistence on etymology and philology (see \"Etymological fallacy\").\n\nThe American philosopher Walter A. Davis, in \"Inwardness and Existence: Subjectivity in/and Hegel, Heidegger, Marx and Freud\", argues that both deconstruction and structuralism are prematurely arrested moments of a dialectical movement that issues from Hegelian \"unhappy consciousness\".\n\nPopular criticism of deconstruction intensified following the Sokal affair, which many people took as an indicator of the quality of deconstruction as a whole, despite the absence of Derrida from Sokal's follow-up book \"Impostures Intellectuelles\".\n\nChip Morningstar holds a view critical of deconstruction, believing it to be \"epistemologically challenged\". He claims the humanities are subject to isolation and genetic drift due to their unaccountability to the world outside academia. During the Second International Conference on Cyberspace (Santa Cruz, California, 1991), he reportedly heckled deconstructionists off the stage. He subsequently presented his views in the article \"How to Deconstruct Almost Anything\", where he stated, \"Contrary to the report given in the 'Hype List' column of issue #1 of Wired ('Po-Mo Gets Tek-No', page 87), we did not shout down the postmodernists. We made fun of them.\"\n\n\n\n"}
{"id": "41591480", "url": "https://en.wikipedia.org/wiki?curid=41591480", "title": "Dhi (Hindu thought)", "text": "Dhi (Hindu thought)\n\nDhi (Sanskrit: धी), this Sanskrit word means 'understanding', 'reflection', 'religious thought', 'mind', 'design', 'intelligence', 'opinion', 'meditation', 'imagination', 'notion', 'intellect', This word is directly connected with the word, Vāc (Sanskrit: वाच) meaning Speech, derived from Vac (Sanskrit: वच) meaning, 'to speak'. \"Dhi\" is the voiced \"Vāc\" or 'Speech', it is the thought-mind or intellect. \"Dhi\" also means 'to hold' or 'to place', and indicates the activity of the intellect.\n\nThe natural meaning of \"Dhi\" is 'Thought' which corresponds to the Sanskrit word \"Buddhi\" which means 'the activity of mind', 'thought', 'understanding' and 'intelligence'. Vedic Sanskrit employs two words \"Dhi\" and Brahman for prayerful or meditative contemplation in which context \"Dhi\" means 'visionary insight', 'intense thought and reflection', and the word Brahman is derived from the root \"brh\", meaning 'to grow', 'to expand'.\nManu Smriti describes ten essential rules for observance of Dharma (the path of righteousness or the 'Law of Being', which binds the people of this world and the whole creation) – \"Dhriti\" ('patience'), \"Kshama\" ('forgiveness'), \"Dama\" ('self-control'), \"Asteya\" ('honesty'), \"Shauch\" ('purity'), \"Indriya-nigrah\" ('control of senses'), \"Dhi\" ('reasoning'), \"Vidya\" ('knowledge and learning'), \"Satya\" ('truthfulness') and \"Akrodha\" ('control of anger').\n\nDhi, the prefix of \"Dhimahi\" and \"Dhiyo\" occurring in the Gayatri Mantra (Rig VedaIII.62.10) refers to 'understanding', and its cognate word \"Buddhi\" means 'reasoning faculty of the mind', which understanding must be transcended to experience the Ultimate Reality. The word, \"Dhira\", meaning 'calm', denotes the seeker whose intellect is saturated in knowledge which word is the combination of \"Dhi\" meaning 'intellect' and \"ra\" meaning 'fire' or 'wisdom'.\nThe Non-Atman i.e. the Anatman, which is by its nature disagreeable, is the object of the function of \"Dhi\" (=\"buddhi\") which reveals the joy (\"ananda\"), the nature of the individual consciousness.\nPatanjali defines Yoga as neutralization of the alternating waves in consciousness; in the phrase \"citta vritti nirodha\" (Yoga Sutra I.2), \"Citta\" refers to the 'thinking principle' and includes 'pranic life forces', to \"Manas\" ('mind' or 'sense consciousness'), \"Ahamkara\" ('egoity') and \"Buddhi\" ('intuitive intelligence'), and \"Vritti\" refers to the waves of thought and emotion that ceaselessly arise and Nirodha refers to 'neutralization', 'cessation' or 'control'. The root \"budh\" and its derivatives appear in the Vedas in the sense of 'kindling' or 'awakening', the word \"buddhi\" appears for the first time in \"Samkhyayana Brahmana Upanishad\". \"Dhi\" is derived from \"dhriti\" and its cognate \"didhiti\", it also refers to flash of intuition which is beyond all purely sensuous perception. The mental organs are \"manas\" ('mind') and \"hrd\" ('heart'), and the mental faculties are \"citta\" ('thought'), \"dhi\" ('mental vision') and \"kratu\" ('mental power'). \"Manas\" is said to perform the processes indicated by the verbal roots \"'cit-\", \"dhi-\" and \"man-\"; \"dhi\" requires \"kratu\" in actualizing visions.\n\nDhi refers to 'vision' or 'inspiration which is the exceptional faculty of acquiring a sudden knowledge of transcendent truth or reality', 'the inner light of visionary insight'. Soma is the Lord of Vision who dispenses inspiration and Speech (Vāc) is inspired thought (\"manisa\") or wisdom guarded by the seers on the seat of \"Rta\". The Rig Veda links language not only to thought (\"manas\") but also to vision (\"dhi\"), a word from which comes \"Dhyana\" meaning 'meditation'.\nIn the Yajurveda (29.8), Sarasvati, the Goddess of Speech, is invoked to grant the gift of \"Dhi\", inspired thought, and thought is linked with \"Vāc\"; Sarasvati is also known as the river of inspired thought,\n\nThe Vedas are the sacred texts of the Hindus. They are the repository of what is the known or required to be known, in other words, the true knowledge or the transcendent eternal wisdom articulated in Sound ('sabda') or Speech ('vāc'). The Vedic seers have associated the power of speech or the spoken word with ultimacy and transcendence – \"ekam sat\" (Rig Veda I.164.46). They also know Vishwakarma, the creator, as Vācaspati, the Lord of Speech (Rig Veda X.81.7) (who is also called Brihaspati and Brahmanaspati), and that Vāc or speech or utterance as Brahman is the creative principle and the absolute force in the universe; the person who has gained its knowledge is said to have attained the highest knowledge (Rig Veda X.125.5). As far as Brahman extends so far does \"Vāc\" (Rig Veda X.114.8).\n\nThe Inspired thought (\"dhi\") that precedes utterance though connected with speech undergoes some modifications while being transformed into speech; the Vedic Rishis tell us that the thoughtful one's produce speech with their mind (Rig Veda X.71.2), the different stages in transformation from \"dhi\" to \"vāc\" are described in the Atharvaveda (VII.1.1). \"Dhi\" is the voiced speech. Goddess Saraswati presides over speech but \"vāc\" extends far above and beyond Saraswati (Rig Veda X.125) beyond all known spheres (Rig Veda X.114.8). Vāc is dependent on breath or air; and the Aitareya Brahmana (IV.42.1) states \"Brahman vai vāk\", Vāc is the mother of the Vedas and the Vedas themselves (Shatapatha Brahmana (6.5.3.4).\nThe Vedas are a form of the ritual and cosmological \"Vāc\" (speech). Vāc is presented as consort of Prajapati (Kathaka Samhita 12.5.27.1) whom the Brahmanas express as 'the expressed' (\"nirukta\") and as the 'unexpressed' (\"anirukta\"), the limited and the unlimited. Taittiriya Aranyaka tells us that Vāc is the imperishable one, the (\"Aksara\"), the first-born of the cosmic order (\"Rta\"), the mother of the Vedas (\"vedanam mata\"), the navel of immortality (\"Amrita\") and therefore Vedas themselves are infinite (\"Ananta\"), immortal (\"amrta\") and imperishable (\"akshita\"). The \"Jaiminiya Upanishad\" tells us that Aum or Om, the essence of all essences, is Vāc. On the human plane the mind precedes speech, and on the cosmic plane Prajapati precedes \"vāc\" as the Lord of Thought and Speech, who brings forth \"vāc\" to unite with \"vāc\" to manifest creation.\n\"Vāc\" was probably the language commonly spoken by the Vedic people as the language of men. \"Vāc\" is another name for Aditi or Viraj.\n\nFor the purpose of invoking Agni and other \"devatas\", the mantras of the Rig Veda have a very essential role to play because the \"Upasaka\" when meditating is required to think of the Rcs as Vāc i.e. speech; it is for this reason that the mantras are chanted and there is a prescribed way to do that chanting. Rishi Medhatithi Kanva (Rig Veda I.12.11) prays:\n\n\"May Agni accept the words of praise (adoration) set in newer hymns composed in Gayatri metre and devoutly sung (chanted), (May Agni) accept the oblations made in it (in the prescribed manner) of the offerings rightly earned and belonging to the performers of rites.\" And, Rishi Ayasya (Rig Veda IX.46.2) praying thus-\n\ninforms us that having acquired the knowledge of the highest the learned people (easily) unravel the deeply hidden meaning of the most subtle kind. This means, that each experience of ours is a re-discovery of ourselves, and that in order to really re-discover ourselves so as to understand our true nature we have to firstly awaken our mind, then make the mind speak loudly enough to be heard because Prana, which is the body of the mind, is that very silence waiting to be heard. A sage of the Rig Veda (Rig Veda X.20.9) states that the creator vested \"Agni\" with three coloured flames and made it brilliant, eminent, swift-acting and hot. The sage of the Chandogya Upanishad tells us that behind all things are these three colours, the rest constituted out of them are a modification and a name. Speech is Rk or \"Brhati\" identified with \"Prana\" whose lord is Brihaspati, the same lord is Brahmanaspati when speech is \"Yajus\" associated with Brahman. Speech is \"Sama\"; it cannot reveal itself for it is as formless as the air on which it rides; it rides upon the streams of air constituting the wind, and words once uttered do not return to the speaker.\n\nYajnavalkya tells King Janaka that the light that comes nearest to the supreme light of the Atman is the light of Vāc i.e. speech, since it is the supreme faculty of reason that finally lifts the consciousness towards the pure self-shining awareness of the Atman, and which after serving as a pointer vanishes or goes to rest. The Vedic sages have all along advocated 'Truth', 'Penance' and 'Study' as special virtues. Amongst these three special virtues Truth is held out to be the supreme virtue to be practised by all aspirants. All primary virtues are firstly imbibed from the parents; Satyakama Jabala acquired the spirit of truthfulness from his mother, and Sanat Kumara taught Narada that Truth has to be sought for realization – \"when one indeed understands Truth in its reality one speaks the truth\".\n\nWhile describing the rituals associated with the Ashvamedha yajna, in the Brihadaranyaka Upanishad we are told that the neighing of the horse, representing the cosmos, is Vāc.\n\nA sage of the Chandogya Upanishad after declaring that the syllable \"Aum\", having the individual and also the cosmic efficacy, not only serves to help the meditation of the individual person but even the Sun travels the universe singing \"Aum\" as does \"Prana\" moving in the body (Ch.Up.I.5.1,3) explains that that \"Aum\" is the essence of all beings on this earth, the essence of a person is speech and the essence of speech is the Rig Veda (Ch.Up.I.1.2) but the essence of Samaveda, which is the essence of the Rig Veda, is \"Udgitha\" which is \"Aum\". He declares that all speech is interwoven on the symbol \"Aum\", in the same manner as the leaves of a tree are woven together on a stalk (Ch.Up.II.23.3). Speech is the fuel of fire which is man (Ch.Up.V.7.1). Mind consists of 'food', the Prana consists of 'water' and speech consists of 'fire' (Ch.Up.VI.6.5). Narada is told by Sanat Kumara that all this is but a name by which one knows, even then speech is greater than name because if there is no speech neither righteousness nor unrighteousness would be known, but surely the mind is greater than speech for mind is the entire world (Ch.Up.VII.2 & 3) establishing the claim of the mind (\"dhi\") for primacy over speech (\"vāc\").\n"}
{"id": "31483317", "url": "https://en.wikipedia.org/wiki?curid=31483317", "title": "Emergent literacies", "text": "Emergent literacies\n\nEmergent literacy is a term that is used to explain a child's knowledge of reading and writing skills before they learn how to read and write words. It signals a belief that, in literate society, young children—even one- and two-year-olds—are in the process of becoming literate. Through the support of parents, caregivers, and educators, a child can successfully progress from emergent to conventional reading.\n\nThe basic components of emergent literacy include:\n\n\nEmergent literacy is of critical importance in early education in light of research showing that children learn skills that prepare them to read years before they start school.\n\nTraditionally, society has considered reading and writing in their formalistic senses, and viewed children as being knowledgeable about literacy only when they were capable of identifying written words without picture clues, and spelling words that adults could read.\n\nIn 1966, New Zealand researcher Marie Clay introduced the concept of emergent reading, using it to describe the earliest behaviors and concepts young children employ in interacting with books even before they are capable of reading in the conventional sense. The 1970s and early 1980s saw robust research activity in children's early language development, early childhood education, and reexamination of the concept of reading readiness. This work resulted in Teale and Sulzby assembling a book authored by various leading researchers of the time that proposed reconceptualizing what happens from birth to the time when children reading and write conventionally as a period of emergent literacy.\n\nSince then, an extensive body of research has expanded the concept, illuminating that a child's literacy development begins well before formal introduction in school, and can be influenced by social interactions with adults, exposure to literacy materials, and the use of engaged learning activities.\nWhile the concept of reading readiness suggested that there was a point in time when children were ready to learn to read and write, Clay's notion of emergent literacy suggested that there were continuities in children's literacy development between early literacy behaviors and those displayed once children could read independently. Clay also emphasized the importance of the relationship between writing and reading in early literacy development. Until then, it was believed that children must learn to read before they could learn to write.\n\nThis component relates to a child's interest in and enjoyment of books. A child with print motivation might enjoy being read to, playing with books, pretending to write, and going to the library. Children who enjoy books are more likely to want to read, and to keep trying, even when it is hard.\n\nThe component \"vocabulary\" relates to the knowing of the names of things. Children with rich vocabularies are at a tremendous educational advantage, since studies show that vocabulary is the best predictor of reading comprehension at the end of second and third grades and is otherwise linked to overall academic achievement.\n\nThis component relates to noticing print, knowing how to handle a book, and knowing how to follow words on a page. It includes knowing that books are organized from left to right, the words are read from left to right and top to bottom, and how to tell words from letters. These skills are invaluable to a child's literacy development because without these skills, a child will have difficulty learning how to read and write.\n\nThis component relates to the ability to describe things and events and to tell stories.\n\nThis component relates to the understanding that letters are different from each other, knowing their names and sounds, and recognizing letters everywhere.\n\nThis component relates to being able to hear and play with the smaller sounds in words.\nIt involves rhyme recognition, syllables, onset, and rime. Types of phonological awareness include: phonemic awareness, syllable awareness, word awareness, and sentence awareness.\n\nEmergent literacy lessons may focus on one emergent literacy skill or blend them. Below are examples of emerging literacy games and activities that each focus primarily on one emergent literacy skill.\n\nBuilding vocabulary\nSorting games can help children build vocabulary skills by asking them to identify defining characteristics of the items being sorted. Special Connections, a teaching resource website provided by Kansas University, suggests a shoe sorting game in which each child takes off one of his or her shoes. The children work together to sort the shoes by different characteristics, thus building vocabulary related to color, types of fasteners (buckle, velcro), shoe type (sandal, gym shoe), etc. This activity could work with other objects such as legos and pasta. The full activity is available online.\nThe Hanen Centre outlines another strategy for teaching vocabulary to promote emergent literacy.\n\nLetter recognition\nLetter recognition games help children learn the letters of the alphabet. In one simple game, the teacher writes each letter of the alphabet on a separate notecard and passes them out to students. The students then have to arrange themselves in alphabetical order. This game is provided by Special Connections, a teaching resource website provided by the University of Kansas, and is available online.\n\nPhonological awareness\nOne type of phonological awareness game involves rhyming, which helps children identify similar sounds in words. In one rhyming game, the teacher can present three different \"consonant-vowel-consonant\" words and ask children which word does not rhyme. For example, cat, log, and dog. The full activity and other similar rhyming activities are available online.\n\nOther activities include: songs and chants; word play, games, rhymes and riddles; Storybooks, poetry, nursery rhymes, Dr. Seuss;\nOral Storytelling; Clapping, jumping, manipulating letters, blocks.\nEverything should be playful, engaging, interactive, social, deliberate, and purposeful, stimulate curiosity, and encourage experimentation with language and comprehensive language and literacy programs.\n\nPrint motivation\nSince print motivation involves a child's interest and enjoyment of books, there are a variety of activities that parents and teachers can share with children to help promote print motivation. Examples include:\n\nPrint motivation tips adapted from the Loudon County Public Library.\n\nPrint awareness\nPrint awareness is a child's understanding of the parts of a book and how a book works. The State Library of Louisiana suggests an activity in which a child shares the parts of a book with an adult. For example, the teacher or parent could ask the child to point out different parts of the book and its contents, such as the front cover; the title; the first line of the book; a word; a letter; and the back cover.\n\nGeorge Mason University suggests additional family activities. These include: Make a book with your children. You might include familiar photographs with labels under each photo, or children might illustrate the book by themselves. Parents could write the words as the children dictate the story. Or, when going out to a restaurant, show the menu to your children and point to the words as you read to them. Let them choose what they want to eat and make it an interactive experience. This will help children understand how print is connected to real life. Additional activities can be found online.\n\nNarrative skills\nChildren can build narrative skills by describing something that happened to him or her, even something as simple as taking a bath. Parents and teachers can promote narrative skills by prompting children for further detail. Other activities to promote narrative skills in both babies and toddlers are available from the Loudon County Library.\n\n\n"}
{"id": "244773", "url": "https://en.wikipedia.org/wiki?curid=244773", "title": "Empty name", "text": "Empty name\n\nIn the philosophy of language, an empty name is a proper name that has no referent.\n\nThe problem of empty names is that empty names have a meaning that it seems they should not have. The name \"Pegasus\" is empty; there is nothing to which it refers. Yet, though there is no Pegasus, we know what the sentence \"Pegasus has two wings\" means. We can even understand the sentence \"There is no such thing as Pegasus.\" But, what can the meaning of a proper name be, except the object to which it refers?\n\nThere are three broad ways which philosophers have tried to approach this problem.\n\nSome philosophers, such as Alexius Meinong have argued that there are two senses of the verb \"exists\", exemplified by the sentence \"there are things that do not exist\". The first, signified by \"there are\", is the so-called \"wide sense\", including Pegasus, the golden mountain, the round square, and so on. The second, signified by \"exist\" is the so-called \"narrow sense\", encompassing only things that are real or existent. The difficulty with this \"two sense\" theory is that there is no strong evidence that there really are two such distinct senses of the verb \"to be\".\n\n"}
{"id": "25273305", "url": "https://en.wikipedia.org/wiki?curid=25273305", "title": "Eternal statement", "text": "Eternal statement\n\nAn eternal statement is a statement whose token instances all have the same truth value. For instance, every inscription or utterance of the sentence \"On July 15, 2009 it rains in Boston\" has the same truth value, no matter when or where it is asserted. This type of statement is distinguished from others in that its context will not influence its truth value. Essentially, an eternal statement is a true statement, regardless of how it used. \n\n"}
{"id": "39104546", "url": "https://en.wikipedia.org/wiki?curid=39104546", "title": "Evolutionary psychology of language", "text": "Evolutionary psychology of language\n\nEvolutionary psychology of language is the study of the evolutionary history of language as a psychological faculty within the discipline of evolutionary psychology. It makes the assumption that language is the result of a Darwinian adaptation.\n\nThere are many competing theories of how language might have evolved, if indeed it is an evolutionary adaptation. They stem from the belief that language development could result from an adaptation, an exaptation, or a by-product. Genetics also influence the study of the evolution of language. It has been speculated that the FOXP2 gene may be what gives humans the ability to develop grammar and syntax.\n\nIn the debate surrounding the evolutionary psychology of language, three sides emerge: those who believe in language as an adaptation, those who believe it is a by-product of another adaptation, and those who believe it is an exaptation.\n\nScientist and psychologists Steven Pinker and Paul Bloom argue that language as a mental faculty shares many likenesses with the complex organs of the body which suggests that, like these organs, language has evolved as an adaptation, since this is the only known mechanism by which such complex organs can develop. The complexity of the mechanisms, the faculty of language and the ability to learn language provides a comparative resource between the psychological evolved traits and the physical evolved traits.\n\nPinker, though he mostly agrees with Noam Chomsky, a linguist and cognitive scientist, in arguing that the fact that children can learn any human language with no explicit instruction suggests that language, including most of grammar, is basically innate and that it only needs to be activated by interaction, but Pinker and Bloom argue that the organic nature of language strongly suggests that it has an adaptational origin.\n\nNoam Chomsky spearheaded the debate on the faculty of language as a cognitive by-product, or spandrel. As a linguist, rather than an evolutionary biologist, his theoretical emphasis was on the infinite capacity of speech and speaking: there are a fixed number of words, but there is an infinite combination of the words. His analysis from this considers that the ability of our cognition to perceive infinite possibilities, or create infinite possibilities, helped give way to the extreme complexity found in our language. Both Chomsky and Gould argue that the complexity of the brain is in itself an adaptation, and language arises from such complexities.\nOn the issue of whether language is best seen as having evolved as an adaptation or as a by product, evolutionary biologist W. Tecumseh Fitch, following Stephen J. Gould, argues that it is unwarranted to assume that every aspect of language is an adaptation, or that language as a whole is an adaptation. He criticizes some strands of evolutionary psychology for suggesting a pan-adaptationist view of evolution, and dismisses Pinker and Bloom's question of whether \"Language has evolved as an adaptation\" as being misleading.\nHe argues instead that from a biological viewpoint the evolutionary origins of language is best conceptualized as being the probable result of a convergence of many separate adaptations into a complex system. A similar argument is made by Terrence Deacon who in \"The Symbolic Species\" argues that the different features of language have co-evolved with the evolution of the mind and that the ability to use symbolic communication is integrated in all other cognitive processes.\n\nExaptations, like adaptations, are fitness-enhancing characteristics, but, according to Stephen Jay Gould, their purposes were appropriated as the species evolved. This can be for one of two reasons: either the trait’s original function was no longer necessary so the trait took on a new purpose or a trait that does not arise for a certain purpose, but later becomes important. Typically exaptations have a specific shape and design which becomes the space for a new function. The foundation of this argument comes from the low-lying position of the larynx in humans. Other mammals have this same positioning of the larynx, but no other species has acquired language. This leads exaptationists to see an evolved modification away from its original purpose.\n\nResearch has shown that “genetic constraints” on language evolution could have caused a “specialized” and “species-specific language module. It is through this module that there are many specified “domain-specific linguistic properties,” such as syntax and agreement. Adaptationists believe that language genes “coevolved with human language itself for the purpose of communication.” This view suggests that the genes that are involved with language would only have coevolved in a very stable linguist environment. This shows that language could not have evolved in a rapidly changing environment because that type of environment would not have been stable enough for natural selection. Without natural selection, the genes would not have coevolved with the ability for language, and instead, would have come from “cultural conventions.” The adaptationist belief that genes coevolved with language also suggests that there are no “arbitrary properties of language.” This is because they would have coevolved with language through natural selection.\nThe Baldwin effect provides a possible explanation for how language characteristics that are learned over time could become encoded in genes. He suggested, like Darwin did, that organisms that can adapt a trait faster have a “selective advantage.” As generations pass, less environmental stimuli is needed for organisms of the species to develop that trait. Eventually no environmental stimuli are needed and it is at this point that the trait has become “genetically encoded.”\n\nThe genetic and cognitive components of language have long been under speculation, only recently have linguists been able to point out a gene that may possibly explain how language works. Evolutionary psychologists hold that the FOXP2 gene may well be associated with the evolution of human language. In the 1980s, psycholinguist Myrna Gopnik identified a dominant gene that causes language impairment in the KE family of Britain. The KE family has a mutation in the FOXP2, that makes them suffer from a speech and language disorder. It has been argued that the FOXP2 gene is the grammar gene, which is what allows humans the ability to form proper syntax and make our communication of higher quality. Children that grow up in a stable environment are able to develop highly proficient language without any instruction. Individuals with a mutation to their FOXP2 gene have trouble mastering complex sentences, and shows signs of developmental verbal dyspraxia.\n\nThis gene most likely evolved in the hominin line after the hominin and the chimpanzee lines split; this accounts for the fact that humans are the only ones able to learn and understand grammar. Humans have a unique allele of this gene, which has otherwise been closely conserved through most of mammalian evolutionary history. This unique allele seems to have first appeared between 100 and 200 thousand years ago, and it is now all but universal in humans. This suggests that speech evolved late in overall spectrum of human evolution.\n\nIn the world there are nearly 7000 languages, there is great amount of variation and this variation is thought to have come about through cultural differentiation. There are four factors that are thought to be the reason as to why there is language variation between cultures: founder effects, drift, hybridization and adaptation. With the vast amounts of lands available different tribes began to form and to claim their territory, in order to differentiate themselves many of these groups made changes to their language and this how the evolution of languages began. There also tended to be drifts in the population a certain group would get lost and be isolated from the rest of the group, this group would lose touch with the other groups and before they knew there had been mutations in their language and a whole new language had been formed.\n\nHybridization also played a big role in the language evolution, one group would come in contact with another tribe and they would pick up words and sounds from each other eventually leading to the formation of a new language. Adaptation would also play a role in the evolution of language differentiation, the environment and the circumstances were constantly changing therefore the groups had to adapt to the environment and their language had to adapt to it as well, it is all about maximizing fitness.\n\nAtkinson theorized that language may have originated in Africa since African languages have a greater variation of speech sounds than other languages. Those sounds are seen as the root for the other languages that exist across the world.\n\nResearch indicates that nonhuman animals (e.g., apes, dolphins, and songbirds) show evidence of language. Comparative studies of the sensory-motor system reveal that speech is not special to humans: nonhuman primates can discriminate between two different spoken languages. Anatomical aspects of humans, particularly the descended larynx, has been believed to be unique to humans' capacity to speak. However, further research revealed that several other mammals have a descended larynx beside humans, which indicates that a descended larynx must not be the only anatomical feature needed for speech production.\nVocal imitation is not uniquely human as well. Songbirds seem to acquire species-specific songs by imitating. Because nonhuman primates do not have a descended larynx, they lack vocal imitative capacity, which is why studies involving these primates have taught them nonverbal means of communication, e.g., sign language.\n\nKoko and Nim Chimpsky are two apes that have successfully learned to use sign language, but not to the extent that a human being can. Nim is a chimpanzee that was taken in by a family in the 1970s and was raised as if he were a human child. Nim was able to master 150 signs, which were limited but useful. Koko was a gorilla that was taken in by a Berkley student. She was able to master 600 signs for generative communication. Koko and Nim were not able to develop speech due to the fact that they lack the larynx which is what distinguishes humans from other animals and allows them to speak.\n\n"}
{"id": "184421", "url": "https://en.wikipedia.org/wiki?curid=184421", "title": "FOXP2", "text": "FOXP2\n\nForkhead box protein P2 (FOXP2) is a protein that, in humans, is encoded by the \"FOXP2\" gene, also known as \"CAGH44\", \"SPCH1\" or \"TNRC10\", and is required for proper development of speech and language. The gene is shared with many vertebrates, where it generally plays a role in communication (for instance, the development of bird song).\n\nInitially identified as the genetic factor of speech disorder in KE family, \"FOXP2\" is the first gene discovered associated with speech and language. The gene is located on chromosome 7 (7q31, at the \"SPCH1\" locus) and is expressed in fetal and adult brain, heart, lung and gut. \"FOXP2\" orthologs have also been identified in other mammals for which complete genome data are available. The \"FOXP2\" protein contains a forkhead-box DNA-binding domain, making it a member of the FOX group of transcription factors, involved in regulation of gene expression. In addition to this characteristic forkhead-box domain, the protein contains a polyglutamine tract, a zinc finger and a leucine zipper. The gene is more active in females than in males, to which could be attributed better language learning in females.\n\nIn humans, mutations of \"FOXP2\" cause a severe speech and language disorder. Versions of \"FOXP2\" exist in similar forms in distantly related vertebrates; functional studies of the gene in mice and in songbirds indicate that it is important for modulating plasticity of neural circuits. Outside the brain \"FOXP2\" has also been implicated in development of other tissues such as the lung and gut.\n\n\"FOXP2\" is popularly dubbed the \"language gene\", but this is only partly correct since there are other genes involved in language development. It directly regulates a number of other genes, including \"CNTNAP2\", \"CTBP1\", and \"SRPX2\".\n\nTwo amino acid substitutions distinguish the human \"FOXP2\" protein from that found in chimpanzees, but only one of these changes is unique to humans. Evidence from genetically manipulated mice and human neuronal cell models suggests that these changes affect the neural functions of \"FOXP2\".\n\n\"FOXP2\" and its gene were discovered as a result of investigations on an English family known as the KE family, half of whom (fifteen individuals across three generations) suffered from a speech and language disorder called developmental verbal dyspraxia. Their case was studied at the Institute of Child Health of University College London. In 1990 Myrna Gopnik, Professor of Linguistics at McGill University, reported that the disorder-affected KE family had severe speech impediment with incomprehensible talk, largely characterized by grammatical deficits. She hypothesized that the basis was not of learning or cognitive disability, but due to genetic factors affecting mainly grammatical ability. (Her hypothesis led to a popularised existence of \"grammar gene\" and a controversial notion of grammar-specific disorder.) In 1995, the University of Oxford and the Institute of Child Health researchers found that the disorder was purely genetic. Remarkably, the inheritance of the disorder from one generation to the next was consistent with autosomal dominant inheritance, i.e., mutation of only a single gene on an autosome (non-sex chromosome) acting in a dominant fashion. This is one of the few known examples of Mendelian (monogenic) inheritance for a disorder affecting speech and language skills, which typically have a complex basis involving multiple genetic risk factors.\n\nIn 1998, Oxford University geneticists Simon Fisher, Anthony Monaco, Cecilia S. L. Lai, Jane A. Hurst, and Faraneh Vargha-Khadem identified an autosomal dominant monogenic inheritance that is localized on a small region of chromosome 7 from DNA samples taken from the affected and unaffected members. The chromosomal region (locus) contained 70 genes. The locus was given the official name \"SPCH1\" (for speech-and-language-disorder-1) by the Human Genome Nomenclature committee. Mapping and sequencing of the chromosomal region was performed with the aid of bacterial artificial chromosome clones. Around this time, the researchers identified an individual who was unrelated to the KE family, but had a similar type of speech and language disorder. In this case the child, known as CS, carried a chromosomal rearrangement (a translocation) in which part of chromosome 7 had become exchanged with part of chromosome 5. The site of breakage of chromosome 7 was located within the SPCH1 region.\n\nIn 2001, the team identified in CS that the mutation is in the middle of a protein-coding gene. Using a combination of bioinformatics and RNA analyses, they discovered that the gene codes for a novel protein belonging to the forkhead-box (FOX) group of transcription factors. As such, it was assigned with the official name of FOXP2. When the researchers sequenced the \"FOXP2\" gene in the KE family, they found a heterozygous point mutation shared by all the affected individuals, but not in unaffected members of the family and other people. This mutation is due to an amino-acid substitution that inhibits the DNA-binding domain of the \"FOXP2\" protein. Further screening of the gene identified multiple additional cases of \"FOXP2\" disruption, including different point mutations and chromosomal rearrangements, providing evidence that damage to one copy of this gene is sufficient to derail speech and language development.\n\n\"FOXP2\" is required for proper brain and lung development. Knockout mice with only one functional copy of the \"FOXP2\" gene have significantly reduced vocalizations as pups. Knockout mice with no functional copies of \"FOXP2\" are runted, display abnormalities in brain regions such as the Purkinje layer, and die an average of 21 days after birth from inadequate lung development.\n\n\"FOXP2\" is expressed in many areas of the brain including the basal ganglia and inferior frontal cortex where it is essential for brain maturation and speech and language development.\n\nA knockout mouse model has been used to examine \"FOXP2\"'s role in brain development and how mutations in the two copies of \"FOXP2\" affect vocalization. Mutations in one copy result in reduced speech while abnormalities in both copies cause major brain and lung developmental issues.\n\nThe expression of \"FOXP2\" is subject to post-transcriptional regulation, particularly micro RNA, which binds to multiple miRNA binding-sites in the neocortex, causing the repression of FOXP2 3’UTR.\n\nThere are several abnormalities linked to \"FOXP2\". The most common mutation results in severe speech impairment known as developmental verbal dyspraxia (DVD) which is caused by a translocation in the 7q31.2 region [t(5;7)(q22;q31.2)]. A missense mutation causing an arginine-to-histidine substitution (R553H) in the DNA-binding domain is thought to be the abnormality in KE. A heterozygous nonsense mutation, R328X variant, produces a truncated protein involved in speech and language difficulties in one KE individual and two of their close family members. R553H and R328X mutations also affected nuclear localization, DNA-binding, and the transactivation (increased gene expression) properties of \"FOXP2\". Although DVD associated with \"FOXP2\" disruptions are thought to be rare (~2% by one estimate), genetic links from \"FOXP2\" to disease usually relate to speech or language problems. \n\nSeveral cases of developmental verbal dyspraxia in humans have been linked to mutations in the \"FOXP2\" gene. Such individuals have little or no cognitive handicap but are unable to correctly perform the coordinated movements required for speech. fMRI analysis of these individuals performing silent verb generation and spoken word repetition tasks showed underactivation of Broca's area and the putamen, brain centers thought to be involved in language tasks. Because of this, \"FOXP2\" has been dubbed the \"language gene\". People with this mutation also experience symptoms not related to language (not surprisingly, as \"FOXP2\" is known to affect development in other parts of the body as well). Scientists have also looked for associations between \"FOXP2\" and autism, and both positive and negative findings have been reported.\n\nThere is some evidence that the linguistic impairments associated with a mutation of the \"FOXP2\" gene are not simply the result of a fundamental deficit in motor control. For examples, the impairments include difficulties in comprehension. Brain imaging of affected individuals indicates functional abnormalities in language-related cortical and basal/ganglia regions, demonstrating that the problems extend beyond the motor system.\n\nThe \"FOXP2\" gene is highly conserved in mammals. The human gene differs from that in non-human primates by the substitution of two amino acids, a threonine to asparagine substitution at position 303 (T303N) and an asparagine to serine substitution at position 325 (N325S). In mice it differs from that of humans by three substitutions, and in zebra finch by seven amino acids. One of the two amino acid differences between human and chimps also arose independently in carnivores and bats. Similar \"FOXP2\" proteins can be found in songbirds, fish, and reptiles such as alligators.\n\nDNA sampling from \"Homo neanderthalensis\" bones indicates that their \"FOXP2\" gene is a little different, though largely similar to those of \"Homo sapiens\" (i.e. humans). \n\nThe \"FOXP2\" gene showed indications of recent positive selection. Some researchers have speculated that positive selection is crucial for the evolution of language in humans. Others, however, have been unable to find a clear association between species with learned vocalizations and similar mutations in \"FOXP2\". Recent data from a large sample of globally distributed genomes showed no evidence of positive selection, suggesting that the original signal of positive selection may be driven by sample composition. Insertion of both human mutations into mice, whose version of \"FOXP2\" otherwise differs from the human and chimpanzee versions in only one additional base pair, causes changes in vocalizations as well as other behavioral changes, such as a reduction in exploratory tendencies, and a decrease in maze learning time. A reduction in dopamine levels and changes in the morphology of certain nerve cells are also observed.\n\nHowever, \"FOXP2\" is extremely diverse in echolocating bats. Twenty-two sequences of non-bat eutherian mammals revealed a total number of 20 nonsynonymous mutations in contrast to half that number of bat sequences, which showed 44 nonsynonymous mutations. All cetaceans share three amino acid substitutions, but no differences were found between echolocating toothed whales and non-echolocating baleen cetaceans. Within bats, however, amino acid variation correlated with different echolocating types.\n\n\"FOXP2\" interacts with a regulatory gene \"CTBP1\". It also downregulates \"CNTNAP2\" gene, a member of the neurexin family found in neurons. The target gene is associated with common forms of language impairment. It regulates the repeat-containing protein X-linked 2 (\"SRPX2\"), which is an epilepsy and language-associated gene in humans, and sound-controlling gene in mice.\n\nIn a mouse \"FOXP2\" knockout study, loss of both copies of the gene caused severe motor impairment related to cerebellar abnormalities and lack of ultrasonic vocalisations normally elicited when pups are removed from their mothers. These vocalizations have important communicative roles in mother-offspring interactions. Loss of one copy was associated with impairment of ultrasonic vocalisations and a modest developmental delay. Male mice on encountering female mice produce complex ultrasonic vocalisations that have characteristics of song. Mice that have the R552H point mutation carried by the KE family show cerebellar reduction and abnormal synaptic plasticity in striatal and cerebellar circuits.\n\nIn songbirds, \"FOXP2\" most likely regulates genes involved in neuroplasticity.\nGene knockdown of \"FOXP2\" in Area X of the basal ganglia in songbirds results in incomplete and inaccurate song imitation. Overexpression of FoxP2 was accomplished through injection of adeno-associated virus serotype 1 (AAV1) into Area X of the brain. This overexpression produced similar effects to that of knockdown; juvenile zebra finch birds were unable to accurately imitate their tutors. Similarly, in adult canaries higher \"FOXP2\" levels also correlate with song changes.\n\nLevels of \"FOXP2\" in adult zebra finches are significantly higher when males direct their song to females than when they sing song in other contexts. “Directed” singing refers to when a male is singing to a female usually for a courtship display. “Undirected” singing occurs when for example, a male sings when other males are present or is alone. Studies have found that FoxP2 levels vary depending on the social context. When the birds were singing undirected song, there was a decrease of FoxP2 expression in Area X. This downregulation was not observed and FoxP2 levels remained stable in birds singing directed song.\n\nDifferences between song-learning and non-song-learning birds have been shown to be caused by differences in \"FOXP2\" gene expression, rather than differences in the amino acid sequence of the \"FOXP2\" protein.\n\n\"FOXP2\" also has possible implications in the development of bat echolocation.\n\n\n"}
{"id": "4829003", "url": "https://en.wikipedia.org/wiki?curid=4829003", "title": "Farfallino alphabet", "text": "Farfallino alphabet\n\nThe farfallino alphabet (in Italian alfabeto farfallino) is a language game used primarily in Italy, which can be regarded as an elementary form of substitution cipher. It is usually used by children for amusement or to converse in (perceived) privacy from adults. The name \"farfallino\" comes from the word \"farfalla\" (butterfly), which is an ordinary Italian word but sounds like the \"codified\" words in farfallino alphabet. The farfallino alphabet is similar to games found in other languages such as jeringonza (Spanish/Portuguese), langue de feu (French), Fay Kee Bolee (Urdu) and pig latin (English).\n\nThe usual rules for farfallino alphabet are based on the substitution of each vowel with a 3 letter sequence where the vowel itself is repeated with an interceding \"f\".\n\nIts translation in Italian is:\nWhich means, in English:\n\nThere are several minor variations to this scheme. One such variation is based on the following substitution rules: \n\nAlthough rules for \"e\" and \"i\" look different, they are not; the additional \"h\" is needed in Italian to enforce a voiced velar plosive sound for letter \"g\", which is implicit in the other combinations. Another more complicated scheme, which is used in some regions of Italy, is as follows:\n\n"}
{"id": "56746967", "url": "https://en.wikipedia.org/wiki?curid=56746967", "title": "From Language to Language", "text": "From Language to Language\n\nFrom Language to Language (Hebrew: משפה לשפה, tr. \"MiSafa LeSafa\") is a 55-minute 2004 Belgian-French-German-Israeli Hebrew-language independent underground experimental documentary art film directed by Nurith Aviv.\n\nThe film, produced by and the Dardenne brothers, was released on DVD by as part of a boxset also including 2008’s \"Langue sacrée, langue parlée\" and 2011’s \"Traduire\", with which they form a trilogy. It contains interviews with Israeli artists and writers such as Aharon Appelfeld, Evgenia Dodina, Salman Masalha, Agi Mishol, Amal Murkus, Prof. Dr. , Haïm Ulliel, and Meir Wieseltier who write in Hebrew even though it is not their native language about the importance of language and asks how the struggle between their mother tongue and Hebrew has affected their art.\n\nBetween its release and 2006, the film was screened and won several awards at DocAviv, Marseille Festival of Documentary Film, Visions du Réel, Internationales Dokumentarfilmfestival München, Musée d’Art et d’Histoire du Judaïsme, , , , Centre culturel international de Cerisy-la-Salle, , Strasbourg Museum of Modern and Contemporary Art, Martin-Gropius-Bau, University of Lausanne, and many other places. The film was produced by ZDF, Arte, , , and . It was also screened at Centre Georges Pompidou in 2015.\n\n"}
{"id": "22487771", "url": "https://en.wikipedia.org/wiki?curid=22487771", "title": "Gutian language", "text": "Gutian language\n\nGutian (; also Qutian) is an extinct unclassified language that was spoken by the Gutian people, who briefly ruled over Sumer as the Gutian dynasty in the 22nd century BCE (middle chronology). The Gutians lived in the territory between the Zagros Mountains and the Tigris. Nothing is known about the language except its existence and a list of names of Gutian rulers in the Sumerian King List.\n\nGutian is included in a list of languages spoken in the region found in the \"Sag\" B tablet, an educational text from the Middle Babylonian period possibly originating from the city of Emar. This text also lists Akkadian, Amorite, Sutean, \"Subarean\" (Hurrian) and Elamite. There is also a mention of \"an interpreter for the Gutean language\" in a tablet from Adab.\n\nThe Gutian king names from the Sumerian list are:\n\n\nThorkild Jacobsen suggested that the recurring ending \"-(e)š\" may have had a grammatical function in Gutian, perhaps as a case marker.\n\nIn a posthumously-published article, W. B. Henning suggested that the different endings of the king names resembled case endings in the Tocharian languages, a branch of Indo-European known from texts found in the Tarim Basin (in the northwest of modern China) dating from the 6th to 8th centuries CE. Henning also compared the name Guti with \"Kuči\", the native name of the Tocharian city of Kucha, and with the name of the Yuezhi, pastoral nomads described in Chinese records as living to the east of the Tarim in the 2nd century BCE, although the latter name is usually reconstructed with a *ŋʷ- initial in Old Chinese. He also compared \"Tukriš\", the name of neighbours of the Guti, with the name \"twγry\" found in Old Turkish manuscripts from the early 9th century CE and thought to refer to the Tocharians. Gamkrelidze and Ivanov explored Henning's suggestion as possible support for their proposal of an Indo-European Urheimat in the Near East. However, most scholars reject the attempt to compare languages separated by more than two millennia.\n"}
{"id": "300264", "url": "https://en.wikipedia.org/wiki?curid=300264", "title": "Heritage language", "text": "Heritage language\n\nA heritage language is a minority language learnt by its speakers at home as children, but it is never fully developed because its speakers grow up with a dominant language in which they become more competent. Polinsky & Kagan label it as a continuum that ranges from fluent speakers to barely-speaking individuals of the home language. In some countries or cultures in which they determine one's mother tongue by the ethnic group, a heritage language would be linked to the native language.\n\nThe term can also refer to the language of a person's family or community that the person does not speak or understand but culturally identify with it.\n\n\"Heritage language\" is the term used to describe a language which is predominantly spoken by \"nonsocietal\" groups and linguistic minorities. \n\nIn various fields, such as foreign language education and linguistics, the definitions of heritage language become more specific and divergent. In foreign language education, heritage language is defined in terms of a student’s upbringing and functional proficiency in the language: a student raised in a home where a non-majority language is spoken is a heritage speaker of that language if she/he possesses some proficiency in it. Under this definition, individuals that have some cultural connection with the language but do not speak it are not considered heritage students. This restricted definition became popular in the mid 1990s with the publication of \"Standards for Foreign Language Learning\" by the American Council on the Teaching of Foreign Languages.\n\nAmong linguists, heritage language is an end-state language that is defined based on the temporal order of acquisition and, often, the language dominance in the individual. A heritage speaker acquires the heritage language as their first language through natural input in the home environment and acquires the majority language as a second language, usually when she/he starts school and talks about different topics with people in school, or by exposure through media (written texts, internet, popular culture etc.). As exposure to the heritage language decreases and exposure to the majority language increases, the majority language becomes the individual’s dominant language and acquisition of the heritage language changes. The results of these changes can be seen in divergence of the heritage language from monolingual norms in the areas of phonology, lexical knowledge (knowledge of vocabulary or words), morphology, syntax, semantics and code-switching, although mastery of the heritage language may vary from purely receptive skills in only informal spoken language to native-like fluency.\n\nAs stated by Polinsky and Kagan: \"The definition of a heritage speaker in general and for specific languages continues to be debated. The debate is of particular significance in such languages as Chinese, Arabic, and languages of India and the Philippines, where speakers of multiple languages or dialects are seen as heritage speakers of a single standard language taught for geographic, cultural or other reasons (Mandarin Chinese, Classical Arabic, Hindi, or Tagalog, respectively).\"\n\nOne idea that prevails in the literature is that \"[heritage] languages include indigenous languages that are often endangered. . . as well as world languages that are commonly spoken in many other regions of the world (Spanish in the United States, Arabic in France)\". However, that view is not shared worldwide. In Canada, for example, Indigenous languages are not classified as heritage languages. \n\nThe label \"heritage\" is given to a language based principally on the social status of its speakers and not necessarily on any linguistic property. Thus, while Spanish typically comes in second in terms of native speakers worldwide and has official status in a number of countries, it is considered a heritage language in the English-dominant United States. Outside the United States, heritage language definitions and use vary.\n\nSpeakers of the same heritage language raised in the same community may differ significantly in terms of their language abilities, yet be considered heritage speakers under this definition. Some heritage speakers may be highly proficient in the language, possessing several registers, while other heritage speakers may be able to understand the language but not produce it. Other individuals that simply have a cultural connection with a minority language but do not speak it may consider it to be their heritage language. It is held by some that ownership does not necessarily depend on usership: “Some Aboriginal people distinguish between usership and ownership. There are even those who claim that they own a language although they only know one single word of it: its name.”\n\nHeritage learners have a fluent command of the dominant language and are comfortable using it in formal settings, due to their exposure to the language through formal education. Their command of the heritage language, however, varies widely. Some heritage learners may lose some fluency in the first language after beginning formal education in the dominant language. Others may use the heritage language consistently at home and with family, but receive minimal to no formal training in the heritage language and thus may struggle with literacy skills or using it in broader settings outside of the home. An additional factor that affects the acquisition of the learner, is whether he or she shows willingness or reluctance towards learning the heritage language.\n\nOne factor that has been shown to influence the loss of fluency in the heritage language is age. Studies have shown that younger bilingual children are more susceptible to fluency loss than older bilingual children. The older the child is when the dominant language is introduced, the less likely he/she is going to lose ability in using his/her first language (the heritage language). This is because the older the child is, the more exposure and knowledge of use the child will have had with the heritage language, and thus the heritage language will remain as their primary language. Researchers found that this phenomenon primarily deals with the memory network of an individual. Once a memory network is organized, it is difficult for the brain to reorganize information contrary to the initial information, because the previous information was processed first. This phenomenon becomes a struggle for adults who are trying to learn a different language. Once an individual has learned a language fluently, they will be heavily influenced by the grammatical rules and pronunciations of their first language they learned, while learning a new language.\n\nAn emerging effective way of measuring the proficiency of a heritage speaker is by speech rate. A study of gender restructuring in heritage Russian showed that heritage speakers fell into two groups: those who maintained the three-gender system and those who radically reanalyzed the system as a two-gender system. The heritage speakers who reanalyzed the three-gender system as a two-gender system had a strong correlation with a slower speech rate. The correlation is straightforward—lower proficiency speakers have more difficulty accessing lexical items; thus, their speech is slowed down.\n\nAlthough speech rate has been shown to be an effective way of measuring proficiency of heritage speakers, some heritage speakers are reluctant to produce any heritage language whatsoever. Lexical proficiency is an alternative method that is also effective in measuring proficiency. In a study with heritage Russian speakers, there was a strong correlation between the speaker's knowledge of lexical items (measured using a basic word list of about 200) and the speaker's control over grammatical knowledge such as agreement, temporal marking, and embedding.\n\nSome heritage speakers explicitly study the language to gain additional proficiency. The learning trajectories of heritage speakers are markedly different from the trajectories of second language learners with little or no previous exposure to a target language. For instance, heritage learners typically show a phonological advantage over second language learners in both perception and production of the heritage language, even when their exposure to the heritage language was interrupted very early in life. Heritage speakers also tend to distinguish, rather than conflate, easily confusable sounds in the heritage language and the dominant language more reliably than second language learners. In morphosyntax as well, heritage speakers have been found to be more native-like than second language learners, although they are typically significantly different from native speakers.\nMany linguists frame this change in heritage language acquisition as “incomplete acquisition” or \"attrition.\" \"Incomplete acquisition,\" loosely defined by Montrul, is \"the outcome of language acquisition that is not complete in childhood.\" In this incomplete acquisition, there are particular properties of the language that were not able to reach age-appropriate levels of proficiency after the dominant language has been introduced. Attrition, as defined by Montrul, is the loss of a certain property of a language after one has already mastered it with native-speaker level accuracy. These two cases of language loss have been used by Montrul and many other linguists to describe the change in heritage language acquisition. However, this is not the only viewpoint of linguists to describe heritage language acquisition. One argument against incomplete acquisition is that the input that heritage speakers receive is different from monolinguals (the input may be affected by cross-generational attrition, among other factors), thus the comparison of heritage speakers against monolinguals is weak. This argument by Pascual and Rothman claims that the acquisition of the heritage language is therefore not incomplete, but complete and simply different from monolingual acquisition of a language. Another argument argues for a shift in focus on the result of incomplete acquisition of a heritage language to the process of heritage language acquisition. In this argument, the crucial factor in changes to heritage language acquisition is the extent to which the heritage speaker activates and processes the heritage language. This new model thus moves away from language acquisition that is dependent on the exposure to input of the language and moves towards dependence on the frequency of processing for production and comprehension of the heritage language.\n\nSome colleges and universities offer courses prepared for speakers of heritage languages. For example, students who grow up learning some Spanish in the home may enroll in a course that will build on their Spanish abilities.\n\n\n\n\n"}
{"id": "2207203", "url": "https://en.wikipedia.org/wiki?curid=2207203", "title": "Historical language", "text": "Historical language\n\nHistorical languages (also known as historic languages) are languages that were spoken in a historical period, but that are distinct from their modern form; that is, they are forms of languages historically attested to from the past which have evolved into more modern forms. Thus, historical languages contrast with dead languages (languages which have become extinct, or undergone language death). Also, historical languages contrast with reconstructed languages (that is, the proto-languages) of theoretical linguistics. One of the approaches to defining and using the concept of historical languages is implemented in the ISO 639 standards.\n\nThe International Organization for Standardization (sometimes by means of a registration authority) maintains and publishes standards for languages, among other things: the ISO 639-3 standards for languages include type H, for historical languages, part of a five-way typology to classify languages. Besides the historic languages, there are also ISO 639-3 classifications for living languages (languages with currently living native speakers), extinct languages (for languages whose last native speaker died within the last few centuries), ancient languages (whose last attested native speaker died more than a millennium ago), and constructed languages (which may or may not have native speakers). Old English is an example of a historic language. The ISO 639 language code for Old English is codice_1. A further ISO 639-3 criterion for historic languages is that they have a distinct literature from their descendant languages: in the example of Old English, Beowulf and other works of Old English literature form a distinct body of material.\n\n\n"}
{"id": "51595982", "url": "https://en.wikipedia.org/wiki?curid=51595982", "title": "Hwanghae dialect", "text": "Hwanghae dialect\n\nHwanghae dialect (황해 방언) is a dialect of Korean spoken in North Hwanghae Province and South Hwanghae Province in North Korea.\n"}
{"id": "37473881", "url": "https://en.wikipedia.org/wiki?curid=37473881", "title": "Hypocognition", "text": "Hypocognition\n\nHypocognition, in cognitive linguistics, means missing and being unable to communicate cognitive and linguistic representations because there are no words for particular concepts.\n\nThe word hypocognition (and its opposite, hypercognition) was coined by American psychiatrist and anthropologist Robert Levy in his 1973 book \"Tahitians: Mind and Experience in the Society Islands\". After 26 months of studying them, Levy described Tahitians as having no words to describe sorrow or guilt, resulting in people who had suffered personal losses describing themselves as feeling sick or strange instead of sad. Levy believed the Tahitians' lack of frames for thinking about and expressing grief contributed to their high suicide rate. He believed that a balance between hypercognition and hypocognition was culturally most desirable.\n\nHypocognition is a phrase commonly used in linguistics. In 2004 George Lakoff used it to describe political progressives in the United States, saying that relative to conservatives they suffer from \"massive hypocognition,\" which he described as the lack of having a progressive philosophy framed around the progressive core values of empathy and responsibility such as \"effective government\" versus \"less government\" or \"broader prosperity\" versus \"free markets.\"\n\nHypocognition has been blamed for preventing the practical application of evidence-based medicine in areas where frames (contextual and presentational influences on perceptions of reality) obscure facts. More generally, experts often overuse their own expertise: e.g. cardiologist diagnose a heart problem when the actual problem is something else.\n"}
{"id": "19001725", "url": "https://en.wikipedia.org/wiki?curid=19001725", "title": "I-message", "text": "I-message\n\nIn interpersonal communication, an I-message or I-statement is an assertion about the feelings, beliefs, values etc. of the person speaking, generally expressed as a sentence beginning with the word \"I\", and is contrasted with a \"you-message\" or \"you-statement\", which often begins with the word \"you\" and focuses on the person spoken to. Thomas Gordon coined the term \"I message\" in the 1960s while doing play therapy with children. He added the concept to his book for parents, \"P.E.T.: Parent Effectiveness Training\" (1970).\n\nI-messages are often used with the intent to be assertive without putting the listener on the defensive. They are also used to take ownership for one's feelings rather than implying that they are caused by another person. An example of this would be to say: \"I really am getting backed up on my work since I don't have the financial report yet\", rather than: \"you didn't finish the financial report on time!\" (The latter is an example of a \"you-statement\").\n\nI-messages or I-statements can also be used in constructive criticism. For instance, one might say, \"I had to read that section of your paper three times before I understood it\", rather than, \"This section is worded in a really confusing way\", or \"You need to learn how to word a paper more clearly.\" The former comment leaves open the possibility that the fault lies with the giver of the criticism. According to the Conflict Resolution Network, I-statements are a dispute resolution conversation opener that can be used to state how one sees things and how one would like things to be, without using inflaming language\n\nWhile the underlying rationale and approach to I-messages is similar in various systems, there are both three-part and four-part models for constructing I-messages. A three-part model is proposed by the University of Tennessee Family & Consumer Sciences for improving communication with children:\n\nAccording to Hope E. Morrow, a common pitfall in I-statement construction is using phrases like \"I feel that...\" or \"I like that...\" which typically express an opinion or judgment. Morrow favors following \"I feel...\" with a feeling such as \"sad\", \"angry\", etc. \n\nGordon advises that to use an I-message successfully, there should be congruence between the words one is using and one's affect, tone of voice, facial expression and body language. Gordon also describes a 3-part I-message, called a \"confrontive\" I-message, with the following parts:\nHe describes the I-message as an appeal for help from the other person, and states that the other person is more likely to respond positively when the message is presented in that way.\n\nIf an \"I\" message contains \"you-messages\", it can be problematic in conflict situations. For example: \"I feel..., when you..., and I want you to...\" This can put the receiver of the statement on the defensive. In a dispute, use of a phrase that begins with \"I want\" may encourage the parties to engage in positional problem solving. This may make conflicts more difficult to resolve. An \"interest-based\" approach to conflict resolution suggests using statements that reflect why the individual wants something.\n\nThe goals of an \"I\" message in an interest-based approach:\n\nThe Ohio Commission on Dispute Resolution and Conflict Management summarized this approach as follows: \"A sender of a message can use a statement that begins with 'I' and expresses the sender's feelings, identifies the unwanted behavior, and indicates a willingness to resolve the dispute, without using 'you' statements or engaging in positional problem solving.\n\nThe Commission proposed a four-part I-message:\n\nMarital stability and relationship analysis researcher John Gottman notes that although I-statements are less likely than You-statements to be critical and to make the listener defensive, \"you can also buck this general rule and come up with 'I' statements like 'I think you are selfish' that are hardly gentle. So the point is not to start talking to your spouse in some stilted psychobabble. Just keep in mind that if your words focus on how \"you're\" feeling rather than on accusing your spouse, your discussion will be far more successful.\"\n\nI-statements have been found to offer a tremendous benefit to clients – patients. I-statements encourage growth and maturation. They are beneficial when employed with an individual struggling with self-defeating thoughts and mindset.\n\nThe therapeutic model varies on its take on the use of I-statements. I-statements are designed to rid the myths from the reality of life. I-statements are further productive in challenging one's innermost feelings. Dr. Asa Don Brown, author with the Canadian Counseling and Psychotherapy Association stated that \"Self-talk reflects your innermost feelings.\" If they reflect your \"inner most\" feelings, then understanding those feelings are necessary in overcoming one's negative perceptions and worldviews, according to Dr. Brown.\n\nI-statements are capable of influencing one's path and design in life. According to Girlshealth.gov, \"An I-statement is a sentence that begins with the word \"I.\" It helps the... (individual) take responsibility for their feelings instead of saying they are caused by the other person. This can help keep relationships open and honest between people when there is a conflict.\" \n\nI statements are important for clarifying one's position, contribution, and desires around a situation, event, and/or life perspective. According to family psychology movement, I-statements are necessary for establishing a healthy relationship and an appropriate level of intimacy.\n\nI-statements help the individual avoid blame, turning blame into personal responsibility. Personal responsibility is key to learning to use I-statements. Without personal responsibility, I-statements are null in their intention.\n\nGordon states, \"Although I-messages are more likely to influence others to change than You-messages, still it is a fact that being confronted with the prospect of having to change is often disturbing to the changee.\" A quick shift by the sender of the I-message to an active listening posture can achieve several important functions in this situation, according to Gordon. He states that in Leader Effectiveness Training courses, this is called \"shifting gears\", and states that the person might shift back to an I-message later in the conversation.\n\nA book about mentoring states that communications specialists find that I-messages are a less threatening way to confront someone one wants to influence, and suggests a three-part I-message: a neutral description of planned behaviour, consequences of the behaviour, and the emotions of the speaker about the situation.\n\nA manual for health care workers calls I-messages an \"important skill\", but emphasizes that use of an I-message does not guarantee that the other person will respond in a helpful way. It presents an I-message as a way that one can take responsibility for one's own feelings and express them without blaming someone else. A manual for social workers presents I-messages as a technique with the purpose of improving the effectiveness of communication.\n\nA study in Hong Kong of children's reactions to messages from their mothers found that children are most receptive to I-messages that reveal distress, and most antagonistic towards critical you-messages. A study with university students as subjects did not find differences in emotional reactions to I-messages and you-messages for negative emotions, but did find differences in reactions for positive emotions.\n\nA study of self-reported emotional reactions to I-statements and you-statements by adolescents found that accusatory you-statements evoked greater anger and a greater inclination for antagonistic response than assertive I-statements.\n\n\n"}
{"id": "2780919", "url": "https://en.wikipedia.org/wiki?curid=2780919", "title": "Indeterminacy of translation", "text": "Indeterminacy of translation\n\nThe indeterminacy of translation is a thesis propounded by 20th-century American analytic philosopher W. V. Quine. The classic statement of this thesis can be found in his 1960 book \"Word and Object\", which gathered together and refined much of Quine's previous work on subjects other than formal logic and set theory. The indeterminacy of translation is also discussed at length in his \"Ontological Relativity\". Crispin Wright suggests that this \"has been among the most widely discussed and controversial theses in modern analytical philosophy\". This view is endorsed by Putnam who states that it is \"the most fascinating and the most discussed philosophical argument since Kant's Transcendental Deduction of the Categories\".\n\nThree aspects of indeterminacy arise, of which two relate to indeterminacy of translation. The three indeterminacies are (i) inscrutability of reference, and (ii) holophrastic indeterminacy, and (iii) the underdetermination of scientific theory. The last of these, not discussed here, refers to Quine's assessment that evidence alone does not dictate the choice of a scientific theory. The first refers to indeterminacy in interpreting individual words or sub-sentences. The second refers to indeterminacy in entire sentences or more extensive portions of discourse.\n\nIndeterminacy of reference refers to the interpretation of words or phrases in isolation, and Quine's thesis is that no unique interpretation is possible, because a 'radical interpreter' has no way of telling which of many possible meanings the speaker has in mind. Quine uses the example of the word \"gavagai\" uttered by a native speaker of the unknown language \"Arunta\" upon seeing a rabbit. A speaker of English could do what seems natural and translate this as \"Lo, a rabbit.\" But other translations would be compatible with all the evidence he has: \"Lo, food\"; \"Let's go hunting\"; \"There will be a storm tonight\" (these natives may be superstitious); \"Lo, a momentary rabbit-stage\"; \"Lo, an undetached rabbit-part.\" Some of these might become less likely – that is, become more unwieldy hypotheses – in the light of subsequent observation. Other translations can be ruled out only by querying the natives: An affirmative answer to \"Is this the same \"gavagai\" as that earlier one?\" rules out some possible translations. But these questions can only be asked once the linguist has mastered much of the natives' grammar and abstract vocabulary; that in turn can only be done on the basis of hypotheses derived from simpler, observation-connected bits of language; and those sentences, on their own, admit of multiple interpretations.\n\nThe situation is made worse when more abstract words are used, not directly attached to public observation:\nThese observations about the need for context brings up the next topic, holophrastic indeterminacy.\n\nIt is confusing that Quine's choice of meaning for 'holophrastic', contrasting it with sub-sentential phrases, appears to run counter to its accepted meaning in linguistics, \"expressing a complex of ideas in a single word or in a fixed phrase\".\nQuine considers the methods available to a field linguist attempting to translate a hitherto unknown language he calls \"Arunta\". He suggests that there are always different ways one might break a sentence into words, and different ways to distribute functions among words. Any hypothesis of translation could be defended only by appeal to context, by determining what other sentences a native would utter. But the same indeterminacy appears there: any hypothesis can be defended if one adopts enough compensatory hypotheses about other parts of the language.\n\nIndeterminacy of translation also applies to the interpretation of speakers of one's own language, and even to one's past utterances. This does not lead to skepticism about meaning – either that meaning is hidden and unknowable, \"or\" that words are meaningless. However, when combined with a (more or less behavioristic) premise that everything that can be learned about the meaning of a speaker's utterances can be learned from his behavior, the indeterminacy of translation may be felt to suggest that there are no such entities as \"meanings\"; in this connection, it is highlighted (or claimed) that the notion of synonymy has no operational definition. But saying that there are no \"meanings\" is not to say that words are not meaningful or significant.\n\nQuine denies an absolute standard of right and wrong in translating one language into another; rather, he adopts a pragmatic stance toward translation, that a translation can be consistent with the behavioral evidence. And while Quine does admit the existence of standards for good and bad translations, such standards are peripheral to his philosophical concern with the act of translation, hinging upon such pragmatic issues as speed of translation, and the lucidity and conciseness of the results. The key point is that more than one translation meets these criteria, and hence that no unique meaning can be assigned to words and sentences.\n\nIn Quine's view, the indeterminacy of translation leads to the inability to separate \"analytic\" statements whose validity lies in the usage of language from \"synthetic\" statements, those that assert facts about the world. The argument hinges on the role of synonymy in analytic statements, \"A natural suggestion, deserving close examination, is that the synonymy of two linguistic forms consists simply in their interchangeability in all contexts without change of truth value\". However, Quine argues, because of the indeterminacy of translation, any attempt to define 'analyticity' on a substitutional basis invariably introduces assumptions of the synthetic variety, resulting in a circular argument. Thus, this kind of substitutability does not provide an adequate explanation of synonyms.\n\n\n"}
{"id": "38746495", "url": "https://en.wikipedia.org/wiki?curid=38746495", "title": "Kanjari language", "text": "Kanjari language\n\nKanjari is an unclassified Indic tribal language of India. It may be one of the Punjabi languages.\n"}
{"id": "21503561", "url": "https://en.wikipedia.org/wiki?curid=21503561", "title": "Language game", "text": "Language game\n\nA language game (also called secret language, ludling, or argot) is a system of manipulating spoken words to render them incomprehensible to the untrained ear. Language games are used primarily by groups attempting to conceal their conversations from others. Some common examples are Pig Latin; the Gibberish family, prevalent in the United States and Sweden; and Verlan, spoken in France.\n\nA common difficulty with language games is that they are usually passed down orally; while written translations can be made, they are often imperfect, and thus spelling can vary widely.\nSome factions argue that words in these spoken tongues should simply be written the way they are pronounced, while others insist that the purity of language demands that the transformation remain visible when the words are imparted to paper.\n\nSome language games such as Pig Latin are so widely known that privacy is virtually impossible, as most people have a passable understanding of how it works and the words can sound very similar to their English counterpart. Although language games are not usually used in everyday conversation, some words from language games have made their way into normal speech, such as \"ixnay\" in English (from Pig Latin), and \"loufoque\" in French (from Louchébem).\n\nOne way in which language games could be organized is by language, for example, Pig Latin, Ubbi Dubbi, and Tutnese could all be in the \"English\" category, and Jeringonza could be in the \"Spanish\" category.\n\nAn alternate method of classifying language games is by their function. For example, Ubbi Dubbi, Bicycle, and all work by inserting a code syllable before the vowel in each syllable. Therefore, these could be classified in the Gibberish family. Also, Double Talk, Língua do Pê, Jeringonza, and B-Sprache all work by adding a consonant after the vowel in each syllable, and then repeating the vowel. Thus, these could be classified in the Double Talk family. Another common type of language game is the spoonerism, in which the onsets of two words are exchanged. Using a standard word for each transformation gives another type, for example, the Finnish \"kontinkieli\", where \"kontti\" is added after each word, and spoonerism applied (kondäntti koonerismspontti koppliedäntti).\n\nAdditionally, Auflinger described some types of speech disguise in some languages near the city of Madang in Papua New Guinea.\n\n\n"}
{"id": "651326", "url": "https://en.wikipedia.org/wiki?curid=651326", "title": "Macaronic language", "text": "Macaronic language\n\nMacaronic language refers to text using a mixture of languages, particularly bilingual puns or situations in which the languages are otherwise used in the same context (rather than simply discrete segments of a text being in different languages). The term can also denote hybrid words, which are effectively \"internally macaronic\". A rough equivalent in spoken language is code-switching, a term in linguistics referring to using more than one language or dialect within the same conversation.\n\nMacaronic Latin in particular is a jumbled jargon made up of vernacular words given Latin endings, or for Latin words mixed with the vernacular in a pastiche (compare dog Latin).\n\nThe word \"macaronic\" comes from the New Latin \"macaronicus\" which is from the Italian \"maccarone\" (\"dumpling\", regarded as coarse peasant fare). The term can have derogatory overtones, and is usually reserved for works where the mixing of languages has a humorous or satirical intent or effect. It is a matter of debate whether the term can be applied to mixed-language literature of a more serious nature and purpose.\n\nTexts that mixed Latin and vernacular language apparently arose throughout Europe at the end of the Middle Ages—a time when Latin was still the working language of scholars, clerics and university students, but was losing ground to vernacular among poets, minstrels and storytellers.\n\nAn early example is from 1130, in the Gospel book of Munsterbilzen Abbey. The following sentence mixes late Old Dutch and Latin:\n<poem>\nTesi samanunga was edele unde scona\net omnium virtutum pleniter plena\n</poem>\nTranslated: \"This community was noble and pure, and completely full of all virtues.\"\n\nThe \"Carmina Burana\" (collected c.1230) contains several poems mixing Latin with Medieval German or French. Another well-known example is the first stanza of the famous carol \"In Dulci Jubilo\", whose original version (written around 1328) had Latin mixed with German, with a hint of Greek. While some of those early works had a clear humorous intent, many use the language mix for lyrical effect.\n\nAnother early example is in the Middle English recitals \"The Towneley Plays\" (c.1460). In \"The Talents\" (play 24), Pontius Pilate delivers a rhyming speech in mixed English and Latin.\n\nA number of English political poems in the 14th century alternated (Middle) English and Latin lines, such as in MS Digby 196:\n<poem>The taxe hath tened [ruined] vs alle,\n\nSeveral Anthems also contain both Latin and English. In the case of 'Nolo mortem pecatoris' by Thomas Morley, the Latin is used as a refrain:\n\n<poem>\nNolo mortem peccatoris; Haec sunt verba Salvatoris.\nFather I am thine only Son, sent down from heav’n mankind to save.\nFather, all things fulfilled and done according to thy will, I have.\nFather, my will now all is this: Nolo mortem peccatoris.\nFather, behold my painful smart, taken for man on ev’ry side;\nEv'n from my birth to death most tart, no kind of pain I have denied,\nbut suffered all, and all for this: Nolo mortem peccatoris.\n</poem>\nTranslated: \"'I do not wish the death of the wicked'; These are the words of the Saviour.\" An allusion to John 3:17 and 2 Peter 3:9.\n\nThe term \"macaronic\" is believed to have originated in Padua in the late 15th century, apparently from \"maccarona\", a kind of pasta or dumpling eaten by peasants at that time. (That is also the presumed origin of \"maccheroni\".) Its association with the genre comes from the \"Macaronea\", a comical poem by Tifi Odasi in mixed Latin and Italian, published in 1488 or 1489. Another example of the genre is \"Tosontea\" by Corrado of Padua, which was published at about the same time as Tifi's \"Macaronea\".\n\nTifi and his contemporaries clearly intended to satirize the broken Latin used by many doctors, scholars and bureaucrats of their time. While this \"macaronic Latin\" (\"macaronica verba\") could be due to ignorance or carelessness, it could also be the result of its speakers trying to make themselves understood by the vulgar folk without resorting to their speech.\n\nAn important and unusual example of mixed-language text is the \"Hypnerotomachia Poliphili\" of Francesco Colonna (1499), which was basically written using Italian syntax and morphology, but using a made-up vocabulary based on roots from Latin, Greek, and occasionally others. However, while the \"Hypnerotomachia\" is contemporary with Tifi's \"Macaronea\", its mixed language is not used for plain humor, but rather as an aesthetic device to underscore the fantastic but refined nature of the book.\n\nTifi's \"Macaronea\" was a popular success, and the writing of humorous texts in macaronic Latin became a fad in the 16th and 17th centuries, particularly in Italian, but also in many other European languages. An important Italian example was \"Baldo\" by Teofilo Folengo, who described his own verses as \"a gross, rude, and rustic mixture of flour, cheese, and butter\".\n\nMacaronic verse is especially common in cultures with widespread bilingualism or language contact, such as Ireland before the middle of the nineteenth century. Macaronic traditional songs such as \"Siúil A Rúin\" are quite common in Ireland. In Scotland, macaronic songs have been popular among Highland immigrants to Glasgow, using English and Scottish Gaelic as a device to express the alien nature of the anglophone environment. An example:\n\nWhen I came down to Glasgow first,\na-mach air Tìr nan Gall.\nI was like a man adrift,\nair iomrall 's doll air chall.\n\nFolk and popular music of the Andes frequently alternates between Spanish and the given South American language of its region of origin.\n\nSome Classical Persian poems were written with alternating Persian and Arabic verses or hemistichs, most famously by Saadi and Hafez. Such poems were called \"molamma‘\" (, literally \"speckled\", plural \"molamma‘āt\" ), Residing in Anatolia, in some of his poems Rumi mixed Persian with Arabic as well as the local languages of Turkish and Greek.\n\nMacaronic verse was also common in medieval India, where the influence of the Muslim rulers led to poems being written in alternating indigenous Hindi and the Persian language. This style was used by the famous poet Amir Khusro and played a major role in the rise of the Urdu or Hindustani language.\n\nThe Sublime song \"Caress Me Down\" alternates between English and Spanish lyrics, at some points between verses, at others between lines within a verse, and occasionally between phrases within a line.\n\nOccasionally language is unintentionally macaronic. One particularly famed piece of schoolyard Greek in France is Xenophon's line \"they did not take the city; but in fact they had no hope of taking it\" (, \"ouk élabon pólin; álla gàr elpìs éphē kaká\"). Read in the French manner, this becomes \"Où qu'est la bonne Pauline? A la gare. Elle pisse et fait caca.\" (\"Where is Pauline the maid? At the [railway] station. She's pissing and taking a shit.\") In English literature, the untranslated line makes an appearance in James Joyce's \"Finnegans Wake\".\n\nMacaronic text is still used by modern Italian authors, e.g. by Carlo Emilio Gadda and Beppe Fenoglio. Other examples are provided by the character Salvatore in Umberto Eco's \"The Name of the Rose\", and the peasant hero of his \"Baudolino\". Dario Fo's \"Mistero Buffo\" (\"Comic Mystery Play\") features grammelot sketches using language with macaronic elements.\n\nThe 2001 novel \"The Last Samurai\" by Helen DeWitt includes portions of Japanese, Classical Greek, and Inuktitut, although the reader is not expected to understand the passages that are not in English.\n\nMacaronic games are used by the literary group Oulipo in the form of interlinguistic homophonic transformation: replacing\na known phrase with homophones from another language. The archetypal example is by François Le Lionnais, who transformed John Keats' \"A thing of beauty is a joy forever\" into \"Un singe de beauté est un jouet pour l'hiver\": 'A monkey of beauty is a toy for the winter'. Another example is the book \"Mots d'Heures\".\n\nMacaronisms figure prominently in \"The Trilogy\" by the Polish novelist Henryk Sienkiewicz, and are one of the major compositional principles for James Joyce's novel \"Finnegans Wake\".\n\nTwo well-known examples of non-humorous macaronic verse are Byron's \"Maid of Athens, ere we part\" (1810, in English with a Greek refrain); and Pearsall's translation of the carol \"In Dulci Jubilo\" (1837, in mixed English and Latin verse).\n\nAn example of modern humorous macaronic verse is the anonymous English/Latin poem \"Carmen Possum\" (\"The Opossum's Song\"), which is sometimes used as a teaching and motivational aid in elementary Latin language classes. Other similar examples are \"The Motor Bus\" by A. D. Godley, and the anonymous \"Up I arose in verno tempore\".\n\nRecent examples are the \"mużajki\" or 'mosaics' (2007) of Maltese poet Antoine Cassar mixing English, Spanish, Maltese, Italian, and French; works of Italian writer Guido Monte; and the late poetry of Ivan Blatný combining Czech with English. \n\nBrian P. Cleary's \"What Can I C'est?\" makes use of macaronic verse, as do other poems in his book \"Rainbow Soup: Adventures in Poetry\":\n\nMy auntie Michelle is big in the BON\n(As well as the hip and the thigh).\nAnd when she exhales, OUI haul out our sails\nAnd ride on the wind of VERSAILLES.\n\nA whole body of comic verse exists created by John O'Mill, pseudonym of Johan van der Meulen, a teacher of English at the Rijks HBS (State Grammar School), Breda, the Netherlands. These are in a mixture of English and Dutch, often playing on common mistakes made when translating from the latter to the former.\n\nThe finale of act 1 of Gilbert and Sullivan's Savoy Opera Iolanthe has several instances of humorous macaronic verse. \n\nFirst, the three Lords mix Italian and Latin phrases into their discussion of Iolanthe's age:\nLord Mountararat: This gentleman is seen, / With a maid of seventeen, / A-taking of his \"dolce far niente\"...\nLord Chancellor: Recollect yourself, I pray, / And be careful what you say- / As the ancient Romans said, \"festina lente\"...\nLord Tolloller: I have often had a use / For a thorough-bred excuse / Of a sudden (which is English for \"repente\")...\nLord Mountararat: Now, listen, pray to me, / For this paradox will be / Carried, nobody at all \"contradicente\"...\n\nThen, the chorus of peers sing macaronic verse as they attempt to resist the fairies' powers:\nOur lordly style you shall not quench with base \"canaille\"! (That word is French.) \nDistinction ebbs before a herd of vulgar \"plebs\"! (A Latin word.)\nTwould fill with joy and madness stark the \"oι πoλλoί\"! (A Greek remark.) \nOne Latin word, one Greek remark, and one that's French.\n\n'Macaronisms' are frequently used in films, especially comedies. In Charlie Chaplin's anti-war comedy \"The Great Dictator\", the title character speaks English mixed with a parody of German (e.g. \"Cheese-und-cracken\"). This was also used by Benzino Napaloni, the parody character of Benito Mussolini, using Italian foods (such as salami and ravioli) as insults.\n\nOther movies featuring macaronic language are the Italian historical comedies \"L'armata Brancaleone\" and \"Brancaleone alle crociate\" (d. Mario Monicelli), which mix modern and medieval Italian as well as Latin (sometimes in rhyme, and sometimes with regional connotations, such as the Italo-Normans using words from modern Sicilian).\n\nMacaronic language appearing in popular songs include Dean Martin's \"That's Amore\" (Italian and English), the Beatles’ \"Michelle\" (French and English), The Clash’s \"Spanish Bombs\" and José Feliciano’s \"Feliz Navidad\" (Spanish and English), the Talking Heads \"Psycho Killer\" (French and English), and The Weeknd's Montreal (French and English).\n\n\n\n"}
{"id": "57559630", "url": "https://en.wikipedia.org/wiki?curid=57559630", "title": "Majena language", "text": "Majena language\n\nMajena, also known as Majiena or Maxiena, is an unclassified, now-extinct language, originally spoken by the alleged Ticomeri people of the Llanos de Mojos plains in northwestern Bolivia. Nothing is known about the language itself, but sources state that it was unintelligible to speakers of the nearby Arawakan languages Moxo and Baure (the term \"Ticomeri\" is a Moxo exonym meaning \"other-language\") and possibly unrelated to any languages of the area. It may therefore have been a language isolate.\n\nSpeakers of the language were identified in the mission settlement of San Borja in the eighteenth century. There is some confusion between the Majena-speaking Ticomeri and another group, also known as \"Ticomeri\", who spoke a divergent dialect of Moxo. Whether the two groups were related (i.e. whether the Ticomeri had abandoned Majena and acquired Moxo) is unknowable, since both were apparently extinct by 1805. \n\n"}
{"id": "22014899", "url": "https://en.wikipedia.org/wiki?curid=22014899", "title": "Medny Aleut language", "text": "Medny Aleut language\n\nMednyj Aleut (also called Copper Island Creole or Copper Island Aleut) is a nearly extinct mixed language spoken on Bering Island. It is characterized by Aleut nouns and Russian verbs, each with the full inflectional complexity of the source languages. There are only five native speakers left.\n\nMednyj Aleut is characterised by a blending of Russian and Aleut (primarily Attu) elements in most components of the grammar, but most profoundly in the verbal morphology. The Aleut component comprises the majority of the vocabulary, all the derivational morphology, part of the simple sentence syntax, nominal inflection and certain other grammatical means. The Russian components comprise verbal inflection, negation, infinitive forms, part of the simple sentence syntax and all of the compound sentence syntax.\n\nOriginally, the language was spoken on Copper Island, from where it takes its name, but all the population of that island was moved to Bering island in 1970.\n\n\n"}
{"id": "1419264", "url": "https://en.wikipedia.org/wiki?curid=1419264", "title": "Modistae", "text": "Modistae\n\nThe Modistae (Latin for \"Modists\"), also known as the speculative grammarians, were the members of a school of grammarian philosophy known as Modism or speculative grammar, active in northern France, Germany, England, and Denmark in the 13th and 14th centuries. Their influence was felt much less in the southern part of Europe, where the somewhat opposing tradition of the so-called \"pedagogical grammar\" never lost its preponderance. \nWilliam of Conches, Peter Helias, and Ralph of Beauvais, also referred to as speculative grammarians predate the Modist movement proper.\n\nThe Modist philosophy was first developed by Martin of Dacia (died 1304) and his colleagues in the mid-13th century, though it would rise to prominence only after its systematization by Thomas of Erfurt decades later, in his treatise \"De modis significandi seu grammatica speculativa\", probably written in the first decade of the 14th century. Until the early twentieth-century this work was assumed to have been authored by John Duns Scotus. Widely reproduced and commented upon in the Middle Ages, it remains the most complete textbook of Modist speculative grammar. The mistaken authorship arose out of the natural affinity of Erfurt's speculative grammar with Scotus's metaphysics.\n\nThe philosophy of the Modistae, as indicated by their name, was based on a theory of 'modes' of meaning in language which was tripartite: modes of being (\"modi essendi\"), modes of understanding (\"modi intelligendi\"), and modes of signifying (\"modi significandi\"). To the Modistae, the various parts of speech were viewed as representing reality in terms of these modes. The \"modi essendi\" are objectively existent qualities in an object of understanding, the \"modi intelligendi\" the understanding's means of representing the \"modi essendi\", and the \"modi significandi\" grammar's means of representing the \"modi intelligendi\" in language. This corresponds to Aristotle's tripartite semantic theory of \"words\" representing \"concepts\" which represent \"objects\".\n\nOpposing nominalism, they assumed that the analysis of the grammar of ordinary language was the key to metaphysics. For the Modistae, grammatical forms, the \"modi significandi\" of verbs, nouns, and adjectives, comprise the deep ontological structure of language, which objectively reflects reality. Their work predicted the concept of universal grammar, suggesting that universal grammatical rules may be extracted from all living languages. Roger Bacon may have given the movement inspiration with his observation that all languages are built upon a common grammar, a shared foundation of ontologically anchored linguistic structures. He argued grammar is substantially the same in all languages, even though it may undergo accidental variations between languages.\n\nThere are parallels between speculative grammar and phenomenology, a fact that was picked up early on by Martin Heidegger, who wrote his first book, \"Die Kategorien-und Bedeutungslehre des Duns Scotus\", on Thomas of Erfurt's treatise (at that time still mistakenly attributed to Duns Scotus).\n\n\n\n\n"}
{"id": "38328195", "url": "https://en.wikipedia.org/wiki?curid=38328195", "title": "Mumpsimus", "text": "Mumpsimus\n\nA mumpsimus () a \"traditional custom obstinately adhered to however unreasonable it may be\", or \"someone who obstinately clings to an error, bad habit or prejudice, even after the foible has been exposed and the person humiliated; also, any error, bad habit, or prejudice clung to in this fashion\". Thus it may describe behaviour or the person who behaves thus. For example, \"all intensive purposes\" is a common eggcorn of the fixed expression \"all intents and purposes\"; if a person who continues to say the eggcorn even after being made aware of the correct form, either the speaker or the phrase may be called a mumpsimus.\n\nThe term originates from an apocryphal story about a poorly educated Catholic priest saying Latin mass who, in reciting the postcommunion prayer (meaning: \"What we have received in the mouth, Lord\"), instead of (meaning: \"we have received\") substitutes the non-word \"mumpsimus\", presumably as a mondegreen. After being made aware of his mistake, he nevertheless persisted with his erroneous version, whether from stubbornness, force of habit, or refusing to believe he was mistaken.\n\nThe story was told by Desiderius Erasmus (1466–1536) in a letter he wrote in August 1516 to Henry Bullock. Erasmus used it as an analogy with those who refused to accept that \"Novum Instrumentum omne\", his edition of the Greek New Testament, corrected errors in the Latin Vulgate. The English diplomat Richard Pace (1482–1536) included a variant in his 1517 work \"De Fructu qui ex Doctrina Percipitur\", where the priest was English and had been saying \"mumpsimus\" for thirty years when corrected. While Pace's book (written in Latin) is credited by the first edition of the \"Oxford English Dictionary\" as the origin of \"mumpsimus\", Pace acknowledged his borrowing in a 1517 letter to Erasmus. \"Mumpsimus and sumpsimus\" became proverbial among Protestants in the early English Reformation.\n\nMumpsimus soon entered the language as a cant word widely used by 16th-century writers.\nIn William Tyndale's 1530 book \"Practice of Prelates\", the word was used in the sense of a stubborn opponent to Tyndale's views. He said that the men whom Cardinal Wolsey had asked to find reasons why Catherine of Aragon was not truly the wife of King Henry VIII of England were \"...all lawyers, and other doctors, mumpsimuses of divinity\". \nIn 1531 Sir Thomas Elyot used the word in his \"Boke named the Gouvernor\" where he said of \"Magnanimitie\" that the word, \"...being yet straunge, as late borowed out of the Latyne, shall not content all men, and specially them whome nothing contenteth out of their accustomed mumpsimus\".\n\nHenry VIII in his speech at the State Opening of Parliament on Christmas Eve 1545 said:\n\nPeter Heylin refers to the king's saying in his 1631 \"The History of St. George of Cappadocia\" when he talks of \"...those self-conceited ones which are so stiffe—as King Harry used to say—in their new sumpsimus...\" \nHugh Latimer (1487–1555) used the term in two sermons he preached in 1552, saying: \"When my neighbour is taught, and knoweth the truth, and will not believe it, but will abide in his old \"mumpsimus\"...\" and again: \"Some be so obstinate in their old \"mumpsimus\", that they cannot abide the true doctrine of God.\"\n\nIn an 1883 polemic on errors in translations of the Christian Bible, John Burgon says: \"If men prefer \"their\" 'mumpsimus' to \"our\" 'sumpsimus', let them by all means have it: but pray let them keep their rubbish to themselves—and at least leave our SAVIOUR's words alone.\"\n\nEugene T. Maleska, 1970s editor of \"The New York Times\" crossword puzzle, received \"dozens of letters\" after \"mumpsimus\" appeared as an answer; he had felt that \"it was time to revive the obsolete noun\". A. Leslie Derbyshire applied it in a 1981 management science book to managers who know how to do a better job but choose not to. \"Garner's Modern English Usage\" says the word could describe George W. Bush because of his persistent habit of pronouncing \"nuclear\" as \"nucular\", despite the error being widely reported.\n"}
{"id": "52961487", "url": "https://en.wikipedia.org/wiki?curid=52961487", "title": "Mycenology", "text": "Mycenology\n\nMycenology is the study of the Mycenaean Greek language and the culture and institutions recorded in that language. It emerged as a discipline auxiliary to classical philology in 1953, following the deciphering of Minoan Linear B script by Alice Kober, Michael Ventris and John Chadwick.\n"}
{"id": "1743222", "url": "https://en.wikipedia.org/wiki?curid=1743222", "title": "Norito", "text": "Norito\n\nThere is no single accepted universally accepted theory to explain the meaning of the term. One theory derives \"norito\" from \"noru\" (宣る, 'to declare'; cf. the verbs \"inoru\" 'to pray' and \"norou\" 'to curse') - combined with the suffix \"-to\". A variant term, \"notto\", is derived from a combination of \"norito\" with \"koto\", 'word'.\n\nThere are various known ways of writing the word in kanji: aside from 祝詞 (currently the standard), 詔戸言, 詔刀言, and 諄辞 are also attested.\n\nOne recent writer summed up the original meaning of \"norito\" as \"a general term meaning magic by means of words.\"\n\nThe first written documentation of \"norito\" dates to 712 CE in the \"Kojiki\" and 720 CE in the \"Nihongi\".\n\nThe Engishiki, a compilation of laws and minute regulation presented by the court compiled in 927 CE, preserves twenty-seven representative forms of \"norito\".\n\n\"Norito\" were (and still are) traditionally written in a variety of \"man'yōgana\" where particles and suffixes are written in a smaller script than the main body of the text. This style of writing, used in imperial edicts (宣命 \"senmyō\") preserved in the \"Shoku Nihongi\" and other texts dating from the 8th century (Nara period), is known as \"senmyōgaki\".\n\n"}
{"id": "27462322", "url": "https://en.wikipedia.org/wiki?curid=27462322", "title": "Partner-assisted scanning", "text": "Partner-assisted scanning\n\nPartner-assisted scanning or listener-assisted scanning is an augmentative and alternative communication technique used to enable a person with severe speech impairments to communicate. The approach is used with individuals who, due to sickness or disability, have severe motor impairments and good memory and attention skills. It is used as an alternative to direct access (e.g. pointing) to symbols, pictures, or speech generating devices when these are not used.\n\nPartner-assisted scanning is a technique used with children who have severe motor and communication impairments, and especially those with additional visual impairment, those who do not yet have an established alternative form of communication, or who are unable to use their usual method, perhaps because their electronic speech output device is being repaired. Adults may also use scanning with a partner when they are not using their more high-tech alternative communication device. Partner-assisted scanning can also be the main means of communication for adults in late stages of diseases such as Amyotrophic Lateral Sclerosis (ALS), multiple sclerosis (MS) or those in intensive care.\n\nIn partner-assisted scanning, the communication partner presents messages or letter choices in a sequential fashion to the individual who wishes to communicate something, and the individual then makes their selection. Scanning refers to the process of items presented one after the other, in the same patterns, until a choice is made as the desired item is reached. Items can be presented either visually, by pointing, or auditorily, by speaking.\n\nEfficiency may be increased in visual partner scanning by the partner first pointing to groups of items, such as rows of letters, and once a row has been selected, proceeding to point to all letters in that row until a choice is made. The communicator can spell words this way in order to express what they need to communicate. Similarly, the partner can point to groups of words. Visual scanning may also be accomplished by the partner pointing to pictures, such as those in a personal communication book, using an agreed upon pattern.\n\nThe selecting system can be divided into two categories: alphanumeric and choice making. These differ, because in the alphanumeric version you scan through letters and numbers. Choice-making is where you present multiple choices. For example, when asked \"Would you like a movie or book?\", the communicator indicates a \"yes\" response. They can do this in a variety of ways, like facial expressions, vocalizations, or body gestures. To determine the best way, one's team of caretakers has to look at the individual's abilities.\n\nAuditory scanning with a partner is often used when the communicator has very poor vision. Groups of letters can be represented by numbers, such as \"1=abcdef\". The partner lists off the numbers, and once a group is selected, he or she will name all letters in that group. Auditory scanning can also be accomplished with lists of novel messages. The partner orally lists the options and then repeats them so the communicator can make a selection. This could be a short list of emotions to inquire as to how someone is feeling (e.g. happy, sad, frustrated). The partner and communicator can memorize many lists, or \"menus\", with sub-lists covering different topics for communication. It is important that lists are repeated in the same order and with pauses after each item, so that there is time to respond.\n\nJean-Dominique Bauby, who had locked-in syndrome, used partner-assisted scanning to communicate and to write his book \"The Diving Bell and the Butterfly\".\n\n\n"}
{"id": "1832038", "url": "https://en.wikipedia.org/wiki?curid=1832038", "title": "Phi features", "text": "Phi features\n\nIn linguistics, especially within generative grammar, phi features (denoted with the Greek letter φ 'phi') are the semantic features of person, number, gender, and case, as encoded in pronominal agreement with nouns and pronouns (the latter are said to consist only of phi-features, containing no lexical head). Several other features are included in the set of phi-features, such as the categorical features ±N (nominal) and ±V (verbal), which can be used to describe lexical categories and case features.\n\nPhi-features are often thought of as the \"silent\" features that exist on lexical heads (or, according to some theories, within the syntactic structure) that are understood for number, gender, person or reflexivity. Due to their silent nature, phi-features are often only understood if someone is a native speaker of a language, or if the translation includes a gloss of all these features. Many languages exhibit a pro-drop phenomenon which means that they rely on other lexical categories to determine the phi-features of the lexical heads.\n\nChomsky first proposed that the N node in a clause carries with it all the features to include person, number and gender. In English, we rely on nouns to determine the phi-features of a word, but other languages rely on inflections of the different parts of speech to determine person, number and gender of the nominal phrases to which they refer. Mainly verbs and adjectives are responsible for bearing inflections which signal the phi-features of a particular subject or object. Verbs appear to be responsible for carrying the most features and tend to carry person, number and gender agreements cross-linguistically for both subjects and objects. Adjectives also carry phi-features in some languages, they tend to agree in number and gender but rarely for person .\n\nIn English, person agreement is understood in the pronoun or noun overtly, while the verb carries the agreement marker to agree with the person phi-features on the Noun. For English, there is only one verb agreement required for the third person singular in the present tense (usually -s), as seen in the table Person Agreement for WALK: English. \n\nIn a null-subject language such as Italian, however, subjects are not required (in fact, in many null subject languages, producing overt subjects is a sign of non-nativity). Therefore, Italian uses a different inflectional morphology for each pronominal that is based not the person features of the nominal subject it agrees with:\n\n- Camminare (\"to walk\"):\ncammino (\"I walk)\", camminiamo (\"we walk\")\n\ncammini (\"you walk\"), camminate (\"you all walk\")\n\ncammina (\"he/she walks\"), camminano (\"they walk\")\nIn English, number agreement is not inflected on Verbs like they are in other languages. This is partly because English is a language that requires subjects and the subjects in English overtly express number. In English, number is a phi-feature that is understood on the noun. In terms of inflectional morphology, the most common in English is \"-s\" inflected on nouns that are plural:\n\n- Ducks, fridges, baseballs, cups, books, mirrors, cars, buildings, clowns, bridges, creams...\n\nSome cases of plurality in English require conjugation of the entire noun to express the phi-feature of plurality:\n\n- Men, women, mice, teeth...\n\nNeither verbs nor adjectives are used to agree with the phi-features of the noun that they are agreeing with in English.\nEnglish is a language that does not have gendered nominal phrases and pronouns (except in the case of proper names of nouns that are sentient beings who belong to a certain gender category) and does not have phi-feature agreement for gender. Many other languages of the world do have gendered nouns. German, for example, has three genders; feminine, masculine and neuter. Italian has two: feminine and masculine phi-features. For Italian, inflections on the adjectives and determiners are used for gender agreement within the pronominal phrase.\n\nReflexivity is overt in English for every person:\n\nmyself\", yourself\", himself, yourselves, ourselves, themselves\n\nIn many languages, reflexivity is not overt for person. A prime example is apparent in French \"se\". French \"se\" is used to express reflexivity for every expression of the third person. For this reason, some theories suggest that reflexive phi-features for languages such as French posit in a level on the syntactic structure that is silent, between the determiner and the noun.\n\nX'-theory approaches categorical features in this way: when a head X selects its' complement to project to X', the XP that it projects to then is a combination of the head X and all of its' categorical features, those being either nominal, verbal, adjectival or prepositional features.\n"}
{"id": "1839743", "url": "https://en.wikipedia.org/wiki?curid=1839743", "title": "Probatio pennae", "text": "Probatio pennae\n\nProbatio pennae (also written \"probatio pennę;\" in Medieval Latin; literally \"pen test\") is the medieval term for breaking in a new pen, and used to refer to text written to test a newly cut pen.\n\nA scribe would normally test a newly cut pen to see if it wrote well by writing a few lines of text on a piece of blotting paper. Sometimes these blotting papers survived due to being used afterwards as book binding material; they often provide unique, less \"serious\" textual material that would otherwise have been lost. A famous example is \"Hebban olla vogala\", one of the first fragments of Dutch literature, which survived from a tenth-century \"probatio pennae\".\n"}
{"id": "8498755", "url": "https://en.wikipedia.org/wiki?curid=8498755", "title": "Radical translation", "text": "Radical translation\n\nRadical translation is a thought experiment in \"Word and Object\", a major philosophical work from American philosopher Willard Van Orman Quine. It is used as an introduction to his theory of the indeterminacy of translation, and specifically to prove the point of inscrutability of reference. Using this concept of radical translation, Quine paints a setting where a linguist discovers a native linguistic community whose linguistic system is completely unrelated to any language familiar to the linguist. Quine then describes the steps taken by the linguist in his attempt to fully translate this unfamiliar language based on the only data he has; the events happening around him combined with the verbal and non-verbal behaviour of natives.\n\nAs a first step, the linguist will use direct translation on occasion sentences. Hearing a lot of utterances of the one-word-sentence 'Gavagai' whenever the linguist sees rabbits, he suspects the one-word-sentence 'Rabbit' to be the correct translation and starts a process of questioning and pointing until he is reasonably certain that the native has the verbal disposition to assent to 'Gavagai' if seeing the stimulus, a rabbit. This stimulus is the affirmative stimulus meaning of 'Gavagai', and the linguist can conclude this is a correct translation.\n\nThe translation of occasion sentences may be complicated through collateral information. A native, with full expertise of his surroundings, may already assent to 'Gavagai' when not even seeing a rabbit, but is sufficiently satisfied to assent when spotting a specific rabbit-fly that only flies around rabbits. The linguist on the other hand has no such expertise, and will wonder why his hypothesis seems off. \nCollateral information can also create a difference of stimulus meaning between members of the same language community. To solve this issue, the linguist will determine intrasubjective stimulus synonymy, enabling him to pair non-observational occasion sentences such as 'Bachelor' and 'Unmarried man'. While they may differ in stimulus meaning between various speakers, they are stimulus synonymous for the entire language community.\n\nIt is also possible for the linguist to determine stimulus analytic sentences, to which the native will assent given any (or no) stimulus. Social analytic sentences are sentences that are stimulus analytic for the entire language community.\n\nSo far the linguist has taken his first steps in the creation of a translation manual. However, he has no idea if the term 'gavagai' is actually synonymous to the term 'rabbit', as it is just as plausible to translate it as 'one second rabbit stage', 'undetached rabbit part', 'the spatial whole of all rabbits', or 'rabbithood'.\nTo question these differences, the linguist now has to translate words and logical particles.\n\nStarting off with the easiest task, to translate logical connectives, he formulates questions where he pairs logical connectives with occasion sentences and going through several rounds of writing down the assent or dissent to these questions from the natives to establish a translation. Any further translation of logical particles is however impossible, as translation of categorical statements (for example) relies on the translation of words, which in turn relies on the translation of categorical statements.\n\nAs it appears impossible to determine a unique correct translation of 'gavagai' caused by the limits of translation, the linguist can take any of the mentioned possibilities and have it correspond to the stimulus meaning through adaption of the logical connectives. This implies there is no matter of fact to which the word refers.\nAn example is to take the sentence 'Gavagai xyz gavagai', of which the linguist assumes it translates to 'This rabbit is the same as this rabbit', and to which the native assents. Now, when 'gavagai' is taken as 'undetached rabbit part' and 'xyz' as 'is part of the same animal as', the sentence 'This undetached rabbit part is part of the same animal as this undetached rabbit part', to which the native would also assent. Both sentences have the same stimulus meaning and truth condition. It therefore is impossible to derive the (object of) reference of the term 'gavagai' from the verbal disposition of the native.\n\nSo far the linguist has been able to\n(1) Translate observational sentences\n(2) Translate truth functions\n(3) Recognize stimulus analytic sentences\n(4) Recognize intrasubjective stimulus synonymous sentences\nTo go beyond the limits of translation by stimulus meaning, the linguist uses analytical hypotheses, where he hypothetically equates parts of native sentences to parts of sentences in his own language. Using this, he can now form new sentences and can create a complete translation manual by trial and error through the use of these sentences and adaption of his analytical hypotheses where needed.\n\nThe whole of analytical hypotheses cannot be evaluated as true or false, as they are predictions that can only be judged within their own system. As a result, all translation is fundamentally undetermined (and not just underdetermined). This indeterminacy is not meaningless, as it is it is possible to construct two separate translation manuals that are equally correct yet incompatible with each other due to having opposing truth values. A good translation is possible, but an objectively right translation of exact terms is impossible.\n\n"}
{"id": "162986", "url": "https://en.wikipedia.org/wiki?curid=162986", "title": "Second language", "text": "Second language\n\nA person’s second language or L2 is a language that is not the native language/first language/L1 of the speaker, but is learned by the speaker after his/her native language (usually a foreign language, see below). Additionally, a person’s second language can be explained as the second language in the country the speaker lives in and they may be both used in daily life. For example, Canada has two official languages (English and French) and some citizens speak and use both of them.<br>\nA person’s dominant language, which is the language the speaker uses most or is most comfortable with, is not necessarily to be his/her first language. The second language can also be the dominant one. For example, the Canadian census defines first language for its purposes as \"the first language learned in childhood and still spoken\", recognizing that for some, the earliest language may be lost, a process known as language attrition. This can happen when young children move, with or without their family (because of immigration or international adoption), to a new language environment.<br>\n\nThe distinction between acquiring and learning was made by Stephen Krashen (1982) as part of his Monitor Theory. According to Krashen, the \"acquisition\" of a language is a natural process; whereas \"learning\" a language is a conscious one. In the former, the student needs to partake in natural communicative situations. In the latter, error correction is present, as is the study of grammatical rules isolated from natural language. Not all educators in second language agree to this distinction; however, the study of how a second language is \"learned/acquired\" is referred to as \"second-language acquisition\" (SLA).\n\nResearch in SLA \"...focuses on the developing knowledge and use of a language by children and adults who already know at least one other language... [and] a knowledge of second-language acquisition may help educational policy makers set more realistic goals for programmes for both foreign language courses and the learning of the majority language by minority language children and adults.\" (Spada & Lightbown, p. 115).\n\nSLA has been influenced by both linguistic and psychological theories. One of the dominant linguistic theories hypothesizes that a \"device\" or \"module\" of sorts in the brain contains innate knowledge. Many psychological theories, on the other hand, hypothesize that cognitive mechanisms, responsible for much of human learning, process language.\n\nOther dominant theories and points of research include 2nd language acquisition studies (which examine if L1 findings can be transferred to L2 learning), verbal behaviour (the view that constructed linguistic stimuli can create a desired speech response), morpheme studies, behaviourism, error analysis, stages and order of acquisition, structuralism (approach that looks at how the basic units of language relate to each other according to their common characteristics), 1st language acquisition studies, contrastive analysis (approach where languages were examined in terms of differences and similarities) and inter-language (which describes L2 learners’ language as a rule-governed, dynamic system) (Mitchell, Myles, 2004). \nThese theories have all influenced second-language teaching and pedagogy. There are many different methods of second-language teaching, many of which stem directly from a particular theory. Common methods are the grammar-translation method, the direct method, the audio-lingual method (clearly influenced by audio-lingual research and the behaviourist approach), the Silent Way, Suggestopedia, community language learning, the Total Physical Response method, and the communicative approach (highly influenced by Krashen’s theories) (Doggett, 1994). Some of these approaches are more popular than others, and are viewed to be more effective. Most language teachers do not use one singular style, but will use a mix in their teaching. This provides a more balanced approach to teaching and helps students of a variety of learning styles succeed.\n\nThe defining difference between a first language (L1) and a second language (L2) is the age the person learned the language. For example, linguist Eric Lenneberg used \"second language\" to mean a language consciously acquired or used by its speaker after puberty. In most cases, people never achieve the same level of fluency and comprehension in their second languages as in their first language. These views are closely associated with the critical period hypothesis.\n\nIn acquiring an L2, Hyltenstam (1992) found that around the age of six or seven seemed to be a cut-off point for bilinguals to achieve native-like proficiency. After that age, L2 learners could get \"near-native-like-ness\" but their language would, while consisting of few actual errors, have enough errors to set them apart from the L1 group. The inability of some subjects to achieve native-like proficiency must be seen in relation to the \"age of onset\" (AO). Later, Hyltenstam & Abrahamsson (2003) modified their age cut-offs to argue that after childhood, in general, it becomes more and more difficult to acquire native-like-ness, but that there is no cut-off point in particular.<br>\n\nAs we are learning more and more about the brain, there is a hypothesis that when a child is going through puberty, that is the time that accents \"start\". Before a child goes through puberty, the chemical processes in the brain are more geared towards language and social communication. Whereas after puberty, the ability for learning a language without an accent has been rerouted to function in another area of the brain—most likely in the frontal lobe area promoting cognitive functions, or in the neural system of hormone allocated for reproduction and sexual organ growth.\n\nAs far as the relationship between age and eventual attainment in SLA is concerned, Krashen, Long, and Scarcella, say that people who encounter foreign language in early age, begin natural exposure to second languages and obtain better proficiency than those who learn the second language as an adult. However, when it comes to the relationship between age and rate SLA, “Adults proceed through early stages of syntactic and morphological development faster than children (where time and exposure are held constant)” (Krashen, Long, Scarcella 573). Also, “older children acquire faster than younger children do (again, in early stages of morphological and syntactic development where time and exposure are held constant)” (573). In other words, adults and older children are fast learners when it comes to the initial stage of foreign language education.\n\nGauthier and Genesee (2011) have done a research which mainly focuses on the second language acquisition of internationally adopted children and results show that early experiences of one language of children can affect their ability to acquire a second language, and usually children learn their second language slower and weaker even during the critical period.<br>\n\nAs for the fluency, it is better to do foreign language education at an early age, but being exposed to a foreign language since an early age causes a “weak identification” (Billiet, Maddens and Beerten 241). Such issue leads to a \"double sense of national belonging,\" that makes one not sure of where he or she belongs to because according to Brian A. Jacob, multicultural education affects students' \"relations, attitudes, and behaviors\" (Jacob 364). And as children learn more and more foreign languages, children start to adapt, and get absorbed into the foreign culture that they “undertake to describe themselves in ways that engage with representations others have made” (Pratt 35). Due to such factors, learning foreign languages at an early age may incur one’s perspective of his or her native country.\nAcquiring a second language can be a lifelong learning process for many. Despite persistent efforts, most learners of a second language will never become fully \"native-like\" in it, although with practice considerable fluency can be achieved. However, children by around the age of 5 have more or less mastered their first language with the exception of vocabulary and a few grammatical structures, and the process is relatively very fast because language is a very complex skill. Moreover, if children start to learn a second language when they are 7 years old or younger, they will also be fully fluent with their second language in a faster speed comparing to the speed of learning by adults who start to learn a second language later in their life. <br>\n\nIn the first language, children do not respond to systematic correction. Furthermore, children who have limited input still acquire the first language, which is a significant difference between input and output. Children are exposed to a language environment of errors and lack of correction but they end up having the capacity to figure out the grammatical rules. Error correction does not seem to have a direct influence on learning a second language. Instruction may affect the rate of learning, but the stages remain the same. Adolescents and adults who know the rule are faster than those who do not. <br>\n\nIn the learning of a second language the correction of errors remains a controversial topic with many differing schools of thought. Throughout the last century much advancement has been made in research on the correction of students’ errors. In the 1950s and 60s the viewpoint of the day was that all errors must be corrected at all costs. Little thought went to students’ feelings or self-esteem in regards to this constant correction (Russell, 2009).\n\nIn the 1970s Dulay and Burt’s studies showed that learners acquire grammar forms and structures in a pre-determined, inalterable order, and that teaching or correcting styles would not change this (Russell, 2009).\n\nIn this same decade Terrell (1977) did studies that showed that there were more factors to be considered in the classroom than the cognitive processing of the students (Russell, 2009). He contested that the affective side of students and their self-esteem were equally important to the teaching process (Russell, 2009).\n\nA few years later in the 1980s, the strict grammar and corrective approach of the 1950s became obsolete. Researchers asserted that correction was often unnecessary and that instead of furthering students’ learning it was hindering them (Russell, 2009). The main concern at this time was relieving student stress and creating a warm environment for them. Stephen Krashen was a big proponent in this hands-off approach to error correction (Russell, 2009).\n\nThe 1990s brought back the familiar idea that explicit grammar instruction and error correction was indeed useful for the SLA process. At this time, more research started to be undertaken to determine exactly which kinds of corrections are the most useful for students. In 1998, Lyster concluded that “recasts” (when the teacher repeats a student’s incorrect utterance with the correct version) are not always the most useful because students do not notice the correction (Russell, 2009). His studies in 2002 showed that students learn better when teachers help students recognize and correct their own errors (Russell, 2009). Mackey, Gas and McDonough had similar findings in 2000 and attributed the success of this method to the student’s active participation in the corrective processes.\n\nAccording to Noam Chomsky, children will bridge the gap between input and output by their innate grammar because the input (utterances they hear) is so poor but all children end up having complete knowledge of grammar. Chomsky calls it the Poverty of Stimulus. And second language learners can do this by applying the rules they learn to the sentence-construction, for example. So learners in both their native and second language have knowledge that goes beyond what they have received, so that people can make correct utterances (phrases, sentences, questions, etc) that they have never learned or heard before.<br>\n\nBilingualism has been an advantage to today's world and being bilingual gives the opportunity to understand and communicate with people with different cultural backgrounds. However, a study done by Optiz and Degner in 2012 shows that sequential bilinguals (i.e. learn their L2 after L1) often relate themselves to the emotions more when they perceive these emotions by their first language/native language/L1, but feel less emotional when by their second language even though they know the meaning of words clearly. The emotional distinction between L1 and L2 indicates that the \"effective valence\" of words is processed less immediate in L2 because of the delayed vocabulary/lexical access to these two languages.<br>\n\nSuccess in language learning can be measured in two ways: likelihood and quality. First language learners \"will\" be successful in both measurements. It is inevitable that all people will learn a first language and with few exceptions, they will be fully successful. For second language learners, success is not guaranteed. For one, learners may become fossilized or \"stuck\" as it were with ungrammatical items. (Fossilization occurs when language errors become a permanent feature. See Canale & Swain (1980), Johnson (1992), Selinker (1972), and Selinker and Lamendella (1978).) The difference between learners may be significant. As noted elsewhere, L2 learners rarely achieve complete \"native-like\" control of the second language. <br>\nFor L2 pronounciation, there are two principles that haven been put forth by Levis (2005). The first is nativeness which means the speakers' ability to approximately reach the speaking pattern of the second language of speakers; and the second, understanding, refers to the speaker's ability to make themselves understood.\nBeing successful in learning a second language can seem like a daunting task. Research has been done to look into why some students are more successful than others. Stern (1975), Rubin (1975) and Reiss (1985) are just a few of the researchers who have dedicated time to this subject. They have worked to determine what qualities make a \"good language learner\" (Mollica, Neussel, 1997). Some of their common findings are that a good language learner uses positive learning strategies, is an active learner who is constantly searching for meaning. Also a good language learner demonstrates a willingness to practice and use the language in real communication. He also monitors himself and his learning, has a strong drive to communicate, and has a good ear and good listening skills (Mollica, Neussel, 1997).<br>\n\nÖzgür and Griffiths have designed an experiment in 2013 about the relationship between different motivations and second language acquisition. They have looked at four types of motivations—intrinsic (inner feelings of learner), extrinsic (reward from outside), integrative (attitude towards learning), and instrumental (practical needs). According to the test results, the intrinsic part has been the main motivation for these student who learn English as their second language. However, students report themselves being strongly instrumentally motivated. In conclusion, learning a second language and being successful depend on every individual.<br>\n\nIn pedagogy and sociolinguistics, a distinction is made between second language and foreign language, the latter is being learned for use in an area where that language is originally from another country and not spoken in the native country of the speakers. And in other words, foreign language is used from the perspective of countries; the second language is used from the perspective of individuals.\n\nFor example, arguably, English in countries such as India, Pakistan, Bangladesh, the Philippines, the Nordic countries and the Netherlands can be considered a second language for many of its speakers, because they learn it young and use it regularly; indeed in southern Asia it is the official language of the courts, government and business. The same can be said for French in Algeria, Morocco and Tunisia, although French is nominally not an official language in any of these Arabic-speaking countries. In practice, French is widely used in a variety of contexts in these countries, and public signs are normally printed in both Arabic and French. A similar phenomenon exists in post-Soviet states such as the Ukraine, Uzbekistan, Kyrgyzstan and Kazakhstan, where Russian can be considered a second language, and there are large Russophone communities there.\n\nHowever, in China (with the exception perhaps of Hong Kong), English must be considered a foreign language due to the lack of opportunities for use, such as historical links, media, conversation between people, and similar vocabulary. Likewise, French would be considered a foreign language in Romania and Moldova. This is despite Romanian and French being Romance languages (unlike Chinese and English, which come from two different language families: Sino-Tibetan and Indo-European). This is also despite Romania and Moldova being the only two countries in the world where Romanian is an official language at the national level, Romania's historical links to France, and both Romanian-speaking countries' membership in the Francophonie.\nPsychological studies have found that speaking two or more languages is good for people's cognitive process and the differences between brains of bilinguals and single language speakers usually provides some mental benefits, according to an article on The Telegraph in 2013. Including but not limited to these: <br>\nBecoming smarter<br>\nSpeaking a second language improves the functions of the brain by thinking and using the different language systems.<br>\nBuilding multitasking skills<br>\nAccording to a study from the Pennsylvania State University, \"juggling language can make better brains\". Because multilingual people are usually good at switching between different language systems, they can be good multitaskers as well. <br>\nImproving memory<br>\nThe vocabulary capacity for a high school graduate student is about 45000 words, according to Nagy and Anderson (1984), and being a bilingual will double this number because learning a language involves memorizing rules and vocabulary.<br>\nSee more in references.<br>\nGeorge H. J. Weber, a Swiss businessman and independent scholar, founder of the Andaman Association and creator of the encyclopedic andaman.org Web site, made a report in December 1997 about the number of secondary speakers of the world's leading languages. Weber used the Fischer Weltalmanach of 1986 as his only source for the L2-speakers data, in preparing the data in the following table. These numbers are here compared with those referred to by Ethnologue, a popular source in the linguistics field. See below Table 1.\n\nCollecting the number of second language speakers of every language is extremely difficult and even the best estimates contain the guess work. Data below updated June 2013 from Ethnologue.com See below Table 2&3.\n\n\n"}
{"id": "858507", "url": "https://en.wikipedia.org/wiki?curid=858507", "title": "Self-referential humor", "text": "Self-referential humor\n\nSelf-referential humor, also known as self-reflexive humor or meta humor, is a type of comedic expression that—either directed toward some other subject, or openly directed toward itself—intentionally alludes to the very person who is expressing the humor in a comedic fashion, or to some specific aspect of that same comedic expression. Self-referential humor expressed discreetly and surrealistically is a form of bathos. In general, self-referential humor often uses hypocrisy, oxymoron, or paradox to create a contradictory or otherwise absurd situation that is humorous to the audience. \n\nSelf-referential humor is sometimes combined with breaking the fourth wall to explicitly make the reference directly to the audience, or make self-reference to an element of the medium that the characters should not be aware of.\n\nOld Comedy of Classical Athens is held to be the first—in the extant sources—form of self-referential comedy. Aristophanes, whose plays form the only remaining fragments of Old Comedy, used fantastical plots, grotesque and inhuman masks and status reversals of characters to slander prominent politicians and court his audience's approval.\n\nRAS syndrome refers to the redundant use of one or more of the words that make up an acronym or initialism with the abbreviation itself, thus in effect repeating one or more words. However, \"RAS\" stands for Redundant Acronym Syndrome; therefore, the full phrase yields \"Redundant Acronym Syndrome syndrome\" and is self-referencing in a comical manner. It also reflects an excessive use of TLAs (Three Letter Acronyms).\n\nMeta has come to be used, particularly in art, to refer to something that is self-referential. Popularised by Douglas Hofstadter who wrote several books on himself and the subject of self-reference, meta-jokes are a popular form of humor.\n\n"}
{"id": "2797420", "url": "https://en.wikipedia.org/wiki?curid=2797420", "title": "Semantic bootstrapping", "text": "Semantic bootstrapping\n\nSemantic bootstrapping is a linguistic theory of child language acquisition which proposes that children can acquire the syntax of a language by first learning and recognizing semantic elements and building upon, or bootstrapping from, that knowledge. This theory proposes that children, when acquiring words, will recognize that words label conceptual categories, such as objects or actions. Children will then use these semantic categories as a cue to the syntactic categories, such as nouns and verbs. Having identified particular words as belonging to a syntactic category, they will then look for other correlated properties of those categories, which will allow them to identify how nouns and verbs are expressed in their language. Additionally, children will use perceived conceptual relations, such as Agent of an event, to identify grammatical relations, such as Subject of a sentence. This knowledge, in turn, allows the learner to look for other correlated properties of those grammatical relations.\n\nThis theory requires two critical assumptions to be true. First, it requires that children are able to perceive the meaning of words and sentences. It does not require that they do so by any particular method, but the child seeking to learn the language must somehow come to associate words with objects and actions in the world. Second, children must know that there is a strong correspondence between semantic categories and syntactic categories. The relationship between semantic and syntactic categories can then be used to iteratively create, test, and refine internal grammar rules until the child's understanding aligns with the language to which they are exposed, allowing for better categorization methods to be deduced as the child obtains more knowledge of the language.\n\nThe semantic bootstrapping theory was first proposed by Steven Pinker in 1982 as a possible explanation of how a child can formulate grammar rules when acquiring a first language. Pinker's theory was inspired by two other proposed solutions to the bootstrapping problem. In 1981, Grimshaw claimed that there are correspondences between syntactic and semantic categories and in 1982, Macnamara postulated that certain semantic elements could serve as an inductive basis for syntactic elements, like parts of speech. Pinker's theory takes these ideas one step further by claiming that children inherently categorize words based upon their semantic properties and have an innate ability to infer syntactic categories from these semantic categories.\n\nA child acquiring a first language possesses, at all stages, an expectation that words will fall into specific grammatical categories. The child does not possess, however, an innate knowledge of how syntactic categories are expressed in the language they are acquiring. When children observe that a word is used to reference a semantic category, they can use their knowledge of the relations between semantic and syntactic categories to infer that this word belongs to a particular syntactic category. As children associate more words with syntactic categories, they can begin tracking other properties that can help them identify these syntactic categories in the absence of semantic evidence. Furthermore, identifying conceptual relations can help them to identify grammatical relations in a similar way. By identifying the semantic categories of words and phrases, children will know the corresponding syntactic categories of these elements and ultimately bootstrap their way to possessing a full understanding of the language’s grammar and formal expression.\n\nRondal and Cession tested the viability of the semantic bootstrapping hypothesis by observing the speech of 18 monolingual English speaking mothers to their normally developing children age 1 to 2 years old. In this experiment, investigators tape-recorded two half-hour sessions of mother-child verbal interactions. Child-directed utterances were extracted and coded for the 16 dependent variables below. These included the semantic categories, grammatical function categories, and part of speech categories. The semantic bootstrapping hypothesis states that a child uses semantic categories to infer grammatical categories. For example, action words (Dependent variable) indicate a verb (Categories), and the names of things (Dependent variable) indicate a noun (Categories). The focus of the experiment was to find out whether the grammatical and semantic categories and relations were correlated in the speech children heard. If they were, then that would indicate the plausibility of the semantic bootstrapping hypothesis. \n\nThe major findings of the experiment show that in terms of grammatical function categories, agents of actions were associated to subjects of the sentence, patients and themes as objects, and goals, locations and instruments as oblique or indirect objects. Rondal and Cession suggested that the input evidence assists children to identify those grammatical function categories by using thematic relations (agent, patient, etc.). They found that semantic notions reliably correlate with specific syntactic elements in parental speech and this may support the child’s construction of grammatical categories. Hence, the results of this experiment point to the soundness of the semantic bootstrapping hypothesis.\n\nAdditional evidence for semantic bootstrapping is illustrated by Gropen et al. and Kim et al.\n\nIn the experiment done by Gropen et al., children and adults were tested to see whether they could predict a verb’s syntax by using the verb’s meaning. In the experiment, locative verbs were used. Locative verbs link the relationship between a moving object and a location. The moving object is known as the ‘Figure’ and the location is known as the ‘Ground’. For example, in the sentence “Peter poured coffee into the cup.” ‘Pour’ is the locative verb, ‘coffee’ is the ‘Figure’ while ‘cup’ is the ‘Ground’. Children and adults were taught novel verbs for actions that involved the transfer of objects to a container. Then they were tested on whether they were able to express the figure or the ground argument as the direct object of the verb. The major findings of Gropen et al.’s experiments illustrated that both children and adults showed no tendency to express the figure entity as the direct object when faced with a locative verb. Instead, when there is a change of state of the ground object, e.g. The glass (ground object) was filled with water (figure object), children and adults are more likely to select that ground object as the direct object. This shows that children are able to link locative verbs to their complements accurately based on their understanding of the meaning of the verb. The result shows that verbs' syntactic argument structures are predictable from their semantic representations.\n\nSimilarly, in the experiment done by Kim et al., children and adults were tested whether they could describe an event using a specific locative verb provided by the experimenters. The major finding was that English-speaking children made errors in the syntax with the ground verb ‘fill’, but they did not make errors with figure verbs like ‘pour’. Kim et al. suggested that the pattern of errors reflects constraints on the syntax-semantics mapping. No language uses manner of motion verbs like 'pour' in the ground syntax. Children's lack of errors with manner of motion verbs suggests that they are subject to the same constraint that shapes cross linguistic variability. Hence, this experiment illustrated that children respect constraints on how verb meanings relate to verb syntax.\n\nThe semantic bootstrapping hypothesis has been criticized by some linguists. An alternative hypothesis to semantic bootstrapping, syntactic bootstrapping, proposes that verbs are always learned based on their syntactic properties rather than their semantic properties. This is sometimes construed as being incompatible with semantic bootstrapping, which proposes that verb meanings can be identified from the extralinguistic context of use. Pinker does not see syntactic bootstrapping as an alternative or necessarily bootstrapping at all. Pinker makes the critical distinction that semantic bootstrapping seeks to answer how children can learn syntax and grammar while the syntactic bootstrapping hypothesis is only concerned with how children learn verb meanings. Pinker believes that syntactic bootstrapping is more accurately \"syntactic cueing of word meaning\" and that this use of syntactic knowledge to obtain new semantic knowledge is in no way contradictory to semantic bootstrapping, but is another technique a child may use in later stages of language acquisition.\n\nLila Gleitman argues that word learning is not as easy as the semantic bootstrapping hypothesis makes it seem. It is not always possible to just look at the world and learn a word from the situation. There are many events in which two verbs could be used to describe the situation. In the example of a chasing and fleeing event, both words could be used to describe the event at hand. For example, both of the following sentences could be used to describe the same event: \nIt is not reasonable to expect a child to be able to figure out which is the correct meaning just by witnessing the event. Additionally, in many situations there are many events happening all at once. For example, if a child were in a park and their parent said \"look the fox is chasing the cat\" how would the child know that they should be directing their attention to the fox and the cat and not the dogs or the other children. This is similar to the gavagai problem. Essentially it is very hard to assume that a child could use word meanings to learn something about syntax when the act of learning the word meanings in the first place is not so easy. Gleitman also points out the near impossibility of learning some other verbs using this hypothesis. Verbs in which there is no action associated with it like 'think', 'hope', 'guess' and 'wonder' are hypothesized to be particularly hard to learn. If children only learned words based on what they saw in the world they would not be able to learn the meanings of these words.\n\nSiegel argues that the semantic bootstrapping hypothesis can not account for how children acquire case marking in split ergative languages. In these languages the agent is not uniformly getting the same case in every sentence. As a result, the child would not have the evidence necessary in the semantics to learn the correct case markings, since the case is not being uniformly assigned.\n\nAmbridge et al. argues against the existence of a universal grammar and in turn against the plausibility of semantic bootstrapping. They argue that since word categories (like verbs) are not cross linguistically applied the same way, these categories must not be innate. If these categories are not innate then they can't be used for semantic bootstrapping, since the theory is reliant on these categories being innate. They also argue that because the patient of the sentence and the instrument of the sentence can occur in the same place this would complicate the child's ability to learn which role corresponds to each part of the scene. For example: \nIn these sentences \"the ball\" is the instrument and \"the dog\" is the patient. However, they can occur in either order in English. There are also languages in which they can only occur in the second order. As a result, the child does not have the information necessary in the semantics to learn these orders, and could reasonably learn both.\n\nFinally Ambridge et al. argue that because children have distributional learning, where they can see trends in sentences like determiners go with nouns, this is sufficient for learning syntax and correlations between syntax and semantics are not necessary to help learn the syntax of the language.\n\n"}
{"id": "33932515", "url": "https://en.wikipedia.org/wiki?curid=33932515", "title": "Social cue", "text": "Social cue\n\nA social cue can either be a verbal or non-verbal hint, which can be positive or negative. These cues guide conversation and other social interactions. A few examples of social cues include: \nSocial cues serve several purposes in social interactions that help to clarify people's meanings and intentions. Cues help provide clues as to whether or not one is being accepted or rejected by those around them. They also provide more information about a person, group or interaction that allow for a higher degree of intimacy and quality of contact. One of the most important impacts of cues on social interactions is the reduction of ambiguity.\n\nSocial cues also play a role in intuition.\n\nHowever, children use social cues somewhat differently from adults. More specifically, children use social cues in order to comprehend and learn about their surroundings. Research has found that children rely more on social cues than adults and that children focus more on gestural than other types of cues.\n\nFacial expressions are signals that we make by moving our facial muscles on our face. Facial expressions generally signify an emotional state, and each emotional state and/or state of mind has a specific facial expression, many of which are universally used around the world. Without seeing someone's facial expression, one would not be able to see if the other person is crying, happy, angry, etc. Furthermore, facial expressions enable us to further comprehend what is going on during situations that are very difficult and/or confusing.\n\nBody language and body posture are other social cues that we use to interpret how someone else is feeling. Other than facial expressions, body language and posture are the main non-verbal social cues that we use.\n\nGestures are specific motions that one makes with the hands in order to further communicate a message. Certain gestures such as pointing gestures, can help direct people's focus to what is important that is going on around them. Not only does using gestures help the speaker to better process what they are saying, but it also helps whoever is listening to that person to better comprehend what the speaker is saying.\n\nProximity represents the physical distance and/or closeness between people. Not only does this affect one's ability to see or touch the other person that they are communicating with, but is also affects one feeling of psychological closeness that one person has for the other. Furthermore, studies have found that people feel more connected to each other when they are in closer proximity to each other.\n\nRecent work done in the field studying social cues has found that perception of social cues is best defined as the combination of multiple cues and processing streams. Zaki suggests that there are two social cognitive processes involved in our perceptions of social cues, which are experience sharing and mentalizing. Experience sharing is a person's tendency to take on another person's facial expressions, posture and internal state. Mentalizing is a person's ability to rationalize another person's state, in relation to goals, intentions and behaviors. One's perception of social cues is often impacted by other cues in the environment. According to Zaki, using a combination of experience sharing, mentalizing and other processes is essential to understanding complex social cues.\n\nJudgments made by others are greatly influenced by facial appearance from multiple cues. There is a wealth of information that people gather simply from a person's face in the blink of an eye, such as gender, emotion, physical attractiveness, competence, threat level and trustworthiness. One of the most highly developed skills that humans have is facial perception. The face is one of the greatest representations of a person. A person's face allows others to gain information about that person, which is helpful when it comes to social interaction. The fusiform face area of the human brain plays a large role in face perception and recognition; however it does not provide useful information for processing emotion recognition, emotional tone, shared attention, impulsive activation of person knowledge and trait implications based on facial appearance.\n\nCognitive learning models illustrate how people connect cues with certain outcomes or responses. Learning can strengthen associations between predictive cues and outcomes and weaken the link between nondescriptive cues and outcomes. Two aspects of the EXIT model learning phenomena have been focused on by Collins et al. The first is blocking which happens when a new cue is introduced with a cue that already has meaning. The second is highlighting which happens when an individual pays close attention to a cue that will change the meaning of a cue that they already know. When a new cue is added along with a previous one it is said that individuals only focus on the new cue to gain a better understanding as to what is going on.\n\nAn important tool for communication in social interactions is the eyes. Even 12-month-old babies respond to the gaze of adults. This indicates that the eyes are an important way to communicate, even before spoken language is developed. People must detect and orient to people's eyes in order to utilize and follow gaze cues. Real-world examples show the degree to which we seek and follow gaze cues may change contingent on how close the standard is to a real social interaction. People may use gaze following because they want to avoid social interactions. Past experiments have found that eye contact was more likely when there was a speaker's face available, for longer periods of real-world time. Individuals use gaze following and seeking to provide information for gaze cuing when information is not provided in a verbal manner. However, people do not seek gaze cues when they are not provided or when spoken instructions contain all of the relevant information.\n\nPeople can gain valuable information from another person's social cues, such as their intentions and future actions. This can help in terms of our own decision making and help alert us to potential dangers or an advantageous event. The ability for people to shift through these social cues in response to others is crucial for effective social interaction and for fruitful communication within the surrounding environment. A stimulus that is perceptually salient can cause a person to automatically use a bottom-up approach or cognitive top-down intentions or goals. This causes one to move in a controlled and calculated manner. A peripheral cue is used to measure spatial cuing, which does not give away information about a targets location.\n\nThere are cues that express both social approval and social disapproval. These cues can be displayed by brief facial displays, warm or cold vocal tones, being sought out or snubbed at a get together. People who are best at being able to read these cues will be better at avoiding further rejection and regaining inclusion by engaging in behaviors that receive warmer responses. According to Picket and colleagues, the social monitoring system (SMS) is used to help individuals take in information from the environment around them and become more attuned to it and it helps them better navigate the social environment. SMS attunes people to cues in their environment that signal both potential belonging and potential rejection. There is also rejection sensitivity where individuals expect and readily perceive rejection from others such that ambiguous social cues come to be seen as signs of rejection. If people are able to correctly read both positive and negative social cues, it will better allow them to learn the contingencies of acceptance and rejection and be able to traverse different environments in a way that allows for greater social inclusion. Individuals high in belonging needs are generally more attuned to social cues involving acceptance or rejection. When these individuals experience high levels of loneliness they begin to experience higher levels of social monitoring and scanning the environment for social cues. A person's level in need for belonging is associated with their ability to sense and accurately decipher verbal and nonverbal social cues. People higher in need to belong show a greater empathic accuracy and more attention to vocal tone. They are also better at identifying emotional facial expressions.\n\nFrom a young age people are taught to use social cues of others to gain insight on about the world around them. There is also evidence that reliance on social cues is a naturally occurring tendency.\n\nResearch has found that from birth babies prefer infant directed speech over adult directed speech. As young as 6 months old babies prefer someone that has previously talked to them and who speaks their native language, over someone who speaks a foreign language. According to Guellai and Steri, at 9-weeks-old babies fixate more on an adult's eye region when they are talking to them, than when they are silent and looking at them. Guellai and Steri concluded that at birth babies are able to read two forms of social cues which are eye gaze and voice.\n\nChildren use social cues such as eye gaze and/or engaging facial expressions to understand adults' intentions while using different signs and symbols. Leekam, Soloman and Teoh hypothesized that children would pay more attention to a task if the adult had an engaging facial expression. They tested their hypothesis on 2 and 3 year olds using three signs: a pointer finger, a replica and an arrow. After their first experiment their hypothesis was supported. They found that young children understood the reasons behind the symbol or sign with the presence of an engaging face. However, when no face was visible performance significantly declined. Leekam, Soloman, and Teoh state that it is understandable that children understood the significance of the pointing sign due to their familiarity with it; children can comprehend the reference of pointing as early as 12 months. The researchers came to the conclusion that it is easier for children to identify an action carried out by a bare hand, as early as 7 months, as opposed to understanding the intent behind an action of a gloved hand. An important social cue that helps children when it comes to the function of a sign or symbol is that of an engaging face. During the difficult and unfamiliar tasks of the study, children looked for social cues more.\n\nAccording to studies on social referencing, infants use the emotional cues of others to guide their behavior. Vocal cues are seen as more effective because infants are used to vocal-only cues from their parents. This was shown in a visual cliff study conducted by Vaish and Striano where infants were left on the shallow end of a plexy glass cliff and mothers were on the other end. The mothers either used facial and vocal cues, facial cues only or vocal cues only to beckon their child forward. The study showed that infants crossed over faster in response to vocal-only cues than facial-only cues. It is believed that the reason infants do this is that they are accustomed to vocal-only cues from their parents.\n\nIn past studies, it has been found that infants use social cues to help them learn new words especially when there are multiple objects present. Most studies have used two or more objects are used simultaneously to see if infants could learn if they are paying attention to cues presented. At 14 months old infants followed an adult's gaze to an object indicating that they believe that the eyes are important for looking. Head turning and gaze are other gazes that infants view as referential cues. Around 18 months social cues become beneficial to infants, though they are not always useful. Young infants rely on attentional cues while older infants rely more on social cues to help them learn things. However, it was found that 12 month old infants could not use cues such as, eye gaze, touching, and handling, to learn labels. Research shows that 15-month-old infants are sensitive to gaze direction directed by adults and are able to correctly use these cues to help with referent novel words.\n\nEven as toddlers, we gain social cues from others and determine how we should behave based upon these cues we receive from adults. Smith and LaFreniere mention RAI (recursive awareness of intentionality), which is the understanding of how the cues one provides will influence the beliefs and actions of those receiving them. RAI is absent in children under the age of 5, but develops during middle childhood. They tested to see if children ages 4, 6, and 8 were able to read the intentions of their partner in a game through both nonverbal hints and facial expressions. They found that 8-year-olds were better able to read their partner's cues and based their decisions off those cues.\n\nIn the classroom there is a development of cues between the teacher and student. It seems that classrooms develop their own way of talking and communicating information. Once a set of verbal and nonverbal behaviors takes place in a classroom on a consistent basis, it becomes a norm/set of rules within the classroom. The following cues are nonverbal indications that give way to certain norms in the classroom:\nTeachers and students develop a way of understanding the way each other thinks, believes, acts and perceives things. A teacher can use the gaze of their eyes and the position of their body to indicate where the student's attention should be held. Sometimes if students are stuck in a previous discussion or cannot determine an appropriate response to the current topic, it could mean that they did not perceive the cues that the teacher was displaying correctly. Both students and teachers must read the cues to gather what is currently going on, how they are supposed to be doing something and the reason behind what they were doing.\n\nBenjamin Straube, Antonia Green, Andreas Jansen, Anjan Chatterjee, and Tilo Kircher found that social cues influence the neural processing of speech-gesture utterances. Past studies have focused on mentalizing as being a part of perception of social cues and it is believed that this process relies on the neural system, which consists of:\nWhen people focus on things in a social context, the medial prefrontal cortex and precuneus areas of the brain are activated, however when people focus on a non-social context there is no activation of these areas. Straube et al. hypothesized that the areas of the brain involved in mental processes were mainly responsible for social cue processing. It is believed that when iconic gestures are involved, the left temporal and occipital regions would be activated and when emblematic gestures were involved the temporal poles would be activated. When it came to abstract speech and gestures, the left frontal gyrus would be activated according to Straube et al. After conducting an experiment on how body position, speech and gestures affected activation in different areas of the brain Straube et al. came to the following conclusions: \n\nThe amygdala, fusiform gyrus, insula, and superior and middle temporal regions have been identified as areas in the brain that play a role in visual emotional cues. It was found that there was greater activation in the bilateral anterior superior temporal gyrus and bilateral fusiform gyrus when it came to emotional stimuli. The amygdala has been connected with the automatic evaluation of threat, facial valence information, and trustworthiness of faces.\n\nWhen it comes to visual cues, individuals follow the gaze of others to find out what they are looking at. It has been found that this response is evolutionarily adaptive due to the fact that it can alert others to happenings in the environment. Almost 50% of the time, peripheral cues have a hard time finding the location of a target. Studies have shown that directed gaze impacts attentional orienting in a seemingly automatic manner. Part of the brain that is involved when another person averts their gaze is also a part of attentional orienting. Past researchers have found that arrow cues are linked to the fronto-parietal areas, whereas arrow and gaze cues were linked to occipito-temporal areas. Therefore, gaze cues may indeed rely on automatic processes more than arrow cues. The importance of eye gaze has increased in importance throughout the evolutionary time period.\n\nHigher level visual regions, such as the fusiform gyrus, extrastriate cortex and superior temporal sulcus (STS) are the areas of the brain that studies have found that link to perceptual processing of social/biological stimuli. Data collected from behavioral studies have found that the right hemisphere is highly connected with the processing of left visual field advantage for face and gaze stimuli. Researchers believe the right STS is also involved in using gaze to understand the intentions of others. While looking at social and nonsocial cues, it has been found that a high level of activity has been found in the bilateral extrastriate cortices in regards to gaze cues versus peripheral cues. There was a study done on two people with split-brain, in order to study each hemisphere to see what their involvement is in gaze cuing. Results suggest that gaze cues show a strong effect with the facial recognition hemisphere of the brain, compared to nonsocial cues. The results of Greene and Zaidel's study suggest that in relation to visual fields, information is processed independently and that the right hemisphere shows greater orienting.\n\nPertaining to emotional expression the superior temporal cortex has been shown to be active during studies focusing on facial perception. However, when it comes to face identity the inferior temporal and fusiform cortex is active. During facial processing the amygdala and fusiform gyrus show a strong functional connection. Face identification can be impaired if there is damage to the orbitofrontal cortex (OFC). The amygdala is active during facial expressions and it improves long-term memory for long term emotional stimuli. It has also been found that there are face response neurons in the amygdala. The connection between the amygdala, OFC, and other medial temporal lobe structures suggest that they play an important role in working memory for social cues. Systems which are critical in perceptually identifying and processing emotion and identity need to cooperate in order to maintain maintenance of social cues.\n\nIn order to monitor changing facial expressions of individuals, the hippocampus and orbitofrontal cortex may be a crucial part in guiding critical real-world social behavior in social gatherings. The hippocampus may well be a part of using social cues to understand numerous appearances of the same person over short delay periods. The orbitofrontal cortex being important in the processing of social cues leads researchers to believe that it works with the hippocampus to create, maintain, and retrieve corresponding representations of the same individual seen with multiple facial expressions in working memory. After coming across the same person multiple times with different social cues, the right lateral orbitofrontal cortex and hippocampus are more strongly employed and display a stronger functional connection when disambiguating each encounter with that individual. During an fMRI scan the lateral orbitofrontal cortex, hippocampus, fusiform gyrus bilaterally showed activation after meeting the same person again and having previously seen two different social cues. This would suggest that both of these brain areas help retrieve correct information about a person's last encounter with the person. The ability to separate the different encounters with different people seen with different social cues leads researchers to believe that it permits for suitable social interactions. Ross, LoPresti and Schon offer that the orbitofrontal cortex and hippocampus are a part of both working memory and long-term memory, which permits flexibility in encoding separate representations of an individual in the varying social contexts in which we encounter them.\n\nOxytocin has been named \"the social hormone\". Research done on rats provide strong evidence that social contact enhances oxytocin levels in the brain which then sets the stage for social bonds. In recent years it has been found that inhaling oxytocin through the nasal passage increases trust toward strangers and increases a person's ability to perceive social cues. Activation of face-induced amygdala was found to be increased by oxytocin in women. There have been findings that oxytocin increases occurrence of attention shifts to the eye region of a face which suggests that it alters the readiness of the brain to socially meaningful stimuli. Dopamine neuron from the ventral tegmental area codes the salience of social as well as nonsocial stimuli. Bartz and his colleagues found that the effects of oxytocin is person-dependent, meaning that every individual will be affected differently, especially those who have trouble in social situations. Research done by Groppe and colleagues supports that motivational salience of social cues is enhanced by oxytocin. Oxytocin has been found to increase cues that are socially relevant.\n\nAccurately interpreting social cues is a vital part of normal social function. However, individuals with certain psychological disorders, including schizophrenia, autism, social anxiety disorder, and ADHD, tend to suffer from difficulties in interpreting and using these cues.\n\nAccording to the Diagnostic and Statistical Manual of Mental Disorders (DSM), schizophrenia is a psychological disorder, which has to include two out of the five symptoms listed below: \nSchizophrenic people find it hard to pick up on social cues. More specifically, people with schizophrenia are found to have deficits in emotional facial recognition, social knowledge, empathy, and non verbal cues, and emotional processing. Most of these aspects are part of a category called social cognition. However, most tasks that are related to social cognition involve emotional processing, empathy, and social norms knowledge. When dealing with facial expression recognition, recent research has found that people with this disorder are unable to recognize facial expressions that exhibit negative emotions, including fear, sadness, anger, and disgust. As a result, Schizophrenic people have trouble comprehending situations that involve different types of empathy, especially situations that require empathy for pain.\n\nIn addition, research has found that those with schizophrenia are more likely to make additional false positives when aspects of the task are more abstract. A false positive is when a participant mistakenly believes that they observed a specific social cue in the vignette shown to them. Therefore, the social cue that they believe they saw happening in the video was nonexistent. In order to see whether someone is able to correctly identify both types of cues, researchers use the Social Cue Recognition Test, also known as SCRT. When the task is defined as being too abstract, this means that it contains abstract cues, which are cues that can be inferred from a social setting. This would consist of actions and situations that contain; affect, goals, and rules. Thus, people with Schizophrenia have trouble making inferences about social situations and settings that deal with abstract aspects. On the other hand, schizophrenic people are better at identifying features that use concrete cues, which are cues that can be observed directly. The reason for this is because concrete clues are more apparent while abstract cues are more ambiguous.\n\nAutistic people or other individuals with social and behavioral disorders fail to read cues correctly. Misreading social cues can lead to a person acting out, which can then result in negative interactions and social disapproval. Therefore, social cues are believed to be an important aspect of inclusion and comfort in personal, interpersonal and social environments.\n\nThe DSM states that Autism is a psychological disorder that has multiple symptoms that fall within three separate symptomatic categories.\n\nThe main social cue impairments of those on the Autistic Spectrum include; interpreting facial expressions, understanding body language, and being able to decipher gaze direction. All three of these cues are classified under the nonverbal communication category. However, prior research has found that Autistic children and Autistic adults have no difficulty in identifying human bodily movements and or body language that is used in everyday and/or normal activities. The aspect that Autistic people have trouble with is more so the ability that is needed to verbally describe the emotions that are connected with these types of bodily movements.\n\nChildren who are not Autistic learn to relate the body movements that they see with the emotions and mental states of others when they have face to face interactions with other children. Having face to face interactions with other people, helps children increase their knowledge of what these body movements represent. After seeing these representations being used multiple times, children are then able to make inferences about the representations and the people making them. This means that the children will be able to make an assumption about a person that they interact with in the future since they already understand what the body movements and or body language represents.\n\nSocial anxiety disorder, also known as social phobia, is a disorder that the DSM identifies as someone who experiences some of the following: \nPeople with Social Anxiety Disorder are found to be overly concerned with the disapproval and approval of others around them. Due to this obsession with what others think of them, people with this disorder tend to interact with either a few or no people at all. As a result, they do not get an appropriate amount of social interaction, which contributes to their deficit in interpreting emotions and facial expressions. More specifically, people with Social Anxiety disorder tend to have a negative bias towards both facial expressions and emotions, which leads them to interpret such cues that are normal and or happy as being negative. Previous research has found that because people with this disorder tend to have a negative bias towards social cues, they take longer to process and comprehend social cues that represent happiness.\n\nADHD stands for attention deficit/hyperactivity disorder, which is a psychological disorder that most commonly exists in children and adults that also have learning disabilities.\n\nIn the DSM, ADHD is classified under two symptom categories, Inattention and Hyperactivity/Impulsivity.\n\nUnder the Inattention grouping, the child must exhibit six or more of the following symptoms for at least six months:\nUnder the Hyperactivity/Impulsivity category, the child must once again exhibit six or more of the following symptoms for at least six months: \nThe DSM also states that these symptoms must interfere or cause impairment in the patient's school, home, or work setting.\n\nIt has been found that children who have both ADHD and a learning disability also have trouble comprehending social cues, have poor social skills, have difficulty creating and/or maintaining friendships, and have trouble reacting to other people's thoughts and feelings. However, part of the reason that children with ADHD have deficits in the social realm is their lack of focus and self control, which obstructs their ability to properly interpret social cues.\n\nMore specifically, people with ADHD tend to focus on too many cues, which disables them from interpreting which cues are more important. Because of this, certain social situations are especially hard for people with ADHD to interpret. One situation that would meet this criteria would be when someone is being deceptive towards them. The reason a deceptive situation would be harder for some with this disorder is because the social cues one gives off when being deceptive are very subtle. Therefore, since people with ADHD already have trouble interpreting social cues, subtle social cues would be even more difficult for someone with this disorder to comprehend and or interpret.\n\nHowever, many studies have found that people with ADHD that take stimulants and/or prescribed medication for ADHD, are better able to interpret which social cues are of the most importance. As a result, they are better at interacting and communicating with others, which then enables them to make and maintain better friendships or relationships.\n\nCommunication on the Internet is very different from communication with others face to face. McKenna and Bargh identified four main differences between face to face communication and communication that takes place on the internet.\n\nThese four differences include: \nAnonymity is a major feature that internet communication can provide. Not only are you not able to see the person's face that you are emailing and or communicating with, but they are also not able to see your face. This can be a very positive feature for those that are socially anxious and or have a social anxiety disorder because it eliminates the idea of being publicly humiliated and or embarrassed, which is something that most people who are socially anxious are very worried about. As a result, people with social anxiety are more inclined to open up, which allows them to get closer and form more relationships with others.\n\nOn the other hand, being anonymous can cause deindividuation, which is when one is no longer an individual, but rather just seen as being part of a group. In other words, one can feel like they are just one person among a thousand others and because of this, they are not as noticeable. This has found to cause some people to behave more impulsively and have less self monitoring. This type of behavior and thinking can cause one to be more blunt and aggressive towards the people that they are communicating with. However, the blunt and aggressive responses can also be due to the fact that the person is not communicating with the other person face to face. However, others have suggested that whether or not the reduced availability of social cues results in negative behavior may depend upon the situation and the individuals goals.\n\nUnlike with face-to-face communication, physical distance and/or proximity are not barriers to communicating on the Internet. The Internet allows people from all over the world to come together and interact with each other. No matter what city or country one lives in, they are able to communicate and or interact with anyone around the world who is on the Internet. As a result, people are able to make friends and communicate with others that they normally would not have been able to interact with due to physical distance. Furthermore, people are able to communicate and stay in contact with their family and friends that may live to far away to visit on a regular basis.\n\nSimilar to Physical distance, time is a feature that does not matter when one is communicating on the internet. For instance, people are able to communicate with others if the person they are communicating with is not online at that moment. One way to do this is through the process of email. By communicating through email, one is able to send another person a message at any time. This also allows one to think about what they would like to say and edit their response before sending it. Furthermore, when one gets the said email, they do not have to respond right away. This means that there is also no time constraint on when one must respond.\n\nAlong with proximity and time, physical appearance is another factor about the internet that is of no importance. Like previously mentioned in the anonymity paragraph, people are unable to see the physical characteristics of the person or persons that they are interacting with on the internet. This allows people to talk to others that they would normally not talk to if they had actually seen the person face to face. As a result, people are able to connect on a more meaningful level and are able to create closer relationships that are not just about physical attraction. This is also considered to be a very positive aspect about the internet.\n\nA positive feature of the internet is that it has millions of different chat rooms and blogs that allow people to communicate with others who share their same interests and values. Not only does this enable people to find others who are similar to them, but it also allows people to find emotional support. However, there also a few negative consequences of the ability to connect with like-minded others online. One negative feature is that it allows people to come together and talk about subjects such as murder, and hate groups.\n\nThe absence of certain social cues online can lead to more misunderstandings than if one were communicating face to face. The reason that this can happen more easily is because when reading an email, people are not able to hear the other person's voice or see the person's facial expression. Both the voice and facial expressions are very important social cues that allow others to understand how someone else is feeling and without them, one can misinterpret what someone is saying and or wrote in an email.\n\n"}
{"id": "25508556", "url": "https://en.wikipedia.org/wiki?curid=25508556", "title": "Speech and language impairment", "text": "Speech and language impairment\n\nSpeech and language impairment are basic categories that might be drawn in issues of communication involve hearing, speech, language, and fluency.\n\nA speech impairment is characterized by difficulty in articulation of words. Examples include stuttering or problems producing particular sounds. Articulation refers to the sounds, syllables, and phonology produced by the individual. Voice, however, may refer to the characteristics of the sounds produced—specifically, the pitch, quality, and intensity of the sound. Often, fluency will also be considered a category under speech, encompassing the characteristics of rhythm, rate, and emphasis of the sound produced \n\nA language impairment is a specific impairment in understanding and sharing thoughts and ideas, i.e. a disorder that involves the processing of linguistic information. Problems that may be experienced can involve the form of language, including grammar, morphology, syntax; and the functional aspects of language, including semantics and pragmatics\n\nAn individual can have one or both types of impairment. These impairments/disorders are identified by a speech and language pathologist.\n\nThe following are brief definitions of several of the more prominent speech disorders:\n\nApraxia of speech is the acquired form of motor speech disorder caused by brain injury, stroke or dementia.\n\nDevelopmental verbal dyspraxia refers specifically to a motor speech disorder. This is a neurological disorder. Individuals suffering from developmental verbal apraxia encounter difficulty saying sounds, syllables, and words. The difficulties are not due to weakness of muscles, but rather on coordination between the brain and the specific parts of the body. Apraxia of speech is the acquired form of this disorder caused by brain injury, stroke or dementia.\n\nInterventions are more effective when they occur individually at first, and between three and five times per week. With improvements, children with apraxia may be transitioned into group therapy settings. Therapeutic exercises must focus on planning, sequencing, and coordinating the muscle movements involved in speech production. Children with developmental verbal dyspraxia must practice the strategies and techniques that they learn in order to improve. In addition to practice, feedback can be helpful to improve apraxia of speech. Tactile feedback (touch), visual feedback (watching self in mirror), and verbal feedback are all important additions. Biofeedback has also been cited as a possible therapy. Functional training involves placing the individual in more speech situations, while providing him/her with a speech model, such as the SLP. Because the cause is neurological, however, some patients do not progress.\nIn these cases, AAC may be more appropriate.\n\nDysarthria is a motor speech disorder that results from a neurological injury. Some stem from central damage, while other stem from peripheral nerve damage. Difficulties may be encountered in respiratory problems, vocal fold function, or velopharyngeal closure, for example.\n\nOrofacial myofunctional disorders refers to problems encountered when the tongue thrusts forward inappropriately during speech. While this is typical in infants, most children outgrow this. Children that continue to exaggerate the tongue movement may incorrectly produce speech sounds, such as /s/, /z/, /ʃ/, /tʃ/, and /dʒ/. For example, the word, \"some,\" might be pronounced as \"thumb\".\n\nThe treatment of OMD will be based upon the professional's evaluation. Each child will present a unique oral posture that must be corrected. Thus, the individual interventions will vary. Some examples include:\n\nSpeech sound disorders may be of two varieties: articulation (the production of sounds) or phonological processes (sound patterns). An articulation disorder may take the form of substitution, omission, addition, or distortion of normal speech sounds. Phonological process disorders may involve more systematic difficulties with the production of particular types of sounds, such as those made in the back of the mouth, like \"k\" and \"g\".\n\nNaturally, abnormalities in speech mechanisms would need to be ruled out by a medical professional. Therapies for articulation problems must be individualized to fit the individual case. The placement approach—instructing the individual on the location in which the tongue should be and how to blow air correctly—could be helpful in difficulties with certain speech sounds. Another individual might benefit more from developing auditory discrimination skills, since he/she has not learned to identify error sounds in his/her speech. Generalization of these learned speech techniques will need to be generalized to everyday situations. Phonological process treatment, on the other hand, can involve making syntactical errors, such as omissions in words. In cases such as these, explicit teaching of the linguistic rules may be sufficient.\n\nSome cases of speech sound disorders, for example, may involve difficulties articulating speech sounds. Educating a child on the appropriate ways to produce a speech sound and encouraging the child to practice this articulation over time may produce natural speech, Speech sound disorder. Likewise, stuttering does not have a single, known cause, but has been shown to be effectively reduced or eliminated by fluency shaping (based on behavioral principles) and stuttering modification techniques.\n\nStuttering is a disruption in the fluency of an individual's speech, which begins in childhood and may persist over a lifetime. Stuttering is a form of disfluency; disfluency becomes a problem insofar as it impedes successful communication between two parties. Disfluencies may be due to unwanted repetitions of sounds, or extension of speech sounds, syllables, or words. Disfluencies also incorporate unintentional pauses in speech, in which the individual is unable to produce speech sounds.\n\nWhile the effectiveness is debated, most treatment programs for stuttering are behavioral. In such cases, the individual learns skills that improve oral communication abilities, such as controlling and monitoring the rate of speech. SLPs may also help these individuals to speak more slowly and to manage the physical tension involved in the communication process. Fluency may be developed by selecting a slow rate of speech, and making use of short phrases and sentences. With success, the speed may be increased until a natural rate of smooth speech is achieved. Additionally, punishment for incorrect speech production should be eliminated, and a permissive speaking environment encouraged. Electronic fluency devices, which alter the auditory input and provide modified auditory feedback to the individual, have shown mixed results in research reviews.\n\nBecause stuttering is such a common phenomenon, and because it is not entirely understood, various opposing schools of thought emerge to describe its etiology. The Breakdown theories maintain that stuttering is the result of a weakening or breakdown in physical systems that are necessary for smooth speech production. Cerebral dominance theories (in the stutterer, no cerebral hemisphere takes the neurological lead) and theories of perseveration (neurological \"skipping record\" of sorts) are both Breakdown theories. Auditory Monitoring theories suggest that stutters hear themselves differently from how other people hear them. Since speakers adjust their communication based upon the auditory feedback they hear (their own speech), this creates conflict between the input and the output process. Psychoneurotic theories posit repressed needs as the source of stuttering. Lastly, Learning theories are straightforward—children learn to stutter. It should be clear that each etiological position would suggest a different intervention, leading to controversy with the field.\n\nVoice disorders range from aphonia (loss of phonation) to dysphonia, which may be phonatory and/or resonance disorders. Phonatory characteristics could include breathiness, hoarseness, harshness, intermittency, pitch, etc. Resonance characteristics refer to overuse or underuse of the resonance chambers resulting in hypernasality or hyponasality. Several examples of voice problems are vocal cord nodules or polyps, vocal cord paralysis, paradoxical vocal fold movement, and spasmodic dysphonia. Vocal cord nodules and polyps are different phenomena, but both may be caused by vocal abuse, and both may take the form of growths, bumps, or swelling on the vocal cords. Vocal fold paralysis is the inability to move one or both of the vocal cords, which results in difficulties with voice and perhaps swallowing. Paradoxical vocal fold movement occurs when the vocal cords close when they should actually be open. Spasmodic dysphonia is caused by strained vocal cord movement, which results in awkward voice problems, such as jerkiness or quavering.\n\nIf nodules or polyps are present, and are large, surgery may be the appropriate choice for removal. Surgery is not recommended for children, however. Other medical treatment may suffice for slighter problems, such as those induced by gastroesophageal reflux disease, allergies, or thyroid problems. Outside of medical and surgical interventions, professional behavioral interventions can be useful in teaching good vocal habits and minimizing abuse of vocal cords. This voice therapy may instruct in attention to pitch, loudness, and breathing exercises. Additionally, the individual may be instructed on the optimal position to produce the maximum vocal quality. Bilateral paralysis is another disorder that may require medical or surgical interventions to return vocal cords to normalcy; unilateral paralysis may be treated medically or behaviorally.\n\nParadoxical vocal fold movement (PVFM) is also treated medically and behaviorally. Behavioral interventions will focus on voice exercises, relaxation strategies, and techniques that can be used to support breath. More generally, however, PVFM interventions focus on helping an individual to understand what triggers the episode, and how to deal with it when it does occur.\n\nWhile there is no cure for spasmodic dysphonia, medical and psychological interventions can alleviate some of the symptoms. Medical interventions involve repeated injections of Botox into one or both of the vocal cords. This weakens the laryngeal muscles, and results in a smoother voice.\n\nA language disorder is an impairment in the ability to understand and/or use words in context, both verbally and nonverbally. Some characteristics of language disorders include improper use of words and their meanings, inability to express ideas, inappropriate grammatical patterns, reduced vocabulary and inability to follow directions. One or a combination of these characteristics may occur in children who are affected by language learning disabilities or developmental language delay. Children may hear or see a word but not be able to understand its meaning. They may have trouble getting others to understand what they are trying to communicate.\n\nInterventions for specific language impairment will be based upon the individual difficulties in which the impairment manifests. For example, if the child is incapable of separating individual morphemes, or units of sound, in speech, then the interventions may take the form of rhyming, or of tapping on each syllable. If comprehension is the trouble, the intervention may focus on developing metacognitive strategies to evaluate his/her knowledge while reading, and after reading is complete. It is important that whatever intervention is employed, it must be generalized to the general education classroom.\n\nSelective mutism is a disorder that manifests as a child that does not speak in at least one social setting, despite being able to speak in other situations. Selective mutism is normally discovered when the child first starts school.\n\nBehavioral treatment plans can be effective in bringing about the desired communication across settings. Stimulus fading involves a gradual desensitization, in which the individual is placed in a comfortable situation and the environment is gradually modified to increase the stress levels without creating a large change in stress level. Shaping relies on behavioral modification techniques, in which successive attempts to produce speech is reinforced. Self-modeling techniques may also be helpful; for example, self-modeling video tapes, in which the child watches a video of him/herself performing the desired action, can be useful.\n\nIf additional confounding speech problems exist, a SLP may work with the student to identify what factors are complicating speech production and what factors might be increasing the mute behaviors. Additionally, he/she might work with the individual to become more comfortable with social situations, and with the qualities of their own voice. If voice training is required, they might offer this as well.\n\nAphasia refers to a family of language disorders that usually stem from injury, lesion, or atrophy to the left side of the brain that result in reception, perception, and recall of language; in addition, language formation and expressive capacities may be inhibited.\n\nLanguage-based learning disabilities, which refer to difficulties with reading, spelling, and/or writing that are evidenced in a significant lag behind the individual's same-age peers. Most children with these disabilities are at least of average intelligence, ruling out intellectual impairments as the causal factor.\n\nThe DSM-5 and the ICD-10 are both used to make specific diagnostic decisions.\nSpeech and language disorders commonly include communication issues, but also extend into various areas such as oral-motor function—sucking, swallowing, drinking, or eating. In some cases, a child's communication is delayed considerably behind his/her same-aged peers. The effects of these disorders can range from basic difficulties in the production of certain letter sounds to more comprehensive inabilities to generate (expressive) or understand (receptive) language. In most cases, the causal factors that create these speech and language difficulties are unknown. There are a wide variety of biological and environmental causal factors that can create them, ranging from drug abuse to neurological issues. For more information on causal hypotheses, refer to the section on models.\n\nDevelopmental disorders tend to have a genetic origin, such as mutations of FOXP2, which has been linked to developmental verbal dyspraxia and specific language impairment. Some of these impairments are caused by genetics. Case histories often reveal a positive family history of communication disorders. Between 28% and 60% of children with a speech and language deficit have a sibling and/or parent who is also affected. Down syndrome is another example of a genetic causal factor that may result in speech and/or language impairments. Stuttering is a disorder that is hypothesized to have a strong genetic component as well.\n\nSome speech and language impairments have environmental causes. A specific language impairment, for example, may be caused by insufficient language stimulation in the environment. If a child does not have access to an adequate role model, or is not spoken to with much frequency, the child may not develop strong language skills. Furthermore, if a child has little stimulating experiences, or is not encouraged to develop speech, that child may have little incentive to speak at all and may not develop speech and language skills at an average pace.\n\nDevelopmental disabilities such as autism and neurological disorders such as cerebral palsy may also result in impaired communicative abilities. Similarly, malformation or malfunctioning of the respiratory system or speech mechanisms may result in speech impairments. For example, a cleft palate will allow too much air to pass through the nasal cavity and a cleft lip will not allow the individual to correctly form sounds that require the upper lip. The development of vocal fold nodules represents another issue of biological causation. In some cases of biological origin, medical interventions such as surgery or medication may be required. Other cases may require speech therapy or behavioral training.\n\nAcquired disorders result from brain injury, stroke or atrophy, many of these issues are included under the Aphasia umbrella.\nBrain damage, for example, may result in various forms of aphasia if critical areas of the brain such as Broca's or Wernicke's area are damaged by lesions or atrophy as part of a dementia.\n\nWhat follows are a list of frequently used measures of speech and language skills, and the age-ranges for which they are appropriate.\n\nUnder the Individuals with Disabilities Education Act (IDEA) 2004, the federal government has defined a speech or language impairment as \"a communication disorder such as stuttering, impaired articulation, a language impairment, or a voice impairment, which adversely affects a child's learning\". In order to qualify in the educational system as having a speech or language impairment, the child's speech must be either unintelligible much of the time or he/she must have been professionally diagnosed as having either a speech impairment or language delay which requires intervention. Additionally, IDEA 2004 contains an exclusionary clause that stipulates that a speech or language impairment may not be either cultural, ethnic, bilingual, or dialectical differences in language, temporary disorders (such as those induced by dental problems), or delayed abilities in producing the most difficult linguistic sounds in a child's age range.\n\nSpeech-language pathologists (SLPs) offer many services to children with speech or language disabilities.\n\nSpeech-language pathologists (SLPs) may provide individual therapy for the child to assist with speech production problems such as stuttering. They may consult with the child's teacher about ways in which the child might be accommodated in the classroom, or modifications that might be made in instruction or environment. The SLP can also make crucial connections with the family, and help them to establish goals and techniques to be used in the home. Other service providers, such as counselors or vocational instructors may also be included in the development of goals as the child transitions into adulthood.\n\nThe individual services that the child receives will depend upon the needs of that child. Simpler problems of speech, such as hoarseness or vocal fatigue (voicing problems) may be solved with basic instruction on how to modulate one's voice. Articulation problems could be remediated by simple practice in sound pronunciation. Fluency problems may be remediated with coaching and practice under the guidance of trained professionals, and may disappear with age. However, more complicated problems, such as those accompanying autism or strokes, may require many years of one-on-one therapy with a variety of service providers. In most cases, it is imperative that the families be included in the treatment plans since they can help to implement the treatment plans. The educators are also a critical link in the implementation of the child's treatment plan.\n\nFor children with language disorders, professionals often relate the treatment plans to classroom content, such as classroom textbooks or presentation assignments. The professional teaches various strategies to the child, and the child works to apply them effectively in the classroom. For success in the educational environment, it is imperative that the SLP or other speech-language professional have a strong, positive rapport with the teacher(s).\n\nSpeech-language pathologists create plans that cater to the individual needs of the patient. If speech is not practical for a patient, the SLP will work with the patient to decide upon an augmentative and alternative communication (AAC) method or device to facilitate communication. They may work with other patients to help them make sounds, improve voices, or teach general communication strategies. They also work with individuals who have difficulties swallowing. In addition to offering these types of communication training services, SLPs also keep records of evaluation, progress, and eventual discharge of patients, and work with families to overcome and cope with communication impairments (Bureau of Labor Statistics, 2009).\n\nIn many cases, SLPs provide direct clinical services to individuals with communication or swallowing disorders. SLPs work with physicians, psychologists, and social workers to provide services in the medical domain, and collaborate with educational professionals to offer additional services for students to facilitate the educational process. Thus, speech-language services may be found in schools, hospitals, outpatient clinics, and nursing homes, among other settings.\n\nThe setting in which therapy is provided to the individual depends upon the age, type, and severity of the individual's impairment. An infant/toddler may engage in an early intervention program, in which services are delivered in a naturalistic environment in which the child is most comfortable—probably his/her home. If the child is school-aged, he/she may receive speech-language services at an outpatient clinic, or even at his/her home school as part of a weekly program. The type of setting in which therapy is offered depends largely upon characteristics of the individual and his/her disability.\n\nAs with any professional practice that is informed by ongoing research, controversies exist in the fields that deal with speech and language disorders. One such current debate relates to the efficacy of oral motor exercises and the expectations surrounding them. According to Lof, non-speech oral motor exercises (NS-OME) includes \"any technique that does not require the child to produce a speech sound but is used to influence the development of speaking abilities\". These sorts of exercises would include blowing, tongue push-ups, pucker-smile, tongue wags, big smile, tongue-to-nose-to-chin, cheek puffing, blowing kisses, and tongue curling, among others. Lof continues, indicating that 85% of SLPs are currently using NS-OME. Additionally, these exercises are used for dysarthria, apraxia, late talkers, structural anomalies, phonological impairments, hearing impairments, and other disorders. Practitioners assume that these exercises will strengthen articulatory structures and generalize to speech acts. Lof reviews 10 studies, and concludes that only one of the studies shows benefits to these exercises (it also suffered serious methodological flaws). Lof ultimately concludes that the exercises employ the same structures, but are used for different functions. The NS-OME position is not without its supporters, however, and the proponents are numerous.\n\nIntervention services will be guided by the strengths and needs determined by the speech and language evaluation. The areas of need may be addressed individually until each one is functional; alternatively, multiple needs may be addressed simultaneously through the intervention techniques. If possible, all interventions will be geared towards the goal of developing typical communicative interaction. To this end, interventions typically follow either a preventive, remedial, or compensatory model. The preventive service model is common as an early intervention technique, especially for children whose other disorders place them at a higher risk for developing later communication problems. This model works to lessen the probability or severity of the issues that could later emerge. The remedial model is used when an individual already has a speech or language impairment that he/she wishes to have corrected. Compensatory models would be used if a professional determines that it is best for the child to bypass the communication limitation; often, this relies on AAC.\n\nLanguage intervention activities are used in some therapy sessions. In these exercises, an SLP or other trained professional will interact with a child by working with the child through play and other forms of interaction to talk to the child and model language use. The professional will make use of various stimuli, such as books, objects, or simple pictures to stimulate the emerging language. In these activities, the professional will model correct pronunciation, and will encourage the child to practice these skills. Articulation therapy may be used during play therapy as well, but involves modeling specific aspects of language—the production of sound. The specific sounds will be modeled for the child by the professional (often the SLP), and the specific processes involved in creating those sounds will be taught as well. For example, the professional might instruct the child in the placement of the tongue or lips in order to produce certain consonant sounds.\n\nTechnology is another avenue of intervention, and can help children whose physical conditions make communication difficult. The use of electronic communication systems allow nonspeaking people and people with severe physical disabilities to engage in the give and take of shared thought.\n\nWhile some speech problems, such as certain voice problems, require medical interventions, many speech problems can be alleviated through effective behavioral interventions and practice. In these cases, instruction in speech techniques or speaking strategies, coupled with regular practice, can help the individual to overcome his/her speaking difficulties. In other, more severe cases, the individual with speech problems may compensate with AAC devices.\n\nSpeech impairments can seriously limit the manner in which an individual interacts with others in work, school, social, and even home environments. Inability to correctly form speech sounds might create stress, embarrassment, and frustration in both the speaker and the listener. Over time, this could create aggressive responses on the part of the listener for being misunderstood, or out of embarrassment. Alternatively, it could generate an avoidance of social situations that create these stressful situations. Language impairments create similar difficulties in communicating with others, but may also include difficulties in understanding what others are trying to say (receptive language). Because of the pervasive nature of language impairments, communicating, reading, writing, and academic success may all be compromised in these students. Similar to individuals with speech impairments, individuals with language impairments may encounter long-term difficulties associated with work, school, social, and home environments.\n\nAugmentative and alternative communication (AAC) includes all forms of communication other than oral communication that an individual might employ to make known his/her thoughts. AAC work to compensate for impairments that an individual might have with expressive language abilities. Each system works to maintain a natural and functional level of communication. There is no one best type of AAC for all individuals; rather, the best type of AAC will be determined by the strengths and weaknesses of a specific individual. While there are a large number of types of AAC, there are fundamentally two categories: aided and unaided.\n\nUnaided systems of communication are those that require both communication parties to be physically present in the same location. Examples of unaided systems include gestures, body language, sign language, and communication boards. Communication boards are devices upon which letters, words, or pictorial symbols might be displayed; the individual may interface with the communication board to express him/herself to the other individual.\n\nAided systems of communication do not require both individuals to be physically present in the same location, though they might be. Aided systems are often electronic devices, and they may or may not provide some form of voice output. If a device does create a voice output, it is referred to as a speech generating device. While the message may take the form of speech output, it may also be printed as a visual display of speech. Many of these devices can be connected to a computer, and in some cases, they may even be adapted to produce a variety of different languages.\n\nStudents identified with a speech and language disability often qualify for an Individualized Education Plan as well as particular services. These include one-on-one services with a speech and language pathologist. Examples used in a session include reading vocabulary words, identifying particular vowel sounds and then changing the context, noting the difference. School districts in the United States often have speech and language pathologists within a special education staff to work with students. Additionally, school districts can place students with speech and language disabilities in a resource room for individualized instruction. A combination of early intervention and individualized support has shown promise increasing long-term academic achievement with students with this disability.\n\nStudents might work individually with a specialist, or with a specialist in a group setting. In some cases, the services provided to these individuals may even be provided in the regular education classroom. Regardless of where these services are provided, most of these students spend small amounts of time in therapy and the large majority of their time in the regular education classroom with their typically developing peers.\n\nTherapy often occurs in small groups of three or four students with similar needs. Meeting either in the office of the speech-language pathologist or in the classroom, sessions may take from 30 minutes to one hour. They may occur several times per week. After introductory conversations, the session is focused on a particular therapeutic activity, such as coordination and strengthening exercises of speech muscles or improving fluency through breathing techniques. These activities may take the form of games, songs, skits, and other activities that deliver the needed therapy. Aids, such as mirrors, tape recorders, and tongue depressors may be utilized to help the children to become aware of their speech sounds and to work toward more natural speech production.\n\nIn 2006, the U.S. Department of Education indicated that more than 1.4 million students were served in the public schools' special education programs under the speech or language impairment category of IDEA 2004. This estimate does not include children who have speech/language problems secondary to other conditions such as deafness; this means that if all cases of speech or language impairments were included in the estimates, this category of impairment would be the largest. Another source has estimated that communication disorders—a larger category, which also includes hearing disorders—affect one of every 10 people in the United States.\n\nASHA has cited that 24.1% of children in school in the fall of 2003 received services for speech or language disorders—this amounts to a total of 1,460,583 children between 3 –21 years of age. Again, this estimate does not include children who have speech/language problems secondary to other conditions. Additional ASHA prevalence figures have suggested the following:\n\nWhile more common in childhood, speech impairments can result in a child being bullied. Bullying is a harmful activity that often takes place at school, though may be present in adult life. Bullying involves the consistent and intentional harassment of another individual, and may be physical or verbal in nature.\n\nSpeech impairments (e.g., stuttering) and language impairments (e.g., dyslexia, auditory processing disorder) may also result in discrimination in the workplace. For example, an employer would be discriminatory if he/she chose to not make reasonable accommodations for the affected individual, such as allowing the individual to miss work for medical appointments or not making onsite-accommodations needed because of the speech impairment. In addition to making such appropriate accommodations, the Americans with Disabilities Act (1990) protects against discrimination in \"job application procedures, hiring, advancement, discharge, compensation, job training, and other terms, conditions, and privileges of employment\".\n\nSmith offers the following definitions of major terms that are important in the world of speech and language disorders.\n\n\nIn the mid 19th century, the scientific endeavors of such individuals as Charles Darwin gave rise to more systematic and scientific consideration of physical phenomenon, and the work of others, such as Paul Broca and Carl Wernicke, also lent scientific rigor to the study of speech and language disorders. The late 19th century saw an increase in \"pre-professionals,\" those who offered speech and language services based upon personal experiences or insights. Several trends were exhibited even in the 19th century, some have indicated the importance of elocution training in the early 19th century, through which individuals would seek out those with training to improve their vocal qualities. By 1925 in the USA interest in these trends lead to the forming of the organization that would become American Speech-Language-Hearing Association (ASHA) and the birth of speech-language pathology.\n\nThe twentieth century has been proposed to be composed of four major periods: Formative Years, Processing Period, Linguistic Era, and Pragmatics Revolution. The Formative Years, which began around 1900 and ended around WWII, was a time during which the scientific rigor extended and professionalism entered the picture. During this period, the first school-based program began in the U.S. (1910). The Processing Period, from roughly 1945-1965, further developed the assessment and interventions available for general communication disorders; much of these focused on the internal, psychological transactions involved in the communication process. During the Linguistic Era, from about 1965-1975, professionals began to separate language deficits from speech deficits, which had major implications for diagnosis and treatment of these communication disorders. Lastly, the Pragmatics Revolution has continued to shape the professional practice by considering major ecological factors, such as culture, in relation to speech and language impairments. It was during this period that IDEA was passed, and this allowed professionals to begin working with a greater scope and to increase the diversity of problems with which they concerned themselves.\n\n\n"}
{"id": "34317709", "url": "https://en.wikipedia.org/wiki?curid=34317709", "title": "Speed typing contest", "text": "Speed typing contest\n\nIn a speed typing contest contestants compete to attain the highest accurate typing speeds. These contests have been common in North America since the 1930s and were used to test the relative efficiency of typing with the Dvorak and QWERTY keyboard layouts.\n\nAs of 2015, there were diverse claims regarding the fastest typing in smartphones and other touchscreen devices with on-screen keyboards. The typical yardstick is writing, with no mistakes, the 160-character text:\n\nA disputed issue is whether auto-correct and predictive features should be allowed. Common sense indicates that they shouldn't, because when typing the record phrase several times the phone learns the text. Speed depends, then, on the phrase being repeated, a poor indicator of performance for everyday use. In the extreme, the phone could learn to predict \"Serrasalmus\" when typing just \"Ser\", but that would be extremely uncomfortable in normal circumstances (\"ser\" is the Spanish word for \"being\"). In fact, Guinness World Records establishes that \"To qualify for the record, no autocorrect or predictive text features are allowed to remain on\".\n\nIn March 2010, Samsung posted a 35.54-second record with predictive texting, but no actual footage. Later that year, Swype, a predictive keyboard for Android and iOS where users swipe their fingers across the keyboard to enter one word per stroke, claimed a record of 25.94 seconds, but with prediction features on. A YouTube user later claimed to have set a 21.8-second record on an iPhone, but the posted video clearly showed autocorrect enabled and correcting at least four mistakes.\n\nIn April 2014, in the midst of a publicity campaign for Windows Phone 8.1, Microsoft Research published a new record of 18.44 seconds, also with predictive features on. This record, obviously dependent on pre-learning by the keyboard's memory, became the object of mockery on the web. It was broken the next month when a time of 18.19 seconds was alleged by Brazilian youngster Marcel Fernandes Filho using the Flesky mobile keyboard on an Android phone. While the firm claimed it was without autocorrection, video footage clearly contradicted this (e.g., the letter \"B\" was pressed when writing \"genera\"); furthermore, only a portion of the complete taping was displayed. This alleged record was admitted by Guinness in spite of violating its own rules of having the autocorrect feature off. Also, a dash (crucial for the record) appeared in the main keyboard, which was never a part of Fleksy's main screen. Thus, questions arose as to whether Guinness had been object of a misinformation scheme or even a party in it. In November 2014, Fleksy claimed Mr Fernandes Filho had broken his own record on a larger phone, but later removed the video.\n\nIn 2015, TipType, a What-You-Type-Is-What-You-Get keyboard with a QWERTY layout but based on sliding movements rather than pressing (similar to Swype), launched a speed contest for phones of traditional size. The company posted a 25-second record with a Samsung Galaxy S3 mini on YouTube and promised USD 500 to anyone bettering that record on a touchscreen of size 4.5\" or less, subject to Guinness World Records rules.\n\nMalaysia began holding an annual contest in 2011. Each participant must pass a certain words per minute (WPM) to be eligible for the final live competition. The contest was jointly organized by team a students, JCI Mines and AYFIC Project. It receives support from Microsoft Malaysia, Malaysian Book of Records (MBR), Multimedia Development Corporation (MDeC), Multimedia IT Society, HYJ Wushu Academy and Blogmakeover, as well as various government agencies. The contest soft launched on 1 July 2011, including a press conference that received Chinese newspaper coverage.\n\nThe initial stage is open to all regardless of age. The 200 fastest entrants enter the final stage. Given a 5-minute time slot, participants can have unlimited 1-minute time trials keeping their best result.\n\nThe winner of the 2011 tournament was Shaun Low Foo Shern, with a speed of 146 words per minute.\n\nThe 2012 French romantic comedy-drama film \"Populaire\" shows the relationship between a speed typist and her trainer.\n\n"}
{"id": "3446949", "url": "https://en.wikipedia.org/wiki?curid=3446949", "title": "Symbol grounding problem", "text": "Symbol grounding problem\n\nThe symbol grounding problem is related to the problem of how words (symbols) get their meanings, and hence to the problem of what meaning itself really is. The problem of meaning is in turn related to the problem of consciousness, or how it is that mental states are meaningful.\n\nGottlob Frege distinguished a referent (the thing that a word refers to) and the word's meaning. This is most clearly illustrated using the proper names of concrete individuals, but it is also true of names of kinds of things and of abstract properties: (1) \"Tony Blair\", (2) \"the prime minister of the UK during the year 2004\", and (3) \"Cherie Blair's husband\" all have the same referent, but not the same meaning.\n\nSome have suggested that the meaning of a (referring) word is the rule or features that one must use in order to successfully pick out its referent. In that respect, (2) and (3) come closer to wearing their meanings on their sleeves, because they are explicitly stating a rule for picking out their referents: \"Find whoever was prime minister of the UK during the year 2004\", or \"find whoever is Cherie's current husband\". But that does not settle the matter, because there's still the problem of the meaning of the components of that rule (\"UK,\" \"during\", \"current\", \"PM\", \"Cherie\", \"husband\"), and how to pick \"them\" out.\n\nThe phrase \"Tony Blair\" (or better still, just \"Tony\") does not have this recursive component problem, because it points straight to its referent, but how? If the meaning is the rule for picking out the referent, what is that rule, when we come down to non-decomposable components like proper names of individuals (or names of \"kinds\", as in \"an unmarried man\" is a \"bachelor\")?\n\nHumans are able to pick out the intended referents of words, such as \"Tony Blair\" or \"bachelor,\" but this process need not be explicit. It is probably an unreasonable expectation to know the explicit rule for picking out the intended referents.\n\nSo if we take a word's meaning to be the means of picking out its referent, then meanings are in our brains. That is meaning in the \"narrow\" sense. If we use \"meaning\" in a \"wider\" sense, then we may want to say that meanings include both the referents themselves and the means of picking them out. So if a word (say, \"Tony-Blair\") is located inside an entity (e.g., oneself) that can use the word and pick out its referent, then the word's wide meaning consists of both the means that that entity uses to pick out its referent, and the referent itself: a wide causal nexus between (1) a head, (2) a word inside it, (3) an object outside it, and (4) whatever \"processing\" is required in order to successfully connect the inner word to the outer object.\n\nBut what if the \"entity\" in which a word is located is not a head but a piece of paper (or a computer screen)? What is its meaning then? Surely all the (referring) words on this screen, for example, have meanings, just as they have referents.\n\nIn the 19th century, the semiotician Charles Saunders Peirce suggested what some think is a similar model: according to his triadic sign model, meaning requires (1) an interpreter, (2) a sign or representamen, (3) an object, and is (4) the virtual product of an endless regress and progress called Semiosis. Some have interpreted Peirce as addressing the problem of grounding, feelings, and intentionality for the understanding of semiotic processes. In recent years, Peirce's theory of signs has been rediscovered by an increasing number of artificial intelligence researchers in the context of symbol grounding problem.\n\nThere would be no connection at all between written symbols and any intended referents if there were no minds mediating those intentions, via their own internal means of picking out those intended referents.\n\nSo the meaning of a word on a page is \"ungrounded.\" Nor would looking it up in a dictionary help: If one tried to look up the meaning of a word one did not understand in a dictionary of a language one did not already understand, one would just cycle endlessly from one meaningless definition to another. One's search for meaning would be ungrounded.\n\nIn contrast, the meaning of the words in one's head—those words one \"does\" understand—are \"grounded\". That mental grounding of the meanings of words mediates between the words on any external page one reads (and understands) and the external objects to which those words refer.\n\nAnother symbol system is natural language (Fodor 1975). On paper or in a computer, language, too, is just a formal symbol system, manipulable by rules based on the arbitrary shapes of words. But in the brain, meaningless strings of squiggles become meaningful thoughts. Harnad has suggested two properties that might be required to make this difference:\n\n\nOne property that static paper or, usually, even a dynamic computer lack that the brain possesses is the capacity to pick out symbols' referents. This is what we were discussing earlier, and it is what the hitherto undefined term \"grounding\" refers to. A symbol system alone, whether static or dynamic, cannot have this capacity (any more than a book can), because picking out referents is not just a computational (implementation-independent) property; it is a dynamical (implementation-dependent) property.\n\nTo be grounded, the symbol system would have to be augmented with nonsymbolic, sensorimotor capacities—the capacity to interact autonomously with that world of objects, events, actions, properties and states that its symbols are systematically interpretable (by us) as referring to. It would have to be able to pick out the referents of its symbols, and its sensorimotor interactions with the world would have to fit coherently with the symbols' interpretations.\n\nThe symbols, in other words, need to be connected directly to (i.e., grounded in) their referents; the connection must not be dependent only on the connections made by the brains of external interpreters like us. Just the symbol system alone, without this capacity for direct grounding, is not a viable candidate for being whatever it is that is really going on in our brains when we think meaningful thoughts (Cangelosi & Harnad 2001).\n\nMeaning as the ability to recognize instances (of objects) or perform actions is specifically treated in the paradigm called \"Procedural Semantics\", described in a number of papers including \"Procedural Semantics\" by Philip N. Johnson-Laird and expanded by William A. Woods in \"Meaning and Links\". A brief summary in Woods' paper reads: \"The idea of procedural semantics is that the semantics of natural language sentences can be characterized in a formalism whose meanings are defined by abstract procedures that a computer (or a person) can either execute or reason about. In this theory the meaning of a noun is a procedure for recognizing or generating instances, the meaning of a proposition is a procedure for determining if it is true or false, and the meaning of an action is the ability to do the action or to tell if it has been done.\"\n\nThe necessity of groundedness, in other words, takes us from the level of the pen-pal Turing test, which is purely symbolic (computational), to the robotic Turing test, which is hybrid symbolic/sensorimotor (Harnad 2000, 2007). Meaning is grounded in the robotic capacity to detect, categorize, identify, and act upon the things that words and sentences refer to (see entries for Affordance and for Categorical perception). On the other hand, if the symbols (words and sentences) refer to the very bits of '0' and '1', directly connected to their electronic implementations, which a (any?) computer system can readily manipulate (thus detect, categorize, identify and act upon), then even non-robotic computer systems could be said to be \"sensorimotor\" and hence able to \"ground\" symbols in this narrow domain. \n\nTo categorize is to do the right thing with the right \"kind\" of thing. The categorizer must be able to detect the sensorimotor features of the members of the category that reliably distinguish them from the nonmembers. These feature-detectors must either be inborn or learned. The learning can be based on trial and error induction, guided by feedback from the consequences of correct and incorrect categorization; or, in our own linguistic species, the learning can also be based on verbal descriptions or definitions. The description or definition of a new category, however, can only convey the category and ground its name if the words in the definition are themselves already grounded category names (Blondin-Massé et al. 2008). So ultimately grounding has to be sensorimotor, to avoid infinite regress (Harnad 2005).\n\nBut if groundedness is a necessary condition for meaning, is it a sufficient one? Not necessarily, for it is possible that even a robot that could pass the Turing test, \"living\" amongst the rest of us indistinguishably for a lifetime, would fail to have in its head what Searle has in his: It could be a zombie, with no one home, feeling feelings, meaning meanings (Harnad 1995). However, it is possible that different interpreters (including different intelligent species of animals) would have different mechanisms for producing meaning in their systems, thus one cannot require that a system different from a human \"experiences\" meaning in the same way that a human does, and vice-versa. \n\nHarnad thus points at consciousness as a second property. The problem of discovering the causal mechanism for successfully picking out the referent of a category name can in principle be solved by cognitive science. But the problem of explaining how consciousness could play an \"independent\" role in doing so is probably insoluble, except on pain of telekinetic dualism. Perhaps symbol grounding (i.e., robotic TT capacity) is enough to ensure that conscious meaning is present, but then again, perhaps not. In either case, there is no way we can hope to be any the wiser—and that is Turing's methodological point (Harnad 2001b, 2003, 2006).\n\nTo answer this question we have to formulate the symbol grounding problem itself (Harnad 1990):\n\nThere is a school of thought according to which the computer is more like the brain—or rather, the brain is more like the computer: According to this view (called \"computationalism\", a variety of functionalism), the future theory explaining how the brain picks out its referents (the theory that cognitive neuroscience may eventually arrive at) will be a purely computational one (Pylyshyn 1984). A computational theory is a theory at the software level. It is essentially a computer algorithm: a set of rules for manipulating symbols. And the algorithm is \"implementation-independent.\" That means that whatever it is that an algorithm is doing, it will do the same thing no matter what hardware it is executed on. The physical details of the dynamical system implementing the computation are irrelevant to the computation itself, which is purely formal; any hardware that can run the computation will do, and all physical implementations of that particular computer algorithm are equivalent, computationally.\n\nA computer can execute any computation. Hence once computationalism finds a proper computer algorithm, one that our brain could be running when there is meaning transpiring in our heads, meaning will be transpiring in that computer too, when it implements that algorithm.\n\nHow would we know that we have a proper computer algorithm? It would have to be able to pass the Turing test. That means it would have to be capable of corresponding with any human being as a pen-pal, for a lifetime, without ever being in any way distinguishable from a real human pen-pal.\n\nJohn Searle formulated the \"Chinese room argument\" in order to disprove computationalism. The Chinese room argument is based on a thought experiment: in it, Searle stated that if the Turing test were conducted in Chinese, then he himself, Searle (who does not understand Chinese), could execute a program that implements the same algorithm that the computer was using without knowing what any of the words he was manipulating meant. \n\nAt first glance, it would seem that if there's no meaning going on inside Searle's head when he is implementing that program, then there's no meaning going on inside the computer when it is the one implementing the algorithm either, computation being implementation-independent. But on a closer look, for a person to execute the same program that a computer would, at very least it would have to have access to a similar bank of memory that the computer has (most likely externally stored). This means that the new computational system that executes the same algorithm is no longer just Searle's original head, but that plus the memory bank (and possibly other devices). \nIn particular, this additional memory could store a digital representation of the intended referent of different words (like images, sounds, even video sequences), that the algorithm would use as a model of, and to derive features assotiated with, the intended referent. The \"meaning\" then is not to be searched in just Searle's original brain, but in the overall system needed to process the algorithm. (Just like when Searle is reading English words, the meaning is not to be located in isolated logical processing areas of the brain, but probably in the overall brain, likely including specific long-term memory areas). \nThus, Searle's not perceiving any meaning in his head alone when simulating the work of a computer, does not imply lack of meaning in the overall system, and thus in the actual computer system passing an advanced Turing test.\n\nHow does Searle know that there is no meaning going on in his head when he is executing such a Turing-test-passing program? Exactly the same way he knows whether there is or is not meaning going on inside his head under any other conditions: He \"understands\" the words of English, whereas the Chinese symbols that he is manipulating according to the algorithm's rules mean nothing whatsoever to him (and there is no one else in his head for them to mean anything to). However, the complete system that is manipulating those Chinese symbols - which is not just Searle's brain, as explained in the previous section - may have the ability to extract meaning from those symbols, in the sense of being able to use internal (memory) models of the intended referents, pick out the intended referents of those symbols, and generally identifying and using their features appropriately.\n\nNote that in pointing out that the Chinese words would be meaningless to him under those conditions, Searle has appealed to consciousness. Otherwise one could argue that there \"would\" be meaning going on in Searle's head under those conditions, but that Searle himself would simply not be conscious of it. That is called the \"Systems Reply\" to Searle's Chinese Room Argument, and Searle rejects the Systems Reply as being merely a reiteration, in the face of negative evidence, of the very thesis (computationalism) that is on trial in his thought-experiment: \"Are words in a running computation like the ungrounded words on a page, meaningless without the mediation of brains, or are they like the grounded words in brains?\"\n\nIn this either/or question, the (still undefined) word \"ungrounded\" has implicitly relied on the difference between inert words on a page and consciously meaningful words in our heads. And Searle is asserting that under these conditions (the Chinese Turing test), the words in his head would not be consciously meaningful, hence they would still be as ungrounded as the inert words on a page.\n\nSo if Searle is right, that (1) both the words on a page and those in any running computer program (including a Turing-test-passing computer program) are meaningless in and of themselves, and hence that (2) whatever it is that the brain is doing to generate meaning can't be just implementation-independent computation, then what \"is\" the brain doing to generate meaning (Harnad 2001a)?\n\n\"Intentionality\" has been called the \"mark of the mental\" because of some observations by the philosopher Brentano to the effect that mental states always have an inherent, intended (mental) object or content toward which they are \"directed\": One sees something, wants something, believes something, desires something, understands something, means something etc., and that object is always something that one has \"in mind\". Having a mental object is part of having anything in mind. Hence it is the mark of the mental. There are no \"free-floating\" mental states that do not also have a mental object. Even hallucinations and imaginings have an object, and even feeling depressed feels like something. Nor is the object the \"external\" physical object, when there is one. One may see a real chair, but the \"intentional\" object of one's \"intentional state\" is the mental chair one has in mind. (Yet another term for intentionality has been \"aboutness\" or \"representationality\": thoughts are always \"about\" something; they are (mental) \"representations\" \"of\" something; but that something is what it is that the thinker has in mind, not whatever external object may or may not correspond to it.)\n\nIf this all sounds like skating over the surface of a problem rather than a real break-through, then the foregoing description has had its intended effect: No, the problem of intentionality is not the symbol grounding problem; nor is grounding symbols the solution to the problem of intentionality. The symbols inside an autonomous dynamical symbol system that is able to pass the robotic Turing test are grounded, in that, unlike in the case of an ungrounded symbol system, they do not depend on the mediation of the mind of an external interpreter to connect them to the external objects that they are interpretable (by the interpreter) as being \"about\"; the connection is autonomous, direct, and unmediated. But \"grounding is not meaning\". Grounding is an input/output performance function. Grounding connects the sensory inputs from external objects to internal symbols and states occurring within an autonomous sensorimotor system, guiding the system's resulting processing and output.\n\nMeaning, in contrast, is something mental. But to try to put a halt to the name-game of proliferating nonexplanatory synonyms for the mind/body problem without solving it (or, worse, implying that there is more than one mind/body problem), let us cite just one more thing that requires no further explication: \"feeling\". The only thing that distinguishes an internal state that merely has grounding from one that has meaning is that it \"feels like something\" to be in the meaning state, whereas it does not feel like anything to be in the merely grounded functional state. Grounding is a functional matter; feeling is a felt matter. And that is the real source of Brentano's vexed peekaboo relation between \"intentionality\" and its internal \"intentional object\": All mental states, in addition to being the functional states of an autonomous dynamical system, are also feeling states: Feelings are not merely \"functed,\" as all other physical states are; feelings are also felt.\n\nHence feeling (sentience) is the real mark of the mental. But the symbol grounding problem is not the same as the mind/body problem, let alone a solution to it. The mind/body problem is actually the feeling/function problem: Symbol-grounding touches only its functional component. This does not detract from the importance of the symbol grounding problem, but just reflects that it is a keystone piece to the bigger puzzle called the mind.\n\nThe neuroscientist Antonio Damasio investigates this marking function of feelings and emotions in his Somatic marker hypothesis. Damasio adds the notion of biologic homeostasis to this discussion, presenting it as an automated bodily regulation process providing intentionality to a mind via emotions. Homeostasis is the mechanism that keeps all bodily processes in healthy balance. All of our actions and perceptions will be automatically \"evaluated\" by our body hardware according to their contribution to homeostasis. This gives us an implicit orientation on how to survive. Such bodily or somatic evaluations can come to our mind in the form of conscious and non-conscious feelings (\"gut feelings\") and lead our decision-making process. The meaning of a word can be roughly conceptualized as the sum of its associations and their expected contribution to homeostasis, where associations are reconstructions of sensomotor perceptions that appeared in contiguity with the word. Yet, the Somatic marker hypothesis is still hotly debated and critics claim that it has failed to clearly demonstrate how these processes interact at a psychological and evolutionary level. The recurrent question that the Somatic marker hypothesis does not address remains: how and why does homeostasis (as in any servomechanism such as a thermostat and furnace) become \"felt\" homeostasis?\n\n\n\n"}
{"id": "39590024", "url": "https://en.wikipedia.org/wiki?curid=39590024", "title": "Tautology (language)", "text": "Tautology (language)\n\nIn literary criticism and rhetoric, a tautology is a statement which repeats the same idea, using near-synonymous morphemes, words, or phrases, that is, \"saying the same thing twice\". Tautology and pleonasm are not consistently differentiated in the literature.\n\nLike pleonasm, it is often considered a fault of style when unintentional. On the other hand, an intentional repetition may be an effective way to emphasize a thought, or help the listener or reader understand a point. \n\nSometimes logical tautologies like \"Boys will be boys\" are conflated with language tautologies, but in general, a rhetorical tautology is not inherently true.\n\nThe word was coined in Hellenistic Greek from ταὐτός (\"the same\") plus λόγος (\"word/idea\"), and transmitted through 3rd-century Latin \"tautologia\" and French \"tautologie\". It first appears in English in the 16th century. The use in the term logical tautology was introduced in English by Wittgenstein in 1919, perhaps following Auguste Comte's usage in 1835.\n\n\nIntentional repetition of meaning intends to amplify or emphasize a particular, usually significant, fact about what is being discussed. For example, a gift is, by definition, free of charge; using the phrase \"free gift\" might emphasize that there are no hidden conditions or fine print, be it the expectation of money or reciprocation, or that the gift is being given by volition.\n\nThis is related to the rhetorical device of hendiadys, where one concept is expressed through the use of two descriptive words or phrases. For example, \"goblets and gold\" meaning wealth, or \"this day and age\" meaning the present time. Superficially these expressions may seem tautological, but they are stylistically sound because the repeated meaning is just a way to emphasize the same idea.\n\nThe use of tautologies is, however, usually unintentional. For example, the phrases \"mental telepathy\", \"planned conspiracies\", and \"small dwarfs\" imply that there are such things as \"physical telepathy, spontaneous conspiracies, and giant dwarfs.\")\n\nParallelism is not tautology, but rather a particular stylistic device. Much Old Testament poetry is based on parallelism: the same thing said twice, but in slightly different ways (Fowler puts it as pleonasm). However, modern biblical study emphasizes that there are subtle distinctions and developments between the two lines, such that they are usually not truly the \"same thing.\" Parallelism can be found wherever there is poetry in the Bible: Psalms, the Books of the Prophets, and in other areas as well.\n\n"}
{"id": "18281488", "url": "https://en.wikipedia.org/wiki?curid=18281488", "title": "That that is is that that is not is not is that it it is", "text": "That that is is that that is not is not is that it it is\n\nThat that is is that that is not is not is that it it is is an English word sequence demonstrating syntactic ambiguity. It is used as an example illustrating the importance of proper punctuation.\n\nThe sequence can be understood as any of four grammatically-correct sequences, each with at least four discrete sentences, by adding punctuation:\n\nThe first two relate a simple philosophical proverb in the style of Parmenides that all that is, is, and that anything that does not exist does not. The phrase was noted in \"Brewer's Dictionary of Phrase and Fable\".\n\nThis phrase appeared in the 1968 American movie \"Charly\", written to demonstrate punctuation to the main character Charly's teacher, in a scene to demonstrate that the surgical operation to make the character smarter had succeeded.\n\n"}
{"id": "27404794", "url": "https://en.wikipedia.org/wiki?curid=27404794", "title": "The Interpreter (Kim novel)", "text": "The Interpreter (Kim novel)\n\nThe Interpreter (2003) is Suki Kim’s first novel. In \"The Interpreter\", Kim creates a twenty-nine-year-old Korean American court interpreter named Suzy Park who makes a startling and ominous discovery during one court case which ultimately reveals the mystery of her parents' homicide. The award winning novel, mainly a murder mystery, breaks through the stereotypical images of the happy immigrant experience with a story of pain, loss, and murder.\n\nSuzy Park is a young, attractive, and achingly alone Korean American woman who works as a court interpreter for the New York City court system. She has had two rocky relationships with married men, worked a series of unsatisfying jobs, and cut ties with her family before her parents were shot dead in an unsolved double murder. The life she has chosen as an interpreter is a reflection of Suzy's searching for her own identity and trying to bridge the two cultures to both of which she feels a detachment. During one court case she discovers that her parents were not murdered by random violence, as the police had indicated, but instead had been shot by political enemies. The discovery provides the glint of a new lead for Park, and the novel tracks her investigation into what really happened, which ultimately reveals the mystery of her parents' homicide.\n\n\n\n"}
{"id": "9032406", "url": "https://en.wikipedia.org/wiki?curid=9032406", "title": "Tupper's self-referential formula", "text": "Tupper's self-referential formula\n\nTupper's self-referential formula is a formula that visually represents itself when graphed at a specific location in the (\"x\", \"y\") plane.\n\nThe formula was defined by Jeff Tupper and appears as an example in Tupper's 2001 SIGGRAPH paper on reliable two-dimensional computer graphing algorithms.\n\nAlthough the formula is called \"self-referential\", Tupper did not name it as such.\n\nThe formula is an inequality defined as:\n\nor, as plaintext,\nwhere ⌊ ⌋ denotes the floor function, and mod is the modulo operation.\n\nLet \"k\" equal the following 543-digit integer:\n\nIf one graphs the set of points (\"x\", \"y\") in 0 ≤ \"x\" < 106 and \"k\" ≤ \"y\" < \"k\" + 17 satisfying the inequality given above, the resulting graph looks like this (the axes in this plot have been reversed, otherwise the picture would be upside-down and mirrored):\n\nThe formula is a general-purpose method of decoding a bitmap stored in the constant \"k\", and it could actually be used to draw any other image. When applied to the unbounded positive range 0 ≤ \"y\", the formula tiles a vertical swath of the plane with a pattern that contains all possible 17-pixel-tall bitmaps. One horizontal slice of that infinite bitmap depicts the drawing formula itself, but this is not remarkable, since other slices depict all other possible formulae that might fit in a 17-pixel-tall bitmap. Tupper has created extended versions of his original formula that rule out all but one slice.\n\nThe constant \"k\" is a simple monochrome bitmap image of the formula treated as a binary number and multiplied by 17. If \"k\" is divided by 17, the least significant bit encodes the upper-right corner (\"k\", 0); the 17 least significant bits encode the rightmost column of pixels; the next 17 least significant bits encode the 2nd-rightmost column, and so on.\n\n\n"}
{"id": "26027341", "url": "https://en.wikipedia.org/wiki?curid=26027341", "title": "United Nations Security Council Resolution 528", "text": "United Nations Security Council Resolution 528\n\nUnited Nations Security Council Resolution 528, adopted on December 21, 1982, after the General Assembly passed Resolution 3190 extolling the virtues of expanded working languages, the Council decided to include Arabic among the working languages of the Security Council.\n\nNo details of the voting were given, other than that it was adopted \"by consensus\".\n\n\n"}
{"id": "32369", "url": "https://en.wikipedia.org/wiki?curid=32369", "title": "Vagueness", "text": "Vagueness\n\nIn philosophy, vagueness refers to an important problem in semantics, metaphysics and philosophical logic. Definitions of this problem vary. A predicate is sometimes said to be vague if the bound of its extension is indeterminate, or appears to be so. The predicate \"is tall\" is vague because there seems to be no particular height at which someone becomes tall. Relatedly, a predicate is sometimes said to be vague if there are borderline cases of its application, such that in these cases competent speakers of the language may faultlessly disagree over whether the predicate applies. The disagreement over whether a hotdog is a sandwich suggests that “sandwich” is vague. \n\nVagueness is commonly introduced by the Sorites paradox. A standard form of this paradox features a 2000 man sequence of progressively taller men, starting with a paradigm case of a short man at one extreme, say George Costanza, and at the other extreme, a paradigm case of a tall one, say Kramer. \n\n\nSorites paradoxes exploit the intuition that some vague predicates are \"tolerant\" with respect to small enough differences on a dimension decisive of their application. This principle may seem to hold on the basis that (for example) no particular height is more justified than others in its vicinity as a cut-off for shortness. This intuition has been called the \"No Sharp Boundaries\" thesis about vague predicates and plays a prominent role in theories of vagueness. \n\nThe Sorites paradox dates to the fourth century BCE and is attributed to Eubulides of Melitus. It has received a resurgence of attention since 1975, when three papers published in \"Synthese\" effectively conceived the contemporary study of vagueness. \n\nThe problem posed by vagueness is to explain its particular kind of indeterminacy. Does vagueness render large portions of ordinary language meaningless? Likely not, since we frequently use vague language to great effect in ordinary discourse. If not, what \"is\" vagueness, at the level of predicate logic? How is it to be modeled without contradiction, and without sacrificing too much of classical logic? Is vagueness semantic, metaphysical or epistemic? \n\nVagueness has in its own right reaped the attention of an extensive literature. In addition, vagueness is a topic that touches many other questions in philosophy, linguistics and cognitive science, not to mention ordinary conversation. \n\nVagueness is philosophically important. Suppose one wants to come up with a definition of \"right\" in the moral sense. One wants a definition to cover actions that are clearly right and exclude actions that are clearly wrong, but what does one do with the borderline cases? Surely, there are such cases. Some philosophers say that one should try to come up with a definition that is itself unclear on just those cases. Others say that one has an interest in making his or her definitions more precise than ordinary language, or his or her ordinary concepts, themselves allow; they recommend one advances precising definitions.\n\nVagueness is also a problem which arises in law, and in some cases judges have to arbitrate regarding whether a borderline case does, or does not, satisfy a given vague concept. Examples include disability (how much loss of vision is required before one is legally blind?), human life (at what point from conception to birth is one a legal human being, protected for instance by laws against murder?), adulthood (most familiarly reflected in legal ages for driving, drinking, voting, consensual sex, etc.), race (how to classify someone of mixed racial heritage), etc. Even such apparently unambiguous concepts such as gender can be subject to vagueness problems, not just from transsexuals' gender transitions but also from certain genetic conditions which can give an individual mixed male and female biological traits (see intersex).\n\nMany scientific concepts are of necessity vague, for instance species in biology cannot be precisely defined, owing to unclear cases such as ring species. Nonetheless, the concept of species can be clearly applied in the vast majority of cases. As this example illustrates, to say that a definition is \"vague\" is not necessarily a criticism. Consider those animals in Alaska that are the result of breeding huskies and wolves: are they dogs? It is not clear: they are borderline cases of dogs. This means one's ordinary concept of doghood is not clear enough to let us rule conclusively in this case.\n\nThe philosophical question of what the best theoretical treatment of vagueness is - which is closely related to the problem of the paradox of the heap, a.k.a. sorites paradox - has been the subject of much philosophical debate.\n\nOne theoretical approach is that of fuzzy logic, developed by American mathematician Lotfi Zadeh. Fuzzy logic proposes a gradual transition between \"perfect falsity\", for example, the statement \"Bill Clinton is bald\", to \"perfect truth\", for, say, \"Patrick Stewart is bald\". In ordinary logics, there are only two truth-values: \"true\" and \"false\". The fuzzy perspective differs by introducing \"an infinite number of truth-values\" along a spectrum between perfect truth and perfect falsity. Perfect truth may be represented by \"1\", and perfect falsity by \"0\". Borderline cases are thought of as having a \"truth-value\" anywhere between 0 and 1 (for example, 0.6). Advocates of the fuzzy logic approach have included K. F. Machina (1976) and Dorothy Edgington (1993).\n\nAnother theoretical approach is known as \"supervaluationism\". This approach has been defended by Kit Fine and Rosanna Keefe. Fine argues that borderline applications of vague predicates are neither true nor false, but rather are instances of \"truth value gaps\". He defends an interesting and sophisticated system of vague semantics, based on the notion that a vague predicate might be \"made precise\" in many alternative ways. This system has the consequence that borderline cases of vague terms yield statements that are neither true, nor false.\n\nGiven a supervaluationist semantics, one can define the predicate 'supertrue' as meaning \"true on all precisifications\". This predicate will not change the semantics of atomic statements (e.g. 'Frank is bald', where Frank is a borderline case of baldness), but does have consequences for logically complex statements. In particular, the tautologies of sentential logic, such as 'Frank is bald or Frank is not bald', will turn out to be supertrue, since on any precisification of baldness, either 'Frank is bald' or 'Frank is not bald' will be true. Since the presence of borderline cases seems to threaten principles like this one (excluded middle), the fact that supervaluationism can \"rescue\" them is seen as a virtue.\n\nSubvaluationism is the logical dual of supervaluationism, and has been defended by Dominic Hyde (2008) and Pablo Cobreros (2011). Whereas the supervaluationist characterises truth as 'supertruth', the subvaluationist characterises truth as 'subtruth', or \"true on at least some precisifications\". \n\nSubvaluationism proposes that borderline applications of vague terms are both true and false. It thus has 'truth-value gluts'. According to this theory, a vague statement is true if it is true on at least one precisification and false if it is false under at least one precisification. If a vague statement comes out true under one precisification and false under another, it is both true and false. Subvaluationism ultimately amounts to the claim that vagueness is a truly contradictory phenomenon. Of a borderline case of 'bald man' it would be both true and false to say that he is bald, and both true and false to say that he is not bald.\n\nA fourth approach, known as the \"epistemicist view\", has been defended by Timothy Williamson (1994), R. A. Sorensen (1988) and (2001), and Nicholas Rescher (2009). They maintain that vague predicates do, in fact, draw sharp boundaries, but that one cannot know where these boundaries lie. One's confusion about whether some vague word does or does not apply in a borderline case is explained as being due to one's ignorance. For example, on the epistemicist view, there is a fact of the matter, for every person, about whether that person is old or not old. It is just that one may sometimes be ignorant of this fact.\n\nOne possibility is that one's words and concepts are perfectly precise, but that objects themselves are vague. Consider Peter Unger's example of a cloud (from his famous 1980 paper, \"The Problem of the Many\"): it's not clear where the boundary of a cloud lies; for any given bit of water vapor, one can ask whether it's part of the cloud or not, and for many such bits, one won't know how to answer. So perhaps one's term 'cloud' denotes a vague object precisely. This strategy has been poorly received, in part due to Gareth Evans's short paper \"Can There Be Vague Objects?\" (1978). Evans's argument appears to show that there can be no vague identities (e.g. \"Princeton = Princeton Borough\"), but as Lewis (1988) makes clear, Evans takes for granted that there are in fact vague identities, and that any proof to the contrary cannot be right. Since the proof Evans produces relies on the assumption that terms precisely denote vague objects, the implication is that the assumption is false, and so the vague-objects view is wrong.\n\nStill by, for instance, proposing alternative deduction rules involving Leibniz's law or other rules for validity some philosophers are willing to defend vagueness as some kind of metaphysical phenomenon. One has, for example, Peter van Inwagen (1990), Trenton Merricks and Terence Parsons (2000).\n\nIn the common law system, vagueness is a possible legal defence against by-laws and other regulations. The legal principle is that delegated power cannot be used more broadly than the delegator intended. Therefore, a regulation may not be so vague as to regulate areas beyond what the law allows. Any such regulation would be \"void for vagueness\" and unenforceable. This principle is sometimes used to strike down municipal by-laws that forbid \"explicit\" or \"objectionable\" contents from being sold in a certain city; courts often find such expressions to be too vague, giving municipal inspectors discretion beyond what the law allows. In the US this is known as the vagueness doctrine and in Europe as the principle of legal certainty.\n\n\n\n"}
{"id": "12393342", "url": "https://en.wikipedia.org/wiki?curid=12393342", "title": "Vernacular orientation", "text": "Vernacular orientation\n\nVernacular orientation refers to the status that a language is afforded by one of its mother-tongue speakers (Tiessen, 2003). This status is exhibited through the sociolinguistic behaviours of a mother-tongue speaker. A speaker who exhibits positive vernacular orientation is one who exhibits a preferred status for their mother tongue in such things as patterns of language use, language attitudes, social networks and even levels of language proficiency. Likewise, a speaker who exhibits negative vernacular orientation is one who exhibits a preferred status for a language other than their mother tongue in these areas of sociolinguistic behaviour.\n\nAn example of research into vernacular orientation as expressed in a community can be found at . This is a study on vernacular orientation in the Talysh community of the city of Sumgayit in the Republic of Azerbaijan for the purpose of gaining a greater understanding of its causes. Vernacular orientation is described in three areas of sociolinguistic behaviour: patterns of vernacular language use, vernacular language proficiency and frequency of vernacular-speaking individuals in social networks. Data was collected through personal interviews. The questionnaires for these interviews were developed using a qualitative-relational research approach. The description of vernacular orientation takes the form of a criteria-based typology of which an analysis of influential factors is ultimately made. This analysis of influential factors demonstrates the interaction between vernacular orientation as described in the typology and the contextual elements of the family, socio-economic dynamics and individual attitudes.\n"}
{"id": "34608521", "url": "https://en.wikipedia.org/wiki?curid=34608521", "title": "Vivid designator", "text": "Vivid designator\n\nIn modal logic and the philosophy of language, a vivid designator is a term which is \"believed\" to designate the same thing in all possible worlds and nothing else where such an object does not exist in a possible world. It is the analogue, in the sense of believing, of a rigid designator, which \"is\" (refers to) the same in all possible worlds, rather than is just \"believed\" to be so.\n\nWillard Van Orman Quine credits David Kaplan (who in turn Montgomery Furth) for the term \"vivid designator\" in his 1953 paper \"Reference and Modality\". He examines the separation between \"de re\" and \"de dicto\" and does away with \"de re\" statements, because \"de re\" statements can only work for names that are used referentially. In fact, both rigid designators and vivid designators are similarly dependent on context and empty otherwise. The same is true of the whole quantified modal logic of necessity because it collapses if essence is withdrawn.\n\n"}
