{"id": "1020090", "url": "https://en.wikipedia.org/wiki?curid=1020090", "title": "1965 in radio", "text": "1965 in radio\n\nThe year 1965 saw a number of significant events in radio broadcasting.\n\n\n\n\n"}
{"id": "4238116", "url": "https://en.wikipedia.org/wiki?curid=4238116", "title": "1988 world oil market chronology", "text": "1988 world oil market chronology\n\n\"Wide use of crude formula pricing in 1988.\"\n|-\n"}
{"id": "47767242", "url": "https://en.wikipedia.org/wiki?curid=47767242", "title": "2003 in Sri Lanka", "text": "2003 in Sri Lanka\n\nThe following lists events that happened during 2003 in Sri Lanka.\n"}
{"id": "4973111", "url": "https://en.wikipedia.org/wiki?curid=4973111", "title": "AP United States History", "text": "AP United States History\n\nAdvanced Placement United States History (also known as AP U.S. History or APUSH) is a course and examination offered by College Board as part of the Advanced Placement Program.\n\nThe AP U.S. History course is designed to provide the same level of content and instruction that students would face in a freshman-level college survey class. AP U.S. History classes generally use a college-level textbook as the foundation for the course.\n\nCommonly used textbooks that meet the curriculum requirements include:\nAmerican conservatives have criticized the curriculum for downplaying American exceptionalism and failing to foster patriotism. In 2014, there were protests against it in the Jefferson County Public Schools district in Colorado. In 2015, a bill to replace the curriculum was passed by the Oklahoma House of Representatives’ Education Committee, but later withdrawn.\n\nThe AP U.S. History exam lasts 3 hours and 15 minutes and consists of two sections; additionally, each section is divided into two parts. Section I, part A includes 55 multiple choice questions with each question containing four choices. The multiple choice questions cover American History from just before European contact with Native Americans to the present day. Moreover, section I, part B includes three short-answer questions. The first two questions are required, but students choose between the third and fourth questions. In total, students are given 95 minutes (55 for the multiple choice section and 40 for three short-answer questions) to complete section I.\n\nSection II of the exam is the free-response section, in which examinees write two essays. Section II, part A, is a document-based question (DBQ), which provides an essay prompt and seven short primary sources or excerpts related to the prompt. Students are expected to write an essay responding to the prompt in which they utilize the sources in addition to outside information. Section II, part B, provides three thematic essay prompts. Students must respond to only one of the three essay prompts. \n\nEach long essay essay question on the AP exam may address any one of three possible historical thinking skills: patterns of continuity and change over time, comparison, or causation. Both of the essay questions will address the same historical thinking skill. In addition, neither essay's time frame will be exclusively before 1607 (the founding of Jamestown) or after 1980 (President Reagan's election). There is a fifteen-minute reading period for students to read the essay prompts, take notes, and brainstorm; but students may begin to write the essays before this period ends. Students will then have 85 minutes to write the two essays; 45 minutes are recommended for the DBQ and 40 minutes for the long essay, but students are free to work on the two essays as they see fit.\n\nIn May 2011, the AP U.S. History Test was taken by 402,947 students worldwide, making it second in terms of number of examinees, behind the AP English Language and Composition exam.\n\nThe AP U.S. History exam is divided into two sections. Section one consists of the multiple choice and short answer questions, while section two consists of the document-based question (DBQ) and a long essay question. Section one is worth 60% of the total AP exam score, with 40% of the total exam score derived from the student's performance on the multiple choice section and 20% of the total exam score derived from the student's performance on the short answer questions. The remaining 40% of the total exam score is derived from section two; the document-based question is worth 25% of the total exam score, while the long essay question is worth 15% of the total exam score.\n\nThe score distributions since 2007 were:\nThe College Board has released information on the composite score range (out of 180) required to obtain each grade:\nNote: The above composite score cut points reflect the pre-2011 grading formula which deducted 0.25 points for every incorrect multiple choice answer.\n\n"}
{"id": "21295163", "url": "https://en.wikipedia.org/wiki?curid=21295163", "title": "African-American heritage of presidents of the United States", "text": "African-American heritage of presidents of the United States\n\nThe African-American heritage of United States presidents relates mostly to questions and claims made by amateur historians as to whether five presidents of the United States who were accepted as white also had significant recent African ancestry. There is no disagreement that President Barack Obama (2009–2017) had a Kenyan father and an American mother of mostly European ancestry. (She and Obama are thought also to be descended from the African indentured servant known in colonial records as John Punch.) The academic consensus of historians is that no president other than Obama has had recent (from the colonial period in U.S. history or after) African ancestry; it rejects claims to the contrary.\n\nThese claims have been made by the historian William Estabrook Chancellor, amateur historian J. A. Rogers, ophthalmologist Leroy William Vaughn, and Auset BaKhufu. All but Chancellor base their theories chiefly on the work of J. A. Rogers, who apparently self-published a pamphlet in 1965 claiming that five presidents of the United States, widely accepted as white, also had African ancestry. Vaughn's and BaKhufu's books also appear to have been self-published.\n\nHistorians' and biographers' studies of these presidents have not supported such claims, nor have the claims been published in any peer-reviewed journal. These authors are generally ignored by scholars. They repeat each other's material and are classified as \"rumormongers and amateur historians.\" Vaughn and BaKhufu have added little substantive research to their claims, although there has been extensive new documentation of race relations by others in the decades since Rogers published his pamphlet.\n\nCitizenship and associated claims have split on two dimensions: formal legal citizenship, and full social and political citizenship. While claims of African ancestry may have created social scandal (and that varied in time and place), even in Thomas Jefferson's time, a person of less than one-quarter African ancestry could be considered legally white. Later this was changed so that a person had to have at least seven-eighths European ancestry to be legally white. Jefferson's mixed-race children from his relationship with Sally Hemings, were seven-eighths white. There is ample evidence in historical records that people of mixed race were accepted as white and full citizens in communities, as they were documented as exercising the rights of citizens to bear arms and vote. Social acceptance by the majority-white community was often the key as to whether a person was considered white, more than details about ancestry, especially in early periods on the frontier when few records were kept and people often did not know much about their origins.\n\nThis classification of ancestry and social class was separate from the legal status derived from \"partus sequitur ventrem\", the law that made children born to slave mothers also slaves. This law hardened slavery as a racial caste system. But, it was not until after the end of slavery and regaining of power by conservative whites in the late 19th-century South that they passed laws to create racial segregation and Jim Crow. From 1890 to 1908, southern states of the former Confederacy passed constitutional amendments and legislation making voter registration more difficult, essentially disfranchising most blacks and tens of thousands of poor whites. Such disfranchisement essentially lasted until the civil rights movement gained Congressional passage of the Voting Rights Act of 1965 to protect constitutional rights of citizens to vote.\n\nIn the early 20th century, southern states tried to find more ways to enforce segregation. Beginning with Tennessee in 1910, through Oklahoma in 1931, most southern states adopted the one-drop rule, and hardened racial lines so that a person of any African ancestry was to be recorded as and considered as black in the binary society. During the same period, Florida, Indiana, Kentucky, Maryland, Missouri, Nebraska, North Dakota, and Utah retained their old \"blood fraction\" statutes \"de jure\", but amended these fractions (one-sixteenth, one-thirty-second) to be equivalent to one-drop \"de facto.\"\n\nIn recent decades, United States historians have more thoroughly explored the years of slavery and opened up discussion of race relations. They have noted that numerous mixed-race families of varying proportions of European and African ancestry developed in colonial and antebellum United States. In award-winning research, Paul Heinegg traced the ancestry of free black families in North Carolina in the 1790 census, finding that most were descended from free people of color in colonial Virginia who migrated to other areas. They were mostly descendants of unions between white women, indentured servant or free, and African men, slave, indentured or free, from years when associations among the working class were fluid. The historian Dr. Ira Berlin praised Heinegg's \"meticulous research\" in his Foreword to his work. Because the white women were free, their mixed-race children were born free.\n\nNell Irvin Painter examined issues of power in \"Southern History Across the Color Line\" (2002). Joshua Rothman looked closely at antebellum Virginia and numerous mixed-race families in \"Notorious in the Neighborhood: Sex and Families across the Color Line in Virginia, 1787–1861\" (2003). In two books, the scholar Annette Gordon-Reed showed how historians had ignored evidence of Thomas Jefferson's and Sally Hemings' long affair and mixed-race children, who were seven-eighths white. In her deep research, however, she did not support claims that Jefferson was of mixed-race descent. DNA studies in 1998 showed a match between the Jefferson male line and a descendant of Eston Hemings, leading experts to conclude that Jefferson was likely the father of Hemings' children. The Thomas Jefferson Foundation agrees that the weight of historical evidence supports this conclusion.\n\nPresident Barack Obama had a Kenyan father and an American mother of mostly European ancestry. A conspiracy theory arose over whether Obama was born in the U.S., a claim generally being that he was born in Africa, which might have denied him the right to be President even if elected. Drawing on a combination of historical documents and Y-DNA analysis, Ancestry.com stated in July 2012 that it is a strong likelihood that Obama is an eleventh great-grandson of the African John Punch, who was formerly an indentured servant and later a slave, through his mother Stanley Ann Dunham. Punch lived in the Colony of Virginia during the seventeenth century.\n\nNone of the claims below have been verified by reliable sources in peer-reviewed publications. Mainline historians do not support these claims.\n\nVaughn and others claim Thomas Jefferson's mother Jane Randolph Jefferson was of mixed-race ancestry. The academic consensus does not support such claims. In her recent analyses of historical evidence about the Hemings and Jeffersons, for example, the scholar Annette Gordon-Reed makes no claim of African descent in the Randolph family.\n\nSpecifically, Vaughn says, \"The chief attack on Jefferson was in a book written by Thomas Hazard in 1867 called \"The Johnny Cake Papers\". Hazard interviewed Paris Gardiner, who said he was present during the 1796 presidential campaign, when one speaker states that Thomas Jefferson was a mean-spirited son of a half-breed Indian squaw and a Virginia mulatto father.\" An overlapping claim is that, in an 18th-century Presidential campaign, someone speaking against Jefferson's candidacy and in favor of that of John Adams accused Jefferson of being \"half Injun, half nigger, half Frenchman\" and born to a \"mulatto father\" or slave and \"a half-breed Indian squaw\", this birth to a mulatto and an Indian allegedly \"well-known in the neighbourhood where he was raised\" but otherwise unproven. Vaughn also quoted biographer Samuel Sloan's statement that there was \"something strange\" about Thomas Jefferson's reportedly destroying papers and personal effects of his mother Jane Randolph Jefferson after her death. That is the extent of his evidence.\n\nThe Thomas Jefferson Foundation, which owns and operates Monticello, the major public history site on Jefferson, characterizes Jefferson's parents this way: \"His father Peter Jefferson was a successful planter and surveyor and his mother Jane Randolph a member of one of Virginia's most distinguished families.\" They describe the quote in \"The Johnny Cake Papers\" as one frequently repeated, but it is attributed in written sources to the 1800 rather than the 1796 election campaign and clearly is one made by political opponents. \"The Johnny Cake Papers\" were a collection of folk tales published in 1879, not 1867, and only one tale commented on Jefferson. The Foundation states:\n\nTo date we have not found this quotation in any sources contemporary to the election of 1800. Its earliest known appearance in print is actually in a collection of New England folk tales, \"The Johnny-Cake Papers\". First published in 1879, the stories told date in many cases back to the beginning of the 19th century, while others are thought to be even older. The reference in question appears in the \"Seventeenth Baking,\" in which a \"most veracious stump orator from Providence\" spoke expansively on the achievements of [president] John Adams,\n\n\nDixon Wecter, in his essay \"Thomas Jefferson, The Gentle Radical,\" discusses various portrayals of Jefferson by his political enemies, and mentions that \"the Jonnycake [sic] Papers later burlesqued such caricatures...\"\n\nAndrew Jackson referred to a charge that his \"Mother ... [was] held to public scorn as a prostitute who intermarried with a Negro, and [that his] ... eldest brother [was] sold as a slave in Carolina.\" Less specific was a rumor of Jackson having \"colored blood\", meaning having \"Negro\" ancestry; this rumor was unproven. President Jackson's father was born in Carrickfergus, County Antrim, in current-day Northern Ireland, around 1738. Scholars Hendrik Booraem, Robert Remini, and H. W. Brands are agreed he had no black ancestors.\n\nAbraham Lincoln's mother Nancy Hanks was claimed to be of African descent.\n\nAccording to historian William E. Barton, a rumor \"current in various forms in several sections of the South\" was that Lincoln's biological father was Abraham Enloe, which Barton dismissed as \"false\". According to Doug Wead, Enloe publicly denied this connection to Lincoln but is reported to have privately confirmed it. Another claim was that Lincoln was \"part Negro\", but that was unproven. Mail received by Lincoln called him \"a negro\" and a \"mulatto\". Thomas Lincoln's \"complexion [was] swarthy\". According to Lincoln's law partner William H. Herndon, Lincoln had \"very dark skin\" although \"his cheeks were leathery and saffron-colored\" and \"his face was ... sallow,\" and \"his hair was dark, almost black\". Abraham Lincoln described himself \"ca.\" 1838–'39 as \"black\" and his \"complexion\" in 1859 as \"dark\" but whether he meant either in an ancestral sense is unknown. The Charleston \"Mercury\" described him as being \"of ... the dirtiest complexion\".\n\nWarren G. Harding was said to have African ancestry; one claim was by his political opponent, a controversial and racist historian, William Estabrook Chancellor. Chancellor said Harding's father was a mulatto and Harding's great-grandmother was black. During Harding's campaign, Democratic opponents spread rumors that Harding's great-great-grandfather was a West Indian black and that other blacks might be found in his family tree. Chancellor publicized rumors, based on supposed family research, but perhaps reflecting no more than local gossip. In an era when the \"one-drop rule\" would classify a person with any African ancestry as black, and black people in the South had been effectively disenfranchised, Harding's campaign manager responded, \"no family in the state (of Ohio) has a clearer, a more honorable record than the Hardings', a blue-eyed stock from New England and Pennsylvania, the finest pioneer blood.\" \"Many biographers have dismissed the rumors of Harding's mixed-race family as little more than a political scandal and Chancellor himself as a Democratic mudslinger and racist ideologue.\" According to Chancellor, Harding got his only academic degree from Iberia College, which had been \"founded to educate fugitive slaves.\" The college was founded by abolitionist supporters in the Presbyterian Church in Ohio for students of both genders and all races. \nWhen asked directly about Chancellor's account, Harding did not make any effort to deny that he may have had an African-American ancestor. He said he did not know and demonstrated that it was not a significant issue.\n\nThe rumors may have been sustained by a statement Harding allegedly made to newspaperman James W. Faulkner on the subject, which he perhaps meant to be dismissive: \"How do I know, Jim? One of my ancestors may have jumped the fence.\" However, while there are gaps in the historical record, studies of his family tree have not found evidence of an African-American ancestor.\n\nIn 2015 genetic testing of Harding's descendants determined, with more than a 95% percent chance of accuracy, that he lacked sub-Saharan African forebears within four previous generations.\n\nCalvin Coolidge's mother Victoria Moor was claimed to be of a mixed-race family in Vermont. Vaughn noted that her surname was derived from \"Moor\", a European term for people of North Africa. He did not note that another meaning of her surname is the landscape feature of moor or bog. People's surnames were often based on such landscape features when surnames became generally adopted in 14th century England. Moor/Moore is a common name in England, Scotland, and Ireland.\n\nDwight D. Eisenhower's mother was said to be of mixed blood from Africa and mulatto. However, historians and biographers of Eisenhower had documented his parents' German, Swiss and English ancestry and long history in America. Some of his immigrant ancestors settled in Pennsylvania in 1741 and after, migrated west to Kansas.\n\nBefore the Constitution of the United States was drafted, John Hanson was one of the Presidents of the Continental Congress, and thus not considered one of the Presidents of the United States by mainstream historians. Though he was a white man from Maryland, a false claim has circulated on the Internet claiming that he was actually the first Black President of the United States, the claim including that the black President Hanson appears on the back of the United States two-dollar bill, but that confused the white Hanson with Senator John Hanson, an African-American man with the same name who helped colonize Liberia, while the face on the two-dollar bill is that of Thomas Heyward, Jr., a white man whose face is in shadow in the portrait reproduced on the currency.\n\nPresident Franklin D. Roosevelt had an ancestor born in North Africa. His ancestor Henry Smith was born to English parents Col. William \"Tangier\" and Martha (Tunstall) Smith in Tangier in present-day Morocco on 19 Jan. 1678/9. While Smith's parents were married in Tangier in 1675, they were both born in England and were of European ancestry. The Mayorship of Tangiers held by Col. William Smith has been used by his descendants to distinguish themselves from other Smith through use of the compound surname Tangiers Smith ever since.\n\n\n"}
{"id": "690842", "url": "https://en.wikipedia.org/wiki?curid=690842", "title": "Age of Discovery", "text": "Age of Discovery\n\nThe Age of Discovery, or the Age of Exploration (approximately from the beginning of the 15th century until the end of the 18th century) is an informal and loosely defined term for the period in European history in which extensive overseas exploration emerged as a powerful factor in European culture and was the beginning of globalization. It also marks the rise of the period of widespread adoption in Europe of colonialism and mercantilism as national policies. Many lands previously unknown to Europeans were discovered by them during this period, though most were already inhabited. From the perspective of many non-Europeans, the Age of Discovery marked the arrival of invaders from previously unknown continents. \nGlobal exploration started with the Portuguese discoveries of the Atlantic archipelagos of Madeira and the Azores, the coast of Africa, and the discovery of the sea route to India in 1498; and the Crown of Castile (Spain) the trans-Atlantic Voyages of Christopher Columbus to the Americas between 1492 and 1502 and the first circumnavigation of the globe in 1519–1522. These discoveries led to numerous naval expeditions across the Atlantic, Indian and Pacific oceans, and land expeditions in the Americas, Asia, Africa and Australia that continued into the late 19th century, and ended with the exploration of the polar regions in the 20th century.\n\nEuropean overseas exploration led to the rise of global trade and the European colonial empires, with the contact between the \"Old World\" (Europe, Asia and Africa) and the \"New World\" (the Americas and Australia) producing the Columbian Exchange; a wide transfer of plants, animals, food, human populations (including slaves), communicable diseases and culture between the Eastern and Western Hemispheres. This represented one of the most-significant global events concerning ecology, agriculture and culture in history. The Age of Discovery and later European exploration allowed the global mapping of the world, resulting in a new world-view and distant civilizations coming into contact, but also led to the propagation of diseases that decimated populations not previously in contact with Eurasia and Africa and to the enslavement, exploitation, military conquest and economic dominance by Europe and its colonies over native populations. It also allowed for the expansion of Christianity throughout the world: with the spread of missionary activity, it eventually became the world's largest religion.\n\nThe Portuguese began systematically exploring the Atlantic coast of Africa from 1418, under the sponsorship of Prince Henry. Under the direction of Henry the Navigator, the Portuguese developed a new, much lighter ship, the caravel, which could sail further and faster, and, above all, was highly manoeuvrable and could sail much nearer the wind, or \"into the wind\". In 1488 Bartolomeu Dias reached the Indian Ocean by this route. In 1492 the Catholic Monarchs of Castile and Aragon funded Christopher Columbus's plan to sail west to reach the Indies by crossing the Atlantic. He landed on a continent uncharted by Europeans and seen as a new world, the Americas. To prevent conflict between Portugal and Castile (the crown under which Columbus made the voyage), the Treaty of Tordesillas was signed dividing the world into two regions of exploration, where each had exclusive rights to claim newly discovered lands.\n\nIn 1498, a Portuguese expedition commanded by Vasco da Gama reached India by sailing around Africa, opening up direct trade with Asia. While other exploratory fleets were sent from Portugal to northern North America, in the following years Portuguese India Armadas also extended this Eastern oceanic route, touching sometimes South America and by this way opening a circuit from the New World to Asia (starting in 1500, under the command of Pedro Alvares Cabral), and explored islands in the South Atlantic and Southern Indian Oceans. Soon, the Portuguese sailed further eastward, to the valuable Spice Islands in 1512, landing in China one year later. In 1513, Spanish Vasco Núñez de Balboa crossed the Isthmus of Panama and reached the \"other sea\" from the New World. Thus, Europe first received news of the eastern and western Pacific within a one-year span around 1512. East and west exploration overlapped in 1522, when a Castilian (Spanish) expedition, led by Portuguese navigator Ferdinand Magellan and later by Spanish Basque navigator Juan Sebastián Elcano, sailing westward, completed the first circumnavigation of the world, while Spanish \"conquistadors\" explored the interior of the Americas, and later, some of the South Pacific islands.\n\nSince 1495, the French and English and, much later, the Dutch entered the race of exploration after learning of these exploits, defying the Iberian monopoly on maritime trade by searching for new routes, first to the western coasts of North and South America, through the first English and French expeditions (starting with the first expedition of John Cabot in 1497 to the north, in the service of England, followed by the French expeditions to South America and later to North America), and into the Pacific Ocean around South America, but eventually by following the Portuguese around Africa into the Indian Ocean; discovering Australia in 1606, New Zealand in 1642, and Hawaii in 1778. Meanwhile, from the 1580s to the 1640s, Russians explored and conquered almost the whole of Siberia, and Alaska in the 1730s.\nBetween the 12th and 15th centuries the European economy was transformed by the interconnecting of river and sea trade routes, causing Europe to become one of the world's most prosperous trading networks. \n\nBefore the 12th century the main obstacle to trade east of the Strait of Gibraltar was lack of commercial incentive rather than inadequate ship design. Economic growth of Spain followed the reconquest of parts of Muslim Spain and the siege of Lisbon (1147 AD). The decline of Fatimid Caliphate naval strength that started before the First Crusade helped the maritime Italian states, mainly Venice, Genoa and Pisa, dominate trade in the eastern Mediterranean, with Italian merchants becoming wealthy and politically influential. The Norman Conquest of England in the late 11th century allowed for peaceful trade on the North Sea. The Hanseatic League, a confederation of merchant guilds and their towns in northern Germany along the North Sea and Baltic Sea, was instrumental in commercial development of the region. In the 12th century the region of Flanders, Hainault and Braband produced the finest quality textiles in northern Europe, which encouraged merchants from Genoa and Venice to sail there directly. Nicolozzo Spinola made the first recorded direct voyage from Genoa to Flanders in 1277.\n\nTechnological advancements that were important to the Age of Exploration were the adoption of the magnetic compass and advances in ship design. \n\nThe compass was an addition to the ancient method of navigation based on sightings of the sun and stars. The compass had been used for navigation in China by the 11th century and was adopted by the Arab traders in the Indian Ocean. The compass spread to Europe by the late 12th or early 13th century. Use of the compass for navigation in the Indian Ocean was first mentioned in 1232. The first mention of use of the compass in Europe was in 1180. The Europeans used a \"dry\" compass, with a needle on a pivot. The compass card was also a European invention.\n\nShips grew in size, required smaller crews and were able to sail longer distances without stopping. This led to significant lower long distance shipping costs by the 14th century.\n\nThe Periplus of the Erythraean Sea, a document dating from 40-60 AD, describes a newly discovered route through the Red Sea to India, with descriptions of the markets in towns around Red Sea, Persian Gulf and the Indian Ocean, including along the eastern coast of Africa, which states \"for beyond these places the unexplored ocean curves around toward the west, and running along by the regions to the south of Aethiopia and Libya and Africa, it mingles with the western sea (possible reference to the Atlantic Ocean)\". European medieval knowledge about Asia beyond the reach of the Byzantine Empire was sourced in partial reports, often obscured by legends, dating back from the time of the conquests of Alexander the Great and his successors. \nAnother source was the Radhanite Jewish trade networks of merchants established as go-betweens between Europe and the Muslim world during the time of the Crusader states.\nIn 1154, the Arab geographer Muhammad al-Idrisi created a description of the world and a world map, the Tabula Rogeriana, at the court of King Roger II of Sicily, but still Africa was only partially known to either Christians, Genoese and Venetians, or the Arab seamen, and its southern extent unknown. There were reports of great African Sahara, but the factual knowledge was limited for the Europeans to the Mediterranean coasts and little else since the Arab blockade of North Africa precluded exploration inland. Knowledge about the Atlantic African coast was fragmented and derived mainly from old Greek and Roman maps based on Carthaginian knowledge, including the time of Roman exploration of Mauritania. The Red Sea was barely known and only trade links with the Maritime republics, the Republic of Venice especially, fostered collection of accurate maritime knowledge.\n\nIndian Ocean trade routes were sailed by Arab traders. Between 1405 and 1421, the Yongle Emperor of Ming China sponsored a series of long range tributary missions under the command of Zheng He (Cheng Ho). The fleets visited Arabia, East Africa, India, Maritime Southeast Asia and Thailand. But the journeys, reported by Ma Huan, a Muslim voyager and translator, were halted abruptly after the emperor's death and were not followed up, as the Chinese Ming Dynasty retreated in the \"haijin\", a policy of isolationism, having limited maritime trade.\n\nBy 1400 a Latin translation of Ptolemy's \"Geographia\" reached Italy coming from Constantinople. The rediscovery of Roman geographical knowledge was a revelation, both for mapmaking and worldview, although reinforcing the idea that the Indian Ocean was landlocked.\n\nA prelude to the Age of Discovery was a series of European expeditions crossing Eurasia by land in the late Middle Ages. Although the Mongols had threatened Europe with pillage and destruction, Mongol states also unified much of Eurasia and, from 1206 on, the \"Pax Mongolica\" allowed safe trade routes and communication lines stretching from the Middle East to China. A series of Europeans took advantage of these to explore eastwards. Most were Italians, as trade between Europe and the Middle East was controlled mainly by the Maritime republics. The close Italian links to the Levant raised great curiosity and commercial interest in countries which lay further east.\n\nThere are a few accounts of merchants from North Africa and the Mediterranean region who traded in the Indian Ocean in late medieval times.\n\nChristian embassies were sent as far as Karakorum during the Mongol invasions of the Levant, from which they gained a greater understanding of the world. The first of these travellers was Giovanni da Pian del Carpine, dispatched by Pope Innocent IV to the Great Khan, who journeyed to Mongolia and back from 1241 to 1247. About the same time, Russian prince Yaroslav of Vladimir, and subsequently his sons Alexander Nevsky and Andrey II of Vladimir, travelled to the Mongolian capital. Though having strong political implications, their journeys left no detailed accounts. Other travellers followed, like French André de Longjumeau and Flemish William of Rubruck, who reached China through Central Asia. Marco Polo, a Venetian merchant, dictated an account of journeys throughout Asia from 1271 to 1295, describing being a guest at the Yuan Dynasty court of Kublai Khan in \"Travels\", and it was read throughout Europe.\n\nIn 1291, in a first Atlantic exploration attempt, merchant brothers Vadino and Ugolino Vivaldi sailed from Genoa with two galleys but disappeared off the Moroccan coast, feeding the fears of oceanic travel. From 1325 to 1354, a Moroccan scholar from Tangier, Ibn Battuta, journeyed through North Africa, the Sahara desert, West Africa, Southern Europe, Eastern Europe, the Horn of Africa, the Middle East and Asia, having reached China. After returning, he dictated an account of his journeys to a scholar he met in Granada, the \"Rihla\" (\"The Journey\"), the unheralded source on his adventures. Between 1357 and 1371 a book of supposed travels compiled by John Mandeville acquired extraordinary popularity. Despite the unreliable and often fantastical nature of its accounts it was used as a reference for the East, Egypt, and the Levant in general, asserting the old belief that Jerusalem was the centre of the world.\n\nFollowing the period of Timurid relations with Europe, in 1439 Niccolò de' Conti published an account of his travels as a Muslim merchant to India and Southeast Asia and, later in 1466–1472, Russian merchant Afanasy Nikitin of Tver travelled to India, which he described in his book \"A Journey Beyond the Three Seas\".\n\nThese overland journeys had little immediate effect. The Mongol Empire collapsed almost as quickly as it formed and soon the route to the east became more difficult and dangerous. The Black Death of the 14th century also blocked travel and trade. The rise of the Ottoman Empire further limited the possibilities of European overland trade.\n\nThe Chinese had wide connections through trade in Asia and had been sailing to Arabia, East Africa, and Egypt since the Tang Dynasty (AD 618–907). Between 1405 and 1421 the third Ming emperor Yongle sponsored a series of long range tributary missions in the Indian Ocean under the command of admiral Zheng He (Cheng Ho).\n\nA large fleet of new junk ships was prepared for these international diplomatic expeditions. The largest of these junks—that the Chinese termed \"bao chuan\" (treasure ships)—may have measured 121 metres (400 feet) stem to stern, and thousands of sailors were involved. The first expedition departed in 1405. At least seven well-documented expeditions were launched, each bigger and more expensive than the last. The fleets visited Arabia, East Africa, India, Malay Archipelago and Thailand (at the time called Siam), exchanging goods along the way. They presented gifts of gold, silver, porcelain and silk; in return, received such novelties as ostriches, zebras, camels, ivory and giraffes. After the emperor's death, Zheng He led a final expedition departing from Nanking in 1431 and returning to Beijing in 1433. It is very likely that this last expedition reached as far as Madagascar. The travels were reported by Ma Huan, a Muslim voyager and translator who accompanied Zheng He on three of the seven expeditions, his account published as \"Ying-Yai Sheng-Lam\" (Overall Survey of the Ocean's Shores) (1433).\n\nThese long distance journeys were not followed up, as the Chinese Ming dynasty retreated in the \"haijin\", a policy of isolationism, having limited maritime trade. Travels were halted abruptly after the emperor's death, as the Chinese lost interest in what they termed barbarian lands turning inward, and successor emperors felt the expeditions were harmful to the Chinese state; Hongxi Emperor ended further expeditions and Xuande Emperor suppressed much of the information about Zheng He's voyages.\n\nFrom the 8th century until the 15th century, the Republic of Venice and neighbouring maritime republics held the monopoly of European trade with the Middle East. The silk and spice trade, involving spices, incense, herbs, drugs and opium, made these Mediterranean city-states phenomenally rich. Spices were among the most expensive and demanded products of the Middle Ages, as they were used in medieval medicine, religious rituals, cosmetics, perfumery, as well as food additives and preservatives. They were all imported from Asia and Africa.\n\nMuslim traders—mainly descendants of Arab sailors from Yemen and Oman—dominated maritime routes throughout the Indian Ocean, tapping source regions in the Far East and shipping for trading emporiums in India, mainly Kozhikode, westward to Ormus in the Persian Gulf and Jeddah in the Red Sea. From there, overland routes led to the Mediterranean coasts. Venetian merchants distributed the goods through Europe until the rise of the Ottoman Empire, that eventually led to the fall of Constantinople in 1453, barring Europeans from important combined-land-sea routes.\n\nForced to reduce their activities in the Black Sea, and at war with Venice, the Genoese had turned to North African trade of wheat, olive oil (valued also as an energy source) and a search for silver and gold. Europeans had a constant deficit in silver and gold, as coin only went one way: out, spent on eastern trade that was now cut off. Several European mines were exhausted, the lack of bullion leading to the development of a complex banking system to manage the risks in trade (the very first state bank, \"Banco di San Giorgio\", was founded in 1407 at Genoa). Sailing also into the ports of Bruges (Flanders) and England, Genoese communities were then established in Portugal, who profited from their enterprise and financial expertise.\n\nEuropean sailing had been primarily close to land cabotage, guided by portolan charts. These charts specified proven ocean routes guided by coastal landmarks: sailors departed from a known point, followed a compass heading, and tried to identify their location by its landmarks. For the first oceanic exploration Western Europeans used the compass, as well as progressive new advances in cartography and astronomy. Arab navigational tools like the astrolabe and quadrant were used for celestial navigation.\n\nIn 1297, with the Portuguese part of the reconquista completed, King Dinis of Portugal took personal interest in exports and in 1317 he made an agreement with Genoese merchant sailor Manuel Pessanha (Pesagno), appointing him first admiral of the Portuguese navy, with the goal of defending the country against Muslim pirate raids. Outbreaks of bubonic plague led to severe depopulation in the second half of the 14th century: only the sea offered alternatives, with most population settling in fishing and trading coastal areas. Between 1325 and 1357 Afonso IV of Portugal encouraged maritime commerce and ordered the first explorations. The Canary Islands, already known to the Genoese, were claimed as officially discovered under patronage of the Portuguese but in 1344 Castile disputed them, expanding their rivalry into the sea.\n\nTo ensure their monopoly on trade, Europeans (beginning with the Portuguese) attempted to install a mediterranean system of trade which used military might and intimidation to divert trade through ports they controlled; there it could be taxed. In 1415, Ceuta was conquered by the Portuguese aiming to control navigation of the African coast. Young prince Henry the Navigator was there and became aware of profit possibilities in the Trans-Saharan trade routes. For centuries slave and gold trade routes linking West Africa with the Mediterranean passed over the Western Sahara Desert, controlled by the Moors of North Africa.\n\nHenry wished to know how far Muslim territories in Africa extended, hoping to bypass them and trade directly with West Africa by sea, find allies in legendary Christian lands to the south like the long-lost Christian kingdom of Prester John and to probe whether it was possible to reach the Indies by sea, the source of the lucrative spice trade. He invested in sponsoring voyages down the coast of Mauritania, gathering a group of merchants, shipowners and stakeholders interested in new sea lanes. Soon the Atlantic islands of Madeira (1419) and the Azores (1427) were reached. In particular, they were discovered by voyages launched by the command of Prince Henry the Navigator. The expedition leader himself, who established settlements on the island of Madeira, was João Gonçalves Zarco.\n\nAt the time, Europeans did not know what lay beyond Cape Non (Cape Chaunar) on the African coast, and whether it was possible to return once it was crossed. Nautical myths warned of oceanic monsters or an edge of the world, but Prince Henry's navigation challenged such beliefs: starting in 1421, systematic sailing overcame it, reaching the difficult Cape Bojador that in 1434 one of Prince Henry's captains, Gil Eanes, finally passed.\n\nA major advance was the introduction of the caravel in the mid-15th century, a small ship able to sail windward more than any other in Europe at the time. Evolved from fishing ships designs, they were the first that could leave the coastal cabotage navigation and sail safely on the open Atlantic. For celestial navigation the Portuguese used the Ephemerides, which experienced a remarkable diffusion in the 15th century. These were astronomical charts plotting the location of the stars over a distinct period of time. Published in 1496 by the Jewish astronomer, astrologer, and mathematician Abraham Zacuto, the Almanach Perpetuum included some of these tables for the movements of stars. These tables revolutionized navigation, allowing the calculation of latitude. Exact longitude, however, remained elusive, and mariners struggled to determine it for centuries. Using the caravel, systematic exploration continued ever more southerly, advancing on average one degree a year. Senegal and Cape Verde Peninsula were reached in 1445 and in 1446, Álvaro Fernandes pushed on almost as far as present-day Sierra Leone.\n\nIn 1453 the fall of Constantinople to the hands of the Ottomans was a blow to Christendom and the established business relations linking with the east. In 1455 Pope Nicholas V issued the bull \"Romanus Pontifex\" reinforcing the previous \"Dum Diversas\" (1452), granting all lands and seas discovered beyond Cape Bojador to King Afonso V of Portugal and his successors, as well as trade and conquest against Muslims and pagans, initiating a \"mare clausum\" policy in the Atlantic. The king, who had been inquiring of Genoese experts about a seaway to India, commissioned the Fra Mauro world map, which arrived in Lisbon in 1459.\n\nIn 1456 Diogo Gomes reached the Cape Verde archipelago. In the next decade several captains at the service of Prince Henry – including the Genoese Antonio da Noli and Venetian Alvise Cadamosto – discovered the remaining islands which were occupied during the 15th century. The Gulf of Guinea would be reached in the 1460s.\n\nIn 1460 Pedro de Sintra reached Sierra Leone. Prince Henry died in November that year after which, given the meagre revenues, exploration was granted to Lisbon merchant Fernão Gomes in 1469, who in exchange for the monopoly of trade in the Gulf of Guinea had to explore each year for five years. With his sponsorship, explorers João de Santarém, Pedro Escobar, Lopo Gonçalves, Fernão do Pó, and Pedro de Sintra made it even beyond those goals. They reached the Southern Hemisphere and the islands of the Gulf of Guinea, including São Tomé and Príncipe and Elmina on the Gold Coast in 1471. (In the Southern Hemisphere, they used the Southern Cross as the reference for celestial navigation.) There, in what came to be called the \"Gold Coast\" in what is today Ghana, a thriving alluvial gold trade was found among the natives and Arab and Berber traders.\n\nIn 1478 (during the War of the Castilian Succession), near the coast at Elmina was fought a large battle between a Castilian armada of 35 caravels and a Portuguese fleet for hegemony of the Guinea trade (gold, slaves, ivory and melegueta pepper). The war ended with a Portuguese naval victory followed by the official recognition by the Catholic Monarchs of Portuguese sovereignty over most of the disputed West African territories embodied in the Treaty of Alcáçovas, 1479. (See entry on Elmina.) This was the first colonial war among European powers.\n\nIn 1481 the recently crowned João II decided to build São Jorge da Mina factory. In 1482 the Congo River was explored by Diogo Cão, who in 1486 continued to Cape Cross (modern Namibia).\n\nThe next crucial breakthrough was in 1488, when Bartolomeu Dias rounded the southern tip of Africa, which he named \"Cape of Storms\" (Cabo das Tormentas), anchoring at Mossel Bay and then sailing east as far as the mouth of the Great Fish River, proving that the Indian Ocean was accessible from the Atlantic. Simultaneously Pêro da Covilhã, sent out travelling secretly overland, had reached Ethiopia having collected important information about the Red Sea and Quenia coast, suggesting that a sea route to the Indies would soon be forthcoming. Soon the cape was renamed by king John II of Portugal the \"Cape of Good Hope\" (Cabo da Boa Esperança), because of the great optimism engendered by the possibility of a sea route to India, proving false the view that had existed since Ptolemy that the Indian Ocean was land-locked.\n\nBased on much later stories of the phantom island known as Bacalao and the carvings on Dighton Rock some have speculated that Portuguese explorer João Vaz Corte-Real discovered Newfoundland in 1473, but the sources cited are considered by mainstream historians to be unreliable and unconvincing.\n\nPortugal's neighbouring fellow Iberian rival, Castile, had begun to establish its rule over the Canary Islands, located off the west African coast, in 1402, but then became distracted by internal Iberian politics and the repelling of Islamic invasion attempts and raids through most of the 15th century. Only late in the century, following the unification of the crowns of Castile and Aragon and the completion of the \"reconquista\", did an emerging modern Spain become fully committed to the search for new trade routes overseas. The Crown of Aragon had been an important maritime potentate in the Mediterranean, controlling territories in eastern Spain, southwestern France, major islands like Sicily, Malta, and the Kingdom of Naples and Sardinia, with mainland possessions as far as Greece. In 1492 the joint rulers conquered the Moorish kingdom of Granada, which had been providing Castile with African goods through tribute, and decided to fund Christopher Columbus's expedition in the hope of bypassing Portugal's monopoly on west African sea routes, to reach \"the Indies\" (east and south Asia) by travelling west. Twice before, in 1485 and 1488, Columbus had presented the project to king John II of Portugal, who rejected it.\n\nOn the evening of 3 August 1492, Columbus departed from Palos de la Frontera with three ships; one larger carrack, \"Santa María\", nicknamed \"Gallega\" (\"the Galician\"), and two smaller caravels, \"Pinta\" (\"the Painted\") and \"Santa Clara\", nicknamed \"Niña\". Columbus first sailed to the Canary Islands, where he restocked for what turned out to be a five-week voyage across the ocean, crossing a section of the Atlantic that became known as the Sargasso Sea.\n\nLand was sighted on 12 October 1492, and Columbus called the island (now The Bahamas) \"San Salvador\", in what he thought to be the \"West Indies\". Columbus also explored the northeast coast of Cuba (landed on 28 October) and the northern coast of Hispaniola, by 5 December. He was received by the native cacique Guacanagari, who gave him permission to leave some of his men behind.\nOn the return, a storm forced him to dock in Lisbon, on 4 March 1493. After a week in Portugal, he set sail for Spain and on 15 March 1493 arrived in Barcelona, where he reported to Queen Isabella and King Ferdinand. Word of his discovery of new lands rapidly spread throughout Europe.\n\nColumbus and other Spanish explorers were initially disappointed with their discoveries—unlike Africa or Asia, the Caribbean islanders had little to trade with the Castilian ships. The islands thus became the focus of colonization efforts. It was not until the continent itself was explored that Spain found the wealth it had sought.\n\nShortly after Columbus's return from what would later be called the \"West Indies\", a division of influence became necessary to avoid conflict between the Spanish and Portuguese. On 4 May 1493, two months after Columbus's arrival, the Catholic Monarchs received a bull (\"Inter caetera\") from Pope Alexander VI stating that all lands west and south of a pole-to-pole line 100 leagues west and south of the Azores or the Cape Verde Islands should belong to Castile and, later, all mainlands and islands then belonging to India. It did not mention Portugal, which could not claim newly discovered lands east of the line.\n\nKing John II of Portugal was not pleased with the arrangement, feeling that it gave him far too little land—preventing him from reaching India, his main goal. He then negotiated directly with King Ferdinand and Queen Isabella of Spain to move the line west, and allowing him to claim newly discovered lands east of it.\n\nAn agreement was reached in 1494, with the Treaty of Tordesillas that divided the world between the two powers. In this treaty the Portuguese received everything outside Europe east of a line that ran 370 leagues west of the Cape Verde islands (already Portuguese), and the islands discovered by Christopher Columbus on his first voyage (claimed for Castile), named in the treaty as Cipangu and Antilia (Cuba and Hispaniola). This gave them control over Africa, Asia and eastern South America (Brazil). The Spanish (Castile) received everything west of this line. At the time of negotiation, the treaty split the known world of Atlantic islands roughly in half, with the dividing line about halfway between Portuguese Cape Verde and the Spanish discoveries in the Caribbean.\n\nPedro Álvares Cabral encountered in 1500 what is now known as the Brazilian coast, originally thought to be a large island. Since it was east of the dividing line, he claimed it for Portugal and this was respected by the Spanish. Portuguese ships sailed west into the Atlantic to get favourable winds for the journey to India, and this is where Cabral was headed on his journey, in a corridor the treaty was negotiated to protect. Some suspect the Portuguese had secretly discovered Brazil earlier, and this is why they had the line moved eastward and how Cabral found it, but there is no reliable evidence of this. Others suspect Duarte Pacheco Pereira secretly discovered Brazil in 1498, but this not considered credible by mainstream historians.\n\nLater the Spanish territory would prove to include huge areas of the continental mainland of North and South America, though Portuguese-controlled Brazil would expand across the line, and settlements by other European powers ignored the treaty.\n\nVery little of the divided area had actually been seen by Europeans, as it was only divided by a geographical definition rather than control on the ground. Columbus's first voyage in 1492 spurred maritime exploration and, from 1497, a number of explorers headed west.\n\nThat year John Cabot, also a commissioned Italian, got letters patent from King Henry VII of England. Sailing from Bristol, probably backed by the local Society of Merchant Venturers, Cabot crossed the Atlantic from a northerly latitude hoping the voyage to the \"West Indies\" would be shorter and made a landfall somewhere in North America, possibly Newfoundland.\nIn 1499 João Fernandes Lavrador was licensed by the King of Portugal and together with Pêro de Barcelos they first sighted Labrador, which was granted and named after him. After returning he possibly went to Bristol to sail in the name of England. Nearly at the same time, between 1499 and 1502 brothers Gaspar and Miguel Corte Real explored and named the coasts of Greenland and also Newfoundland. Both explorations are noted in the 1502 Cantino planisphere.\n\nIn 1497, newly crowned King Manuel I of Portugal sent an exploratory fleet eastwards, fulfilling his predecessor's project of finding a route to the Indies. In July 1499 news spread that the Portuguese had reached the \"true indies\", as a letter was dispatched by the Portuguese king to the Spanish Catholic Monarchs one day after the celebrated return of the fleet.\n\nThe third expedition by Columbus in 1498 was the beginning of the first successful Castilian (Spanish) colonization in the West Indies, on the island of Hispaniola. Despite growing doubts, Columbus refused to accept that he had not reached the Indies. During the voyage he discovered the mouth of the Orinoco River on the north coast of South America (now Venezuela) and thought that the huge quantity of fresh water coming from it could only be from a continental land mass, which he was certain was the Asian mainland.\n\nAs shipping between Seville and the West Indies grew, knowledge of the Caribbean islands, Central America and the northern coast of South America grew.\nOne of these Spanish fleets, that of Alonso de Ojeda and Amerigo Vespucci in 1499–1500, reached land at the coast of what is now Guyana, when the two explorers seem to have separated in opposite directions. Vespucci sailed southward, discovering the mouth of the Amazon River in July 1499, and reaching 6°S, in present-day north east Brazil, before turning around.\n\nIn the beginning of 1500 Vicente Yáñez Pinzon was blown off course by a storm and reached what is now the north east coast of Brazil on 26 January 1500, exploring as far south as the present-day state of Pernambuco. His fleet was the first to fully enter the Amazon River estuary which he named \"Río Santa María de la Mar Dulce\" (\"Saint Mary's River of the Freshwater Sea\"). However, the land was too far east for the Castilians to claim under the Treaty of Tordesillas, but the discovery created Castilian (\"Spanish\") interest, with a second voyage by Pinzon in 1508 (an expedition that coasted the northern coast to the Central American coastal mainland, in search of a passage to the East) and a voyage in 1515–16 by a navigator of the 1508 expedition, Juan Díaz de Solís. The 1515–16 expedition was spurred on by reports of Portuguese exploration of the region (see below). It ended when de Solís and some of his crew disappeared when exploring a River Plate river in a boat, but what it found re-ignited Spanish interest, and colonization began in 1531.\n\nIn April 1500, the second Portuguese India Armada, headed by Pedro Álvares Cabral, with a crew of expert captains, including Bartolomeu Dias and Nicolau Coelho, encountered the Brazilian coast as it swung westward in the Atlantic while performing a large \"volta do mar\" to avoid becalming in the Gulf of Guinea. On 21 April 1500 a mountain was seen and was named \"Monte Pascoal\", and on 22 April Cabral landed on the coast. On 25 April the entire fleet sailed into the harbour they named \"Porto Seguro\" (Port Secure). Cabral perceived that the new land lay east of the line of Tordesillas, and sent an envoy to Portugal with the discovery in letters, including the letter of Pero Vaz de Caminha. Believing the land to be an island, he named it Ilha de Vera Cruz (Island of the True Cross). Some historians have suggested that the Portuguese may have encountered the South American bulge earlier while sailing the \"volta do mar\", hence the insistence of John II in moving the line west of Tordesillas in 1494—so his landing in Brazil may not have been an accident; although John's motivation may have simply been to increase the chance of claiming new lands in the Atlantic. From the east coast, the fleet then turned eastward to resume the journey to the southern tip of Africa and India. Cabral was the first captain to touch four continents, leading the first expedition that connected and united Europe, Africa, the New World, and Asia.\n\nAt the invitation of King Manuel I of Portugal, Amerigo Vespucci—a Florentine who had been working for a branch of the Medici Bank in Seville since 1491, fitting oceanic expeditions and travelling twice to The Guianas with Juan de la Cosa in the service of Spain—participated as observer in these exploratory voyages to the east coast of South America. The expeditions became widely known in Europe after two accounts attributed to him, published between 1502 and 1504, suggested that the newly discovered lands were not the Indies but a \"New World\", the \"Mundus novus\", Latin title of a contemporary document based on Vespucci letters to Lorenzo di Pierfrancesco de' Medici, which had become widely popular in Europe. It was soon understood that Columbus had not reached Asia but had found a new continent, the Americas. The Americas were named in 1507 by cartographers Martin Waldseemüller and Matthias Ringmann, probably after Amerigo Vespucci.\n\nIn 1501–1502, one of these Portuguese expeditions, led by Gonçalo Coelho (and/or André Gonçalves or Gaspar de Lemos), sailed south along the coast of South America to the bay of present-day Rio de Janeiro. Amerigo Vespucci's account states that the expedition reached the latitude \"South Pole elevation 52° S\", in the \"cold\" latitudes of what is now southern Patagonia (possibly near the Strait), before turning back. Vespucci wrote that they headed toward the southwest and south, following \"a long, unbending coastline\" (apparently coincident with the southern South American coast). This seems controversial, since he changed part of his description in the subsequent letter, stating a shift, from about 32° S (Southern Brazil), to south-southeast, to open sea; maintaining, however, that they reached 50°/52° S (if it was by his own decision or by D. Manuel's censors who had to pressure him to alter his account, because he had revealed far too much to Lorenzo de' Medici and into the public domain, is unknown).\n\nIn 1503, Binot Paulmier de Gonneville, challenging the Portuguese policy of \"mare clausum\", led one of the earliest French Normand and Breton expeditions to Brazil. He intended to sail to the East Indies, but near the Cape of Good Hope his ship was diverted to west by a storm, and landed in the present day state of Santa Catarina (southern Brazil), on 5 January 1504.\nIn 1511–1512, Portuguese captains João de Lisboa and Estevão de Fróis reached the River Plate estuary in present-day Uruguay and Argentina, and went as far south as the present-day Gulf of San Matias at 42°S (recorded in the \"Newen Zeytung auss Pressilandt\" meaning \"New Tidings from the Land of Brazil\"). The expedition reached a cape extending north to south which they called Cape of \"Santa Maria\" (Punta del Este, keeping the name the Cape nearby); and after 40°S they found a \"Cape\" or \"a point or place extending into the sea\", and a \"Gulf\" (in June and July). After they had navigated for nearly to round the cape, they again sighted the continent on the other side, and steered towards the northwest, but a storm prevented them from making any headway. Driven away by the \"Tramontane\" or north wind, they retraced their course. Also gives the first news of the \"White King\" and the \"people of the mountains\" to the interior (the Inca Empire), and a gift, an ax of silver, obtained from the Charrúa natives on their return (\"to the coast or side of \"Brazil\"\"), and \"to West\" (along the coast and the River Plate estuary), and offered to King Manuel I. Christopher de Haro, a Flemish of Sephardic origin (one of the financiers of the expedition along with D. Nuno Manuel), who would serve the Spanish Crown after 1516, believed that the navigators had discovered a southern \"strait\" to west and Asia.\n\nIn 1519, an expedition sent by the Spanish Crown to find a way to Asia was led by the experienced Portuguese navigator Ferdinand Magellan. The fleet explored the rivers and bays as it charted the South American coast until it found a way to the Pacific Ocean through the Strait of Magellan.\n\nIn 1524–1525, Aleixo Garcia, a Portuguese conquistador (possibly a veteran of the Solís expedition of 1516), led a private expedition of a few shipwrecked Castilian and Portuguese adventurers, that recruited about 2000 Guaraní Indians. They explored the territories of present-day southern Brazil, Paraguay and Bolivia, using the native trail network, the \"Peabiru\". They were also the first Europeans to cross the Chaco and reach the outer territories of the Inca Empire on the hills of the Andes, near Sucre.\n\nProtected from direct Spanish competition by the treaty of Tordesillas, Portuguese eastward exploration and colonization continued apace. Twice, in 1485 and 1488, Portugal officially rejected Christopher Columbus's idea of reaching India by sailing westwards. King John II of Portugal's experts rejected it, for they held the opinion that Columbus's estimation of a travel distance of was undervalued, and in part because Bartolomeu Dias departed in 1487 trying the rounding of the southern tip of Africa, therefore they believed that sailing east would require a far shorter journey. Dias's return from the Cape of Good Hope in 1488, and Pêro da Covilhã's travel to Ethiopia overland indicated that the richness of the Indian Sea was accessible from the Atlantic. A long-overdue expedition was prepared.\n\nUnder new king Manuel I of Portugal, on July 1497 a small exploratory fleet of four ships and about 170 men left Lisbon under the command of Vasco da Gama. By December the fleet passed the Great Fish River—where Dias had turned back—and sailed into unknown waters. On 20 May 1498, they arrived at Calicut. The efforts of Vasco da Gama to get favourable trading conditions were hampered by the low value of their goods, compared with the valuable goods traded there. Two years and two days after departure, Gama and a survivor crew of 55 men returned in glory to Portugal as the first ships to sail directly from Europe to India.\n\nIn 1500, a second, larger fleet of thirteen ships and about 1500 men were sent to India. Under command of Pedro Álvares Cabral they made a first landfall on the Brazilian coast; later, in the Indian Ocean, one of Cabral's ships reached Madagascar (1501), which was partly explored by Tristão da Cunha in 1507; Mauritius was discovered in 1507, Socotra occupied in 1506. In the same year Lourenço de Almeida landed in Sri Lanka, the eastern island named \"Taprobane\" in remote accounts of Alexander the Great's and 4th-century BC Greek geographer Megasthenes. On the Asiatic mainland the first factories (trading-posts) were established at Kochi and Calicut (1501) and then Goa (1510).\n\nIn 1511, Afonso de Albuquerque conquered Malacca for Portugal, then the centre of Asian trade. East of Malacca, Albuquerque sent several diplomatic missions: Duarte Fernandes as the first European envoy to the Kingdom of Siam (modern Thailand).\n\nGetting to know the secret location of the so-called \"spice islands\"—the Maluku Islands, mainly the Banda, then the single world source of nutmeg and cloves, was the main purpose for the travels in the Indian sea—he sent an expedition led by António de Abreu to Banda (via Java and the Lesser Sunda Islands), where they were the first Europeans to arrive in early 1512, after taking a route through which they also reached first the islands of Buru, Ambon and Seram. From Banda Abreu returned to Malacca, while his vice-captain Francisco Serrão, after a separation forced by a shipwreck and heading north, reached once again Ambon and sank off Ternate, where he obtained a license to build a Portuguese fortress-factory: the Fort of São João Baptista de Ternate, which founded the Portuguese presence in the Malay Archipelago.\n\nIn May 1513 Jorge Álvares, one of the Portuguese envoys, reached China. Although he was the first to land on Lintin Island in the Pearl River Delta, it was Rafael Perestrello—a cousin of the famed Christopher Columbus—who became the first European explorer to land on the southern coast of mainland China and trade in Guangzhou in 1516, commanding a Portuguese vessel with a crew from a Malaysian junk that had sailed from Malacca. Fernão Pires de Andrade visited Canton in 1517 and opened up trade with China. The Portuguese were defeated by the Chinese in 1521 at the Battle of Tunmen and in 1522 at the Battle of Xicaowan, during which the Chinese captured Portuguese breech-loading swivel guns and reverse engineered the technology, calling them \"Folangji\" 佛郎機 (Frankish) guns, since the Portuguese were called \"Folangji\" by the Chinese. After a few decades, hostilities between the Portuguese and Chinese ceased and in 1557 the Chinese allowed the Portuguese to occupy Macau.\n\nTo enforce a trade monopoly, Muscat, and Hormuz in the Persian Gulf, were seized by Afonso de Albuquerque in 1507 and in 1515, respectively. He also entered into diplomatic relations with Persia. In 1513 while trying to conquer Aden, an expedition led by Albuquerque cruised the Red Sea inside the Bab al-Mandab, and sheltered at Kamaran island. In 1521, a force under António Correia conquered Bahrain, ushering in a period of almost eighty years of Portuguese rule of the Gulf archipelago. In the Red Sea, Massawa was the most northerly point frequented by the Portuguese until 1541, when a fleet under Estevão da Gama penetrated as far as Suez.\n\nIn 1513, about south of Acandí, in present-day Colombia, Spanish Vasco Núñez de Balboa heard unexpected news of an \"other sea\" rich in gold, which he received with great interest. With few resources and using information given by \"caciques\", he journeyed across the Isthmus of Panama with 190 Spaniards, a few native guides, and a pack of dogs.\n\nUsing a small brigantine and ten native canoes, they sailed along the coast and made landfalls. On September 6, the expedition was reinforced with 1,000 men, fought several battles, entered a dense jungle and climbed the mountain range along the Chucunaque River from where this \"other sea\" could be seen. Balboa went ahead and, before noon September 25, he saw in the horizon an undiscovered sea, becoming the first European to have seen or reached the Pacific from the New World. The expedition descended towards the shore for a short reconnaissance trip, thus becoming the first Europeans to navigate the Pacific Ocean off the coast of the New World. After travelling more than , Balboa named the bay where they ended up \"San Miguel\". He named the new sea \"Mar del Sur\" (South Sea), since they had travelled south to reach it. Balboa's main purpose in the expedition was the search for gold-rich kingdoms. To this end, he crossed through the lands of \"caciques\" to the islands, naming the largest one \"Isla Rica\" (Rich Island, today known as Isla del Rey). He named the entire group \"Archipiélago de las Perlas\", which they still keep today.\n\nIn 1515–1516, the Spanish fleet led by Juan Díaz de Solís sailed down the east coast of South America as far as Río de la Plata, which Solís named shortly before he died, while trying to find a passage to the \"South Sea\".\n\nAt the same time, the Portuguese in Southeast Asia made the first European report on the western Pacific, having identified Luzon east of Borneo and named its inhabitants the \"Luções\", in the modern Philippines.\n\nBy 1516 several Portuguese navigators, conflicting with King Manuel I of Portugal, had gathered in Seville to serve the newly crowned Charles I of Spain. Among them were explorers Diogo and Duarte Barbosa, Estêvão Gomes, João Serrão and Ferdinand Magellan, cartographers Jorge Reinel and Diogo Ribeiro, cosmographers Francisco and Ruy Faleiro and the Flemish merchant Christopher de Haro. Ferdinand Magellan—who had sailed in India for Portugal up to 1513, when the Maluku Islands were reached, kept contact with Francisco Serrão living there—developed the theory that the islands were in the Tordesillas Spanish area, supported on studies by Faleiro brothers.\n\nAware of the efforts of the Spanish to find a route to India by sailing west, Magellan presented his plan to Charles I of Spain. The king and Christopher de Haro financed Magellan's expedition. A fleet was put together, and Spanish navigators such as Juan Sebastián Elcano joined the enterprise. On August 10, 1519, they departed from Seville with a fleet of five ships—the flagship \"Trinidad\" under Magellan's command, \"San Antonio\", \"Concepcion\", \"Santiago\" and \"Victoria\", the first being a caravel, and all others rated as carracks or \"naus\"—with a crew of about 237 men from several nations, with the goal of reaching the Maluku Islands by travelling west, trying to reclaim it under Spain's economic and political sphere.\nThe fleet sailed further and further south, avoiding the Portuguese territories in Brazil, and became the first to reach Tierra del Fuego at the tip of the Americas. On October 21, starting in Cape Virgenes, they began an arduous trip through a 373-mile (600 km) long strait that Magellan named \"Estrecho de Todos los Santos\", the modern Strait of Magellan. On November 28, three ships entered the Pacific Ocean—then named \"Mar Pacífico\" because of its apparent stillness. The expedition managed to cross the Pacific. Magellan died in the battle of Mactan in the Philippines, leaving the Spaniard Juan Sebastián Elcano the task of completing the voyage, reaching the Spice Islands in 1521. On September 6, 1522 \"Victoria\" returned to Spain, thus completing the first circumnavigation of the globe. Of the men who set out on five ships, only 18 completed the circumnavigation and managed to return to Spain in this single vessel led by Elcano. Seventeen others arrived later in Spain: twelve captured by the Portuguese in Cape Verde some weeks earlier, and between 1525 and 1527, and five survivors of the \"Trinidad\". Antonio Pigafetta, a Venetian scholar and traveller who had asked to be on board and become a strict assistant of Magellan, kept an accurate journal that become the main source for much of what we know about this voyage.\n\nThis round-the-world voyage gave Spain valuable knowledge of the world and its oceans which later helped in the exploration and settlement of the Philippines. Although this was not a realistic alternative to the Portuguese route around Africa (the Strait of Magellan was too far south, and the Pacific Ocean too vast to cover in a single trip from Spain) successive Spanish expeditions used this information to explore the Pacific Ocean and discovered routes that opened up trade between Acapulco, New Spain (present-day Mexico) and Manila in the Philippines.\n\nSoon after Magellan's expedition, the Portuguese rushed to seize the surviving crew and built a fort in Ternate. In 1525, Charles I of Spain sent another expedition westward to colonize the Maluku Islands, claiming that they were in his zone of the Treaty of Tordesillas. The fleet of seven ships and 450 men was led by García Jofre de Loaísa and included the most notable Spanish navigators: Juan Sebastián Elcano and Loaísa, who lost their lives then, and the young Andrés de Urdaneta.\n\nNear the Strait of Magellan one of the ships was pushed south by a storm, reaching 56° S, where they thought seeing \"earth's end\": so Cape Horn was crossed for the first time. The expedition reached the islands with great difficulty, docking at Tidore. The conflict with the Portuguese established in nearby Ternate was inevitable, starting nearly a decade of skirmishes.\n\nAs there was not a set eastern limit to the Tordesillas line, both kingdoms organized meetings to resolve the issue. From 1524 to 1529 Portuguese and Spanish experts met at Badajoz-Elvas trying to find the exact location of the antimeridian of Tordesillas, which would divide the world into two equal hemispheres. Each crown appointed three astronomers and cartographers, three pilots and three mathematicians. Lopo Homem, Portuguese cartographer and cosmographer was in the board, along with cartographer Diogo Ribeiro on the Spanish delegation. The board met several times, without reaching an agreement: the knowledge at that time was insufficient for an accurate calculation of longitude, and each group gave the islands to its sovereign. The issue was settled only in 1529, after a long negotiation, with the signing of Treaty of Zaragoza, that attributed the Maluku Islands to Portugal and the Philippines to Spain.\n\nBetween 1525 and 1528 Portugal sent several expeditions around the Maluku Islands. Gomes de Sequeira and Diogo da Rocha were sent north by the governor of Ternate Jorge de Menezes, being the first Europeans to reach the Caroline Islands, which they named \"Islands de Sequeira\". In 1526, Jorge de Meneses docked on Biak and Waigeo islands, Papua New Guinea. Based on these explorations stands the theory of Portuguese discovery of Australia, one among several competing theories about the early discovery of Australia, supported by Australian historian Kenneth McIntyre, stating it was discovered by Cristóvão de Mendonça and Gomes de Sequeira.\n\nIn 1527 Hernán Cortés fitted out a fleet to find new lands in the \"South Sea\" (Pacific Ocean), asking his cousin Álvaro de Saavedra Cerón to take charge. On October 31 of 1527 Saavedra sailed from New Spain, crossing the Pacific and touring the north of New Guinea, then named \"Isla de Oro\". In October 1528 one of the vessels reached the Maluku Islands. In his attempt to return to New Spain he was diverted by the northeast trade winds, which threw him back, so he tried sailing back down, to the south. He returned to New Guinea and sailed northeast, where he sighted the Marshall Islands and the Admiralty Islands, but again was surprised by the winds, which brought him a third time to the Moluccas. This westbound return route was hard to find, but was eventually discovered by Andrés de Urdaneta in 1565.\n\nRumours of undiscovered islands northwest of Hispaniola had reached Spain by 1511 and king Ferdinand II of Aragon was interested in forestalling further exploration. While Portuguese were making huge gains in the Indian Ocean, the Spanish invested in exploring inland in search of gold and valuable resources. The members of these expeditions, the \"conquistadors\", came from a variety of backgrounds including artisans, merchants, clergy, lesser nobility and freed slaves. They usually supplied their own equipment in exchange for a share in profits, having no direct connection with the royal army, and often no professional military training or experience.\n\nIn the Americas the Spanish found a number of empires that were as large and populous as those in Europe. However, small bodies of \"conquistadors\", with large armies of Indigenous Americans groups, managed to conquer these states. During this time, pandemics of European disease such as smallpox devastated the indigenous populations. Once Spanish sovereignty was established, the Spanish focused on the extraction and export of gold and silver.\n\nIn 1512, to reward Juan Ponce de León for exploring Puerto Rico in 1508, king Ferdinand urged him to seek these new lands. He would become governor of discovered lands, but was to finance himself all exploration. With three ships and about 200 men, Léon set out from Puerto Rico in March 1513. In April they sighted land and named it \"La Florida\"—because it was Easter (Florida) season—believing it was an island, becoming credited as the first European to land in the continent. The arrival location has been disputed between St. Augustine, Ponce de León Inlet and Melbourne Beach. They headed south for further exploration and on April 8 encountered a current so strong that it pushed them backwards: this was the first encounter with the Gulf Stream that would soon become the primary route for eastbound ships leaving the Spanish Indies bound for Europe. They explored down the coast reaching Biscayne Bay, Dry Tortugas and then sailing southwest in an attempt to circle Cuba to return, reaching Grand Bahama on July.\n\nIn 1517 Cuba's governor Diego Velázquez de Cuéllar commissioned a fleet under the command of Hernández de Córdoba to explore the Yucatán peninsula. They reached the coast where Mayans invited them to land, but were attacked at night and only a remnant of the crew returned. Velázquez then commissioned another expedition led by his nephew Juan de Grijalva, who sailed south along the coast to Tabasco, part of the Aztec empire. In 1518 Velázquez gave the mayor of the capital of Cuba, Hernán Cortés, the command of an expedition to secure the interior of Mexico but, due to an old gripe between them, revoked the charter.\n\nIn February 1519 Cortés went ahead anyway, in an act of open mutiny. With about 11 ships, 500 men, 13 horses and a small number of cannons he landed in Yucatán, in Mayan territory, claiming the land for the Spanish crown. From Trinidad he proceeded to Tabasco and won a battle against the natives. Among the vanquished was La Malinche, his future mistress, who knew both (Aztec) Nahuatl language and Maya, becoming a valuable interpreter and counsellor. Through her, Cortés learned about the wealthy Aztec Empire.\n\nIn July his men took over Veracruz and he placed himself under direct orders of new king Charles I of Spain. There Cortés asked for a meeting with Aztec Emperor Montezuma II, who repeatedly refused. They headed to Tenochtitlan and on the way made alliances with several tribes. In October, accompanied by about 3,000 Tlaxcaltec they marched to Cholula, the second largest city in central Mexico. Either to instill fear upon the Aztecs waiting for him or (as he later claimed) wishing to make an example when he feared native treachery, they massacred thousands of unarmed members of the nobility gathered at the central plaza and partially burned the city.\n\nArriving in Tenochtitlan with a large army, on November 8 they were peacefully received by Moctezuma II, who deliberately let Cortés enter the heart of the Aztec Empire, hoping to know them better to crush them later. The emperor gave them lavish gifts in gold which enticed them to plunder vast amounts. In his letters to King Charles, Cortés claimed to have learned then that he was considered by the Aztecs to be either an emissary of the feathered serpent god Quetzalcoatl or Quetzalcoatl himself—a belief contested by a few modern historians. But he soon learned that his men on the coast had been attacked, and decided to hostage Moctezuma in his palace, demanding a ransom as tribute to King Charles.\n\nMeanwhile, Velasquez sent another expedition, led by Pánfilo de Narváez, to oppose Cortès, arriving in Mexico in April 1520 with 1,100 men. Cortés left 200 men in Tenochtitlan and took the rest to confront Narvaez, whom he overcame, convincing his men to join him. In Tenochtitlán one of Cortés's lieutenants committed a massacre in the Great Temple, triggering local rebellion. Cortés speedily returned, attempting the support of Moctezuma but the Aztec emperor was killed, possibly stoned by his subjects. The Spanish fled for the Tlaxcaltec during the \"Noche Triste\", where they managed a narrow escape while their back guard was massacred. Much of the treasure looted was lost during this panicked escape. After a battle in Otumba they reached Tlaxcala, having lost 870 men. Having prevailed with the assistance of allies and reinforcements from Cuba, Cortés besieged Tenochtitlán and captured its ruler Cuauhtémoc in August 1521. As the Aztec Empire ended he claimed the city for Spain, renaming it Mexico City.\n\nA first attempt to explore western South America was undertaken in 1522 by Pascual de Andagoya. Native South Americans told him about a gold-rich territory on a river called Pirú. Having reached San Juan River (Colombia), Andagoya fell ill and returned to Panama, where he spread news about \"Pirú\" as the legendary El Dorado. These, along with the accounts of success of Hernán Cortés, caught the attention of Pizarro.\n\nFrancisco Pizarro had accompanied Balboa in the crossing of the Isthmus of Panama. In 1524 he formed a partnership with priest Hernando de Luque and soldier Diego de Almagro to explore the south, agreeing to divide the profits. They dubbed the enterprise the \"Empresa del Levante\": Pizarro would command, Almagro would provide military and food supplies, and Luque would be in charge of finances and additional provisions.\n\nOn 13 September 1524, the first of three expeditions left to conquer Peru with about 80 men and 40 horses. The expedition was a failure, reaching no farther than Colombia before succumbing to bad weather, hunger and skirmishes with hostile locals, where Almagro lost an eye. The place names bestowed along their route, \"Puerto deseado\" (desired port), \"Puerto del hambre\" (port of hunger) and \"Puerto quemado\" (burned port), attest to the difficulties of their journey. Two years later they began a second expedition with reluctant permission from the Governor of Panama. In August 1526, they left with two ships, 160 men and several horses. Upon reaching San Juan River they separated, Pizarro staying to explore the swampy coasts and Almagro sent back for reinforcements. Pizarro's main pilot sailed south and, after crossing the equator, captured a raft from Tumbes. To his surprise, it carried textiles, ceramic and much-desired gold, silver, and emeralds, becoming the central focus of the expedition. Soon Almagro joined with reinforcements and they resumed. After a difficult voyage facing strong winds and currents, they reached Atacames where they found a large native population under Inca rule, but they did not land.\n\nPizarro remained safe near the coast, while Almagro and Luque went back for reinforcements with proof of the rumoured gold. The new governor outright rejected a third expedition and ordered two ships to bring everyone back to Panama. Almagro and Luque grasped the opportunity to join Pizarro. When they arrived at the \"Isla de Gallo\", Pizarro drew a line in the sand, saying: \"There lies Peru with its riches; Here, Panama and its poverty. Choose, each man, what best becomes a brave Castilian.\" Thirteen men decided to stay and became known as \"The Famous Thirteen\". They headed for \"La Isla Gorgona\", where they remained for seven months before the arrival of provisions.\n\nThey decided to sail south and, by April 1528, reached the northwestern Peruvian Tumbes Region and were warmly received by local \"Tumpis\". Two of Pizarro's men reported incredible riches, including gold and silver decorations around the chief's house. They saw for the first time a llama which Pizarro called \"little camels\". The natives named the Spanish \"Children of the Sun\" for their fair complexion and brilliant armours. They decided then to return to Panama to prepare a final expedition. Before leaving they sailed south through territories they named such as Cabo Blanco, port of Payta, Sechura, Punta de Aguja, Santa Cruz, and Trujillo, reaching the ninth degree south.\n\nIn the spring of 1528 Pizarro sailed for Spain, where he had an interview with king Charles I. The king heard of his expeditions in lands rich in gold and silver and promised to support him. The \"Capitulación de Toledo\" authorized Pizarro to proceed with the conquest of Peru. Pizarro was then able to convince many friends and relatives to join: his brothers Hernándo Pizarro, Juan Pizarro, Gonzalo Pizarro and also Francisco de Orellana, who would later explore the Amazon River, as well as his cousin Pedro Pizarro.\n\nPizarro's third and final expedition left Panama for Peru on 27 December 1530. With three ships and one hundred and eighty men they landed near Ecuador and sailed to Tumbes, finding the place destroyed. They entered the interior and established the first Spanish settlement in Peru, San Miguel de Piura. One of the men returned with an Incan envoy and an invitation for a meeting. Since the last meeting, the Inca had begun a civil war and Atahualpa had been resting in northern Peru following the defeat of his brother Huáscar. After marching for two months, they approached Atahualpa. He refused the Spanish, however, saying he would \"be no man's tributary.\" There were fewer than 200 Spanish to his 80,000 soldiers, but Pizarro attacked and won the Incan army in the Battle of Cajamarca, taking Atahualpa captive at the so-called ransom room. Despite fulfilling his promise of filling one room with gold and two with silver, he was convicted for killing his brother and plotting against Pizarro, and was executed.\n\nIn 1533, Pizarro invaded Cuzco with indigenous troops and wrote to King Charles I: \"This city is the greatest and the finest ever seen in this country or anywhere in the Indies ... it is so beautiful and has such fine buildings that it would be remarkable even in Spain.\" After the Spanish had sealed the conquest of Peru, Jauja in fertile Mantaro Valley was established as Peru's provisional capital, but it was too far up in the mountains, and Pizarro founded the city of Lima on 18 January 1535, which Pizarro considered one of the most important acts in his life.\n\nIn 1543 three Portuguese traders accidentally became the first Westerners to reach and trade with Japan. According to Fernão Mendes Pinto, who claimed to be in this journey, they arrived at Tanegashima, where the locals were impressed by firearms that would be immediately made by the Japanese on a large scale.\n\nThe Spanish conquest of the Philippines was ordered by Philip II of Spain, and Andrés de Urdaneta was the designated commander. Urdaneta agreed to accompany the expedition but refused to command and Miguel López de Legazpi was appointed instead. The expedition set sail on November 1564. After spending some time on the islands, Legazpi sent Urdaneta back to find a better return route. Urdaneta set sail from San Miguel on the island of Cebu on June 1, 1565, but was obliged to sail as far as 38 degrees North latitude to obtain favourable winds.\nHe reasoned that the trade winds of the Pacific might move in a gyre as the Atlantic winds did. If in the Atlantic, ships made the \"Volta do mar\" to pick up winds that would bring them back from Madeira, then, he reasoned, by sailing far to the north before heading east, he would pick up trade winds to bring him back to North America. His hunch paid off, and he hit the coast near Cape Mendocino, California, then followed the coast south. The ship reached the port of Acapulco, on October 8, 1565, having travelled in 130 days. Fourteen of his crew died; only Urdaneta and Felipe de Salcedo, nephew of López de Legazpi, had strength enough to cast the anchors.\n\nThus, a cross-Pacific Spanish route was established, between Mexico and the Philippines. For a long time these routes were used by the Manila galleons, thereby creating a trade link joining China, the Americas, and Europe via the combined trans-Pacific and trans-Atlantic routes.\n\nNations outside Iberia refused to acknowledge the Treaty of Tordesillas. France, the Netherlands and England each had a long maritime tradition and had been engaging in privateering. Despite Iberian protections, the new technologies and maps soon made their way north.\n\nIn 1568 the Dutch rebelled against the rule of Philip II of Spain leading to the Eighty Years' War. War between England and Spain also broke out. In 1580 Philip II became King of Portugal, as heir to the Crown. The combined empires were simply too big to go unchallenged by European rivals.\n\nPhilip's troops conquered the important trading cities of Bruges and Ghent. Antwerp, then the most important port in the world, fell in 1585. The Protestant population was given two years to settle affairs before leaving the city. Many settled in Amsterdam. Those were mainly skilled craftsmen, rich merchants of the port cities and refugees that fled religious persecution, particularly Sephardi Jews from Portugal and Spain and, later, the Huguenots from France. The Pilgrim Fathers also spent time there before going to the New World. This mass immigration was an important driving force: a small port in 1585, Amsterdam quickly transformed into one of the most important commercial centres in the world. After the defeat of the Spanish Armada in 1588 there was a huge expansion of maritime trade even though the defeat of the English Armada would confirm the naval supremacy of the Spanish navy over the emergent competitors.\n\nThe emergence of Dutch maritime power was swift and remarkable: for years Dutch sailors had participated in Portuguese voyages to the east, as able seafarers and keen mapmakers. In 1592, Cornelis de Houtman was sent by Dutch merchants to Lisbon, to gather as much information as he could about the Spice Islands. In 1595, merchant and explorer Jan Huyghen van Linschoten, having travelled widely in the Indian Ocean at the service of the Portuguese, published a travel report in Amsterdam, the \"Reys-gheschrift vande navigatien der Portugaloysers in Orienten\" (\"Report of a journey through the navigations of the Portuguese in the East\"). This included vast directions on how to navigate between Portugal and the East Indies and to Japan. That same year Houtman followed this directions in the Dutch first exploratory travel that discovered a new sea route, sailing directly from Madagascar to Sunda Strait in Indonesia and signing a treaty with the Banten Sultan.\n\nDutch and British interest, fed on new information, led to a movement of commercial expansion, and the foundation of English (1600), and Dutch (1602) chartered companies. Dutch, French, and English sent ships which flouted the Portuguese monopoly, concentrated mostly on the coastal areas, which proved unable to defend against such a vast and dispersed venture.\n\nThe 1497 English expedition led by Italian Venetian John Cabot (Giovanni Caboto) was the first of a series of French and English missions exploring North America. Spain put limited efforts into exploring the northern part of the Americas, as its resources were concentrated in Central and South America where more wealth had been found. These expeditions were hoping to find an oceanic Northwest Passage to Asian trade. This was never discovered, but other possibilities were found, and in the early 17th century colonists from a number of Northern European states began to settle on the east coast of North America. In 1520–1521 the Portuguese João Álvares Fagundes, accompanied by couples of mainland Portugal and the Azores, explored Newfoundland and Nova Scotia (possibly reaching the Bay of Fundy on the Minas Basin), and established a fishing colony on the Cape Breton Island, that would last until at least the 1570s or near the end of the century.\n\nIn 1524, Italian Giovanni da Verrazzano sailed at the behest of Francis I of France, who was motivated by indignation over the division of the world between Portuguese and Spanish. Verrazzano explored the Atlantic Coast of North America, from South Carolina to Newfoundland, and was the first recorded European to visit what would later become the Virginia Colony and the United States. In the same year Estevão Gomes, a Portuguese cartographer who had sailed in Ferdinand Magellan's fleet, explored Nova Scotia, sailing South through Maine, where he entered New York Harbor, the Hudson River and eventually reached Florida in August 1525. As a result of his expedition, the 1529 Diogo Ribeiro world map outlines the East coast of North America almost perfectly. From 1534 to 1536, French explorer Jacques Cartier, believed to have accompanied Verrazzano to Nova Scotia and Brazil, was the first European to travel inland in North America, describing the Gulf of Saint Lawrence, which he named \"The Country of Canadas\", after Iroquois names, claiming what is now Canada for Francis I of France.\n\nEuropeans explored the Pacific Coast beginning in the mid-16th century. Francisco de Ulloa explored the Pacific coast of present-day Mexico including the Gulf of California, proving that Baja California was a peninsula. Despite his discoveries, the myth persisted in Europe that California was an island. His account provided the first recorded use of the name \"California\". João Rodrigues Cabrilho, a Portuguese navigator sailing for the Spanish Crown, was the first European to set foot in California, landing on September 28, 1542 on the shores of San Diego Bay and claiming California for Spain. He also landed on San Miguel, one of the Channel Islands, and continued as far as Point Reyes. After his death the crew continued exploring as far north as Oregon.\n\nThe English naval commander Francis Drake sailed along the coast in 1579 somewhere north of Cabrillo's landing site—the actual location of Drake's landing was secret and is still undetermined\n—and claimed the land for England, calling it Nova Albion. The term \"Nova Albion\" was therefore used on many European maps to designate territory north of the Spanish settlements.\n\nBetween 1609 and 1611, after several voyages on behalf of English merchants to explore a prospective Northeast Passage to India, Kingdom of England's Henry Hudson, under the auspices of the Dutch East India Company (VOC), explored the region around present-day New York City, while looking for a western route to Asia. He explored the Hudson River and laid the foundation for Dutch colonization of the region. Hudson's final expedition ranged farther north in search of the Northwest Passage, leading to his discovery of the Hudson Strait and Hudson Bay. After wintering in the James Bay, Hudson tried to press on with his voyage in the spring of 1611, but his crew mutinied and they cast him adrift.\n\nFrance, the Netherlands, and England were left without a sea route to Asia, either via Africa or South America. When it became apparent that there was no route through the heart of the Americas, attention turned to the possibility of a passage through northern waters, which English called the Northwest Passage. The desire to establish such a route motivated much of the European exploration of both coasts of North America and in Russia. In Russia the idea of a possible seaway connecting the Atlantic and the Pacific was first put forward by the diplomat Gerasimov in 1525, although Russian settlers on the coast of the White Sea, the Pomors, had been exploring parts of the route as early as the 11th century.\n\nIn 1553 English explorer Hugh Willoughby with chief pilot Richard Chancellor were sent out with three vessels in search of a passage by London's Company of Merchant Adventurers to New Lands. During the voyage across the Barents Sea, Willoughby thought he saw islands to the north, and islands called Willoughby's Land were shown on maps published by Plancius and Mercator into the 1640s. The vessels were separated by \"terrible whirlwinds\" in the Norwegian Sea and Willoughby sailed into a bay near the present border between Finland and Russia. His ships with the frozen crews, including Captain Willoughby and his journal, were found by Russian fishermen a year later. Richard Chancellor was able to drop anchor in the White Sea and trudge his way overland to Moscow and Ivan the Terrible's Court, opening trade with Russia and the Company of Merchant Adventurers became the Muscovy Company.\n\n5 June 1594, Dutch cartographer Willem Barentsz departed from Texel in a fleet of three ships to enter the Kara Sea, with the hopes of finding the Northeast Passage above Siberia. At Williams Island the crew encountered a polar bear for the first time. They managed to bring it on board, but the bear rampaged and was killed. Barentsz reached the west coast of Novaya Zemlya and followed it northward, before being forced to turn back in the face of large icebergs.\n\nThe following year, Prince Maurice of Orange named him chief pilot of a new expedition of six ships, loaded with merchant wares that the Dutch hoped to trade with China. The party came across Samoyed \"wild men\" but eventually turned back upon discovering the Kara Sea frozen. In 1596, the States-General offered a high reward for anybody who \"successfully\" navigated the Northeast Passage. The Town Council of Amsterdam purchased and outfitted two small ships, captained by Jan Rijp and Jacob van Heemskerk, to search for the elusive channel, under the command of Barents. They set off on May, and on June discovered Bear Island and Spitsbergen, sighting its northwest coast. They saw a large bay, later called Raudfjorden and entered Magdalenefjorden, which they named \"Tusk Bay\", sailing into the northern entrance of Forlandsundet, which they called \"Keerwyck\", but were forced to turn back because of a shoal. On 28 June they rounded the northern point of Prins Karls Forland, which they named \"Vogelhoek\", on account of the large number of birds, and sailed south, passing Isfjorden and Bellsund, which were labelled on Barentsz's chart as \"Grooten Inwyck\" and \"Inwyck\".\n\nThe ships once again reached Bear Island on 1 July, which led to a disagreement. They parted ways, with Barentsz continuing northeast, while Rijp headed north. Barentsz reached Novaya Zemlya and, to avoid becoming entrapped in ice, headed for the Vaigatch Strait but became stuck within the icebergs and floes. Stranded, the 16-man crew was forced to spend the winter on the ice. The crew used lumber from their ship to build a lodge they called \"Het Behouden Huys\" (The Kept House). Dealing with extreme cold, they used the merchant fabrics to make additional blankets and clothing and caught Arctic foxes in primitive traps, as well as polar bears. When June arrived, and the ice had still not loosened its grip on the ship, scurvy-ridden survivors took two small boats out into the sea. Barentsz died at sea on 20 June 1597, while studying charts. It took seven more weeks for the boats to reach Kola where they were rescued by a Russian merchant vessel. Only 12 crewmen remained, reaching Amsterdam in November. Two of Barentsz' crewmembers later published their journals, Jan Huyghen van Linschoten, who had accompanied him on the first two voyages, and Gerrit de Veer who had acted as the ship's carpenter on the last.\n\nIn 1608, Henry Hudson made a second attempt, trying to go across the top of Russia. He made it to Novaya Zemlya but was forced to turn back. Between 1609 and 1611, Hudson, after several voyages on behalf of English merchants to explore a prospective Northern Sea Route to India, explored the region around modern New York City while looking for a western route to Asia under the auspices of the Dutch East India Company (VOC).\n\n\"Terra Australis Ignota\" (Latin, \"the unknown land of the south\") was a hypothetical continent appearing on European maps from the 15th to the 18th centuries, with roots in a notion introduced by Aristotle. It was depicted on the mid-16th-century Dieppe maps, where its coastline appeared just south of the islands of the East Indies; it was often elaborately charted, with a wealth of fictitious detail. The discoveries reduced the area where the continent could be found; however, many cartographers held to Aristotle's opinion, like Gerardus Mercator (1569) and Alexander Dalrymple even so late as 1767 argued for its existence, with such arguments as that there should be a large landmass in the Southern Hemisphere as a counterweight to the known landmasses in the Northern Hemisphere. As new lands were discovered, they were often assumed to be parts of this hypothetical continent.\n\nJuan Fernandez, sailing from Chile in 1576, claimed he had discovered the Southern Continent. Luis Váez de Torres, a Galician navigator working for the Spanish Crown, proved the existence of a passage south of New Guinea, now known as Torres Strait. Pedro Fernandes de Queirós, a Portuguese navigator sailing for the Spanish Crown, saw a large island south of New Guinea in 1606, which he named La Australia del Espiritu Santo. He represented this to the King of Spain as the Terra Australis incognita. In fact, it was not Australia but an island in present-day Vanuatu.\n\nDutch navigator and colonial governor, Willem Janszoon sailed from the Netherlands for the East Indies for the third time on December 18, 1603, as captain of the \"Duyfken\" (or \"Duijfken\", meaning \"Little Dove\"), one of twelve ships of the great fleet of Steven van der Hagen. Once in the Indies, Janszoon was sent to search for other outlets of trade, particularly in \"the great land of Nova Guinea and other East and Southlands.\" On November 18, 1605, the \"Duyfken\" sailed from Bantam to the coast of western New Guinea. Janszoon then crossed the eastern end of the Arafura Sea, without seeing the Torres Strait, into the Gulf of Carpentaria. On February 26, 1606, he made landfall at the Pennefather River on the western shore of Cape York in Queensland, near the modern town of Weipa. This is the first recorded European landfall on the Australian continent. Janszoon proceeded to chart some of the coastline, which he thought was a southerly extension of New Guinea. In 1615, Jacob le Maire and Willem Schouten's rounding of Cape Horn proved that Tierra del Fuego was a relatively small island.\n\nIn 1642–1644 Abel Tasman, also a Dutch explorer and merchant in the service of the VOC, circumnavigated New Holland proving that Australia was not part of the mythical southern continent. He was the first known European expedition to reach the islands of Van Diemen's Land (now Tasmania) and New Zealand and to sight the Fiji islands, which he did in 1643. Tasman, his navigator Visscher, and his merchant Gilsemans also mapped substantial portions of Australia, New Zealand and the Pacific Islands.\n\nIn the mid-16th century the Tsardom of Russia conquered the Tatar khanates of Kazan and Astrakhan, thus annexing the entire Volga Region and opening the way to the Ural Mountains. The colonization of the new easternmost lands of Russia and further onslaught eastward was led by the rich merchants Stroganovs. Tsar Ivan IV granted vast estates near the Urals as well as tax privileges to Anikey Stroganov, who organized large scale migration to these lands. Stroganovs developed farming, hunting, saltworks, fishing, and ore mining on the Urals and established trade with Siberian tribes.\n\nAround 1577, Semyon Stroganov and other sons of Anikey Stroganov hired a Cossack leader called Yermak to protect their lands from the attacks of Siberian Khan Kuchum. By 1580 Stroganovs and Yermak came up with the idea of the military expedition to Siberia, in order to fight Kuchum in his own land. In 1581 Yermak began his voyage into the depths of Siberia. After a few victories over the khan's army, Yermak's people defeated the main forces of Kuchum on Irtysh River in a 3-day Battle of Chuvash Cape in 1582. The remains of the khan's army retreated to the steppes, and thus Yermak captured the Siberia Khanate, including its capital Qashliq near modern Tobolsk. Kuchum still was strong and suddenly attacked Yermak in 1585 in the dead of night, killing most of his people. Yermak was wounded and tried to swim across the Wagay River (Irtysh's tributary), but drowned under the weight of his own chain mail. The Cossacks had to withdraw from Siberia completely, but thanks to Yermak's having explored all the main river routes in West Siberia, Russians successfully reclaimed all his conquests just several years later.\nIn the early 17th century the eastward movement of Russians was slowed by the internal problems in the country during the Time of Troubles. However, very soon the exploration and colonization of the huge territories of Siberia was resumed, led mostly by Cossacks hunting for valuable furs and ivory. While Cossacks came from the Southern Urals, another wave of Russians came by the Arctic Ocean. These were Pomors from the Russian North, who already had been making fur trade with Mangazeya in the north of the Western Siberia for quite a long time. In 1607 the settlement of Turukhansk was founded on the northern Yenisei River, near the mouth of Lower Tunguska, and in 1619 Yeniseysky ostrog was founded on the mid-Yenisei at the mouth of the Upper Tunguska.\n\nBetween 1620 and 1624 a group of fur hunters led by Demid Pyanda left Turukhansk and explored some of the Lower Tunguska, wintering in the proximity of the Vilyuy and Lena rivers. According to later legendary accounts (folktales collected a century after the fact), Pyanda discovered the Lena River. He allegedly explored some of its length, reaching as far as central Yakutia. He returned up the Lena until it became too rocky and shallow, and portaged to the Angara River. In this way, Pyanda may have become the first Russian to meet Yakuts and Buryats. He built new boats and explored some of the Angara, finally reaching Yeniseysk and discovering that the Angara (a Buryat name) and Upper Tunguska (Verkhnyaya Tunguska, as initially known by Russians) are one and the same river.\n\nIn 1627 Pyotr Beketov was appointed Yenisei voevoda in Siberia. He successfully carried out the voyage to collect taxes from Zabaykalye Buryats, becoming the first Russian to step in Buryatia. He founded the first Russian settlement there, Rybinsky ostrog. Beketov was sent to the Lena River in 1631, where in 1632 he founded Yakutsk and sent his Cossacks to explore the Aldan and farther down the Lena, to found new fortresses, and to collect taxes.\n\nYakutsk soon turned into a major starting point for further Russian expeditions eastward, southward and northward. Maksim Perfilyev, who earlier had been one of the founders of Yeniseysk, founded Bratsky ostrog on the Angara in 1631, and in 1638 he became the first Russian to step into Transbaikalia, travelling there from Yakutsk.\nIn 1643 Kurbat Ivanov led a group of Cossacks from Yakutsk to the south of the Baikal Mountains and discovered Lake Baikal, visiting its Olkhon Island. Later Ivanov made the first chart and description of Baikal.\n\nIn 1639 a group of explorers led by Ivan Moskvitin became the first Russians to reach the Pacific Ocean and to discover the Sea of Okhotsk, having built a winter camp on its shore at the Ulya River mouth. The Cossacks learned from the locals about the large Amur River far to the south. In 1640 they apparently sailed south, explored the south-eastern shores of the Okhotsk Sea, perhaps reaching the mouth of the Amur River and possibly discovering the Shantar Islands on their way back. Based on Moskvitin's account, Kurbat Ivanov drew the first Russian map of the Far East in 1642.\n\nIn 1643, Vasily Poyarkov crossed the Stanovoy Range and reached the upper Zeya River in the country of the Daurs, who were paying tribute to the Manchu Chinese. After wintering, in 1644 Poyarkov pushed down the Zeya and became the first Russian to reach the Amur River. He sailed down the Amur and finally discovered the mouth of that great river from land. Since his Cossacks provoked the enmity of the locals behind, Poyarkov chose a different way back. They built boats and in 1645 sailed along the Sea of Okhotsk coast to the Ulya River and spent the next winter in the huts that had been built by Ivan Moskvitin six years earlier. In 1646 they returned to Yakutsk.\nIn 1644 Mikhail Stadukhin discovered the Kolyma River and founded Srednekolymsk. A merchant named Fedot Alekseyev Popov organized a further expedition eastward, and Semyon Dezhnyov became a captain of one of the kochi. In 1648 they sailed from Srednekolymsk down to the Arctic and after some time they rounded Cape Dezhnyov, thus becoming the first explorers to pass through the Bering Strait and to discover Chukotka and the Bering Sea. All their kochi and most of their men (including Popov himself) were lost in storms and clashes with the natives. A small group led by Dezhnyov reached the mouth of the Anadyr River and sailed up it in 1649, having built new boats from the wreckage. They founded Anadyrsk and were stranded there, until Stadukhin found them, coming from Kolyma by land. Subsequently, Stadukhin set off south in 1651 and discovered Penzhin Bay on the northern coast of the Okhotsk Sea. He also may have explored the western shores of Kamchatka.\n\nIn 1649–50 Yerofey Khabarov became the second Russian to explore the Amur River. Through Olyokma, Tungur and Shilka Rivers he reached Amur (Dauria), returned to Yakutsk and then back to Amur with a larger force in 1650–53. This time he was met with armed resistance. He built winter quarters at Albazin, then sailed down Amur and found Achansk, which preceded the present-day Khabarovsk, defeating or evading large armies of Daurian Manchu Chinese and Koreans on his way. He charted the Amur in his \"Draft of the Amur river\". Subsequently, Russians held on to the Amur Region until 1689, when by the Treaty of Nerchinsk this land was assigned to Chinese Empire (it was returned, however, by the Treaty of Aigun in 1858).\n\nIn 1659–65 Kurbat Ivanov was the next head of Anadyrsky ostrog after Semyon Dezhnyov. In 1660 he sailed from Anadyr Bay to Cape Dezhnyov. Atop his earlier pioneering charts, Ivanov is credited with creation of the early map of Chukotka and Bering Strait, which was the first to show on paper (very schematically) the yet undiscovered Wrangel Island, both Diomede Islands and Alaska, based on the data collected from the natives of Chukotka.\n\nSo, by the mid-17th century, Russians established the borders of their country close to modern ones, and explored almost the whole of Siberia, except the eastern Kamchatka and some regions north of the Arctic Circle. The conquest of Kamchatka later would be achieved in the early 1700s by Vladimir Atlasov, while the discovery of the Arctic coastline and Alaska would be completed by the Great Northern Expedition in 1733–1743.\n\nEuropean overseas expansion led to the contact between the Old and New Worlds producing the Columbian Exchange, named after Columbus. It involved the transfer of goods unique to one hemisphere to another. Europeans brought cattle, horses, and sheep to the New World, and from the New World Europeans received tobacco, potatoes and maize. Other items becoming important in global trade were the sugarcane and cotton crops of the Americas, and the gold and silver brought from the Americas not only to Europe but elsewhere in the Old World.\n\nThe new trans-oceanic links and their domination by the European powers led to the Age of Imperialism, where European colonial powers came to control most of the planet. The European appetite for trade, commodities, empire and slaves greatly affected many other areas of the world. Spain participated in the destruction of aggressive empires in the Americas, only to substitute its own, and forcibly replaced the original religions. The pattern of territorial aggression was repeated by other European empires, most notably the Dutch, Russian, French and British. Christianity replaced older \"pagan\" rituals, as were new languages, political and sexual cultures, and in some areas like North America, Australia, New Zealand and Argentina, the indigenous peoples were abused and driven off most of their lands, being reduced to small, dependent minorities.\n\nSimilarly, in coastal Africa, local states supplied the appetite of European slave traders, changing the complexion of coastal African states and fundamentally altering the nature of African slavery, causing impacts on societies and economies deep inland. (See Atlantic slave trade).\n\nAboriginal peoples were living in North America at this time and still do today. There were many conflicts between Europeans and Natives. The Europeans had many advantages over the natives. They gave them diseases that they had not been exposed to before and this wiped out 50–90% of their population. (See Population history of indigenous peoples of the Americas.)\n\nMaize and manioc were introduced into Africa in the 16th century by the Portuguese. They are now important staple foods, replacing native African crops. Alfred W. Crosby speculated that increased production of maize, manioc, and other New World crops led to heavier concentrations of population in the areas from which slavers captured their victims.\n\nIn the 16th-century economy of China, the Ming Dynasty was stimulated by trade with the Portuguese, Spanish, and Dutch. China became involved in a new global trade of goods, plants, animals, and food crops known as the Columbian Exchange. Trade with European powers and the Japanese brought in massive amounts of silver, which then replaced copper and paper banknotes as the common medium of exchange in China. During the last decades of the Ming the flow of silver into China was greatly diminished, thereby undermining state revenues and indeed the entire Ming economy. This damage to the economy was compounded by the effects on agriculture of the incipient Little Ice Age, natural calamities, crop failure, and sudden epidemics. The ensuing breakdown of authority and people's livelihoods allowed rebel leaders such as Li Zicheng to challenge Ming authority.\n\nNew crops that had come to Asia from the Americas via the Spanish colonizers in the 16th century contributed to the Asia's population growth. Although the bulk of imports to China were silver, the Chinese also purchased New World crops from the Spanish Empire. This included sweet potatoes, maize, and peanuts, foods that could be cultivated in lands where traditional Chinese staple crops—wheat, millet, and rice—could not grow, hence facilitating a rise in the population of China. In the Song Dynasty (960–1279), rice had become the major staple crop of the poor; after sweet potatoes were introduced to China around 1560, it gradually became the traditional food of the lower classes.\n\nThe arrival of the Portuguese to Japan in 1543 initiated the Nanban trade period, with the Japanese adopting several technologies and cultural practices, like the arquebus, European-style cuirasses, European ships, Christianity, decorative art, and language. After the Chinese had banned direct trade by Chinese merchants with Japan, the Portuguese filled this commercial vacuum as intermediaries between China and Japan. The Portuguese bought Chinese silk and sold it to the Japanese in return for Japanese-mined silver; since silver was more highly valued in China, the Portuguese could then use Japanese silver to buy even larger stocks of Chinese silk. However, by 1573—after the Spanish established a trading base in Manila—the Portuguese intermediary trade was trumped by the prime source of incoming silver to China from the Spanish Americas.\n\nItalian Jesuit Matteo Ricci (1552–1610) was the first European allowed into the Forbidden City. He taught the Chinese how to construct and play the spinet, translated Chinese texts into Latin and vice versa, and worked closely with his Chinese associate Xu Guangqi (1562–1633) on mathematical work.\n\nAs a wider variety of global luxury commodities entered the European markets by sea, previous European markets for luxury goods stagnated. The Atlantic trade largely supplanted pre-existing Italian and German trading powers which had relied on their Baltic, Russian and Islamic trade links. The new commodities also caused social change, as sugar, spices, silks and chinawares entered the luxury markets of Europe.\n\nThe European economic centre shifted from the Mediterranean to Western Europe. The city of Antwerp, part of the Duchy of Brabant, became \"the centre of the \"entire\" international economy\", and the richest city in Europe at this time. Centred in Antwerp first and then in Amsterdam, \"Dutch Golden Age\" was tightly linked to the Age of Discovery. Francesco Guicciardini, a Venetian envoy, stated that hundreds of ships would pass Antwerp in a day, and 2,000 carts entered the city each week. Portuguese ships laden with pepper and cinnamon would unload their cargo. With many foreign merchants resident in the city and governed by an oligarchy of banker-aristocrats forbidden to engage in trade, the economy of Antwerp was foreigner-controlled, which made the city very international, with merchants and traders from Venice, Ragusa, Spain and Portugal and a policy of toleration, which attracted a large Orthodox Jewish community. The city experienced three booms during its golden age, the first based on the pepper market, a second launched by New World silver coming from Seville (ending with the bankruptcy of Spain in 1557), and a third boom, after the Treaty of Cateau-Cambresis, in 1559, based on the textiles industry.\n\nDespite initial hostilities, by 1549 the Portuguese were sending annual trade missions to Shangchuan Island in China. In 1557 they managed to convince the Ming court to agree on a legal port treaty that would establish Macau as an official Portuguese trade colony. The Portuguese friar Gaspar da Cruz (c. 1520 February 5, 1570) wrote the first complete book on China and the Ming Dynasty that was published in Europe; it included information on its geography, provinces, royalty, official class, bureaucracy, shipping, architecture, farming, craftsmanship, merchant affairs, clothing, religious and social customs, music and instruments, writing, education, and justice.\nFrom China the major exports were silk and porcelain, adapted to meet European tastes. The Chinese export porcelains were held in such great esteem in Europe that, in English, \"china\" became a commonly–used synonym for \"porcelain\". Kraak porcelain (believed to be named after the Portuguese carracks in which it was transported) was among the first Chinese ware to arrive in Europe in mass quantities. Only the richest could afford these early imports, and Kraak often featured in Dutch still life paintings. Soon the Dutch East India Company established a lively trade with the East, having imported 6 million porcelain items from China to Europe between the years 1602 to 1682. The Chinese workmanship impressed many. Between 1575 and 1587 Medici porcelain from Florence was the first successful attempt to imitate Chinese porcelain. Although Dutch potters did not immediately imitate Chinese porcelain, they began to do it when the supply to Europe was interrupted, after the death of Wanli Emperor in 1620. Kraak, mainly the blue and white porcelain, was imitated all over the world by potters in Arita, Japan and Persia—where Dutch merchants turned when the fall of the Ming Dynasty rendered Chinese originals unavailable—and ultimately in Delftware. Dutch and later English Delftware inspired by Chinese designs persisted from about 1630 to the mid-18th century alongside European patterns.\n\nAntonio de Morga (1559–1636), a Spanish official in Manila, listed an extensive inventory of goods that were traded by Ming China at the turn of the 16th to 17th century, noting there were \"rarities which, did I refer to them all, I would never finish, nor have sufficient paper for it\". After noting the variety of silk goods traded to Europeans, Ebrey writes of the considerable size of commercial transactions: In one case a galleon to the Spanish territories in the New World carried over 50,000 pairs of silk stockings. In return China imported mostly silver from Peruvian and Mexican mines, transported via Manila. Chinese merchants were active in these trading ventures, and many emigrated to such places as the Philippines and Borneo to take advantage of the new commercial opportunities.\n\nThe increase in gold and silver experienced by Spain coincided with a major inflationary cycle both within Spain and Europe, known as the price revolution. Spain had amassed large quantities of gold and silver from the New World. In the 1520s large scale extraction of silver from Mexico's Guanajuato began. With the opening of the silver mines in Zacatecas and Bolivia's Potosí in 1546 large shipments of silver became the fabled source of wealth. During the 16th century, Spain held the equivalent of US$1.5 trillion (1990 terms) in gold and silver from New Spain. Being the most powerful European monarch at a time full of war and religious conflicts, the Habsburg rulers spent the wealth in wars and arts across Europe. \"I learnt a proverb here\", said a French traveller in 1603: \"Everything is dear in Spain except silver\". The spent silver, suddenly spread throughout a previously cash-starved Europe, caused widespread inflation. The inflation was worsened by a growing population with a static production level, low salaries and a rising cost of living, which damaged local industry. Increasingly, Spain became dependent on the revenues flowing in from the mercantile empire in the Americas, leading to Spain's first bankruptcy in 1557 due to rising military costs. Phillip II of Spain defaulted on debt payments in 1557, 1560, 1575 and 1596. The increase in prices as a result of currency circulation fuelled the growth of the commercial middle class in Europe, the \"bourgeoisie\", which came to influence the politics and culture of many countries.\n\nOne effect of the inflation, particularly in Great Britain, was that tenant farmers who held long term leases from lords saw real decreases in rent. Some lords opted to sell their leased land, giving rise to small land-owing farmers such as yeoman and gentlemen farmers.\n\n\n"}
{"id": "5901268", "url": "https://en.wikipedia.org/wiki?curid=5901268", "title": "Bailleur", "text": "Bailleur\n\nA bailleur, a French term, is a land owner who outsourced uncultivated parcels of land as part of an early Middle Age sharecropping system known as \"complant\" — a precursor to the métayage system. Under this system, a laborer known as a prendeur would agree to cultivate land owned by the \"bailleur\" in exchange for ownership of the crop and its production. For use of the \"bailleur's\" soil, the \"prendeur\" promised a share (normally a third to two-thirds) of the crop's production or its revenue to the \"bailleur\". The length of this partnership varied and sometimes would extend over generations. \n"}
{"id": "52728834", "url": "https://en.wikipedia.org/wiki?curid=52728834", "title": "Burchell's Shelter", "text": "Burchell's Shelter\n\nBurchell’s Shelter is a small rock overhang and archaeological site located in a kloof in the Ghaap Escarpment at Campbell in the Northern Cape, South Africa. As an archaeological site it has a shallow deposit containing late Holocene, mainly nineteenth century remains. Further interest in the shelter derives from the existence of an eyewitness description by the traveller William Burchell of the last Stone Age hunter-gatherers who inhabited the shelter. Hence it presented an opportunity, recognised by archaeologist Anthony Humphreys, to examine the occupation of the shelter from both an historical and an archaeological point of view.\n\nStrong springs near the head of the valley – at what would become the village of Campbell – had been noted by the Griqua polity based at Klaarwater (Griquatown) in 1805, but it was not before 1811 that they occupied the place, then known as ‘Knovel Valley'. In that year the missionary the Revd Lambert Jansz, in the company of the traveller William Burchell, took possession of the fountains (springs) in the name of the London Missionary Society.\n\nDuring this visit Burchell met and described the inhabitants of the rock shelter in the kloof. As they were soon afterwards absorbed into the community settling at what became Campbell, Burchell's account is a description of people at the very end of the Stone Age hunter-gatherer phase in this area.\n"}
{"id": "442948", "url": "https://en.wikipedia.org/wiki?curid=442948", "title": "Calendar era", "text": "Calendar era\n\nA calendar era is the year numbering system used by a calendar. For example, the Gregorian calendar numbers its years in the Western Christian era (the Coptic Orthodox and Ethiopian Orthodox churches have their own Christian eras). The instant, date, or year from which time is marked is called the \"epoch\" of the era. There are many different calendar eras such as Saka Era.\n\nIn antiquity, regnal years were counted from the accession of a monarch. This makes the Chronology of the ancient Near East very difficult to reconstruct, based on disparate and scattered king lists, such as the Sumerian King List and the Babylonian Canon of Kings. In East Asia, reckoning by era names chosen by ruling monarchs ceased in the 20th century except for Japan, where they are still used.\n\nFor over a thousand years, ancient Assyria used a system of eponyms to identify each year. Each year at the Akitu festival (celebrating the Mesopotamian new year), one of a small group of high officials (including the king in later periods) would be chosen by lot to serve as the \"limmu\" for the year, which meant that he would preside over the Akitu festival and the year would bear his name. The earliest attested \"limmu\" eponyms are from the Assyrian trading colony at Karum Kanesh in Anatolia, dating to the very beginning of the 2nd millennium BC, and they continued in use until the end of the Neo-Assyrian Period, ca. 612 BC.\n\nAssyrian scribes compiled \"limmu\" lists, including an unbroken sequence of almost 250 eponyms from the early 1st millennium BC. This is an invaluable chronological aid, because a solar eclipse was recorded as having taken place in the \"limmu\" of Bur-Sagale, governor of Guzana. Astronomers have identified this eclipse as one that took place on 15 June, 763 BC, which has allowed absolute dates of 892 to 648 BC to be assigned to that sequence of eponyms. This list of absolute dates has allowed many of the events of the Neo-Assyrian Period to be dated to a specific year, avoiding the chronological debates that characterize earlier periods of Mesopotamian history.\n\nAmong the ancient Greek historians and scholars, a common method of indicating the passage of years was based on the Olympic Games, first held in 776 BC. The Olympic Games provided the various independent city-states with a mutually recognizable system of dates. Olympiad dating was not used in everyday life. This system was in use from the 3rd century BC. The modern Olympic Games (or Summer Olympic Games beginning 1896) do not continue the four year periods from ancient Greece: the 669th Olympiad would have begun in the summer of 1897, but the modern Olympics were first held in 1896.\n\nAnother common system was the indiction cycle (15 indictions made up an agricultural tax cycle in Roman Egypt, an indiction being a year in duration). Documents and events began to be dated by the year of the cycle (e.g., \"fifth indiction\", \"tenth indiction\") in the 4th century, and this system was used long after the tax ceased to be collected. It was used in Gaul, in Egypt, and in most parts of Greece until the Islamic conquest, and in the Eastern Roman Empire until its conquest in 1453. \n\nThe rule for computing the indiction from the AD year number, which he had just invented, was stated by Dionysius Exiguus: add 3 and divide by 15; the remainder is the indiction, with 0 understood to be the fifteenth indiction. Thus 2001 was the ninth indiction. The beginning of the year for the indiction varied.\n\nThe Seleucid era was used in much of the Middle East from the 4th century BC to the 6th century AD, and continued until the 10th century AD among Oriental Christians. The era is computed from the epoch 312 BC: in August of that year Seleucus I Nicator captured Babylon and began his reign over the Asian portions of Alexander the Great's empire. Thus depending on whether the calendar year is taken as starting on 1 Tishri or on 1 Nisan (respectively the start of the Jewish civil and ecclesiastical years) the Seleucid era begins either in 311 BC (the Jewish reckoning) or in 312 BC (the Greek reckoning: October–September).\n\nAn early and common practice was Roman 'consular' dating. This involved naming both \"consules ordinarii\" who had taken up this office on January 1 (since 153 BC) of the relevant civil year. Sometimes one or both consuls might not be appointed until November or December of the previous year, and news of the appointment may not have reached parts of the Roman empire for several months into the current year; thus we find the occasional inscription where the year is defined as \"after the consulate\" of a pair of consuls.\n\nThe use of consular dating ended in AD 541 when the emperor Justinian I discontinued appointing consuls. The last consul nominated was Anicius Faustus Albinus Basilius. Soon afterwards, imperial regnal dating was adopted in its place.\n\nAnother method of dating, rarely used, was \"anno urbis conditae\" (Latin: \"in the year of the founded city\" (abbreviated AUC), where \"city\" meant Rome). (It is often incorrectly given that AUC stands for \"ab urbe condita\", which is the title of Titus Livius's history of Rome.)\n\nSeveral epochs were in use by Roman historians. Modern historians usually adopt the epoch of Varro, which we place in 753 BC.\n\nThe system was introduced by Marcus Terentius Varro in the 1st century BC. The first day of its year was Founder's Day (April 21), although most modern historians assume that it coincides with the modern historical year (January 1 to December 31). It was rarely used in the Roman calendar and in the early Julian calendar – naming the two consuls that held office in a particular year was dominant. AD 2018 is thus approximately the same as AUC 2771 (2018 + 753).\n\nAbout AD 400, the Iberian historian Orosius used the AUC era. Pope Boniface IV (about AD 600) may have been the first to use both the AUC era and the \"Anno Domini\" era (he put AD 607 = AUC 1360).\n\nAnother system that is less commonly found than might be thought was the use of the regnal year of the Roman emperor. At first, Augustus indicated the year of his reign by counting how many times he had held the office of consul, and how many times the Roman Senate had granted him Tribunican powers, carefully observing the fiction that his powers came from these offices granted to him, rather than from his own person or the many legions under his control. His successors followed his practice until the memory of the Roman Republic faded (about AD 200), when they began to use their regnal year openly.\n\nSome regions of the Roman Empire dated their calendars from the date of Roman conquest, or the establishment of Roman rule.\n\nThe Spanish era counted the years from 38 BC, probably the date of a new tax imposed by the Roman Republic on the subdued population of Iberia. The date marked the establishment of Roman rule in Spain and was used in official documents in Portugal, Aragon, Valencia, and in Castile, into the 14th century. This system of calibrating years fell to disuse in 1381 and was replaced by today's \"Anno Domini\".\n\nThroughout the Roman and Byzantine periods, the Decapolis and other Hellenized cities of Syria and Palestine used the Pompeian era, counting dates from the Roman general Pompey's conquest of the region in 63 BC.\n\nA different form of calendar was used to track longer periods of time, and for the inscription of calendar dates (i.e., identifying when one event occurred in relation to others). This form, known as the Long Count, is based upon the number of elapsed days since a mythological starting-point. According to the calibration between the Long Count and Western calendars accepted by the great majority of Maya researchers (known as the GMT correlation), this starting-point is equivalent to August 11, 3114 BC in the proleptic Gregorian calendar or 6 September in the Julian calendar (−3113 astronomical).\n\nA great many local systems or eras were also important, for example the year from the foundation of one particular city, the regnal year of the neighboring Persian emperor, and eventually even the year of the reigning Caliph.\n\nMost of the traditional calendar eras in use today were introduced at the time of transition from Late Antiquity to the Early Middle Ages, roughly between the 6th and 10th centuries.\n\n\nThe era based on the Incarnation of Christ was introduced by Dionysius Exiguus in 525 and is in continued use with various reforms and derivations. The distinction between the Incarnation being the conception or the Nativity of Jesus was not drawn until the late ninth century. The beginning of the numbered year varied from place to place: when, in 1600, Scotland adopted January 1 as the date the year number changes, this was already the case in much of continental Europe. England adopted this practice in 1752.\n\n\n\n\n\nThe Hindu Saka Era influences the calendars of southeast Asian indianized kingdoms.\n\n\n\n\n\n\n\n"}
{"id": "24737614", "url": "https://en.wikipedia.org/wiki?curid=24737614", "title": "Canteen Kopje", "text": "Canteen Kopje\n\nCanteen Kopje is an archaeological site, formally protected as a grade 2 provincial heritage site, and approved in 2017 for re-grading to national status, situated outside Barkly West in the Northern Cape, South Africa. The place was previously known as Klipdrift, meaning stony drift, a translation from a still earlier !Ora name, !\"a\" |\"aub\". Canteen Kopje is best known for its long and exceptionally rich Earlier Stone Age sequence, spanning circa >0.5 to 1.7 million years, occurring within gravels exposed in late nineteenth/early twentieth century mining pits. Also attracting attention are more recent archaeological levels in the overlying Hutton Sands, which contain material known as Fauresmith, Middle Stone Age, Later Stone Age, and late Iron Age with evidence of protocolonial/colonial contact and interaction, probably, with nineteenth century diamond diggers. \nThe importance of Canteen Kopje as a heritage site was recognized, and a 9 hectare area known as Erf 91 was proclaimed as a protected reserve in 1948. Gideon Retief, Mining Commissioner of Barkly West from 1942 to 1951, was instrumental in preserving the site and creating the first open air exhibit here. Subsequently, in 2000, information panels were erected by the McGregor Museum. These were refurbished in 2016. A walking trail was laid out for visitors to view the early diamond diggings and archaeological research sites. The Barkly West Museum contains further information and examples of artefacts from the site, while material excavated by archaeologists is housed principally by the McGregor Museum, the approved archaeological repository for the Northern Cape Province in nearby Kimberley.\n\nIn 2016 the protected heritage site was directly threatened after the Department of Minerals and Energy issued a permit for part of the site to be mined. Although a heritage permit had not been issued by the South African Heritage Resources Agency, mining commenced on 18 March 2016. An urgent interdicted was granted by the Northern Cape Division of the High Court of South Africa on 19 March, being made final on 19 April 2016.\n\nIn the 1940s the archaeologist C. van Riet Lowe predicted: “When the last diamond claim has been abandoned, archaeologists throughout the world will be interested in Canteen Kopje, in the Vaal River diggings, where lie the prehistoric remains of a million years of human evolution.”\n\nOne of the hills in the vicinity of Canteen Kopje was the site of the first alluvial diamond diggings (as opposed to surface prospecting) on the Diamond Fields of South Africa, which precipitated the rush to these parts in 1870. Digging continued here until the early 1940s.\n\nBatlhaping \"Kgosi\" (Chief) Jantjie Mothibi controlled, for as long as he could, the influx of white “diamond seekers” to the region. Prospectors were allowed to use sharp sticks, but were not permitted to “touch the ground with pick and shovel”. For their part, as noted by Jerome Babe in his 1872 book, \"The South African Diamond Fields\", “Natives would form themselves in long lines, joined hand in hand, and walk slowly over the ground and look for diamonds, especially after rain; and if they found one they would take it to a trader...[Finds were exchanged for] horses, wagons, cows, sheep, cash, goods, etc at a deuce of a pace”.\n\nIn January 1870 diggers from KwaZulu-Natal were working their way along the Vaal River, finding diamonds at Klipdrift, on the “Old Koppie”, upslope from Canteen Kopje. Using “pick and shovel, in spite of the natives”, they unearthed more, precipitating the diamond rush. Soon both banks of the Vaal River were thronging with diggers of many nationalities, and by the end of the year there were five thousand people at Klipdrift alone.\n\nThe diggers formed a Mutual Protection Association and elected Stafford Parker as their leader. Klipdrift was renamed Parkerton (from 1873 it was called Barkly West), and a Diggers’ Republic was proclaimed in July 1870.\n\nA popular early cradle sieve for recovery of diamonds was the so-called “Long Tom”, which was reliant on large quantities of water. An improved version less dependent on water was developed by the American digger, author of \"The South African Diamond Fields\", Jerome Babe. His ‘dry sifter’, known as the “Yankee Baby”, is still used in the twenty first century by some small-scale diggers. At the time, its inventor was said to be “the first Babe to rock his own cradle”.\n\nThe centrifugal or rotary washing machine – now standard on diggings in the area – is more sophisticated. In a slurry, a concentrate of heavy diamond-bearing deposit is separated from lighter waste.\n\nDiggers staked their claims near the river, and dug the gravel where it was exposed at or near the surface. Where the gravel was buried deeper under silt and sand - such as at Canteen Kopje - large pits were dug. From these and from vertical shafts, the diggers tunnelled out precarious passageways in which a man could hardly stand.\n\nThe sequence of geological deposits in the vicinity of Canteen Kopje comprises:\n\n\nDiamonds at or near Canteen Kopje are confined to the Older and Younger Gravels. Around 90-120 million years ago, a swarm of volcanic pipes, centred on Kimberley to the east, brought diamond-bearing kimberlite to a higher surface formed of Karoo Sequence sediments. Subsequent erosion has lowered the entire regional landscape by over 1200 metres and in the process the diamonds were released from their host rock. It has been estimated that at least 50 million carats of diamonds were set free in this way from the five kimberlite pipes in the vicinity of Kimberley alone. Most of those were flushed away to the sea long ago in past and present river channels, but along the way some were trapped in alluvial deposits such as the Older and Younger Gravels along rivers in this region.\n\nEarlier Stone Age artefacts were noted in the area by Colonel James Henry Bowker and Mary Elizabeth Barber at the time of the earliest diamond diggings. Eminent prehistorians including C. van Riet Lowe, the French prehistorian, the Abbé Henri Breuil and J. Desmond Clark visited and described it. Breuil was here in 1929 and again in the 1940s, when he famously noted that \"not only are there enough specimens [there] to fill a museum to overflowing but to build it of them also.\"\n\nOn account both of the mining history as well as the finding of Acheulean artefacts at this spot, a 10 morgen portion of Canteen Kopje was declared a National Monument (since 2000 known as a provincial heritage site) in 1948. Mining recommenced in the vicinity in the 1990s and Canteen Kopje was nearly lost. Pressure was exerted for the site to be de-proclaimed as a heritage site, to allow for renewed diamond digging and ‘empowerment’ of small scale miners. The local community recognised the value of conserving heritage and supported the efforts of the then National Monuments Council and the McGregor Museum to preserve the site, which was then developed as an open-air museum. The new Barkly West Museum was created at the same time.\n\nRenewed threat was experienced in 2016. In 2014 the Department of Minerals (DMR) issued a permit for mining to take place on part of the declared site. The South African Heritage Resources Agency (SAHRA) was alerted and in response, because of the existing formal declaration, a Cease Works Order was put in place to prevent mining from taking place. Pressure was exerted however and in March 2016 the Cease Works Order was lifted, following which, on 16 March 2016, a diamond mining operation commenced work by fencing off an area around that for which they have a DMR mining permit. Public access to the remainder of the heritage site was blocked. Section 27(18) of the National Heritage Resources Act (NHRA) (Act 25 of 1999) states that: \"No person may destroy, damage, deface, excavate, alter, remove from its original position, subdivide or change the planning status of any heritage site without a permit issued by the heritage resources authority responsible for the protection of such site.\" Section 51. (1) of the NHRA states that: \"Notwithstanding the provisions of any other law, any person who contravenes— (a) sections 27(18), 29(10), 32(13) or 32(19) is guilty of an offence and liable to a fine or imprisonment or both such fine and imprisonment as set out in item 1 of the Schedule.\" Since the mining concern has commenced mining operations without such a permit issued by SAHRA, it is clearly in contravention of an Act of the Republic of South Africa and therefore is guilty of an offence.\n\nExcavations in the late 1990s were carried out by Peter Beaumont of the McGregor Museum. John McNabb from the University of Southampton worked with Beaumont in analysing the Acheulean stone artefact technology. Further excavations have been carried out by archaeologists from the University of the Witwatersrand (inter alia for application of cosmogenic nuclide burial dating) and the University of Toronto. The current active programme of research has yielded an as yet unpublished basal date of some 2.3 million years, while excavations involving students from the Sol Plaatje University in Kimberley investigate the most recent circa 19th century contact period archaeology showing interaction between local communities and colonial diggers.\n\nCrucial to the interpretation of the archaeology of the site, is an understanding of site formation in relation to the adjacent hill and the Vaal River which at different periods cut down first to the north of the site and then the south west.\n\nIn 2007-9 a 7-metre sequence through Hutton Sands and Gravels was excavated to carry out dating and a detailed analysis of the lithic profile. There is a marked 'Victoria West' Acheulean horizon (named for the town in the Karoo where these stone tools were first described) in the upper part of the gravels, subject to a current Southampton PhD project. The lower part of the sequence contains simpler, older Acheulean technology.\n\nLater Stone Age material at and just below the surface has been studied in two excavations by archaeologists from the University of the Witwatersrand and Toronto.\n\nThe Canteen Kopje Skull was found in the vicinity in 1925 by diamond digger Kenneth Kemp, working 2.4 m down at an unrecorded locality at Canteen Kopje. A number of fitting skull fragments were presented by Kemp to the magistrate J.G. van Alphen, who in turn donated them to the McGregor Museum. They were studied soon afterwards by Robert Broom, who described it in \"Nature\" in 1929.\n\nIn Broom’s reconstruction, the skull appeared to have features similar to an allegedly archaic skeleton found at Boskop near Johannesburg. In 2011-12 X-ray Computerised Tomography scans of the skull, carried out at the South African Nuclear Energy Corporation near Pretoria, suggested it falls within the range of variation of Khoe-San populations of the Holocene (last 12 000 years), and is not ‘archaic’ as Broom had suggested. Reconsideration of the evidence also points to it having come from the Hutton Sands and not the Younger Gravels, as previously presumed.\n\n"}
{"id": "57187471", "url": "https://en.wikipedia.org/wiki?curid=57187471", "title": "Christopher Reinhart", "text": "Christopher Reinhart\n\nChristopher Reinhart is a historian, researcher and research assistant in History Department, Faculty of Humanities, University of Indonesia. His research focuses on ancient history of Indonesia and Southeast Asia. After moving from Bern, he decided to stay in Indonesia and becoming a member of History Department, University of Indonesia. He wrote several articles, journals and studies about Indonesia during his time in Indonesia:\nHe recently moderated a general lecture (openbaar lezing) of Prof. Susanto Zuhdi on History Fair, University of Indonesia \n"}
{"id": "623992", "url": "https://en.wikipedia.org/wiki?curid=623992", "title": "Demilitarisation", "text": "Demilitarisation\n\nDemilitarisation or demilitarization may mean the reduction of state armed forces. For instance, the demilitarisation of Northern Ireland entailed the reduction of British security and military apparatuses. Demilitarisation in this sense is usually the result of a peace treaty ending a war or a major conflict. The principle is distinguished from demobilization, which refers to the drastic voluntary reduction in the size of a victorious army. \n\nDemilitarisation was a policy in a number of countries after both world wars. In the aftermath of World War I, the United Kingdom greatly reduced its military strength, which is also referred to as disarmament. The resulting position of British military weakness during the rise of the Nazi regime in Germany was among the causes that led to the policy of appeasement.\n\nThe conversion of a military or paramilitary force into a civilian one is also called demilitarisation. For example, the Italian Polizia di Stato demilitarised in 1981, and the Austrian Gendarmerie merged with the national police, making up a new civilian body. Demilitarisation can also refer to the policies employed by Allied forces during the occupation of Japan and Germany after World War II. The Japanese and German militaries were re-badged to disassociate them from their recent war history, but were kept active and reinforced to help the allies face the new Soviet threat that had become evident as World War 2 ended, and the Cold War began.\n\nDemilitarisation can also refer to the reduction of one or more types of weapons or weapons systems \"(See Arms Control)\" or the removal of combat equipment from a warship \"(See Japanese battleship Hiei)\".\n\nA demilitarised zone is a specific area, such as a buffer zone between nations previously engaged in armed conflict, where military persons, equipment or activities are forbidden. This can also include areas designated during conflicts in which nations, military powers or contending groups forbid military installations, activities or personnel. The demilitarised zone is also free from all activities that assist the war efforts of any of the belligerents. Generally, this zone is protected from attack and many countries forbid their troops from targeting because it would constitute a grave breach or a serious war crime that would likely warrant the institution of criminal proceedings. In the case, however, of the Korean Demilitarised Zone, of the areas beyond the demilitarized strip that separates both sides, are heavily militarized.\n\nExamples of demilitarisation include:\n\n\n"}
{"id": "44379567", "url": "https://en.wikipedia.org/wiki?curid=44379567", "title": "Dialectical materialism", "text": "Dialectical materialism\n\nDialectical materialism is a philosophy of science and nature developed in Europe and based on the writings of Karl Marx and Friedrich Engels.\n\nDialectical materialism adapts the Hegelian dialectic for traditional materialism, which examines the subjects of the world in relation to each other within a dynamic, evolutionary environment, in contrast to metaphysical materialism, which examines parts of the world within a static, isolated environment.\n\nDialectical materialism accepts the evolution of the natural world and the emergence of new qualities of being at new stages of evolution. As Z. A. Jordan notes, \"Engels made constant use of the metaphysical insight that the higher level of existence emerges from and has its roots in the lower; that the higher level constitutes a new order of being with its irreducible laws; and that this process of evolutionary advance is governed by laws of development which reflect basic properties of 'matter in motion as a whole'.\"\n\nThe formulation of the Soviet version of dialectical and historical materialism (such as in Stalin's book \"Dialectical and Historical Materialism\") in the 1930s by Joseph Stalin and his associates, became the \"official\" Soviet interpretation of Marxism. It was codified and popularized in textbooks which were required reading in the Soviet Union as well as in some Eastern European countries. It was exported to China as the \"official\" interpretation of Marxism.\n\nMarx and Engels never used the words \"dialectical materialism\" in their own writings. The term was coined in 1887 by Joseph Dietzgen, a socialist who corresponded with Marx, during and after the failed 1848 German Revolution. Casual mention of the term \"dialectical materialism\" is also found in the biography \"Frederick Engels\", by philosopher Karl Kautsky, written in the same year. Marx himself had talked about the \"materialist conception of history\", which was later referred to as \"historical materialism\" by Engels. Engels further explained the \"materialist dialectic\" in his \"Dialectics of Nature\" in 1883. Georgi Plekhanov, the father of Russian Marxism, later introduced the term \"dialectical materialism\" to Marxist literature. Joseph Stalin further delineated and defined dialectical and historical materialism as the world outlook of Marxism-Leninism, and as a method to study society and its history.\n\nMarx and Engels each began their adulthood as Young Hegelians, one of several groups of intellectuals inspired by the philosopher Georg Wilhelm Friedrich Hegel. Marx's doctoral thesis, \"The Difference Between the Democritean and Epicurean Philosophy of Nature\", was concerned with the atomism of Epicurus and Democritus, which is considered the foundation of materialist philosophy. Marx was also familiar with Lucretius's theory of \"clinamen\". Marx and Engels both concluded that Hegelian philosophy, at least as interpreted by their former colleagues, was too abstract and was being misapplied in attempts to explain the social injustice in recently industrializing countries such as Germany, France, and the United Kingdom, which was a growing concern in the early 1840s.\n\nIn contrast to the conventional Hegelian dialectic of the day, which emphasized the idealist observation that human experience is dependent on the mind's perceptions, Marx developed Marxist dialectics, which emphasized the materialist view that the world of the concrete shapes socioeconomic interactions and that those in turn determine sociopolitical reality. Whereas some Hegelians blamed religious alienation (estrangement from the traditional comforts of religion) for societal ills, Marx and Engels concluded that alienation from economic and political autonomy, coupled with exploitation and poverty, was the real culprit. In keeping with dialectical ideas, Marx and Engels thus created an alternative theory, not only of why the world is the way it is but also of which actions people should take to make it the way it ought to be. In \"Theses on Feuerbach\" (1845), Marx wrote, \"The philosophers have only \"interpreted\" the world, in various ways. The point, however, is to \"change\" it.\" Dialectical materialism is thus closely related to Marx's and Engels's historical materialism (and has sometimes been viewed as synonymous with it). Marx rejected the language of \"thesis, antithesis, synthesis\".\n\nDialectical materialism is an aspect of the broader subject of materialism, which asserts the primacy of the material world: in short, matter precedes thought. Materialism is a realist philosophy of science, which holds that the world is material; that all phenomena in the universe consist of \"matter in motion,\" wherein all things are interdependent and interconnected and develop according to natural law; that the world exists outside us and independently of our perception of it; that thought is a reflection of the material world in the brain, and that the world is \"in principle\" knowable. Marx criticized classical materialism as another idealist philosophy—idealist because of its transhistorical understanding of material contexts. The Young Hegelian Ludwig Feuerbach had rejected Hegel's idealistic philosophy and advocated materialism. Despite being strongly influenced by Feuerbach, Marx rejected Feuerbach's version of materialism as inconsistent. The writings of Engels, especially \"Anti-Dühring\" (1878) and \"Dialectics of Nature\" (1875–82), were the source of the main doctrines of dialectical materialism.\n\nThe concept of dialectical materialism emerges from statements by Marx in the second edition postface to his magnum opus, \"Capital\". There Marx says he intends to use Hegelian dialectics but in revised form. He defends Hegel against those who view him as a \"dead dog\" and then says, \"I openly avowed myself as the pupil of that mighty thinker Hegel.\" Marx credits Hegel with \"being the first to present [dialectic's] form of working in a comprehensive and conscious manner\". But he then criticizes Hegel for turning dialectics upside down: \"With him it is standing on its head. It must be turned right side up again, if you would discover the rational kernel within the mystical shell.\"\n\nMarx's criticism of Hegel asserts that Hegel's dialectics go astray by dealing with ideas, with the human mind. Hegel's dialectic, Marx says, inappropriately concerns \"the process of the human brain\"; it focuses on ideas. Hegel's thought is in fact sometimes called dialectical idealism, and Hegel himself is counted among a number of other philosophers known as the German idealists. Marx, on the contrary, believed that dialectics should deal not with the mental world of ideas but with \"the material world\", the world of production and other economic activity.\n\nFor Marx, human history cannot be fitted into any neat \"a priori\" schema. He explicitly rejects the idea of Hegel's followers that history can be understood as \"a person apart, a metaphysical subject of which real human individuals are but the bearers\". To interpret history as though previous social formations have somehow been aiming themselves toward the present state of affairs is \"to misunderstand the historical movement by which the successive generations transformed the results acquired by the generations that preceded them\". Marx's rejection of this sort of teleology was one reason for his enthusiastic (though not entirely uncritical) reception of Darwin's theory of natural selection.\n\nFor Marx, dialectics is not a formula for generating predetermined outcomes but is a method for the empirical study of social processes in terms of interrelations, development, and transformation. In his introduction to the Penguin edition of Marx's \"Capital\", Ernest Mandel writes, \"When the dialectical method is applied to the study of economic problems, economic phenomena are not viewed separately from each other, by bits and pieces, but in their inner connection as an integrated totality, structured around, and by, a basic predominant mode of production.\"\n\nMarx's own writings are almost exclusively concerned with understanding human history in terms of systemic processes, based on modes of production (broadly speaking, the ways in which societies are organized to employ their technological powers to interact with their material surroundings). This is called \"historical materialism\". More narrowly, within the framework of this general theory of history, most of Marx's writing is devoted to an analysis of the specific structure and development of the capitalist economy.\n\nFor his part, Engels applies a \"dialectical\" approach to the natural world in general, arguing that contemporary science is increasingly recognizing the necessity of viewing natural processes in terms of interconnectedness, development, and transformation. Some scholars have doubted that Engels's \"dialectics of nature\" is a legitimate extension of Marx's approach to social processes. Other scholars have argued that despite Marx's insistence that humans are natural beings in an evolving, mutual relationship with the rest of nature, Marx's own writings pay inadequate attention to the ways in which human agency is constrained by such factors as biology, geography, and ecology.\n\nEngels postulated three laws of dialectics from his reading of Hegel's \"Science of Logic\". Engels elucidated these laws as the materialist dialectic in his work \"Dialectics of Nature\":\n\n\nThe first law, which originates with the ancient Ionian philosopher Heraclitus, was seen by both Hegel and Vladimir Lenin as the central feature of a dialectical understanding of things:\n\nThe second law Hegel took from Ancient Greek philosophers, notably the paradox of the heap, and explanation by Aristotle, and it is equated with what scientists call phase transitions. It may be traced to the ancient Ionian philosophers, particularly Anaximenes from whom Aristotle, Hegel, and Engels inherited the concept. For all these authors, one of the main illustrations is the phase transitions of water. There has also been an effort to apply this mechanism to social phenomena, whereby population increases result in changes in social structure. The law of the passage of quantitative changes into qualitative changes can also be applied to the process of social change and class conflict.\n\nThe third law, \"negation of the negation\", originated with Hegel. Although Hegel coined the term \"negation of the negation\", it gained its fame from Marx's using it in \"Capital\". There Marx wrote this: \"The [death] knell of capitalist private property sounds. The expropriators [capitalists] are expropriated. The capitalist mode of appropriation, the result of the capitalist mode of production, produces capitalist private property. This is the first negation [antithesis] of individual private property. [The \"first negation\", or antithesis, negates the thesis, which in this instance is feudalism, the economic system that preceded capitalism.] ... But capitalist production begets, with the inexorability of a law of Nature, its own negation. It [final communism, the synthesis] is the negation of [the] negation.\"\n\nZ. A. Jordan notes, \"Engels made constant use of the metaphysical insight that the higher level of existence emerges from and has its roots in the lower; that the higher level constitutes a new order of being with its irreducible laws; and that this process of evolutionary advance is governed by laws of development which reflect basic properties of 'matter in motion as a whole'.\"\n\nAfter reading Hegel's \"Science of Logic\" in 1914, Lenin made some brief notes outlining three \"elements\" of logic. They are:\n\n\nLenin develops these in a further series of notes, and appears to argue that \"the transition of quantity into quality and vice versa\" is an example of the unity and opposition of opposites expressed tentatively as \"not only the unity of opposites but the transitions of every determination, quality, feature, side, property into every other [into its opposite?].\"\n\nAlso, in his essay \"On the Question of Dialectics\", Lenin stated that \"Development is the 'struggle' of opposites.\"\nHe stated that \"The unity (coincidence, identity, equal action) of opposites is conditional, temporary, transitory, relative. The struggle of mutually exclusive opposites is absolute, just as development and motion are absolute.\"\n\nIn \"Materialism and Empiriocriticism\" (1908), Lenin explained \"dialectical materialism\" as three axes: (i) the materialist inversion of Hegelian dialectics, (ii) the historicity of ethical principles ordered to class struggle, and (iii) the convergence of \"laws of evolution\" in physics (Helmholtz), biology (Darwin), and in political economy (Marx). Hence, Lenin was philosophically positioned between historicist Marxism (Labriola) and determinist Marxism—a political position close to \"social Darwinism\" (Kautsky). Moreover, late-century discoveries in physics (x-rays, electrons), and the beginning of quantum mechanics, philosophically challenged previous conceptions of matter and materialism, thus matter seemed to be disappearing. Lenin disagreed:\n'Matter disappears' means that the limit within which we have hitherto known matter disappears, and that our knowledge is penetrating deeper; properties of matter are disappearing that formerly seemed absolute, immutable, and primary, and which are now revealed to be relative and characteristic only of certain states of matter. For the \"sole\" 'property' of matter, with whose recognition philosophical materialism is bound up, is the property of \"being an objective reality\", of existing outside of the mind.\n\nLenin was developing the work of Engels, who said that \"with each epoch-making discovery, even in the sphere of natural science, materialism has to change its form.\" One of Lenin's challenges was distancing materialism, as a viable philosophical outlook, from the \"vulgar materialism\" expressed in the statement \"the brain secretes thought in the same way as the liver secretes bile\" (attributed to 18th-century physician Pierre Jean Georges Cabanis); \"metaphysical materialism\" (matter composed of immutable particles); and 19th-century \"mechanical materialism\" (matter as random molecules interacting per the laws of mechanics). The philosophic solution that Lenin (and Engels) proposed was \"dialectical materialism\", wherein matter is defined as \"objective reality\", theoretically consistent with (new) developments occurring in the sciences.\n\nLenin reassessed Feuerbach's philosophy and concluded that it was in line with dialectical materialism.\n\nGyörgy Lukács, Minister of Culture in the brief Béla Kun government of the Hungarian Soviet Republic (1919), published \"History and Class Consciousness\" (1923), in which he defined \"dialectical materialism\" as the knowledge of society as a whole, knowledge which, in itself, was the class consciousness of the proletariat. In the first chapter \"What is Orthodox Marxism?\", Lukács defined \"orthodoxy\" as fidelity to the \"Marxist method\", not fidelity to \"dogmas\":\nOrthodox Marxism, therefore, does not imply the uncritical acceptance of the results of Marx's investigations. It is not the \"belief\" in this or that thesis, nor the exegesis of a \"sacred\" book. On the contrary, orthodoxy refers exclusively to method. It is the scientific conviction that dialectical materialism is the road to truth and that its methods can be developed, expanded, and deepened, only along the lines laid down by its founders. (§1)\nIn his later works and actions, Lukács became a leader of Democratic Marxism. He modified many of his formulations of his 1923 works and went on to develop a Marxist ontology and played an active role in democratic movements in Hungary in 1956 and the 1960s. He and his associates became sharply critical of the formulation of dialectical materialism in the Soviet Union that was exported to those countries under its control. In the 1960s, his associates became known as the Budapest School.\n\nLukács philosophical criticism of Marxist revisionism proposed an intellectual return to the Marxist method. As did Louis Althusser, who later defined Marxism and psychoanalysis as \"conflictual sciences\"; that political factions and revisionism are inherent to Marxist theory and political praxis, because dialectical materialism is the philosophic product of class struggle:\n\nFor this reason, the task of orthodox Marxism, its victory over Revisionism and utopianism can never mean the defeat, once and for all, of false tendencies. It is an ever-renewed struggle against the insidious effects of bourgeois ideology on the thought of the proletariat. Marxist orthodoxy is no guardian of traditions, it is the eternally vigilant prophet proclaiming the relation between the tasks of the immediate present and the totality of the historical process. (§5)\n...the premise of dialectical materialism is, we recall: 'It is not men's consciousness that determines their existence, but, on the contrary, their social existence that determines their consciousness'... Only when the core of existence stands revealed as a social process can existence be seen as the product, albeit the hitherto unconscious product, of human activity. (§5)\n\nPhilosophically aligned with Marx is the criticism of the individualist, bourgeois philosophy of the subject, which is founded upon the voluntary and conscious subject. Against said ideology is the primacy of social relations. Existence—and thus the world—is the product of human activity, but this can be seen only by accepting the primacy of social process on individual consciousness. This type of consciousness is an effect of ideological mystification.\n\nAt the 5th Congress of the Communist International (July 1924), Grigory Zinoviev formally denounced Lukács's heterodox definition of \"orthodox Marxism\" as exclusively derived from fidelity to the \"Marxist method\", and not to Communist party dogmas; and denounced the Marxism developments of the German theorist Karl Korsch.\n\nIn the 1930s, Joseph Stalin and his associates formulated a version of dialectical and historical materialism that became the \"official\" Soviet interpretation of Marxism. It was codified in Stalin's work, \"Dialectical and Historical Materialism\" (1938), and popularized in textbooks used for compulsory education within the Soviet Union and throughout the Eastern Bloc. It was exported to China as the \"official\" interpretation of Marxism but, in its Soviet formulation, has since then been widely rejected there.\n\nIn \"On Contradiction\" (1937), Mao outlined a version of dialectical materialism that subsumed two of Engels's three principal laws of dialectics, \"the transformation of quantity into quality\" and \"the negation of the negation\" as sub-laws (and not principal laws of their own) of the first law, \"the unity and interpenetration of opposites\".\n\nHistorian of science Loren Graham has detailed at length the role played by dialectical materialism in the Soviet Union in disciplines as diverse as biology, psychology, chemistry, cybernetics, quantum mechanics, and cosmology. He has concluded that, despite the Lysenko period in genetics and constraints on free inquiry imposed by political authorities, dialectical materialism had a positive influence on the work of many Soviet scientists.\n\nSome evolutionary biologists, such as Richard Lewontin and the late Stephen Jay Gould, have tried to employ dialectical materialism in their approach. They view dialectics as playing a precautionary heuristic role in their work. From Lewontin's perspective, we get this idea:\nDialectical materialism is not, and never has been, a programmatic method for solving particular physical problems. Rather, a dialectical analysis provides an overview and a set of warning signs against particular forms of dogmatism and narrowness of thought. It tells us, \"Remember that history may leave an important trace. Remember that being and becoming are dual aspects of nature. Remember that conditions change and that the conditions necessary to the initiation of some process may be destroyed by the process itself. Remember to pay attention to real objects in time and space and not lose them in utterly idealized abstractions. Remember that the qualitative effects of context and interaction may be lost when phenomena are isolated\". And above all else, \"Remember that all the other caveats are only reminders and warning signs whose application to different circumstances of the real world is contingent.\"\nGould shared similar views regarding a heuristic role for dialectical materialism. He wrote that:\n\n...dialectical thinking should be taken more seriously by Western scholars, not discarded because some nations of the second world have constructed a cardboard version as an official political doctrine.\n...when presented as guidelines for a philosophy of change, not as dogmatic precepts true by fiat, the three classical laws of dialectics embody a holistic vision that views change as interaction among components of complete systems and sees the components themselves not as a priori entities, but as both products and inputs to the system. Thus, the law of \"interpenetrating opposites\" records the inextricable interdependence of components: the \"transformation of quantity to quality\" defends a systems-based view of change that translates incremental inputs into alterations of state, and the \"negation of negation\" describes the direction given to history because complex systems cannot revert exactly to previous states.\nThis heuristic was also applied to the theory of punctuated equilibrium proposed by Gould and Niles Eldredge. They wrote that \"history, as Hegel said, moves upward in a spiral of negations\", and that \"punctuated equilibria is a model for discontinuous tempos of change (in) the process of speciation and the deployment of species in geological time.\" They noted that \"the law of transformation of quantity into quality\", \"holds that a new quality emerges in a leap as the slow accumulation of quantitative changes, long resisted by a stable system, finally forces it rapidly from one state into another\", a phenomenon described in some disciplines as a paradigm shift. Apart from the commonly cited example of water turning to steam with increased temperature, Gould and Eldredge noted another analogy in information theory, \"with its jargon of equilibrium, steady state, and homeostasis maintained by negative feedback\", and \"extremely rapid transitions that occur with positive feedback\".\n\nLewontin, Gould, and Eldredge were thus more interested in dialectical materialism as a heuristic than a dogmatic form of 'truth' or a statement of their politics. Nevertheless, they found a readiness for critics to \"seize upon\" key statements and portray punctuated equilibrium, and exercises associated with it, such as public exhibitions, as a \"Marxist plot\".\n\nSome critics argue against dialectical materialism on account of its adherence to a purely materialist worldview, while others have objections to the dialectic method it employs. There are critics, such as the Marxist Alain Badiou, who dispute the way the concept is interpreted. Joseph Needham, an influential historian of science and a Christian who nonetheless was an adherent of dialectical materialism, suggested that a more appropriate term might be \"dialectical organicism\". Leszek Kołakowski, writing in \"Main Currents of Marxism\" (1976), argued that dialectical materialism consists partly of \"truisms with no specific Marxist content\", partly of \"philosophical dogmas\", partly of nonsense, and partly of statements that—depending on how they are interpreted—could be any of these things. Max Eastman argued that dialectical materialism lacks a psychological basis.\n\nPhilosopher Allen Wood argued that, in its form as an official Soviet philosophy, dialectical materialism was doomed to be superficial because \"creativity or critical thinking\" was impossible in an authoritarian environment. Nevertheless, he considered the basic aims and principles of dialectical materialism to be in harmony with rational scientific thought.\n\n"}
{"id": "9097253", "url": "https://en.wikipedia.org/wiki?curid=9097253", "title": "Digital Revolution", "text": "Digital Revolution\n\nThe Digital Revolution, also known as the Third Industrial Revolution, is the shift from mechanical and analogue electronic technology to digital electronics which began anywhere from the late 1950s to the late 1970s with the adoption and proliferation of digital computers and digital record keeping that continues to the present day. Implicitly, the term also refers to the sweeping changes brought about by digital computing and communication technology during (and after) the latter half of the 20th century. Analogous to the Agricultural Revolution and Industrial Revolution, the Digital Revolution marked the beginning of the Information Age.\n\nCentral to this revolution is the mass production and widespread use of digital logic circuits, and its derived technologies, including the computer, digital cellular phone, and the Internet. These technological innovations have transformed traditional production and business techniques.\n\nThe notion of the digital revolution is part of the Schumpeterian theory of socio-economic evolution, which consists of an incessant process of creative destruction that modernizes the modus operandi of society as a whole, including its economic, social, cultural, and political organization.\n\nThe motor of this incessant force of creative destruction is technological change. While the key carrier technology of the first Industrial Revolution (1770–1850) was based on water-powered mechanization, the second Kondratiev wave (1850–1900) was enabled by steam-powered technology, the third (1900–1940) was characterized by the electrification of social and productive organization, the fourth by motorization and the automated mobilization of society (1940–1970), and the most recent one by the digitization of social systems. Each one of those so-called long waves has been characterized by a sustained period of social modernization, most notably by sustained periods of increasing economic productivity. According to Carlota Perez: \"this quantum jump in productivity can be seen as a technological revolution, which is made possible by the appearance in the general cost structure of a particular input that we could call the 'key factor', fulfilling the following conditions: (1) clearly perceived low-and descending-relative cost; (2) unlimited supply for all practical purposes; (3) potential all-pervasiveness; (4) a capacity to reduce the costs of capital, labour and products as well as to change them qualitatively\". Digital Information and Communication Technologies fulfill those requirements and therefore represent a general purpose technology that can transform an entire economy, leading to a modern, and more developed form of socio-economic and political organization often referred to as the post-industrial society, the fifth Kondratiev, Information society, digital age, and network society, among others.\n\nThe Agricultural Revolution led to agricultural cities in the ancient world in the Middle East, Mesoamerica, China, the Indus Valley, Southern Europe and South America.\n\nThe Industrial Revolution and Digital Revolution are now taking place concurrently in China and India as people leave the rural areas for industrial and high tech cities like Beijing, Shanghai, and Mumbai.\n\nThe underlying technology was invented in the later half of the 19th century, including Babbage's analytical engine and the telegraph. Digital communication became economical for widespread adoption after the invention of the personal computer. Claude Shannon, a Bell Labs mathematician, is credited for having laid out the foundations of digitalization in his pioneering 1948 article, \"A Mathematical Theory of Communication\". The digital revolution converted technology that had been analog into a digital format. By doing this, it became possible to make copies that were identical to the original. In digital communications, for example, repeating hardware was able to amplify the digital signal and pass it on with no loss of information in the signal. Of equal importance to the revolution was the ability to easily move the digital information between media, and to access or distribute it remotely.\n\nThe turning point of the revolution was the change from analogue to digitally recorded music. During the 1980s the digital format of optical compact discs gradually replaced analog formats, such as vinyl records and cassette tapes, as the popular medium of choice.\n\nIn 1947, the transistor was invented, leading the way to more advanced digital computers. From the late 1940s, Universities, the Military, and Business developed computer systems, to digitally replicate and automate previously manualy performed mathematical calculations, with the LEO (computer) being the first commercially available general purpose computer.\n\nA key step toward mass commercialization was the advent of the planar process in 1959 by Jean Hoerni, an employee of Fairchild Semiconductor. This enabled integrated circuits to be mass produced using the techniques of photolithography. \n\nFrom 1969 to 1971, Intel developed the Intel 4004, an early microprocessor that laid the foundations for the microcomputer revolution that began in the 1970s.\n\nThe public was first introduced to the concepts that would lead to the Internet when a message was sent over the ARPANET in 1969. Packet switched networks such as ARPANET, Mark I, CYCLADES, Merit Network, Tymnet, and Telenet, were developed in the late 1960s and early 1970s using a variety of protocols. The ARPANET in particular led to the development of protocols for internetworking, in which multiple separate networks could be joined together into a network of networks.\n\nThe Whole Earth movement of the 1960s advocated the use of new technology.\n\nIn the 1970s, the home computer was introduced, time-sharing computers, the video game console, the first coin-op video games, and the golden age of arcade video games began with Space Invaders. As digital technology proliferated, and the switch from analog to digital record keeping became the new standard in business, a relatively new job description was popularized, the data entry clerk. Culled from the ranks of secretaries and typists from earlier decades, the data entry clerk's job was to convert analog data (customer records, invoices, etc.) into digital data.\n\nIn developed nations, computers achieved semi-ubiquity during the 1980s as they made their way into schools, homes, business, and industry. Automated teller machines, industrial robots, CGI in film and television, electronic music, bulletin board systems, and video games all fueled what became the zeitgeist of the 1980s. Millions of people purchased home computers, making household names of early personal computer manufacturers such as Apple, Commodore, and Tandy. To this day the Commodore 64 is often cited as the best selling computer of all time, having sold 17 million units (by some accounts) between 1982 and 1994.\n\nIn 1984, the U.S. Census Bureau began collecting data on computer and Internet use in the United States; their first survey showed that 8.2% of all U.S. households owned a personal computer in 1984, and that households with children under the age of 18 were nearly twice as likely to own one at 15.3% (middle and upper middle class households were the most likely to own one, at 22.9%). By 1989, 15% of all U.S. households owned a computer, and nearly 30% of households with children under the age of 18 owned one. By the late 1980s, many businesses were dependent on computers and digital technology.\n\nMotorola created the first mobile phone, Motorola DynaTac, in 1983. However, this device used analog communication - digital cell phones were not sold commercially until 1991 when the 2G network started to be opened in Finland to accommodate the unexpected demand for cell phones that was becoming apparent in the late 1980s.\n\nCompute! magazine predicted that CD-ROM would be the centerpiece of the revolution, with multiple household devices reading the discs.\n\nThe first true digital camera was created in 1988, and the first were marketed in December 1989 in Japan and in 1990 in the United States. By the mid-2000s, they would eclipse traditional film in popularity.\n\nDigital ink was also invented in the late 1980s. Disney's CAPS system (created 1988) was used for a scene in 1989's The Little Mermaid and for all their animation films between 1990's The Rescuers Down Under and 2004's Home On The Range.\n\nTim Berners-Lee invented the World Wide Web in 1989.\n\nThe first public digital HDTV broadcast was of the 1990 World Cup that June; it was played in 10 theaters in Spain and Italy. However HDTV did not become a standard until the mid-2000s outside Japan.\n\nThe World Wide Web became publicly accessible in 1991, which had been available only to government and universities. In 1993 Marc Andreessen and Eric Bina introduced Mosaic, the first web browser capable of displaying inline images and the basis for later browsers such as Netscape Navigator and Internet Explorer. The Internet expanded quickly, and by 1996, it was part of mass culture and many businesses listed websites in their ads. By 1999 almost every country had a connection, and nearly half of Americans and people in several other countries used the Internet on a regular basis. However throughout the 1990s, \"getting online\" entailed complicated configuration, and dial-up was the only connection type affordable by individual users; the present day mass Internet culture was not possible.\n\nIn 1989 about 15% of all households in the United States owned a personal computer, by 2000, this was up to 51%; for households with children nearly 30% owned a computer in 1989, and in 2000 65% owned one.\n\nCell phones became as ubiquitous as computers by the early 2000s, with movie theaters beginning to show ads telling people to silence their phones. They also became much more advanced than phones of the 1990s, most of which only took calls or at most allowed for the playing of simple games.\n\nText messaging existed in the 1990s but was not widely used until the early 2000s, when it became a cultural phenomenon.\n\nThe digital revolution became truly global in this time as well - after revolutionizing society in the developed world in the 1990s, the digital revolution spread to the masses in the developing world in the 2000s.\n\nIn late 2005 the population of the Internet reached 1 billion, and 3 billion people worldwide used cell phones by the end of the decade. HDTV became the standard television broadcasting format in many countries by the end of the decade.\n\nBy 2012, over 2 billion people used the Internet, twice the number using it in 2007. Cloud computing had entered the mainstream by the early 2010s. By 2015, tablet computers and smartphones were expected to exceed personal computers in Internet usage. By 2016, half of the world's population was connected.\n\nIn the late 1980s, less than 1% of the world's technologically stored information was in digital format, while it was 94% in 2007, with more than 99% by 2014. The year 2002 is estimated to be the year when human kind was able to store more information in digital, than in analog format (the \"beginning of the digital age\").\n\nIt is estimated that the world's capacity to store information has increased from 2.6 (optimally compressed) exabytes in 1986, to some 5,000 exabytes in 2014 (5 zettabytes).\n\n\n\n\nConversion of below analog technologies to digital. (The decade indicated is the period when digital became dominant form.)\n\n\nDecline or disappearance of below analog technologies:\n\nDisappearance of other technologies also attributed to digital revolution. (Analog–digital classification doesn't apply to these.)\n\n\nImprovements in digital technologies.\n\nUnderlying the digital revolution was the development of the digital electronic computer, the personal computer, and particularly the microprocessor with its steadily increasing performance (as described by Moore's law), which enabled computer technology to be embedded into a huge range of objects from cameras to personal music players. Equally important was the development of transmission technologies including computer networking, the Internet and digital broadcasting. 3G phones, whose social penetration grew exponentially in the 2000s, also played a very large role in the digital revolution as they simultaneously provide ubiquitous entertainment, communications, and online connectivity.\n\nPositive aspects include greater interconnectedness, easier communication, and the exposure of information that in the past could have more easily been suppressed by totalitarian regimes. Michio Kaku wrote in his books Physics of the Future that the failure of the Soviet coup of 1991 was due largely to the existence of technology such as the fax machine and computers that exposed classified information.\n\nThe Revolutions of 2011 were enabled by social networking and smartphone technology; however these revolutions in hindsight largely failed to reach their goals as hardcore Islamist governments and in Syria a civil war have formed in the absence of the dictatorships that were toppled.\n\nThe economic impact of the digital revolution has been large. Without the World Wide Web (WWW), for example, globalization and outsourcing would not be nearly as feasible as they are today. The digital revolution radically changed the way individuals and companies interact. Small regional companies were suddenly given access to much larger markets. Concepts such as On-demand services and manufacturing and rapidly dropping technology costs made possible innovations in all aspects of industry and everyday life.\n\nAfter initial concerns of an IT productivity paradox, evidence is mounting that digital technologies have significantly increased the productivity and performance of businesses.\n\nNegative effects include information overload, Internet predators, forms of social isolation, and media saturation. In a poll of prominent members of the national news media, 65 percent said the Internet is hurting journalism more than it is helping by allowing anyone no matter how amateur and unskilled to become a journalist; causing information to be muddier and the rise of conspiracy theory in a way it didn't exist in the past.\n\nIn some cases, company employees' pervasive use of portable digital devices and work related computers for personal use—email, instant messaging, computer games—were often found to, or perceived to, reduce those companies' productivity. Personal computing and other non-work related digital activities in the workplace thus helped lead to stronger forms of privacy invasion, such as keystroke recording and information filtering applications (spyware and content-control software).\n\nPrivacy in general became a concern during the digital revolution. The ability to store and utilize such large amounts of diverse information opened possibilities for tracking of individual activities and interests. Libertarians and privacy rights advocates feared the possibility of an Orwellian future where centralized power structures control the populace via automatic surveillance and monitoring of personal information in such programs as the CIA's Information Awareness Office. Consumer and labor advocates opposed the ability to direct market to individuals, discriminate in hiring and lending decisions, invasively monitor employee behavior and communications and generally profit from involuntarily shared personal information.\n\nThe Internet, especially the WWW in the 1990s, opened whole new avenues for communication and information sharing. The ability to easily and rapidly share information on a global scale brought with it a whole new level of freedom of speech. Individuals and organizations were suddenly given the ability to publish on any topic, to a global audience, at a negligible cost, particularly in comparison to any previous communication technology.\n\nLarge cooperative projects could be endeavored (e.g. Open-source software projects, SETI@home). Communities of like-minded individuals were formed (e.g. MySpace, Tribe.net). Small regional companies were suddenly given access to a larger marketplace.\n\nIn other cases, special interest groups as well as social and religious institutions found much of the content objectionable, even dangerous. Many parents and religious organizations, especially in the United States, became alarmed by pornography being more readily available to minors. In other circumstances the proliferation of information on such topics as child pornography, building bombs, committing acts of terrorism, and other violent activities were alarming to many different groups of people. Such concerns contributed to arguments for censorship and regulation on the WWW.\n\nCopyright and trademark issues also found new life in the digital revolution. The widespread ability of consumers to produce and distribute exact reproductions of protected works dramatically changed the intellectual property landscape, especially in the music, film, and television industries.\n\nThe digital revolution, especially regarding privacy, copyright, censorship and information sharing, remains a controversial topic. As the digital revolution progresses it remains unclear to what extent society has been impacted and will be altered in the future.\n\nWhile there have been huge benefits to society from the digital revolution, especially in terms of the accessibility of information, there are a number of concerns. Expanded powers of communication and information sharing, increased capabilities for existing technologies, and the advent of new technology brought with it many potential opportunities for exploitation. The digital revolution helped usher in a new age of mass surveillance, generating a range of new civil and human rights issues. Reliability of data became an issue as information could easily be replicated, but not easily verified. The digital revolution made it possible to store and track facts, articles, statistics, as well as minutiae hitherto unfeasible.\n\nFrom the perspective of the historian, a large part of human history is known through physical objects from the past that have been found or preserved, particularly in written documents. Digital records are easy to create but also easy to delete and modify. Changes in storage formats can make recovery of data difficult or near impossible, as can the storage of information on obsolete media for which reproduction equipment is unavailable, and even identifying what such data is and whether it is of interest can be near impossible if it is no longer easily readable, or if there is a large number of such files to identify. Information passed off as authentic research or study must be scrutinized and verified.\n\nThese problems are further compounded by the use of digital rights management and other copy prevention technologies which, being designed to only allow the data to be read on specific machines, may well make future data recovery impossible. The Voyager Golden Record, which is intended to be read by an intelligent extraterrestrial (perhaps a suitable parallel to a human from the distant future), is recorded in analog rather than digital format specifically for easy interpretation and analysis.\n\n\n"}
{"id": "50353024", "url": "https://en.wikipedia.org/wiki?curid=50353024", "title": "Dobravac", "text": "Dobravac\n\nDobravac (; 1280) or Dobravec (Добравец) was a Serbian nobleman serving in the crown land of Hum, with the title of \"tepčija\". He is mentioned in a document dated 1280 as serving the countess of Hum (). He had a clerk or assistant, Mojše, who sold two of his bondmaids in Ragusa (Dubrovnik) that year. Although Dobravac's jurisdiction is unknown from the quotation, he was not a \"veliki tepčija\" (serving the king directly); his office was limited to the Hum land, but his type of work was the same as that of the \"veliki tepčija\". The \"tepčija\" had executive authorities; his \"otroci\" ( \"otrok\"), were servants, lesser in rank but not slaves.\n\nThe name is an old Serbian name, found in medieval epigraphy.\n"}
{"id": "49326236", "url": "https://en.wikipedia.org/wiki?curid=49326236", "title": "Dublin Rising 1916-2016", "text": "Dublin Rising 1916-2016\n\nDublin Rising 1916-2016 is a website celebrating the 100 year anniversary of the 1916 Easter Rising which took place in Dublin, Ireland in Easter of 1916. The website tours the streets of Dublin, while allowing the user to interact with statements and photographs. It is narrated by the Dublin actor Colin Farrell while guiding the user to various important buildings and events in the rising of the Irish republic.\n\nLaunched on January 12, 2016 by the Taoiseach Enda Kenny and the Minister for Arts, Heritage and the Gaeltacht Heather Humphreys, the website has received great media attention with the aim to teach the future generations how Ireland fought for their independence.\n"}
{"id": "368956", "url": "https://en.wikipedia.org/wiki?curid=368956", "title": "Duff Cooper Prize", "text": "Duff Cooper Prize\n\nThe Duff Cooper Prize is a literary prize awarded annually for the best work of history, biography, political science or (very occasionally) poetry, published in English or French. The prize was established in honour of Duff Cooper, a British diplomat, Cabinet member and author. The prize was first awarded in 1956 to Alan Moorehead for his \"Gallipoli\". At present, the winner receives a first edition copy of Duff Cooper's autobiography \"Old Men Forget\" and a cheque for £5,000.\n\nAfter Duff Cooper's death in 1954, a group of his friends decided to establish a trust to endow a literary prize in his memory. The trust appoints five judges. Two of them are \"ex officio\": the Warden of New College, Oxford, and a member of Duff Cooper's family (initially, Duff Cooper's son, John Julius Norwich for the first thirty-six years, and then John Julius' daughter, Artemis Cooper). The other three judges appointed by the trust serve for five years and they appoint their own successors. The first three judges were Maurice Bowra, Cyril Connolly and Raymond Mortimer. At present, the three appointed judges are writer and biographer Patrick Marnham, film critic John McBratney, and former \"TLS\" editor Lindsay Duguid. \n\nFrom 2013, the prize has been known as The Pol Roger Duff Cooper Prize, following a sponsorship by Pol Roger.\n\nSource: Duff Cooper Prize\n\n\n\n"}
{"id": "1291656", "url": "https://en.wikipedia.org/wiki?curid=1291656", "title": "Early modern period", "text": "Early modern period\n\nThe early modern period of modern history follows the late Middle Ages of the post-classical era. Although the chronological limits of the period are open to debate, the timeframe spans the period after the late portion of the post-classical age (c. 1500), known as the Middle Ages, through the beginning of the Age of Revolutions (c. 1800) and is variously demarcated by historians as beginning with the Fall of Constantinople in 1453, with the Renaissance period, and with the Age of Discovery (especially with the voyages of Christopher Columbus beginning in 1492, but also with Vasco da Gama's discovery of the sea route to the East in 1498), and ending around the French Revolution in 1789.\n\nHistorians in recent decades have argued that from a worldwide standpoint, the most important feature of the early modern period was its globalizing character. The period witnessed the exploration and colonization of the Americas and the rise of sustained contacts between previously isolated parts of the globe. The historical powers became involved in global trade, as the exchange of goods, plants, animals, and food crops extended to the Old World and the New World. The Columbian Exchange greatly affected the human environment.\n\nNew economies and institutions emerged, becoming more sophisticated and globally articulated over the course of the early modern period. This process began in the medieval North Italian city-states, particularly Genoa, Venice, and Milan. The early modern period also included the rise of the dominance of the economic theory of mercantilism. The European colonization of the Americas, Asia, and Africa occurred during the 15th to 19th centuries, and spread Christianity around the world.\n\nThe early modern trends in various regions of the world represented a shift away from medieval modes of organization, politically and economically. Feudalism declined in Europe, while the period also included the Protestant Reformation, the disastrous Thirty Years' War, the Commercial Revolution, the European colonization of the Americas, and the Golden Age of Piracy.\n\nBy the 16th century the economy under the Ming Dynasty was stimulated by trade with the Portuguese, the Spanish, and the Dutch, while Japan engaged in the Nanban trade after the arrival of the first European Portuguese during the Azuchi-Momoyama period.\n\nOther notable trends of the early modern period include the development of experimental science, accelerated travel due to improvements in mapping and ship design, increasingly rapid technological progress, secularized civic politics, and the emergence of nation states. Historians typically date the end of the early modern period when the French Revolution of the 1790s began the \"late modern\" period.\n\nAround the beginning of the Ming dynasty (1368—1644), China was leading the world in mathematics as well as science. However, Europe soon caught up to China's scientific and mathematical achievements and surpassed them. The reason behind China's lag in advancement has speculated by many scholars. A historian named Colin Ronan claims that though there is no one specific answer, there must be a connection between China's urgency for new discoveries being weaker than Europe's and China's inability to capitalize on its early advantages. Ronan believes that China's Confucian bureaucracy and traditions led to China not having a scientific revolution, which led China to have fewer scientists who would break the existing orthodoxies, like Galileo Galilei. Despite inventing gunpowder in the 9th century, it was in Europe that the classic handheld firearms, matchlocks, were invented, with evidence of use around the 1480s. China was using the matchlocks by 1540, after the Portuguese brought their matchlocks to Japan in the early 1500s. China during the Ming Dynasty established a bureau to maintain its calendar. The bureau was necessary because the calendars were linked to celestial phenomena and that needs regular maintenance because twelve lunar months have 344 or 355 days, so occasional leap months have to be added in order to maintain 365 days per year.\n\nIn the 16th century the Ming dynasty flourished over maritime trade with the Portuguese, Spanish and Dutch Empires. The trade brought in a massive amount of silver, which China at the time needed desperately. Prior to China's global trade, its economy ran on a paper money. However, in the 14th century, China's paper money system suffered a crisis, and by the mid-15th century, crashed. The silver imports helped fill the void left by the broken paper money system, which helps explain why the value of silver in China was twice as high as the value of silver in Spain during the end of the 16th century.\n\nThe Ming Dynasty suffered an economic collapse in the seventeenth-century because of heavy inflation of silver, and the European trade depression of the 1620s. The economy sunk to the point where all of China's trading partner cut ties with them: Philip IV restricted shipments of exports from Acapulco, the Japanese cut off all trade with Macau, and the Dutch severed connections between Gao and Macau.\n\nThe damage to the economy was compounded by the effects on agriculture of the incipient Little Ice Age, natural calamities, crop failure and sudden epidemics. The ensuing breakdown of authority and people's livelihoods allowed rebel leaders, such as Li Zicheng, to challenge Ming authority.\n\nThe Ming Dynasty fell around 1644 to the Qing Dynasty, the last ruling dynasty of China, ruling from 1644 to 1912 (with a brief, abortive restoration in 1917). During its reign, the Qing Dynasty became highly integrated with Chinese culture.\n\nFollowing contact with the Portuguese on Tanegashima Isle in 1543, the Japanese adopted several of the technologies and cultural practices of their visitors, whether in the military area (the arquebus, European-style cuirasses, European ships), religion (Christianity), decorative art, language (integration to Japanese of a Western vocabulary) and culinary: the Portuguese introduced tempura and valuable refined sugar.\n\nThe Azuchi–Momoyama period saw the political unification that preceded the establishment of the Tokugawa shogunate. Although a start date of 1573 is often given, in more broad terms, the period begins with Oda Nobunaga's entry into Kyoto in 1568, when he led his army to the imperial capital in order to install Ashikaga Yoshiaki as the 15th, and ultimately final, shōgun of the Ashikaga shogunate, and it lasts until the coming to power of Tokugawa Ieyasu after his victory over supporters of the Toyotomi clan at the Battle of Sekigahara in 1600.\n\nThe Edo period from 1600 to 1868 characterized early modern Japan. The Tokugawa shogunate was a feudalist regime of Japan established by Tokugawa Ieyasu and ruled by the \"shōguns\" of the Tokugawa clan. The period gets its name from the capital city, Edo, now called Tokyo. The Tokugawa shogunate ruled from Edo Castle from 1603 until 1868, when it was abolished during the Meiji Restoration in the late Edo period (often called the Late Tokugawa shogunate).\n\nIn 1392, General Yi Seong-gye established the Joseon dynasty (1392–1910) with a largely bloodless coup. Yi Seong-gye moved the capital of Korea to the location of modern-day Seoul. The dynasty was heavily influenced by Confucianism, which also played a large role to shaping Korea's strong cultural identity. King Sejong the Great (1418–1450), one of the only two kings in Korea's history to earn the title of great in their posthumous titles, reclaimed Korean territory to the north and created the Korean alphabet, Hangeul.\n\nDuring the end of the 16th century, Korea was invaded twice by Japan, first in 1592 and again in 1597. Japan failed both times due to Admiral Yi Sun-sin, Korea's revered naval genius, who lead the Korean Navy using advanced metal clad ships called turtle ships. Because the ships were armed with cannons, Admiral Yi's navy was able to demolish the Japanese invading fleets, destroying hundreds of ships in Japan's second invasion. During the 17th century, Korea was invaded again, this time by the Manchurian, who would later take over China as the Qing Dynasty. In 1637, King Injo was forced to surrender to the Qing forces, and was ordered to send princesses as concubine to the Qing Prince Dorgon.\n\nAfter invasions from Manchuria, Joseon experienced nearly 200 years of peace. However, whatever power the kingdom recovered during its isolation further waned as the 18th century came to a close, and Korea was faced with internal strife, power struggles, international pressure and rebellions at home. The Joseon dynasty declined rapidly in the late 19th century.\n\nOn the Indian subcontinent, the Lodi dynasty ruled over the Delhi Sultanate during its last phase. The dynasty founded by Bahlul Lodi ruled from 1451 to 1526. The dynasty's last ruler, Ibrahim Lodhi, was defeated and killed by Babur in the first Battle of Panipat.\n\nThe Vijayanagara Empire was based in the Deccan Plateau, but its power was diminished after a major military defeat in 1565 by the Deccan sultanates. The empire is named after its capital city of Vijayanagara.\n\nThe rise of the Great Mughal Empire is usually dated from 1526, around the end of the Middle Ages. It was an Islamic Persianate imperial power that ruled most of the area as Hindustan by the late 17th and the early 18th centuries. The empire dominated South and Southwestern Asia.\n\nAt the start of the modern era, the Spice Route between India and China crossed Majapahit, an archipelagic empire based on the island of Java. It was the last of the major Hindu empires of Maritime Southeast Asia and is considered one of the greatest states in Indonesian history. Its influence extended to states in Sumatra, the Malay Peninsula, Borneo and eastern Indonesia, but the effectiveness of the influence is the subject of debate. Majapahit found itself unable to control the rising power of the Sultanate of Malacca, which grew to stretch from Muslim Malay settlements of Bukit (Phuket), Setol (Satun), Pantai ni (Pattani) bordering Ayutthaya Kingdom of Siam (Thailand) in the north to Sumatra in the southwest. The Portuguese invaded its capital in 1511 and in 1528 the Sultanate of Johor was established by a Malaccan prince to succeed Malacca.\n\nDuring the early modern era, the Ottoman state enjoyed an expansion and consolidation of power, leading to a \"Pax Ottomana\". This was perhaps the golden age of the Ottoman Empire. The Ottomans expanded southwest into North Africa while battling with the re-emergent Persian Shi'a Safavid Empire to the east.\n\nIn the Saracen sphere, the Ottomans seized Egypt in 1517 and established the regencies of Algeria, Tunisia, and Tripoli (between 1519 and 1551), Morocco remaining an independent Arabized Berber state under the Sharifan dynasty.\n\nIn the Ethiopian Highlands, the Solomonic dynasty established itself in the 13th century. Claiming direct descent from the old Axumite royal house, the Solomonic ruled the region well into modern history. In the 16th century, Shewa and the rest of Abyssinia were conquered by the forces of Ahmed Gurey of the Adal Sultanate to the northwest. The conquest of the area by the Oromo ended in the contraction of both Adal and Abyssinia, changing regional dynamics for centuries to come.\n\nThe Ajuran Empire, which was one of the largest and strongest empires in the Horn of Africa, began to decline in the 17th century, and several powerful successor states came to prominence. The Geledi Sultanate, established by Ibrahim Adeer, was a notable successor of the Ajuran Sultanate. The Sultanate reached its apex under the successive reigns of Sultan Yusuf Mahamud Ibrahim (reigned 1798 to 1848), who successfully consolidated Geledi power during the Bardera wars, and Sultan Ahmed Yusuf, who forced regional powers such as the Omani Empire to pay tribute. The Majeerteen Sultanate was a Somali Sultanate in the Horn of Africa. Ruled by King Osman Mahamuud during its golden age, it controlled much of northern and central Somalia in the 19th and early 20th centuries. The polity had all of the organs of an integrated modern state and maintained a robust trading network. Along with the Sultanate of Hobyo ruled by Sultan Yusuf Ali Kenadid, the Majeerteen Sultanate was eventually annexed into Italian Somaliland in the early 20th century, following the military Campaign of the Sultanates.\n\nThe Songhai Empire took control of the trans-Saharan trade at the beginning of the modern era. It seized Timbuktu in 1468 and Jenne in 1473, building the regime on trade revenues and the cooperation of Muslim merchants. The empire eventually made Islam the official religion, built mosques, and brought Muslim scholars to Gao.\n\nAround the beginning of the modern era, the Benin Kingdom was an independent trading power in the southeastern coastline of West Africa, blocking the access of other inland nations to the coastal ports. Benin may have housed 100,000 inhabitants at its height, spreading over twenty-five square kilometres, enclosed by three concentric rings of earthworks. By the late 15th century Benin was in contact with Portugal. At its apogee in the 16th and 17th centuries, Benin encompassed parts of southeastern Yorubaland and the western Igbo.\n\nThe Safavid Empire was a great Shia Persianate empire after the Islamic conquest of Persia and established of Islam, marking an important point in the history of Islam in the east. The Safavid dynasty was founded about 1501. From their base in Ardabil, the Safavids established control over all of Persia and reasserted the Iranian identity of the region, thus becoming the first native dynasty since the Sassanids to establish a unified Iranian state. Problematic for the Safavids was the powerful Ottoman Empire. The Ottomans, a Sunni dynasty, fought several campaigns against the Safavids.\n\nWhat fueled the growth of Safavid economy was its position between the burgeoning civilizations of Europe to its west and Islamic Central Asia to its east and north. The Silk Road, which led from Europe to East Asia, revived in the 16th century. Leaders also supported direct sea trade with Europe, particularly England and The Netherlands, which sought Persian carpet, silk, and textiles. Other exports were horses, goat hair, pearls, and an inedible bitter almond hadam-talka used as a spice in India. The main imports were spice, textiles (woolens from Europe, cotton from Gujarat), metals, coffee, and sugar. Despite their demise in 1722, the Safavids left their mark by establishing and spreading Shi'a Islam in major parts of the Caucasus and West Asia.\n\nIn the 16th to early 18th centuries, Central Asia was under the rule of Uzbeks, and the far eastern portions were ruled by the local Pashtuns. Between the 15th and 16th centuries, various nomadic tribes arrived from the steppes, including the Kipchaks, Naymans, Kanglis, Khongirad, and Manguds. These groups were led by Muhammad Shaybani, who was the Khan of the Uzbeks.\n\nThe lineage of the Afghan Pashtuns stretches back to the Hotaki dynasty. Following Muslim Arab and Turkic conquests, Pashtun \"ghazis\" (warriors for the faith) invaded and conquered much of northern India during the Lodhi dynasty and Suri dynasty. Pashtun forces also invaded Persia, and the opposing forces were defeated in the Battle of Gulnabad. The Pashtuns later formed the Durrani Empire.\n\nThis era in Western Europe is referred to as the early modern European period and includes the Protestant Reformation, the European wars of religion, the Age of Discovery and the beginning of European colonialism, the rise of strong centralized governments, the beginnings of recognizable nation-states that are the direct antecedents of today's states, the Age of Enlightenment, and from the associated scientific advances the first phase of the Industrial Revolution. The emergence of cultural and political dominance of the Western world during this period is known as the Great Divergence.\n\nThe early modern period is taken to end with the French Revolution, the Napoleonic Wars, and the dissolution of the Holy Roman Empire at the Congress of Vienna.\nAt the end of the early modern period, the British and Russian empires had emerged as world powers from the multipolar contest of colonial empires, while the three great Asian empires of the early modern period, Ottoman Turkey, Mughal India and Qing China, all entered a period of stagnation or decline.\n\nThe expression \"early modern\" is at times incorrectly used as a substitute for the term Renaissance. However, \"Renaissance\" is properly used in relation to a diverse series of cultural developments that occurred over several hundred years in many different parts of Europe — especially central and northern Italy — and it spans the transition from late medieval civilization to the opening of the early modern period. In the visual arts and architecture, the term 'early modern' is not a common designation as the Renaissance period is clearly distinct from what came later. Only in the study of literature is the early modern period a standard designation. European music of the period is generally divided between Renaissance and Baroque. Similarly, philosophy is divided between Renaissance philosophy and the Enlightenment. In other fields, there is far more continuity through the period such as warfare and science.\n\nWhen gunpowder was introduced to Europe, it was immediately used almost exclusively in weapons and explosives for warfare. Though it was invented in China, gunpowder arrived in Europe already formulated for military use and European countries took advantage of it and were the first to create the classic firearms. The advances made in gunpowder and firearms was directly tied to the decline in the use of plate armor because of the inability of the armor to protect one from bullets.\n\nIn the early modern period, the Holy Roman Empire was a union of territories in Central Europe under a Holy Roman Emperor the first of which was Otto I. The last was Francis II, who abdicated and dissolved the Empire in 1806 during the Napoleonic Wars. Despite its name, for much of its history the Empire did not include Rome within its borders.\n\nThe Renaissance was a cultural movement that spanned roughly the 14th to the 17th century, beginning in Italy in the Late Middle Ages and later spreading to the rest of Europe. The term is also used more loosely to refer to the historic era, but since the changes of the Renaissance were not uniform across Europe, this is a general use of the term. As a cultural movement, it encompassed a rebellion of learning based on classical sources, the development of linear perspective in painting, and gradual but widespread educational reform.\n\nJohannes Gutenberg is credited as the first European to use movable type printing, around 1439, and as the global inventor of the mechanical printing press. Nicolaus Copernicus formulated a comprehensive heliocentric cosmology (1543), which displaced the Earth from the center of the universe. His book, \"De revolutionibus orbium coelestium\" (\"On the Revolutions of the Celestial Spheres\") began modern astronomy and sparked the Scientific Revolution. Another notable individual was Machiavelli, an Italian political philosopher, considered a founder of modern political science. Machiavelli is most famous for a short political treatise, The Prince, a work of realist political theory.\n\nAmong the notable royalty of the time, Charles the Bold, known as \"Charles the Bold (or Rash)\" to his enemies, he was the last Valois Duke of Burgundy, and his early death was a pivotal, if under-recognized, moment in European history. Charles has often been regarded as the last representative of the feudal spirit — a man who possessed no other quality than a blind bravery. Upon his death, Charles left an unmarried nineteen-year-old daughter, Mary of Burgundy, as his heir. Her marriage would have enormous implications for the political balance of Europe. The Habsburg Emperor secured the match for his son, the future Maximilian I, Holy Roman Emperor, with the aid of Mary's stepmother, Margaret. In 1477, the territory of the Duchy of Burgundy was annexed by France. In the same year, Mary married Maximilian, Archduke of Austria, giving the Habsburgs control of the remainder of the Burgundian Inheritance.\n\nClaude de Lorraine was the first Duke of Guise, from 1528 to his death. Claude distinguished himself at the battle of Marignano (1515), and was long in recovering from the twenty-two wounds he received in the battle. In 1521, he fought at Fuenterrabia, and Louise of Savoy ascribed the capture of the place to his efforts. In 1523 he became governor of Champagne and Burgundy, after defeating at Neufchâteau the imperial troops who had invaded this province. In 1525 he destroyed the Anabaptist peasant army, which was overrunning Lorraine, at Lupstein, near Saverne (Zabern). On the return of Francis I from captivity in 1528, Claude was made Duke of Guise in the peerage of France, though up to this time only princes of the royal house had held the title of duke and peer of France. The Guises, as cadets of the sovereign house of Lorraine and descendants of the house of Anjou, claimed precedence of the Bourbon princes of Condé and Conti.\n\nThe 3rd Duke of Alba was a nobleman of importance in the early modern period, nicknamed the \"Iron Duke\" by the Protestants of the Low Countries because of his harsh rule and cruelty. Tales of atrocities committed during his military operations in Flanders became part of Dutch and English folklore, forming a central component of the Black Legend.\n\nIn England, Henry VIII was the King of England and a significant figure in the history of the English monarchy. Although in the greater part of his reign he brutally suppressed the influence of the Protestant Reformation in England, a movement having some roots with John Wycliffe in the 14th century, he is more popularly known for his political struggles with Rome. These struggles ultimately led to the separation of the Church of England from papal authority, the Dissolution of the Monasteries, and establishing himself as the Supreme Head of the Church of England. Though Henry reportedly became a Protestant on his death-bed, he advocated Catholic ceremony and doctrine throughout his life. Royal support for the English Reformation began with his heirs, the devout Edward VI and the renowned Elizabeth I, whilst daughter Mary I temporarily reinstated papal authority over England. Henry also oversaw the legal union of England and Wales with the Laws in Wales Acts 1535–1542. He is also noted for his six wives, two of whom were beheaded.\n\nChristianity was challenged at the beginning of the modern period with the fall of Constantinople in 1453 and later by various movements to reform the church (including Lutheran, Zwinglian, and Calvinist), followed by the Counter Reformation.\n\nThe Hussite Crusades involved the military actions against and amongst the followers of Jan Hus in Bohemia ending ultimately with the Battle of Grotniki. Also known as the Hussite Wars, they were arguably the first European war in which hand-held gunpowder weapons such as muskets made a decisive contribution. The Taborite faction of the Hussite warriors were basically infantry, and their many defeats of larger armies with heavily armored knights helped effect the infantry revolution. In totality, the Hussite Crusades were inconclusive.\n\nThe last crusade, the \"Crusade of 1456\", was organized to counter the expanding Ottoman Empire and lift the Siege of Belgrade, and was led by John Hunyadi and Giovanni da Capistrano. The siege eventually escalated into a major battle, during which Hunyadi led a sudden counterattack that overran the Turkish camp, ultimately compelling the wounded Sultan Mehmet II to lift the siege and retreat. The siege of Belgrade has been characterized as having \"decided the fate of Christendom\". The noon bell ordered by Pope Callixtus III commemorates the victory throughout the Christian world to this day.\n\nNearly a hundred years later, the Peace of Augsburg officially ended the idea that all Christians could be united under one church. The principle of \"cuius regio, eius religio\" (\"whose the region is, [it shall have] his religion\") established the religious, political and geographic divisions of Christianity, and this was established in international law with the Treaty of Westphalia in 1648, which legally ended the concept of a single Christian hegemony, i.e. the \"One, Holy, Catholic, and Apostolic Church\" of the Nicene Creed. Each government determined the religion of their own state. Christians living in states where their denomination was \"not\" the established church were guaranteed the right to practice their faith in public during allotted hours and in private at their will. With the Treaty of Westphalia, the Wars of Religion came to an end, and in the Treaty of Utrecht of 1713 the concept of the sovereign national state was born. The \"Corpus Christianum\" has since existed with the modern idea of a tolerant and diverse society consisting of many different communities.\n\nThe modern Inquisition refers to any one of several institutions charged with trying and convicting heretics (or other offenders against canon law) within the Catholic Church. In the modern era, the first manifestation was the Spanish Inquisition of 1478 to 1834. The Inquisition prosecuted individuals accused of a wide array of crimes related to heresy, including sorcery, blasphemy, Judaizing and witchcraft, as well for censorship of printed literature. Because of its objective — combating heresy — the Inquisition had jurisdiction only over baptized members of the Church (which, however, encompassed the vast majority of the population in Catholic countries). Secular courts could still try non-Christians for blasphemy (most of the witch trials went through secular courts).\n\nThe Protestant Reformation and rise of modernity in the early 16th century entailed the start of a series of changes in the \"Corpus Christianum\". Martin Luther challenged the Catholic Church with his Ninety-Five Theses, generally accepted as the beginning of the Reformation, a Christian reform movement in Europe, though precursors such as Jan Hus predate him. The Protestant movement of the 16th century occurred under the protection of the Electorate of Saxony, an independent hereditary electorate of the Holy Roman Empire. The Elector Frederick III established a university at Wittenberg in 1502. The Augustinian monk Martin Luther became professor of philosophy there in 1508. At the same time, he became one of the preachers at the castle church of Wittenberg.\n\nOn 31 October 1517, Luther posted his \"Ninety-Five Theses\" on the door of the All Saints' Church, which served as a notice board for university-related announcements. These were points for debate that criticized the Church and the Pope. The most controversial points centered on the practice of selling indulgences (especially by Johann Tetzel) and the Church's policy on purgatory. The reform movement soon split along certain doctrinal lines. Religious disagreements between various leading figures led to the emergence of rival Protestant churches. The most important denominations to emerge directly from the Reformation were the Lutherans, and the Reformed/Calvinists/Presbyterians. The process of reform had decidedly different causes and effects in other countries. In England, where it gave rise to Anglicanism, the period became known as the English Reformation. Subsequent Protestant denominations generally trace their roots back to the initial reforming movements.\n\nThe Diet of Worms in 1521, presided by Emperor Charles V, declared Martin Luther a heretic and an outlaw (although Charles V was more preoccupied with maintaining his vast empire than with arresting Luther). As a result of Charles V's distractions in East Europe and in Spain, he agreed through the Diet of Speyer in 1526 to allow German princes to effectively decide themselves whether to enforce the Edict of Worms or not, for the time being. After returning to the empire, Charles V attended the Diet of Augsburg in 1530 to order all Protestants in the empire to revert to Catholicism. In response, the Protestant territories in and around Germany formed the Schmalkaldic League to fight against the Catholic Holy Roman Empire. Charles V left again to handle the advance of the Ottoman Turks. He returned in 1547 to launch a military campaign against the Schmalkaldic League and to issue an imperial law requiring all Protestants to return to Catholic practices (with a few superficial concessions to Protestant practices). Warfare ended when Charles V relented in the Peace of Passau (1552) and in the Peace of Augsburg (1555), which formalized the law that the rulers of a land decide its religion.\n\nOf the late Inquisitions in the modern era, there were two different manifestations:\nThis Portuguese inquisition was a local analogue of the more famous Spanish Inquisition. The Roman Inquisition covered most of the Italian peninsula as well as Malta and also existed in isolated pockets of papal jurisdiction in other parts of Europe, including Avignon.\n\nThe Catholic Reformation began in 1545 when the Council of Trent was called in reaction to the \"Protestant Rebellion\". The idea was to reform the state of worldliness and disarray that had befallen some of the clergy of the Church, while reaffirming the spiritual authority of the Catholic Church and its position as the sole true Church of Christ on Earth. The effort sought to prevent further damage to the Church and her faithful at the hands of the newly formed Protestant denominations.\n\nIn development of the Third Rome ideas, the Grand Duke Ivan IV (the \"Awesome\" or \"the Terrible\") was officially crowned the first Tsar (\"Caesar\") of Russia in 1547. The Tsar promulgated a new code of laws (Sudebnik of 1550), established the first Russian feudal representative body (Zemsky Sobor) and introduced local self-management into the rural regions. During his long reign, Ivan IV nearly doubled the already large Russian territory by annexing the three Tatar khanates (parts of disintegrated Golden Horde): Kazan and Astrakhan along the Volga River, and Sibirean Khanate in South Western Siberia. Thus by the end of the 16th century Russia was transformed into a multiethnic, multiconfessional and transcontinental state.\n\nThe Age of Discovery was a period from the early 15th century and continuing into the early 17th century, during which European ships traveled around the world to search for new trading routes and partners to feed burgeoning capitalism in Europe. They also were in search of trading goods such as gold, silver and spices. In the process, Europeans encountered peoples and mapped lands previously unknown to them. This factor in the early European modern period was a globalizing character; the 'discovery' of the Americas and the rise of sustained contacts between previously isolated parts of the globe was an important historical event.\n\nThe search for new routes was based on the fact that the Silk Road was controlled by the Ottoman Empire, which was an impediment to European commercial interests, and other Eastern trade routes were not available to the Europeans due to Muslim control. The ability to outflank the Muslim states of North Africa was seen as crucial to European survival. At the same time, the Iberians learnt much from their Arab neighbors. The northwestern region of Eurasia has a very long coastline, and has arguably been more influenced by its \"maritime history\" than any other continent. Europe is uniquely situated between several navigable seas, and intersected by navigable rivers running into them in a way that greatly facilitated the influence of maritime traffic and commerce. In the maritime history of Europe, the carrack and caravel both incorporated the lateen sail that made ships far more maneuverable. By translating the Arab versions of lost ancient Greek geographical works into Latin, European navigators acquired a deeper knowledge of the shape of Africa and Asia.\n\nMercantilism was the dominant school of economic thought throughout the early modern period (from the 16th to the 18th century). This led to some of the first instances of significant government intervention and control over the economy, and it was during this period that much of the modern capitalist system was established. Internationally, mercantilism encouraged the many European wars of the period and fueled European imperialism. Belief in mercantilism began to fade in the late 18th century, as the arguments of Adam Smith and the other classical economists won out.\n\nThe Commercial Revolution was a period of economic expansion, colonialism, and mercantilism that lasted from approximately the 16th century until the early 18th century. Beginning with the Crusades, Europeans rediscovered spices, silks, and other commodities rare in Europe. This development created a new desire for trade, which expanded in the second half of the Middle Ages. European nations, through voyages of discovery, were looking for new trade routes in the fifteenth and sixteenth centuries, which allowed the European powers to build vast, new international trade networks. Nations also sought new sources of wealth. To deal with this new-found wealth, new economic theories and practices were created. Because of competing national interest, nations had the desire for increased world power through their colonial empires. The Commercial Revolution is marked by an increase in general commerce, and in the growth of non-manufacturing pursuits, such as banking, insurance, and investing.\n\nIn the Old World, the most desired trading goods were gold, silver, and spices. Western Europeans used the compass, new sailing ship technologies, new maps, and advances in astronomy to seek a viable trade route to Asia for valuable spices that Mediterranean powers could not contest.\n\nIn terms of shipping advances, the most important developments were the creation of the carrack and caravel designs in Portugal. These vessels evolved from medieval European designs from the North Sea and both the Christian and Islamic Mediterranean. They were the first ships that could leave the relatively placid and calm Mediterranean, Baltic or North Sea and sail safely on the open Atlantic.\n\nWhen the carrack and then the caravel were developed in Iberia, European thoughts returned to the fabled East. These explorations have a number of causes. Monetarists believe the main reason the Age of Exploration began was because of a severe shortage of bullion in Europe. The European economy was dependent on gold and silver currency, but low domestic supplies had plunged much of Europe into a recession. Another factor was the centuries-long conflict between the Iberians and the Muslims to the south.\n\nThe Golden Age of Piracy is a designation given to one or more outbursts of piracy in the early modern period, spanning from the mid-17th century to the mid-18th century. The buccaneering period covers approximately the late 17th century. The period is characterized by Anglo-French seamen based on Jamaica and Tortuga attacking Spanish colonies and shipping in the Caribbean and eastern Pacific. A sailing route known as the Pirate Round was followed by certain Anglo-American pirates at the turn of the 18th century, associated with long-distance voyages from Bermuda and the Americas to rob Muslim and East India Company targets in the Indian Ocean and Red Sea. The post-Spanish Succession period extending into the early 18th century, when Anglo-American sailors and privateers left unemployed by the end of the War of the Spanish Succession turned en masse to piracy in the Caribbean, the American eastern seaboard, the West African coast, and the Indian Ocean.\n\nThe 15th to 18th century period is marked by the first European colonies, the rise of strong centralized governments, and the beginnings of recognizable European nation states that are the direct antecedents of today's states. Although the Renaissance included revolutions in many intellectual pursuits, as well as social and political upheaval, it is perhaps best known for European artistic developments and the contributions of such polymaths as Leonardo da Vinci and Michelangelo, who inspired the term \"Renaissance man\".\n\nDuring the Baroque period the Thirty Years' War in Central Europe decimated the population by up to 20%. In 1648, the Peace of Westphalia, consisting of the treaties of Osnabrück and Münster, signed on May 15 and October 24, respectively, ended several wars in Europe and established the beginning of sovereign states. The treaties involved the Holy Roman Emperor, Ferdinand III (Habsburg), the Kingdoms of Spain, France and Sweden, the Netherlands and their respective allies among the princes and the Republican Imperial States of the Holy Roman Empire.\n\nThe Peace of Westphalia resulted from the first modern diplomatic congress. Until 1806, the regulations became part of the constitutional laws of the Holy Roman Empire. The Treaty of the Pyrenees, signed in 1659, ended the war between France and Spain and is often considered part of the overall accord.\n\nThe Age of Absolutism describes the monarchical power that was unrestrained by any other institutions, such as churches, legislatures, or social elites of the European monarchs during the transition from feudalism to capitalism. Monarchs described as absolute can especially be found in the 17th century through the 19th century. Nations that adopted Absolutism include France, Prussia, and Russia. Nobles tended to trade privileges for allegiance throughout the eighteenth century, so that the interests of the nobility aligned with that of the crown. Absolutism is characterized by the ending of feudal partitioning, consolidation of power with the monarch, rise of state power, unification of the state laws, drastic increase in tax revenue collected by the monarch, and a decrease in the influence of nobility.\n\nFor much of the reign of Louis XIV, who was known as the \"Sun King\" (French: \"le Roi Soleil\"), France stood as the leading power in Europe, engaging in three major wars—the Franco-Dutch War, the War of the League of Augsburg, and the War of the Spanish Succession—and two minor conflicts—the War of Devolution, and the War of the Reunions. Louis believed in the Divine Right of Kings, the theory that the King was crowned by God and accountable to him alone. Consequently, he has long been considered the archetypal absolute monarch. Louis XIV continued the work of his predecessor to create a centralized state, governed from the capital to sweep away the remnants of feudalism that persisted in parts of France. He succeeded in breaking the power of the provincial nobility, much of which had risen in revolt during his minority called the Fronde, and forced many leading nobles to live with him in his lavish Palace of Versailles.\n\nMen who featured prominently in the political and military life of France during this period include Mazarin, Jean-Baptiste Colbert, Turenne, Vauban. French culture likewise flourished during this era, producing a number of figures of great renown, including Molière, Racine, Boileau, La Fontaine, Lully, Le Brun, Rigaud, Louis Le Vau, Jules Hardouin Mansart, Claude Perrault and Le Nôtre.\n\nBefore the Age of Revolution, the English Civil War was a series of armed conflicts and political machinations between Parliamentarians and Royalists. The first and second civil wars pitted the supporters of King Charles I against the supporters of the Long Parliament, while the third war saw fighting between supporters of King Charles II and supporters of the Rump Parliament. The Civil War ended with the Parliamentary victory at the Battle of Worcester. The monopoly of the Church of England on Christian worship in England ended with the victors consolidating the established Protestant Ascendancy in Ireland. Constitutionally, the wars established the precedent that an English monarch cannot govern without Parliament's consent. The English Restoration, or simply put as the Restoration, began in 1660 when the English, Scottish and Irish monarchies were all restored under Charles II after the Commonwealth of England that followed the English Civil War. The Glorious Revolution of 1688 establishes modern parliamentary democracy in England.\n\nThe War of the Spanish Succession was a war fought between 1701 and 1714, in which several European powers combined to stop a possible unification of the Kingdoms of Spain and France under a single Bourbon monarch, upsetting the European balance of power. It was fought mostly in Europe, but it included Queen Anne's War in North America. The war was marked by the military leadership of notable generals like the duc de Villars, the Jacobite Duke of Berwick, the Duke of Marlborough and Prince Eugene of Savoy.\n\nThe Peace of Utrecht established after a series of individual peace treaties signed in the Dutch city of Utrecht concluded between various European states helped end the War of the Spanish Succession. The representatives who met were Louis XIV of France and Philip V of Spain on the one hand, and representatives of Queen Anne of Great Britain, the Duke of Savoy, and the United Provinces on the other. The treaty enregistred the defeat of French ambitions expressed in the wars of Louis XIV and preserved the European system based on the balance of power. The Treaty of Utrecht marked the change from Spanish to British naval supremacy.\n\nThe term \"colonialism\" is normally used with reference to discontiguous overseas empires rather than contiguous land-based empires, European or otherwise. European colonisation during the 15th to 19th centuries resulted in the spread of Christianity to Sub-Saharan Africa, the Americas, Australia and the Philippines.\n\nChristopher Columbus discovered the Americas in 1492. Subsequently, the major sea powers in Europe sent expeditions to the New World to build trade networks and colonies and to convert the native peoples to Christianity. Pope Alexander VI divided newly discovered lands outside Europe between Spain and Portugal along a north-south meridian 370 leagues west of the Cape Verde islands (off the west coast of Africa). The division was never accepted by the rulers of England or France. (See also the Treaty of Tordesillas, which followed the papal decree.)\n\nWhat is now called Latin America, a designation first used in the late 19th century, was claimed by Spain and Portugal. The Western Hemisphere, the New World, was divided between the two Iberian powers by the Treaty of Tordesillas in what until the late 16th-century, was an area that could be called \"Ibero-America.\" Spain called its overseas empire there \"The Indies,\" with Portugal calling its territory in South America Brazil, after the dyewood found there. Spain concentrated building its empire where there were large indigenous populations, \"Indians,\" who could be compelled to work and large deposits of precious metals, mainly silver. Both New Spain (colonial Mexico) and Peru fit those criteria and the Spanish crown established viceroyalties to rule those two large areas. As Spanish settlements and the economy grew in size and complexity, the Spanish established viceroyalties in the eighteenth century during administrative reforms Rio de la Plata (southeastern South America) and New Granada (northern South America).\n\nInitially, Portuguese settlements (Brazil) in the coastal northeast were of lesser importance in the larger Portuguese overseas empire, where lucrative commerce and small settlements devoted to trade were established in coastal Africa, India and China. With sparse indigenous populations that could not be coerced to work and no known deposits of precious metals, Portugal sought a high-value, low-bulk export product and found it in sugarcane. Black African slave labour from Portugal's West African possessions was imported to do the grueling agricultural work. As the wealth of the Ibero-America increased, some Western European powers (Dutch, French, British, Danish) sought to duplicate the model in areas that the Iberians had not settled in numbers. They seized Caribbean islands from the Spanish and transferred the model of sugar production on plantations with slave labour and settled in northern areas of North America in what are now the Eastern Seaboard of the United States and Canada.\n\nNorth America outside the zone of Spanish settlement was a contested area in the 17th century. Spain had founded small settlements in Florida and Georgia but nowhere near the size of those in New Spain or the Caribbean islands. France, The Netherlands, and Great Britain held several colonies in North America and the West Indies from the 17th century, 100 years after the Spanish and Portuguese established permanent colonies. The British colonies in North America were founded between 1607 (Virginia) and 1733 (Georgia). The Dutch explored the east coast of North America and began founding settlements in what they called New Netherland (now New York State.). France colonized what is now Eastern Canada, founding Quebec City in 1608. France's loss in the Seven Years' War resulted in the transfer of New France to Great Britain. The Thirteen Colonies, in lower British North America, rebelled against British rule in 1775, largely due to the taxation that Great Britain was imposing on the colonies. The British colonies in Canada remained loyal to the crown, and a provisional government formed by the Thirteen Colonies proclaimed their independence on July 4, 1776 and subsequently became the original 13 United States of America. With the 1783 Treaty of Paris ending the American Revolutionary War, Britain recognised the former Thirteen Colonies' independence.\n\nA recent development in early modern history is the creation of Atlantic World as a category. The term generally encompasses western Europe, West Africa, North and South and America and the Caribbean islands. It seeks to show both local and regional development and the connections between the various geographical regions.\n\nConcerning the development of Eastern philosophies, much of Eastern philosophy had been in an advanced state of development from study in the previous centuries. The various philosophies include Indian philosophy, Chinese philosophy, Iranian philosophy, Japanese philosophy, and Korean philosophy.\n\nThe Islamic Golden Age reached its peak in the High Middle Ages, stopped short by the Mongol invasions of the 13th century. The re-establishment of three major Muslim empires by the 16th century (the aforementioned Ottoman Safavid and Mughal Empires) gave rise to a Muslim cultural revival. The Safavids established Twelver Shi'a Islam as Iran's official religion, thus giving Iran a separate identity from its Sunni neighbors.\n\nThe early modern period was initiated by the Protestant Reformation and the collapse of the unity of the medieval Western Church.\nThe theology of Calvinism in particular has been argued as instrumental to the rise of capitalism (\"The Protestant Ethic and the Spirit of Capitalism\").\n\nThe Counter-Reformation was a period of Catholic revival in response to the Protestant Reformation during the mid-16th to mid-17th centuries. The Counter-Reformation was a comprehensive effort, involving ecclesiastical or structural reforms as well as a political dimension and spiritual movements.\n\nSuch reforms included the foundation of seminaries for the proper training of priests in the spiritual life and the theological traditions of the Church, the reform of religious life by returning orders to their spiritual foundations and new spiritual movements focusing on the devotional life and a personal relationship with Christ, including the Spanish mystics and the French school of spirituality. It also involved political activities that included the Roman Inquisition.\n\nNew religious orders were a fundamental part of this trend. Orders such as the Capuchins, Ursulines, Theatines, Discalced Carmelites, the Barnabites, and especially the Jesuits strengthened rural parishes, improved popular piety, helped to curb corruption within the church and set examples that would be a strong impetus for Catholic renewal.\n\nWith the adoption of large-scale printing after 1500, Italian Renaissance Humanism spread northward to France, Germany, Holland and England, where it became associated with the Protestant Reformation. In France, pre-eminent Humanist Guillaume Budé (1467–1540) applied the philological methods of Italian Humanism to the study of antique coinage and to legal history, composing a detailed commentary on Justinian's Code. Although a royal absolutist (and not a republican like the early Italian \"umanisti\"), Budé was active in civic life, serving as a diplomat for Francis I and helping to found the Collège des Lecteurs Royaux (later the Collège de France). Meanwhile, Marguerite de Navarre, the sister of Francis I, herself a poet, novelist and religious mystic, gathered around her and protected a circle of vernacular poets and writers, including Clément Marot, Pierre de Ronsard and François Rabelais.\n\nThe philosophy of 17th-century Europe marks the departure from medieval scholasticism and the often occultist approach of Renaissance philosophy.\nThe period was typified in Europe by the great system-builders, philosophers who presented unified systems of epistemology, metaphysics, logic, and ethics and often politics and the physical sciences as well.\n\nImmanuel Kant classified his predecessors into two schools: the rationalists and the empiricists, The three main rationalists are normally taken to have been René Descartes, Baruch Spinoza, and Gottfried Leibniz.\n\nThe first great advances towards modern science were made in the mid-17th century, most notably the theory of gravity by Isaac Newton (1643–1727). Newton, Spinoza, John Locke (1632–1704) and Pierre Bayle (1647–1706) were philosophers sparking the Age of Enlightenment in the following century.\n\nThe Great Divergence is epitomized by the \"Age of Enlightenment\" (or \"Age of Reason\").\nThe Enlightenment, starting in the 1750s, flourished until about 1790–1800, after which the emphasis on reason gave way to Romanticism's emphasis on emotion and a Counter-Enlightenment gained force.\n\nThe centre of the Enlightenment was France, where it was based in the salons and culminated in the great \"Encyclopédie\" (1751–1772), edited by Denis Diderot (1713–1784) with contributions by hundreds of leading philosophes (intellectuals) such as Voltaire (1694–1778) and Montesquieu (1689–1755). The French Enlightenment was received in Germany, notably fostered by Frederick the Great, the king of Prussia, and gave rise to a flowering of German philosophy, represented foremost by Immanuel Kant.\n\nThe French and German developments were further influential in Scottish, Russian, Spanish and Polish philosophy.\n\nIn modern history, the end of the early period falls in the late 18th century, as an Age of Revolutions dawns, beginning with those in North America and France. Subsequent important political changes occurred throughout Europe, including upheavals following the Napoleonic Wars, the redrawing of the map of Europe through the Second Treaty of Paris, the rise of new concepts of nationalism and the reorganization in military forces. The end of the early modern period is usually also associated with the Industrial Revolution, which began in Britain in the mid-18th century.\n\n\n\n\n\n\n\n"}
{"id": "9758", "url": "https://en.wikipedia.org/wiki?curid=9758", "title": "Era", "text": "Era\n\nAn era is a span of time defined for the purposes of chronology or historiography, as in the regnal eras in the history of a given monarchy, a calendar era used for a given calendar, or the geological eras defined for the history of Earth.\n\nComparable terms are epoch, age, period, saeculum, aeon (Greek \"aion\") and Sanskrit yuga.\n\nThe word has been in use in English since 1615, and is derived from Late Latin \"aera\" \"an era or epoch from which time is reckoned,\" probably identical to Latin \"æra\" \"counters used for calculation,\" plural of \"æs\" \"brass, money\".\nThe Latin word use in chronology seems to have begun in 5th century Visigothic Spain, where it appears in the \"History\" of Isidore of Seville, and in later texts. The Spanish era is calculated from 38 BC, perhaps because of a tax (cfr. indiction) levied in that year, or due to a miscalculation of the Battle of Actium, which occurred in 31 BC. \n\nLike epoch, \"era\" in English originally meant \"the starting point of an age\"; the meaning \"system of chronological notation\" is c.1646; that of \"historical period\" is 1741.\n\nIn chronology, an era is the highest level for the organization of the measurement of time. A calendar era indicates a span of many years which are numbered beginning at a specific reference date (epoch), which often marks the origin of a political state or cosmology, dynasty, ruler, the birth of a leader, or another significant historical or mythological event; it is generally called after its focus accordingly as in \"Victorian era\".\n\nIn large-scale natural science, there is need for another time perspective, independent from human activity, and indeed spanning a far longer period (mainly prehistoric), where \"geologic era\" refers to well-defined time spans. \nThe next-larger division of geologic time is the eon. The Phanerozoic Eon is subdivided into eras. There are currently three eras defined in the Phanerozoic; the following table lists them from youngest to oldest (BP is an abbreviation for \"before present\").\n\nThe older Proterozoic and Archean eons are also divided into eras.\n\nFor periods in the history of the universe, the term \"epoch\" is typically preferred, but \"era\" is used e.g. of the \"Stelliferous Era\".\n\nCalendar eras count the years since a particular date (epoch), often one with religious significance. Anno mundi (\"year of the world\") refers to a group of calendar eras based on a calculation of the age of the world, assuming it was created as described in the Book of Genesis. In Jewish religious contexts one of the versions is still used, and many Eastern Orthodox religious calendars used another version until 1728. Hebrew year 5772 AM began at sunset on 28 September 2011 and ended on 16 September 2012. In the Western church Anno Domini (=AD = CE), counting the years since the birth of Jesus on traditional calculations, was always dominant. \n\nThe Islamic calendar, which also has variants, counts years from the Hijra or emigration of the Islamic prophet Muhammad from Mecca to Medina, which occurred in 622 CE. The Islamic year is some days shorter than 365; January 2012 fell in 1433 AH (\"After Hijra\").\n\nFor a time ranging from 1872 to the Second World War, the Japanese used the imperial year system (\"kōki\"), counting from the year when the legendary Emperor Jimmu founded Japan which occurred in 660 BC.\n\nMany Buddhist calendars count from the death of the Buddha, which according to the most commonly used calculations was in 545-543 BCE or 483 BCE. Dates are given as \"BE\" for \"Buddhist Era\"; 2000 CE was 2543 BE in the Thai solar calendar.\n\nOther calendar eras of the past counted from political events, such as the Seleucid era and the Ancient Roman \"ab urbe condita\" (\"AUC\"), counting from the foundation of the city.\n\nThe word era also denotes the units used under a different, more arbitrary system where time is not represented as an endless continuum with a single reference year, but each unit starts counting from one again as if time starts again. The use of regnal years is a rather impractical system, and a challenge for historians if a single piece of the historical chronology is missing, and often reflects the preponderance in public life of an absolute ruler in many ancient cultures. Such traditions sometimes outlive the political power of the throne, and may even be based on mythological events or rulers who may not have existed (for example Rome numbering from the rule of Romulus and Remus). In a manner of speaking the use of the supposed date of the birth of Christ as a base year is a form of an era.\nIn East Asia, each emperor's reign may be subdivided into several reign periods, each being treated as a new era. The name of each was a motto or slogan chosen by the emperor. Different East Asian countries utilized slightly different systems, notably:\n\n\nA similar practice survived in the United Kingdom until quite recently, but only for formal official writings: in daily life the ordinary year A.D. has been used for a long time, but Acts of Parliament were dated according to the years of the reign of the current Monarch, so that \"61 & 62 Vict c. 37\" refers to the Local Government (Ireland) Act 1898 passed in the session of Parliament in the 61st/62nd year of the reign of Queen Victoria.\n\n\"Era\" can be used to refer to well-defined periods in historiography, such as the Roman era, Elizabethan era, Victorian era, etc.\nUse of the term for more recent periods or topical history might include Soviet era, and \"\" in the history of modern popular music, such as the \"Big Band era\", \"Disco era\", etc.\n\n"}
{"id": "808876", "url": "https://en.wikipedia.org/wiki?curid=808876", "title": "Euhemerism", "text": "Euhemerism\n\nEuhemerism () is an approach to the interpretation of mythology in which mythological accounts are presumed to have originated from real historical events or personages. Euhemerism supposes that historical accounts become myths as they are exaggerated in the retelling, accumulating elaborations and alterations that reflect cultural mores. It was named for the Greek mythographer Euhemerus, who lived in the late 4th century BC. In the more recent literature of myth, such as \"Bulfinch's Mythology\", euhemerism is termed the \"historical theory\" of mythology. \n\nEuhemerus was not the first to attempt to rationalize mythology in historical terms, as euhemeristic views are found in earlier writings including those of Xenophanes, Herodotus, Hecataeus of Abdera and Ephorus. However, the enduring influence of Euhemerus upon later thinkers such as Ennius and Antoine Banier identified him as the traditional founder of this school of thought.\n\nIn a scene described in Plato's \"Phaedrus\", Socrates offers a euhemeristic interpretation of a myth concerning Boreas and Orithyia:\n\nSocrates illustrates a euhemeristic approach to the myth of Boreas abducting Orithyia. He shows how the story of Boreas, the northern wind, can be rationalised: Orithyia is pushed off the rock cliffs through the equation of Boreas with a natural gust of wind, which accepts Orithyia as a historical personage. But here he also implies that this is equivalent to rejecting the myth. Socrates, despite holding some euhemeristic views, mocked the concept that all myths could be rationalized, noting that the mythical creatures of \"absurd forms\" such as Centaurs and the Chimera could not easily be explained.\n\nIn the ancient skeptic philosophical tradition of Theodorus of Cyrene and the Cyrenaics, Euhemerus forged a new method of interpretation for the contemporary religious beliefs. Though his work is lost, the reputation of Euhemerus was that he believed that much of Greek mythology could be interpreted as natural or historical events subsequently given supernatural characteristics through retelling. Subsequently Euhemerus was considered to be an atheist by his opponents, most notably Callimachus.\n\nEuhemerus' views were rooted in the deification of men, usually kings, into gods through apotheosis. In numerous cultures, kings were exalted or venerated into the status of divine beings and worshipped after their death, or sometimes even while they ruled. Dion, the tyrant ruler of Syracuse, was deified while he was alive and modern scholars consider his apotheosis to have influenced Euhemerus' views on the origin of all gods. Euhemerus was also living during the contemporaneous deification of the Seleucids and \"pharaoization\" of the Ptolemies in a fusion of Hellenic and Egyptian traditions.\n\nEuhemerus argued that Zeus was a mortal king who died on Crete, and that his tomb could still be found there with the inscription bearing his name. This claim however did not originate with Euhemerus, as the general sentiment of Crete during the time of Epimenides of Knossos (c. 600 BC) was that Zeus was buried somewhere in Crete. For this reason, the Cretans were often considered atheists, and Epimenides called them all liars (see Epimenides paradox). Callimachus, an opponent of Euhemerus' views on mythology, argued that Zeus' Cretan tomb was fabricated, and that he was eternal:\n\nA later Latin scholium on the \"Hymns\" of Callimachus attempted to account for the tomb of Zeus. According to the scholium, the original tomb inscription read: \"The tomb of Minos, the son of Jupiter\" but over time the words \"Minos, the son\" wore away leaving only \"the tomb of Jupiter\". This had misled the Cretans into thinking that Zeus had died and was buried there.\n\nInfluenced by Euhemerus, Porphyry in the 3rd century AD claimed that Pythagoras had discovered the tomb of Zeus on Crete and written on the tomb's surface an inscription reading: \"Here died and was buried Zan, whom they call Zeus\". Varro also wrote about the tomb of Zeus.\n\nHostile to paganism, the early Christians, such as the Church Fathers, embraced euhemerism in attempt to undermine the validity of pagan gods. The usefulness of euhemerist views to early Christian apologists may be summed up in Clement of Alexandria's triumphant cry in \"Cohortatio ad gentes\": \"Those to whom you bow were once men like yourselves.\"\n\nThe \"Wisdom of Solomon\", a deuterocanonical book, has a passage, , giving a euhemerist explanation of the origin of idols.\n\nThe early Christian apologists deployed the euhemerist argument to support their position that pagan mythology was merely an aggregate of fables of human invention. Cyprian, a North African convert to Christianity, wrote a short essay \"De idolorum vanitate\" (\"On the Vanity of Idols\") in AD 247 that assumes the euhemeristic rationale as though it needed no demonstration. Cyprian begins:\n\nCyprian proceeds directly to examples, the apotheosis of Melicertes and Leucothea; \"The Castors [i.e. Castor and Pollux] die by turns, that they may live,\" a reference to the daily sharing back and forth of their immortality by the Heavenly Twins. \"The cave of Jupiter is to be seen in Crete, and his sepulchre is shown,\" Cyprian says, confounding Zeus and Dionysus but showing that the Minoan cave cult was still alive in Crete in the third century AD. In his exposition, it is to Cyprian's argument to marginalize the syncretism of pagan belief, in order to emphasize the individual variety of local deities:\n\nEusebius in his \"Chronicle\" employed euhemerism to argue the Babylonian God Baʿal was a deified ruler and that the god Belus was the first Assyrian king.\n\nEuhemeristic views are found expressed also in Tertullian (\"De idololatria\"), the \"Octavius\" of Marcus Minucius Felix and in Origen. Arnobius' dismissal of paganism in the fifth century, on rationalizing grounds, may have depended on a reading of Cyprian, with the details enormously expanded. Isidore of Seville, compiler of the most influential early medieval encyclopedia, devoted a chapter \"De diis gentium\" to elucidating, with numerous examples and elaborated genealogies of gods, the principle drawn from Lactantius, \"Quos pagani deos asserunt, homines olim fuisse produntur.\" (\"Those whom pagans claim to be gods were once mere men.\") Elaborating logically, he attempted to place these deified men in the six great periods of history as he divided it, and created mythological dynasties. Isidore's euhemeristic bent was codified in a rigid parallel with sacred history in Petrus Comestor's appendix to his much translated \"Historia scholastica\" (written ca. 1160), further condensing Isidore to provide strict parallels of figures from the pagan legend, as it was now viewed in historicised narrative, and the mighty human spirits of the patriarchs of the Old Testament. Martin of Braga in his \"De correctione rusticorum\" wrote idolatry stemmed from post-deluge survivors of Noah's family who began to worship the Sun and stars instead of God. In his view the Greek gods were deified descendants of Noah who were once real personages.\n\nChristian writers during the Middle Ages continued to embrace euhemerism, such as Vincent of Beauvais, Petrus Comestor, Roger Bacon and Godfrey of Viterbo.\n“After all, it was during this time that Christian apologists had adopted the views of the rationalist Greek philosophers. And had captured the purpose for Euhemerism, which was to explain the mundane origins of the Hellenistic divinities. Euhemerism explained simply in two ways: first in the strictest sense as a movement which reflected the known views of Euhemerus' Hiera Anagraphe regarding Panchaia and the historicity of the family of Saturn and Uranus. The principal sources of these views are the handed-down accounts of Lactantius and Diodorus; or second, in the widest sense, as a rationalist movement which sought to explain the mundane origins of all the Hellenistic gods and heroes as mortals.” Other modern theorists labeled Euhemerism as a “subject of classical paganism that was fostered in the minds of the people of the Middle Ages through the realization that while in most respects the ancient Greeks and Roman had been superior to themselves, they had been in error regarding their religious beliefs. An examination of the principal writings in Middle English with considerable reading of literature other than English, discloses the fact that the people of the Middle Ages rarely regarded the so-called gods as mere figments of the imagination but rather believed that they were or had been real beings, sometimes possessing actual power.” (John Daniel Cook)\n\nIn his 2011 book, \"The Christ-Myth Theory and Its Problems\", Robert M. Price supported the Christ myth theory and suggested that the process of searching for a historical Jesus was like euhemerism.\n\nIn the \"Prose Edda\", composed around 1220, the Christian Icelandic bard and historian Snorri Sturluson proposes that the Norse gods were originally historical leaders and kings. Odin, the father of the gods, is introduced as a historical person originally from Asia Minor, tracing his ancestry back to Priam, the king of Troy during the Trojan War. \nAs Odin travels north to settle in the Nordic countries, he establishes the royal families ruling in Denmark, Sweden and Norway at the time:\n\nThus, while Snorri's euhemerism follows the early Christian tradition, the effect is not simply to discredit the divinity of the gods of a religion on the wane, but also (on the model of Virgil's \"Aeneid\") to hint that the 'divinisation' was done in order to legitimize more recent Scandinavian rulers.\n\nEuhemeristic interpretations of mythology continued throughout the early modern period from the 16th century, to modern times. In 1711, the French historian Antoine Banier in his \"Mythologie et la fable expliqués par l'histoire\" (\"The mythology and fables of the ancients, explained\") presented strong arguments for a euhemerist interpretation of Greek mythology. Jacob Bryant's \"A New System or Analysis of Ancient Mythology\" (1744) was also another key work on euhemerism of the period, but argued so from a Biblical basis. Of the early 19th century, George Stanley Faber was another Biblical euhemerist. His work \"The Origin of Pagan Idolatry\" (1816) proposed that all the pagan nations worshipped the same gods, who were all deified men. Outside of Biblical influenced literature, some archaeologists embraced euhemerist views since they discovered myths could verify archaeological findings. Heinrich Schliemann was a prominent archaeologist of the 19th century who argued myths had embedded historical truths. Schliemann was an advocate of the historical reality of places and characters mentioned in the works of Homer. He excavated Troy and claimed to have discovered artifacts associated with various figures from Greek mythology, including the Mask of Agamemnon and Priam's Treasure.\n\nHerbert Spencer embraced some euhemeristic arguments in attempt to explain the anthropocentric origin of religion, through ancestor worship. Rationalizing methods of interpretation that treat some myths as traditional accounts based upon historical events are a continuous feature of some modern readings of mythology.\n\nThe twentieth century poet and mythographer Robert Graves offered many such \"euhemerist\" interpretations in his telling of \"The White Goddess\" (1948) and \"The Greek Myths\" (1955). His suggestions that such myths record and justify the political and religious overthrow of earlier cult systems have been widely criticized and are rejected by most scholars.\n\n"}
{"id": "4725513", "url": "https://en.wikipedia.org/wiki?curid=4725513", "title": "European Association of History Educators", "text": "European Association of History Educators\n\nThe European Association of History Educators (EUROCLIO) was established in 1992 with the support of the Council of Europe. The NGO works as a European wide facilitator for innovation and progress in history Education. The organisation contributes not only to the development, but also on the actual implementation of regional, national and European long-term projects, which focus on establishing knowledge, experience and expertise in the countries by training and consulting teachers. EUROCLIO develops teaching materials, builds and maintains professional Networks and acts as advisor to governments, international organisations, NGOs, History Teacher Associations and other Organisations. EUROCLIO is supported by the Europe for Citizens Programme of the European Union and has, for many years, Official Participatory Status and is part of the EU Stake Holder's Network in Education and Training.\n\nEUROCLIO was officially founded in 1993, but already in 1992, delegates from Denmark, Switzerland, Belgium, Portugal, Hungary, Estonia, the Netherlands, France, the United Kingdom, Finland, Lithuania, Luxembourg, Sweden and Norway (14 countries), representing 18 history Teachers Associations decided that a European organization was needed to support the learning and teaching of history by sharing and exchanging knowledge and professional experience. EUROCLIO was founded by Joke van der Leeuw-Roord. The immediate cause for the foundation of such an institute was the collapse of the Iron Curtain in 1989 and the dissolution of the Soviet Union in 1992. These events changed the scope and perspective of history and history education in Europe completely and for many countries, a European dimension in history education suddenly became possible and important for the future. History education is frequently used as a vehicle for political propaganda, hatred and aggression, but now the decision was made to renew contacts between East and West and reinforce a history education that could act as a tool to foster integration, peace and stability in Europe. From 1993 on, EUROCLIO grew rapidly and today it represents 64 member organizations from 46 (mostly) European countries, connecting 40,000 historians and history educators in primary, secondary and higher educational institutes.\n\nEUROCLIO received the following international recognition:\n\nThe organization supports the development of responsible and innovative history, heritage and citizenship education by promoting critical thinking, mutual respect, peace, stability and democracy.\n\nEUROCLIO focuses on three target areas:\n\nEUROCLIO has member organizations from Albania, Armenia, Azerbaijan, Austria, Bosnia-Herzegovina, Bulgaria, Croatia, Cyprus, Czech Republic, Denmark, Estonia, England, Finland, France, Germany, Georgia, Hungary, Iceland, Ireland, Israel, Italy, Kyrgyzstan, Kosovo, Lebanon Lithuania, Latvia, Luxembourg, Macedonia, Malta, Moldova, Montenegro, Netherlands, Northern Ireland, Norway, Poland, Portugal, Rumania, Russia, Scotland, Serbia, Slovakia, Slovenia, Spain, Switzerland, Turkey and Ukraine. A full overview of member organisations is available on the EUROCLIO website\n\nThe EUROCLIO secretariat is located in The Hague, Netherlands. The secretariat is managed by Acting Executive Director Steven Stegers.\n\nEUROCLIO is governed by an international volunteer board that is elected annually by the general assembly. Since its foundation in 1992, EUROCLIO has had board members from Belgium, Cyprus, Denmark, Germany, Greece, Hungary, Iceland, Italy, Latvia, the Netherlands, Norway, Switzerland, Turkey, Macedonia, Portugal, Slovenia, Ukraine, and the United Kingdom.\n\nThe EUROCLIO Honorary Board consists of notable scholars and individuals who are prominent in public life and academic circles, including several former heads of state. They allow themselves to be listed as EUROCLIO Honorary Board Members as a token of their recognition of EUROCLIO's work and mission.\n\nHonorary board members include:\n\n\nEUROCLIO is an affiliate of the following networks:\n\nEUROCLIO is official partner of UNESCO.\n\nEach year, EUROCLIO organises an International Training and Development Course where, on average, History Educators from more than 35 countries meet, learn and discuss a variety of topics and good practice to broaden their perspectives. These Annual Conferences take place in different countries and in close co-operation with local History Teachers’ Associations. In 2009, the Conference was in Nicosia, Cyprus, on the theme “Taking the Perspective of the Others: Intercultural Dialogue and History Teaching”. This Conference is co-organised by nine Teacher Unions and History Educators’ Associations from across the divide.\n\nAll EUROCLIO Teacher Training activities are in close co-operation with both local academics and institutes for history teacher education, and international experts to train history teachers how to use the most modern teaching methods in their classes. For example: history educators everywhere recognise the importance of ICT as a learning and communications tool, and want further training in how to develop these areas and how to extend their skills in using ICT to promote historical understanding and learning. EUROCLIO operates through the medium of English for international work, and in home languages with translations for the experts supporting projects and in developmental work.\n\nSince its foundation, EUROCLIO has organised more than 30 International Conferences and more than 70 National and Regional Training and Development Courses.\n\nEUROCLIO implements several long term programmes:\n\nAlbanian\n, Bosnian, Croatian, English, Macedonian, Montegrin, Serbian and Slovenian.\n\n\n"}
{"id": "349339", "url": "https://en.wikipedia.org/wiki?curid=349339", "title": "Georgian era", "text": "Georgian era\n\nThe Georgian era is a period in British history from 1714 to , named after the Hanoverian kings George I, George II, George III and George IV. The sub-period that is the Regency era is defined by the regency of George IV as Prince of Wales during the illness of his father George III. The definition of the Georgian era is often extended to include the relatively short reign of William IV, which ended with his death in 1837.\n\nThe term \"Georgian\" is typically used in the contexts of social and political history and architecture. The term \"Augustan literature\" is often used for Augustan drama, Augustan poetry and Augustan prose in the period 1700–1740s. The term \"Augustan\" refers to the acknowledgement of the influence of Latin literature from the ancient Roman Republic.\n\nGeorgian society and its preoccupations were well portrayed in the novels of writers such as Henry Fielding, Mary Shelley and Jane Austen, characterised by the architecture of Robert Adam, John Nash and James Wyatt and the emergence of the Gothic Revival style, which hearkened back to a supposed golden age of building design.\n\nThe flowering of the arts was most vividly shown in the emergence of the Romantic poets, principally through Samuel Taylor Coleridge, William Wordsworth, Percy Bysshe Shelley, William Blake, John Keats, Lord Byron and Robert Burns. Their work ushered in a new era of poetry, characterised by vivid and colourful language, evocative of elevating ideas and themes.\n\nThe paintings of Thomas Gainsborough, Sir Joshua Reynolds and the young J. M. W. Turner and John Constable illustrated the changing world of the Georgian period – as did the work of designers like Capability Brown, the landscape designer.\n\nFine examples of distinctive Georgian architecture are Edinburgh's New Town, Georgian Dublin, Grainger Town in Newcastle upon Tyne, the Georgian Quarter of Liverpool and much of Bristol and Bath.\n\nThe music of John Field, Handel, Haydn, Clementi, Johann Christian Bach, William Boyce, Mozart, Beethoven and Mendelssohn was some of the most popular in England at that time.\n\nIt was a time of immense social change in Britain, with the beginnings of the Industrial Revolution which began the process of intensifying class divisions, and the emergence of rival political parties like the Whigs and Tories.\n\nIn rural areas the Agricultural Revolution saw huge changes to the movement of people and the decline of small communities, the growth of the cities and the beginnings of an integrated transportation system but, nevertheless, as rural towns and villages declined and work became scarce there was a huge increase in emigration to Canada, the North American colonies (which became the United States during the period) and other parts of the British Empire.\n\nThe evangelical movement inside and outside the Church of England gained strength in the late 18th and early 19th century. The movement challenged the traditional religious sensibility that emphasized a code of honor for the upper-class, and suitable behaviour for everyone else, together with faithful observances of rituals. John Wesley (1703–1791) and his followers preached revivalist religion, trying to convert individuals to a personal relationship with Christ through Bible reading, regular prayer, and especially the revival experience. Wesley himself preached 52,000 times, calling on men and women to \"redeem the time\" and save their souls. Wesley always operated inside the Church of England, but at his death, it set up outside institutions that became the Methodist Church. It stood alongside the traditional nonconformist churches, Presbyterians, Congregationalist, Baptists, Unitarians, and Quakers. The nonconformist churches, however, were less influenced by revivalism.\n\nThe Church of England remained dominant, but it had a growing evangelical, revivalist faction the \"Low Church\". Its leaders included William Wilberforce and Hannah More. It reached the upper class through the Clapham Sect. It did not seek political reform, but rather the opportunity to save souls through political action by freeing slaves, abolishing the duel, prohibiting cruelty to children and animals, stopping gambling, avoiding frivolity on the Sabbath; they read the Bible every day. All souls were equal in God's view, but not all bodies, so evangelicals did not challenge the hierarchical structure of English society. As R.J. Morris noted in his 1983 article \"Voluntary Societies and British Urban Elites, 1780-1850,\" \"[m]id-eighteenth-century Britain was a stable society in the sense that those with material and ideological power were able to defend this power in an effective and dynamic manner,\" but \"in the twenty years after 1780, this consensus structure was broken.\" Anglican Evangelicalism thus, as historian Lisa Wood has argued in her book \"Modes of Discipline: Women, Conservatism, and the Novel After the French Revolution\", functioned as a tool of ruling-class social control, buffering the discontent that in France had inaugurated a revolution; yet it contained within itself the seeds for challenge to gender and class hierarchies.\n\nThe Georgian period saw continual warfare, including the Seven Years' War, known in America as the French and Indian War (1756–63), the American Revolutionary War (1775–83), the French Revolutionary Wars (1792–1802), the Irish Rebellion of 1798, and the Napoleonic Wars (1803–15). The British won most of the wars except for the American Revolution, where the combined weight of the United States, France, Spain and the Netherlands overwhelmed Britain, which stood alone without allies.\n\nThe loss of some of the American Colonies in the American War of Independence was regarded as a national disaster and was seen by some foreign observers as heralding the end of Britain as a great power. In Europe, the wars with France dragged on for nearly a quarter of a century, 1793–1815. Victory over Napoleon at the Battle of Trafalgar (1805) and the Battle of Waterloo (1815) under Admiral Lord Nelson and the Duke of Wellington brought a sense of triumphalism and political reaction.\n\nThe expansion of empire brought fame to statesmen and explorers such as Clive of India and Captain Cook, and sowed the seeds of the worldwide British Empire of the Victorian and Edwardian eras which were to follow.\n\nThe era was prosperous as entrepreneurs extended the range of their business around the globe. By the 1720s Britain was one of the most prosperous countries in the world, and Daniel Defoe boasted:\n\nWhile the other major powers were primarily motivated toward territorial gains, and protection of their dynasties (such as the Habsburg and Bourbon dynasties, and the House of Hohenzollern), Britain had a different set of primary interests. Its main diplomatic goal (besides protecting the homeland from invasion) was building a worldwide trading network for its merchants, manufacturers, shippers and financiers. This required a hegemonic Royal Navy so powerful that no rival could sweep its ships from the world's trading routes, or invade the British Isles. The London government enhanced the private sector by incorporating numerous privately financed London-based companies for establishing trading posts and opening import-export businesses across the world. Each was given a monopoly of trade to the specified geographical region. The first enterprise was the Muscovy Company set up in 1555 to trade with Russia. Other prominent enterprises included the East India Company, and the Hudson's Bay Company in Canada. The Company of Royal Adventurers Trading to Africa had been set up in 1662 to trade in gold, ivory and slaves in Africa; it was reestablished as the Royal African Company in 1672 and focused on the slave trade. British involvement in the each of the four major wars, 1740 to 1783, paid off handsomely in terms of trade. Even the loss of the 13 colonies was made up by a very favorable trading relationship with the new United States of America. British gained dominance in the trade with India, and largely dominated the highly lucrative slave, sugar, and commercial trades originating in West Africa and the West Indies. China would be next on the agenda. Other powers set up similar monopolies on a much smaller scale; only the Netherlands emphasized trade as much as England.\n\nMercantilism was the basic policy imposed by Britain on its colonies. Mercantilism meant that the government and the merchants became partners with the goal of increasing political power and private wealth, to the exclusion of other empires. The government protected its merchants—and kept others out—by trade barriers, regulations, and subsidies to domestic industries in order to maximise exports from and minimise imports to the realm. The government had to fight smuggling, which became a favourite American technique in the 18th century to circumvent the restrictions on trading with the French, Spanish or Dutch. The goal of mercantilism was to run trade surpluses, so that gold and silver would pour into London. The government took its share through duties and taxes, with the remainder going to merchants in Britain. The government spent much of its revenue on a large and powerful Royal Navy, which not only protected the British colonies but threatened the colonies of the other empires, and sometimes seized them. The colonies were captive markets for British industry, and the goal was to enrich the mother country.\n\nMost of the companies earned good profits, and enormous personal fortunes were created in India, but there was one major fiasco that caused heavy losses. The South Sea Bubble was a business enterprise that exploded in scandal. The South Sea Company was a private business corporation supposedly set up much like the other trading companies, with a focus on South America. Its actual purpose was to renegotiate previous high-interest government loans amounting to ₤31 million through market manipulation and speculation. It issued stock four times in 1720 that reached about 8,000 investors. Prices kept soaring every day, from ₤130 a share to ₤1,000, with insiders making huge paper profits. The Bubble collapsed overnight, ruining many speculators. Investigations showed bribes had reached into high places—even to the king. The prime minister Robert Walpole managed to wind it down with minimal political and economic damage, although some losers fled to exile or committed suicide.\n\nWith the ending of the War with France, Great Britain entered a period of greater economic depression and political uncertainty, characterised by social discontent and unrest. The Radical political party published a leaflet called \"The Political Register\", also known as \"The Two Penny Trash\" to its rivals. The so-called March of the Blanketeers saw 400 spinners and weavers march from Manchester to London in March 1817 to hand the Government a petition. The Luddites destroyed and damaged machinery in the industrial north-west of England. The Peterloo Massacre in 1819 began as a protest rally which saw 60,000 people gathering to protest about their living standards, but was quelled by military action and saw eleven people killed and 400 wounded. The Cato Street Conspiracy of 1820 sought to blow up the Cabinet and then move on to storm the Tower of London and overthrow the government. This too was thwarted, with the conspirators executed or transported to Australia.\n\nHistorians have long explored the importance of the Scottish Enlightenment, as well as the American Enlightenment, while debating the very existence of the English Enlightenment.\n\nEnglish historian Peter Gay argues that the Scottish Enlightenment \"was a small and cohesive group of friends – David Hume, Adam Smith, Adam Ferguson, and others – who knew one another intimately and talked to one another incessantly. Education was a priority in Scotland, both at the local level and especially in four universities that had stronger reputations than any in England. The Enlightenment culture was based on close readings of new books, and intense discussions that took place daily at such intellectual gathering places in Edinburgh as The Select Society and, later, The Poker Club as well as within Scotland's ancient universities (St Andrews, Glasgow, Edinburgh and Aberdeen). Sharing the humanist and rationalist outlook of the European Enlightenment of the same time period, the thinkers of the Scottish Enlightenment asserted the importance of human reason combined with a rejection of any authority that could not be justified by reason. In Scotland, the Enlightenment was characterised by a thoroughgoing empiricism and practicality where the chief values were improvement, virtue, and practical benefit for the individual and society as a whole. Among the fields that rapidly advanced were philosophy, economics, history architecture, and medicine. Leaders included Francis Hutcheson, David Hume, Adam Smith, Dugald Stewart, Thomas Reid, William Robertson, Henry Home, Lord Kames, Adam Ferguson, John Playfair, Joseph Black and James Hutton. The Scottish Enlightenment influenced England and the American colonies, and to a lesser extent continental Europe.\n\nThe very existence of an English Enlightenment has been hotly debated by scholars. The majority of textbooks and standard surveys make no room for an English Enlightenment. Some European surveys include England, others ignore it but do include as enlightenment intellectuals such representative Englishmen as Newton, Locke, Jonathan Swift, although they do include coverage of such major intellectuals as Joseph Addison, Edward Gibbon, John Locke, Isaac Newton, Alexander Pope, Joshua Reynolds, and Jonathan Swift. Roy Porter argues that the reason for the neglect was the assumption that the movement was primarily French-inspired, that it was largely a-religious or anti-clerical, and it stood in outspoken defiance to the established order. Porter admits that after the 1720s, England could claim few thinkers to equal Diderot, Voltaire or Rousseau. Indeed, its leading intellectuals, such as Edward Gibbon, Edmund Burke, and Samuel Johnson were all quite conservative and supported the standing order. Porter says the reason was that Enlightenment had come early to England, and had succeeded so that the culture had accepted political liberalism, philosophical empiricism, and religious toleration of the sort that intellectuals on the continent had to fight for against powerful odds. The coffee-house culture provided an ideal venue for enlightened conversation. Furthermore, England rejected the collectivism of the continent, and emphasized the improvement of individuals as the main goal of enlightenment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"Note: In the twentieth century, the period 1910–1936 was informally called the Georgian Era during the reign of George V (following the Edwardian Era), and is sometimes still referred to as such; see Georgian Poetry.\"\n\n"}
{"id": "2619114", "url": "https://en.wikipedia.org/wiki?curid=2619114", "title": "Golden age (metaphor)", "text": "Golden age (metaphor)\n\nA golden age is a period in a field of endeavor when great tasks were accomplished. The term originated from early Greek and Roman poets, who used it to refer to a time when mankind lived in a better time and was pure (see Golden Age).\n\nThe ancient Greek philosopher Hesiod introduced the term in his \"Works and Days\", when referring to the period when the \"Golden Race\" of man lived. This was part of fivefold division of Ages of Man, starting with the Golden age, then the Silver Age, the Bronze Age, the Age of Heroes (including the Trojan War), and finally, the current Iron Age. The concept was further refined by Ovid, in his \"Metamorphoses\", into the four \"metal ages\" (golden, silver, bronze, and iron).\n\nBy definition, the Golden Age is always in the past.\n\nThe Golden age as described by Hesiod was an age where all humans were created directly by the Olympian gods. They did not have women in their ranks, and could not reproduce. They lived long lives in peace and harmony, and were oblivious of death. The \"Golden race\" were however mortals, but would die peacefully and in their sleep unmarked by sickness and age. Ovid emphasizes the justice and peace that defined the Golden Age. He described it as a time before man learned the art of navigation, and as a pre-agricultural society. The idea of a Golden age lingered in literature and historical understanding throughout the Greek and Roman periods. It was partly replaced by the Christian Six Ages of the World based on the biblical chronology in the early Middle Ages.\n\nThe term \"Golden age\" has always had a metaphoric element. A few centuries after Hesiod, Plato pointed out that the \"Golden race\" were not made from gold as such, but that the term should be understood metaphorically. The classical idea of the \"metal ages\" as actual historical periods held sway throughout the Greek and Roman periods. While supplemented by St. Augustine's \"Six Ages of the World\", the classical ideas were never entirely eradicated, and it resurfaced to form the basis of division of time in early archaeology\n\nAt the birth of modern archaeology in the 18th century, the \"Golden age\" was associated with a pre-agricultural society. However, already in the 16th century, the term \"Golden age\" was replaced by \"Stone age\" in the three-age system. Still, Rousseau used the term for a loosely defined historical period characterized by the \"State of nature\" as late as the during the late 18th century. While the concept of an Iron and Bronze Age are still used by historians and archaeologists, the \"Golden age\" of Hesiod was a purely mythical period, and has come to signify any period in history where the state of affairs for a specific phenomenon appear to have been on their height, better than in the periods proceeding it and following the \"Golden Age\". It is sometimes still employed for the hunter-gatherer tribal societies of the Mesolithic, but only as a metaphor.\n\nA society's Golden Age marks that period in its history having a heightened output of art, science, literature, and philosophy.\n\n\n\nA golden age is often ascribed to the years immediately following some technological innovation. It is during this time that writers and artists ply their skills to this new medium. Therefore, there are Golden Ages of both radio and television. During this nascent phase the technology allows new ideas to be expressed, as new art forms flower quickly into new areas:\n\n\nAt least one technology had its \"Golden Age\" in its latter years:\n\nTechnology and creativity spawn new genres in literature and theatre. The onset of a new genre will be its Golden Age:\n\n\n\nCompanies will use \"Golden Age\" as a marketing euphemism to replace \"senior citizen\":\n\n\n\n"}
{"id": "7391958", "url": "https://en.wikipedia.org/wiki?curid=7391958", "title": "Great Divergence", "text": "Great Divergence\n\nThe Great Divergence is a term made popular by Kenneth Pomeranz's book by that title, (also known as the European miracle, a term coined by Eric Jones in 1981) referring to the process by which the Western world (i.e. Western Europe and the parts of the New World where its people became the dominant populations) overcame pre-modern growth constraints and emerged during the 19th century as the most powerful and wealthy world civilization, eclipsing Medieval India, Qing China, the Islamic World, Joseon Korea, and Tokugawa Japan.\n\nScholars have proposed a wide variety of theories to explain why the Great Divergence happened, including geography, culture, institutions, colonialism, resources, and \"accidents of history\". Scholars also trace back the beginning of the Great Divergence to different periods, with many tracing it back to the Industrial Revolution in 18th-century Britain, while others trace it back to earlier periods of Western history, such as the commercial revolution and the origins of mercantilism and capitalism during the Renaissance and the Age of Discovery, the rise of the European colonial empires, proto-globalization, the Scientific Revolution, or the Age of Enlightenment. The \"traditional view\", sometimes described as a near-consensus view, is that the Great Divergence occurred before the Industrial Revolution, with Western European states surpassing China, Japan and the Middle East by 1750. However, the \"revisionist\" view of the \"California School\" estimates that the divergence started around 1800 during the Industrial Revolution. In the twentieth century, the Great Divergence peaked before the First World War and continued until the early 1970s, then, after two decades of indeterminate fluctuations, in the late 1980s it was replaced by the Great Convergence as the majority of Third World countries reached economic growth rates significantly higher than those in most First World countries.\n\nTechnological advances, in areas such as railroads, steamboats, mining, and agriculture, were embraced to a higher degree in the West than the East during the Great Divergence. Technology led to increased industrialization and economic complexity in the areas of agriculture, trade, fuel and resources, further separating the East and the West. Western Europe's use of coal as an energy substitute for wood in the mid-19th century gave it a major head start in modern energy production.\n\nThe term \"Great Divergence\" was coined by Samuel P. Huntington in 1996 and used by Kenneth Pomeranz in his book \"The Great Divergence: China, Europe, and the Making of the Modern World Economy\" (2000). The same phenomenon was discussed by Eric Jones, whose 1981 book \"\" popularized the alternate term \"European Miracle\". Broadly, both terms signify a socioeconomic shift in which European countries advanced ahead of others during the modern period.\n\nThe timing of the Great Divergence is in dispute among historians. The traditional dating is as early as the 16th (or even 15th) century, with scholars arguing that Europe had been on a trajectory of higher growth since that date. Pomeranz and others argue that the period of most rapid divergence was during the 19th century. Citing nutrition data and chronic European trade deficits as evidence, these scholars argue that before that date Asia was wealthier and more advanced, especially China in the Yangzi Delta and India, as well as Egypt. Others, while accepting parity of incomes between the most prosperous parts of China, India, Egypt and Europe in the late 18th century, trace the first significant changes in European economies back to the 17th century. Others argue that the cultural factors behind the divergence can be traced to earlier periods and institutions such as the Renaissance and the Chinese imperial examination system.\n\nUnlike modern industrial economies, pre-modern economies were constrained by conditions which greatly limited economic growth. Although core regions in Eurasia had achieved a relatively high standard of living by the 18th century, shortages of land, soil degradation, deforestation, lack of dependable energy sources, and other ecological constraints limited growth in per capita incomes. Rapid rates of depreciation on capital meant that a great part of savings in pre-modern economies were spent on replacing depleted capital, hampering capital accumulation. Massive windfalls of fuel, land, food and other resources were necessary for continued growth and capital accumulation, leading to colonialism.\nThe Industrial Revolution overcame these restraints, allowing rapid, sustained growth in per capita incomes for the first time in human history.\n\nAfter the Viking, Muslim and Magyar invasions waned in the 10th century, Europe entered a period of prosperity, population growth and territorial expansion known as the High Middle Ages.\nTrade and commerce revived, with increased specialization between areas and between the countryside and artisans in towns.\nBy the 13th century the best land had been occupied and agricultural income began to fall, though trade and commerce continued to expand, especially in Venice and other northern Italian cities.\nThe 14th century brought a series of calamities: famines, wars, the Black Death and other epidemics.\nThe resulting drop in the population led to falling rents and rising wages, undermining the feudal and manorial relationships that had characterized Medieval Europe.\n\nAccording to a 2014 study, \"there was a ‘little divergence’ within Europe between 1300 and 1800: real wages in the North Sea area more or less stabilized at the level attained after the Black Death, and remained relatively high (above subsistence) throughout the early modern period (and into the nineteenth century); whereas, on the other hand, real wages in the ‘periphery’ (in Germany, Italy, and Spain) began to fall after the fifteenth century and returned to some kind of subsistence minimum during the 1500–1800 period. This ‘little divergence’ in real wages mirrors a similar divergence in GDP per capita: in the ‘periphery’ of Europe there was almost no per capita growth (or even a decline) between 1500 and 1800, whereas in Holland and England real income continued to rise and more or less doubled in this period.\"\n\nIn the Age of Exploration navigators discovered new routes to the Americas and Asia.\nCommerce expanded, together with innovations such as joint stock companies and various financial institutions.\nNew military technologies favored larger units, leading to a concentration of power in states whose finances relied on trade.\nFrance and Spain developed absolute monarchies reliant on high taxes and state-backed monopolies, leading to economic decline.\nThe Dutch Republic was controlled by merchants, while Parliament gained control of England after a long struggle culminating in the Glorious Revolution.\nThese arrangements proved more hospitable to economic development.\nAt the end of the 16th century London and Antwerp began pulling away from other European cities, as illustrated in the following graph of real wages in several European cities:\n\nThe West had a series of unique advantages compared to Asia, such as the proximity of coal mines; the discovery of the New World, which alleviated ecological restraints on economic growth (land shortages etc.); and the profits from colonization.\n\nChina had a larger population than Europe throughout the Common Era.\nUnlike Europe, it was politically united for long periods during that time.\n\nDuring the Song Dynasty (960–1279), the country experienced a revolution in agriculture, water transport, finance, urbanization, science and technology, which made the Chinese economy the most advanced in the world from about 1100. Mastery of wet-field rice cultivation opened up the hitherto underdeveloped south of the country, while later northern China was devastated by Jurchen and Mongol invasions, floods and epidemics. The result was a dramatic shift in the center of population and industry from the home of Chinese civilization around the Yellow River to the south of the country, a trend only partially reversed by the re-population of the north from the 15th century. By 1300, China had fallen behind Italy in living standards.\n\nIn the late imperial period (1368–1911), comprising the Ming and Qing dynasties, taxation was low, and the economy and population grew significantly, though without substantial increases in productivity.\nChinese goods such as silk, tea and ceramics were in great demand in Europe, leading to an inflow of silver, expanding the money supply and facilitating the growth of competitive and stable markets.\nBy the end of the 18th century, population density levels exceeded those in Europe. China had more large cities but far fewer small ones than in contemporary Europe. The traditional view is that the Great Divergence between China and Europe had begun by 1750, before the Industrial Revolution. Revisionist scholarship, however, estimates that the Great Divergence did not begin until the 19th century, during the Industrial Revolution.\n\nBy the 1500s, India benefited from extensive external and internal trade. Its agriculture was highly efficient as well as its industry. Unlike China, Japan and western and central Europe, India did not experience extensive deforestation until the 19th and 20th centuries. It thus had no pressure to move to coal as a source of energy. From the 17th century, cotton textiles from Mughal India became popular in Europe, with some governments banning them to protect their wool industries. In the 18th century, India was the most important manufacturer in world trade, producing about 25% of the world's industrial output in 1750, with Mughal Bengal in particular being globally dominant in industries such as textile manufacturing and shipbuilding.\n\nIn early modern Europe, there was significant demand for products from Mughal India, particularly cotton textiles, as well as goods such as spices, peppers, indigo, silks, and saltpeter (for use in munitions). European fashion, for example, became increasingly dependent on Indian textiles and silks. In the 17th and 18th centuries, India accounted for 95% of British imports from Asia, and the Bengal Subah alone accounted for 40% of Dutch imports from Asia. Amiya Kumar Bagchi estimates 10.3% of Bihar's populace were involved in hand spinning thread, 2.3% weaving, and 9% in other manufacturing trades, in 1809-13, to satisfy this demand. In contrast, there was very little demand for European goods in India, which was largely self-sufficient, thus Europeans had very little to offer, except for some woolen textiles, unprocessed metals and a few luxury items. The trade imbalance caused Europeans to export large quantities of gold and silver to India in order to pay for Indian imports.\n\nThe Middle East was more advanced than Western Europe in 1000 CE, on par by the middle of the 16th century, but by 1750, leading Middle-Eastern states had fallen behind the leading Western European states of Britain and the Netherlands.\n\nAn example of a Middle-Eastern country that had an advanced economy in the early 19th century was Ottoman Egypt, which had a highly productive industrial manufacturing sector, and per-capita income that was comparable to leading Western European countries such as France and higher than that of Japan and Eastern Europe. Other parts of the Ottoman Empire, particularly Syria and southeastern Anatolia, also had a highly productive manufacturing sector that was evolving in the 19th century. In 1819, Egypt under Muhammad Ali began programs of state-sponsored industrialization, which included setting up factories for weapons production, an iron foundry, large-scale cotton cultivation, mills for ginning, spinning and weaving of cotton, and enterprises for agricultural processing. By the early 1830s, Egypt had 30 cotton mills, employing about 30,000 workers. In the early 19th century, Egypt had the world's fifth most productive cotton industry, in terms of the number of spindles per capita. The industry was initially driven by machinery that relied on traditional energy sources, such as animal power, water wheels, and windmills, which were also the principle energy sources in Western Europe up until around 1870. While steam power had been experimented with in Ottoman Egypt by engineer Taqi ad-Din Muhammad ibn Ma'ruf in 1551, when he invented a steam jack driven by a rudimentary steam turbine, it was under Muhammad Ali of Egypt in the early 19th century that steam engines were introduced to Egyptian industrial manufacturing. Boilers were manufactured and installed in Egyptian industries such as ironworks, textile manufacturing, paper mills, and hulling mills. Compared to Western Europe, Egypt also had superior agriculture and an efficient transport network through the Nile. Economic historian Jean Batou argues that the necessary economic conditions for rapid industrialization existed in Egypt during the 1820s–1830s.\n\nAfter the death of Muhammad Ali in 1849, his industrialization programs fell into decline, after which, according to historian Zachary Lockman, “Egypt was well on its way to full integration into a European-dominated world market as supplier of a single raw material, cotton.” Lockman argues that, had Egypt succeeded in its industrialization programs, “it might have shared with Japan [or the United States] the distinction of achieving autonomous capitalist development and preserving its independence.”\n\nJapanese society was governed by the Tokugawa Shogunate, which divided Japanese society into a strict hierarchy and intervened considerably in the economy through state monopolies and restrictions on foreign trade; however, in practice, the Shogunate's rule was often circumvented. From 725-1974, Japan experienced GDP per capita growth at an annual rate of 0.04%, with major periods of positive per capita GDP growth occurring during 1150-1280, 1450-1600 and after 1730. There were no significant periods of sustained growth reversals. Relative to the United Kingdom, GDP per capita was at roughly similar levels until the middle of the 17th century. By 1850, per capita incomes in Japan were approximately a quarter of the British level. However, 18th-century Japan had a higher life expectancy, 41.1 years for adult males, compared with 31.6 to 34 for England, between 27.5 and 30 for France, and 24.7 for Prussia.\n\nIn its earlier days, Korea had healthy international trading relationships, receiving merchants from as far as the Middle East. Because of its strategic value to its neighboring countries, however, Korea had been invaded several times during its Goryeo and Joseon eras, starting with the Mongol invasion in the 13th century. Though repelled due to its strong navy and aid from China, the Japanese invasions in the late 16th century were particularly devastating to the peninsula and it never truly recovered until the modern era. Due to relatively frequent invasions, increased Western colonization of Asia, and the arrival of Christian missionaries, Korea began a long period of isolationism, maintaining diplomatic relationships primarily with China only. For the rest of the Joseon period, the country was marred by economic hardships, peasant revolts, and political factionalism until it was annexed by Japan in the early 20th century.\n\nPre-colonial Sub-Saharan Africa was politically fragmented, just as early modern Europe was. Africa was however far more sparsely populated than Europe. According to University of Michigan political scientist Mark Dincecco, \"the high land/ labor ratio may have made it less likely that historical institutional centralization at the “national level” would occur in sub-Saharan Africa, thwarting further state development.\" The transatlantic slave trade may have further weakened state power in Africa.\n\nScholars have proposed numerous theories to explain why the Great Divergence occurred.\n\nIn metallurgy and steam engines the Industrial Revolution made extensive use of coal and coke - as cheaper, more plentiful and more efficient than wood and charcoal.\nCoal-fired steam engines also operated in the railways and in shipping, revolutionizing transport in the early 19th century.\n\nKenneth Pomeranz drew attention to differences in the availability of coal between West and East. Due to regional climate, European coal mines were wetter, and deep mines did not become practical until the introduction of the Newcomen steam engine to pump out groundwater. In mines in the arid northwest of China, ventilation to prevent explosions was much more difficult.\n\nAnother difference involved geographic distance; although China and Europe had comparable mining technologies, the distances between the economically developed regions and coal deposits differed vastly. The largest coal deposits in China are located in the northwest, within reach of the Chinese industrial core during the Northern Song (960-1127). During the 11th century China developed sophisticated technologies to extract and use coal for energy, leading to soaring iron production. The southward population shift between the 12th and 14th centuries resulted in new centers of Chinese industry far from the major coal deposits. Some small coal deposits were available locally, though their use was sometimes hampered by government regulations. In contrast, Britain contained some of the largest coal deposits in Europe - all within a relatively compact island.\n\nOttoman Egypt, which used steam power for industrial manufacturing under Muhammad Ali Pasha (ruled 1805-1848), had a lack of coal resources. However, Muhammad Ali Pasha's prospectors searched for coal deposits, and boilers were manufactured and installed in various industries. Egypt also imported coal from overseas, at similar prices to what imported coal cost in France, until the 1830s, when Cairo gained access to coal sources in Lebanon, which had a yearly coal output of 4,000 tons. Economic historian Jean Batou argues that, in addition to having the necessary conditions for rapid industrialization, Egypt also had the necessary conditions for the adoption of oil as a potential energy source for its steam engines later in the 19th century.\n\nA common argument is that Europe had more free and efficient markets than other civilizations, which has been cited as a reason for the Great Divergence. In Europe, market efficiency was disrupted by the prevalence of feudalism and mercantilism. Practices such as entail, which restricted land ownership, hampered the free flow of labor and buying and selling of land. These feudal restrictions on land ownership were especially strong in continental Europe. China had a relatively more liberal land market, hampered only by weak customary traditions. Bound labor, such as serfdom and slavery were more prevalent in Europe than in China, even during the Manchu conquest. Urban industry in the West was more restrained by guilds and state-enforced monopolies than in China, where in the 18th century the principal monopolies governed salt and foreign trade through Guangzhou. Pomeranz rejects the view that market institutions were the cause of the Great Divergence, and concludes that China was closer to the ideal of a market economy than Europe.\n\nEconomic historian Paul Bairoch presents a contrary argument, that Western countries such as the United States, Britain and Spain did not initially have free trade, but had protectionist policies in the early 19th century, as did China and Japan. In contrast, he cites the Ottoman Empire as an example of a state that did have free trade, which he argues had a negative economic impact and contributed to its deindustrialization. The Ottoman Empire had a liberal trade policy, open to foreign imports, which has origins in capitulations of the Ottoman Empire, dating back to the first commercial treaties signed with France in 1536 and taken further with capitulations in 1673 and 1740, which lowered duties to only 3% for imports and exports. The liberal Ottoman policies were praised by British economists advocating free trade, such as J. R. McCulloch in his \"Dictionary of Commerce\" (1834), but later criticized by British politicians opposing free trade, such as prime minister Benjamin Disraeli, who cited the Ottoman Empire as \"an instance of the injury done by unrestrained competition\" in the 1846 Corn Laws debate:\n\nJared Diamond in the book \"Guns, Germs, and Steel\" argues that explicit outlawing of new technology was an important explanation for the divergence. For example, in China in 1432, a new Emperor outlawed the building of ocean-going ships, in which China was the world leader at the time. Diamond traces this to differences in geography. Outside Europe advanced cultures developed in areas whose geography was conducive to large, monolithic, isolated empires. In these conditions policies of technological and social stagnation could persist. On the other hand, Europe's geography favored balkanization into smaller, closer, nation-states, as its many natural barriers (mountains, rivers) provide defensible borders. As a result, governments that suppressed economic and technological progress soon corrected their mistakes or were out-competed relatively quickly. He argues that geographical factors created the conditions for more rapid internal superpower change (Spain succeeded by France and then by the United Kingdom) than was possible elsewhere in Eurasia.\n\nBeginning in the early 19th century, economic prosperity rose greatly in the West due to improvements in technological efficiency, as evidenced by the advent of new conveniences including the railroad, steamboat, steam engine, and the use of coal as a fuel source. These innovations contributed to the Great Divergence, elevating Europe and the United States to high economic standing relative to the East.\n\nIt has been argued the attitude of the East towards innovation is one of the other factors that might have played a big role in the West's advancements over the East. According to David Landes, after a few centuries of innovations and inventions, it seemed like the East stopped trying to innovate and began to sustain what they had. They kept nurturing their pre-modern inventions and did not move forward with the modern times. China decided to continue a self-sustaining process of scientific and technological advancement on the basis of their indigenous traditions and achievements. The East’s attitude towards innovation showed that they focused more on experience, while the West focused on experimentation. The East did not see the need to improve on their inventions and thus from experience, focused on their past successes. While they did this, the West was focused more on experimentation and trial by error, which led them to come up with new and different ways to improve on existing innovations and create new ones.\n\nIn the early 19th century, Egypt under Muhammad Ali began a program of state-sponsored industrialization, quick to adopt steam engine technology, and manufacturing boilers for installation in a number of industries, including ironworks, textile manufacturing, paper mills, and hulling mills. While there was a lack of coal deposits in Egypt, Muhammad Ali Pasha's prospectors searched for coal deposits in Egypt while importing coal from overseas at similar prices to what imported coal cost in France, until the 1830s when Egypt gained access to coal sources in Lebanon with its yearly coal output of 4,000 tons. Economic historian Jean Batou argues that Egypt had the necessary economic conditions for rapid industrialization in the early 19th century, and for the adoption of oil as a potential energy source for its steam engines later in the 19th century.\n\nClassical economists, beginning with Adam Smith and Thomas Malthus, argued that high wages in the West stimulated labor-saving technological advancements. Economic historian Robert Allen has argued that high wages, cheap capital and very cheap energy in Britain made it the ideal place for the industrial revolution to occur. These factors made it vastly more profitable to invest in research and development, and to put technology to use in Britain than other societies.\n\nHowever, more recent studies have depicted living standards in 18th century China and pre-Industrial Revolution Europe as comparable. Life expectancy in China and Japan for adult males were 39.6 and 41.1 respectively, compared with 34 for England, between 27.5 and 30 for France, and 24.7 for Prussia. Chinese laborers in the Yangtze delta consumed 4,600 calories per day on average (laborers in China overall consumed 2,637 calories on average) compared with 2,000-2,500 calories per day for England. According to Pomeranz and others, there was modest per capita growth in both regions, the Chinese economy was not stagnant, and in many areas, especially agriculture, was ahead of Western Europe. Chinese cities were also ahead in public health. Economic historian Paul Bairoch estimated that China's GNP per capita in 1800 was $228 in 1960 US dollars ($ in 1990 dollars), higher than Western Europe's $213 ($ in 1990 dollars) at the time.\n\nThere have been similar findings for India. Real wages and living standards in 18th-century Bengal and Mysore were higher than in Britain, which in turn had the highest living standards in Europe. Workers in the textile industry, for example, earned more in Bengal and Mysore than they did in Britain, while agricultural labour in Britain had to work longer hours to earn the same amount as in Mysore. In the late 18th century, Mysore's average per-capita income was five times higher than subsistence level, i.e. five times higher than $400 (1990 international dollars), or $2,000 per capita. In comparison, the highest national per-capita incomes in 1820 were $1,838 for the Netherlands and $1,706 for Britain.\n\nSimilarly for Ottoman Egypt, its per-capita income in 1800 was comparable to that of leading Western European countries such as France, and higher than the overall average income of Europe and Japan. Economic historian Jean Barou estimated that, in terms of 1960 dollars, Egypt in 1800 had a per-capita income of $232 ($ in 1990 dollars). In comparison, per-capita income in terms of 1960 dollars for France in 1800 was $240 ($ in 1990 dollars), for Eastern Europe in 1800 was $177 ($ in 1990 dollars), and for Japan in 1800 was $180 ($ in 1990 dollars).\n\nAccording to Paul Bairoch, in the mid-18th century, \"the average standard of living in Europe was a little bit lower than that of the rest of the world.\" He estimated that, in 1750, the average GNP per capita in the Eastern world (particularly China, India and the Middle East) was $188 in 1960 dollars ($ in 1990 dollars), higher than the West's $182 ($ in 1990 dollars). He argues that it was after 1800 that Western European per-capita income pulled ahead. However, the average incomes of China and Egypt were still higher than the overall average income of Europe.\n\nA number of economic historians have argued that European colonialism played a major role in the deindustrialization of non-Western societies. Paul Bairoch, for example, cites British colonialism in India as a primary example, but also argues that European colonialism played a major role in the deindustrialization of other countries in Asia, the Middle East, and Latin America, and contributed to a sharp economic decline in Africa. Other modern economic historians have blamed British colonial rule for India's deindustrialization in particular. The colonization of India is seen as a major factor behind both India's deindustrialization and Britain's Industrial Revolution.\n\nUp until the 19th century, India was the world's leading cotton textile manufacturer, with Bengal and Mysore the centers of cotton production. In order to compete with India, Britain invested in labour-saving technical progress for textile manufacture during the Industrial Revolution, while implementing protectionist policies such as bans and tariffs to restrict Indian imports. At the same time, the British East India Company's rule in India contributed to its deindustrialization, with the decline of native industry opening up a new market for British goods. British colonization forced open the large Indian market to British goods while restricting Indian imports to Britain, and raw cotton was imported from India without taxes or tariffs to British factories which manufactured textiles from Indian cotton and sold them back to the Indian market. India thus served as both an important supplier of raw goods such as cotton to British factories and a large captive market for British manufactured goods. In addition, the capital amassed from Bengal following its conquest after the Battle of Plassey in 1757 was used to invest in British industries such as textile manufacturing and greatly increase British wealth. Britain eventually surpassed India as the world's leading cotton textile manufacturer in the 19th century. British colonial rule has been blamed for the subsequently dismal state of British India's economy, with investment in Indian industries limited since it was a colony.\n\nLuxury consumption is regarded by many scholars to have stimulated the development of capitalism and thus contributed to the Great Divergence. Proponents of this view argue that workshops, which manufactured luxury articles for the wealthy, gradually amassed capital to expand their production and then emerged as large firms producing for a mass market; they believe that Western Europe's unique tastes for luxury stimulated this development further than other cultures. However, others counter that luxury workshops were not unique to Europe; large cities in China and Japan also possessed many luxury workshops for the wealthy, and that luxury workshops do not necessarily stimulate the development of \"capitalistic firms\".\n\nDifferences in property rights have been cited as a possible cause of the Great Divergence. This view states that Asian merchants could not develop and accumulate capital because of the risk of state expropriation and claims from fellow kinsmen, which made property rights very insecure compared to those of Europe. However, others counter that many European merchants were de facto expropriated through defaults on government debt, and that the threat of expropriation by Asian states was not much greater than in Europe, except in Japan.\n\nGovernment and policies are seen as an integral part of modern societies and have played a major role in how different economies have been formed. The Eastern societies had governments which were controlled by the ruling dynasties and thus, were not a separate entity. Their governments at the time lacked policies that fostered innovation and thus resulted in slow advancements. As explained by Cohen, the east had a restrictive system of trade that went against the free world market theory; there was no political liberty or policies that encouraged the capitalist market (Cohen, 1993). This was in contrast to the western society that developed commercial laws and property rights which allowed for the protection and liberty of the marketplace. Their capitalist ideals and market structures encouraged innovation.\n\nPomeranz (2000) argues that much of the land market in China was free, with many supposedly hereditary tenants and landlords being frequently removed or forced to sell their land. Although Chinese customary law specified that people within the village were to be offered the land first, Pomeranz states that most of the time the land was offered to more capable outsiders, and argues that China actually had a freer land market than Europe.\nPomeranz does not address the most common form of land sale, known as the conditional sale. The conditional sale allowed the seller to return to the buyer many years after the sale, and many times, to demand extra payments. He also does not account for the inability of landlords to collect rent on second crops.\n\nHowever, Robert Brenner and Chris Isett emphasize differences in land tenancy rights. They argue that in the lower Yangtze, most farmers either owned land or held secure tenancy at fixed rates of rent, so that neither farmers nor landlords were exposed to competition. In 15th century England, lords had lost their serfs, but were able to assert control over almost all of the land, creating a rental market for tenant farmers. This created competitive pressures against subdividing plots, and the fact that plots could not be directly passed on to sons forced them to delay marriage until they had accumulated their own possessions. Thus in England both agricultural productivity and population growth were subject to market pressures throughout the early modern period.\n\nA 2017 study found that secure property rights in Europe, but not in large parts of the Middle-East, contributed to the increase of expensive labour-saving capital goods, such as water-mills, windmills, and cranes, in medieval Europe but its decrease in the Middle-East.\n\nA variety of theories posit Europe's unique relationship with the New World as a major cause of the Great Divergence. The high profits earned from the colonies and the slave trade constituted 7 percent a year, a relatively high rate of return considering the high rate of depreciation on pre-industrial capital stocks, which limited the amount of savings and capital accumulation. Early European colonization was sustained by profits through selling New World goods to Asia, especially silver to China. According to Pomeranz, the most important advantage for Europe was the vast amount of fertile, uncultivated land in the Americas which could be used to grow large quantities of farm products required to sustain European economic growth and allowed labor and land to be freed up in Europe for industrialization. New World exports of wood, cotton, and wool are estimated to have saved England the need for 23 to of cultivated land (by comparison, the total amount of cultivated land in England was just 17 million acres), freeing up immense amounts of resources. The New World also served as a market for European manufactures.\n\nChen (2012) also suggested that the New World as a necessary factor for industrialization, and trade as a supporting factor causing less developed areas to concentrate on agriculture supporting industrialized regions in Europe.\n\nThe high-level equilibrium trap theory argues that China did not undergo an indigenous industrial revolution since its economy was in a stable equilibrium, where supply and demand for labor were equal, disincentivizing the development of labor-saving capital.\n\nRosenberg and Birdzell claims that the so-called \"eastern culture\" of \"respect\" and \"unquestionable devotion\" to the ruling dynasty was as a result of a culture where the control of the dynasty led to a \"silent society\" that \"did not ask questions or experiment without the approval or order from the ruling class\". On the other hand, they claimed that the West of the late medieval era did not have a central authority or absolute state, which allowed for a free flow of ideas (Rosenberg, Birdzell, 1986). This so-called \"eastern culture\" also supposedly showed a \"dismissal of change\" due to their \"fear of failure\" and disregard for the imitation of outside inventions and science; this was different from the \"western culture\" which they claimed to be willing to experiment and imitate others to benefit their society. They claimed that this was a culture where change was encouraged, and sense of anxiety and disregard for comfort led them to be more innovative. Max Weber argued in \"The Protestant Ethic and the Spirit of Capitalism\" that capitalism in northern Europe evolved when the Protestant work ethic (particularly Calvinist) influenced large numbers of people to engage in work in the secular world, developing their own enterprises and engaging in trade and the accumulation of wealth for investment. In his book \"\" he blames Chinese culture for the non-emergence of capitalism in China. Chen (2012) similarly claims that cultural differences were the most fundamental cause for the divergence, arguing that the Humanism of the Renaissance followed by the Enlightenment (including revolutionary changes in attitude towards religion) enabled a mercantile, innovative, individualistic, and capitalistic spirit. For Ming Dynasty China, he claims there existed repressive measures which stifled dissenting opinions and nonconformity. He claimed that Confucianism taught that disobedience to one's superiors was supposedly tantamount to \"sin\". In addition Chen claimed that merchants and artificers had less prestige than they did in Western Europe. Justin Yifu Lin has argued for the role of the imperial examination system in removing the incentives for Chinese intellectuals to learn mathematics or to conduct experimentation.\n\nHowever, many scholars who have studied Confucian teachings have criticized the claim that the philosophy promoted unquestionable loyalty to one's superiors and the state. The core of Confucian philosophy itself was already Humanistic and Rationalistic; it \"[does] not share a belief in divine law and [does] not exalt faithfulness to a higher law as a manifestation of divine will.\"\n\nOne of the central teachings of Confucianism is that one should remonstrate with authority. Many Confucians throughout history disputed their superiors in order to not only prevent the superiors and the rulers from wrongdoing, but also to maintain the independent spirits of the Confucians.\n\nFurthermore, the merchant class of China throughout all of Chinese history were usually wealthy and held considerable influence above their supposed social standing. Historians like Yu Yingshi and Billy So have shown that as Chinese society became increasingly commercialized from the Song dynasty onward, Confucianism had gradually begun to accept and even support business and trade as legitimate and viable professions, as long as merchants stayed away from unethical actions. Merchants in the meantime had also benefited from and utilized Confucian ethics in their business practices. By the Song period, the Scholar-officials themselves were using intermediary agents to participate in trading.\nThis is true especially in the Ming-Qing dynasties, when the social status of merchants had rose to such significance that by the late Ming period, many scholar-officials were unabashed to declare publicly in their official family histories that they had family members who were merchants. Consequently, while Confucianism did not actively promote profit seeking, it did not hinder China’s commercial development either.\n\nOf the developed cores of the Old world, India was distinguished by its caste system of bound labor, which hampered economic and population growth and resulted in relative underdevelopment compared to other core regions. Compared with other developed regions, India still possessed large amounts of unused resources. India's caste system gave an incentive to elites to drive their unfree laborers harder when faced with increased demand, rather than invest in new capital projects and technology. The Indian economy was characterized by vassal-lord relationships, which weakened the motive of financial profit and the development of markets; a talented artisan or merchant could not hope to gain much personal reward. Pomeranz argues that India was not a very likely site for an industrial breakthrough, despite its sophisticated commerce and technologies.\n\nAspects of Islamic law have been proposed as an argument for the divergence for the Muslim world. Economist Timur Kuran argues that Islamic institutions which had at earlier stages promoted development later started preventing more advanced development by hampering formation of corporations, capital accumulation, mass production, and impersonal transactions. Other similar arguments proposed include the gradual prohibition of independent religious judgements (Ijtihad) and a strong communalism which limited contacts with outside groups and the development of institutions dealing with more temporary interactions of various kinds, according to Kuran. According to historian Donald Quataert, however, the Ottoman Middle East's manufacturing sector was highly productive and evolving in the 19th century. Quataert criticizes arguments rooted in Orientalism, such as \"now-discredited stereotypes concerning the inferiority of Islam\", economic institutions having stopped evolving after the Islamic Golden Age, and decline of Ijtihad in religion negatively affecting economic evolution. Economic historian Paul Bairoch noted that Ottoman law promoted liberal free trade earlier than Britain and the United States, arguing that free trade had a negative economic impact on the Ottoman Empire and contributed to its deindustrialization, in contrast to the more protectionist policies of Britain and the United States in the early 19th century.\n\nIn his book \"A Farewell to Alms\", Gregory Clark argues that the human psychological traits (such as literacy, numeracy, and delayed gratification) needed for the divergence spread in England between 1200 and 1800 \"at least culturally and perhaps also genetically\". A shorter online version of Clark's work can be found here: http://faculty.econ.ucdavis.edu/faculty/gclark/papers/Capitalism%20Genes.pdf\n\nEconomic historian Joel Mokyr has argued that political fragmentation (the presence of a large number of European states) made it possible for heterodox ideas to thrive, as entrepreneurs, innovators, ideologues and heretics could easily flee to a neighboring state in the event that the one state would try to suppress their ideas and activities. This is what set Europe apart from the technologically advanced, large unitary empires such as China. China had both a printing press and movable type, yet the industrial revolution would occur in Europe. In Europe, political fragmentation was coupled with an \"integrated market for ideas\" where Europe's intellectuals used the lingua franca of Latin, had a shared intellectual basis in Europe's classical heritage and the pan-European institution of the Republic of Letters.\n\nEconomic historian Tuan-Hwee Sng has argued that the large size of the Chinese state contributed to its relative decline in the 19th century:The vast size of the Chinese empire created a severe principal-agent problem and constrained how the country was governed. In particular, taxes had to be kept low due to the emperor's weak oversight of his agents and the need to keep corruption in check. The Chinese state's fiscal weaknesses were long masked by its huge tax base. However, economic and demographic expansion in the eighteenth century exacerbated the problems of administrative control. This put a further squeeze on the nation's finances and left China ill-prepared for the challenges of the nineteenth century.One reason why Japan was able to modernize and adopt the technologies of the West was due to its much smaller size relative to China.\n\nThe historian Jeffrey G. Williamson has argued that India went through a period of deindustrialization in the latter half of the 18th century as an indirect outcome of the collapse of the Mughal Empire, with British rule later causing further deindustrialization. According to Williamson, the decline of the Mughal Empire led to a decline in agricultural productivity, which drove up food prices, then nominal wages, and then textile prices, which led to India losing a share of the world textile market to Britain even before it had superior factory technology, though Indian textiles still maintained a competitive advantage over British textiles up until the 19th century. Economic historian Prasannan Parthasarathi, however, has argued that there wasn't any such economic decline for several post-Mughal states, notably Bengal Subah and the Kingdom of Mysore, which were comparable to Britain in the late 18th century, until British colonial policies caused deindustrialization.\n\nStanford political scientist Gary W. Cox argues in a 2017 study,that Europe's political fragmentation interacted with her institutional innovations to foster substantial areas of “economic liberty,” where European merchants could organize production freer of central regulation, faced fewer central restrictions on their shipping and pricing decisions, and paid lower tariffs and tolls than their counterparts elsewhere in Eurasia. When fragmentation afforded merchants multiple politically independent routes on which to ship their goods, European rulers refrained from imposing onerous regulations and levying arbitrary tolls, lest they lose mercantile traffic to competing realms. Fragmented control of trade routes magnified the spillover effects of political reforms. If parliament curbed arbitrary regulations and tolls in one realm, then neighboring rulers might have to respond in kind, even if they themselves remained without a parliament. Greater economic liberty, fostered by the interaction of fragmentation and reform, unleashed faster and more inter-connected urban growth. Justin Yifu Lin argued that China's large population size proved beneficial in technological advancements prior to the 14th century, but that the large population size was not an important factor in the kind of technological advancements that resulted in the Industrial Revolution. Early technological advancements depended on \"learning by doing\" (where population size was an important factor, as advances could spread over a large political unit), whereas the Industrial Revolution was the result of experimentation and theory (where population size is less important.\n\nA number of economists have argued that representative government was a factor in the Great Divergence. The argue that absolutist governments, where rulers are not broadly accountable, are bad for property rights and innovation, and that they are prone to corruption and rent-seeking. Representative governments however were accountable to broader segments of the population and thus had to protect property rights and not rule in arbitrary ways, which caused economic prosperity.\n\nA 2017 study in the \"American Economic Review\" found that \"globalization was the major driver of the economic divergence between the rich and the poor portions of the world in the years 1850-1900.\" The states that benefited from globalization were \"characterised by strong constraints on executive power, a distinct feature of the institutional environment that has been demonstrated to favour private investment.\"\n\nA number of economic historians have posited that the Industrial Revolution may have partly occurred where and when it did due to luck and chance.\n\nThe Old World methods of agriculture and production could only sustain certain lifestyles. Industrialization dramatically changed the European economy and allowed it to attain much higher levels of wealth and productivity than the other Old World cores. Although Western technology later spread to the East, differences in uses preserved the Western lead and accelerated the Great Divergence.\n\nWhen analyzing comparative use-efficiency, the economic concept of total factor productivity (TFP) is applied to quantify differences between countries. TFP analysis controls for differences in energy and raw material inputs across countries and is then used to calculate productivity. The difference in productivity levels, therefore, reflects efficiency of energy and raw materials use rather than the raw materials themselves. TFP analysis has shown that Western countries had higher TFP levels on average in the 19th century than Eastern countries such as India or China, showing that Western productivity had surpassed the East.\n\nSome of the most striking evidence for the Great Divergence comes from data on per capita income. The West's rise to power directly coincides with per capita income in the West surpassing that in the East. This change can be attributed largely to the mass transit technologies, such as railroads and steamboats, that the West developed in the 19th century. The construction of large ships, trains, and railroads greatly increased productivity. These modes of transport made moving large quantities of coal, corn, grain, livestock and other goods across countries more efficient, greatly reducing transportation costs. These differences allowed Western productivity to exceed that of other regions.\n\nEconomic historian Paul Bairoch has estimated the GDP per capita of several major countries in 1960 US dollars after the Industrial Revolution in the early 19th century, as shown below.\n\nHis estimates show that the GDP per capita of Western European countries rose rapidly after industrialization.\n\nFor the 18th century, and in comparison to non-European regions, Bairoch in 1995 stated that, in the mid-18th century, \"the average standard of living in Europe was a little bit lower than that of the rest of the world.\"\n\nBefore and during the early 19th century, much of continental European agriculture was underdeveloped compared to Asian Cores and England. This left Europe with abundant idle natural resources. England, on the other hand, had reached the limit of its agricultural productivity well before the beginning of the 19th century. Rather than taking the costly route of improving soil fertility, the English increased labor productivity by industrializing agriculture. From 1750 to 1850, European nations experienced population booms; however, European agriculture was barely able to keep pace with the dietary needs. Imports from the Americas, and the reduced caloric intake required by industrial workers compared to farmers allowed England to cope with the food shortages. By the turn of the 19th century, much European farmland had been eroded and depleted of nutrients. Fortunately, through improved farming techniques, the import of fertilizers, and reforestation, Europeans were able to recondition their soil and prevent food shortages from hampering industrialization. Meanwhile, many other formerly hegemonic areas of the world were struggling to feed themselves – notably China.\n\nThe global demand for wood, a major resource required for industrial growth and development, was increasing in the first half of the 19th century. A lack of interest of silviculture in Western Europe, and a lack of forested land, caused wood shortages. By the mid-19th century, forests accounted for less than 15% of land use in most Western European countries. Fuel costs rose sharply in these countries throughout the 18th century and many households and factories were forced to ration their usage, and eventually adopt forest conservation policies. It was not until the 19th century that coal began providing much needed relief to the European energy shortage. China had not begun to use coal on a large scale until around 1900, giving Europe a huge lead on modern energy production.\n\nThrough the 19th century, Europe had vast amounts of unused arable land with adequate water sources. However, this was not the case in China; most idle lands suffered from a lack of water supply, so forests had to be cultivated. Since the mid-19th century, northern China's water supplies have been declining, reducing its agricultural output. By growing cotton for textiles, rather than importing, China exacerbated its water shortage.\nDuring the 19th century, supplies of wood and land decreased considerably, greatly slowing growth of Chinese per capita incomes.\n\nDuring the era of European imperialism, periphery countries were often set up as specialized producers of specific resources. Although these specializations brought the periphery countries temporary economic benefit, the overall effect inhibited the industrial development of periphery territories. Cheaper resources for core countries through trade deals with specialized periphery countries allowed the core countries to advance at a much greater pace, both economically and industrially, than the rest of the world.\n\nEurope's access to a larger quantity of raw materials and a larger market to sell its manufactured goods gave it a distinct advantage through the 19th century. In order to further industrialize, it was imperative for the developing core areas to acquire resources from less densely populated areas, since they lacked the lands required to supply these resources themselves. Europe was able to trade manufactured goods to their colonies, including the Americas, for raw materials. The same sort of trading could be seen throughout regions in China and Asia, but colonization brought a distinct advantage to the West. As these sources of raw materials began to proto-industrialize, they would turn to import substitution, depriving the hegemonic nations of a market for their manufactured goods. Since European nations had control over their colonies, they were able to prevent this from happening. Britain was able to use import substitution to its benefit when dealing with textiles from India. Through industrialization, Britain was able to increase cotton productivity enough to make it lucrative for domestic production, and overtake India as the world's leading cotton supplier. Although Britain had limited cotton imports to protect its own industries, they allowed cheap British products into colonial India from the early 19th century. The colonial administration failed to promote Indian industry, preferring to export raw materials.\n\nWestern Europe was also able to establish profitable trade with Eastern Europe. Countries such as Prussia, Bohemia and Poland had very little freedom in comparison to the West; forced labor left much of Eastern Europe with little time to work towards proto-industrialization and ample manpower to generate raw materials.\n\nA 2017 study in the \"Quarterly Journal of Economics\" argued, \"medieval European institutions such as guilds, and specific features such as journeymanship, can explain the rise of Europe relative to regions that relied on the transmission of knowledge within closed kinship systems (extended families or clans)\". Guilds and journeymanship were superior for creating and disseminating knowledge, which contributed to the occurrence of the Industrial Revolution in Europe.\n\n\n\n\n\n"}
{"id": "50371799", "url": "https://en.wikipedia.org/wiki?curid=50371799", "title": "Göttingen School of History", "text": "Göttingen School of History\n\nThe Göttingen school of history was a group of historians associated with a particular style of historiography located at the University of Göttingen in the late 18th century. This group of historians played an important role in creating a \"scientific\" basis for historical research, and were also responsible for coining two fundamental groups of terminologies in scientific racism:\n\nThe University of Göttingen was the original centre of the \"\" or history as an academic discipline, and became a major centre for globally-orientated anthropology. The school itself was one of the newest universities in Europe, having been founded in 1734 by , and the first to require the obligation to conduct and publish research alongside lecturing. The historians of this school sought to write a universal history by combining the critical methods of Jean Mabillon with that of the philosophical historians such as Voltaire and Edward Gibbon.\n\n"}
{"id": "7705856", "url": "https://en.wikipedia.org/wiki?curid=7705856", "title": "History of Indigenous Australians", "text": "History of Indigenous Australians\n\nThe History of Indigenous Australians began at least 65,000 years ago when humans first populated Australia.\n\nThe origin of first humans to populate the southern continent remains a matter of conjecture and debate. Some anthropologist believe they could have arrived as a result of the earliest human migrations out of Africa. Although they likely migrated to the territory, later named Australia, though Southeast Asia they are not demonstrably related to any known Asian or Polynesian population. There is evidence of genetic and linguistic interchange between Australians in the far north and the Austronesian peoples of modern-day New Guinea and the islands, but this may be the result of recent trade and intermarriage.\n\nAt the time of first European contact, it is generally estimated that between 315,000 to 750,000 people lived in Australia, in diverse groups, but upper estimates place the total population as high as 1.25 million. A cumulative population of 1.6 billion people has been estimated to have lived in Australia over 65,000 years prior to British colonisation. The regions of heaviest Indigenous population were the same temperate coastal regions that are currently the most heavily populated. In the early 1900s it was commonly believed that the Aboriginal population of Australia was leading toward extinction. The population shrank from those present when colonisation occurred in 1788 to 50,000 in 1930; this was primarily due to an outbreak of smallpox and to a lesser extent from other diseases.\n\nPost-colonisation, the coastal Indigenous populations were soon absorbed, depleted or forced from their lands; the traditional aspects of Aboriginal life which remained persisted most strongly in areas such as the Great Sandy Desert where European settlement has been sparse. The greatest population density was to be found in the southern and eastern regions of the continent, the Murray River valley in particular. However, Aboriginal Australians maintained successful communities throughout Australia, from the cold and wet highlands of Tasmania to the more arid parts of the continental interior. Technologies, diets and hunting practices varied according to the local environment.\n\nIt is believed that the first early human migration to Australia was achieved when this landmass formed part of the Sahul continent, connected to the island of New Guinea via a land bridge. It is also possible that people came by island hopping via an island chain between Sulawesi and New Guinea and the other reaches North Western Australia via Timor. The exact timing of the arrival of the ancestors of the Aboriginal Australians has been a matter of dispute among archaeologists. The most generally accepted date for first arrival is between 40,000–80,000 years BP. Near Penrith in New South Wales, since 1971 numerous Aboriginal stone tools have been found in Cranebrook Terraces gravel sediments having dates of 45,000 to 50,000 years BP. When these results were new they were controversial, but more recent dating of the same strata in 1987 and 2003 has corroborated these dates. A 48,000 BCE date is based on a few sites in northern Australia dated using thermoluminescence.\n\nA large number of sites have been radiocarbon dated to around 38,000 BCE, leading some researchers to doubt the accuracy of the thermoluminescence technique. Radiocarbon dating is limited to a maximum age of around 40,000 years. Some estimates have been given as widely as from 30,000 to 68,000 BCE. Earlier dates are requiring new techniques such as optically stimulated luminescence (OSL) and accelerator mass spectrometry (AMS), and the evidence for an earlier date of arrival is growing. Charles Dortch has dated recent finds on Rottnest Island, Western Australia at 70,000 years BP. The rock shelters at Malakunanja II (a shallow rock-shelter about 50 kilometres inland from the present coast) and of Nauwalabila I (70 kilometres further south) show evidence of used pieces of ochre – evidence for paint used by artists 60,000 years ago. Using OSL Rhys Jones has obtained a date for stone tools in these horizons dating from 53,000–60,000 years ago.\n\nThermoluminescence dating of the Jinmium site in the Northern Territory suggested a date of 116,000 plus or minus 12,000 BCE. Although this result received wide press coverage, it is not accepted by most archaeologists. Only Africa has older physical evidence of habitation by modern humans. There is also evidence of a change in fire regimes in Australia, drawn from reef deposits in Queensland, between 70 and 100,000 years ago, and the integration of human genomic evidence from various parts of the world also supports a date of before 60,000 years for the arrival of Australian Aboriginal people in the continent.\n\nHumans reached Tasmania approximately 40,000 years ago by migrating across a land bridge from the mainland that existed during the last glacial maximum. After the seas rose about 12,000 years ago and covered the land bridge, the inhabitants there were isolated from the mainland until the arrival of European settlers.\n\nShort statured aboriginal tribes inhabited the rainforests of North Queensland, of which the best known group is probably the Tjapukai of the Cairns area. These rainforest people, collectively referred to as Barrineans, were once considered to be a relic of an earlier wave of Negrito migration to the Australian continent, but this theory no longer finds much favour.\n\nMungo Man, whose remains were discovered in 1974 near Lake Mungo in New South Wales, is the oldest human yet found in Australia. Although the exact age of Mungo Man is in dispute, the best consensus is that he is at least 40,000 years old. Stone tools also found at Lake Mungo have been estimated, based on stratigraphic association, to be about 50,000 years old. Since Lake Mungo is in south-eastern Australia, many archaeologists have concluded that humans must have arrived in north-west Australia at least several thousand years earlier.\n\nIn 2012, the results of large-scale genotyping has indicated that Aboriginal Australians, the indigenous peoples of New Guinea and the Mamanwa, an indigenous people of the southern Philippines are closely related, having diverged from a common origin approximately 36,000 years ago. The same studies show that Aboriginal genomes consist of up to 11% Indian DNA which is uniformly spread through Northern Australia, indicating a substantial gene flow between Indian populations and Northern Australia occurred around 4,230 years ago. Changes in tool technology and food processing appear in the archaeological record around this time, suggesting there may have been migration from India.\n\nWhen the north-west of Australia, which is closest to Asia, was first occupied, the region consisted of open tropical forests and woodlands. After around 10,000 years of stable climatic conditions, by which time the Aboriginal people had settled the entire continent, temperatures began cooling and winds became stronger, leading to the beginning of an ice age. By the glacial maximum, 25,000 to 15,000 years ago, the sea level had dropped to around 140 metres below its present level. Australia was connected to New Guinea and the Kimberley region of Western Australia was separated from Southeast Asia (\"Wallacea\") by a strait only approximately 90 km wide. Rainfall was 40% to 50% lower than modern levels, depending on region, while the lower CO levels (half pre-industrial levels) meant that vegetation required twice as much water for photosynthesis.\n\nThe Kimberley, including the adjacent exposed continental Sahul Shelf, was covered by vast grasslands dominated by flowering plants of the family Poaceae, with woodlands and semi-arid scrub covering the shelf joining New Guinea to Australia. Southeast of the Kimberley, from the Gulf of Carpentaria to northern Tasmania the land, including the western and southern margins of the now exposed continental shelves, was covered largely by extreme deserts and sand dunes. It is believed that during this period no more than 15% of Australia supported trees of any kind. While some tree cover remained in the southeast of Australia, the vegetation of the wetter coastal areas in this region was semi-arid savannah, while some tropical rainforests survived in isolated coastal areas of Queensland.\n\nTasmania was covered primarily by cold steppe and alpine grasslands, with snow pines at lower altitudes. There is evidence that there may have been a significant reduction in Australian Aboriginal populations during this time, and there would seem to have been scattered \"refugia\" in which the modern vegetation types and Aboriginal populations were able to survive. Corridors between these refugia seem to be routes by which people kept in contact, and they seem to have been the basis for what are now called \"Songlines\" today. With the end of the ice age, strong rains returned, until around 5,500 years ago, when the wet season cycle in the north ended, bringing with it a megadrought that lasted 1,500 years. The return of reliable rains around 4,000 years BP gave Australia its current climate.\n\nFollowing the Ice Age, Aboriginal people around the coast, from Arnhem Land, the Kimberley and the southwest of Western Australia, all tell stories of former territories that were drowned beneath the sea with the rising coastlines after the Ice Age. It was this event that isolated the Tasmanian Aboriginal people on their island, and probably led to the extinction of Aboriginal cultures on the Bass Strait Islands and Kangaroo Island in South Australia. In the interior, the end of the Ice Age may have led to the recolonisation of the desert and semi-desert areas by Aboriginal people of the Northern Territory. This in part may have been responsible for the spread of languages of the Pama–Nyungan language family and secondarily responsible for the spread of male initiation rites involving circumcision. There has been a long history of contact between Papuan peoples of the Western Province, Torres Strait Islanders and the Aboriginal people in Cape York.\n\nThe Aboriginal Australians lived through great climatic changes and adapted successfully to their changing physical environment. There is much ongoing debate about the degree to which they modified the environment. One controversy revolves around the role of indigenous people in the extinction of the marsupial megafauna (also see Australian megafauna). Some argue that natural climate change killed the megafauna. Others claim that, because the megafauna were large and slow, they were easy prey for human hunters. A third possibility is that human modification of the environment, particularly through the use of fire, indirectly led to their extinction. Oral history demonstrates \"the continuity of culture of Indigenous Australians\" for at least 10,000 years. This is shown by correlation of oral history stories with verifiable incidents including known changes in sea levels and their associated large changes in location of ocean shorelines; oral records of megafauna; and comets.\n\nThe introduction of the dingo, possibly as early as 3500 BCE, showed that contact with South East Asian peoples continued, as the closest genetic connection to the dingo seems to be the wild dogs of Thailand. This contact was not just one-way, as the presence of kangaroo ticks on these dogs demonstrates. Dingoes began and evolved in Asia. The earliest known dingo-like fossils are from Ban Chiang in north-east Thailand (dated at 5500 years BP) and from north Vietnam (5000 years BP). According to skull morphology, these fossils occupy a place between Asian wolves (prime candidates were the pale footed (or Indian) wolf \"Canis lupus pallipes\" and the Arabian wolf \"Canis lupus arabs\") and modern dingoes in Australia and Thailand.\n\nMost scientists presently believe that it was the arrival of the Australian Aboriginal people on the continent and their introduction of fire-stick farming that was responsible for these extinctions. Fossil research published in 2017 indicates that Aboriginal people and megafauna coexisted for \"at least 17,000 years\". Aboriginal Australians used fire for a variety of purposes: to encourage the growth of edible plants and fodder for prey; to reduce the risk of catastrophic bushfires; to make travel easier; to eliminate pests; for ceremonial purposes; for warfare and just to \"clean up country.\" There is disagreement, however, about the extent to which this burning led to large-scale changes in vegetation patterns.\n\nAboriginal Australians were limited to the range of foods occurring naturally in their area, but they knew exactly when, where and how to find everything edible. Anthropologists and nutrition experts who have studied the tribal diet in Arnhem Land found it to be well-balanced, with most of the nutrients modern dietitians recommend. But food was not obtained without effort. In some areas both men and women had to spend from half to two-thirds of each day hunting or foraging for food. Each day, the women of the group went into successive parts of one countryside with wooden digging sticks and plaited dilly bags or wooden coolamons. Larger animals and birds, such as kangaroos and emus, were speared or disabled with a thrown club, boomerang, or stone. Many Indigenous hunting devices were used to get within striking distance of prey. The men were excellent trackers and stalkers, approaching their prey running where there was cover, or 'freezing' and crawling when in the open. They were careful to stay downwind and sometimes covered themselves with mud to disguise their smell.\n\nFish were sometimes taken by hand by stirring up the muddy bottom of a pool until they rose to the surface, or by placing the crushed leaves of poisonous plants in the water to stupefy them. Fish spears, nets, wicker or stone traps were also used in different areas. Lines with hooks made from bone, shell, wood or spines were used along the north and east coasts. Dugong, turtle and large fish were harpooned, the harpooner launching himself bodily from the canoe to give added weight to the thrust. The mode of life and material cultures varied greatly from region to region. While Torres Strait Island populations were agriculturalists who supplemented their diet through the acquisition of wild foods, most Aboriginal Australians were hunter-gatherers. Aboriginal Australians along the coast and rivers were also expert fishermen. Some Aboriginal and Torres Strait Islander people relied on the dingo as a companion animal, using it to assist with hunting and for warmth on cold nights.\n\nIn present-day Victoria, for example, there were two separate communities with an economy based on eel-farming in complex and extensive irrigated pond systems; one on the Murray River in the state's north, the other in the south-west near Hamilton in the territory of the Djab Wurrung, which traded with other groups from as far away as the Melbourne area (see Gunditjmara). A primary tool used in hunting is the spear, launched by a woomera or spear-thrower in some locales. Boomerangs were also used by some mainland Indigenous Australians. The non-returnable boomerang (known more correctly as a Throwing Stick), more powerful than the returning kind, could be used to injure or even kill a kangaroo.\n\nOn mainland Australia no animal other than the dingo was domesticated, however domestic pigs were utilised by Torres Strait Islanders. The typical Aboriginal diet included a wide variety of foods, such as pig, kangaroo, emu, wombats, goanna, snakes, birds, many insects such as honey ants, Bogong moths and witchetty grubs. Many varieties of plant foods such as taro, coconuts, nuts, fruits and berries were also eaten.\n\nPermanent villages were the norm for most Torres Strait Island communities. In some areas mainland Aboriginal Australians also lived in semi-permanent villages, most usually in less arid areas where fishing could provide for a more settled existence. Most Indigenous communities were semi-nomadic, moving in a regular cycle over a defined territory, following seasonal food sources and returning to the same places at the same time each year. From the examination of middens, archaeologists have shown that some localities were visited annually by Indigenous communities for thousands of years. In the more arid areas Aboriginal Australians were nomadic, ranging over wide areas in search of scarce food resources. There is evidence of substantial change in indigenous culture over time. Rock painting at several locations in northern Australia has been shown to consist of a sequence of different styles linked to different historical periods. There is also prominent rock paintings found in the Sydney basin area which date to around 5,000 years.\n\nHarry Lourandos has been the leading proponent of the theory that a period of hunter-gatherer intensification occurred between 3000 and 1000 BCE. Intensification involved an increase in human manipulation of the environment (for example, the construction of eel traps in Victoria), population growth, an increase in trade between groups, a more elaborate social structure, and other cultural changes. A shift in stone tool technology, involving the development of smaller and more intricate points and scrapers, occurred around this time. This was probably also associated with the introduction to the mainland of the Australian dingo.\n\nMany Indigenous communities also have a very complex kinship structure and in some places strict rules about marriage. In traditional societies, men are required to marry women of a specific moiety. The system is still alive in many Central Australian communities. To enable men and women to find suitable partners, many groups would come together for annual gatherings (commonly known as corroborees) at which goods were traded, news exchanged, and marriages arranged amid appropriate ceremonies. This practice both reinforced clan relationships and prevented inbreeding in a society based on small semi-nomadic groups.\n\nIn 1770, Lieutenant James Cook claimed the east coast of Australia in the name of the United Kingdom and named it New South Wales. Cook's declaration was made unilaterally and without any consultation with First Australians, in spite of his direct written orders from The Admiralty, which instructed him to conclude a treaty with the inhabitants (if any) and obtain their permission for the expropriation of land. British colonisation of Australia began in Sydney in 1788. The most immediate consequence of British settlement – within weeks of the first colonists' arrival – was a wave of European epidemic diseases such as chickenpox, smallpox, influenza and measles, which spread in advance of the frontier of settlement. The worst-hit communities were the ones with the greatest population densities, where disease could spread more readily. In the arid centre of the continent, where small communities were spread over a vast area, the population decline was less marked. Disease was the principal cause of population decline.\n\nThe second consequence of British settlement was appropriation of land and water resources. The settlers took the view that Aboriginal Australians were nomads with no concept of land ownership, who could be driven off land wanted for farming or grazing and who would be just as happy somewhere else. In fact the loss of traditional lands, food sources and water resources was often fatal, particularly to communities already weakened by disease. Additionally, Aboriginal Australians groups had a deep spiritual and cultural connection to the land, so that in being forced to move away from traditional areas, cultural and spiritual practices necessary to the cohesion and well-being of the group could not be maintained. Proximity to settlers also brought venereal disease, to which Aboriginal Australians had no tolerance and which greatly reduced Aboriginal fertility and birthrates. Settlers also brought alcohol, opium and tobacco, and substance abuse has remained a chronic problem for Aboriginal communities ever since. Entire communities in the moderately fertile southern part of the continent simply vanished without trace, often before European settlers arrived or recorded their existence.\n\nDeadly infectious diseases like smallpox, influenza and tuberculosis were always major causes of Aboriginal deaths. Smallpox alone killed more than 50% of the Aboriginal population. In 1789, a disastrous smallpox epidemic broke out, killing up to 70% of the Indigenous people of the Sydney region. Based on information recorded in the journals of some members of the First Fleet, it has been surmised that the Aborigines of the Sydney region had never encountered the disease before and lacked immunity to it. Unable to understand or counter the sickness, they often fled, leaving the sick with some food and water to fend for themselves. As the clans fled, the epidemic spread further along the coast and into the hinterland. This had a disastrous effect on Aboriginal society; with many of the productive hunters and gatherers dead, those who survived the initial outbreak began to starve.\n\nLieutenant William Bradley recorded the first indications of the severity of the disaster that had struck the Aboriginal population of Sydney when he described his shock at the small number of them to be seen on the harbour and its shores compared with previous times. The British had not seen smallpox in anyone among themselves before the outbreak. Although there were fears about the health of some of the convicts on the First Fleet, these were subsequently dismissed by Surgeon-General John White who believed they were suffering from \"slight inflammatory complaints\". The origin of the smallpox epidemic is controversial, and it has been speculated that the surgeons on board the First Fleet brought vials of smallpox matter and either accidentally or intentionally released it as a \"biological weapon\". In 2014, writing in \"Journal of Australian Studies\", Christopher Warren concluded that British marines were most likely to have spread smallpox, possibly without informing Governor Phillip but conceded in his conclusion that \"today's evidence only provides for a balancing of probabilities and this is all that can be attempted.\"\n\nOn the mainland, prolonged conflict followed the frontier of European settlement. In 1834, John Dunmore Lang wrote: \"There is black blood at this moment on the hands of individuals of good repute in the colony of New South Wales of which all the waters of New Holland would be insufficient to wash out the indelible stains.\" In 1790, an Aboriginal leader Pemulwuy in Sydney resisted the Europeans, waging a guerrilla-style warfare on the settlers in a series of wars known as the Hawkesbury and Nepean Wars, which spanned 26 years, from 1790 to 1816. In 1838, twenty eight Aboriginal people were killed at the Myall Creek massacre; seven of the convict settlers responsible, six white men and one African man, were tried, convicted and hung for the murders. Many Aboriginal communities resisted the settlers, such as the Noongar of south-western Australia, led by Yagan, who was killed in 1833. The Kalkadoon of Queensland also resisted the settlers, and there was a massacre of over 200 people on their land at Battle Mountain in 1884. There was a massacre at Coniston in the Northern Territory in 1928. Poisoning of food and water has been recorded on several different occasions. The number of violent deaths at the hands of white people is still the subject of debate, with a figure of around 10,000 - 20,000 deaths being advanced by historians such as Henry Reynolds. However the methodology behind figures such as this one has been criticised due to the fact that only white deaths were documented in frontier conflicts, forcing historians to estimate a country-wide white-black death ratio in violent confrontations and infer from this the number of Aboriginal deaths. Reynolds, and other historians, estimate that up to 3,000 white people were killed by Aboriginal Australians in the frontier violence. By the 1870s all the fertile areas of Australia had been appropriated, and Aboriginal communities reduced to impoverished remnants living either on the fringes of European communities or on lands considered unsuitable for settlement.\n\nThe Palawa, or Indigenous people of Tasmania, were particularly hard-hit. Nearly all of them, apparently numbering somewhere between 2,000 and 15,000 when white settlement began, were dead by the 1870s. It is widely claimed that this was the result of a genocidal policy, in the form of the \"Black War\". Other historians dispute this. Geoffrey Blainey wrote that, in Tasmania, by 1830: \"Disease had killed most of them but warfare and private violence had also been devastating.\" Josephine Flood wrote: \"The catastrophic death rate was due to new diseases, particularly pulmonary and sexually transmitted ones.\" Historian Keith Windschuttle also disagrees that violence was the principal cause. He argues that there are plausible recorded accounts of approximately 120 Aboriginal Tasmanians killed in 1803–47, that there were an unknown number of unrecorded killings and that many of these were killed in 'self-defence' by settlers. Windschuttle argues some accounts of killings are implausible for a variety of reasons such as incidents involving improbably large death tolls given the muzzle-loading, single-shot muskets in use and that the low number of plausible recorded killings is one indicator of a relatively low level of conflict. Another scholar, H. A. Willis, has subsequently disputed Windschuttle's figures and has documented 188 Palawa killed by settlers in 1803–34 alone, with possibly another 145 killed during the same period. Such counts do not consider undocumented violence and must be regarded as minimum estimates. It is also claimed, but untrue, that the last Aboriginal Tasmanian was Truganini, who died in 1876. This belief stems from a distinction between \"full bloods\" and \"half castes\" that is now generally regarded as racist. Palawa people survived, in missions set up on the islands of Bass Strait.\nNevertheless, some initial contact between Aboriginal people and Europeans was peaceful, starting with the Guugu Yimithirr people who met James Cook near Cooktown in 1770. Bennelong served as interlocutor between the Eora people of Sydney and the British colony, and was the first Aboriginal Australian to travel to England, staying there between 1792 and 1795. Aboriginal people were known to help European explorers, such as John King, who lived with a tribe for two and a half months after the ill-fated Burke and Wills expedition of 1861. Also living with Indigenous people was William Buckley, an escaped convict, who was with the Wautharong people near Melbourne for thirty-two years, before being found in 1835. Many Indigenous people adapted to European culture, working as stock hands or labourers. The first Australian cricket team, which toured England in 1868, was principally made up of Indigenous players.\n\nAs the European pastoral industries developed, several economic changes came about. The appropriation of prime land and the spread of European livestock over vast areas made a traditional Indigenous lifestyle less viable, but also provided a ready alternative supply of fresh meat for those prepared to incur the settlers' anger by hunting livestock. The impact of disease and the settlers' industries had a profound impact on the Indigenous Australians' way of life. With the exception of a few in the remote interior, all surviving Indigenous communities gradually became dependent on the settler population for their livelihood.\n\nIn south-eastern Australia, during the 1850s, large numbers of white pastoral workers deserted employment on stations for the Australian goldrushes. Indigenous women, men and children became a significant source of labour. Most Indigenous labour was unpaid, instead Indigenous workers received rations in the form of food, clothing and other basic necessities. In the later 19th century, settlers made their way north and into the interior, appropriating small but vital parts of the land for their own exclusive use (waterholes and soaks in particular), and introducing sheep, rabbits and cattle, all three of which ate out previously fertile areas and degraded the ability of the land to carry the native animals that were vital to Indigenous economies. Indigenous hunters would often spear sheep and cattle, incurring the wrath of graziers, after they replaced the native animals as a food source. As large sheep and cattle stations came to dominate northern Australia, Indigenous workers were quickly recruited. Several other outback industries, notably pearling, also employed Aboriginal workers.\n\nIn many areas Christian missions provided food and clothing for Indigenous communities and also opened schools and orphanages for Indigenous children. In some places colonial governments provided some resources.\n\nIn spite of the impact of disease, violence and the spread of foreign settlement and custom, some Indigenous communities in remote desert and tropical rainforest areas survived according to traditional means until well into the 20th century. In 1914 around 800 Aboriginal people answered the call to arms, despite restrictions on Indigenous Australians serving in the military. As the war continued, these restrictions were relaxed as more recruits were needed. Many enlisted by claiming they were Māori or Indian.\n\nBy the 1920s, the Indigenous population had declined to between 50,000 and 90,000, and the belief that the Indigenous Australians would soon die out was widely held, even among Australians sympathetic to their situation. But by about 1930, those Indigenous Australians who had survived had acquired better resistance to imported diseases, and birthrates began to rise again as communities were able to adapt to changed circumstances. From the 1940s, the availability of penicillin to treat imported diseases also had a marked effect on reversing the population decline.\n\nIn the Northern Territory, significant frontier conflict continued. Both isolated Europeans and visiting Asian fishermen were killed by hunter gatherers until the start of World War II in 1939. It is known that some European settlers in the centre and north of the country shot Indigenous people during this period. One particular series of killings became known as the Caledon Bay crisis, and became a watershed in the relationship between Indigenous and non-Indigenous Australians.\n\nIn the early 20th century, anthropologists' influence dominated society's view of aboriginals in Australia. They were viewed as a different race that was not as evolved as Europeans. Starting in the 1880 and continuing into the 20th century, debate continued on where between ape and man could the aboriginal be situated in evolutionary terms. In the mid-1920s, there was a shift in focus away from physical anthropological issues of race and towards a cultural anthropological concerns established by field-work. New studies described aboriginals' social organisation, religious belief and practice. Alfred Radcliffe-Brown, the father of modern social anthropology, published his \"Social Organization of Australian Tribes\" in 1931.\n\nBy the end of World War II, many Indigenous men had served in the military and were paid an equitable salary. However, Aboriginal workers remained unfree labourers, paid only small amounts of cash in addition to rations, and had their movements severely restricted by regulations and/or police action. On 4 February 1939, Jack Patten led a strike at Cummeragunja Mission in New South Wales. The people of Cummeragunja were protesting their harsh treatment under what was a draconian system. A once successful farming enterprise was taken from their control, and residents were forced to subsist on meager rations. Approximately 200 people left their homes, taking part in the Cummeragunja walk-off, and the majority crossed the border into Victoria, never to return home.\n\nOn 1 May 1946, Aboriginal station workers in the Pilbara region of Western Australia started the 1946 Pilbara strike and never returned to work. Mass layoffs across northern Australia followed the Federal Pastoral Industry Award of 1968, which required the payment of a minimum wage to Aboriginal station workers, as they were not paid by the Pastoralist discretion, many however were not and those who were had their money held by the government. Many of the workers and their families became refugees or fringe dwellers, living in camps on the outskirts of towns and cities.\n\nIn 1949, the right to vote in federal elections was extended to Indigenous Australians who had served in the armed forces, or were enrolled to vote in state elections. At that time, those Indigenous Australians who lived in Queensland, Western Australia and the Northern Territory were still ineligible to vote in state elections, consequently they did not have the right to vote in federal elections.\n\nAll Indigenous Australians were given the right to vote in Commonwealth elections in Australia by the Menzies government in 1962. The first federal election in which all Aboriginal Australians could vote was held in November 1963. The right to vote in state elections was granted in Western Australia in 1962 and Queensland was the last state to do so in 1965.\n\nThe 1967 referendum, passed with a 90% majority, allowed Indigenous Australians to be included in the Commonwealth parliament's power to make special laws for specific races, and to be included in counts to determine electoral representation. This has been the largest affirmative vote in the history of Australia's referendums.\n\nIn 1971, Yolngu people at Yirrkala sought an injunction against Nabalco to cease mining on their traditional land. In the resulting historic and controversial Gove land rights case, Justice Blackburn ruled that Australia had been terra nullius before European settlement, and that no concept of Native title existed in Australian law. Although the Yolngu people were defeated in this action, the effect was to highlight the absurdity of the law, which led first to the Woodward Commission, and then to the Aboriginal Land Rights Act.\n\nIn 1972, the Aboriginal Tent Embassy was established on the steps of Parliament House in Canberra, in response to the sentiment among Indigenous Australians that they were \"strangers in their own country\". A Tent Embassy still exists on the same site.\n\nIn 1975, the Whitlam government drafted the Aboriginal Land Rights Act, which aimed to restore traditional lands to Indigenous people. After the dismissal of the Whitlam government by the Governor-General, a reduced-scope version of the Act (known as the Aboriginal Land Rights Act 1976) was introduced by the coalition government led by Malcolm Fraser. While its application was limited to the Northern Territory, it did grant \"inalienable\" freehold title to some traditional lands.\n\nIn 1984, a group of Pintupi people who were living a traditional hunter-gatherer desert-dwelling life were tracked down in the Gibson Desert in Western Australia and brought into a settlement. They are believed to have been the last uncontacted tribe in Australia.\n\nA 1987 federal government report described the history of the \"Aboriginal Homelands Movement\" or \"Return to Country movement\" as \"a concerted attempt by Aboriginal people in the 'remote' areas of Australia to leave government settlements, reserves, missions and non-Aboriginal townships and to re-occupy their traditional country.\"\n\nIn 1992, the Australian High Court handed down its decision in the Mabo Case, declaring the previous legal concept of \"terra nullius\" to be invalid. This decision legally recognised certain land claims of Indigenous Australians in Australia prior to British Settlement. Legislation was subsequently enacted and later amended to recognise Native Title claims over land in Australia.\n\nIn 1998, as the result of an inquiry into the forced removal of Indigenous children (see Stolen generation) from their families, a National Sorry Day was instituted, to acknowledge the wrong that had been done to Indigenous families. Many politicians, from both sides of the house, participated, with the notable exception of the Prime Minister, John Howard.\n\nIn 1999 a referendum was held to change the Australian Constitution to include a preamble that, amongst other topics, recognised the occupation of Australia by Indigenous Australians prior to British Settlement. This referendum was defeated, though the recognition of Indigenous Australians in the preamble was not a major issue in the referendum discussion, and the preamble question attracted minor attention compared to the question of becoming a republic.\n\nIn 2004, the Australian Government abolished The Aboriginal and Torres Strait Islander Commission (ATSIC), which had been Australia's top Indigenous organisation. The Commonwealth cited corruption and, in particular, made allegations concerning the misuse of public funds by ATSIC's chairman, Geoff Clark, as the principal reason. Indigenous specific programmes have been mainstreamed, that is, reintegrated and transferred to departments and agencies serving the general population. The Office of Indigenous Policy Coordination was established within the then Department of Immigration and Multicultural and Indigenous Affairs, and now with the Department of Families, Community Services and Indigenous Affairs to coordinate a \"whole of government\" effort.\n\nIn June 2005, Richard Frankland, founder of the 'Your Voice' political party, in an open letter to Prime Minister John Howard, advocated that the eighteenth-century conflicts between Aboriginal and colonial Australians \"be recognised as wars and be given the same attention as the other wars receive within the Australian War Memorial\". In its editorial on 20 June 2005, Melbourne newspaper, The Age, said that \"Frankland has raised an important question,\" and asked whether moving \"work commemorating Aborigines who lost their lives defending their land ... to the War Memorial [would] change the way we regard Aboriginal history.\"\n\nIn 2008, Prime Minister Kevin Rudd made a formal apology for the Stolen Generations.\n\n\n\n"}
{"id": "4170165", "url": "https://en.wikipedia.org/wiki?curid=4170165", "title": "History of mentalities", "text": "History of mentalities\n\nThe history of mentalities is a calque of the French term \"histoire des mentalités\", which might also be translated as \"history of attitudes\", \"mindsets\" or \"world-views\". The term describes a particular manner of researching history. This approach is associated with the \"critical turn\" (\"tournant critique\") taken by the historians of the \"Annales\" School, particularly around the 1960s.\n\nIn keeping with the \"Annales\"' interest in the \"longue durée\" (long-term), the history of mentalities focuses on the mindsets of past cultural and social groups, and their gradual changes over time, as opposed to the history of particular events, or economic trends. The term can also be seen as an equivalent to, or a form of, cultural history or historical anthropology\n\nThe history of mentalities, or \"histoire des mentalités\", is a term used to describe works of history aimed at describing and analyzing the ways in which people of a given time period thought about, interacted with, and classified the world around them. The history of mentalities has been used as a historical tool by several historians and scholars from various schools of history. Notably, the historians of the \"Annales\" School helped to develop the history of mentalities and construct a methodology from which to operate. In establishing this methodology, they sought to limit their analysis to a particular place and a particular time. This approach lends itself to the intensive study that characterizes microhistory, another field which adopted the history of mentalities as a tool of historical analysis.\n\nThe origin of the term history of mentalities lies in the writings of the \"Annales\" historians such as Georges Duby and Roger Chartier. In seeking to create works of total history, \"Annales\" historians tended not to simply rely on the political or event oriented history of past generations. Michael Harsgor points out in that the challenge of the \"Annales\" historians was not to create this deterministic history that appeared to rely heavily on teleological conclusions, such as the Marxist forms of history being written at the time. Rather, Harsgor writes that the \"Annales\" historians tasked themselves with the creation of social structures, \"which means covering the skeleton of the basic economic analysis with the flesh of demographic, cultural, mental, and event psychoanalytical data.\" It has also been said that \"Annales\" historians, in their attempts at the creation of total history, considered the history of mentalities a single aspect in the creation of that history. Simply put, they were attempting to reconstruct the world of whatever time period they were examining. In his works, such as \"The Three Orders: Feudal Society Imagined\" and his work on William Marshal, Duby focused on the development of ideologies within the structures that permeated the various aspects of an individual's life.\n\nThis development in methodology would prove crucial for other historians who would use the history of mentalities to attempt to reconstruct the worldviews of individuals and extrapolate their findings to the population at large in the form of microhistories. These historians would largely concern themselves with social and cultural history in order to form their history of mentalities, narrowing their realm historical inquiry by not concerning themselves with the broad economic serialization that had become so important for the \"Annales\" historians. Carlo Ginzburg's book, \"The Cheese and the Worms\", is archetypical of the microhistories that emerged with the history of mentalities in mind. Ginzburg attempted to reconstruct peasant mentalities in sixteenth century Italy by examining the trial records of a single miller, Domenico Scandella, called Menocchio, and trying to find currents or similarities in otherwise fragmentary and obscure evidence.\n\nSimilar techniques can be seen in Robert Darnton's \"The Great Cat Massacre\", which uses microhistory to establish the mentalities of groups at different social levels of French society. Darnton concerns himself greatly with the ways in which people viewed the world around them. He interprets the symbolic significance of journeymen printers massacring neighborhood cats as a display of frustration with the growing bourgeoisie class. Similarly, and in keeping with the tradition of the history of mentalities, Darnton devotes a chapter to an analysis of a bourgeoisie's description of his city, in an effort to determine how an individual in a given social situation would interpret and make sense of the world around them. Darnton uses this description to demonstrate that the ways in which events might be portrayed might be completely unsupported by the ways in which individuals of the time might have interpreted those events.\n\nCriticisms have emerged regarding the history of mentalities at all stages of its development. In particular, Marxist historians were quick to criticize the \"Annales\" historians for \"attempts to include the study of mentalities in a general synthesis, which can only lead to the publication of articles reflecting a basic reliance upon faith accompanied by a consequent disparagement of reason.\" Carlo Ginzburg himself has criticized the methods of the history of mentalities for its \"decidedly classless character.\"\n\n\n"}
{"id": "55850415", "url": "https://en.wikipedia.org/wiki?curid=55850415", "title": "Indigo Era", "text": "Indigo Era\n\nThe Indigo Era, or \"Indigo economies\", is a concept first publicized in early 2016 by international businessman Mikhail Fridman, the co-founder of LetterOne, an international investment business. He used the term to describe what he views as an emerging new era of economies and economics based on ideas, innovation, and creativity, which he sees as replacing economies which are based on the possession of natural resources. The word \"indigo\" was initially chosen based on the term indigo children, which has been used to describe people with unusual and innovative abilities.\n\nHe describes the Indigo Era as a disruptive era driven by extraordinary levels of human creativity, where abnormally talented individuals and entities are able to realize new levels of human potential and economic achievement. It is \"a new economic era where the main source of national wealth is no longer resource rent but the socio-economic infrastructure that allows every person to realise his or her intellectual or creative potential.\" But, according to Fridman – based on his observations of recent economic indicators, political and market volatility, and historical patterns – it is also an era that will generate winners and losers as lagging countries and groups fail to adapt quickly enough.\n\nIn late 2016 LetterOne's \"Global Perspectives\" journal published an Indigo Index, ranking 152 countries on their ability to compete and grow as economies move away from being powered by natural resources to being powered by ideas, creativity, and digital skills. In 2017 it launched the Indigo Prize, to award new concepts of economic measurement beyond mere GDP as countries in the 21st century transition into economies where innovation, creativity, and digital skills are economic drivers. The competition is intended to \"stimulate debate about factors currently measured, given evolving economies, technology and skill bases, and what should now be taken into consideration in official economic statistics that measure the health, size and growth of a modern economy.\"\n\nThe economic term \"Indigo Era\" was publicized in early 2016 by Mikhail Fridman, the co-founder of the international investment business LetterOne. He used the term to describe the new economic era based on ideas, innovation, and creativity – which he theorizes is replacing the previous era which he sees as defined by the struggle for natural resources and land that contains them, and which is measured by GDP. The word \"indigo\" was adopted from the term indigo children, which has been used to describe people with unusual and innovative abilities. LetterOne's \"Global Perspectives\" website adds that the indigo symbolism \"embodies a breaking of the norm, something that is highly reflective of the new era that we are entering into, one that lacks convention and is driven by innovation.\"\n\nIn an April 2016 article in \"RealClearPolitics\", retitled and reprinted in May 2016 in the \"Jerusalem Post\", and reprinted in November 2016 under the original title in LetterOne's \"Global Perspectives\" journal, Fridman wrote:\n\nIn a series of articles published in 2016, Fridman cites the recent extreme volatility in markets, and worldwide political change and instability, as signs of an emerging global shift. He notes two frequently cited prominent indicators of an economic shift: the sharp decline in prices of natural resources including oil, and the slowing of China's economic growth despite this decline in the cost of natural resources.\n\nHe and other commentators also note the rise of populism and populist leaders and candidates, both right-wing and left-wing, as these changes occur. Meanwhile, companies like Apple and Google – digital and technological companies he calls \"Indigo companies\" – have replaced longterm traditional natural-resource or manufacturing companies such as Exxon as the world's largest companies.\n\nFridman observes that throughout history innovations, alternatives, and technologies have always overcome any perceived shortages of any natural resource. He therefore posits that the new \"Indigo era\", fueled by digital and technological resources, will be marked by a shift away from the struggle for natural resources and their perceived scarcity, to a reliance on ideas, innovation, and creativity and on supporting the intellectual and creative potential of each human being: \"The world has entered a new era where the source of a nation's wealth is no longer natural resources. Intellectual capacity has now replaced land, raw materials and trade routes as the biggest source of wealth.\"\n\nAccording to Fridman, three interconnected factors are needed for successful Indigo companies and an Indigo economy:\n\nHe notes that most emerging economies have focused on building physical structures (roads, buildings, cities, physical infrastructure) rather than the complex legal, political, and social systems, institutions, and changes that will support an effective free and innovative intellectual-resource economy. The freedoms, protections, and political and legal frameworks of developed Western countries rest on centuries-long histories, socio-political traditions, and mindsets, and therefore will be difficult to replicate quickly in emerging economies. Fridman singles out India as an emerging country that has adequate legal infrastructure and freedom to probably survive the Indigo shift.\n\nFridman considers the growth of Indigo economies to be a paradigm shift; he states that the pace at which technology is developing is creating worldwide tectonic shifts, and predicts huge global change over the next five to ten years. He and other analysts predict that the growing economic gap between free, creative economies and groups in contrast to repressive, authoritarian, totalitarian, or tradition-bound economies or groups will widen and create resentment and hostilities – whether this is between nations or within nations. Those left behind may be either emerging countries, or the average person – as opposed to the intellectual elites – within developed Western countries.\n\nAuthoritarian leaders and authoritarianism often rise during periods of uncertainty and insecurity and economic deprivation. Fridman maintains however that in this ever-changing new economic era, the main source of wealth in a country or region will no longer be a natural resource, but a social infrastructure that will allow everyone to realise their intellectual and creative potential. Therefore, he asserts that \"The future Indigo economy is an economy of free people. And this means that the world will become more and more free.\"\n\nIn November 2016 LetterOne launched a journal, \"Global Perspectives\", as a platform to explore \"the new emerging economic era, the Indigo era, from different perspectives, including education, religion, politics, economics, history and business\" and to examine \"global issues through the eyes of leading commentators and business people around the world\". The inaugural issue contained articles by Fridman, Dominic Barton, Michael Bloomberg, Stan Greenberg, Carl Bildt, Vince Cable, Ken Robinson, Brent Hoberman, Alex Klein, Deirdre McCloskey, Yuri Milner, Nick D'Aloisio, Lynda Gratton, Parag Khanna, Ian Goldin, George Freeman, Ian Bremmer, and others.\n\nThe November 2016 inaugural issue of \"Global Perspectives\" also published an Indigo Index, which rated 152 countries based on five key metrics for doing business as economies move away from being powered by natural resources to being powered by creativity and digital skills. The five metrics are: creativity and innovation, economic diversity, digital economy, freedom, and stability and legal frameworks, which were scored based on over 30 measures from published data sources such as the World Bank, UNESCO, the CIRI Human Rights Data Project, the Center for International Development at Harvard University, and the Global Education Monitoring Report. The index sought to measure a country's entrepreneurial ecosystem, and therefore its potential to adapt and develop.\n\nEach country was given a combined overall Indigo Score, with 200 being the highest possible score. The 10 top-ranked countries were Sweden, Switzerland, Finland, Denmark, the UK, the Netherlands, Norway, Germany, Ireland, and Japan. The United States was 18th overall.\n\nThe report also included three key findings: Creativity and innovation was the biggest overall driver of high scores; this accentuated the importance of fostering entrepreneurialism and lifelong learning and of investing heavily in people. Nordic countries scored particularly high on the Indigo Index, with three Nordic countries in the top four and four Nordic countries in the top ten; this was attributed to their high rankings both in creativity and innovation and in freedom. And the lowest-scoring countries were beset with social and political problems, such as war, political turmoil, and corruption.\n\nIn July 2017, LetterOne's \"Global Perspectives\" journal announced the Indigo Prize, to stimulate discussion towards finding a new way of measuring the economy in the 21st century that moves beyond the limitations of mere GDP measurements.\n\nEntrants were asked to submit an essay of up to 5,000 words answering the question:\n\nEntries were due 15 September 2017, and were open worldwide to groups or individuals over the age of 16, with entries particularly encouraged from people at academic institutions, businesses, charities, think tanks, consultancies, or other organisations. The award amount was announced as £100,000, with second- and third-place winners to receive £25,000 and £10,000.\n\nThe judging panel included:\n\nThe winners of the inaugural Indigo Prize were announced on 25 October 2017. A joint first prize, £125,000 to be equally split, was awarded to two teams of writers: Diane Coyle and Benjamin Mitra-Kahn; and Jonathan Haskel, Carol Corrado, \"et al.\" A third place \"Rising star\" award of £10,000 was given to Alice Lassman.\n\nCoyle is professor of economics at the University of Manchester, and Mitra-Kahn is chief economist at IP Australia. They proposed radically replacing GDP with a dashboard measuring six key assets: physical assets, natural capital, human capital, intellectual property, social and institutional capital, and net financial capital. Their essay stated that \"GDP never pretended to be a measure of economic welfare\", and proposed that the new measure should assess \"the range of assets needed to maximise individuals' capabilities to lead the life they would like to lead\"; this would include \"financial and physical capital but also natural and intangible capital\". They asserted that the new statistics should focus on measuring changes in the stock of important assets, rather than flows of income, expenditure, and output. Tracking the evolution of stocks of physical assets, financial assets and liabilities, natural capital, skill levels, and implicit state liabilities would better measure the sustainability of the economy. Coyle and Mitra-Kahn also proposed interim improvements to GDP measurements – such as better measurement of intangibles, adjusting for the distribution of income, and removing unproductive financial activity – before scrapping it entirely.\n\nHaskel is professor of economics at Imperial College Business School. Rather than abandoning GDP, he proposed refining, updating, and extending the existing GDP measure. He proposed better measurement of services and intangibles, and direct measurement of the economic welfare being created by digital goods. His essay focused on the fact that economies have dramatically changed structure since GDP was originally developed, with more knowledge production, more digital goods, more free things and free information, and more intangible assets such as intellectual property. He also emphasized the importance of factoring in the environment, sustainability, and societal welfare, in addition to calculating the value of goods and services that are provided for free.\n\nLassman, the recipient of the \"Rising star\" award, was a 19-year-old geography student at Durham University. Her entry proposed a \"Global Integration and Individual Potential\" index, which measures each nation on two levels: its value relative to other nations, and the individuals and their contributions within each nation.\n\n"}
{"id": "33393921", "url": "https://en.wikipedia.org/wiki?curid=33393921", "title": "International Society for the Study of Medievalism", "text": "International Society for the Study of Medievalism\n\nThe International Society for the Study of Medievalism is an academic organization that exists to promote the interdisciplinary study of the popular and scholarly reception of the Middle Ages in postmedieval times. The society is based on the work and studies of Leslie J. Workman (1927–2001), who is recognized as the founder of the academic study of medievalism in the English-speaking world. The work of the society is characterized as open to innovative and inclusive interdisciplinary scholarship. As Elena Levy-Navarro writes: \"The Society has not restricted itself to a single definition of medievalism, and has, both by its calls for papers and by its acceptance and inclusion, encouraged academics to explore medievalism in such disparate phenomenon as the 'Celtic' tattoo, medieval gaming, and the early modern. Such an expansiveness that resists firm boundaries, and thus resists any efforts to develop a concrete field of specialty over which the academic can preside as expert is evident to the continued commitment of its members to electronic media that can provide (for those who can afford it) open access to its collective work, including its journal, \"Year’s Work in Medievalism\", and its community-authored blog, \"Medievally Speaking\". One need only consider the subtitle of this blog—'An Open Access Review Journal Encouraging Critical Engagement with the Continuing Process of Inventing the Middle Ages' (emphasis mine)—to see that the members insist on an openness, in which they critically engage—but not adjudicate—the 'continuing process of inventing the Middle Ages.'\" In 2017, the ISSM's president, Richard Utz, published a short monograph, \"Medievalism: A Manifesto\", that embedded the subject of medievalism studies within the larger academic contexts of reception studies, feminism, gender studies, and medieval studies.\n\nThe society maintains a peer-reviewed journal, \"Studies in Medievalism\", an online journal for shorter articles (\"The Year's Work in Medievalism\"), and a review journal, \"Medievally Speaking\" edited by Richard Utz. They also organize annual conference sessions at the International Congress on Medieval Studies at Western Michigan University and the International Medieval Congress at the University of Leeds, and hold their own Annual International Conferences on Medievalism at institutions of higher education worldwide.\n\n\"Studies in Medievalism\" is an annual publication that, as noted on its title page, \"provides an interdisciplinary medium of exchange for scholars in all fields, including the visual and other arts, concerned with any aspect of the post-medieval idea and study of the Middle Ages and its influence, both scholarly and popular, of this study on Western society after 1500.\"\n\nThe series was founded in 1979 by Leslie J. Workman as an independent publication. It is now published by Boydell & Brewer, Ltd., and has been edited since 2006 by Karl Fugelso. Since 2009, each volume has begun with a series of 3,000-word, commissioned essays on such topics as \"Defining Medievalism(s),\" \"Defining Neomedievalism(s),\" and \"Medievalism and the Corporation.\" But the series is otherwise open to any paper that addresses medievalism in at least 6,000 words, and recent topics have ranged from representations of King Alfred in Charles Dickens' \"A Child's History of England\" to medievalist music in Peter Jackson's \"The Lord of the Rings\" films.\n\n\"Studies in Medievalism\" does not publish reviews. All reviews of works, performances, etc., re-imagining the Middle Ages in postmedieval times are published in the journal's online review \"arm,\" \"Medievally Speaking\".\n\nThe journal \"The Year's Work in Medievalism\" is currently edited by Edward L. Risden (St. Norbert College) and Richard Utz (Georgia Tech). Former editors include Leslie J. Workman and Gwendolyn Morgan (Montana State University).\n"}
{"id": "15503838", "url": "https://en.wikipedia.org/wiki?curid=15503838", "title": "Landscape zodiac", "text": "Landscape zodiac\n\nA landscape zodiac (or terrestrial zodiac) is a map of the stars on a gigantic scale, formed by features in the landscape, such as roads, streams and field boundaries. Perhaps the best known alleged example is the Glastonbury Temple of the Stars, situated around Glastonbury in Somerset, England. The temple is thought by some to depict a colossal zodiac.\n\nThe theory was first put forward in 1935 by Katherine Maltwood, an artist who \"discovered\" the zodiac in a vision, and held that the \"temple\" was created by Sumerians about 2700 BC. Interest was re-ignited in 1969 by Mary Caine in an article in the magazine \"Gandalf's Garden\".\n\nThe landscape zodiac plays an important role in many occult theories. It has been associated with the Celtic Saints, Grail legend and King Arthur (according to some legends buried in Glastonbury).\n\nThe idea was examined by two independent studies, one by Ian Burrow in 1975 and the other in 1983 by Tom Williamson and Liz Bellamy, using the standard methods of landscape historical research. Both studies concluded that the evidence contradicted the idea. The eye of Capricorn identified by Maltwood was a haystack. The western wing of the Aquarius phoenix was a road laid in 1782 to run around Glastonbury, and older maps dating back to the 1620s show the road had no predecessors. The Cancer boat (not a crab as would be expected) is made up of a network of eighteenth century drainage ditches and paths. There are some Neolithic paths preserved in the peat of the bog formerly comprising most of the area, but none of the known paths match the lines of the zodiac features. There is no support for this theory, or for the existence of the \"temple\" in any form, from conventional archaeologists or mainstream historians.\n\nBeside the Glastonbury arrangement further zodiacs have been alleged in Britain in following years including:\n\n\nThere is rarely a strong scientific case for these discoveries. Their nebulous existence is in many ways similar to urban myths, ufology, or ley lines. They seem to play a part in personal belief systems, possibly as fictional devices; for example \"The Brighton Zodiac\" - created by Sally Hurst, based on the streets of that town - features as a plot device in Robert Rankin's novel \"The Brightonomicon\". Mark Valentine has compiled a checklist of 'The Literature of Terrestrial Zodiacs in Britain' in 'The Network of Ley Hunters' Newsletter'().\n\nIn the walks around the M25 motorway documented in psychogeographer Iain Sinclair's 2003 novel \"London Orbital\", the walkers trace the mythical Kingston upon Thames Zodiac.\n\n\n"}
{"id": "39003363", "url": "https://en.wikipedia.org/wiki?curid=39003363", "title": "Library theft", "text": "Library theft\n\nTheft from libraries is the crime of stealing books, DVDs or other media from libraries. It is typically prevented by installing electronic article surveillance alarms at the doors. Library materials are tagged and if the tag is not deactivated it sounds an alarm. In some libraries with older or rare materials, readers are not allowed to take coats or bags into the reading area except for a few items in a clear plastic bag. Security cameras are not commonly used in libraries for privacy reasons.\n\nOne study commissioned in the UK estimated the average loss rate of libraries to theft at 5.3%.\n\nIn the U.S. state of Pennsylvania, the third conviction for library theft is a felony, regardless of the value of material.\n\nLibrary thieves, who may be staff or regular visitors of the library, risk being discovered if a book is found in the library catalog but missing from the shelves. To avoid this, some library thieves have been careful to also steal the catalog card describing the book.\n\nIn public libraries, librarians have noticed common themes in what subjects are most frequently stolen. Books with topics like sex and witchcraft are popular with thieves, as are guides for General Educational Development testing.\n\nIn a poll taken in 1996, the top three books that went missing were: \"The Joy of Sex\", GED Examination Books, and the \"Prophecies\" of Nostradamus.\n\nRare books departments of libraries especially fall target to professional thieves. In 1996, two rare early Mormon manuscripts were stolen from the Public Library of Cincinnati and Hamilton County, when the thief requested the manuscript and replaced it with a facsimile.\n\nDocument theft is the crime of stealing documents of historical, literary, or cultural interest from public or private archives, often for the purpose of sale to private collectors. In many cases, document thieves occupy positions of trust, or have established records of legitimate accomplishment, prior to their crimes. Examples of notable convicted document thieves include former New York State archivist Daniel D. Lorello, Frede Møller-Kristensen, who between 1968 and 1978 stole some 1,600 historical books worth more than $50 million from the Danish National Library, and antiquities dealer E. Forbes Smiley III, who stole nearly 100 maps from libraries in the United States and Great Britain over the course of eight years. In addition to letters, maps, and other manuscript material, rare books also attract the attention of document thieves. John Charles Gilkey, for instance, stole hundreds of thousands of dollars' worth of rare books over the course of many years. These crimes were largely the product of a personal obsession, illustrating the range of motives in document thefts.\n\n"}
{"id": "3201673", "url": "https://en.wikipedia.org/wiki?curid=3201673", "title": "List of North American settlements by year of foundation", "text": "List of North American settlements by year of foundation\n\nThis is a list of settlements in North America by founding year and present-day country.\n\n\n"}
{"id": "13316", "url": "https://en.wikipedia.org/wiki?curid=13316", "title": "List of historical anniversaries", "text": "List of historical anniversaries\n\nCondensed list of historical anniversaries.\n\n"}
{"id": "4825806", "url": "https://en.wikipedia.org/wiki?curid=4825806", "title": "Lists of book-based war films", "text": "Lists of book-based war films\n\nThe list of films based around war books is divided into the following:\n\n"}
{"id": "146649", "url": "https://en.wikipedia.org/wiki?curid=146649", "title": "Living history", "text": "Living history\n\nLiving history is an activity that incorporates historical tools, activities and dress into an interactive presentation that seeks to give observers and participants a sense of stepping back in time. Although it does not necessarily seek to reenact a specific event in history, living history is similar to, and sometimes incorporates, historical reenactment. Living history is an educational medium used by living history museums, historic sites, heritage interpreters, schools and historical reenactment groups to educate the public or their own members in particular areas of history, such as clothing styles, pastimes and handicrafts, or to simply convey a sense of the everyday life of a certain period in history.\n\nLiving history approach to gain authenticity is less about replaying a certain event according to a planned script as in other reenactment fields. It is more about an immersion of players in a certain era, to catch, in the sense of Walter Benjamin the 'spiritual message expressed in every monument's and every site's own \"trace\" and \"aura\"', even in the Age of Mechanical Reproduction.\n\nAn early example of the spiritual and futuristic side of living history can be found in Guido von List's book \"Der Wiederaufbau von Carnuntum\" (1900), which suggested rebuilding the Roman Carnuntum military camp in Vienna's neighborhood as a sort of amusement park (compare \"Westworld\"). List, himself a right wing neopagan, asked his staff of landlords, waiters and rangers to be dressed in historical gear. He also asked to have any visitors redressed in costumes and described rituals to signify \"in-game\" and \"out-game\" status to enhance the immersion experience. E.g. the role of the garment is of interest till today.\n\nThe term 'living history' describes the performance of bringing history to life for the general public in a rather freewheeling manner. The players are less confined in their actions, but often have to stay at a certain place or building. Historical presentation includes a continuum from well researched attempts to recreate a known historical event for educational purposes, through representations with theatrical elements, to competitive events for purposes of entertainment. The line between amateur and professional presentations at living history museums can be blurred, same as the border to Live action role-playing games.\n\nWhile the pros latter routinely use museum professionals and trained interpreters to help convey the story of history to the public, some museums and historic sites employ living history groups with high standards of authenticity for the same role at special events. Such events do not necessarily include a mock battle but aim at portraying the life, and more importantly the lifestyle, of people of the period. This often includes both military and civilian impressions. Occasionally, storytelling or acting sketches take place to involve or explain the everyday life or military activity to the viewing public. More common are craft and cooking demonstrations, song and leisure activities, and lectures. Combat training or duels can also be encountered even when larger combat demonstrations are not present.\n\nIn the United States, on the National Park Service land, NPS policy \"does not allow for battle reenactments (simulated combat with opposing lines and casualties) on NPS property.\" There are exceptions i.e. Saylors Creek, Gettysburg. These are highly controlled with exacting safety factors, as well as, exacting historical truths.\n\nIn Germany medieval reenactment is usually associated with living history and renaissance faires and festivals, which are found in nearly each city. So e.g. the Peter and Paul festival in Bretten. the Landshut Wedding or the Schloss Kaltenberg knights tournament. The majority of combat reenactment groups are battlefield reenactment groups, some of which have become isolated to some degree because of a strong focus on authenticity.\n\nEvents with the professional reenactment-group Ulfhednar lead to a controversy in German archaeology. The German Polish living history group was supported by large museums and scholars and, since 2000 has largely coined the image of early history in Germany and international. Among others, a paper with the programmatic title \"Under the crocheted Swastika, Germanic Living History and rightwing affects\" started the dispute 2009. On the other hand, communist Eastern German had some problems with accepting \"indianistic\" living history reenactors, a widespread variety in Eastern Germany, which were closely monitored by the security forces.\nThat sort of 'second hand' living history is as well part of western Germany folklore and tries for a high level of authenticity.\n\nActivities may be confined to wearing period dress and perhaps explaining relevant historical information, either in role (also called first-person interpretation) or out of character (also called third-person interpretation). While many museums allow their staff to move in and out of character to better answer visitor questions, some encourage their staff to stay in role at all times.\n\nLiving history portrayal often involves demonstrating everyday activities such as cooking, cleaning, medical care, or particular skills and handicrafts. Depending on the historical period portrayed, these might include spinning, sewing, loom weaving, tablet weaving, inkle weaving or tapestry weaving, cloth dyeing, basket weaving, rope making, leather-working, shoemaking, metalworking, glassblowing, woodworking or other crafts. Considerable research is often applied to identifying authentic techniques and often recreating replica tools and equipment.\n\nHistorical reenactment groups often attempt to organize such displays in an encampment or display area at an event, and have a separate area for combat reenactment activities. While some such exhibits may be conducted in character as a representation of typical everyday life, others are specifically organized to inform the public and so might include an emphasis on handicrafts or other day-to-day activities, which are convenient to stage and interesting to watch, and may be explained out of character. During the 1990s, reenactment groups, primarily American Civil War groups, began to show interest in this style of interpretation and began using it at their reenactments.\n\nAs David Thelen has written, many Americans use the past in their daily lives, while simultaneously viewing the place where they often encounter history – the school – with varying levels of distrust and disconnectedness. Living history can be a tool used to bridge the gap between school and daily life to educate people on historical topics. Living history is not solely an objective retelling of historical facts. Its importance lies more in presenting visitors with a sense of a way of life, than in recreating exact events, accurate in every detail.\n\nMany factors contribute to creating a setting in which visitors to living history sites can become active participants in their historical education. Two of the most important are the material culture and the interpreters. Material culture both grounds the audience in the time and place being portrayed, and provides a jumping-off point for conversation. “Interpreters” are the individuals who embody historical figures at living history sites. It is their responsibility to take the historical research that has been done on the sites and decide what meaning it has. These meanings are often a melding of fact and folklore.\n\nFolklore is an important aspect of living histories because it provides stories which visitors relate to. Whether it is an interpreter embodying a past individual’s personal story or discussing a superstition of the time, these accounts allow the audience to see these past figures not as names on a page, but as actual people. However, folklore is also more than stories. Objects, such as dolls or handmade clothing, among others, are considered “folk artifacts,” which are grouped under the heading of “material culture.”\n\nIndividuals can participate in living histories as a type of experiential learning in which they make discoveries firsthand, rather than reading about the experience of others. Living history can also be used to supplement and extend formal education. Collaborations between professional historians who work at living history sites and teachers can lead to greater enthusiasm about studying history at all grade levels. Many living history sites profess a dedication to education within their mission statements. For instance, the motto of Colonial Williamsburg, “That the Future May Learn from the Past,” proclaims the site’s commitment to public edification, as does the portion of the website created for the sole purpose of aiding teachers in instruction on the village.\n\nCertain educators, such as James Percoco in his Springfield, Virginia high school class, have chosen to integrate public history into their curricula. Since 1991, Percoco has led a class entitled “Applied History,” in which his students have contributed over 20,000 hours of service to various institutions of public history. Formal education can help visitors interpret what they see at living history sites. By providing a structured way of looking at living histories, as well as questions to think about during visits, formal education can enrich the experience, just as living histories can enrich learning in the classroom.\n\nSome museums such as Middelaldercentret in Denmark provides living history for school children as a part of their education.\n\n\n\n"}
{"id": "41207268", "url": "https://en.wikipedia.org/wiki?curid=41207268", "title": "Marxist historiography", "text": "Marxist historiography\n\nMarxist historiography, or historical materialist historiography, is a school of historiography influenced by Marxism. The chief tenets of Marxist historiography are the centrality of social class and economic constraints in determining historical outcomes.\n\nMarxist historiography has made contributions to the history of the working class, oppressed nationalities, and the methodology of history from below. The chief problematic aspect of Marxist historiography has been an argument on the nature of history as \"determined\" or \"dialectical\"; this can also be stated as the relative importance of subjective and objective factors in creating outcomes.\n\nMarxist history is generally deterministic: it posits a direction of history, towards an end state of history as classless human society. Marxist historiography, that is, the writing of Marxist history in line with the given historiographical principles, is generally seen as a tool. Its aim is to bring those oppressed by history to self-consciousness, and to arm them with tactics and strategies from history: it is both a historical and a liberatory project.\n\nHistorians who use Marxist methodology, but disagree with the mainstream of Marxism, often describe themselves as \"marxist\" historians (with a lowercase \"M\"). Methods from Marxist historiography, such as class analysis, can be divorced from the liberatory intent of Marxist historiography; such practitioners often refer to their work as \"marxian\" or \"Marxian\".\n\nFriedrich Engels' most important historical contribution was \"Der deutsche Bauernkrieg\" (\"The German Peasants' War\"), which analysed social warfare in early Protestant Germany in terms of emerging capitalist classes. \"The German Peasants' War\" indicate the Marxist interest in history from below and class analysis, and attempts a dialectical analysis.\n\nMarx's most important works on social and political history include \"The Eighteenth Brumaire of Louis Napoleon\", \"The Communist Manifesto\", \"The German Ideology\", and those chapters of \"Das Kapital\" dealing with the historical emergence of capitalists and proletarians from pre-industrial English society.\n\nEngels' short treatise \"The Condition of the Working Class in England in 1844\" (1870s) was salient in creating the socialist impetus in British politics.\n\nKey to understanding Marxist historiography is his view of labor. For Marx \"historical reality is none other than objectified labor, and all conditions of labor given by nature, including the organic bodies of people, are merely preconditions and 'disappearing moments' of the labor process.\" This emphasis on the physical as the determining factor in history represents a break from virtually all previous historians. Until Marx developed his theory of historical materialism, the overarching determining factor in the direction of history was some sort of divine agency. In Marx's view of history \"God became a mere projection of human imagination\" and more importantly \"a tool of oppression\". There was no more sense of divine direction to be seen. History moved by the sheer force of human labor, and all theories of divine nature were a concoction of the ruling powers to keep the working people in check. For Marx, \"The first historical act is... the production of material life itself.\" As one might expect, Marxist history not only begins with labor, it ends in production: \"history does not end by being resolved into \"self-consciousness\" as \"spirit of the spirit,\" but that in it at each stage there is found a material result: a sum of productive forces, a historically created relation of individuals to nature and to one another, which is handed down to each generation from its predecessor...\" For further, and much more comprehensive, information on this topic, see historical materialism.\n\nMarxist historiography suffered in the Soviet Union, as the government requested overdetermined historical writing. Soviet historians tended to avoid contemporary history (history after 1905) where possible and effort was predominantly directed at premodern history. As history was considered to be a politicised academic discipline, historians limited their creative output to avoid prosecution.\n\nNotable histories include the \"Short Course History of the Communist Party of the Soviet Union (Bolshevik)\", published in the 1930s, which was written in order to justify the nature of Bolshevik party life under Joseph Stalin.\n\nA circle of historians inside the Communist Party of Great Britain (CPGB) formed in 1946. They shared a common interest in \"history from below\" and class structure in early capitalist society. While some members of the group (most notably Christopher Hill and E. P. Thompson) left the CPGB after the 1956 Hungarian Revolution, the common points of British Marxist historiography continued in their works. They placed a great emphasis on the subjective determination of history. E. P. Thompson famously engaged Althusser in \"The Poverty of Theory\", arguing that Althusser's theory overdetermined history, and left no space for historical revolt by the oppressed.\n\nThompson's \"The Making of the English Working Class\" is one of the works commonly associated with this group. Eric Hobsbawm's \"Bandits\" is another example of this group's work.\n\nC. L. R. James was also a great pioneer of the 'history from below' approach. Living in Britain when he wrote his most notable work \"The Black Jacobins\" (1938), he was an anti-Stalinist Marxist and so outside of the CPGB.\n\nIn India, D. D. Kosambi is considered the founding father of Marxist historiography. The senior-most scholars of Marxist historiography are R. S. Sharma, Irfan Habib, D. N. Jha and K. N. Panikkar.\n\nOne debate in Indian history that relates to a historical materialist schema is on the nature of feudalism in India. D. D. Kosambi in the 1960s outlined the idea of \"feudalism from below\" and \"feudalism from above\". R. S. Sharma largely agrees with Kosambi in his various books. Most Indian Marxists argue that the economic origins of communalism are feudal remnants and the economic insecurities caused by slow development under a \"world capitalist system.\"\n\nB. R. Ambedkar criticized Marxists, as he deemed them to be unaware or ignorant of the specifics of caste issues. A number of historians have also debated Marxist historians and critically examined their analysis of history of India. Since the late 1990s, Hindu nationalist scholars especially have polemicized against the Marxist tradition in India for neglecting what they believe to be the country's 'illustrious past.' Marxists are held responsible for aiding or defending Muslims, who figure in Hindu nationalist discourse as the enemy within. An example of such a critique is Arun Shourie's \"Eminent Historians\" (1998).\n\n\n"}
{"id": "51296636", "url": "https://en.wikipedia.org/wiki?curid=51296636", "title": "Murder of Seth Rich", "text": "Murder of Seth Rich\n\nThe murder of Seth Rich occurred on Sunday, July 10, 2016, at 4:20 a.m. in the Bloomingdale neighborhood of Washington, D.C. Rich died from two shots to the back. \n\nThe 27-year-old Rich was an employee of the Democratic National Committee (DNC), and his murder spawned several right-wing conspiracy theories, including the false claim that Rich had been involved with the leaked DNC emails in 2016, contradicted by the law enforcement branches that investigated the murder. It was also contradicted by the July 2018 indictment of 12 Russian military intelligence agents for hacking the e-mail accounts and networks of Democratic Party officials and by the U.S. intelligence community's conclusion the leaked DNC emails were part of Russian interference in the 2016 United States elections. Fact-checking websites like PolitiFact.com, Snopes.com, and FactCheck.org stated that these theories were false and unfounded. \"The New York Times\", \"Los Angeles Times\", and \"The Washington Post\" wrote that the promotion of these conspiracy theories was an example of fake news.\n\nRich's parents condemned the conspiracy theorists and said that these individuals were exploiting their son's death for political gain, and their spokesperson called the conspiracy theorists \"disgusting sociopaths\". They requested a retraction and apology from Fox News after the network promoted the conspiracy theory, and sent a cease and desist letter to the investigator Fox News used. The investigator stated that he had no evidence to back up the claims which Fox News attributed to him. Fox News issued a retraction, but did not apologize or publicly explain what went wrong. In return, the Rich family filed a defamation lawsuit against Fox News in March 2018,<ref name=\"Grynbaum_3/13/2018\"></ref> which was dismissed in August 2018, when a judge ruled that the plaintiffs failed to prove \"extreme and outrageous\" conduct by the defendants under the legal standard.\n\nRich grew up in a Jewish family in Omaha, Nebraska. He volunteered for the Nebraska Democratic Party, interned for Senator Ben Nelson, was active in Jewish outreach, and worked with the United States Census Bureau. In 2011, he graduated from Creighton University with a degree in political science. He moved to Washington, D.C. to work for pollster Greenberg Quinlan Rosner. In 2014 he began working for the Democratic National Committee (DNC) as the Voter Expansion Data Director. One of his tasks at the DNC was the development of a computer application to help voters locate polling stations.\n\nOn Sunday, July 10, 2016, at 4:20 a.m., Rich was shot about a block from his apartment at the southwest corner of Flagler Place and W Street Northwest in the Bloomingdale neighborhood of Washington, D.C.\n\nEarlier that night he had been at Lou's City Bar, a sports pub from his apartment, in Columbia Heights, where he was a regular customer. He left when the bar was closing, at about 1:30 or 1:45 a.m. Police were alerted to gunfire at 4:20 a.m. by an automated gunfire locator. Within approximately one minute after the gun shots, police officers found Rich conscious with multiple gunshot wounds. He was transported to a nearby hospital, where he later died. According to police, he died from two shots to the back and may have been killed in an attempted robbery, noting that the neighborhood had recently been plagued by robberies. Rich's mother told NBC's Washington affiliate WRC-TV, \"There had been a struggle. His hands were bruised, his knees are bruised, his face is bruised, and yet he had two shots to his back, and yet they never took anything... They didn't finish robbing him, they just took his life.\" The police told the family they had located a surveillance recording showing a glimpse of the legs of two people who could possibly be the killers.\n\nOn the day after the shooting, DNC Chair Debbie Wasserman Schultz issued a statement mourning his loss and praising Rich's work to support voter rights. Two days after the shooting, Hillary Clinton spoke of his death during a speech advocating limiting the availability of guns.\n\nIn September 2016, Rich's parents and girlfriend appeared on the syndicated television show \"Crime Watch Daily\" to speak about the murder case. In October 2016, a plaque and bike rack outside the DNC headquarters were dedicated to Rich's memory. In February 2017, the Beth El Synagogue in Omaha named after Rich an existing scholarship that helps Jewish children attend summer camps.\n\nThe Rich family accepted the \"pro bono\" public relations services of Republican lobbyist Jack Burkman in September 2016. The Rich family and Burkman held a joint press conference on the murder in November 2016. In January 2017, Burkman launched an advertising campaign in Northwest D.C. searching for information regarding Seth's death. This included billboard advertisements and canvassing with flyers. In late February, Burkman told media outlets he had a lead that the Russian government was involved in Rich's death, and the Rich family then distanced itself from Burkman. On March 19, 2017, Rich's brother, Aaron, started a GoFundMe campaign to try to raise $200,000 for private investigation, public outreach activities, and a reward fund.\n\nThe Rich family was approached by Ed Butowsky (a friend of Trump advisor Steve Bannon and a frequent Fox News contributor), who recommended having Fox News contributor and former homicide detective Rod Wheeler investigate Seth's murder. Butowsky said Wheeler had been recommended to him. The family gave Wheeler permission to investigate, though they did not hire him. When questioned by CNN, Butowsky denied involvement in the case, but later admitted he was involved and had offered to pay Wheeler's fees. After Wheeler asserted links between Rich and Wikileaks in a Fox affiliate interview on May 15, 2017—an assertion he later backpedaled from—the family spokesman said that the family regretted working with Wheeler. Wheeler then sued Fox News on August 1, 2017, for mental anguish and emotional distress, alleging that he had been misquoted in a story that was then published on the urging of Trump.\n\nThe Metropolitan Police Department of the District of Columbia (MPDC) posted its customary reward of $25,000 for information about the death.\n\nOn August 9, 2016, WikiLeaks announced a $20,000 reward for information about Rich's murder leading to a conviction, although Rich's family said they were unable to verify this reward offer. WikiLeaks stated that this offer should not be taken as implying Rich had been involved in leaking information to them.\n\nIn November 2016, Republican lobbyist Jack Burkman said he was personally offering a $100,000 reward in addition to those announced by the police department and WikiLeaks, and he added another $5,000 to his offer in December and another $25,000 in January. Burkman said he hoped the money would help \"get to the truth of what happened here and will either debunk the conspiracy theories or validate them\".\n\nRight-wing conspiracy theories began circulating in the days following Rich's death, including false claims that his murder was connected to the DNC email leak of 2016, or the FBI's investigation of the Clinton Foundation. A post on Twitter before Rich's memorial service originated the idea that his killing was a political assassination. Subsequently, the conspiracy theory was spread on the subreddit /r/The Donald, and on July 29, 2016, the website \"Heat Street\" reported on these Reddit posts. Reddit users attempted to tie the homicide to prior \"Clinton Body Count\" conspiracy theories. The conspiracy theory was later popularized by Donald Trump political adviser Roger Stone via his Twitter account.\n\nAccording to British journalist Duncan Campbell, the Russian intelligence agency, GRU, tried to implicate Rich as the source of the stolen DNC emails, in order to draw attention away from themselves. Datestamps on the DNC files were altered to show the data had been obtained on July 5, 2016, five days before Rich's death, and the timezone was changed to Eastern Time, within which Washington, D.C. falls. Guccifer 2.0, the alleged GRU front that provided the emails to Wikileaks, then reported that Rich had been their source. Based partly on their acceptance of the false dates, some experts then concluded that the emails had been copied in the DNC offices, and had not been hacked from outside.\n\nJulian Assange, the founder of WikiLeaks, fueled the speculation in an interview with \"Nieuwsuur\" published on August 9, 2016, which touched on the topic of risks faced by WikiLeaks' sources. Unbidden, Assange brought up the case of Seth Rich. When asked directly whether Rich was a source, Assange nodded, then said \"we don't comment on who our sources are\". Subsequent statements by WikiLeaks emphasized that the organization was not naming Rich as a source. For context, Assange was well-known as a longtime critic of Clinton, and it subsequently came to light that WikiLeaks communicated with the Trump campaign over other issues, casting doubt on Assange's motivation.\n\nIn April 2018, Twitter direct messages revealed that even as Assange was suggesting publicly that WikiLeaks had obtained emails from Seth Rich, Assange was trying to obtain more emails from the hacker Guccifer 2.0, who was at the time suspected of being linked to Russian intelligence. \"BuzzFeed\" described the messages as \"the starkest proof yet that Assange knew a likely Russian government hacker had the Democrat leaks he wanted. And they reveal the deliberate bad faith with which Assange fed the groundless claims that Rich was his source, even as he knew the documents' origin.\" WikiLeaks' supporters on social media argued Assange's actions were consistent with WikiLeaks' mission.\n\nThese conspiracy theories were promoted by Mike Cernovich, Sean Hannity, Geraldo Rivera, Kim Dotcom, Paul Joseph Watson, Newt Gingrich, Jack Posobiec, and others.\n\nThe same venues that fomented the false Pizzagate conspiracy theory helped to promulgate the Seth Rich murder conspiracy theories, and each shared similar features. Both were promoted by individuals subscribing to far-right politics, and by campaign officials and individuals appointed to senior-level national security roles by Donald Trump. After prior coordination on Facebook, each theory was spread on Twitter by automated bots using a branded hashtag, with the goal of becoming a trending topic. Both the Pizzagate conspiracy theory and the Seth Rich murder conspiracy theory were spread in the subreddit forum /r/The Donald. In both conspiracy theories, the promoters attempted to shift the burden of proof — asking others to attempt to disprove their claims, without citing substantiated evidence. \"Slate\"s Elliot Hannon called the claims about Seth Rich a \"PizzaGate-like conspiracy theory surrounding Rich's death\", \"The Huffington Post\" described it as \"the 'alt-right' idiocy of Pizzagate all over again\", NPR's David Folkenflik said Fox News coverage of it \"evokes the pizza-gate terrible allegations utterly unfounded\", and Margaret Sullivan wrote for \"The Washington Post\": \"The Seth Rich lie has become the new Comet Ping Pong ... Crazy, baseless and dangerous.\"\n\nThe conspiracy theories have been debunked by law enforcement, as well as by fact-checking websites like PolitiFact.com, Snopes.com, and FactCheck.org.\n\nThe Metropolitan Police Department of the District of Columbia described the murder as related to a bungled attempted robbery, and said \"the assertions put forward by Mr. Wheeler are unfounded.\" The FBI told PolitiFact.com that the MPD was investigating the homicide.\n\nAssistant Police Chief Peter Newsham said the police had no information suggesting a connection between Rich's death and data obtained by WikiLeaks.\n\nPeople who worked with Rich said he was not an expert computer hacker helping to leak information to foreigners. Andrew Therriault, a data scientist who had mentored Rich, said although he had recently been working as a programmer, this \"wasn't his background\", and another co-worker said Rich was very upset when he heard hackers associated with Russian intelligence services had broken into the DNC computers and could be interfering with the election.\n\nRich family representative, Brad Bauman, responding to the conspiracy theorists' claim that the FBI was investigating the case said, \"The FBI is not now and has never been a party to this investigation.\"\n\nFactCheck.org analyzed statements by Newt Gingrich related to the conspiracy theory, where Gingrich said Rich \"apparently was assassinated\" subsequent to \"having given WikiLeaks something like … 53,000 [DNC] emails and 17,000 attachments\". FactCheck.org determined this claim was \"unsupported\" and determined \"there's no evidence for his claim.\"\n\nPolitiFact.com said the assertion that Rich gave emails to WikiLeaks is a \"baseless claim\", concluding \"Gingrich and others are talking about an unfounded conspiracy theory as if it's a matter of fact. It is far from it. We rate his claim Pants on Fire.\" In a separate analysis, PolitiFact.com concluded: \"There's no evidence there's any link between Rich and WikiLeaks. The FBI has indirectly denied investigating the case, which Washington police consider a robbery gone wrong.\"\n\nSnopes.com looked into the matter and stated: \"We were able to confirm the FBI is not investigating Rich's murder — it is an MPD investigation.\" Snopes contacted a spokesman for the Washington, D.C. mayor's office, who said, \"All claims made by Mr. Wheeler are false and take fake news to a whole new level. The family deserves better and everyday MPD continues to work diligently to solve this case.\" Snopes rated the claim \"DNC staffer Seth Rich sent 'thousands of leaked e-mails' to WikiLeaks before he was murdered\" as \"False\".\n\nThe fabrications were described as fake news and falsehoods by \"The New York Times\". \"The New York Times\" cited the conspiracy theories as an example of the persistence of false claims, concluding: \"fake news dies hard\". The \"Los Angeles Times\" called the conspiracy theories \"unsubstantiated rumors\".\n\n\"The Washington Post\" cited the conspiracy theories as an example of the power of fake news to spread virally online. The paper used the example as a case study of the persistence of fake news, and found that television news media can be a soft target for such false stories. \"The Washington Post\" further found that the proliferation of fake news via Facebook had decreased, but remained powerful on Twitter due to spread via online bots. They found that the conspiracy theories with the largest potential to spread on the Internet were those that held attraction for both the alt-right movements and the political left wing. \"The Washington Post\" concluded that even if a particular false story had been sufficiently debunked, such fact-checking was unable to stop the spread of the falsehoods online.\n\nOn May 15, 2017, Fox 5 DC (WTTG) reported the uncorroborated and later largely retracted claims by Rod Wheeler, a Fox News contributor and former homicide detective, that there was evidence Seth Rich had contacted WikiLeaks and that law enforcement were covering this up; claims that were never independently verified by Fox. The next day, Fox News published a lead story on its website and provided extensive coverage on its cable news channel about what it later said were Wheeler's uncorroborated claims about the murder of Seth Rich; in the lead story Fox News removed from their website a few days later, they stated that Wheeler's claims had been \"corroborated by a federal investigator who spoke to Fox News.\" In reporting these claims, the Fox News report re-ignited conspiracy theories about the killing. According to NPR, within a day of the original Fox report, \"Google searches for Rich had overtaken searches for James Comey, even amid continuous news about the former FBI director's conversations with Trump.\" \"The Washington Post\"s Callum Borchers noted Fox News chose to lead with this story at a time when most other media outlets were covering Donald Trump's disclosure of classified information to Russia.\n\nOther news organizations revealed Wheeler was a Donald Trump supporter, a paid Fox News contributor, and according to NBC News had \"developed a reputation for making outlandish claims, such as one appearance on Fox News in 2007 in which he warned that underground networks of pink pistol-toting lesbian gangs were raping young women\". \"The Washington Post\" noted it is \"rare for a news organization to have such a close relationship with the people it is covering\", as Wheeler was \"playing three roles at once: as a Fox source, as a paid contributor to the network and as a supposedly independent investigator of the murder\". When Wheeler appeared on Sean Hannity's Fox News shows, these multiple roles were not disclosed to viewers. After Wheeler's Fox News interview on May 15, 2017, Brad Bauman, a communications professional and spokesman for the Rich family, said the family was asking Fox News and the Fox affiliate to retract their reports and apologize for damaging their son's legacy.\n\nThe family spokesperson, the Washington, D.C. police department, the Washington, D.C. mayor's office, the FBI, and law enforcement sources familiar with the case all disputed Wheeler's claims. The family said, \"We are a family who is committed to facts, not fake evidence that surfaces every few months to fill the void and distract law enforcement and the general public from finding Seth's murderers.\" Bauman criticized Fox News for its reporting, saying he believed that the outlet was motivated by a desire to deflect attention from the Trump-Russia story: \"I think there's a very special place in hell for people that would use the memory of a murder victim in order to pursue a political agenda.\"\n\nLater that day, Wheeler told CNN he had no evidence that Rich had contacted Wikileaks. Wheeler claimed that Fox had presented his quotes misleadingly and that he only learned about the possible existence of the evidence from a Fox News reporter. Despite this, Sean Hannity's show and \"Fox & Friends\" continued to promote the conspiracy theory for the remainder of the week. Former House Speaker Newt Gingrich and Geraldo Rivera took part in spreading the conspiracy. Hannity had on his program Tom Fitton of Judicial Watch, who said the organization filed Freedom of Information Act requests for documents from Washington, D.C. Mayor Muriel E. Bowser, and from the Metropolitan Police. Sean Hannity furthermore promoted the uncorroborated claims of Kim Dotcom, a New Zealand resident sought by the United States on fraud charges who claimed without evidence that Rich had been in contact with him before his death. Fox News host Julie Roginsky was critical of the conspiracy theory peddlers, stating on Twitter and on her television show: \"The exploitation of a dead man whose family has begged conspiracy theorists to stop is really egregious. Please stop.\" Fox News was also criticized by conservative outlets, such as the \"Weekly Standard\", \"National Review\", and \"Red State\", and conservative columnists, such as Jennifer Rubin, Michael Gerson, and John Podhoretz. In September 2017, \"NPR\" noted that Fox News had yet to apologize for its false story or explain what went wrong; \"When a story of this scale crumbles, most news organizations feel obligated to explain what happened and why. Not so far at Fox.\"\n\nOn May 19, 2017, an attorney for the Rich family sent a cease and desist letter to Wheeler.\n\nFox News issued a retraction of the story on May 23, 2017 and removed the original article, and did not apologize or specify what went wrong or how it did so. Despite this, Hannity, who pushed the theory, remained unapologetic, saying \"I retracted nothing\" and \"I am not going to stop trying to find the truth.\" In their May 23 statement, Fox News said, \"The article was not initially subjected to the high degree of editorial scrutiny we require for all our reporting. Upon appropriate review, the article was found not to meet those standards and has since been removed.\" Media ethics writer Kelly McBride criticized the retraction as \"woefully inadequate\", writing that it did not specify exactly what was inaccurate, or provide correct information in place of the retracted story.\n\nOn May 23, 2017, Sean Hannity stated on his television program that he would cease discussing the issue. Hannity said his decision to cease commenting on the matter was related to the family of the murder victim: \"Out of respect for the family's wishes, for now, I am not discussing the matter at this time.\" In the same statement wherein he promised to cease discussion of the topic, he vowed to pursue facts in the future: \"I promise you I am not going to stop trying to find the truth.\" Several advertisers including Crowne Plaza Hotels, Cars.com, Leesa Mattress, USAA, Peloton and Casper Sleep pulled their marketing from his program on Fox News. Crowne Plaza Hotels later said that it was not their policy to advertise on political commentary shows, and had not been aware of their sponsorship of the show. USAA soon returned to advertising on Fox News after receiving customer input.\n\nOn August 1, 2017, Rod Wheeler, the private investigator hired by Butowsky who was the first to claim links between Seth Rich's murder and the DNC hack on Fox, but who later appeared to retract his claims, filed a lawsuit (Case 1:17-cv-05807 Southern District of New York), in which 21st Century Fox, the Fox News Channel, Fox News reporter Malia Zimmerman and Ed Butowsky are named as defendants, stating that quotes attributed to him in the original Fox News piece were fabricated. The lawsuit also alleges that the fabricated quotes were included in the Fox News story at the urging of the Trump White House.\n\nText messages and audio apparently supporting this assertion were included in the filing of the lawsuit. About a month before the story was aired on Fox News, Wheeler and Butowsky met at the White House with the White House Press Secretary Sean Spicer to review the planned story on Seth Rich's murder. After talking to Wheeler and Butowsky, Zimmerman sent Wheeler a draft of a story without any quotes from Wheeler on May 11. On May 14 Butowsky texted Wheeler saying \"Not to add any more pressure but the president just read the article. He wants the article out immediately. It's now all up to you. But don't feel the pressure.\" Butowsky also left a voicemail for Wheeler which said \"We have the full, uh, attention of the White House on this. And tomorrow, let's close this deal, whatever we've got to do.\"\nButowsky said Seymour Hersh confirmed a link between Rich and the FBI. Hersh confirmed the conversation with Butowsky but told NPR the link was \"gossip\" and that Butowsky exaggerated its significance.\n\nIn an email to Fox News Butowsky also wrote about the purpose behind the Seth Rich story: \"One of the big conclusions we need to draw from this is that the Russians did not hack our computer systems and ste[a]l emails and there was no collusion (between) Trump and the Russians.\" He also instructed Wheeler that \"[T]he narrative in the interviews you might use is that you and [Zimmerman's] work prove that the Russians didn't hack into the DNC and steal the emails and impact our elections (...) If you can, try to highlight this puts the Russian hacking story to rest.\"\n\nWhen the story aired on Fox News, it included supposed quotes from Wheeler and was written as if the accusations against the DNC came from him. Wheeler alleges that the quotes were fabricated and should not have been attributed to him.\n\nIn later recordings Butowsky told Wheeler that the claims being attributed to him were false but says that \"One day you're going to win an award for having said those things you didn't say.\" He also says \"I know that's not true, if I'm under oath, I would say I never heard him say that.\"\n\nJudge George B. Daniels dismissed this lawsuit in August 2018.\n\nIn May 2017, Seth Rich's brother Aaron Rich issued a statement saying, \"We simply want to find his killers and grieve. Instead, we are stuck having to constantly fight against non-facts, baseless allegations, and general stupidity to defend my brother's name and legacy.\"\n\nThe family spokesperson said \"At this point, only people with transparent political agendas or sociopaths are still perpetuating Seth Rich conspiracies.\"\n\nHis parents authored a piece in \"The Washington Post\" on May 23, 2017 titled: \"We're Seth Rich's parents. Stop politicizing our son's murder,\" in which they wrote:\n\nIn March 2018, Rich's family filed a lawsuit against Fox News, Fox reporter Malia Zimmerman, and Fox contributor Ed Butowsky, for publishing a news report about Seth Rich. The suit alleges that the report fueled conspiracy theories about Rich's death and caused the family emotional distress. Judge George B. Daniels dismissed the lawsuit in August 2018, stating that the case failed to prove \"extreme and outrageous\" conduct on the part of defendants, as that standard is determined under New York state law. \n\nAlso in March 2018, Aaron Rich filed a lawsuit against Butowsky, Couch, America First Media, and \"The Washington Times\" for suggesting he had played a role in the purported theft of emails from the DNC. On October 1, 2018, as part of a settlement they had reached with Aaron Rich, \"The Washington Times\" retracted the relevant articles and issued an apology to Rich and his family.\n\n\n\n"}
{"id": "4224324", "url": "https://en.wikipedia.org/wiki?curid=4224324", "title": "Origin of water on Earth", "text": "Origin of water on Earth\n\nThe origin of water on Earth, or the reason that there is clearly more liquid water on Earth than on the other rocky planets of the Solar System, is not completely understood. There exist numerous more or less mutually compatible hypotheses as to how water may have accumulated on Earth's surface over the past 4.5 billion years in sufficient quantity to form oceans.\n\nComets, trans-Neptunian objects, or water-rich meteoroids (protoplanets) from the outer reaches of the asteroid belt colliding with Earth may have brought water to the world's oceans. Asteroids may have been primarily responsible based on several studies, including measurements of the ratio of the hydrogen isotopes deuterium and protium, since similar percentage impurities as in carbon-rich chondrites were found in oceanic water, whereas previous measurement of the isotopes' concentrations in comets and trans-Neptunian objects correspond only slightly to water on Earth. In January 2018, researchers reported that two 4.5 billion-year-old meteorites found on Earth contained liquid water alongside a wide diversity of deuterium-poor organic matter.\n\nLarge-enough planetesimals were heated by the decay of aluminium-26. This could cause water to rise to the surface. Recent studies suggest that water with similar deuterium-to-hydrogen ratio was already available at the time of Earth's formation, as evidenced in ancient eucrite meteorites originating from the asteroid Vesta.\n\nThat Earth's water originated purely from comets is implausible, since a result of measurements of the isotope ratios of deuterium to protium (D/H ratio) in the four comets Halley, Hyakutake, Hale–Bopp, and 67P/Churyumov–Gerasimenko, by researchers such as David Jewitt, is approximately double that of oceanic water. What is, however, unclear is whether these comets are representative of those from the Kuiper belt. According to Alessandro Morbidelli, the largest part of today's water comes from protoplanets formed in the outer asteroid belt that plunged towards Earth, as indicated by the D/H proportions in carbon-rich chondrites. The water in carbon-rich chondrites point to a similar D/H ratio as oceanic water. Nevertheless, mechanisms have been proposed to suggest that the D/H-ratio of oceanic water may have increased significantly throughout Earth's history. Such a proposal is consistent with the possibility that a significant amount of the water on Earth was already present during the planet's early evolution.\n\nRecent measurements of the chemical composition of Moon rocks suggest that Earth was born with its water already present. Investigating lunar samples carried to Earth by the Apollo 15 and 17 missions found a deuterium-to-hydrogen ratio that matched the isotopic ratio in carbonaceous chondrites. The ratio is also similar to that found in water on Earth. The findings suggest a common source of water for both objects. This supports a theory that Jupiter temporarily migrated into the inner Solar System, destabilizing the orbits of water-rich carbonaceous chondrites. As a result, some of the bodies could have fallen inwards and become part of the raw material for making Earth and its neighbors. The discovery of water vapor out-gassing from Ceres provides related information on water-ice content of the asteroid belt.\n\nGradual \"dehydration melting\"—leakage of water stored in hydrate minerals of Earth's rocks—could have formed a portion of its water. Water may also have come from volcanism: water vapor in the atmosphere that originated in volcanic eruptions may have condensed to form rain, slowly filling Earth's oceanic basins.\n\nA sizeable quantity of water would have been in the material that formed Earth. Water molecules would have escaped Earth's gravity more easily when it was less massive during its formation. Hydrogen and helium are expected to leak from the atmosphere continually, but the lack of denser noble gases in the modern atmosphere suggests that something disastrous happened to the early atmosphere.\n\nPart of the young planet is theorized to have been disrupted by the impact which created the Moon, which should have caused melting of one or two large areas. Present composition does not match complete melting and it is hard to melt and mix huge rock masses completely. However, a fair fraction of material should have been vaporized by this impact, creating a rock-vapor atmosphere around the young planet. The rock vapor would have condensed within two thousand years, leaving behind hot volatiles which probably resulted in a heavy carbon dioxide atmosphere with hydrogen and water vapor. Liquid water oceans existed despite the surface temperature of because of the atmospheric pressure of the heavy CO atmosphere. As cooling continued, subduction and dissolving in ocean water removed most CO from the atmosphere but levels oscillated wildly as new surface and mantle cycles appeared.\n\nStudy of zircons has found that liquid water must have existed as long ago as 4.404 ± 0.008 Ga, very soon after the formation of Earth. This requires the presence of an atmosphere. The Cool early Earth theory covers a range from about 4.4 Ga to 4.0 Ga.\n\nIn fact, recent studies of zircons (in the fall of 2008) found in Australian Hadean rock hold minerals that point to the existence of plate tectonics as early as 4 billion years ago. If this holds true, the previous beliefs about the Hadean period are far from correct. That is, rather than a hot, molten surface and atmosphere full of carbon dioxide, Earth's surface would be very much like it is today. The action of plate tectonics traps vast amounts of carbon dioxide, thereby reducing greenhouse effects, and leading to a much cooler surface temperature, and the formation of solid rock, and possibly even life.\n\nSome terrestrial water may have had a biochemical origin, during the Great Oxygenation Event, via redox reactions and photosynthesis.\n\nIn the early 1930s, Cornelis van Niel discovered that sulfide-dependent chemoautotrophic bacteria (purple sulfur bacteria) fix carbon and synthesize water as a byproduct of a photosynthetic pathway using hydrogen sulfide and carbon dioxide:\n\nFew modern organisms use this method of photosynthesis, making their water contribution negligible. But on the hydrogen-sulfide-rich and oxygen-poor early Earth, a small but significant portion of Earth's water may have been synthesized biochemically through this pathway.\n\n"}
{"id": "4077467", "url": "https://en.wikipedia.org/wiki?curid=4077467", "title": "Pentecontaetia", "text": "Pentecontaetia\n\nPentecontaetia (, \"the period of fifty years\") is the term used to refer to the period in Ancient Greek history between the defeat of the second Persian invasion of Greece at Plataea in 479 BC and the beginning of the Peloponnesian War in 431 BC. The term originated with a scholiast on Thucydides, who used it in their description of the period. The \"Pentecontaetia\" was marked by the rise of Athens as the dominant state in the Greek world and by the rise of Athenian democracy. Since Thucydides focused his account on these developments, the term is generally used when discussing developments in and involving Athens.\n\nShortly after the Greek victory of 479 BC, Athens assumed the leadership of the Delian League, a coalition of states that wished to continue the war against Persia. This league experienced a number of successes and was soon established as the dominant military force of the Aegean. Athenian control over the league grew as some \"allies\" were reduced to the status of tribute-paying subjects and by the middle of the 5th century BC (the league treasury was moved from Delos to Athens in 454 BC) the league had been transformed into an Athenian empire. Athens benefited greatly from this tribute, undergoing a cultural renaissance and undertaking massive public building projects, including the Parthenon; Athenian democracy, meanwhile, developed into what is today called radical or Periclean democracy, in which the popular assembly of the citizens and the large, citizen juries exercised near-complete control over the state.\n\nThe later years of the \"Pentecontaetia\" were marked by increasing conflict between Athens and the traditional land powers of Greece, led by Sparta. Between 460 BC and 445 BC, Athens fought a shifting coalition of mainland powers in what is now known as the First Peloponnesian War. During the course of this conflict, Athens gained and then lost control of large areas of central Greece. The conflict was concluded by the Thirty Years' Peace, which lasted until the end of the \"Pentecontaetia\" and the beginning of the Peloponnesian War.\n\nThe eventual breakdown of the peace was triggered by increasing conflict between Athens and several of Sparta's allies. Athens' alliance with Corcyra and attack on Potidaea enraged Corinth, and the Megarian decree imposed strict economic sanctions on Megara, another Spartan ally. These disputes, along with a general perception that Athenian power had grown too powerful, led to the breakdown of the Thirty Years Peace; the Peloponnesian War broke out in 431 BC.\n\n479—Rebuilding of Athens: Although the Greeks were victorious in the Persian War, many Greeks believed that the Persians would retaliate. This led Athens to rebuild its long walls that were razed by the Persian Army during the occupation of Attica in 480.\n\n478—Formation of the Delian League: Athens and other city states form a coalition against Persia.\n\n477—The Conquest of Eion: Cimon, the son of Miltiades of Marathon fame, led Athens to numerous victorious campaigns and war profits. In 477, he led an army against Persian-occupied Eion in northern Greece. Athens was able to benefit from this invasion since the region was rich in timber, which was critical to building Athens' burgeoning naval fleet.\n\n476—The Conquest of Scyros: The invasions continued with success on a par with Cimon's prior campaigns. In 476, Athens fought against the pirates of Scyros, as the Delian League wanted to reduce piracy around the region and capture the important materials for itself.\n\n469—Operation in Asia Minor and the Battle of Eurymedon: From the beginning of 469 to 466, the Delian league led an army to Asia Minor against Persia. Cimon persuaded Greek settlements on the Carian and Lycian coast to rebel against Persia. This led the Persian army to mobilize a force to fight Cimon in the Battle of Eurymedon in Pamphylsia. Cimon was able to defeat the Persian army swiftly and the war profits were used to finance Athens' city walls.\n\n465—Operations in Northern Greece: Athens' powers and desire for expansion grow. In 465, after cleruchizing the Chersonese, they tried to gain control of Thasos. Thucydides wrote that Sparta contemplated an invasion of Attica in order to help free Thasos. However, in the aftermath of a catastrophic earthquake and subsequent helot uprising in Sparta, no attack—if indeed such was projected—was launched.\n\n461—The Debate in Athens over Helping Sparta: With a legion of Helots rebelling against Sparta, Athens offered Sparta their help by sending a force of 4,000 Hoplites to suppress the rebels. According to Thucydides, Sparta decided to dismiss Cimon's Athenian Army, because they felt that Athens would convince the Helots on Ithome to form a coalition and besiege Sparta. Spartans did not feel comfortable with such a large Athenian force inside their city. If the Athenians were to turn their backs on Sparta, the city would not be able to protect itself. At this point, Sparta acknowledged that Athens might be getting too powerful. According to Thucydides, the Athenians were deeply offended by their removal from Ithome. They denounced their original treaty with Sparta made during the Greco-Persian Wars, then proceeded to make an alliance with Argos, a major enemy of the Spartans. \n\n460—Athens' Clash with Corinth over Megara: Megarians joined the Delian League due to a war between Megara and Corinth. This angered the Corinthians. Even using Athens' weakest soldiers, being the old and young men who were left behind in the city, they were able to win the war against Corinth with ease.\n\n460—The Athenian Expedition to Egypt: Athens led a coalition with the Egyptians to rebel against Persia. However, their six-year expedition did not lead to much success against Persia, as 100 Athenian ships were destroyed in the Delta region.\n\n458—The Long Walls: The construction of the long walls gave Athens a major military advantage by forming a barrier around the city-state and its harbors, which allowed their ships to access waterways without threat from outside forces. Two walls were constructed from the city to the sea, one to Phaleron and the other to Piraeus. Athens relied on these long walls to protect itself from invasion, while sending off its superior vessels to bombard opponents' cities.\n\n458—The Battle of Tanagra: According to Thucydides, Spartans aided the Dorians by invading Greece, because they were motivated by ethnic solidarity. Sparta sent out 1500 Hoplites and an additional 10,000 from their allies' forces to suppress the Phocians' Army invading Doris. The Spartans were victorious, but they found themselves stuck in this foreign land. Athens, suspecting a plot by the Spartans to overthrow the democracy and to prevent the building of the Long Walls, then attacked the Spartans at Tanagra in Boeotia with a force of 14,000. The Spartans were victorious in this battle.\n\n457—The Battle of Oenophyta: After the Spartans returned home from Tanagra, the Athenians conquered Boetia and Phocis after a battle at Oenophyta. They then proceeded to tear down Tanagra's fortifications. \n\n450—The Peace of Callias—Although this peace treaty is subject to scholarly debate, allegedly Athens and Persia agreed to a ceasefire.\n\n447—Athens' forces were defeated at Coronea, causing the Athenian army to flee Boeotia.\n\n446—The Peloponnesian Invasion of Attica: Athens continued their indirect war with Sparta by attempting to gain control of Delphi. City-states such as Megara and Euboea began to rebel against Athens and the Delian League when the Spartan Army invaded Athenian territory.\n\n445—The Thirty-Year Peace Between Athens and Sparta: After losing Attica, Boeotia and Megara, Athens agreed to a thirty-year peace in return for all the conquered areas in the Peloponnesian region. From this point on, all future conflicts between Athens and Sparta were resolved under arbitration.\n\n447—Athenian Colonization and the Colony of Brea: With the 30-year peace treaty, Athens was able to concentrate attention towards growth rather than war. From 447-445, the Delian League was able to influence city-states near the Mediterranean to join and pay tribute (phoro). This helped the region because the tributes paid by each and every city-state were reduced with the increasing number of members joining the league.\n\n441—The Samian Revolt—Athens decided to besiege Samos after their revolt in 441. However, Persia decided to take the opportunity to support Samos even though they have signed the Peace of Callias with Athens. Athens would eventually spend 1200 talents to fund the war through the Delian League's treasury. Some scholars believed that Sparta might have aided Samos as well, but decided to pull out, having they signed the Thirty-year peace treaty.\n\n437—The Foundation of Amphipolis: With vast resources, especially timber for ship building, Athens founded the city of Amphipolis on the Strymon River. Amphipolis was immensely important to Athens since it controlled many trading routes.\n\n432—The Potidaean Affair: Athens was threatened by the possibility of a revolt, plotted by Corinth and Macedon. After fighting in Macedon, which ended when the two countries came to terms with each other, Athens came to Potidaea. They had previously demanded that Potidaea tear down their long walls and banish Corinth ambassadors. However, by the time Athens reached Potidaea, the residents were in full revolt and prepared to fight Athens with support from the Corinthian army. The Corinthians was also able to influence the Spartans to join the cause, since Sparta didn't want to lose such an affluent ally. The fighting concluded with an Athenian victory. \n\n432—The Megarian Decree: With Sparta's aid, Megara urged Athens to drop their decree against them since it was hurting their economy; they were forbidden to use Athen's markets and harbors. Athens claims that Megarians insulted them by trespassing on land sacred to Demeter and murdering an Athenian ambassador. However, most scholars believe it was an act of vengeance when Megara revolted during the early parts of the Pentecontaetia.\n\n432—Peloponnesian War—This marked the end of the Pentecontaetia, as Athens and Sparta engaged in all-out war, which eventually led to the demise of the Athenian Empire.\n\nAfter the exile of Cimon in Athens, his rivals Ephialtes and Pericles implemented democratic social reforms. In 462, Ephialtes challenged the Areopagus, claiming that they were abusing their powers. Part of the reform was to introduce \"graphe paranomon\" or public protest against illegal decrees. Any citizen would have the right to challenge a previous degree instilled by the Areopagus and claim it as invalid. The assembly would have to conduct a \"dokimasia\" or examination of state officials before they enter office. Opportunities for citizens to join the office were increased tremendously when 500 members were added. Transferring the powers of the Areopagus to all Athenian citizens enabled a more democratic society. \n\nThese democratic ideals are reflected in the use of personal names without a Patronymic on inscriptions of casualty lists from around this time, such as those of the tribe Erechtheis dated to 460/459BC and the Argive dead at the Battle of Tanagra (457 BC).. Without the Patronymic or demotic it would have been impossible to identify the particular individual being referred to when multiplicity of the same name occurred, thus both reducing the impact of the long list and ensuring that individuals are deprived of their social context.\n\nAfter Ephialtes death, his younger partner Pericles continued with reforms, transforming Athens into the most democratic city-state of Ancient Greece. During 450, he implemented a state salary of two obols per day for jurors to increase public participation from citizens. However, this system caused an outrage from the elites, claiming that the poor were uneducated and incapable of governing.\n\nThucydides offers us a unique perspective to view the Peloponnesian War since he actually took part in the conflict. This first-hand experience allows a look into the mind of a person at the center of the ordeal. The conflict between Athens and Sparta is in Thucydides’ eyes an inevitable confrontation of the two major powers. The beginning of this tension begins during the incipient stages of the Athenian empire following the defeat of Persia during a period called the “pentekontaetia”. The pentekontaetia began in 479 and ended with the outbreak of war. With great confidence in their military abilities, perhaps a bit of instilled machoism, and the need for an anti-Persian alliance, Athens begins recruiting various Greek city-states into an alliance called the Delian League. The growth of Athenian power through the Delian League is centered on a growing navy, the rebuilding of the walls that protect the city from land-based attackers, and an aggressive push to extend their influence which included a few skirmishes with other powers. Thucydides writes about how this period of growth was an inevitable cause of war, “Their supremacy grew during the interval between the present war and the Persian wars, through their military and political actions recounted below against the barbarians, against their own allies in revolt, and against the Peloponnesians whom they encountered on various occasions.” (1.97 [2])\n\nAthenian naval supremacy was a great fear of Sparta and her allies. While the Spartans combat prowess was unmatched on land, when it came to the sea Athens was the clear victor. This split seemed to have already been accepted by the Spartans many years earlier, however the aggressiveness and effectiveness of Athenian naval warfare had yet to be fully realized. According to Thucydides following the defeat of Persia, Athens begins to reconstruct the long walls which connected the main city of Athens to the port of Piraeus around 478. “Spartan feeling was at that time very friendly towards Athens on account of the patriotism which she had displayed in the struggle with Mede. Still the defeat of their wishes could not but cause them secret annoyance.” (1.92 [1]) The Spartan annoyance stems partly from the long walls being a major deterrent to land based, non-siege tactics which the Spartans were particularly adept at, but also from the way in which the deal was brokered.\n\nThucydides writes of Themistocles, an envoy to Sparta, who in 479 changed the tide of history by hiding the facts regarding the construction of the walls around Athens and those of the Piraeus. In Themistocles’speech to the Spartan assembly Thucydides points out that at this point Athenian independence was highlighted. “Wherever they had deliberated with the Spartans, they had proved themselves to be in judgment second to none.” (1.91 [5]) This is an important step because Themistocles articulates that Athens is an independent state with its own agenda that brushed over that of others. This is a very important point in the lead up to the Peloponnesian War because one man is credited with making the split. Themistocles through his cunningness asserts an independent and strong Athenian identity. He makes it clear after the walls have been secured (ensuring Athenian strength) that Athens is independent and is making self-interested decisions. Furthermore, Themistocles also predicts that the growth in Athenian power will be centered on the sea. “For he first ventured to tell them to stick to the sea and forthwith began to lay the foundations of the empire.” (1.93 [5]) Thucydides credits Themistocles with the determining point in which Athens becomes an empire creating the divide between Sparta and Athens.\n\n"}
{"id": "196556", "url": "https://en.wikipedia.org/wiki?curid=196556", "title": "Postmodernity", "text": "Postmodernity\n\nPostmodernity (post-modernity or the postmodern condition) is the economic or cultural state or condition of society which is said to exist \"after\" modernity. (In this context, \"modern\" is not used in the sense of \"contemporary\", but merely as a name for a specific period in history.) Some schools of thought hold that modernity ended in the late 20th century – in the 1980s or early 1990s – and that it was replaced by postmodernity, while others would extend modernity to cover the developments denoted by postmodernity, while some believe that modernity ended after World War II. The idea of the post-modern condition is sometimes characterised as a culture stripped of its capacity to function in any linear or autonomous state as opposed to the progressive mindstate of modernism.\n\nPostmodernity can mean a personal response to a postmodern society, the conditions in a society which make it postmodern or the state of being that is associated with a postmodern society as well a historical epoch. In most contexts it should be distinguished from postmodernism, the adoption of postmodern philosophies or traits in art, literature, culture and society. In fact, today, historical perspectives on the developments of postmodern art (postmodernism) and postmodern society (postmodernity) can be best described as two umbrella terms for processes engaged in an ongoing dialectical relationship, the result of which is the evolving culture of the contemporary world.\n\n\"Postmodernity\" is the state or condition of being postmodern – after or in reaction to that which is modern, as in postmodern art (\"see postmodernism\"). Modernity is defined as a period or condition loosely identified with the Progressive Era, the Industrial Revolution, or the Enlightenment. In philosophy and critical theory \"postmodernity\" refers to the state or condition of society which is said to exist \"after\" modernity, a historical condition that marks the reasons for the end of modernity. This usage is ascribed to the philosophers Jean-François Lyotard and Jean Baudrillard.\n\nOne \"project\" of modernity is said by Habermas to have been the fostering of progress by incorporating principles of rationality and hierarchy into public and artistic life. (See also postindustrial, Information Age.) Lyotard understood modernity as a cultural condition characterized by constant change in the pursuit of progress. Postmodernity then represents the culmination of this process where constant change has become the \"status quo\" and the notion of progress obsolete. Following Ludwig Wittgenstein's critique of the possibility of absolute and total knowledge, Lyotard further argued that the various metanarratives of progress such as positivist science, Marxism, and structuralism were defunct as methods of achieving progress.\n\nThe literary critic Fredric Jameson and the geographer David Harvey have identified postmodernity with \"late capitalism\" or \"flexible accumulation\", a stage of capitalism following finance capitalism, characterised by highly mobile labor and capital and what Harvey called \"time and space compression\". They suggest that this coincides with the breakdown of the Bretton Woods system which, they believe, defined the economic order following the Second World War. (See also consumerism, critical theory.)\n\nThose who generally view modernity as obsolete or an outright failure, a flaw in humanity's evolution leading to disasters like Auschwitz and Hiroshima, see postmodernity as a positive development. Other philosophers, particularly those seeing themselves as within the modern project, see the state of postmodernity as a negative consequence of holding postmodernist ideas. For example, Jürgen Habermas and others contend that postmodernity represents a resurgence of long running counter-enlightenment ideas, that the modern project is not finished and that universality cannot be so lightly dispensed with. Postmodernity, the consequence of holding postmodern ideas, is generally a negative term in this context.\n\nPostmodernity is a condition or a state of being associated with changes to institutions and creations (Giddens, 1990) and with social and political results and innovations, globally but especially in the West since the 1950s, whereas postmodernism is an aesthetic, literary, political or social philosophy, the \"cultural and intellectual phenomenon\", especially since the 1920s' new movements in the arts. Both of these terms are used by philosophers, social scientists and social critics to refer to aspects of contemporary culture, economics and society that are the result of features of late 20th century and early 21st century life, including the fragmentation of authority and the commoditization of knowledge (\"see\" \"Modernity\"). \n\nThe relationship between postmodernity and critical theory, sociology and philosophy is fiercely contested. The terms \"postmodernity\" and \"postmodernism\" are often hard to distinguish, the former being often the result of the latter. The period has had diverse political ramifications: its \"anti-ideological ideas\" appear to have been associated with the feminist movement, racial equality movements, gay rights movements, most forms of late 20th century anarchism and even the peace movement as well as various hybrids of these in the current anti-globalization movement. Though none of these institutions entirely embraces all aspects of the postmodern movement in its most concentrated definition they all reflect, or borrow from, some of its core ideas. \n\nSome authors, such as Lyotard and Baudrillard, believe that modernity ended in the late 20th century and thus have defined a period subsequent to modernity, namely postmodernity, while others, such as Bauman and Giddens, would extend modernity to cover the developments denoted by postmodernity. Others still contend that modernity ended with the Victorian Age in the 1900s.\n\nPostmodernity has been said to have gone through two relatively distinct phases the first beginning in the late 1940s and 1950s and ending with the Cold War (when analog media with limited bandwidth encouraged a few, authoritative media channels) and the second beginning at the end of the Cold War (marked by the spread of cable television and \"new media\" based on digital means of information dissemination and broadcast).\n\nThe first phase of postmodernity overlaps the end of modernity and is regarded by many as being part of the modern period \"(see lumpers/splitters, periodization)\". Television became the primary news source, manufacturing decreased in importance in the economies of Western Europe and the United States but trade volumes increased within the developed core. In 1967–1969 a crucial cultural explosion took place within the developed world as the baby boom generation, which had grown up with postmodernity as its fundamental experience of society, demanded entrance into the political, cultural and educational power structure. A series of demonstrations and acts of rebellion – ranging from nonviolent and cultural, through violent acts of terrorism – represented the opposition of the young to the policies and perspectives of the previous age. Opposition to the Algerian War and the Vietnam War, to laws allowing or encouraging racial segregation and to laws which overtly discriminated against women and restricted access to divorce, increased use of marijuana and psychedelics, the emergence of pop cultural styles of music and drama, including rock music and the ubiquity of stereo, television and radio helped make these changes visible in the broader cultural context. This period is associated with the work of Marshall McLuhan, a philosopher who focused on the results of living in a media culture and argued that participation in a mass media culture both overshadows actual content disseminated and is liberating because it loosens the authority of local social normative standards.\n\nThe second phase of postmodernity is defined by \"digitality\" – the increasing power of personal and digital means of communication including fax machines, modems, cable and high speed internet, which has altered the condition of postmodernity dramatically: digital production of information allows individuals to manipulate virtually every aspect of the media environment. This has brought producers into conflict with consumers over intellectual capital and intellectual property and led to the creation of a new economy whose supporters argue that the dramatic fall in information costs will alter society fundamentally.\n\nIt began to be argued that digitality or what Esther Dyson referred to as \"being digital\" had emerged as a separate condition from postmodernity. Those holding this position argued that the ability to manipulate items of popular culture, the World Wide Web, the use of search engines to index knowledge, and telecommunications were producing a \"convergence\" which would be marked by the rise of \"participatory culture\" in the words of Henry Jenkins and the use of media devices, such as Apple's iPod.\n\nThe simplest, but not necessarily most correct demarcation point of this era is the collapse of the Soviet Union and the liberalisation of China in 1991. Francis Fukuyama wrote \"The End of History\" in 1989 in anticipation of the fall of the Berlin wall. He predicted that the question of political philosophy had been answered, that large scale wars over fundamental values would no longer arise since \"all prior contradictions are resolved and all human needs satisfied.\" This is a kind of 'endism' also taken up by Arthur Danto who in 1984 acclaimed that Andy Warhol's Brillo boxes asked the right question of art and hence art had ended.\n\nThe debate on postmodernity has two distinct elements that are often confused; (1) the nature of contemporary society and (2) the nature of the critique of contemporary society. The first of these elements is concerned with the nature of changes that took place during the late 20th century. There are three principal analyses. Theorists such as Callinicos (1991) and Calhoun (1995) offer a conservative position on the nature of contemporary society, downplaying the significance and extent of socio-economic changes and emphasizing a continuity with the past. Second a range of theorists have tried to analyze the present as a development of the \"modern\" project into a second, distinct phase that is nevertheless still \"modernity\": this has been termed the \"second\" or \"risk\" society by Ulrich Beck (1986), \"late\" or \"high\" modernity by Giddens (1990, 1991), \"liquid\" modernity by Zygmunt Bauman (2000), and the \"network\" society by Castells (1996, 1997). Third are those who argue that contemporary society has moved into a literally post-modern phase distinct from modernity. The most prominent proponents of this position are Lyotard and Baudrillard.\n\nAnother set of issues concerns the nature of critique, often replaying debates over (what can be crudely termed) universalism and relativism, where modernism is seen to represent the former and postmodernity the latter. Seyla Benhabib (1995) and Judith Butler (1995) pursue this debate in relation to feminist politics, Benhabib arguing that postmodern critique comprises three main elements; an anti-foundationalist concept of the subject and identity, the death of history and of notions of teleology and progress, and the death of metaphysics defined as the search for objective truth. Benhabib argues forcefully against these critical positions, holding that they undermine the bases upon which feminist politics can be founded, removing the possibility of agency, the sense of self-hood and the appropriation of women’s history in the name of an emancipated future. The denial of normative ideals removes the possibility for utopia, central for ethical thinking and democratic action.\n\nButler responds to Benhabib by arguing that her use of postmodernism is an expression of a wider paranoia over anti-foundationalist philosophy, in particular, poststructuralism.\n\nButler uses the debate over the nature of the post-modernist critique to demonstrate how philosophy is implicated in power relationships and defends poststructuralist critique by arguing that the critique of the subject itself is the beginning of analysis, not the end, because the first task of enquiry is the questioning of accepted \"universal\" and \"objective\" norms.\n\nThe Benhabib-Butler debate demonstrates that there is no simple definition of a postmodern theorist as the very definition of postmodernity itself is contested. Michel Foucault rejected the label of postmodernism explicitly in interviews yet is seen by many, such as Benhabib, as advocating a form of critique that is \"postmodern\" in that it breaks with utopian and transcendental \"modern\" critiques by calling universal norms of the Enlightenment into question. Giddens (1990) rejects this characterisation of \"modern critique\", pointing out that a critique of Enlightenment universals was central to philosophers of the modern period, most notably Nietzsche.\n\nJameson views a number of phenomena as distinguishing postmodernity from modernity. He speaks of \"a new kind of superficiality\" or \"depthlessness\" in which models that once explained people and things in terms of an \"inside\" and an \"outside\" (such as hermeneutics, the dialectic, Freudian repression, the existentialist distinction between authenticity and inauthenticity, and the semiotic distinction of signifier and signified) have been rejected.\n\nSecond is a rejection of the modernist \"Utopian gesture\", evident in Van Gogh, of the transformation through art of misery into beauty whereas in the postmodernism movement the object world has undergone a \"fundamental mutation\" so that it has \"now become a set of texts or simulacra\" (Jameson 1993:38). Whereas modernist art sought to redeem and sacralize the world, to give life to world (we might say, following Graff, to give the world back the enchantment that science and the decline of religion had taken away from it), postmodernist art bestows upon the world a \"deathly quality… whose glacéd X-ray elegance mortifies the reified eye of the viewer in a way that would seem to have nothing to do with death or the death obsession or the death anxiety on the level of content\" (ibid.). Graff sees the origins of this transformative mission of art in an attempted substitution of art for religion in giving meaning to the world that the rise of science and Enlightenment rationality had removed – but in the postmodern period this is seen as futile.\n\nThe third feature of the postmodern age that Jameson identifies is the \"waning of affect\" – not that all emotion has disappeared from the postmodern age but that it lacks a particular kind of emotion such as that found in \"Rimbaud's magical flowers 'that look back at you'\". He notes that \"pastiche eclipses parody\" as \"the increasing unavailability of the personal style\" leads to pastiche becoming a universal practice.\n\nJameson argues that distance \"has been abolished\" in postmodernity, that we \"are submerged in its henceforth filled and suffused volumes to the point where our now postmodern bodies are bereft of spatial co-ordinates\". This \"new global space\" constitutes postmodernity's \"moment of truth\". The various other features of the postmodern that he identifies \"can all now be seen as themselves partial (yet constitutive) aspects of the same general spatial object\". The postmodern era has seen a change in the social function of culture. He identifies culture in the modern age as having had a property of \"semi-autonomy\", with an \"existence… above the practical world of the existent\" but, in the postmodern age, culture has been deprived of this autonomy, the cultural has expanded to consume the entire social realm so that all becomes \"cultural\". \"Critical distance\", the assumption that culture can be positioned outside \"the massive Being of capital\" upon which left-wing theories of cultural politics are dependent, has become outmoded. The \"prodigious new expansion of multinational capital ends up penetrating and colonizing those very pre-capitalist enclaves (Nature and the Unconscious) which offered extraterritorial and Archimedean footholds for critical effectivity\". (Jameson 1993:54)\n\n can be said to focus on conditions of life which became increasingly prevalent in the late 20th century in the most industrialized nations, including the ubiquity of mass media and mass production, the rise of a global economy and a shift from manufacturing to service economies. Jameson and Harvey described it as consumerism, where manufacturing, distribution and dissemination have become exceptionally inexpensive but social connectedness and community have become rarer. Other thinkers assert that postmodernity is the natural reaction to mass broadcasting in a society conditioned to mass production and mass politics. The work of Alasdair MacIntyre informs the versions of postmodernism elaborated by such authors as Murphy (2003) and Bielskis (2005), for whom MacIntyre's postmodern revision of Aristotelianism poses a challenge to the kind of consumerist ideology that now promotes capital accumulation.\n\nThe sociological view of postmodernity ascribes it to more rapid transportation, wider communication and the ability to abandon standardization of mass production, leading to a system which values a wider range of capital than previously and allows value to be stored in a greater variety of forms. Harvey argues that postmodernity is an escape from \"Fordism\", a term coined by Antonio Gramsci to describe the mode of industrial regulation and accumulation which prevailed during the Keynesian era of economic policy in OECD countries from the early 1930s to the 1970s. Fordism for Harvey is associated with Keynesianism in that the first concerns methods of production and capital-labor relations while the latter concerns economic policy and regulation. Post-fordism is therefore one of the basic aspects of postmodernity from Harvey's point of view.\n\nArtifacts of postmodernity include the dominance of television and popular culture, the wide accessibility of information and mass telecommunications. Postmodernity also exhibits a greater resistance to making sacrifices in the name of progress discernible in environmentalism and the growing importance of the anti-war movement. Postmodernity in the industrialised core is marked by increasing focus on civil rights and equal opportunity as well as movements such as feminism and multiculturalism and the backlash against these movements. The postmodern political sphere is marked by multiple arenas and possibilities of citizenship and political action concerning various forms of struggle against oppression or alienation (in collectives defined by sex or ethnicity) while the modernist political arena remains restricted to class struggle.\n\nTheorists such as Michel Maffesoli believe that postmodernity is corroding the circumstances that provide for its subsistence and will eventually result in a decline of individualism and the birth of a new neo-Tribal era.\n\nAccording to theories of postmodernity, economic and technological conditions of our age have given rise to a decentralized, media-dominated society in which ideas are only simulacra, inter-referential representations and copies of each other with no real, original, stable or objective source of communication and meaning. Globalization, brought on by innovations in communication, manufacturing and transportation, is often cited as one force which has driven the decentralized modern life, creating a culturally pluralistic and interconnected global society lacking any single dominant center of political power, communication or intellectual production. The postmodernist view is that inter-subjective, not objective, knowledge will be the dominant form of discourse under such conditions and that ubiquity of dissemination fundamentally alters the relationship between reader and that which is read, between observer and the observed, between those who consume and those who produce.\n\nIn \"Spaces of Hope\" Harvey argues that postmodern political movements have been indirectly responsible for weakening class issues (in the Marxist sense) and the critical consciousness of this field of action which, in his opinion, is now more significant than during the Fordist period. For Harvey this class conflict is far from solved (something postmodern theorists ignore, according to his argument): globalization has made it more difficult for labour organisations to tackle underpaid work in poor conditions without labour rights and the amount of surplus value earned by corporations is far larger because of the differential between the high prices paid by western consumers and the low wages earned by south-east Asian labourers.\n\nAnother conceptualization has argued that postmodernity might be best described within the framework of epistemological shifts. This argument presupposes that epistemological shifts occur as a result of changes in culture, society, and technology and suggests that the political, cultural, and technological changes of the 1960s and 1970s stimulated an epistemological shift from modernity to postmodernity. Or said differently, the ways in which people communicate, receive, and justify knowledge (i.e. epistemology) change and these changes are argued to broadly influence cultures, worldviews, and people groups. [See French (2016), French & Ehrman (2016), or Sørensen (2007).\n\nCriticisms of the postmodern condition can broadly be put into four categories: criticisms of postmodernity from the perspective of those who reject modernism and its offshoots, criticisms from supporters of modernism who believe that postmodernity lacks crucial characteristics of the modern project, critics from within postmodernity who seek reform or change based on their understanding of postmodernism, and those who believe that postmodernity is a passing, and not a growing, phase in social organization.\n\n\n\n\n"}
{"id": "1499508", "url": "https://en.wikipedia.org/wiki?curid=1499508", "title": "Pre-Adamite", "text": "Pre-Adamite\n\nThe pre-Adamite hypothesis or pre-adamism is the theological belief that humans (or intelligent yet non-human creatures) existed before the biblical character Adam. Pre-adamism is therefore distinct from the conventional Jewish, Christian or Muslim belief that Adam was the first human. Advocates of this hypothesis are known as \"pre-Adamites\", along with the humans who they believe existed before Adam.\n\nSt. Augustine's \"The City of God\" contains two chapters indicating a debate between Christians and pagans over human origins: Book XII, chapter 10 is titled \"Of the falseness of the history that the world hath continued many thousand years\" and the title of book XVIII, chapter 40 is \"The Egyptians' abominable lyings, to claim their wisdom the age of 100,000 years\". The titles indicate that Augustine saw pagan ideas concerning both the history of the world and the chronology of the human race as incompatible with the Genesis creation narrative. Augustine’s position on this matter was supported by most rabbis and by the church fathers, who generally dismissed views on the antiquity of the world as myths and fables not requiring any considered refutation.\n\nIn early Islam, a common belief held that mankind is actually the successor of other intelligent creatures such as Jinn and Hinn. Medieval Muslim traditions often referred to the Jinn as \"pre-Adamites\", depicted as human-like in various ways. Although the notion of Jinn as pre-adamites was generally accepted, the idea that before the known Adam there lived other humans was a controversial one. From the mid-ninth century onwards the idea appeared, that God created several Adams each of whom presides over an era lasting around 50.000 years. Although these conceptions was regarded as heretic by most Muslims, it was widely accepted by Ismailis and Sufis. \n\nA book titled \"Nabatean Agriculture\", written or translated by Ibn Wahshiyya in 904, collated texts about the activities and beliefs of Arabic groups such as the Nabataeans, in defence of Babylonian culture against Islam. The book discussed the ideas that people lived before Adam, that he had parents, and that he came from India.\n\nThe Jewish poet Yehuda Halevi wrote his Kitab al Khazari between 1130 and 1140, featuring a discussion where the King of the Khazars questioned three theologians (a Jewish rabbi, a Christian, and a Muslim) which was the true religion, and raised the challenge that people in India said they had buildings and antiquities which were millions of years old. The rabbi responded that his faith was unshaken, as the Indians lacked \"a fixed form of religion, or a book concerning which a multitude of people held the same opinion, and in which no historical discrepancy could be found.\" The rabbi dismissed Indians as dissolute, unreliable people, whose claims could be ignored. Later in the book, Halevi rejected the \"Nabatean\" claims as these people did not know of the revelation in Scripture, and he dismissed Greek theories of an eternal world. In his conclusion, Halevi maintained that Adam was the first human in this world but left open other possibilities: \"If, after all, a believer in the Law finds himself compelled to admit an eternal matter and the existence of many worlds prior to this one, this would not impair his belief that this world was created at a certain epoch, and that Adam and Noah were the first human beings.\"\n\nThe claims in \"Nabatean Agriculture\" were also disputed by Maimonides (1135–1204) in \"The Guide for the Perplexed\". He attributed the concepts to the Sabians and said they were just legends and mythology which deviated from monotheism though drawing on Jewish sources, but in refuting the speculations, he circulated an outline of the ideas among other scholars: \"They deem \"Adam\" to have been an individual born of male and female like any other human individuals, but they glorify him and say that he was a prophet, the envoy of the moon, who called people to worship the moon. and there are compilations of his on how to cultivate the soil.\" He noted the claim that Adam came from India, and went on to Babylon.\n\nThe presence of a belief in the existence of men before Adam among the Familists, a religious community in Friesland, was noted by John Rogers in 1578.\n\nIn 1591, Giordano Bruno argued that, because no one could imagine that the Jews and the Ethiopians had the same ancestry, God must have either created separate Adams or that Africans were the descendants of pre-Adamic races.\n\nThe 17th-century French millenarian Isaac La Peyrère, because of his influence on subsequent thinkers and movements, is usually credited with formulating the pre-Adamite theory. In his \"Prae-Adamitae\", published in Latin in 1655, La Peyrère argued that Paul's words in should be interpreted to mean that \"if Adam sinned in a morally meaningful sense there must have been an Adamic law according to which he sinned. If law began with Adam, there must have been a lawless world before Adam, containing people.\" Thus, according to La Peyrère, there must have been two creations; first the creation of the Gentiles and then the creation of Adam, who was the father of the Hebrews. The existence of pre-Adamites, La Peyrère argued, explained Cain's taking of a wife and the building of a city after Abel's murder in the Book of Genesis. This account of human origins became the basis for 19th century theories of polygenism and modern racism.\n\nSome date the origins of the racial theory precisely to 24 April 1684, when François Bernier distinguished four or five races (with no hierarchical distinction between them) in an article titled (\"A new division of the Earth, according to the different species or races of men who inhabit it\") published in the \"Journal des sçavans\". Because of widespread theological opposition to the pre-Adamite theories of his friend La Peyrère, Bernier published his paper anonymously.\n\nDuring the Age of Enlightenment, pre-Adamism was adopted widely as a challenge to the biblical account of human origins. In the 19th century, the idea was welcomed by advocates of white superiority. A number of racist interpretive frameworks involving the early chapters of Genesis arose from pre-Adamism. Some pre-Adamite theorists held the view that Cain left his family for an inferior tribe described variously as \"white Mongols\" or that Cain took a wife from one of the inferior pre-Adamic peoples.\n\nVarious Sufis, especially Sultan Bahu, a famous 17th-century mystic of the Qadiriyya, a Sufi order, advocated this theory. In one of his writings, he wrote, \"Once God said to the Prophet \"O Muhammad I created an Adam before I created your father Adam, whom I gave a life of thousand years. Then I created fifteen thousand Adams all of whom I gave a life of ten thousand years. After that I created your Adam.\"\n\nAccording to that statement, the pre-Adamic era lasted for 150,100,000 years.\n\nIn 19th century Europe, pre-Adamism was attractive to those intent on demonstrating the inferiority of non-Western peoples, and in the United States, it appealed to those attuned to racial theories who found it unattractive to contemplate a common history with non-whites.\n\nScientists such as Charles Caldwell, Josiah C. Nott and Samuel G. Morton rejected the view that non-whites were the descendants of Adam. Morton combined pre-Adamism with cranial measurements. As Michael Barkun explains:\nIn 1860, Isabella Duncan wrote \"Pre-Adamite Man, Or, The Story of Our Old Planet and Its Inhabitants, Told by Scripture & Science\", a mixture of geology and scriptural interpretation. The book was popular among a number of geologists because it mixed biblical events with science. She suggested that the pre-Adamites are today's angels. Since they were without sin, for sin did not enter the world until Adam disobeyed God, there was no reason for them not to have been at least raptured into heaven, anticipating what would again occur with the second coming of Jesus Christ. Duncan also believed that some angels had sinned and fallen from Heaven, which caused them to become demons. Duncan supposed that such an upheaval would leave geological scars on the earth. The concept of ice ages, pioneered by Louis Agassiz, seemed to provide evidence of such events, drawing the line between the pre-Adamic era and the modern one, which she posited began about 6,000 years ago.\n\nFollowing the American Civil War, Southerners were increasingly receptive to arguments that supported their belief in black inferiority. In 1867, Buckner H. Payne, under the pen name Ariel, wrote a pamphlet, \"The Negro: What is His Ethnological Status?\" He argued that the Negro is a pre-Adamic beast of the field (specifically, a higher order of monkey), which was preserved on Noah's Ark. In 1891, William Campbell, under the pen name \"Caucasian\", wrote in \"Anthropology for the People: A Refutation of the Theory of the Adamic Origin of All Races\" that the non-white peoples were not descendants of Adam and therefore \"not brothers in any proper sense of the term, but inferior creations\" and that polygenism was the \"only theory reconcilable with scripture.\"\n\nFollowing Payne, Campbell viewed the Great Flood as a consequence of intermarriage between the white (Adamic) and nonwhite (pre-Adamic) peoples \"the only union we can think of that is reasonable and sufficient to account for the corruption of the world and the consequent judgement.\"\n\nLester A Hoyle wrote a book in 1875, \"The Pre-Adamite, or who tempted Eve?\" He claimed that there had been five distinct creations of races, and only the fifth, the white race, of which Adam was the father, had been made in God’s own image and likeness.\n\nIn an unusual blend of contemporary evolutionary thinking and pre-Adamism, the Vanderbilt University theistic evolutionist and geologist Alexander Winchell argued in his 1878 tract, \"Adamites and Preadamites\", for the pre-Adamic origins of the human race, on the basis that the Negroes were too racially inferior to have developed from the Biblical Adam. Winchell also believed that the laws of evolution operated according to the will of God.\n\nThe Irish lawyer Dominick McCausland, a Biblical literalist and anti-Darwinian polemicist, maintained the theory to uphold the Mosaic timescale. He held that the Chinese were descended from Cain and that the \"Caucasian\" race would eventually exterminate all others. He maintained that only the \"Caucasian\" descendants of Adam were capable of creating civilisation, and he tried to explain away the numerous non-\"Caucasian\" civilisations by attributing them all to a vanished \"Caucasian\" race, the Hamites.\n\nIn 1900, Charles Carroll wrote \"The Negro a Beast; or, In the Image of God\". He concludes in the book that the white race was made in the image and likeness of God and that Adam gave birth to only the white race, and Negros are pre-Adamite beasts, who could not possibly have been made in God's image and likeness because they are beastlike, immoral and ugly. Carroll claimed that the pre-Adamite races, such as blacks, did not have souls. Carroll believed that race mixing was an insult to God and spoiled God's racial plan of creation. According to Carroll, the mixing of races had also led to the errors of atheism and evolution.\n\nThe Scottish millennialist George Dickison wrote \"The Mosaic Account of Creation, As Unfolded in Genesis, Verified by Science\" in 1902. The book mixed science with a scientifically enhanced reading of Genesis and lists geological discoveries that showed that men existed before Adam had been created and that Earth was much older than the 6000-year-old span of the Adamic race. Dickison welcomed scientific discoveries from fossil evidence and the palaontological record and used them as evidence for pre-Adamism.\n\nAllan Kardec, the founder of Spiritualism taught polygenism and that the earth was populated \"from time immemorial\" and that the Adamic race has \"pushed all other races forward\".\n\nThe doctrine known as British Israelism, which developed in England in the 19th century, also sometimes included a pre-Adamic worldview but that was a minority position. The model viewed pre-Adamites as a race of inferior bestial creatures apart from Adam, who was the first white man and consequently the first son of God. In the narrative, Satan seduces Eve, and the resulting offspring is a hybrid creature, Cain. Later, Cain flees to East Turkestan to establish a colony of followers intent on realizing the Devil’s plan for domination of the earth. A further elaboration of this myth involved the identification of the Jews with the Canaanites, the putative descendants of Cain, but the eponymous ancestor of the Canaanites is not Cain but Canaan. It followed that if the tribes of Judah were supposed to have intermarried with Cain’s descendants, the Jews were both the offspring of Satan and the descendents of sundry nonwhite pre-Adamic races.\n\nIn the United States, British Israelism developed into the aggressively anti-Semitic Christian Identity movement in which the Jews were \"mongrelized\" serpent seed.\n\nNon-racist pre-Adamism can be traced back to Paschal Beverly Randolph, an occultist. Paschal was of Malagasy and Native American ancestry and was a spokesman against slavery. Paschal believed in Pre-Adamism and wrote \"Pre-Adamite Man: Demonstrating The Existence of the Human Race Upon the Earth 100,000 Thousand Years Ago!\" under the name Griffin Lee in 1863. The book was a unique contribution towards pre-Adamism because it was not based on only biblical grounds. Randolph used a wide range of sources to write his book from many different world traditions, esoterica and ancient religions. In the book, Paschal claims that Adam was not the first man and that pre-Adamite men existed on all continents around the globe 35,000 to 100,000 years ago. His book is different from many of the other writings by other pre-Adamite authors because Randolph claimed that the pre-Adamites were civilised men, but other pre-Adamite authors argued that the pre-Adamites were beasts or (not fully human) hominids.\n\nPre-Adamite theories have also been held by a number of mainstream Christians such as the Congregational evangelist R. A. Torrey (1856–1928), who believed in the Gap Theory and that pre-Adamites had survived into the present day.\n\nGleason Archer was a believer in pre-Adamism. He wrote in his 1985 book, \"A Survey of Old Testament Introduction\", \"To revert to the problem of the Pithecanthropus, the Swanscombe man, the Neanderthal and all the rest (possibly even the Cro-magnon man, who is apparently to be classed as \"Homo sapiens\", but whose remains seem to date back at least to 20,000 B.C.) it seems best to regard these races as all prior to Adam’s time, and not involved in the Adamic covenant. We must leave the question open, in view of the cultural remains, whether these pre-Adamic creatures had souls (or, to use the trichotomic terminology, spirits).\" \n\nGleason went on to assert that only Adam and his descendants were infused with the breath of God and a spiritual nature corresponding to God himself, and he said that all mankind subsequent to Adam’s time must have been literally descended from him. However, he retains the concept of pre-Adamic races (such as the Cro-Magnon man), and says: \"They may have been exterminated by God for unknown reasons prior to the creation of the original parent of the present human race\".\n\nMore recently, such ideas have been promoted by Kathryn Kuhlman and Derek Prince among Pentecostals, John Stott among Anglicans, and Old Earth creationist Hugh Ross.\n\nImmanuel Velikovsky was a believer in pre-Adamism. He wrote \"In the Beginning\". In the book, Velikovsky describes catastrophes that had occurred before those described in his first book, \"Worlds in Collision\". In the first section, his chapter \"The Pre-Adamite Age\" discusses pre-Adamism. He wrote that the \"talmudic-rabbinical tradition believed that before Adam was created, the world was more than once inhabited and more than once destroyed.\" Moreover, he wrote that according to the evidence from many different traditions, Adam and Eve were not a single human pair and there must have been many of them.\n\n"}
{"id": "2541498", "url": "https://en.wikipedia.org/wiki?curid=2541498", "title": "Public history", "text": "Public history\n\nPublic history is a broad range of activities undertaken by people with some training in the discipline of history who are generally working outside of specialized academic settings. Public history practice is deeply rooted in the areas of historic preservation, archival science, oral history, museum curatorship, and other related fields. The field has become increasingly professionalized in the United States and Canada since the late 1970s. Some of the most common settings for the practice of public history are museums, historic homes and historic sites, parks, battlefields, archives, film and television companies, and all levels of government.\n\nBecause it incorporates a wide range of practices and takes place in many different settings, public history proves resistant to being precisely defined. Four key elements often emerge from the discourse of those who identify themselves as public historians:\n\nThese elements are expressed in the 1989 mission statement of the U.S.-based National Council on Public History: \"To promote the utility of history in social through professional practice.\". They are also present in a definition drafted by the NCPH board in 2007, stating, \"Public history is a movement, methodology, and approach that promotes the collaborative study and practice of history; its practitioners embrace a mission to make their special insights accessible and useful to the public.\" However, this draft definition prompted some challenges on the H-Public listserv from people in the field, who raised questions about whether public history is solely an endeavor by professional or trained historians, or if shared historical authority should be a key element of the field. Others have pointed out that the existence of many \"publics\" for public history complicates the task of definition. For example, historian Peter Novick has questioned whether much of what is termed public history should actually be called \"private\" history (for example, the creation of corporate histories or archives) or \"popular\" history (for example, research or exhibits conducted outside the norms of the historical discipline). Cathy Stanton has also identified a more radical element in North American public history but has asked: 'how much room is there for the progressive component in the public history movement?' Hilda Kean and Paul Ashton have also discussed the differences in public history in Britain, Australia, New Zealand and the U.S., arguing against 'a rigid demarcation between \"historians\" and \"their publics\"'. A 2008 survey of almost 4,000 practitioners predominantly in the U.S. showed that a substantial proportion (almost one quarter of respondents) expressed some reservations about the term and whether it applied to their own work.\n\nIn general, those who embrace the term \"public historian\" accept that the boundaries of the field are flexible. Its definition remains a work in progress, subject to continual re-evaluation of practitioners' relationships with different audiences, goals, and political, economic, or cultural settings.\n\nPublic history refers to a wide variety of professional and academic fields. Some of these include:\n\nIn addition, a sub-field of scholarly study has developed over the past several decades which focuses on the history and theory of collective memory and history-making. This body of scholarship (typified by the winners of the National Council on Public History Book Award) may also be considered to be \"public history.\"\n\nPublic history has many antecedents. These include history museums, historical societies, public and private archives and collections, hereditary and memorial associations, preservation organizations, historical and heritage projects and offices within government agencies, and depictions of history in popular culture of all kinds (for example, historical fiction). Ludmilla Jordanova has also observed that 'the state... lies at the heart of public history', linking public history to the rise of the nation state. (English Theologian William Paley declared in 1794 that 'public history' was a 'register of the successes and disappointments... and the quarrels of those who engage in contentions [for] power'.) In the late nineteenth and early twentieth centuries, a distinct historical discipline formed within Western universities, and this had the effect of gradually separating scholars who practiced history professionally from amateur or public practitioners. While there continued to be trained historians working in public settings, there was a general retreat from public engagement among professional historians by the middle decades of the twentieth century.\n\nDuring the 1970s, a number of political, economic, social, and historiographical developments worked to reverse this trend, converging to produce a new field that explicitly identified itself as “public history”. The social justice movements of the 1960s and 1970s had sparked an interest in the histories of non-dominant people and groups—for example, women, working-class people, ethnic and racial minorities—rather than the “great men” who had traditionally been the focus of many historical narratives. In Britain, this emerged through the History Workshop Movement. Many historians embraced social history as a subject, and some were eager to become involved in public projects as a way of using their scholarship in activist or public-oriented ways. In the U.S., a severe shortage of academic jobs for historians led many to consider careers outside the academy. At the same time, publicly funded efforts were underway in many Western countries, ranging from national celebrations like the United States Bicentennial to multiculturalist projects in Australia and Canada, paralleled by widespread public interest in genealogy, the tracing of folk and family “roots”, and other history-related activities. In the wake of deindustrialization in many industrial places, governments also supported regeneration or revitalization projects that increasingly included the use of local history and culture as an attraction or a basis for “re-branding” a depressed area. Out of necessity, inclination, or both, a growing number of people with graduate training in history found employment in these kinds of non-academic settings. Public policy decisions like the passage of the U.S. National Historic Preservation Act of 1966 and the Canadian government's addition of “historical researcher” as a civil service category in the 1970s, along with the rise of cultural tourism and the increasing professionalization of many museums and historical societies, have spurred the growth of the field.\n\nIn the U.S., the birth of the public history field can be traced to the University of California, Santa Barbara, where Robert Kelley, a member of the history faculty, obtained a Rockefeller Foundation grant in 1976 to create a graduate program to train young historians for public and private sector careers. Kelley drew on his own extensive experience as a consultant and legal witness in water litigation cases in conceiving the idea of “public history” as a field in its own right. Conferences in Scottsdale, Arizona in 1978 and Montecito, California in 1979 helped to catalyze the new field. The launch of a professional journal, \"The Public Historian\", in 1978, and the founding of the National Council on Public History in 1979 further served to give public-minded historians in the academy and isolated practitioners outside of it a sense that they shared a set of missions, experiences, and methods.\n\nPublic history in Canada has followed a similar trajectory in many ways, including the experience of an academic “jobs crisis” in the 1970s and the importance of government as a source of employment for public historians. In 1983, the University of Waterloo created a Masters program in Public History (now defunct), followed by The University of Western Ontario in 1986, and Carleton University in 2002. Also as in the U.S., Canadian public funding for history and heritage projects has shrunk in the past two decades, with public historians increasingly accountable to funders for the effectiveness of their work. Public history also exists as an identifiable field in Australia and to a lesser extent in Europe and other places. In Latin America, public history finds its highest expression in Brazil, where public history is closely connected with social history and oral history. The Brazilian Public History Network, created in 2012, has been responsible for promoting publications and sponsoring events of national and international scope aimed to foster a creative and cosmopolitan dialogue. As in the U.S. and Canada, there are many public projects involving historians and the interpretation of history that do not necessarily claim the specific label “public history.” The International Federation for Public History,(IFPH-FIHP) was formed in 2010 and became an international association with elected Steering Committee in January 2012. IFPH is also a permanent Internal Commission of the International Committee of Historical Sciences (ICHS-CISH). The IFPH seeks to broaden international exchanges about the practice and teaching of public history and it is one of the constitutive co-operation partners of the journal \"Public History Weekly\".\n\nPublic history continues to develop and define itself. There are currently many graduate and undergraduate public history programs in the U.S., Canada, and other countries (see list and links below). The field has a natural synergy with digital history, with its emphasis on access and broad participation in the creation of historical knowledge. In recent years there has been a growing body of public historical scholarship, including works recognized by the annual NCPH Book Award. In several countries, studies have been conducted to explore how people understand and engage with the past, deepening public historians’ sense of how their own work can best connect with their audiences. While high-profile “history wars” have taken place over public exhibits and interpretations of history in many places in recent years (for example, Australia's ongoing debate over the history of colonisation and indigenous peoples, the furor over Jack Granatstein’s 1998 book “Who Killed Canadian History?”, or the 1994 controversy over the National Museum of American History's planned exhibit on the Enola Gay bomber), public historians tend to welcome these as opportunities to participate in vigorous public discussions over the meanings of the past, debating how people arrive at those meanings.\n\nAn evolving form of locally collected and publicly presented history, seen in projects like If This House Could Talk are a less critical and validated public presentation of history, yet offer engagement at the grass roots level that may encourage new forms of collecting history about the everyday.\n\nThe National Council on Public History's Robert Kelley Memorial Award, “honors distinguished and outstanding achievements by individuals, institutions, non-profit or corporate entities for having made significant inroads in making history relevant to individual lives of ordinary people outside of academia.” Its recipients reflect a broad mix of scholarly, governmental, and popular projects:\n\nAn extensive listing of undergraduate and graduate programs in public history in the U.S., Canada, and elsewhere, are on the National Council on Public History website.\n\n\n"}
{"id": "2644613", "url": "https://en.wikipedia.org/wiki?curid=2644613", "title": "Quantitative history", "text": "Quantitative history\n\nQuantitative history is an approach to historical research that makes use of quantitative, statistical and computer tools. It is considered a branch of \"social science history\" and has four leading journals: \"Historical Methods\" (1967- ), \"Journal of Interdisciplinary History\" (1968- ), the \"Social Science History\" (1976- ), and \"Cliodynamics: The Journal of Quantitative History and Cultural Evolution\" (2010- ).\n\nQuantitative historians start with databases. Large quantities of economic and demographic data are available in print format. Quantifiers move these into computerized databases. The largest repository is the Inter-university Consortium for Political and Social Research (ICPSR) at the University of Michigan, which provides access to an extensive collection of downloadable political and social data for the United States and the world.\n\nEconomic historians use major data sets, especially those collected by governments since the 1920s. Historians of slavery have used census data, sales receipts and price information to reconstruct the economic history of slavery.\n\n\"Content analysis\" is a technique borrowed from journalism research whereby newspapers, magazines or similar sources are numerically coded according to a standardized list of topics. [Neuendorf, \"The Content Analysis Guidebook\" (2002)]\n\nQuantifiers study topics like voting behavior of groups in elections, the roll call behavior of legislators, public opinion distribution, and the occurrence rate of wars and legislation. \"'Collective biography\" uses standardized information on a large group to deduce patterns of thought and behavior.\n\nThe \"new social historians\" (new in the 1960s) use census data and other data sets to study entire populations. Topics include demographic issues such as population growth rates, rates of birth, death, marriage and disease, occupational and education distributions, and migrations and population changes.\n\nAn especially challenging technique is linking names (\"nominal record linkage\") of the same person whose information appears in multiple source such as censuses, city directories, employment files and voting registration lists.\n\nCliodynamics employs a scientific approach to the study of history and combines insights from cultural evolution, macrosociology, and economic history/cliometrics to produce and analyse large quantitative datasets and identify general principles about the evolutionary dynamics and functioning of historical societies.\n\nIn 2007-2008, the most viewed articles in \"Social Science History\" represented the breadth and style of the field. The five most viewed were:\n\n\n\n\n\n"}
{"id": "24397942", "url": "https://en.wikipedia.org/wiki?curid=24397942", "title": "The Arctic Home in the Vedas", "text": "The Arctic Home in the Vedas\n\nThe Arctic Home in the Vedas is a book on the origin of Aryanic People by Bal Gangadhar Tilak, a mathematician turned astronomer, historian, journalist, philosopher and political leader of India. It propounded the idea that the North Pole was the original home of Aryans during the pre-glacial period which they had to leave due to the ice deluge around 8000 B.C. and had to migrate to the Northern parts of Europe and Asia in search of lands for new settlements. In support to his theory, Tilak presented certain Vedic hymns, Avestic passages, Vedic chronology and Vedic calendars with interpretations of the contents in detail.\n\nThe book was written at the end of 1898, but was first published in March 1903 in Pune.\n\nMan was believed to be post-glacial, and the theory of an Asiatic origin of the Aryan peoples prevailed. The age of the oldest Vedic period, however, was carried back to 4500 BC by scholars including the author himself after scientific astronomical research in correlation with the evidence found in the Vedic hymns.\n\nTilak cites a book by William F. Warren, the first President of Boston University, \"Paradise Found or the Cradle of the Human Race at the North Pole\", as having anticipated his ideas to some extent. Warren dedicated his book to Max Müller, with whom Tilak had shared ideas before the book was completed.\n\nTilak held the view that further study of Vedic hymns and Avestan passages might reveal the long vista of primitive Aryan antiquity.\n\n\n\nThe book has about 500 pages, containing a Preface by the Author and thirteen chapters.\n\n1) Vedic References\n\n2) Avestic References\n\n\"The Arctic Home in the Vedas\" has been cited in the works of Julius Evola, Savitri Devi, Rene Guenon, Jean Haudry and John G. Bennett. M.S. Golwalkar, in his 1939 publication \"We or Our Nationhood Defined\", famously stated that \"Undoubtedly [...] we — Hindus — have been in undisputed and undisturbed possession of this land for over eight or even ten thousand years before the land was invaded by any foreign race.\" Golwalkar was inspired by Tilak's \"The Arctic Home in the Vedas. Gowalkar took over the idea of 10,000 years, arguing that the North Pole at that time was located in India.\n\n\n"}
{"id": "17129718", "url": "https://en.wikipedia.org/wiki?curid=17129718", "title": "The Eastern Origins of Western Civilisation", "text": "The Eastern Origins of Western Civilisation\n\nThe Eastern Origins of Western Civilisation, written by John M. Hobson in 2004, is a book that argues against the historical theory of the rise of the West after 1492 as a \"virgin birth\", but rather as a product of Western interactions with more technically and socially advanced Eastern civilization.\n\nThe text reinterprets Eurocentric ideas of Europe's contributions to world development. For example, it provides evidence that a complex system of global trade existed long before Mercantilist Europe, that social and economic theories in the Enlightenment came from encounters with new cultures rather than with Greek and Roman heritage, and that modern European hegemony resulted from situational advantages rather than from inherent superior traits.\n\n\nA reviewer for the Culture Mandala wrote Hobson's work \"complements and builds on the insights of Frank, Braudel and others to illustrate in great detail both how substantial China's historical achievement has been and how much the West has distorted history to serve the purpose of its imperial civilizing mission\".\n\nJohn Hall of McGill University, writing in the English Historical Review, claims that Hobson's work is prone to wild exaggerations and \"tends to cite only those parts of an author’s work that agree with his argument, and misses out whole realms of scholarship\". Hobson, Hall continues, \"tends to give us bad sociology,\" and his construct of Eurocentrism is \"often a straw man.\" Generally, Hall remarks that Hobson makes \"odd claims,\" such as asserting that \"Adam Smith depended upon Chinese intellectual discoveries\". Hall claims that Hobson's \"general picture seems to fail\".\n\n\n"}
{"id": "9730490", "url": "https://en.wikipedia.org/wiki?curid=9730490", "title": "The Lost Tomb of Jesus", "text": "The Lost Tomb of Jesus\n\nThe Lost Tomb of Jesus is a documentary co-produced and first broadcast on the Discovery Channel and Vision TV in Canada on March 4, 2007, covering the discovery of the Talpiot Tomb. It was directed by Canadian documentary and film maker Simcha Jacobovici and produced by Felix Golubev and Ric Esther Bienstock, while James Cameron served as executive producer. (Jacobovici and Cameron had previously created \"The Exodus Decoded\".) The film was released in conjunction with a book about the same subject, \"The Jesus Family Tomb\", issued in late February 2007 and co-authored by Jacobovici and Charles R. Pellegrino. The documentary and book's claims are the subject of controversy within the archaeological and theological fields, as well as among linguistic and biblical scholars.\n\nThe film describes the finding of the Talpiot Tomb during a housing construction project, and posits that it was the family tomb of Jesus. The film states that ten ossuaries were found in the cave, of which six are the subject of the film. Further, it claims that one of the ten ossuaries went missing years ago, presumably stolen.\n\nThe excavation report for the predecessor of the Israel Antiquities Authority was written by Amos Kloner, now professor of archaeology at Israel's Bar-Ilan University. Kloner dissociated himself from the claims made in the documentary. He said it was incorrect to call it \"never before reported information\" and that he had published all the details in the journal \"Antiqot\" in 1996. He had not said it was the tomb of Jesus' family. \"I think it is very unserious [sic] work. I do scholarly work…,\" Kloner said. \"[This film] is all nonsense.\"\nSix of the nine remaining ossuaries bear inscriptions. \"The Lost Tomb of Jesus\" posits that three of those carry the names of figures from the New Testament. The meanings of the epigraphs are disputed. The makers of the documentary claim that four leading epigraphers have corroborated their interpretation of the inscriptions. As translated in \"The Lost Tomb of Jesus\" and \"The Jesus Family Tomb\", they read as follows:\n\n\nThe film further claims that the tenth ossuary, which went missing years ago, is the James Ossuary purported to contain the body of James, the brother of Jesus.\n\nIn \"The Jesus Family Tomb\", Simcha Jacobovici claims the James Ossuary would have been a part of this tomb, but was removed by artifact dealers, and thus discovered separately (citation needed). The James Ossuary's authenticity has been called into question, and Oded Golan, one of its past owners, was charged with fraud in connection to the artifact, but exonerated on all counts of forgery.\n\nBen Witherington III, who worked with Jacobovici on a Discovery Channel documentary on the James Ossuary, denies this connection on two grounds:\n\nAnother consideration was that the measurements of the James Ossuary did not match the measurements listed for the tenth ossuary, which is no longer stored with the rest of the collection. The James Ossuary was listed as being approximately 50 centimeters (19.6 inches) long by 30 centimeters (11.8 inches) wide on one end, and 25.5 centimeters (10 inches) on the other end (citation needed). The tenth ossuary in the Talpiot collection is listed as 60 centimeters (23.6 inches) long by 26 centimeters (10.2 inches) by 30 centimeters (11.8 inches) (citation needed). Furthermore, Amos Kloner has stated that the tenth ossuary had no inscription. Also, Joe Zias, former curator of the Rockefeller Museum who received and catalogued the ossuaries, refuted this claim on his personal site (citation needed).\n\nNew information has now shown that the discrepancy in the measurements had to do with measuring the base of the ossuary, which is indeed 50 centimeters (19.6 inches), rather than the length. The top length of the James Ossuary, not the base, which is trapezoidal in shape, according to the latest re-measurement carried out by the Israel Antiquities Authority, is 57.5 centimeters (22.6 inches.) (citation needed). While compelling, this does not prove that the James Ossuary is the missing tenth Talpiot ossuary.\n\nAnalysis of mitochondrial DNA performed by Lakehead University on the remains found in the ossuary marked \"Jesus son of Joseph\" and the one marked \"Mariamne\" or \"Mary\" (who some claim to be Mary Magdalene) found that the two occupants were not blood relations on their mothers' side. Based on these tests, the makers of the documentary suggest that \"Jesus\" and \"Mariamne\" were probably married \"because otherwise they would not have been buried together in a family tomb,\" but the remains were not dated using radiocarbon to further sustain this supposition, neither was any announced DNA testing done on the others ossuaries to see if any familial relation existed there. Additionally, scholars argue the DNA tests only prove that they did not have the same mother and they could easily have been father/daughter, cousins, half brother/sister, or any number of possibilities that do not include a matrilineage line.\n\nThe film proposes new interpretations of the events regarding Jesus depicted in the New Testament, as seen by mainstream Christianity. The film's suggestions contradict\nthe basis of the faith and may be considered blasphemous by Christians:\n\nThe claim that Jesus was married also undermines the theological metaphor of the Church being the \"Bride of Christ\" (found in the writings of the New Testament). Jimmy Akin, director of Apologetics and Evangelization at Catholic Answers, wrote: \"This image would never have arisen if there was a Mrs. Jesus living right there in Jerusalem…. We know about [the wives of religion founders] because they were honored figures as wives of The Founder, and if Jesus had a wife then (a) we would know about it and (b) the whole Church-as-the-Bride-of-Christ metaphor would never have come into existence.\" As for a possible \"son of Jesus,\" he noted: \"We tend to know about even the daughters of religious founders. Muhammad's daughter Fatima comes to mind. It would be much harder to sneak a forgotten son by the eyes of history…. It's not just hard to sneak sons past because patriarchal cultures focus more on sons; it's also because of this: In traditional societies, the son is looked on as the father's natural successor.\"\n\nThe filmmakers denied that the claims made in the film contradicted key teachings of Christianity, such as the resurrection and ascension. The film's religious consultant James Tabor stated that the fact that Jesus' tomb was discovered does not put in doubt biblical accounts of his resurrection, which he said could have been spiritual. With regard to the ascension, the documentary's website suggests that while the tomb's discovery does not render impossible the notion of a spiritual ascension, it does contradict the belief that Jesus physically ascended to heaven.\n\nFinding someone's remains in Jesus' tomb conforms to the Muslim belief that a substitute for him was crucified, while he was raised bodily to heaven. The Islamic view of his disappearance, as mentioned in the Qur'an, states: \"That they said (in boast), \"We killed Al-Masih 'Isa the son of Maryam, the Messenger of Allah\"; but they killed him not, nor crucified him, but so it was made to appear to them\". The general Muslim interpretation of the verse is that God, to revenge from Judas' betrayal to Jesus (the fatherless prophet), made his face similar to that of Jesus, while Jesus ascended into heaven and is to return near the end of time and kill the anti-Christ. Accordingly, the discovered remains in his tomb would then actually belong to Judas, a Roman guard, or a volunteering disciple.\n\nFollowing the March 4, 2007, airing of \"The Lost Tomb of Jesus\" on the Discovery Channel, American journalist Ted Koppel aired a program entitled \"The Lost Tomb of Jesus—A Critical Look\", whose guests included the director Simcha Jacobovici, James Tabor, Chair of the Department of Religious Studies at the University of North Carolina at Charlotte who served as a consultant and advisor on the documentary, Jonathan Reed, Professor of Religion at the University of LaVerne and co-author of \"Excavating Jesus Beneath the Stones, Behind the Text,\" and William Dever, an archaeologist with over 50 years experience in Middle Eastern archaeological digs.\n\nAlan Cooperman, writer of \"The Washington Post\" article also states this: \"Similar assessments came yesterday from two Israeli scholars, Amos Kloner, who originally excavated the tomb, and Joe Zias, former curator of archaeology at the Israeli Antiquities Authority. Kloner told the Jerusalem Post that the documentary is \"nonsense.\" Zias described it in an e-mail to \"The Washington Post\" as a \"hyped up film which is intellectually and scientifically dishonest.\"\n\nIsraeli archaeologist Amos Kloner, who was among the first to examine the tomb when it was first discovered, said the names marked on the coffins were very common at the time.\n\"I don't accept the news that it was used by Jesus or his family,\" and \"The documentary filmmakers are using it to sell their film.\" he told the BBC News website.\n\nDuring the documentary \"The Lost Tomb of Jesus\", various professionals had claimed:\n\n\nDuring Ted Koppel's critique, \"The Lost Tomb of Jesus—a Critical Look\", Koppel revealed he had denials from these three people that Simcha Jacobovici had misquoted in the documentary.\n\n\nThe archaeologist William Dever summed it up when he stated on Koppel's critical analysis, \"The Lost Tomb of Jesus—A Critical Look\", that Jacobovici's and Cameron's \"conclusions were already drawn in the beginning\" of the inquiry and that their \"argument goes far beyond any reasonable interpretation.\"\n\nThree skulls were found on the floor of the tomb in 1980 which the film makers assert was usual but others disagree: \"This too was decidedly not typical. In ancient Jerusalem, the dead were placed inside tombs; in tombs, the dead were placed inside ossuaries. If anything was left behind, it was a lamp or a bottle of perfume, not skulls.\"\n\nEarly Christianity scholar R. Joseph Hoffmann, chair of the Committee for the Scientific Examination of Religion, says the film alerts the public to the fact that there are no secure conclusions when it comes to the foundational history of a religious tradition. But he charges that the film \"is all about bad assumptions,\" beginning with the assumption that the boxes contain Jesus of Nazareth and his family. From his view as a historian specializing in the social history of earliest Christianity, he found it \"amazing how evidence falls into place when you begin with the conclusion—and a hammer.\"\n\nWhen interviewed about the upcoming documentary, Amos Kloner, who oversaw the original archaeological dig of this tomb in 1980 said:\n\n\"Newsweek\" reports that the archaeologist who personally numbered the ossuaries dismissed any potential connection:\n\nThe aforementioned Joe Zias has published in his own site a \"viewers' guide\" to the Talpiot Tomb documentary, in which he systematically rebuts the film's argumentation and gives much background information about the people involved in it.\n\nPfann also thinks the inscription read as \"Jesus\" has been misread and suggests that the name \"Hanun\" might be a more accurate rendering.\n\n\"The Washington Post\" reports that William G. Dever (mentioned above as excavating ancient sites in Israel for 50 years) offered the following:\n\nAsbury Theological Seminary's Ben Witherington III points out some other circumstantial problems with linking this tomb to Jesus' family:\n\nThe Archaeological Institute of America, self-described on their website as \"North America's oldest and largest organization devoted to the world of archeology,\" has published online their own criticism of the \"Jesus tomb\" claim: \n\"The identification of the Talpiyot tomb as the tomb of Jesus and his family is based on a string of problematic and unsubstantiated claims [...] [It] contradicts the canonical Gospel accounts of the death and burial of Jesus and the earliest Christian traditions about Jesus. This claim is also inconsistent with all of the available information—historical and archaeological—about how Jews in the time of Jesus buried their dead, and specifically the evidence we have about poor, non-Judean families like that of Jesus. It is a sensationalistic claim without any scientific basis or support.\"\n\nDarrell Bock, a New Testament scholar and research professor of New Testament studies at Dallas Theological Seminary points out some of the inconsistencies, including: \"If Jesus' family came from Galilee, why would they have a family tomb in Jerusalem?\"\n\nBen Witherington points out an inconsistency related to the James Ossuary. He points out that the James Ossuary came from Silwan, not Talpiot. In addition, the James Ossuary had dirt on it that \"matched up with the soil in that particular spot in Jerusalem.\" In his opinion, this is problematic, because \"the ossuaries that came out of Talpiot came out of a rock cave from a different place, and without such soil in it.\" Therefore, he believes that it is difficult to believe that the one known family member of Jesus was buried separately and far away from Jesus' family.\n\nIn addition, during the trial of antiquities dealer Oded Golan there has been testimony from former FBI agent Gerald Richard that a photo of the James ossuary, showing it in Golan's home, was taken in the 1970s, based on tests done by the FBI photo lab. This would make it impossible for the James Ossuary to have been discovered with the rest of the Talpiot ossuaries in the 1980s.\n\nWith reference to the DNA tests, Witherington wrote in his blog: \"[T]he most the DNA evidence can show is that several of these folks are interrelated…. We would need an independent control sample from some member of Jesus' family to confirm that these were members of Jesus' family. We do not have that at all.\" This quote clarifies the fact that the documentarians do not believe they have tested the DNA and have proven it to be Jesus. They simply used DNA testing to prove that the \"Jesus son of Joseph\" and the \"Mariamne\" in this tomb were not maternally related (i.e. that they did not have the same mother or grandmother). The film asserted that this DNA evidence suggests they were probably spouses. Critics contend they could have been paternally related (e.g. father and daughter, or grandfather and granddaughter), or related by someone else's marriage. Mariamne could just as well have been the wife of one of the other two males in the ossuary.\n\n\"The New York Times\" article of February 27, 2007, (reprinted in full on many websites) states:\nThe documentary's director and its driving force, Simcha Jacobovici…, said there was enough mitochondrial DNA for a laboratory in Ontario to conclude that the bodies in the \"Jesus\" and \"Mary Magdalene\" ossuaries were not related on their mothers' side. From this, Mr. Jacobovici deduced that they were a couple, because otherwise they would not have been buried together in a family tomb. In an interview, Mr. Jacobovici was asked why the filmmakers did not conduct DNA testing on the other ossuaries to determine whether the one inscribed Judah, son of Jesus was genetically related to either the Jesus or Mary Magdalene boxes; or whether the Jesus remains were actually the offspring of Mary. \"We're not scientists. At the end of the day we can't wait till every ossuary is tested for DNA,\" he said. \"We took the story that far. At some point you have to say, I've done my job as a journalist.\"\nIn the televised debate following the airing of the film, Ted Koppel pressed Jacobovici on the same question and received the same response. According to the authors of one blog, \"the response is manifestly disingenuous. The question, in fact, necessarily arises whether the team or one of its members decided not to proceed with any further DNA tests. Such tests may have revealed that none of the ossuaries are related—hence defeating the underlying presupposition that the crypt was in fact a family tomb, and thereby eliminating any valid basis at all for producing and showing the film.\"\n\nWilliam G. Dever said that some of the inscriptions on the ossuaries are unclear, but that all of the names are common. \"I've known about these ossuaries for many years and so have many other archaeologists, and none of us thought it was much of a story because these are rather common Jewish names from that period. It's a publicity stunt, and it will make these guys very rich, and it will upset millions of innocent people because they don't know enough to separate fact from fiction.\"\n\nJodi Magness, an archaeologist at the University of North Carolina-Chapel Hill, notes that at the time of Jesus, wealthy families buried their dead in tombs cut by hand from solid rock, putting the bones in niches in the walls and then, later, transferring them to ossuaries. \"If Jesus' family had been wealthy enough to afford a rock-cut tomb, it would have been in Nazareth, not Jerusalem,\" Magness writes.\n\nAccording to Magness, the names on the Talpiot ossuaries indicate that the tomb belonged to a family from Judea, the area around Jerusalem, where people were known by their first name and father's name. As Galileans, Jesus and his family members would have used their first name and hometown. \"This whole case (for the tomb of Jesus) is flawed from beginning to end.\"\n\nThere is no information on analyzing relation of \"Mary\" and \"Jesus son of Joseph\" or any other tomb occupants. In Jewish tradition of the time, after one year, when bodies in rock-cut tombs were decomposed, bones were collected, cleaned and then finally placed in an ossuary. Due to this conduct there is no real assurance that what scientists have really examined are remnants of \"Mariamne e Mara\" and \"Jesus son of Joseph.\"\n\nDavid Mavorah, a curator of the Israel Museum in Jerusalem, points out that the names on the ossuaries were extremely common. \"We know that Joseph, Jesus and Mariamne were all among the most common names of the period. To start with all these names being together in a single tomb and leap from there to say this is the tomb of Jesus is a little far-fetched, to put it politely.\" David Mavorah is an expert of Israeli Antiquity, and (presumably) not an expert of statistics. However, Andrey Feuerverger, the statistician cited by the makers of the documentary, has said that determination of the identity of those in the tomb was the purview of biblical historians, and not statisticians. For another interpretation of the statistics see the statistics section above.\n\nProfessor Amos Kloner, former Jerusalem district archaeologist of the Israel Antiquities Authority and the first archaeologist to examine the tomb in 1980, told the \"Yedioth Ahronoth\" newspaper that the name Jesus had been found 71 times in burial caves at around that time. Furthermore, he said that the inscription on the ossuary is not clear enough to ascertain, and although the idea fails to hold up by archaeological standards it makes for profitable television. Quote: \"The new evidence is not serious, and I do not accept that it is connected to the family of Jesus…. They just want to get money for it.\"\n\nRichard Bauckham, professor at the University of St Andrews, catalogued ossuary names from that region since 1980. He records that based on the catalogue, \"Jesus\" was the 6th most popular name of Jewish men, and \"Mary/Mariamne\" was the single most popular name of Jewish women at that time. Therefore, finding two ossuaries containing the names \"Jesus\" and \"Mary/Mariamne\" is not significant at all, and the chances of it being the ossuaries of Jesus and Mary Magdalene are \"very small indeed.\"\n\nConcerning the inscription attributed to Jesus son of Joseph, Steve Caruso, a professional Aramaic translator using a computer to visualize different interpretations, claims that although it is \"possible\" to read it as \"Yeshua\" that \"overall it is a very strong possibility that this inscription is not <nowiki>'</nowiki>\"Yeshua` bar Yehosef\".'\"\n\nThe name \"Mary\" and its derivatives may have been used by up to 25% of Jewish women at that time.\n\nLawrence E. Stager, the Dorot professor of archaeology of Israel at Harvard, said the documentary was \"exploiting the whole trend that caught on with \"The Da Vinci Code.\" One of the problems is there are so many biblically illiterate people around the world that they don't know what is real judicious assessment and what is what some of us in the field call 'fantastic archaeology.'\"\n\nWilliam G. Dever said, \"I'm not a Christian. I'm not a believer. I don't have a dog in this fight. I just think it's a shame the way this story is being hyped and manipulated.\"\n\nJodi Magness criticized the decision of the documentary makers to make their claims at a news conference rather than in a peer-reviewed scientific article. By going directly to the media, she said, the filmmakers \"have set it up as if it's a legitimate academic debate, when the vast majority of scholars who specialize in archeology of this period have flatly rejected this.\"\n\nJoe Zias, former curator of archeology at the Israeli Antiquities Authority, described it in an e-mail to \"The Washington Post\" as a \"hyped-up film which is intellectually and scientifically dishonest.\" He also wrote an extended Viewers Guide to Understanding the Talpiot Tomb documentary, published on his web site.\nFrançois Bovon has also written to say that his comments were misused. In a letter to the Society of Biblical Literature, he wrote:\n\nFollowing a symposium at Princeton in January 2008 media interest in the Talpiot tomb was reignited. \"Time\" and CNN devoted extensive coverage, implying that the case had been re-opened.\n\nScholars who had been present at the symposium then accused Jacobovici and Cameron of misleading the media in claiming the symposium reopened their theory as viable. Several scholars, including all the archaeologists and epigraphers, who delivered papers at the symposium issued an open letter of complaint claiming misrepresentation, saying that Jacobovici and Cameron's claims of support from the symposium are \"nothing further from the truth\".\n\nOn March 15, 2007, Discovery Channel released a DVD of the documentary with a listed running time of \"2 hours.\"\n\n\n\n\n"}
{"id": "1390457", "url": "https://en.wikipedia.org/wiki?curid=1390457", "title": "The Old Straight Track", "text": "The Old Straight Track\n\nThe Old Straight Track: Its Mounds, Beacons, Moats, Sites and Mark Stones is a book by Alfred Watkins, first published in 1925, describing the existence of alleged ley lines in Britain.\n\nWatkins presents a methodical and thorough exposition of his theories of ley lines, following an earlier much shorter publication, \"Early British Trackways\" (1922). The book has a preface, thirty chapters, four appendices and an index. There are many figures, and photographs taken by the author.\n\nThe book is considered the first book written about leys, and the first book to document and map alleged ley lines in Britain, primarily southern England.\n\nThe book was disregarded by archaeologists but saw a resurgence of interest with the rise of New Age ideas in the 1960s. Watkins' ideas also influenced contemporary psychogeography, including Iain Sinclair's \"Lud Heat\" (1975), which in turn influenced Peter Ackroyd's novel \"Hawksmoor\" (1985).\n\nWatkins' work met with early scepticism from archaeologists, one of whom, O. G. S. Crawford, refused to accept advertisements for \"The Old Straight Track\" in the journal \"Antiquity\". \n\nOne criticism of Watkins' ley line theory states that given the high density of historic and prehistoric sites in Britain and other parts of Europe, finding straight lines that \"connect\" sites is trivial and ascribable to coincidence. A statistical analysis of lines concluded: \"the density of archaeological sites in the British landscape is so great that a line drawn through virtually anywhere will 'clip' a number of sites.\" \n\nThe book was reprinted as on April 2, 1994 by \"Abacus\". Editions or reprints were published in 1925, 1933, 1945, 1948, 1970, 1974 and 1994. The Abacus edition of 1970 was reprinted up to 1999 at least, and carries a copyright dated 1970 \"Allen Watkins and Marion Watkins\".\n\n"}
{"id": "296021", "url": "https://en.wikipedia.org/wiki?curid=296021", "title": "Thirty Tyrants", "text": "Thirty Tyrants\n\nThe Thirty Tyrants (, \"hoi triákonta týrannoi\") were a pro-Spartan oligarchy installed in Athens after its defeat in the Peloponnesian War in 404 BC. Upon Lysander's request, the Thirty were elected as a government, not just as a legislative committee. The Thirty Tyrants maintained power for eight months. Though brief, their reign resulted in the killing of 5% of the Athenian population, the confiscation of citizens' property, and the exile of other democratic supporters. They became known as the \"Thirty Tyrants\" because of their cruel and oppressive tactics. The two leading members were Critias and Theramenes.\n\nWith Spartan support, the Thirty established an interim government in Athens. The Thirty were concerned with the revision and/or erasure of democratic laws inscribed on the wall next to the Stoa Basileios. Consequently, the Thirty reduced the rights of Athenian citizens in order to institute an oligarchical regime. The Thirty appointed a council of 500 to serve the judicial functions formerly belonging to all the citizens. However, not all Athenian men had their rights removed. In fact, the Thirty chose 3,000 Athenian men \"to share in the government\". These hand-selected individuals had the right to carry weapons, to have a jury trial, and to reside within city limits. The list of the selected 3,000 was consistently revised. Although little is known about these 3,000 men ‒ for a complete record was never documented ‒ it is hypothesised that the Thirty appointed these select few as the only men the Thirty could find who were devotedly loyal to their regime. The majority of Athenian citizens did not support the rule of the Thirty.\n\nLed by Critias, the Thirty Tyrants presided over a reign of terror in which they executed, murdered, and exiled hundreds of Athenians, seizing their possessions afterward. Both Isocrates and Aristotle (the latter in the \"Athenian Constitution\") have reported that the Thirty executed 1500 people without trial. Critias, a former pupil of Socrates, has been described as \"the first Robespierre\" because of his cruelty and inhumanity; he evidently aimed to end democracy, regardless of the human cost. The Thirty removed criminals as well as many ordinary citizens whom they considered \"unfriendly\" to the new regime for expressing support for the democracy. One of their targets was Theramenes, whom Critias believed to be a threat to the rule of the oligarchy. Critias accused Theramenes of conspiracy and treason, and then forced him to drink hemlock. Many wealthy citizens were executed simply so the oligarchs could confiscate their assets, which were then distributed among the Thirty and their supporters. They also hired 300 \"lash-bearers\" or whip-bearing men to intimidate Athenian citizens.\n\nThe Thirty's regime did not meet with much overt opposition, although many Athenians disliked the new form of government. Those who did not approve of the new laws could either fight ‒ and risk exile or execution ‒ or accept the Thirty's rule. Some supporters of democracy chose to fight and were exiled, among them Thrasybulus, a trierarch in the Athenian navy and noted supporter of democratic government. The uprising that overthrew the Thirty in 403 BC was orchestrated by a group of exiles led by Thrasybulus. Critias was killed in the initial revolt.\n\nThe Thirty Tyrants' brief reign was marred by violence and corruption. In fact, historians have argued that the violence and brutality the Thirty carried out in Athens was necessary to transition Athens from a democracy to an oligarchy. However, the violence produced an unanticipated paradox. The more violent the Thirty's regime became, the more opposition they faced. The increased level of opposition ultimately resulted in the upheaval of the Thirty's regime by Thrasybulus' rebel forces. After the revolution, Athens needed to decide the best way to govern the liberated city-state and to reconcile the atrocities committed by the Thirty. It was decided to give amnesty to all of the members of the selected 3,000, except for the Thirty themselves, the Eleven, and the ten who ruled in Piraeus. After the revolution that overthrew the Thirty Tyrants, Athens and her citizens struggled to reconcile and rebuild.\n\nPlato, in the opening portion of his \"Seventh Letter\", recounts the rule of the Thirty Tyrants during his youth. He explains that following the revolution, fifty-one men became rulers of a new government, with a specific group of thirty in charge of the public affairs of Athens. Ten of the fifty-one were to rule the city, and eleven were sent to rule Piraeus. Plato corroborates the general consensus found in other sources: the rule of the Thirty was \"reviled as it was by many\". The rule of the Thirty made the former democracy resemble a golden age in comparison. Plato also includes an account of the interaction between Socrates and the Thirty.\n\nIn \"The Republic\", Plato mentions Lysias, one of the men from Athens who escaped the Thirty's reign of terror. Lysias' brother Polemarchus \"fell victim to the Thirty Tyrants\".\n\nDue to their desire to remain in complete control over Athens, the Thirty sought to exile or kill anyone who outwardly opposed their regime. Socrates remained in the city through this period, which caused the public to associate him with the Thirty and may have contributed to his eventual death sentence, especially since Critias had been his student.\n\nIn Plato's \"Apology\", Socrates recounts an incident in which the Thirty once ordered him (and four other men) to bring before them Leon of Salamis, a man known for his justice and upright character, for execution. While the other four men obeyed, Socrates refused, not wanting to partake in the guilt of the executioners. However, he did not attempt to warn or save Leon of Salamis. By disobeying, Socrates may have been placing his own life in jeopardy, and he claimed it was only the disbanding of the oligarchy soon afterward that saved his life:\n\n\"When the oligarchy came into power, the Thirty Commissioners in their turn summoned me and four others to the Round Chamber and instructed us to go and fetch Leon of Salamis from his home for execution. This was of course only one of many instances in which they issued such instructions, their object being to implicate as many people as possible in their crimes. On this occasion, however, I again made it clear, not by my words but by my actions, that the attention I paid to death was zero (if that is not too unrefined a claim); but that I gave all my attention to avoiding doing anything unjust or unholy. Powerful as it was, that government did not terrify me into doing a wrong action. When we came out of the rotunda, the other four went to Salamis and arrested Leon, but I simply went home.\"\n\nLater on in his \"Seventh Letter\", Plato describes the interaction between the Thirty and Socrates from his own point of view: \"They tried to send a friend of mine, the aged Socrates, whom I should scarcely scruple to describe as the most upright man of that day, with some other persons to carry off one of the citizens by force to execution, in order that, whether he wished it, or not, he might share the guilt of their conduct; but he would not obey them, risking all consequences in preference to becoming a partner in their iniquitous deeds.\"\n\nThe Italian historian Luciano Canfora has inferred that another of Socrates' students, Xenophon, may have played an important part in the rule of the Thirty, as one of the two commanders of the cavalry, which were the Thirty's militia. Indeed, in his book \"Hipparchos\" (Commander of the cavalry), Xenophon only mentions one of the commanders (there were always two), only to revile him, but never mentions the other.\n\nIn Xenophon's \"Memorabilia\" (Bk 1, Ch 2), Xenophon also reports a contentious confrontation between Socrates and the Thirty, Critias included. Socrates is summoned before the group and ordered not to instruct or speak to anyone, whereupon Socrates mocks the order by asking whether he will be allowed to ask to buy food in the marketplace. Xenophon uses the episode to illustrate both Socrates' own critique of the slaughtering of Athenian citizens by the Thirty, as well as make the case that the relationship between Critias and Socrates had significantly deteriorated by the time Critias obtained power.\n\nThe names of the Thirty are listed by Xenophon:\n\n\n"}
{"id": "33926999", "url": "https://en.wikipedia.org/wiki?curid=33926999", "title": "Triadization", "text": "Triadization\n\nTriadization (or triadisation) is a proposed alternative to the theory of globalization. It states that political, economic and socio-cultural integration have been limited to three regions of the world: Japan and the newly industrialized countries of Southeast Asia, Western Europe and North America. \n\nOutside of these regions, according to the theory, the effects of so-called \"globalization\" have not been felt, and hence it cannot be truly called \"global\". Instead, the economic interdependence between the countries of the \"triad\" supposedly leads to the alienation of the developing world. This alienation is described by the theory as the result of the fact that \"fragmentation of the world into regional blocks is taking place, featured in the tendency to strengthen economic interdependence and transactions within them but not among them\". This further entrenches the position of the triad, and prevents the growth of the rest of the world.\n"}
{"id": "175075", "url": "https://en.wikipedia.org/wiki?curid=175075", "title": "Yuga", "text": "Yuga\n\nYuga in Hinduism is an epoch or era within a four-age cycle. A complete Yuga starts with the \"Satya Yuga\", via \"Treta Yuga\" and \"Dvapara Yuga\" into a \"Kali Yuga\". Our present time is a \"Kali Yuga\", which started at 3102 BCE with the end of the Kurukshetra War (or Mahabharata war).\n\nThere are four Yugas in one cycle:\n\n\nAccording to one Puranic astronomical estimate, the four Yuga have the following durations:\n\nTogether, these four yuga constitute one Mahayuga and equal 4.32 million human years. According to one version, there are 1,000 Mahayugas in one day of Brahma or 4.32 billion human years. A Mahakalpa consists of 100 years of Brahma.\n\nAccording to Srimad Bhagavatam 3.11.19, which most scholars agree was composed around 500 to 1000 CE, the Yugas are much longer, using a divine year in which one day is equal to one human year, thus:\nThe Viṣṇu Purāṇa Time measurement section of the Viṣṇu Purāṇa Book I Chapter III adds:\n\n\nWhile the long yuga count is the most popular, it does not correlate to any known celestial motion found in the Astronomical Almanac. The value of 24,000 years fits relatively close with the modern astronomical calculation of one full precession of the equinox, which takes 25,772 years. Thus the yuga cycle may have some basis in known terrestrial cycles. Srimad Bhagavatam 3.11.19 describes the timespans of the devas, in which a year of a yuga is a year of the demigods. It is this second sloka which appears to have been modified over the years.\n\nThe ages see a gradual decline of dharma, wisdom, knowledge, intellectual capability, life span, emotional and physical strength.\n\nIn the present days we may be said to live in a \"Kali Yuga\", which is said to have started in 3102 BCE with the end of the Mahabharata war. This date is also considered by many Hindus to be the day that Krishna left Earth and went to his abode.\n\n\n"}
