{"id": "54876824", "url": "https://en.wikipedia.org/wiki?curid=54876824", "title": "Aarhus Symposium", "text": "Aarhus Symposium\n\nAarhus Symposium is an annual leadership conference taking place at the University of Aarhus, Denmark, on the first Friday in November. The aim of the event is to connect leaders of today with leaders of tomorrow. To do so, a wide range of key decision-makers are invited to share their experiences and engage in discussions with students from various universities. Hereby, the symposium allows students to relate their academic insights to the broader business society.\n\nAarhus Symposium was founded in 2011 and has since expanded its concept to also involve Aarhus Symposium Focus and Aarhus Symposium Challenge.\n\nAarhus Symposium is a non-profit organisation, and all symposia are organised by voluntary students together with a pro-bono board of directors.\n\nFour students at Aarhus University established Aarhus Symposium in 2011: David Scherer, Jens Riis Andersen, Kasper Vinther Olesen, and Andreas Emmertsen. They gathered support from other students to organise the very first Aarhus Symposium with the objective of building a bridge between students, i.e. the future leaders, and leaders in today’s businesses and society.\n\nThe first annual Aarhus Symposium welcomed renowned speakers from the business society such as Carsten Bjerg (then CEO of Grundfos), Lars Rohde (then CEO of ATP), and Maria Rønn (CEO of Danmarks Radio). Throughout the years, the programme has extended to include prominent speakers such as His Royal Highness The Crown Prince of Denmark, Lars Rebien Sørensen (president and CEO of Novo Nordisk), and the Danish Prime Minister Lars Løkke Rasmussen.\n\nAarhus Symposium has grown through the years as a result of wide support from students, speakers, partners, and others. In 2012, the Organising Committee introduced Battle of the Economists; an event to take place on Monday in the week of Aarhus Symposium. It provided a national focus to the overall theme of Aarhus Symposium. The event was renamed Aarhus Symposium Focus in 2016 to broaden the possibilities for topics that exceed economic issues.\n\nIn 2013, Aarhus Symposium Challenge was established to strengthen the connection between students and the leaders of today. Aarhus Symposium Challenge is an essay competition in which selected speakers put forth a challenge for students to solve. Through their essay, students obtain a seat at both Aarhus Symposium and Aarhus Symposium Focus, and they potentially qualify for Leaders’ Forum. Since its initiation in 2013, an increasing number of students have participated in Aarhus Symposium Challenge, making it the primary sign-up for Aarhus Symposium and Aarhus Symposium Focus.\n\nAarhus Symposium takes place on the first Friday in November. Here, business executives and key decision-makers are invited to share their experiences and insights regarding a specific theme. They do so with different perspectives that reflect the tracks, i.e. subtopics, of the event.\n\n\"Formerly known as Battle of the Economists\"\n\nAarhus Symposium Focus is an annual conference which takes place on Monday in the week of Aarhus Symposium. Here, experts with various backgrounds are invited to share their thoughts on a topic related to the overall theme of Aarhus Symposium. The event provides a national focus as the topic strives to reflect one of Denmark’s most critical challenges.\n\nAarhus Symposium Challenge is an essay competition where selected speakers put forth a challenge for students to solve. By submitting a qualified essay, students obtain a seat at both Aarhus Symposium and Aarhus Symposium Focus. Additionally, the participating students compete for the Aarhus Symposium Award and a spot in Leaders’ Forum.\n\nLeaders’ Forum is an exclusive and intimate session where selected students discuss their essay contribution with the leader that put forth the respective challenge. Only the best essay contributions under each challenge topic qualifies for this informal session.\n\nThroughout the years, Leaders’ Forum has attracted much attention from the media inasmuch as it is unique in a Danish context and provides both the attending students and the top leaders the opportunity to learn from each other.\n\nThe most extraordinary essay contribution in Aarhus Symposium Challenge will be rewarded the Aarhus Symposium Award on stage at the very end of Aarhus Symposium. Prior winners of the Aarhus Symposium Award are:\nBesides facilitating Aarhus Symposium and Aarhus Symposium Focus, Aarhus Symposium also hosts a variety of other events that takes places at Aarhus University. Most notable are Aarhus Symposium Theme Announcement and Aarhus Symposium Challenge Launch; both of which are closely linked to the three key elements of Aarhus Symposium.\n\nThe Organising Committee of Aarhus Symposium consists of approximately 35 voluntary students, who have the responsibility for planning, funding, promoting, and executing all events. The Organising Committee is divided into smaller groups with specific focus areas:\n\n"}
{"id": "21188248", "url": "https://en.wikipedia.org/wiki?curid=21188248", "title": "Analog-to-digital timeline", "text": "Analog-to-digital timeline\n\nThis page serves as a timeline to show when analog devices were first made with digital circuits and systems.\n\n\n"}
{"id": "28986172", "url": "https://en.wikipedia.org/wiki?curid=28986172", "title": "Boutique Week", "text": "Boutique Week\n\nBoutique Week is a bi-annual shopping event in New York, Boston, Los Angeles, Chicago, and Miami. Boutique Week was launched in October 2010 in New York, Boston, and Los Angeles with over 40 boutiques participating in each city. Each of the participating boutiques offers their merchandise at a discount of at least 25% off during the selected week.\n\nBoutique Week is supported by local government in these cities as an effort to stimulate the economy and raise awareness for small local businesses.\n\nBoutique Week also raises money for Nancy Lublin's non-profit organisation Dress for Success, supplying women with interview suits and resources they need for success in today's workforce.\n\nBoutique Week was founded in July 2010 by Polina Raygorodskaya and Olga Vidisheva.\n\nPolina Raygorodskaya is the founder and president of Polina Fashion LLC. Formerly a top runway model, Raygorodskaya earned a BS degree in Business Administration at Babson College. Her entrepreneurial endeavors have been recognized by Fox Business Channel and LegalZoom. In 2007, Business Week named her as one of the \"Best 25 Entrepreneurs Under 25\".\n\nOlga Vidisheva is currently pursuing a Masters degree in Business Administration at Harvard Business School. Most recently, she worked for Chanel in their 'Fashion' and 'Fragrance and Beauté' marketing divisions.\n\n"}
{"id": "20261829", "url": "https://en.wikipedia.org/wiki?curid=20261829", "title": "Chronology of the Great Famine", "text": "Chronology of the Great Famine\n\nThe Chronology of the Great Famine ( or \"An Drochshaol\", litt: \"The Bad Life\") documents a period of Irish history between 1845 and 1852 during which time the population of Ireland was reduced by 20 to 25 percent. The proximate cause was famine resulting from a potato disease commonly known as late blight. Although blight ravaged potato crops throughout Europe during the 1840s, the impact and human cost in Irelandwhere a third of the population was entirely dependent on the potato for foodwas exacerbated by a host of political, social and economic factors which remain the subject of historical debate.\n\nAn important and controversial point of debate, that is notable amongst Irish people, was that Irish food supplies were sufficient until it was taken away by the British the feed the British, and the landlords kept economic benefits to themselves. Some commentators and writers controversially compared this explanation to \"genocide\".\n\nAt the beginning of August, Sir Robert Peel, the British Prime Minister, received news of a potato disease in the South of England. This was the first recorded evidence that the 'blight' which had ravaged the potato crop in North America in 1843-1844 had crossed the Atlantic. Cecil Woodham-Smith would write that a failure in England would be serious, but for Ireland, it would be a disaster.\n\nFollowing earlier reports of incidences of the blight in England, on 13 September 1845 potato blight was first reported in Ireland. The crops at Dublin were suddenly perishing, it was reported in the \"Gardeners' Chronicle\", asking \"where will Ireland be in the event of a universal potato rot?\" The British Government were nevertheless optimistic through the next few weeks.\n\n\nThe principle of the Corn Laws had been to keep the price of home-grown grain up. Duties on imported grain assured English farmers a minimum and profitable price. The burden of a higher price for bread was carried by the labouring classes, in particular factory workers and operatives. It was claimed that if the Corn Laws were repealed all those connected with the land would be ruined and the established social organisation of the country destroyed.\n\nAccording to Cecil Woodham-Smith, the rising wrath of Tories and landlords ensured \"all interest in Ireland was submerged.\" She writes that the Tory Mayor of Liverpool refused to call a meeting for the relief of Irish distress. She continues that the Mansion House Committee in Dublin was accused of 'deluding the public with a false alarm', and the blight itself 'was represented as the invention of agitators on the other side of the water'. The entanglement of the Irish famine with the repeal of the Corn Laws, she says, was a key misfortune for Ireland. The potato failure was eclipsed by the domestic issue of Corn Law repeal. The Irish famine, she writes, \"slipped into the background.\"\n\n\nThe first deaths from hunger took place in early 1846. In March Peel set up a programme of public works in Ireland but was forced to resign as Prime Minister on 29 June. The new Whig administration under Lord Russell, influenced by their laissez-faire belief that the market would provide the food needed then halted government food and relief works, leaving many hundreds of thousands of people without any work, money or food. Grain continued to be exported from the country. Private initiatives such as The Central Relief Committee of the Society of Friends (Quakers) attempted to fill the gap caused by the end of government relief and eventually the government reinstated the relief works, although bureaucracy slowed the release of food supplies. The blight almost totally destroyed the 1846 crop and the Famine worsened considerably. By December a third of a million destitute people were employed in public works.\n\nThere were average crop yields in the 1847 harvest, but due to lack of seed potatoes to plant, the crop was low. Crowds began to throng the public works during the last months of 1846 and the start of 1847, which promoted exactly the social conditions for the spread of 'famine fever.' In late January and February, legislation called the Temporary Relief Act went through the British parliament; it became popularly known as the Soup Kitchen Act and occasionally as Burgoyne's Act. This system of relief was designed to deliver cheap food directly and gratuitously to the destitute masses. This system of relief would be terminated in September. The government also announced an additional change in the system of relief. After August 1847, the permanent Poor Law was to be extended and was to become responsible for providing relief and as a result, all relief would be financed by the local Poor Law rates. This put impossible loads on local poor rates, particularly in the rural west and south. With the mass emigration of the famine era, the horrors of the 'coffin ships' and 1847 have ever since been associated in the popular mind, according to James S. Donnelly.\n\nIn December 1847 The Crime and Outrage Bill (Ireland) 1847 was enacted due to growing Irish nationalist agitation that was causing the British government concern about a possible violent rebellion against British rule in Ireland.\n\nThe bill gave the Lord Lieutenant of Ireland the power to organise the island into districts and bring police forces into them at the districts' expense. It limited who could own guns, and required all of the men in the district between the ages of 16 and 60 to assist in apprehending suspected murderers when landlords were killed, or else be guilty of a misdemeanour themselves.\n\nThe blight returned in 1848 and outbreaks of cholera were reported. Evictions became common among the Irish who could not keep up with the demands of their British landlords. Famine victims on outdoor relief peaked in July at almost 840,000 people. On 29 July an uprising against the government was led by William Smith O'Brien. After a skirmish at \"Widow McCormack's house\" in the village of Ballingarry, County Tipperary the leaders of the rebellion fled to America or were sentenced to transportation.\n\nThe potato crop failed again in 1849 and famine was accompanied by cholera outbreaks. This deadly cholera epidemic killed one of Ireland's greatest poets: James Clarence Mangan.\n\nThe Famine ended.\n\nBy 1851 census figures showed that the population of Ireland had fallen to 6,575,000 – a drop of 1,600,000 in ten years. Cormac Ó Gráda and Joel Mokyr have described the 1851 census as a famous but flawed source. They contend that the combination of institutional and individuals figures gives \"an incomplete and biased count\" of fatalities during the famine. The famine left in its wake up to a million dead and another million emigrated. The famine caused a sense of lasting bitterness by the Irish towards the British government, whom many blamed — then and now — for the starvation of so many people. The fall-out of the famine continued for decades afterwards.\n\n\n\n"}
{"id": "19167840", "url": "https://en.wikipedia.org/wiki?curid=19167840", "title": "Chronology of the universe", "text": "Chronology of the universe\n\nThe chronology of the universe describes the history and future of the universe according to Big Bang cosmology. The earliest stages of the universe's existence are estimated as taking place 13.8 billion years ago, with an uncertainty of around 21 million years at the 68% confidence level.\n\nFor the purposes of this summary, it is convenient to divide the chronology of the universe since it originated, into five parts. It is generally considered meaningless or unclear whether time existed before this chronology:\n\nEarliest stages of chronology shown below (before neutrino decoupling) are an active area of research and based on ideas which are still speculative and subject to modification as scientific knowledge improves.\n\n\"Time\" column is based on extrapolation of observed metric expansion of space back in the past. For the earliest stages of chronology this extrapolation may be invalid. To give one example, eternal inflation theories propose that inflation lasts forever throughout most of the universe, making the notion of \"N seconds since Big Bang\" ill-defined.\n\nThe radiation temperature refers to the cosmic background radiation and is given by 2.725·(1+\"z\"), where \"z\" is the redshift.\n\nThe Planck epoch is an era in traditional (non-inflationary) Big Bang cosmology immediately after the event which began our known universe. During this epoch, the temperature and average energies within the universe were so inconceivably high compared to any temperature we can observe today, that everyday subatomic particles could not form, and even the four fundamental forces that shape our universe—electromagnetism, gravitation, weak nuclear interaction, and strong nuclear interaction—were combined and formed one fundamental force. Little is understood about physics at this temperature; different hypotheses propose different scenarios. Traditional big bang cosmology predicts a gravitational singularity before this time, but this theory relies on the theory of general relativity, which is thought to break down for this epoch due to quantum effects.\n\nIn inflationary models of cosmology, times before the end of inflation (roughly 10 second after the Big Bang) do not follow the same timeline as in traditional big bang cosmology. Models that aim to describe the universe and physics during the Planck epoch are generally speculative and fall under the umbrella of \"New Physics\". Examples include the Hartle–Hawking initial state, string landscape, string gas cosmology, and the ekpyrotic universe.\n\nAs the universe expanded and cooled, it crossed transition temperatures at which forces separated from each other. These phase transitions can be visualised as similar to condensation and freezing phase transitions of ordinary matter. At certain temperatures/energies, water molecules change their behaviour and structure, and they will behave completely differently. Like steam turning to water, the fields which define our universe's fundamental forces and particles also completely change their behaviors and structures when the temperature/energy falls below a certain point. This is not apparent in everyday life, because it only happens at much, much, higher temperatures than we usually see in our present universe.\n\nThese phase transitions are believed to be caused by a phenomenon of quantum fields called \"symmetry breaking\".\n\nIn everyday terms, as the universe cools, it becomes possible for the quantum fields that create the forces and particles around us, to settle at lower energy levels and with higher levels of stability. In doing so, they completely shift how they interact. Forces and interactions arise due to these fields, so the universe can behave very differently above and below a phase transition. For example, in a later epoch, a side effect of one phase transition is that suddenly, many particles that had no mass at all acquire a mass (they begin to interact with the Higgs boson), and a single force begins to manifest as two separate forces.\n\nThe grand unification epoch began with a phase transitions of this kind, when gravitation separated from the universal combined gauge force. This caused two forces to now exist: gravity, and an electrostrong interaction. There is no hard evidence yet, that such a combined force existed, but many physicists believe it did. The physics of this electrostrong interaction would be described by a so-called grand unified theory (GUT).\n\nThe grand unification epoch ended with a second phase transition, as the electrostrong interaction in turn separated, and began to manifest as two separate interactions, called the strong and electroweak interactions.\n\nDepending on how epochs are defined, and the model being followed, the electroweak epoch may be considered to start before or after the inflationary epoch. In some models it is described as including the inflationary epoch. In other models, the electroweak epoch is said to begin after the inflationary epoch ended, at roughly 10 seconds.\n\nAccording to traditional big bang cosmology, the electroweak epoch began 10 seconds after the Big Bang, when the temperature of the universe was low enough (10 K) for the Electronuclear Force to begin to manifest as two separate interactions, called the strong and the electroweak interactions. (The electroweak interaction will also separate later, dividing into the electromagnetic and weak interactions). The exact point where electrostrong symmetry was broken is not certain, because of the very high energies of this event.\n\nAt this point, the very early universe suddenly and very rapidly expanded to at least 10 times its previous volume (and possibly much more). This is equivalent to a linear increase of at least 10 times in every spatial dimension – equivalent to an object 1 nanometer (10 m, about half the width of a molecule of DNA) in length, expanding to one approximately 10.6 light years (about 62 trillion miles) long in a tiny fraction of a second. This change is known as inflation.\n\nAlthough light and objects within spacetime cannot travel faster than the speed of light, in this case it was the metric governing the size and geometry of spacetime itself that changed in scale. Changes to the metric are not limited by the speed of light.\n\nIn some models, it is thought to have been triggered by the separation of the strong and electroweak interactions which ended the grand unification epoch. One of the theoretical products of this phase transition was a scalar field called the inflaton field. As this field settled into its lowest energy state throughout the universe, it generated an enormous repulsive force that led to a rapid expansion of space itself. Inflation explains several observed properties of the current universe that are otherwise difficult to account for, including explaining how today's universe has ended up so exceedingly homogeneous (similar) on a very large scale, even though it was highly disordered in its earliest stages.\n\nIt is not known exactly when the inflationary epoch ended, but it is thought to have been between 10 and 10 seconds after the Big Bang. The rapid expansion of space meant that elementary particles remaining from the grand unification epoch were now distributed very thinly across the universe. However, the huge potential energy of the inflation field was released at the end of the inflationary epoch, as the inflaton field decayed into other particles, known as \"reheating\". This heating effect led to the universe being repopulated with a dense, hot mixture of quarks, anti-quarks and gluons. In other models, reheating is often considered to mark the start of the electroweak epoch, and some theories, such as warm inflation, avoid a reheating phase entirely.\n\nIn non-traditional versions of Big Bang theory (known as \"inflationary\" models), inflation ended at a temperature corresponding to roughly 10 second after the Big Bang, but this does \"not\" imply that the inflationary era lasted less than 10 second. To explain the observed homogeneity of the universe, the duration in these models must be longer than 10 second. Therefore, in inflationary cosmology, the earliest meaningful time \"after the Big Bang\" is the time of the \"end\" of inflation. \n\nAfter inflation ended, the universe continued to expand, but at a very slow rate. The slow expansion began to speed up after several billion years, believed to be due to dark energy, and is still expanding today.\n\nOn March 17, 2014, astrophysicists of the BICEP2 collaboration announced the detection of inflationary gravitational waves in the B-mode power spectrum which was interpreted as clear experimental evidence for the theory of inflation. However, on June 19, 2014, lowered confidence in confirming the cosmic inflation findings was reported and finally, on February 2, 2015, a joint analysis of data from BICEP2/Keck and Planck satellite concluded that the statistical \"significance [of the data] is too low to be interpreted as a detection of primordial B-modes\" and can be attributed mainly to polarized dust in the Milky Way.\n\nAs the universe's temperature continued to fall below a certain very high energy level, a third symmetry breaking occurs. So far as we currently know, it was the final symmetry breaking event in the formation of our universe. It is believed that below some energies unknown yet, the Higgs field spontaneously acquires a vacuum expectation value. When this happens, it breaks electroweak gauge symmetry. This has two related effects:\n\n\nAfter electroweak symmetry breaking, the fundamental interactions we know of – gravitation, electromagnetism, the strong interaction and the weak interaction – have all taken their present forms, and fundamental particles have mass, but the temperature of the universe is still too high to allow the formation of many fundamental particles we now see in the universe.\n\nIf supersymmetry is a property of our universe, then it must be broken at an energy that is no lower than 1 TeV, the electroweak scale. The masses of particles and their superpartners would then no longer be equal. This very high energy could explain why no superpartners of known particles have ever been observed.\n\nAfter cosmic inflation ends, the universe is filled with a hot quark–gluon plasma, the remains of reheating. From this point onwards the physics of the early universe is much better understood, and the energies involved in the Quark epoch are directly amenable to experiment.\n\nThe quark epoch began approximately 10 seconds after the Big Bang. This was the period in the evolution of the early universe immediately after electroweak symmetry breaking, when the fundamental interactions of gravitation, electromagnetism, the strong interaction and the weak interaction had taken their present forms, but the temperature of the universe was still too high to allow quarks to bind together to form hadrons.\n\nDuring the quark epoch the universe was filled with a dense, hot quark–gluon plasma, containing quarks, leptons and their antiparticles. Collisions between particles were too energetic to allow quarks to combine into mesons or baryons.\n\nThe quark epoch ended when the universe was about 10 seconds old, when the average energy of particle interactions had fallen below the binding energy of hadrons.\n\n\"Perhaps by 10 seconds.\"\n\nBaryons are subatomic particles such as protons and neutrons, that are composed of three quarks. It would be expected that both baryons, and particles known as antibaryons would have formed in equal numbers. However, this does not seem to be what happened – as far as we know, the universe was left with far more baryons than antibaryons. In fact, almost no antibaryons are observed in nature. It is not clear how this came about. Any explanation for this phenomenon must allow the Sakharov conditions related to baryogenesis to have been satisfied at some time after the end of cosmological inflation. Current particle physics suggests asymmetries under which these conditions would be met, but these asymmetries appear to be too small to account for the observed baryon-antibaryon asymmetry of the universe.\n\nThe quark–gluon plasma that composes the universe cools until hadrons, including baryons such as protons and neutrons, can form.\nInitially, hadron/anti-hadron pairs could form, so matter and anti-matter were in thermal equilibrium. However, as the temperature of the universe continued to fall, new hadron/anti-hadron pairs were no longer produced, and most of the newly formed hadrons and anti-hadrons annihilated each other, giving rise to pairs of high-energy photons. A comparatively small residue of hadrons remained at about 1 second of cosmic time, when this epoch ended. \n\nTheory predicts that about 1 neutron remained for every 7 protons. We believe this to be correct because, at a later stage, all the neutrons and some of the protons fused, leaving hydrogen, a hydrogen isotope called deuterium, helium and other elements, which we can measure. A 1:7 ratio of hadrons at the end of this epoch would indeed produce the observed element ratios in the early as well as current universe.\n\nAt approximately 1 second after the Big Bang neutrinos decouple and begin traveling freely through space. As neutrinos rarely interact with matter, these neutrinos still exist today, analogous to the much later cosmic microwave background emitted during recombination, around 377,000 years after the Big Bang. The neutrinos from this event have a very low energy, around 10 times smaller than is possible with present-day direct detection. Even high energy neutrinos are notoriously difficult to detect, so this cosmic neutrino background (CNB) may not be directly observed in detail for many years, if at all.\n\nHowever, Big Bang cosmology makes many predictions about the CNB, and there is very strong indirect evidence that the cosmic neutrino background exists, both from Big Bang nucleosynthesis predictions of the helium abundance, and from anisotropies in the cosmic microwave background. One of these predictions is that neutrinos will have left a subtle imprint on the cosmic microwave background (CMB). It is well known that the CMB has irregularities. Some of the CMB fluctuations were roughly regularly spaced, because of the effect of baryonic acoustic oscillations. In theory, the decoupled neutrinos should have had a very slight effect on the phase of the various CMB fluctuations.\n\nIn 2015, it was reported that such shifts had been detected in the CMB. Moreover, the fluctuations corresponded to neutrinos of almost exactly the temperature predicted by Big Bang theory ( compared to a prediction of 1.95K), and exactly three types of neutrino, the same number of neutrino flavours currently predicted by the Standard Model.\n\nPrimordial black holes are a hypothetical type of black hole proposed in 1966, that may have formed during the so-called \"radiation dominated era\", due to the high densities and inhomogeneous conditions within the first second of cosmic time. Random fluctuations could lead to some regions becoming dense enough to undergo gravitational collapse, forming black holes. Current understandings and theories place tight limits on the abundance and mass of these objects.\n\nTypically, primordial black hole formation requires density contrasts (regional variations in the Universe's density) of around formula_1 (10%), where formula_2 is the average density of the Universe. Several mechanisms could produce dense regions meeting this criterion during the early universe, including reheating, cosmological phase transitions and (in so-called \"hybrid inflation models\") axion inflation. Since primordial black holes didn't form from stellar gravitational collapse, their masses can be far below stellar mass (~2×10 g). Stephen Hawking calculated in 1971 that primordial black holes could weigh as little as 10 g. But they can have any size, so they could also be large, and may have contributed to the formation of galaxies.\n\nThe majority of hadrons and anti-hadrons annihilate each other at the end of the hadron epoch, leaving leptons (such as the electron, muons and certain neutrinos) and anti-leptons, dominating the mass of the universe. \n\nThe lepton epoch follows a similar path to the earlier hadron epoch. Initially leptons and anti-leptons are produced in pairs. About 10 seconds after the Big Bang the temperature of the universe falls to the point at which new lepton/anti-lepton pairs are no longer created and most remaining leptons and anti-leptons quickly annihilate each other, giving rise to pairs of high energy photons, and leaving a small residue of non-annihilated leptons.\n\nAfter most leptons and anti-leptons are annihilated at the end of the lepton epoch, most of the mass-energy in the universe is left in the form of photons. (Much of the rest of its mass-energy is in the form of neutrinos and other relativistic particles). Therefore the energy of the universe, and its overall behavior, is dominated by its photons. These photons continue to interact frequently with charged protons, electrons and (eventually) nuclei. They continue to do so for about the next 377,000 years.\n\nBetween about 2 and 20 minutes after the Big Bang, the temperature and pressure of the universe allow nuclear fusion to occur, giving rise to nuclei of a few light elements beyond hydrogen (\"Big Bang nucleosynthesis\"). About 25% of the protons, and all the neutrons fuse to form deuterium, a hydrogen isotope, and most of the deuterium quickly fuses to form helium-4. \n\nAtomic nuclei will easily unbind (break apart) above a certain temperature, related to their binding energy. From about 2 minutes, the falling temperature means that deuterium no longer unbinds, and is stable, and starting from about 3 minutes, helium and other elements formed by the fusion of deuterium also no longer unbind and are stable.\n\nThe short duration and falling temperature means that only the simplest and fastest fusion processes can occur. Only tiny amounts of nuclei beyond helium are formed, because nucleosynthesis of heavier elements is difficult and requires thousands of years even in stars. Small amounts of tritium (another hydrogen isotope) and beryllium-7 and -8 are formed, but these are unstable and are quickly lost again. A small amount of deuterium is left unfused because of the very short duration.\n\nTherefore, the only stable nuclides created by the end of Big Bang nucleosynthesis are protium (single proton/hydrogen nucleus), deuterium, helium-3, helium-4, and lithium-7. By mass, the resulting matter is about 75% hydrogen nuclei, 25% helium nuclei, and perhaps 10 by mass of Lithium-7. The next most common stable isotopes produced are lithium-6, beryllium-9, boron-11, carbon, nitrogen and oxygen (\"CNO\"), but these have predicted abundances of between 5 and 30 parts in 10 by mass, making them essentially undetectable and negligible.\n\nThe amounts of each light element in the early universe can be estimated from old galaxies, and is strong evidence for the Big Bang. For example, the Big Bang should produce about 1 neutron for every 7 protons, allowing for 25% of all nucleons to be fused into helium-4 (2 protons and 2 neutrons out of every 16 nucleons), and this is the amount we find today, and far more than can be easily explained by other processes. Similarly, deuterium fuses extremely easily; any alternative explanation must also explain how conditions existed for deuterium to form, but also left some of that deuterium unfused and not immediately fused again into helium. Any alternative must also explain the proportions of the various light elements and their isotopes. A few isotopes, such as lithium-7, were found to be present in amounts that differed from theory, but over time, these differences have been resolved by better observations.\n\nUntil now, the universe's large scale dynamics and behavior have been determined mainly by radiation – meaning, those constituents that move relativistically (at or near the speed of light), such as photons and neutrinos. As the universe cools, from around 47,000 years (z=3600), the universe's large scale behavior becomes dominated by matter instead. This occurs because the energy density of matter begins to exceed both the energy density of radiation and the vacuum energy density. Around or shortly after this time, the densities of non-relativistic matter (atomic nuclei) and relativistic radiation (photons) become equal, the Jeans length, which determines the smallest structures that can form (due to competition between gravitational attraction and pressure effects), begins to fall and perturbations, instead of being wiped out by free-streaming radiation, can begin to grow in amplitude.\n\nAccording to the Lambda-CDM model, by this stage, the matter in the universe is around 84.5% cold dark matter and 15.5% \"ordinary\" matter. (However the total matter in the universe is only 31.7%, much smaller than the 68.3% of dark energy). There is overwhelming evidence that dark matter exists and dominates our universe, but since the exact nature of dark matter is still not understood, Big Bang theory does not presently cover any stages in its formation.\n\nFrom this point on, and for several billion years to come, the presence of dark matter accelerates the formation of structure in our universe. In the early universe, dark matter gradually gathers in huge filaments under the effects of gravity. This amplifies the tiny inhomogeneities (irregularities) in the density of the universe which was left by cosmic inflation. Over time, slightly denser regions become denser and slightly rarefied (emptier) regions become more rarefied. Ordinary matter eventually gathers together faster than it would otherwise do, because of the presence of these concentrations of dark matter.\n\nAbout 377,000 years after the Big Bang, two connected events occurred: recombination and photon decoupling. Recombination describes the ionized particles combining to form the first neutral atoms, and decoupling refers to the photons released (\"decoupled\") as the newly formed atoms settle into more stable energy states.\n\nJust before recombination, the baryonic matter in the universe was at a temperature where it formed a hot ionized plasma. Most of the photons in the universe interacted with electrons and protons, and could not travel significant distances without interacting with ionized particles. As a result, the universe was opaque or \"foggy\". Although there was light, it was not possible to see, nor can we observe that light through telescopes.\n\nAt around 377,000 years, the universe has cooled to a point where free electrons can combine with the hydrogen and helium nuclei to form neutral atoms. This process is relatively fast (and faster for the helium than for the hydrogen), and is known as recombination. The name is slightly inaccurate and is given for historical reasons: in fact the electrons and atomic nuclei were combining for the first time.\n\nDirectly combining in a low energy state (ground state) is less efficient, so these hydrogen atoms generally form with the electrons still in a high energy state, and once combined, the electrons quickly release energy in the form of one or more photons as they transition to a low energy state. This release of photons is known as photon decoupling. Some of these decoupled photons are captured by other hydrogen atoms, the remainder remain free. By the end of recombination, most of the protons in the universe have formed neutral atoms. This change from charged to neutral particles means that the mean free path photons can travel before capture in effect becomes infinite, so any decoupled photons that have not been captured can travel freely over long distances (see Thomson scattering). The universe has become transparent to visible light, radio waves and other electromagnetic radiation for the first time in its history.\nThe photons released by these newly formed hydrogen atoms initially had a temperature/energy of around ~ 4000 K. This would have been visible to the eye as a pale yellow/orange tinted, or \"soft\", white color. Over billions of years since decoupling, as the universe has expanded, the photons have been red-shifted from visible light to radio waves (microwave radiation corresponding to a temperature of about 2.7 K). Red shifting describes the photons acquiring longer wavelengths and lower frequencies as the universe expanded over billions of years, so that they gradually changed from visible light to radio waves. These same photons can still be detected as radio waves today. They form the cosmic microwave background (\"CMB\"), and they provide crucial evidence of the early universe and how it developed.\n\nAround the same time as recombination, existing pressure waves within the electron-baryon plasma – known as baryon acoustic oscillations – became embedded in the distribution of matter as it condensed, giving rise to a very slight preference in distribution of large-scale objects. Therefore, the cosmic microwave background is a picture of the universe at the end of this epoch including the tiny fluctuations generated during inflation (see diagram), and the spread of objects such as galaxies in the universe is an indication of the scale and size of the universe as it developed over time.\n\nAfter recombination and decoupling, the universe was transparent and had cooled enough to allow light to travel long distances, but there were no light-producing structures such as stars and galaxies. Stars and galaxies are formed when dense regions of gas form due to the action of gravity, and this takes a long time within a near-uniform density of gas and on the scale required, so it is estimated that stars did not exist for perhaps hundreds of millions of years after recombination.\n\nThis period, known as the Dark Ages, began around 377,000 years after the Big Bang. During the Dark Ages, the temperature of the universe cooled from some 4000 K down to about 60 K, and only two sources of photons existed: the photons released during recombination/decoupling (as neutral hydrogen atoms formed), which we can still detect today as the cosmic microwave background (CMB), and photons occasionally released by neutral hydrogen atoms, known as the 21 cm spin line of neutral hydrogen. The hydrogen spin line is in the microwave range of frequencies, and within 3 million years, the CMB photons had redshifted out of visible light to infrared; from that time until the first stars, there were no visible light photons. Other than perhaps some rare statistical anomalies, the universe was truly dark.\n\nThe October 2010 discovery of UDFy-38135539, the first observed galaxy to have existed during the following reionization epoch, gives us a window into these times. The galaxy earliest in this period observed and thus also the most distant galaxy ever observed is currently on the record of Leiden University's Richard J. Bouwens and Garth D. Illingsworth from UC Observatories/Lick Observatory. They found the galaxy UDFj-39546284 to be at a time some 480 million years after the Big Bang or about halfway through the Cosmic Dark Ages at a distance of about 13.2 billion light-years. More recently, the UDFy-38135539, EGSY8p7 and GN-z11 galaxies were found to be around 380–550 million years after the Big Bang and at a distance of around 13.4 billion light-years. There is also currently an observational effort underway to detect the faint 21 cm spin line radiation, as it is in principle an even more powerful tool than the cosmic microwave background for studying the early universe.\n\nStructures may have begun to emerge from around 150 million years, and stars and early galaxies gradually emerged from around 400 to 700 million years. As they emerged, the Dark Ages gradually ended. Because this process was gradual, the Dark Ages only fully ended around 1 billion (1000 million) years, as the universe took its present appearance.\n\nFor about 6.6 million years, between about 10 to 17 million years after the Big Bang (redshift 137–100), the background temperature was between 373 K and 273 K, a temperature compatible with liquid water and common biological chemical reactions. Loeb (2014) speculated that primitive life might in principle have appeared during this window, which he called \"the Habitable Epoch of the Early Universe\". Loeb argues that carbon-based life might have evolved in a hypothetical pocket of the early universe that was dense enough both to generate at least one massive star that subsequently releases carbon in a supernova, and that was also dense enough to generate a planet. (Such dense pockets, if they existed, would have been extremely rare.) Life would also have required a heat differential, rather than just uniform background radiation; this could be provided by naturally-occurring geothermal energy. Such life would likely have remained primitive; it is highly unlikely that intelligent life would have had sufficient time to evolve before the hypothetical oceans freeze over at the end of the habitable epoch.\n\nThe matter in the universe is around 84.5% cold dark matter and 15.5% \"ordinary\" matter. Since the start of the matter-dominated era, the dark matter has gradually been gathering in huge spread out (diffuse) filaments under the effects of gravity. Ordinary matter eventually gathers together faster than it would otherwise do, because of the presence of these concentrations of dark matter. It is also slightly more dense at regular distances due to early baryon acoustic oscillations (BAO) which became embedded into the distribution of matter when photons decoupled. Unlike dark matter, ordinary matter can lose energy by many routes, which means that as it collapses, it can lose the energy which would otherwise hold it apart, and collapse more quickly, and into denser forms. Ordinary matter gathers where dark matter is denser, and in those places it collapses into clouds of mainly hydrogen gas. The first stars and galaxies form from these clouds. Where numerous galaxies have formed, galaxy clusters and superclusters will eventually arise. Large voids with few stars will develop between them, marking where dark matter became less common.\n\nStructure formation in the big bang model proceeds hierarchically, due to gravitational collapse, with smaller structures forming before larger ones. The earliest structures to form are the first stars (known as population III stars), dwarf galaxies, and quasars (which are thought to be bright, early active galaxies containing a supermassive black hole surrounded by a inward-spiralling accretion disk of gas). Before this epoch, the evolution of the universe could be understood through linear cosmological perturbation theory: that is, all structures could be understood as small deviations from a perfect homogeneous universe. This is computationally relatively easy to study. At this point non-linear structures begin to form, and the computational problem becomes much more difficult, involving, for example, \"N\"-body simulations with billions of particles. The Bolshoi Cosmological Simulation is a high precision simulation of this era.\n\nThese Population III stars are also responsible for turning the few light elements that were formed in the Big Bang (hydrogen, helium and small amounts of lithium) into many heavier elements. They can be huge as well as perhaps small – and non-metallic (no elements except hydrogen and helium). The larger stars have very short lifetimes compared to most Main Sequence stars we see today, so they commonly finish burning their hydrogen fuel and explode as supernovae after mere millions of years, seeding the universe with heavier elements over repeated generations. They mark the start of the Stelliferous (starry) era.\n\nAs yet, no Population III stars have been found, so our understanding of them is based on computational models of their formation and evolution. Fortunately, observations of the Cosmic Microwave Background radiation can be used to date when star formation began in earnest. Analysis of such observations made by the European Space Agency's Planck telescope in 2016 concluded that the first generation of stars formed 700 million years after the Big Bang.\n\nQuasars provides some additional evidence of early structure formation. Their light shows evidence of elements such as carbon, magnesium, iron and oxygen. This is evidence that by the time quasars formed, a massive phase of star formation had already taken place, including sufficient generations of population III stars to give rise to these elements.\n\nAs the first stars, dwarf galaxies and quasars gradually form, the intense radiation they emit reionizes much of the surrounding universe; splitting the neutral hydrogen atoms back into a plasma of free electrons and protons for the first time since recombination and decoupling.\n\nReionization is evidenced from observations of quasars. Quasars are a form of active galaxy, and the most luminous objects observed in the universe. Electrons in neutral hydrogen have a specific patterns of absorbing photons, related to electron energy levels and called the Lyman series. Ionized hydrogen does not have electron energy levels of this kind. Therefore, light travelling through ionized hydrogen and neutral hydrogen shows different absorption lines. In addition, the light will have travelled for billions of years to reach us, so any absorption by neutral hydrogen will have been redshifted by varied amounts, rather than by one specific amount, indicating when it happened. These features make it possible to study the state of ionization at many different times in the past. They show that reionization began as \"bubbles\" of ionized hydrogen which became larger over time. They also show that the absorption was due to the general state of the universe (the intergalactic medium) and not due to passing through galaxies or other dense areas. Reionization might have started as early as \"z\"=16 (250 million years of cosmic time) and was complete by around \"z\"=9 or 10 (500 million years). The epoch of reionization probably ended by around \"z\"=5 or 6 (1 billion years) as the era of Population III stars and quasars – and their intense radiation – came to an end, and the ionized hydrogen gradually reverted to neutral atoms.\n\nThese observations have narrowed down the period of time during which reionization took place, but the source of the photons that caused reionization is still not completely certain. To ionize neutral hydrogen, an energy larger than 13.6 eV is required, which corresponds to ultraviolet photons with a wavelength of 91.2 nm or shorter, implying that the sources must have produced significant amount of ultraviolet and higher energy. Protons and electrons will recombine if energy is not continuously provided to keep them apart, which also sets limits on how numerous the sources were and their longevity. With these constraints, it is expected that quasars and first generation stars and galaxies were the main sources of energy. The current leading candidates from most to least significant are currently believed to be population III stars (the earliest stars) (possibly 70%), dwarf galaxies (very early small high-energy galaxies) (possibly 30%), and a contribution from quasars (a class of active galactic nuclei).\n\nHowever, by this time, matter had become far more spread out due to the ongoing expansion of the universe. Although the neutral hydrogen atoms were again ionized, the plasma was much more thin and diffuse, and photons were much less likely to be scattered. Despite being reionized, the universe remained largely transparent during reionization. As the universe continued to cool and expand, reionization gradually ended.\n\nMatter continues to draw together under the influence of gravity, to form galaxies. The stars from this time period, known as Population II stars, are formed early on in this process, with more recent Population I stars formed later. Gravitational attraction also gradually pulls galaxies towards each other to form groups, clusters and superclusters. The Hubble Ultra Deep Field observatory has identified a number of small galaxies merging to form larger ones, at 800 million years of cosmic time (13 billion years ago) (this age estimate is now believed to be slightly overstated).\n\nJohannes Schedler's project has identified a quasar CFHQS 1641+3755 at 12.7 billion light-years away, when the universe was just 7% of its present age. On July 11, 2007, using the 10-metre Keck II telescope on Mauna Kea, Richard Ellis of the California Institute of Technology at Pasadena and his team found six star forming galaxies about 13.2 billion light years away and therefore created when the universe was only 500 million years old. Only about 10 of these extremely early objects are currently known. More recent observations have shown these ages to be shorter than previously indicated. The most distant galaxy observed as of October 2016, GN-z11, has been reported to be 32 billion light years away, a vast distance made possible through space-time expansion (redshift z=11.1; comoving distance of 32 billion light-years; lookback time of 13.4 billion years).\n\nThe universe has appeared much the same as it does now, for many billions of years. It will continue to look similar for many more billions of years into the future.\n\nBased upon the emerging science of nucleocosmochronology, the Galactic thin disk of the Milky Way is estimated to have been formed 8.8 ± 1.7 billion years ago.\n\nFrom about 9.8 billion years of cosmic time, the universe's large-scale behavior is believed to have gradually changed for the third time in its history. Its behavior had originally been dominated by radiation (relativistic constituents such as photons and neutrinos) for the first 47,000 years, and since about 377,000 years of cosmic time, its behavior had been dominated by matter. During its matter-dominated era, the expansion of the universe had begun to slow down, as gravity reigned in the initial outward expansion. But from about 9.8 billion years of cosmic time, observations show that that the expansion of the universe slowly stops decelerating, and gradually begins to accelerate again, instead. \n\nWhile the precise cause is not known, the observation is accepted as correct by the cosmologist community. By far the most accepted understanding is that this is due to an unknown form of energy which has been given the name \"dark energy\". \"Dark\" in this context means that it is not directly observed, but can currently only be studied by examining the effect it has on the universe. Research is ongoing to understand this dark energy. Dark energy is now believed to be the single largest component of the universe, as it constitutes about 68.3% of the entire mass-energy of the physical universe.\n\nDark energy is believed to act like a cosmological constant - a scalar field that exists throughout space. Unlike gravity, the effects of such a field do not diminish (or only diminish slowly) as the universe grows. While matter and gravity have a greater effect initially, their effect quickly diminishes as the universe continues to expand. Objects in the universe, which are initially seen to be moving apart as the universe expands, continue to move apart, but their outward motion gradually slows down. This slowing effect becomes smaller as the universe becomes more spread out. Eventually, the outward and repulsive effect of dark energy begins to dominate over the inward pull of gravity. Instead of slowing down and perhaps beginning to move inward under the influence of gravity, from about 9.8 billion years of cosmic time, the expansion of space starts to slowly accelerate \"outward\" at a gradually \"increasing\" rate.\n\nThe universe has existed for around 13.8 billion years, and we believe that we understand it well enough to predict its large-scale development for many billions of years into the future – perhaps as much as 100 billion years of cosmic time (about 86 billion years from now). Beyond that, we need to better understand the universe to make any accurate predictions. Therefore, the universe could follow a variety of different paths beyond this time.\n\nThere are several competing scenarios for the possible long-term evolution of the universe. Which of them will happen, if any, depends on the precise values of physical constants such as the cosmological constant, the possibility of proton decay, the energy of the vacuum (meaning, the energy of \"empty\" space itself), and the natural laws beyond the Standard Model.\nIf the expansion of the universe continues and it stays in its present form, eventually all but the nearest galaxies will be carried away from us by the expansion of space at such a velocity that our observable universe will be limited to our own gravitationally bound local galactic cluster. In the very long term (after many trillions – thousands of billions – of years, cosmic time), the Stelliferous Era will end, as stars cease to be born and even the longest-lived stars gradually die. Beyond this, all objects in the universe will cool and (with the possible exception of protons) gradually decompose back to their constituent particles and then into subatomic particles and very low level photons and other fundamental particles, by a variety of possible processes. But this will take a duration of time that is almost inconceivable to most people, compared to which the entire 13.8 billion years of the universe would be a tiny instant in time.\n\nUltimately, in the extreme future, the following scenarios have been proposed for the ultimate fate of the universe.\n\nIn this kind of extreme timescale, extremely rare quantum phenomena may also occur that are extremely unlikely to be seen on a timescale smaller than trillions of years. These may also lead to unpredictable changes to the state of the universe which would not be likely to be significant on any smaller timescale. For example, on a timescale of millions of trillions of years, black holes might appear to evaporate almost instantly, uncommon quantum tunneling phenomena would appear to be common, and quantum (or other) phenomena so unlikely that they might occur just once in a trillion years may occur many times.\n\n"}
{"id": "18958074", "url": "https://en.wikipedia.org/wiki?curid=18958074", "title": "Closure (business)", "text": "Closure (business)\n\nClosure is the term used to refer to the actions necessary when it is no longer necessary or possible for a business or other organization to continue to operate. Closure may be the result of a bankruptcy, where the organization lacks sufficient funds to continue operations, as a result of the proprietor of the business dying, as a result of a business being purchased by another organization (or a competitor) and shut down as superfluous, or because it is the non-surviving entity in a corporate merger. A closure may occur because the purpose for which the organization was created is no longer necessary.\n\nWhile a closure is typically of a business or a non-profit organization, any entity which is created by human beings can be subject to a closure, from a single church to a whole religion, up to and including an entire country if, for some reason, it ceases to exist.\n\nClosures are of two types, voluntary or involuntary. Voluntary closures of organizations are much rarer than involuntary ones, as, in the absence of some change making operations impossible or unnecessary, most operations will continue until something happens that causes a change requiring this situation.\n\nThe most common form of voluntary closure would be when those involved in an organization such as a social club, a band, or other non-profit organization decide to cease operating. Once the organization has paid any outstanding debts and completed any pending operations, closure may simply mean that the organization ceases to exist.\n\nIf an organization has debts that cannot be paid, it may be necessary to perform a liquidation of its assets. If there is anything left after the assets are converted to cash, in the case of a for-profit organization, the remainder is distributed to the stockholders; in the case of a non-profit, by law any remaining assets must be distributed to another non-profit.\n\nIf an organization has more debts than assets, it may have to declare bankruptcy. If the organization is viable, it may reorganizes itself as a result of the bankruptcy and continue operations. If it is not viable for the business to continue operating, then a closure occurs through a bankruptcy liquidation: its assets are liquidated, the creditors are paid from whatever assets could be liquidated, and the business ceases operations.\n\nPossibly the largest \"closure\" in history (but more closely analogous to a demerger) was the split of the Soviet Union into its constituent countries. In comparison, the end of East Germany can be considered a merger rather than a closure as West Germany assumed all of the assets and liabilities of East Germany. The end of the Soviet Union was the equivalent of a closure through a bankruptcy liquidation, because while Russia assumed most of the assets and responsibilities of the former Soviet Union, it did not assume all of them. There have been issues over who is responsible for unpaid parking tickets accumulated by motor vehicles operated on behalf of diplomatic missions operated by the former Soviet Union in other countries, as Russia claims it is not responsible for them.\n\nSeveral major business closures include the bankruptcy of the Penn Central railroad, the Enron scandals, and MCI Worldcom's bankruptcy and eventual merger into Verizon.\n"}
{"id": "52454436", "url": "https://en.wikipedia.org/wiki?curid=52454436", "title": "Devendrar Jayanti", "text": "Devendrar Jayanti\n\nDevendrar Jayanthi is a festival celebrated annually on 11 September. It is organised by various political parties, community organisations and civil societies in Southern Tamil Nadu to commemorate the memory of Immanuvel Devendrar, a freedom fighter and Indian National Congress leader who took part in the Quit India movement during the British Raj era. He worked in the Indian Army in independent India and later he fought for the rights of depressed class people of Southern Tamil Nadu, particularly for upliftment of Pallar caste. He was a close associate of chief minister K. Kamaraj.\n\nImmanuel Devendrar was a member of the Indian National Congress and a close associate of its leader, K. Kamaraj. At that time, Congress was supported by influential communities of southern Tamil Nadu, such as the Pallars and Nadars, and opposed by the Forward Block, which was itself favoured by the Maravar community. The two sides clashed during elections. Violence erupted notably in the districts of Ramanathapuram and Madurai which claimed over 40 lives. Devendrar was killed at this time and the anniversary of his death is today celebrated by various political parties and community organisations and civil societies as Devendrar Jayanthi.\n\nDevendrar Jayanti is among the celebrations sometimes criticised as being designed mainly as expressions of caste pride and political power, which sometimes turn into inter-caste violence. The critics claim that political parties used them as a form of vote bank politics.\n\nThese critics are rebutted by people who say that every caste has its own leader and the people are celebrating the memories of their leaders. Despite of these arguments every year the government is struggling to maintain the law and order during these celebrations.\n"}
{"id": "23081696", "url": "https://en.wikipedia.org/wiki?curid=23081696", "title": "Digitas NewFront", "text": "Digitas NewFront\n\nThe Digitas NewFront is an annual marketing conference first held during Internet Week New York. Hosted by Digitas and its brand content entity, The Third Act, the event's stated purpose is to \"bring together content creators, distributors, talent and brands to harness creative media opportunities made possible in the age of digital marketing\". In 2009, it was broadcast via public webcast. The event was produced by Amanda Anderson.\n\nFirst launched in 2008, the event was titled \"Digital Content NewFront\". The event title was later shortened to \"The NewFront\" with the stated mission to \"explore and help evolve the brand content and distribution landscape\". The event showcased online video content companies like 60 Frames, MySpaceTV, MTV New Media, Generate, Next New Networks and Vuguru. Speakers and panelists included Michael Eisner, CEO of Tornate and Vuguru, former Disney CEO and Dmitry Shapiro, the founder of Veoh Networks.\n\nIn 2018, the NewFronts ran for one week rather than two.\n\n\n\n\n\n\n\n\n"}
{"id": "418480", "url": "https://en.wikipedia.org/wiki?curid=418480", "title": "EgyptAir Flight 648", "text": "EgyptAir Flight 648\n\nEgyptAir Flight 648 was a regularly scheduled international flight between Athens Ellinikon International Airport in Greece and Cairo International Airport in Egypt. On 23 November 1985, a Boeing 737-200 airliner, registered SU-AYH, servicing the flight was hijacked by the terrorist organization Abu Nidal. The subsequent raid on the aircraft by Egyptian troops resulted in dozens of deaths, making the hijacking of Flight 648 one of the deadliest such incidents in history. \n\nOn 23 November 1985, Flight 648 took off at 8pm on its Athens-to-Cairo route. Ten minutes after takeoff, three Palestinian members of Abu Nidal hijacked the aircraft. The terrorists, calling themselves the Egypt Revolution, were heavily armed with guns and grenades. The terrorist leader, Omar Rezaq, proceeded to check all passports. At this point, an Egyptian Security Service agent, Mustafa Kamal, aboard opened fire, killing one terrorist before being wounded along with two flight attendants. In the exchange of fire the fuselage was punctured, causing a rapid depressurization. The aircraft was forced to descend to to allow the crew and passengers to breathe.\n\nLibya was the original destination for the hijackers, but due to negative publicity the hijacking would have had if flown to Libya and the fact that the plane did not have enough fuel, Malta was chosen as a more suitable option. The aircraft was running dangerously low on fuel, experiencing serious pressurization problems and carrying a number of wounded passengers. However, Maltese authorities did not give permission for the aircraft to land; the Maltese government had previously refused permission to other hijacked aircraft, including on 23 September 1982 when an Alitalia aircraft was hijacked on its way to Italy. The EgyptAir 648 hijackers insisted, and forced the pilot, Hani Galal, to land at Luqa Airport. As a last-ditch attempt to stop the landing, the runway lights were switched off, but the pilot managed to land the damaged aircraft safely.\n\nNationalities of the passengers included the following:\nThe Mexican passengers were actress Lupita Pallás and her daughter Laila Ortiz de Pinedo, mother and sister of Mexican actor Jorge Ortiz de Pinedo.\n\nAt first, Maltese authorities were optimistic they could solve the crisis. Malta had good relations with the Arab world, and 12 years earlier had successfully resolved a potentially more serious situation when a KLM Boeing 747 landed there under similar circumstances. The Maltese Prime Minister, Karmenu Mifsud Bonnici, rushed to the airport's control tower and assumed responsibility for the negotiations. Aided by an interpreter, he refused to refuel the aircraft, or to withdraw Maltese armed forces which had surrounded the plane, until all passengers were released. Eleven passengers and two injured flight attendants were allowed off the plane. The hijackers then started shooting hostages, starting with Tamar Artzi, an Israeli woman, whom they shot in the head and back. Artzi survived her wounds. Rezaq, the chief hijacker, threatened to kill a passenger every 15 minutes until his demands were met. His next victim was Nitzan Mendelson, another Israeli woman, killing her. He then shot three Americans – Patrick Scott Baker, Scarlett Marie Rogenkamp and Jackie Nink Pflug. Of the five passengers shot, Artzi, Baker and Pflug survived; Mendelson died in a Maltese hospital a week after the hijacking. A British passenger commented that he saw that Rezaq had to raise his gun in order to shoot Baker, who was about 6' 5\" tall.\n\nFrance, the United Kingdom and the United States all offered to send anti-hijack forces. Bonnici was under heavy pressure from both the hijackers and from the United States and Egypt, whose ambassadors were at the airport. The non-aligned Maltese government feared that the Americans or the Israelis would arrive and take control of the area, as the U.S. Naval Air Station Sigonella was only 20 minutes away. A U.S. Air Force C-130 Hercules with an aeromedical evacuation team from Rhein-Main Air Base (2nd Aeromedical Evacuation Squadron) near Frankfurt, Germany, and rapid-deploying surgical teams from Wiesbaden Air Force Medical Center were on standby at the U.S. Navy Hospital at Naples. When the U.S. told Maltese authorities that Egypt had a special forces counterterrorism team trained by the U.S. Delta Force ready to move in, they were granted permission to come. The Egyptian Unit 777 under the command of Major-General Kamal Attia was flown in, led by four American officers. Negotiations were prolonged as much as possible, and it was agreed that the plane should be attacked on the morning of 25 November when food was to be taken into the aircraft. Soldiers dressed up as caterers would jam the door open and attack.\n\nWithout warning Egyptian commandos launched the raid about an hour and a half before it had been originally planned. They blasted open the passenger doors and luggage compartment doors with explosives. Bonnici claimed that these unauthorized explosions caused the internal plastic of the plane to catch fire, causing widespread suffocation. On the other hand, the \"Times of Malta\", quoting sources at the airport on the day, held that when the hijackers realized that they were being attacked, they lobbed hand grenades into the passenger area, killing people and starting the fire aboard.\n\nThe storming of the aircraft killed 54 of the remaining 87 passengers, as well as two crew members and one hijacker. Only one hijacker — Omar Rezaq, who had survived — remained undetected by the Maltese government. The terrorist leader, who was injured during the storming of the aircraft, had removed his hood and ammunition and pretended to be an injured passenger. Egyptian commandos tracked Rezaq to St. Luke's General Hospital and, holding the doctors and medical staff at gunpoint, entered the casualty ward looking for him. He was arrested when some of the passengers in the hospital recognized him.\n\nA total of 58 of the 95 passengers and crew had died, as well as two of the three hijackers, by the time the crisis was over. Maltese medical examiners estimated that eight passengers were shot dead by the commandos.\n\nRezaq faced trial in Malta, but with no anti-terrorism legislation, he was tried on other charges. There was widespread fear that terrorists would hijack a Maltese plane or carry out a terrorist attack in Malta as an act of retribution. Rezaq received a 25-year sentence, of which he served eight. His release caused a diplomatic incident between Malta and the U.S. because Maltese law strictly prohibited trying a person twice, in any jurisdiction, on charges connected to the same series of events (having wider limitations compared to classic double jeopardy). Following his immediate expulsion on release, he was captured on arrival in Nigeria. After three months he was handed over to the U.S., brought before a U.S. court and, on 7 October 1996, sentenced to life imprisonment with a no-parole recommendation.\n\nIn his 1989 book \"Massacre in Malta\", John A. Mizzi writes:\n\nMizzi adds:\n\nMizzi also mentions how Maltese soldiers positioned in the vicinity of the aircraft were equipped with rifles but were not issued ammunition. An Italian secret service report on the incident showed how the fire inside the aircraft was caused by the Egyptian commandos who placed explosives in the aircraft cargo hold – the most vulnerable part of the aircraft, as it held the oxygen tanks which blew up. During the hijacking, only the Socialist Party media and state-controlled television were given information on the incident. Such was the censorship of the media, that the Maltese people first heard of the disaster through RAI TV, when its correspondent Enrico Mentana spoke live on the air via a direct phone call: \"Parlo da Malta. Qui c'è stato un massacro ...\" (\"I'm speaking from Malta. Here there's just been a massacre ...\") Shortly before this broadcast, a news bulletin on the Maltese national television had erroneously stated that all passengers had been released and were safe.\n\nDecisions taken by the Maltese government drew criticism from overseas. The United States protested to Malta about U.S. personnel sent to resolve the issue having been confined to Air Squadron HQ and the U.S. Embassy in Floriana. The United States had seen the situation as so ‘hot’ that it had ordered a number of its naval ships, including an aircraft carrier, to move toward Malta for contingency purposes.\n\nEgyptAir still flies the Athens–Cairo route, now assigned flight numbers 748 and 750 and is now performed by Boeing 737-800. The flight number 648 \nis now on its Riyadh–Cairo route.\n\nThe events of the hijacking were related in an account by American survivor Jackie Nink Pflug, who had been shot in the head, on the Biography Channel television program \"I Survived...\", which was broadcast on 13 April 2009. Laurence Zrinzo, the neurologist and neurosurgeon who established neurosurgery as a sub-speciality in the Maltese islands, performed Ms Pflug's neurosurgical procedure. Ms Pflug also related details about the flight and the attack in her 2001 book, \"Miles to Go Before I Sleep\". The incident was chronicled and reenacted in an \"Interpol Investigates\" episode, \"Terror in the Skies\", broadcast by the National Geographic Channel.\n\nThe hijacking is also the subject of the book \"Valinda, Our Daughter\", written by Canadian author Gladys Taylor.\n\nThe events of the hijacking are described in and used to further the plot in Brad Thor's novel Path of the Assassin.\n\n\n"}
{"id": "2770842", "url": "https://en.wikipedia.org/wiki?curid=2770842", "title": "Event (philosophy)", "text": "Event (philosophy)\n\nIn philosophy, events are objects in time or instantiations of properties in objects.\n\nJaegwon Kim theorized that events are structured.<br>\nThey are composed of three things:\nEvents are defined using the operation [x, P, t].<br>\nA unique event is defined by two principles:<br>\nThe existence condition states “[x, P, t] exists if and only if object x exemplifies the n-adic P at time t”. This means a unique event exists if the above is met. The identity condition states “[x, P, t] is [y, Q, t`] if and only if x=y, P=Q and t=t`].\n\nKim uses these to define events under five conditions:\n\nOther problems exist within Kim’s theory, as he never specified what properties were (e.g. universals, tropes, natural classes, etc.). In addition, it is not specified if properties are few or abundant. The following is Kim’s response to the above.\n\nThere is also a major debate about the essentiality of a constitutive object. There are two major questions involved in this: If one event occurs, could it have occurred in the same manner if it were another person, and could it occur in the same manner if it would have occurred at a different time? Kim holds that neither are true and that different conditions (i.e. a different person or time) would lead to a separate event. However, some consider it natural to assume the opposite.\n\nDonald Davidson and John Lemmon proposed a theory of events that had two major conditions, respectively: a causal criterion and a spatiotemporal criterion.\n\nThe causal criterion defines an event as two events being the same if and only if they have the same cause and effect.\n\nThe spatiotemporal criterion defines an event as two events being the same if and only if they occur in the same space at the same time. Davidson however provided this scenario; if a metal ball becomes warmer during a certain minute, and during the same minute rotates through 35 degrees, must we say that these are the same event? However, one can argue that the warming of the ball and the rotation are possibly temporally separated and are therefore separate events.\n\nDavid Lewis theorized that events are merely spatiotemporal regions and properties (i.e. membership of a class). He defines an event as “e is an event only if it is a class of spatiotemporal regions, both thisworldly (assuming it occurs in the actual world) and otherworldly.” The only problem with this definition is it only tells us what an event could be, but does not define a unique event. This theory entails modal realism, which assumes possible worlds exist; worlds are defined as sets containing all objects that exist as a part of that set. However, this theory is controversial. Some philosophers have attempted to remove possible worlds, and reduce them to other entities. They hold that the world we exist in is the only world that actually exists, and that possible worlds are only possibilities.\n\nLewis’ theory is composed of four key points. Firstly, the non-duplication principle; it states that x and y are separate events if and only if there is one member of x that is not a member of y (or vice versa). Secondly, there exist regions that are subsets of possible worlds and thirdly, events are not structured by an essential time.\n\nIn \"Being and Event\", Alain Badiou writes that the event (\"événement\") is a multiple which basically does not make sense according to the rules of the \"situation,\" in other words existence. Hence, the event \"is not,\" and therefore, in order for there to be an event, there must be an \"intervention\" which changes the rules of the situation in order to allow that particular event to be (\"to be\" meaning to be a multiple which belongs to the multiple of the situation — these terms are drawn from or defined in reference to set theory). In his view, there is no \"one,\" and everything that a \"multiple.\" \"One\" happens when the situation \"counts,\" or accounts for, acknowledges, or defines something: it \"counts it as one.\" For the event to be counted as one by the situation, or counted in the one of the situation, an intervention needs to decide its belonging to the situation. This is because his definition of the event violates the prohibition against self-belonging (in other words, it is a set-theoretical definition which violates set theory's rules of consistency), thus does not count as extant on its own.\n\nGilles Deleuze lectured on the concept of \"event\" on March 10, 1987. A sense of the lecture is described by James Williams. Williams also wrote, \"From the point of view of the difference between two possible worlds, the event is all important\". He also stated, \"Every event is revolutionary due to an integration of signs, acts and structures through the whole event. Events are distinguished by the intensity of this revolution, rather than the types of freedom or chance.\" In 1988 Deleuze published a magazine article \"Signes et événements\"\n\nIn his book \"Nietszche and Philosophy\", he addresses the question \"Which one is beautiful?\" In the preface to the English translation he wrote:\n\nThe Danish philosopher Ole Fogh Kirkeby deserves mentioning, as he has written a comprehensive trilogy about the event, or in Danish \"begivenheden\". In the first work of the trilogy \"Eventum tantum – begivenhedens ethos\" (Eventum tantum - the ethos of the event) he distinguishes between three levels of the event, inspired from Nicola Cusanus: Eventum tantum as non aliud, the alma-event and the proto-event.\n\n\n"}
{"id": "50186510", "url": "https://en.wikipedia.org/wiki?curid=50186510", "title": "Event Supplier and Services Association", "text": "Event Supplier and Services Association\n\nEvent Supplier and Services Association (ESSA) is a trade association in the United Kingdom which represents contractors and suppliers of goods and services to the exhibition industry.\n\nESSA was established in 2008 to promote the commercial, technical, and service interests of British event companies and suppliers. It was incorporated in 2008 as private company limited by guarantee without share capital. Alongside its sister organisations, the Association of Event Organisers (AEO) and Association of Event Venues (AEV), it aims to integrate the industry with a \"united voice\" and increase its share of the market.\n\n\n\n\n"}
{"id": "10061279", "url": "https://en.wikipedia.org/wiki?curid=10061279", "title": "Event chain methodology", "text": "Event chain methodology\n\nEvent chain methodology is an uncertainty modeling and schedule network analysis technique that is focused on identifying and managing events and relationship between them (event chains) that affect project schedules. Event chain methodology is an extension of quantitative project risk analysis with Monte Carlo simulations. It is the next advance beyond critical path method and critical chain project management. Event chain methodology helps to mitigate the effect of motivational and cognitive biases in estimating and scheduling. It improves accuracy of risk assessment and helps to generate more realistic risk adjusted project schedules.\n\nEvent chain methodology is an extension of traditional Monte Carlo simulation of project schedules where uncertainties in task duration and costs are defined by statistical distribution. For example, task duration can be defined by three point estimates: low, base, and high. The results of analysis is a risk adjusted project schedule, crucial tasks, and probabilities that project will be completed on time and on budget. Defining uncertainties using statistical distribution provide accurate results if there is a reliable historical data about duration and cost of similar tasks in previous projects. Another approach is to define uncertainties using risk events or risk drivers, which can be assigned to different tasks or resources. Information about probabilities and impact of such events is easier to elicit, which improves accuracy of analysis. Risks can be recorded in the Risk register. Event chain methodology was first proposed in the period of 2002-2004. It is fully or partially implemented in a number of software application. Event Chain Methodology is based on six principles and has a number of outcomes.\n\nActivities (tasks) are not a continuous uniform procedure. Tasks are affected by external events, which transform an activity from one state to another. One of the important properties of an event is the moment when an event occurs during the course of an activity. This moment, when an event occurs, in most cases is probabilistic and can be defined using statistical distribution. The original state is called a ground state, other states are called excited states. For example, if the team completes their job on activity, they can move to other activities. The notion of an activity's state is important because certain events can or cannot occur when activity is in certain state. It means that the state of an activity is subscribed to the events. Events can be local, affecting particular tasks or resources, or global affecting all tasks or resources.\n\nEvents can be related to other events, which will create event chains. These event chains can significantly affect the course of the project. \nFor example, requirement changes can cause an activity to be delayed. To accelerate the activity, the project manager allocates a resource from another activity, which then leads to a missed deadline. Eventually, this can lead to the failure of the project. It could be different relationship between events. One event can trigger one or multiple events.\n\nEvents can be correlated with each other without one triggering another one. In this case if one risk has occurred, another one will occur and vice versa. One event assigned in one activity can execute another activity or group of activities. In many cases it the execution of risk response plans. For example, event “structural defect is discovered” can cause one or many activities “Repair”. Events can cause other events to occur either immediately or with a delay. The delay is a property of the event subscription. The delay can be deterministic, but in most cases, it is probabilistic. Also risks can be transferred from one activity to another. To define event chains, we need to identify a \"sender\", the event that initiates the chain of events. The sender event can cause one or more events that effect multiple activities. These are called \"receiver\" events. In turn, the receiver events can also act as sender events.\n\nEvent chain diagram is a visualization that shows the relationships between events and tasks and how the events affect each other. The simplest way to represent these chains is to depict them as arrows associated with certain tasks or time intervals on the Gantt chart. Here are a few important rules:\n\nBy using event chain diagrams to visualize events and event chains, the modeling and analysis of risks and uncertainties can be significantly simplified.\nAnother tool that can be used to simplify the definition of events is a state table. Columns in the state table represent events; rows represent the states of an activity. Information for each event in each state includes four properties of event subscription: probability, moment of event, excited state, and impact of the event.\n\nOnce events and event chains are defined, quantitative analysis using Monte Carlo simulation can be performed to quantify the cumulative effect of the events. Probabilities and impacts of risks assigned to activities are used as input data for Monte Carlo simulation of the project schedule. In most projects it is necessary to supplement the event based variance with uncertainties as distributions related to duration, start time, cost, and other parameters.\n\nIn Event chain methodology, risk can not only affect schedule and cost, but also other parameters such as safety, security, performance, technology, quality, and other objectives. In other words one event can belong to different categories. The result of the analysis would show risk exposure for different categories as well as integrated project risk score for all categories. This integrated project risk score is calculated based on relative weights for each risk category.\n\nMonte Carlo simulation provides the capability, through sensitivity analysis, to identify single or chains of events. These chains of events can be identified by analyzing the correlations between the main project parameters, such as project duration or cost, and the event chains. These are called “critical events” or “critical chains of events”. By identifying critical events or critical chains of events, we can identify strategies to minimize their negative effects: Avoid, Transfer, Mitigate, or Accept. Event and event chain ranking is performed for all risk categories (schedule-related and non-schedule) as part of one process. Integrated risk probability, impact and score can be calculated using weights for each risk category.\n\nMonitoring the activity's progress ensures that updated information is used to perform the analysis. During the course of the project, the probability and time of the events can be recalculated based on actual data. The main reason for performance tracking is forecasting an activity’s duration and cost if an activity is partially completed and certain events are assigned to the activity. Event chain methodology reduces the risk probability and impact automatically based on the percent of work completed. Advanced analysis can be performed using a Bayesian approach. It is possible to monitor the chance that a project will meet a specific deadline. This chance is constantly updated as a result of the Monte Carlo analysis. Critical events and event chains can be different at the various phases of the project\n\nSometimes events can cause the start of an activity that has already been completed. This is a very common scenario for real life projects; sometimes a previous activity must be repeated based on the results of a succeeding activity. Event chain methodology simplifies modeling of these scenarios The original project schedule does not need to be updated, all that is required is to define the event and assign it to an activity that points to the previous activity. In addition, a limit to the number of times an activity can be repeated must be defined.\n\nIf an event or event chain occurs during the course of a project, it may require some risk response effort. \nRisk response plans execution are triggered by events, which occur if an activity is in an excited state. Risk response events may attempt to transform the activity from the excited state to the ground state. Response plans are an activity or group of activities (small schedule) that augment the project schedule if a certain event occurs. The solution is to assign the response plan to an event or event chain. The same response plan can be used for one or more events.\n\nOne potential event is the reassignment of a resource from one activity to another, which can occur under certain conditions. For example, if an activity requires more resources to complete it within a fixed period, this will trigger an event to reallocate the resource from another activity. Reallocation \nof resources can also occur when activity duration reaches a certain deadline or the cost exceeds a certain value. Events can be used to model different situations with resources, e.g. temporary leave, illness, vacations, etc.\n\n\n\n"}
{"id": "18515583", "url": "https://en.wikipedia.org/wiki?curid=18515583", "title": "Event management software", "text": "Event management software\n\nEvent management software is the generic term for a wide range of software products that are used in the management of professional and academic conferences, trade exhibitions, conventions and smaller events such as Continuing Professional Development (CPD) meetings.\n\nThe most common event management applications are:\n"}
{"id": "1647073", "url": "https://en.wikipedia.org/wiki?curid=1647073", "title": "Event videography", "text": "Event videography\n\nEvent videography is a video production, the art of capturing social and special events onto video by a videographer. The term is used to describe the videography of any event, aside from weddings and wedding videography.\n\nEvent videography is an offshoot of wedding videography and encompasses the video documentation of social functions, such as First Communions, anniversaries, dance recitals, bar mitzvahs, color guard contests, proms, concerts, etc.\n\nEvent videography started shortly after the introduction of consumer-based video cameras, or camcorders, in the late 1970s, as videographers, who had businesses documenting weddings, began to look for other markets to offer their services.\n\nThe art of event videography is somewhat similar today as it was back when the camcorder was first introduced. The main differences lie in the improved video camera technology and equipment. Advances in high definition technology are being applied to event videography.\n\n"}
{"id": "52443600", "url": "https://en.wikipedia.org/wiki?curid=52443600", "title": "Funke Bucknor-Obruthe", "text": "Funke Bucknor-Obruthe\n\nFunke Bucknor-Obruthe (born 27 June 1976) is a Nigerian entrepreneur and lawyer. She is the founder and CEO of Zapphaire Events and is regarded as one of Nigeria's pioneering event planners.\n\nBucknor-Obruthe was born to Segun and Shola Bucknor in Lagos State, Southwestern Nigeria. She began her basic and secondary school education at Fountain Nursery and Primary School, Lagos, and Nigeria Navy Secondary School, Lagos, before she proceeded to study Law at the University of Lagos. In 2000, she was called to bar after attending the Nigerian Law School in Abuja.\n\nAfter practising law briefly, Bucknor-Obruthe was employed at Tie Communications, an advertisement agency, where she worked for a short period. In 2003, her love for event planning made her start Zapphaire Events, an independent event planning enterprise. She has since gone on to plan and organize several high-profile events within and outside Nigeria and has won awards and recognition including being featured in CNN's \"Inside Africa\" for planning a Nigerian royal wedding. Some of these include the Future Award for \"Entrepreneur of the Year\" (2006), the \"Wedding Planner Magazine\" Award for \"Wedding Planner of the Year\" (2007), Go2girl Life Achievement Awards (2011), Nigerian Events Awards for Outstanding Contribution to the Events Industry (2012).\n\n\nIn 2014, Nigerian online magazine \"YNaija\" listed Bucknor-Obruthe in its \"10 Most Powerful Under-40s in Business\". In 2016, she was listed in the BBC's \"100 Women\" series.\n\nBucknor-Obruthe is married to Onome Obruthe, with whom she has two children. She is the elder sister of Nigerian media personality Tosyn Bucknor.\n"}
{"id": "16191394", "url": "https://en.wikipedia.org/wiki?curid=16191394", "title": "Geohazard", "text": "Geohazard\n\nA geohazard is a geological state that may lead to widespread damage or risk. Geohazards are geological and environmental conditions and involve long-term or short-term geological processes. Geohazards can be relatively small features, but they can also attain huge dimensions (e.g., submarine or surface landslide) and affect local and regional socio-economy to a large extent (e.g., tsunamis).\n\nHuman activities, such as drilling through overpressured zones—could result in significant risk, and as such mitigation and prevention are paramount, through improved understanding of geohazards, their preconditions, causes and implications. In other cases, particularly in montane regions, natural processes can cause catalytic events of a complex nature, such as an avalanche hitting a lake causes a debris flow, with consequences potentially hundreds of miles away, or creating a lahar by volcanism.\n\nThe continued and multi-disciplinary investigation into the occurrence and implications of geohazards, in particular offshore geohazards in relation with the oil and gas exploration, lead to specific mitigation studies and establishing relevant prevention mechanisms.\n\n\nEleven distinct flood basalt episodes occurred in the past 250 million years, resulting in large volcanic provinces, creating plateaus and mountain ranges on Earth. Large igneous provinces have been connected to five mass extinction events. The timing of six out of eleven known provinces coincide with periods of global warming and marine anoxia/dysoxia. Thus, suggesting that volcanic CO2 emissions can force an important effect on the climate system.\n\n"}
{"id": "42286204", "url": "https://en.wikipedia.org/wiki?curid=42286204", "title": "GigMasters", "text": "GigMasters\n\nGigMasters Inc. is an event services booking platform. It is headquartered in South Norwalk, Connecticut.\nGigMasters matches entertainers with planners of weddings, dances, parties, festivals, celebrations and corporate events.\n\nGigMasters was founded in 1997 by New York area entrepreneurs Michael Caldwell and Kevin Kinyon. In February of that year, the company launched the first version of its website. In September 2010, GigMasters raised $200,000 in expansion funding from investor James Marciano.\n\nIn 2013, about half of the company's booking were wedding-related. In November 2013, the company raised $1.3 million in series A funding by XO Group, parent company of TheKnot.com. Kristin Savilia, XO Group's Executive Vice President, joined GigMasters' board of directors.\n\nIn September 2014, Inc. Magazine ranked GigMasters as one of the nation's 5000 fastest growing private companies.\n\nIn October, 2015, the Caldwell and Kinyon, creators of GigMasters, sold the company for $8.5 million to XO Group.\n\nGigMasters sorts entries by instrument and by event or service type. Musicians create profiles and describe their services. Potential customers can enter their location and search for the service they need.\n"}
{"id": "40929468", "url": "https://en.wikipedia.org/wiki?curid=40929468", "title": "Hunchun incident", "text": "Hunchun incident\n\nThe Hunchun incident (October 2, 1920) was a reported raid on a Japanese consulate in Manchuria resulting in the death of thirteen Japanese. The Japanese government used this incident to justify sending thousands of Imperial Japanese troops into Manchuria on October 5, 1920. These escalations culminated with the Battle of Qingshanli (October 21–26, 1920) between Japan and the Korean Independence Army, where Korean rebels fought Japanese soldiers.\n\nFor more than a decade prior to Korea’s March 1st Movement (1919) nationalist groups of Korean rebels, many of whom were former soldiers in the Korean army, organized into various pro-independence factions in Manchuria. Due to its strategic location across the Korean border, guerilla fighters could effectively launch raids on Japanese consular police stations, and then retreat back to the Chinese side of the boundary. For example, Hong Pomdo (a previous Righteous Army leader) created the Korean Independence Army and trained so-called independence fighters in Yanji. Additionally, the Northern Route Military Headquarters was established under the leadership of So Il, with Kim Chwajin commanding more than four hundred independence fighters at its officer training school. Separately, Yi Tonghwi also trained over 3,000 independence fighters in Hunchun and armed them with weapons provided by the Red Bolshevik army.\n\nResponding to the March 1st Movement’s failure to secure independence and arouse international sentiments toward the Koreans’ plight under Japanese colonial rule, disaffected Koreans came together on April 13, 1919 in Shanghai to form a republican Korean provisional government with the hope of working together with the independence factions in Manchuria to eventually obtain freedom from Japan.\n\nAs the momentum behind Korean independence movements in Manchuria increased, Japanese consular police chief Suematsu Kichiji became increasingly concerned about increasing radical Bolshevism among Koreans. To try and suppress these movements, he ordered numerous illegal police raids on suspected radical Jiandao base camps, which were protested by local Chinese leaders. While it is clear that some of the Korean guerrilla fighters in Manchuria were influenced by leftist ideologies, the major factions primarily supported the Shanghai Provisional Government and were focused primarily on Korean independence and self-determination.\n\nAngered by the Japanese suppression of the March 1st Movement, Korean independence fighters in Manchuria began increasing their raids against Japanese border posts, killing numerous Japanese guards, with the eventual goal of advancing into Korea to remove the Japanese. During the early summer months of 1920, Korean rebels fought with Japanese troops in thirty-two battles along the border. After one particular Japanese counterattack, Hong Pomdo’s forces surrounded and killed 120 Japanese soldiers and wounded more than 200.\n\nIn effort to contain the Korean rebels, Japan petitioned both Tokyo and the Chinese government to help, but received little assistance. Subsequently, on October 2, 1920, a Japanese consulate in the Chinese city of Hunchun in Jilin Province was attacked and burned to the ground purportedly (according to Japanese sources) by the Korean Independence Army, killing thirteen Japanese people. It was further reported that the “bandits” carrying out this attack “committed indiscriminate acts of murder and pillage” and “looted local shops.”\n\nMany South Korean historians maintain, however, that the attack on Hunchun was not carried out by the Korean rebels, but rather was staged by the Japanese to justify incursion into Manchuria. Some South Korean sources further believe that the attack was coordinated with Chinese bandit leader Ch'ang-chiang-hao who had been bribed by the Japanese to carry out the attack with several bandits in order to incriminate the Koreans. These sources maintain that Chang went further than the Japanese had requested him to in the scale of his attack. Other South Korean scholars even maintain that the entire incident was a complete Japanese fabrication.\n\nNorth Korea is likewise skeptical about the Japanese narrative of the incident, with official sources recently asserting that “the Japanese imperialists cooked up the ‘Hunchun incident’ in which they hurled mounted bandits into attacking their consulate and kicked up a wholesale whirlwind of suppression against Koreans in Northeast China under that pretext.”\n\nThough it is difficult for historians to determine who was behind the attack, or whether the incident actually took place, this controversial event is historically significant because Japan used it to justify its escalated military intervention in Manchuria. Japan petitioned and received permission from China to send 15,000 troops from the 19th Division of the Chosen Army of Japan to contain the Korean rebel armies in Jilin province.\n\nIn reaction to the Hunchun incident, a Japanese punitive “Jiandao Expedition” was accordingly sent to Manchuria, and used “search and destroy” patrols to suppress the guerrilla fighters by carrying out numerous arrests and executions. By December 1920, a Korean Commission report described that Japanese soldiers had burned down thirty-two villages and killed “all the male inhabitants of the [Hunchun] district, and massacred 145 peaceful inhabitants.” One house was reportedly burned down with “women and children inside.”\n\nThough Korean independence forces in Manchuria were never effectively organized under the leadership of the Shanghai Provisional Government, they did achieve notable military victories against the Japanese brigades. The most significant of these was the Battle of Qingshanli, where about 400 Korean rebels were able to defeat the better-trained Japanese after four days of intense combat. In this battle the Koreans killed about 1,200 Japanese soldiers while losing only 60 of their own. However, according to Japanese records, 11 soldiers were killed in action, 24 wounded.\n\nIn early 1921, after a series of skirmishes and retreats on both sides, as well as criticism from local Chinese authorities and the international community, most members of the 19th Division withdrew from eastern Manchuria. Some of the socialist-leaning Korean rebels were then recruited by the Red Bolshevik army to assist in its civil war prior to the formation of the Soviet Union.\n"}
{"id": "572337", "url": "https://en.wikipedia.org/wiki?curid=572337", "title": "International crisis", "text": "International crisis\n\nThe term international crisis is widespread term without a single common definition. To some, it involves \"a sequence of interactions between the governments of two or more sovereign states in severe conflict, short of actual war, but involving the perception of a dangerously high probability of war\".\n\nLebow gives a breakdown of three types of international crises:\n\nWith the exception of a justification of hostilities, the study of international crises assumes that neither side actually wants to go to war, but must be visibly prepared to do so. In the words of Groucho Marx, \"Always be sincere, even if you don't mean it\".\n\nGeorge's book presents an overview of the process and conflicting goals of crisis management as well as many examples. He discusses a number of strategies, including:\n\n\n\nInternational crises tend to result in war, almost by definition; they are then remembered best not as crises but as causes of wars. For information on international crises that resulted immediately in war, see List of wars.\n\nGiven the above, some of the crises that are best-known \"as crises\" were defused. The following crises did not immediately provoke large-scale violence, but set of anger in countries:\n\n\n\n\n"}
{"id": "163678", "url": "https://en.wikipedia.org/wiki?curid=163678", "title": "Kalimantaan", "text": "Kalimantaan\n\nKalimantaan is a novel by C. S. Godshalk offering a fictionalized account of the exploits of James Brooke in Sarawak in Borneo.\n\nThe novel uses of a variety of writing forms, including diary entries, letters, and straight narrative to tell its story. The author intentionally makes it difficult to determine what \"really\" happens in the story from dreams and fantasies of the characters.\n\nIn 1839, an English adventurer arrived on the northwest coast of Borneo, commissioned to deliver a letter of gratitude to the Sultan of Brunei for having safely returned the crew of a British merchantman, lost on his coast. It was a region full of headhunters, pirate tribes, and slave traders. Most Europeans with the temerity to enter the region had never been heard from again. This particular adventurer, however, seems to know how to play one power against another and manages to keep his balance in the midst of chaos. After performing a service for the Sultan (resolving a local tribal conflict through the use of his schooner's guns and leading an organized assault on a small native river fort), he is named governor of Sarawak, subject to the Sultan of Brunei. Within a few years, he has become the Rajah of Sarawak, an independent state, and established a dynasty that will last one hundred years.\n\nGodshalk has changed names and details while evoking a sense of the time, place, and atmosphere of the real events. The real adventurer was James Brooke; Ms. Godshalk's is named Gideon Barr. James Brooke's schooner was named the \"Royalist\"; Gideon Barr's is the \"Carolina\" (named after his mother). James Brooke was succeeded by his nephew, Charles Johnson, who took the last name Brooke. Gideon Barr is succeeded by his nephew Richard Hogg (Ms. Godshalk does not deal with the change of last name since her story focuses on Gideon's life and ends with his death).\n\nAlthough many of the events described actually took place, one cannot simply change the names and read the novel as history. James Brooke's mother died in 1844, two years after he became Rajah. Gideon's mother dies in Borneo much earlier while he is in grade school in England, providing him an emotional link to Borneo James Brooke did not have. James Brooke never married a European, although there is evidence that he was married to a Malay woman. Gideon Barr marries an Englishwoman to provide himself an \"air of permanence\" as Rajah and we see much of the later portion of the story through Amelia Barr's eyes. Amelia Barr is fictional, but largely based on Margaret Brooke, wife of the second Rajah, and her book \"My Life in Sarawak\". Gideon also maintains a Malayan mistress who provides a note of tragedy in the way her presence poisons Gideon and Amelia's relationship.\n\nOn the other hand, the 30,000 pounds that Brooke/Barr inherited at his father's death which enabled him to acquire his schooner, the massacre of the sons of the Sultan of Brunei, the Chinese insurrection of 1857, and the commission of inquiry in Singapore all took place as described. The inquiry in Singapore was concerned with the battle of Labuan in which Brooke/Barr led British warships in a pre-emptive strike against a pirate fleet, breaking the power of the Bugis for the next twenty years. Brooke/Barr's enemies attempted to use this against him by claiming he had used British naval power to slaughter innocent natives.\n\nGodshalk uses Malay words extensively in the book. While she provides a brief Malay glossary as an appendix, it does not cover all the words she uses. Enjoyment of \"Kalimantaan\" will be enhanced if one knows the following Malay words which are not in the glossary provided by the author:\n\n\"Kampilan\", actually a Filipino word, designates a long native sword.\n\n"}
{"id": "20820712", "url": "https://en.wikipedia.org/wiki?curid=20820712", "title": "Katie Martin", "text": "Katie Martin\n\nKatie Martin (born Katie Louise Van Veen on January 8, 1972) is an American consultant in eco-friendly special events, floral design, and green events and life styles.\n\nMartin was born in Washington, DC. She graduated from the University of Maryland, College Park, in 1994 with a BS in accounting. She has one son and is married to Neftali Miguel Vasquez Perez.\n\n\nMartin’s work also has been showcased in \"DC Modern Luxury Magazine\", \"Flower Magazine\", \"Catering Magazine\", \"Florists' Review\", \"Washington Woman\", \"Grace Ormonde\", \"Upscale Magazine\", \"Bride & Bloom\", \"Modern Bride\", \"My Day Magazine\", \"The Knot\", \"Engaged Magazine\", and \"La Bella Bride\".\n\nFounded in 1998, Martin's wedding and event planning company, Elegance & Simplicity Wedding & Event Designers, Inc. (located in Bethesda, Maryland with a sister office in Santo Domingo, Dominican Republic) has planned about 3,500 weddings worldwide. Martin also founded and runs Green Life DC, a consulting firm that helps individuals, families, events and businesses be more environmentally friendly.\n\nCurrently Martin is writing a book on green weddings.\n\n"}
{"id": "43209882", "url": "https://en.wikipedia.org/wiki?curid=43209882", "title": "Killing of Sergio Guereca", "text": "Killing of Sergio Guereca\n\nOn June 7, 2010, Jesus Mesa Jr., a U.S. Border Patrol agent, shot and killed Sergio Adrian Hernandez Guereca on the concrete riverbed separating Ciudad Juarez, Chihuahua, Mexico and El Paso, Texas. At the time of the shooting Guereca, a 15-year-old-Mexican national was standing on the Mexican side of the Mexico–United States border, while the agent was on the American side. The agent claimed after the shooting that he had used deadly force because Guereca had been throwing rocks.\nThe shooting led to a protracted court case which examined whether the 5th amendment protected Guereca's life even though he was not standing on US soil. The case was heard by the Supreme Court of the United States in February 2017.\n"}
{"id": "48494190", "url": "https://en.wikipedia.org/wiki?curid=48494190", "title": "Kurram incident", "text": "Kurram incident\n\nOn 30 September 2010, U.S. helicopters entered Pakistani airspace after ground troops determined that a mortar attack by militants in Pakistan was imminent, according to the Coalition. Pakistani Frontier Corps troops manning the Mandata Kadaho border post fired warning shots, and the helicopters responded by firing two missiles that destroyed the post. Three soldiers were killed and another three wounded. Pakistan responded by closing a key NATO supply route for eleven days.\n"}
{"id": "40979521", "url": "https://en.wikipedia.org/wiki?curid=40979521", "title": "Leander Tomarkin", "text": "Leander Tomarkin\n\nLeander William Tomarkin (13 December 1895 – 1967) was a Swiss impostor who claimed to possess a doctorate in medicine, as well as to have invented a miracle medicine for the cure of typhus, tuberculosis, meningitis, and malaria. He ascended to become the personal physician of Victor Emmanuel, king of Italy, and he convinced Albert Einstein to become patron of a conference organised by him.\n\nLeander Tomarkin was born on 13 December 1895 in Zollikon, Switzerland. A doctor's son, he was the black sheep of the family, obtaining bad results at school and dropping a chemistry degree at college. He also soon developed a reputation of dishonesty. He did not take up regular employment but spent his time in his father's laboratory, hoping to invent something.\n\nTomarkin rose to fame when he offered to cure Pope Benedict XV pneumonia in January 1922. The Pope died without Tomarkin being allowed to treat him but reporters subsequently picked up the story and enabled the progress of Tomarkin's medical career with publicising his \"Antimicrobum tomarkin\" medicine, whose active ingredient he named \"Aminoortobenzoilsulfoisoamiloidrocupronucleinforminsodico\". The Antimicrobum was to reduce pneumonia mortality from about one third to 2%. Tomarkin was allowed to treat a cousin of Victor Emmanuel III of Italy, and the cousin recovered. As a result the king named Tomarkin the personal physician of the family. A clinical test at the Santo Spirito hospital in Rome was also successful, later attributed to the better care for test patient and the relatively early stage of pneumonia that the patients were in.\n\nIn May 1924 Tomarkin emigrated to the United States, and three years later founded Tomarkin-Foundation Chemistry Research. At this research centre he developed \"Catalysan\" and \"Disulphamin\", claiming that these medicines bring about mood changes and treat sickness in that way. The Tomarkin Foundation soon spread to Europe. Its dependency in Locarno started to organise conferences between 1930 and 1938. These conferences were set beautifully and had rich side programs and thus attracted prominent people such as surgeon Ferdinand Sauerbruch. In 1931 Albert Einstein assumed the honorary presidency of the conference. Einstein only stayed in that position for one year, after a former landlady of Tomarkin contacted him to help retrieve debts.\n\nAt the onset of World War II Tomarkin again emigrated to the US, due to his Jewish ancestry. With the development of industrially manufactured antibiotics in 1939 his medical invention became obsolete. He ventured into other areas, trying to invent waterproof paint and synthetic diamonds but was unsuccessful with both. Tomarkin died in 1967.\n\n\n"}
{"id": "30835697", "url": "https://en.wikipedia.org/wiki?curid=30835697", "title": "Led Zeppelin – The 1980s, Part One", "text": "Led Zeppelin – The 1980s, Part One\n\nLed Zeppelin – The 1980s, Part One was a planned autumn 1980 concert tour of North America by the rock band Led Zeppelin. It was scheduled to take place from 17 October through 15 November of that year and cover much of the East Coast and Midwest. The band cancelled the tour when drummer John Bonham died on 25 September, one day after the group's initial rehearsal for the tour.\n\nIn the wake of Led Zeppelin's turmoil-plagued 1977 American tour, which ended abruptly with the sudden death of his son Karac, singer Robert Plant had become averse to touring America with the band. His reluctance to do so persisted despite the success of the \"In Through the Out Door\" album and the band's return to the stage at the 1979 Knebworth Festival after a two-year absence. Following the conclusion of Led Zeppelin's successful Tour Over Europe 1980, however, Plant had a change of heart and informed Led Zeppelin's manager Peter Grant that he was willing to undertake an American tour with the band in the autumn of 1980. According to writer Mick Wall, though,\n\nGrant had been concerned about the band's lengthy absence from one of its primary markets, and had correctly viewed the European tour as a way of rekindling Plant's interest in performing in America. Relieved by Plant's change of heart and mindful of the singer's conditions, Grant began planning a nineteen-date tour covering the American East Coast and Midwest, and envisioned Led Zeppelin undertaking additional West Coast and UK tours in early 1981. The band began preparations for the tour with renewed optimism about Led Zeppelin's future, with John Paul Jones in particular commenting that the band had \"new energy\" and was \"almost in a rebirth situation.\" John Bonham's death, however, resulted in the scuttling of the band's touring plans, and ultimately in the demise of Led Zeppelin itself, with the breakup of the band officially announced on 4 December 1980.\n\nWhile Jones's view of the state of Led Zeppelin on the eve of the 1980 North American tour was a positive one, writer Chris Welch saw things differently. In his biography of Peter Grant, Welch questioned the wisdom of the band undertaking a U.S. tour at that point in time:\n\nWelch and writers Dave Lewis and Mick Wall particularly questioned John Bonham's physical and emotional fitness to tour North America at that stage. They note that by the fall of 1980 Bonham's dislike of touring, which had been steadily growing over the years, was virtually as strong as Plant's. He was particularly nervous about the potential backlash he might experience in the U.S. from his involvement in the backstage brawl at the Oakland Coliseum during Led Zeppelin's 1977 tour. As Bonham grew older, moreover, the demands of touring—along with the effects of his alcohol and drug use—took an increasing toll on his energy and stamina, and by 1980 he was struggling with fatigue. He had already permanently dropped his lengthy drum solos from the band's onstage performances. While he came across to Lewis at the time as \"delighted\" about the upcoming trek, Bonham privately confided on the eve of the ill-fated rehearsals for \"Led Zeppelin - The 1980s, Part One\" that he felt depressed and uneasy about going on tour, and that he felt his drumming was no longer up to scratch. He reportedly told Plant, \"I've had it with playing drums. Everybody plays better than me. I'll tell you what, when we get to the rehearsal, you play the drums and I'll sing.\" After that initial rehearsal on 24 September, he complained again about going on tour while engaging in a drinking binge that would prove to be fatal.\n\nIronically, on 25 September, at the same time the rest of the band and its entourage were learning of Bonham's death, thousands of Led Zeppelin fans in Chicago were eagerly obtaining copies of that day's \"Chicago Tribune\" containing mail order applications for the upcoming November concerts. This proved to be fruitless since the tour was immediately cancelled.\n\nThe intended tour itinerary was as follows:\nFor the concerts on this tour, the band intended to use a scaled-down approach similar to the one they used for the European tour, which entailed fewer lighting effects, less improvisation, and fewer extended solos than their 1970s concerts. The previously rehearsed but unperformed \"In Through the Out Door\" track \"Carouselambra\" was included in the tentative set-list.\n\n"}
{"id": "10150504", "url": "https://en.wikipedia.org/wiki?curid=10150504", "title": "List of auto shows and motor shows by continent", "text": "List of auto shows and motor shows by continent\n\nAn auto show (also: motor show or car show) is a public exhibition of current automobile models, debuts, concept cars, or out-of-production classics. The five most prestigious auto shows, sometimes called the \"Big Five\", are generally considered to be held in Frankfurt, Geneva, Detroit, Paris and Tokyo.\n\n\n\n\n\n\n\n"}
{"id": "12261050", "url": "https://en.wikipedia.org/wiki?curid=12261050", "title": "List of games with concealed rules", "text": "List of games with concealed rules\n\nGames with concealed rules are games where the rules are intentionally concealed from new players, either because their discovery is part of the game itself, or because the game is a hoax and the rules do not exist. In fiction, the counterpart of the first category are games that supposedly do have a rule set, but that rule set is not disclosed.\n\n\n\n\n\n\n"}
{"id": "5531650", "url": "https://en.wikipedia.org/wiki?curid=5531650", "title": "List of helicopter prison escapes", "text": "List of helicopter prison escapes\n\nA helicopter prison escape is made when an inmate escapes from a prison by means of a helicopter. This list includes prisoner escapes where a helicopter was used in an attempt to free prisoners from a place of internment, a prison or correctional facility.\n\nOne of the earliest instances of using a helicopter to escape a prison was the escape of Joel David Kaplan, nicknamed \"Man Fan\", on August 19, 1971 from the Santa Martha Acatitla in Mexico. Kaplan was a New York businessman who not only successfully escaped the prison but eventually escaped Mexico and went on to write a book about his experience, \"The 10-Second Jailbreak\".\n\nFrance has had more recorded helicopter escape attempts than any other country, with at least 11. One of the most notable French jail breaks occurred in 1986, when the wife of bank robber Michel Vaujour studied for months to learn how to fly a helicopter. Using her newly acquired skills, she rented a white helicopter and flew low over Paris to pluck her husband off the roof of his fortress prison. Vaujour was later seriously wounded in a shootout with police, and his pilot wife was arrested.\n\nThe record for most helicopter escapes goes to convicted murderer Pascal Payet, who has used helicopters to escape from prisons in 2001, 2003, and most recently 2007.\n\nAnother multiple helicopter escapee is Vasilis Paleokostas who on February 22, 2009 escaped for the second time from the same prison. Because of this, many prisons have taken applicable precautions, such as nets or cables strung over open prison courtyards.\n\n"}
{"id": "2281261", "url": "https://en.wikipedia.org/wiki?curid=2281261", "title": "List of historical reenactment events", "text": "List of historical reenactment events\n\nThis is a list of historical reenactment events.\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "34657877", "url": "https://en.wikipedia.org/wiki?curid=34657877", "title": "List of occasions known by their dates", "text": "List of occasions known by their dates\n\nThis is a list of occasions, such as holidays and events, named after or commonly referred to by the calendar day on which they fall.\n\n"}
{"id": "942315", "url": "https://en.wikipedia.org/wiki?curid=942315", "title": "List of peasant revolts", "text": "List of peasant revolts\n\nThis is a chronological list of conflicts in which peasants played a significant role.\n\nHistory of peasant wars spans over a period of over two thousand years. A variety of reasons fueled the emergence of the peasant revolt phenomenon, including:\n\n\nLater peasant revolts such as the Telangana Rebellion were also influenced by agrarian socialist ideologies.\n\nThe majority of peasant rebellions ended prematurely and were unsuccessful. Peasants suffered from limited funding and lacked the training and organisational capabilities of professional armies.\n\nThe list gives the name, the date, the peasant allies and enemies, and the result of these conflicts following this legend:\n\n\n"}
{"id": "487164", "url": "https://en.wikipedia.org/wiki?curid=487164", "title": "List of public lecture series", "text": "List of public lecture series\n\nRecurrent series of prestigious public lectures are presented in various countries.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "24912020", "url": "https://en.wikipedia.org/wiki?curid=24912020", "title": "List of royal weddings", "text": "List of royal weddings\n\nA royal wedding is a marriage ceremony involving members of a royal family. Weddings involving senior members of the royal family are often seen as important occasions of state and attract significant national and international attention. The following is a list of notable royal weddings:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "1681795", "url": "https://en.wikipedia.org/wiki?curid=1681795", "title": "Local news", "text": "Local news\n\nIn journalism, local news refers to coverage of events, by the news, in a local context that would not be an interest of another locality, or otherwise be of national or international scope. Local news, in contrast to national or international news, caters to the news of their regional and local communities; they focus on more localized issues and events. Some key features of local newsrooms includes regional politics, business, and human interest stories. Local news readership has been declining in recent years, according to a recent study.\n\nOpt-outs of local television news are frequent before, during, or after national evening news television programming. Often times, television networks can also commission or make provisions for their local stations to produce a longer standalone local news programmes. In some cases, local television markets/viewing areas within a country may even have a dedicated 24-hour local news channel. Local news stations have also started covering less and less local politics in favor of stories that they believe will garner more clicks or attention. A study has also shown that there has also been less investigative journalism within local news stations in recent years.\n\nLocal news largely covers the following:\n\nNational and international news, however, tend to cover a wider range of content, including news concerning specialized institutions of wide-ranging international power or influence, such as:\n\nIn the United States, local news is provided on local commercial broadcasting channels (some of which are television network affiliates). They can either be standalone newscasts that run for at least a half-hour or short segments that air attached to national morning newscasts approximately 25 and 55 minutes past the hour. As not all stations are owned and operated by a television network, the graphics, branding, and studio designs of a station's newscasts often differ from the network they are affiliated with although in recent years, affiliates have made some form of on-air reference to their corresponding networks in the branding of their newscasts. In addition, the local news departments of stations also superimpose their on-screen digital clocks, thermometers, and (occasionally) local news tickers on graphics provided by networks during morning network newscasts. Some cable channels are dedicated to local news coverage. Examples of this include NY1 in New York and NewsChannel 8 in the Washington DC market.\n\nIn the United Kingdom, most local news is provided on a local network station with similar branding and studio design to that of the national network news. Examples of this include the nationally networked BBC News and its regional news services such as BBC North West Tonight (on BBC North West) and BBC Newsline (on BBC Northern Ireland); the nationally networked ITV News and its regional stations including ITV Granada and UTV. The long version of BBC and ITV's local news shows often air during the 18:00 hour on weekday evenings. STV, which simulcasts most of the ITV network's programmes in Scotland, is not owned and operated by ITV but has its own branded newscast that broadcasts Scottish-centred news at the same time as ITV's regional news services.\n\nIn France, most local news is aired on France Televisions' France 3. Additionally BFM TV also has a local news channel for the Ile-de-France region called BFM Paris.\n\nNorway's public broadcaster, NRK1, airs a local news programme called NRK Distriktsnyheter (name of viewing area) every weekday evening at 18:45 Central European Time, just before the main national newscast Dagsrevyen. A replay of all local newscasts across the country is shown on NRK2 the following morning (Tuesday to Saturday).\n\nIn Sweden, SVT's regional news is simply called SVT Nyheter (name of viewing area) which shares the same branding as the network's main newscast, Rapport. Unlike SVT's counterparts in the US and UK, during morning programmes, the local news opt-out airs in the middle of each half-hour. Since June 2007, the morning regional cut-ins no longer feature an in-studio presenters but instead show compiled short reports from various correspondents across the region. When SVT World was still airing, the simulcast of the morning programme featured a different regional opt-out during each half-hour. A 13-minute standalone local newscast airs at 18:30 Central European Time each weekday evening after Sportnytt (SVT's sport news) on SVT1. Additionally, a short local news segment is incorporated into SVT's other evening newscast Aktuellt which airs on SVT2. In that case, this local news segment shares the same branding and graphics as Aktuellt. There are no local SVT newscasts on Saturdays.\n\nA lot of newspapers specialise in covering the cities they are based in. Although paper copies of local newspapers are usually sold and circulated exclusively in the local areas they operate (with entities such as libraries or relatives wanting a copy of the paper where a family member is mentioned being mailed copies of outside of circulation areas), companies may make digital copies of their newspapers available to interested readers directly on their website or through services such as PressReader often with a paid subscription.\n\nIn the United States, although newspapers such as \"The New York Times\" and \"The Washington Post\" have a 'national' focus on their front pages, they still have dedicated sections for news in the areas they are based in. Weather sections also highlight conditions in the local area and the sport sections feature local teams alongside national sport stories. Their local editions also feature local classified ads.\n\nIn the age of digital media, local news readership has started to fall. This can be attributed to the younger generation's disinterest in traditional news sources and the inability of news stations to fully integrate their business models and practices into the age of digital journalism. While national and international news industries began using Twitter as a way to break news and interact with their audiences, local news mediums have fallen behind, trending towards using Twitter as a secondary source for spreading information rather than a primary tool for audience engagement.\n\nSince Internet sites reach a larger audience, more local news agencies have started their own websites to compete in the digital age. Websites are a great way for local news stations to produce more interactive content, which engages the audiences and increases readership.\n\nAside from the Internet, Twitter specifically has become a great way to engage the younger generation in news, gain more readership, and spread information. National news sources have started using Twitter to quickly notify the public of breaking news and to interact with their readers, but local news have failed to integrate Twitter and other forms of social media into their journalism practices as successfully. While local TV news stations have actually been a bit more effective with using social media, local newspapers have overall fallen behind. By engaging the audience and spreading important information, social media has been considered a solid method for strengthening the core standards of journalism. As a result, social media like Twitter has become a vital tool for news agencies to incorporate into their everyday practices.\n\nAs a result of the transition to digital content, local news agencies have had to change their business models. Although they previously gained revenue from subscriptions, more agencies have started making money from online advertising, but this only accounts for a small portion of revenue. This loss in revenue has been linked to a decline in local journalistic integrity, because with less profit, the need to make money through clickbait articles has become a necessity.\n\n"}
{"id": "13041514", "url": "https://en.wikipedia.org/wiki?curid=13041514", "title": "Neocatastrophism", "text": "Neocatastrophism\n\nNeocatastrophism is the hypothesis that life-exterminating events such as gamma-ray bursts have acted as a galactic regulation mechanism in the Milky Way upon the emergence of complex life in its habitable zone. It is proposed as an explanation of Fermi's paradox since it provides a mechanism which would have delayed the otherwise expected advent of intelligent beings in the local galaxy nearby to Earth. This is an avenue to explain why none so far have been detected by humans.\n\nIt is estimated that Earth-like planets in the Milky Way started forming 9 billion years ago, and that their median age is 6.4 ± 0.7 Ga. Moreover, 75% of stars in the galactic habitable zone are older than the Sun. This makes the existence of potential planets with evolved intelligent life more likely than not to be older than that of the Earth (4.54 Ga). This creates an observational dilemma since interstellar travel, (even of the \"slow\" kind that is nearly within the reach of present Earth technology) could in theory, if this had arisen elsewhere, take from only 5 million to 50 million years to colonize the galaxy. This leads to a conundrum first posed in 1950 by the physicist Enrico Fermi in his namesake paradox: \"Why are no aliens or their artifacts physically here?\"\n\nThe hypothesis posits that astrobiological evolution is subject to regulation mechanisms that arrest or postpone the advent of complex creatures capable of interstellar communication and traveling technology. These regulation mechanisms act to temporarily sterilize planets of biology in the galactic habitable zone. The main proposed regulation mechanism is gamma-ray bursts.\n\nPart of the neocatastrophism hypothesis is that stellar evolution produces a decreasing frequency of such catastrophic events increasing the length of the \"window\" in which intelligent life might arise as galaxies age. According to modeling, this creates the possibility of a phase transition at which point a galaxy turns from a place that is essentially dead (with a few pockets of simple life) to one that is crowded with complex life forms.\n"}
{"id": "27869730", "url": "https://en.wikipedia.org/wiki?curid=27869730", "title": "New Milford, New Hampshire", "text": "New Milford, New Hampshire\n\nNew Milford is a fictional town in New Hampshire, United States. It was the subject of a hoax article published in 2011 by \"The White Pine Series of Architectural Monographs\", which described the community as being a flourishing Victorian-era village in the White Mountains during the early 20th century. According to the article, New Milford had been incorporated in 1852 by working-class quarry workers, had enjoyed prosperity for many years, and then declined in the early 20th century, following a succession of unfortunate disasters at the quarry site, the decline of rail-based tourism, the Great Depression, and the outbreak of World Wars. Research by the Milford, New Hampshire, Historical Society and the New Hampshire State Library following the publication of the article led to the discovery that the article was fictitious.\n\n"}
{"id": "23815", "url": "https://en.wikipedia.org/wiki?curid=23815", "title": "Pope Joan", "text": "Pope Joan\n\nPope Joan, 855–857, (\"Ioannes Anglicus\") was, according to popular legend, a woman who reigned as pope for a few years during the Middle Ages. Her story first appeared in chronicles in the 13th century and subsequently spread throughout Europe. The story was widely believed for centuries, but most modern scholars regard it as fictional.\n\nMost versions of her story describe her as a talented and learned woman who disguised herself as a man, often at the behest of a lover. In the most common accounts, due to her abilities, she rose through the church hierarchy and was eventually elected pope. Her sex was revealed when she gave birth during a procession, and she died shortly after, either through murder or natural causes. The accounts state that later church processions avoided this spot, and that the Vatican removed the female pope from its official lists and crafted a ritual to ensure that future popes were male. In the 16th century, Siena Cathedral featured a bust of Joan among other pontiffs; this was removed after protests in 1600.\n\nJean de Mailly's chronicle, written around 1250, contains the first mention of an unnamed female pope, and it inspired several more accounts over the next several years. The most popular and influential version is that interpolated into Martin of Opava's \"Chronicon Pontificum et Imperatorum\", later in the 13th century. Martin introduced details that the female pope's birth name was John Anglicus of Mainz, that she reigned in the 9th century, and that she entered the church to follow her lover. The legend was generally accepted as true until the 16th century, when a widespread debate among Catholic and Protestant writers called the story into question; various writers noted the implausibly long gap between Joan's supposed lifetime and her first appearance in texts. It was actually a Protestant scholar, David Blondel, who ultimately demonstrated the impossibility of the Pope Joan story \"from start to finish.\" Pope Joan is now widely accepted to be fictional, though the legend remains influential in art, literature, drama, and film.\n\nThe earliest mention of a female pope appears in the Dominican Jean de Mailly's chronicle of Metz, \"Chronica Universalis Mettensis\", written in the early 13th century. In his telling, the female pope is not named, and the events are set in 1099. According to Jean:\n\nJean de Mailly's story was picked up by his fellow Dominican Stephen of Bourbon, who adapted it for his work on the \"Seven Gifts of the Holy Ghost\". However, the legend gained its greatest prominence when it appeared in the third \"recension\" (edited revision) of Martin of Opava's \"Chronicon Pontificum et Imperatorum\" later in the 13th century. This version, which may have been by Martin himself, is the first to attach a name to the figure, indicating that she was known as \"John Anglicus\" or \"John of Mainz.\" It also changes the date from the 11th to the 9th century, indicating that Joan reigned between Leo IV and Benedict III in the 850s. According to the \"Chronicon\":\n\nOne version of the \"Chronicon\" gives an alternative fate for the female pope. According to this, she did not die immediately after her exposure, but was confined and deposed, after which she did many years of penance. Her son from the affair eventually became Bishop of Ostia, and ordered her entombment in his cathedral when she died.\n\nOther references to the female pope are attributed to earlier writers, though none appears in manuscripts that predate the \"Chronicon\". The one most commonly cited is Anastasius Bibliothecarius (d. 886), a compiler of \"Liber Pontificalis\", who was a contemporary of the female Pope by the \"Chronicon\"'s dating. However, the story is found in only one unreliable manuscript of Anastasius. This manuscript, in the Vatican Library, bears the relevant passage inserted as a footnote at the bottom of a page. It is out of sequence, and in a different hand, one that dates from after the time of Martin of Opava. This \"witness\" to the female pope is likely to be based upon Martin's account, and not a possible source for it. The same is true of Marianus Scotus's \"Chronicle of the Popes\", a text written in the 11th century. Some of its manuscripts contain a brief mention of a female pope named Johanna (the earliest source to attach to her the female form of the name), but all these manuscripts are later than Martin's work. Earlier manuscripts do not contain the legend.\n\nSome versions of the legend suggest that subsequent popes were subjected to an examination whereby, having sat on a so-called \"sedia stercoraria\" or \"dung chair\" containing a hole, a cardinal had to reach up and establish that the new pope had testicles, before announcing \"Duos habet et bene pendentes\" (\"He has two, and they dangle nicely\"), or \"habet\" (\"he has them\") for short.\n\nThere were associated legends as well. In the 1290s, the Dominican Robert of Uzès recounted a vision in which he saw the seat \"where, it is said, the pope is proved to be a man\". Pope Joan has been associated with marvelous happenings. Petrarch (1304–74) wrote in his \"Chronica de le Vite de Pontefici et Imperadori Romani\" that after Pope Joan had been revealed as a woman:\n\nHowever, the attribution of this work to Petrarch may be incorrect.\n\nFrom the mid-13th century onward, the legend was widely disseminated and believed. Joan was used as an \"exemplum\" in Dominican preaching. Bartolomeo Platina, the scholar who was prefect of the Vatican Library, wrote his \"Vitæ Pontificum Platinæ historici liber de vita Christi ac omnium pontificum qui hactenus ducenti fuere et XX\" in 1479 at the behest of his patron, Pope Sixtus IV. The book contains the following account of the female Pope:\nPope John VIII: John, of English extraction, was born at Mentz (Mainz) and is said to have arrived at popedom by evil art; for disguising herself like a man, whereas she was a woman, she went when young with her paramour, a learned man, to Athens, and made such progress in learning under the professors there that, coming to Rome, she met with few that could equal, much less go beyond her, even in the knowledge of the scriptures; and by her learned and ingenious readings and disputations, she acquired so great respect and authority that upon the death of Pope Leo IV (as Martin says) by common consent she was chosen pope in his room. As she was going to the Lateran Church between the Colossean Theatre (so called from Nero's Colossus) and St. Clement's her travail came upon her, and she died upon the place, having sat two years, one month, and four days, and was buried there without any pomp. This story is vulgarly told, but by very uncertain and obscure authors, and therefore I have related it barely and in short, lest I should seem obstinate and pertinacious if I had admitted what is so generally talked. I had better mistake with the rest of the world, though it be certain, that what I have related may be thought not altogether incredible.\nReferences to the female Pope abound in the later Middle Ages and Renaissance. Giovanni Boccaccio wrote about her in \"De Mulieribus Claris\" (1353). The \"Chronicon\" of Adam of Usk (1404) gives her a name, Agnes, and furthermore mentions a statue in Rome that is said to be of her. This statue had never been mentioned by any earlier writer anywhere; presumably it was an actual statue that came to be taken to be of the female pope. A late-14th-century edition of the \"Mirabilia Urbis Romae\", a guidebook for pilgrims to Rome, tells readers that the female Pope's remains are buried at St. Peter's. It was around this time that a long series of busts of past Popes was made for the Duomo of Siena, which included one of the female pope, named as \"Johannes VIII, Foemina de Anglia\" and included between Leo IV and Benedict III.\n\nAt his trial in 1415, Jan Hus argued that the Church does not necessarily need a pope, because, during the pontificate of \"Pope Agnes\" (as he also called her), it got on quite well. Hus's opponents at this trial insisted that his argument proved no such thing about the independence of the Church, but they did not dispute that there had been a female pope at all.\n\nIn 1587, Florimond de Raemond, a magistrate in the parlement de Bordeaux and an antiquary, published his first attempt to deconstruct the legend, \"Erreur Populaire de la Papesse Jeanne\" (also subsequently published under the title \"L'Anti-Papesse\"). The tract applied humanist techniques of textual criticism to the Pope Joan legend, with the broader intent of supplying sound historical principles to ecclesiastical history, and the legend began to come apart, detail by detail. Raemond's \"Erreur Populaire\" went through successive editions, reaching a fifteenth as late as 1691.\n\nIn 1601, Pope Clement VIII declared the legend of the female pope to be untrue. The famous bust of her, inscribed \"Johannes VIII, Femina ex Anglia,\" which had been carved for the series of papal figures in the Duomo di Siena about 1400 and was noted by travelers, was either destroyed or recarved and relabeled, replaced by a male figure, that of Pope Zachary.\n\nThe legend of Pope Joan was \"effectively demolished\" by David Blondel, a mid-17th century Protestant historian, who suggested that Pope Joan's tale may have originated in a satire against Pope John XI, who died in his early 20s. Blondel, through detailed analysis of the claims and suggested timings, argued that no such events could have happened.\n\nThe 16th-century Italian historian Onofrio Panvinio, commenting on one of Bartolomeo Platina's works that refer to Pope Joan, theorized that the story of Pope Joan may have originated from tales of Pope John XII; John reportedly had many mistresses, including one called Joan, who was very influential in Rome during his pontificate.\n\nAt the time of the Reformation, various Protestant writers took up the Pope Joan legend in their anti-Catholic writings, and the Catholics responded with their own polemic. According to Pierre Gustave Brunet, Various authors, in the 16th and 17th centuries, occupied themselves with Pope Joan, but it was from the point of view of the polemic engaged in between the partisans of Lutheran or Calvinist reform and the apologists of Catholicism.\nAn English writer, Alexander Cooke, wrote a book entitled \"Pope Joane: A Dialogue between a Protestant and a Papist\", which purported to prove the existence of Pope Joan by reference to Catholic traditions. It was republished in 1675 as \"A Present for a Papist: Or the Life and Death of Pope Joan, Plainly Proving Out of the Printed Copies, and Manscriptes of Popish Writers and Others, That a Woman called Joan, Was Really Pope of Rome, and Was There Deliver'd of a Bastard Son in the Open Street as She Went in Solemn Procession\". The book gives an account of Pope Joan giving birth to a son in plain view of all those around, accompanied by a detailed engraving showing a rather surprised looking baby peeking out from under the Pope's robes. Even in the 19th century, authors such as Ewaldus Kist and Karl Hase discussed the story as a real occurrence. However, other Protestant writers, such as David Blondel and Gottfried Leibniz, rejected the story.\n\nMost modern scholars dismiss Pope Joan as a medieval legend. One of Britain's preeminent historians dismisses the myth with a logical assessment of evidence. The \"Oxford Dictionary of Popes\" declares that there is \"no contemporary evidence for a female Pope at any of the dates suggested for her reign\", but nonetheless acknowledges that Pope Joan's legend was widely believed for centuries, even by Catholics.\n\nThe 1910 \"Catholic Encyclopedia\" elaborated on the historical timeline problem:\n\nBetween Leo IV and Benedict III, where Martinus Polonus places her, she cannot be inserted, because Leo IV died 17 July 855, and immediately after his death Benedict III was elected by the clergy and people of Rome; but, owing to the setting up of an Antipope, in the person of the deposed Cardinal Anastasius, he was not consecrated until 29 September. Coins exist which bear both the image of Benedict III and of Emperor Lothair, who died 28 September 855; therefore Benedict must have been recognized as pope before the last-mentioned date. On 7 October 855, Benedict III issued a charter for the Abbey of Corvey. Hincmar, Archbishop of Reims, informed Nicholas I that a messenger whom he had sent to Leo IV learned on his way of the death of this Pope, and therefore handed his petition to Benedict III, who decided it (Hincmar, ep. xl in P.L., CXXXVI, 85). All these witnesses prove the correctness of the dates given in the lives of Leo IV and Benedict III, and there was no interregnum between these two Popes, so that at this place there is no room for the alleged Popess.\n\nIt has also been noted that enemies of the papacy in the 9th century make no mention of a female pope. For example, Photios I of Constantinople, who became Patriarch in 858 and was deposed by Pope Nicholas I in 863, was an enemy of the pope. He vehemently asserted his own authority as patriarch over that of the pope in Rome, and would have made the most of any scandal of that time regarding the papacy; but he never mentions the story once in any of his voluminous writings. Indeed, at one point he mentions \"Leo and Benedict, successively great priests of the Roman Church\".\n\nRosemary and Darroll Pardoe, authors of \"The Female Pope: The Mystery of Pope Joan\", theorize that if a female pope did exist, a more plausible time frame is 1086 and 1108, when there were several antipopes; during this time the reign of the legitimate popes Victor III, Urban II, and Paschal II was not always established in Rome, since the city was occupied by Henry IV, Holy Roman Emperor, and later sacked by the Normans. This also agrees with the earliest known version of the legend, by Jean de Mailly, as he places the story in the year 1099. De Mailly's \"account\" was acknowledged by his companion Stephen of Bourbon.\n\nPeter Stanford, a British writer and former editor of \"The Catholic Herald\", concluded in \"The Legend of Pope Joan: In Search of the Truth\" (2000) \"Weighing all th[e] evidence, I am convinced that Pope Joan was an historical figure, though perhaps not all the details about her that have been passed on down the centuries are true\". Stanford's work has been criticised as \"credulous\" by one mainstream historian.\nAgainst the lack of historical evidence to her existence, the question remains as to why the Pope Joan story has been popular and widely believed. Philip Jenkins in \"\" suggests that the periodic revival of what he calls this \"anti-papal legend\" has more to do with feminist and anti-Catholic wishful thinking than historical accuracy.\n\nThe \"sede stercoraria\", the throne with a hole in the seat, now at St. John Lateran (the formal residence of the popes and center of Catholicism), is to be considered. This and other toilet-like chairs were used in the consecration of Pope Pascal II in 1099. In fact, one is still in the Vatican Museums, another at the Musée du Louvre. The reason for the configuration of the chair is disputed. It has been speculated that they originally were Roman bidets or imperial birthing stools, which because of their age and imperial links were used in ceremonies by Popes intent on highlighting their own imperial claims (as they did also with their Latin title, \"Pontifex Maximus\").\n\nAlain Boureau quotes the humanist Jacopo d'Angelo de Scarparia, who visited Rome in 1406 for the enthronement of Gregory XII. The pope sat briefly on two \"pierced chairs\" at the Lateran: \"... the vulgar tell the insane fable that he is touched to verify that he is indeed a man\", a sign that this corollary of the Pope Joan legend was still current in the Roman street.\n\nMedieval popes, from the 13th century onward, did indeed avoid the direct route between the Lateran and St Peter's, as Martin of Opava claimed. However, there is no evidence that this practice dated back any earlier. The origin of the practice is uncertain, but it is quite likely that it was maintained because of widespread belief in the Joan legend, and it was thought genuinely to date back to that period.\n\nAlthough some medieval writers referred to the female pope as \"John VIII\", a genuine Pope John VIII reigned between 872 and 882. Due to the Dark Ages' lack of records, confusion often reigns in the evaluation of events.\n\nA problem sometimes connected to the Pope Joan legend is the fact that there is no Pope John XX in any list. It is said this reflects a renumbering of the popes to exclude Joan from history. Historians have known since Louis Duchesne's critical edition of the \"Liber Pontificalis\" that the \"renumbering\" was actually due to a misunderstanding in the textual transmission of the official papal lists. In the course of the 11th century, in the time after John XIX, the entry for John XIV had been misread as referring to two different popes of this name. These two popes then came to be distinguished as \"Iohannes XIV\" and \"Iohannes XIV bis\" (\"John XIV the second\").\n\nThe existence of a second Pope John XIV was widely accepted in the 13th century, hence the numbering of Popes John XV through XIX was regarded as being erroneous. When Petrus Hispanus was elected pope in 1276 and chose the papal name John, he decided to correct this error by skipping the number XX. He numbered himself John XXI, thus acknowledging the presumed existence of John XIV \"bis\" in the 10th century.\n\nIn 2018, an analysis of several silver coins from the 850s A.D, done by researchers from Flinders University indicated that they were inscribed with the name Johannes Anglicus. From the dating of the 850s, when there were missing papal records, led the researchers to believe the legend was genuine.\n\nPope Joan has remained a popular subject for fictional works. Plays include Ludwig Achim von Arnim's \"Päpstin Johanna\" (1813), a fragment by Bertolt Brecht (in \"Werke\". Bd. 10), and a monodrama, \"Pausin Johanna\" by Cees van der Pluijm (1996).\n\nThe Greek author Emmanuel Rhoides' 1866 novel, \"The Papess Joanne\", was admired by Mark Twain and Alfred Jarry and freely translated by Lawrence Durrell as \"The Curious History of Pope Joan\" (1954). The American Donna Woolfolk Cross's 1996 historical romance, \"Pope Joan\", was recently made into a German musical as well as the movie described below. Other novels include Wilhelm Smets's \"Das Mährchen von der Päpstin Johanna auf’s Neue erörtert\" (1829), Marjorie Bowen's \"Black Magic\" (1909), Ludwig Gorm's \"Päpstin Johanna\" (1912), Yves Bichet's \"La Papesse Jeanne\" (2005), and Hugo N. Gerstl's \"Scribe: The Story of the Only Female Pope\" (2005).\n\nThere have been two films based on the story of Pope Joan: \"Pope Joan\" (1972), directed by Michael Anderson, was titled \"The Devil's Imposter\" in the US. In 2009, it was recut to include more of John Briley's original script and released as \"She... who would be Pope\". Also in 2009, another film with the title \"Pope Joan\" was released, this one a German, British, Italian and Spanish production directed by Sönke Wortmann and produced by Bernd Eichinger, based on Cross's novel.\n\nThe play \"Top Girls\" by Caryl Churchill featured Pope Joan as a character, who was invited to a restaurant along with other historically important women in the past by a modern-day woman, Marlene, to discuss the restriction of feminism in the past.\n\nPope Joan is referenced in the video game \"Persona 5\", as the inspiration for Johanna, one of the titular personas (cognitive beings used by humans to battle demons) belonging to Makoto Niijima.\n\n\n\n\n\n"}
{"id": "48811741", "url": "https://en.wikipedia.org/wiki?curid=48811741", "title": "Rene van Helsdingen", "text": "Rene van Helsdingen\n\nRene Peter Onno Rubiono van Helsdingen (born 25 February 1957) is a Dutch pianist and composer. \n\nHe studied classical music with Komter Loeber in Blaricum in the Netherlands from 1962–72. Then he studied jazz music with Terry Trotter and Lazlo Cser in Los Angeles in 1979. His earliest influences include Oscar Peterson, McCoy Tyner and Bill Evans. \n\nOver the years pianist René has recorded and produced for many different labels, such as Virgin, Timeless, WEA, Dureco, Zebra Acoustic, Pacific Music, Turning Point records, Munich Records, demajors Independent Music Industry Jakarta and his own labels: Relukreul records, and Helsdingen Music, The Netherlands. Helsdingen writes most of his repertoire. Australian newspaper \"The Age\" characterised him as \"A rewarding pianist who can play comfortably in the groove, or create more impressionistic patterns, or quiet, subtle musings. Perhaps the most notable quality of his solos is brevity. René allows himself a few extended workouts and avoids the trap of repeating himself or overstating his case.\" \n\nHelsdingen has organized many successful tours, projects and festivals sponsored by ngo’s , governmental institutions, companies to which he was responsible with regard to the control over the budgets made available.\n"}
{"id": "28962098", "url": "https://en.wikipedia.org/wiki?curid=28962098", "title": "Riders of Judgment", "text": "Riders of Judgment\n\nRiders of Judgment is the fifth book chronologically in Frederick Manfred's \"The Buckskin Man Tales\", which trace themes through five novels set in the 19th Century Great Plains. The story fictionalizes Wyoming's Johnson County War, based on Manfred's original research (which relied heavily on Johnson County Historian Thelma Condit). His analysis of events is close to the story as recounted in Helena Huntington Smith's \"The War on Powder River\", which was published about ten years after Manfred's novel.\n\nThe novel was the source for the made-for-television film \"The Johnson County War,\" starring Tom Berenger. Manfred's novelization uses Nate Champion, Jack Flagg, and John Tisdale as the models for his Hammett brothers, Cain, Harry, and Dale, and turns Frank Canton into a strange family nemesis called variously Hunt Lawton and Link Keeler. Manfred changes the names of the county and the nearby towns.\n\n"}
{"id": "27852663", "url": "https://en.wikipedia.org/wiki?curid=27852663", "title": "Sustainable event management", "text": "Sustainable event management\n\nSustainable event management (also known as event greening) is the process used to produce an event with particular concern for environmental, economic and social issues. Sustainability in event management incorporates socially and environmentally responsible decision making into the planning, organisation and implementation of, and participation in, an event. It involves including sustainable development principles and practices in all levels of event organisation, and aims to ensure that an event is hosted responsibly. It represents the total package of interventions at an event, and needs to be done in an integrated manner. Event greening should start at the inception of the project, and should involve all the key role players, such as clients, organisers, venues, sub-contractors and suppliers.\n\nThe first time that environmental concerns were raised by the public was at the 1992 Albertville Winter Olympics in France, which led to the first ‘green Games’ in Lillehammer, Norway, in 1994. The Lillehammer Olympic Organizing Committee received the UNEP Global 500 Award for setting environmental standards which were absent from previous Olympic games.\n\nThe Centennial Olympic Congress, Congress of Unity, held in Paris in 1994, recognised the importance of the environment and sustainable development, which led to the inclusion of a paragraph in Rule 2 of the Olympic Charter. The International Olympic Committee (IOC) has acknowledged its particular responsibility in terms of promoting sustainable development, and regards the environment as the third dimension of Olympism, alongside sport and culture. This led to its decision in 1995 to create an IOC Sport and Environment Commission. \n\nEnvironmental Guidelines for the Summer Olympics were developed to guide Olympic hosts to ensure that facilities are constructed in a more environmentally friendly manner. The Guidelines were successfully used in the 2000 Sydney Olympic Games. As a result, the organizers of the Sydney Games were honoured with the Global 500 Award in 2001 for organizing the greenest games ever. Since then, other major sports events have also considered their environmental impact. \n\nA major aspect of UNEP’s work is with the IOC. A cooperative agreement was signed in 1994 with IOC and an Agenda 21 for Sport and Environment developed. Since 2002, UNEP has participated in a task force of the UN Secretary-General on the use of sport for the implementation of the United Nations Development Goals. UNEP also supports the IOC in organizing world conferences and regional seminars on sport and the environment.\n\nDuring the 2006 FIFA World CupTM in Germany, Green Goal was launched, which was also implemented in South Africa for the 2010 FIFA World CupTM. The Host City Cape Town Green Goal programme had been awarded the International Olympic Committee (IOC) Sport and Environment Award. Nominated by FIFA, the award recognised the efforts of the Host City Cape Town to mitigate negative environmental impacts of the FIFA World Cup and to maximise a positive environmental and social legacy.\n\nEvent greening is however not only limited to sports events, and other examples include the World Summit on Sustainable Development (WSSD), Johannesburg 2002, and UNFCCC 15th Conference of the Parties (COP15) held in Copenhagen in 2010.\n\nMonitoring and evaluation is an essential component of event greening, and should be used to make continuous improvement. A detailed plan needs to be in place to ensure that information is gathered on all aspects of the event – before, during, and also after the event. This ensures that information is available to understand the effects of greening interventions (e.g. to what extent was water used, and how did water-saving measures reduce water use), as well as the potential improvements to future event-greening initiatives.\n\nWith large events it is best to ensure an independent report, which complies with international standards, such as the Global Reporting Initiative (GRI). The GRI Event Organizers Supplement provides organizations in the sector with a tailored version of GRI’s Reporting Guidelines. It includes the original Guidelines, which set out the Reporting Principles, Disclosures on Management Approach and Performance Indicators for economic, environmental and social issues. The Event Organizers Supplement’s capture the issues that matter most for event organizers to be reported on:\n\nThe British Standard (BS 8901) has been developed specifically for the events industry with a purpose of helping the industry to operate in a more sustainable manner. The standard defines the requirements for a sustainability event management system to ensure an enduring and balanced approach to economic activity, environmental responsibility and social progress relating to events.\n\nIt requires organizations to identify and understand the effects that their activities have on the environment, on society and on the economy both within the organization and the wider economy; and put measures in place to minimize the negative effects. These standards will however be replaced by the International Standard (ISO 20121) for Sustainability Management Systems.\n\n"}
{"id": "38635568", "url": "https://en.wikipedia.org/wiki?curid=38635568", "title": "The Poppy Fields", "text": "The Poppy Fields\n\nThe Poppy Fields were a fictitious teenage group, invented by the Welsh rock band, The Alarm. The Poppy Fields scored a hit with the release of \"45 RPM\" that would become The Alarm's first hit in over a decade. Mike Peters revealed the truth on live radio as Radio 1 was conducting a 2004 broadcast of their then current chart countdown. The story was highlighted by international news outlets with several headlines being published globally.\n\nImmediately after exposing the hoax, the music video for \"45 RPM\" was replaced by an edited version that included The Alarm's members alongside the hyped members of The Poppy Fields. Peters had enticed a young band called the Wayriders to lip-sync the song for the music video while posing as members of the nonexistent group. The events surrounding this hoax have spawned the cinematic release of \"Vinyl\", its soundtrack, The Alarm \"Vinyl Tour 2013\", and the subsequent announcement of a 2013 tour by The Alarm in support of the soundtrack.\n\nIn an interview with BBC News Online, Mike Peters said \"The Alarm, most famous for their 1983 hit '68 Guns', were not always taken seriously by DJs\" because of a combination of the age of the band's members and a perception that their image was outdated. Peters said, \"The Alarm as an entity have been going for 20-odd years and history can go against you – we wanted to break the barrier down.\" He continued by saying that \"[The Alarm members] wanted to stir up the water a little bit, break the mould\" and have the song judged on its own merits and musical value, instead of judgement being based on the perception of the band. Peters told \"The Guardian\": \"We noticed that a lot of bands suffer when they attempt comebacks because people generally don't believe they can ever be as good as they once were. We wanted to make sure we are judged purely on the strength of the music, and not by our old hairstyles.\"\n\nWith The Alarm's decision to perpetrate the hoax, Mike Peters gained the cooperation of a group of young musicians from Chester called the Wayriders to lip-sync The Alarm's material and pass it off as their own. The first release by the fictitious band was promoted as a cover of The Alarm's 1983 hit, \"68 Guns\". In fact it was The Alarm all along, and instead of a cover, it was a re-released version. The demo enticed executives in music production to record an album from the band called \"In The Poppy Fields\" which saw its advance release of the single, \"45 RPM\" entering Britain's top 30 chart. Critical reviews of the band echoed the promoters' official introduction of the band as a tribute to bands like Sex Pistols, and The Clash, with even more modern acts like Rancid being compared. The truth of the song's origin was not revealed until after the song entered the charts at number 24, a credit originally earned by The Poppy Fields from unsuspecting patrons who had accepted the act as fresh and new.\n\nFilming for \"Vinyl\" began in the Denbighshire resort town of Rhyl in August 2010. \"Vinyl\"s soundtrack features new songs by The Alarm specifically composed for the film including the cinematic anthem, \"Free Rock And Roll\", recorded by The Alarm with \"Vinyl\"s leading actor, Phil Daniels, in a song with The Alarm's lead vocalist and founding member, Mike Peters. The song was released as an EP single on 28 January 2013 in tandem with a national television campaign featuring both the film's cast and members of The Alarm.\n\n\n"}
{"id": "3017748", "url": "https://en.wikipedia.org/wiki?curid=3017748", "title": "Types of fiction with multiple endings", "text": "Types of fiction with multiple endings\n\nMultiple endings refer to a case in entertainment where the story could end in different ways.\n\n\n\n\nDVDs may include an alternate ending as a special feature. These are usually not considered canon.\n\nFilms which include multiple endings within the main cut of the film:\n\n\n\n"}
{"id": "29071145", "url": "https://en.wikipedia.org/wiki?curid=29071145", "title": "World news", "text": "World news\n\nWorld news or international news or even foreign coverage is the news media jargon for news from abroad, about a country or a global subject. For journalism, it is a branch that deals with news either sent by foreign correspondents or news agencies, or – more recently – information that is gathered or researched through distance communication technologies, such as telephone, satellite TV or the internet.\n\nAlthough in most of the English-speaking world this field is not usually regarded as a specific specialization for journalists, it is so in nearly all the world. Particularly in the United States, there is a blurred distinction between world news and \"national\" news when they include directly the national government or national institutions, such as wars in which the US are involved or summits of multilateral organizations in which the US are a member.\n\nAt the birth of modern journalism, most news were foreign, as registered by the courants of the 17th century in West and Central Europe, such as the \"Daily Courant\" (England), the \"Nieuwe Tijudinger\" (Antwerp), the \"Relation\" (Strasbourg), the \"Avisa Relation oder Zeitung\" (Wolfenbüttel) and the \"Courante Uyt Italien, Duytsland & C.\" (Amsterdam). Since these papers were aimed at bankers and merchants, they brought mostly news from other markets, which usually meant other nations. In any case, it is worthy to remark that nation-states were still incipient in 17th-century Europe.\n\nFrom the 19th century on, with newspapers already established in Europe, the United States and a few other countries, innovations in telecommunications such as the telegraph made news from abroad easier to be spread. The first news agencies were then founded, like AFP (France), Reuters (UK), Wolff (currently DPA, Germany) and the AP (US).\n\nWar journalism is one of the best known subfields of world news (although war coverage can be national for the media of belligerent countries themselves).\n\nThere are essentially two types of reporters who do foreign reporting: the foreign correspondent (full-time reporter employed by a news source) and the special envoy (sent abroad to cover a specific subject, temporarily stationed in a location).\n\nThe correspondent is a reporter based in a foreign city (often the capital of a country) covering a region, a country or sometimes even an entire continent. He or she regularly files stories to the news editor. He/she gathers materials for these stories from local officials, members of the community, and the local media, as well as from events he/she directly witnesses. Correspondents typically stay in touch with the local community and maintain contacts with other journalists and correspondents in order to identify strategic sources in the government, among diplomats, members of the military and other organizations on the ground who may provide important information.\n\nThe number of foreign correspondents has dropped significantly over the past 20 years or more. Often, a media company is either uninterested or unable to afford to support a single correspondent, such as in many developing countries. In some places, they cannot obtain visas due to political constraints, or otherwise dangerous conditions prohibit a media company from stationing a reporter there. In recent years, the drop in foreign correspondents has been due to cutbacks within media companies (often, but not always, a result of economics alone). Among English language newspapers, only eight daily newspapers have full-time correspondents in more than ten foreign stations, four from the US, three from the UK and one from India: \n\n35 – \"Wall Street Journal\" (US): Baghdad, Bangkok, Beijing, Beirut, Berlin, Brussels, Buenos Aires, Dubai, Frankfurt, Hong Kong, Istanbul, Jakarta, Jerusalem, Johannesburg, Kabul, Kuala Lumpur, Lagos, London, Manila, Mexico City, Moscow, Mumbai, New Delhi, Paris, Prague, Rio de Janeiro, Rome, São Paulo, Seoul, Shanghai, Singapore, Taipei, Tokyo, Toronto, Zurich\n\n24 – \"New York Times\" (US): Baghdad, Beijing, Beirut, Berlin, Cairo, Caracas, Dakar, Hong Kong, Islamabad, Jakarta, Jerusalem, Johannesburg, Kabul, London, Mexico City, Moscow, Mumbai, Nairobi, New Delhi, Paris, Rome, São Paulo, Shanghai, Tokyo\n\n19 – \"Financial Times\" (UK): Beijing, Berlin, Bombay, Brussels, Dubai, Frankfurt, Hong Kong, Jakarta, Jerusalem, Moscow, Mumbai, New Delhi, New York, Paris, Taipei, Tokyo, Shanghai, Sydney, Washington\n\n17 – \"Washington Post\" (US): Baghdad, Beijing, Berlin, Bogotá, Cairo, Islamabad, Jerusalem, Kabul, London, Mexico City, Moscow, Nairobi, New Delhi, Paris, Shanghai, Tehran, Tokyo\n\n15 – \"The Guardian\" (UK): Accra, Bangkok, Beijing, Berlin, Brussels, Kabul, Islamabad, Jerusalem, Los Angeles, Madrid, New York, Paris, Rome, Tehran, Tokyo\n\n13 – \"The Daily Telegraph\" (UK): Beijing, Brussels, Jerusalem, Kabul, Los Angeles, Moscow, Nairobi, New Delhi, New York, Paris, Shanghai, Sydney, Washington\n\n13 – \"Los Angeles Times\" (US): Baghdad, Beijing, Beirut, Cairo, Islamabad, Jerusalem, Johannesburg, Kabul, London, Mexico City, Moscow, New Delhi, Seoul\n\n12 – \"The Hindu\" (India): Addis Ababa, Beijing, Colombo, Dhaka, Dubai, Islamabad, Kathmandu, London, Moscow, Paris, Singapore, Washington \n\nWhen reporters working abroad have no permanent labor contract with media outlets, they are called stringers. Since they have no salary, stringers usually produce material for several different companies at once.\n\nA news agency is an organization of journalists established to supply news reports to news organizations: newspapers, magazines, and radio and television broadcasters. Such an agency may also be referred to as a wire service, newswire or news service. The bulk of major news agency services contains foreign news.\n\nThe major news agencies generally prepare hard news stories and feature articles that can be used by other news organizations with little or no modification, and then sell them to other news organizations. They provide these articles in bulk electronically through wire services (originally they used telegraphy; today they frequently use the Internet). Corporations, individuals, analysts and intelligence agencies may also subscribe.\n\n\n"}
{"id": "27903559", "url": "https://en.wikipedia.org/wiki?curid=27903559", "title": "You Me Bum Bum Train", "text": "You Me Bum Bum Train\n\nYou Me Bum Bum Train is an Interactive theatre performance devised by Kate Bond and Morgan Lloyd in 2004. The pair met as art students in Brighton, where they were studying illustration and film.\n\n\"You Me Bum Bum Train\" gained critical acclaim in the United Kingdom when it was awarded the Oxford Samuel Beckett Theatre Trust prize while showing in a disused office in London. In 2010 it won the Evening Standard Theatre Award for outstanding newcomer. \n\nIt returned in 2012 in a former postal depot in Holborn, and a new version of the show – at Empire House in Stratford, east London in 2012 – was nominated for an Olivier Award for Outstanding Achievement in an Affiliate Theatre.\n\nIn 2015 the show was mounted again, this time in at what had been Foyles bookshop on London's Charing Cross Road where their last show, started on 25 February 2016, finished on 29 April.\n\nVisitors to the performance pass through a series of scenes of which they have no foreknowledge, in which they are either passive or where they must improvise a part without any preparation. Hanna Hanra, writing for \"Vice\", described it as a series of \"highly detailed, absurd real life scenarios following one another on a nonsense high-paced narrative\".\n\nThe entertainment magazine \"Dazed & Confused\" reported; \"What was one of London's more obtuse treasures is set to become one of Great Britain's proudest moments.\" \"The Times\" said; \"It leaves you questioning everything, and it's lots of fun.\" Time Out magazine wrote; \"My highlight of 2008 was You Me Bum Bum Train, if only real life were that interesting.\"\n\n\"You Me Bum Bum Train\" has provoked controversy due to the fact that none of the performers gets paid, though the directors stress that performers and crew are involved on a voluntary basis, that many are not trained professionals and that they are under no obligation to stay during performances.\n\nThe company was criticized for its ticketing system which caused problems for ticket buyers in June 2015.\n\nIn November 2015 the trade union Equity criticised their £150,000 Arts Council England funding as YMBBT were advertising for professional dancers but were not paying them, despite selling tickets \"at rates typical of a West End show.\" \n\nIn June 2016 the trade union BECTU criticised YMBBT for \"exploiting workers after advertising for unpaid production interns.\" BECTU launched an investigation concerning \"the legality of the “outrageous” internships, which would see successful applicants work at least two days each week for a minimum four hours each day.\" \n"}
