{"id": "1069446", "url": "https://en.wikipedia.org/wiki?curid=1069446", "title": "Aerial survey", "text": "Aerial survey\n\nAerial survey is a method of collecting geomatics or other imagery by using airplanes, helicopters, UAVs, balloons or other aerial methods. Typical types of data collected include aerial photography, Lidar, remote sensing (using various visible and invisible bands of the electromagnetic spectrum, such as infrared, gamma, or ultraviolet) and also geophysical data (such as aeromagnetic surveys and gravity. It can also refer to the chart or map made by analysing a region from the air. Aerial survey should be distinguished from satellite imagery technologies because of its better resolution, quality and atmospheric conditions (which can negatively impact and obscure satellite observation). Today, aerial survey is sometimes recognized as a synonym for aerophotogrammetry, part of photogrammetry where the camera is placed in the air. Measurements on aerial images are provided by photogrammetric technologies and methods.\n\nAerial surveys can provide information on many things not visible from the ground.\n\n\nAerial surveys are used for:\n\n\nAerial surveys use a measuring camera where the elements of its interior orientation are known, but with much larger focal length and film and specialized lenses.\n\nIn order to carry out an aerial survey, a sensor needs to be fixed to the interior or the exterior of the airborne platform with line-of-sight to the target it is remotely sensing. With manned aircraft, this is accomplished either through an aperture in the skin of the aircraft or mounted externally on a wing strut. With unmanned aerial vehicles (UAVs), the sensor is typically mounted under or inside.\n\nAerial survey systems are typically operated with the following:\n\n\n"}
{"id": "3740489", "url": "https://en.wikipedia.org/wiki?curid=3740489", "title": "Antichthones", "text": "Antichthones\n\nAntichthones, in geography, are those peoples who inhabit the antipodes, regions on opposite sides of the Earth. The word is compounded of the Greek \"ὰντὶ\" (\"opposed\") and \"χθών\" (\"earth\").\nClassical and Medieval Europe considered the Earth to be divided by the equator into two hemispheres, the northern and southern; those who inhabited one of these hemispheres were said to be antichthones to those of the other. This idea was expounded by Mela and other Classical authors, though Christian writers, who believed that all people on earth must be descended from Adam, denied the possibility that any southern land, if it existed, could be inhabited by humans. St. Augustine, arguing from a position of scriptural inerrancy, wrote in his \"City of God\" \"it is too absurd to say, that some men might have taken ship and traversed the whole wide ocean, and crossed from this side of the world to the other, and that thus even the inhabitants of that distant region are descended from that one first man.\"\n\n"}
{"id": "9511063", "url": "https://en.wikipedia.org/wiki?curid=9511063", "title": "Borden Base Line", "text": "Borden Base Line\n\nThe Borden Base Line is a historic survey line (7.42 miles, long) running north/south through Hatfield and South Deerfield, Massachusetts. It was completed in 1831, and is now on the List of historic civil engineering landmarks.\n\nThe base line measurement was the first project of its kind undertaken in America, and essential for Massachusetts' pioneering Trigonometrical Survey, performed under chief engineer Robert Treat Paine. Its careful measurement was critical, since the accuracy of the whole triangulation network depended on it.\n\nThe base line was measured with greater accuracy than previously possible by using a new measuring device invented by Simeon Borden, which employed a bi-metallic measuring instrument to provide constant readings despite temperature variations. His apparatus was long, enclosed in a tube, and employed with four compound microscopes.\n\nBorden was a highly competent engineer whose ability was widely recognized. Indeed, the entire project became generally known as the Borden Survey. He measured the base line with a nominal accuracy of better than one part in 5 million. As Professor A. D. Butterfield has written, \"The work performed and results obtained far surpassed in magnitude and attainment of any previous work of this kind in America.\"\n\nIt appears that the north end of the baseline lies just south of the intersection of today's Route 116 and Route 5 in South Deerfield, Massachusetts. According to the Valley Historians, the south end is still marked by a copper plug set into a boulder, located in the back yard of the house at 30 Bridge Street, Hatfield, Massachusetts.\n\n\n"}
{"id": "9987963", "url": "https://en.wikipedia.org/wiki?curid=9987963", "title": "Brunton, Inc.", "text": "Brunton, Inc.\n\nBrunton, Inc. ® is a manufacturer of technical outdoor gear located in Riverton, Wyoming. Brunton is well known for innovation in the categories of recreational compasses, navigational equipment, and survey instruments.\n\nDavid W. Brunton, a Canadian-born geologist and mining engineer, and William Aimsworth, a skilled watch repairman, founded Brunton in 1895. The firm is most famous for its earliest product, the Brunton Pocket Transit®. Geologists, foresters, surveyors, and archaeologists use this handheld compass and clinometer. Often simply called a \"Brunton\", the \"Pocket Transit\" was first patented in 1894 by David Brunton, who commissioned William Ainsworth & Sons to manufacture his invention in Denver, Colorado. \nThe company later incorporated as William Ainsworth Inc. and for many years produced the \"Pocket Transit\" along with surveying transits, theodolites, and other instruments.\n\nBy 1965, William Ainsworth Inc. was owned by a series of corporate conglomerates, and product quality varied as the company changed hands repeatedly. In 1972, a group of businessmen from Riverton, Wyoming bought the company and formed Brunton, Inc. In Riverton, Brunton began producing a new series of recreational outdoor compasses, hunting knives, and binoculars in addition to the \"Brunton Pocket Transit\".\n\nIn 1996, the company was acquired by Silva of Sweden AB, the original Swedish-based manufacturer of the \"Silva\" brand compass. Initially, Brunton sold Silva of Sweden compasses and GPS devices imported from Sweden under the \"Elite\" \"Pro Elite\", \"Nexus\", and \"MNS\" labels (Johnson Outdoors retained the exclusive rights to the \"Silva\" ® brand name in North America). Brunton began sourcing some of its compass models from Asia.\n\nIn 2006, the Silva Group was acquired by the Finnish Fiskars Corporation. Along with the rest of the Silva Group, Brunton became part of the Outdoor division of Fiskars. As of 2009, Brunton, Inc. employed about 40 people.\n\nIn December 2009, Fiskars announced the sale of Brunton Inc. to Fenix Outdoor AB, a Swedish company. As a result of Fiskars divestment of Brunton Inc., Silva of Sweden AB ceased all exports of its Swedish-made compasses and GPS devices to North America, including the \"Nexus\", \"Elite\", and \"Pro Elite\" lines. In turn, Brunton ceased export of its model 8020, 8040, and 9020 compasses to Silva of Sweden AB. \n\nAs of March 2012, the company employed around 68 people at its Riverton, Wyoming manufacturing facility.\n\nAs William Ainsworth Inc., production of the \"Pocket Transit™\" continued\".\" The \"Pocket Transit\" remains in production today, and is offered in numerous versions and configurations. In 1970, the company introduced the \"Brunton Cadet\", a simplified evolution of the Pocket Transit incorporating a compass and clinometer, intended for use in training students in the fields of geology, forestry, mining, and surveying. The company soon began marketing the \"Cadet\" to instruct Boy Scouts in the principles of surveying. \n\nIn 1972, the newly formed Brunton, Inc. began compass and transit production in Riverton, Wyoming. Compasses included the \"Pocket Transit\", \"Cadet\", and an emergency compass called the \"Life Card\", designed to float in a bowl of water. This was followed in 1981 by the Model 8040 \"Sportsman's Compass\"™, a map (baseplate) compass with folding cover and mirror sight. In the same year, Brunton introduced the Model 9020. This small baseplate compass was designed for hikers, outdoorsmen, and hunters.\n\nOver the next ten years, Brunton would introduce a full range of map or baseplate compasses based on a liquid-filled vial with \"no-tools adjustment\" for magnetic declination. This new line included Models \"8010\", \"8020\", \"8040\", \"9020\", and the compact 9030 \"Trailbuster\". Brunton baseplate compasses with a G suffix (i.e. \"9020G)\" featured bright yellow-green acrylic baseplates. Brunton often included UTM and map scales for U.S. standard 1:24,000 and 1:62,500 USGS topographic maps. The \"Model 9030 Trailbuster\"™, intended to replicate the popular 1960s-era Taylor \"Model 2912\" field compass, omitted the baseplate in order to minimize space and weight.\n\nIn 1991, the U.S. military purchased a number of Brunton Model \"8010\" \"Smoke Chaser\"™ compasses originally produced for U.S. Forest Service fire-fighting crews. These were stocked in survival kits for U.S. Navy and Marine flight crews. These Model 8010 compasses used clear baseplates and were equipped with lanyards. The compasses were shipped in plain cardboard boxes with military stock number NSN 6605-00-553-8795. Brunton discontinued all 8000- and 9000- series compasses in 2011.\n\nAfter being aquired by Silva, Brunton began selling Silva of Sweden compasses and GPS devices. The Nexus line included the Silva Model 15T and Model 25 \"Ranger\" compasses, rebranded as the Nexus 15TDC and 25TDC Pro Elite. Brunton also began importing some compass models from Taiwan and mainland China, including the \"Model 9030\" and \"Models 9075\" and \"9077\" lensatic compasses. Silva of Sweden also sold some Brunton models under the Silva \"Voyager\"™ name.\n\nIn 1998, Brunton introduced its \"Eclipse™\" range of liquid-filled baseplate compasses featuring low-profile vials, a magnified readout in 1-degree increments, and a patented \"circle-over-circle\" magnetized disk in place of a traditional pointed needle. The \"Eclipse\" compasses included the \"Model 8096 GPS\", the \"Model 8097\", and the \"Model 8099 Pro\". Like older Brunton outdoor compasses, the \"Eclipse\" series used \"no-tools\" adjustable declination. Designed by Brunton, but imported from China, some owners of \"Eclipse\" compasses reported issues with air bubbles forming in the compass vials.\n\nIn 2000, Brunton introduced an electronic fluxgate compass called the \"Brunton Outback\"™. Imported from Taiwan, the \"Outback\" featured gimbal-mounted magnetic sensors which allowed the unit to be tilted up to 15 degrees while producing accurate readings. The \"Outback\" stored up to 10 bearings in its memory. A night navigation mode warned if the user was moving off-track with illuminated arrows. The \"Outback\" was eventually replaced by the Brunton \"Nomad\"™ electronic compass. After complaints about calibration and inaccurate bearings, the \"Nomad\" was discontinued in 2011. \nIn 2009, Brunton stopped selling most Silva of Sweden products. The \"Nexus\" and \"Elite\" lines were discontinued, as well as the \"Brunton 54LU\" (\"Silva Model 54).\" The \"Brunton 54LU\" was marketed to foresters, surveyors, geologists, and SAR teams before being discontinued. Some Silva models, including the \"Brunton 15TDCL\" and \"Brunton 16DLU\", were later sourced from a production facility in China. In 2011, Brunton discontinued the Models 8010G, 8020, 8040G, 9020G, and 9030 compasses.\n\nIn 2012, Brunton introduced a new series of outdoor compasses called \"O.S.S.\"™ (\"Orbital Sighting System)\". Like the \"Eclipse\" series, the O.S.S.™ compasses featured a large liquid-filled capsule and \"circle-over-circle\" north indicator. In addition, several design improvements set the \"O.S.S.\"™ apart. These included a deep-well 'global' vial, a serrated outer bezel, a needle with an orienting circle instead of a magnetized disc, and map meridian lines imprinted in the base of the housing. Unlike older \"Eclipse\" compasses, \"O.S.S.\" compasses were assembled in Riverton, Wyoming from components made in the United States. As of 2012, Brunton is the only major compass manufacturer with U.S.-based production facilities.\n\nIn 2014, Brunton dropped the circle-over-circle magnetized disk/needle design used in the \"Eclipse\" and \"O.S.S.\" series. Their current line of baseplate compasses, the TruArc™ series uses rare-earth magnets to stabilize the north indicator (needle), These compasses are designed to work in all magnetic zones. \n\nIn 2000, Silva of Sweden AB introduced its Silva \"Multi-Navigator\" GPS device. Brunton marketed the product in North America as the Brunton \"MNS\"™. The \"MNS\" featured an electronic compass, barometer, and barometric altimeter in addition to GPS functionality. With a relatively high energy consumption of 210 mA (or 270 mA with illumination on), the \"MNS\" had a battery life of around 10 hours. At $399, the \"Brunton MNS\" faced intense competition competitors such as \"Garmin\" and \"Magellan.\" Products with better battery life and improved scrolling menu displays kep the \"MNS\" from gaining significant market share. Furthermore, the \"MNS\" was not WAAS capable and did not offer internal storage of waypoints, routes or tracks. In 2004, Silva and Brunton introduced a slightly lower-priced, WAAS-capable GPS receiver called the \"Atlas\"™. This product also failed to gain a significant share of the handheld GPS market, and the Brunton \"MNS\" and \"Atlas\" were both discontinued by Brunton in 2009.\n\nIn 1992, Brunton introduced a line of binoculars and other optical equipment aimed at the hunting and outdoor recreation market. The optics line was discontinued in 2014.\n\n\n"}
{"id": "5395439", "url": "https://en.wikipedia.org/wiki?curid=5395439", "title": "Cave survey", "text": "Cave survey\n\nA cave survey is a map of all or part of a cave system, which may be produced to meet differing standards of accuracy depending on the cave conditions and equipment available underground. Cave surveying and cartography, i.e. the creation of an accurate, detailed map, is one of the most common technical activities undertaken within a cave and is a fundamental part of speleology. Surveys can be used to compare caves to each other by length, depth and volume, may reveal clues on speleogenesis, provide a spatial reference for other areas of scientific study and assist visitors with route-finding.\n\nTraditionally, cave surveys are produced in two-dimensional form due to the confines of print, but given the three-dimensional environment inside a cave, modern techniques using computer aided design are increasingly used to allow a more realistic representation of a cave system.\n\nThe first known plan of a cave dates from 1546, and was of a man-made cavern in tufa called the Stufe di Nerone (Nero's Oven) in Pozzuoli near Naples in Italy. The first natural cave to be mapped was the Baumannshöhle in Germany, of which a sketch from 1656 survives.\n\nAnother early survey dates from before 1680, and was made by John Aubrey of Long Hole in the Cheddar Gorge. It consists of an elevational section of the cave. Numerous other surveys of caves were made in the following years, though most are sketches and are limited in accuracy. The first cave that is likely to have been accurately surveyed with instruments is the Grotte de Miremont in France. This was surveyed by a civil engineer in 1765 and includes numerous cross-sections. Édouard-Alfred Martel was the first person to describe surveying techniques. His surveys were made by having an assistant walk down the passage until they were almost out of sight. Martel would then take a compass bearing to the assistant's light, and measure the distance by pacing up to the assistant. This would equate to a modern-day BCRA Grade 2 survey.\n\nThe first cave to have its centreline calculated by a computer is the Fergus River Cave in Ireland, which was plotted by members of the UBSS in 1964. The software was programmed onto a large university mainframe computer and a paper plot was produced.\n\nThere are many variations to surveying methodology, but most are based on a similar set of steps which haven't changed fundamentally in 250 years, although the instruments (compass and tape) have got smaller and more accurate. Since the late 1990s digital instruments such as distometers have started to change the process, leading to the advent of fully paperless surveying around 2007. The main variation on the normal methodology detailed below have been devices such as LIDAR and SONAR surveyors that produce a point cloud rather than a series of linked stations. Video-based surveying also exists in prototype form.\n\nA survey team begins at a fixed point (such as the cave entrance) and measures a series of consecutive line-of-sight measurements between stations. The stations are temporary fixed locations chosen chiefly for their ease of access and clear sight along the cave passage. In some cases, survey stations may be permanently marked to create a fixed reference point to which to return at a later date.\n\nThe measurements taken between the stations include:\n\nCoincident with recording straight-line data, details of passage dimensions, shape, gradual or sudden changes in elevation, the presence or absence of still or flowing water, the location of notable features and the material on the floor are recorded, often by means of a sketch map.\n\nLater, the cartographer analyses the recorded data, converting them into two-dimensional measurements by way of geometrical calculations. From them he/she creates a \"line-plot\"; a scaled geometrical representation of the path through the cave.\n\nThe cartographer then draws details around the line-plot, using the additional data of passage dimensions, water flow and floor/wall topography recorded at the time, to produce a completed cave survey. Cave surveys drawn on paper are often presented in two-dimensional \"plan\" and/or \"profile\" views, while computer surveys may simulate three dimensions. Although primarily designed to be functional, some cavers consider cave surveys as an art form.\n\nHydrolevelling is an alternative to measuring depth with clinometer and tape that has a long history of use in Russia. The technique is regularly used in building construction for finding two points with the same height, as in levelling a floor. In the simplest case, a tube with both ends open is used, attached to a strip of wood, and the tube is filled with water and the depth at each end marked. In Russia, measuring the depth of caves by hydrolevelling began in the 1970s, and was considered to be the most accurate means of measuring depth despite the difficulties in using the cumbersome equipment of the time. Interest in the method has been revived following the discovery of Voronja on the Arabica Massif in the Caucasus – currently the world's deepest cave.\n\nThe hydrolevel device used in recent Voronja expeditions comprises a transparent tube filled with water, which is coiled or placed on a reel. A rubber glove which acts as a reservoir is placed on one end of the tube, and a metal box with a transparent window is placed on the other. A diver's digital wristwatch with a depth gauge function is submerged in the box. If the rubber glove is placed on one station and the box with the depth gauge is placed on a lower one, then the hydrostatic pressure between the two points depends only on the difference in heights and the density of the water, i.e. the route of the tube does not affect the pressure in the box. Reading the depth gauge gives the apparent depth change between the higher and lower station. Depth changes are 'apparent' because depth gauges are calibrated for sea water, and the hydrolevel is filled with fresh water. Therefore, a coefficient must be determined to convert apparent depth changes to true depth changes. Adding the readings for consecutive pairs of stations gives the total depth of the cave.\n\nThe accuracy, or \"grade\", of a cave survey is dependent on the methodology of measurement. A common survey grading system is that created by the British Cave Research Association in the 1960s, which uses a scale of six grades.\n\n\n\n\n\nThe equipment used to undertake a cave survey continues to improve. The use of computers, inertia systems, and electronic distance finders has been proposed, but few practical underground applications have evolved at present.\n\nDespite these advances, faulty instruments, imprecise measurements, recording errors or other factors may still result in an inaccurate survey, and these errors are often difficult to detect. Some cave surveyors measure each station twice, recording a \"back-sight\" to the previous station in the opposite direction. A back-sight compass reading that is different by 180 degrees and a clinometer reading that is the same value but with the reverse direction (positive rather than negative, for example) indicates that the original measurement was accurate.\n\nWhen a loop within a cave is surveyed back to its starting point, the resulting line-plot should also form a closed loop. Any gap between the first and last stations is called a \"loop-closure error\". If no single error is apparent, one may assume the loop-closure error is due to cumulative inaccuracies, and cave survey software can 'close the loop' by averaging possible errors throughout the loop stations. Loops to test survey accuracy may also be made by surveying across the surface between multiple entrances to the same cave.\n\nThe use of a low-frequency cave radio can also verify survey accuracy. A receiving unit on the surface can pinpoint the depth and location of a transmitter in a cave passage by measurement of the geometry of its radio waves. A survey over the surface from the receiver back to the cave entrance forms an artificial loop with the underground survey, whose loop-closure error can then be determined.\n\nIn the past, cavers were reluctant to redraw complex cave maps after detecting survey errors. Today, computer cartography can automatically redraw cave maps after data has been corrected.\n\nThere are a large number of surveying packages available on various computer platforms, most of which have been developed by cavers with a basis in computer programming. Many of the packages perform particularly well for specific tasks, and as such many cave surveyors will not solely choose one product over another for all cartographic tasks.\n\nA popular program for producing a centerline survey is Survex, which was originally developed by members of the Cambridge University Caving Club for processing survey data from club expeditions to Austria. It was released to the public in 1992. The centerline data can then be exported in various formats and the cave detail drawn in with various other programmes such as AutoCAD, Adobe Illustrator and Inkscape. Other programmes such as 'Tunnel' and Therion have full centerline and map editing capabilities. Therion notably, when it closes survey loops, warps the passages to fit over their length, meaning that entire passages do not have to be redrawn.\n\nTerrestrial LiDAR units are increasing significantly in accuracy and decreasing in price. Several Caves have been \"scanned\" using both \"time of flight\" and \"phase shift\" LiDAR units. The differences are in the relative accuracies available to each. The Oregon Caves National Park, was LiDAR scanned in August 2011, as were the Paisley Caves Archaeological dig sigte in SE Oregon. Both were scanned with a FARO Focus Phase shift scanner with +/-2mm accuracy. The Oregon Caves were scanned from the main public entrance to the 110 exit and were loop surveyed to the point of beginning. The data is not yet available for public use, but copies are retained by both the US Park Service and i-TEN Associates in Portland, Oregon.\n\nIn recent years an underground geographic positioning technology called HORTA has been utilized in the mining industry. The technology utilizes a gyroscope and an accelerometer to aid in 3D-position determination.\n\nSuch automated methods have provided a more than fifty-fold increase in underground surveying productivity with more accurate and finer detail maps as well.\n\n\n"}
{"id": "39935679", "url": "https://en.wikipedia.org/wiki?curid=39935679", "title": "Center for Urban and Regional Analysis", "text": "Center for Urban and Regional Analysis\n\nCenter for Urban and Regional Analysis (CURA) \nThe Center for Urban & Regional Analysis (CURA) is an interdisciplinary research organization of The Ohio State University. CURA's mission is to serve as a bridge across academia, industry, and the policy sector by providing spatial analysis of economic, social, environmental, and health issues in urban and regional settings in Ohio and beyond. The organization explores various social, political, economic, geographic, economic, and public health issues using Geographic Information Systems (GIS) and other spatial analysis techniques. CURA also offers a speaker series which brings a wide range of speakers to campus each semester. \n\nThe movement for an urban center began in 1995 with a recommendation from the Committee on Applied Social and Public Policy. Funding followed three years later in 1998. CURA then was formed at The Ohio State University in 1999 as the Urban and Regional Analysis Initiative (URAI). Two years later, in April 2001, the organization officially renamed itself the Center for Urban & Regional Analysis and was given final approval by the Board of Trustees. The change was announced in the University's newspaper, The Lantern. The organization was projected to receive $240,000 per year in funding from the state of Ohio along with an additional $150,000 from the Office of Academic Affairs.\n\nCURA has conducted extensive research and analysis on various topics such as air traffic, urban growth, land use, food accessibility, crime, housing, and data mapping through GIS technology. It is one of just eight Ohio Urban University Program (UUP) research institutes. The center provides a place for researchers from many fields to collaborate on critical urban issues.\n\nThe Center for Urban and Regional Analysis is closely associated with Ohio State's Austin E. Knowlton School of Architecture and the Geography Department but collaborates with a wide range of departments and centers at Ohio State including:\n\nIn June 2013, CURA, in collaboration with the Chadwick Arboretum and Learning Gardens, completed a web-based Tree Tour of Ohio State's historic Oval. The Story Map, hosted on ArcGIS.com, provides the user with a guided walking tour of 32 significant and historic trees along with information about each tree's environmental and financial benefits.\n\nIn partnership with the Kirwan Institute of Ohio State, CURA is working to digitize Ohio's redlining maps from the 1930s.\n\nOhio State's Food Innovation Center and the Mid-Ohio Foodbank are working with CURA and using GIS to find ways to increase the equity of fresh food distribution.\n\nCURA partnered with Center for Aviation Studies at OSU to create maps displaying the accessibility of domestic air service in the United States. The maps show data for over 400 airports with an index describing the level of air service of a given region. The project requires the continued input of data to show how the accessibility of given airports changes over time. Graduate Affiliate Kejing Peng created a detailed web application displaying the results of the air traffic analysis. The T100 Airport Traffic Analysis is both interactive and informative to users, providing a great deal of information on individual airports across the country.\n\nWith Ohio State's Facilities Operations and Development, CURA Graduate Associate Shaun Fontanella is planning to develop digital signs for central buildings on campus. The signs will display and track energy consumption of each building in order to encourage decreased consumption.\n\n"}
{"id": "1527098", "url": "https://en.wikipedia.org/wiki?curid=1527098", "title": "Clairaut's theorem", "text": "Clairaut's theorem\n\nClairaut's theorem is a general mathematical law giving the surface gravity on a viscous rotating ellipsoid in equilibrium under the action of its gravitational field and centrifugal force. It was published in 1743 by Alexis Claude Clairaut in his \"Théorie de la figure de la terre, tirée des principes de l'hydrostatique\" (\"Theory of the shape of the earth, drawn from the principles of hydrostatics\") which synthesized physical and geodetic evidence that the Earth is an oblate rotational ellipsoid. It was initially used to relate the gravity at any point on the Earth's surface to the position of that point, allowing the ellipticity of the Earth to be calculated from measurements of gravity at different latitudes. Today it has been largely supplanted by the Somigliana equation.\n\nAlthough it had been known since antiquity that the Earth was spherical, by the 17th century evidence was accumulating that it was not a perfect sphere. In 1672 Jean Richer found the first evidence that gravity was not constant over the Earth (as it would be if the Earth were a sphere); he took a pendulum clock to Cayenne, French Guiana and found that it lost minutes per day compared to its rate at Paris. This indicated the acceleration of gravity was less at Cayenne than at Paris. Pendulum gravimeters began to be taken on voyages to remote parts of the world, and it was slowly discovered that gravity increases smoothly with increasing latitude, gravitational acceleration being about 0.5% greater at the poles than at the equator.\n\nBritish physicist Isaac Newton explained this in his \"Principia Mathematica\" (1687) in which he outlined his theory and calculations on the shape of the Earth. Newton theorized correctly that the Earth was not precisely a sphere but had an oblate ellipsoidal shape, slightly flattened at the poles due to the centrifugal force of its rotation. Since the surface of the Earth is closer to its center at the poles than at the equator, gravity is stronger there. Using geometric calculations, he gave a concrete argument as to the hypothetical ellipsoid shape of the Earth.\n\nThe goal of \"Principia\" was not to provide exact answer for natural phenomena, but to theorize potential solutions to these unresolved factors in science. Newton pushed for scientists to look further into the unexplained variables. Two prominent researchers that he inspired were Alexis Clairaut and Pierre Louis Maupertuis. They both sought to prove the validity of Newton's theory on the shape of the Earth. In order to do so, they went on an expedition to Lapland in an attempt to accurately measure the meridian arc. From such measurements they could calculate the eccentricity of the Earth, its degree of departure from a perfect sphere. Clairaut confirmed that Newton's theory that the Earth was ellipsoidal was correct, but his calculations were in error, and wrote a letter to the Royal Society of London with his findings. The society published an article in Philosophical Transactions the following year in 1737 that revealed his discovery. Clairaut showed how Newton's equations were incorrect, and did not prove an ellipsoid shape to the Earth. However, he corrected problems with the theory, that in effect would prove Newton's theory correct. Clairaut believed that Newton had reasons for choosing the shape that he did, but he did not support it in \"Principia.\" Clairaut's article did not provide an valid equation to back up his argument as well. This created much controversy in the scientific community.\n\nIt was not until Clairaut wrote \"Théorie de la figure de la terre\" in 1743 that a proper answer was provided. In it, he promulgated what is more formally known today as Clairaut's theorem.\n\nClairaut's formula for the acceleration due to gravity \"g\" on the surface of a spheroid at latitude φ, was:\n\nwhere formula_2 is the value of the acceleration of gravity at the equator, \"m\" the ratio of the centrifugal force to gravity at the equator, and \"f\" the flattening of a meridian section of the earth, defined as:\n(where \"a\" = semimajor axis, \"b\" = semiminor axis).\n\nClairaut derived the formula under the assumption that the body was composed of concentric coaxial spheroidal layers of constant density. \nThis work was subsequently pursued by Laplace, who relaxed the initial assumption that surfaces of equal density were spheroids.\nStokes showed in 1849 that the theorem applied to any law of density so long as the external surface is a spheroid of equilibrium. A history of the subject, and more detailed equations for \"g\" can be found in Khan.\n\nThe above expression for \"g\" has been supplanted by the Somigliana equation (after Carlo Somigliana):\n\nwhere,\n\nFor Earth, formula_2 = 9.7803253359 ms; formula_9 = 9.8321849378 ms; \"k\" = 0.00193185265241 ; \"e\" = 0.00669437999013: \n\nThe spheroidal shape of the Earth is the result of the interplay between gravity and centrifugal force caused by the Earth's rotation about its axis. In his \"Principia\", Newton proposed the equilibrium shape of a homogeneous rotating Earth was a rotational ellipsoid with a flattening \"f\" given by 1/230. As a result, gravity increases from the equator to the poles. By applying Clairaut's theorem, Laplace found from 15 gravity values that \"f\" = 1/330. A modern estimate is 1/298.25642. See Figure of the Earth for more detail.\n\nFor a detailed account of the construction of the reference Earth model of geodesy, see Chatfield.\n"}
{"id": "7417294", "url": "https://en.wikipedia.org/wiki?curid=7417294", "title": "Dodman", "text": "Dodman\n\nA dodman (plural \"dodmen\") or a hoddyman dod is a local English vernacular word for a land snail. The word is used in some of the counties of England. This word is found in the Norfolk dialect, according to the Oxford English Dictionary. Fairfax, in his \"Bulk and Selvedge\" (1674), speaks of “a snayl or dodman.”\n\nHodimadod is a similar word for snail that is more commonly used in the Buckinghamshire dialect.\n\nAlternatively (and apparently now more commonly used in the Norfolk dialect) are the closely related words Dodderman or Doddiman. In everyday folklore, these words are popularly said to be derived from the surname of a travelling cloth seller called Dudman, who supposedly had a bent back and carried a large roll of cloth on his back. The words to dodder, doddery, doddering, meaning to progress in an unsteady manner, are popularly said to have the same derivation.\n\nA traditional Norfolk rhyme goes as follows:\nSource: Dictionary of Phrase and Fable, E. Cobham Brewer, 1894\n\nThe 'inventor' of ley lines, Alfred Watkins, thought that in the words \"dodman\" and the builder's \"hod\" there was a survival of an ancient British term for a surveyor. Watkins felt that the name came about because the snail's two horns resembled a surveyor's two surveying rods. Watkins also supported this idea with an etymology from 'doddering along' and 'dodge' (akin, in his mind, to the series of actions a surveyor would carry out in moving his rod back and forth until it accurately lined up with another one as a backsight or foresight) and the Welsh verb 'dodi' meaning to lay or place. He thus decided that The Long Man of Wilmington was an image of an ancient surveyor.\n"}
{"id": "28341466", "url": "https://en.wikipedia.org/wiki?curid=28341466", "title": "Exploration of Antarctica", "text": "Exploration of Antarctica\n\nThe exploration of the Antarctica includes:\n"}
{"id": "8231648", "url": "https://en.wikipedia.org/wiki?curid=8231648", "title": "GPS-aided GEO augmented navigation", "text": "GPS-aided GEO augmented navigation\n\nThe GPS-aided GEO augmented navigation (GAGAN) is an implementation of a regional satellite-based augmentation system (SBAS) by the Indian government. It is a system to improve the accuracy of a GNSS receiver by providing reference signals. The AAI's efforts towards implementation of operational SBAS can be viewed as the first step towards introduction of modern Communication, navigation and surveillance/Air Traffic Management system over Indian airspace.\n\nThe project has established 15 Indian reference stations, 3 Indian navigation land uplink stations, 3 Indian mission control centers, and installation of all associated software and communication links. It will be able to help pilots to navigate in the Indian airspace by an accuracy of 3 m. This will be helpful for landing aircraft in marginal weather and difficult approaches like Mangalore and Leh airports.\n\nThe project was created in three phases through 2008 by the Airport Authority of India with the help of the Indian Space Research Organisation's (ISRO) technology and space support. The goal is to provide navigation system for all phases of flight over the Indian airspace and in the adjoining area. It is applicable to safety-to-life operations, and meets the performance requirements of international civil aviation regulatory bodies.\n\nThe space component became available after the launch of the GAGAN payload on the GSAT-8 communication satellite, which was successfully launched. This payload was also part of the GSAT-4 satellite that was lost when the geosynchronous satellite launch vehicle (GSLV) failed during launch in April 2010. A final system acceptance test was conducted during June 2012 followed by system certification during July 2013.\n\nTo begin implementing a satellite-based augmentation system over the Indian airspace, Wide Area Augmentation System (WAAS) codes for L1 frequency and L5 frequency were obtained from the United States Air Force and U.S Department of Defense on November 2001 and March 2005. The system will use eight reference stations located in Delhi, Guwahati, Kolkata, Ahmedabad, Thiruvananthapuram, Bangalore, Jammu and Port Blair, and a master control center at Bangalore. US defense contractor Raytheon has stated they will bid to build the system.\n\nA national plan for satellite navigation including implementation of technology demonstration system (TDS) over the Indian air space as a proof of concept had been prepared jointly by Airports Authority of India (AAI) and ISRO. TDS was successfully completed during 2007 by installing eight Indian Reference Stations (INRESs) at eight Indian airports and linked to the Master Control Center (MCC) located near Bangalore. Preliminary system acceptance testing has been successfully completed in December 2010. The ground segment for GAGAN, which has been put up by the Raytheon, has 15 reference stations scattered across the country. Two mission control centres, along with associated uplink stations, have been set up at Kundalahalli in Bangalore. One more control centre and uplink station are to come up at Delhi. As a part of the programme, a network of 18 total electron content (TEC) monitoring stations were installed at various locations in India to study and analyse the behaviour of the ionosphere over the Indian region.\n\nGAGAN's TDS signal in space provides a three-metre accuracy as against the requirement of 7.6 metres. Flight inspection of GAGAN signal is being carried out at Kozhikode, Hyderabad, Nagpur and Bangalore airports and the results have been satisfactory so far.\n\nOne essential component of the GAGAN project is the study of the ionospheric behaviour over the Indian region. This has been specially taken up in view of the uncertain nature of the behaviour of the ionosphere in the region. The study will lead to the optimisation of the algorithms for the ionospheric corrections in the region.\n\nTo study the ionospheric behaviour more effectively over entire Indian airspace, Indian universities and R&D labs, which are involved in the development of regional based ionotropic model for GAGAN, have suggested nine more TEC stations.\n\nGAGAN after its final operational phase completion, will be compatible with other SBAS systems such as the wide-area augmentation system (WAAS), the European Geostationary Navigation Overlay Service (EGNOS) and the Multi-functional Satellite Augmentation System (MSAS) and will provide seamless air navigation service across regional boundaries. While the ground segment consists of eight reference stations and a master control center, which will have sub systems such as data communication network, SBAS correction and verification system, operations and maintenance system, performance monitoring display and payload simulator, Indian land uplinking stations will have dish antenna assembly. The space segment will consist of one geo-navigation transponder.\n\nA flight-management system based on GAGAN will then be poised to save operators time and money by managing climb, descent and engine performance profiles. The FMS will improve the efficiency and flexibility by increasing the use of operator-preferred trajectories.\nIt will improve airport and airspace access in all weather conditions, and the ability to meet the environmental and obstacle clearance constraints. It will also enhance reliability and reduce delays by defining more precise terminal area procedures that feature parallel routes and environmentally optimised airspace corridors.\n\n\nThe first GAGAN transmitter was integrated into the GSAT-4 geostationary satellite, and had a goal of being operational in 2008. Following a series of delays, GSAT-4 was launched on 15 April 2010, however it failed to reach orbit after the third stage of the Geosynchronous Satellite Launch Vehicle Mk.II that was carrying it malfunctioned.\n\nIn 2009, Raytheon had won an 82 million dollar contract. It was mainly dedicated to modernise Indian air navigation system. The vice president of Command & Control Systems, Raytheon Network Centric Systems, Andy Zogg commented:\n\nGAGAN will be the world's most advanced air navigation system and further reinforces India's leadership in the forefront of air navigation. GAGAN will greatly improve safety, reduce congestion and enhance communications to meet India's growing air traffic management needs\n\nIn 2012, the Defence Research and Development Organisation received a \"miniaturised version\" of the device with all the features from global positioning systems (GPS) and global navigation satellite systems (GNSS). The module weighing just 17 gm, can be used in multiple platforms ranging from aircraft (e.g. winged or rotor-craft) to small boats, ships. Reportedly, it can also assist \"survey applications\". It is a cost-efficient device and can be of \"tremendous\" civilian use. The navigation output is composed of GPS, GLONASS and GPS+GLONASS position, speed and time data. According to a statement released by the DRDO, G3oM is a state-of-the-art technology receiver, integrating Indian GAGAN as well as both global positioning system and GLONASS systems.\n\nAccording to Deccan chronicle:\nG. Satheesh Reddy, associate director of the city-based Research Centre Imarat, said the product is bringing about a quantum leap in the area of GNSS technology and has paved the way for highly miniaturised GNSS systems for the future.\n\nOn 30 December 2012, the Directorate General of Civil Aviation (DGCA), India provisionally certified the GPS-aided geo-augmented navigation (GAGAN) system to RNP0.1 (Required Navigation Performance, 0.1 Nautical Mile) service level. The certification enabled aircraft fitted with SBAS equipment to use GAGAN signal in space for navigation purposes.\n\nGSAT-8 is an Indian geostationary satellites, which was successfully launched using Ariane 5 on 21 May 2011 and is positioned in geosynchronous orbit at 55 degrees E longitude.\n\nGSAT-10 is envisaged to augment the growing need of Ku and C-band transponders and carries 12 Ku Band, 12 C Band and 12 Extended C Band transponders and a GAGAN payload. The spacecraft employs the standard I-3K structure with power handling capability of around 6 kW with a lift off mass of 3400 kg. GSAT-10 was successfully launched by Ariane 5 on 29 September 2012.\n\nGSAT-15 carries 24 Ku band transponders with India coverage beam and a GAGAN payload. was successfully launched on 10 November 2015, 21:34:07 UTC, completing the constellation.\n\nThe Indian government has stated that it intends to use the experience of creating the GAGAN system to enable the creation of an autonomous regional navigation system called the Indian Regional Navigation Satellite System IRNSS.\n\nIRNSS-1\nIndian regional navigational satellite system (IRNSS)-1, the first of the seven satellites of the IRNSS constellation, carries a navigation payload and a C-band ranging transponder. The spacecraft employs an optimised I-1K structure with a power handling capability of around 1660W and a lift off mass of 1425 kg, and is designed for a nominal mission life of 10 years. The first satellite of IRNSS constellation was launched onboard PSLV (C22) on 1 July 2012. While the full constellation was planned to be realised during 2014 time frame, launch of subsequent satellites got delayed.\n\nCurrently all 7 satellites are in orbit but in 2017 it was announced that all three rubidium atomic clocks on board IRNSS-1A had failed, mirroring similar failures in the Galileo constellation. The first failure occurred in July 2016, following which two other clocks also failed. This rendered the satellite somewhat redundant and required replacement. Although the satellite still performs other functions, the data is coarse, and thus cannot be used for accurate measurements. ISRO plans to replace it with IRNSS-1H in July or August 2017.\n\nTwo more clocks in the navigational system had started showing signs of abnormality, thereby taking the total number of failed clocks to five.\n\nAs a precaution to extend the operational life of navigation satellite, ISRO is running only one rubidium atomic clock instead of two in the remaining six satellites. Each satellite has three clocks, therefore a total of 27 clocks for all satellites in the system (including standby satellites). The clocks of both IRNSS and GALILEO were supplied by SpectraTime. ISRO replaced the atomic clocks in two standby NavIC satellites. The setback comes at a time when IRNSS is yet to start commercial operations.\n\nKarnataka Forest Department has used GAGAN to build a new, accurate and publicly available satellite based database of its forestlands. This is a followup to the Supreme Court directive to states to update and put up their respective forest maps. The geospatial database of forestlands pilot has used data from the Cartosat-2 satellite. The maps are meant to rid authorities of ambiguities related to forest boundaries and give clarity to forest administrators, revenue officials as also the public, according to R.K. Srivastava, chief conservator of forests (headquarters).\n\nVarious Indian manufactured missiles including the BrahMos will use GAGAN for guidance.\n\n\n\n"}
{"id": "925631", "url": "https://en.wikipedia.org/wiki?curid=925631", "title": "Garden design", "text": "Garden design\n\nGarden design is the art and process of designing and creating plans for layout and planting of gardens and landscapes. Garden design may be done by the garden owner themselves, or by professionals of varying levels of experience and expertise. Most professional garden designers have some training in horticulture and the principles of design. Garden designer, Rev David Coles, further elaborated this definition at the Chelsea Flower Show (2018, BBC1, Chelsea) by stating that good garden design, while being on the one hand a “serious discipline” should embody a “playful creative mindfulness”. He postulates that successful garden designs enable transcendence from a physical sensory experience to a mindful awareness of being interconnected with nature. \nSome are also landscape architects, a more formal level of training that usually requires an advanced degree and often a state license. Amateur gardeners may also attain a high level of experience from extensive hours working in their own gardens, through casual study, serious study in Master Gardener Programs, or by joining gardening clubs.\n\nWhether gardens are designed by a professional or an amateur, certain principles form the basis of effective garden design, resulting in the creation of gardens to meet the needs, goals, and desires of the users or owners of the gardens.\n\nElements of garden design include the layout of hard landscape, such as paths, walls, water features, sitting areas and decking; as well as the plants themselves, with consideration for their horticultural requirements, their season-to-season appearance, lifespan, growth habit, size, speed of growth, and combinations with other plants and landscape features. Consideration is also given to the maintenance needs of the garden, including the time or funds available for regular maintenance, which can affect the choice of plants in terms of speed of growth, spreading or self-seeding of the plants, whether annual or perennial, and bloom-time, and many other characteristics.\n\nImportant considerations in the garden design include how the garden will be used, the desired stylistic genre (formal or informal, modern or traditional etc.), and the way the garden space will connect to the home or other structures in the surrounding areas. All of these considerations are subject to the limitations of the prescribed budget.\n\nA garden's location can have a substantial influence on its design. Topographical landscape features such as steep slopes, vistas, hills, and outcrops may suggest or determine aspects of design such as layout and can be used and augmented in order to create a particular impression. The soils of the site will affect what types of plant may be grown, as will the garden's climate zone and various microclimates. The locational context of the garden can also influence its design. For example, an urban setting may require a different design style In contrast to a rural one. Similarly, a windy coastal location may necessitate a different treatment compared to a sheltered inland site.\n\nThe quality of a garden's soil can have a significant influence on a garden's design and its subsequent success. Soil influences the availability of water and nutrients, the activity of soil micro-organisms, and temperature within the root zone, and thus may have a determining effect on the types of plants which will grow successfully in the garden. However, soils may be replaced or improved in order to make them more suitable.\n\nTraditionally, garden soil is improved by amendment, the process of adding beneficial materials to the native subsoil and particularly the topsoil. The added materials, which may consist of compost, peat, sand, mineral dust, or manure, among others, are mixed with the soil to the preferred depth. The amount and type of amendment may depend on many factors, including the amount of existing soil humus, the soil structure (clay, silt, sand, loam etc.), the soil acidity/alkalinity, and the choice of plants to be grown. One source states that, \"conditioning the soil thoroughly before planting enables the plants to establish themselves quickly and so play their part in the design.\" However, not all gardens are, or should be, amended in this manner, since many plants prefer an impoverished soil. In this case, poor soil is better than a rich soil that has been artificially enriched.\n\nThe design of a garden can be affected by the nature of its boundaries, both external and internal, and in turn the design can influence the boundaries, including via creation of new ones. Planting can be used to modify an existing boundary line by softening or widening it. Introducing internal boundaries can help divide or break up a garden into smaller areas.\n\nThe main types of boundary within a garden are hedges, walls and fences. A hedge may be evergreen or deciduous, formal or informal, short or tall, depending on the style of the garden and purpose of the boundary. A wall has a strong foundation beneath it at all points, and is usually - but not always - built from brick, stone or concrete blocks. A fence differs from a wall in that it is anchored only at intervals, and is usually constructed using wood or metal (such as iron or wire mesh).\n\nBoundaries may be constructed for several reasons: to keep out livestock or intruders, to provide privacy, to create shelter from strong winds and provide microclimates, to screen unattractive structures or views, and to create an element of surprise.\n\nIn temperate western gardens, a smooth expanse of lawn is often considered essential to a garden. However garden designers may use other surfaces, for example those \"made up of loose gravel, small pebbles, or wood chips\" in order to create a different appearance and feel. Designers may also utilise the contrast in texture and color between different surfaces in order to create an overall pattern in the design.\n\nSurfaces for paths and access points are chosen for practical as well as aesthetic reasons. Issues such as safety, maintenance and durability may need to be considered by the designer. Gardens designed for public access need to cope with heavier foot traffic and hence may utilise surfaces – such as resin-bonded gravel – that are rarely used in private gardens.\n\nPlanting design requires design talent and aesthetic judgement combined with a good level of horticultural, ecological and cultural knowledge. It includes two major traditions: formal rectilinear planting design (Persia and Europe); and formal asymmetrical (Asia) and naturalistic planting design.\n\nPersian gardens are credited with originating aesthetic and diverse planting design. A correct Persian garden will be divided into four sectors with water being very important for both irrigation and aesthetics. The four sectors symbolize the Zoroastrian elements of sky, earth, water and plants. Planting in ancient and Medieval European gardens was often a mix of herbs for medicinal use, vegetables for consumption, and flowers for decoration. Purely aesthetic planting layouts developed after the Medieval period in , as are shown in late-renaissance paintings and plans. The designs of the Italian Renaissance garden were geometrical and plants were used to form spaces and patterns. The gardens of the French Renaissance and Baroque Garden à la française era continued the 'formal garden' planting aesthetic.\n\nIn Asia the asymmetrical traditions of planting design in Chinese gardens and Japanese gardens originated in the Jin Dynasty (265–420) of China. The gardens' plantings have a controlled but naturalistic aesthetic. In Europe the arrangement of plants in informal groups developed as part of the English Landscape Garden style, and subsequently the French landscape garden, and was strongly influenced by the picturesque art movement.\n\nA planting plan gives specific instructions, often for a contractor about how the soil is to be prepared, what species are to be planted, what size and spacing is to be used and what maintenance operations are to be carried out under the contract. Owners of private gardens may also use planting plans, not for contractual purposes, as an aid to thinking about a design and as a record of what has been planted. A planting strategy is a long term strategy for the design, establishment and management of different types of vegetation in a landscape or garden.\n\nPlanting can be established by directly employed gardeners and horticulturalists or it can be established by a landscape contractor (also known as a landscape gardener). Landscape contractors work to drawings and specifications prepared by garden designers or landscape architects.\n\nGarden furniture may range from a \"patio set\" consisting of a table, four or six chairs and a parasol, through benches, swings, various lighting, to stunning artifacts in brutal concrete or weathered oak. Patio heaters, that run on bottled butane or propane, are often used to enable people to sit outside at night or in cold weather. A picnic table, is used for the purpose of eating a meal outdoors such as in a garden.\n\nThe materials used to manufacture modern patio furniture include stones, metals, vinyl, plastics, resins, glass, and treated woods.\n\nWhile sunlight is not always easily controlled by the gardener, it is an important element of garden design. The amount of available light is a critical factor in determining what plants may be grown. Sunlight will, therefore, have a substantial influence on the character of the garden. For example, a rose garden is generally not successful in full shade, while a garden of hostas may not thrive in hot sun. As another example, a vegetable garden may need to be placed in a sunny location, and if that location is not ideal for the overall garden design goals, the designer may need to change other aspects of the garden.\n\nIn some cases, the amount of available sunlight can be influenced by the gardener. The location of trees, other shade plants, garden structures, or, when designing an entire property, even buildings, might be selected or changed based on their influence in increasing or reducing the amount of sunlight provided to various areas of the property.\n\nIn other cases, the amount of sunlight is not under the gardener's control. Nearby buildings, plants on other properties, or simply the climate of the local area, may limit the available sunlight. Or, substantial changes in the light conditions of the garden may not be within the gardener's means. In this case, it is important to plan a garden that is compatible with the existing light conditions.\n\nGarden lighting can be an important aspect of garden design. In most cases, various types of lighting techniques may be classified and defined by heights: safety lighting, uplighting, and downlighting. Safety lighting is the most practical application. However, it is more important to determine the type of lamps and fittings needed to create the desired effects. Light regulates three major plant processes: photosynthesis, phototropism, and photoperiodism.\n\nPhotosynthesis provides the energy required to produce the energy source of plants.\n\nPhototropism is the effect of light on plant growth that causes the plant to grow toward or away from the light. Photoperiodism is a plant’s response or capacity to respond to photoperiod, a recurring cycle of light and dark periods of constant length.\n\nGarden design, and the Islamic garden tradition, began with creating the Paradise garden in Ancient Persia, in Western Asia. It evolved over the centuries, and in the different cultures Islamic dynasties came to rule in Central— South Asia, the Near East, North Africa, and the Iberian Peninsula.\n\nSome styles and examples include:\n\nGarden design history and precedents from the Mediterranean region include:\n\nA formal garden in the Persian garden and European garden design traditions is rectilinear and axial in design. The equally formal garden, without axial symmetry (asymmetrical) or other geometries, is the garden design tradition of Chinese gardens and Japanese gardens. The Zen garden of rocks, moss and raked gravel is an example. The Western model is an ordered garden laid out in carefully planned geometric and often symmetrical lines. Lawns and hedges in a formal garden need to be kept neatly clipped for maximum effect. Trees, shrubs, subshrubs and other foliage are carefully arranged, shaped and continually maintained. A French garden or Garden à la française, is a specific kind of formal garden, laid out in the manner of André Le Nôtre; it is centered on the façade of a building, with radiating avenues and paths of gravel, lawns, parterres and pools (\"bassins\") of reflective water enclosed in geometric shapes by stone coping, with fountains and sculpture.\n\nThe Garden à la française style has origins in fifteenth-century Italian Renaissance gardens, such as the Villa d'Este, Boboli Gardens, and Villa Lante in Italy. The style was brought to France and expressed in the gardens of the French Renaissance. Some of the earliest formal parterres of clipped evergreens were those laid out at Anet by Claude Mollet, the founder of a dynasty of nurserymen-designers that lasted deep into the 18th century. The Gardens of Versailles are an ultimate example of Garden à la française, composed of many different distinct gardens, and designed by André Le Nôtre.\n\nEnglish Renaissance gardens in a rectilinear formal design were a feature of the stately homes. The introduction of the parterre was at Wilton House in the 1630s. In the early eighteenth century, the publication of Dezallier d'Argenville, \" La théorie et la pratique du jardinage\" (1709) was translated into English and German, and was the central document for the later formal gardens of Continental Europe.\n\nTraditional formal Spanish garden design evolved with Persian garden and influences. The internationally renowned Alhambra and Generalife in Granada, built in the Moorish Al-Andalus era, have influenced design for centuries. The Ibero-American Exposition of 1929 World's Fair in Seville, Spain was located in the celebrated Maria Luisa Park (\"Parque de Maria Luisa\") designed by Jean-Claude Nicolas Forestier.\n\nFormal gardening in the Italian and French manners was reintroduced at the turn of the twentieth century. Beatrix Farrand's formal Italian garden areas at Dumbarton Oaks in Washington, D.C., and Achille Duchêne's restored French water parterre at Blenheim Palace in England are examples of the modern formal garden. The Conservatory Garden in Central Park of New York City features a formal garden, as do many other parks and estates such as Filoli in California.\n\nThe simplest formal garden would be a box-trimmed hedge lining or enclosing a carefully laid out flowerbed or garden bed of simple geometric shape, such as a knot garden. The more developed and elaborate formal gardens contain statuary and fountains.\nFeatures in a formal garden may include:\n\nThe English Landscape Garden style practically swept away the geometries of earlier English and European Renaissance formal gardens. William Kent and Lancelot \"Capability\" Brown were leading proponents, among many other designers. The naturalistic English Garden style (French:\" Jardin anglais\", Italian: \"Giardino all'inglese\", German: \"Englischer Landschaftsgarten\") of the 1730s and on transformed private and civic garden design across Europe. The French Landscape Garden subsequently continued the style's development on the Continent.\n\nA cottage garden uses an informal design, traditional materials, dense plantings, and a mixture of ornamental and edible plants. Cottage gardens go back many centuries, but their popularity grew in 1870s England in response to the more structured Victorian English estate gardens that used restrained designs with massed beds of brilliantly colored greenhouse annuals. They are more casual by design, depending on grace and charm rather than grandeur and formal structure. The influential British garden authors and designers, William Robinson at Gravetye Manor in Sussex, and Gertrude Jekyll at Munstead Wood in Surrey, both wrote and gardened in England. Jekyll's series of thematic gardening books emphasized the importance and value of natural plantings were an influence in Europe and the United States. Also influential half a century later was Margery Fish, whose surviving garden at East Lambrook Manor emphasizes, among other things, native plant life and the natural patterns produced by self-spreading and self-seeding.\n\nThe earliest cottage gardens were far more practical than modern versions—with an emphasis on vegetables and herbs, along with fruit trees, beehives, and even livestock if land allowed. Flowers were used to fill any spaces in between. Over time, flowers became more dominant. Modern day cottage gardens include countless regional and personal variations of the more traditional English cottage garden.\n\nThe traditional kitchen garden, also known as a potager, is a seasonally used space separate from the rest of the residential garden – the ornamental plants and lawn areas. Most vegetable gardens are still miniature versions of old family farm plots with square or rectangular beds, but the kitchen garden is different not only in its history, but also its design.\n\nThe kitchen garden may be a landscape feature that can be the central feature of an ornamental, all-season landscape, but can be little more than a humble vegetable plot. It is a source of herbs, vegetables, fruits, and flowers, but it is also a structured garden space, a design based on repetitive geometric patterns.\n\nThe kitchen garden has year-round visual appeal and can incorporate permanent perennials or woody plantings around (or among) the annual plants.\n\nA Shakespeare garden is a themed garden that cultivates plants mentioned in the works of William Shakespeare. In English-speaking countries, particularly the United States, these are often public gardens associated with parks, universities, and Shakespeare festivals. Shakespeare gardens are sites of cultural, educational, and romantic interest and can be locations for outdoor weddings.\n\nSigns near the plants usually provide relevant quotations. A Shakespeare garden usually includes several dozen species, either in herbaceous profusion or in a geometric layout with boxwood dividers. Typical amenities are walkways and benches and a weather-resistant bust of Shakespeare. Shakespeare gardens may accompany reproductions of Elizabethan architecture. Some Shakespeare gardens also grow species typical of the Elizabethan period but not mentioned in Shakespeare's plays or poetry.\n\nA rock garden, also known as a rockery or an alpine garden, is a type of garden that features extensive use of rocks or stones, along with plants native to rocky or alpine environments.\n\nRock garden plants tend to be small, both because many of the species are naturally small, and so as not to cover up the rocks. They may be grown in troughs (containers), or in the ground. The plants will usually be types that prefer well-drained soil and less water.\n\nThe usual form of a rock garden is a pile of rocks, large and small, aesthetically arranged, and with small gaps between, where the plants will be rooted. Some rock gardens incorporate bonsai.\n\nSome rock gardens are designed and built to look like natural outcrops of bedrock. Stones are aligned to suggest a bedding plane and plants are often used to conceal the joints between the stones. This type of rock garden was popular in Victorian times, often designed and built by professional landscape architects. The same approach is sometimes used in modern campus or commercial landscaping, but can also be applied in smaller private gardens.\n\nThe Japanese rock garden, in the west often referred to as \"Zen garden\", is a special kind of rock garden which contains few plants.\nRock gardens have become increasingly popular as landscape features in tropical countries such as Thailand. The combination of wet weather and heavy shade trees, along with the use of heavy plastic liners to stop unwanted plant growth, has made this type of arrangement ideal for both residential and commercial gardens due to its easier maintenance and drainage.\n\nNatural landscaping, also called native gardening, is the use of native plants, including trees, shrubs, groundcover, and grasses which are indigenous to the geographic area of the garden.\n\nNatural landscaping is adapted to the climate, geography and hydrology and should require no pesticides, fertilizers and watering to maintain, given that native plants have adapted and evolved to local conditions over thousands of years. However, these applications may be necessary for some preventive care of trees and other vegetation in areas of degraded or weedy landscapes.\n\nNative plants suit today's interest in \"low-maintenance\" gardening and landscaping, with many species vigorous and hardy and able to survive winter cold and summer heat. Once established, they can flourish without irrigation or fertilization, and are resistant to most pests and diseases.\n\nMany municipalities have quickly recognized the benefits of natural landscaping due to municipal budget constraints and reductions and the general public is now benefiting from the implementation of natural landscaping techniques to save water and create more personal time.\n\nNative plants provide suitable habitat for native species of butterflies, birds, pollinators, and other wildlife. They provide more variety in gardens by offering myriad alternatives to the often planted introduced species, cultivars, and invasive species. The indigenous plants have co-evolved with animals, fungi and microbes, to form a complex network of relationships. They are the foundation of their native habitats and ecosystems, or natural communities.\n\nSuch gardens often benefit from the plants being evolved and habituated to the local climate, pests and herbivores, and soil conditions, and so may require fewer to no soil amendments, irrigation, pesticides, and herbicides for a lower maintenance, more sustainable landscape.\n\nJapanese and Korean gardens, originally influenced by Chinese gardens, can be found at Buddhist temples and historic sites, private homes, in neighborhood or city parks, and at historical landmarks such as Buddhist temples. Some of the Japanese gardens most famous in the Western world and Japan are gardens in the \"karesansui\" (rock garden) tradition. The Ryōan-ji temple garden is a well-known example. There are Japanese gardens of various styles, with plantings and often evoking \"wabi sabi\" simplicity. In Japanese culture, garden-making is a high art, intimately linked to the arts of calligraphy and ink painting.\n\nThe contemporary style garden has gained popularity in the UK in the last 10 years. This is partly due to the increase of modern housing with small gardens as well as the cultural shift towards contemporary design . This style of garden can be defined by the use 'clean' design lines, with focus on hard landscaping materials like stone, hardwood, rendered walls. Planting style is bold but simple with the use of drifts of one or two plants that repeat throughout the design. Grasses are a very popular choice for this style of design. Lighting effects also play an integral role in the modern garden. Subtle lighting effects can be achieved with the use of carefully placed low voltage LED lights incorporated into paving and walls.\n\nA residential or private domestic garden, is the most common form of garden and is in proximity to a residence, such as the 'front garden' or 'back garden'. The front garden may be a formal and semi-public space and so subject to the constraints of convention and local laws. While typically found in the yard of the residence, a garden may also be established on a roof, in an atrium or courtyard, on a balcony, in windowboxes, or on a patio. Residential gardens are typically designed at human scale, as they are most often intended for private use. However, the garden of a great house or a large estate may be larger than a public park.\n\nResidential gardens may feature specialized gardens, such as those for exhibiting one particular type of plant, or special features, such as rockery or water features. They are also used for growing herbs and vegetables and are thus an important element of sustainability.\n\n"}
{"id": "31846623", "url": "https://en.wikipedia.org/wiki?curid=31846623", "title": "Geo-enable", "text": "Geo-enable\n\nGeo-Enable is a neologism, a portmanteau of Geospatial or Geographic and Enablement. Associated words include Geo-Enablment and Geo-Enabling.\n\nAs a verb it is increasingly used in the fields of Geographic Information System (GIS), Web Development, Mobility, Information Management (IM) and IT. Similar to the terms 'Web-Enabled' or 'GPS-Enabled' - 'Geo-Enable' suggests the application of location or geospatial information as part of business processes or using 'location intelligence' to augment non-spatial information systems and/or Business Intelligence (BI).\n\nGeospatial Enablement can be thought of as the integrated use of Geographic Information, as opposed to using Geographic Information within a geographic and technology-centric environment of something such as a GPS or GIS.\n\nA definition given by GeoEnable Ltd is:\n\n'Geo-Enablement n.:\n1. Embedding and leveraging the power of location and geography within workflows and business processes.\n2. The act of deriving and utilising geography within non-spatial information.\n3. The state of being enabled using location information.' \n\nAnother definition by the US Government is:\n\n'To geo-enable is to apply geospatial capabilities to a business process in order to establish the authoritative spatial location of business data, and enable contextual spatial analysis.' \n\n"}
{"id": "10220287", "url": "https://en.wikipedia.org/wiki?curid=10220287", "title": "Geo (microformat)", "text": "Geo (microformat)\n\nGeo is a microformat used for marking up WGS84 geographical coordinates (latitude;longitude) in (X)HTML. Although termed a \"draft\" specification, this is a formality, and the format is stable and in widespread use; not least as a sub-set of the published hCalendar and hCard microformat specifications, neither of which is still a draft.\n\nUse of Geo allows parsing tools (for example other websites, or Firefox's Operator extension) to extract the locations, and display them using some other website or mapping tool, or to load them into a GPS device, index or aggregate them, or convert them into an alternative format.\n\n\nThe Geo microformat is applied using three HTML classes. For example, the marked-up text:\n\nbecomes:\n\nby adding the class-attribute values \"geo\", \"latitude\" and \"longitude\".\n\nThis will display \n\nand a geo microformat for that location, Belvide Reservoir, which will be detected, on this page, by microformat parsing tools.\n\nEach Geo microformat may be wrapped in an hCard microformat, allowing for the inclusion of personal, organisational or venue names, postal addresses, telephone contacts, URLs, pictures, etc.\n\nThere are three active proposals, none mutually-exclusive, to extend the geo microformat:\n\nOrganisations and websites using Geo include:\n\n\nMany of the organisations publishing hCard include a geo as part of that.\n\n\n"}
{"id": "995417", "url": "https://en.wikipedia.org/wiki?curid=995417", "title": "Geodetic datum", "text": "Geodetic datum\n\nA geodetic datum or geodetic system is a coordinate system, and a set of reference points, used to locate places on the Earth (or similar objects). An approximate definition of sea level is the datum WGS 84, an ellipsoid, whereas a more accurate definition is Earth Gravitational Model 2008 (EGM2008), using at least 2,159 spherical harmonics. Other datums are defined for other areas or at other times; ED50 was defined in 1950 over Europe and differs from WGS 84 by a few hundred meters depending on where in Europe you look. \nMars has no oceans and so no sea level, but at least two martian datums have been used to locate places there.\n\nDatums are used in geodesy, navigation, and surveying by cartographers and satellite navigation systems to translate positions indicated on maps (paper or digital) to their real position on Earth. Each starts with an ellipsoid (stretched sphere), and then defines latitude, longitude and altitude coordinates. One or more locations on the Earth's surface are chosen as anchor \"base-points\".\n\nThe difference in co-ordinates between datums is commonly referred to as \"datum shift\". The datum shift between two particular datums can vary from one place to another within one country or region, and can be anything from zero to hundreds of meters (or several kilometers for some remote islands). The North Pole, South Pole and Equator will be in different positions on different datums, so True North will be slightly different. Different datums use different interpolations for the precise shape and size of the Earth (reference ellipsoids).\n\nBecause the Earth is an imperfect ellipsoid, localised datums can give a more accurate representation of the area of coverage than WGS 84. OSGB36, for example, is a better approximation to the geoid covering the British Isles than the global WGS 84 ellipsoid. However, as the benefits of a global system outweigh the greater accuracy, the global WGS 84 datum is becoming increasingly adopted.\n\nHorizontal datums are used for describing a point on the Earth's surface, in latitude and longitude or another coordinate system. Vertical datums measure elevations or depths.\n\nIn surveying and geodesy, a \"datum\" is a reference system or an approximation of the Earth's surface against which positional measurements are made for computing locations. Horizontal datums are used for describing a point on the Earth's surface, in latitude and longitude or another coordinate system. Vertical datums are used to measure elevations or underwater depths.\n\nThe horizontal datum is the model used to measure positions on the Earth. A specific point on the Earth can have substantially different coordinates, depending on the datum used to make the measurement. There are hundreds of local horizontal datums around the world, usually referenced to some convenient local reference point. Contemporary datums, based on increasingly accurate measurements of the shape of the Earth, are intended to cover larger areas. The WGS 84 datum, which is almost identical to the NAD83 datum used in North America and the ETRS89 datum used in Europe, is a common standard datum.\n\nFor example, in Sydney there is a 200 metres (700 feet) difference between GPS coordinates configured in GDA (based on global standard WGS 84) and AGD (used for most local maps), which is an unacceptably large error for some applications, such as surveying or site location for scuba diving.\n\nA vertical datum is used as a reference point for elevations of surfaces and features on the Earth including terrain, bathymetry, water levels, and man-made structures. Vertical datums are either: tidal, based on sea levels; gravimetric, based on a geoid; or geodetic, based on the same ellipsoid models of the Earth used for computing horizontal datums.\n\nIn common usage, elevations are often cited in height above sea level, although what “sea level” actually means is a more complex issue than might at first be thought: the height of the sea surface at any one place and time is a result of numerous effects, including waves, wind and currents, atmospheric pressure, tides, topography, and even differences in the strength of gravity due to the presence of mountains etc.\n\nFor the purpose of measuring the height of objects on land, the usual datum used is mean sea level (MSL). This is a tidal datum which is described as the arithmetic mean of the hourly water elevation taken over a specific 19 years cycle. This definition averages out tidal highs and lows (caused by the gravitational effects of the sun and the moon) and short term variations. It will not remove the effects of local gravity strength, and so the height of MSL, relative to a geodetic datum, will vary around the world, and even around one country. Countries tend to choose the mean sea level at one specific point to be used as the standard “sea level” for all mapping and surveying in that country. (For example, in Great Britain, the national vertical datum, Ordnance Datum Newlyn, is based on what was mean sea level at Newlyn in Cornwall between 1915 and 1921). However, zero elevation as defined by one country is not the same as zero elevation defined by another (because MSL is not the same everywhere), which is why locally defined vertical datums differ from one another.\n\nA different principle is used when choosing a datum for nautical charts. For safety reasons, a mariner must be able to know the minimum depth of water that could occur at any point. For this reason, depths and tides on a nautical chart are measured relative to chart datum, which is defined to be a level below which tide rarely falls. Exactly how this is chosen depends on the tidal regime in the area being charted and on the policy of the hydrographic office producing the chart in question; a typical definition is Lowest Astronomical Tide (the lowest tide predictable from the effects of gravity), or Mean Lower Low Water (the average lowest tide of each day), although MSL is sometimes used in waters with very low tidal ranges.\n\nConversely, if a ship is to safely pass under a low bridge or overhead power cable, the mariner must know the minimum clearance between the masthead and the obstruction, which will occur at high tide. Consequently, bridge clearances etc. are given relative to a datum based on high tide, such as Highest Astronomical Tide or Mean High Water Springs.\n\nSea level does not remain constant throughout geological time, and so tidal datums are less useful when studying very long-term processes. In some situations sea level does not apply at all — for instance for mapping Mars' surface — forcing the use of a different \"zero elevation\", such as mean radius.\n\nA geodetic vertical datum takes some specific zero point, and computes elevations based on the geodetic model being used, without further reference to sea levels. Usually, the starting reference point is a tide gauge, so at that point the geodetic and tidal datums might match, but due to sea level variations, the two scales may not match elsewhere. An example of a gravity-based geodetic datum is NAVD88, used in North America, which is referenced to a point in Quebec, Canada. Ellipsoid-based datums such as WGS 84, GRS80 or NAD83 use a theoretical surface that may differ significantly from the geoid.\n\nIn geodetic coordinates, the Earth's surface is approximated by an ellipsoid, and locations near the surface are described in terms of latitude (formula_1), longitude (formula_2), and height (formula_3).\n\nGeodetic latitude (formula_1), resp. altitude, is different from geocentric latitude (formula_5), resp. altitude. Geodetic latitude is determined by the angle between the equatorial plane and normal to the ellipsoid, whereas geocentric latitude is determined by the angle between the equatorial plane and line joining the point to the centre of the ellipsoid (see figure). Unless otherwise specified, latitude is geodetic latitude.\n\nThe ellipsoid is completely parameterised by the semi-major axis formula_6 and the flattening formula_7.\n\nFrom formula_6 and formula_7 it is possible to derive the semi-minor axis formula_10, first eccentricity formula_11 and second eccentricity formula_12 of the ellipsoid\n\nAGD66 and AGD84 both use the parameters defined by Australian National Spheroid (see below)\n\nGDA94 uses the parameters defined by GRS80 (see below)\n\nSee GDA Technical Manual document for more details; the value given above for the flattening is not exact.\n\nThe Global Positioning System (GPS) uses the World Geodetic System 1984 (WGS 84) to determine the location of a point near the surface of the Earth.\n\nSee The official World Geodetic System 1984 document for more details.\n\nA more comprehensive list of geodetic systems can be found here\n\nDatum conversion is the process of converting the coordinates of a point from one datum system to another. Datum conversion may frequently be accompanied by a change of grid projection.\n\nA reference datum is a known and constant surface which is used to describe the location of unknown points on the Earth. Since reference datums can have different radii and different center points, a specific point on the Earth can have substantially different coordinates depending on the datum used to make the measurement. There are hundreds of locally developed reference datums around the world, usually referenced to some convenient local reference point. Contemporary datums, based on increasingly accurate measurements of the shape of the Earth, are intended to cover larger areas. The most common reference Datums in use in North America are NAD27, NAD83, and WGS 84.\n\nThe North American Datum of 1927 (NAD 27) is \"the horizontal control datum for the United States that was defined by a location and azimuth on the Clarke spheroid of 1866, with origin at (the survey station) Meades Ranch (Kansas).\" ... The geoidal height at Meades Ranch was assumed to be zero, as sufficient gravity data was not available, and this was needed to relate surface measurements to the datum. \"Geodetic positions on the North American Datum of 1927 were derived from the (coordinates of and an azimuth at Meades Ranch) through a readjustment of the triangulation of the entire network in which Laplace azimuths were introduced, and the Bowie method was used.\" (http://www.ngs.noaa.gov/faq.shtml#WhatDatum ) NAD27 is a local referencing system covering North America.\n\nThe North American Datum of 1983 (NAD 83) is \"The horizontal control datum for the United States, Canada, Mexico, and Central America, based on a geocentric origin and the Geodetic Reference System 1980 (GRS80). \"This datum, designated as NAD 83 ...is based on the adjustment of 250,000 points including 600 satellite Doppler stations which constrain the system to a geocentric origin.\" NAD83 may be considered a local referencing system.\n\nWGS 84 is the World Geodetic System of 1984. It is the reference frame used by the U.S. Department of Defense (DoD) and is defined by the National Geospatial-Intelligence Agency (NGA) (formerly the Defense Mapping Agency, then the National Imagery and Mapping Agency). WGS 84 is used by DoD for all its mapping, charting, surveying, and navigation needs, including its GPS \"broadcast\" and \"precise\" orbits. WGS 84 was defined in January 1987 using Doppler satellite surveying techniques. It was used as the reference frame for broadcast GPS Ephemerides (orbits) beginning January 23, 1987. At 0000 GMT January 2, 1994, WGS 84 was upgraded in accuracy using GPS measurements. The formal name then became WGS 84 (G730), since the upgrade date coincided with the start of GPS Week 730. It became the reference frame for broadcast orbits on June 28, 1994. At 0000 GMT September 30, 1996 (the start of GPS Week 873), WGS 84 was redefined again and was more closely aligned with International Earth Rotation Service (IERS) frame ITRF 94. It was then formally called WGS 84 (G873). WGS 84 (G873) was adopted as the reference frame for broadcast orbits on January 29, 1997. Another update brought it to WGS84(G1674).\n\nThe WGS 84 datum, within two meters of the NAD83 datum used in North America, is the only world referencing system in place today. WGS 84 is the default standard datum for coordinates stored in recreational and commercial GPS units.\n\nUsers of GPS are cautioned that they must always check the datum of the maps they are using. To correctly enter, display, and to store map related map coordinates, the datum of the map must be entered into the GPS map datum field.\n\nExamples of map datums are:\n\n\n\n"}
{"id": "51208627", "url": "https://en.wikipedia.org/wiki?curid=51208627", "title": "Geographic data and information", "text": "Geographic data and information\n\nGeographic data and information are defined in the ISO/TC 211 series of standards as data and information having an implicit or explicit association with a location relative to the Earth.\n\nIt is also called geospatial data and information, georeferenced data and information, as well as geodata and geoinformation.\n\nApproximately 90% of government sourced data has a location component.\n\n\n"}
{"id": "8782181", "url": "https://en.wikipedia.org/wiki?curid=8782181", "title": "Geographical zone", "text": "Geographical zone\n\nThe five main latitude regions of the Earth's surface comprise geographical zones, divided by the major circles of latitude. The differences between them relate to climate. They are as follows: \n\n\nOn the basis of latitudinal extent, the globe is divided into three broad heat zones.\n\nThe Torrid is also known as the Tropics. The zone is bounded on the north by the Tropic of Cancer and on the south by the Tropic of Capricorn; these latitudes mark the northern and southern extremes in which the sun seasonally passes directly overhead. This happens annually, but in the region between, the sun passes overhead twice a year.\n\nIn the Northern Hemisphere, in the sun's apparent northward migration after the March equinox, it passes overhead once, then after the June solstice, at which time it reaches the Tropic of Cancer, it passes over again on its apparent southward journey. After the September equinox the sun passes into the Southern Hemisphere. It then passes similarly over the southern tropical regions until it reaches the Tropic of Capricorn at the December solstice, and back again as it returns northwards to the Equator.\n\nIn the two Temperate Zones also known as tropical zone not, consisting of the tepid latitudes, the Sun is never directly overhead, and the climate is mild, generally ranging from warm to cool. The four annual seasons, spring, summer, autumn and winter, occur in these areas. The North Temperate Zone includes Europe, Northern Asia, and North and Central America. The South Temperate Zone includes Southern Australasia, southern South America, and Southern Africa.\n\nThe two Frigid Zones, or polar regions, experience the midnight sun and the polar night for part of the year - at the edge of the zone there is one day at the winter solstice when the Sun is invisible, and one day at the summer solstice when the sun remains above the horizon for 24 hours. In the center of the zone (the pole) the day is one year long with six months of daylight and six months of night. The Frigid Zones are the coldest regions of Earth and are generally covered in ice and snow.It receives slanting rays of the sun as this region lies farthest from the equator. Summer season in this region lies lasts for about 2 to 3 months and there is almost 24 hour sunlight during summer.\n\nThe concept of a geographical zone was first hypothesized by the ancient Greek scholar Parmenides and lastingly modified by Aristotle. Both philosophers theorized the Earth divided into three types of climatic zones based on their distance from the equator.\n\nLike Parmeneides, thinking that the area near the equator was too hot for habitation, Aristotle dubbed the region around the equator (from 23.5° N to 23.5° S) the \"Torrid Zone.\" Both philosophers reasoned the region from the Arctic Circle to the pole to be permanently frozen. This region, thought uninhabitable, was called the \"Frigid Zone.\" The only area believed to be habitable was the northern \"Temperate Zone\" (the southern one not having been discovered), lying between the \"Frigid Zones\" and the \"Torrid Zone\". However, humans have inhabited almost all climates on Earth, including inside the Arctic Circle.\n\nAs knowledge of the Earth's geography improved, a second \"Temperate Zone\" was discovered south of the equator, and a second \"Frigid Zone\" was discovered around the Antarctic. Although Aristotle's map was oversimplified, the general idea was correct. Today, the most commonly used climate map is the Köppen climate classification, developed by Russian climatologist of German descent and amateur botanist Wladimir Köppen (1846–1940), which divides the world into five major climate regions, based on average annual precipitation, average monthly precipitation, and average monthly temperature.\n\n"}
{"id": "1870398", "url": "https://en.wikipedia.org/wiki?curid=1870398", "title": "Geotagging", "text": "Geotagging\n\nGeotagging or GeoTagging, is the process of adding geographical identification metadata to various media such as a geotagged photograph or video, websites, SMS messages, QR Codes or RSS feeds and is a form of geospatial metadata. This data usually consists of latitude and longitude coordinates, though they can also include altitude, bearing, distance, accuracy data, and place names, and perhaps a time stamp.\n\nGeotagging can help users find a wide variety of location-specific information from a device. For instance, someone can find images taken near a given location by entering latitude and longitude coordinates into a suitable image search engine. Geotagging-enabled information services can also potentially be used to find location-based news, websites, or other resources. Geotagging can tell users the location of the content of a given picture or other media or the point of view, and conversely on some media platforms show media relevant to a given location.\n\nThe related term geocoding refers to the process of taking non-coordinate based geographical identifiers, such as a street address, and finding associated geographic coordinates (or vice versa for reverse geocoding). Such techniques can be used together with geotagging to provide alternative search techniques.\n\nGeotagging has become a popular feature on several social media platforms, such as Facebook and Instagram.\n\nFacebook users can geotag photos that can be added to the page of the location they are tagging. Users may also use a feature that allows them to find nearby Facebook friends, by generating a list of people according to the location tracker in their mobile devices.\n\nInstagram uses a map feature that allows users to geotag photos. The map layout pin points specific photos that the user has taken on a world map.\n\nThe geographical location data used in geotagging will, in almost every case, be derived from the global positioning system, and based on a latitude/longitude-coordinate system that presents each location on the earth from 180° west through 180° east along the Equator and 90° north through 90° south along the prime meridian.\n\nThere are two main options for geotagging photos; capturing GPS information at the time the photo is taken or \"attaching\" the photograph to a map after the picture is taken.\n\nIn order to capture GPS data at the time the photograph is captured, the user must have a camera with built in GPS or a standalone GPS along with a digital camera. Because of the requirement for wireless service providers in United States to supply more precise location information for 911 calls by September 11, 2012, more and more cell phones have built-in GPS chips. Most smart phones already use a GPS chip along with built-in cameras to allow users to automatically geotag photos. Others may have the GPS chip and camera but do not have internal software needed to embed the GPS information within the picture. A few digital cameras also have built-on or built-in GPS that allow for automatic geotagging.\nDevices use GPS, A-GPS or both. A-GPS can be faster getting an initial fix if within range of a cell phone tower, and may work better inside buildings. Traditional GPS does not need cell phone towers and uses standard GPS signals outside of urban areas. Traditional GPS tends to use more battery power. Almost any digital camera can be coupled with a stand-alone GPS and post processed with photo mapping software, to write the location information to the image's exif header.\n\nGPS coordinates may be represented in text in a number of ways, with more or fewer decimals:\n\nWith photos stored in JPEG, TIFF and many other file formats, the geotag information, storing camera location and sometimes heading, is typically embedded in the metadata, stored in Exchangeable image file format (Exif) or Extensible Metadata Platform (XMP) format. These data are not visible in the picture itself but are read and written by special programs and most digital cameras and modern scanners. Latitude and longitude are stored in units of degrees with decimals. This geotag information can be read by many programs, such as the cross-platform open source ExifTool. An example readout for a photo might look like:\n\nor the same coordinates could also be presented as decimal degrees:\n\nWhen stored in Exif, the coordinates are represented as a series of rational numbers in the GPS sub-IFD. Here is a hexadecimal dump of the relevant section of the Exif metadata (with big-endian byte order):\n\nIn the field of remote sensing the geotagging goal is to store coordinates of every pixel in the image. One approach is used with the orthophotos where we store coordinates of four corners and all the other pixels can be georeferenced by interpolation. The four corners are stored using GeoTIFF or World file standards. Hyperspectral images take a different approach defining a separate file of the same spatial dimensions as the image where latitude and longitude of each pixel are stored as two 2D layers in so called \"Input geometry data\" (IGM) files, also known as GEO files.\n\nAudio/video files can be geotagged via: metadata, audio encoding, overlay, or with companion files. Metadata records the geospatial data in the encoded video file to be decoded for later analysis. One of the standards used with unmanned aerial vehicle is which allows geocoding of corner points and horizon lines in individual video frames. Audio encoding involves a process of converting gps data into audio data such as modem squawk. Overlay involves overlaying GPS data as text on the recorded video. Companion files are separate data files which correspond to respective audio/video files. Companion files are typically found in the .KML and .GPX data formats. For audio and video files which use the vorbiscomment metadata format (including Opus, Ogg Vorbis, FLAC, Speex, and Ogg Theora), there is a proposed GEO LOCATION field which can be used. Like all vorbiscomments, it is plain text, and it takes the form:\n\ncodice_25\n\nfor example:\n\ncodice_26\n\nThe GeoSMS standard works by embedding one or more 'geo' URIs in the body of an SMS, for example:\n\nRFC 1876 defines a means for expressing location information in the Domain Name System. LOC resources records can specify the latitude, longitude, altitude, precision of the location, and the physical size of on entity attached to an IP address. However, in practice not all IP addresses have such a record, so it is more common to use geolocation services to find the physical location of an IP address.\n\nThe GeoURL method requires the ICBM tag (plus optional Dublin Core metadata), which is used to geotag standard web pages in HTML format:\nThe similar Geo Tag format allows the addition of placename and region tags:\nThe RDF method is defined by W3 Group and presents the information in RDF tags:\n<rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n</rdf:RDF>\nThe Geo microformat allows coordinates within HyperText Markup Language pages to be marked up in such a way that they can be \"discovered\" by software tools. Example:\nA proposal has been developed to extend Geo to cover other bodies, such as Mars and the Moon.\n\nAn example is the Flickr photo-sharing Web site, which provides geographic data for any geotagged photo in all of the above-mentioned formats.\n\nNo industry standards exist, however there are a variety of techniques for adding geographical identification metadata to an information resource. One convention, established by the website Geobloggers and used by more and more sites, e.g. photo sharing sites Panoramio and Flickr, and the social bookmarking site del.icio.us, enables content to be found via a location search. Such sites allow users to add metadata to an information resource via a set of so-called \"machine tags\" (see folksonomy).\n\nThis describes the geographic coordinates of a particular location in terms of latitude (geo:lat) and longitude (geo:lon). These are expressed in decimal degrees in the WGS84 datum, which has become something of a default geodetic datum with the advent of GPS.\n\nUsing three tags works within the constraint of having tags that can only be single 'words'. Identifying geotagged information resources on sites like Flickr and del.icio.us is done by searching for the 'geotagged' tag, since the tags beginning 'geo:lat=' and 'geo:lon=' are necessarily very variable.\n\nAnother option is to tag with a Geohash:\n\nA further convention proposed by FlickrFly adds tags to specify the suggested viewing angle and range when the geotagged location is viewed in Google Earth:\n\nThese three tags would indicate that the camera is pointed heading 225° (south west), has a 45° tilt and is 560 metres from the subject.\n\nWhere the above methods are in use, their coordinates may differ from those specified by the photo's internal Exif data, for example because of a correction or a difference between the camera's location and the subject's.\n\nIn order to integrate geotags in social media and enhance text readability or oral use, the concept of 'meetag' or tag-to-meet has been proposed. Differing from hashtag construction, meetag includes the geolocation information after an underscore. A meetag is therefore a word or an unspaced phrase prefixed with an underscore (\"_\"). Words in messages on microblogging and social networking services may be tagged by putting \"_\" before them, either as they appear in a sentence, (e.g. \"There is a concert going _montreuxjazzfestival\", \"the world wide web was invented _cern _geneve\", ...) or appended to it.\n\nGeoblogging attaches specific geographic location information to blog entries via \"geotags\". Searching a list of blogs and pictures tagged using geotag technology allows users to select areas of specific interest to them on interactive maps.\n\nThe progression of GPS technology, along with the development of various online applications, has fueled the popularity of such tagged blogging, and the combination of GPS Phones and GSM localization, has led to the moblogging, where blog posts are tagged with exact position of the user. Real-time geotagging relays automatically geotagged media such as photos or video to be published and shared immediately.\n\nFor better integration and readability of geotags into blog texts, the meetag syntax has been proposed, which transforms any word, sentence, or precise geolocalization coordinates prefixed with an underscore into a 'meetag'. It not only lets one express a precise location but also takes in account dynamically changing geolocations.\n\nOne of the first attempts to initiate the geotagging aspect of searching and locating articles seems to be the now-inoperative site Wikinear.com, launched in 2008, which showed the user Wikipedia pages that are geographically closest to one's current location.\n\nThe 2009 app Cyclopedia works relatively well showing geotagged Wikipedia articles located within several miles of ones location, integrated with a street-view mode, and 360-degree mode.\n\nThe app Respotter Wiki, launched in 2009, claims to feature Wikipedia searching via a map, also allowing users to interact with people around them, via messaging and reviews, etc. The app, in its current function, however, seems to give only geotagged photo results.\n\nAs of 2017, the provides a simple map search tool which can display tagged articles near to a particular location, as well as a variety of more sophisticated tools integrated with external mapping services.\n\nFollowing a scientific study and several demonstrative websites, a discussion on the privacy implications of geotagging has raised public attention. In particular, the automatic embedding of geotags in pictures taken with smartphones is often ignored by cell-phone users. As a result, people are often not aware that the photos they publish on the Internet have been geotagged. Many celebrities reportedly gave away their home location without knowing it. According to the study, a significant number of for-sale advertisements on Craigslist, that were otherwise anonymized, contained geotags, thereby revealing the location of high-valued goods—sometimes in combination with clear hints to the absence of the offerer at certain times. Publishing photos and other media tagged with exact geolocation on the Internet allows random people to track an individual's location and correlate it with other information. Therefore, criminals could find out when homes are empty because their inhabitants posted geotagged and timestamped information both about their home address and their vacation residence. These dangers can be avoided by removing geotags with a metadata removal tool for photos before publishing them on the Internet.\n\nIn 2007, four United States Army Apache helicopters were destroyed on the ground by Iraqi insurgent mortar fire; the insurgents had made use of embedded coordinates in web-published photographs (geotagging) taken of the helicopters by soldiers.\n\nAnother newly realised danger of geotagging is the location information provided to criminal gangs and poachers on the whereabouts of often endangered animals. This can effectively make tourists scouts for these poachers, so geotagging should be turned off when photographing these animals.\n\n"}
{"id": "37280343", "url": "https://en.wikipedia.org/wiki?curid=37280343", "title": "Hügelkultur", "text": "Hügelkultur\n\nHügelkultur is a horticultural technique where a mound constructed from decaying wood debris and other compostable biomass plant materials is later (or immediately) planted as a raised bed. Adopted by permaculture advocates, it is suggested the technique helps to improve soil fertility, water retention, and soil warming, thus benefiting plants grown on or near such mounds.\n\nHügelkultur is a German word meaning mound culture or hill culture. It is said to have been practiced in German and Eastern European societies for hundreds of years. \n\nThe term is first published in a 1962 German gardening booklet by Herrman Andrä. Inspired by observation of the diversity and success of plants growing in a pile of woody debris, \"mound culture\" is suggested (as opposed to \"flatland culture\"). This was also posited as an easy way to utilise woody debris without burning, which was illegal. Andrä appears to have been influenced by Rudolf Steiner's biodynamic agriculture. Steiner developed his biodynamic philosophy through meditation and clairvoyance, and rejected scientific inquiry on the grounds that his methods were “true and correct unto themselves.” Andrä quotes a 1924 lecture on biodynamics by Steiner, which describes mixing of soil with composting or decaying material in earthen hillocks. Joined by author Hans Beba, another German gardener, \"Hill Culture - the horticultural method of the future\" was revised and republished several times in the 1970s and 1980s.\n\nThe technique was later adopted and developed by Sepp Holzer, an Austrian permaculture advocate. More recent permaculture advocates such as Paul Wheaton and Geoff Lawton strongly promote Hügelkultur beds as a perfect permaculture design.\n\nIn its basic form, mounds are constructed by piling logs, branches, plant waste, compost and additional soil directly on the ground. The pile has the form of a pyramid. The sides of the two slopes both have a grade of between 65 and 80 degrees. The beds are usually about by in area and about high. However, this height reduces as decomposition progresses.\n\nWhen positioned on sloped terrain, the beds need to be put at an angle to the hillside (rather than having them parallel to it). This makes sure the beds do not receive unequal amounts of water. In most cases, it is useful to have the beds positioned against the prevailing wind direction.\n\nThe raised bed can form light-duty swales, circles and mazes. Mounds may also be made from alternating layers of wood, sod, compost, straw, and soil. Although their construction is straightforward, planning is necessary to prevent steep slopes that would result in erosion. \n\nIn his book \"Desert or Paradise: Restoring Endangered Landscapes Using Water Management, Including Lake and Pond Construction\", Holzer describes a method of constructing Hügelkultur which incorporates rubbish such as cardboard, clothes and kitchen waste. He recommends building mounds that are wide and any length. Mounds are built in a trench in sandy soil, and without a trench if the ground is wet.\n\nThe mound is left to rest for several months before planting, although some advise immediate planting.\n\nAnything can be grown on the raised beds, but if the bed will decompose/release its nutrients quickly (so long as it is not made of bulky materials like tree trunks), more demanding crops such as pumpkins, courgettes, cucumbers, cabbages, tomatoes, sweet corn, celery, or potatoes are grown in the first year, after which the bed is used for less demanding crops like beans, peas, and strawberries.\nThe original German publications described the mounds as having a lifespan of 5-6 years, after which they had to be rebuilt from scratch.\n\nAs of 2017 there are no peer-reviewed scientific studies available regarding the efficacy of the technique. A few university student projects investigate Hügelkultur but have not been published in scientific journals. \n\nOne small scale and short term student project investigated the Hügelkultur method as a potential use for yard trimmings waste, and also if lima beans, kale and okra planted on a Hügelkultur mound showed any signs of nutrient deficiency compared to a non-raised control bed. It was found that over 11 tons of yard trimmings were used in the mound, and no evidence of macronutrient deficiency could be detected in the crops in the short term. Indeed, despite concerns that incorporation of large quantities of high carbon woody matter would lead to nitrogen immobilization and hence nitrogen deficiency in the crop, a higher level of nitrogen was found in the raised bed. However the micronutrient iron was lower relative to the control bed. The author speculated that no nitrogen deficiency occurred since the roots of the plants did not penetrate past the superficial layers of the mound into the deeper wood-containing region.\n\nA student thesis investigated the water holding capacity of Hügelkultur beds and whether the technique could be useful to prevent karst rocky desertification in China. Over 3 months of measurements, water concentration in hügel mounds remained high. Samples from hugel sites contained almost twice as much water as those from flat control plots. It was suggested that 1 Hectare of hügels has 3-10 times more water than a flat plot affected by karst rocky desertification.\n\nMany publications and websites advocate the technique based on personal experience of the authors. Some have criticised the technique as lacking genuine scientific principles, and running counter to the ecological principles of soil building with litterfall. \n\nHügelkultur is said to replicate the natural process of decomposition that occurs on forest floors, however in natural ecosystems wood would be present at the soil surface. Trees that fall in a forest often become nurse logs decaying and providing ecological facilitation to seedlings. As the wood decays, its porosity increases, allowing it to store water like a sponge. The water is slowly released back into the environment, benefiting nearby plants.\n\nHügelkultur beds are said to be ideal for areas where the underlying soil is of poor quality or compacted. They tend to be easier to maintain due to their relative height above the ground. \n\nDecomposition speed of organic material depends on the carbon to nitrogen ratio of the material, among other factors. Wood breaks down relatively slowly because it has one of the highest carbon to nitrogen ratios of all organic matter that is used in composting. If the wood is not processed into smaller pieces with larger surface area to speed up chemical reactions, breakdown is even slower. The decomposition process may in the short term take more nitrogen from the soil through microbial activity (nitrogen immobilization), if not enough nitrogen is available. Thus in the short term the fertility of the soil may be decreased before eventually, perhaps after 1-2 years, the nitrogen level is increased past the original level. Traditionally therefore, it is said to be advantageous to balance \"browns\" (e.g. woodchippings) with \"greens\" (e.g. leaves) for efficient composting, and to allow compost to become well-rotted before applying it a bed to prevent competition between soil bacteria and plants for nitrogen, reducing yield.\n\nAlthough Hügelkultur beds can safely retain water in light-duty applications (for example, conserving the moisture of rain that falls on the bed), creating heavy-duty rainwater retention areas behind Hügelkultur beds on contour, to catch surface runoff from surrounding areas, can be dangerous. Some designers conflate the Hügelkultur bed's appearance with that of solid earthworks, but Hügelkultur beds cannot predictably control large amounts of stormwater in the way that solid earthworks can. Whereas embankment dams or the hillsides of swales can be relied on to hold back many thousands of gallons of water for weeks to allow it to seep into the ground, and berms can slow runoff, Hügelkultur beds are different in two ways: earthworks have no buoyant core (whereas Hügelkultur mounds contain logs), and the soil that they are made of is compacted. If fresh or dried timber is used in the bed, it may become buoyant in the water-saturated substrate, bursting from the soil covering and releasing all the sitting water through a breach. This can be an issue for years, until the wood is sufficiently rotten and infused with water. Another consideration is that Hügelkultur beds will degrade, shrinking over time into much lower mounds of soft, rich soil. This means that the retention area will have less depth as time goes on, but it also means that the uncompacted soil will remain a threat to breaching even if the logs become saturated.\n\nThere is a recorded instance of a breach occurring in a new project. Upon the first rainstorm, the retention areas behind the Hügelkultur beds filled with water and broke through. The released water carried the freshly-buried logs and dirt downhill, smashing a hole in a building being used as a church and filling the space with mud. No injuries were reported.\n\nSome permaculturists have taken mild positions against the \"hügel swales\" still being promoted by other permaculturists, citing the danger and cross-purposes of Hügelkultur beds and swales.\n\nOver-fertilized plants are said to have less flavor, and too much nitrogen can be consumed by eating certain plants which have been over-fertilised (e.g. spinach). Advocates state that overfertilization is a risk in the first year if woodchips are used, which will break down too fast. Instead raised beds made with whole logs release nutrients slowly over a period of years. It has been suggested that excessive use of decomposing organic matter in Hügelkultur could leach out and contaminate and disrupt soil and water habitats.\n\n"}
{"id": "33475644", "url": "https://en.wikipedia.org/wiki?curid=33475644", "title": "Israeli Geographical Association", "text": "Israeli Geographical Association\n\nIsraeli Geographical Association (, \"HaAguda HaGe'ografit HaYisra'elit\") is a professional association of geographers in Israel. the Society members engaged in all areas of human and physical Geography. the Israeli Geographic Society is working since 1959 to promote Israel's varied geography and its representation in the world. Israeli Geographical Association is a member of International Geographical Union (IGU). \"\nBetween the goals of the Association: to promote knowledge, geographical research and teaching, raising awareness of the achievements and contribution to geography, geography domain representation in various forums, promoting the professional status of geographers.\nBetween tasks Association: Annual Conference which takes place during Hanukkah and Society Awards which geographically unique contribution to geographical education, distributing a monthly newsletter and journals including the Journal \"Horizons in Geography\", running a distribution list and a website.\nThe Association operates under the auspices of the Israeli Student Organization of Geography, member of European Students of Geography (EGEA).\nThe Association is a nonprofit organization and it operates according to democratic principles. The Association Council and the President is chosen every two years and are a higher authority. Between the presidents of the Association in the past, Israel Prize laureates were: Professor David Amiran, Prof. Dov Nir, Prof. and Prof. Arie Shachar.\n\n"}
{"id": "56028198", "url": "https://en.wikipedia.org/wiki?curid=56028198", "title": "Journal of Coastal Research", "text": "Journal of Coastal Research\n\nThe Journal of Coastal Research is a bimonthly peer-reviewed scientific journal covering research on coastal studies and processes. It was established in 1984 as Litoralia, obtaining its current name in 1985. It is published by the Coastal Education and Research Foundation, whose president and executive director, Charles W. Finkl, is also the journal's editor-in-chief. The journal has been a member of BioOne since 2005. According to the \"Journal Citation Reports\", the journal has a 2016 impact factor of 0.915, ranking it 193rd out of 229 journals in the category \"Environmental Sciences\".\n"}
{"id": "23797849", "url": "https://en.wikipedia.org/wiki?curid=23797849", "title": "Laminar sublayer", "text": "Laminar sublayer\n\nThe laminar sublayer, also called the viscous sublayer, is the region of a mainly-turbulent flow that is near a no-slip boundary and in which the flow is laminar. As such, it is a type of boundary layer. The existence of the laminar sublayer can be understood in that the flow velocity decreases towards the no-slip boundary. Because of this, the Reynolds number decreases until at some point the flow crosses the threshold from turbulent to laminar.\n\nThe laminar sublayer is important for river-bed ecology: below the laminar-turbulent interface, the flow is stratified, but above it, it rapidly becomes well-mixed. This threshold can be important in providing homes and feeding grounds for benthic organisms.\n\nWhether the roughness due to the bed sediment or other factors are smaller or larger than this sublayer has an important bearing in hydraulics and sediment transport. Flow is defined as hydraulically rough if the roughness elements are larger than the laminar sublayer (thereby perturbing the flow), and as hydraulically smooth if they are smaller than the laminar sublayer (and therefore ignorable by the main body of the flow).\n"}
{"id": "2861044", "url": "https://en.wikipedia.org/wiki?curid=2861044", "title": "Land description", "text": "Land description\n\nA land description location of the written words which delineate a specific piece of real property. Also known as a \"Legal Description\". In the written transfer of real property, it is universally required that the instrument of conveyance (deed) include a written description of the property.\n\n\n"}
{"id": "5283831", "url": "https://en.wikipedia.org/wiki?curid=5283831", "title": "Landscape detailing", "text": "Landscape detailing\n\nLandscape detailing describes the process of integrating soft landscape materials and hard landscape materials to create a landscape design. It requires knowledge of:\nDesigning Landscape detailing can be boiled down to three different steps:Function, Structure, and Appearance. Function allows you to satisfy the requirements of the landscape to serve a purpose. Structure is the physical implementation of function through the best available resources; usually those of a local character. Appearance is about obtaining visual satisfaction, commonly known as aesthetic values.\n\nLandscape detailing can influence the attitude and mood of a landscape. A study was conducted on how young people feel when in a natural oriented landscape versus an engineered habitat. The results showed that more structured landscapes are preferred in young people. Detailing in landscape allows the designer to make choices that help influence the landscape; allowing the potential to be shown.(1)\n\nLandscape can have an influence on how communities and societies evolve and vice verse. Communities can shape how the landscape is used based on the needs of the community. We can see an example of this in Canada's landscape and the role the railroads had in shaping the community. With the introduction of the railroad, Canada's wild lands were more susceptible to exploitation. On the contrary to that, the railroad system also allowed the community to experience Canada's array of National Parks.(2)\n\nLandscape detailing is not just limited to actual land, but can also be seen as a way to improve waterfront area; making the waterfront a more appealing setting for the public to enjoy. Typically when addressing the relationship of landscape detailing and water, we think of drainage and how the landscape can be manipulated to serve the user; as to prevent flooding and maintain water flows.(3)\n\nWith today's every expanding technologies, there has been an increase in ways to convey landscape detailing. The visualization tools can be split into two categories; traditional and computerized. Traditional ways to convey details in the landscape would be simply a pen/pencil, paper maps, and models; while the computerized way would to use GIS, 3D virtual modelling,or simulations using layers of photography to convey urban areas that have potential to be molded. (4)\n\nAesthetics are an important part of Landscape Detailing,the visual quality of a landscape is what is noticed by others and therefore the goal is to achieving pleasing aesthetic without creating a synthetic feel. Art and design are also qualities that enhance the landscape. Artistic influence has a direct role in planning a landscape.(5)\n\n\n\n"}
{"id": "1034969", "url": "https://en.wikipedia.org/wiki?curid=1034969", "title": "Levelling", "text": "Levelling\n\nLevelling (British English) or leveling (American English); is a branch of surveying, the object of which is to establish or verify or measure the height of specified points relative to a datum. It is widely used in cartography to measure geodetic height, and in construction to measure height differences of construction artifacts.\n\nOptical levelling employs an optical level,which consists of a precision telescope with crosshairs and Stadia marks. The cross hairs are used to establish the level point on the target, and the stadia allow range-finding; stadia are usually at ratios of 100:1, in which case one metre between the stadia marks on the levelling staff represents 100 metres from the target.\nThe complete unit is normally mounted on a tripod, and the telescope can freely rotate 360° in a horizontal plane. The surveyor adjusts the instrument's level by coarse adjustment of the tripod legs and fine adjustment using three precision levelling screws on the instrument to make the rotational plane horizontal. The surveyor does this with the use of a bull's eye level built into the instrument mount.\nThe surveyor looks through the eyepiece of telescope while an assistant holds a vertical level staff which is a graduated in inches or centimeters. The level staff is placed with its foot on the point for which the level measurement is required. The telescope is rotated and focused until the level staff is plainly visible in the crosshairs. In the case of a high accuracy manual level, the fine level adjustment is made by an altitude screw, using a high accuracy bubble level fixed to the telescope. This can be viewed by a mirror whilst adjusting or the ends of the bubble can be displayed within the telescope, which also allows assurance of the accurate level of the telescope whilst the sight is being taken. However, in the case of an automatic level, altitude adjustment is done automatically by a suspended prism due to gravity, as long as the coarse levelling is accurate within certain limits. When level, the staff graduation reading at the crosshairs is recorded, and an identifying mark or marker placed where the level staff rested on the object or position being surveyed.\n\nA typical procedure for a linear track of levels from a known datum is as follows. Set up the instrument within of a point of known or assumed elevation. A rod or staff is held vertical on that point and the instrument is used manually or automatically to read the rod scale. This gives the height of the instrument above the starting (backsight) point and allows the height of the instrument (H.I.) above the datum to be computed.\nThe rod is then held on an unknown point and a reading is taken in the same manner, allowing the elevation of the new (foresight) point to be computed. The procedure is repeated until the destination point is reached. It is usual practice to perform either a complete loop back to the starting point or else close the traverse on a second point whose elevation is already known. The closure check guards against blunders in the operation, and allows residual error to be distributed in the most likely manner among the stations.\n\nSome instruments provide three crosshairs which allow stadia measurement of the foresight and backsight distances. These also allow use of the average of the three readings (3-wire leveling) as a check against blunders and for averaging out the error of interpolation between marks on the rod scale.\n\nThe two main types of levelling are single-levelling as already described, and double-levelling (Double-rodding). In double-levelling, a surveyor takes two foresights and two backsights and makes sure the difference between the foresights and the difference between the backsights are equal, thereby reducing the amount of error. Double-levelling costs twice as much as single-levelling.\n\nWhen using an optical level, the endpoint may be out of the effective range of the instrument. There may be obstructions or large changes of elevation between the endpoints. In these situations, extra setups are needed. Turning is a term used when referring to moving the level to take an elevation shot from a different location.\n\nTo \"turn\" the level, one must first take a reading and record the elevation of the point the rod is located on. While the rod is being kept in exactly the same location, the level is moved to a new location where the rod is still visible. A reading is taken from the new location of the level and the height difference is used to find the new elevation of the level gun. This is repeated until the series of measurements is completed.\n\nThe level must be horizontal to get a valid measurement. Because of this, if the horizontal crosshair of the instrument is lower than the base of the rod, the surveyor will not be able to sight the rod and get a reading. The rod can usually be raised up to 25 feet high, allowing the level to be set much higher than the base of the rod.\n\nThe curvature of the earth means that a line of sight that is horizontal at the instrument will be higher and higher above a spheroid at greater distances. The effect may be significant for some work at distances under 100 meters.\n\nThe line of sight is horizontal at the instrument, but is not a straight line because of refraction in the air. The change of air density with elevation causes the line of sight to bend toward the earth.\n\nThe combined correction for refraction and curvature is approximately: \nFor precise work these effects need to be calculated and corrections applied. For most work it is sufficient to keep the foresight and backsight distances approximately equal so that the refraction and curvature effects cancel out. Refraction is generally the greatest source of error in leveling. For short level lines the effects of temperature and pressure are generally insignificant, but the effect of the temperature gradient \"dT / dh\" can lead to errors.\n\nAssuming error-free measurements, if the Earth's gravity field were completely regular and gravity constant, leveling loops would always close precisely:\n\naround a loop. In the real gravity field of the Earth, this happens only approximately; on small loops typical of engineering projects, the loop closure is negligible, but on larger loops covering regions or continents it is not.\n\nInstead of height differences, \"geopotential differences\" do close around loops:\n\nwhere formula_5 stands for gravity at the leveling interval \"i\". For precise leveling networks on a national scale, the latter formula should always be used.\n\nshould be used in all computations, producing geopotential values formula_7 for the benchmarks of the network.\n\n The wye level is the oldest and bulkiest of the older style optical instruments. A low-powered telescope is placed in a pair of clamp mounts, and the instrument then leveled using a spirit level, which is mounted parallel to the main telescope.\n\nThe dumpy level was developed by English civil engineer William Gravatt, while surveying the route of a proposed railway line from London to Dover. More compact and hence both more robust and easier to transport, it is commonly believed that dumpy levelling is less accurate than other types of levelling, but such is not the case. Dumpy levelling requires shorter and therefore more numerous sights, but this fault is compensated by the practice of making foresights and backsights equal.\n\nPrecise level designs were often used for large leveling projects where utmost accuracy was required. They differ from other levels in having a very precise spirit level tube and a micrometer adjustment to raise or lower the line of sight so that the crosshair can be made to coincide with a line on the rod scale and no interpolation is required.\n\nAutomatic levels make use of a compensator that ensures that the line of sight remains horizontal once the operator has roughly leveled the instrument (to within maybe 0.05 degree). The surveyor sets the instrument up quickly and doesn't have to relevel it carefully each time he sights on a rod on another point. It also reduces the effect of minor settling of the tripod to the actual amount of motion instead of leveraging the tilt over the sight distance. Three level screws are used to level the instrument.\n\nLaser levels project a beam which is visible and/or detectable by a sensor on the leveling rod. This style is widely used in construction work but not for more precise control work. An advantage is that one person can perform the levelling independently, whereas other types require one person at the instrument and one holding the rod.\n\nThe sensor can be mounted on earth-moving machinery to allow automated grading.\n\n\n"}
{"id": "52740768", "url": "https://en.wikipedia.org/wiki?curid=52740768", "title": "List of downs", "text": "List of downs\n\nDown is used in the name of geographical features or locations that are downland or close to downland, including:\n\n\n\n"}
{"id": "23135988", "url": "https://en.wikipedia.org/wiki?curid=23135988", "title": "List of international presidential trips made by Barack Obama", "text": "List of international presidential trips made by Barack Obama\n\nThis is a list of international presidential trips made by Barack Obama, the 44th president of the United States. Barack Obama made 52 international trips to 58 different countries (in addition to visiting the West Bank) during his presidency, which began on January 20, 2009 and ended on January 20, 2017. He set the record as the most-traveled president for any first year in office. Obama made ten trips to 21 countries (four countries were visited twice) and was out of the U.S. a total of 40 days.\nThe number of visits per country where he traveled are:\n\nThe following international trips were made by Barack Obama during 2009:\n\nThe following international trips were made by Barack Obama during 2010:\n\nThe following international trips were made by Barack Obama in 2011:\n\nThe following international trips were made by Barack Obama during 2012:\n\nThe following international trips were made by Barack Obama during 2013:\n\nThe following international trips were made by Barack Obama during 2014:\n\nThe following international trips were made by Barack Obama during 2015:\n\nThe following international trips were made by Barack Obama during 2016:\n\n\n"}
{"id": "29955313", "url": "https://en.wikipedia.org/wiki?curid=29955313", "title": "List of presidential trips made by Barack Obama during 2010", "text": "List of presidential trips made by Barack Obama during 2010\n\nThis is a list of presidential trips made by Barack Obama during 2010, the second year of his presidency as the 44th President of the United States. During 2010, Obama traveled to eight different nation states internationally, in addition to many more trips made domestically within the United States.\n\nThis list excludes trips made within Washington, D.C., the U.S. federal capital in which the White House, the official residence and principal workplace of the President, is located. Additionally excluded are trips to Camp David, the country residence of the President, and to the private home of the Obama family in Kenwood, Chicago.\n"}
{"id": "45515618", "url": "https://en.wikipedia.org/wiki?curid=45515618", "title": "List of presidential trips made by Barack Obama during 2015", "text": "List of presidential trips made by Barack Obama during 2015\n\nThis is a list of presidential trips made by Barack Obama during 2015, the seventh year of his presidency as the 44th President of the United States.\n\nThis list excludes trips made within Washington, D.C., the U.S. federal capital in which the White House, the official residence and principal workplace of the President, is located. Additionally excluded are trips to Camp David, the country residence of the President, and to the private home of the Obama family in Kenwood, Chicago, Illinois.\n"}
{"id": "56348751", "url": "https://en.wikipedia.org/wiki?curid=56348751", "title": "List of presidential trips made by Ilham Aliyev", "text": "List of presidential trips made by Ilham Aliyev\n\nThis article consists of the list of international official and work trips made by Ilham Aliyev, the fourth and current President of Azerbaijan, during the terms of his presidency.\n\nTrips during the first presidential term (2003-2008)\nTrips during the second presidential term (2008-2013)\n\nTrips during the third presidential term (2013-2018)\n\nTrips during the third presidential term (2018-Present)\n\n"}
{"id": "11485690", "url": "https://en.wikipedia.org/wiki?curid=11485690", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: A", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: A\n\n\n"}
{"id": "2882854", "url": "https://en.wikipedia.org/wiki?curid=2882854", "title": "Longitude by chronometer", "text": "Longitude by chronometer\n\nLongitude by chronometer is a method, in navigation, of determining longitude using a marine chronometer, which was developed by John Harrison during the first half of the eighteenth century. It is an astronomical method of calculating the longitude at which a position line, drawn from a sight by sextant of any celestial body, crosses the observer's assumed latitude. In order to calculate the position line, the time of the sight must be known so that the celestial position i.e. the Greenwich Hour Angle (Celestial Longitude - measured in a westerly direction from Greenwich) and Declination (Celestial Latitude - measured north or south of the equational or celestial equator), of the observed celestial body is known. All that can be derived from a single sight is a single position line, which can be achieved at any time during daylight when both the sea horizon and the sun are visible. To achieve a fix, more than one celestial body and the sea horizon must be visible. This is usually only possible at dawn and dusk.\n\nThe angle between the sea horizon and the celestial body is measured with a sextant and the time noted. The Sextant reading is known as the 'Sextant Altitude'. This is corrected by use of tables to a 'True Altitude'. The actual declination and hour angle of the celestial body are found from astronomical tables for the time of the measurement and together with the 'True Altitude' are put into a formula with the assumed latitude. This formula calculates the 'True Hour Angle' which is compared to the assumed longitude providing a correction to the assumed longitude. This correction is applied to the assumed position so that a position line can be drawn through the assumed latitude at the corrected longitude at 90° to the azimuth (bearing) on the celestial body. The observer's position is somewhere along the position line, not necessarily at the found longitude at the assumed latitude. If two or more sights or measurements are taken within a few minutes of each other a 'fix' can be obtained and the observer's position determined as the point where the position lines cross.\n\nThe azimuth (bearing) of the celestial body is also determined by use of astronomical tables and for which the time must also be known.\n\nFrom this, it can be seen that a navigator will need to know the time very accurately so that the position of the observed celestial body is known just as accurately. The position of the sun is given in degrees and minutes north or south of the equational or celestial equator and east or west of Greenwich, established by the English as the Prime Meridian.\n\nThe desperate need for an accurate chronometer was finally met in the mid 18th century when an Englishman, John Harrison, produced a series of chronometers that culminated in his celebrated model H-4 that satisfied the requirements for a shipboard standard time-keeper.\n\nMany nations, such as France, have proposed their own reference longitudes as a standard, although the world’s navigators have generally come to accept the reference longitudes tabulated by the British. The reference longitude adopted by the British became known as the Prime Meridian and is now accepted by most nations as the starting point for all longitude measurements. The Prime Meridian of zero degrees longitude runs along the meridian passing through the Royal Observatory at Greenwich, England. Longitude is measured east and west from the Prime Meridian. To determine \"longitude by chronometer,\" a navigator requires a chronometer set to the local time at the Prime Meridian. Local time at the Prime Meridian has historically been called Greenwich Mean Time (GMT), but now, due to international sensitivities, has been renamed as Coordinated Universal Time (UTC), and is known colloquially as \"zulu time\".\n\nNoon sights obtain the observer's Latitude. It is impossible to determine longitude with an accuracy better than 10nmi by means of a noon sight. A noon sight is called a Meridian Altitude. While it is very easy to determine the observer's latitude at noon without knowing the exact time, longitude cannot accurately be measured at noon. At noon the sun's change of altitude is very slow, so determining the exact time that the sun is at its zenith by direct observation is impossible, and therefore it is impossible to obtain an accurate longitude at the moment of Zenith. However, it is possible to determine the time of zenith for longitude with a useful accuracy by performing a mean time of observation when the sun is on its ascent and descent prior to and following its moment of Zenith. By taking a sextant reading within 15 to 30 minutes prior to local noon (zenith) and noting the time, then leaving the sextant set to the same angle and subsequently observing the moment in time at which the sun passes through the sight tube on its descent from Zenith between a half-hour and hour later, the two times can be averaged to obtain a longitude sufficiently accurate for navigation (within 2nmi).\n\nUnfortunately, the Earth does not make a perfect circular orbit around the Sun. Due to the elliptical nature of the Earth’s orbit around the Sun, the speed of the Sun’s apparent orbit around the Earth varies throughout the year and that causes it to appear to speed up and slow down very slightly. Consequently, noon at the Prime Meridian is rarely if ever exactly at 1200 UTC, but rather it occurs some minutes and seconds before or after that time each day. This slight daily variation has been calculated and is listed for each day of the year in the Nautical Almanac under the title of \"Equation of time\". This variation must be added to or subtracted from the UTC of local apparent noon to improve the accuracy of the calculation. Even with that, other factors, including the difficulty of determining the exact moment of local apparent noon due to the flattening of the Sun’s arc across the sky at its highest point, diminish the accuracy of determining longitude by chronometer as a method of celestial navigation. Accuracies of less than error in position are difficult to achieve using the \"longitude by chronometer\" method. Other celestial navigation methods involving more extensive use of both the Nautical Almanac and sight reduction tables are used by navigators to achieve accuracies of one nautical mile (1.9 km) or less.\n\n This only calculates a longitude at the assumed latitude though a position line can be drawn. The observer is somewhere along the position line.\nTime sight is a general method for determining longitude by celestial observations using a chronometer; these observations are reduced by solving the navigational triangle for meridian angle and require known values for altitude, latitude, and declination; the meridian angle is converted to local hour angle and compared with Greenwich hour angle.\n\nIf \"Dec\" is the declination of the observed celestial body and Ho is its observed altitude, the local hour angle, \"LHA\", is obtained for a known latitude \"B\" by:\n\nformula_1\n\nThe time sight was a complement to the noon sight or latitude by Polaris in order to obtain a fix.\n\n\n\n"}
{"id": "7957331", "url": "https://en.wikipedia.org/wiki?curid=7957331", "title": "Massey Medal", "text": "Massey Medal\n\nThe Royal Canadian Geographical Society (RCGS) awards the Massey Medal annually to recognize outstanding personal achievement in the exploration, development or description of the geography of Canada. The award was established in 1959, by the Massey Foundation, named for industrialist Hart Massey.\n\n"}
{"id": "19159", "url": "https://en.wikipedia.org/wiki?curid=19159", "title": "Mile", "text": "Mile\n\nThe mile is an English unit of length of linear measure equal to 5,280 feet, or 1,760 yards, and standardised as exactly 1,609.344 metres by international agreement in 1959.\n\nWith qualifiers, \"mile\" is also used to describe or translate a wide range of units derived from or roughly equivalent to the Roman mile, such as the nautical mile (now 1.852 km exactly), the Italian mile (roughly 1.852 km), and the Chinese mile (now 500 m exactly). The Romans divided their mile into 5,000 roman feet but the greater importance of furlongs in pre-modern England meant that the statute mile was made equivalent to 8 furlongs or 5,280 feet in 1593. This form of the mile then spread to the British-colonized nations some of which continue to employ the mile. The US Geological Survey now employs the metre for official purposes but legacy data from its 1927 geodetic datum has meant that a separate US survey mile ( km) continues to see some use. While most countries replaced the mile with the kilometre when switching to the International System of Units, the international mile continues to be used in some countries, such as Liberia, Myanmar, the United Kingdom, the United States, and a number of countries with fewer than one million inhabitants, most of which are UK or US territories, or have close historical ties with the UK or US.\n\nThe mile was usually abbreviated m. in the past but is now sometimes written as mi to avoid confusion with the SI metre. However, derived units, such as miles per hour or miles per gallon, continue to be universally abbreviated as mph and mpg, respectively.\n\nThe modern English word \"mile\" derives from Middle English ' and Old English ', which was cognate with all other Germanic terms for \"miles\". These derived from apocopated forms of the Latin ' or ', the plural of ' or ', literally \"thousand\" but used as a clipped form of ' or ', the Roman mile of one thousand paces.\n\nThe present international mile is usually what is understood by the unqualified term \"mile\". When this distance needs to be distinguished from the nautical mile, the international mile may also be described as a \"land mile\" or \"statute mile\". In British English, the \"statute mile\" may refer to the present international miles or to any other form of English mile since the 1593 Act of Parliament, which set it as a distance of 1,760 yards. Under American law, however, the \"statute mile\" refers to the US survey mile. Foreign and historical units translated into English as miles usually employ a qualifier to describe the kind of mile being used but this may be omitted if it is obvious from the context, such as a discussion of the 2nd-century Antonine Itinerary describing its distances in terms of \"miles\" rather than \"Roman miles\".\n\nThe mile has been variously abbreviated—with and without a trailing period—as m, M, ml, and mi. The American National Institute of Standards and Technology now uses and recommends mi in order to avoid confusion with the SI metre (m) and millilitre (ml). However, derived units such as miles per hour or miles per gallon continue to be abbreviated as mph and mpg rather than mi/h and mi/gal. In the United Kingdom road signs use m as the abbreviation for mile though height and width restrictions also use m as the abbreviation for the metre, which may be displayed alongside feet and inches. The BBC style holds that \"There is no acceptable abbreviation for 'miles'\" and so it should be spelt out when used in describing areas.\n\nThe Roman mile (',  \"thousand paces\";  m.p.; also ' and \"\") consisted of a thousand paces as measured by every other step—as in the total distance of the left foot hitting the ground 1,000 times. The ancient Romans, marching their armies through uncharted territory, would often push a carved stick in the ground after each 1,000 paces. Well-fed and harshly driven Roman legionaries in good weather thus created longer miles. The distance was indirectly standardised by Agrippa's establishment of a standard Roman foot (Agrippa's own) in 29 BC, and the definition of a pace as 5 feet. An Imperial Roman mile thus denoted 5,000 Roman feet. Surveyors and specialized equipment such as the decempeda and dioptra then spread its use. In modern times, Agrippa's Imperial Roman mile was empirically estimated to have been about in length. In Hellenic areas of the Empire, the Roman mile (, \"mílion\") was used beside the native Greek units as equivalent to 8 stadia of 600 Greek feet. The \"mílion\" continued to be used as a Byzantine unit and was also used as the name of the zero mile marker for the Byzantine Empire, the Milion, located at the head of the Mese near Hagia Sophia.\n\nThe Roman mile also spread throughout Europe, with its local variations giving rise to the different units below.\n\nAlso arising from the Roman mile is the \"milestone\". All roads radiated out from the Roman Forum throughout the Empire – 50,000 miles of stone-paved roads. At every mile was placed a shaped stone, on which was carved a Roman numeral, indicating the number of miles from the center of Rome – the Forum. Hence, one always knew how far one was from Rome.\n\nThe Italian mile (',  ') was traditionally considered a direct continuation of the Roman mile, equal to 1000 paces, although its actual value over time or between regions could vary greatly. It was often used in international contexts from the Middle Ages into the 17th century and is thus also known as the \"geographical mile\", although the geographical mile is now a separate standard unit.\n\nThe Arabic mile (, \"al-mīl\") was not the common Arabic unit of length; instead, Arabs and Persians traditionally used the longer parasang or \"Arabic league\". The Arabic mile was, however, used by medieval geographers and scientists and constituted a kind of precursor to the nautical or geographical mile. It extended the Roman mile to fit an astronomical approximation of 1 arcminute of latitude measured directly north-and-south along a meridian. Although the precise value of the approximation remains disputed, it was somewhere between 1.8 and 2.0 km.\n\nThe \"old English mile\" of the medieval and early modern periods varied but seems to have measured about 1.3 international miles (1.9 km). The English long continued the Roman computations of the mile as 5000 feet, 1000 paces, or 8 longer divisions, which they equated with their \"furrow's length\" or furlong.\n\nThe origins of English units are \"extremely vague and uncertain\", but seem to have been a combination of the Roman system with native British and Germanic systems both derived from multiples of the barleycorn. Probably by the reign of Edgar in the 10th century, the nominal prototype physical standard of English length was an arm-length iron bar (a yardstick) held by the king at Winchester; the foot was then one-third of its length. Henry I was said to have made a new standard in 1101 based on his own arm. Following the issuance of Magna Carta, the barons of Parliament directed John and his son to keep the king's standard measure (\"\") and weight at the Exchequer, which thereafter verified local standards until its abolition in the 19th century. New brass standards are known to have been constructed under Henry VII and Elizabeth I.\n\nArnold's \"Customs of London\" recorded a mile shorter than previous ones, coming to 0.947 international miles or 1.524 km.\nThe English statute mile was established by a Weights and Measures Act of Parliament in 1593 during the reign of Queen Elizabeth I. The act on the Composition of Yards and Perches had shortened the length of the foot and its associated measures, causing the two methods of determining the mile to diverge. Owing to the importance of the surveyor's rod in deeds and surveying undertaken under Henry VIII, decreasing the length of the rod by would have amounted to a significant tax increase. Parliament instead opted to maintain the mile of 8 furlongs (which were derived from the rod) and to increase the number of feet per mile from the old Roman value. The applicable passage of the statute reads: \"A Mile shall contain eight Furlongs, every Furlong forty Poles, and every Pole shall contain sixteen Foot and half.\" The statute mile therefore contained 5,280 feet or 1,760 yards. The distance was not uniformly adopted. Robert Morden had multiple scales on his 17th-century maps which included continuing local values: his map of Hampshire, for example, bore two different \"miles\" with a ratio of and his map of Dorset had three scales with a ratio of . In both cases, the traditional local units remained longer than the statute mile.\n\nThe Welsh mile (' or ') was 3 miles and 1470 yards long (6.17 km). It comprised 9000 paces ('), each of 3 Welsh feet (') of 9 inches, usually reckoned as equivalent to the English inch. Along with other Welsh units, it was said to have been codified under Dyfnwal the Bald and Silent and retained unchanged by Hywel the Good. Along with other Welsh units, it was discontinued following the conquest of Wales by the English under Edward I in the 13th century.\n\nThe Scots mile was longer than the English mile, as mentioned by Robert Burns in the first verse of his poem \"Tam o' Shanter\". It comprised 8 (Scots) furlongs divided into 320 falls or faws (Scots rods). It varied from place to place but the most accepted equivalencies are 1,976 Imperial yards (1.123 statute miles or 1.81 km).\n\nIt was legally abolished three times: first by a 1685 act of the Scottish Parliament, again by the 1707 Treaty of Union with England, and finally by the Weights and Measures Act 1824. It had continued in use as a customary unit through the 18th century but had become obsolete by its final abolition.\n\nThe Irish mile (' or ') measured 2240 yards: approximately 1.27 statute miles or 2.048 kilometres. It was used in Ireland from the 16th century plantations until the 19th century, with residual use into the 20th century. The units were based on \"English measure\" but used a linear perch measuring as opposed to the English rod of .\n\n\nThe international mile is precisely equal to (or  km as a fraction). It was established as part of the 1959 international yard and pound agreement reached by the United States, the United Kingdom, Canada, Australia, New Zealand, and South Africa, which resolved small but measurable differences that had arisen from separate physical standards each country had maintained for the yard. As with the earlier statute mile, it continues to comprise 1,760 yards or 5,280 feet.\n\nThe old Imperial value of the yard was used in converting measurements to metric values in India in a 1976 Act of the Indian Parliament. However, the current National Topographic Database of the Survey of India is based on the metric WGS-84 datum, which is also used by the Global Positioning System.\n\nThe difference from the previous standards was 2 ppm, or about 3.2 millimeters ( inch) per mile. The U.S. standard was slightly longer and the old Imperial standards had been slightly shorter than the international mile. When the international mile was introduced in English-speaking countries, the basic geodetic datum in America was the North American Datum of 1927 (NAD27). This had been constructed by triangulation based on the definition of the foot in the Mendenhall Order of 1893, with 1 foot =  metres and the definition was retained for data derived from NAD27, but renamed the \"U.S. survey foot\" to distinguish it from the international foot.\n\nThe exact length of the land mile varied slightly among English-speaking countries until the international yard and pound agreement in 1959 established the yard as exactly 0.9144 metres, giving a mile exactly 1,609.344 metres. The U.S. adopted this international mile for most purposes, but retained the pre-1959 mile for some land-survey data, terming it the \"U. S. survey mile\". In the United States, \"statute mile\" normally refers to the survey mile, about 3.219 mm ( inch) longer than the international mile (the international mile is exactly 0.0002% less than the U.S. survey mile).\n\nWhile most countries replaced the mile with the kilometre when switching to the International System of Units, the international mile continues to be used in some countries, such as Liberia, Myanmar, the United Kingdom and the United States. It is furthermore used in a number of countries with vastly less than a million inhabitants, most of which are UK or US territories, or have close historical ties with the UK or US: American Samoa, Bahamas, Belize, British Virgin Islands, Cayman Islands, Dominica, Falkland Islands, Grenada, Guam, The N. Mariana Islands, Samoa, St. Lucia, St. Vincent & The Grenadines, St. Helena, St. Kitts & Nevis, the Turks & Caicos Islands, and the U.S. Virgin Islands.\nThe mile is even encountered in Canada, though this is predominantly in rail transport and horse racing, as the roadways have been metricated since 1977.\n\nThe \"U.S. survey mile\" is 5,280 survey feet, or about 1,609.347 metres. In the United States, \"statute mile\" formally refers to the survey mile, but for most purposes, the difference between the survey mile and the international mile is insignificant—one international mile is U.S. survey miles—so \"statute mile\" can be used for either. But in some cases, such as in the U.S. State Plane Coordinate Systems (SPCSs), which can stretch over hundreds of miles, the accumulated difference \"can be\" significant, so it is important to note that the reference is to the U.S. survey mile.\n\nThe United States redefined its yard in 1893, but this resulted in U.S. and Imperial measures of distance having very slightly different lengths.\n\nThe North American Datum of 1983 (NAD83), which replaced the NAD27, is defined in meters. State Plane Coordinate Systems were then updated, but the National Geodetic Survey left individual states to decide which (if any) definition of the foot they would use. All State Plane Coordinate Systems are defined in meters, and 42 of the 50 states only use the metre-based State Plane Coordinate Systems. However, eight states also have State Plane Coordinate Systems defined in feet, seven of them in U.S. Survey feet and one in international feet.\n\nState legislation in the U.S. is important for determining which conversion factor from the metric datum is to be used for land surveying and real estate transactions, even though the difference (2 ppm) is hardly significant, given the precision of normal surveying measurements over short distances (usually much less than a mile). Twenty-four states have legislated that surveying measures be based on the U.S. survey foot, eight have legislated that they be based on the international foot, and eighteen have not specified which conversion factor to use.\n\nThe \"nautical mile\" was originally defined as one minute of arc along a meridian of the Earth. Navigators use dividers to step off the distance between two points on the navigational chart, then place the open dividers against the minutes-of-latitude scale at the edge of the chart, and read off the distance in nautical miles. The Earth is not perfectly spherical but an oblate spheroid, so the length of a minute of latitude increases by 1% from the equator to the poles. Using the WGS84 ellipsoid, the commonly accepted Earth model for many purposes today, one minute of latitude at the WGS84 equator is 6,046 feet and at the poles is 6,107.5 feet. The average is about 6,076 feet (about 1,852 metres or 1.15 statute miles).\n\nIn the United States, the nautical mile was defined in the 19th century as 6,080.2 feet (1,853.249 m), whereas in the United Kingdom, the \"Admiralty nautical mile\" was defined as 6,080 feet (1,853.184 m) and was about one minute of latitude in the latitudes of the south of the UK. Other nations had different definitions of the nautical mile, but it is now internationally defined to be exactly .\n\nThe nautical mile per hour is known as the knot. Nautical miles and knots are almost universally used for aeronautical and maritime navigation, because of their relationship with degrees and minutes of latitude and the convenience of using the latitude scale on a map for distance measuring.\n\nThe data mile is used in radar-related subjects and is equal to 6,000 feet (1.8288 kilometres). The radar mile is a unit of time (in the same way that the light year is a unit of distance), equal to the time required for a radar pulse to travel a distance of two miles (one mile each way). Thus, the radar statute mile is 10.8 μs and the radar nautical mile is 12.4 μs.\n\nThe geographical mile is based upon the length of a meridian of latitude. The German geographical mile () was previously ° of latitude (7.4127 km).\n\nCities in the continental United States often have streets laid out by miles. Detroit, Indianapolis, Chicago, Phoenix, Philadelphia, Las Vegas, Los Angeles, and Miami, are several examples. Typically the largest streets are about a mile apart, with others at smaller intervals. In the Manhattan borough of New York City \"streets\" are close to 20 per mile, while the major numbered \"avenues\" are about six per mile. (Centerline to centerline, 42nd Street to 22nd Street is supposed to be 5250 feet while 42nd Street to 62nd Street is supposed to be 5276 ft 8 in.)\n\nThe informal term \"metric mile\" is used in sports such as track and field athletics and speed skating to denote a distance of . In United States high-school competition, the term is sometimes used for a race of .\n\nThe Scandinavian mile (') remains in common use in Norway and Sweden, where it has meant precisely 10 km since metrication occurred in 1889. It is used in informal situations and in measurements of fuel consumption, which are often given as litres per '. In formal situations (such as official road signs) and where confusion may occur with international miles, it is avoided in favour of kilometres.\n\nThe Swedish mile was standardised as 36,000 Swedish feet or 10.687 km in 1649; before that it varied by province from about 6 to 14.485 km.\n\nBefore metrication, the Norwegian mile was 11.298 km.\n\nThe traditional Finnish ' was translated as ' in Swedish and also set equal to 10 km during metrication in 1887, but is much less commonly used.\n\nA comparison of the different lengths for a \"mile\", in different countries and at different times in history, is given in the table below. Leagues are also included in this list because, in terms of length, they fall in between the short West European miles and the long North, Central and Eastern European miles.\n\nSimilar units:\n\nEven in English-speaking countries that have moved from the Imperial to the metric system (for example, Australia, Canada, and New Zealand), the mile is still used in a variety of idioms. These include:\n\n\n"}
{"id": "37754", "url": "https://en.wikipedia.org/wiki?curid=37754", "title": "Mountain", "text": "Mountain\n\nA mountain is a large landform that rises above the surrounding land in a limited area, usually in the form of a peak. A mountain is generally steeper than a hill. Mountains are formed through tectonic forces or volcanism. These forces can locally raise the surface of the earth. Mountains erode slowly through the action of rivers, weather conditions, and glaciers. A few mountains are isolated summits, but most occur in huge mountain ranges.\n\nHigh elevations on mountains produce colder climates than at sea level. These colder climates strongly affect the ecosystems of mountains: different elevations have different plants and animals. Because of the less hospitable terrain and climate, mountains tend to be used less for agriculture and more for resource extraction and recreation, such as mountain climbing.\n\nThe highest mountain on Earth is Mount Everest in the Himalayas of Asia, whose summit is above mean sea level. The highest known mountain on any planet in the Solar System is Olympus Mons on Mars at .\n\nThere is no universally accepted definition of a mountain. Elevation, volume, relief, steepness, spacing and continuity have been used as criteria for defining a mountain. In the Oxford English Dictionary a mountain is defined as \"a natural elevation of the earth surface rising more or less abruptly from the surrounding level and attaining an altitude which, relatively to the adjacent elevation, is impressive or notable.\"\n\nWhether a landform is called a mountain may depend on local usage. Mount Scott outside Lawton, Oklahoma is only from its base to its highest point. Whittow's \"Dictionary of Physical Geography\" states \"Some authorities regard eminences above as mountains, those below being referred to as hills.\"\n\nIn the United Kingdom and the Republic of Ireland, a mountain is usually defined as any summit at least 2,000 feet (or 610 metres) high, whilst the official UK government's definition of a mountain, for the purposes of access, is a summit of 600 metres or higher. In addition, some definitions also include a topographical prominence requirement, typically . At one time the U.S. Board on Geographic Names defined a mountain as being or taller, but has abandoned the definition since the 1970s. Any similar landform lower than this height was considered a hill. However, today, the United States Geological Survey (USGS) concludes that these terms do not have technical definitions in the US.\n\nThe UN Environmental Programme's definition of \"mountainous environment\" includes any of the following:\nUsing these definitions, mountains cover 33% of Eurasia, 19% of South America, 24% of North America, and 14% of Africa. As a whole, 24% of the Earth's land mass is mountainous.\n\nThere are three main types of mountains: volcanic, fold, and block. All three types are formed from plate tectonics: when portions of the Earth's crust move, crumple, and dive. Compressional forces, isostatic uplift and intrusion of igneous matter forces surface rock upward, creating a landform higher than the surrounding features. The height of the feature makes it either a hill or, if higher and steeper, a mountain. Major mountains tend to occur in long linear arcs, indicating tectonic plate boundaries and activity.\n\nVolcanoes are formed when a plate is pushed below another plate, or at a mid-ocean ridge or hotspot. At a depth of around 100 km, melting occurs in rock above the slab (due to the addition of water), and forms magma that reaches the surface. When the magma reaches the surface, it often builds a volcanic mountain, such as a shield volcano or a stratovolcano. Examples of volcanoes include Mount Fuji in Japan and Mount Pinatubo in the Philippines. The magma does not have to reach the surface in order to create a mountain: magma that solidifies below ground can still form dome mountains, such as Navajo Mountain in the US.\n\nFold mountains occur when two plates collide: shortening occurs along thrust faults and the crust is overthickened. Since the less dense continental crust \"floats\" on the denser mantle rocks beneath, the weight of any crustal material forced upward to form hills, plateaus or mountains must be balanced by the buoyancy force of a much greater volume forced downward into the mantle. Thus the continental crust is normally much thicker under mountains, compared to lower lying areas. Rock can fold either symmetrically or asymmetrically. The upfolds are anticlines and the downfolds are synclines: in asymmetric folding there may also be recumbent and overturned folds. The Jura Mountains are an example of fold mountains.\n\nBlock mountains are caused by faults in the crust: a plane where rocks have moved past each other. When rocks on one side of a fault rise relative to the other, it can form a mountain. The uplifted blocks are block mountains or horsts. The intervening dropped blocks are termed graben: these can be small or form extensive rift valley systems. This form of landscape can be seen in East Africa, the Vosges, the Basin and Range Province of Western North America and the Rhine valley. These areas often occur when the regional stress is extensional and the crust is thinned.\n\nDuring and following uplift, mountains are subjected to the agents of erosion (water, wind, ice, and gravity) which gradually wear the uplifted area down. Erosion causes the surface of mountains to be younger than the rocks that form the mountains themselves. Glacial processes produce characteristic landforms, such as pyramidal peaks, knife-edge arêtes, and bowl-shaped cirques that can contain lakes. Plateau mountains, such as the Catskills, are formed from the erosion of an uplifted plateau.\n\nIn earth science, \"erosion\" is the action of surface processes (such as water flow or wind) that removes soil, rock, or dissolved material from one location on the Earth's crust, and then transport it away to another location (not to be confused with weathering which involves no movement). The particulate breakdown of rock or soil into clastic sediment is referred to as \"physical\" or \"mechanical\" erosion; this contrasts with \"chemical\" erosion, where soil or rock material is removed from an area by its dissolving into a solvent (typically water), followed by the flow away of that solution. Eroded sediment or solutes may be transported just a few millimeters, or for thousands of kilometers.\nClimate in the mountains becomes colder at high elevations, due to an interaction between radiation and convection. Sunlight in the visible spectrum hits the ground and heats it. The ground then heats the air at the surface. If radiation were the only way to transfer heat from the ground to space, the greenhouse effect of gases in the atmosphere would keep the ground at roughly , and the temperature would decay exponentially with height.\n\nHowever, when air is hot, it tends to expand, which lowers its density. Thus, hot air tends to rise and transfer heat upward. This is the process of convection. Convection comes to equilibrium when a parcel of air at a given altitude has the same density as its surroundings. Air is a poor conductor of heat, so a parcel of air will rise and fall without exchanging heat. This is known as an adiabatic process, which has a characteristic pressure-temperature dependence. As the pressure gets lower, the temperature decreases. The rate of decrease of temperature with elevation is known as the adiabatic lapse rate, which is approximately 9.8 °C per kilometer (or 5.4 °F per 1000 feet) of altitude.\n\nNote that the presence of water in the atmosphere complicates the process of convection. Water vapor contains latent heat of vaporization. As air rises and cools, it eventually becomes saturated and cannot hold its quantity of water vapor. The water vapor condenses (forming clouds), and releases heat, which changes the lapse rate from the dry adiabatic lapse rate to the moist adiabatic lapse rate (5.5 °C per kilometer or 3 °F per 1000 feet) \nThe actual lapse rate can vary by altitude and by location.\n\nTherefore, moving up 100 meters on a mountain is roughly equivalent to moving 80 kilometers (45 miles or 0.75° of latitude) towards the nearest pole. This relationship is only approximate, however, since local factors such as proximity to oceans (such as the Arctic Ocean) can drastically modify the climate. As the altitude increases, the main form of precipitation becomes snow and the winds increase.\n\nThe effect of the climate on the ecology at an elevation can be largely captured through a combination of amount of precipitation, and the biotemperature, as described by Leslie Holdridge in 1947. Biotemperature is the mean temperature; all temperatures below are considered to be 0 °C. When the temperature is below 0 °C, plants are dormant, so the exact temperature is unimportant. The peaks of mountains with permanent snow can have a biotemperature below .\n\nThe colder climate on mountains affects the plants and animals residing on mountains. A particular set of plants and animals tend to be adapted to a relatively narrow range of climate. Thus, ecosystems tend to lie along elevation bands of roughly constant climate. This is called altitudinal zonation.\nIn regions with dry climates, the tendency of mountains to have higher precipitation as well as lower temperatures also provides for varying conditions, which enhances zonation.\n\nSome plants and animals found in altitudinal zones tend to become isolated since the conditions above and below a particular zone will be inhospitable and thus constrain their movements or dispersal. These isolated ecological systems are known as sky islands.\n\nAltitudinal zones tend to follow a typical pattern. At the highest elevations, trees cannot grow, and whatever life may be present will be of the alpine type, resembling tundra. Just below the tree line, one may find subalpine forests of needleleaf trees, which can withstand cold, dry conditions. Below that, montane forests grow. In the temperate portions of the earth, those forests tend to be needleleaf trees, while in the tropics, they can be broadleaf trees growing in a rain forest.\n\nThe highest known permanently tolerable altitude is at . At very high altitudes, the decreasing atmospheric pressure means that less oxygen is available for breathing, and there is less protection against solar radiation (UV). Above elevation, there is not enough oxygen to support human life. This is known as the \"death zone\". The summits of Mount Everest and K2 are in the death zone.\n\nMountains are generally less preferable for human habitation than lowlands, because of harsh weather and little level ground suitable for agriculture. While 7% of the land area of Earth is above , only 140 million people live above that altitude and only 20-30 million people above elevation. About half of mountain dwellers live in the Andes, Central Asia, and Africa.\n\nWith limited access to infrastructure, only a handful of human communities exist above of elevation. Many are small and have heavily specialized economies, often relying on industries such as agriculture, mining, and tourism. An example of such a specialized town is La Rinconada, Peru, a gold-mining town and the highest elevation human habitation at . A counterexample is El Alto, Bolivia, at , which has a highly diverse service and manufacturing economy and a population of nearly 1 million.\n\nTraditional mountain societies rely on agriculture, with higher risk of crop failure than at lower elevations. Minerals often occur in mountains, with mining being an important component of the economics of some montane societies. More recently, tourism supports mountain communities, with some intensive development around attractions such as national parks or ski resorts. About 80% of mountain people live below the poverty line.\n\nMost of the world's rivers are fed from mountain sources, with snow acting as a storage mechanism for downstream users. More than half of humanity depends on mountains for water.\n\nIn geopolitics mountains are often seen as preferable \"natural boundaries\" between polities.\n\nMountaineering, mountain climbing, or alpinism is the sport, hobby or profession of hiking, skiing, and climbing mountains. While mountaineering began as attempts to reach the highest point of unclimbed big mountains it has branched into specializations that address different aspects of the mountain and consists of three areas: rock-craft, snow-craft and skiing, depending on whether the route chosen is over rock, snow or ice. All require experience, athletic ability, and technical knowledge to maintain safety.\n\nHeights of mountains are typically measured above sea level. Using this metric, Mount Everest is the highest mountain on Earth, at . There are at least 100 mountains with heights of over above sea level, all of which are located in central and southern Asia. The highest mountains above sea level are generally not the highest above the surrounding terrain. There is no precise definition of surrounding base, but Denali, Mount Kilimanjaro and Nanga Parbat are possible candidates for the tallest mountain on land by this measure. The bases of mountain islands are below sea level, and given this consideration Mauna Kea ( above sea level) is the world's tallest mountain and volcano, rising about from the Pacific Ocean floor.\n\nThe highest mountains are not generally the most voluminous. Mauna Loa () is the largest mountain on Earth in terms of base area (about ) and volume (about ). Mount Kilimanjaro is the largest non-shield volcano in terms of both base area () and volume (). Mount Logan is the largest non-volcanic mountain in base area ().\n\nThe highest mountains above sea level are also not those with peaks farthest from the centre of the Earth, because the figure of the Earth is not spherical. Sea level closer to the equator is several miles farther from the centre of the Earth. The summit of Chimborazo, Ecuador's tallest mountain, is usually considered to be the farthest point from the Earth's centre, although the southern summit of Peru's tallest mountain, Huascarán, is another contender. Both have elevations above sea level more than less than that of Everest.\n\n\n\n"}
{"id": "4229819", "url": "https://en.wikipedia.org/wiki?curid=4229819", "title": "Navigation system", "text": "Navigation system\n\nA navigation system is a (usually electronic) system that aids in navigation. Navigation systems may be entirely on board a vehicle or vessel (on the ships) bridge, or they may be located elsewhere and communicate via radio or other signals with a vehicle or vessel, or they may use a combination of these methods.\n\nNavigation systems may be capable of:\n\n\n\n"}
{"id": "5393695", "url": "https://en.wikipedia.org/wiki?curid=5393695", "title": "Pan American Institute of Geography and History", "text": "Pan American Institute of Geography and History\n\nThe Pan American Institute of Geography and History is an international organisation dedicated to the generation and transference of knowledge specialized in the fields of cartography, geography, history and geophysics.\n\nThe institute was created on February 7, 1928, during a conference held in Havana. The city that was established to be the host was Mexico City. The Institute signed an agreement with the Organization of American States and became a specialized organization of the OAS. In 1974 this agreement was modified and signed.\n\nIt publishes the following academic journals:\n\n"}
{"id": "491787", "url": "https://en.wikipedia.org/wiki?curid=491787", "title": "Position fixing", "text": "Position fixing\n\nPosition fixing is the branch of navigation concerned with the use of a variety of visual and electronic methods to determine the position of a vehicle or person on the surface of the Earth.\n\nThese techniques include:\n\n\nPositions may be expressed as a bearing and range from a known landmark or as an angles of latitude and longitude relative to a map datum.\n\nGenerally speaking a position fix is calculated by taking into account measurements (referred to as observations) of distances or angles to reference points whose positions are known. In 2D surveys observations of three reference points are enough to compute a position in a two dimensional plane. In practice observations are subject to errors resulting from various physical and atmospheric factors that influence the measurement of distances and angles.\n\nA practical example of obtaining a position fix would be for a ship to take bearing measurements on three lighthouses positioned along the coast. These measurements could be made visually using a hand bearing compass, or in poor visibility electronically using radar or radio direction finding. Since all physical observations are subject to errors the resulting position fix is also subject to error. Although in theory two lines of position (LOP) are enough to define a point, in practice 'crossing' more LOPs provides greater accuracy and confidence, especially if the lines cross at a good angle to each other. Three LOPs are considered the minimum for a practical navigational fix. The three LOPs when drawn on the chart will in general form a triangle, known as a 'cocked hat'. The navigator will have more confidence in a position fix that is formed by a small cocked hat with angles close to those of an equilateral triangle. \n\nIt is not true to say that the navigator's true position is 'definitely' within the cocked hat on the chart. The area of doubt surrounding a position fix is called an error ellipse. To minimize the error, electronic navigation systems generally use more than three reference points to compute a position fix to increase the data redundancy. As more redundant reference points are added the position fix becomes more accurate and the area of the resulting error ellipse decreases.\n\nThe process of combining multiple observations to compute a position fix is equivalent to solving a system of linear equations. Navigation systems use regression algorithms such as Least squares in order to compute a position fix in 3D space. This is most commonly done by combining distance measurements to 4 or more GPS satellites, which orbit the earth along paths of predetermined position.\n\n"}
{"id": "32110355", "url": "https://en.wikipedia.org/wiki?curid=32110355", "title": "Precise Point Positioning", "text": "Precise Point Positioning\n\nPrecise Point Positioning (PPP) is a Global Navigation Satellite System (GNSS) positioning method to calculate very precise positions up to few centimeter level using a single (GNSS) receiver in a dynamic and global reference framework like International Terrestrial Reference System (ITRS). PPP methods are different from (DGNSS) positioning methods which differentiate errors using one or more reference stations with known positions. The PPP approach combines precise clocks and orbits, so-called precise ephemeris, calculated from a global network to calculate a precise position with a single receiver, which can be double or single frequency.\n\nHistorically precise positioning was associated with surveying and geodesy. It makes use of carrier-phase observables, allowing positioning precisions of a fraction of a carrier wavelength, 19 or 24 cm. It also makes use of precise ephemeris, generated by the geodetic community -- the IGS, International GNSS Service -- from measurements by a global network of tracking stations. Recently, the dissemination over the Internet in low-latency real time -- e.g., APPS, the Automatic Precise Positioning Service of NASA JPL -- has made possible to do such precise positioning also in real time, giving us the PPP technique. \n\nWith the advent of Global Navigation Satellite Systems (GNSS) such as the Global Positioning System (GPS), precise positioning has been incorporated into production processes in mining, agriculture and construction. The main application has been in machine guidance and machine automation which require high levels of precision.\n\nPrecise positioning is also increasingly used in the fields of robotics and autonomous navigation.\n\n"}
{"id": "17660060", "url": "https://en.wikipedia.org/wiki?curid=17660060", "title": "RINEX", "text": "RINEX\n\nIn the field of geodesy, Receiver Independent Exchange Format (RINEX) is a data interchange format for raw satellite navigation system data. This allows the user to post-process the received data to produce a more accurate result — usually with other data unknown to the original receiver, such as better models of the atmospheric conditions at time of measurement.\n\nThe final output of a navigation receiver is usually its position, speed or other related physical quantities. However, the calculation of these quantities are based on a series of measurements from one or more satellite constellations. Although receivers calculate positions in real time, in many cases it is interesting to store intermediate measures for later use. RINEX is the standard format that allows the management and disposal of the measures generated by a receiver, as well as their off-line processing by a multitude of applications, whatever the manufacturer of both the receiver and the computer application.\n\nThe RINEX format is designed to evolve over time, adapting to new types of measurements and new satellite navigation systems. The first RINEX version was published by W. Gurtner and G. Mader in the CSTG GPS Bulletin of September/October 1990. Since 1993 the RINEX 2 is available, which has been revised and adopted several times. RINEX enables storage of measurements of pseudorange, carrier-phase, Doppler and signal-to-noise from GPS (including GPS modernization signals e.g. L5 and L2C), GLONASS, Galileo, Beidou, along with data from EGNOS and WAAS satellite based augmentation systems (SBAS), QZSS, simultaneously. RINEX version 3.02 was submitted in April 2013 and is capable of new measurements from GPS or Galileo systems. The most recent version is RINEX 3.03 from July 2015 with update 1 to 3.03 published in 2017.\n\nAlthough not part of the RINEX format, the \"Hatanaka compression scheme \" is commonly used to reduced the size of RINEX files, resulting in an ASCII-based CompactRINEX format.. It uses higher-order time differences to reduce the number of characters needed to store time data.\n\n"}
{"id": "621182", "url": "https://en.wikipedia.org/wiki?curid=621182", "title": "Reference ellipsoid", "text": "Reference ellipsoid\n\nIn geodesy, a reference ellipsoid is a mathematically defined surface that approximates the geoid, the truer figure of the Earth, or other planetary body.\nBecause of their relative simplicity, reference ellipsoids are used as a preferred surface on which geodetic network computations are performed and point coordinates such as latitude, longitude, and elevation are defined.\n\nIn the context of standardization and geographic applications, a \"geodesic reference ellipsoid\" is the mathematical model used as foundation by Spatial reference system or Geodetic datum definitions.\n\nIn 1687 Isaac Newton published the Principia in which he included a proof that a rotating self-gravitating fluid body in equilibrium takes the form of an oblate ellipsoid of revolution which he termed an oblate spheroid. Current practice uses the word 'ellipsoid' alone in preference to the full term 'oblate ellipsoid of revolution' or the older term 'oblate spheroid'. In the rare instances (some asteroids and planets) where a more general ellipsoid shape is required as a model the term used is triaxial (or scalene) ellipsoid. A great many ellipsoids have been used with various sizes and centres but modern (post-GPS) ellipsoids are centred at the actual center of mass of the Earth or body being modeled.\n\nThe shape of an (oblate) ellipsoid (of revolution) is determined by the shape parameters of that ellipse which generates the ellipsoid when it is rotated about its minor axis. The semi-major axis of the ellipse, \"a\", is identified as the equatorial radius of the ellipsoid: the semi-minor axis of the ellipse, \"b\", is identified with the polar distances (from the centre). These two lengths completely specify the shape of the ellipsoid but in practice geodesy publications classify reference ellipsoids by giving the semi-major axis and the \"inverse \"flattening, , The flattening, \"f\", is simply a measure of how much the symmetry axis is compressed relative to the equatorial radius: \nFor the Earth, \"f\" is around corresponding to a difference of the major and minor semi-axes of approximately . Some precise values are given in the table below and also in Figure of the Earth. For comparison, Earth's Moon is even less elliptical, with a flattening of less than , while Jupiter is visibly oblate at about and one of Saturn's triaxial moons, Telesto, is nearly to .\n\nA great many other parameters are used in geodesy but they can all be related to one or two of the set \"a\", \"b\" and \"f\". They are listed in ellipse.\n\nA primary use of reference ellipsoids is to serve as a basis for a coordinate system of latitude (north/south), longitude (east/west), and elevation (height).\nFor this purpose it is necessary to identify a \"zero meridian\", which for Earth is usually the Prime Meridian. For other bodies a fixed surface feature is usually referenced, which for Mars is the meridian passing through the crater Airy-0. It is possible for many different coordinate systems to be defined upon the same reference ellipsoid.\n\nThe longitude measures the rotational angle between the zero meridian and the measured point. By convention for the Earth, Moon, and Sun it is expressed in degrees ranging from −180° to +180° For other bodies a range of 0° to 360° is used.\n\nThe latitude measures how close to the poles or equator a point is along a meridian, and is represented as an angle from −90° to +90°, where 0° is the equator. The common or \"geodetic latitude\" is the angle between the equatorial plane and a line that is normal to the reference ellipsoid. Depending on the flattening, it may be slightly different from the \"geocentric (geographic) latitude\", which is the angle between the equatorial plane and a line from the center of the ellipsoid. For non-Earth bodies the terms \"planetographic\" and \"planetocentric\" are used instead.\n\nThe coordinates of a geodetic point are customarily stated as geodetic latitude and longitude, i.e., the direction in space of the geodetic normal containing the point, and the height \"h\" of the point over the reference ellipsoid. See geodetic system for more detail. If these coordinates, i.e., latitude \"ϕ\", longitude \"λ\" and height \"h\", are given, one can compute the \"geocentric rectangular coordinates\" of the point as follows:\n\nwhere\nand \"a\" and \"b\" are the equatorial radius (semi-major axis) and the polar radius (semi-minor axis), respectively. \"N\" is the \"radius of curvature in the prime vertical\".\n\nIn contrast, extracting \"φ\", \"λ\" and \"h\" from the rectangular coordinates usually requires iteration. A straightforward method is given in an OSGB publication and also in web notes. More sophisticated methods are outlined in geodetic system.\n\nCurrently the most common reference ellipsoid used, and that used in the context of the Global Positioning System, is the one defined by WGS 84.\n\nTraditional reference ellipsoids or \"geodetic datums\" are defined regionally and therefore non-geocentric, e.g., ED50. Modern geodetic datums are established with\nthe aid of GPS and will therefore be geocentric, e.g., WGS 84.\n\nReference ellipsoids are also useful for geodetic mapping of other planetary bodies including planets, their satellites, asteroids and comet nuclei. Some well observed bodies such as the Moon and Mars now have quite precise reference ellipsoids.\n\nFor rigid-surface nearly-spherical bodies, which includes all the rocky planets and many moons, ellipsoids are defined in terms of the axis of rotation and the mean surface height excluding any atmosphere. Mars is actually egg shaped, where its north and south polar radii differ by approximately , however this difference is small enough that the average polar radius is used to define its ellipsoid. The Earth's Moon is effectively spherical, having almost no bulge at its equator. Where possible, a fixed observable surface feature is used when defining a reference meridian.\n\nFor gaseous planets like Jupiter, an effective surface for an ellipsoid is chosen as the equal-pressure boundary of one bar. Since they have no permanent observable features, the choices of prime meridians are made according to mathematical rules.\n\nSmall moons, asteroids, and comet nuclei frequently have irregular shapes. For some of these, such as Jupiter's Io, a scalene (triaxial) ellipsoid is a better fit than the oblate spheroid. For highly irregular bodies, the concept of a reference ellipsoid may have no useful value, so sometimes a spherical reference is used instead and points identified by planetocentric latitude and longitude. Even that can be problematic for non-convex bodies, such as Eros, in that latitude and longitude don't always uniquely identify a single surface location.\n\n\n\n"}
{"id": "32655756", "url": "https://en.wikipedia.org/wiki?curid=32655756", "title": "Running survey", "text": "Running survey\n\nA running survey is a rough survey made by a vessel while coasting. Bearings to landmarks are taken at intervals as the vessel sails offshore, and are used to fix features on the coast and further inland. Intervening coastal detail is sketched in. \n\nThe method was used by James Cook, and subsequently by navigators who sailed under—or were influenced by—him, including George Vancouver, William Bligh and Matthew Flinders.\n"}
{"id": "3472330", "url": "https://en.wikipedia.org/wiki?curid=3472330", "title": "Sun sensor", "text": "Sun sensor\n\nA sun sensor is a navigational instrument used by spacecraft to detect the position of the sun. Sun sensors are used for attitude control, solar array pointing, gyro updating, and fail-safe recovery.\n\nIn addition to spacecraft, sun sensors find use in ground-based weather stations and sun-tracking systems, and aerial vehicles including balloons and UAVs.\n\nThere are various types of sun sensors, which differ in their technology and performance characteristics. Sun presence sensors provide a binary output, indicating when the sun is within the sensor's field of view. Analog and digital sun sensors, in contrast, indicate the angle of the sun by continuous and discrete signal outputs, respectively.\n\nIn typical sun sensors, a thin slit at the top of a rectangular chamber allows a line of light to fall on an array of photodetector cells at the bottom of the chamber. A voltage is induced in these cells, which is registered electronically. By orienting two sensors perpendicular to each other, the direction of the sun can be fully determined.\n\nOften, multiple sensors will share processing electronics.\n\nThere are a number of design and performance criteria which dictate the selection of a sun sensor model:\n\n"}
{"id": "41624490", "url": "https://en.wikipedia.org/wiki?curid=41624490", "title": "Surveying in early America", "text": "Surveying in early America\n\nThe history of surveying in early America included the mapping of large, unknown territories and the layout of the District of Columbia. Several presidents were involved, including George Washington.\n\nGeorge Washington was not only a founding political father of the U.S., he was a founding surveyor of Virginia, as well. At the age of eleven, he inherited Ferry Farm. When George reached school age, instead of a career in the Royal Navy, George went to school to study surveying and geometry. His first surveying tools were from his own storehouse on Ferry Farm. At the age of 17, under the tutelage of Joshua Fry, he surveyed the northern neck of Virginia and became the county surveyor for Culpeper County, Virginia. By the time of the French and Indian War, he had laid out most of northern Virginia, and this knowledge would contribute to his success during the war.\n\nFrom 1747 to 1799, he surveyed 200 tracts of land, and due to his also being a land speculator, he amassed of land.\n\nDuring the Revolutionary War, he appointed the first geographer of the Continental Army, Robert Erskine.\n\nSurveying was not only for the wealthy plantation owners, but the entire new nation needed to be surveyed, and resurveyed. Most of all, the proposed new capital city, bearing Washington’s name, needed to be surveyed. A two-man team would survey what became the District of Columbia in 1791. The first was Benjamin Banneker, a free ex-slave, who learned to read, write, and do math from his grandmother. Banneker would go on to be a leading astronomer, mathematician, clock maker, and most of all, a surveyor. The second man was Andrew Ellicott. He would go on to do several prominent surveys of the area and assist Lewis and Clark in planning their expedition.\n\nPrior to independence, Peter Jefferson, along with his son Thomas Jefferson, were land surveyors for the crown. At this time, surveyors used a system known as the metes and bounds system, which used \"monuments\"; identifiable objects such as rocks, trees etc., as property markers. The surveyor would measure from monument to monument. The major problem with this system was the fact that these monuments were not necessarily permanent. As a result, Thomas Jefferson was involved in the creation the Public Land Survey System. A comparison of county boundaries in the various states graphically displays the difference between the systems, as counties in the Eastern states are irregularly shaped whereas counties in the Midwest tend to be square or rectangular.\n\nNeeding money to pay the debts for the Revolutionary War, Jefferson began selling land in the Northwest Territory in plots of for $2.50 an acre. Soon after, he sold the land in plots of for 1.25 an acre. The NW Territory was surveyed using the Rectangular System. This system used a central point determined by a Principal North-South Meridian Line and an East-West Base line.\n\nJefferson convinced Congress to accept the land deal with Napoleon. As a result of the Louisiana Purchase and Jefferson’s love for nature, Jefferson organized the Lewis and Clark expedition. Andrew Ellicott taught Lewis and Clark how to use a sextant to map their position. Lewis and Clark would leave from Wood River, Illinois and document the wilderness all the way to the Pacific Ocean.\n\nAbraham Lincoln came to New Salem in 1831, and shortly after in 1832, he lost in his bid to become a state representative. The Sangamon County Surveyor, John Calhoun, then offered Lincoln a job as Deputy Surveyor due to the high volume of resurveying.\n\nAs Deputy Surveyor, Lincoln surveyed five towns, four roads, and thirty properties. The first was the plat for Huron, a proposed town North of Springfield that never came to be. The proposal was that county would build a canal to straighten the Sangamon River, but the canal was never built. The last town Lincoln laid out was New Boston, a town at the confluence of the Iowa River and the Mississippi River. Instead of payment for his work, Lincoln had his surveying equipment repossessed and sold. Unknown to Lincoln, Jimmy Short, a friend, bought all of his equipment, his horse, and his saddlebags. Short returned Lincoln’s surveying equipment and later, as president, Lincoln returned the favor by making Short the Indian Agent of the Round Lake Indian Reservation.\n"}
{"id": "5651308", "url": "https://en.wikipedia.org/wiki?curid=5651308", "title": "Time to first fix", "text": "Time to first fix\n\nTime To First Fix (TTFF) is a measure of the time required for a GPS receiver to acquire satellite signals and navigation data, and calculate a position solution (called a fix).\nThe TTFF is commonly broken down into three more specific scenarios, as defined in the GPS equipment guide:\n\n\nMany receivers can use as many as twelve channels simultaneously, allowing quicker fixes. Many cell phones reduce the time to first fix by using assisted GPS (A-GPS): they acquire almanac and ephemeris data over a fast network connection from the cell phone operator rather than over the slow radio connection from the satellites.\n\n\n"}
{"id": "7951280", "url": "https://en.wikipedia.org/wiki?curid=7951280", "title": "Tourist landscape", "text": "Tourist landscape\n\nA tourist landscape can be described as constructed through a large number of symbolic and material transformations of an original physical and/or socioeconomic landscape in order to serve the interests of tourists and the tourist industry.\n\nSince the early days of tourism, landscape has played an important role in the decision making for holiday destinations. In trying to escape from an ordinary taken-for-granted-world, people of all periods have looked to far-away landscapes in order to re-create.\n\nLandscapes are no longer exclusively shaped by the productive claims of agricultural interests. Their forms are increasingly frequently a reflection of the consumer demand and recreation, tourism and even nature conservation combine to model the ‘new aesthetics of nature’ (Wilson, 1992). The media shows people ever more varied images of their surroundings. Commercial broadcast by the World Wide Fund for Nature, vacation folders displayed by the tour operators and tourist boards, and the travel reports published in magazines determine to a large degree how the ideal tourist landscape appearance. The most influential parties come from the new middle class, consisting of individuals and groups who are concentrated in professions like the media and fashion, education, and the arts and sciences. In this context the tourism industry constructs the rural idyll, an understanding of the countryside based partly on reality, but largely on nostalgia and romance:\n\nHowever, by this aesthetic appropriation the landscape has become an assemblage of beautiful forms that ignores the basically vital aspects.\n\nA related problem is that tourism landscapes are frequently subject to the characteristic problems of common pool resources - a tendency toward overuse and a lack of incentive for individuals to invest in maintaining or improving the resource (Healy, 1994). Scenic landscapes are often the result of active (traditional) land management. The fading away of the pastoral economy in Alpine regions or the traditional orchard economy in parts of the Mediterranean threatens the characteristic scenery of old cultural landscapes.\n\nTo the peoples of Northern Europe the Mediterranean landscape represented an ideal that has to be admired, sketched, painted and visited. From the beginning of the nineteenth century on the Mediterranean landscape functioned as a promotional objective of the nascent tourist industry. The presence of celebrities and highly effective publicity campaigns in combination with the work of many artists turned the regional geographical landscape into a tourist landscape, a dream space for the twentieth century.\nLuginbühl (1992) suggests that tourist publicity posters that appeared toward the end of the nineteenth century were used to represent the Mediterranean landscape and to reinforce the selective view of that landscape held by an elite stratum of society.\nCharacteristic of these posters is the emphasis on the ‘exotic’ in the Mediterranean landscape. Plant life especially is used to symbolise the ideal tourist scenery whilst constructing a landscape that retreats from reality:\n\nAnother example of impressive transformations is the pilgrim’s way to Santiago de Compostela, one of the most famous long distance routes in Europe. The different itineraries formed a kind of religious network in the past. Now the EC has discovered the importance of this route and has themed it as the cultural route of Europe. Subsidised by EC funds a considerable part of the authentic pilgrim’s way in the Tiere de Campos in Northwestern Spain has been completely transformed into a comfortable tracking road. Trees have been planted on every ten meters, supplied with water by a smart irrigation system. After every kilometer the tired modern pilgrim can take some rest. Nobody has to be afraid in getting lost in this area because even the smallest village is signposted by an impressive stone. So the suffering of the former pilgrims has become unreachable for the modern ones. They are degraded to ordinary tourists. And the landscape? It is rationalised and it seems to be a question of time before the first multinational company establishes a chain of fast-food outlets along the route.\n\nIn the Netherlands the ideal of an ‘exotic holiday-destination’ is without any doubt strongly influenced by the image of the Mediterranean landscape. It is incorporated in the designing of holiday villages and the enormous increase of these facilities in the last decades has transformed parts of the Netherlands into real leisure landscapes. The encroachment of brick and concrete over the landscape is visible in favourable tourist regions such as the coastal zones and the Veluwe region. The high quality holiday villages sell a subtropical illusion in a country with a temperate maritime climate. The Mediterranean concept became predominant in the design, the range of services and the names of resorts such as Porte Zelande or Porte Grève in the province of Zeeland. The inspiration for the design of Porte Zelande on the Brouwersdam was drawn from Port Grimaud in southern France. \nPort Grimaud can be considered as one of the most well-known examples of a radical landscape transformation. In 1962, the architect Spoerry acquired a stretch of marshy land near Saint Tropez. He transformed this area to the ultimate example of future leisure ports.\n\nBeach parks and résidences have become popular and change the landscape dramatically in certain regions. Another example can be find along the Languedoc-Roussillon coast in southern France in the huge leisure based urbanisation around Port Leucate.\n\nIn order to differentiate themselves to win the favour of clients, resorts ponder to the attractive environment in the form of landscape and culture. In addition to some holyday villages, golf links are also making inroads on the countryside. The holiday villages developed most recently tend to be in the immediate vicinity of nature preserves or the sea coast. The use that people make of the surroundings of a holiday village is becoming more and more intensive, changing the appearance of the landscape into a tourist landscape.\n\n"}
{"id": "29030725", "url": "https://en.wikipedia.org/wiki?curid=29030725", "title": "Transverse Mercator: Redfearn series", "text": "Transverse Mercator: Redfearn series\n\nThe article Transverse Mercator projection restricts itself to general features of the projection. This article describes in detail one of the (two) implementations developed by Louis Krüger in 1912; that expressed as a power series in the longitude difference from the central meridian. These series were recalculated by Lee in 1946, by Redfearn in 1948, and by Thomas in 1952. They are often referred to as the Redfearn series, or the Thomas series. This implementation is of great importance since it is widely used in the U.S. State Plane Coordinate System, in national (Britain, Ireland and many others) and also international mapping systems, including the Universal Transverse Mercator coordinate system (UTM). They are also incorporated into the Geotrans coordinate converter made available by the United States National Geospatial-Intelligence Agency. When paired with a suitable geodetic datum, the series deliver high accuracy in zones less than a few degrees in east-west extent.\n\nThe series must be used with a geodetic datum which specifies the position, orientation and shape of a Reference ellipsoid. Although the projection formulae depend only on the shape parameters of the reference ellipsoid the full set of datum parameters is necessary to link the projection coordinates to true positions in three-dimensional space. The datums and reference ellipsoids associated with particular implementations of the Redfearn formulae are listed below. A comprehensive list of important ellipsoids is given in the article on the Figure of the Earth.\n\nIn specifying ellipsoids it is normal to give the semi-major axis (equatorial axis), formula_1, along with either the inverse flattening, formula_2, or the semi-minor axis (polar axis), formula_3, or sometimes both. The series presented below use the eccentricity, formula_4, in preference to the flattening, formula_5. In addition they use the parameters formula_6, called the third flattening, and formula_7, the second eccentricity. There are only two independent shape parameters and there are many relations between them: in particular\nThe projection formulae also involve formula_9, the radius of curvature of the meridian (at latitude formula_10), and formula_11, the radius of curvature in the prime vertical.\n(The prime vertical is the vertical plane orthogonal to the meridian plane at a point on the ellipsoid). The radii of curvature are defined as follows:\nIn addition the functions formula_13 and formula_14 are defined as:\nFor compactness it is normal to introduce the following abbreviations:\n\nThe article on Meridian arc describes several methods of computing formula_17, the meridian distance from the equator to a point at latitude formula_10 : the expressions given below are those used in the \"'actual\" implementation of the Transverse Mercator projection by the OSGB. The truncation error is less than 0.1mm so the series is certainly accurate to within 1mm, the design tolerance of the OSGB implementation.\nwhere the coefficients are given to order formula_20 (order formula_21) by\nThe meridian distance from equator to pole is \nThe form of the series specified for UTM is a variant of the above exhibiting higher order terms with a truncation error of 0.03mm.\n\nNeither the OSGB nor the UTM implementations define an inverse series for the meridian distance; instead they use an iterative scheme. For a given meridian distance formula_24 first set formula_25 and then iterate using\nuntil formula_27mm.\n\nThe inversion \"can\" be effected by a series, presented here for later reference. For a given meridian distance, formula_24, define the rectifying latitude by\nThe geodetic latitude corresponding to formula_24 is (Snyder page 17):\nwhere, to formula_32,\n\nThe normal aspect of the Mercator projection of a sphere of radius formula_34 is described by the equations\nwhere formula_36, the isometric latitude, is given by\nOn the ellipsoid the isometric latitude becomes\nBy construction, the projection from the geodetic coordinates (formula_10,formula_40) to the coordinates (formula_36,formula_40) is conformal. If the coordinates (formula_36,formula_40) are used to define a point formula_45 in the complex plane, then any analytic function formula_46 will define another conformal projection. Kruger's method involves seeking the specific formula_46 which generates a uniform scale along the central meridian, formula_48. He achieved this by investigating a Taylor series approximation with the projection coordinates given by:\nwhere the real part of formula_50 must be proportional to the meridian distance function formula_17. The (complex) coefficients formula_52 depend on derivatives of formula_46 which can be reduced to derivatives of formula_17 with respect to formula_36, (not formula_10). The derivatives are straightforward to evaluate in principle but the expressions become very involved at high orders because of the complicated relation between formula_36 and formula_10. Separation of real and imaginary parts gives the series for formula_59 and formula_60 and further derivatives give the scale and convergence factors.\n\nThis section presents the eighth order series as published by Redfearn (but with formula_59 and formula_60 interchanged and the longitude difference from the central meridian denoted by formula_40 instead of formula_64). Equivalent eighth order series, with different notations, can be found in Snyder (pages 60–64) and at many web sites such as that for the Ordnance Survey of Great Britain.\n\nThe direct series are developed in terms of the longitude difference from the central meridian, expressed in radians: the inverse series are developed in terms of the ratio formula_65. The projection is normally restricted to narrow zones (in longitude) so that both of the expansion parameters are typically less than about 0.1, guaranteeing rapid convergence. For example in each UTM zone these expansion parameters are less than 0.053 and for the British national grid (NGGB) they are less than 0.09. All of the direct series giving formula_59, formula_60, scale formula_68, convergence formula_69 are functions of both latitude and longitude and the parameters of the ellipsoid: all inverse series giving formula_10, formula_40, formula_68, formula_69 are functions of both formula_59 and formula_60 and the parameters of the ellipsoid.\n\nIn the following series formula_40 is the \"difference\" of the longitude of an arbitrary point and the longitude of the chosen central meridian: formula_40 is in radians and is positive east of the central meridian. The W coefficients are functions of formula_10 listed below. The series for formula_60 reduces to the scaled meridian distance when formula_48.\n\nThe inverse series involve a further construct: the footpoint latitude. Given a point formula_82 on the projection the footpoint is defined as the point on the central meridian with coordinates formula_83. Since the scale on the central meridian is formula_84 the meridian distance from the equator to the footpoint is equal to formula_85. The corresponding footpoint latitude, formula_86, is calculated by iteration or the inverse meridian distance series as described above.\nDenoting functions evaluated at formula_86 by a subscript '1', the inverse series are:\n\nThe point scale formula_68 is independent of direction for a conformal transformation. It may be calculated in terms of geographic or projection coordinates. Note that the series for formula_68 reduce to formula_84 when either formula_48 or formula_94 . The convergence formula_69 may also be calculated (in radians) in terms of geographic or projection coordinates:\n\nThe exact solution of Lee-Thompson, implemented by Karney (2011), is of great value in assessing the accuracy of the truncated Redfearn series. It confirms that the truncation error of the (eighth order) Redfearn series is less than 1 mm out to a longitude difference of 3 degrees, corresponding to a distance of 334 km from the central meridian at the equator but a mere 35 km at the northern limit of an UTM zone.\n\nThe Redfearn series become much worse as the zone widens. Karney discusses Greenland as an instructive example. The long thin landmass is centred on 42W and, at its broadest point, is no more than 750 km from that meridian whilst the span in longitude reaches almost 50 degrees. The Redfearn series attain a maximum error of 1 kilometre.\n\nThe implementations give below are examples of the use of the Redfearn series. The defining documents in various countries differ slightly in notation and, more importantly, in the neglect of some of the small terms. The analysis of small terms depends on the latitude and longitude ranges in the various grids. There are also slight differences in the formulae utilised for meridian distance: one extra term is sometimes added to the formula specified above but such a term is less than 0.1mm.\n\nThe implementation of the transverse Mercator projection in Great Britain is fully described in the OSGB document A guide to coordinate systems in Great Britain, Appendices A.1, A.2 and C.\nThe extent of the grid is 300 km to the east and 400 km to the west of the central meridian and 1300 km north from the \"false\" origin, (OSGB Section 7.1), but with the exclusion of parts of Northern Ireland, Eire and France. A grid reference is denoted by the pair (E,N) where E ranges from slightly over zero to 800000m and N ranges from zero to 1300000m. To reduce the number of figures needed to give a grid reference, the grid is divided into 100 km squares, which each have a two-letter code. National Grid positions can be given with this code followed by an easting and a northing both in the range 0 and 99999m. \n\nThe projection formulae differ slightly from the Redfearn formulae presented here. They have been simplified by neglect of most terms of seventh and eighth order in formula_40 or formula_65: the only exception is seventh order term in the series for formula_40 in terms of formula_65. This simplification is based on the examination of the Redfearn terms over the \"actual\" extent of the grid. The only other differences are (a) the absorption of the central scale factor into the radii of curvature and meridian distance, (b) the replacement of the parameter formula_102 by the parameter formula_103 (defined ).\n\nThe OSGB manual includes a discussion of the Helmert transformations which are required to link geodetic coordinates on Airy 1830 ellipsoid and on WGS84.\n\nThe article on the Universal Transverse Mercator projection gives a general survey, but the full specification is defined in U.S. Defense Mapping Agency Technical Manuals TM8358.1 and TM8358.2. This section provides details for zone 30 as another example of the Redfearn formulae (usually termed Thomas formulae in the United States.)\nThe series adopted for the meridian distance incorporates terms of fifth order in formula_6 but the manual states that these are less than 0.03 mm (TM8358.2 Chapter 2). The projection formulae use, formula_7, the second eccentrity (defined ) instead of formula_6. The grid reference schemes are defined in the article Universal Transverse Mercator coordinate system. The accuracy claimed for the UTM projections is 10 cm in grid coordinates and 0.001 arc seconds for geodetic coordinates.\n\nThe transverse Mercator projection in Eire and Northern Ireland (an international implementation spanning one country and part of another) is currently implemented in two ways:\n\nIrish grid reference system\nThe Irish grid uses the OSGB projection formulae.\n\nIrish Transverse Mercator\nThis is an interesting example of the transition between use of a traditional ellipsoid and a modern global ellipsoid. The adoption of radically different false origins helps to prevent confusion between the two systems.\n\n"}
{"id": "3786565", "url": "https://en.wikipedia.org/wiki?curid=3786565", "title": "Water level (device)", "text": "Water level (device)\n\nA water level; \"[Alfadolasticho]\" is a device used for matching elevations of locations that are too far apart for a spirit level to span. The simplest water level is a section of clear tubing, partially filled with water. Water is easily procured for use, and easily discarded after use. The ends are held vertical, and the rest of the tubing lies on the ground or floor. The water level at each end of the tube will be at the same elevation, whether the two ends are adjacent or far apart. Water levels have been used for many years. The water level is lower-tech than the laser level, but it can be more accurate over long distances, and works without a sightline, such as around corners. To avoid error, all of the water should be at the same temperature. Other sources of error include difficulty reading due to meniscus.\n\nIf the water level is used often, dye can be added to the water to make it easier to see. If the water level is used outdoors in winter, antifreeze can be added to the water. Automotive window washer fluid can also be used for antifreeze and increased visibility. Additionally it inhibits the formation of error causing bubbles. A surfactant (surface active agent), such as hand-dishwashing liquid detergent, can be added to the water to significantly lower the surface tension of the water. This liquid solution will flow more easily and more rapidly in the tube than plain water, so operation of the device will be more precise, repeatable, and responsive – particularly when using a small-diameter tube. Also, this liquid solution can be emptied from a small-diameter tube more easily than plain water.\n\n"}
