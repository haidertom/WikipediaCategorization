{"id": "18622896", "url": "https://en.wikipedia.org/wiki?curid=18622896", "title": "Africa Specialty Group", "text": "Africa Specialty Group\n\nThe Africa Specialty Group is one of many specialty groups within the Association of American Geographers. The group is composed of academic geographers with research interests in Africa. This group publishes the African Geographical Review, a peer-reviewed academic journal.\n\n"}
{"id": "9470391", "url": "https://en.wikipedia.org/wiki?curid=9470391", "title": "Alberta Township System", "text": "Alberta Township System\n\nThe Alberta Township System (ATS) is a land surveying system used in the Canadian province of Alberta and other parts of western Canada.\n\nIn principle there is a mathematical basis for the Alberta Township System (ATS) variant of the Dominion Land Survey (DLS) system as implemented in Canada. The implementation in western Canada reflects a number of slightly different approaches, as well as a large number of errors.\n\nLong before the Dominion Land Surveyor (DLS) first came into official existence in 1872, licensed surveyors known as Provincial Land Surveyors had been functioning in the Provinces of Ontario and Quebec (then called Canada West and Canada East) under an Act of 1849. Establishing a system of examination for new aspirants to the title of \"Dominion Land Surveyor\" was officially adopted in 1874. In 1910 The Alberta Surveyors Act prescribed the system and the methods whereby land surveys were to be carried out under the general purview of a provincial Director of Surveys whose responsibility it was to see that all survey work was performed in accordance with the provisions of that Act.\n\nThe system is also used by provincial governments when selling exploration rights, and oil and gas wells are referenced by their location as defined within the Alberta Township System.\n\nBelow is a brief description of how to lay out the DLS grid for Alberta.\n\nLay off ticks from the 49th parallel of latitude to the 60th parallel. This gives 127 township lines.\n\nThe 49th parallel of latitude is the first base line of the ATS system. On it lay off ticks westwards starting at the 110th line of longitude (4th DLS meridian). Start over at the 114th and 118th lines of longitude (5th and 6th DLS meridians). Extend these ticks due north (following a line of constant longitude) to the first correction line. This gets you your first set of range lines.\n\nStarting at the 49th parallel (first base line) go directly north. This gets you to the second base line. At the latitude corresponding to this distance from the 49th parallel lay off ticks westwards from 110th meridian as you did at the 1st base line. The circumference of the earth has decreased as you went northwards, so there will be fewer full ticks than there were one base line south. Extend north and south from these ticks. This gets you your next set of range lines. You will note there is an offset between the range lines extending north from the lower base line and those extending south from the current ones. This offset occurs along what is called a correction line.\n\nRepeat the base line process every northwards (to the 32nd).\n\nAll this will result in a mesh of cells nominally six miles (plus 3 or 6 chains for road allowances) on a side. Each such cell is called a township (not to be confused with the township lines laid off earlier). Subdivide the township into 36 sections by laying off ticks of one-sixth of each township side and connecting them by north-south and east-west lines. The sections are numbered sinusoidally starting from the southeast corner of the township.\n\nSections can be similarly subdivided into quarters by placing and connecting ticks at the halfway point on each section side. Use the same process to subdivide sections into legal subdivisions (LSD) except place the tick at the one-quarter waypoints. LSDs are numbered sinusoidally starting at the southeast corner of the section.\n\nWhile the ATS format is still proprietary, online conversion tools have been developed.\n\n\n\n"}
{"id": "1965097", "url": "https://en.wikipedia.org/wiki?curid=1965097", "title": "Autonomous province", "text": "Autonomous province\n\nAutonomous province is term for a type of administrative territorial entity. \nTwo autonomous provinces exist:\n\nTwo autonomous provinces exist:\n\n"}
{"id": "14983686", "url": "https://en.wikipedia.org/wiki?curid=14983686", "title": "Brussels Geographic Conference", "text": "Brussels Geographic Conference\n\nThe Brussels Geographic Conference was held in Brussels Belgium in September 1876 at the request of King Leopold II of Belgium. At the conference were invited nearly forty well-known experts, mainly they were schooled in the geographic sciences or were wealthy philanthropists. Before the guests returned to their respective countries, they voted to establish the International African Association. This initiative would in the end pave the way for the creation of Congo Free State.\n\n\n"}
{"id": "337871", "url": "https://en.wikipedia.org/wiki?curid=337871", "title": "Butte", "text": "Butte\n\nIn geomorphology, a butte () is an isolated hill with steep, often vertical sides and a small, relatively flat top; buttes are smaller landforms than mesas, plateaus, and tablelands. The word \"butte\" comes from a French word meaning \"small hill\"; its use is prevalent in the Western United States, including the southwest where \"mesa\" is used for the larger landform. Because of their distinctive shapes, buttes are frequently landmarks in plains and mountainous areas. In differentiating mesas and buttes, geographers use the rule of thumb that a mesa has a top that is wider than its height, while a butte has a top that is narrower than its height.\n\nThe Mitten Buttes of Monument Valley in Arizona are two of the most distinctive and widely recognized buttes. Monument Valley and the Mittens provided backgrounds in scenes from many western-themed films, including seven movies directed by John Ford. The Devils Tower in northeastern Wyoming is a laccolithic butte composed of igneous rock rather than sandstone, limestone or other sedimentary rocks.\n\nThree other notable formations that are either named \"butte\" or may be considered buttes even though they do not conform to the formal geographer's rule are Scotts Bluff in Nebraska which is actually a collection of five bluffs, Crested Butte which is a mountain in Colorado, and Elephant Butte which is now an island in Elephant Butte Reservoir in New Mexico.\n\nAmong the well-known non-flat-topped buttes in the United States are Bear Butte, South Dakota, Black Butte, Oregon, and the Sutter Buttes in California. In many cases, buttes have been given other names that do not use the word \"butte\", for example, Courthouse Rock, Nebraska. Also, some large hills that are technically not buttes have names using the word \"butte\", examples of which are Kamiak Butte and Chelan Butte in Washington state.\n\nButtes form by weathering and erosion when hard caprock overlies a layer of less resistant rock that is eventually worn away. The harder rock on top of the butte resists erosion. The caprock provides protection for the less resistant rock below from wind abrasion which leaves it standing isolated. As the top is further eroded by abrasion and weathering, the excess material that falls off adds to the scree or talus slope around the base. On a much smaller scale, the same process forms hoodoos.\n\n\n"}
{"id": "143335", "url": "https://en.wikipedia.org/wiki?curid=143335", "title": "Celestial navigation", "text": "Celestial navigation\n\nCelestial navigation, also known as astronavigation, is the ancient and modern practice of position fixing that enables a navigator to transition through a space without having to rely on estimated calculations, or dead reckoning, to know their position. Celestial navigation uses \"sights\", or angular measurements taken between a celestial body (e.g. the Sun, the Moon, a planet, or a star) and the visible horizon. The Sun is most commonly used, but navigators can also use the Moon, a planet, Polaris, or one of 57 other navigational stars whose coordinates are tabulated in the nautical almanac and air almanacs.\n\nCelestial navigation is the use of angular measurements (sights) between celestial bodies and the visible horizon to locate one's position in the world, on land as well as at sea. At a given time, any celestial body is located directly over one point on the Earth's surface. The latitude and longitude of that point is known as the celestial body's geographic position (GP), the location of which can be determined from tables in the nautical or air almanac for that year.\n\nThe measured angle between the celestial body and the visible horizon is directly related to the distance between the celestial body's GP and the observer's position. After some computations, referred to as sight reduction, this measurement is used to plot a line of position (LOP) on a navigational chart or plotting work sheet, the observer's position being somewhere on that line. (The LOP is actually a short segment of a very large circle on Earth that surrounds the GP of the observed celestial body. An observer located anywhere on the circumference of this circle on Earth, measuring the angle of the same celestial body above the horizon at that instant of time, would observe that body to be at the same angle above the horizon.) Sights on two celestial bodies give two such lines on the chart, intersecting at the observer's position (actually, the two circles would result in two points of intersection arising from sights on two stars described above, but one can be discarded since it will be far from the estimated position—see the figure at example below). Most navigators will use sights of three to five stars, if available, since that will result in only one common intersection and minimizes the chance of error. That premise is the basis for the most commonly used method of celestial navigation, referred to as the 'altitude-intercept method'.\n\nThere are several other methods of celestial navigation that will also provide position-finding using sextant observations, such as the noon sight, and the more archaic lunar distance method. Joshua Slocum used the lunar distance method during the first recorded single-handed circumnavigation of the world. Unlike the altitude-intercept method, the noon sight and lunar distance methods do not require accurate knowledge of time. The altitude-intercept method of celestial navigation requires that the observer know exact Greenwich Mean Time (GMT) at the moment of his observation of the celestial body, to the second—since for every four seconds that the time source (commonly a chronometer or, in aircraft, an accurate \"hack watch\") is in error, the position will be off by approximately one nautical mile.\n\nAn example illustrating the concept behind the intercept method for determining one’s position is shown to the right. (Two other common methods for determining one’s position using celestial navigation are the longitude by chronometer and ex-meridian methods.) In the adjacent image, the two circles on the map represent lines of position for the Sun and Moon at 1200 GMT on October 29, 2005. At this time, a navigator on a ship at sea measured the Moon to be 56 degrees above the horizon using a sextant. Ten minutes later, the Sun was observed to be 40 degrees above the horizon. Lines of position were then calculated and plotted for each of these observations. Since both the Sun and Moon were observed at their respective angles from the same location, the navigator would have to be located at one of the two locations where the circles cross.\n\nIn this case the navigator is either located on the Atlantic Ocean, about west of Madeira, or in South America, about southwest of Asunción, Paraguay. In most cases, determining which of the two intersections is the correct one is obvious to the observer because they are often thousands of miles apart. As it is unlikely that the ship is sailing across South America, the position in the Atlantic is the correct one. Note that the lines of position in the figure are distorted because of the map’s projection; they would be circular if plotted on a globe.\n\nAn observer in the Gran Chaco point would see the Moon at the left of the Sun, and an observer in the Madeira point would see the Moon at the right of the Sun.\n\nAccurate angle measurement evolved over the years. One simple method is to hold the hand above the horizon with one's arm stretched out. The width of the little finger is an angle just over 1.5 degrees elevation at extended arm's length and can be used to estimate the elevation of the sun from the horizon plane and therefore estimate the time until sunset. The need for more accurate measurements led to the development of a number of increasingly accurate instruments, including the kamal, astrolabe, octant and sextant. The sextant and octant are most accurate because they measure angles from the horizon, eliminating errors caused by the placement of an instrument's pointers, and because their dual mirror system cancels relative motions of the instrument, showing a steady view of the object and horizon.\n\nNavigators measure distance on the globe in degrees, arcminutes and arcseconds. A nautical mile is defined as 1852 meters, but is also (not accidentally) one minute of angle along a meridian on the Earth. Sextants can be read accurately to within 0.2 arcminutes, so the observer's position can be determined within (theoretically) 0.2 miles, about 400 yards (370 m). Most ocean navigators, shooting from a moving platform, can achieve a practical accuracy of 1.5 miles (2.8 km), enough to navigate safely when out of sight of land.\n\nPractical celestial navigation usually requires a marine chronometer to measure time, a sextant to measure the angles, an almanac giving schedules of the coordinates of celestial objects, a set of sight reduction tables to help perform the height and azimuth computations, and a chart of the region. </small> With sight reduction tables, the only calculations required are addition and subtraction. Small handheld computers, laptops and even scientific calculators enable modern navigators to \"reduce\" sextant sights in minutes, by automating all the calculation and/or data lookup steps. Most people can master simpler celestial navigation procedures after a day or two of instruction and practice, even using manual calculation methods.\n\nModern practical navigators usually use celestial navigation in combination with satellite navigation to correct a dead reckoning track, that is, a course estimated from a vessel's position, course and speed. Using multiple methods helps the navigator detect errors, and simplifies procedures. When used this way, a navigator will from time to time measure the sun's altitude with a sextant, then compare that with a precalculated altitude based on the exact time and estimated position of the observation. On the chart, one will use the straight edge of a plotter to mark each position line. If the position line indicates a location more than a few miles from the estimated position, more observations can be taken to restart the dead-reckoning track.\n\nIn the event of equipment or electrical failure, taking sun lines a few times a day and advancing them by dead reckoning allows a vessel to get a crude running fix sufficient to return to port. One can also use the Moon, a planet, Polaris, or one of 57 other navigational stars to track celestial positioning.\n\nLatitude was measured in the past either by measuring the altitude of the Sun at noon (the \"noon sight\"), or by measuring the altitudes of any other celestial body when crossing the meridian (reaching its maximum altitude when due north or south), and frequently by measuring the altitude of Polaris, the north star (assuming it is sufficiently visible above the horizon, which it is not in the Southern Hemisphere). Polaris always stays within 1 degree of the celestial north pole. If a navigator measures the angle to Polaris and finds it to be 10 degrees from the horizon, then he is about 10 degrees north of the equator. This approximate latitude is then corrected using simple tables or almanac corrections to determine a latitude theoretically accurate to within a fraction of a mile. Angles are measured from the horizon because locating the point directly overhead, the zenith, is not normally possible. When haze obscures the horizon, navigators use artificial horizons, which are horizontal mirrors of pans of reflective fluid, especially mercury historically. In the latter case, the angle between the reflected image in the mirror and the actual image of the object in the sky is exactly twice the required altitude.\n\nLongitude can be measured in the same way. If the angle to Polaris can be accurately measured, a similar measurement to a star near the eastern or western horizons will provide the longitude. The problem is that the Earth turns 15 degrees per hour, making such measurements dependent on time. A measure a few minutes before or after the same measure the day before creates serious navigation errors. Before good chronometers were available, longitude measurements were based on the transit of the moon, or the positions of the moons of Jupiter. For the most part, these were too difficult to be used by anyone except professional astronomers. The invention of the modern chronometer by John Harrison in 1761 vastly simplified longitudinal calculation.\n\nThe longitude problem took centuries to solve and was dependent on the construction of a non-pendulum clock (as pendulum clocks cannot function accurately on a tilting ship, or indeed a moving vehicle of any kind). Two useful methods evolved during the 18th century and are still practised today: lunar distance, which does not involve the use of a chronometer, and use of an accurate timepiece or chronometer.\n\nPresently, lay-person calculations of longitude can be made by noting the exact local time (leaving out any reference for Daylight Saving Time) when the sun is at its highest point in the sky. The calculation of noon can be made more easily and accurately with a small, exactly vertical rod driven into level ground—take the time reading when the shadow is pointing due north (in the northern hemisphere). Then take your local time reading and subtract it from GMT (Greenwich Mean Time) or the time in London, England. For example, a noon reading (1200 hours) near central Canada or the US would occur at approximately 6 pm (1800 hours) in London. The six-hour differential is one quarter of a 24-hour day, or 90 degrees of a 360-degree circle (the Earth). The calculation can also be made by taking the number of hours (use decimals for fractions of an hour) multiplied by 15, the number of degrees in one hour. Either way, it can be demonstrated that much of central North America is at or near 90 degrees west longitude. Eastern longitudes can be determined by adding the local time to GMT, with similar calculations.\n\nThe older method, called \"lunar distances\", was refined in the 18th century and employed with decreasing regularity at sea through the middle of the 19th century. It is only used today by sextant hobbyists and historians, but the method is theoretically sound, and can be used when a timepiece is not available or its accuracy is suspect during a long sea voyage. The navigator precisely measures the angle between the moon and the sun, or between the moon and one of several stars near the ecliptic. The observed angle must be corrected for the effects of refraction and parallax, like any celestial sight. To make this correction the navigator would measure the altitudes of the moon and sun (or star) at about the same time as the lunar distance angle. Only rough values for the altitudes were required. Then a calculation with logarithms or graphical tables requiring ten to fifteen minutes' work would convert the observed angle to a geocentric lunar distance. The navigator would compare the corrected angle against those listed in the almanac for every three hours of Greenwich time, and interpolate between those values to get the actual Greenwich time aboard ship. Knowing Greenwich time and comparing against local time from a common altitude sight, the navigator can work out his longitude.\n\nThe considerably more popular method was (and still is) to use an accurate timepiece to directly measure the time of a sextant sight. The need for accurate navigation led to the development of progressively more accurate chronometers in the 18th century (see John Harrison). Today, time is measured with a chronometer, a quartz watch, a shortwave radio time signal broadcast from an atomic clock, or the time displayed on a GPS. A quartz wristwatch normally keeps time within a half-second per day. If it is worn constantly, keeping it near body heat, its rate of drift can be measured with the radio and, by compensating for this drift, a navigator can keep time to better than a second per month. Traditionally, a navigator checked his chronometer from his sextant, at a geographic marker surveyed by a professional astronomer. This is now a rare skill, and most harbourmasters cannot locate their harbour's marker.\n\nTraditionally, three chronometers were kept in gimbals in a dry room near the centre of the ship. They were used to set a hack watch for the actual sight, so that no chronometers were ever exposed to the wind and salt water on deck. Winding and comparing the chronometers was a crucial duty of the navigator. Even today, it is still logged daily in the ship's deck log and reported to the Captain before eight bells on the forenoon watch (shipboard noon). Navigators also set the ship's clocks and calendar.\n\nThe celestial line of position concept was discovered in 1837 by Thomas Hubbard Sumner when, after one observation, he computed and plotted his longitude at more than one trial latitude in his vicinity – and noticed that the positions lay along a line. Using this method with two bodies, navigators were finally able to cross two position lines and obtain their position – in effect determining both latitude and longitude. Later in the 19th century came the development of the modern (Marcq St. Hilaire) intercept method; with this method the body height and azimuth are calculated for a convenient trial position, and compared with the observed height. The difference in arcminutes is the nautical mile \"intercept\" distance that the position line needs to be shifted toward or away from the direction of the body's subpoint. (The intercept method uses the concept illustrated in the example in the “How it works” section above.) Two other methods of reducing sights are the longitude by chronometer and the ex-meridian method.\n\nWhile celestial navigation is becoming increasingly redundant with the advent of inexpensive and highly accurate satellite navigation receivers (GPS), it was used extensively in aviation until the 1960s, and marine navigation until quite recently. However; since a prudent mariner never relies on any sole means of fixing his position, many national maritime authorities still require deck officers to show knowledge of celestial navigation in examinations, primarily as a backup for electronic/satellite navigation. One of the most common current usages of celestial navigation aboard large merchant vessels is for compass calibration and error checking at sea when no terrestrial references are available.\n\nThe U.S. Air Force and U.S. Navy continued instructing military aviators on celestial navigation use until 1997, because:\n\nThe United States Naval Academy announced that it was discontinuing its course on celestial navigation (considered to be one of its most demanding non-engineering courses) from the formal curriculum in the spring of 1998. In October 2015, citing concerns about the reliability of GPS systems in the face of potential hostile hacking, the USNA reinstated instruction in celestial navigation in the 2015–16 academic year.\n\nAt another federal service academy, the US Merchant Marine Academy, there was no break in instruction in celestial navigation as it is required to pass the US Coast Guard License Exam to enter the Merchant Marine. It is also taught at Harvard, most recently as Astronomy 2.\n\nCelestial navigation continues to be used by private yachtsmen, and particularly by long-distance cruising yachts around the world. For small cruising boat crews, celestial navigation is generally considered an essential skill when venturing beyond visual range of land. Although GPS (Global Positioning System) technology is reliable, offshore yachtsmen use celestial navigation as either a primary navigational tool or as a backup.\n\nCelestial navigation was used in commercial aviation up until the early part of the jet age; early Boeing 747s had a \"sextant port\" in the roof of the cockpit. It was only phased out in the 1960s with the advent of inertial navigation and doppler navigation systems, and today's satellite-based systems which can locate the aircraft's position accurate to a 3-meter sphere with several updates per second.\n\nA variation on terrestrial celestial navigation was used to help orient the Apollo spacecraft en route to and from the Moon. To this day, space missions such as the Mars Exploration Rover use star trackers to determine the attitude of the spacecraft.\n\nAs early as the mid-1960s, advanced electronic and computer systems had evolved enabling navigators to obtain automated celestial sight fixes. These systems were used aboard both ships and US Air Force aircraft, and were highly accurate, able to lock onto up to 11 stars (even in daytime) and resolve the craft's position to less than . The SR-71 high-speed reconnaissance aircraft was one example of an aircraft that used a combination of automated celestial and inertial navigation. These rare systems were expensive, however, and the few that remain in use today are regarded as backups to more reliable satellite positioning systems.\n\nIntercontinental ballistic missiles use celestial navigation to check and correct their course (initially set using internal gyroscopes) while flying outside the Earth's atmosphere. The immunity to jamming signals is the main driver behind this seemingly archaic technique.\n\nX-ray pulsar-based navigation and timing (XNAV) is an experimental navigation technique whereby the periodic X-ray signals emitted from pulsars are used to determine the location of a vehicle, such as a spacecraft in deep space. A vehicle using XNAV would compare received X-ray signals with a database of known pulsar frequencies and locations. Similar to GPS, this comparison would allow the vehicle to triangulate its position accurately (±5 km). The advantage of using X-ray signals over radio waves is that X-ray telescopes can be made smaller and lighter. On 9 November 2016 the Chinese Academy of Sciences launched an experimental pulsar navigation satellite called XPNAV 1. SEXTANT (Station Explorer for X-ray Timing and Navigation Technology) is a NASA-funded project developed at the Goddard Space Flight Center that is testing XNAV on-orbit on board the International Space Station in connection with the NICER project, launched on 3 June 2017 on the SpaceX CRS-11 ISS resupply mission.\n\nCelestial navigation trainers for aircraft crews combine a simple flight simulator with a planetarium.\n\nAn early example is the Link Celestial Navigation Trainer, used in the Second World War. Housed in a high building, it featured a cockpit accommodating a whole bomber crew (pilot, navigator and bombardier). The cockpit offered a full array of instruments which the pilot used to fly the simulated aeroplane. Fixed to a dome above the cockpit was an arrangement of lights, some collimated, simulating constellations from which the navigator determined the plane's position. The dome's movement simulated the changing positions of the stars with the passage of time and the movement of the plane around the earth. The navigator also received simulated radio signals from various positions on the ground. Below the cockpit moved \"terrain plates\" – large, movable aerial photographs of the land below – which gave the crew the impression of flight and enabled the bomber to practise lining up bombing targets. A team of operators sat at a control booth on the ground below the machine, from which they could simulate weather conditions such as wind or cloud. This team also tracked the aeroplane's position by moving a \"crab\" (a marker) on a paper map.\n\nThe Link Celestial Navigation Trainer was developed in response to a request made by the Royal Air Force (RAF) in 1939. The RAF ordered 60 of these machines, and the first one was built in 1941. The RAF used only a few of these, leasing the rest back to the US, where eventually hundreds were in use.\n\n"}
{"id": "1527098", "url": "https://en.wikipedia.org/wiki?curid=1527098", "title": "Clairaut's theorem", "text": "Clairaut's theorem\n\nClairaut's theorem is a general mathematical law giving the surface gravity on a viscous rotating ellipsoid in equilibrium under the action of its gravitational field and centrifugal force. It was published in 1743 by Alexis Claude Clairaut in his \"Théorie de la figure de la terre, tirée des principes de l'hydrostatique\" (\"Theory of the shape of the earth, drawn from the principles of hydrostatics\") which synthesized physical and geodetic evidence that the Earth is an oblate rotational ellipsoid. It was initially used to relate the gravity at any point on the Earth's surface to the position of that point, allowing the ellipticity of the Earth to be calculated from measurements of gravity at different latitudes. Today it has been largely supplanted by the Somigliana equation.\n\nAlthough it had been known since antiquity that the Earth was spherical, by the 17th century evidence was accumulating that it was not a perfect sphere. In 1672 Jean Richer found the first evidence that gravity was not constant over the Earth (as it would be if the Earth were a sphere); he took a pendulum clock to Cayenne, French Guiana and found that it lost minutes per day compared to its rate at Paris. This indicated the acceleration of gravity was less at Cayenne than at Paris. Pendulum gravimeters began to be taken on voyages to remote parts of the world, and it was slowly discovered that gravity increases smoothly with increasing latitude, gravitational acceleration being about 0.5% greater at the poles than at the equator.\n\nBritish physicist Isaac Newton explained this in his \"Principia Mathematica\" (1687) in which he outlined his theory and calculations on the shape of the Earth. Newton theorized correctly that the Earth was not precisely a sphere but had an oblate ellipsoidal shape, slightly flattened at the poles due to the centrifugal force of its rotation. Since the surface of the Earth is closer to its center at the poles than at the equator, gravity is stronger there. Using geometric calculations, he gave a concrete argument as to the hypothetical ellipsoid shape of the Earth.\n\nThe goal of \"Principia\" was not to provide exact answer for natural phenomena, but to theorize potential solutions to these unresolved factors in science. Newton pushed for scientists to look further into the unexplained variables. Two prominent researchers that he inspired were Alexis Clairaut and Pierre Louis Maupertuis. They both sought to prove the validity of Newton's theory on the shape of the Earth. In order to do so, they went on an expedition to Lapland in an attempt to accurately measure the meridian arc. From such measurements they could calculate the eccentricity of the Earth, its degree of departure from a perfect sphere. Clairaut confirmed that Newton's theory that the Earth was ellipsoidal was correct, but his calculations were in error, and wrote a letter to the Royal Society of London with his findings. The society published an article in Philosophical Transactions the following year in 1737 that revealed his discovery. Clairaut showed how Newton's equations were incorrect, and did not prove an ellipsoid shape to the Earth. However, he corrected problems with the theory, that in effect would prove Newton's theory correct. Clairaut believed that Newton had reasons for choosing the shape that he did, but he did not support it in \"Principia.\" Clairaut's article did not provide an valid equation to back up his argument as well. This created much controversy in the scientific community.\n\nIt was not until Clairaut wrote \"Théorie de la figure de la terre\" in 1743 that a proper answer was provided. In it, he promulgated what is more formally known today as Clairaut's theorem.\n\nClairaut's formula for the acceleration due to gravity \"g\" on the surface of a spheroid at latitude φ, was:\n\nwhere formula_2 is the value of the acceleration of gravity at the equator, \"m\" the ratio of the centrifugal force to gravity at the equator, and \"f\" the flattening of a meridian section of the earth, defined as:\n(where \"a\" = semimajor axis, \"b\" = semiminor axis).\n\nClairaut derived the formula under the assumption that the body was composed of concentric coaxial spheroidal layers of constant density. \nThis work was subsequently pursued by Laplace, who relaxed the initial assumption that surfaces of equal density were spheroids.\nStokes showed in 1849 that the theorem applied to any law of density so long as the external surface is a spheroid of equilibrium. A history of the subject, and more detailed equations for \"g\" can be found in Khan.\n\nThe above expression for \"g\" has been supplanted by the Somigliana equation (after Carlo Somigliana):\n\nwhere,\n\nFor Earth, formula_2 = 9.7803253359 ms; formula_9 = 9.8321849378 ms; \"k\" = 0.00193185265241 ; \"e\" = 0.00669437999013: \n\nThe spheroidal shape of the Earth is the result of the interplay between gravity and centrifugal force caused by the Earth's rotation about its axis. In his \"Principia\", Newton proposed the equilibrium shape of a homogeneous rotating Earth was a rotational ellipsoid with a flattening \"f\" given by 1/230. As a result, gravity increases from the equator to the poles. By applying Clairaut's theorem, Laplace found from 15 gravity values that \"f\" = 1/330. A modern estimate is 1/298.25642. See Figure of the Earth for more detail.\n\nFor a detailed account of the construction of the reference Earth model of geodesy, see Chatfield.\n"}
{"id": "56428137", "url": "https://en.wikipedia.org/wiki?curid=56428137", "title": "Dalsfjord Lighthouse Museum", "text": "Dalsfjord Lighthouse Museum\n\nThe Dalsfjord Lighthouse Museum () is a Norwegian museum dedicated to documenting and presenting the social history of the people that built lighthouses, sector lights, markers, moorings, and ports along the Norwegian coastline.\n\nThe museum is located in Dravlaus in the municipality of Volda, and it is part of the Sunnmøre Museum Foundation. The museum was opened in a new location with a new exhibit on November 8, 2012.\n\n"}
{"id": "11553912", "url": "https://en.wikipedia.org/wiki?curid=11553912", "title": "Deep-sea exploration", "text": "Deep-sea exploration\n\nDeep-sea exploration is the investigation of physical, chemical, and biological conditions on the sea bed, for scientific or commercial purposes. Deep-sea exploration is considered as a relatively recent human activity compared to the other areas of geophysical research, as the depths of the sea have been investigated only during comparatively recent years. The ocean depths still remain as a largely unexplored part of the planet, and form a relatively undiscovered domain.\n\nIn general, modern scientific Deep-sea exploration can be said to have begun when French scientist Pierre Simon de Laplace investigated the average depth of the Atlantic ocean by observing tidal motions registered on Brazilian and African coasts. He calculated the depth to be , a value later proven quite accurate by soundings measurement. Later on, with increasing demand for submarine cables installment, accurate soundings was required and the first investigations of the sea bottom were undertaken. First deep-sea life forms were discovered in 1864 when Norwegian researchers obtained a sample of a stalked crinoid at a depth of . The British Government sent out the \"Challenger\" expedition (a ship called ) in 1872 which discovered 715 new genera and 4,417 new species of marine organisms over the space of four years.\n\nThe first instrument used for deep-sea investigation was the sounding weight, used by British explorer Sir James Clark Ross. With this instrument, he reached a depth of in 1840. The \"Challenger\" expedition used similar instruments called Baillie sounding machines to extract samples from the sea bed.\n\nIn 1960, Jacques Piccard and United States Navy Lieutenant Donald Walsh descended in the bathyscaphe \"Trieste\" into the Mariana Trench, the deepest part of the world's oceans, to make the deepest dive in history: . On 25 March 2012, filmmaker James Cameron descended into the Mariana Trench and, for the first time, is expected to have filmed and sampled the bottom.<ref name=\"NYT-03/08/2012\"></ref>\n\nNavy Lieutenant Matthew Maury to aid installation of the first trans-continent telegraph cables in 1858, and a few examples of deep marine creatures.\n\nFrom 1872 to 1876, a landmark ocean study was carried out by British scientists aboard HMS \"Challenger\", a sailing vessel that was redesigned into a laboratory ship. The \"Challenger\" expedition covered , and shipboard scientists collected hundreds of samples, hydrographic measurements, and specimens of marine life. They are also credited with providing the first real view of major seafloor features such as the deep ocean basins. They discovered more than 4,700 new species of marine life, including deep-sea organisms.\n\nDeep-sea exploration advanced considerably in the 1900s thanks to a series of technological inventions, ranging from sonar system to detect the presence of objects underwater through the use of sound to manned deep-diving submersibles such as . Operated by the Woods Hole Oceanographic Institution, \"Alvin\" is designed to carry a crew of three people to depths of . The submarine is equipped with lights, cameras, computers, and highly maneuverable robotic arms for collecting samples in the darkness of the ocean's depths.\n\nHowever, the voyage to the ocean bottom is still a challenging experience. Scientists are working to find ways to study this extreme environment from the shipboard. With more sophisticated use of fiber optics, satellites, and remote-control robots, scientists one day may explore the deep sea from a computer screen on the deck rather than out of a porthole.\n\nThe extreme conditions in the deep sea require elaborate methods and technologies, which has been the main reason why its exploration has a comparatively short history.\nIn the following, important key stones of deep sea exploration are listed.\n\n\nThe sounding weight, one of the first instruments used for the sea bottom investigation, was designed as a tube on the base which forced the seabed in when it hit the bottom of the ocean. British explorer Sir James Clark Ross fully employed this instrument to reach a depth of in 1840.\n\nSounding weights used on were slightly advanced called \"Baillie sounding machine\". The British researchers used wire-line soundings to investigate sea depths and collected hundreds of biological samples from all the oceans except the Arctic. Also used on HMS \"Challenger\" were dredges and scoops, suspended on ropes, with which samples of the sediment and biological specimens of the seabed could be obtained.\n\nA more advanced version of the sounding weight is the gravity corer. The gravity corer allows researchers to sample and study sediment layers at the bottom of oceans. The corer consists of an open-ended tube with a lead weight and a trigger mechanism that releases the corer from its suspension cable when the corer is lowered over the seabed and a small weight touches the ground. The corer falls into the seabed and penetrates it to a depth of up to . By lifting the corer, a long, cylindrical sample is extracted in which the structure of the seabed’s layers of sediment is preserved. Recovering sediment cores allows scientists to see the presence or absence of specific fossils in the mud that may indicate climate patterns at times in the past, such as during the ice ages. Samples of deeper layers can be obtained with a corer mounted in a drill. The drilling vessel JOIDES Resolution is equipped to extract cores from depths of as much as below the ocean bottom. (See Ocean Drilling Program)\n\nEcho-sounding instruments have also been widely used to determine the depth of the sea bottom since World War II. This instrument is used primarily for determining the depth of water by means of an acoustic echo. A pulse of sound sent from the ship is reflected from the sea bottom back to the ship, the interval of time between transmission and reception being proportional to the depth of the water. By registering the time lapses between outgoing and returning signals continuously on paper tape, a continuous mapping of the seabed is obtained. The majority of the ocean floor has been mapped in this way.\n\nIn addition, high-resolution television cameras, thermometers, pressure meters, and seismographs are other notable instruments for deep-sea exploration invented by the technological advance. These instruments are either lowered to the sea bottom by long cables or directly attached to submersible buoys. Deep-sea currents can be studied by floats carrying an ultrasonic sound device so that their movements can be tracked from aboard the research vessel. Such vessels themselves are equipped with state -of-art navigational instruments, such as satellite navigation systems, and global positioning systems that keep the vessel in a live position relative to a sonar beacon on the bottom of the ocean.\n\nBecause of the high pressure, the depth to which a diver can descend without special equipment is limited. The deepest recorded made by a skin diver is . Revolutionary new diving suits, such as the \"JIM suit,\" allows divers to reach depths up to approximately . Some additional suits feature thruster packs that boost a diver to different locations underwater.\n\nTo explore even deeper depths, deep-sea explorers must rely on specially constructed steel chambers to protect them. The American explorer William Beebe, also a naturalist from Columbia University in New York, was the designer of the first practical bathysphere to observe marine species at depths that could not be reached by a diver. The Bathysphere, a spherical steel vessel, was designed by Beebe and his fellow engineer Otis Barton, an engineer at Harvard University. In 1930 Beebe and Barton reached a depth of , and in 1934. The potential danger was that if the cable broke, the occupants could not return to the surface. During the dive, Beebe peered out of a porthole and reported his observations by telephone to Barton who was on the surface.\n\nIn 1948, Swiss physicist Auguste Piccard tested a much deeper-diving vessel he invented called the bathyscaphe, a navigable deep-sea vessel with its gasoline-filled float and suspended chamber or gondola of spherical steel. On an experimental dive in the Cape Verde Islands, his bathyscaphe successfully withstood the pressure on it at , but its body was severely damaged by heavy waves after the dive. In 1954, with this bathyscaphe, Piccard reached a depth of . In 1953, his son Jacques Piccard joined in building new and improved bathyscaphe , which dived to in field trials. The United States Navy acquired \"Trieste\" in 1958 and equipped it with a new cabin to enable it to reach deep ocean trenches. In 1960, Jacques Piccard and United States Navy Lieutenant Donald Walsh descended in \"Trieste\" to the deepest known point on Earth - the Challenger Deep in the Mariana Trench, successfully making the deepest dive in history: .\nAn increasing number of occupied submersibles are now employed around the world. The American-built that is operated by the Woods Hole Oceanographic Institution, is a three-person submarine that can dive to about and is equipped with a mechanical manipulator to collect bottom samples. \"Alvin\" made its first test dive in 1964, and has performed more than 3,000 dives to average depths of . \"Alvin\" has also involved in a wide variety of research projects, such as one where giant tube worms were discovered on the Pacific Ocean floor near the Galápagos Islands.\n\nOne of the first unmanned deep sea vehicles was developed by the University of California with a grant from the Allan Hancock Foundation in the early 1950s to develop a more economical method of taking photos miles under the sea with an unmanned steel high-pressure sphere called a benthograph which contained a camera and strobe light. The original benthograph built by USC was very successful in taking a series of underwater photos until it became wedged between some rocks and could not be retrieved.\n\nROVs, or remote operated vehicles, are seeing increasing use in underwater exploration. These submersibles are piloted through a cable which connects to the surface ship, and they can reach depths of up to . New developments in robotics have also led to the creation of AUVs, or autonomous underwater vehicles. The robotic submarines are programmed in advance, and receive no instruction from the surface. HROV combine features of both ROVs and AUV, operating independently or with a cable. was employed in 1985 to locate the wreck of ; the smaller was also used to explore the shipwreck.\n\nIn 1974, \"Alvin\" (operated by the Woods Hole Oceanographic Institution and the Deep Sea Place Research Center), the French bathyscaphe \"Archimède\", and the French diving saucer \"Cyane\", assisted by support ships and , explored the great rift valley of the Mid-Atlantic Ridge, southwest of the Azores. About 5,200 photographs of the region were taken, and samples of relatively young solidified magma were found on each side of the central fissure of the rift valley, giving additional proof that the seafloor spreads at this site at a rate of about per year (see plate tectonics,).\n\nIn a series of dives conducted between 1979–1980 into the Galápagos rift, off the coast of Ecuador, French, Italian, Mexican, and U.S. scientists found vents, nearly high and about across, discharging a mixture of hot water (up to ) and dissolved metals in dark, smoke-like plumes (see hydrothermal vent,). These hot springs play an important role in the formation of deposits that are enriched in copper, nickel, cadmium, chromium, and uranium.\n\n\n"}
{"id": "28341466", "url": "https://en.wikipedia.org/wiki?curid=28341466", "title": "Exploration of Antarctica", "text": "Exploration of Antarctica\n\nThe exploration of the Antarctica includes:\n"}
{"id": "24490545", "url": "https://en.wikipedia.org/wiki?curid=24490545", "title": "Exploration of North America", "text": "Exploration of North America\n\nThe exploration of North America by non-indigenous people was a continuing effort to map and explore the continent of North America. It spanned centuries, and consisted of efforts by numerous people and expeditions from various foreign countries to map the continent. The European colonization of the Americas followed.\n\nAccording to the Sagas of Icelanders, Norse sailors (often called Vikings) from Iceland first settled Greenland in the 980s. Erik the Red explored and settled southwestern Greenland, which he named to entice potential Icelandic settlers, eventually establishing the Eastern and Western Settlements, which were abandoned around 1350.\n\nL'Anse aux Meadows, an archaeological site on the northernmost tip of Newfoundland, and a second site in southwestern Newfoundland, are the only known sites of a Norse village in North America outside of Greenland. These sites are notable for their possible connections with the attempted colony of Vinland established by Leif Erikson in 1003.\n\nThe Viking voyages did not become common knowledge in the Old World, and Europeans remained unaware of the existence of the Americas as a whole, until the first decades following the year 1492. Many expeditions were launched from European nations in search of a Northwest Passage to East Asia (or \"the Indies\" as the region was called) in order to establish a shorter trade route to China than the Silk Road, a trade route which had become desperately needed and yet exacerbated by the Fall of Constantinople. Also, the Castilian crown needed an alternative to the Portuguese controlled eastern maritime trade route around Africa to India and East Asia.\nOn August 3, 1492, Christopher Columbus set sail from the Port of Palos de la Frontera in the Province of Huelva, from the newly \"los Reyes Católicos\" coordinated Kingdoms of Castile and Aragon, in present-day Spain, financed by Queen Isabella I of Castille. Columbus's Letter on the First Voyage of his discovery of the Bahamas, Cuba, and Hispaniola spread the news across Europe quickly. Columbus rediscovered and explored much of the Lesser Antilles in his second voyage then discovered both Trinidad and Tobago on his third voyage whilst skirting the northern South American coast. His fourth voyage was spent scanning the Central American coast. The Voyages of Christopher Columbus opened the New World.\n\nItalian navigator and explorer Giovanni Caboto (known in English as John Cabot) is credited with the discovery of continental North America on June 24, 1497, under the commission of Henry VII of England. Though the exact location of his discovery remains disputed, the Canadian and United Kingdom governments' official position is that he landed on the island of Newfoundland. The English presence through Giovanni Caboto was signaled in Juan de la Cosa's map of 1500.\n\nIn 1499 João Fernandes Lavrador was licensed by the King of Manuel I of Portugal and together with Pêro de Barcelos they reached Greenland and sighted Labrador for the first time since Leif Erikson, which was granted and named after Lavrador. After returning he possibly went to Bristol to sail in the name of England. Nearly at the same time, between 1499 and 1502 the brothers Gaspar and Miguel Corte Real explored and named the coasts of Greenland, Labrador and also Newfoundland, naming \"Terra Verde\" the explored North American coasts. Both explorations were signaled in 1502 Cantino planisphere.\n\nIt was soon understood that Columbus had not reached Asia, but rather found what was to Europeans a New World, which in 1507 was named \"America\", probably after Amerigo Vespucci, on the Waldseemüller map.\n\nIn 1500, Pedro Álvares Cabral was sent by Portugal to explore South America. He is considered to be the discoverer of Brazil.\n\nAragon King Ferdinand II sent Juan Ponce de León from the fledgling colony on Hispaniola to verify rumors of undiscovered land to the northwest. On April 2, 1513, Ponce de León disembarked on the northeast coast of what he named Florida for the crown. The exact location is disputed, but historians have offered the possibilities of St. Augustine, Ponce de León Inlet, and Melbourne Beach. He encountered the powerful Gulf Stream and found a passage through the Florida Keys to land on the southwestern Gulf Coast of Florida on the Gulf of Mexico. Again, the exact location is disputed. While it is true that Columbus visited Puerto Rico and the Virgin Islands in 1493, Ponce de Leon was the first known European to reach the present-day United States mainland.\n\nOn September 25, 1513, Spanish conquistador Vasco Núñez de Balboa was the first European to see the Pacific Ocean once he crossed the Isthmus of Panama. He claimed all the territory touching it for the Crown, later to affect colonization of Las Californias.\n\nAround 1519-1521, Portuguese explorer João Álvares Fagundes explored the coasts of Newfoundland, Labrador and Nova Scotia, with a mission to create colonies.\n\nIn 1524, Italian explorer Giovanni da Verrazzano sailed for King Francis I of France and is known as the first European since the Norse to explore the Atlantic coast of North America. Arriving near the Cape Fear River delta, he explored the coastlines of present-day states of South Carolina and North Carolina, entering the Pamlico Sound, and bypassing entrances to the Chesapeake Bay. Believing the New York Harbor to be a lake, he sailed past Long Island, exploring Narragansett Bay and Newfoundland.\n\nIn 1524-1525, Portuguese explorer Estevão Gomes, on behalf of Charles I of Spain, explored present-day Nova Scotia sailing South along the Maine coast. Gomes entered New York Harbor and saw the Hudson River(which he named the \"San Antonio River\"). Because of his expedition, the 1529 Diogo Ribeiro world map outlines the East coast of North America almost perfectly.\n\nIn 1534, Jacques Cartier planted a cross in the Gaspé Peninsula, on the Gulf Gulf of Saint Lawrence and claimed the land in the name of Francis I. In 1535 Cartier explored the St. Lawrence river and also claimed the region for France.\nAfter two failed attempts to reach East Asia by circumnavigating Siberia, Henry Hudson sailed west in 1609 under the Dutch East India Company. He, too, passed Cape Cod, Chesapeake Bay and the Delaware Bay, instead sailing up the Hudson River on September 11, 1609 in search of a fabled connection to the Pacific via what was actually the Great Lakes. In Hudson's fourth and final voyage, he discovered, mapped, and explored the Hudson Strait, Hudson Bay and James Bay.\n\nOther major sea-based explorers were Captain James Cook, George Vancouver, and Charles Wilkes.\n\nThere were numerous Spanish explorers and conquistadors who explored the Southwest of North America (including present-day west and central United States) and cross the continent (east to west) in its southern regions, mainly from the second quarter to the middle of the 16th century, such as Álvar Núñez Cabeza de Vaca and Francisco Vásquez de Coronado, but also the North American Southeast and south-central regions, s Soto]].\n\nIn 1608 Samuel de Champlain founded what is now Quebec City, which would become the first permanent settlement and the capital of New France. He took personal administration over the city and its affairs, and sent out expeditions to explore the interior. Champlain himself discovered Lake Champlain in 1609. By 1615, he had travelled by canoe up the Ottawa River through Lake Nipissing and Georgian Bay to the centre of Huron country near Lake Simcoe. During these voyages, Champlain aided the Wendat (aka 'Hurons') in their battles against the Iroquois Confederacy. As a result, the Iroquois would become enemies of the French and be involved in multiple conflicts.\n\nFrom 1679 to 1682 René-Robert Cavelier, Sieur de La Salle explored the Great Lakes region of the United States and Canada, and the entire course of Mississippi River to the Gulf of Mexico.\n\nFrom 1697 to 1702 Eusebio Kino explored the Sonoran Desert and on his journey to the Colorado River Delta discovered an overland route to Baja California that was then commonly believed to be an island. In 1683 Kino lead the first European overland crossing of Baja California.\n\nEuropean exploration of western Canada was largely motivated by the fur trade and the search for the elusive Northwest Passage. Hudson's Bay Company explorer Henry Kelsey has the distinction of being the first European to see the northern Great Plains in 1690.\n\nAnthony Henday was the first to have seen the Rocky Mountains, in 1754, but curiously did not mention it in his journals. From his westernmost geographic position (roughly near the town of Olds, Alberta, halfway between Calgary and Red Deer, Alberta) the Rockies should have been quite conspicuous, but he was likely trying to disguise the disappointing fact that an unknown range of seemingly impassible mountains now stood between the HBC and the Pacific. Samuel Hearne found the Coppermine River in 1769-71 in his failed search for copper ore deposits. Burned by these shortfalls, the HBC largely quit exploration.\n\nThe North West Company, on the other hand, used a business model that required constant expansion into untapped areas. Under the auspices of the NWC, Alexander Mackenzie discovered the Mackenzie River in 1789 and was the first European to reach the North-American Pacific overland, via the Bella Coola River, in 1793. Simon Fraser reached the Pacific in 1808 via the Fraser River.\n\nDavid Thompson, widely regarded as the greatest land geographer that ever lived, traveled over 90,000 km during his lifetime. In 1797, Thompson was sent south by his employers to survey part of the Canada-U.S. boundary along the water routes from Lake Superior to Lake of the Woods to satisfy unresolved questions of territory arising from the Jay Treaty between Great Britain and the United States. By 1798 Thompson had completed a survey of from Grand Portage, through Lake Winnipeg, to the headwaters of the Assiniboine and Mississippi Rivers, as well as two sides of Lake Superior. In 1798, the company sent him to Red Deer Lake (in present-day Alberta) to establish a trading post. The English translation of Lac La Biche-Red Deer Lake-first appeared on the Mackenzie map of 1793. Thompson spent the next few seasons trading based in Fort George (now in Alberta), and during this time led several expeditions into the Rocky Mountains. In 1811/1812 he followed the Columbia River to the Pacific, and in 1814 used his notes and measurements to draft the first European-style map of western Canada, covering 3.9 million square kilometres.\n\nLewis and Clark were the first Americans to venture into the newly acquired territory of the Louisiana Purchase, at the order of President Thomas Jefferson. They discovered many new geographical features, Indian tribes, and animal and plant species. John Colter was a member of the expedition who subsequently became a guide for others in the 'Old West,' and did some explorations of his own.\n\nJohn C. Frémont led many important explorations in the Great Plains, Great Basin, Oregon territory, and Mexican Alta California.\n\nJoseph Reddeford Walker was one of the most prominent of the explorers, and charted many new paths through the West, which often were then utilized by emigrants crossing to settle in Western towns and communities. In 1833, his exploring party discovered a route along the Humboldt River across present-day Nevada, ascending the Sierra Nevada following the Carson River and descending via Stanislaus River drainages to Monterey. His return route across the southern Sierra was via Walker Pass, named after Walker by John Charles Fremont. The approach of the Sierra via the Carson River route later became known as the California Trail, the primary route for the emigrants to the gold fields during the California gold rush.\n\nAs the American population of the West increased, the US government launched ongoing official explorations mainly through the US Army Corps of Topographical Engineers. One of the main officers and explorers in this unit was George Wheeler. In 1872, the US Congress authorized an ambitious plan to map the portion of the United States west of the 100th meridian at a scale of 8 miles to the inch. This plan necessitated what became known as the Wheeler Survey, along with the Clarence King and John Wesley Powell Surveys, and expeditions by Ferdinand Vandeveer Hayden. In 1879, all such efforts were reorganized as the United States Geological Survey.\n\n\n\n\n"}
{"id": "1188260", "url": "https://en.wikipedia.org/wiki?curid=1188260", "title": "Foghorn", "text": "Foghorn\n\nA foghorn is a fog signal that uses sound to warn vehicles of navigational hazards like rocky coastlines, or boats of the presence of other vessels, in foggy conditions. The term is most often used in relation to marine transport. When visual navigation aids such as lighthouses are obscured, foghorns provide an audible warning of rock outcrops, shoals, headlands, or other dangers to shipping.\n\nAll foghorns use a vibrating column of air to create an audible tone, but the method of setting up this vibration differs. Some horns, like the Daboll trumpet, used vibrating plates or metal reeds, a similar principle to a modern electric car horn. Others used air forced through holes in a revolving cylinder or disk, in the same manner as a siren. Semi-automatic operation of foghorns was achieved by using a clockwork mechanism (or \"coder\") to sequentially open the valves admitting air to the horns; each horn was given its own timing characteristics to help mariners identify them.\n\nAudible fog signals have been used in one form or another for hundreds of years, initially simply bells or gongs struck manually.\n\nAt some lighthouses, a small cannon was let off periodically to warn away ships, but this had the obvious disadvantage of having to be fired manually throughout the whole period the fog persisted (which could be for several days). Lighthouse windows and lighting apparatus were susceptible to damage depending on the proximity of the explosion. One incident of lax handling of explosives nearby resulted in a concussion that propelled the lighthouse keeper at Fort Amherst, who was seated, to the other end of the room. In the United States, whistles were also used where a source of steam power was available, though Trinity House, the British lighthouse authority, did not employ them, preferring an explosive signal.\n\nThroughout the 19th century efforts were made to automate the signalling process. Trinity House eventually developed a system (the \"Signal, Fog, Mk I\") for firing a gun-cotton charge electrically. However, the charge had to be manually replaced after each signal. At Portland Bill, for example, which had a five-minute interval between fog-signals, this meant the horns had to be lowered, the two new charges inserted, and the horns raised again every five minutes during foggy periods.\nClockwork systems were also developed for striking bells.\n\nCaptain James William Newton claimed to have been the inventor of the fog signalling technique using loud and low notes.\n\nThe first automated steam-powered foghorn was invented by Robert Foulis, a Scotsman who emigrated to Saint John, New Brunswick, Canada. Foulis is said to have heard his daughter playing the piano in the distance on a foggy night, and noticed the low notes were more audible than the higher notes: he then designed a device to produce a low-frequency sound, as well as a code system for use with it. Foulis repeatedly presented his concept to the Commissioners of Light Houses for the Bay of Fundy for installation on Partridge Island. While the Commissioners initially rejected Foulis's plan, one commissioner eventually encouraged Foulis to submit detailed plans to the Commission. For reasons unknown, the plans were given to another Canadian engineer, T. T. Vernon Smith, who officially submitted them to the Commissioners as his own. The foghorn was constructed at Partridge Island in 1859 as the Vernon-Smith horn. After protest by Foulis and a legislative inquiry, Foulis was credited as the true inventor, but he never patented or profited from his invention.\n\nThe development of fog signal technology continued apace at the end of the 19th century. During the same period an inventor, Celadon Leeds Daboll, developed a coal-powered foghorn called the Daboll trumpet for the American lighthouse service, though it was not universally adopted. A few Daboll trumpets remained in use until the mid-20th century.\n\nIn the United Kingdom, experiments to develop more effective foghorns were carried out by John Tyndall and Lord Rayleigh, amongst others. The latter's ongoing research for Trinity House culminated in a design for a siren with a large trumpet designed to achieve maximum sound propagation (see reference for details of the Trials of Fog Signals), installed in Trevose Head Lighthouse, Cornwall in 1913.\n\nOne of the first automated fog bells was the Stevens Automatic Bell Striker.\n\nSome later fog bells were placed under water, particularly in especially dangerous areas, so that their sound (which would be a predictable code, such as the number \"23\") would be carried further and reverberate through the ship's hull. For example, this technique was used at White Shoal Light (Michigan). This was an earlier precursor to RACON.\n\nFrom the early 20th century an improved device called the diaphone, originally invented as an organ stop by Robert Hope-Jones, and developed as a fog signal by John Northey of Toronto, became the standard foghorn apparatus for new installations. Diaphones were powered by compressed air and could emit extremely powerful low-frequency notes.\n\nIn 1982, the Dutch broadcaster VPRO aired a live foghorn concert on national radio, relaying the sound of the foghorns in Emden, Calais, Nieuwpoort, Scheveningen, Den Helder, Lelystad, Urk, Marken and Kornwerderzand, mixed with studio music by sound artist Alvin Curran. \n\nSince automation of lighthouses became common in the 1960s and 1970s, most older foghorn installations have been removed to avoid the need to run the complex machinery associated with them, and have been replaced with electrically powered diaphragm or compressed air horns. Activation is completely automated: a laser or photo beam is shot out to sea, and if the beam reflects back to the source (i.e. the laser beam is visible due to the fog), the sensor sends a signal to activate the foghorn. In many cases, modern navigational aids have rendered large, long-range foghorns completely unnecessary, according to the International Association of Lighthouse Authorities.\n\nFog signals have also been used on railway lines since the middle of the 19th century to indicate to the driver of a moving train that a broken down train, a work party, or some other unforeseen hazard is on the line ahead. Small explosive detonators or torpedoes are placed on the track, and detonated by the pressure of the wheels of the oncoming train. The loud report of the explosion provides the indication to the driver, that in most cases requires the train to be stopped immediately. During World War II, these devices were modified to detonate demolition charges during railroad sabotage operations.\n\n\n"}
{"id": "44907259", "url": "https://en.wikipedia.org/wiki?curid=44907259", "title": "GPS2SMS", "text": "GPS2SMS\n\nThe GPS2SMS term describes the transfer of co-ordinates of an object or person by means of SMS text messaging. For this, the following applications are suitable:\n\nSMS messages can be sent from any device that has a GSM modem or phone and a GPS receiver. There are commercial handheld devices in the market, built-in systems for vehicles, software for computers or mobile devices, as well as some homebuilding projects, such as a small device that connects a mobile phone with a GPS.\n\nFor the detection of theft of a vehicle, a device may be used which sends an SMS alert to the monitor coordinates of the object, as soon as it leaves a particular area.\n\n"}
{"id": "925631", "url": "https://en.wikipedia.org/wiki?curid=925631", "title": "Garden design", "text": "Garden design\n\nGarden design is the art and process of designing and creating plans for layout and planting of gardens and landscapes. Garden design may be done by the garden owner themselves, or by professionals of varying levels of experience and expertise. Most professional garden designers have some training in horticulture and the principles of design. Garden designer, Rev David Coles, further elaborated this definition at the Chelsea Flower Show (2018, BBC1, Chelsea) by stating that good garden design, while being on the one hand a “serious discipline” should embody a “playful creative mindfulness”. He postulates that successful garden designs enable transcendence from a physical sensory experience to a mindful awareness of being interconnected with nature. \nSome are also landscape architects, a more formal level of training that usually requires an advanced degree and often a state license. Amateur gardeners may also attain a high level of experience from extensive hours working in their own gardens, through casual study, serious study in Master Gardener Programs, or by joining gardening clubs.\n\nWhether gardens are designed by a professional or an amateur, certain principles form the basis of effective garden design, resulting in the creation of gardens to meet the needs, goals, and desires of the users or owners of the gardens.\n\nElements of garden design include the layout of hard landscape, such as paths, walls, water features, sitting areas and decking; as well as the plants themselves, with consideration for their horticultural requirements, their season-to-season appearance, lifespan, growth habit, size, speed of growth, and combinations with other plants and landscape features. Consideration is also given to the maintenance needs of the garden, including the time or funds available for regular maintenance, which can affect the choice of plants in terms of speed of growth, spreading or self-seeding of the plants, whether annual or perennial, and bloom-time, and many other characteristics.\n\nImportant considerations in the garden design include how the garden will be used, the desired stylistic genre (formal or informal, modern or traditional etc.), and the way the garden space will connect to the home or other structures in the surrounding areas. All of these considerations are subject to the limitations of the prescribed budget.\n\nA garden's location can have a substantial influence on its design. Topographical landscape features such as steep slopes, vistas, hills, and outcrops may suggest or determine aspects of design such as layout and can be used and augmented in order to create a particular impression. The soils of the site will affect what types of plant may be grown, as will the garden's climate zone and various microclimates. The locational context of the garden can also influence its design. For example, an urban setting may require a different design style In contrast to a rural one. Similarly, a windy coastal location may necessitate a different treatment compared to a sheltered inland site.\n\nThe quality of a garden's soil can have a significant influence on a garden's design and its subsequent success. Soil influences the availability of water and nutrients, the activity of soil micro-organisms, and temperature within the root zone, and thus may have a determining effect on the types of plants which will grow successfully in the garden. However, soils may be replaced or improved in order to make them more suitable.\n\nTraditionally, garden soil is improved by amendment, the process of adding beneficial materials to the native subsoil and particularly the topsoil. The added materials, which may consist of compost, peat, sand, mineral dust, or manure, among others, are mixed with the soil to the preferred depth. The amount and type of amendment may depend on many factors, including the amount of existing soil humus, the soil structure (clay, silt, sand, loam etc.), the soil acidity/alkalinity, and the choice of plants to be grown. One source states that, \"conditioning the soil thoroughly before planting enables the plants to establish themselves quickly and so play their part in the design.\" However, not all gardens are, or should be, amended in this manner, since many plants prefer an impoverished soil. In this case, poor soil is better than a rich soil that has been artificially enriched.\n\nThe design of a garden can be affected by the nature of its boundaries, both external and internal, and in turn the design can influence the boundaries, including via creation of new ones. Planting can be used to modify an existing boundary line by softening or widening it. Introducing internal boundaries can help divide or break up a garden into smaller areas.\n\nThe main types of boundary within a garden are hedges, walls and fences. A hedge may be evergreen or deciduous, formal or informal, short or tall, depending on the style of the garden and purpose of the boundary. A wall has a strong foundation beneath it at all points, and is usually - but not always - built from brick, stone or concrete blocks. A fence differs from a wall in that it is anchored only at intervals, and is usually constructed using wood or metal (such as iron or wire mesh).\n\nBoundaries may be constructed for several reasons: to keep out livestock or intruders, to provide privacy, to create shelter from strong winds and provide microclimates, to screen unattractive structures or views, and to create an element of surprise.\n\nIn temperate western gardens, a smooth expanse of lawn is often considered essential to a garden. However garden designers may use other surfaces, for example those \"made up of loose gravel, small pebbles, or wood chips\" in order to create a different appearance and feel. Designers may also utilise the contrast in texture and color between different surfaces in order to create an overall pattern in the design.\n\nSurfaces for paths and access points are chosen for practical as well as aesthetic reasons. Issues such as safety, maintenance and durability may need to be considered by the designer. Gardens designed for public access need to cope with heavier foot traffic and hence may utilise surfaces – such as resin-bonded gravel – that are rarely used in private gardens.\n\nPlanting design requires design talent and aesthetic judgement combined with a good level of horticultural, ecological and cultural knowledge. It includes two major traditions: formal rectilinear planting design (Persia and Europe); and formal asymmetrical (Asia) and naturalistic planting design.\n\nPersian gardens are credited with originating aesthetic and diverse planting design. A correct Persian garden will be divided into four sectors with water being very important for both irrigation and aesthetics. The four sectors symbolize the Zoroastrian elements of sky, earth, water and plants. Planting in ancient and Medieval European gardens was often a mix of herbs for medicinal use, vegetables for consumption, and flowers for decoration. Purely aesthetic planting layouts developed after the Medieval period in , as are shown in late-renaissance paintings and plans. The designs of the Italian Renaissance garden were geometrical and plants were used to form spaces and patterns. The gardens of the French Renaissance and Baroque Garden à la française era continued the 'formal garden' planting aesthetic.\n\nIn Asia the asymmetrical traditions of planting design in Chinese gardens and Japanese gardens originated in the Jin Dynasty (265–420) of China. The gardens' plantings have a controlled but naturalistic aesthetic. In Europe the arrangement of plants in informal groups developed as part of the English Landscape Garden style, and subsequently the French landscape garden, and was strongly influenced by the picturesque art movement.\n\nA planting plan gives specific instructions, often for a contractor about how the soil is to be prepared, what species are to be planted, what size and spacing is to be used and what maintenance operations are to be carried out under the contract. Owners of private gardens may also use planting plans, not for contractual purposes, as an aid to thinking about a design and as a record of what has been planted. A planting strategy is a long term strategy for the design, establishment and management of different types of vegetation in a landscape or garden.\n\nPlanting can be established by directly employed gardeners and horticulturalists or it can be established by a landscape contractor (also known as a landscape gardener). Landscape contractors work to drawings and specifications prepared by garden designers or landscape architects.\n\nGarden furniture may range from a \"patio set\" consisting of a table, four or six chairs and a parasol, through benches, swings, various lighting, to stunning artifacts in brutal concrete or weathered oak. Patio heaters, that run on bottled butane or propane, are often used to enable people to sit outside at night or in cold weather. A picnic table, is used for the purpose of eating a meal outdoors such as in a garden.\n\nThe materials used to manufacture modern patio furniture include stones, metals, vinyl, plastics, resins, glass, and treated woods.\n\nWhile sunlight is not always easily controlled by the gardener, it is an important element of garden design. The amount of available light is a critical factor in determining what plants may be grown. Sunlight will, therefore, have a substantial influence on the character of the garden. For example, a rose garden is generally not successful in full shade, while a garden of hostas may not thrive in hot sun. As another example, a vegetable garden may need to be placed in a sunny location, and if that location is not ideal for the overall garden design goals, the designer may need to change other aspects of the garden.\n\nIn some cases, the amount of available sunlight can be influenced by the gardener. The location of trees, other shade plants, garden structures, or, when designing an entire property, even buildings, might be selected or changed based on their influence in increasing or reducing the amount of sunlight provided to various areas of the property.\n\nIn other cases, the amount of sunlight is not under the gardener's control. Nearby buildings, plants on other properties, or simply the climate of the local area, may limit the available sunlight. Or, substantial changes in the light conditions of the garden may not be within the gardener's means. In this case, it is important to plan a garden that is compatible with the existing light conditions.\n\nGarden lighting can be an important aspect of garden design. In most cases, various types of lighting techniques may be classified and defined by heights: safety lighting, uplighting, and downlighting. Safety lighting is the most practical application. However, it is more important to determine the type of lamps and fittings needed to create the desired effects. Light regulates three major plant processes: photosynthesis, phototropism, and photoperiodism.\n\nPhotosynthesis provides the energy required to produce the energy source of plants.\n\nPhototropism is the effect of light on plant growth that causes the plant to grow toward or away from the light. Photoperiodism is a plant’s response or capacity to respond to photoperiod, a recurring cycle of light and dark periods of constant length.\n\nGarden design, and the Islamic garden tradition, began with creating the Paradise garden in Ancient Persia, in Western Asia. It evolved over the centuries, and in the different cultures Islamic dynasties came to rule in Central— South Asia, the Near East, North Africa, and the Iberian Peninsula.\n\nSome styles and examples include:\n\nGarden design history and precedents from the Mediterranean region include:\n\nA formal garden in the Persian garden and European garden design traditions is rectilinear and axial in design. The equally formal garden, without axial symmetry (asymmetrical) or other geometries, is the garden design tradition of Chinese gardens and Japanese gardens. The Zen garden of rocks, moss and raked gravel is an example. The Western model is an ordered garden laid out in carefully planned geometric and often symmetrical lines. Lawns and hedges in a formal garden need to be kept neatly clipped for maximum effect. Trees, shrubs, subshrubs and other foliage are carefully arranged, shaped and continually maintained. A French garden or Garden à la française, is a specific kind of formal garden, laid out in the manner of André Le Nôtre; it is centered on the façade of a building, with radiating avenues and paths of gravel, lawns, parterres and pools (\"bassins\") of reflective water enclosed in geometric shapes by stone coping, with fountains and sculpture.\n\nThe Garden à la française style has origins in fifteenth-century Italian Renaissance gardens, such as the Villa d'Este, Boboli Gardens, and Villa Lante in Italy. The style was brought to France and expressed in the gardens of the French Renaissance. Some of the earliest formal parterres of clipped evergreens were those laid out at Anet by Claude Mollet, the founder of a dynasty of nurserymen-designers that lasted deep into the 18th century. The Gardens of Versailles are an ultimate example of Garden à la française, composed of many different distinct gardens, and designed by André Le Nôtre.\n\nEnglish Renaissance gardens in a rectilinear formal design were a feature of the stately homes. The introduction of the parterre was at Wilton House in the 1630s. In the early eighteenth century, the publication of Dezallier d'Argenville, \" La théorie et la pratique du jardinage\" (1709) was translated into English and German, and was the central document for the later formal gardens of Continental Europe.\n\nTraditional formal Spanish garden design evolved with Persian garden and influences. The internationally renowned Alhambra and Generalife in Granada, built in the Moorish Al-Andalus era, have influenced design for centuries. The Ibero-American Exposition of 1929 World's Fair in Seville, Spain was located in the celebrated Maria Luisa Park (\"Parque de Maria Luisa\") designed by Jean-Claude Nicolas Forestier.\n\nFormal gardening in the Italian and French manners was reintroduced at the turn of the twentieth century. Beatrix Farrand's formal Italian garden areas at Dumbarton Oaks in Washington, D.C., and Achille Duchêne's restored French water parterre at Blenheim Palace in England are examples of the modern formal garden. The Conservatory Garden in Central Park of New York City features a formal garden, as do many other parks and estates such as Filoli in California.\n\nThe simplest formal garden would be a box-trimmed hedge lining or enclosing a carefully laid out flowerbed or garden bed of simple geometric shape, such as a knot garden. The more developed and elaborate formal gardens contain statuary and fountains.\nFeatures in a formal garden may include:\n\nThe English Landscape Garden style practically swept away the geometries of earlier English and European Renaissance formal gardens. William Kent and Lancelot \"Capability\" Brown were leading proponents, among many other designers. The naturalistic English Garden style (French:\" Jardin anglais\", Italian: \"Giardino all'inglese\", German: \"Englischer Landschaftsgarten\") of the 1730s and on transformed private and civic garden design across Europe. The French Landscape Garden subsequently continued the style's development on the Continent.\n\nA cottage garden uses an informal design, traditional materials, dense plantings, and a mixture of ornamental and edible plants. Cottage gardens go back many centuries, but their popularity grew in 1870s England in response to the more structured Victorian English estate gardens that used restrained designs with massed beds of brilliantly colored greenhouse annuals. They are more casual by design, depending on grace and charm rather than grandeur and formal structure. The influential British garden authors and designers, William Robinson at Gravetye Manor in Sussex, and Gertrude Jekyll at Munstead Wood in Surrey, both wrote and gardened in England. Jekyll's series of thematic gardening books emphasized the importance and value of natural plantings were an influence in Europe and the United States. Also influential half a century later was Margery Fish, whose surviving garden at East Lambrook Manor emphasizes, among other things, native plant life and the natural patterns produced by self-spreading and self-seeding.\n\nThe earliest cottage gardens were far more practical than modern versions—with an emphasis on vegetables and herbs, along with fruit trees, beehives, and even livestock if land allowed. Flowers were used to fill any spaces in between. Over time, flowers became more dominant. Modern day cottage gardens include countless regional and personal variations of the more traditional English cottage garden.\n\nThe traditional kitchen garden, also known as a potager, is a seasonally used space separate from the rest of the residential garden – the ornamental plants and lawn areas. Most vegetable gardens are still miniature versions of old family farm plots with square or rectangular beds, but the kitchen garden is different not only in its history, but also its design.\n\nThe kitchen garden may be a landscape feature that can be the central feature of an ornamental, all-season landscape, but can be little more than a humble vegetable plot. It is a source of herbs, vegetables, fruits, and flowers, but it is also a structured garden space, a design based on repetitive geometric patterns.\n\nThe kitchen garden has year-round visual appeal and can incorporate permanent perennials or woody plantings around (or among) the annual plants.\n\nA Shakespeare garden is a themed garden that cultivates plants mentioned in the works of William Shakespeare. In English-speaking countries, particularly the United States, these are often public gardens associated with parks, universities, and Shakespeare festivals. Shakespeare gardens are sites of cultural, educational, and romantic interest and can be locations for outdoor weddings.\n\nSigns near the plants usually provide relevant quotations. A Shakespeare garden usually includes several dozen species, either in herbaceous profusion or in a geometric layout with boxwood dividers. Typical amenities are walkways and benches and a weather-resistant bust of Shakespeare. Shakespeare gardens may accompany reproductions of Elizabethan architecture. Some Shakespeare gardens also grow species typical of the Elizabethan period but not mentioned in Shakespeare's plays or poetry.\n\nA rock garden, also known as a rockery or an alpine garden, is a type of garden that features extensive use of rocks or stones, along with plants native to rocky or alpine environments.\n\nRock garden plants tend to be small, both because many of the species are naturally small, and so as not to cover up the rocks. They may be grown in troughs (containers), or in the ground. The plants will usually be types that prefer well-drained soil and less water.\n\nThe usual form of a rock garden is a pile of rocks, large and small, aesthetically arranged, and with small gaps between, where the plants will be rooted. Some rock gardens incorporate bonsai.\n\nSome rock gardens are designed and built to look like natural outcrops of bedrock. Stones are aligned to suggest a bedding plane and plants are often used to conceal the joints between the stones. This type of rock garden was popular in Victorian times, often designed and built by professional landscape architects. The same approach is sometimes used in modern campus or commercial landscaping, but can also be applied in smaller private gardens.\n\nThe Japanese rock garden, in the west often referred to as \"Zen garden\", is a special kind of rock garden which contains few plants.\nRock gardens have become increasingly popular as landscape features in tropical countries such as Thailand. The combination of wet weather and heavy shade trees, along with the use of heavy plastic liners to stop unwanted plant growth, has made this type of arrangement ideal for both residential and commercial gardens due to its easier maintenance and drainage.\n\nNatural landscaping, also called native gardening, is the use of native plants, including trees, shrubs, groundcover, and grasses which are indigenous to the geographic area of the garden.\n\nNatural landscaping is adapted to the climate, geography and hydrology and should require no pesticides, fertilizers and watering to maintain, given that native plants have adapted and evolved to local conditions over thousands of years. However, these applications may be necessary for some preventive care of trees and other vegetation in areas of degraded or weedy landscapes.\n\nNative plants suit today's interest in \"low-maintenance\" gardening and landscaping, with many species vigorous and hardy and able to survive winter cold and summer heat. Once established, they can flourish without irrigation or fertilization, and are resistant to most pests and diseases.\n\nMany municipalities have quickly recognized the benefits of natural landscaping due to municipal budget constraints and reductions and the general public is now benefiting from the implementation of natural landscaping techniques to save water and create more personal time.\n\nNative plants provide suitable habitat for native species of butterflies, birds, pollinators, and other wildlife. They provide more variety in gardens by offering myriad alternatives to the often planted introduced species, cultivars, and invasive species. The indigenous plants have co-evolved with animals, fungi and microbes, to form a complex network of relationships. They are the foundation of their native habitats and ecosystems, or natural communities.\n\nSuch gardens often benefit from the plants being evolved and habituated to the local climate, pests and herbivores, and soil conditions, and so may require fewer to no soil amendments, irrigation, pesticides, and herbicides for a lower maintenance, more sustainable landscape.\n\nJapanese and Korean gardens, originally influenced by Chinese gardens, can be found at Buddhist temples and historic sites, private homes, in neighborhood or city parks, and at historical landmarks such as Buddhist temples. Some of the Japanese gardens most famous in the Western world and Japan are gardens in the \"karesansui\" (rock garden) tradition. The Ryōan-ji temple garden is a well-known example. There are Japanese gardens of various styles, with plantings and often evoking \"wabi sabi\" simplicity. In Japanese culture, garden-making is a high art, intimately linked to the arts of calligraphy and ink painting.\n\nThe contemporary style garden has gained popularity in the UK in the last 10 years. This is partly due to the increase of modern housing with small gardens as well as the cultural shift towards contemporary design . This style of garden can be defined by the use 'clean' design lines, with focus on hard landscaping materials like stone, hardwood, rendered walls. Planting style is bold but simple with the use of drifts of one or two plants that repeat throughout the design. Grasses are a very popular choice for this style of design. Lighting effects also play an integral role in the modern garden. Subtle lighting effects can be achieved with the use of carefully placed low voltage LED lights incorporated into paving and walls.\n\nA residential or private domestic garden, is the most common form of garden and is in proximity to a residence, such as the 'front garden' or 'back garden'. The front garden may be a formal and semi-public space and so subject to the constraints of convention and local laws. While typically found in the yard of the residence, a garden may also be established on a roof, in an atrium or courtyard, on a balcony, in windowboxes, or on a patio. Residential gardens are typically designed at human scale, as they are most often intended for private use. However, the garden of a great house or a large estate may be larger than a public park.\n\nResidential gardens may feature specialized gardens, such as those for exhibiting one particular type of plant, or special features, such as rockery or water features. They are also used for growing herbs and vegetables and are thus an important element of sustainability.\n\n"}
{"id": "53452291", "url": "https://en.wikipedia.org/wiki?curid=53452291", "title": "Geography of aging", "text": "Geography of aging\n\nGeography of aging or gerontological geography is an emerging field of knowledge of Human Geography that analyzes the socio-spatial implications of aging of the population from the understanding of the relationships between the physical-social environment and the elderly, at different scales, micro (City, region, country), etc.\n\nSince the 1970s in a number of developed countries such as the United States, Canada, the United Kingdom, Germany, Sweden, France, Spain, Australia, New Zealand and Japan, there have been increasing studies focusing on the understanding of spatial patterns of aging population, as well as aspects related to residential changes and provision of health and social services. Among the geographers of aging is S. Harper, who identified the phenomenon of aging associated with the social construction of old age and the processes of residential mobility of this group to the urban periphery, mainly nursing homes and sheltered housing.\n\nThe contribution of geographers of aging, such as Graham D. Rowles, SM. Golant, S. Harper, G. Laws, are contributing to environmental gerontology by understanding the environmental aspects of gerontology in developed and developing countries. Also in Spain, some geographers, such as Gloria Fernández-Mayoralas, Fermina Rojo-Pérez and Vicente Rodríguez-Rodríguez, have made outstanding contributions to the study of residential strategies, access to health services, and, in general, quality of Life of the elderly, as well as the impacts of Northern European retirees on the Costa del Sol (Spain).\n\nIn Latin America and Spain, Diego Sánchez-González has shed light on the deepening of issues such as the physical-built and social environment and the quality of life of the elderly; the importance of the natural environment (therapeutic natural landscape) on active and healthy aging in the place; residential strategies for the maintenance of the elderly in the communities; the socio-environmental vulnerability of the elderly in the face of climate change; as well as issues related to the attachment to the place (identity and public space); elderly people with disabilities and social exclusion; leisure and tourism of elderly; and the planning of gerontological and geriatric services.\n\n"}
{"id": "392831", "url": "https://en.wikipedia.org/wiki?curid=392831", "title": "Hinterland", "text": "Hinterland\n\nHinterland is a German word meaning \"the land behind\" (a city, a port, or similar). The term's use in English was first documented by geographer George Chisholm in his \"Handbook of Commercial Geography\" (1888).\n\nThe term \"hinterland\" has several meanings. It may refer to:\n\n\nA further sense in which the term is commonly applied, especially by British politicians, is in talking about an individual's depth and breadth of knowledge of other matters (or lack thereof), specifically of academic, artistic, cultural, literary and scientific pursuits. For instance, one could say, \"X has a vast hinterland\", or \"Y has no hinterland\". The spread of this usage is usually credited to Denis Healey (British Defence Secretary 1964–1970, Chancellor of the Exchequer 1974–1979) and his wife Edna Healey, initially in the context of the supposed lack of hinterland of former Prime Minister Margaret Thatcher.\n"}
{"id": "6709094", "url": "https://en.wikipedia.org/wiki?curid=6709094", "title": "Hunter Industries", "text": "Hunter Industries\n\nHunter Industries is a manufacturer of irrigation equipment for the landscaping and golf course industries, based in San Marcos, California. They are the second largest employer in San Marcos after the San Marcos Unified School District\n\nHunter produces pop-up gear-driven rotors, spray sprinklers, valves, controllers, central controllers and weather sensors. The company reports that it holds more than 250 product patents and 40 trademarks, and conducts business in 125 countries. The company was founded in 1981 by Edwin J. Hunter and Paul M. Hunter, to produce a compact landscape sprinkler called the \"PGP\" (an acronym meaning \"professional gear-driven pop-up\"), the first sprinkler to utilize \"matched-precipitation\" regardless of the radii or arc. The former president and CEO was Richard E. Hunter, Edwin’s son. Richard's son, Greg Hunter, is the current president.\n\nHunter Industries products are used in a wide array of locations including sports stadiums, national landmarks, hotels, and city parks. They also offer products in several other industries, such as customer manufacturing, landscape lighting (through its acquisition of FX Luminaire in 2009), and the medical industry. They operate manufacturing facilities in both San Marcos, California, and Tijuana, Mexico as well as having overseas offices located in China. They previously operated a manufacturing plant in Cary, NC, from 1992 to 2009, the plant closed due to poor market conditions at the time.\n\nIn 2016, the Center for Executive Excellence (CEE) recognized Hunter Industries as one of twelve companies that excelled in promoting a successful business culture.\n\nOn June 16, 2017 Hunter industries acquired Dispensing Dynamics International from Kinderhook Industries. This acquisition marks Hunter Industries' first major foray into a market unrelated to irrigation or landscape products.\n\nOn January 4, 2016 Hunter Industries acquired Florida-based Senninger Irrigation. The two companies have been strategic partners since 2004. On June 24, 2015 the firm acquired all landscape irrigation products, patents, and trademarks from Alex-Tronix Controls.\n\nIn 2009 it acquired landscape lighting company FX Luminaire, and in 2008 it acquired custom molding company Grizzle & Hunter Plastics LLC., now re-branded as Hunter Custom Manufacturing.\n\nIn 2007 Hunter acquired the MP Rotator product line from Walla Walla Sprinkler company through an agreement with Nelson Irrigation Corporation. In 1999 it acquired the Legacy Golf irrigation product line from Buckner Incorporated.\n\nAs part of the increased focus on environmental sustainability in the irrigation industry, Hunter Industries has rolled out new and more eco-friendly sprinkler's, including the \"MP800SR Rotator\" (short range) and new dripline and subsurface irrigation offerings such as the \"eco-mat\".\n\nOn October 26, 2003 a fire was started at the main location of Hunter Industries likely by a disgruntled employee or ex-employee, though no one was ever prosecuted for the crime. The fire caused damage to inventory and production areas of the plant, and caused the company to undergo major rebuilding. Fires had been started in 8 locations of the building using accelerants. Total losses reported due to the fire was $17 million USD.\n\n"}
{"id": "24937024", "url": "https://en.wikipedia.org/wiki?curid=24937024", "title": "Kilometric point", "text": "Kilometric point\n\nA \"kilometric point\" (, ; PK) is a term used in metricated areas, especially in France and Spain, to provide reference points alongside a transport route such as a road, a railway line or a canal. It is calculated according to the distance in kilometres from a fixed commencement point. In the English-speaking world, its equivalent would be milepost or mile marker.\n"}
{"id": "23797849", "url": "https://en.wikipedia.org/wiki?curid=23797849", "title": "Laminar sublayer", "text": "Laminar sublayer\n\nThe laminar sublayer, also called the viscous sublayer, is the region of a mainly-turbulent flow that is near a no-slip boundary and in which the flow is laminar. As such, it is a type of boundary layer. The existence of the laminar sublayer can be understood in that the flow velocity decreases towards the no-slip boundary. Because of this, the Reynolds number decreases until at some point the flow crosses the threshold from turbulent to laminar.\n\nThe laminar sublayer is important for river-bed ecology: below the laminar-turbulent interface, the flow is stratified, but above it, it rapidly becomes well-mixed. This threshold can be important in providing homes and feeding grounds for benthic organisms.\n\nWhether the roughness due to the bed sediment or other factors are smaller or larger than this sublayer has an important bearing in hydraulics and sediment transport. Flow is defined as hydraulically rough if the roughness elements are larger than the laminar sublayer (thereby perturbing the flow), and as hydraulically smooth if they are smaller than the laminar sublayer (and therefore ignorable by the main body of the flow).\n"}
{"id": "38263069", "url": "https://en.wikipedia.org/wiki?curid=38263069", "title": "Land systems of Western Australia", "text": "Land systems of Western Australia\n\nLand systems of Western Australia are systematic land resource concepts, where the tying in of geographical, geological, and ecological data is processed to provide land planning and land management systems with sets of information that can process large areas of land in terms of agricultural and other usages.\n\nAt times land systems are not referred to directly, but used within terms of \"land resources\" and \"landform resources\" analysis and appraisal. The government departments from which reports and papers emanate include the Agricultural and Mining departments, as well as Land administration bodies.\n\n"}
{"id": "3282051", "url": "https://en.wikipedia.org/wiki?curid=3282051", "title": "Landscape Institute", "text": "Landscape Institute\n\nThe Landscape Institute (LI) is a British professional body for landscape architects. Founded in 1929 as the Institute of Landscape Architects, it was granted a Royal Charter in 1997. The Institute aims to promote landscape architecture, and to regulate the profession with a code of conduct that members must abide by. As of June 2013, it has 6,000 members, 3,300 of whom are chartered.\n\nIt publishes the professional journal \"Landscape\" (formerly \"Landscape Design\"), and is a member of the International Federation of Landscape Architects. \n\nThe growth of landscape architecture has been led by government legislation since the 1940s, such as the New Towns Act (1946) which required landscape masterplans to be prepared, and the European Environmental Impact Assessment Directive EIA Directive (85/337/EEC) (1985) which has led to the increase in environmental impact assessments. From the 1950s to the 1980s, the public sector, particularly local authorities, were the largest employers of landscape architects, with a minority working in private practice. Today the private sector is the larger employer, although the largest single employer of landscape architects in the UK are the charitable Groundwork Trusts. \n\nThomas Mawson was the first President of the Institute of Landscape Architects (ILA) in 1929, and also one of the first professionals in the UK (along with Patrick Geddes) to use 'landscape architect' as a professional title. Before becoming President of the ILA, Mawson had been a President of the Town Planning Institute. His own career had developed from garden design to urban design.\n\nLI members include landscape designers, landscape managers, landscape planners, landscape scientists and urban designers. \nThe Affiliate membership category is an open category with minimal requirements. To become a professional member, however, candidates must first have completed an LI accredited university course or alternatively be assessed as a special case for admission as a \"Licentiate\". Following this they proceed along the Pathway to Chartership (P2C), a mentored and supervised programme of learning which culminates in an interview with two examiners who are senior members of the profession, once the candidate has attained an agreed level of competency. This process was formerly known as 'Part IV' of the Landscape Institute's own design examination. Parts I to III were replaced by the system of accredited degree courses in the mid 1980s. \n\nOnly fully qualified members of the LI are permitted to use the protected title 'Chartered Member of the Landscape Institute' and the designation 'CMLI'. Chartered membership of the LI is accepted throughout Europe, The USA, Australia, New Zealand and Canada . while many countries who lack their own chartered professional body for Landscape Architects recognised as a badge of excellence. In May 2009 there were just under 6,000 members of the institute of which 3,000 were chartered.\n\nIn 2008, the LI, supported by CABE launched a campaign, projected to run for five years, to increase the number of Landscape Architects in the UK. Entitled \"I want to be a landscape architect\", it has its own website, and focuses on increasing the number of postgraduate and undergraduate students taking LI accredited courses.\n\nThe LI is one of the steering group partners of Neighbourhoods Green a partnership initiative which works with social landlords and housing associations to highlight the importance of, and raise the overall quality of design and management for, open and green space in social housing.\n\n\n"}
{"id": "21003502", "url": "https://en.wikipedia.org/wiki?curid=21003502", "title": "List of firsts in the Geographic North Pole", "text": "List of firsts in the Geographic North Pole\n\nThis is a list of firsts in the Geographic North Pole.\n\n"}
{"id": "1760214", "url": "https://en.wikipedia.org/wiki?curid=1760214", "title": "List of natural phenomena", "text": "List of natural phenomena\n\nTypes of natural phenomena include:\n\nWeather, fog, thunder, tornadoes; biological processes, decomposition, germination; physical processes, wave propagation, erosion; tidal flow, and natural disasters such as electromagnetic pulses, volcanic eruptions, and earthquakes.\n\n\n\nGeological processes include erosion, sedimentation, and volcanic activities such as geysers and earthquakes.\n\nViolent meteorological phenomena are called storms. Regular, cyclical phenomena include seasons and atmospheric circulation. Climate change is often semi-regular.\n\n\n\n"}
{"id": "16563341", "url": "https://en.wikipedia.org/wiki?curid=16563341", "title": "List of political and geographic subdivisions by total area in excess of 200,000 square kilometers", "text": "List of political and geographic subdivisions by total area in excess of 200,000 square kilometers\n"}
{"id": "46306107", "url": "https://en.wikipedia.org/wiki?curid=46306107", "title": "List of presidential trips made by Barack Obama during 2014", "text": "List of presidential trips made by Barack Obama during 2014\n\nThis is a list of presidential trips made by Barack Obama during 2014, the sixth year of his presidency as the 44th President of the United States.\n\nThis list excludes trips made within Washington, D.C., the U.S. federal capital in which the White House, the official residence and principal workplace of the President, is located. Additionally excluded are trips to Camp David, the country residence of the President, and to the private home of the Obama family in Kenwood, Chicago.\n"}
{"id": "11485690", "url": "https://en.wikipedia.org/wiki?curid=11485690", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: A", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: A\n\n\n"}
{"id": "11485898", "url": "https://en.wikipedia.org/wiki?curid=11485898", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: D", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: D\n\n\n"}
{"id": "9895080", "url": "https://en.wikipedia.org/wiki?curid=9895080", "title": "Local Notice to Mariners", "text": "Local Notice to Mariners\n\nA Local Notice to Mariners is an authoritative instruction issued by a designated official, typically the harbormaster.\n\nIn the United States, notices are issued by each U.S. Coast Guard District to disseminate important information affecting navigational safety within that District. This Notice reports changes and deficiencies in aids to navigation maintained by the Coast Guard. Other marine information such as new charts, channel depths, naval operations, and regattas is included. Since temporary information of short duration is not included in the weekly Notice to Mariners, the \"Local Notice to Mariners\" may be the only source of such information. Small craft using the Intracoastal Waterway and small harbors not normally used by oceangoing vessels need it to keep charts and publications up-to-date.\n\nSince correcting information for U.S. charts in the \"Notice to Mariners\" is obtained from the Coast Guard Local Notices, it is normal to expect a lag of 1 or 2 weeks for the \"Notice to Mariners\" to publish a correction from this source.\n\nThe \"Local Notice to Mariners\" may be obtained free of charge by contacting the appropriate Coast Guard District Commander. Vessels operating in ports and waterways in several districts must obtain the \"Local Notice to Mariners\" from each district. \n\nThe text of the US material originated from section 422 of The American Practical Navigator, a document produced by the government of the United States of America.\n\nLNTMs are, by definition, concerned with local issues. Each issuing authority has its own series of LNTMs – there is no international standard numbering or indexing scheme. Individual LNTMs may concern short or long term situations. At Portsmouth, mariners are instructed by LNTM 28/07 to \"keep clear of warship berths\". At Holyhead, LNTM 5/2008 concerns \"Bunkering or transferring oil in port\". At Chichester, No 16 of 2008 \"Sea defence works at Hayling Island\" gives timely information about dredging operations.\n\n\n"}
{"id": "10528515", "url": "https://en.wikipedia.org/wiki?curid=10528515", "title": "Location intelligence", "text": "Location intelligence\n\nLocation intelligence (LI), or spatial intelligence, is the process of deriving meaningful insight from geospatial data relationships to solve a particular problem. It involves layering multiple data sets spatially and/or chronologically, for easy reference on a map, and its applications span industries, categories and organizations.\n\nMaps have been used to represent information throughout the ages, but what might be referenced as the first example of true location 'intelligence' was in London in 1854 when John Snow was able to debunk theories about the spread of cholera by overlaying a map of the area with the location of water pumps and was able to narrow the source to a single water pump. This layering of information over a map was able to identify relationships between different sets of geospatial data.\n\nLocation or geographical information system (GIS) tools enable spatial experts to collect, store, analyze and visualize data. Location intelligence experts can use a variety of spatial and business analytical tools to measure optimal locations for operating a business or providing a service. Location intelligence experts begin with defining the business ecosystem which has many interconnected economic influences. Such economic influences include but are not limited to culture, lifestyle, labor, healthcare, cost of living, crime, economic climate and education.\n\nThe term \"location intelligence\" is often used to describe the people, data and technology employed to geographically \"map\" information. These mapping applications can transform large amounts of data into color-coded visual representations that make it easy to see trends and generate meaningful intelligence. The creation of location intelligence is directed by domain knowledge, formal frameworks, and a focus on decision support. Location cuts across through everything i.e. devices, platforms, software and apps, and is one of the most important ingredient of understanding context in sync with social data, mobile data, user data, sensor data.\n\nLocation intelligence is also used to describe the integration of a geographical component into business intelligence processes and tools, often incorporating spatial database and spatial OLAP tools.\n\nIn 2012, Wayne Gearey from the real estate industry (JLL) offered the first applied course on location intelligence at the University of Texas at Dallas in which he defined location intelligence as the process for selecting the optimal location that will support workplace success and address a variety of business and financial objectives.\n\nPitney Bowes MapInfo Corporation describes location intelligence as follows: \"Spatial information, commonly known as \"Location\", relates to involving, or having the nature of where. Spatial is not constrained to a geographic location however most common business uses of spatial information deal with how spatial information is tied to a location on the earth. Miriam-Webster® defines Intelligence as \"The ability to learn or understand, or the ability to apply knowledge to manipulate one`s environment.\" Combining these terms alludes to how you achieve an understanding of the spatial aspect of information and apply it to achieve a significant competitive advantage.\"\n\nDefinition by ESRI is as follows: \"Location Intelligence is defined as the capacity to organize and understand complex data through the use of geographic relationships. LI organizes business and geographically referenced data to reveal the relationship of location to people, events, transactions, facilities, and assets.\"\n\nDefinition by Yankee Group within their White Paper \"Location Intelligence in Retail Banking: \"...a business management term that refers to spatial data visualization, contextualization and analytical capabilities applied to solve a business problem.\"\n\nNear defines location intelligence as the gamut of geo-spatial analytic models, algorithms, techniques and tools that harness location-indexed streaming and static data to provide requisite answers to questions around location such as the attributes of i) a place, ii) people visiting a place, and iii) products consumed at a place. Location intelligence platforms encapsulate these technologies, ingest relevant data sources, and provide it as data-as-a-service, or use it to power data-driven products.\n\nInstarea defines location intelligence as \"Using machine learning algorithms to uncover trends that would be otherwise unknown using human based rules in a large location data set.\"\n\nLocation intelligence is used by a broad range of industries to improve overall business results. Applications include:\n\n"}
{"id": "2960822", "url": "https://en.wikipedia.org/wiki?curid=2960822", "title": "Marsden square", "text": "Marsden square\n\nMarsden square mapping or Marsden squares is a system that divides a chart of the world with latitude-longitude gridlines (e.g. plate carrée projection, Mercator or other) between 80°N and 70°S latitudes (or 90°N and 80°S: refer chart at Ocean Teacher’s Ocean Geography page) into grid cells of 10° latitude by 10° longitude, each with a unique, numeric identifier. William Marsden, when first secretary of the Admiralty, conceived of this method for collecting and combining information respecting the oceans .\n\nOn the plate carrée projection the grid cells appear square, however if the Mercator projection is used, the grid cells appear “stretched” vertically nearer the tops and bottoms of the map.\n\nOn the actual surface of the Globe, the cells are approximately “square” only adjacent to the equator, and become progressively narrower and tapered (also with curved northern and southern boundaries) as they approach the poles, and cells adjoining the poles are unique in possessing three faces rather than four.\n\nEach one of the 540 10°x10° squares is allocated a number from 1 to 288 and from 300 to 551 (see image to the right), plus the sequence extends to 936 in higher latitudes, and then can also be subdivided into 100 one-degree squares numbered from 00 to 99 in order to improve accuracy.\n\nMarsden squares have mostly been used for identifying the geographic position of meteorological data, and are described further in various publications of the World Meteorological Organization (WMO). The 10°x10° square identifiers typically use a minimal number of characters (between 1 and 3 digits) which was/is an operational advantage for low bandwidth transmission systems.\n\nHowever the rules for allocating numbers to squares do not follow a consistent pattern, so that reverse-engineering (decoding) the relevant square boundaries from any particular Marsden Square identifier is not particularly straightforward (a look-up table is probably the simplest in practice).\n\nSlightly confusingly, an alternative (and more consistent), four-digit notation for global 10°x10° squares is actually known as World Meteorological Organization squares but does not seem to be actively promoted by the WMO itself. \n"}
{"id": "18116860", "url": "https://en.wikipedia.org/wiki?curid=18116860", "title": "Most Ancient European Towns Network", "text": "Most Ancient European Towns Network\n\nThe Most Ancient European Towns Network is a working group of the oldest cities in Europe. It was founded in 1994, with the idea coming from the town of Argos in Greece, presented to the European Union. The group exists to discuss issues such as archaeological research, tourism and incorporating monuments into urban planning.\n\nThe members include the following cities. The chairmanship of the group rotates between the members.\n\n\nThe first meeting was held on 22–26 June 1994.\n\n"}
{"id": "21994", "url": "https://en.wikipedia.org/wiki?curid=21994", "title": "Navigation research", "text": "Navigation research\n\nWhereas originally the term Navigation applies to the process of directing a ship to a destination, Navigation research deals with fundamental aspects of navigation in general. It can be defined as \"The process of determining and maintaining a course or trajectory to a goal location\" (Franz, Mallot, 2000).\nIt concerns basically all moving agents, biological or artificial, or remote-controlled.\n\nFranz and Mallot proposed a navigation hierarchy in \"Robotics and Autonomous Systems 30\" (2006):\nThere are two basic methods for navigation:\n\n\nIn human navigation people visualize different routes in their minds to plan how to get from one place to another. The things which they rely on to plan these routes vary from person to person and are the basis of the differing navigational strategies.\nSome people use measures of distance and absolute directional terms (north, south, east, and west) in order to visualize the best pathway from point to point. The use of these more general, external cues as directions is considered part of an allocentric navigation strategy. Allocentric navigation is typically seen in males and is beneficial primarily in large and/or unfamiliar environments. This likely has some basis in evolution when males would have to navigate through large and unfamiliar environments while hunting. The use of allocentric strategies when navigating primarily activates the hippocampus and parahippocampus in the brain. This navigation strategy relies more on a mental, spatial map than visible cues, giving it an advantage in unknown areas but a flexibility to be used in smaller environments as well. The fact that it is mainly males that favor this strategy is likely related to the generalization that males are better navigators than females as it is better able to be applied in a greater variety of settings.\n\nEgocentric navigation relies on more local landmarks and personal directions (left/right) to navigate and visualize a pathway. This reliance on more local and well-known stimuli for finding their way makes it difficult to apply in new locations, but is instead most effective in smaller, familiar environments. Evolutionarily, egocentric navigation likely comes from our ancestors who would forage for their food and need to be able to return to the same places daily to find edible plants. This foraging usually occurred in relatively nearby areas and was most commonly done by the females in hunter-gatherer societies. Females, today, are typically better at knowing where various landmarks are and often rely on them when giving directions. Egocentric navigation causes high levels of activation in the right parietal lobe and prefrontal regions of the brain that are involved in visuospatial processing.\n\nOutdoor robots can use GPS in a similar way to automotive navigation systems.\nAlternative systems can be used with floor plan instead of maps for indoor robots, combined with localization wireless hardware.\n\n\n"}
{"id": "648077", "url": "https://en.wikipedia.org/wiki?curid=648077", "title": "ONS coding system", "text": "ONS coding system\n\nIn the United Kingdom, the Office for National Statistics maintains a series of codes to represent a wide range of geographical areas of the UK, for use in tabulating census and other statistical data. These codes are referred to as ONS codes or GSS codes referring to the \"Government Statistical Service\" of which ONS is part.\n\nThe previous hierarchical system of codes has been replaced as from January 2011 by a nine-character code for all types of geography, in which there is no relation between the code for a lower-tier area and the corresponding parent area. The older coding system has now been phased out.\n\nInformation from the 2011 Census is published for a wide variety of geographical units. These areas include:\n\n\nSuper Output Areas (SOAs) are a set of geographical areas developed following the 2001 census, initially to facilitate the calculation of the Indices of Deprivation 2004 and subsequently for a range of additional Neighbourhood Statistics (NeSS). The aim was to produce a set of areas of consistent size, whose boundaries would not change (unlike electoral wards), suitable for the publication of data such as the Indices of Deprivation. They are an aggregation of adjacent Output Areas with similar social characteristics. Lower Layer Super Output Areas (LSOAs) typically contain 4 to 6 OAs with a population of around 1500. Middle Layer Super Output Areas (MSOAs) on average have a population of 7,200. The hierarchy of Output Areas and the two tiers of Super Output Areas have become known as the Neighbourhood Statistics Geography.\n\nThe older ONS code was constructed top down: \nFor example, codice_1 for Cambridgeshire.\nFor example, codice_2 for Cambridge district or codice_3 for Fenland.\nFor example, codice_4 for Greenwich (London Borough) or codice_5 for Middlesbrough.\nFor example, codice_6 for Petersfield Ward within Cambridge district. \n\nThe current system replaces these codes with a fixed length code of nine characters. The first three characters indicate the level of geography and the six digits following define the individual unit. For example, the Royal Borough of Greenwich is coded as codice_10, Middlesbrough is codice_11, Cambridge codice_12 and Fenland codice_13.\n\nThe meaning of some common three character prefixes is as follows:\nFor a full and up-to-date listing of GSS names and codes, please follow the link to ONS Geography's Code History Database, below.\n\n\n"}
{"id": "44455214", "url": "https://en.wikipedia.org/wiki?curid=44455214", "title": "Order of the Geoduck", "text": "Order of the Geoduck\n\nOrder of the Geoduck is an international award issued by the International Rogaining Federation for long-term high level contributions to international rogaining. The award takes the form of a replica geoduck, a saltwater clam found on the Pacific coast of North America.\n\nGeoduck Awardees have been:\n"}
{"id": "25313082", "url": "https://en.wikipedia.org/wiki?curid=25313082", "title": "Pan-region", "text": "Pan-region\n\nA pan-region is a geographic region or state’s sphere of economic, political and cultural influence extending beyond that state's borders. For example, the pan-region of the United States of America (USA) regions both bordering the USA and its close neighbors including, Canada, Mexico, and many South America other states.\n\nThe idea of pan-regions or spheres of economic and cultural influence was first developed by Karl Ernst Haushofer (8/27/1869-3/10/1946), a German General, geographer and geo-politician. Pan-regions contributed to Geopolitik or the German theories of foreign policy during the interwar period (1918–1939) or the time from the end of World War I and the beginning of World War II. Haushofer’s pan-regions divided the world under three supreme leading states in economy, politics and culture. Those three states included the USA who controlled North America and much of South America, Germany who controlled Europe, much of Africa and western Asia and Japan who controlled central, eastern, and the islands of southern Asia. These leading states could expect their regions to develop economic and political alliance with their leading state as well as yield to sanctions and major cultural designations.\n\nHistorically, the world was divided into three spheres of control, however after the end of World War II, Germany and Japan’s control over their various regions have diminished with the success of other nations. For example, German control over Europe has suffered with the development of the European Union and emergence of other foreign powers. Japan also is beginning to lose economic dominance over its pan-region with the emergence of a thriving Chinese economy.\n"}
{"id": "154487", "url": "https://en.wikipedia.org/wiki?curid=154487", "title": "Parkway", "text": "Parkway\n\nA parkway is a broad, landscaped highway thoroughfare. The term is particularly used for a roadway in a park or connecting to a park from which trucks and other heavy vehicles are excluded. Many parkways originally intended for scenic, recreational driving have evolved into major urban and commuter routes.\n\nThe term \"parkway\" is sometimes applied more generally to a variety of limited-access roads.\n\nIn Russia, long, broad (multi-lane) and beautified thoroughfares are referred to as prospekts.\n\nOver the years, many different types of roads have been labeled parkways.\n\nThe first parkways in the United States were developed during the late 19th century by landscape architects Frederick Law Olmsted and Beatrix Farrand as roads segregated for pedestrians, bicyclists, equestrians, and horse carriages, such as the Eastern Parkway, which is credited as the world's first parkway, and Ocean Parkway in the New York City borough of Brooklyn. The terminology \"parkway\" to define this type of road was coined by Calvert Vaux and Frederick Law Olmsted in their proposal to link city and suburban parks with \"pleasure roads\".\n\nNewer roads such as Bidwell in Buffalo, New York and Park Presidio Boulevard in San Francisco, California were designed for automobiles and are broad and divided by large landscaped central medians. \n\nDuring the early 20th century, the meaning of the word was expanded to include limited-access highways designed for recreational driving of automobiles, with landscaping. These parkways originally provided scenic routes without very slow or commercial vehicles, at grade intersections, or pedestrian traffic. Examples are the Merritt Parkway in Connecticut and the Vanderbilt Motor Parkway in New York. But their success led to more development, expanding a city's boundaries, eventually limiting the parkway's recreational driving use. The Arroyo Seco Parkway between Downtown Los Angeles and Pasadena, California is an example of lost pastoral aesthetics. It and others have become major commuting routes, while retaining the name \"parkway\".\n\nIn New York City, construction on the Long Island Motor Parkway (Vanderbilt Parkway) began in 1906 and planning for the Bronx River Parkway in 1907. In the 1920s, the New York City Metropolitan Area's parkway system grew under the direction of Robert Moses, the president of the New York State Council of Parks and Long Island State Park Commission, who used parkways to create and access state parks, especially for city dwellers. As Commissioner of New York City Parks under Mayor LaGuardia, he extended the parkways to the heart of the city, creating and linking its parks to the greater metropolitan systems.\n\nMost of the New York metropolitan parkways were designed by Gilmore Clark. The famed \"Gateway to New England\" Merritt Parkway in Connecticut was designed in the 1930s as a pleasurable alternative for affluent locals to the congested Boston Post Road, running through forest with each bridge designed uniquely to enhance the scenery. Another example is the Sprain Brook Parkway from The Bronx to become the Taconic State Parkway to Chatham, New York. Landscape architect George Kessler designed extensive parkway systems for Kansas City, Missouri; Memphis, Tennessee; Indianapolis; and other cities at the beginning of the 20th century.\n\nIn the 1930s, as part of the New Deal the U.S. federal government constructed National Parkways designed for recreational driving and to commemorate historic trails and routes. These divided four-lane parkways have lower speed limits and are maintained by the National Park Service. An example is the Civilian Conservation Corps (CCC) built Blue Ridge Parkway in the Appalachian Mountains of North Carolina and Virginia.\n\nOthers are: Skyline Drive in Virginia; the Natchez Trace Parkway in Mississippi, Alabama, and Tennessee; and the Colonial Parkway in eastern Virginia's Historic Triangle area. The George Washington Memorial Parkway and the Clara Barton Parkway, running along the Potomac River near Washington, D.C. and Alexandria, Virginia, were also constructed during this era.\n\nIn Kentucky the term \"parkway\" designates a controlled-access highway in the , with nine built in the 1960s and 1970s. They were toll roads until the construction bonds were repaid, and are now freeways since 2006.\n\nThe Arroyo Seco Parkway from Pasadena to Los Angeles, built in 1940, was the first segment of the vast Southern California freeway system. It became part of State Route 110 and was renamed the Pasadena Freeway. A 2010 restoration of the freeway brought the Arroyo Seco Parkway designation back.\nIn the New York metropolitan area, contemporary parkways are predominantly controlled-access highways restricted to non-commercial traffic, excluding trucks and tractor-trailers. Some have low overpasses that also exclude buses. The Vanderbilt Parkway, an exception in western Suffolk County, is a surviving remnant of the Long Island Motor Parkway that became a surface street, no longer with controlled-access or non-commercial vehicle restrictions. The Palisades Interstate Parkway is a post-war parkway that starts at the George Washington Bridge, heads north through New Jersey, continuing through Rockland and Orange counties in New York. The Palisades Parkway was built to allow for a direct route from New York City to Harriman State Park.\n\nIn New Jersey, the Garden State Parkway, connecting the urban Northeast U.S. with the Jersey Shore and Atlantic City, is restricted to buses and non-commercial traffic north of the Route 18 interchange but is one of the busiest toll roads in the country.\n\nIn the Pittsburgh region, two of the major Interstates are referred to informally as parkways. The Parkway East (I-376, formally the Penn-Lincoln Parkway) connects Downtown Pittsburgh to Monroeville, Pennsylvania. The Parkway West (I-376) runs through the Fort Pitt Tunnel and links Downtown to Pittsburgh International Airport, southbound I-79, Imperial, Pennsylvania, and westbound US 22/US 30. The Parkway North (I-279) connects Downtown to Franklin Park, Pennsylvania and northbound I-79.\nIn the suburbs of Philadelphia, U.S. Route 202 follows an at-grade parkway alignment known as the \"U.S. Route 202 Parkway\" between Montgomeryville and Doylestown. The parkway varies from two to four lanes in width, has shoulders, a walking path called the US 202 Parkway Trail on the side, and a speed limit. The parkway opened in 2012 as a bypass of a section of US 202 between the two towns; it had originally been proposed as a four-lane freeway before funding for the road was cut.\n\nIn Minneapolis, the Grand Rounds Scenic Byway system has of streets designated as parkways. These are not freeways; they have a slow speed limit, pedestrian crossings, and stop signs.\n\nIn Cincinnati, parkways are major roads which trucks are prohibited from using. Some Cincinnati parkways, such as Columbia Parkway, are high-speed, limited-access roads, while others, such as Central Parkway, are multi-lane urban roads without controlled access. Columbia Parkway carries US-50 traffic from downtown towards east-side suburbs of Mariemont, Anderson, and Milford, and is a limited access road from downtown to the Village of Mariemont.\n\n\"Parkway\" is used in the names of many Canadian roads, including major routes through national parks, scenic drives, major urban thoroughfares, and even regular freeways that carry commercial traffic.\n\nParkways in the National Capital Region are administered by the National Capital Region (Canada). However, some of them are named \"drive\" or \"driveway\".\n\nThe term in Canada is also applied to multi-use paths and greenways used by walkers and cyclists.\n\n\nThe United Kingdom has parkways (known in that region as a carriageway) in many large towns and cities. Most examples are motorways or A roads. Some parkways including Chelmsford Parkway have flyovers leading to major roads.\n\nSeveral mainly park-and-ride-status railway stations in England have the suffix \"parkway\" in their name. The etymology is from the original U.S. meaning as the Bristol Parkway railway station was named after the adjacent M32 motorway, originally known as The Parkway because of its green-buffered route into the city. Bristol Parkway was the first railway station so named, in 1972. The majority of such stations were opened in the late 20th century to relieve pressure on existing city centre stations. Examples such as Didcot Parkway are renamings following the expansion of the car parking facilities where the name is used promotionally (for example commuters to Oxford are encouraged to leave their car at Didcot and travel to Oxford by train) whereas in others with multi-storey car parks serving modest settlements such as Brookwood and Fleet the suffix has not been adopted.\n\nLuton Airport Parkway and Southampton Airport Parkway are examples serving Luton and Southampton airports. Some were so named as they are not in easy walking distance of an airport terminal; passengers use shuttle bus services, although Southampton Airport station is within easy walking distance of Southampton Airport and has no separate car parking facilities of its own.\n\nThe city and third-generation new town of Peterborough (population of 184,500 as at 2011 census) has an overall free-capacity system roads branded as \"parkways\", which together with other roads provide routes for much through traffic and local traffic sufficient to cope in most peak hours. The majority are dual carriageways, with many of their junctions numbered. Five main parkways (Soke Parkway, Nene Parkway, Fletton Parkway, Frank Perkins Parkway, Paston Parkway) form an orbital outer ring road. Orton Parkway, Werrington Parkway, Longthorpe Parkway are named after the settlements they serve. For example, Werrington Parkway is an arbitrary renaming of a short section of the A15 Lincoln Road.\n\nIn the City of Plymouth, the A38 is called \"The Parkway\" and bisects a rural belt of the local authority area, which coincides with the geographical centre; it has two junctions to enter the downtown part of the city.\n\nThe Australian Capital Territory uses the term \"parkway\" to refer to roadways of a standard approximately equivalent to what would be designated as an \"expressway\", \"freeway\", or \"motorway\" in other areas. Parkways generally have multiple lanes in each direction of travel, no intersections (crossroads are accessed by interchanges), high speed limits, and are of dual carriageway design (or have high crash barriers on the median).\n\nVictoria uses the term \"parkway\" to sometimes refer to smaller local access roads that travel through parkland. Unlike other uses of the term, these parkways are not high-speed routes but may still have some degree of limited access.\n\nSingapore uses the term \"parkway\" as an alternative to \"expressway\". As such, parkways are also dual carriageways with high speed limits and interchanges. The East Coast Parkway is currently the only expressway in Singapore that uses this terminology.\n\n\n"}
{"id": "13352174", "url": "https://en.wikipedia.org/wiki?curid=13352174", "title": "Quadrant (instrument)", "text": "Quadrant (instrument)\n\nA quadrant is an instrument that is used to measure angles up to 90°. Different versions of this instrument could be used to calculate various readings, such as longitude, latitude, and time of day. It was originally proposed by Ptolemy as a better kind of astrolabe. Several different variations of the instrument were later produced by medieval Muslim astronomers.\n\nThe term “quadrant”, meaning one fourth, refers to the fact that early versions of the instrument were derived from astrolabes. The quadrant condensed the workings of the astrolabe into an area one fourth the size of the astrolabe face; it was essentially a quarter of an astrolabe.\n\nOne of the earliest accounts of a quadrant comes from Ptolemy's Almagest around 150 CE. He described a “plinth” that could measure the altitude of the noon sun by projecting the shadow of a peg on a graduated arc of 90 degrees. This quadrant was unlike later versions of the instrument; it was larger and consisted of several moving parts. Ptolemy’s version was a derivative of the astrolabe and the purpose of this rudimentary device was to measure the meridian angle of the sun.\n\nIslamic astronomers in the Middle Ages improved upon these ideas and constructed quadrants throughout the Middle East, in observatories such as Marageh, Rey and Samarkand. At first these quadrants were usually very large and stationary, and could be rotated to any bearing to give both the altitude and azimuth for any celestial body. As Islamic astronomers made advancements in astronomical theory and observational accuracy they are credited with developing four different types of quadrants during the Middle Ages and beyond. The first of these, the sine quadrant, was invented by Muhammad ibn Musa al-Khwarizmi in the 9th century at the House of Wisdom in Baghdad. The other types were the universal quadrant, the horary quadrant and the astrolabe quadrant.\n\nDuring the Middle Ages the knowledge of these instruments spread to Europe. In the 13th century Jewish astronomer Jacob ben Machir ibn Tibbon was crucial in further developing the quadrant. He was a skilled astronomer and wrote several volumes on the topic, including an influential book detailing how to build and use an improved version of the quadrant. The quadrant that he invented came to be known as the “novus quadrans”, or new quadrant. This device was revolutionary because it was the first quadrant to be built that did not involve several moving parts and thus could be much smaller and more portable.\n\nTibbon’s Hebrew manuscripts were translated into Latin and improved upon by French scholar Peter Nightingale several years later. Because of the translation, Tibbon, or Prophatius Judaeus as he was known in Latin, became an influential name in astronomy. His new quadrant was based upon the idea that the stereographic projection that defines a planispheric astrolabe can still work if the astrolabe parts are folded into a single quadrant. The result was a device that was far cheaper, easier to use and more portable than a standard astrolabe. Tibbon’s work had a far reach and influenced Copernicus, Christopher Clavius and Erasmus Reinhold; and his manuscript was referenced in Dante’s Divine Comedy.\n\nAs the quadrant became smaller and thus more portable, its value for navigation was soon realized. The first documented use of the quadrant to navigate at sea is in 1461, by Diogo Gomes. Sailors began by measuring the height of Polaris to ascertain their latitude. This application of quadrants is generally attributed to Arab sailors who traded along the east coast of Africa and often travelled out of sight of land. It soon became more common to take the height of the sun at a given time due to the fact that Polaris disappears south of the equator.\n\nIn 1618 English Mathematician Edmund Gunter further adapted the quadrant with an invention that came to be known as the Gunter quadrant. This pocket sized quadrant was revolutionary because it was inscribed with projections of the tropics, the equator, the horizon and the ecliptic. With the correct tables one could use the quadrant to find the time, the date, the length of the day or night, the time of sunrise and sunset and the meridian. The Gunter quadrant was extremely useful but it had its drawbacks; the scales only applied to a certain latitude so the instrument's use was limited at sea.\n\nThere are several types of quadrants:\n\n\nThey can also be classified as:\n\nThe geometric quadrant is a quarter-circle panel usually of wood or brass. Markings on the surface might be printed on paper and pasted to the wood or painted directly on the surface. Brass instruments had their markings scribed directly into the brass.\n\nFor marine navigation, the earliest examples were found around 1460. They were not graduated in degrees but rather had the latitudes of the most common destinations directly scribed on the limb. When in use, the navigator would sail north or south until the quadrant indicated he was at the destination's latitude, turn in the direction of the destination and sail to the destination maintaining a course of constant latitude. After 1480, more of the instruments were made with limbs graduated in degrees.\n\nAlong one edge there were two sights forming an alidade. A plumb bob was suspended by a line from the centre of the arc at the top.\n\nIn order to measure the altitude of a star, the observer would view the star through the sights and hold the quadrant so that the plane of the instrument was vertical. The plumb bob was allowed to hang vertical and the line indicated the reading on the arc's graduations. It was not uncommon for a second person to take the reading while the first concentrated on observing and holding the instrument in proper position.\n\nThe accuracy of the instrument was limited by its size and by the effect the wind or observer's motion would have on the plumb bob. For navigators on the deck of a moving ship, these limitations could be difficult to overcome.\n\nIn order to avoid staring into the sun to measure its altitude, navigators could hold the instrument in front of them with the sun to their side. By having the sunward sighting vane cast its shadow on the lower sighting vane, it was possible to align the instrument to the sun. Care would have to be taken to ensure that the altitude of the centre of the sun was determined. This could be done by averaging the elevations of the upper and lower umbra in the shadow.\n\nIn order to perform measurements of the altitude of the sun, a back observation quadrant was developed.\n\nWith such a quadrant, the observer viewed the horizon from a \"sight vane\" (C in the figure on the right) through a slit in the \"horizon vane\" (B). This ensured the instrument was level. The observer moved the \"shadow vane\" (A) to a position on the graduated scale so as to cause its shadow to appear coincident with the level of the horizon on the horizon vane. This angle was the elevation of the sun.\n\nLarge frame quadrants were used for astronomical measurements, notably determining the altitude of celestial objects. They could be permanent installations, such as mural quadrants. Smaller quadrants could be moved. Like the similar astronomical sextants, they could be used in a vertical plane or made adjustable for any plane.\n\nWhen set on a pedestal or other mount, they could be used to measure the angular distance between any two celestial objects.\n\nThe details on their construction and use are essentially the same as those of the astronomical sextants; refer to that article for details.\n\nNavy: Used to gauge elevation on ships cannon, the quadrant had to be placed on each gun's trunnion in order to judge range, after the loading. The reading was taken at the top of the ship's roll, the gun adjusted,and checked, again at the top of the roll, and he went to the next gun, until all that were going to be fired were ready. The ship's Gunner was informed, who in turn informed the captain...You may fire when ready...at the next high roll, the cannon would be fired.\n\nIn more modern applications, the quadrant is attached to the trunion ring or of a large naval gun to align it to benchmarks welded to the ship's deck. This is done to ensure firing of the gun hasn't \"warped the deck.\" A flat surface on the mount gunhouse or turret is also checked against benchmarks, also, to ensure large bearings and/or bearing races haven't changed... to \"calibrate\" the gun.\n\nDuring the Middle Ages, makers often added customization to impress the person for whom the quadrant was intended. In large, unused spaces on the instrument, a sigil or badge would often be added to denote the ownership by an important person or the allegiance of the owner. \n\n\n\n"}
{"id": "621182", "url": "https://en.wikipedia.org/wiki?curid=621182", "title": "Reference ellipsoid", "text": "Reference ellipsoid\n\nIn geodesy, a reference ellipsoid is a mathematically defined surface that approximates the geoid, the truer figure of the Earth, or other planetary body.\nBecause of their relative simplicity, reference ellipsoids are used as a preferred surface on which geodetic network computations are performed and point coordinates such as latitude, longitude, and elevation are defined.\n\nIn the context of standardization and geographic applications, a \"geodesic reference ellipsoid\" is the mathematical model used as foundation by Spatial reference system or Geodetic datum definitions.\n\nIn 1687 Isaac Newton published the Principia in which he included a proof that a rotating self-gravitating fluid body in equilibrium takes the form of an oblate ellipsoid of revolution which he termed an oblate spheroid. Current practice uses the word 'ellipsoid' alone in preference to the full term 'oblate ellipsoid of revolution' or the older term 'oblate spheroid'. In the rare instances (some asteroids and planets) where a more general ellipsoid shape is required as a model the term used is triaxial (or scalene) ellipsoid. A great many ellipsoids have been used with various sizes and centres but modern (post-GPS) ellipsoids are centred at the actual center of mass of the Earth or body being modeled.\n\nThe shape of an (oblate) ellipsoid (of revolution) is determined by the shape parameters of that ellipse which generates the ellipsoid when it is rotated about its minor axis. The semi-major axis of the ellipse, \"a\", is identified as the equatorial radius of the ellipsoid: the semi-minor axis of the ellipse, \"b\", is identified with the polar distances (from the centre). These two lengths completely specify the shape of the ellipsoid but in practice geodesy publications classify reference ellipsoids by giving the semi-major axis and the \"inverse \"flattening, , The flattening, \"f\", is simply a measure of how much the symmetry axis is compressed relative to the equatorial radius: \nFor the Earth, \"f\" is around corresponding to a difference of the major and minor semi-axes of approximately . Some precise values are given in the table below and also in Figure of the Earth. For comparison, Earth's Moon is even less elliptical, with a flattening of less than , while Jupiter is visibly oblate at about and one of Saturn's triaxial moons, Telesto, is nearly to .\n\nA great many other parameters are used in geodesy but they can all be related to one or two of the set \"a\", \"b\" and \"f\". They are listed in ellipse.\n\nA primary use of reference ellipsoids is to serve as a basis for a coordinate system of latitude (north/south), longitude (east/west), and elevation (height).\nFor this purpose it is necessary to identify a \"zero meridian\", which for Earth is usually the Prime Meridian. For other bodies a fixed surface feature is usually referenced, which for Mars is the meridian passing through the crater Airy-0. It is possible for many different coordinate systems to be defined upon the same reference ellipsoid.\n\nThe longitude measures the rotational angle between the zero meridian and the measured point. By convention for the Earth, Moon, and Sun it is expressed in degrees ranging from −180° to +180° For other bodies a range of 0° to 360° is used.\n\nThe latitude measures how close to the poles or equator a point is along a meridian, and is represented as an angle from −90° to +90°, where 0° is the equator. The common or \"geodetic latitude\" is the angle between the equatorial plane and a line that is normal to the reference ellipsoid. Depending on the flattening, it may be slightly different from the \"geocentric (geographic) latitude\", which is the angle between the equatorial plane and a line from the center of the ellipsoid. For non-Earth bodies the terms \"planetographic\" and \"planetocentric\" are used instead.\n\nThe coordinates of a geodetic point are customarily stated as geodetic latitude and longitude, i.e., the direction in space of the geodetic normal containing the point, and the height \"h\" of the point over the reference ellipsoid. See geodetic system for more detail. If these coordinates, i.e., latitude \"ϕ\", longitude \"λ\" and height \"h\", are given, one can compute the \"geocentric rectangular coordinates\" of the point as follows:\n\nwhere\nand \"a\" and \"b\" are the equatorial radius (semi-major axis) and the polar radius (semi-minor axis), respectively. \"N\" is the \"radius of curvature in the prime vertical\".\n\nIn contrast, extracting \"φ\", \"λ\" and \"h\" from the rectangular coordinates usually requires iteration. A straightforward method is given in an OSGB publication and also in web notes. More sophisticated methods are outlined in geodetic system.\n\nCurrently the most common reference ellipsoid used, and that used in the context of the Global Positioning System, is the one defined by WGS 84.\n\nTraditional reference ellipsoids or \"geodetic datums\" are defined regionally and therefore non-geocentric, e.g., ED50. Modern geodetic datums are established with\nthe aid of GPS and will therefore be geocentric, e.g., WGS 84.\n\nReference ellipsoids are also useful for geodetic mapping of other planetary bodies including planets, their satellites, asteroids and comet nuclei. Some well observed bodies such as the Moon and Mars now have quite precise reference ellipsoids.\n\nFor rigid-surface nearly-spherical bodies, which includes all the rocky planets and many moons, ellipsoids are defined in terms of the axis of rotation and the mean surface height excluding any atmosphere. Mars is actually egg shaped, where its north and south polar radii differ by approximately , however this difference is small enough that the average polar radius is used to define its ellipsoid. The Earth's Moon is effectively spherical, having almost no bulge at its equator. Where possible, a fixed observable surface feature is used when defining a reference meridian.\n\nFor gaseous planets like Jupiter, an effective surface for an ellipsoid is chosen as the equal-pressure boundary of one bar. Since they have no permanent observable features, the choices of prime meridians are made according to mathematical rules.\n\nSmall moons, asteroids, and comet nuclei frequently have irregular shapes. For some of these, such as Jupiter's Io, a scalene (triaxial) ellipsoid is a better fit than the oblate spheroid. For highly irregular bodies, the concept of a reference ellipsoid may have no useful value, so sometimes a spherical reference is used instead and points identified by planetocentric latitude and longitude. Even that can be problematic for non-convex bodies, such as Eros, in that latitude and longitude don't always uniquely identify a single surface location.\n\n\n\n"}
{"id": "711230", "url": "https://en.wikipedia.org/wiki?curid=711230", "title": "Regional geography", "text": "Regional geography\n\nRegional geography is a major branch of geography. It focuses on the interaction of different cultural and natural geofactors in a specific land or landscape, while its counterpart, systematic geography, concentrates on a specific geofactor at the global level. \n\nAttention is paid to unique characteristics of a particular region such as natural elements, human elements, and regionalization which covers the techniques of delineating space into regions. Rooted in the tradition of the German speaking countries, the two pillars of regional geography are the idiographic study of \"Länder\" or spatial individuals (specific places, countries, continents) and the typological study of \"Landschaften\" or spatial types (landscapes such as coastal regions, mountain regions, border regions, etc.).\n\nRegional geography is also a certain approach to geographical study, comparable to quantitative geography or critical geography. This approach prevailed during the second half of the 19th century and the first half of the 20th century, a period when then regional geography paradigm was central within the geographical sciences. It was later criticised for its descriptiveness and the lack of theory. Strong criticism was leveled against it in particular during the 1950s and the quantitative revolution. Main critics were G. H. T. Kimble and Fred K. Schaefer. The regional geography paradigm has influenced many other geographical sciences, including economic geography and geomorphology. Regional geography is still taught in some universities as a study of the major regions of the world, such as Northern and Latin America, Europe, and Asia and their countries. In addition, the notion of a city-region approach to the study of geography, underlining urban-rural interactions, gained credence since the mid-1980s. Some geographers have also attempted to reintroduce a certain amount of regionalism since the 1980s. This involves a complex definition of regions and their interactions with other scales.\n\nNotable figures in regional geography were Alfred Hettner in Germany, with his concept of chorology; Paul Vidal de la Blache in France, with the possibilism approach (possibilism being a softer notion than environmental determinism); and, in the United States, Richard Hartshorne with his concept of areal differentiation. The school of Carl O. Sauer, strongly influenced by Alfred Hettner and Paul Vidal de la Blache, is also seen as regional geography in its broadest sense.\n\n"}
{"id": "37372585", "url": "https://en.wikipedia.org/wiki?curid=37372585", "title": "Saxon milepost", "text": "Saxon milepost\n\nA Saxon milepost (, colloquially \"sächsische Postmeilensäule\" or \"Postsäule\") was a milepost in the former Electorate of Saxony that gave distances expressed as journey times to the nearest eighth of an hour. With one hour being the equivalent of one league, this corresponds to a distance of about 566 m. The design of the mileposts varied according to the distance at which they were placed. They were hewn from natural stone into the shape of an obelisk, an ancient herma or a stele. Their prototype was the Roman milepost. From its German name \"römische Meilensäule\" the rather inaccurate German description of \"Säule\" (lit.: \"column\") was derived. The Saxon head postal director (\"Oberpostdirektor\"), Paul Vermehren, brought about their inception based on official distance surveys, whose results were given in leagues on the post mileposts. A league in Saxony at that time (1722 to 1840) was meant to be an hour's journey, equivalent to half a mile or 4.531 kilometres.\n\nSaxon postal mileposts were set up during the reign of August the Strong and his successor along all important postal and trading routes and in almost all towns in the Electorate of Saxony to indicate the official distances. This was intended to be the basis for the creation of a unified calculation of postal charges. Because the territory of the Electorate of Saxony was larger than that of the present-day German state of Saxony, these mileposts are nowadays also found in the states of Thuringia, Brandenburg and Saxony-Anhalt, as well as in Poland.\n\nThe locations and images of surviving or replaced Saxon mileposts may be seen in the .\n\nIn 1695, the head of the Saxon post office, \"Oberpostmeister\" Ludwig Wilhelm, proposed a systematic survey of the road from Leipzig to Dresden with wooden, roadside posts at regular intervals. This prompted prince elector Augustus the Strong, on 18 June 1695, to order \"that certain mileposts are to be erected\". He charged the \"Kondukteur\" (building supervisor) Heinrich Niedhart with this task. The Electoral Saxon forestry superintendents were instructed to provide the wood, and the administrators of the electoral Saxon districts were to ensure that the posts were erected.\n\nFurthermore, before 1700 wooden fingerposts withs distance markings (so-called \"Arm(en)säulen\" or \"arm columns\") were commonplace on the roads of Saxony. These consisted of a wooden post, at the upper end of which were direction indicators in the shape of human arms and hands. Because the wood rotted rapidly as a result of its constant exposure to moisture, many of these fingerposts collapsed a few years after they had been erected and became unusable.\n\nThe establishment of postal mileposts in electoral Saxony was not an isolated phenomenon. Similar posts or stones with distances marked on them were erected along the roads in a number of countries.\n\nThe basis for the introduction of Saxon mileposts was the cartographic work of the pastor, Adam Friedrich Zürner, from Skassa. Zürner had prepared a map of Großenhain, which attracted the attention of Augustus the Strong. After further cartographic work, the prince elector gave him the task on 12 April 1713 of: \"\"recording districts, including the lordships, manor estates, towns, villages and the like, on geographic maps\" (original: \"Aemter samt denen darinnen befindlichen Herrschaften, Rittergütern, Städten, Dörfern und dergleichen mehr in mappas geographicas bringen\"). This entailed the topographic survey of Electoral Saxony. In addition to the heartland, it covered the electoral Saxon parts of the counties of Henneberg and Mansfeld, the Schönburg estates, the estates of the Albertine branches of Saxe-Merseburg, Saxe-Weissenfels and Saxe-Zeitz as well as the two Lusatias.\n\nThe resulting cartographic material remained largely secret for several decades for military reasons. The prince elector only had an improved postal map published which was the result of an extension to the contract that followed a few weeks later. This \"Chur-Sächsische Post-Charte\"\", first published in 1718, and its subsequent editions, remained in use until the 19th century.\n\nBecause the distances stated at that time were frequently based on imprecise estimates, Zürner had to survey the distances afresh or verify existing data. To achieve that he designed a survey vehicle in the shape of an electoral Saxon baggage coach. Each revolution of the rear wheel of the coach with a circumference of one Dresden rod (\"Dresdner Rute\"), i.e. 4.531 metres, was transmitted to a mechanical counter in the coach by means of a chain. Zürner's assistants used a measuring cart in the shape of a wheelbarrow for those tracks unsuitable for a coach, which likewise measured the distances by the turning of a wheel and which was carried as the so-called \"fifth wheel on the wagon\" (\"fünftes Rad am Wagen\") in a case on the surveying coach. Both methods enabled a very accurate survey of roads.\nAnother problem was the lack of standard units of measurement. At that time there were miles (\"Meilen\") of various length even within the Electorate. To achieve standardization, the Electoral Saxon post mile was therefore introduced on 17 March 1722, whereby 1 mile = 2 leagues = 2,000 Dresden rods = 9.062 kilometres. To indicate distances on the mileposts, Zürner used the league (\"Wegstunde\"), which equalled a half mile.\n\nThe survey journeys usually began in Leipzig or Dresden, the counter being set to zero at the posthouse in each city. As a result, a Leipzig or a Dresden distance is quoted. During such a journey, the assistant to the surveyor had to drive a numbered wooden stake into the ground every quarter of a mile and dig a hole next to it. The excavated material was then used to help fix the wooden post securely. The landowner was responsibility for looking after the survey stake.\n\nIn several cases the surveys were also conducted outside the territory of the electorate. Everywhere where Saxon land was interrupted by other territories, roads that were used by the Saxon post office were surveyed, with the permission of the territorial owner.\n\nSurveying was especially difficult in Upper Lusatia because there the landowners of the estates of the realm tried to impede Zürner's activity. Zürner was able to begin surveying Upper and Lower Lusatia only on 29 June 1723. The survey work on the most important roads in the state was completed by 1733.\n\nOn 19 September 1721, an Electoral order was issued to the districts (\"Ämter\") of Dresden, Meißen and Großenhain, to erect stone columns as mileposts. On 1 November 1721, this order was extended to the entire state. On the same day the state authorities in charge issued the general ordinance for the \"Establishment of Stone Postal Columns\" (\"Setzung der steinernen Post-Säulen\") and the instruction that the costs of erecting them were to be borne by the landowner of the locations affected. For Upper Lusatia, a separate instruction followed on 24 November 1721.\n\nZürner, who had been tasked by Augustus the Strong on 14 December 1721, worked out himself the details of which mileposts were to be erected. Zürner set forth that a large distance column (\"Distanzsäule\") was to be erected immediately in front of the gates of a town. Similarly there were to be quarter-mile, half-mile and whole-mile stones at the corresponding intervals. In the Saxon part of the County of Henneberg cast iron posts were erected instead of the usual stone columns, and in the County of Mansfeld there were no mileposts at all.\n\nOriginally about 300 distance mileposts and around 1,200 other roadside mileposts were erected. About 200 of them have at least partly survived or have been faithfully reconstructed. Replicas were increasingly made after 1990.\n\nToday the Saxon section of the Old Dresden to Teplitz Post Road is considered the historic transport link with the most surviving postal mileposts.\n\nThe material used for the mileposts in Saxony varies widely. They were usually made from the prevailing building stone of the local area, which is also reflected in the building materials used in Saxony's architecture in general. Elbe sandstone from several quarries in Saxon Switzerland and the area of the Tharandt Forest was used for most of the stones. Other frequently used materials were Rochlitz porphyry in Central Saxony and Lusatian granite in eastern Saxony. In the Chemnitz area, Hilbersdorf porphyritic tuff quarried at Hilbersdorf and Flöha was used as a milepost material In the upper Ore Mountains and the Vogtland mileposts were made of local granite, for example, Wiesenbad Granite, granite of the Greifensteine area, Schwarzenberg Granite, Kirchberg Granite or Bad Brambach Granite of the \"Fichtelgebirge type\". The different weathering properties of these diverse types of stone proves to be a challenge for the conservation of these monuments in many cases. This is also the reason why numerous mileposts no longer exist.\n\nBoth the costs and the responsibility for erecting the mileposts had to be borne by the authorities of the respective towns and villages. As a result, the measures did not gain universal approval throughout the land. Because the means of the towns varied considerably depending on their size and industrial structure, the financial impact on them was very variable. Regardless of their size, they often had a similar number of town gates and therefore a comparable number of milestone columns to put up. Frequently there were three to five gates. In 1722, the Saxon \"Landtag\" asked the prince elector to cancel the expensive project that had invoked the opposition of many town councils and landowners. Many towns tried to ignore the edict or delay its implementation.\n\nIn order to enforce the implementation of his instructions, the elector had resort to harsh measures and threatened negligence, tardiness or damage to the mileposts with disciplinary action in an order of 24 July 1722; and in another edict of 7 September 1724, fines of 20 talers were imposed against every official guilty of missing deadlines and in each individual case of neglect. Especially on the roads of Central Saxony, in the towns of Colditz, Grimma, Oschatz, Rochlitz and Waldheim, as well as the routes from these towns to Leipzig and thence Zeitz the gaps were particularly noticeable and were, in a decree of 7 September, subject to public reprimand by the prince elector.\n\nIn the course of this dispute, many places strove to erect one milepost column only. Zürner knew the location of many small towns and villages very precisely. During the course of his project, he proceeded to support the towns in their requests and advocated the elector's consent. In many cases their requests were granted. On the national roads, therefore, only wooden mileposts were erected or existing ones repaired. After 1727 the practice of erecting one column per town was carried out in many cases.\n\nAs the order dated 19 September 1721 incorporated a comprehensive memorandum of 24 items and was accompanied by a list of the benefits of the regulation, it appears that problems had been anticipated from the outset. For example, as advantages of the national survey, the memorandum called pointed out that the payment of \"delivery men, relay services, postal items and other goods\" would be verifiable and the prices could no longer be fixed arbitrarily, that there would be fewer complaints from travellers about high fees that had hitherto taken up the time of courts and higher authorities, and that journey times and delivery times would be precisely defined by the survey. Another argument was that the roads would be more easily recognisable in the winter and at night.\n\nOpposition to the postal mileposts was especially strong in Upper Lusatia. In 1723, the town councils of Bautzen and Görlitz refused to entertain Zürner in this matter. Not until 31 March 1724 did the estates of Upper Lusatia declare themselves ready to carry out the instructions.\n\nBecause mileposts were occasionally damaged or even knocked down, an order was issued in 1724 that such crimes would be punished by imprisonment and other \"hard and exemplary punishments\".\n\nDue to persistent opposition the Saxon Landtage was finally able to issue a decree on 12 April 1728 that - contrary to the Elector's wishes - the mileposts need only be erected on main and postal roads.\n\nTo what extent Augustus the Strong was personally involved in the development of the designs for the mileposts is not clear. Their final appearance, which was based on baroque and classical prototypes, was linked to the senior state architect (\"Oberlandesbaumeister\"), Matthäus Daniel Pöppelmann.\n\nThe large distance mileposts (\"Distanzsäule\") comprised seven elements. The pedestal was formed by the plinth, dado and cornice (or cap). The column consists of the base (\"Zwischenplatte\" or \"Schaftfuß\"), the shaft, a block sowing the coat of arms (\"Wappenstück\"), and the finial (\"Aufsatz\" or \"Spitze\"). The columns have an average height of 8 ells (4.53 metres) and rest on a pedestal half an ell high. The individual elements were held together by means of iron pegs cast in lead. On the shaft of the column the names of the destinations were inscribed at Zürner's direction in a Fraktur font and based on the distance tables that had been worked out for each town. Several routes crossed state borders, and this was indicated by the letters \"gr\" (for \"Grenze\" or \"border\") or a horizontal line. Part of the inscription on all columns was a post horn on all four sides, which was the emblem of the state's postal sovereignty. The arms of the Electorate of Saxony with a gilded crown and the Polish royal crown with the royal Polish-Lithuanian coat of arms were shown on the superstructure.\n\nThe mileposts originally erected in front of the town gates usually had the distances marked on two sides and the names of the destination towns on the other two sides. Later columns, erected in the market squares, had the distances marked on all four sides.\n\nThe full mile stone (\"Ganzmeilensäule\") was to mark every full mile along the post road. It is about 3.75 metres high and resembles the large distance milepost in shape. They are however more slender and have no section showing the coat of arms. The information was inscribed on two sides so that travellers in both directions could read them. On the road side was the so-called serial number (\"Reihennummer\") with which all roadside columns and mileposts were numbered in sequence. Because a number was assigned every quarter of a mile, each full-milepost had a serial number divisible by four.\n\nThe half mile stone (\"Halbmeilensäule\"), also called the league post (\"Stundensäule\") because the league corresponded to half a mile, had a lower pedestal surmounted by a shaft that tapered from top to bottom. A roof-shaped, chamfered finial formed the uppermost element. Its total height is about 3 metres. It bore the same inscriptions as the full mile stone. The herm-like design of this column is a reason why only a few stones of this type have survived until today. The serial number is even, but not divisible by four.\n\nThe quarter mile stone (\"Viertelmeilenstein\") rests on a low pedestal and consists of a rectangular column or stele. Its total height is about 1.7 metres. There are no inscriptions on these mileposts other than the monogram \"AR\", a post horn symbol, the year of manufacture and, on the narrow side facing the road, the serial number which was an odd number.\n\nPreparations for the introduction of the metric system in the Kingdom of Saxony were made as part of the work of the Standardization Commission (\"Normalaichungscommission\"), led by Albert Christian Weinlig and Julius Ambrosius Hülße. These two men envisaged a transition phase from the old units. Almost simultaneously, similar efforts were being made at the level of the German Confederation. A new survey was carried out in 1858, and between 1859 and 1865 a new system of milestones – the were made in the shape of station milestones (\"Stationssteine\"), full mile, half mile, junction (\"Abzweig-\") and border crossing stones (\"Grenzübergangssteine\"), noting that, from 1840, 1 mile = 7.5 km. Upon the full introduction of the metric system around 1900, some of these were converted to kilometer, chaussee, boundary (\"Flurgrenz\") and roadkeeper stones (\"Straßenwärtersteine\").\n\n\n"}
{"id": "26203820", "url": "https://en.wikipedia.org/wiki?curid=26203820", "title": "Society for the History of Discoveries", "text": "Society for the History of Discoveries\n\nSociety for the History of Discoveries (or SHD), founded in 1960, is an international, United States-based, organization formed to stimulate interest in teaching, research, and publishing the history of geographical exploration. Its members include those from several academic disciplines as well as archivists, non-affiliated scholars, and laypersons with an interest in history. SHD advances its goals by organizing annual meetings at which pertinent scholarly research papers are presented, by publishing a scholarly journal with articles on geographic exploration, and by annually offering an award to student research papers in the field. The Society is a US non-profit 501(c)(3) organization administered by a voluntary and unpaid team of council members and officers. Membership is open to all who have an interest in the history of geographical exploration. It publishes a semiannual journal, \"Terrae Incognitae\".\n\nThe origin of the Society for the History of Discoveries (SHD) can be traced back to the summer of 1960 at an academic conference in Lisbon, Portugal, that commemorated the quincentenery of the death of Prince Henry the Navigator. American scholars John (Jack) Parker, Thomas (Thom) Goldstein, and Vsevolod (Steve) Slesarev, determined that there should be an organization in the United States that would encourage research into the history of exploration and discovery. Later, in December 1960, Goldstein posted a notice at the New York City meeting of the American Historical Association inviting interested parties to meet at a nearby restaurant. The people who attended that December 1960 luncheon constituted themselves as an executive board for a period of one year, and proceeded to organize SHD.\n\nAt the beginning of 1961, there were a total of twenty-one members in the Society. The appeal of this newly created learned Society was wide. Because there were no barriers to qualify for membership, within a short time historians, geographers, librarians, museum curators, archivists, philosophers, mathematicians, linguists, cartographers, navigators, medical doctors, editors, book sellers, book and map collectors, and independent scholars comprised the membership. Also, because there were no gender barriers, women scholars readily found a friendly intellectual home, and not only were they among the earliest members attracted to the new Society, they quickly assumed leadership positions. By 2010, the organization’s membership counted over three hundred people, and numerous institutions subscribe to the Society’s journal, \"Terrae Incognitae\".\n\nThe founding members established the major goals to stimulate interest in teaching, research, and publishing the history of geographical exploration. Since its inception, the scope of the Society's activities encompasses the discovery, exploration, and mapping of the earth's land and sea surface from earliest times to the present - the explorers and the explored. Fields of specialization thus include the history of European expansion, the history of cartography, navigation, colonial settlement, biography, and bibliography. To further its mission, the Society since 1969 has published annually a journal, \"Terrae Incognitae\", and a newsletter, which since 2000 is titled \"Terra Cognita\".\n\nRecords of the Society are archived in Special Collections at The University of Texas at Arlington Library.\n\nDuring most of its history, the Society was governed by three elected officers and six members of Council. The officers were President, Vice President, and Secretary-Treasurer. In 2006, the by-laws were changed to add another officer. Because the demands on the Secretary-Treasurer had grown, the office of Secretary-Treasurer was divided into two positions, Executive Secretary and Treasurer. Duties are found at the Society’s Articles of Association, available via the Society website. Council meets formally at the annual meeting, and during the year via email and other technologies.\n\nThe Society for the History of Discoveries determined at its 1966 annual meeting at West Point, New York, to publish an annual journal. It has become a major part of the Society’s identity, and all agree that the unpaid editor performs the Society’s most difficult and important task. Bruce Solnick was appointed Executive Editor, and first published by Nico Israel in Amsterdam, the first volume of \"Terrae Incognitae\" appeared in 1969. The peer-reviewed journal was published annually from 1969 through 2010. Beginning in 2011, the journal is published semiannually. Past and current editors are listed at the Society website. In addition to scholarly articles, each issue of \"Terrae Incognitae\" includes reviews of recent literature, and since 1979, an extensive bibliography of recent publications related to exploration and discovery. Beginning in 2008 the editorial board of \"Terrae Incognitae\" extended the number of book reviews to be published in each issue.\n\nA paper by Commodore Pieter Verhoog was read by John Parker at the Columbus, Ohio, annual meeting in 1980 which interested those in attendance so much that a special session on the Columbus 1492 landfall was scheduled at the next annual meeting in Athens, Georgia. In addition to focusing on the Columbus landfall at the meeting, John Parker and Louis De Vorsey were charged with producing a special issue dedicated to the first landfall, and it was published in 1983 as Volume 15. It was re-published in 1985 by Wayne State University Press as a book titled \"In the Wake of Columbus: Islands and Controversy\". One important and enduring result of the scholarship represented in Volume 15 was a highly received new translation of Columbus’ \"Diario\" by two Society members, Oliver Dunn and James Kelley, which was published to acclaim by the University of Oklahoma Press in 1991.\n\nBeginning in 2010, \"Terrae Incognitae\" is published by Maney Publishing, an independent publisher operating internationally. Maney produces the journal, both printed hard copies and also, in the future, an online version. Maney will provide a full back issue archive online for institutional subscribers, and freely searchable electronic abstracts. When Maney began publication of the journal in 2010, it announced that it would scan and make available in electronic form the back issues to the membership.\n\nPublished by the University of Chicago Press:\n\nAlong with \"Terrae Incognitae\", the Society for the History of Discoveries also publishes an annual report each autumn, and 'Terra Cognita', a newsletter in the spring. These documents, prepared by the Executive Secretary, include Council and business meeting minutes, election results, membership (including a directory) information, reports from committees, abstracts of papers read at the annual meeting, information on upcoming meeting sites, obituaries, various announcements of interest to members, a financial report, and one of the most popular functions, news of members. Periodically, the Society’s Articles of Association are reprinted.\n\nThe venues of annual meeting are contingent upon invitations from universities, libraries, maritime museums, map societies, and from organizations familiar with the purpose of the Society. Since 1960, annual meetings usually are held in the Fall, but the 1989 and 1997 meetings were held in the Summer. On several occasions, the Society met jointly with the Hakluyt Society, the North American Society for Oceanic History, and others.\n\n"}
{"id": "226762", "url": "https://en.wikipedia.org/wiki?curid=226762", "title": "Speed of advance", "text": "Speed of advance\n\nSpeed of advance (SOA) is used to indicate the speed to be made along the intended track. The intended (anticipated, desired) speed along the track with respect to the earth, taking into consideration the effect of known or predicted current; speed along the track. SOA is also used to designate the average speed that must be made good to arrive at a destination at a specified time.\n\n"}
{"id": "40676951", "url": "https://en.wikipedia.org/wiki?curid=40676951", "title": "Standard port", "text": "Standard port\n\nA Standard port is a port whose tidal predictions are directly given in the Tide tables.\n\nTide predictions for standard ports are based on continuous observation of tide over a period of at least one year. These predictions are given in feet or meters, with respect to the chart datum for average meteorological conditions. Some examples of primary ports are Bhavnagar, Bombay, Cochin, Manila, Karachi, Singapore, Suez, Port Dickson, etc. Standard ports are marked in bold letters in the Index pages of Admiralty Tide Tables (or Tidal almanac). Tidal predictions are usually made by the Bureau of Meteorology of that country.\n\nSecondary ports (also called \"Secondary place\" in some countries like Australia), on the other hand, are ports for which tides have to be calculated, based on a primary port with a similar tidal curve. Some examples of Secondary ports are Rabigh, Porto Novo, Porbandar, Port Cornwalis, Sharjah, The Sandheads (Hugli), etc.\n"}
{"id": "53245269", "url": "https://en.wikipedia.org/wiki?curid=53245269", "title": "Stray Dog West", "text": "Stray Dog West\n\nStray Dog West is an island in Greenland. It is a candidate for the northernmost island on Earth.\n"}
{"id": "43576000", "url": "https://en.wikipedia.org/wiki?curid=43576000", "title": "Temporary adjustments of theodolites", "text": "Temporary adjustments of theodolites\n\nTemporary adjustments are set of operations which are performed on a theodolite to make it ready for taking observations. These include its initial setting up on a tripod or other stand, centering, levelling up and focusing of eyepiece.\n\n Exact centering is done by using the shifting head of the instrument. During this, first the screw-clamping ring of the sliding head is loosened and the upper plate of the shifting head is slid over the lower one until the plumb bob is exactly over the station mark. After the exact centering, the screw clamping ring is tightened. This can be done by means of a forced centering plate or tribrach. An optical or laser plummet is normally used for the most accurate setting. The centering and levelling of the instrument is interactive and iterative; a re-levelling may change the centering, so error each is eliminated in successively until negligible.\n\nLeveling of an instrument is done to make it vertical axis with respect to the apparent force of gravity at the station.\n\nFor two spirit vials at right angles;\n\nOtherwise, repeat the whole process starting from step 1 to step 5.\n\nThe same principle applies for a bulls-eye level:\n\n\nTo obtain an accurate clear sighting, the cross hairs should be in focus; adjust the eyepiece to do this.\n\nFor focusing of the eye piece, point the telescope to the sky or hold a piece of white paper in front of telescope. Move the eye-piece in and out until a distinct sharp black image of the cross-hairs is seen. This confirms proper focusing.\nTo Clearly view the object being sighted Focus the objective lens.\n\nIt is done for each independent observation to bring the image of the object in the plane of cross hairs. It includes following steps of operation: First, direct the telescope towards the object for observation. Next, turn the focusing screw until the image of the object appears clear and sharp as the observer looks through properly focused eye-piece. If focusing has been done properly, there will be no parallax i.e., there will be no apparent movement of the image relative to the cross hairs if the observer moves his eye from one side to the other or from top to bottom.\n\n"}
{"id": "4878962", "url": "https://en.wikipedia.org/wiki?curid=4878962", "title": "Thomas Larcom", "text": "Thomas Larcom\n\nMajor-General Sir Thomas Aiskew Larcom, 1st Baronet PC FRS (24 December 1801 – 15 June 1879) was a leading official in the early Irish Ordnance Survey that started in 1824. He later became a poor law commissioner, census commissioner and finally executive head of the British administration in Ireland as under-secretary to the Lord-Lieutenant of Ireland, a position the government of the day was eager for him to take.\n\nThe longest-serving under-secretary (1853–1868), and a man of unusual abilities, Larcom had a distinguished career in his adopted country and acted with an impartiality that won him respect from all parties. In 1868 he was admitted to the Irish Privy Council and created a Baronet.\n\n\n"}
{"id": "27919989", "url": "https://en.wikipedia.org/wiki?curid=27919989", "title": "Timeline of European exploration", "text": "Timeline of European exploration\n\nThe following timeline covers European exploration from 1418 to 1957.\n\nThe 15th century witnessed the rounding of the feared Cape Bojador and Portuguese exploration of the west coast of Africa, while in the last decade of the century the Spanish sent expeditions to the New World, focusing on exploring the Caribbean Sea, and the Portuguese discovered the sea route to India. In the 16th century, various countries sent exploring parties into the interior of the Americas, as well as to their respective west and east coasts north to California and Labrador and south to Chile and Tierra del Fuego. In the 17th century, the Russians explored and conquered Siberia in search of sables, while the Dutch roughly worked on the chart for Australia. The 18th century saw the first extensive exploration of the South Pacific and the discovery of Alaska, while the nineteenth was dominated by exploration of the polar regions (not to mention excursions into the heart of Africa). By the 20th century, the poles themselves had been reached.\n\n\n\n\n \n\n\n\n"}
{"id": "435795", "url": "https://en.wikipedia.org/wiki?curid=435795", "title": "United States Board on Geographic Names", "text": "United States Board on Geographic Names\n\nThe United States Board on Geographic Names (BGN) is a federal body operating under the United States Secretary of the Interior. The purpose of the board is to establish and maintain uniform usage of geographic names throughout the federal government of the United States.\n\nThe board was created in 1890 by executive order; its present form derives from a law of 1947.\nOn January 8, 1890, T. C. Mendenhall, superintendent of the US Coast and Geodetic Survey Office, wrote to 10 noted geographers \"to suggest the organization of a Board made up of representatives from the different Government services interested, to which may be referred any disputed question of geographical orthography.\" President Benjamin Harrison signed Executive Order 28 on September 4, 1890, establishing the United States Board on Geographic Names. \"To this Board shall be referred all unsettled questions concerning geographic names. The decisions of the Board are to be accepted [by federal departments] as the standard authority for such matters.\" The board was given authority to resolve all unsettled questions concerning geographic names. Decisions of the board were accepted as binding by all departments and agencies of the federal government.\n\nThe board has developed principles, policies, and procedures governing the use of domestic and foreign geographic names. It also deals with the names of geographical features underseas and in Antarctica.\n\nAlthough its official purpose is to resolve name problems and new name proposals for the federal government, the board also plays a similar role for the general public. Any person or organization, public or private, may make inquiries or request the board to render formal decisions on proposed new names, proposed name changes, or names that are in conflict. Generally, the BGN defers federal name use to comply with local usage. There are a few exceptions. For example, in rare cases where a locally used name is very offensive, the BGN may decide against adoption of the local name for federal use.\n\nIn federal mapping and names collection efforts, there is often a phase lag where a delay occurs in adoption of a locally used name. Sometimes the delay is several decades. Volunteers in the Earth Science Corps are used to assist the US Geological Survey in collecting names of geographic features.\n\nThe Geographic Names Information System, developed by the BGN in cooperation with the US Geological Survey, includes topographic map names and bibliographic references. The names of books and historic maps which confirm the feature or place name are cited. Variant names, alternatives to official federal names for a feature, are also recorded.\n\nThe BGN has members from six federal departments as well as the Central Intelligence Agency, the Government Publishing Office, the Library of Congress, and the US Postal Service. The BGN rules on hundreds of naming decisions annually and stores over two million geographical records in its databases at geonames.usgs.gov. State and local governments, and private mapping organizations usually follow the BGN's decisions.\n\nThe BGN has an executive committee and two permanent committees with full authority: the 10- to 15-member Domestic Names Committee and the 8- to 10-member Foreign Names Committee. Both comprise government employees only. Each maintains its own database.\n\nThe BGN does not create a place name, the BGN responds to proposals for names from federal agencies; state, local, and tribal governments; and the public. The BGN does not translate terms, but instead accurately uses foreign names in the Roman alphabet. For non-Roman languages, the BGN uses transliteration systems or creates them for less well-known languages.\n\nThe BGN currently publishes names on its website. In the past, the BGN issued its decisions in various publications under different titles at different intervals with various information included. In 1933, the BGN published a significant consolidated report of all decisions from 1890 to 1932 in its \"Sixth Report of the United States Geographic Board 1890–1932\". For many years, the BGN published a quarterly report under the title \"Decisions on Geographic Names\".\n\nThe BGN was established in 1890 as the \"Board on Geographical Names\" and has undergone several name changes. In 1934, it was transferred to the Department of the Interior. The 1969 BGN publication \"Decisions on Geographic Names in the United States\" stated the agency's chief purpose as:\n\nIn 1963, the Advisory Committee on Undersea Features was started for a standardization of names of undersea features.\n\n\n\n"}
{"id": "5322293", "url": "https://en.wikipedia.org/wiki?curid=5322293", "title": "Western Australia border", "text": "Western Australia border\n\nThe Western Australian border was originally designated as 129th meridian east longitude (129° east). However, the border marked on the ground is some distance from this line. Kununurra is the closest town to the Western Australian border, being about 25 km west of the border. The closest settlement is Border Village, 1,734 km to the south on the South Australian side of the border, on Eyre Highway.\n\nThe Western Australian (WA) border marked on the ground, is not as straight as it looks on a map. The Northern Territory border with Western Australia and the South Australian border with Western Australia are displaced east–west by approximately 127 metres, due to errors within the limits of surveying technology available in the 1920s.\n\nWhere Western Australia meets the Northern Territory (NT) and South Australia (SA) borders is a 127-metre segment running east–west along the 26th parallel south latitude (26° south).\n\nIn June 1968, two monuments were erected to mark each end of this 127-metre segment, At the easternmost of these concrete border markers all three borders meet, at Surveyor Generals Corner.\n\nIn 1788 Governor Phillip claimed the continent of Australia only as far west as the 135th meridian east (135° east) in accordance with his commission. (26 January 1788 – MAP)\n\nIt has been suggested that the 1788 claim by the British of 135° east was in reference to Spain's claims under the Treaty of Tordesillas. Spain was seen as no longer having an interest in the area. On the other hand, the other signatories to the treaty, the Portuguese still had a presence in Macau and East Timor. Adoption of 135° east as a boundary would minimise provocation of the Portuguese. By 1825, however, Britain was powerful enough and found it convenient to adopt the original line of the Portuguese under the treaty, 129° east.\n\nThe line of 129° east first became a border in Australia as the western border of New South Wales (NSW) in 1825 (16 July 1825 – MAP).\n\nOn 16 July 1825, the western boundary of New South Wales was relocated at 129° east to take in the new settlement at Melville Island.\n\nFrom 1825 to 1829 129° east was the NSW border, except that the settlement of King George's Sound, now Albany, was part of New South Wales from its establishment on 26 December 1826, until 7 March 1831 when it was made part of the Swan River Colony.\n\nFollowing the settlement of the Swan River Colony (SRC) in 1829 (2 May 1829 – MAP), the eastern boundary was declared to be 129° east, that is coinciding with the western boundary of New South Wales at the time.\n\nThe Swan River Colony, started in 1829, was commissioned as the colony of Western Australia in March 1831.\n\nFrom 1829 to 1832 129° east was the SRC/NSW border.\n\nThe name of the Swan River Colony changed to Western Australia in 1832 (6 February 1832 – MAP).\n\nFrom 1832 to 1846 129° east was the WA/NSW border.\n\nIn 1846 the colony of North Australia (NA) was proclaimed by Letters Patent, which was all of New South Wales north of 26° south. (17 February 1846 – Map).\n\nFrom 1846 to 1847 129° east was the WA/NA border north of 26° south and the WA/NSW border south of the 26th parallel.\n\nIn 1847 the colony of North Australia was revoked and reincorporated into New South Wales. (15 April 1847 – MAP).\n\nFrom 1847 to 1860 129° east was once again the WA/NSW border.\n\nIn 1860 South Australia, which had been proclaimed a colony in 1836 (28 December 1836 – MAP), west to the 132° east, changed their western border from 132° east to 129° east (1860 – MAP).\n\nFrom 1860 to 1863 129° east was the WA/NSW border north of 26° south and the WA/SA border south of the 26th parallel.\n\nIn 1863 that part of New South Wales to the north of South Australia was annexed to South Australia by Letters Patent and became known as the Northern Territory of South Australia (NToSA). (6 July 1863 – MAP).\n\nFrom 1863 to 1911 129° east was the WA/NToSA border north of 26° south and the WA/SA border south of the 26th parallel\n\nIn 1911 the Northern Territory (NT) was split off from South Australia to be administered by the Commonwealth. (1 January 1911 – MAP).\n\nFrom 1911 to 1927 129° east was the WA/NT border north of 26° south and the WA/SA border south of the 26th parallel.\n\nIn 1927 the Northern Territory was split into two territories, North Australia (NA) and Central Australia (CA). (1 March 1927 – MAP).\n\nFrom 1927 to 1931 129° east was once again the WA/NA border and WA/CA border, both north of 26° south and the WA/SA border south of the 26th parallel.\n\nIn 1931 North Australia and Central Australia were reunited as the Northern Territory.\n(12 June 1931 – MAP).\n\nFrom 1931 to the present 129° east has been the WA/NT border north of 26° south and the WA/SA border south of the 26th parallel.\n\nFixing the position of the border of Western Australia on the ground has a rich history. In March 1920 the Western Australian Government Astronomer, H. B. Curlewis gave a talk at the WA Museum about the history of the determination of longitude, in relation to using what was at that time a new technology, by using wireless time signals to determine the position of the border between South Australia and Western Australia, as close to the 129th east meridian as possible.\n\nPreliminary work on the border determinations began in November 1920 when the Government Astronomer for South Australia, G.F. Dodwell and the Government Astronomer of Western Australia, H.B. Curlewis met at Deakin, Western Australia on the East-West Trans-Australian Railway.\n\nThe other members of the party were Messrs. Clive Melville Hambidge and J. Crabb, of the Survey Department; Warrant Officer V. D. Bowen, in charge of wireless apparatus lent by the Defence Department; and Mr. C. A. Maddern, of the Adelaide Observatory, all from Adelaide.\n\nConcrete piers for the astronomical observing instruments were erected in readiness for the final determinations that were to be held in 1921. Observations were made for the purpose of testing under field conditions the instruments and methods to be used in 1921.\n\nThis expedition, to determine 129° east on the ground, created worldwide scientific interest and involved the cooperation of the Astronomer Royal and the Royal Observatory, Greenwich, with wireless time signals sent by the French wireless Service, that were transmitted from the at Saint-Genis-Laval, near Lyons, France, between 17 and 24 November 1920. Wireless time signals were also sent from the Adelaide Observatory, transmitted by the Adelaide Radio Station, to enable the beats of the Adelaide sidereal clock to be used as a control on the rate of the chronometer used for the boundary observation.\n\nAfter these initial tests a comprehensive program was then arranged for the second stage of the border determinations, which were to take place during the following year and dates were then set for that to happen, from 20 April to 10 May 1921.\n\nOne of the concrete piers mentioned, which were cubic concrete blocks slightly smaller than a cubic metre, would later be named as the Deakin Pillar (1921), being from where the larger border marker, the Deakin Obelisk (1926), would be set out from.\n\nThe Deakin Pillar is approximately 2.82 km west of the Deakin Obelisk. The Deakin Obelisk was erected as closely as was possible with the technology of 1926 to 129° east.\n\nThe Deakin Obelisk has a copper plug embedded into the top centre of the concrete obelisk, which determines, on the ground, the South Australian border with Western Australia by a line drawn south to the coastline of the Great Australian Bight and north through this point to 26° south.\n\nShortly after the 1921 determinations of the border of South Australia and Western Australia, the Government Astronomer for South Australia, G.F. Dodwell and the Government Astronomer of Western Australia, H.B. Curlewis and party travelled by the State Ship Bambra to the port of Wyndham, Western Australia.\nFrom Wyndham they were guided by Michael Patrick (\"M.P.\") Durack to a point he perceived as the northern boundary between his Argyle Downs Station and Jack Kilfoyle's Rosewood Station, which was also Western Australia's border with the Northern Territory or 129° east. Most of Rosewood station is in the Northern Territory but some distance further south Rosewood also extends into the East Kimberley Region of Western Australia.\n\nFrom the chosen position, two concrete pillars were erected similar to those described above and portable radio masts set up, before the determinations were carried out by the scientists using the same methods of wireless time signals as were used at Deakin.\n\nOne of the concrete pillars erected, which was the one used as the point of the determinations, was marked by the expedition party to show how far east of Greenwich they were in hours, minutes and seconds, and became known as the Austral Pillar.\n\nThe Austral Pillar, the point selected for the scientific determinations of 1921 would later be found to be about 2 km east from the border of 129° east on that part of Rosewood Station, therefore inside the Northern Territory.\n\nThe Kimberley Obelisk was erected as closely as was possible with the technology of 1927 to 129° east. Over several weeks during 1927, a Western Australian survey crew from the WA Department of Lands and Surveys travelled to Wyndham, then to the Austral Pillar site to set out from that point to the border, where they then erected the much more substantial Kimberley Obelisk.\n\nThe Kimberley Obelisk has a copper plug embedded into the top of the concrete obelisk, which officially determines the WA/NT border on the ground, near 129° east, by a line drawn north to the northern coastline near the Joseph Bonaparte Gulf and south through this point at the Kimberley Obelisk to the 26th parallel.\n\n"}
