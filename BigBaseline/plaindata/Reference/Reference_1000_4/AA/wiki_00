{"id": "46806415", "url": "https://en.wikipedia.org/wiki?curid=46806415", "title": "Abbreviation (music)", "text": "Abbreviation (music)\n\nAbbreviations in music are of two kinds, namely, abbreviations of terms related to musical expression, and the true musical abbreviations by the help of which certain passages, chords, etc., may be notated in a shortened form, to the greater convenience of both composer and performer. Abbreviations of the first kind are like most abbreviations in language; they consist for the most part of the initial letter or first syllable of the word employed—as for instance, or for the dynamic markings piano and forte, \"cresc.\" for crescendo, \"Ob.\" for oboe, \"Fag.\" for bassoon (). This article is about abbreviations used in music notation. For abbreviations of terms related to musical expression and music in general, see Glossary of musical terminology.\n\nThe continued repetition of a note or chord is expressed by a stroke or strokes across the stem, or above or below the note if it be a whole note or double whole note. The number of strokes denotes the subdivision of the written note into eighth notes, sixteenth notes, etc., unless the word tremolo or tremolando is added, in which case the repetition is as rapid as possible, without regard to the exact number of notes played. (When strokes are added to notes shorter than a quarter note, each beam counts as a stroke.) In the first bar of the example below, the half note with the single stroke across the stem in the \"written\" staff becomes 4 eighth notes in the \"played\" staff. Through the use of 2 strokes across the stem in the second bar, the next full note is expressed as a phrase of 16 sixteenth notes.\n\n\\relative c\" « { \\override Score.TimeSignature #'stencil = ##f } \\new staff { c2:8^\\markup { Written: } <e c g>: | c1:16 | \\time 2/4 f,2:32 | \\time 4/4 f4:8 a:8 c:16 f:16 | b,8:16 d:16 b:16 g:16 a:32 b:32 c:32 d:32 \\bar \"|.\" } \\new staff { c8^\\markup { Played: } c c c <e c g> <e c g> <e c g> <e c g> | c16 c c c c c c c c c c c c c c c | f,32 f f f f f f f f f f f f f f f | f8 f a a c16 c c c f f f f | b, b d d b b g g a32 a a a b b b b c c c c d d d d } »\n</score>\n\nOn bowed instruments the rapid reiteration of a single note is easy, but in piano music an octave or chord becomes necessary to produce a tremolo, the manner of writing and performing of which is seen below.\n\n\\relative c\" « { \\override Score.TimeSignature #'stencil = ##f } \\time 2/4 \\new staff { <g g'>4:16 ^\\markup { \\italic tremolo } <e' c g>:16 | \\repeat tremolo 4 { <c e>16^\\markup { \\italic tremolo } g } | s4 } \\new staff { g'32*8/12 g, g' g, g' g, g' g, g' g, g' g, <c e>32*8/12 g <c e> g <c e> g <c e> g <c e> g <c e> g | <c e>32 g <c e> g <c e> g <c e> g <c e> g <c e> g <c e> g <c e> g | s4 } »\n</score>\n\nIn the abbreviation expressed by strokes, as above, the passage to be abbreviated can contain no note of greater length than an eighth note, but it is possible also to divide a long note into quarter notes, by means of dots (sometimes known as \"divisi\" dots) placed over it, as below.\n\n\\relative c\" « { \\override Score.TimeSignature #'stencil = ##f } \\time 4/4 \\new staff { c2^\\markup { .. } c2^\\markup { .. } | c1^\\markup { ... } | s2 } \\new staff { c4 c c c | c c c c | s2 } »\n</score>\n\nThis is however seldom done, as only a small amount of space is saved. When a long note has to be repeated in the form of triplets or sextuplets, the figure 3 or 6 is usually placed over it in addition to the stroke across the stem, and the note is sometimes, though not necessarily, written dotted.\n\n\\relative c\" « { \\override Score.TimeSignature #'stencil = ##f } \\time 4/4 \\new staff { c4:8^\\markup { \\smaller { \\italic 3 } } c4:8^\\markup { \\smaller { \\italic 3 } } c2:8^\\markup { \\smaller { \\italic 6 } } \\bar \"||\" \\time 4/4 \\omit TupletNumber \\tuplet 3/2 { c4.:8^\\markup { \\smaller { \\italic 3 } } } \\tuplet 3/2 { c4.:8^\\markup { \\smaller { \\italic 3 } } } \\tuplet 6/4 { c4.:16^\\markup { \\smaller { \\italic 6 } } } \\tuplet 6/4 { c4.:16^\\markup { \\smaller { \\italic 6 } } } \\bar \"||\" } \\new staff { \\tuplet 3/2 4 {c8 c c c c c c c c c c c} | \\tuplet 3/2 4 {c8 c c c c c} \\tuplet 6/4 4 {c16 c c c c c c c c c c c} } »\n</score>\n\nThe repetition of a group of two notes is abbreviated by two notes (most often half notes or whole notes) connected by the number of strokes ordinarily used to express eighth notes, sixteenth notes, etc., according to the rate of movement intended, as below. It will be observed that a passage lasting for the value of one half note requires two half notes to express it, on account of the group consisting of two notes.\n\n\\relative c' « { \\override Score.TimeSignature #'stencil = ##f } \\time 4/4 \\new staff { \\repeat tremolo 2 { f8 a } \\repeat tremolo 4 { f16 a} | \\repeat tremolo 4 { f8 a } | s4 } \\new staff { f8 a f a f16 a f a f a f a | f8 a f a f a f a | s4 } »\n</score>\n\nAs seen above, half notes are often written with the strokes beaming the notes together (which is unambiguous as white notes with beams are not otherwise used in music), but with quarter notes and shorter the strokes must be separated from the stems to prevent them being misread as a shorter note value.\n\n\\relative c\" « { \\override Score.TimeSignature #'stencil = ##f } \\time 2/4 \\new staff { \\repeat tremolo 4 { c32 a } \\repeat tremolo 4 { g64 c } \\repeat tremolo 4 { g64 b } | s4 } \\new staff { c32 a c a c a c a g64 [c g c g c g c] g [b g b g b g b] | s4 } »\n</score>\n\nA group of three, four, or more notes is abbreviated by the repetition of the cross strokes without the notes as many times as the group has to be repeated.\n\n\\relative c' « { \\override Score.TimeSignature #'stencil = ##f } \\time 4/4 \\new staff { \\repeat percent 2 { e8[ g c g] } | \\repeat percent 4 { e16 g c g } \\bar \"||\" } \\new staff { e8 g c g e g c g | e16 g c g e g c g e g c g e g c g } »\n</score>\n\nThis can also be written with the notes forming the group are written as a chord, with the necessary number of strokes across the stem. In this case the word \"simili\" or \"segue\" is added, to show that the order of notes in the first group (which must be written out in full) is to be repeated, and to prevent the possibility of mistaking the effect intended for the repetition of the chord as a whole.\n\n\\relative c' « { \\override Score.TimeSignature #'stencil = ##f } \\time 4/4 \\new staff { d16 f a f <d f a>2.:16^\\markup { \\italic simili } | s4 } \\new staff { d16 f a f d f a f d f a f d f a f | s4 } »\n</score>\n\nAnother sign of abbreviation of a group consists of an oblique line with two dots, one on each side; this serves to indicate the repetition of a group of any number of notes of any length. This can even apply to a passage composed of several groups, provided such passage is not more than two bars in length.\n\n\\relative c' « { \\override Score.TimeSignature #'stencil = ##f } \\time 4/4 \\new staff { \\repeat percent 2 { e16 g f e f g a b c g a b c d e f g a g f e d c b a g c b a g a f } \\bar \"||\" } \\new staff { e16 g f e f g a b c g a b c d e f g a g f e d c b a g c b a g a f | e g f e f g a b c g a b c d e f g a g f e d c b a g c b a g a f } »\n</score>\n\nA more usual method of abbreviating the repetition of a passage of the length of the above is to write over it the word \"bis\" (twice), or in some cases \"ter\" (three times), or to enclose it between the dots of an ordinary repeat sign.\n\nPassages intended to be played in octaves are often written as single notes with the words \"coll' ottava\" or \"coll' 8va\" placed above or below them, according as the upper or lower octave is to be added.\n\n« { \\override Score.TimeSignature #'stencil = ##f } \\time 2/4 \\new Staff { c\"8^\\markup { \\smaller { \\italic \"coll' 8\" \\super \\italic \"va\" } } d\" e\" f\" \\bar \"||\" \\clef bass g_\\markup { \\smaller { \\italic \"coll' 8\" \\super \\italic \"va\" } } e c4 \\bar \"||\" s4 } \\new Staff { <c\" c>8 <d\" d> <e\" e> <f\" f> | \\clef bass <g g,> <e e,> <c c,>4 | s4 } »\n</score>\n\nThe word \"8\" (or sometimes \"8 alta\" or \"8 bassa\") written above or below a passage does not add octaves, but merely transposes the passage an octave higher or lower. In clarinet music the word \"chalumeau\" is used to signify that the passage is to be played an octave lower than written.\n\n« { \\override Score.TimeSignature #'stencil = ##f } \\time 4/4 \\new Staff { \\ottava #1 f8 e d c \\ottava #0 b\"^\\markup { \\smaller \\italic loco } a\" g\"4 \\bar \"||\" \\clef bass \\ottava #-1 a,8 b, c, d, \\ottava #0 e_\\markup { \\smaller \\italic loco } f g4 \\bar \"||\" \\clef treble \\ottava #-1 \\set Staff.ottavation = #\"chalumeau\" e8 g c' g f a c' a | g \\ottava #0 e'_\\markup { \\smaller \\italic clar. } g' c\" e\"2 \\bar \"||\" } \\new Staff { f8 e d c b\" a\" g\"4 | \\clef bass a,8 b, c, d, e, f, g,4 | \\clef treble e8 g c' g f a c' a | g e' g' c\" e\"2 } »\n</score>\n\nAll these alterations (which can scarcely be considered abbreviations except that they spare the use of ledger lines) are counteracted, and the passage restored to its usual position, by the ending of the enclosing bracket, the word \"loco\", or in clarinet music \"clarinette\".\n\nIn orchestral music it often happens that certain of the instruments play in unison; when this is the case the parts are sometimes not all written in the score, but the lines belonging to one or more of the instruments are left blank, and the words \"coi violini\" or \"col basso\", etc., are added, to indicate that the instruments in question have to play in unison with the violins or basses, as the case may be, or when two instruments of the same kind, such as first and second violins, have to play in unison, the word \"unisono\" or \"col primo\" is placed instead of the notes in the line belonging to the second. Where two parts are written on one staff in a score the sign \"a 2\" denotes that both play the same notes; and \"a 1\" that the second of the two is resting. The indication \"a 3\" or \"a 4\" at the head of fugues indicates the number of parts or voices in which the fugue is written.\n\nAn abbreviation which is often very troublesome to the conductor occurs in manuscript scores, when a considerable part of the composition is repeated without alteration, and the corresponding number of bars are left vacant, with the remark \"come sopra\" (as above). This is not met with in printed scores.\n\nThere are also abbreviations relating to music analysis, some of which are of great value. In figured bass, for instance, the various chords are expressed by figures, and the several authors in the nineteenth century invented or availed themselves of various methods of shortly expressing the different chords and intervals, particularly using Roman numeral analysis.\n\nGottfried Weber represents an interval by a number with one or two dots before it to express minor or diminished, and one or two after it for major or augmented.\n\nJohann Anton André makes use of a right triangle to express a triad, and a square, for a seventh chord, the inversions being indicated by one, two, or three small vertical lines across their base, and the classification into major, minor, diminished, or augmented by the numbers 1, 2, 3, or 4, placed in the centre.\n"}
{"id": "20831654", "url": "https://en.wikipedia.org/wiki?curid=20831654", "title": "Alan Palmer", "text": "Alan Palmer\n\nAlan Warwick Palmer (born 1926) is a British author of historical and biographical books.\n\nPalmer was educated at Bancroft's School, Woodford Green, London, and Oriel College, Oxford. He spent 19 years as senior history teacher at Highgate School before becoming a full-time writer and researcher. His late wife, Veronica Palmer collaborated on several of his books.\n\nHe was elected a Fellow of the Royal Society of Literature in 1980.\n\n\n\n"}
{"id": "2887701", "url": "https://en.wikipedia.org/wiki?curid=2887701", "title": "Bible (screenwriting)", "text": "Bible (screenwriting)\n\nA bible (also known as a story bible, show bible, series bible, or pitch bible) is a reference document used by screenwriters for information on a television series' characters, settings, and other elements.\n\nShow bibles are updated with information on the characters after the information has been established on screen. For example, the \"Frasier\" show bible was \"scrupulously maintained\", and anything established on air — \"the name of Frasier's mother, Niles' favorite professor, Martin's favorite bar...even a list of Maris' [dozens of] food allergies\" — was reflected in the bible. The updated bible then serves as a resource for writers to keep everything within the series consistent. \n\nOther show bibles are used as sales documents to help a television network or studio understand a series, and are sometimes given to new writers when they join the writing staff for the same reason. These types of bibles discuss the backstories of the main characters and the history of the series' fictional universe.\n\nTelevision series often rely on writers' assistants and script coordinators to serve as \"walking bibles\" in remembering details about a series.\n\nIn the United States, writing the show bible of a produced series earns that writer the 24 units of required credit necessary to qualify for membership in the Writers Guild of America.\n\n\n"}
{"id": "27778631", "url": "https://en.wikipedia.org/wiki?curid=27778631", "title": "Breviograph", "text": "Breviograph\n\nA breviograph or brevigraph (from , short, and Greek \"grapho\", to write) is a type of scribal abbreviation in the form of an easily written symbol, character, flourish or stroke, based on a modified letter form to take the place of a common letter combination, especially those occurring at the beginning or end of a word. Breviographs were used frequently by stenographers, law clerks and scriveners, and they were also found in early printed books and tracts. Their use declined after the 17th century.\n\nExamples of breviographs:\n\n\n"}
{"id": "10018490", "url": "https://en.wikipedia.org/wiki?curid=10018490", "title": "Citation Style Language", "text": "Citation Style Language\n\nThe Citation Style Language (CSL) is an open XML-based language to describe the formatting of citations and bibliographies. Reference management programs using CSL include Zotero, Mendeley and Papers.\n\nCSL was created by Bruce D'Arcus for use with OpenOffice.org, and an XSLT-based \"CiteProc\" CSL processor. CSL was further developed in collaboration with Zotero developer Simon Kornblith. Since 2008, the core development team consists of D'Arcus, Frank Bennett and Rintze Zelle.\n\nThe releases of CSL are 0.8 (March 21, 2009), 0.8.1 (February 1, 2010), 1.0 (March 22, 2010), and 1.0.1 (September 3, 2012). CSL 1.0 was a backward-incompatible release, but styles in the 0.8.1 format can be automatically updated to the CSL 1.0 format.\n\nOn its release in 2006, Zotero became the first application to adopt CSL. In 2008 Mendeley was released with CSL support, and in 2011, Papers and Qiqqa gained support for CSL-based citation formatting.\n\n\nThe CSL project maintains a CSL 1.0 style repository, which contains over 9000 styles (more than 1700 unique styles).\n\n"}
{"id": "1809113", "url": "https://en.wikipedia.org/wiki?curid=1809113", "title": "Comparative biology", "text": "Comparative biology\n\nComparative biology uses natural variation and disparity to understand the patterns of life at all levels—from genes to communities—and the critical role of organisms in ecosystems. Comparative biology is a cross-lineage approach to understanding the phylogenetic history of individuals or higher taxa and the mechanisms and patterns that drives it. Comparative biology encompasses Evolutionary Biology, Systematics, Neontology, Paleontology, Ethology, Anthropology, and Biogeography as well as historical approaches to Developmental biology, Genomics, Physiology, Ecology and many other areas of the biological sciences.The comparative approach also has numerous applications in human health, genetics, biomedicine, and conservation biology. The biological relationships (phylogenies, pedigree) are important for comparative analyses and usually represented by a phylogenetic tree or cladogram to differentiate those features with single origins (Homology) from those with multiple origins (Homoplasy).\n\n"}
{"id": "16264661", "url": "https://en.wikipedia.org/wiki?curid=16264661", "title": "Comparative case", "text": "Comparative case\n\nThe comparative case (abbreviated ) is a grammatical case used in languages such as Mari and Chechen to mark a likeness to something. \n\nIt is not to be confused with the comparative degree, a much more widely used paradigm used to signify heightening of adjectives and adverbs.\n\nIn Mari, the comparative case is marked with the suffix -ла ('-la') For example, if something were to taste like fish (кол - 'kol'), the form used would be колла - 'kolla'). It is also used in regard to languages, when denoting the language a person is speaking, writing, or hearing. Then, however, the accentuation varies slightly from the standard case. Usually, the suffix is not stressed. When it is used with languages, however, it is stressed.\n\nIn Chechen, it is marked with the suffix \"-l\". For example, \"sha\" is 'ice', \"shiila\" is 'cold', and \"shal shiila\" is 'cold as ice'.\n\n"}
{"id": "4481195", "url": "https://en.wikipedia.org/wiki?curid=4481195", "title": "Comparative cultural studies", "text": "Comparative cultural studies\n\nComparative cultural studies is a contextual approach to the study of culture in a global and intercultural context. Focus is placed on the theory, method, and application of the study process(es) rather than on the \"what\" of the object(s) of study.\n\nIn comparative cultural studies, selected tenets of comparative literature are merged with selected tenets of the field of cultural studies (including culture theories, (radical) constructivism, communication theories, and systems theories) with the objective to study culture and culture products (including but not restricted to literature, communication, media, art, etc.). This is performed in a contextual and relational construction and with a plurality of methods and approaches, interdisciplinary, and, if and when required, including teamwork. In comparative cultural studies, it is the processes of communicative action(s) in culture and the how of these processes that constitute the main objectives of research and study. However, scholarship in comparative cultural studies does not exclude textual analysis proper of other established fields of study. In comparative cultural studies, ideally, the framework of and methodologies available in the systemic and empirical study of culture are favored. Scholarship in comparative cultural studies includes the theoretical, as well as methodological and applied postulate to move and to dialogue between cultures, languages, literature, and disciplines: attention to other cultures against essentialist notions and practices and beyond the paradigm of the nation-state is a basic and founding element of the framework and its application.\n\n\n"}
{"id": "9435784", "url": "https://en.wikipedia.org/wiki?curid=9435784", "title": "Comparative physiology", "text": "Comparative physiology\n\nComparative physiology is a subdiscipline of physiology that studies and exploits the diversity of functional characteristics of various kinds of organisms. It is closely related to evolutionary physiology and environmental physiology. Many universities offer undergraduate courses that cover comparative aspects of animal physiology. According to Clifford Ladd Prosser, \"Comparative Physiology\nis not so much a defined discipline as a viewpoint, a philosophy.\"\n\nOriginally, physiology focused primarily on human beings, in large part from a desire to improve medical practices. When physiologists first began comparing different species it was sometimes out of simple curiosity to understand how organisms work but also stemmed from a desire to discover basic physiological principles. This use of specific organisms convenient to study specific questions is known as the Krogh Principle.\n\nC. Ladd Prosser, a founder of modern comparative physiology, outlined a broad agenda for comparative physiology in his 1950 edited volume (see summary and discussion in Garland and Carter):\n\n1. To describe how different kinds of animals meet their needs.\n\n2. The use of physiological information to reconstruct phylogenetic relationships of organisms.\n\n3. To elucidate how physiology mediates interactions between organisms and their environments.\n\n4. To identify \"model systems\" for studying particular physiological functions.\n\n5. To use the \"kind of animal\" as an experimental variable.\n\nComparative physiologists often study organisms that live in \"extreme\" environments (e.g., deserts) because they expect to find especially clear examples of evolutionary adaptation. One example is the study of water balance in desert-inhabiting mammals, which have been found to exhibit kidney specializations.\n\nSimilarly, comparative physiologists have been attracted to \"unusual\" organisms, such as very large or small ones. As an example, of the latter, hummingbirds have been studied. As another example, giraffe have been studied because of their long necks and the expectation that this would lead to specializations related to the regulation of blood pressure. More generally, ectothermic vertebrates have been studied to determine how blood acid-base balance and pH change as body temperature changes.\n\nIn the United States, research in comparative physiology is funded by both the National Institutes of Health and the National Science Foundation.\n\nA number of scientific societies feature sections on comparative physiology, including:\n\nKnut Schmidt-Nielsen (1915–2007) was a major figure in vertebrate comparative physiology, serving on the faculty at Duke University for many years and training a large number of students (obituary). He also authored several books, including an influential text, all known for their accessible writing style.\n\nGrover C. Stephens (1925–2003) was a well-known invertebrate comparative physiologist, serving on the faculty of the University of Minnesota until becoming the founding chairman of the Department of Organismic Biology at the University of California at Irvine in 1964. He was the mentor for numerous graduate students, many of whom have gone on to further build the field (obituary). He authored several books and in addition to being an accomplished biologist was also an accomplished pianist and philosopher.\n\n\n\n"}
{"id": "1719952", "url": "https://en.wikipedia.org/wiki?curid=1719952", "title": "Comparative research", "text": "Comparative research\n\nComparative research is a research methodology in the social sciences that aims to make comparisons across different countries or cultures. A major problem in comparative research is that the data sets in different countries may not use the same categories, or define categories differently (for example by using different definitions of poverty).\n\nAs Moutsios argues, cross-cultural and comparative research should be seen as part of the scientific spirit that arose in Greece in the 6th century and the overall appreciation of knowledge and learning that was characteristic of the 5th century. In other words, it is part of the emergence of \"episteme\" and \"philo-sophia\", as a love for knowledge that is independent from material benefits. \"Episteme\", as a form and activity in the field of \"logos\", marked the break of cognitive closure and advanced empirical inquiry, logical argumentation and the search for truth. And the high esteem for intellectual activity gave rise to a genuine curiosity about other cultures – which has lain thereafter at the heart of comparative inquiry.\n\nMoreover, behind the Greek comparative gaze also was the philosophical and political questioning which characterised the life of the democratic \"polis\". Philosophical inquiry, from the Milesians down to the Sophists, questioned the representations and the cognitive traditions of their own people; the inquiry of the traditions of other peoples was, as Herodotus’ \"Histories\" demonstrate, an activity associated with the ethos of philosophical critique that characterised democratic life in Greece. Similarly, questioning of the Greek laws and institutions and its related values and practices (e.g. \"isegoria\" and \"parrhesia\"), as part of Greek politics, is associated with the effort of the first historians to reflect on home institutions through researching those of others.\n\nAccording also to Karl Deutsch, we have been using this form of investigation for over 2,000 years. Comparing things is essential to basic scientific and philosophic inquiry, which has been done for a long time. Most authors are more conservative in their estimate of how long comparative research has been with us. It is largely an empty debate over the definition of the tradition with those questioning whether comparing things counts as comparative research.\n\nTextbooks on this form of study were beginning to appear by the 1880s, but its rise to extreme popularity began after World War II. There are numerous reasons that comparative research has come to take a place of honour in the toolbox of the social scientist. Globalization has been a major factor, increasing the desire and possibility for educational exchanges and intellectual curiosity about other cultures. Information technology has enabled greater production of quantitative data for comparison, and international communications technology has facilitated this information to be easily spread.\n\nComparative research, simply put, is the act of comparing two or more things with a view to discovering something about one or all of the things being compared. This technique often utilizes multiple disciplines in one study. When it comes to method, the majority agreement is that there is no methodology peculiar to comparative research. The multidisciplinary approach is good for the flexibility it offers, yet comparative programs do have a case to answer against the call that their research lacks a \"seamless whole.\" \n\nThere are certainly methods that are far more common than others in comparative studies, however. Quantitative analysis is much more frequently pursued than qualitative, and this is seen by the majority of comparative studies which use quantitative data. The general method of comparing things is the same for comparative research as it is in our everyday practice of comparison. Like cases are treated alike, and different cases are treated differently; the extent of difference determines how differently cases are to be treated. If one is able to sufficiently distinguish two carry the research conclusions will not be very helpful. \n\nSecondary analysis of quantitative data is relatively widespread in comparative research, undoubtedly in part because of the cost of obtaining primary data for such large things as a country's policy environment. This study is generally aggregate data analysis. Comparing large quantities of data (especially government sourced) is prevalent. A typical method of comparing welfare states is to take balance of their levels of spending on social welfare.\n\nIn line with how a lot of theorizing has gone in the last century, comparative research does not tend to investigate \"grand theories,\" such as Marxism. It instead occupies itself with middle-range theories that do not purport to describe our social system in its entirety, but a subset of it. A good example of this is the common research program that looks for differences between two or more social systems, then looks at these differences in relation to some other variable coexisting in those societies to see if it is related. The classic case of this is Esping-Andersen's research on social welfare systems. He noticed there was a difference in types of social welfare systems, and compared them based on their level of decommodification of social welfare goods. He found that he was able to class welfare states into three types, based on their level of decommodification. He further theorized from this that decommodification was based on a combination of class coalitions and mobilization, and regime legacy. Here, Esping-Andersen is using comparative research: he takes many western countries and compares their level of decommodification, then develops a theory of the divergence based on his findings.\n\nComparative research can take many forms. Two key factors are space and time. Spatially, cross-national comparisons are by far the most common, although comparisons within countries, contrasting different areas, cultures or governments also subsist and are very constructive, especially in a country like New Zealand, where policy often changes depending on which race it pertains to. Recurrent interregional studies include comparing similar or different countries or sets of countries, comparing one's own country to others or to the whole world.\n\nThe historical comparative research involves comparing different time-frames. The two main choices within this model are comparing two stages in time (either snapshots or time-series), or just comparing the same thing over time, to see if a policy's effects differ over a stretch of time.\n\nWhen it comes to subject matter of comparative inquiries, many contend there is none unique to it. This may indeed be true, but a brief perusal of comparative endeavours reveals there are some topics more recurrent than others. Determining whether socioeconomic or political factors are more important in explaining government action is a familiar theme. In general, however, the only thing that is certain in comparative research issues is the existence of differences to be analysed.\n\n\n"}
{"id": "2466507", "url": "https://en.wikipedia.org/wiki?curid=2466507", "title": "Comparative sociology", "text": "Comparative sociology\n\nComparative sociology involves comparison of the social processes between nation states, or across different types of society (for example capitalist and socialist). There are two main approaches to comparative sociology: some seek similarity across different countries and cultures whereas others seek variance. For example, structural Marxists have attempted to use comparative methods to discover the general processes that underlie apparently different social orderings in different societies. The danger of this approach is that the different social contexts are overlooked in the search for supposed universal structures.\n\nOne sociologist who employed comparative methods to understand variance was Max Weber, whose studies attempted to show how differences between cultures explained the different social orderings that had emerged (see for example \"The Protestant Ethic and the Spirit of Capitalism\" and Sociology of religion).\n\nThere is some debate within sociology regarding whether the label of 'comparative' is suitable. Emile Durkheim argued in \"The Rules of Sociological Method\" (1895) that all sociological research was in fact comparative since social phenomenon are always held to be typical, representative or unique, all of which imply some sort of comparison. In this sense, all sociological analysis is comparative and it has been suggested that what is normally referred to as comparative research, may be more appropriately called cross-national research.\n\n"}
{"id": "11797804", "url": "https://en.wikipedia.org/wiki?curid=11797804", "title": "Comparison (grammar)", "text": "Comparison (grammar)\n\nComparison is a feature in the morphology or syntax of some languages, whereby adjectives and adverbs are inflected or modified to indicate the relative degree of the property defined by the adjective or adverb. The comparative expresses a comparison between two (or more) entities or groups of entities in quality, quantity, or degree; the superlative is the form of an adverb or adjective that is the greatest degree of a given descriptor.\n\nThe grammatical category associated with comparison of adjectives and adverbs is degree of comparison. The usual degrees of comparison are the \"positive\", which simply denotes a property (as with the English words \"big\" and \"fully\"); the \"comparative\", which indicates \"greater degree (as \"bigger\" and \"more fully\"); and the \"superlative\", which indicates \"greatest degree (as \"biggest\" and \"most fully\"). Some languages have forms indicating a very large degree of a particular quality (called elative in Semitic linguistics). Other languages (e.g. English) can express lesser degree, e.g. \"beautiful\", \"less beautiful\", \"least beautiful\".\n\nThe comparative is frequently associated with adjectives and adverbs because these words take the \"-er\" suffix or modifying word \"more\" or \"less\" (e.g., \"faster\", \"more intelligent\", \"less wasteful\"); it can also, however, appear when no adjective or adverb is present, for instance with nouns (e.g., \"more men than women\"). One preposition, \"near\", also has a superlative form, as in \"Find the restaurant nearest your house\".\n\nComparatives and superlatives may be formed morphologically, by inflection, as with the English and German \"-er\" and \"-(e)st\" forms, or syntactically, as with the English \"more...\" and \"most...\" and the French \"plus...\" and \"le plus...\" forms. Common adjectives and adverbs often produce irregular forms, such as \"better\" and \"best\" (from \"good\") and \"less\" and \"least\" (from \"little/few\") in English, and \"meilleur\" (from \"bon\") and \"mieux\" (from the adverb \"bien\") in French.\n\nMost if not all languages have some means of forming the comparative, although these means can vary significantly from one language to the next.\n\nComparatives are often used with a conjunction or other grammatical means to indicate with what the comparison is being made, as with \"than\" in English, \"als\" in German, etc. In Russian and Greek (Ancient, Koine and Modern) this can be done by placing the compared noun in the genitive case. With superlatives, the class of things being considered for comparison may be indicated, as in \"the best swimmer out of all the girls\".\n\nLanguages also possess other structures for comparing adjectives and adverbs; English examples include \"as... as\" and \"less/least...\".\n\nА few languages apply comparison to nouns and even verbs. One such language is Bulgarian, where expressions like \"по̀ човек (po chovek), най човек (nay chovek), по-малко човек (po malko chovek)\" (literally \"more person\", \"most person\", \"less person\" but normally \"better kind of a person\", \"best kind of person\", \"not that good kind of a person\") and \"по̀ обичам (po obicham), най-малко обичам (nay malko obicham)\" (\"I like more\", \"I like the least\") are quite usual.\n\nIn many languages, including English, traditional grammar requires the comparative form to be used when exactly two things are being considered, even in constructions where the superlative would be used when considering a larger number. For instance, \"May the better man win\" would be considered correct if there are only two individuals competing. However, this rule is not always observed in informal usage; the form \"May the best man win\" will often be used in that situation, as it would if there were three or more competitors involved.\n\nIn some contexts, such as advertising or political speeches, absolute and relative comparatives are intentionally employed in a way that invites a comparison, and yet the basis of comparison is not established. This is a common rhetorical device used to create an implication of significance where one may not actually be present. Although such usage is common, it is sometimes considered ungrammatical.\n\nFor example:\n\nEnglish has two parallel systems of comparison, a morphological one formed using the suffixes \"-er\" (the \"comparative\") and \"-est\" (the \"superlative\"), with some irregular forms; and a syntactic one, formed with the adverbs \"more\" and \"most\".\n\nAs a general rule, words with one syllable require the suffix (except for the four words: fun, real, right, wrong), words with three or more syllables require \"more\" or \"most\", and words with two syllables may use one system or the other; which words use which system is a matter of idiom. Some adjectives, \"e.g.\" 'polite', can use either form, with different frequencies according to context.\n\nMorphological comparison uses the suffixes \"-er\" (the \"comparative\") and \"-est\" (the \"superlative\"). These inflections are of Germanic origin and are cognate with the Latin suffixes -\"ior\" and -\"issimus\" and Ancient Greek -\"īōn\" and -\"istos\". They are typically added to shorter words, words of Anglo-Saxon origin, and borrowed words which have been fully assimilated into the English vocabulary. Usually the words which take these inflections have fewer than three syllables.\n\nThis system also contains a number of irregular forms, some of which, like \"good\", \"better\", and \"best\", contain suppletive forms. These irregular forms include:\n\nThe second system of comparison in English appends the grammatical particles \"more\" and \"most\", themselves the irregular comparatives of \"many\" and \"much\", to the adjective or adverb being modified. This series can be compared to a system containing the diminutives \"less\" and \"least\".\n\nThis system is most commonly used with words of French or Latin derivation; with adjectives and adverbs formed with suffixes other than \"-ly\" (e.g., \"beautiful\"); and with longer, technical, or infrequently used words. For example:\n\nSome adjectives, the absolute or ungradable adjectives do not appear to logically allow degrees. Some qualities are either \"present\" or \"absent\", such as being Cretaceous or igneous, so it appears illogical to call anything \"very Cretaceous\", or to characterize something as \"more igneous\" than something else.\n\nSome grammarians object to the use of the superlative or comparative with words such as \"full\", \"complete\", \"unique\", or \"empty\", which by definition already denote either a totality, an absence, or an absolute. However, such words are routinely and frequently qualified in contemporary speech and writing. This type of usage conveys more of a figurative than a literal meaning, because in a strictly literal sense, something cannot be more or less unique or empty to a greater or lesser degree.\n\nMany prescriptive grammars and style guides include adjectives for inherently superlative qualities to be ungradable. Thus, they reject expressions such as \"more perfect\", \"most unique\", and \"most parallel\" as illogical pleonasms: after all, if something is unique, it is one of a kind, so nothing can be \"very unique\", or \"more unique\" than something else.\n\nOther style guides argue that terms like \"perfect\" and \"parallel\" never apply \"exactly\" to things in real life, so they are commonly used to mean \"nearly perfect\", \"nearly parallel\", and so on; in this sense, \"more perfect\" (\"i.e.\", more nearly perfect, closer to perfect) and \"more parallel\" (\"i.e.\", more nearly parallel, closer to parallel) are meaningful.\n\nIn most Balto-Slavic languages (such as Czech, Polish, Lithuanian and Latvian), the comparative and superlative forms are also declinable adjectives.\n\nIn Bulgarian, comparative and superlative forms are formed with the clitics \"по-\" (\"more\") and \"най-\" (\"most\"):\n\nIn Czech, Polish, Slovak and Slovene, comparative is formed from the base form of an adjective with a suffix and superlative is formed with a circumfix (equivalent to adding a prefix to the comparative).\n\nIn Russian, comparative and superlative forms are usually formed with a suffix:\n\nIn contrast to English, the relative and the superlative are joined into the same degree (the superlative), which can be of two kinds: comparative (e.g. \"the most beautiful\") and absolute (e.g. \"very beautiful\").\n\nFrench: The superlative is created from the comparative by inserting the definitive article (la, le, or les), or the possessive article (\"mon\", \"ton\", \"son\", etc.), before \"plus\" or \"moins\" and the adjective determining the noun. For instance: \"Elle est la plus belle femme\" → (she is the most beautiful woman); \"Cette ville est la moins chère de France\" → (this town is the least expensive in France); \"C'est sa plus belle robe\" → (It is her most beautiful dress). It can also be created with the suffix \"-issime\" but only with certain words, for example: \"C'est un homme richissime\" → (That is the most rich man). Its use is often rare and ironic.\n\nPortuguese and Italian distinguish comparative superlative \"(superlativo relativo)\" and absolute superlative \"(superlativo absoluto/assoluto).\nFor the comparative superlative they use the words \"mais\" and \"più\" between the article and the adjective, like \"most\" in English.\nFor the absolute superlative they either use \"muito\"/\"molto\" and the adjective or modify the adjective by taking away the final vowel and adding \"issimo\" (singular masculine), \"issima\" (singular feminine), \"íssimos\"/\"issimi\" (plural masculine), or \"íssimas\"/\"issime\" (plural feminine). For example:\nThere are some irregular forms for some words ending in \"-re\" and \"-le\" (deriving from Latin words ending in \"-er\" and \"-ilis\") that have a superlative form similar to the Latin one. In the first case words lose the ending \"-re\" and they gain the endings \"errimo\" (singular masculine), \"errima\" (singular feminine), \"érrimos\"/\"errimi\" (plural masculine), or \"érrimas\"/\"errime\" (plural feminine); in the second case words lose the \"-l\"/\"-le\" ending and gain \"ílimo\"/\"illimo\" (singular masculine), \"ílima\"/\"illima\" (singular feminine), \"ílimos\"/\"illimi\" (plural masculine), or \"íli\nRomanian, similar to Portuguese and Italian, distinguishes comparative and absolute superlatives. The comparative uses the word \"mai\" before the adjective, which operates like \"more\" or \"-er\" in English. For example: \"luminos\" → bright, \"mai luminos\" → brighter. To weaken the adjective, the word \"puțin\" (little) is added between \"mai\" and the adjective, for example \"mai puțin luminos\" → less bright. For absolute superlatives, the gender-dependent determinant \"cel\" precedes \"mai,\" conjugated as \"cel / cei\" for male singular / plural and \"cea / cele\" for female singular / plural. For example: \"cea mai luminoasă stea\" → the brightest star; \"cele mai frumoase fete\" → the most beautiful girls; \"cel mai mic morcov\" → the smallest carrot.\n\nScottish Gaelic: When comparing one entity to another in the present or the future tense, the adjective is changed by adding an \"e\" to the end and \"i\" before the final consonant(s) if the final vowel is broad. Then, the adjective is preceded by \"nas\" to say \"more,\" and \"as\" to say \"most.\" (The word \"na\" is used to mean \"than\".) Adjectives that begin with \"f\" are lenited. and \"as\" use different syntax constructions. For example:\nTha mi nas àirde na mo pheathraichean.\" → I am taller than my sisters.\nIs mi as àirde.\" → I am the tallest.\n\nAs in English, some forms are irregular, i.e. nas fheàrr (better), nas miosa (worse), etc.\n\nIn other tenses, \"nas\" is replaced by \"na bu\" and \"as\" by \"a bu,\" both of which lenite the adjective if possible. If the adjective begins with a vowel or an \"f\" followed by a vowel, the word \"bu\" is reduced to \"b\"'. For example:\n\n\nWelsh is similar to English in many respects. The ending \"-af\" is added onto regular adjectives in a similar manner to the English \"-est\", and with (most) long words \"mwyaf\" precedes it, as in the English \"most\". Also, many of the most common adjectives are irregular. Unlike English, however, when comparing just two things, the superlative \"must\" be used, e.g. of two people - \"John ydy'r talaf\" (John is the tallest).\n\nIn Akkadian cuneiform, (on a 12 paragraph clay tablet), from the time period of the 1350 BC Amarna letters (a roughly 20-year body of letters), two striking examples of the superlative extend the common grammatical use. The first is the numeral \"10,\" as well as \"7 and 7.\" The second is a verb-spacement adjustment.\n\nThe term \"7 and 7\" means 'over and over'. The phrase itself is a superlative, but an addition to some of the Amarna letters adds \"more\" at the end of the phrase (EA 283, \"Oh to see the King-(pharaoh)):\" \"... I fall at the feet of the king, my lord. I fall at the feet of the king, my lord, 7 and 7 times\" more, \"...\". The word 'more' is Akkadian \"mila\", and by Moran is 'more' or 'overflowing'. The meaning in its letter context is \"...over and over again, overflowing,\" (as 'gushingly', or 'obsequiously', as an underling of the king).\n\nThe numeral 10 is used for \"ten times greater\" in EA 19, \"Love and Gold\", one of King Tushratta's eleven letters to the Pharaoh-(Amenhotep IV-\"Akhenaton\"). The following quote using 10, also closes out the small paragraph by the second example of the superlative, where the verb that ends the last sentence is spread across the letter in s-p-a-c-i-n-g, to accentuate the last sentence, and the verb itself (i.e. the relational kingly topic of the paragraph):\n\nThe actual last paragraph line contains three words: 'may it be', 'flourish', and 'us'. The verb flourish (from napāhu?, \"to light up, to rise\"), uses: -e-le-né-ep-pi-, and the spaces. The other two words on the line, are made from two characters, and then one: \"...may it be, flourish-our (relations).\"\n\nIn Estonian, the superlative form can usually be formed in two ways. One is a periphrastic construction with \"kõige\" followed by the comparative form. This form exists for all adjectives. For example: the comparative form of \"sinine\" 'blue' is \"sinisem\" and therefore the periphrastic superlative form is \"kõige sinisem\". There is also a synthetic (\"short\") superlative form, which is formed by adding \"-m\" to the end of the plural partitive case. For \"sinine\" the plural partitive form is \"siniseid\" and so \"siniseim\" is the short superlative. The short superlative does not exist for all adjectives and, in contrast to the \"kõige\"-form, has a lot of exceptions.\n\n"}
{"id": "1338683", "url": "https://en.wikipedia.org/wiki?curid=1338683", "title": "Corecursion", "text": "Corecursion\n\nIn computer science, corecursion is a type of operation that is dual to recursion. Whereas recursion works analytically, starting on data further from a base case and breaking it down into smaller data and repeating until one reaches a base case, corecursion works synthetically, starting from a base case and building it up, iteratively producing data further removed from a base case. Put simply, corecursive algorithms use the data that they themselves produce, bit by bit, as they become available, and needed, to produce further bits of data. A similar but distinct concept is \"generative recursion\" which may lack a definite \"direction\" inherent in corecursion and recursion.\n\nWhere recursion allows programs to operate on arbitrarily complex data, so long as they can be reduced to simple data (base cases), corecursion allows programs to produce arbitrarily complex and potentially infinite data structures, such as streams, so long as it can be produced from simple data (base cases) in a sequence of \"finite\" steps. Where recursion may not terminate, never reaching a base state, corecursion starts from a base state, and thus produces subsequent steps deterministically, though it may proceed indefinitely (and thus not terminate under strict evaluation), or it may consume more than it produces and thus become non-\"productive\". Many functions that are traditionally analyzed as recursive can alternatively, and arguably more naturally, be interpreted as corecursive functions that are terminated at a given stage, for example recurrence relations such as the factorial.\n\nCorecursion can produce both finite and infinite data structures as results, and may employ self-referential data structures. Corecursion is often used in conjunction with lazy evaluation, to produce only a finite subset of a potentially infinite structure (rather than trying to produce an entire infinite structure at once). Corecursion is a particularly important concept in functional programming, where corecursion and codata allow total languages to work with infinite data structures.\n\nCorecursion can be understood by contrast with recursion, which is more familiar. While corecursion is primarily of interest in functional programming, it can be illustrated using imperative programming, which is done below using the generator facility in Python. In these examples local variables are used, and assigned values imperatively (destructively), though these are not necessary in corecursion in pure functional programming. In pure functional programming, rather than assigning to local variables, these computed values form an invariable sequence, and prior values are accessed by self-reference (later values in the sequence reference earlier values in the sequence to be computed). The assignments simply express this in the imperative paradigm and explicitly specify where the computations happen, which serves to clarify the exposition.\n\nA classic example of recursion is computing the factorial, which is defined recursively by \"0! := 1\" and \"n! := n × (n - 1)!\".\n\nTo \"recursively\" compute its result on a given input, a recursive function calls (a copy of) \"itself\" with a different (\"smaller\" in some way) input and uses the result of this call to construct its result. The recursive call does the same, unless the \"base case\" has been reached. Thus a call stack develops in the process. For example, to compute \"fac(3)\", this recursively calls in turn \"fac(2)\", \"fac(1)\", \"fac(0)\" (\"winding up\" the stack), at which point recursion terminates with \"fac(0) = 1\", and then the stack unwinds in reverse order and the results are calculated on the way back along the call stack to the initial call frame \"fac(3)\" that uses the result of \"fac(2) = 2\" to calculate the final result as \"3 × 2 = 3 × fac(2) =: fac(3)\" and finally return \"fac(3) = 6\". In this example a function returns a single value.\n\nThis stack unwinding can be explicated, defining the factorial \"corecursively\", as an iterator, where one \"starts\" with the case of formula_1, then from this starting value constructs factorial values for increasing numbers \"1, 2, 3...\" as in the above recursive definition with \"time arrow\" reversed, as it were, by reading it \"backwards\" as The corecursive algorithm thus defined produces a \"stream\" of \"all\" factorials. This may be concretely implemented as a generator. Symbolically, noting that computing next factorial value requires keeping track of both \"n\" and \"f\" (a previous factorial value), this can be represented as:\nor in Haskell, \n\nmeaning, \"starting from formula_3, on each step the next values are calculated as formula_4\". This is mathematically equivalent and almost identical to the recursive definition, but the formula_5 emphasizes that the factorial values are being built \"up\", going forwards from the starting case, rather than being computed after first going backwards, \"down\" to the base case, with a formula_6 decrement. Note also that the direct output of the corecursive function does not simply contain the factorial formula_7 values, but also includes for each value the auxiliary data of its index \"n\" in the sequence, so that any one specific result can be selected among them all, as and when needed.\n\nNote the connection with denotational semantics, where the denotations of recursive programs is built up corecursively in this way.\n\nIn Python, a recursive factorial function can be defined as:\n\nThis could then be called for example as codice_1 to compute \"5!\".\n\nA corresponding corecursive generator can be defined as:\n\nThis generates an infinite stream of factorials in order; a finite portion of it can be produced by:\n\nThis could then be called to produce the factorials up to \"5!\" via:\n\nIf we're only interested in a certain factorial, just the last value can be taken, or we can fuse the production and the access into one function,\n\nAs can be readily seen here, this is practically equivalent (just by substituting codice_2 for the only codice_3 there) to the accumulator argument technique for tail recursion, unwound into an explicit loop. Thus it can be said that the concept of corecursion is an explication of the embodiment of iterative computation processes by recursive definitions, where applicable.\n\nIn the same way, the Fibonacci sequence can be represented as:\nNote that because the Fibonacci sequence is a recurrence relation of order 2, the corecursive relation must track two successive terms, with the formula_9 corresponding to shift forward by one step, and the formula_10 corresponding to computing the next term. This can then be implemented as follows (using parallel assignment):\n\nIn Haskell, \n\nTree traversal via a depth-first approach is a classic example of recursion. Dually, breadth-first traversal can very naturally be implemented via corecursion.\n\nWithout using recursion or corecursion specifically, one may traverse a tree by starting at the root node, placing its child nodes in a data structure, then iterating by removing node after node from the data structure while placing each removed node's children back into that data structure. If the data structure is a stack (LIFO), this yields depth-first traversal, and if the data structure is a queue (FIFO), this yields breadth-first traversal.\n\nUsing recursion, a (post-order) depth-first traversal can be implemented by starting at the root node and recursively traversing each child subtree in turn (the subtree based at each child node) – the second child subtree does not start processing until the first child subtree is finished. Once a leaf node is reached or the children of a branch node have been exhausted, the node itself is visited (e.g., the value of the node itself is outputted). In this case, the call stack (of the recursive functions) acts as the stack that is iterated over.\n\nUsing corecursion, a breadth-first traversal can be implemented by starting at the root node, outputting its value, then breadth-first traversing the subtrees – i.e., passing on the \"whole list\" of subtrees to the next step (not a single subtree, as in the recursive approach) – at the next step outputting the value of all of their root nodes, then passing on their child subtrees, etc. In this case the generator function, indeed the output sequence itself, acts as the queue. As in the factorial example (above), where the auxiliary information of the index (which step one was at, \"n\") was pushed forward, in addition to the actual output of \"n\"!, in this case the auxiliary information of the remaining subtrees is pushed forward, in addition to the actual output. Symbolically:\nmeaning that at each step, one outputs the list of values of root nodes, then proceeds to the child subtrees. Generating just the node values from this sequence simply requires discarding the auxiliary child tree data, then flattening the list of lists (values are initially grouped by level (depth); flattening (ungrouping) yields a flat linear list). In Haskell, \nThese can be compared as follows. The recursive traversal handles a \"leaf node\" (at the \"bottom\") as the base case (when there are no children, just output the value), and \"analyzes\" a tree into subtrees, traversing each in turn, eventually resulting in just leaf nodes – actual leaf nodes, and branch nodes whose children have already been dealt with (cut off \"below\"). By contrast, the corecursive traversal handles a \"root node\" (at the \"top\") as the base case (given a node, first output the value), treats a tree as being \"synthesized\" of a root node and its children, then produces as auxiliary output a list of subtrees at each step, which are then the input for the next step – the child nodes of the original root are the root nodes at the next step, as their parents have already been dealt with (cut off \"above\"). Note also that in the recursive traversal there is a distinction between leaf nodes and branch nodes, while in the corecursive traversal there is no distinction, as each node is treated as the root node of the subtree it defines.\n\nNotably, given an infinite tree, the corecursive breadth-first traversal will traverse all nodes, just as for a finite tree, while the recursive depth-first traversal will go down one branch and not traverse all nodes, and indeed if traversing post-order, as in this example (or in-order), it will visit no nodes at all, because it never reaches a leaf. This shows the usefulness of corecursion rather than recursion for dealing with infinite data structures.\n\nIn Python, this can be implemented as follows.\nThe usual post-order depth-first traversal can be defined as:\n\nThis can then be called by codice_4 to print the values of the nodes of the tree in post-order depth-first order.\n\nThe breadth-first corecursive generator can be defined as:\n\nThis can then be called to print the values of the nodes of the tree in breadth-first order:\n\nInitial data types can be defined as being the least fixpoint (up to isomorphism) of some type equation; the isomorphism is then given by an initial algebra. Dually, final (or terminal) data types can be defined as being the greatest fixpoint of a type equation; the isomorphism is then given by a final coalgebra.\n\nIf the domain of discourse is the category of sets and total functions, then final data types may contain infinite, non-wellfounded values, whereas initial types do not. On the other hand, if the domain of discourse is the category of complete partial orders and continuous functions, which corresponds roughly to the Haskell programming language, then final types coincide with initial types, and the corresponding final coalgebra and initial algebra form an isomorphism.\n\nCorecursion is then a technique for recursively defining functions whose range (codomain) is a final data type, dual to the way that ordinary recursion recursively defines functions whose domain is an initial data type.\n\nThe discussion below provides several examples in Haskell that distinguish corecursion. Roughly speaking, if one were to port these definitions to the category of sets, they would still be corecursive. This informal usage is consistent with existing textbooks about Haskell. Also note that the examples used in this article predate the attempts to define corecursion and explain what it is.\n\nThe rule for \"primitive corecursion\" on codata is the dual to that for primitive recursion on data. Instead of descending on the argument by pattern-matching on its constructors (that \"were called up before\", somewhere, so we receive a ready-made datum and get at its constituent sub-parts, i.e. \"fields\"), we ascend on the result by filling-in its \"destructors\" (or \"observers\", that \"will be called afterwards\", somewhere - so we're actually calling a constructor, creating another bit of the result to be observed later on). Thus corecursion \"creates\" (potentially infinite) codata, whereas ordinary recursion \"analyses\" (necessarily finite) data. Ordinary recursion might not be applicable to the codata because it might not terminate. Conversely, corecursion is not strictly necessary if the result type is data, because data must be finite.\n\nIn \"Programming with streams in Coq: a case study: the Sieve of Eratosthenes\" we find\n\nwhere primes \"are obtained by applying the primes operation to the stream (Enu 2)\". Following the above notation, the sequence of primes (with a throwaway 0 prefixed to it) and numbers streams being progressively sieved, can be represented as \nor in Haskell, \n\nThe authors discuss how the definition of codice_5 is not guaranteed always to be \"productive\", and could become stuck e.g. if called with codice_6 as the initial stream.\n\nHere is another example in Haskell. The following definition produces the list of Fibonacci numbers in linear time:\nThis infinite list depends on lazy evaluation; elements are computed on an as-needed basis, and only finite prefixes are ever explicitly represented in memory. This feature allows algorithms on parts of codata to terminate; such techniques are an important part of Haskell programming.\n\nThis can be done in Python as well:\nThe definition of codice_7 can be inlined, leading to this:\n\nThis example employs a self-referential \"data structure\". Ordinary recursion makes use of self-referential \"functions\", but does not accommodate self-referential data. However, this is not essential to the Fibonacci example. It can be rewritten as follows:\n\nThis employs only self-referential \"function\" to construct the result. If it were used with strict list constructor it would be an example of runaway recursion, but with non-strict list constructor this guarded recursion gradually produces an indefinitely defined list.\n\nCorecursion need not produce an infinite object; a corecursive queue is a particularly good example of this phenomenon. The following definition produces a breadth-first traversal of a binary tree in linear time:\n\nThis definition takes an initial tree and produces a list of subtrees. This list serves dual purpose as both the queue and the result ( produces its output notches after its input back-pointer, , along the ). It is finite if and only if the initial tree is finite. The length of the queue must be explicitly tracked in order to ensure termination; this can safely be elided if this definition is applied only to infinite trees. \n\nAnother particularly good example gives a solution to the problem of breadth-first labeling. The function codice_8 visits every node in a binary tree in a breadth first fashion, and replaces each label with an integer, each subsequent integer is bigger than the last by one. This solution employs a self-referential data structure, and the binary tree can be finite or infinite.\n\nAn apomorphism (such as an anamorphism, such as unfold) is a form of corecursion in the same way that a paramorphism (such as a catamorphism, such as fold) is a form of recursion.\n\nThe Coq proof assistant supports corecursion and coinduction using the CoFixpoint command.\n\nCorecursion, referred to as \"circular programming,\" dates at least to , who credits John Hughes and Philip Wadler; more general forms were developed in . The original motivations included producing more efficient algorithms (allowing 1 pass over data in some cases, instead of requiring multiple passes) and implementing classical data structures, such as doubly linked lists and queues, in functional languages.\n\n\n"}
{"id": "7931", "url": "https://en.wikipedia.org/wiki?curid=7931", "title": "Dictionary", "text": "Dictionary\n\nA dictionary, sometimes known as a wordbook, is a collection of words in one or more specific languages, often arranged alphabetically (or by radical and stroke for ideographic languages), which may include information on definitions, usage, etymologies, pronunciations, translation, etc. or a book of words in one language with their equivalents in another, sometimes known as a lexicon. It is a lexicographical reference that shows inter-relationships among the data.\n\nA broad distinction is made between general and specialized dictionaries. Specialized dictionaries include words in specialist fields, rather than a complete range of words in the language. Lexical items that describe concepts in specific fields are usually called terms instead of words, although there is no consensus whether lexicology and terminology are two different fields of study. In theory, general dictionaries are supposed to be semasiological, mapping word to definition, while specialized dictionaries are supposed to be onomasiological, first identifying concepts and then establishing the terms used to designate them. In practice, the two approaches are used for both types. There are other types of dictionaries that do not fit neatly into the above distinction, for instance bilingual (translation) dictionaries, dictionaries of synonyms (thesauri), and rhyming dictionaries. The word dictionary (unqualified) is usually understood to refer to a general purpose monolingual dictionary.\n\nThere is also a contrast between \"prescriptive\" or \"descriptive\" dictionaries; the former reflect what is seen as correct use of the language while the latter reflect recorded actual use. Stylistic indications (e.g. \"informal\" or \"vulgar\") in many modern dictionaries are also considered by some to be less than objectively descriptive.\n\nAlthough the first recorded dictionaries date back to Sumerian times (these were bilingual dictionaries), the systematic study of dictionaries as objects of scientific interest themselves is a 20th-century enterprise, called lexicography, and largely initiated by Ladislav Zgusta. The birth of the new discipline was not without controversy, the practical dictionary-makers being sometimes accused by others of \"astonishing\" lack of method and critical-self reflection.\n\nThe oldest known dictionaries were Akkadian Empire cuneiform tablets with bilingual Sumerian–Akkadian wordlists, discovered in Ebla (modern Syria) and dated roughly 2300 BCE. The early 2nd millennium BCE \"Urra=hubullu\" glossary is the canonical Babylonian version of such bilingual Sumerian wordlists. A Chinese dictionary, the c. 3rd century BCE \"Erya\", was the earliest surviving monolingual dictionary; although some sources cite the c. 800 BCE Shizhoupian as a \"dictionary\", modern scholarship considers it a calligraphic compendium of Chinese characters from Zhou dynasty bronzes. Philitas of Cos (fl. 4th century BCE) wrote a pioneering vocabulary \"Disorderly Words\" (Ἄτακτοι γλῶσσαι, \"\") which explained the meanings of rare Homeric and other literary words, words from local dialects, and technical terms. Apollonius the Sophist (fl. 1st century CE) wrote the oldest surviving Homeric lexicon. The first Sanskrit dictionary, the Amarakośa, was written by Amara Sinha c. 4th century CE. Written in verse, it listed around 10,000 words. According to the \"Nihon Shoki\", the first Japanese dictionary was the long-lost 682 CE \"Niina\" glossary of Chinese characters. The oldest existing Japanese dictionary, the c. 835 CE \"Tenrei Banshō Meigi\", was also a glossary of written Chinese. In \"Frahang-i Pahlavig\", Aramaic heterograms are listed together with their translation in Middle Persian language and phonetic transcription in Pazand alphabet. A 9th-century CE Irish dictionary, Sanas Cormaic, contained etymologies and explanations of over 1,400 Irish words. In India around 1320, Amir Khusro compiled the Khaliq-e-bari which mainly dealt with Hindustani and Persian words.\nArabic dictionaries were compiled between the 8th and 14th centuries CE, organizing words in rhyme order (by the last syllable), by alphabetical order of the radicals, or according to the alphabetical order of the first letter (the system used in modern European language dictionaries). The modern system was mainly used in specialist dictionaries, such as those of terms from the Qur'an and hadith, while most general use dictionaries, such as the \"Lisan al-`Arab\" (13th century, still the best-known large-scale dictionary of Arabic) and \"al-Qamus al-Muhit\" (14th century) listed words in the alphabetical order of the radicals. The \"Qamus al-Muhit\" is the first handy dictionary in Arabic, which includes only words and their definitions, eliminating the supporting examples used in such dictionaries as the \"Lisan\" and the \"Oxford English Dictionary\".\nIn medieval Europe, glossaries with equivalents for Latin words in vernacular or simpler Latin were in use (e.g. the Leiden Glossary). The \"Catholicon\" (1287) by Johannes Balbus, a large grammatical work with an alphabetical lexicon, was widely adopted. It served as the basis for several bilingual dictionaries and was one of the earliest books (in 1460) to be printed. In 1502 Ambrogio Calepino's \"Dictionarium\" was published, originally a monolingual Latin dictionary, which over the course of the 16th century was enlarged to become a multilingual glossary. In 1532 Robert Estienne published the \"Thesaurus linguae latinae\" and in 1572 his son Henri Estienne published the \"Thesaurus linguae graecae\", which served up to the 19th century as the basis of Greek lexicography. The first monolingual dictionary written in Europe was the Spanish, written by Sebastián Covarrubias' \"Tesoro de la lengua castellana o española\", published in 1611 in Madrid, Spain. In 1612 the first edition of the \"Vocabolario degli Accademici della Crusca\", for Italian, was published. It served as the model for similar works in French and English. In 1690 in Rotterdam was published, posthumously, the \"Dictionnaire Universel\" by Antoine Furetière for French. In 1694 appeared the first edition of the \"Dictionnaire de l'Académie française\". Between 1712 and 1721 was published the \"Vocabulario portughez e latino\" written by Raphael Bluteau. The Real Academia Española published the first edition of the \"Diccionario de la lengua española\" in 1780, but their \"Diccionario de Autoridades\", which included quotes taken from literary works, was published in 1726. The \"Totius Latinitatis lexicon\" by Egidio Forcellini was firstly published in 1777; it has formed the basis of all similar works that have since been published.\n\nThe first edition of \"A Greek-English Lexicon\" by Henry George Liddell and Robert Scott appeared in 1843; this work remained the basic dictionary of Greek until the end of the 20th century. And in 1858 was published the first volume of the Deutsches Wörterbuch by the Brothers Grimm; the work was completed in 1961. Between 1861 and 1874 was published the \"Dizionario della lingua italiana\" by Niccolò Tommaseo. Between 1862 and 1874 was published the six volumes of \"A magyar nyelv szótára\" (Dictionary of Hungarian Language) by Gergely Czuczor and János Fogarasi. Émile Littré published the Dictionnaire de la langue française between 1863 and 1872. In the same year 1863 appeared the first volume of the \"Woordenboek der Nederlandsche Taal\" which was completed in 1998. Also in 1863 Vladimir Ivanovich Dahl published the \"Explanatory Dictionary of the Living Great Russian Language\". The Duden dictionary dates back to 1880, and is currently the prescriptive source for the spelling of German. The decision to start work on the \"Svenska Akademiens ordbok\" was taken in 1787.\n\nThe earliest dictionaries in the English language were glossaries of French, Spanish or Latin words along with their definitions in English. The word \"dictionary\" was invented by an Englishman called John of Garland in 1220 — he had written a book \"Dictionarius\" to help with Latin \"diction\". An early non-alphabetical list of 8000 English words was the \"Elementarie\", created by Richard Mulcaster in 1582.\n\nThe first purely English alphabetical dictionary was \"A Table Alphabeticall\", written by English schoolteacher Robert Cawdrey in 1604. The only surviving copy is found at the Bodleian Library in Oxford. This dictionary, and the many imitators which followed it, was seen as unreliable and nowhere near definitive. Philip Stanhope, 4th Earl of Chesterfield was still lamenting in 1754, 150 years after Cawdrey's publication, that it is \"a sort of disgrace to our nation, that hitherto we have had no… standard of our language; our dictionaries at present being more properly what our neighbors the Dutch and the Germans call theirs, word-books, than dictionaries in the superior sense of that title.\" \n\nIn 1616, John Bullokar described the history of the dictionary with his \"English Expositor\". \"Glossographia\" by Thomas Blount, published in 1656, contains more than 10,000 words along with their etymologies or histories. Edward Phillips wrote another dictionary in 1658, entitled \"The New World of English Words: Or a General Dictionary\" which boldly plagiarized Blount's work, and the two denounced each other. This created more interest in the dictionaries. John Wilkins' 1668 essay on philosophical language contains a list of 11,500 words with careful distinctions, compiled by William Lloyd. Elisha Coles published his \"English Dictionary\" in 1676.\n\nIt was not until Samuel Johnson's \"A Dictionary of the English Language\" (1755) that a more reliable English dictionary was produced. Many people today mistakenly believe that Johnson wrote the first English dictionary: a testimony to this legacy. By this stage, dictionaries had evolved to contain textual references for most words, and were arranged alphabetically, rather than by topic (a previously popular form of arrangement, which meant all animals would be grouped together, etc.). Johnson's masterwork could be judged as the first to bring all these elements together, creating the first \"modern\" dictionary.\n\nJohnson's dictionary remained the English-language standard for over 150 years, until the Oxford University Press began writing and releasing the \"Oxford English Dictionary\" in short fascicles from 1884 onwards. It took nearly 50 years to complete this huge work, and they finally released the complete \"OED\" in twelve volumes in 1928. It remains the most comprehensive and trusted English language dictionary to this day, with revisions and updates added by a dedicated team every three months. One of the main contributors to this modern dictionary was an ex-army surgeon, William Chester Minor, a convicted murderer who was confined to an asylum for the criminally insane.\n\nIn 1806, American Noah Webster published his first dictionary, \"\". In 1807 Webster began compiling an expanded and fully comprehensive dictionary, \"An American Dictionary of the English Language;\" it took twenty-seven years to complete. To evaluate the etymology of words, Webster learned twenty-six languages, including Old English (Anglo-Saxon), German, Greek, Latin, Italian, Spanish, French, Hebrew, Arabic, and Sanskrit.\n\nWebster completed his dictionary during his year abroad in 1825 in Paris, France, and at the University of Cambridge. His book contained seventy thousand words, of which twelve thousand had never appeared in a published dictionary before. As a spelling reformer, Webster believed that English spelling rules were unnecessarily complex, so his dictionary introduced American English spellings, replacing \"colour\" with \"color\", substituting \"wagon\" for \"waggon\", and printing \"center\" instead of \"centre\". He also added American words, like \"skunk\" and \"squash\", that did not appear in British dictionaries. At the age of seventy, Webster published his dictionary in 1828; it sold 2500 copies. In 1840, the second edition was published in two volumes.\n\nIn a general dictionary, each word may have multiple meanings. Some dictionaries include each separate meaning in the order of most common usage while others list definitions in historical order, with the oldest usage first.\n\nIn many languages, words can appear in many different forms, but only the undeclined or unconjugated form appears as the headword in most dictionaries. Dictionaries are most commonly found in the form of a book, but some newer dictionaries, like StarDict and the \"New Oxford American Dictionary\" are dictionary software running on PDAs or computers. There are also many online dictionaries accessible via the Internet.\n\nAccording to the \"Manual of Specialized Lexicographies\", a specialized dictionary, also referred to as a technical dictionary, is a dictionary that focuses upon a specific subject field. Following the description in \"The Bilingual LSP Dictionary\", lexicographers categorize specialized dictionaries into three types: A multi-field dictionary broadly covers several subject fields (e.g. a business dictionary), a single-field dictionary narrowly covers one particular subject field (e.g. law), and a sub-field dictionary covers a more specialized field (e.g. constitutional law). For example, the 23-language Inter-Active Terminology for Europe is a multi-field dictionary, the American National Biography is a single-field, and the African American National Biography Project is a sub-field dictionary. In terms of the coverage distinction between \"minimizing dictionaries\" and \"maximizing dictionaries\", multi-field dictionaries tend to minimize coverage across subject fields (for instance, \"Oxford Dictionary of World Religions\" and \"Yadgar Dictionary of Computer and Internet Terms\") whereas single-field and sub-field dictionaries tend to maximize coverage within a limited subject field (\"The Oxford Dictionary of English Etymology\").\n\nAnother variant is the glossary, an alphabetical list of defined terms in a specialized field, such as medicine (medical dictionary).\n\nThe simplest dictionary, a defining dictionary, provides a core glossary of the simplest meanings of the simplest concepts. From these, other concepts can be explained and defined, in particular for those who are first learning a language. In English, the commercial defining dictionaries typically include only one or two meanings of under 2000 words. With these, the rest of English, and even the 4000 most common English idioms and metaphors, can be defined.\n\nLexicographers apply two basic philosophies to the defining of words: \"prescriptive\" or \"descriptive\". Noah Webster, intent on forging a distinct identity for the American language, altered spellings and accentuated differences in meaning and pronunciation of some words. This is why American English now uses the spelling \"color\" while the rest of the English-speaking world prefers \"colour\". (Similarly, British English subsequently underwent a few spelling changes that did not affect American English; see further at American and British English spelling differences.)\n\nLarge 20th-century dictionaries such as the \"Oxford English Dictionary\" (OED) and \"Webster's Third\" are descriptive, and attempt to describe the actual use of words. Most dictionaries of English now apply the descriptive method to a word's definition, and then, outside of the definition itself, and information alerting readers to attitudes which may influence their choices on words often considered vulgar, offensive, erroneous, or easily confused. \"Merriam-Webster\" is subtle, only adding italicized notations such as, \"sometimes offensive\" or \"stand\" (nonstandard). \"American Heritage\" goes further, discussing issues separately in numerous \"usage notes.\" \"Encarta\" provides similar notes, but is more prescriptive, offering warnings and admonitions against the use of certain words considered by many to be offensive or illiterate, such as, \"an offensive term for...\" or \"a taboo term meaning...\".\n\nBecause of the widespread use of dictionaries in schools, and their acceptance by many as language authorities, their treatment of the language does affect usage to some degree, with even the most descriptive dictionaries providing conservative continuity. In the long run, however, the meanings of words in English are primarily determined by usage, and the language is being changed and created every day. As Jorge Luis Borges says in the prologue to \"El otro, el mismo\": \"It is often forgotten that (dictionaries) are artificial repositories, put together well after the languages they define. The roots of language are irrational and of a magical nature.\"\n\nSometimes the same dictionary can be descriptive in some domains and prescriptive in others. For example, according to Ghil'ad Zuckermann, the \"Oxford English-Hebrew Dictionary\" is \"at war with itself\": whereas its coverage (lexical items) and glosses (definitions) are descriptive and colloquial, its vocalization is prescriptive. This internal conflict results in absurd sentences such as \"hi taharóg otí kshetiré me asíti lamkhonít\" (she'll tear me apart when she sees what I've done to the car). Whereas \"hi taharóg otí\", literally 'she will kill me', is colloquial, me (a variant of ma 'what') is archaic, resulting in a combination that is unutterable in real life.\n\nA historical dictionary is a specific kind of descriptive dictionary which describes the development of words and senses over time, usually using citations to original source material to support its conclusions.\n\nIn contrast to traditional dictionaries, which are designed to be used by human beings, dictionaries for natural language processing (NLP) are built to be used by computer programs. The final user is a human being but the direct user is a program. Such a dictionary does not need to be able to be printed on paper. The structure of the content is not linear, ordered entry by entry but has the form of a complex network (see Diathesis alternation). Because most of these dictionaries are used to control machine translations or cross-lingual information retrieval (CLIR) the content is usually multilingual and usually of huge size. In order to allow formalized exchange and merging of dictionaries, an ISO standard called Lexical Markup Framework (LMF) has been defined and used among the industrial and academic community.\n\n\nIn many languages, such as the English language, the pronunciation of some words is not consistently apparent from their spelling. In these languages, dictionaries usually provide the pronunciation. For example, the definition for the word \"dictionary\" might be followed by the International Phonetic Alphabet spelling . American English dictionaries often use their ownpronunciation respelling systems with diacritics, for example \"dictionary\" is respelled as \"dĭk′shə-nĕr′ē\" in the American Heritage Dictionary. The IPA is more commonly used within the British Commonwealth countries. Yet others use their own pronunciation respelling systems without diacritics: for example, \"dictionary\" may be respelled as . Some online or electronic dictionaries provide audio recordings of words being spoken.\n\nHistories and descriptions of the dictionaries of other languages on Wikipedia include:\n\n\nThe age of the Internet brought online dictionaries to the desktop and, more recently, to the smart phone. David Skinner in 2013 noted that \"Among the top ten lookups on Merriam-Webster Online at this moment are 'holistic, pragmatic, caveat, esoteric' and 'bourgeois.' Teaching users about words they don’t already know has been, historically, an aim of lexicography, and modern dictionaries do this well.\"\nThere exist a number of websites which operate as online dictionaries, usually with a specialized focus. Some of them have exclusively user driven content, often consisting of neologisms. Some of the more notable examples include:\n\n\n\n"}
{"id": "358999", "url": "https://en.wikipedia.org/wiki?curid=358999", "title": "Difference feminism", "text": "Difference feminism\n\nTaking for granted an equal moral status as persons, difference feminism asserts that there are differences between men and women but that no value judgment can be placed upon them.\n\nThe term \"difference feminism\" developed during the \"equality-versus-difference debate\" in American feminism in the 1980s and 1990s, but subsequently fell out of favor and use. In the 1990s feminists addressed the binary logic of \"difference\" versus \"equality\" and moved on from it, notably with postmodern and/or deconstructionist approaches that either dismantled or did not depend on that dichotomy.\n\nDifference feminism did not require a commitment to essentialism. Most strains of difference feminism did not argue that there was a biological, inherent, ahistorical, or otherwise \"essential\" link between womanhood and traditionally feminine values, habits of mind (often called \"ways of knowing\"), or personality traits. These feminists simply sought to recognize that, in the present, women and men are significantly different and to explore the devalued \"feminine\" characteristics.\n\nSome strains of difference feminism, for example Mary Daly's, argue not just that women and men were different, and had different values or different ways of knowing, but that women and their values were superior to men's. This viewpoint does not require essentialism, although there is ongoing debate about whether Daly's feminism is essentialist.\n\nDifference feminism was developed by feminists in the 1980s, in part as a reaction to popular liberal feminism (also known as \"equality feminism\"), which emphasized the similarities between women and men in order to argue for equal treatment for women. Difference feminism, although it still aimed at equality between men and women, emphasized the differences between men and women and argued that identicality or sameness are not necessary in order for men and women, and masculine and feminine values, to be treated equally. Liberal feminism aimed to make society and law gender-neutral, since it saw recognition of gender difference as a barrier to rights and participation within liberal democracy, while difference feminism held that gender-neutrality harmed women \"whether by impelling them to imitate men, by depriving society of their distinctive contributions, or by letting them participate in society only on terms that favor men\".\n\nDifference feminism drew on earlier nineteenth-century strains of thought, for example the work of German writer Elise Oelsner, which held that not only should women be allowed into formerly male-only spheres and institutions (e.g. public life, science) but that those institutions should also be expected to change in a way that recognizes the value of traditionally devalued feminine ethics (like care [see ethics of care]). On the latter point, many feminists have re-read the phrase \"difference feminism\" in a way that asks \"what difference does feminism make?\" (e.g. to the practice of science) rather than \"what differences are there between men and women\"?\n\nSome have argued that the thought of certain prominent second-wave feminists, like psychologist Carol Gilligan and radical feminist theologian Mary Daly, is \"essentialist.\" In philosophy essentialism is the belief that \"(at least some) objects have (at least some) essential properties.\" In the case of sexual politics essentialism is taken to mean that \"women\" and \"men\" have fixed essences or essential properties (e.g. behavioral or personality traits) that cannot be changed. However, essentialist interpretations of Daly and Gilligan have been questioned by some feminist scholars, who argue that charges of \"essentialism\" are often used more as terms of abuse than as theoretical critiques based on evidence, and do not accurately reflect Gilligan or Daly's views.\n\n"}
{"id": "8366559", "url": "https://en.wikipedia.org/wiki?curid=8366559", "title": "Difference theory", "text": "Difference theory\n\nDifference theory has roots in the studies of John Gumperz, who examined differences in cross-cultural communication. While difference theory deals with cross-gender communication, the male and female genders are often presented as being two separate cultures, hence the relevance of Gumperz's studies. In her development of the difference theory, Deborah Tannen drew on the work of Daniel Maltz and Ruth Borker, in particular their 1982 paper, \"A Cultural Approach to Male-Female Miscommunication\", which itself drew on the work of Gumperz. Mary Talbot makes reference to the term \"gender-specific culture\" in her critique of the difference theory, and this idea of genders being culturally separated is embodied by the 1992 publication \"Men Are from Mars, Women Are from Venus\". Difference theory is often compared with dominance theory and deficit theory, and together with the more contemporary dynamic theory they make up four of the theories most widely referred to and compared in the study of language and gender.\n\nThe reason for the popularity of Tannen's book \"You Just Don't Understand\", and the resultant popularisation of difference theory, is generally attributed to the style of Tannen's work, in which she adopts a neutral position on differences in genderlect by making no value-judgements about use of language by either gender. Talbot comments that this means the book provides explanations for domestic disputes without \"pointing the finger\" at anyone.\n\nDifference theory as postulated by Tannen is generally summarised into six categories, each of which pairs contrasting uses of language by males and females.\n\nTannen states that, for men, the world is a competitive place in which conversation and speech are used to build status, whereas for women the world is a network of connections, and that they use language to seek and offer support. In demonstrating this, Tannen uses the example of her husband and herself, who at one point had jobs in different cities. She remarks that whenever someone commented on this, she interpreted it as being an offer of sympathy or support. Her husband, on the other hand, took such comments as being criticisms and attempts to put him down. Tannen remarks that this displays the different approaches that women and men take in terms of status and support. Furthermore, men are also more likely to interrupt to get their point across and hence gain status.\n\nWomen seek comfort and sympathy for their problems, whilst men will seek a solution to the problem.\n\nTannen states that men's conversation is message-oriented, i.e. based upon communicating information. For women, conversation is much more important for building relationships and strengthening social links.\n\nMen will use direct imperatives (\"close the door\", \"switch on the light\") when speaking to others. Women encourage the use of superpolite forms, however (\"let's\", \"would you mind if ...?\").\n\nTannen asserts that most women avoid conflict in language at all costs, and instead attempt to resolve disagreements without any direct confrontation, to maintain positive connection and rapport. Men, on the other hand, are more likely to use confrontation as a way of resolving differences and thereby negotiating status. Tannen supports this view by making reference to the work of Walter J. Ong, whose 1981 publication, \"Fighting for Life\", asserts that \"expressed adversativeness\" is more an element of male culture than female culture. Tannen stresses that both forms of communication are valid ways of creating involvement and forming bonds.\n\nDifference theory asserts that in general men favour independence, while women are more likely to seek intimacy. Tannen demonstrates this with the example of a husband making a decision without consulting his wife. She theorises that he does so because he doesn't want to feel a loss of independence that would come from saying, \"Let me consult this with my wife first.\" Women, by contrast, like to demonstrate that they have to consult with their partner, as this is seen to be proof of the intimacy of the relationship. Tannen asserts that women, seeing the world as a network of connections and relationships, view intimacy as key to achieving consensus and avoiding the appearance of superiority, whereas men, who are more likely to view the world in terms of status, see independence as being key to establishing their status. Tannen also clarifies that while both men and women seek independence and intimacy, men tend to be focused on the former, while women tend to focus on the latter.\n\nGeneral criticisms are that Tannen's observations are largely anecdotal and cannot be said for all conjugal conversations, let alone mixed-gender interactions as a whole.\n\n\n"}
{"id": "58632079", "url": "https://en.wikipedia.org/wiki?curid=58632079", "title": "Encyclopedia of Forensic and Legal Medicine 2nd Edition", "text": "Encyclopedia of Forensic and Legal Medicine 2nd Edition\n\nThe Encyclopedia of Forensic and Legal Medicine 2nd Edition is a reference source and pioneering 4 set encyclopedia of forensics and medico-legal knowledge published by Academic Press, Elsevier in 2016. This has been edited by the renowned British forensic specialist Jason Payne-James and Australian forensic pathologist Roger W. Byard and an international editorial board. \nThis reference work includes more than 300 articles contributed by forensic medicine and forensic science experts from all over the world. The encyclopedia is a complete reference source of articles covering from forensics, criminal investigations, health-care, legal, judicial, ballistics, toxicology,fingerprinting, DNA typing, disaster victim identification to autopsy and postmortem examination.\n\nThe encyclopedia is especially meant for forensic, medical, chemistry, physics, laboratory technologists and anthropology students and specialists such as forensic experts, lawyers, judicial officers, judges, police and investigating offices, nurses, medical officers etc. All the articles of the encyclopedia are available through Science direct and Scopus.\n"}
{"id": "500948", "url": "https://en.wikipedia.org/wiki?curid=500948", "title": "Field guide", "text": "Field guide\n\nA field guide is a book designed to help the reader identify wildlife (plants or animals) or other objects of natural occurrence (e.g. minerals). It is generally designed to be brought into the 'field' or local area where such objects exist to help distinguish between similar objects. Field guides are often designed to help users distinguish animals and plants that may be similar in appearance but are not necessarily closely related.\n\nIt will typically include a description of the objects covered, together with paintings or photographs and an index. More serious and scientific field identification books, including those intended for students, will probably include identification keys to assist with identification, but the publicly accessible field guide is more often a browsable picture guide organized by family, colour, shape, location or other descriptors.\n\nPopular interests in identifying things in nature probably were strongest in bird and plant guides. Perhaps the first popular field guide to plants in the United States was the 1893 \"How to Know the Wildflowers\" by \"Mrs. William Starr Dana\" (Frances Theodora Parsons). In 1890, Florence Merriam published \"Birds Through an Opera-Glass\", describing 70 common species. Focused on living birds observed in the field, the book is considered the first in the tradition of modern, illustrated bird guides. In 1902, now writing as Florence Merriam Bailey (having married the zoologist Vernon Bailey), she published \"Handbook of Birds of the Western United States\". By contrast, the \"Handbook\" is designed as a comprehensive reference for the lab rather a portable book for the field. It was arranged by taxonomic order and had clear descriptions of species size, distribution, feeding, and nesting habits.\n\nFrom this point into the 1930s, features of field guides were introduced by Chester A. Reed and others such as changing the size of the book to fit the pocket, including colour plates, and producing guides in uniform editions that covered subjects such as garden and woodland flowers, mushrooms, insects, and dogs.\n\nIn 1934, Roger Tory Peterson, using his fine skill as an artist, changed the way modern field guides approached identification. Using color plates with paintings of similar species together – and marked with arrows showing the differences – people could use his bird guide in the field to compare species quickly to make identification easier. This technique, the \"Peterson Identification System\", was used in most of Peterson's Field Guides from animal tracks to seashells and has been widely adopted by other publishers and authors as well.\n\nToday, each field guide has its own range, focus and organization. Specialist publishers such as Croom Helm, along with organisations like the Audubon Society, the RSPB, the Field Studies Council, National Geographic, HarperCollins, and many others all produce quality field guides.\n\nIt is somewhat difficult to generalise about how field guides are intended to be used, because this varies from one guide to another, partly depending on how expert the targeted reader is expected to be.\n\nFor general public use, the main function of a field guide is to help the reader identify a bird, plant, rock, butterfly or other natural object down to at least the popular naming level. To this end some field guides employ simple keys and other techniques: the reader is usually encouraged to scan illustrations looking for a match, and to compare similar-looking choices using information on their differences. Guides are often designed to first lead readers to the appropriate section of the book, where the choices are not so overwhelming in number.\n\nGuides for students often introduce the concept of identification keys. Plant field guides such as \"Newcomb's Wildflower Guide\" (which is limited in scope to the wildflowers of northeastern North America) frequently have an abbreviated key that helps limit the search. Insect guides tend to limit identification to Order or Family levels rather than individual species, due to their diversity.\n\nMany taxa show variability and it is often difficult to capture the constant features using a small number of photographs. Illustrations by artists or post processing of photographs help in emphasising specific features needed to for reliable identification. Peterson introduced the idea of lines to point to these key features. He also noted the advantages of illustrations over photographs:\n\nField guides aid in improving the state of knowledge of various taxa. By making the knowledge of experienced museum specialists available to amateurs, they increase the gathering of information by amateurs from a wider geographic area and increasing the communication of these findings to the specialists.\n\n"}
{"id": "190975", "url": "https://en.wikipedia.org/wiki?curid=190975", "title": "Ibid.", "text": "Ibid.\n\nIbid is an abbreviation for the Latin word \"ibīdem\", meaning \"in the same place\", commonly used in an endnote, footnote, bibliography citation, or scholarly reference to refer to the source cited in the preceding note or list item. This is similar to \"īdem\", literally meaning \"the same\", abbreviated \"Id.\", which is commonly used in legal citation.\n\nIbid. may also be used in the Harvard (name-date) system for in-text references where there has been a close previous citation from the same source material. The previous reference should be immediately visible, e.g. within the same paragraph or page. Some academic publishers now prefer that \"ibid.\" not be italicized, as it is a commonly found term.\n\nSince ibid. is an abbreviation where the last two letters of the word are omitted, it takes a full stop (period) in both British and American usage.\n\nReference 2 is the same as reference 1: E. Vijh, \"Latin for Dummies\" on page 23, whereas reference 3 refers to the same work but at a different location, namely page 29. Intervening entries require a reference to the original citation in the form Ibid. <citation #>, as in reference 5.\n\n\n\n"}
{"id": "1930406", "url": "https://en.wikipedia.org/wiki?curid=1930406", "title": "Impredicativity", "text": "Impredicativity\n\nSomething that is impredicative, in mathematics, logic and philosophy of mathematics, is a self-referencing definition. Roughly speaking, a definition is impredicative if it invokes (mentions or quantifies over) the set being defined, or (more commonly) another set that contains the thing being defined. There is no generally accepted precise definition of what it means to be predicative or impredicative. Authors have given different but related definitions.\n\nThe opposite of impredicativity is predicativity, which essentially entails building stratified (or ramified) theories where quantification over lower levels results in variables of some new type, distinguished from the lower types that the variable ranges over. A prototypical example is intuitionistic type theory, which retains ramification so as to discard impredicativity.\n\nRussell's paradox is a famous example of an impredicative construction—namely the set of all sets that do not contain themselves. The paradox is that such a set cannot exist: If it would exist, the question could be asked whether it contains itself or not — if it does then by definition it should not, and if it does not then by definition it should.\n\nThe greatest lower bound of a set , , also has an impredicative definition: if and only if for all elements of , is less than or equal to , and any less than or equal to all elements of is less than or equal to . This definition quantifies over the set (potentially infinite, depending on the order in question) whose members are the lower bounds of , one of which being the glb itself. Hence predicativism would reject this definition.\n\nThe terms \"predicative\" and \"impredicative\" were introduced by , though the meaning has changed a little since then. \n\nSolomon Feferman provides a historical review of predicativity, connecting it to current outstanding research problems.\n\nThe vicious circle principle was suggested by Henri Poincaré (1905-6, 1908) and Bertrand Russell in the wake of the paradoxes as a requirement on legitimate set specifications. Sets that do not meet the requirement are called \"impredicative\".\n\nThe first modern paradox appeared with Cesare Burali-Forti's 1897 \"A question on transfinite numbers\" and would become known as the Burali-Forti paradox. Cantor had apparently discovered the same paradox in his (Cantor's) \"naive\" set theory and this become known as Cantor's paradox. Russell's awareness of the problem originated in June 1901 with his reading of Frege's treatise of mathematical logic, his 1879 \"Begriffsschrift\"; the offending sentence in Frege is the following:\nIn other words, given the function is the variable and is the invariant part. So why not substitute the value for itself? Russell promptly wrote Frege a letter pointing out that:\nFrege promptly wrote back to Russell acknowledging the problem:\nWhile the problem had adverse personal consequences for both men (both had works at the printers that had to be emended), van Heijenoort observes that \"The paradox shook the logicians' world, and the rumbles are still felt today. ... Russell's paradox, which uses the bare notions of set and element, falls squarely in the field of logic. The paradox was first published by Russell in \"The principles of mathematics\" (1903) and is discussed there in great detail ...\". Russell, after six years of false starts, would eventually answer the matter with his 1908 theory of types by \"propounding his \"axiom of reducibility\". It says that any function is coextensive with what he calls a \"predicative\" function: a function in which the types of apparent variables run no higher than the types of the arguments\". But this \"axiom\" was met with resistance from all quarters.\n\nThe rejection of impredicatively defined mathematical objects (while accepting the natural numbers as classically understood) leads to the position in the philosophy of mathematics known as predicativism, advocated by Henri Poincaré and Hermann Weyl in his \"Das Kontinuum\". Poincaré and Weyl argued that impredicative definitions are problematic only when one or more underlying sets are infinite.\n\nErnst Zermelo in his 1908 \"A new proof of the possibility of a well-ordering\" presents an entire section \"b. \"Objection concerning nonpredicative definition\"\" where he argued against \"Poincaré (1906, p. 307) [who states that] a definition is 'predicative' and logically admissible only if it \"excludes\" all objects that are dependent upon the notion defined, that is, that can in any way be determined by it\". He gives two examples of impredicative definitions – (i) the notion of Dedekind chains and (ii) \"in analysis wherever the maximum or minimum of a previously defined \"completed\" set of numbers is used for further inferences. This happens, for example, in the well-known Cauchy proof of the fundamental theorem of algebra, and up to now it has not occurred to anyone to regard this as something illogical\". He ends his section with the following observation: \"A definition may very well rely upon notions that are equivalent to the one being defined; indeed, in every definition \"definiens\" and \"definiendum\" are equivalent notions, and the strict observance of Poincaré's demand would make every definition, hence all of science, impossible\".\n\nZermelo's example of minimum and maximum of a previously defined \"completed\" set of numbers reappears in Kleene 1952:42-42 where Kleene uses the example of Least upper bound in his discussion of impredicative definitions; Kleene does not resolve this problem. In the next paragraphs he discusses Weyl's attempt in his 1918 \"Das Kontinuum\" (\"The Continuum\") to eliminate impredicative definitions and his failure to retain the \"theorem that an arbitrary non-empty set of real numbers having an upper bound has a least upper bound (cf. also Weyl 1919)\".\n\nRamsey argued that \"impredicative\" definitions can be harmless: for instance, the definition of \"tallest person in the room\" is impredicative, since it depends on a set of things of which it is an element, namely the set of all persons in the room. Concerning mathematics, an example of an impredicative definition is the smallest number in a set, which is formally defined as: if and only if for all elements of , is less than or equal to , and is in .\n\nBurgess (2005) discusses predicative and impredicative theories at some length, in the context of Frege's logic, Peano arithmetic, second order arithmetic, and axiomatic set theory.\n\n\n"}
{"id": "161388", "url": "https://en.wikipedia.org/wiki?curid=161388", "title": "Indirect self-reference", "text": "Indirect self-reference\n\nIndirect self-reference describes an object referring to itself \"indirectly\".\n\nFor example, define the function f such that f(x) = x(x). Any function passed as an argument to f is invoked with itself as an argument, and thus in any use of that argument is indirectly referring to itself.\n\nThis example is similar to the Scheme expression \"((lambda(x)(x x)) (lambda(x)(x x)))\", which is expanded to itself by beta reduction, and so its evaluation loops indefinitely despite the lack of explicit looping constructs. An equivalent example can be formulated in lambda calculus.\n\nIndirect self-reference is special in that its self-referential quality is not explicit, as it is in the sentence \"this sentence is false.\" The phrase \"this sentence\" refers directly to the sentence as a whole. An indirectly self-referential sentence would replace the phrase \"this sentence\" with an expression that effectively still referred to the sentence, but did not use the pronoun \"this.\"\n\nAn example will help to explain this. Suppose we define the quine of a phrase to be the quotation of the phrase followed by the phrase itself. So, the quine of:\nwould be:\nwhich, incidentally, is a true statement.\n\nNow consider the sentence:\n\nThe quotation here, plus the phrase \"when quined,\" indirectly refers to the entire sentence. The importance of this fact is that the remainder of the sentence, the phrase \"makes quite a statement,\" can now make a statement about the sentence as a whole. If we had used a pronoun for this, we could have written something like \"this sentence makes quite a statement.\"\n\nIt seems silly to go through this trouble when pronouns will suffice (and when they make more sense to the casual reader), but in systems of mathematical logic, there is generally no analog of the pronoun. It is somewhat surprising, in fact, that self-reference can be achieved at all in these systems.\n\nUpon closer inspection, it can be seen that in fact, the Scheme example above uses a quine, and f(x) is actually the quine function itself.\n\nIndirect self-reference was studied in great depth by W. V. Quine (after whom the operation above is named), and occupies a central place in the proof of Gödel's incompleteness theorem. Among the paradoxical statements developed by Quine is the following:\n\n"}
{"id": "17878314", "url": "https://en.wikipedia.org/wiki?curid=17878314", "title": "Information source", "text": "Information source\n\nAn information source is a person, thing, or place from which information comes, arises, or is obtained. Information souces can be known as primary or secondary. That source might then inform a person about something or provide knowledge about it. Information sources are divided into separate distinct categories, primary, secondary, tertiary, and so on.\n\n"}
{"id": "15293025", "url": "https://en.wikipedia.org/wiki?curid=15293025", "title": "Informationsdienst Wissenschaft", "text": "Informationsdienst Wissenschaft\n\nInformationsdienst Wissenschaft e.V. or idw (The Science Information Service) operates an Internet platform, which bundles the press reports and dates of important events from about 1,000 scientific institutions, including universities, technical colleges, governmental and non-governmental research institutes and institutes to support research or scientific administration. idw (a registered charitable society) also operates an expert broker, the idw expert finder, which is exclusively for journalists. This makes idw one of the most comprehensive sources of science news in the German-speaking area. Foreign journalists and institutions (mostly European) now use idw as well. \n\nThe two main objectives of idw are:\n\nThe information in idw can be accessed free of charge - either directly on idw’s www pages, or by using an individually configurable RSS feed or as an e-mail subscriber. Any user can request the information covering the topics and regions which interest him. All idw services can be used free of cost - the current news ticker, the science calendar, research in the archive (which contains more than 350,000 press releases), and the list of institutions linked to idw. idw also provides journalists with instruments for contacting experts, and maintains a database with science photos.\nThe members' press offices have various possibilities of communicating with journalists. Membership is only offered to German or foreign institutions which perform research or teaching, or which support science or are active in science in some other way.\n\nThe original idea of idw was to provide experts for journalists. Using the American ProfNet as example, the press officers of Universitaet Bayreuth, the Ruhr University Bochum and the Clausthal University of Technology, in collaboration with Computing Centre of Clausthal University of Technology/TU Clausthal, developed a concept for a German language network, by means of the new media. The concept was technically implemented by the staff of the Computing Centre of the Clausthal University of Technology. A total of nine staff members in Bayreuth, Bochum and Clausthal are responsible for programming, maintaining and developing the idw operating system, for user services and further development of the content.\n\nThe initial phase (1996–1999) was guaranteed by project support from the Federal Ministry for Education and Research (BMBF). The technical development of the idw was supported by the Ministry, together with the Stifterverband fuer die Deutsche Wissenschaft (Donor Association for German Science). idw has been working closely for years with the initiative Wissenschaft im Dialog (Science in Dialogue). idw has been economically independent since 2000 and is financed by contributions from member institutions. It has been organised as a registered charitable society (gemeinnütziger e. V.) since 2002.\n\nidw has developed as a recognised and accepted source for German language science and for science journalism. It has become an instrument for public relations work for scientific institutions. \nAbout 37,000 subscribers (figure for June 2018) receive regular reports from idw, including some 7,900 journalists. About 1,000 institutions publish their press reports and dates of important events via idw.\n\n"}
{"id": "5995840", "url": "https://en.wikipedia.org/wiki?curid=5995840", "title": "L. G. Pine", "text": "L. G. Pine\n\nLeslie Gilbert Pine (22 December 1907 – 15 May 1987) was a British author, lecturer, and researcher in the areas of genealogy, nobility, history, heraldry and animal welfare. He was born in 1907 in Bristol, England and died in Bury St. Edmunds, Suffolk in 1987. He was the son of Lilian Grace Beswetherick and Henry Moorshead Pine (a tea merchant).\n\nFrom 1935 to 1940 he served as an assistant editor at Burke's Peerage Ltd. During World War II he was an officer in the Royal Air Force intelligence branch, serving in North Africa, Italy, Greece, and India; he retired with the rank of Squadron Leader. After the war and until 1960, he was Burke's executive director. Pine edited \"Burke's Peerage,\" 1949-1959; \"Burke's Landed Gentry (of Great Britain),\" 1952; \"Burke's Landed Gentry (of Ireland),\" 1958; and, \"Burke's Distinguished Families of America,\" 1939, 1947. He also edited \"The International Year Book and Statesmen's Who's Who,\" 1953-1960; \"Author's and Writer's Who's Who,\" 1948, 1960; \"Who's Who in Music,\" 1949; and, \"Who's Who in the Free Churches,\" 1951.\n\nA graduate of London University, he became a Barrister-at-Law, Inner Temple, in 1953. Pine was a member of the International Institute of Genealogy and Heraldry, Fellow of the Society of Antiquaries of Scotland, a Fellow of the Ancient Monuments Society, a Life Fellow of the Institute of Journalists, a Freeman of the City of London, and a Liveryman of the Glaziers' Company. In 1959 he was the unsuccessful Conservative candidate for Bristol Central.\n\nHe was managing editor of a British hunting magazine, \"Shooting Times\", from 1960 to 1964. He later authored an important book highly critical of sport hunting, \"After Their Blood\", in which he wrote: \"It is our duty as men and women of God’s redeemed creation to try not to increase the suffering of the world, but to lessen it. To get rid of bloodsports will be a great step toward this end.\"\n\nIn 1948 Leslie Pine married Grace V. Griffin (20 August 1914- ). Their only child, Richard Pine, was born in London on 21 August 1949.\n\nHis books include:\n\n\nPine is also the primary contributor to the article \"genealogy\" in \"Encyclopædia Britannica\".\n\n"}
{"id": "30795401", "url": "https://en.wikipedia.org/wiki?curid=30795401", "title": "Liar paradox in early Islamic tradition", "text": "Liar paradox in early Islamic tradition\n\nMany early Islamic philosophers and logicians discussed the liar paradox. Their work on the subject began in the 10th century and continued to Athīr al-Dīn al-Abharī and Nasir al-Din al-Tusi of the middle 13th century and beyond. Although the Liar paradox has been well known in Greek and Latin traditions, the works of Arabic scholars have only recently been translated into English.\n\nEach group of early Islamic philosophers discussed different problems presented by the paradox. They pioneered unique solutions that were not influenced by Western ideas.\n\nAthīr al-Dīn Mufaḍḍal (b. ʿUmar Abharī, d. 663/1264) was a Persian philosopher, astronomer and mathematician from the city of Abhar in Persia. There is some speculation that his works on the Liar paradox could have been known to Western logicians, and in particular to Thomas Bradwardine.\n\nHe analyzed the Liar sentence as follows:\n\nIn other words, Athīr says that if the Liar sentence is false, which means that the Liar falsely declares that all he says at the moment is false, then the Liar sentence is true; and, if the Liar sentence is true, which means that the Liar truthfully declares that all he says at the moment is false, then the Liar sentence is false. In any case, the Liar sentence is both true and false at the same time, which is a paradox.\n\nAthīr offers the following solution for the paradox:\n\nAccording to the traditional idealization that presumably was used by Athīr, the sentence as an universal proposition is false only, when \"either it has a counter-instance or its subject term is empty\".\n\n\nThe Liar sentence, however, has neither an empty subject nor counter-instance. This fact creates obstacles for Athīr's view, who must show what is unique about the Liar sentence, and how the Liar sentence still could be only true or false in view of the \"true\" and \"false\" conditions set up in the universal proposition's description. Athīr tries to solve the paradox by applying to it the laws of negation of a conjunction and negation of a disjunction.\n\nAhmed Alwishah, who has a Ph.D. in Islamic Philosophy and David Sanson, who has a Ph.D. in Philosophy explain that Athīr actually claims that:\n\n(1) \"It is not the case that, if the Liar Sentence is not both true and false, then it is true.\"\n\nAlwishah and Sanson continue:\n\"The general principle behind (1) is clear enough: the negation of a conjunction does not entail the negation of a conjunct; so from not both true and false you cannot infer not false and so true. Abharī appears to be saying that the Liar rests on an elementary scope fallacy! But, of course, Abharī is not entitled to (1). In some cases, the negation of a conjunction does entail the negation of a conjunct: 'not both P and P' for example, entails 'not P'. As a general rule, the negation of a conjunction entails the negation of each conjunct whenever the conjuncts are logically equivalent, i.e., whenever the one follows from the other and vice verse. So Abharī is entitled to (1) only if he is entitled to assume that ‘The Liar Sentence is true’ and ‘The Liar Sentence is false’ are not logically equivalent.\"\n\nThe Liar sentence is a universal proposition (The Liar says All I say ...), so \"if it is (non–vacuously) false it must have a counter–instance\". But in this case scenario, when the only thing that the liar is saying is the single sentence declaring that what he is saying at the moment is false, the only available counter–instance is the Liar sentence itself. When staging the paradox Abharī said: \"if it is not true, then it is necessary that one of his sentences at this moment is true, as long as he utters something. But, he says nothing at this moment other than this sentence. Thus, this sentence is necessarily true and false\" So the explanation provided by Abharī himself demonstrates that both \"'The Liar Sentence is false' and 'The Liar Sentence is true' are logically equivalent. If they are logically equivalent, then, contrary to (1), the negation of the conjunction does entail the negation of each conjunct. Abharī’s 'solution; therefore fails.\"\n\nNaṣīr al-Dīn al-Ṭūsī was a Persian polymath and prolific writer: an astronomer, biologist, chemist, mathematician, philosopher, physician, physicist, scientist, theologian and Marja Taqleed. He adhered to the Ismaili, and subsequently Twelver Shī‘ah Islamic belief systems. The Arab scholar Ibn Khaldun (1332–1406) considered Tusi to be the greatest of the later Persian scholars.\n\nṬūsī's work on the paradox begins with a discussion of the paradox and the solution offered by Abharī, with which Ṭūsī disagrees. As Alwishah and Sanson point out \"Ṭūsī argues that whatever fancy thing (conjunction, conditional) Abharī wants to identify as the truth condition for the Liar Sentence, it will not matter, because pace Abharī, we can generate the paradox without inferring, from the negation of a complex truth condition, the negation of one of its parts. We can argue directly that its being false entails the negation of its being false, and so entails its being true.\"\n\nṬūsī then prepares a stage for his own solution of the Liar paradox, writing that:\nHe does not see a reason that could prevent a declarative sentence to declare something about another declarative sentence.\n\nWith an example of two declarative sentences, (D1) \"It is false\" and (D2) \"Zayd is sitting\", Ṭūsī explains how one declarative sentence (D1) can declare another declarative sentence (D2) to be false: \"It is false that Zayd is sitting\". There is no paradox in the above two declarative sentences because they have different subjects. To generate a paradox a declarative sentence must declare something about itself. If (D1) falsely declares itself to be not (D1) then this false declaration referencing to itself as being \"false\" creates a paradox.\n\nṬūsī writes: \n\nThe above conclusions are very important to the history of Liar Paradox. Alwishah and Sanson point out: \"It is hard to overemphasize how remarkable this passage is. The contemporary reader will be familiar with the idea that the Liar Paradox is a paradox of selfreference. But Ṭūsī is, as far as we know, the first person to express this idea. This passage has no precedent in any tradition. Ṭūsī has performed three remarkable feats in short order. First, his Liar Sentence is singular: its subject is itself, and it declares itself to be false. Gone, then, is the choice between universal or particular Liar Sentence, and the associated problem of adding further assumptions to generate a genuine paradox. Second, he has characterized the paradox as one of self-reference. Third, he has identified a key assumption that might be responsible for generating the entire problem: the assumption that a declarative sentence, by its nature, can declare-something-about anything.\"\n\nRecognizing that, if a declarative sentence that declares itself being false, is false, this does not necessitate it being true. Ṭūsī says that it would be absurd to say that this declarative sentence is true only because it is not false. Ṭūsī writes:\n\nṬūsī then interprets the definitions of \"true\" and \"false\", in an attempt to prove that those definitions should not be taken into consideration when dealing with a declarative sentence that declares itself, as its own subject, to be false.\n\nAl-Baghdādī's definition of \"truth\" and \"falsity\" says that: \"truth is an agreement with the subject, and falsity is the opposite of that\". Ṭūsī argues that this definition cannot be applied to a declarative sentence that declares its own subject to be false because then there are at least two opposite parts that are in disagreement with each other. The same subject cannot be in disagreement with itself. Therefore a self–referenced declarative sentence that declares itself to be false is neither false nor true, and truth/falsity definitions are not applicable to those sentences.\n\nṬūsī stopped short from offering a solution for the Liar sentences discussed by Āmidī \"All that I say at this moment is false\". This sentence presents a different case scenario because it can be interpreted as declaring something about itself, and something about another sentence. The solution for this paradox is absent from Ṭūsī's papers.\n"}
{"id": "33447383", "url": "https://en.wikipedia.org/wiki?curid=33447383", "title": "Metabibliography", "text": "Metabibliography\n\nA metabibliography (or biblio-bibliography) is a bibliography of bibliographies.\n\nBibliographies serve the finding of relevant documents. Metabibliographies serve the finding of the relevant bibliographies in which the relevant documents may be found. One might quote Patrick Wilson:\n\n\"For if knowledge is power, power over knowledge is power to increase one's power; and if the stock of writings is thought of mainly as it represents a stock of knowledge, it is natural to propose treating it as a \"resource\" to be subjected to rational control, managemenet and utilization.\" (Wilson, 1968, p. 145).\n\nMetabibliographies are valuable for building reference collections, but usually of less interest to the average user, who rely on bibliographies selected by others.\n\n\n\n"}
{"id": "4807639", "url": "https://en.wikipedia.org/wiki?curid=4807639", "title": "Microsoft Bookshelf", "text": "Microsoft Bookshelf\n\nMicrosoft Bookshelf was a reference collection introduced in 1987 as part of Microsoft's extensive work in promoting CD-ROM technology as a distribution medium for electronic publishing. The original MS-DOS version showcased the massive storage capacity of CD-ROM technology, and was accessed while the user was using one of 13 different word processor programs that Bookshelf supported. Subsequent versions were produced for Windows and became a commercial success as part of the Microsoft Home brand. It was often bundled with personal computers as a cheaper alternative to the Encarta Suite. The Encarta Deluxe Suite / Reference Library versions also bundled Bookshelf.\n\nMicrosoft Bookshelf was discontinued in 2000. In later editions of the Encarta suite (Encarta 2000 and onwards), Bookshelf was replaced with a dedicated \"Encarta Dictionary\", a superset of the printed edition. There has been some controversy over the decision, since the dictionary lacks the other books provided in Bookshelf which many found to be a useful reference, such as the dictionary of quotations (replaced with a quotations section in \"Encarta\" that links to relevant articles and people) and the Internet Directory, although the directory is now a moot point since many of the sites listed in offline directories no longer exist.\n\nThe original 1987 edition contained \"The Original Roget's Thesaurus of English Words and Phrases\", \"The American Heritage Dictionary of the English Language\", World Almanac and Book of Facts, Bartlett's Familiar Quotations, The Chicago Manual of Style (13th Edition), the U.S. ZIP Code Directory, Houghton Mifflin Usage Alert, Houghton Mifflin Spelling Verifier and Corrector, Business Information Sources, and Forms and Letters. Titles in non-US versions of Bookshelf were different. For example, the 1997 UK edition included the Chambers Dictionary, Bloomsbury Treasury of Quotations, and Hutchinson Concise Encyclopedia.\n\nThe Windows release of Bookshelf added a number of new reference titles, including \"The Concise Columbia Encyclopedia\" and an Internet Directory. Other titles were added and some were dropped in subsequent years. By 1994, the English-language version also contained the \"Columbia Dictionary of Quotations\"; \"The Concise Columbia Encyclopedia\"; the \"Hammond Intermediate World Atlas\"; and \"The People's Chronology\". By 2000, the collection came to include the \"Encarta Desk Encyclopedia\", the \"Encarta Desk Atlas\", the \"Encarta Style Guide\" and a specialized \"Computer and Internet Dictionary\" by Microsoft Press.\n\nBookshelf 1.0 used a proprietary hypertext engine that Microsoft acquired when it bought the company Cytation in 1986. Also used for Microsoft Stat Pack and Microsoft Small Business Consultant, it was a Terminate and Stay Resident (TSR) program that ran alongside a dominant program, unbeknownst to the dominant program. Like Apple's similar Hypercard reader, Bookshelf engine's files used a single compound document, containing large numbers of subdocuments (\"cards\" or \"articles\"). They both differ from current browsers which normally treat each \"page\" or \"article\" as a separate file.\n\nThough similar to Apple's Hypercard reader in many ways, the Bookshelf engine had several key differences. Unlike Hypercard files, Bookshelf files required compilation and complex markup codes. This made the files more difficult to pirate, addressing a key concern of early electronic publishers. Furthermore, Bookshelf's engine was designed to run as fast as possible on slow first-generation CD-ROM drives, some of which required as much as a half-second to move the drive head. Such hardware constraints made Hypercard impractical for high-capacity CD-ROMs. Bookshelf also had full text searching capability, which made it easy to find needed information.\n\nCollaborating with DuPont, the Microsoft CD-ROM division developed a Windows version of its engine for applications as diverse as document management, online help, and a CD-ROM encyclopedia. In a skunkworks project, these developers worked secretly with Multimedia Division developers so that the engine would be usable for more ambitious multimedia applications. Thus they integrated a multimedia markup language, full text search, and extensibility using software objects, all of which are commonplace in modern internet browsing.\n\nIn 1992, Microsoft started selling the Bookshelf engine to third-party developers, marketing the product as Microsoft Multimedia Viewer. The idea was that such a tool would help a burgeoning growth of CD-ROM titles that would spur demand for Windows. Although the engine had multimedia capabilities that would not be matched by Web browsers until the late 1990s, Microsoft Viewer did not enjoy commercial success as a standalone product. However, Microsoft continued to use the engine for its Encarta and WinHelp applications, though the multimedia functions are rarely used in Windows help files.\n\nIn 1993, the developers who were working on the next generation viewer were moved to the Cairo systems group which was charged with delivering Bill Gates' 'vision' of 'Information at your fingertips'. This advanced browser was a fully componentized application using what are now known as Component Object Model objects, designed for hypermedia browsing across large networks and whose main competitor was thought to be Lotus Notes. Long before Netscape appeared, this team, known as the WEB (web enhanced browser) team had already shipped a network capable hypertext browser capable of doing everything that HTML browsers would not be able to do until the turn of the century. Nearly all technologies of Cairo shipped. The WEB browser was not one of them, though it influenced the design of many other common Microsoft technologies.\n\n\"BYTE\" in 1989 listed Microsoft Bookshelf as among the \"Excellence\" winners of the BYTE Awards, stating that it \"is the first substantial application of CD-ROM technology\" and \"a harbinger of personal library systems to come\".\n\n"}
{"id": "1091767", "url": "https://en.wikipedia.org/wiki?curid=1091767", "title": "Non-well-founded set theory", "text": "Non-well-founded set theory\n\nNon-well-founded set theories are variants of axiomatic set theory that allow sets to contain themselves and otherwise violate the rule of well-foundedness. In non-well-founded set theories, the foundation axiom of ZFC is replaced by axioms implying its negation.\n\nThe study of non-well-founded sets was initiated by Dmitry Mirimanoff in a series of papers between 1917 and 1920, in which he formulated the distinction between well-founded and non-well-founded sets; he did not regard well-foundedness as an axiom. Although a number of axiomatic systems of non-well-founded sets were proposed afterwards, they did not find much in the way of applications until Peter Aczel’s hyperset theory in 1988.\n\nThe theory of non-well-founded sets has been applied in the logical modelling of non-terminating computational processes in computer science (process algebra and final semantics), linguistics and natural language semantics (situation theory), philosophy (work on the Liar Paradox), and in a different setting, non-standard analysis.\n\nIn 1917, Dmitry Mirimanoff introduced the concept of well-foundedness of a set:\n\nIn ZFC, there is no infinite descending ∈-sequence by the axiom of regularity. In fact, the axiom of regularity is often called the \"foundation axiom\" since it can be proved within ZFC (that is, ZFC without the axiom of regularity) that well-foundedness implies regularity. In variants of ZFC without the axiom of regularity, the possibility of non-well-founded sets with set-like ∈-chains arises. For example, a set \"A\" such that \"A\" ∈ \"A\" is non-well-founded.\n\nAlthough Mirimanoff also introduced a notion of isomorphism between possibly non-well-founded sets, he considered neither an axiom of foundation nor of anti-foundation. In 1926, Paul Finsler introduced the first axiom that allowed non-well-founded sets. After Zermelo adopted Foundation into his own system in 1930 (from previous work of von Neumann 1925–1929) interest in non-well-founded sets waned for decades. An early non-well-founded set theory was Willard Van Orman Quine’s New Foundations, although it is not merely ZF with a replacement for Foundation.\n\nSeveral proofs of the independence of Foundation from the rest of ZF were published in 1950s particularly by Paul Bernays (1954), following an announcement of the result in earlier paper of his from 1941, and by Ernst Specker who gave a different proof in his Habilitationsschrift of 1951, proof which was published in 1957. Then in 1957 Rieger's theorem was published, which gave a general method for such proof to be carried out, rekindling some interest in non-well-founded axiomatic systems. The next axiom proposal came in a 1960 congress talk of Dana Scott (never published as a paper), proposing an alternative axiom now called SAFA. Another axiom proposed in the late 1960s was Maurice Boffa's axiom of superuniversality, described by Aczel as the highpoint of research of its decade. Boffa's idea was to make foundation fail as badly as it can (or rather, as extensionality permits): Boffa's axiom implies that every extensional set-like relation is isomorphic to the elementhood predicate on a transitive class.\n\nA more recent approach to non-well-founded set theory, pioneered by M. Forti and F. Honsell in the 1980s, borrows from computer science the concept of a bisimulation. Bisimilar sets are considered indistinguishable and thus equal, which leads to a strengthening of the axiom of extensionality. In this context, axioms contradicting the axiom of regularity are known as anti-foundation axioms, and a set that is not necessarily well-founded is called a hyperset.\n\nFour mutually independent anti-foundation axioms are well-known, sometimes abbreviated by the first letter in the following list:\nThey essentially correspond to four different notions of equality for non-well-founded sets. The first of these, AFA, is based on accessible pointed graphs (apg) and states that two hypersets are equal if and only if they can be pictured by the same apg. Within this framework, it can be shown that the so-called Quine atom, formally defined by Q={Q}, exists and is unique.\n\nEach of the axioms given above extends the universe of the previous, so that: V ⊆ A ⊆ S ⊆ F ⊆ B. In the Boffa universe, the distinct Quine atoms form a proper class.\n\nIt is worth emphasizing that hyperset theory is an extension of classical set theory rather than a replacement: the well-founded sets within a hyperset domain conform to classical set theory.\n\nAczel’s hypersets were extensively used by Jon Barwise and John Etchemendy in their 1987 book \"The Liar\", on the liar's paradox; The book is also good introduction to the topic of non-well-founded sets.\n\nBoffa’s superuniversality axiom has found application as a basis for axiomatic nonstandard analysis.\n\n\n\n"}
{"id": "2673834", "url": "https://en.wikipedia.org/wiki?curid=2673834", "title": "Numeronym", "text": "Numeronym\n\nA numeronym is a number-based word.\n\nMost commonly, a numeronym is a word where a number is used to form an abbreviation (albeit not an acronym or an initialism). Pronouncing the letters and numbers may sound similar to the full word: \"K9\" for \"canine\" (phonetically: \"kay\" + \"nine\").\n\nAlternatively, the letters between the first and last are replaced with a number representing the number of letters omitted, such as \"i18n\" for \"internationalization\". Sometimes the last letter is also counted and omitted. These word shortenings are sometimes called \"alphanumeric acronyms\", \"alphanumeric abbreviations\", or \"numerical contractions\".\n\nAccording to Tex Texin, the first numeronym of this kind was \"S12n\", the electronic mail account name given to Digital Equipment Corporation (DEC) employee Jan Scherpenhuizen by a system administrator because his surname was too long to be an account name. By 1985, colleagues who found Jan's name unpronounceable often referred to him verbally as \"S12n\" (\"ess-twelve-en\"). The use of such numeronyms became part of DEC corporate culture.\n\nA number may also denote how many times the character before or after it is repeated. This is typically used to represent a name or phrase in which several consecutive words start with the same letter, as in W3 (World Wide Web) or W3C (World Wide Web Consortium).\n\nSome numeronyms are composed entirely of numbers, such as \"212\" for \"New Yorker\", \"4-1-1\" for \"information\", \"9-1-1\" for \"help\", and \"101\" for \"basic introduction to a subject\". Words of this type have existed for decades, including those in 10-code, which has been in use since before World War II.\n\nChapter or title numbers of some jurisdictions' statutes have become numeronyms, for example 5150 and 187 from California's penal code. Largely because the production of many American movies and television programs are based in California, usage of these terms has spread beyond its original location and user population.\n\nThe concept of incorporating numbers into words can also be found in Leet-speak, where numbers are frequently substituted for orthographically similar letters (e.g. \"H4CK3D\" for \"HACKED\").\n\nAnne H. Soukhanov, editor of the new \"Microsoft Encarta College Dictionary\", gives the original meaning of the term as \"a telephone number that spells a word or a name\" on a telephone dial.\n\nWhere words have multiple meanings, abbreviations such as these are almost always used to refer to their computing sense; for example, \"G11n\" for \"globalization\" refers to software preparedness for global distribution, and not the social trend of globalization. In some cases, the use of appropriate case makes it easier to distinguish between letters such as uppercase I/i and lower case L/l.\n\n"}
{"id": "18134289", "url": "https://en.wikipedia.org/wiki?curid=18134289", "title": "Qualitative comparative analysis", "text": "Qualitative comparative analysis\n\nIn statistics, qualitative comparative analysis (QCA) is a data analysis technique for determining which logical conclusions a data set supports. The analysis begins with listing and counting all the combinations of variables observed in the data set, followed by applying the rules of logical inference to determine which descriptive inferences or implications the data supports. The technique was originally developed by Charles Ragin in 1987.\n\nIn the case of categorical variables, QCA begins by listing and counting all types of cases which occur, where each type of case is defined by its unique combination of values of its independent and dependent variables. For instance, if there were four categorical variables of interest, {A,B,C,D}, and A and B were dichotomous (could take on two values), C could take on five values, and D could take on three, then there would be 60 possible types of observations determined by the possible combinations of variables, not all of which would necessarily occur in real life. By counting the number of observations that exist for each of the 60 unique combination of variables, QCA can determine which descriptive inferences or implications are empirically supported by a data set. Thus, the input to QCA is a data set of any size, from small-N to large-N, and the output of QCA is a set of descriptive inferences or implications the data supports.\n\nIn QCA's next step, inferential logic or Boolean algebra is used to simplify or reduce the number of inferences to the minimum set of inferences supported by the data. This reduced set of inferences is termed the \"prime implicates\" by QCA adherents. For instance, if the presence of conditions A and B is always associated with the presence of a particular value of D, regardless of the observed value of C, then the value that C takes is irrelevant. Thus, all five inferences involving A and B and any of the five values of C may be replaced by the single descriptive inference \"(A and B) implies the particular value of D\".\n\nTo establish that the prime implicants or descriptive inferences derived from the data by the QCA method are causal requires establishing the existence of causal mechanism using another method such as process tracing, formal logic, intervening variables, or established multidisciplinary knowledge. The method is used in social science and is based on the binary logic of Boolean algebra, and attempts to ensure that all possible combinations of variables that can be made across the cases under investigation are considered.\n\nThe technique of listing case types by potential variable combinations assists with case selection by making investigators aware of all possible case types that would need to be investigated, at a minimum, if they exist, in order to test a certain hypothesis or to derive new inferences from an existing data set. In situations where the available observations constitute the entire population of cases, this method alleviates the small N problem by allowing inferences to be drawn by evaluating and comparing the number of cases exhibiting each combination of variables. The small N problem arises when the number of units of analysis (e.g. countries) available is inherently limited. For example: a study where countries are the unit of analysis is limited in that are only a limited number of countries in the world (less than 200), less than necessary for some (probabilistic) statistical techniques. By maximizing the number of comparisons that can be made across the cases under investigation, causal inferences are according to Ragin possible. This technique allows the identification of multiple causal pathways and interaction effects that may not be detectable via statistical analysis that typically requires its data set to conform to one model. Thus, it is the first step to identifying subsets of a data set conforming to particular causal pathway based on the combinations of covariates prior to quantitative statistical analyses testing conformance to a model; and helps qualitative researchers to correctly limit the scope of claimed findings to the type of observations they analyze.\n\nAs this is a logical (deterministic) and not a statistical (probabilistic) technique, with \"crisp-set\" QCA (csQCA), the original application of QCA, variables can only have two values, which is problematic as the researcher has to determine the values of each variable. For example: GDP per capita has to be divided by the researcher in two categories (e.g. low = 0 and high = 1). But as this variable is essentially a continuous variable, the division will always be arbitrary. A second, related problem is that the technique does not allow an assessment of the effect of the relative strengths of the independent variables (as they can only have two values). Ragin, and other scholars such as Lasse Cronqvist, have tried to deal with these issues by developing new tools that extend QCA, such as multi-value QCA (mvQCA) and fuzzy set QCA (fsQCA). Note: Multi-value QCA is simply QCA applied to observations having categorical variables with more than two values. Crisp-Set QCA can be considered a special case of Multi-value QCA. \n\nStatistical methodologists have argued that QCA's strong assumptions render its findings both fragile and prone to type I error. Simon Hug argues that deterministic hypotheses and error-free measures are exceedingly rare in social science and uses Monte Carlo simulations to demonstrate the fragility of QCA results if either assumption is violated. Chris Krogslund, Donghyun Danny Choi, and Mathias Poertner further demonstrate that QCA results are highly sensitive to minor parametric and model-susceptibility changes and are vulnerable to type I error. Bear F. Braumoeller further explores the vulnerability of the QCA family of techniques to both type I error and multiple inference. Braumoeller also offers a formal test of the null hypothesis and demonstrates that even very convincing QCA findings may be the result of chance.\n\nQCA can be performed probabilistically or deterministically with observations of categorical variables. For instance, the existence of a descriptive inference or implication is supported deterministically by the absence of any counter-example cases to the inference; i.e. if a researcher claims condition X implies condition Y, then, deterministically, there must not exist any counterexample cases having condition X, but not condition Y. However, if the researcher wants to claim that condition X is a probabilistic 'predictor' of condition Y, in another similar set of cases, then the proportion of counterexample cases to an inference to the proportion of cases having that same combination of conditions can be set at a threshold value of for example 80% or higher. For each prime implicant that QCA outputs via its logical inference reduction process, the \"coverage\" — percentage out of all observations that exhibit that implication or inference — and the \"consistency\" — the percentage of observations conforming to that combination of variables having that particular value of the dependent variable or outcome — are calculated and reported, and can be used as indicators of the strength of such a explorative probabilistic inference. In real-life complex societal processes, QCA enables the identification of multiple sets of conditions that are consistently associated with a particular output value in order to explore for causal predictors.\n\nFuzzy set QCA aims to handle variables, such as GDP per capita, where the number of categories, decimal values of monetary units, becomes too large to use mvQCA, or in cases were uncertainty or ambiguity or measurement error in the classification of a case needs to be acknowledged.\n\nQCA has now become used in many more fields than political science which Ragin first developed the method for. Today the method has been used in:\n"}
{"id": "25407", "url": "https://en.wikipedia.org/wiki?curid=25407", "title": "Recursion", "text": "Recursion\n\nRecursion occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no loop or infinite chain of references can occur.\n\nIn mathematics and computer science, a class of objects or methods exhibit recursive behavior when they can be defined by two properties:\n\nFor example, the following is a recursive definition of a person's ancestors:\n\nThe Fibonacci sequence is a classic example of recursion:\n\nformula_1\n\nformula_2\n\nformula_3\n\nMany mathematical axioms are based upon recursive rules. For example, the formal definition of the natural numbers by the Peano axioms can be described as: \"0 is a natural number, and each natural number has a successor, which is also a natural number.\" By this base case and recursive rule, one can generate the set of all natural numbers.\n\nRecursively defined mathematical objects include functions, sets, and especially fractals.\n\nThere are various more tongue-in-cheek \"definitions\" of recursion; see recursive humor.\n\nRecursion is the process a procedure goes through when one of the steps of the procedure involves invoking the procedure itself. A procedure that goes through recursion is said to be 'recursive'.\n\nTo understand recursion, one must recognize the distinction between a procedure and the running of a procedure. A procedure is a set of steps based on a set of rules. The running of a procedure involves actually following the rules and performing the steps. An analogy: a procedure is like a written recipe; running a procedure is like actually preparing the meal.\n\nRecursion is related to, but not the same as, a reference within the specification of a procedure to the execution of some other procedure. For instance, a recipe might refer to cooking vegetables, which is another procedure that in turn requires heating water, and so forth. However, a recursive procedure is where (at least) one of its steps calls for a new instance of the very same procedure, like a sourdough recipe calling for some dough left over from the last time the same recipe was made. This immediately creates the possibility of an endless loop; recursion can only be properly used in a definition if the step in question is skipped in certain cases so that the procedure can complete, like a sourdough recipe that also tells you how to get some starter dough in case you've never made it before. Even if properly defined, a recursive procedure is not easy for humans to perform, as it requires distinguishing the new from the old (partially executed) invocation of the procedure; this requires some administration of how far various simultaneous instances of the procedures have progressed. For this reason recursive definitions are very rare in everyday situations. An example could be the following procedure to find a way through a maze. Proceed forward until reaching either an exit or a branching point (a dead end is considered a branching point with 0 branches). If the point reached is an exit, terminate. Otherwise try each branch in turn, using the procedure recursively; if every trial fails by reaching only dead ends, return on the path that led to this branching point and report failure. Whether this actually defines a terminating procedure depends on the nature of the maze: it must not allow loops. In any case, executing the procedure requires carefully recording all currently explored branching points, and which of their branches have already been exhaustively tried.\n\nLinguist Noam Chomsky among many others has argued that the lack of an upper bound on the number of grammatical sentences in a language, and the lack of an upper bound on grammatical sentence length (beyond practical constraints such as the time available to utter one), can be explained as the consequence of recursion in natural language. This can be understood in terms of a recursive definition of a syntactic category, such as a sentence. A sentence can have a structure in which what follows the verb is another sentence: \"Dorothy thinks witches are dangerous\", in which the sentence \"witches are dangerous\" occurs in the larger one. So a sentence can be defined recursively (very roughly) as something with a structure that includes a noun phrase, a verb, and optionally another sentence. This is really just a special case of the mathematical definition of recursion.\n\nThis provides a way of understanding the creativity of language—the unbounded number of grammatical sentences—because it immediately predicts that sentences can be of arbitrary length: \"Dorothy thinks that Toto suspects that Tin Man said that...\". There are many structures apart from sentences that can be defined recursively, and therefore many ways in which a sentence can embed instances of one category inside another. Over the years, languages in general have proved amenable to this kind of analysis.\n\nRecently, however, the generally accepted idea that recursion is an essential property of human language has been challenged by Daniel Everett on the basis of his claims about the Pirahã language. Andrew Nevins, David Pesetsky and Cilene Rodrigues are among many who have argued against this. Literary self-reference can in any case be argued to be different in kind from mathematical or logical recursion.\n\nRecursion plays a crucial role not only in syntax, but also in natural language semantics. The word \"and\", for example, can be construed as a function that can apply to sentence meanings to create new sentences, and likewise for noun phrase meanings, verb phrase meanings, and others. It can also apply to intransitive verbs, transitive verbs, or ditransitive verbs. In order to provide a single denotation for it that is suitably flexible, \"and\" is typically defined so that it can take any of these different types of meanings as arguments. This can be done by defining it for a simple case in which it combines sentences, and then defining the other cases recursively in terms of the simple one. \n\nA recursive grammar is a formal grammar that contains recursive production rules.\n\nRecursion is sometimes used humorously in computer science, programming, philosophy, or mathematics textbooks, generally by giving a circular definition or self-reference, in which the putative recursive step does not get closer to a base case, but instead leads to an infinite regress. It is not unusual for such books to include a joke entry in their glossary along the lines of:\n\nA variation is found on page 269 in the index of some editions of Brian Kernighan and Dennis Ritchie's book \"The C Programming Language\"; the index entry recursively references itself (\"recursion 86, 139, 141, 182, 202, 269\"). The earliest version of this joke was in \"Software Tools\" by Kernighan and Plauger, and also appears in \"The UNIX Programming Environment\" by Kernighan and Pike. It did not appear in the first edition of \"The C Programming Language\".\n\nAnother joke is that \"To understand recursion, you must understand recursion.\" In the English-language version of the Google web search engine, when a search for \"recursion\" is made, the site suggests \"Did you mean: \"recursion\".\" An alternative form is the following, from Andrew Plotkin: \"If you already know what recursion is, just remember the answer. Otherwise, find someone who is standing closer to Douglas Hofstadter than you are; then ask him or her what recursion is.\"\n\nRecursive acronyms can also be examples of recursive humor. PHP, for example, stands for \"PHP Hypertext Preprocessor\", WINE stands for \"WINE Is Not an Emulator.\" and GNU stands for \"GNU's not Unix\".\n\nThe canonical example of a recursively defined set is given by the natural numbers:\n\nAnother interesting example is the set of all \"true reachable\" propositions in an axiomatic system.\n\n\nThis set is called 'true reachable propositions' because in non-constructive approaches to the foundations of mathematics, the set of true propositions may be larger than the set recursively constructed from the axioms and rules of inference. See also Gödel's incompleteness theorems.\n\nFinite subdivision rules are a geometric form of recursion, which can be used to create fractal-like images. A subdivision rule starts with a collection of polygons labelled by finitely many labels, and then each polygon is subdivided into smaller labelled polygons in a way that depends only on the labels of the original polygon. This process can be iterated. The standard `middle thirds' technique for creating the Cantor set is a subdivision rule, as is barycentric subdivision.\n\nA function may be partly defined in terms of itself. A familiar example is the Fibonacci number sequence: \"F\"(\"n\") = \"F\"(\"n\" − 1) + \"F\"(\"n\" − 2). For such a definition to be useful, it must lead to non-recursively defined values, in this case \"F\"(0) = 0 and \"F\"(1) = 1.\n\nA famous recursive function is the Ackermann function, which—unlike the Fibonacci sequence—cannot easily be expressed without recursion.\n\nApplying the standard technique of proof by cases to recursively defined sets or functions, as in the preceding sections, yields structural induction, a powerful generalization of mathematical induction widely used to derive proofs in mathematical logic and computer science.\n\nDynamic programming is an approach to optimization that restates a multiperiod or multistep optimization problem in recursive form. The key result in dynamic programming is the Bellman equation, which writes the value of the optimization problem at an earlier time (or earlier step) in terms of its value at a later time (or later step).\n\nIn set theory, this is a theorem guaranteeing that recursively defined functions exist. Given a set \"X\", an element \"a\" of \"X\" and a function formula_7, the theorem states that there is a unique function formula_8 (where formula_4 denotes the set of natural numbers including zero) such that\nfor any natural number \"n\".\n\nTake two functions formula_8 and formula_13 such that:\n\nwhere \"a\" is an element of \"X\".\n\nIt can be proved by mathematical induction that formula_18 for all natural numbers \"n\":\n\nBy induction, formula_18 for all formula_25.\n\nA common method of simplification is to divide a problem into subproblems of the same type. As a computer programming technique, this is called divide and conquer and is key to the design of many important algorithms. Divide and conquer serves as a top-down approach to problem solving, where problems are solved by solving smaller and smaller instances. A contrary approach is dynamic programming. This approach serves as a bottom-up approach, where problems are solved by solving larger and larger instances, until the desired size is reached.\n\nA classic example of recursion is the definition of the factorial function, given here in C code:\n\nIf not having reached the base case and returning with value every instantiation of the above function creates a new instance of the function, passing to it an input reduced by (), and returns the result of this (recursive) call, multiplied by its own value of , analogously to the mathematical definition of the factorial.\n\nRecursion in computer programming is exemplified when a function is defined in terms of simpler, often smaller versions of itself. The solution to the problem is then devised by combining the solutions obtained from the simpler versions of the problem. One example application of recursion is in parsers for programming languages. The great advantage of recursion is that an infinite set of possible sentences, designs or other data can be defined, parsed or produced by a finite computer program.\n\nRecurrence relations are equations to define one or more sequences recursively. Some specific kinds of recurrence relation can be \"solved\" to obtain a non-recursive definition.\n\nUse of recursion in an algorithm has both advantages and disadvantages. The main advantage is usually simplicity. The main disadvantage is often that the algorithm may require large amounts of memory if the depth of the recursion is very large.\n\nThe Russian Doll or Matryoshka Doll is a physical artistic example of the recursive concept.\n\nRecursion has been used in paintings since Giotto's \"Stefaneschi Triptych\", made in 1320. Its central panel contains the kneeling figure of Cardinal Stefaneschi, holding up the triptych itself as an offering.\n\nM. C. Escher's \"Print Gallery\" (1956) is a print which depicts a distorted city which contains a gallery which recursively contains the picture, and so \"ad infinitum\".\n\n\n"}
{"id": "20110874", "url": "https://en.wikipedia.org/wiki?curid=20110874", "title": "Reference", "text": "Reference\n\nReference is a relation between objects in which one object designates, or acts as a means by which to connect to or link to, another object. The first object in this relation is said to \"refer to\" the second object. It is called a \"name\" for the second object. The second object, the one to which the first object refers, is called the \"referent\" of the first object. A name is usually a phrase or expression, or some other symbolic representation. Its referent may be anything – a material object, a person, an event, an activity, or an abstract concept.\n\nReferences can take on many forms, including: a thought, a sensory perception that is audible (onomatopoeia), visual (text), olfactory, or tactile, emotional state, relationship with other, spacetime coordinate, symbolic or alpha-numeric, a physical object or an energy projection. In some cases, methods are used that intentionally hide the reference from some observers, as in cryptography.\n\nReferences feature in many spheres of human activity and knowledge, and the term adopts shades of meaning particular to the contexts in which it is used. Some of them are described in the sections below.\n\nThe word \"reference\" is derived from Middle English \"referren\", from Middle French \"référer\", from Latin \"referre\", \"to carry back\", formed from the prefix \"re\"- and \"ferre\", \"to bear\". A number of words derive from the same root, including \"refer\", \"referee\", \"referential\", \"referent\", \"referendum\".\n\nThe verb \"refer (to)\" and its derivatives may carry the sense of \"link to\" or \"connect to\", as in the meanings of \"reference\" described in this article. Another sense is \"consult\"; this is reflected in such expressions as reference work, reference desk, job reference, etc.\n\nIn semantics, reference is generally construed as the relationships between nouns or pronouns and objects that are named by them. Hence, the word \"John\" refers to the person John. The word \"it\" refers to some previously specified object. The object referred to is called the \"referent\" of the word. Sometimes the word-object relation is called \"denotation\"; the word denotes the object. The converse relation, the relation from object to word, is called \"exemplification\"; the object exemplifies what the word denotes. In syntactic analysis, if a word refers to a previous word, the previous word is called the \"antecedent\".\n\nGottlob Frege argued that reference cannot be treated as identical with meaning: \"Hesperus\" (an ancient Greek name for the evening star) and \"Phosphorus\" (an ancient Greek name for the morning star) both refer to Venus, but the astronomical fact that '\"Hesperus\" is \"Phosphorus\"' can still be informative, even if the \"meanings\" of \"Hesperus\" and \"Phosphorus\" are already known. This problem led Frege to distinguish between the sense and reference of a word. Some cases seem to be too complicated to be classified within this framework; the acceptance of the notion of secondary reference may be necessary to fill the gap. See also Opaque context.\n\nThe very concept of the linguistic sign is the combination of content and expression, the former of which may refer entities in the world or refer more abstract concepts, e.g. thought.\nCertain parts of speech exist only to express reference, namely anaphora such as pronouns. The subset of reflexives expresses co-reference of two participants in a sentence. These could be the agent (actor) and patient (acted on), as in \"The man washed himself\", the theme and recipient, as in \"I showed Mary to herself\", or various other possible combinations.\n\nIn computer science, references are data types that refer to an object elsewhere in memory and are used to construct a wide variety of data structures, such as linked lists. Generally, a reference is a value that enables a program to directly access the particular data item. Most programming languages support some form of reference. For the specific type of reference used in the C++ language, see reference (C++).\n\nThe notion of reference is also important in relational database theory; see referential integrity.\n\nReferences to many types of printed matter may come in an electronic or machine-readable form. For books, there exists the ISBN and for journal articles, the Digital object identifier (DOI) is gaining relevance. Information on the Internet may be referred to by a Uniform Resource Identifier (URI).\n\nIn terms of mental processing, a self-reference is used in psychology to establish identification with a mental state during self-analysis. This seeks to allow the individual to develop own frames of reference in a greater state of immediate awareness. However, it can also lead to circular reasoning, preventing evolution of thought.\n\nAccording to Perceptual Control Theory (PCT), a reference condition is the state toward which a control system's output tends to alter a controlled quantity. The main proposition is that \"All behavior is oriented all of the time around the control of certain quantities with respect to specific reference conditions.\"\n\nIn academics and scholarship, an author-title-date information in bibliographies and footnotes, specifying complete works of other people. Copying of material by another author without proper citation or without required permissions is plagiarism.\n\nKeeping a diary allows an individual to use references for personal organization, whether or not anyone else understands the systems of reference used. However, scholars have studied methods of reference because of their key role in communication and co-operation between \"different\" people, and also because of misunderstandings that can arise. Modern academic study of reference has been developing since the 19th century.\n\nIn scholarship, a reference may be a citation of a text that has been used in the creation of a piece of work such as an essay, report, or oration. Its primary purpose is to allow people who read such work to examine the author's sources, either for validity or to learn more about the subject. Such items are often listed at the end of an article or book in a section marked \"Bibliography\" or \"References\". A bibliographical section often contains works not cited by the author, but used as background reading or listed as potentially useful to the reader. A reference section contains only those works cited by the author(s) in the main text.\n\nIn patent law, a reference is a document that can be used to show the state of knowledge at a given time and that therefore may make a claimed invention obvious or anticipated. Examples of references are patents of any country, magazine articles, Ph.D. theses that are indexed and thus accessible to those interested in finding information about the subject matter, and to some extent Internet material that is similarly accessible.\n\nIn art, a reference is an item from which a work is based. This may include:\nAnother example of reference is samples of various musical works being incorporated into a new one.\n\n\n"}
{"id": "47089125", "url": "https://en.wikipedia.org/wiki?curid=47089125", "title": "Roving reference", "text": "Roving reference\n\nRoving reference, also called roaming reference, is a library service model in which, instead of being positioned at a static reference desk, a librarian moves throughout the library to locate patrons with questions or concerns and offer them help in finding or using library resources.\n\nRoving reference as a library service practice was first formalized in the late 1980s and early 1990s. A 1999 report from the International Federation of Library Associations identified several advantages and disadvantages with roving reference in the pre-mobile era. The roving model allowed librarians to engage with \"the majority of users who have questions in mind [who] do not approach the reference desk for assistance\". However, libraries reported that some staff were uncomfortable with the practice, and that there were concerns about user privacy.\n\nBeginning in the 2000s, librarians used laptops or laptop carts to engage in technology-supported roaming reference. Since the development of mobile technologies, roving reference can be facilitated with the use of such technologies, such as tablet computers, which allow librarians to readily check the online public access catalogue or the library's electronic databases while away from their desk. This has contributed to the increased popularization of roving-reference programs as supplements for more traditional reference desks. The model has also been extended to service beyond the library building (library outreach), for example in a dormitory or faculty building at an academic institution.\n"}
{"id": "49632241", "url": "https://en.wikipedia.org/wiki?curid=49632241", "title": "Self-perpetuation", "text": "Self-perpetuation\n\nSelf-perpetuation, the capability of something to cause itself to continue to exist, is one of the main characteristics of life. Organisms' capability of reproduction leads to self-perpetuation of the species, if not to the individual. Populations self-perpetuate and grow. Entire ecosystems show homeostasis, and thus perpetuate themselves. The slow modifying effect of succession and similar shifts in the composition of the system can, however, not be neglected in the long run. Overall, life's object's capabilities of self-perpetuation are always accompanied by evolution, a perfect steady state of the biological system is never reached. Sexual reproduction is also a form of imperfect self-replication and thus imperfect self-perpetuation because of recombination and mutation. Organisms are not like self-replicating machine but amass random modifications from generation to generation. The property of self-perpetuation in the strict sense thus only applies to life itself.\n\nIn a social context, self-perpetuation is tied to reflexivity and (usually) positive feedback loops:\nDepending on the time scope or the context, self-perpetuation either depends on self-sustainability, or is equivalent to it. While we may talk about the self-sustainability of an ecosystem, this depends amongst other factor on the self-perpetuation of its constituting species.\n\nIn computer science, self-reproducing programs constitute an incomplete metaphor for self-perpetuation. A better analogue can be seen in computer viruses which are actually able to self-reproduce - given a suitable computing environment.\n\n"}
{"id": "16122539", "url": "https://en.wikipedia.org/wiki?curid=16122539", "title": "Self-reference puzzle", "text": "Self-reference puzzle\n\nA self-reference puzzle is a type of logical puzzle where the question in the puzzle refers to the attributes of the puzzle itself.\nA common example is that a \"fill in the blanks\" style sentence is given, but what is filled in the blanks can contribute to the sentence itself. An example is \"There are _____ e's in this sentence.\", for which a solution is \"eight\" (since including the \"eight\", there are 8 e's in the sentence).\n\n"}
{"id": "858507", "url": "https://en.wikipedia.org/wiki?curid=858507", "title": "Self-referential humor", "text": "Self-referential humor\n\nSelf-referential humor, also known as self-reflexive humor or meta humor, is a type of comedic expression that—either directed toward some other subject, or openly directed toward itself—intentionally alludes to the very person who is expressing the humor in a comedic fashion, or to some specific aspect of that same comedic expression. Self-referential humor expressed discreetly and surrealistically is a form of bathos. In general, self-referential humor often uses hypocrisy, oxymoron, or paradox to create a contradictory or otherwise absurd situation that is humorous to the audience. \n\nSelf-referential humor is sometimes combined with breaking the fourth wall to explicitly make the reference directly to the audience, or make self-reference to an element of the medium that the characters should not be aware of.\n\nOld Comedy of Classical Athens is held to be the first—in the extant sources—form of self-referential comedy. Aristophanes, whose plays form the only remaining fragments of Old Comedy, used fantastical plots, grotesque and inhuman masks and status reversals of characters to slander prominent politicians and court his audience's approval.\n\nRAS syndrome refers to the redundant use of one or more of the words that make up an acronym or initialism with the abbreviation itself, thus in effect repeating one or more words. However, \"RAS\" stands for Redundant Acronym Syndrome; therefore, the full phrase yields \"Redundant Acronym Syndrome syndrome\" and is self-referencing in a comical manner. It also reflects an excessive use of TLAs (Three Letter Acronyms).\n\nMeta has come to be used, particularly in art, to refer to something that is self-referential. Popularised by Douglas Hofstadter who wrote several books on himself and the subject of self-reference, meta-jokes are a popular form of humor.\n\n"}
{"id": "12153317", "url": "https://en.wikipedia.org/wiki?curid=12153317", "title": "Sixpenny Library", "text": "Sixpenny Library\n\nErnest Benn Limited’s Sixpenny Library is a complete series of reference books published in the late 1920s and early 1930s. The library included over one hundred and eighty volumes. The series was edited by William Rose, who solicited current authorities in such areas as history, literature, religion, psychology, science, and economics. Some contributing authors were Hilaire Belloc, Maurice Baring, J.B. Priestley, Sir (later Lord) Robert Baden-Powell, Sir Oliver Lodge, S.V Keeling and Sir Ernest Benn himself. \"The Spectator\", in November 1927, after announcing some the latest additions to \"Messrs Benn's excellent Sixpenny Library\" devoted a further paragraph to his contribution on Trade (both of which are free to read online). Partial lists of the books published in the series can be found here and here.\n\nThe books were praised by critics for their excellence, brevity, and inexpensive price.\n"}
{"id": "738307", "url": "https://en.wikipedia.org/wiki?curid=738307", "title": "Stephanus pagination", "text": "Stephanus pagination\n\nStephanus pagination is a system of reference and organization used in modern editions and translations of Plato (and less famously, Plutarch) based on the three volume 1578 edition of Plato's complete works translated by Joannes Serranus (Jean de Serres) and published by Henricus Stephanus (Henri Estienne) in Geneva.\n\nIn the case of Plato's works, Stephanus pagination first divides the works into numbers that are the page numbers of each of the Stephanus edition's three volumes, and each such page and page number is further subdivided into lettered sections which correspond to parallel Greek/Latin translated passages on a given page, mostly commonly a, b, c, d, and e. This system is used in modern scholarship to cite Plato. For Plato's works, unique coordinates for a passage can therefore be given with three pieces of information: the work's name, the (Stephanus) page number, and the letter denoting the passage. For example, \"\"Symposium\" 172a\" cites \"Symposium\", Stephanus page 172 (the volume in which \"Symposium\" occurs, as it happens, volume 3), passage a. To avoid ambiguity in this scheme, either the Platonic work or the volume must be cited; absent this, \"page 50\" might refer to any of the \"pages 50\" across Stephanus' three volumes. Reference to Stephanus manifestly presupposes the existing ordering of the work in its given volumes, but given historical disagreement as to the chronology and proper ordering of Plato's works, care should therefore be taken when referring to Stephanus pagination as opposed to another scheme.\n\nMore specific citations may add line numbers, e.g. \"Symposium\" 209a5–9, but these generally refer to the lines in John Burnet's Oxford Classical Text, not to Estienne's line divisions.\n\nThere are some peculiarities in the Stephanus page numbers. The length of each page and each paragraph can vary if extra commentary appears on the page of the 1578 edition. Thus Stephanus pages are not all of the same length. Some pages do not have all the paragraphs a through e. There are also gaps in the sequence of Stephanus page numbers for Plato's \"Republic\" and \"Laws\". The reason is that the editors added separate introductions to each 'book' of these longer works, and thus the page numbers of these introductions are not used to refer to pages in Plato's dialogues. \n\nThe spurious dialogue \"Halcyon\" was included in the corpus of Lucian's works and does not have Stephanus numbers.\n\nBekker numbering is the comparable system for the works of Aristotle, and Diels–Kranz numbering is the comparable system for Pre-Socratic philosophy. Unlike Stephanus pagination, Bekker numbering starts with page 1 and proceeds through all of Aristotle's works without starting over, regardless of the number of volumes needed for a given edition. Bekker numbering therefore has the advantage, not shared by Stephanus pagination, of giving compact, unambiguous numerical citation of a given passage, page, etc, without the absolute necessity in order to avoid ambiguity to specify the dialogue, work or volume which exists in the case of Stephanus.\n\n\n\n\n\n"}
{"id": "26681002", "url": "https://en.wikipedia.org/wiki?curid=26681002", "title": "Text annotation", "text": "Text annotation\n\nText Annotation is the practice and the result of adding a note or gloss to a text, which may include highlights or underlining, comments, footnotes, tags, and links. Text annotations can include notes written for a reader's private purposes, as well as shared annotations written for the purposes of collaborative writing and editing, commentary, or social reading and sharing. In some fields, text annotation is comparable to metadata insofar as it is added post hoc and provides information about a text without fundamentally altering that original text. Text annotations are sometimes referred to as marginalia, though some reserve this term specifically for hand-written notes made in the margins of books or manuscripts. Annotations are extremely useful and help to develop knowledge of English literature.\n\nThis article covers both private and socially shared text annotations, including hand-written and information technology-based annotation. For information on annotation of Web content, including images and other non-textual content, see also Web annotation.\n\nText annotation may be as old as writing on media, where it was possible to produce an additional copy with a reasonable effort. It became a prominent activity around 1000 AD in Talmudic commentaries and Arabic rhetorics treaties. In the Medieval era, scribes who copied manuscripts often made marginal annotations that then circulated with the manuscripts and were thus shared with the community; sometimes annotations were copied over to new versions when such manuscripts were later recopied.\n\nWith the rise of the printing press and the relative ease of circulating and purchasing individual (rather than shared) copies of texts, the prevalence of socially shared annotations declined and text annotation became a more private activity consisting of a reader interacting with a text. Annotations made on shared copies of texts (such as library books) are sometimes seen as devaluing the text, or as an act of defacement. Thus, print technologies support the circulation of annotations primarily as formal scholarly commentary or textual footnotes or endnotes rather than marginal, handwritten comments made by private readers, though handwritten comments or annotations were common in collaborative writing or editing.\n\nComputer-based technologies have provided new opportunities for individual and socially shared text annotations that support multiple purposes, including readers’ individual reading goals, learning, social reading, writing and editing, and other practices. Text annotation in Information Technology (IT) systems raises technical issues of access, linkage, and storage that are generally not relevant to paper-based text annotation, and thus research and development of such systems often addresses these areas.\n\nText annotations can serve a variety of functions for both private and public reading and communication practices. In their article \"From the Margins to the Center: The Future of Annotation,\" scholars Joanna Wolfe and Christine Neuwirth identify four primary functions that text annotations commonly serve in the modern era, including: (1)\"facilitat[ing] reading and later writing tasks,\" which includes annotations that support reading for both personal and professional purposes; (2)\"eavesdrop[ping] on the insights of other readers,\" which involves sharing of annotations; (3)\"provid[ing] feedback to writers or promote communication with collaborators,\" which can include personal, professional, and education-related feedback; and (4)\"call[ing] attention to topics and important passages,\" for which scholarly annotations, footnotes, and call-outs often function. Regarding the ways that annotations can support individual reading tasks, Catherine Marshall points out that the ways that readers annotate texts depends on the purpose, motivation, and context of reading. Readers may annotate to help interpret a text, to call attention to a section for future reference or reading, to support memory and recall, to help focus attention on the text as they read, to work out a problem related to the text, or create annotations not specifically related to the text at all.\n\nEducational research in text annotation has examined the role that both private and shared text annotations can play in supporting learning goals and communication. Much educational research examines how students’ private annotation of texts supports comprehension and memory; for example, research indicates that annotating texts causes more in-depth processing of information, which results in greater recall of information.\n\nOther areas of educational research investigate the benefits of socially shared text annotations for collaborative learning, both for paper-based and IT-based annotation sharing. For example, studies by Joanna Wolfe have investigated the benefits of exposure to others’ annotations on student readers and writers. In a 2000 study, Wolfe found that exposing students to others’ annotations influenced their perceptions of the annotators, which in turn shaped their responses to the material and their written products. In a later study, Wolfe found that viewing others’ written comments on a paper text, especially pairs of annotations that present opposing responses to the text, can help students engage in the type of critical reading and stance-taking necessary for effective argumentative writing.\n\nWhile shared annotations can benefit individual readers, it is important to note that, \"since the 1920s, literacy theory has increasingly emphasized the importance of social factors in the development of literacy.\" Thus, shared annotations can not only help one to better understand the content of a particular text, but may also aid in the acquirement of literacy skills. For example, a mother may leave marks inside a book to draw the attention of her child to a particular theme or concept; thanks to the development of audio annotations, parents may now leave notes for children who are just starting to read and may struggle with textual annotations.\n\nMore recent research in the effects of shared text annotations has focused on the learning applications for web-based annotation systems, some of which were developed based on design recommendations from studies outlined above. For example, Ananda Gunawardena, Aaron Tan, and David Kaufer conducted a pilot study to examine whether annotating documents in Classroom Salon, a web-based annotation and social reading platform, encouraged active reading, error detection, and collaboration in a computer science course at Carnegie Mellon University. This study suggested a correlation between students’ overall performance in the course and their ability to identify errors in a text that they annotated in Classroom Salon; it also found that students were likely to change their annotations in response to annotations made by others in the course.\n\nSimilarly, the web-based annotation tool HyLighter was used in a first-year writing course and shown to improve the development of students’ mental models of texts, including supporting reading comprehension, critical thinking, and the ability to develop a thesis. The collaboration with peers and experts around a shared text improved these skills and brought the communities’ understanding closer together.\n\nA meta-analysis of empirical studies into the higher-education uses of social annotation (SA) tools indicates such tools have been tested in several courses, among them English, sport psychology, and hypermedia. Studies have indicated that social annotation functions, including commenting, information sharing, and highlighting, can support instruction designed to foster collaborative learning and communication, as well as reading comprehension, metacognition, and critical analysis. Several studies indicated that students enjoyed using social annotation tools, and that it improved motivation in the course.\n\nText annotations have long been used in writing and revision processes as a way for reviewers to suggest changes and communicate about a text. In book publishing, for example, the collaboration of authors and editors to develop and revise a manuscript frequently involves exchanges of both in-line revisions or notes as well as marginal annotations. Similarly, copyeditors often make marginal annotations or notes that explain or suggest revisions or are directed at the author as questions or suggestions (commonly called \"queries\"). Asynchronous collaborative writing and document development often depend on text annotations as a way not only to suggest revisions but also to exchange ideas during document development or to facilitate group decision making, though such processes are often complicated by the use of different communication technologies (such as phone calls or emails as well as document sharing) for distinct tasks. Text annotations can also function to allow group or community members to communicate about a shared text, such as a doctor annotating a patient's chart.\n\nMuch research into the functionality and design of collaborative IT-based writing systems, which often support text annotation, has occurred in the area of computer-supported cooperative work.\n\nResearch in the design and development of annotation systems uses specific terminology to refer to distinct structural components of annotations and also distinguishes among options for digital annotation displays.\n\nThe structural components of any annotation can be roughly divided into three primary elements: a \"body\", an \"anchor\", and a \"marker\". The body of an annotation includes reader-generated symbols and text, such as handwritten commentary or stars in the margin. The anchor is what indicates the extent of the original text to which the body of the annotation refers; it may include circles around sections, brackets, highlights, underlines, and so on. Annotations may be anchored to very broad stretches of text (such as an entire document) or very narrow sections (such as a specific letter, word, or phrase). The marker is the visual appearance of the anchor, such as whether it is a grey underline or a yellow highlight. An annotation that has a body (such as a comment in the margin) but no specific anchor has no marker.\n\nIT-based annotation systems utilize a variety of display options for annotations, including:\nAnnotation interfaces may also allow highlighting or underlining, as well as threaded discussions. Sharing and communicating through annotations anchored to specific documents is sometimes referred to as \"anchored discussion\".\n\nIT-based annotation systems include standalone and client-server systems. In the 1980s and 1990s, a number of such systems were built in the context of libraries, patent offices, and legal text processing. Their design led researchers to produce taxonomies of annotation forms. Text annotation research has taken place at several institutions, including Xerox research centers in Palo Alto and Grenoble (France), the Hitachi Central Research Lab (in particular for annotation of patents), and in relation with the construction of the new French National Library between 1989 and 1995 at the Institut de Recherche en Informatique de Toulouse and in the company AIS (Advanced Innovation Systems).\n\nAnnotation functionality has been present in text processing software for many years through inline notes displayed as pop-ups, footnotes, and endnotes; however, it is only recently that functionality for displaying annotations as marginalia has appeared in programs such as OpenOffice.org/LibreOffice Writer and Microsoft Word. Personal or standalone annotation include word processing software that supports embedded or anchored text annotations as well as Adobe Acrobat, which in addition to commenting allows highlights, stamps, and other types of markup.\n\nTim Berners-Lee had already implemented the concept of directly editing web documents in 1990 in WorldWideWeb, the first web browser, but later ported versions removed this collaborative ability. An early version of NCSA Mosaic in 1993 also included a collaborative annotation capability, though it was quickly removed. Web Distributed Authoring and Versioning, WebDAV, was then reintroduced as an extension.\n\nA different approach to distributed authoring consists in first gathering many annotations from a wide public, and then integrate them all in order to produce a further version of a document. This approach was pioneered by Stet, the system put in place to gather comments on drafts of version 3 of the GNU General Public License. This system arose after a specific requirement, which it served egregiously, but was not so easily configurable as to be convenient for annotating any other document on the web. The co-ment system uses annotation interface concepts similar to Stet's, but it is based on an entirely new implementation, using Django/Python on the server side and various AJAX libraries such as JQuery on the client side. Both Stet and co-ment are licensed under the GNU Affero General Public License.\n\nSince 2011, the non-profit Hypothes Is Project has offered the free, open web annotation service Hypothes.is. The service features annotation via a Chrome extension, bookmarklet or proxy server, as well as integration into a LMS or CMS. Both webpages and PDFs can be annotated. Other web-based text annotation systems are collaborative software for distributed text editing and versioning, which also feature annotation and commenting interfaces. For example, HyLighter supports synchronous and asynchronous interactions, general commenting, comment tagging, threaded discussions and comment filtering. Other annotation tools under these category are more focused on NLP tasks as Named-entity recognition, relationship extraction or normalization. Some tools support manual tagging of data or automatic annotations via supervised learning.\n\nSpecialized Web-based text annotations exist in the context of scientific publication, either for refereeing or post-publication. The on-line journal PLoS ONE, published by the Public Library of Science, has developed its own Web-based system where scientists and the public can comment on published articles. The annotations are displayed as pop-ups with an anchor in the text.\n\n\n"}
{"id": "30334", "url": "https://en.wikipedia.org/wiki?curid=30334", "title": "Thesaurus", "text": "Thesaurus\n\nIn general usage, a thesaurus is a reference work that lists words grouped together according to similarity of meaning (containing synonyms and sometimes antonyms), in contrast to a dictionary, which provides definitions for words, and generally lists them in alphabetical order. The main purpose of such reference works for users \"to find the word, or words, by which [an] idea may be most fitly and aptly expressed\" – to quote Peter Mark Roget, architect of the best known thesaurus in the English language.\n\nAlthough including synonyms, a thesaurus should not be taken as a complete list of all the synonyms for a particular word. The entries are also designed for drawing distinctions between similar words and assisting in choosing exactly the right word. Unlike a dictionary, a thesaurus entry does not give the definition of words.\n\nIn library science and information science, thesauri have been widely used to specify domain models. Recently, thesauri have been implemented with Simple Knowledge Organization System (SKOS).\n\nThe word \"thesaurus\" is derived from 16th-century New Latin, in turn from Latin \"thēsaurus\", which is the Latinisation of the Greek (\"thēsauros\"), \"treasure, treasury, storehouse\". The word \"thēsauros\" is of uncertain etymology. Douglas Harper derives it from the root of the Greek verb τιθέναι \"tithenai\", \"to put, to place.\" Robert Beekes rejected an Indo-European derivation and suggested a Pre-Greek suffix .\n\nFrom the 16th to the 19th centuries, the term \"thesaurus\" was applied to any dictionary or encyclopedia, as in the \"Thesaurus linguae latinae\" (1532), and the \"Thesaurus linguae graecae\" (1572). The meaning \"collection of words arranged according to sense\" is first attested in 1852 in Roget's title and \"thesaurer\" is attested in Middle English for \"treasurer\".\n\nIn antiquity, Philo of Byblos authored the first text that could now be called a thesaurus. In Sanskrit, the Amarakosha is a thesaurus in verse form, written in the 4th century. Eventhough Amarakosha mentions 18 prior works, they have all been lost.\n\nThe first modern thesaurus was \"Roget's Thesaurus\", first compiled in 1805 by Peter Mark Roget, and published in 1852. Since its publication it has never been out of print and is still a widely used work across the English-speaking world. Entries in \"Roget's Thesaurus\" are listed conceptually rather than alphabetically.\nRoget described his thesaurus in the foreword to the first edition:\n\nIt is now nearly fifty years since I first projected a system of verbal classification similar to that on which the present work is founded. Conceiving that such a compilation might help to supply my own deficiencies, I had, in the year 1805, completed a classed catalogue of words on a small scale, but on the same principle, and nearly in the same form, as the Thesaurus now published.\nThesauri have been used to perform automatic word-sense disambiguation and text simplification for machine translation systems.\n\n"}
{"id": "303405", "url": "https://en.wikipedia.org/wiki?curid=303405", "title": "Universal set", "text": "Universal set\n\nIn set theory, a universal set is a set which contains all objects, including itself. In set theory as usually formulated, the conception of a universal set leads to a paradox (Russell's paradox) and is consequently not allowed. However, some non-standard variants of set theory include a universal set.\n\nThere is no standard notation for the universal set of a given set theory. Common symbols include V, U and ξ.\n\nZermelo–Fraenkel set theory and related set theories, which are based on the idea of the cumulative hierarchy, do not allow for the existence of a universal set. It is directly contradicted by the axiom of regularity, and its existence would cause paradoxes which would make the theory inconsistent.\n\nRussell's paradox prevents the existence of a universal set in Zermelo–Fraenkel set theory and other set theories that include Zermelo's axiom of comprehension.\nThis axiom states that, for any formula formula_1 and any set , there exists another set \nthat contains exactly those elements of that satisfy formula_3. If a universal set  existed and the axiom of comprehension could be applied to it, then\nthere would also exist another set formula_4, the set of all sets that do not contain themselves. However, as Bertrand Russell observed, this set is paradoxical. If it contains itself, then it should not contain itself, and vice versa. For this reason, it cannot exist.\n\nA second difficulty with the idea of a universal set concerns the power set of the set of all sets. Because this power set is a set of sets, it would necessarily be a subset of the set of all sets, provided that both exist. However, this conflicts with Cantor's theorem that the power set of any set (whether infinite or not) always has strictly higher cardinality than the set itself.\n\nThe difficulties associated with a universal set can be avoided either by using a variant of set theory in which the axiom of comprehension is restricted in some way, or by using a universal object that is not considered to be a set.\n\nThere are set theories known to be consistent (if the usual set theory is consistent) in which the universal set does exist (and formula_5 is true). In these theories, Zermelo's axiom of comprehension does not hold in general, and the axiom of comprehension of naive set theory is restricted in a different way. A set theory containing a universal set is necessarily a non-well-founded set theory.\nThe most widely studied set theory with a universal set is Willard Van Orman Quine's New Foundations. Alonzo Church and also published work on such set theories. Church speculated that his theory might be extended in a manner consistent with Quine's,\n\nAnother example is positive set theory, where the axiom of comprehension is restricted to hold only for the positive formulas (formulas that do not contain negations). Such set theories are motivated by notions of closure in topology.\n\nThe idea of a universal set seems intuitively desirable in the Zermelo–Fraenkel set theory, particularly because most versions of this theory do allow the use of quantifiers over all sets (see universal quantifier). One way of allowing an object that behaves similarly to a universal set, without creating paradoxes, is to describe and similar large collections as proper classes rather than as sets. One difference between a universal set and a universal class is that the universal class does not contain itself, because proper classes cannot be elements of other classes. Russell's paradox does not apply in these theories because the axiom of comprehension operates on sets, not on classes.\n\nThe category of sets can also be considered to be a universal object that is, again, not itself a set. It has all sets as elements, and also includes arrows for all functions from one set to another. \nAgain, it does not contain itself, because it is not itself a set.\n\n\n"}
{"id": "411562", "url": "https://en.wikipedia.org/wiki?curid=411562", "title": "Xmas", "text": "Xmas\n\nXmas is a common abbreviation of the word \"Christmas\". It is sometimes pronounced , but \"Xmas\", and variants such as \"Xtemass\", originated as handwriting abbreviations for the typical pronunciation . The \"X\" comes from the Greek letter \"Chi\", which is the first letter of the Greek word \"Χριστός\", which in English is \"Christ\".\nThe \"-mas\" part is from the Latin-derived Old English word for \"Mass\".\n\nThere is a common misconception that the word \"Xmas\" stems from a secular attempt to remove the religious tradition from Christmas by taking the \"Christ\" out of \"Christmas\", but its use dates back to the 16th century.\n\n\"Xmas\" is deprecated by some modern style guides, including those at the \"New York Times\", \"The Times\", \"The Guardian\", and the BBC. Millicent Fenwick, in the 1948 \"Vogue's Book of Etiquette\", states that \"'Xmas' should never be used\" in greeting cards. \"The Cambridge Guide to Australian English Usage\" states that the spelling should be considered informal and restricted to contexts where concision is valued, such as headlines and greeting cards. \"The Christian Writer's Manual of Style\", while acknowledging the ancient and respectful use of \"Xmas\" in the past, states that the spelling should never be used in formal writing.\n\nEarly use of \"Xmas\" includes Bernard Ward's \"History of St. Edmund's college, Old Hall\" (originally published circa 1755). An earlier version, \"X'temmas\", dates to 1551. Around 1100 the term was written as \"Xp̄es mæsse\" in the \"Anglo-Saxon Chronicle\". \"Xmas\" is found in a letter from George Woodward in 1753. Lord Byron used the term in 1811, as did Samuel Coleridge (1801) and Lewis Carroll (1864). In the United States, the fifth American edition of William Perry's \"Royal Standard English Dictionary\", published in Boston in 1800, included in its list of \"Explanations of Common Abbreviations, or Contraction of Words\" the entry: \"Xmas. Christmas.\" Oliver Wendell Holmes, Jr. used the term in a letter dated 1923. Since at least the late 19th century, \"Xmas\" has been in use in various other English-language nations. Quotations with the word can be found in texts first written in Canada, and the word has been used in Australia, and in the Caribbean. \"Merriam-Webster's Dictionary of English Usage\" stated that modern use of the term is largely limited to advertisements, headlines and banners, where its conciseness is valued. The association with commerce \"has done nothing for its reputation\", according to the dictionary.\n\nIn the United Kingdom, the former Church of England Bishop of Blackburn, Alan Chesters, recommended to his clergy that they avoid the spelling.\nIn the United States, in 1977 New Hampshire Governor Meldrim Thomson sent out a press release saying that he wanted journalists to keep the \"Christ\" in Christmas, and not call it Xmas—which he called a \"pagan\" spelling of Christmas.\n\nThe abbreviation of Christmas as \"Xmas\" is the source of disagreement among Christians who observe the holiday. \n\nThe December 1957 \"News and Views\" published by the Church League of America, a conservative organization co-founded in 1937 by George Washington Robnett, attacked the use of Xmas in an article titled \"X=The Unknown Quantity\". The claims were picked up later by Gerald L. K. Smith, who in December 1966 claimed that Xmas was a \"blasphemous omission of the name of Christ\" and that \"'X' is referred to as being symbolical of the unknown quantity.\" Smith further argued that Jews introduced Santa Claus to suppress the New Testament accounts of Jesus, and that the United Nations, at the behest of \"world Jewry\", had \"outlawed the name of Christ\". There is, however, a well documented history of use of \"Χ\" (actually a chi) as an abbreviation for \"Christ\" (Χριστός) and possibly also a symbol of the cross. The abbreviation appears on many Orthodox Christian religious icons.\n\nDennis Bratcher, writing for a website for Christians, states \"there are always those who loudly decry the use of the abbreviation 'Xmas' as some kind of blasphemy against Christ and Christianity\". Among them are evangelist Franklin Graham and CNN journalist Roland S. Martin. Graham stated in an interview: \"for us as Christians, this is one of the most holy of the holidays, the birth of our savior Jesus Christ. And for people to take Christ out of Christmas. They're happy to say merry Xmas. Let's just take Jesus out. And really, I think, a war against the name of Jesus Christ.\" Roland Martin likewise relates the use of \"Xmas\" to his growing concerns of increasing commercialization and secularization of one of Christianity's highest holy days. Bratcher posits that those who dislike abbreviating the word are unfamiliar with a long history of Christians using X in place of \"Christ\" for various purposes.\n\nThe word \"Christ\" and its compounds, including \"Christmas\", have been abbreviated in English for at least the past 1,000 years, long before the modern \"Xmas\" was commonly used. \"Christ\" was often written as \"Xρ\" or \"Xt\"; there are references in the \"Anglo-Saxon Chronicle\" as far back as 1021. This X and P arose as the uppercase forms of the Greek letters χ (Ch) and ρ (R) used in ancient abbreviations for Χριστος (Greek for \"Christ\"). The labarum, an amalgamation of the two Greek letters rendered as ☧, is a symbol often used to represent Christ in Catholic, Protestant, and Orthodox Christian Churches.\n\nThe \"Oxford English Dictionary\" (\"OED\") and the \"OED Supplement\" have cited usages of \"X-\" or \"Xp-\" for \"Christ-\" as early as 1485. The terms \"Xtian\" and less commonly \"Xpian\" have also been used for \"Christian\". The \"OED\" further cites usage of \"Xtianity\" for \"Christianity\" from 1634. According to \"Merriam-Webster's Dictionary of English Usage\", most of the evidence for these words comes from \"educated Englishmen who knew their Greek\".\n\nIn ancient Christian art, χ and χρ are abbreviations for Christ's name. In many manuscripts of the \"New Testament\" and icons, Χ is an abbreviation for Χριστος, as is XC (the first and last letters in Greek, using the lunate sigma); compare IC for Jesus in Greek.\n\nOther proper names containing the name \"Christ\" besides those mentioned above are sometimes abbreviated similarly, either as \"X\" or \"Xt\", both of which have been used historically, e.g., \"Xtopher\" or \"Xopher\" for \"Christopher\", or \"Xtina\" or \"Xina\" for the name \"Christina\".\n\nIn the 17th and 18th centuries, \"Xene\" and \"Exene\" were common spellings for the given name Christine. The American singer Christina Aguilera has sometimes gone by the name \"Xtina\". Similarly, Exene Cervenka has been a noted American singer-songwriter since 1977.\n\nThis usage of \"X\" to spell the syllable \"kris\" (rather than the sounds \"ks\") has extended to \"xtal\" for \"crystal\", and on florists' signs to \"xant\" for \"chrysanthemum\", even though these words are not etymologically related to \"Christ\": \"crystal\" comes from a Greek word meaning \"ice\" (and not even using the letter χ), and \"chrysanthemum\" comes from Greek words meaning \"golden flower\", while \"Christ\" comes from a Greek word meaning \"anointed\".\n\nIn the animated television series \"Futurama\", which is set in the 31st century, Xmas is the official name for the day formerly known as Christmas (which, in the episode \"Xmas Story\", is said to have become an \"archaic pronunciation\").\n\nIn the American version of the board game \"Monopoly\", players can draw a card from the Community Chest which reads: \"Xmas fund matures. Collect $100\".\n\n\n"}
