{"id": "44018253", "url": "https://en.wikipedia.org/wiki?curid=44018253", "title": "BWF World Junior Ranking", "text": "BWF World Junior Ranking\n\nThe BWF World Junior Ranking is the official ranking of the Badminton World Federation, introduced since January 2011. Players must be under 19 years of age to be eligible in the World Junior Rankings. Players will be removed from the World Junior Ranking once they have reached 19 years of age on 1 January. In doubles, players will be ranked as individuals and not as pairs.\n\nBadminton Asia Confederation may select up to two tournaments to upgrade to European Junior Championships level and up to three tournaments to the upgraded Asian and European Tournaments level as stated in World Junior ranking table below. Badminton Europe can select up to three tournaments to upgrade to the upgraded Asian and European International Tournaments level. Points are awarded according to the following table:\n\nThe following is a list of players who have achieved the number one position since 29 December 2011 (current number one players are marked in bold):\n\n\"Last update: 29 November 2018\"\n"}
{"id": "6230543", "url": "https://en.wikipedia.org/wiki?curid=6230543", "title": "British DX Club", "text": "British DX Club\n\nThe British DX Club (abbreviated form \"BDXC\") is an association of radio hobbyists, based in the United Kingdom. It caters mainly for, though not exclusively, DXers and Short Wave listeners. It was founded in 1974 and was originally known as the \"Twickenham DX Club\" (after the Middlesex, UK, town where it was originally based), but re-launched in 1979 as the British DX Club. The name change was made to reflect its growing national and international membership which currently stands at around 500. To distinguish it from similar organisations in other countries, the club's abbreviated name for international use is BDXC-UK.\n\nBDXC publishes a monthly magazine \"Communication\", which is registered with the British Library (ISSN 0958-2142). The main contents of a typical magazine consist of a mixture of DX \"loggings\", details of radio station frequencies and programmes, letters and articles of general interest on broadcasting topics. These topics include:\n\nUK News, Webwatch, DX News, Propagation, DRM News, Mediumwave Report, Collectors Corner (vintage Radio's etc.), The Audio Circle, Beyond The Horizon, Mediumwave Logbook, Tropical Logbook, HF Logbook, Alternative Airwaves (Pirate Radio), and members contributions.\n\nIn 1976, the club launched a monthly audio magazine on cassette tape, BDXC Audio Circle (formerly known as BDXC Tape Circle). This is now also distributed on Compact Disc and as an MP3 downloadable file for subscribing members only.\n\nThe BDXC also has an email news group for club members to distribute news and DX 'catches' to subscribed members. The Audio Circle also has its own email group.\n\nBDXC and its members are important contributors to each edition of the World Radio Television Handbook (WRTH) an annual publication listing broadcasting times and frequencies of most of the world's national and international broadcasters. Information on other UK DX clubs is also included in WRTH.\n\n"}
{"id": "31950461", "url": "https://en.wikipedia.org/wiki?curid=31950461", "title": "Centre for Health and International Relations", "text": "Centre for Health and International Relations\n\nThe Centre for Health and International Relations (CHAIR) was founded (2003) in the belief that there are compelling reasons for linking international relations, foreign policy, security and health. CHAIR is based in the Department of International Politics, Aberystwyth University, Aberystwyth, Wales. The founder and director is Professor Colin McInnes.\n\nIn addition to research into the global politics of health broadly defined, CHAIR is also involved in research in the following areas:\n\n\nAssociated staff working on the ongoing 'The Transformation of Global Health Governance: Competing World Views and Crises' project from the London School of Hygiene and Tropical Medicine:\n\n"}
{"id": "715200", "url": "https://en.wikipedia.org/wiki?curid=715200", "title": "Democratic globalization", "text": "Democratic globalization\n\nDemocratic globalisation is a social movement towards an institutional system of global democracy. This would, in their view, bypass nation-states, corporate oligopolies, ideological NGOs, cults and mafias. One of its most prolific proponents is the British political thinker David Held. In the last decade he published a dozen books regarding the spread of democracy from territorially defined nation states to a system of global governance that encapsulates the entire world. For some, democratic mundialisation is a variant of democratic globalisation stressing the need for the direct election of world leaders and members of global institutions by citizens worldwide; for others, it is just another name for democratic globalisation.\n\nThese proponents state that democratic globalisation's purpose is to:\n\nSupporters of the democratic globalization movement draw a distinction between their movement and the one most popularly known as the 'anti-globalization' movement, claiming that their movement avoids ideological agenda about economics and social matters. Democratic globalization supporters state that the choice of political orientations should be left to the world citizens, via their participation in world democratic institutions.\nSome proponents in the \"anti-globalization movement\" do not necessarily disagree with this position. For example, George Monbiot, normally associated with the anti-globalization movement (who prefers the term Global Justice Movement) in his work \"Age of Consent\" has proposed similar democratic reforms of most major global institutions, suggesting direct democratic elections of such bodies, and suggests a form of \"world government.\"\n\nDemocratic globalization supports the extension of political democratization to economic and financial globalization. It is based upon an idea that free international transactions benefit the global society as a whole. They believe in financially\nopen economies, where the government and central bank must be transparent in order to retain the confidence of the markets, since transparency spells doom for autocratic regimes. They promote democracy that makes leaders more accountable to the citizenry through the removal of restrictions on such transactions.\n\nThe democratic globalization movement started to get public attention when New York Times reported its demonstration to contest a World Trade Organization (WTO) in Seattle, Washington, November 1999. This gathering was to criticize unfair trade and undemocratic globalization of the WTO, World Bank, World Economic Forum (WEF), the International Monetary Fund. Its primary tactics were public rallies, street theater and civil disobedience.\n\nDemocratic globalization, proponents claim, would be reached by creating democratic global institutions and changing international organizations (which are currently intergovernmental institutions controlled by the nation-states), into global ones controlled by world citizens. The movement suggests to do it gradually by building a limited number of democratic global institutions in charge of a few crucial fields of common interest. Its long-term goal is that these institutions federate later into a full-fledged democratic world government.\n\nThus, it supports the International Campaign for the Establishment of a United Nations Parliamentary Assembly, that would allow for participation of member nations' legislators and, eventually, direct election of United Nations (UN) parliament members by citizens worldwide.\n\nSome supporters of the democratic globalization movement draw a distinction between their movement and the one most popularly known as the 'anti-globalization' movement, claiming that their movement avoids ideological agenda about economics and social matters although, in practice, it is often difficult to distinguish between the two camps. Democratic globalization supporters state that the choice of political orientations should be left to the world citizens, via their participation in world democratic institutions and direct vote for world presidents (see presidentialism).\n\nSome supporters of the \"anti-globalization movement\" do not necessarily disagree with this position. For example, George Monbiot, normally associated with the anti-globalization movement (who prefers the term Global Justice Movement) in his work \"Age of Consent\" has proposed similar democratic reforms of most major global institutions, suggesting direct democratic elections of such bodies by citizens, and suggests a form of \"federal world government\".\n\nDemocratic globalization, proponents claim, would be reached by creating democratic global institutions and changing international organizations (which are currently intergovernmental institutions controlled by the nation-states), into global ones controlled by voting by the citizens. The movement suggests to do it gradually by building a limited number of democratic global institutions in charge of a few crucial fields of common interest. Its long-term goal is that these institutions federate later into a full-fledged democratic world government.\n\nThey propose the creation of world services for citizens, like world civil protection and prevention (from natural hazards) services.\n\nThe concept of democratic globalization has supporters from all fields. Many of the campaigns and initiatives for global democracy, such as the UNPA campaign, list quotes by and names of their supporters on their websites.\n\nSome of the most prolific proponents are the British political thinker David Held and the Italian political theorist Daniele Archibugi. In the last decade they published several books regarding the spread of democracy from territorially defined nation states to a system of global governance that encapsulates the entire planet. Richard Falk has developed the idea from an international law perspective, Ulrich Beck from a sociological approach and Jürgen Habermas has elaborate the normative principles.\n\n\nJim Stark has initiated a process for a Democratic World Parliament through a Global Referendum. As of August 20, 2013, 22,126 people have voted. So far, the votes are 95.3% in favor of creating a democratic world parliament. Portable voting booths are available at http://voteworldparliament.org/shadowbox/getballot.html. Online voting at Mr. Stark's website is at voteworldparliament.org. Mr. Stark has published a companion book to the online referendum entitled \"Rescue Plan for Planet Earth\".\n\n\n\n"}
{"id": "30250507", "url": "https://en.wikipedia.org/wiki?curid=30250507", "title": "Discrete logarithm records", "text": "Discrete logarithm records\n\nDiscrete logarithm records are the best results achieved to date in solving the discrete logarithm problem, which is the problem of finding solutions \"x\" to the equation \"g\" = \"h\" given elements \"g\" and \"h\" of a finite cyclic group \"G\". The difficulty of this problem is the basis for the security of several cryptographic systems, including Diffie–Hellman key agreement, ElGamal encryption, the ElGamal signature scheme, the Digital Signature Algorithm, and the elliptic curve cryptography analogs of these. Common choices for \"G\" used in these algorithms include the multiplicative group of integers modulo \"p\", the multiplicative group of a finite field, and the group of points on an elliptic curve over a finite field.\n\nOn 16 June 2016, Thorsten Kleinjung, Claus Diem, Arjen K. Lenstra, Christine Priplata, and Colin Stahlke announced the computation of a discrete logarithm modulo a 232-digit (768-bit) safe prime, using the number field sieve. The computation was started in February 2015 and took approximately 6600 core years scaled to an Intel Xeon E5-2660 at 2.2 GHz.\n\nPrevious records for integers modulo \"p\" include:\n\n\nThe current record () in a finite field of characteristic 2 was announced by Robert Granger, Thorsten Kleinjung, and Jens Zumbrägel on 31 January 2014. This team was able to compute discrete logarithms in GF(2) using about 400,000 core hours. New features of this computation include a modified method for obtaining the logarithms of degree two elements and a systematically optimized descent strategy.\n\nPrevious records in a finite field of characteristic 2 were announced by:\n\n\nThe current record () in a finite field of characteristic 2 of prime degree was announced by Thorsten Kleinjung on 17 October 2014. The calculation was done in a field of 2 elements and followed essentially the path sketched for formula_1 in with two main exceptions in the linear algebra computation and the descent phase. The total running time was less than four core years. The previous record in a finite field of characteristic 2 of prime degree was announced by the CARAMEL group on April 6, 2013. They used the function field sieve to compute a discrete logarithm in a field of 2 elements.\n\nThe current record () for a field of characteristic 3 was announced by \nGora Adj, Isaac Canales-Martinez, Nareli Cruz-Cortés, Alfred Menezes, Thomaz Oliveira, Francisco Rodriguez-Henriquez, and Luis Rivera-Zamarripa on . The calculation was done in the 4841-bit finite field with 3 elements and was performed on several computers at CINVESTAV and\nthe University of Waterloo. In total, about 200 core years of computing time was expended on the computation.\nPrevious records in a finite field of characteristic 3 were announced:\n\n\nOver fields of \"moderate\"-sized characteristic, notable computations as of 2005 included those a field of 65537 elements (401 bits) announced on 24 Oct 2005, and in a field of 370801 elements (556 bits) announced on 9 Nov 2005. The current record (as of 2013) for a finite field of \"moderate\" characteristic was announced on 6 January 2013. The team used a new variation of the function field sieve for the medium prime case to compute a discrete logarithm in a field of 33341353 elements (a 1425-bit finite field). The same technique had been used a few weeks earlier to compute a discrete logarithm in a field of 33553771 elements (an 1175-bit finite field).\n\nOn 25 June 2014, Razvan Barbulescu, Pierrick Gaudry, Aurore Guillevic, and François Morain announced a new computation of a discrete logarithm in a finite field whose order has 160 digits and is a degree 2 extension of a prime field. The algorithm used was the number field sieve (NFS), with various modifications. The total computing time was equivalent to 68 days on one core of CPU (sieving) and 30 hours on a GPU (linear algebra).\n\nCerticom Corp. has issued a series of Elliptic Curve Cryptography challenges. Level I involves fields of 109-bit and 131-bit sizes. Level II includes 163, 191, 239, 359-bit sizes. All Level II challenges are currently believed to be computationally infeasible.\n\nThe Level I challenges which have been met are:\n\n\nNone of the 131-bit (or larger) challenges have been met .\n\nIn July 2009, Joppe W. Bos, Marcelo E. Kaihara, Thorsten Kleinjung, Arjen K. Lenstra and Peter L. Montgomery announced that they had carried out a discrete logarithm computation on an elliptic curve modulo a 112-bit prime. The computation was done on a cluster of over 200 PlayStation 3 game consoles over about 6 months. They used the common parallelized version of Pollard rho method.\n\nIn April 2014, Erich Wenger and Paul Wolfger from Graz University of Technology solved the discrete logarithm of a 113-bit Koblitz curve in extrapolated 24 days using an 18-core Virtex-6 FPGA cluster. In January 2015,the same researchers solved the discrete logarithm of an elliptic curve defined over a 113-bit binary field. The average runtime is around 82 days using a 10-core Kintex-7 FPGA cluster.\n\nOn 2 December 2016, Daniel J. Bernstein, Susanne Engels, Tanja Lange, Ruben Niederhagen, Christof Paar, Peter Schwabe, and Ralf Zimmermann announced the solution of a generic 117.35-bit elliptic curve discrete logarithm problem on a binary curve, using an optimized FPGA implementation of a parallel version of Pollard's rho algorithm. The attack ran for about six months on 64 to 576 FPGAs in parallel.\n\nOn 23 August 2017, Takuya Kusaka, Sho Joichi, Ken Ikuta, Md. Al-Amin Khandaker, Yasuyuki Nogami, Satoshi Uehara, Nariyoshi Yamai, and Sylvain Duquesne announced that they had solved a discrete logarithm problem on a 114-bit \"pairing-friendly\" Barreto-Naehrig (BN) curve, using the special sextic twist property of the BN curve to efficiently carry out the random walk of Pollard’s rho method. The implementation used 2000 CPU cores and took about 6 months to solve the problem.\n\n"}
{"id": "4088601", "url": "https://en.wikipedia.org/wiki?curid=4088601", "title": "Environmental migrant", "text": "Environmental migrant\n\nEnvironmental migrants are people who are forced to leave their home region due to sudden or long-term changes to their local environment. These are changes which compromise their well-being or secure livelihood. Such changes are held to include increased droughts, desertification, sea level rise, and disruption of seasonal weather patterns (i.e. monsoons). Climate refugees may choose to flee to or migrate to another country, or they may migrate internally within their own country.\n\nThe term \"environmental migrant\" is used somewhat interchangeably with a range of similar terms, such as ecological refugee, environmental refugee, climate refugee, forced environmental migrant, environmentally motivated migrant, climate change refugee, environmentally displaced person (EDP), disaster refugee, environmental displacee, eco-refugee, ecologically displaced person, or environmental-refugee-to-be (ERTB). The term climate exiles has been used to refer to those climate migrants who may be in danger of becoming stateless. The distinctions between these terms are contested.\n\nDespite problems in formulating a uniform and clear-cut definition of 'environmental migration', such a concept has increased as an issue of concern in the 2000s as policy-makers, environmental and social scientists attempt to conceptualize the potential societal effects of climate change and general environmental degradation. \"Unless it is assumed\" in order to consider a person a climate refugee, nature or the environment could be considered the persecutor.\n\nClimate refugees do not really fit into any of the legal definitions of a refugee. Not all climate refugees migrate from their home country, on occasion they are just displaced within their country of origin. Moreover, the refugees aren't leaving their homes because of fear they will be persecuted, or because of \"generalized violence or events seriously disturbing public order.\" Even though the definition of who is a refugee was expanded since its first international and legally binding definition in 1951 people who are forced to flee due to environmental change are still not offered the same legal protection as refugees.\n\nThe term \"environmental refugee\" was first proposed by Lester Brown in 1976. The International Organization for Migration (IOM) proposes the following definition for environmental migrants:\n\"Environmental migrants are persons or groups of persons who, for compelling reasons of sudden or progressive changes in the environment that adversely affect their lives or living conditions, are obliged to leave their habitual homes, or choose to do so, either temporarily or permanently, and who move either within their country or abroad.\"\n\nClimate refugees or climate migrants are a subset of environmental migrants who were forced to flee \"due to sudden or gradual alterations in the natural environment related to at least one of three impacts of climate change: sea-level rise, extreme weather events, and drought and water scarcity.\"\n\nThe International Organisation for Migration proposes three types of environmental migrants:\n\n“those displaced temporarily due to local disruption such as an avalanche or earthquake; those who migrate because environmental degradation has undermined their livelihood or poses unacceptable risks to health; and those who resettle because land degradation has resulted in desertification or because of other permanent and untenable changes in their habitat.”\n\nOther categorisations include:\n\n\n\n\nThere have been a number of attempts over the decades to enumerate environmental migrants and refugees. Jodi Jacobson (1988) is cited as the first researcher to enumerate the issue, stating that there were already up to 10 million ‘Environmental Refugees’. Drawing on ‘worst-case scenarios’ about sea-level rise, she argued that all forms of ‘Environmental Refugees’ would be six times as numerous as political refugees. By 1989, Mustafa Tolba, Executive Director of UNEP, was claiming that 'as many as 50 million people could become environmental refugees' if the world did not act to support sustainable development. In 1990, the Intergovernmental Panel on Climate Change (IPCC 1990: 20) declared that the greatest single consequence of climate change could be migration, ‘with millions of people displaced by shoreline erosion, coastal flooding and severe drought’. In the mid-1990s, British environmentalist, Norman Myers, became the most prominent proponent of this ‘maximalist’ school (Suhrke 1993). Noting, that \"environmental refugees will soon become the largest group of involuntary refugees\". Additionally, he stated that there were 25 million environmental refugees in the mid-1990s, further claiming that this figure could double by 2010, with an upper limit of 200 million by 2050 (Myers 1997). Myers argued that the causes of environmental displacement would include desertification, lack of water, salination of irrigated lands and the depletion of biodiversity. He also hypothesised that displacement would amount to 30m in China, 30m in India, 15m in Bangladesh, 14m in Egypt, 10m in other delta areas and coastal zones, 1m in island states, and with otherwise agriculturally displaced people totalling 50m by 2050. More recently, Myers has suggested that the figure by 2050 might be as high as 250 million.\nThese claims have gained significant currency, with the most common projection being that the world will have 150–200 million climate change refugees by 2050. Variations of this claim have been made in influential reports on climate change by the IPCC (Brown 2008: 11) and the Stern Review on the Economics of Climate Change (Stern et al. 2006: 3), as well as by NGOs such as Friends of the Earth, Greenpeace Germany (Jakobeit and Methmann 2007) and Christian Aid; and inter-governmental organisations such as the Council of Europe, UNESCO, IOM (Brown 2008) and UNHCR.\n\nNorman Myers is the most cited researcher in this field, who found that 25 million environmental migrants existed in 1995 in his work (Myers & Kent 1995), which drew upon over 1000 sources. However, Vikram Kolmannskog has stated that Myers’ work can be ‘criticized for being inconsistent, impossible to check and failing to take proper account of opportunities to adapt’ (2008: 9). Furthermore, Myers himself has acknowledged that his figures are based upon ‘heroic extrapolation’ (Brown 2008: 12). More generally, Black has argued that there is ‘surprisingly little scientific evidence’ that indicates that the world is ‘filling-up with environmental refugees’ (1998: 23). Indeed, Francois Gemenne has stated that: 'When it comes to predictions, figures are usually based on the number of people living in regions at risk, and not on the number of people actually expected to migrate. Estimates do not account for adaptation strategies [or] different levels of vulnerability' (Gemenne 2009: 159).\n\nAccording to the Internal Displacement Monitoring Centre, more than 42 million people were displaced in Asia and the Pacific during 2010 and 2011, more than twice the population of Sri Lanka. This figure includes those displaced by storms, floods, and heat and cold waves. Still others were displaced by drought and sea-level rise. Most of those compelled to leave their homes eventually returned when conditions improved, but an undetermined number became migrants, usually within their country, but also across national borders.\n\nClimate-induced migration is a highly complex issue which needs to be understood as part of global migration dynamics. Migration typically has multiple causes, and environmental factors are intertwined with other social and economic factors, which themselves can be influenced by environmental changes. Environmental migration should not be treated solely as a discrete category, set apart from other migration flows. A 2012 Asian Development Bank study argues that climate-induced migration should be addressed as part of a country's development agenda, given the major implications of migration on economic and social development. The report recommends interventions both to address the situation of those who have migrated, as well as those who remain in areas subject to environmental risk. It says: \"To reduce migration compelled by worsening environmental conditions, and to strengthen the resilience of at-risk communities, governments should adopt policies and commit financing to social protection, livelihoods development, basic urban infrastructure development, and disaster risk management.\"\n\nAdditionally, it is maintained that the poor populate areas that are most at risk for environmental destruction and climate change, including coastlines, flood-lines, and steep slopes. As a result, climate change threatens areas already suffering from extreme poverty. \"The issue of equity is crucial. Climate affects us all, but does not affect us all equally,\" UN Secretary-General Ban Ki-moon told delegates at a climate conference in Indonesia. Africa is also one of the world regions where environmental displacement is critical largely due to droughts and other climate-related eventualities.\n\nIn Minqin county, Gansu Province, \"10,000 people have left the area and have become \"shengtai yimin\", 'ecological migrants'\".\n\nIn 2013 a claim of a Kiribati man of being a \"climate change refugee\" under the Convention relating to the Status of Refugees (1951) was determined by the New Zealand High Court to be untenable.\nThe Refugee Convention did not apply as there is no persecution or serious harm related to any of the five stipulated convention grounds. The Court rejected the argument that the international community itself (or countries which can be said to have been historically high emitters of carbon dioxide or other greenhouse gases) were the “persecutor” for the purposes of the Refugee Convention.\nThis analysis of the need for the person to identify persecution of the type described in the Refugee Convention does not exclude the possibility that a people for countries experiencing severe impacts of climate change can come with the Refugee Convention. However, it is not the climate change event itself, rather the social and political response to climate change, which is likely to create the pathway for a successful claim. The New Zealand Immigration and Protection Tribunal and the High Court, “there is a complex inter-relationship between natural disasters, environmental degradation and human vulnerability. Sometimes a tenable pathway to international protection under the Refugee Convention can result. Environmental issues sometimes lead to armed conflict. There may be ensuing violence towards or direct repression of an entire section of a population. Humanitarian relief can become politicised, particularly in situations where some group inside a disadvantaged country is the target of direct discrimination.” The New Zealand Court of Appeal also rejected the claim in a 2014 decision. On further appeal, the New Zealand Supreme Court confirmed the earlier adverse rulings against the application for refugee status, with the Supreme Court also rejecting the proposition “that environmental degradation resulting from climate change or other natural disasters could never create a pathway into the Refugee Convention or protected person jurisdiction.”\n\nIn 2014 attention was drawn to an appeal to the New Zealand Immigration and Protection Tribunal against the deportation of a Tuvaluan family on the basis that they were \"climate change refugees\", who would suffer hardship resulting from the environmental degradation of Tuvalu. However the subsequent grant of residence permits to the family was made on grounds unrelated to the refugee claim. The family was successful in their appeal because, under the relevant immigration legislation, there were \"exceptional circumstances of a humanitarian nature\" that justified the grant of resident permits as the family was integrated into New Zealand society with a sizeable extended family which had effectively relocated to New Zealand.\n\nThere have been 178 Alaskan communities threatened by erosion of their land. The annual temperature has steadily increased over the last fifty years, with Alaska seeing it double (compared to the rate seen across the rest of the United States) to the rate of 3.4 degrees, with an alarming 6.3 degrees increase for the winters over the past fifty years. Many of the communities residing in these areas have been living off the land for generations. There is an eminent threat of loss of culture and loss of tribal identity with these communities.\n\nIn 2003, the Army Corps of Engineers identified four Alaskan villages which need to relocate due to the risk of flooding and erosion. More villages were added to this list between 2003 and 2016. One of the villages, Shishmaref, has 650 people who are at risk of becoming the first American community climate refugees. However, relocation is proving difficult because there is no governmental institutional framework that exists for the aid of climate refugees in the United States. The Obama administration promised to fund $50.4 billion to help with relocation efforts in 2016.\n\nIsle de Jean Charles, Louisiana, home to the Biloxi-Chitimacha-Choctaw First Nation, is being depopulated with federal grant money, due to saltwater intrusion and sea level rise. This Indigenous Nation residing on the Isle de Jean Charles is facing the effects of climate change. The resettlement of this community of around 100, exists as the first migration of a total community in the state of Louisiana. This state has lost almost 2000 square miles of its coast within the last 87 years and now an alarming rate of almost 16 square miles a year is disappearing. In early 2016, a 48-million-dollar grant was the first allocation of federal tax dollars to aid a community suffering from direct impact of climate change. Louisiana has lost land mass comparable to the size of the state of Delaware revealing land mass loss that is at a rate faster than many places in the world. The resettlement plan for the Isle de Jean Charles is at the forefront of responding to climate change without destroying the community that resides within.\n\nThe Quinault village of Taholah has requested $60 million to relocate away from the encroaching Pacific Ocean.\n\nMany peer-reviewed articles analyzing migration in South America have found multiple types of linkages between climate change and its effect on migration.The effects and results vary based on the type of climatic change, socioeconomic status and demographic characteristics of migrants and the distance and direction of the migration. Since most climate migration studies are done in the developed world, scientists have called for more quantitative research within the developing world, including South America. Migration in South America does not always increase as a result of increased environmental threats but is affected by factors such as climate variability and land suitability. These migrations happen either gradually or suddenly but are typically directed from rural to urban areas. Inter-provincial migration is shown to not be as heavily influenced by environmental changes whereas migration outside of the home country is heavily influenced by environmental changes. The results of a climactic event catalyzing migration change depending on the onset of the event, however, climate change related events such as drought and hurricanes augment or increase youth migration. Youth are more likely to migrate as a response to climate-related events. As a result, children who have been displaced are found to travel shorter distances to find work in rural destinations versus further to an urban area. Researchers suggest a review of the terms that define who is an environmental migrant since policy-making bodies and intergovernmental agencies most affect responses when an environmental event causes people to migrate. Because of the increase in interest in this topic in the past decade some people call for a measure called preventive resettlement. The cases in which preventive resettlement appear appropriate is typically discerned by local and governmental bodies. Others call for an increase in social programs to both prevent and help in a migration event.\n\nSome Kuna people, such as those in the settlement of Gardi Sugdub, have decided to relocate from islands to the mainland of Panama due to sea level rise.\n\nThe International Organization for Migration (IOM) expects the scale of global migration to rise as a result of accelerated climate change. It, therefore, recommends policymakers around the world to take a proactive stance on the matter. The IOM is composed of 146 member states and 13 observer states and \"works closely with governments in promoting migration management that ensures humane and orderly migration that is beneficial to migrants and societies.\" Additionally, When interviewing Oliver- Smith, an anthropologist and member of the UN group, National Geographic Magazine noted that \"there are at least 20 million environmental refugees worldwide, the [UN] group says – more than those displaced by war and political repression combined.\" Therefore, it is imperative that we begin to recognize this recent division of refugee.\n\nThe Environmental Justice Foundation (EJF) has argued that the people who will be forced to move due to climate change currently have no adequate recognition in international law. The EJF contends that a new multilateral legal instrument is required to specifically address the needs of \"climate refugees\" in order to confer protection to those fleeing environmental degradation and climate change. They have also asserted that additional funding is needed to enable developing countries to adapt to climate change. Sujatha Byravan and Sudhir Chella Rajan have argued for the use of the term 'climate exiles' and for international agreements to provide them political and legal rights, including citizenship in other countries, bearing in mind those countries' responsibilities and capabilities.\n\nIn some cases, climate change may lead to conflict arising between countries that as a result of flooding or other conditions produce a large number of refugees, and bordering countries that build fences to keep out these refugees. The Bangladesh–India border is largely separated via a fence, and case studies suggest the possibility of violent conflict arising due to people fleeing from areas suffering from the destruction of arable land. Current migration has already resulted in low-scale conflicts.\n\nThe Intergovernmental Panel on Climate Change (IPCC) predicts that sea levels will increase with up to 0.6 meters by 2100. This will cause populations to wipe out entirely. Small areas may have nothing left. This could lead to the loss of millions of refugees. Refugee organizations have taken on cases of many different refugees. The Organization for Refugees Asylum and Migration (ORAM) is designed to help refugees in seeking status and resettlement. They are designed to help refugees overcome the Refugee process. ORAM’s main goal is to protect the vulnerable refugees for the laws put on refugee and help end the refugee asylum process. There is a ton of legal action taken against refugees. Political laws are put on the refugees to either harm or hurt the refugees.\n\nReaction as for the possible acceptance of possible environmental migrants is mixed, this is because of countries dealing with other domestic problems. For example, India, which has a population of over 1 billion people, is building an India-Bangladesh barrier. While the stated purpose of the barrier is to deter drug trade, the barrier may also help prevent the possible refuge of 20 million Bangladeshis who may be displaced by future climate change. This is a contrast to Canada in which public pressure is slowly building to create policies that will allow accommodation and better planning. On 20 September 2016, Prime Minister Trudeau of Canada told the UN Summit for Refugees and Migrants that plans just for resettlement would not be enough. Sweden which had allowed refugees to seek asylum from areas of war in an open door policy has changed to a policy that is more deterrent of asylum seekers and is even offering money for asylum seekers to withdraw their requests. The United States, which was warned under the Obama administration to prepare for climate change and the refugees, may have more difficulties being prepared to do so under current President Donald Trump. This can be seen as Trump denies the possibility of climate change, has signed executive orders dismantling environmental protections, and has ordered the EPA to remove climate change information from their public site, likely signaling America's unwillingness to acknowledge the future possibility of increased environmental refugees from climate change.\n\nAsylum is the freedom of prosecution in the country the people want to be in. Different countries have their own rules and laws of asylum. The United States, for example, has a system recognized by federal and international laws. France was the first country to constitute the right to asylum. So the right to asylum differs in different nations. There is a still fight for the right to asylum in some areas of the world.\n\nIn the UK, research is being done on how climate change’s impact on countries that are emigrated to will vary due to the infrastructure of those countries. They want to put into place policies so that those who have to migrate could go throughout Europe, and have solid emergency planning in place so that the people being displaced would have a swift and quick plan of escape once their environment can no longer handle inhabitants-slow or sudden onset. The end goal of this work is to determine the best course of action in the event of various environmental catastrophes.\n\n The notion of 'environmental migrant', and particularly 'climate refugee', has gained traction in popular culture. A documentary entitled \"Climate Refugees\" has been released. \"Climate Refugees\" is an Official Selection for the 2010 Sundance Film Festival. More recently, Short Documentary Academy Award Nominee, Sun Come Up (2011), tells the story of Carteret islanders who are forced to leave their ancestral land in response to climate change and migrate to war-torn Bougainville \nSince 2007, German artist Hermann Josef Hack has shown his World Climate Refugee Camp in the centers of various European cities. The model camp, made of roughly 1000 miniature tents, is a public art intervention that depicts the social impacts of climate change.\n\n\n\n\n"}
{"id": "24060108", "url": "https://en.wikipedia.org/wiki?curid=24060108", "title": "Faith and Globalisation Initiative", "text": "Faith and Globalisation Initiative\n\nThe Faith and Globalisation Initiative (FGI) is an international group of universities created in 2008 by former British prime minister Tony Blair and his Faith Foundation.\nThe Faith and Globalisation Initiative is \"bringing together some of the world’s leading research Universities to form a global network focusing on the emerging field of faith and globalisation\".\n\nIn 2008 Yale University was the first university the Foundation started working with and in 10 months it expanded the network to include the National University of Singapore, Durham University and McGill University. Two years later the Foundation developed an associate university programme which seeks to foster the study of faith and globalisation in a broad range of higher education institutions.\n\nThe institutions were selected on the basis of their ability to contribute to the Initiative, but also to ensure that they have a geographic and cultural spread that lends multiple perspectives to the discipline.\n\nKey objectives of the FGI are the following:\n\nAs of January 2011, the participating members of the Faith and Globalisation Network of Universities are:\n\nLead Universities:\n\nAssociate Universities:\n\n"}
{"id": "1508112", "url": "https://en.wikipedia.org/wiki?curid=1508112", "title": "Four continents", "text": "Four continents\n\nEuropeans in the 16th century divided the world into four continents: Africa, America, Asia and Europe. Each of the four continents was seen to represent its quadrant of the world—Europe in the north, Asia in the east, Africa in the south, and America in the west. This division fit the Renaissance sensibilities of the time, which also divided the world into four seasons, four classical elements, four cardinal directions, four classical virtues, etc.\n\nThe four parts of the world or the four corners of the world refers to the Americas (the \"west\"), Europe (the \"north\"), Asia (the \"east\"), and Africa (the \"south\"). \n\nBefore the discovery of the New World a commonplace of classical and medieval geography had been the \"three parts\" in which, from Mediterranean and European perspectives, the world was divided: Europe, Asia and Africa. As Laurent de Premierfait, the pre-eminent French translator of Latin literature in the early fifteenth century, informed his readers:\nAsia is one of the three parts of the world, which the authors divide in Asia, Africa and Europe. Asia extends towards the Orient as far as the rising sun (\"devers le souleil levant\"), towards the south (\"midi\") it ends at the great sea, towards the occident it ends at our sea, and towards the north (\"septentrion\") it ends in the Maeotian marshes and the river named \"Thanaus\".\n\nFor Laurent's French readers, Asia ended at \"our sea\", the Mediterranean; Europeans were only dimly aware of the Ural Mountains, which divide Europe from Asia in the eyes of the modern geographer, and which represent the geological suture between two fragmentary continents, or cratons. Instead, the division between these continents in the European-centered picture was the Hellespont, which neatly separated Europe from Asia. From the European perspective, into the Age of Discovery, Asia began beyond the Hellespont with Asia Minor, where the Roman province of Asia had lain, and stretched away to unimaginably exotic and distant places— \"the Orient\".\n\nIn the sixteenth century America too was full of exotic promise: the \"New World\".\n\nIn 1603, Cesare Ripa published a book of emblems for the use of artists and artisans who might be called upon to depict allegorical figures. He covered an astonishingly wide variety of fields, and his work was reprinted many times. It was still being brought up-to-date in the 18th century. The illustrations reveal fixed Eurocentric perceptions of the nature of the \"four corners of the world.\" Ripa's \"Europe\" (\"illustration, left\") is the land of abundance (cornucopia) of kings and the pope, whose crowns and the papal tiara lie at her feet, and of cities.\n\n\"Africa\", by contrast (\"illustration, below right\") wears the elephant headdress (worn by rulers depicted on Hellenistic Bactrian coins) and is accompanied by a lion, the scorpion of the desert sands and Cleopatra's asps. \"Asia\" (\"illustration, right\"), the seat of Religion, carries a smoking censer as a camel takes its ease.\n\nAnd the iconic image of \"America\" (\"illustration, below left\") shows a Native American maiden in a feathered headdress, with bow and arrow. Perhaps she represents a fabled Amazon from the river that already carried the name.\n\nThe American millionaire philanthropist James Hazen Hyde, who inherited a majority share in Equitable Life Assurance Society, formed a collection of allegorical prints illustrating the Four Continents that are now at the New-York Historical Society; Hyde's drawings and a supporting collection of sets of porcelain table ornaments and other decorative arts illustrating the Four Continents were shared by various New York City museums.\nThe Renaissance associated one major river to each of the continents.\nThe Four Rivers theme appears for example in the Fontana dei Quattro Fiumi in the Piazza Navona in Rome.\n\nWith the confirmed discovery that Australia was an island continent, the theme of the \"Four Continents\" lost much of its drive, long before a sixth continent, Antarctica, was discovered. The iconography survived as the Four Corners of the World, however, generally in self-consciously classicizing contexts: for instance, in New York, in front of the Beaux-Arts Alexander Hamilton U.S. Custom House (1907), four sculptural groups by Daniel Chester French symbolize the \"Four Corners of the World.\"\n\n\n\n"}
{"id": "41895524", "url": "https://en.wikipedia.org/wiki?curid=41895524", "title": "Freedom Rising", "text": "Freedom Rising\n\nFreedom Rising: Human Empowerment and the Quest for Emancipation is a 2013 book by the German political scientist Christian Welzel, professor of political culture and political sociology at Leuphana University Lueneburg and vice-president of the World Values Survey.\n\nThe title, \"Freedom Rising\", refers to the rapid expansion of universal freedoms and democracy. As the author explains at the beginning of his book, people have never voiced their desires for freedoms so frequently and powerfully as today. They do so not only inside but even outside democracies. Starting from here, Christian Welzel’s book is about the human quest for freedoms and the human desire for emancipation. The result is a far-reaching theory of emancipation, which describes the human empowerment process.\n\nThe book comprises twelve chapters that are organized in four parts. While the first chapter is theoretical, all subsequent chapters are empirical and test the propositions laid out in Chapter 1. The empirical research builds on cross-cultural and longitudinal evidence form the World Values Surveys and European Values Surveys.\n\n(Chapter 1: A Theory of Emancipation;\nChapter 2: Mapping Differences;\nChapter 3: Multilevel Drivers;\nChapter 4: Tracing Change)\n\nThe first part provides a basic understanding of emancipative values. Welzel introduces the endogenous cause to human development in his sequence thesis of emancipation. The thesis establishes a main direction of causality from action resources (founding element) to emancipative values (linking element) to civic entitlements (completing element). It argues that emancipative values result from expanding resources which implies that they are a universal and not a Western-bound concept. The concept of cross-fertilization highlights the amplification of a person's values when they are shared by more people in the same society.\n\n(Chapter 5: Intrinsic Qualities; \nChapter 6: Benign Individualism;\nChapter 7: Collective Action)\n\nThe second part presents emancipative values as a pro-social set of values and a groundbreaking civic force that \"unlocks a population's intrinsic qualities, vitalizes civil society, and creates social capital\". Welzel illustrates that rising emancipative values cause a strategic shift from acquisition strategies to thriving strategies. As thriving strategies aim at fulfillment, pro-social behavior is encouraged. The activating and empowering impulse of emancipative values instigates people to have their shared claims heard. As such emancipative values are a crucial source of bottom-up democratization processes.\n\n(Chapter 8: Entitling People;\nChapter 9: The Rights Revolution;\nChapter 10: The Paradox of Democracy)\n\nThe third part centers on the democratic impulse that emanates from emancipative values. Welzel presents democracy as the institutional element of people's power and action resources together with emancipative values as the two pre-institutional elements of people power. Empirical evidence shows that rising emancipative values have a much higher effect on expanding rights than rights have on rising emancipative values. Welzel concludes that institutions themselves cannot create empowering qualities but depend on them so that the source of democracy lies in the people's desire for emancipation. Here, \"Freedom Rising\" disproves the prominent view in political economy which states that institutions come first. Finally, chapter 10 solves the democratic paradox that widespread desires for democracy among people coexist with deficient or even absent democracy. Welzel argues that this is the case when these desires are decoupled from an emphasis on emancipative values that is a critical-liberal orientation.\n\n(Chapter 11: The Redirection of Civilization;\nChapter 12: The Sustainability Challenge)\n\nThe last part looks at emancipative values from a broad civilizational perspective and discusses their significance in history. Welzel presents the cool-water condition (CW condition) as the truly exogenous cause of human empowerment. The last chapter elaborates on the role of emancipative values in meeting the sustainability challenge. Here, Welzel addresses the dilemma that results from the negative environmental impact of technological advancement on the one hand and the positive environmental impact of emancipative values on environmental quality on the other hand. Closer investigation shows that the negative impact of technological advancement is lower than the positive impact of emancipative values on environmental quality. Human empowerment thus helps redirecting society towards sustainable development.\n\nThe Human Empowerment Process is defined by Welzel as a \"humanistic transformation of civilization that makes societies increasingly people-powered\". It can be observed when freedoms grow so that Welzel calls it an emancipatory process. It is completed when people are acting freely as agents of their values.\nWelzel distinguishes between three different stages of the human condition in societies. The human condition can be (1) suffering – weak capabilities and narrow guarantees, (2) struggling – mediocre capabilities and guarantees, (3) thriving – strong capabilities and wide guarantees.\n\nWelzel builds his human empowerment framework on an evolutionary theory of emancipation. Emancipation is hereby understood as the universal human desire for an existence free from domination. Emancipative values emphasize freedom of choice and equality of opportunities. In Freedom Rising Welzel identifies the human desire to live free from external constraints as the single source of the human empowerment trend.\n\nThe theory of emancipation rests upon one evolutionary root principle: the utility ladder of freedom. Welzel argues that emancipative values do not guide people's actions as long as existential constraints on human life are strong. However, freedoms gain utility when people become more capable due to improving living conditions and rising action resources. In this case emancipative values start guiding people's actions. Emancipative values thus constitute the psychological core and the inspirational source of the human empowerment process. As such they motivate social movement activity and promote anti-discrimination norms. Since joint action among capable and motivated people is so difficult to resist, rulers must at some point give in and guarantee the claimed entitlements, and also abide by them. The third element in the human empowerment process is thus civic entitlements.\n\nThe Sequence thesis explains the endogenous causation of the human empowerment process. It establishes the dominant flow of impact among the three elements of the human development process from action resources to emancipative values to civic entitlements. Freedoms grow in a utility-value-guarantee sequence.\nThe sequence thesis implies an important condition, which defies the most common view that human development is caused by institutions. In contrast to other political scientists like Francis Fukuyama, Daron Acemoglu and James A. Robinson, Christian Welzel demonstrates that institutions guaranteeing universal freedoms are not the cause but the result of the human empowerment process.\n\nThe sequence thesis of emancipation theory fails to deliver an exogenous causation of human empowerment. Chapter 11 thus introduces a second thesis — the source thesis of emancipation. It posits the original source of human empowerment in the cool-water condition (CW-condition), which \"is a combination of (1) moderately cold climates, (2) continuous rainfalls over all seasons, and (3) permanently navigable waterways\". According to the source thesis, CW areas offer water autonomy and a higher disease security which naturally locates them higher on the utility ladder of freedom. Welzel demonstrates that the CW condition prevented a transition to agriculture in the first place since foraging was a freer lifestyle. Technological advancement in CW areas was thus lower than in other areas for a long time. With emerging urban markets the situation changed. Water autonomy created derivative autonomies that turned out to be an accelerator of technological advancement. Autonomy in market access encouraged a transition to quality-breeding strategies in people's reproductive behavior with the result that the workforce became less numerous but more valuable. Rising labor demands provided an incentive to invent technologies that save costly labor. The technological advancement involved more widespread action resources, which enhanced people's capabilities to exercise freedoms. From here the sequence thesis of emancipation takes over.\n\nUntil today human development is far advanced in all of the world's CW areas, that is in Western Europe, in Japan, in distinctive areas of Northern America, Australia, and New Zealand.\n\nWelzel stresses that — in the era of globalization — human empowerment begins to diffuse elsewhere and slowly dissociates from the CW condition. This erodes the monopoly of the West over human empowerment.\n\n\"Freedom Rising\" received two academic awards:\n\n"}
{"id": "38346167", "url": "https://en.wikipedia.org/wiki?curid=38346167", "title": "Gavi, the Vaccine Alliance", "text": "Gavi, the Vaccine Alliance\n\nGavi, the Vaccine Alliance (Gavi for short; previously the GAVI Alliance, and before that the Global Alliance for Vaccines and Immunization) is a public–private global health partnership committed to increasing access to immunisation in poor countries.\n\nGavi brings together developing country and donor governments, the World Health Organization, UNICEF, the World Bank, the vaccine industry in both industrialised and developing countries, research and technical agencies, civil society, the Bill & Melinda Gates Foundation and other private philanthropists.\n\nGavi was created in 2000 as a successor to the Children's Vaccine Initiative, which had been launched in 1990. \n\nDr. Seth Berkley has been the CEO of GAVI since 2011.\n\nThe Bill and Melinda Gates Foundation has donated $1.5 billion to the alliance as of January 2013.\n\nIn August 2014, Gavi changed its name from \"GAVI Alliance\" and introduced a new logo. Both changes were revealed in August; it had by then acquired the gavi.org domain name and changed its primary domain from gavialliance.org to gavi.org.\n\n"}
{"id": "22163671", "url": "https://en.wikipedia.org/wiki?curid=22163671", "title": "Genoese map", "text": "Genoese map\n\nThe Genoese map is a 1457 world map. The map relied extensively on the account of the traveler to Asia Niccolo da Conti, rather than the usual source of Marco Polo. The author is not known, but is a more modern development than the Fra Mauro world map, with fairly good proportions given to each continents. The map also depicts a three-masted European ship in the Indian Ocean, something which had not occurred yet at the time.\n\nA Genoese flag in the upper northwest corner of the map establishes this map’s origin, along with the coat of arms of the Spinolas, a prominent Genoese mercantile family. Niccolò de'Conti was from a noble mercantile family; at an early age he decided to follow in the family tradition by establishing a lucrative trading operation in the East.\n\nThe Genoese map’s sea monsters reflect the cartographer’s interest in exotic wonders, which is everywhere in evidence on the map, and typical of the scientific outlook of the early modern period, which was driven by curiosity and took a great interest in marvels. The demon-like monster in particular is evidence of the cartographer’s research in recent travel literature to find sea monsters for his map.\n\nThis map was done in rich color and was not made particularly used for anything but for display.They say this map was sent to the Portuguese court in 1474 and then to Columbus and this is the map that he used to travel the India sea to the Atlantic but was never proven. The map is now the property of the Italian government and is to be found in the Biblioteca Nazionale Centrale of Florence however the map was not taken care of due to the way it’s been handled throughout the years.\n\nThe ships that could carry a thousand men—six hundred seamen and four hundred soldiers. The larger vessels also carried small boats, which were used, as Marco Polo states, “to lay out the anchors, catch fish, bring supplies aboard, and the like. When the ship is under sail, she carries these boats slung to her side.” Many of the vessels had as many as four decks, and even the smaller ones, fifty or sixty cabins. Vegetables, we are told, were sometimes grown on board.\n\nThe oval form is not unknown among medieval maps. Hugh of Saint Victor had described the world as being the shape of Noah’s Ark, and Ranulf Higden world maps were oval. A standard way of describing the earth was to compare it to an egg. The main purpose of the analogy seems to have been to describe the various spheres surrounding the earth (egg white, shell), but the idea of an egg shape could have been derived from these works. Another possibility is that the oval form represents the \"mandorla\", or nimbus, which surrounded Christ in many medieval works of art.\n\n\n"}
{"id": "50885443", "url": "https://en.wikipedia.org/wiki?curid=50885443", "title": "Global Polio Eradication Initiative", "text": "Global Polio Eradication Initiative\n\nThe Global Polio Eradication Initiative is an initiative created in 1988, just after the World Health Assembly resolved to eradicate the disease poliomyelitis by the year 2000. It was described by the World Health Organization as the largest public health initiative in history.\n\nThe strategy for the eradication of polio rests on immunizing every at risk child until there is no one left for the disease to transmit to and the disease eventually dies out. The Initiative is spearheaded by the following Organizations:\n\n\nKey tactics used by the GPEI include strengthening childhood immunization through oral vaccines, conducting surveillance \nthrough investigation of acute flaccid paralysis cases among children under 15 years old (in order to determine areas where the virus is truly eradicated), and conducting \"mop up\" campaigns in areas where cases of polio have been identified.\n\nBy 2012 the GPEI had raised 9 billion dollars in funding and in alone 2011 the GPEI received a 1.1 billion dollars, for a budget of 0.98 billion dollars. 30% of their funding came from the Gates Foundation 30% from developed governments, 27% from countries at risk of polio, and the rest was made up of donations from non profits, private funders, and other foundations. It is likely that the GPEI will become almost entirely funded by private organizations in the future.\n\nIn 1995 a Global Certification Commission was created to oversee the certification of the eradication of wild-type poliovirus transmissions. Certification for the six WHO regions requires all of the countries in that region to be certified by the commission. By the year 2000 both the regions of the Western Pacific and the Americas met the criteria to be certified free of polio transmissions. By 2012 the initial number of estimated cases in 1988 of 350,000 across 125 endemic countries has dropped to 650 confirmed cases. In addition the 3 of the six WHO regions are now certified polio eradicated (Europe, the Americas, The West Pacific). India, which many thought would face the greatest challenge to eradication was removed from the list of endemic countries. According to the most recent study by the GPEI, in 2016, there are only three countries still listed as endemic, Nigeria, Afghanistan and Pakistan.\n\nIt is owing to this dramatic reduction that the funding for the GPEI will likely soon come entirely from private donors and foundations such as the Gates Foundation instead of from individual countries. In fact Bill Gates has listed polio eradication as one of his \"Top Personal Priorities\".\n\nA 2011 study by Middlebury College (commissioned by the Gates Foundation) indicated a list recommendations for how the GPEI should operate moving forward:\n\n\nThe final steps of polio eradication for the GPEI, or what is known as the \"endgame\" are as follows:\n\n"}
{"id": "36579494", "url": "https://en.wikipedia.org/wiki?curid=36579494", "title": "Global apartheid", "text": "Global apartheid\n\nGlobal apartheid is a term used to mean minority rule in international decision-making. The term comes from apartheid, the system of governmental that ruled South Africa until 27 April 1994 when people of all races were able to vote as equals for the first time.\n\nThe concept of global apartheid has been developed by many researchers, including Titus Alexander, Bruno Amoroso, Patrick Bond, Gernot Kohler, Arjun Makhijiani, Ali Mazuri, Vandana Shiva, Anthony H. Richmond, Joseph Nevins, Muhammed Asadi, Gustav Fridolin, and many others.\n\nThe first use of the term may have been by Gernot Koehler in a 1978 Working Paper for the World Order Models Project. In 1995 Koehler develop this in \"The Three Meanings of Global Apartheid: Empirical, Normative, Existential\".\n\nIts best known use was by Thabo Mbeki, then-President of South Africa, in a 2002 speech, drawing comparisons of the status of the world's people, economy, and access to natural resources to the apartheid era. Mbeki got the term from Titus Alexander, initiator of Charter 99, a campaign for global democracy, who was also present at the UN Millennium Summit and gave him a copy of \"Unravelling Global Apartheid\".\n\nMinority rule in global governance is based on national sovereignty rather than racial identity, but in many other respects the history and structures of apartheid South Africa can be seen as a microcosm of the world. Following the Great Depression in the 1930s and the Second World War, the United States and United Kingdom used their political power to create systems of economic management and protection to mitigate the worst effects of free trade and neutralise the competing appeals of communism and national socialism. In South Africa \"civilized labour\" policies restricted public employment to whites, reserved skilled jobs for whites and controlled the movement of non-whites through a system of pass laws. In the West, escalating tariff barriers reserved manufacturing work for Europeans and Americans while immigration laws controlled the movement of immigrants seeking work.\n\nAt a political level, the West still dominates global decision-making through minority control of the central banking system (Bank of International Settlements), IMF, World Bank, Security Council and other institutions of global governance. The G8 represent less than 15% of world population, yet have over 60% of its income. 80% of the permanent members of the UN Security Council represent white Western states, 60% from Europe. The West has veto power in the World Bank, IMF and WTO and regulates global monetary policy through the Bank of International Settlements (BIS). By tradition, the head of the World Bank is always a US citizen, nominated by the US President, and the IMF is a European. Although the rest of the world now has a majority in many international institutions, it does not have the political power to reject decisions by the Western minority.\n\nIn \"The Clash of Civilizations and the Remaking of World Order\", Samuel P. Huntington describes how \"the United States together with Britain and France make the crucial decisions on political and security issues; the United States together with Germany and Japan make the crucial decisions on economic issues.\" Huntington quoted Jeffrey R Bennett to claim that Western nations:\n\n\nHuntington presents a ‘framework, a paradigm, for viewing global politics’ to protect “Western civilization”. He argues that other civilizations threaten the West through immigration, cultural differences, growing economic strength and potential military power. ‘If North America and Europe renew their moral life, build on their cultural commonality, and develop close forms of economic and political integration to supplement their security collaboration in NATO, they could generate a third Euroamerican phase of Western affluence and political influence. Meaningful political integration would in some measure counter the relative decline in the West’s share of the world’s people, economic product, and military capabilities and revive the power of the West in the eyes of the leaders of other civilizations.’ However, this ‘depends overwhelmingly on whether the United States reaffirms its identity as a Western nation and defines its global role as the leader of Western civilization.’ [p308]\n\nAlexander identifies numerous \"pillars of global apartheid\" including:\n\nInternational decision-making has a legacy of inequality which some authors have compared to historical apartheid in South Africa.\n"}
{"id": "1777495", "url": "https://en.wikipedia.org/wiki?curid=1777495", "title": "Global change", "text": "Global change\n\nGlobal change refers to planetary-scale changes in the Earth system. The system consists of the land, oceans, atmosphere, polar regions, life, the planet's natural cycles and deep Earth processes. These constituent parts influence one another. The Earth system now includes human society, so global change also refers to large-scale changes in society.\n\nMore completely, the term \"global change\" encompasses: population, climate, the economy, resource use, energy development, transport, communication, land use and land cover, urbanization, globalization, atmospheric circulation, ocean circulation, the carbon cycle, the nitrogen cycle, the water cycle and other cycles, sea ice loss, sea-level rise, food webs, biological diversity, pollution, health, over fishing, and more.\n\nIn 1980, a group of scientists led by Swedish meteorologist Bert Bolin set up an international program called the World Climate Research Programme (WCRP), to determine whether the climate was changing, whether climate could be predicted and whether humans were in some way responsible for the change. The programme was sponsored by the World Meteorological Organization and the International Council for Science (ICSU). As time went on, there was a growing realisation that climate change was one part of a larger phenomenon, global change. In 1987, a team of researchers, led again by Bert Bolin, James McCarthy, Paul Crutzen, H. Oeschger and others, successfully argued for an international research programme to investigate global change. This programme, sponsored by ICSU, is the International Geosphere-Biosphere Programme (IGBP). The programme has eight projects investigating different parts of the Earth system and links between them.\n\nIGBP, WCRP and a third programme, the International Human Dimensions Programme (IHDP, founded in 1996), spearheaded a landmark science conference held in Amsterdam in 2001. The conference, \"Challenges of a Changing Earth: Global Change Open Science Conference\", led to the Amsterdam Declaration which stated, \"In addition to the threat of significant climate change, there is growing concern over the ever-increasing human modification of other aspects of the global environment and the consequent implications for human well-being. Basic goods and services supplied by the planetary life support system, such as food, water, clean air and an environment conducive to human health, are being affected increasingly by global change.\"\n\nThe declaration goes on to say, \"The international global change programmes urge governments, public and private institutions and people of the world to agree that an ethical framework for global stewardship and strategies for Earth System management are urgently needed.\"\n\nMany nations now have their own global change programmes and institutes, for example the US Global Change Research Program and the UK's Quantifying and Understanding the Earth System (QUEST) programme. And since the Amsterdam conference another international programme focusing on biodiversity has been set up, DIVERSITAS. These programmes form the Earth System Science Partnership.\n\nIn 2012, these international programmes held another major science conference in London, Planet Under Pressure: new knowledge towards solutions.\n\nIn the past, the main drivers of global change have been solar variation, plate tectonics, volcanism, proliferation and abatement of life, meteorite impact, resource depletion, changes in Earth's orbit around the sun and changes in the tilt of Earth on its axis. There is overwhelming evidence that now the main driver of planetary-scale change, or global change, is the growing human population's demand for energy, food, goods, services and information, and its disposal of its waste products. In the last 250 years, global change has caused climate change, widespread species extinctions, fish-stock collapse, desertification, ocean acidification, ozone depletion, pollution, and other large-scale shifts.\n\nScientists working on the International Geosphere-Biosphere Programme have said that Earth is now operating in a \"no analogue\" state. Measurements of Earth system processes, past and present, have led to the conclusion that the planet has moved well outside the range of natural variability in the last half million years at least. \"Homo sapiens\" have been around for about 200,000 years.\n\nWhat this means for the planet and society remains unclear. But, in the last 20 years there has been an enormous international research effort to understand global change and the Earth system. An aim of this research is to work out if there are planetary boundaries and are we approaching them. Scientists, international governmental organizations and lobbying organizations like World Wide Fund for Nature argue that current consumption levels, particularly in developed countries, are not sustainable because there is a very real danger they will push the planet into a new state. What this new state might look like is still being debated, but sea levels are likely to rise several meters, the pH of the oceans, a measure of its acidity, is likely to drop farther than it has in 20 million years, and global atmospheric and ocean circulations may shift markedly. The major cycles – carbon, nitrogen, sulfur, phosphorus, water – and other important parameters would alter, bringing drought to some places, floods to others. Governments will no longer be able to take for granted the relative environmental stability that has allowed human society to flourish and led to rapid globalization. Most of the population of the planet will be affected. The re-insurance industry is already taking measures to protect its interests and maximize profits as turbulent times approach.\n\nHumans have always altered their environment. The advent of agriculture around 10000 years ago led to a radical change in land use that still continues. But, the relatively small human population had little impact on a global scale until the start of the industrial revolution in 1750. This event, followed by the invention of the Haber-Bosch process in 1909, which allowed large-scale manufacture of fertilizers, led directly to rapid changes to many of the planet's most important physical, chemical and biological processes.\n\nThe 1950s marked a shift in gear: global change began accelerating. Between 1950 and 2010, the population more than doubled. In that time, rapid expansion of international trade coupled with upsurges in capital flows and new technologies, particularly information and communication technologies, led to national economies becoming more fully integrated. There was a tenfold increase in economic activity and the world's human population became more tightly connected than ever before. The period saw sixfold increases in water use and river damming. About 70 percent of the world's freshwater resource is now used for agriculture. This rises to 90 percent in India and China. Half of the Earth's land surface had now been domesticated. By 2010, urban population, for the first time, exceeded rural population. And there has been a fivefold increase in fertilizer use. Indeed, manufactured reactive nitrogen from fertilizer production and industry now exceeds global terrestrial production of reactive nitrogen. Without artificial fertilizers there would not be enough food to sustain a population of seven billion people.\n\nThese changes to the human sub-system have a direct influence on all components of the Earth system. The chemical composition of the atmosphere has changed significantly. Concentrations of important greenhouse gases, carbon dioxide, methane and nitrous oxide are rising fast. Over Antarctica a large hole in the ozone layer appeared. Fisheries collapsed: most of the world's fisheries are now fully or over-exploited. Thirty percent of tropical rainforests disappeared.\n\nIn 2000, Nobel prize-winning scientist Paul Crutzen announced the scale of change is so great that in just 250 years, human society has pushed the planet into a new geological era: the Anthropocene. This name has stuck and there are calls for the Anthropocene to be adopted officially. If it is, it may be the shortest of all geological eras. Evidence suggests that if human activities continue to change components of the Earth system, which are all interlinked, this could heave the Earth system out of a one state and into a new state.\n\nGlobal change in a societal context encompasses social, cultural, technological, political, economic and legal change. Terms closely related to global change and society are globalization and global integration. Globalization began with long-distance trade and urbanism. The first record of long distance trading routes is in the third millennium BC. Sumerians in Mesopotamia traded with settlers in the Indus Valley, in modern-day India.\n\nSince 1750, but more significantly, since the 1950s, global integration has accelerated. This era has witnessed incredible global changes in communications, transportation, and computer technology. Ideas, cultures, people, goods, services and money move around the planet with ease. This new global interconnectedness and free flow of information has radically altered notions of other cultures, conflicts, religions and taboos. Now, social movements can and do form at a planetary scale.\n\nEvidence, if more were needed, of the link between social and environmental global change came with the 2008-2009 global financial crisis. The crisis pushed the planet's main economic powerhouses, the United States, Europe and much of Asia into recession. According to the Global Carbon Project, global atmospheric emissions of carbon dioxide fell from an annual growth rate of around 3.4% between 2000 and 2008, to a growth rate of about 2% in 2008.\n\nHumans are altering the planet's biogeochemical cycles in a largely unregulated way with limited knowledge of the consequences. Without steps to effectively manage the Earth system – the planet's physical, chemical, biological and social components – it is likely there will be severe impacts on people and ecosystems. Perhaps the largest concern is that a component of the Earth system, for example, an ocean circulation, the Amazon rainforest, or Arctic sea ice, will reach a tipping point and flip from its current state to another state: flowing to not flowing, rainforest to savanna, or ice to no ice. A domino effect could ensue with other components of the Earth system changing state rapidly.\n\nIntensive research over the last 20 years has shown that tipping points do exist in the Earth system, and wide-scale change can be rapid – a matter of decades. Potential tipping points have been identified and attempts have been made to quantify thresholds. But to date, the best efforts can only identify loosely defined \"planetary boundaries\" beyond which tipping points exist but their precise locations remain elusive.\n\nThere have been calls for a better way to manage the environment on a planetary scale, sometimes referred to as managing \"Earth's life support system\". The United Nations was formed to stop wars and provide a platform for dialogue between countries. It was not created to avoid major environmental catastrophe on regional or global scales. But several international environmental conventions exist under the UN, including the Framework Convention on Climate Change, Montreal Protocol, Convention to Combat Desertification, and Convention on Biological Diversity. Additionally, the UN has two bodies charged with coordinating environmental and development activities, the United Nations Environment Programme (UNEP) and the United Nations Development Programme (UNDP).\n\nIn 2004, the IGBP published \"Global Change and the Earth System, a planet under pressure.\" The publication's executive summary concluded: \"An overall, comprehensive, internally consistent strategy for stewardship of the Earth system is required\". It stated that a research goal is to define and maintain a stable equilibrium in the global environment.\n\nIn 2007, France called for UNEP to be replaced by a new and more powerful organization called the \"United Nations Environment Organization\". The rationale was that UNEP's status as a \"programme\", rather than an \"organization\" in the tradition of the World Health Organization or the World Meteorological Organization, weakened it to the extent that it was no longer fit for purpose given current knowledge of the state of the planet.\n"}
{"id": "20250534", "url": "https://en.wikipedia.org/wiki?curid=20250534", "title": "Global recession", "text": "Global recession\n\nA global recession is recession that affects many countries around the world—that is, a period of global economic slowdown or declining economic output.\n\nThe International Monetary Fund defines a global recession as \"a decline in annual percapita real World GDP (purchasing power parity weighted), backed up by a decline or worsening for one or more of the seven other global macroeconomic indicators: Industrial production, trade, capital flows, oil consumption, unemployment rate, percapita investment, and percapita consumption\".\n\nAccording to this definition, since World War II there were only four global recessions (in 1975, 1982, 1991 and 2009), all of them only lasting a year (although the 1991 recession would have lasted until 1993 if the IMF had used normal exchange rate weighted percapita real World GDP rather than the purchasing power parity weighted percapita real World GDP). The 2009 global recession, also known as the Great Recession, was by far the worst of the four postwar recessions, both in terms of the number of countries affected and the decline in real World GDP per capita.\n\nBefore April 2009, the IMF argued that a global annual real GDP growth rate of 3.0 percent or less was \"equivalent to a global recession\". By this measure, there were six global recessions since 1970: 1974–75, 1980–83, 1990–93, 1998, 2001–02, and 2008–09.\n\nInformally, a national recession is a period of declining economic output. In a 1974 \"New York Times\" article, Julius Shiskin suggested several rules of thumb to identify a recession, which included two successive quarterly declines in gross domestic product (GDP), a measure of the nation's output. This two-quarter metric is now a commonly held definition of a recession. In the United States, the National Bureau of Economic Research (NBER) is regarded as the authority which identifies a recession and which takes into account several measures in addition to GDP growth before making an assessment. In many developed nations (but not the United States), the two-quarter rule is also used for identifying a recession.\n\nWhereas a national recession is identified by two quarters of decline, defining a global recession is more difficult, because a Developing country is expected to have a higher GDP growth than a Developed country. According to the IMF, the real GDP growth of the emerging and developing countries is on an uptrend and that of advanced economies is on a downtrend since late 1980s. The world growth is projected to slow from 5% in 2007 to 3.75% in 2008 and to just over 2% in 2009. Downward revisions in GDP growth vary across regions. Among the most affected are commodity exporters, and countries with acute external financing and liquidity problems. Countries in East Asia (including China) have suffered smaller declines because their financial situations are more robust. They have benefited from falling commodity prices and they have initiated a shift toward macroeconomic policy easing.\n\nThe IMF estimates that global recessions occur over a cycle lasting between eight and ten years. During what the IMF terms the past three global recessions of the last three decades, global per capita output growth was zero or negative.\n\n\n"}
{"id": "52619428", "url": "https://en.wikipedia.org/wiki?curid=52619428", "title": "Global regionalization", "text": "Global regionalization\n\nGlobal regionalization is a process which is parallel to globalization. The most important feature of the global community is globalization of many processes and phenomena of the development of international relations, strengthening relationships and interdependence of modern states in the second half of the 20th century. Globalization is evident not only globally, but also regionally. An important component of international relations in the 21st century is regional development and cooperation. In this regard, the importance of regional significant factor in current international relations.\nMost of the changes which is observed in today's world are associated with the development of the information sphere.\nThere were predictable transformation and give rise to the beginning of the entry of humanity into a global information society. The researchers are note five definitions of information society-related parameters identification newness of the world which are technological, economic, concerning employment, spatial or cultural nature.\nThe significance of the information society in terms of its impact on system are consisting of international relations. In 2000 G-8 Summit in Okinawa adopted a Charter on Global Information Society, which are reflected to the changes in the world information. The same issues in lot of attention were paid to the Millennium Summit.\n\nThe driving forces of regionalization are not only state, but also non-governmental structure (the economic \"interest groups\", NGOs, political parties, etc.). World regionalism is one of the manifestations of globalization and at the same time it is the opposite trend. Globalization is accompanied by a regionalization of international relations, transfer of public functions to sub-national or international level. Regions helps to protect public relations of globalization from negative impact and act as an independent subject of international relations. Many developing countries see in regionalization attempt to confront global competition. In the context of globalization acquires special relevance selective protectionism - gradual global economic integration, combining openness to the outside world with the protection of national interests.\nUniversal theories of regions are exist on the theories of the problem, type, goals and objectives of the study. The following theoretical concepts are reflect to the processes of regionalism, which is a consequence of globalization. They are can be as : Multipolar world theory, the theory of large spaces, the theory of convergence and regional joint doctrine.\nIn the study of regionalism are analyzed the regionalization emerging in response to the challenges of globalization, regionalization, such as institutional integration of the process of interpenetration merging national productions which are combine together social and political institutional structure of the state. \nThere are different forms and types of integration. They are characterized by the degree of freedom of movement within groups factors of production. Currently there are mentioned forms of regional economic integration as: free trade area (FTA); Customs Union (CU); single or common market (BP); Economic Union (EU); Economic and Monetary Union (EMU) and others.\n\nIncreased of exposure information changes on the international relations caused by a number of features of the information. The first feature - information not only decreases or disappears in his large-scale use but it is starting point for the formation of new species and new qualities. The second feature - information is a fundamental principle for the development and decision-making at all levels of government, including the level of global governance. Third - feature information is \"Oedipus effect\", is the ability to influence the mind and behavior of individuals and society in general.\nDeveloping of the global information society are influenced by the progress of new information and communication technologies (ICT) in conjunction with the globalization of markets, both within individual countries and internationally. As a result, the harmonious joining the information society and respecting the necessary balance required coordinating efforts by the state as a body that can fully express the interests of society. Creating of a global information society are requires to the overcoming informational imbalances that exist in the world between different countries and regions, as well as information imbalances existing within themselves, for example, between different social groups. Because of these disparities, the task of building the information society acquire varying degrees of importance for different countries. Due to the intensification of information exchange and its interplay with economic imbalances interaction available information provided to the growing influence of politics, economics and culture.\nIn 1993 the Vice President of US - A. Gore used the term \"information superhighway.\" In the field of information, the states like Singapore, Finland, Sweden, Denmark, Canada, Switzerland, Norway, Australia and Iceland are according to the United States. In the information technology ratings Russia is in the sixth place in the top ten. Below - Morocco, Egypt, Sri Lanka, Bulgaria, Vietnam, the Philippines, Peru, Tanzania. In 1996 was adopted the programme \" Participation in international cultural exchange\" by the Federal Law.\nTo stay among the countries that affect global politics and largely define it, needs to strengthen active in shaping the global information society. At the end of 2001 Russia issued to the First Committee of the UN General Assembly resolution \"Developments in the field of information and telecommunications in the context of international security\". However, according to the Institute of the Information Society, 64% of the population of Russia does not feel the need to use the Internet. This figure was the result of adding Methodology Center for International Development at Harvard University \"Ready for the networked world\" (Readiness for the Networked World) and Russian realities which is relevant to the assessment: human capital, business climate and using of ICT in culture. It appears to the \"effect resource economy.\" It is most clearly seen when comparing the two global markets: the global oil market which is estimated at 650 billion dollars, (Russia's share in it - 16%); ICT world market - about $1 trillion share in it represents the hundredths of a percent (Vaganov, 2004).\nThe impact which formed of global information society on international relations has not only positive but also negative effects. Thus, the importance of international cooperation is often less important for the media industry, which allows for requests of the audience. Everywhere we are seeing a decline in international news programs, very costly and have a constant audience for stories related to the consumption and criminal chronicle (Atlas Monde diplomatique, 2007). Media increasingly contribute to the formation of world opinion, laying patterns to assess the achievements of globalization as well as risks and challenges of globalization.\nFor example, growth media publications about the terrorist threat is much ahead of terrorist activity in the world (Chernikov, 2002). However, there is no sufficient information on such global issues as water crisis, or human trafficking. All this points are need for the transformation of information policy.\n\nThe list of current unrecognized states in scientific publications is large. It includes the Republic of China on Taiwan and the Turkish Republic of Northern Cyprus. Often can be added the Republic of Somaliland, Tamil Eelam (Ceylon), and more recently - the Islamic State of Waziristan, whose independence was proclaimed in February 2006. Occasionally in this context refers to Southern Sudan, Kashmir, Western Sahara, Palestine, Kurdistan and some other areas (e.g. exotic Sealand). \nConsequently, the unrecognized state - it is the common name of public entities who are possessing all the attributes of statehood (control of territory, control system, the actual sovereignty) at the same time deprived of full or partial international diplomatic recognition and thus can not de jure act as in international relations. They should not be confused with self-declared republics (- it is education, which is itself declared, but no more). Some authors believe that the term of \"unrecognized state\" - incorrect (they believe that unrecognized state - is education that passed even though the short period of statehood, it ended in failure) and prefer the term \"State de facto\".\nInternational legal conflict between the right of nations and self-determination are enshrined in the famous decision of the UN General Assembly on decolonization in 1960. The principle of territorial integrity of States - is the principle of inviolability of borders which is officially recognized by all European countries, USA and Canada in the Conference on Security and Cooperation in Europe in Helsinki in 1975.\nUncertainty state by the international community negatively affects its legal status and operational capabilities. Such a state can not be in active economic activities can not conclude trade contracts and implement multilateral investment and infrastructure projects. The area relies only on the international community to humanitarian aid, social and cultural projects, cooperation with various countries and regions in its infancy. Thus the political and legal recognition of any territory depends for its existence and development.\nTop prospects in terms of possible transformations is the current status of Kosovo. It is about independence in some form, as this concerned the United States and the European Union. Apparently, Serbia will only be able to postpone such a decision or to bargain for themselves some political and economic concessions (integration of Serbia into the EU or Kosovo section). On the other hand, if the recognition of Kosovo be qualified as a unique case (a unique case) it could provoke a serious precedent in countries where the problem of ethnic separatism.\nAbkhazia, Transnistria and South Ossetia can rely on partial, incomplete recognition of Russia, but their future prospects far from obvious. This \"half independence\" will not be recognized by the United States, European Union, India, China and many other countries. There is the slightest chance of changing the status of Nagorno Karabakh. This situation is mainly determined by the position of the US, EU, Russia, Iran and Turkey.\nTo effectively address the problem of unrecognized states is likely to develop the clear international legal criteria under which after a certain period unrecognized state formation can count on international recognition.\nWith all the reservations can be stated that unrecognized independent state players are the regional and international politics. Their influence on political processes is quite noticeable. Globalization has created additional opportunities for long-term existence of unrecognized states without their formal recognition by other countries. It is gradually becoming the norm.\n\n\"Global Regionalization as a Way to Counteraction the Global Financial Threats\" dr Victor Reutov (Crimean economic institute SHEE «Vadym Hetman Kyiv National Economic University» Simferopol)\n"}
{"id": "2400074", "url": "https://en.wikipedia.org/wiki?curid=2400074", "title": "Global studies", "text": "Global studies\n\nGlobal studies is the interdisciplinary study of political, economic, legal, ecological and cultural interconnectedness. Predominant subjects are politics, economics and law on an international level. Global studies is oriented around the study of globalization as it relates to intercontinental politics, the global economy, international law, market relations, the movement of people and resources, global communications, the effect of human activity on the environment, and many more topics. Global studies is often used to map global change and is both micro and macro in scope. The Cambridge English Dictionary defines global studies as \"the study of political, economic, and social situations in the world\".\n\nGlobal studies tackles the aforementioned topics by examining global power structures influenced by perspectives such as Orientalism and Eurocentrism. Global studies is distinguished from international studies by its broader focus – international studies is only one aspect of global studies. In cases such as international studies or international relations, the concept of 'national' confines the meaning of those fields of study. By comparison, global studies has a broader reach, from the global to the local.\n\nThe development of global studies in secondary and tertiary education is arguably a product of globalization, and its consequent results on the international community. In the late 20th century, an unprecedented rise in communications technologies and computerization occurred around the world, again enhancing the processes of globalization: “it is a shift in our very life circumstances ... the speed of change is closely allied to the growth of communication, and development in information and communication technologies have been exponential ... globalization is a fact of life from which we cannot retreat.”. As a result of this constantly changing global community, education providers began to see a need for the introduction of global studies into secondary school curricula (i.e. introduction of global issues through already existing subjects), and to create global studies degrees for tertiary students (i.e. sole degrees with a global focus).\n\nAccording to Jan Nederveen Pieterse, Mellichamp Professor of Global Studies and Sociology at The University of California, Santa Barbara:The first Global Studies conference took place at the University of Illinois Chicago in 2008; the 2009 conference was held in Dubai on the theme Views from Dubai: The Gulf and Globalization. The 2010 conference was in Busan, South Korea under the heading Global Rebalancing: East Asia and Globalization; the 2011 conference took place in Rio de Janeiro on Emerging societies and Emancipation; the 2012 conference was at Moscow University on the theme of Eurasia and Globalization: Complexity and Global studies; and the 2013 conference took place in New Delhi on the theme of Social Development in South Asia.The Global Studies Journal was founded in 2008 and is \"devoted to mapping and interpreting new trends and patterns in globalization\".\n\nThere can be much confusion about the use of the terms, \"global studies\" and \"international studies.\"\n\nThey are at times used interchangeably and differences in meaning are not evident, however, both disciplines are concerned with political, social and cultural issues, with the main focus of study being placed on international community interaction. However, subtle distinctions can be made between the two phrases. International studies generally looks at exchanges between states, multilateral or bilateral agreements, diplomacy and how issues are handled between two or more states. Global studies, in contrast, focuses on globally shared issues.\n\nIt has also been suggested that there are left wing and right wing connotations to each phrase, international studies being preferred by the right wing (i.e. relations between states) and global studies preferred by the left (i.e. issues affecting all global citizens).\n\nThe terms have also been described as such:\n\nInternational studies might be called the grandfather of global education. It often includes the study of countries, world religions, languages and international relations ... (global studies) is centred on the concept of connectedness – recognizing local/ global connections, the commonalities all humans share, and how understanding how national borders have become practically irrelevant for many global actors.\n\nFive defining characteristics of global studies were identified by scholars at the first annual meeting of the Global Studies Consortium in Tokyo in 2008:\n\nThe field of global studies revolves around the impacts of globalization and the growing interdependence of states, economies, societies, cultures, and people. This necessitates that students are well versed and capable of critical analysis when it comes to global issues. Some of the most pressing issues in global studies are national security and diplomacy, effective citizenship in a participatory democracy, global competitiveness in a world market and the desire to enter the aid and development sector.\n\nThe first major funding for international education was the 1966 International Education Act in the US. It provided funding to institutions of higher education to create and strengthen international studies programs. Created at the time of the Cold War, this act stressed the need for all citizens (with a focus on USA citizens) to understand global issues in order to build skills for diplomacy.”The importance of diplomacy as a driving force for political development is well known and understood. It is of great importance as a long term instrument for conflict prevention.”\n\nThe development of issues and crisis on a global scale such as international terrorism, climate change and environmental degradation, pandemics (such as ebola), and the Great Recession have convinced policymakers of the importance of global studies and international education to national security and diplomacy.\n\nA second motivation for global studies is facilitating a better understanding of the global marketplace. Many international companies have identified the need for a workforce that has the skills to work cross-culturally and identify and serve the needs of a global market. Some international companies, such as Microsoft, have taken the lead in convening policymakers and key stakeholders to demand additional investment in education. The US state and federal governments have also placed global studies as a key priority for preparing a competitive workforce. Furthermore, in 2002 the Australian federal government (through its development body AusAID) used some of its funding to introduce a ‘Global Education Program.’ This program aims to increase understanding of development and international issues among Australian students. It provides teachers with professional development opportunities with NGOs and thorough curriculum support. The program “informs and encourages teachers to introduce students to global issues in a classroom setting.” Higher education institutions have closely followed with integrating international studies across disciplines. It is rare to find a leading business school without an international focus.\n\nA third motivation for global studies is the creation of an effective citizenry. In the US, the National Council of Social Studies states that the purpose of social studies is to “teach students the content knowledge, intellectual skills, and civic values necessary for fulfilling the duties of citizenship in a participatory democracy.” A key goal of the NCSS is “global education”. As globalization causes the lines between national and international to become blurred, it becomes increasingly important for citizens to understand global relationships. The creation of effective Global citizenship results in people who are willing to, and have the capacity to become involved in local and global issues. In the UK, local government research conducted in the surrounding areas of London has found that citizens must have the opportunity to become involved and then possess the skill, knowledge and confidence to take part. The outcomes are often very positive, leading to an improvement in services, better quality of democratic participation and community education. \nTo achieve effective citizenship, students must be educated in ways that engage and place emphasis on the importance of global issues. By studying a subject such as global studies, students can gain the knowledge required to become effective citizens.\n\nSome critical scholars note that beyond content, students must be taught \"global cognition\" in order to truly understand global perspectives. These scholars believe that in order to fully understand world issues, students must recognize that their perspective is not necessarily shared by others and understand the social forces that influence their views. These perspectives encourage engagement with new promises and threats for the promotion of human rights, social justice, and political participation.\n\nBy 2006, the international development sector had expanded exponentially, with the “NGO sector now being the 8th largest economy in the world ... employing nearly 19 million paid workers.\" Financing health projects used to be the biggest issue in global aid, but private and public organizations like the Bill and Melinda Gates Foundation have helped overcome such problems. The issue now is making sure that the money is used in a proper manner to help those in need of the primary essentials of life. Studying global studies may lead to involvement in the aid and development sector in multiple ways. These can include working in post-conflict or natural disaster zones, improving public services in developing communities (health, education, infrastructure, agriculture) or aiding private sector growth through business and market models. Through studying global studies, students can be equipped with cross cultural knowledge, field experience and an awareness of global issues. Many students are now studying global studies in order to enter this sector.\n\nLearning outcomes for global studies vary depending on the institutes curriculum and students individual focuses. Although, introductory courses are designed to cover a wide range of topics in a single semester, students are expected to delve into a specific phenomenon or area of study for their academic career. there are some generic outcomes that students are expected to develop over the duration of study. These include, but are not limited to:\n\nGlobal studies scholars are eligible for a myriad of professions, tackling political, social, and economic issues on an international scale that work to improve the human condition.\n\n\nUniversity of Cape Town\nhttps://www.news.uct.ac.za/article/-2010-12-06-global-studies-programme-gives-students-larger-perspective\n\nHamline University, Saint Paul\nHofstra University\n\n\n\n\n\n"}
{"id": "44373791", "url": "https://en.wikipedia.org/wiki?curid=44373791", "title": "Globalization (Christian Perspective)", "text": "Globalization (Christian Perspective)\n\nGlobalization allowed interaction between countries and the global market and has grown economies to higher levels. It is a highly debated subject and there is a great deal to be discussed about it. One perspective on this worldwide movement is the Christian (religious) point of view. First of all, Christians believe in a higher authority, and aim to model their lives in obedience to their God. That being said, they value community and ultimately care for all the people their God has created. That is on a global scale, not only local. They feel a responsibility to the poor, and encourage globalization as it provides more opportunities for countries with weak economies that struggle with poverty. Work is valuable and there is importance in working in a global economy.\n\nThere are three main approaches to this topic from this perspective. There is the Evangelical Approach, Catholic Social teaching, and the Non-Evangelical Perspective.\n\nThe evangelical approach focuses on the spread of the gospel of Jesus Christ through globalization. Globalization opens many doors to many countries, and this perspective looks at that as an opportunity. It is an opportunity to spread the Christian teaching through the doors that have been opened. In this context globalization is seen as a tool, a stepping stone towards achieving the evangelical goal.\n\nThe Catholic social teaching looks at globalization with the aim of improving it. Improving it in the sense that they desire to shift the focus to a more humanitarian goal. Thomas Friedman wrote that, \"the more I observed the system of globalization at work, the more obvious it was that it had unleashed forest-crushing forces of development and Disney-round-the-clock homogenization which, if left unchecked, had the potential to destroy the environment and uproot cultures at a pace never before seen in human history.\" in his book \"The Lexus and the Olive Tree\" In this perspective, globalization is not viewed as a positive development, but can be seen as a way to reach more people and create a more socially conscious global environment.\n\nThe non-evangelical perspective highlights the benefits of globalisation through reach. It emphasizes the number of people now more easily contacted and the cultures more easily understood. In this view the focus is not the spread of the gospel but the connecting of the \"body of Christ\" on a global level. It is basically the universal church being more easily unified through the barriers broken down by globalization.\n"}
{"id": "14098", "url": "https://en.wikipedia.org/wiki?curid=14098", "title": "History of the Americas", "text": "History of the Americas\n\nThe prehistory of the Americas (North, South, and Central America, and the Caribbean) begins with people migrating to these areas from Asia during the height of an Ice Age. These groups are generally believed to have been isolated from peoples of the \"Old World\" until the coming of Europeans in the 10th century from Norway and with the voyages of Christopher Columbus in 1492.\n\nThe ancestors of today's American Indigenous peoples were the Paleo-Indians; they were hunter-gatherers who migrated into North America. The most popular theory asserts that migrants came to the Americas via Beringia, the land mass now covered by the ocean waters of the Bering Strait. Small lithic stage peoples followed megafauna like bison, mammoth (now extinct), and caribou, thus gaining the modern nickname \"big-game hunters.\" Groups of people may also have traveled into North America on shelf or sheet ice along the northern Pacific coast.\n\nCultural traits brought by the first immigrants later evolved and spawned such cultures as Iroquois on North America and Pirahã of South America. These cultures later developed into civilizations. In many cases, these cultures expanded at a later date than their Old World counterparts. Cultures that may be considered advanced or civilized include Norte Chico, Cahokia, Zapotec, Toltec, Olmec, Maya, Aztec, Chimor, Mixtec, Moche, Mississippian, Puebloan, Totonac, Teotihuacan, Huastec people, Purépecha, Izapa, Mazatec, Muisca, and the Inca.After the voyages of Christopher Columbus in 1492, Spanish, Portuguese and later English, French and Dutch colonial expeditions arrived in the New World, conquering and settling the discovered lands, which led to a transformation of the cultural and physical landscape in the Americas. Spain colonized most of the Americas from present-day Southwestern United States, Florida and the Caribbean to the southern tip of South America. Portugal settled in what is mostly present-day Brazil while England established colonies on the Eastern coast of the United States, as well as the North Pacific coast and in most of Canada. France settled in Quebec and other parts of Eastern Canada and claimed an area in what is today the central United States. The Netherlands settled New Netherland (administrative centre New Amsterdam - now New York), some Caribbean islands and parts of Northern South America.\n\nEuropean colonization of the Americas led to the rise of new cultures, civilizations and eventually states, which resulted from the fusion of Native American and European traditions, peoples and institutions. The transformation of American cultures through colonization is evident in architecture, religion, gastronomy, the arts and particularly languages, the most widespread being Spanish (376 million speakers), English (348 million) and Portuguese (201 million). The colonial period lasted approximately three centuries, from the early 16th to the early 19th centuries, when Brazil and the larger Hispanic American nations declared independence. The United States obtained independence from England much earlier, in 1776, while Canada formed a federal dominion in 1867. Others remained attached to their European parent state until the end of the 19th century, such as Cuba and Puerto Rico which were linked to Spain until 1898. Smaller territories such as Guyana obtained independence in the mid-20th century, while certain Caribbean islands and French Guiana remain part of a European power to this day.\n\n \nThe specifics of Paleo-Indian migration to and throughout the Americas, including the exact dates and routes traveled, are subject to ongoing research and discussion. The traditional theory has been that these early migrants moved into the Beringia land bridge between eastern Siberia and present-day Alaska around 40,000 – 17,000 years ago, when sea levels were significantly lowered due to the Quaternary glaciation. These people are believed to have followed herds of now-extinct Pleistocene megafauna along \"ice-free corridors\" that stretched between the Laurentide and Cordilleran ice sheets. Another route proposed is that, either on foot or using primitive boats, they migrated down the Pacific Northwest coast to South America. Evidence of the latter would since have been covered by a sea level rise of a hundred meters following the last ice age.\n\nArchaeologists contend that the Paleo-Indian migration out of Beringia (eastern Alaska), ranges from 40,000 to around 16,500 years ago. This time range is a hot source of debate. The few agreements achieved to date are the origin from Central Asia, with widespread habitation of the Americas during the end of the last glacial period, or more specifically what is known as the late glacial maximum, around 16,000 – 13,000 years before present.\n\nThe American Journal of Human Genetics released an article in 2007 stating \"Here we show, by using 86 complete mitochondrial genomes, that all Indigenous American haplogroups, including Haplogroup X (mtDNA), were part of a single founding population.\" Amerindian groups in the Bering Strait region exhibit perhaps the strongest DNA or mitochondrial DNA relations to Siberian peoples. The genetic diversity of Amerindian indigenous groups increase with distance from the assumed entry point into the Americas. Certain genetic diversity patterns from West to East suggest, particularly in South America, that migration proceeded first down the west coast, and then proceeded eastward. Geneticists have variously estimated that peoples of Asia and the Americas were part of the same population from 42,000 to 21,000 years ago.\n\nNew studies shed light on the founding population of indigenous Americans, suggesting that their ancestry traced to both east Asian and western Eurasians who migrated to North America directly from Siberia. A 2013 study in the journal Nature reported that DNA found in the 24,000-year-old remains of a young boy in Mal’ta Siberia suggest that up to one-third of the indigenous Americans may have ancestry that can be traced back to western Eurasians, who may have \"had a more north-easterly distribution 24,000 years ago than commonly thought\" Professor Kelly Graf said that \"Our findings are significant at two levels. First, it shows that Upper Paleolithic Siberians came from a cosmopolitan population of early modern humans that spread out of Africa to Europe and Central and South Asia. Second, Paleoindian skeletons with phenotypic traits atypical of modern-day Native Americans can be explained as having a direct historical connection to Upper Paleolithic Siberia.\" A route through Beringia is seen as more likely than the Solutrean hypothesis.\n\nOn October 3, 2014, the Oregon cave where the oldest DNA evidence of human habitation in North America was found was added to the National Register of Historic Places. The DNA, radiocarbon dated to 14,300 years ago, was found in fossilized human coprolites uncovered in the Paisley Five Mile Point Caves in south central Oregon.\n\nThe Lithic stage or \"Paleo-Indian period\", is the earliest classification term referring to the first stage of human habitation in the Americas, covering the Late Pleistocene epoch. The time period derives its name from the appearance of \"Lithic flaked\" stone tools. Stone tools, particularly projectile points and scrapers, are the primary evidence of the earliest well known human activity in the Americas. Lithic reduction stone tools are used by archaeologists and anthropologists to classify cultural periods.\n\nSeveral thousand years after the first migrations, the first complex civilizations arose as hunter-gatherers settled into semi-agricultural communities. Identifiable sedentary settlements began to emerge in the so-called Middle Archaic period around 6000 BCE. Particular archaeological cultures can be identified and easily classified throughout the Archaic period.\n\nIn the late Archaic, on the north-central coastal region of Peru, a complex civilization arose which has been termed the Norte Chico civilization, also known as Caral-Supe. It is the oldest known civilization in the Americas and one of the five sites where civilization originated independently and indigenously in the ancient world, flourishing between the 30th and 18th centuries BC. It pre-dated the Mesoamerican Olmec civilization by nearly two millennia. It was contemporaneous with the Egypt following the unification of its kingdom under Narmer and the emergence of the first Egyptian hieroglyphics.\n\nMonumental architecture, including earthwork platform mounds and sunken plazas have been identified as part of the civilization. Archaeological evidence points to the use of textile technology and the worship of common god symbols. Government, possibly in the form of theocracy, is assumed to have been required to manage the region. However, numerous questions remain about its organization. In archaeological nomenclature, the culture was pre-ceramic culture of the pre-Columbian Late Archaic period. It appears to have lacked ceramics and art.\n\nOngoing scholarly debate persists over the extent to which the flourishing of Norte Chico resulted from its abundant maritime food resources, and the relationship that these resources would suggest between coastal and inland sites.\n\nThe role of seafood in the Norte Chico diet has been a subject of scholarly debate. In 1973, examining the Aspero region of Norte Chico, Michael E. Moseley contended that a maritime subsistence (seafood) economy had been the basis of society and its early flourishing. This theory, later termed \"maritime foundation of Andean Civilization\" was at odds with the general scholarly consensus that civilization arose as a result of intensive grain-based agriculture, as had been the case in the emergence of civilizations in northeast Africa (Egypt) and southwest Asia (Mesopotamia).\n\nWhile earlier research pointed to edible domestic plants such as squash, beans, lucuma, guava, pacay, and camote at Caral, publications by Haas and colleagues have added avocado, achira, and corn (Zea Mays) to the list of foods consumed in the region. In 2013, Haas and colleagues reported that maize was a primary component of the diet throughout the period of 3000 to 1800 BC.\n\nCotton was another widespread crop in Norte Chico, essential to the production of fishing nets and textiles. Jonathan Haas noted a mutual dependency, whereby \"The prehistoric residents of the Norte Chico needed the fish resources for their protein and the fishermen needed the cotton to make the nets to catch the fish.\"\n\nIn the 2005 book \"\", journalist Charles C. Mann surveyed the literature at the time, reporting a date \"sometime before 3200 BC, and possibly before 3500 BC\" as the beginning date for the formation of Norte Chico. He notes that the earliest date securely associated with a city is 3500 BC, at Huaricanga in the (inland) Fortaleza area.\n\nThe Norte Chico civilization began to decline around 1800 BC as more powerful centers appeared to the south and north along its coast, and to the east within the Andes Mountains.\n\nAfter the decline of the Norte Chico civilization, several large, centralized civilizations developed in the Western Hemisphere: Chavin, Nazca, Moche, Huari, Quitus, Cañaris, Chimu, Pachacamac, Tiahuanaco, Aymara and Inca in the Central Andes (Ecuador, Peru and Bolivia); Muisca in Colombia ; Taínos in Dominican Republic (Hispaniola, Española) and part of Caribbean; and the Olmecs, Maya, Toltecs, Mixtecs, Zapotecs, Aztecs and Purepecha in southern North America (Mexico, Guatemala).\n\nThe Olmec civilization was the first Mesoamerican civilization, beginning around 1600-1400 BC and ending around 400 BC. Mesoamerica is considered one of the six sites around the globe in which civilization developed independently and indigenously. This civilization is considered the mother culture of the Mesoamerican civilizations. The Mesoamerican calendar, numeral system, writing, and much of the Mesoamerican pantheon seem to have begun with the Olmec.\n\nSome elements of agriculture seem to have been practiced in Mesoamerica quite early. The domestication of maize is thought to have begun around 7,500 to 12,000 years ago. The earliest record of lowland maize cultivation dates to around 5100 BC. Agriculture continued to be mixed with a hunting-gathering-fishing lifestyle until quite late compared to other regions, but by 2700 BC, Mesoamericans were relying on maize, and living mostly in villages. Temple mounds and classes started to appear. By 1300/ 1200 BC, small centres coalesced into the Olmec civilization, which seems to have been a set of city-states, united in religious and commercial concerns. The Olmec cities had ceremonial complexes with earth/clay pyramids, palaces, stone monuments, aqueducts and walled plazas. The first of these centers was at San Lorenzo (until 900 bc). La Venta was the last great Olmec centre. Olmec artisans sculpted jade and clay figurines of Jaguars and humans. Their iconic giant heads - believed to be of Olmec rulers - stood in every major city.\n\nThe Olmec civilization ended in 400 BC, with the defacing and destruction of San Lorenzo and La Venta, two of the major cities. It nevertheless spawned many other states, most notably the Mayan civilization, whose first cities began appearing around 700-600 BC. Olmec influences continued to appear in many later Mesoamerican civilizations.\n\nCities of the Aztecs, Mayas, and Incas were as large and organized as the largest in the Old World, with an estimated population of 200,000 to 350,000 in Tenochtitlan, the capital of the Aztec empire. The market established in the city was said to have been the largest ever seen by the conquistadors when they arrived. The capital of the Cahokians, Cahokia, located near modern East St. Louis, Illinois, may have reached a population of over 20,000. At its peak, between the 12th and 13th centuries, Cahokia may have been the most populous city in North America. Monk's Mound, the major ceremonial center of Cahokia, remains the largest earthen construction of the prehistoric New World.\n\nThese civilizations developed agriculture as well, breeding maize (corn) from having ears 2–5 cm in length to perhaps 10–15 cm in length. Potatoes, tomatoes, pumpkins, beans, avocados, and chocolate are now the most popular of the pre-Columbian agricultural products. The civilizations did not develop extensive livestock as there were few suitable species, although alpacas and llamas were domesticated for use as beasts of burden and sources of wool and meat in the Andes. By the 15th century, maize was being farmed in the Mississippi River Valley after introduction from Mexico. The course of further agricultural development was greatly altered by the arrival of Europeans.\n\n\nCahokia was a major regional chiefdom, with trade and tributary chiefdoms located in a range of areas from bordering the Great Lakes to the Gulf of Mexico.\n\n\nThe Iroquois League of Nations or \"People of the Long House\", based in present-day upstate and western New York, had a confederacy model from the mid-15th century. It has been suggested that their culture contributed to political thinking during the development of the later United States government. Their system of affiliation was a kind of federation, different from the strong, centralized European monarchies.\n\nLeadership was restricted to a group of 50 sachem chiefs, each representing one clan within a tribe; the Oneida and Mohawk people had nine seats each; the Onondagas held fourteen; the Cayuga had ten seats; and the Seneca had eight. Representation was not based on population numbers, as the Seneca tribe greatly outnumbered the others. When a sachem chief died, his successor was chosen by the senior woman of his tribe in consultation with other female members of the clan; property and hereditary leadership were passed matrilineally. Decisions were not made through voting but through consensus decision making, with each sachem chief holding theoretical veto power. The Onondaga were the \"firekeepers\", responsible for raising topics to be discussed. They occupied one side of a three-sided fire (the Mohawk and Seneca sat on one side of the fire, the Oneida and Cayuga sat on the third side.)\n\nElizabeth Tooker, an anthropologist, has said that it was unlikely the US founding fathers were inspired by the confederacy, as it bears little resemblance to the system of governance adopted in the United States. For example, it is based on inherited rather than elected leadership, selected by female members of the tribes, consensus decision-making regardless of population size of the tribes, and a single group capable of bringing matters before the legislative body.\n\nLong-distance trading did not prevent warfare and displacement among the indigenous peoples, and their oral histories tell of numerous migrations to the historic territories where Europeans encountered them. The Iroquois invaded and attacked tribes in the Ohio River area of present-day Kentucky and claimed the hunting grounds. Historians have placed these events as occurring as early as the 13th century, or in the 17th century Beaver Wars.\n\nThrough warfare, the Iroquois drove several tribes to migrate west to what became known as their historically traditional lands west of the Mississippi River. Tribes originating in the Ohio Valley who moved west included the Osage, Kaw, Ponca and Omaha people. By the mid-17th century, they had resettled in their historical lands in present-day Kansas, Nebraska, Arkansas and Oklahoma. The Osage warred with Caddo-speaking Native Americans, displacing them in turn by the mid-18th century and dominating their new historical territories.\n\n\nThe Pueblo people of what is now the Southwestern United States and northern Mexico, living conditions were that of large stone apartment like adobe structures. They live in Arizona, New Mexico, Utah, Colorado, and possibly surrounding areas.\n\nChichimeca was the name that the Mexica (Aztecs) generically applied to a wide range of semi-nomadic peoples who inhabited the north of modern-day Mexico, and carried the same sense as the European term \"barbarian\". The name was adopted with a pejorative tone by the Spaniards when referring especially to the semi-nomadic hunter-gatherer peoples of northern Mexico.\n\nThe Zapotec emerged around 1500 years BCE. Their writing system influenced the later Olmec. They left behind the great city Monte Alban.\n\nThe Olmec civilization emerged around 1200 BCE in Mesoamerica and ended around 400 BCE. Olmec art and concepts influenced surrounding cultures after their downfall. This civilization was thought to be the first in America to develop a writing system. After the Olmecs abandoned their cities for unknown reasons, the Maya, Zapotec and Teotihuacan arose.\n\nThe Purepecha civilization emerged around 1000 CE in Mesoamerica . They flourished from 1100 CE to 1530 CE. They continue to live on in the state of Michoacán. Fierce warriors, they were never conquered and in their glory years, successfully sealed off huge areas from Aztec domination.\n\n\nMaya history spans 3,000 years. The Classic Maya may have collapsed due to changing climate in the end of the 10th century.\n\nThe Toltec were a nomadic people, dating from the 10th - 12th century, whose language was also spoken by the Aztecs.\n\nTeotihuacan (4th century BCE - 7/8th century CE) was both a city, and an empire of the same name, which, at its zenith between 150 and the 5th century, covered most of Mesoamerica.\n\nThe Aztec having started to build their empire around 14th century found their civilization abruptly ended by the Spanish conquistadors. They lived in Mesoamerica, and surrounding lands. Their capital city Tenochtitlan was one of the largest cities of all time.\n\nThe oldest known civilization of the Americas was established in the Norte Chico region of modern Peru. Complex society emerged in the group of coastal valleys, between 3000 and 1800 BCE. The Quipu, a distinctive recording device among Andean civilizations, apparently dates from the era of Norte Chico's prominence.\n\nThe Chavín established a trade network and developed agriculture by as early as (or late compared to the Old World) 900 BCE according to some estimates and archaeological finds. Artifacts were found at a site called Chavín in modern Peru at an elevation of 3,177 meters. Chavín civilization spanned from 900 BCE to 300 BCE.\n\nHolding their capital at the great city of Cusco, the Inca civilization dominated the Andes region from 1438 to 1533.\nKnown as \"Tahuantinsuyu\", or \"the land of the four regions\", in Quechua, the Inca culture was highly distinct and developed. Cities were built with precise, unmatched stonework, constructed over many levels of mountain terrain. Terrace farming was a useful form of agriculture. There is evidence of excellent metalwork and even successful trepanation of the skull in Inca civilization.\n\nAround 1000, the Vikings established a short-lived settlement in Newfoundland, now known as L'Anse aux Meadows. Speculations exist about other Old World discoveries of the New World, but none of these are generally or completely accepted by most scholars.\n\nSpain sponsored a major exploration led by Italian explorer Christopher Columbus in 1492; it quickly led to extensive European colonization of the Americas. The Europeans brought Old World diseases which are thought to have caused catastrophic epidemics and a huge decrease of the native population. Columbus came at a time in which many technical developments in sailing techniques and communication made it possible to report his voyages easily and to spread word of them throughout Europe. It was also a time of growing religious, imperial and economic rivalries that led to a competition for the establishment of colonies.\n\n15th to 19th century colonies in the New World:\n\nThe formation of sovereign states in the New World began with the United States Declaration of Independence of 1776. The American Revolutionary War lasted through the period of the Siege of Yorktown — its last major campaign — in the early autumn of 1781, with peace being achieved in 1783.\nThe Spanish colonies won their independence in the first quarter of the 19th century, in the Spanish American wars of independence. Simón Bolívar and José de San Martín, among others, led their independence struggle. Although Bolivar attempted to keep the Spanish-speaking parts of Latin America politically allied, they rapidly became independent of one another as well, and several further wars were fought, such as the Paraguayan War and the War of the Pacific. (See Latin American integration.) In the Portuguese colony Dom Pedro I (also Pedro IV of Portugal), son of the Portuguese king Dom João VI, proclaimed the country's independence in 1822 and became Brazil's first Emperor. This was peacefully accepted by the crown in Portugal, upon compensation.\n\nSlavery has had a significant role in the economic development of the New World after the colonization of the Americas by the Europeans. The cotton, tobacco, and sugar cane harvested by slaves became important exports for the United States and the Caribbean countries.\n\nAs a part of the British Empire, Canada immediately entered World War I when it broke out in 1914. Canada bore the brunt of several major battles during the early stages of the war, including the use of poison gas attacks at Ypres. Losses became grave, and the government eventually brought in conscription, despite the fact this was against the wishes of the majority of French Canadians. In the ensuing Conscription Crisis of 1917, riots broke out on the streets of Montreal. In neighboring Newfoundland, the new dominion suffered a devastating loss on July 1, 1916, the First day on the Somme.\n\nThe United States stayed out of the conflict until 1917, when it joined the Entente powers. The United States was then able to play a crucial role at the Paris Peace Conference of 1919 that shaped interwar Europe. Mexico was not part of the war, as the country was embroiled in the Mexican Revolution at the time.\n\nThe 1920s brought an age of great prosperity in the United States, and to a lesser degree Canada. But the Wall Street Crash of 1929 combined with drought ushered in a period of economic hardship in the United States and Canada. From 1936 to 1949, there was a popular uprising against the anti-Catholic Mexican government of the time, set off specifically by the anti-clerical provisions of the Mexican Constitution of 1917.\n\nOnce again, Canada found itself at war before its neighbors, however even Canadian contributions were slight before the Japanese attack on Pearl Harbor. The entry of the United States into the war helped to tip the balance in favour of the allies. Two Mexican tankers, transporting oil to the United States, were attacked and sunk by the Germans in the Gulf of Mexico waters, in 1942. The incident happened in spite of Mexico's neutrality at that time. This led Mexico to enter the conflict with a declaration of war on the Axis nations. The destruction of Europe wrought by the war vaulted all North American countries to more important roles in world affairs, especially the United States, which emerged as a \"superpower\".\n\nThe early Cold War era saw the United States as the most powerful nation in a Western coalition of which Mexico and Canada were also a part. In Canada, Quebec was transformed by the Quiet Revolution and the emergence of Quebec nationalism. Mexico experienced an era of huge economic growth after World War II, a heavy industrialization process and a growth of its middle class, a period known in Mexican history as \"El Milagro Mexicano\" (the Mexican miracle). The Caribbean saw the beginnings of decolonization, while on the largest island the Cuban Revolution introduced Cold War rivalries into Latin America.\n\nThe civil rights movement in the U.S. ended Jim Crow and empowered black voters in the 1960s, which allowed black citizens to move into high government offices for the first time since Reconstruction. However, the dominant New Deal coalition collapsed in the mid 1960s in disputes over race and the Vietnam War, and the conservative movement began its rise to power, as the once dominant liberalism weakened and collapsed. Canada during this era was dominated by the leadership of Pierre Elliot Trudeau. In 1982, at the end of his tenure, Canada enshrined a new constitution.\n\nCanada's Brian Mulroney not only ran on a similar platform but also favored closer trade ties with the United States. This led to the Canada-United States Free Trade Agreement in January 1989. Mexican presidents Miguel de la Madrid, in the early 1980s and Carlos Salinas de Gortari in the late 1980s, started implementing liberal economic strategies that were seen as a good move. However, Mexico experienced a strong economic recession in 1982 and the Mexican peso suffered a devaluation. In the United States president Ronald Reagan attempted to move the United States back towards a hard anti-communist line in foreign affairs, in what his supporters saw as an attempt to assert moral leadership (compared to the Soviet Union) in the world community. Domestically, Reagan attempted to bring in a package of privatization and regulation to stimulate the economy.\n\nThe end of the Cold War and the beginning of the era of sustained economic expansion coincided during the 1990s. On January 1, 1994, Canada, Mexico and the United States signed the North American Free Trade Agreement, creating the world's largest free trade area. In 2000, Vicente Fox became the first non-PRI candidate to win the Mexican presidency in over 70 years. The optimism of the 1990s was shattered by the 9/11 attacks of 2001 on the United States, which prompted military intervention in Afghanistan, which also involved Canada. Canada did not support the United States' later move to invade Iraq, however.\n\nIn the U.S. the Reagan Era of conservative national policies, deregulation and tax cuts took control with the election of Ronald Reagan in 1980. By 2010, political scientists were debating whether the election of Barack Obama in 2008 represented an end of the Reagan Era, or was only a reaction against the bubble economy of the 2000s (decade), which burst in 2008 and became the Late-2000s recession with prolonged unemployment.\n\nDespite the failure of a lasting political union, the concept of Central American reunification, though lacking enthusiasm from the leaders of the individual countries, rises from time to time. In 1856–1857 the region successfully established a military coalition to repel an invasion by United States adventurer William Walker. Today, all five nations fly flags that retain the old federal motif of two outer blue bands bounding an inner white stripe. (Costa Rica, traditionally the least committed of the five to regional integration, modified its flag significantly in 1848 by darkening the blue and adding a double-wide inner red band, in honor of the French tricolor).\n\nIn 1907, a Central American Court of Justice was created. On December 13, 1960, Guatemala, El Salvador, Honduras, and Nicaragua established the Central American Common Market (\"CACM\"). Costa Rica, because of its relative economic prosperity and political stability, chose not to participate in the CACM. The goals for the CACM were to create greater political unification and success of import substitution industrialization policies. The project was an immediate economic success, but was abandoned after the 1969 \"Football War\" between El Salvador and Honduras. A Central American Parliament has operated, as a purely advisory body, since 1991. Costa Rica has repeatedly declined invitations to join the regional parliament, which seats deputies from the four other former members of the Union, as well as from Panama and the Dominican Republic.\n\nIn the 1960s and 1970s, the governments of Argentina, Brazil, Chile, and Uruguay were overthrown or displaced by U.S.-aligned military dictatorships. These dictatorships detained tens of thousands of political prisoners, many of whom were tortured and/or killed (on inter-state collaboration, see Operation Condor). Economically, they began a transition to neoliberal economic policies. They placed their own actions within the United States Cold War doctrine of \"National Security\" against internal subversion. Throughout the 1980s and 1990s, Peru suffered from an internal conflict (see Túpac Amaru Revolutionary Movement and Shining Path). Revolutionary movements and right-wing military dictatorships have been common, but starting in the 1980s a wave of democratization came through the continent, and democratic rule is widespread now. Allegations of corruption remain common, and several nations have seen crises which have forced the resignation of their presidents, although normal civilian succession has continued.\n\nInternational indebtedness became a notable problem, as most recently illustrated by Argentina's default in the early 21st century. In recent years, South American governments have drifted to the left, with socialist leaders being elected in Chile, Bolivia, Brazil, Venezuela, and a leftist president in Argentina and Uruguay. Despite the move to the left, South America is still largely capitalist. With the founding of the Union of South American Nations, South America has started down the road of economic integration, with plans for political integration in the European Union style.\n\n"}
{"id": "48714730", "url": "https://en.wikipedia.org/wiki?curid=48714730", "title": "Ideoscape", "text": "Ideoscape\n\nIdeoscape is a term used to describe one of Arjun Appadurai’s five dimensions of global cultural flows. The five dimensions consist of ethnoscapes, mediascapes, technoscapes, financescapes, and ideoscapes. The suffix -\"scape\" denotes that these terms are perspectival constructs inflected by the historical, linguistic, and political situatedness of different kinds of actors: \"nation-states, multinationals, diasporic communities, as well as subnational groupings and movements\". This can either be religious, political, or economic. Because cultural exchange and transactions have typically been restricted in the past due to geographical and economical aspects, Appadurai’s five dimensions give the opportunity for cultural transactions to occur. Ideoscapes is the movement of ideologies. It is often political and usually has to do with the ideologies of states and the counterideologies of movements explicitly oriented to capturing state power or a piece of it. Ideoscapes are usually composed of ideas, terms, and images including “freedom, welfare, rights, sovereignty, representation, and democracy”.\n"}
{"id": "33065537", "url": "https://en.wikipedia.org/wiki?curid=33065537", "title": "Infectious Disease Research Institute", "text": "Infectious Disease Research Institute\n\nThe Infectious Disease Research Institute (IDRI) is a non-profit organization based in Seattle, in the United States, and which conducts global health research on infectious diseases.\n\nIDRI was founded in 1993.\n\nIDRI is collaborating with the United States Agency for International Development to develop a malaria vaccine with the Walter Reed Army Institute of Research using Walter Reed's CelTOS malaria antigen in conjunction with IDRI's GLA-SE adjuvant.\n\nOn February 2012, IDRI launched the world’s first clinical trial of the visceral leishmaniasis vaccine. The vaccine is a recombinant form of two fused Leishmania parasite proteins with an adjuvant. Two phase 1 clinical trials with healthy volunteers are to be conducted. The first one takes place in Washington and is followed by a trial in India. The trials are funded by the Bill & Melinda Gates Foundation.\n"}
{"id": "27308924", "url": "https://en.wikipedia.org/wiki?curid=27308924", "title": "Institute for Health Metrics and Evaluation", "text": "Institute for Health Metrics and Evaluation\n\nThe Institute for Health Metrics and Evaluation (IHME) is a research institute working in the area of global health statistics and impact evaluation at the University of Washington in Seattle. The Institute is headed by Dr. Christopher J.L. Murray, a physician and health economist, and professor at the University of Washington Department of Global Health, which is part of the School of Medicine. IHME's goal, as stated on the Institute's website, is \"to identify the best strategies to build a healthier world. By measuring health, tracking program performance, finding ways to maximize health system impact, and developing innovative measurement systems, IHME provides a foundation for informed decision-making that ultimately will lead to better health globally\" IHME (2011). IHME conducts research and trains scientists, policymakers, and the public in health metrics concepts, methods, and tools. Its mission includes judging the effectiveness and efficacy of health initiatives and national health systems. IHME's work seeks to be complementary to the United Nations' work in the World Health Organization in that it shares many tasks but is independent from member countries.\n\nIHME gathers health-related data from all available sources. It develops innovative analytical tools to track trends in mortality, diseases, and risk factors, and capsulizes many of its research findings in data visualizations. It evaluates interventions such as vaccines, malaria control policies, cancer screenings, and birth care. To enable researchers to replicate IHME's work and to foster new research, IHME created the Global Health Data Exchange (GHDx) where methods and results are cataloged and freely accessible. IHME is also committed to expanding the field of health metrics by training students at the post-baccalaureate and post-graduate levels.\n\nIHME was launched in June 2007 based on a core grant of $105 million primarily funded by the Bill & Melinda Gates Foundation. Among its earliest projects was to produce new estimates of mortality rates, which were published in \"The Lancet\" in September 2007. The Institute updated these in 2010\nand again in 2014. Maternal, child, and adult mortality estimates have been published, as well.\nFounding board members included Chair Julio Frenk, Dean of the Harvard School of Public Health; Harvey Fineberg, President of the Institute of Medicine; Gro Harlem Brundtland, former Prime Minister of Norway; Tedros Adhanom Ghebreyesus, the Minister of Health for Ethiopia; K. Srinath Reddy, President of the Public Health Foundation of India; Tomris Turmen, President of the International Children's Center and Head of the Department of Pediatrics/Newborn Medicine at the University of Ankara Medical School in Ankara, Turkey; Lincoln Chen, President of the China Medical Board; Jane Halton, who has served as Secretary of the Department of Health and Ageing in Australia, as well as the Department of Finance; and David Roux, Co-Chief Executive of Silver Lake Partners.\n\nCurrent board members are Frenk; Fineberg; Chen; Halton; and Roux, in addition to Stephen J. Cucchiaro, Chief Investment Officer of Windhaven Investment Management; Sally Davies, Chief Medical Officer (CMO) for England; and John W. Stanton, managing director of Trilogy Partnership.\n\nIn 2011, IHME co-sponsored the first Global Health Metrics & Evaluation conference in Seattle with \"The Lancet\", London School of Hygiene & Tropical Medicine, Harvard School of Public Health, and University of Queensland School of Population Health.\n\nIn 2017, the Gates Foundation provided IHME with another $279 million grant.\n\nIHME also has launched policy reports on a wide range of topics, including a June 2010 report on child and maternal mortality. The findings were updated in 2014. In 2009, IHME launched its series of Financing Global Health policy reports. The initial report led to meetings with staff from the US House Foreign Affairs Committee and with a task force appointed by US President Barack Obama to guide the funding of his new Global Health Initiative. Annual updates have been published since then.\n\nRecent publications have included estimations of causes of death worldwide, the incidence of HIV, TB, and malaria, as well as obesity, cigarette smoking, heart disease, and small area estimation of diabetes rates in the United States. IHME has also worked with other organizations on projects. For example, IHME researchers helped create the 2010 WHO World Malaria Report, generating all the estimates for insecticide-treated nets. IHME has also collaborated on country-level research projects, including a partnership with the Kingdom of Saudi Arabia to help create a health surveillance system to track disease trends and inform policy. \nThere is a list of publications at IHME's website.\n\nIn the Global Burden of Diseases, Injuries, and Risk Factors (GBD) Study 2010, a worldwide consortium of 500 researchers, coordinated by IHME measured the impact of more than 290 health conditions and 67 health risk factors worldwide. The GBD enterprise produced estimates in 21 regions around the world for disability-adjusted life years by age and sex for the past two decades. Part of this research has involved conducting in-person surveys in several countries and gathering health information through a website survey. The team created a cause of death database that includes 60 years of data, or almost 800 million deaths. To illustrate the findings, IHME released a suite of interactive data visualizations, which are available to the public.\n\nThe aim is to allow policymakers and other decision-makers to \"compare the effects of different diseases – such as cancer versus depression – that kill people prematurely and cause ill health,\" to show disease trends over time, and to inform policy, IHME states on its website.\n\nIt has been labeled \"the most comprehensive review of the state of humanity's health ever undertaken.\"\n\nThe UK and China are among the countries working with IHME to generate subnational burden of disease estimates at the county and province levels.\n\nIn January 2014, IHME began releasing updates to the work, called the Global Burden of Diseases, Injuries, and Risk Factors (GBD) Study 2013. The work generated over 1 billion estimates of health outcomes. GBD estimates are now being updated annually.\n\nSome of the findings have been controversial. In 2012, IHME researchers estimated 1.2 million people died from malaria in 2010, double the WHO's estimate.\n\nThe Disease Control Priorities Network project generates cost-effectiveness estimates for a range of health interventions. A team of demographers, statisticians, economists, and other experts are studying how to improve the allocation of resources among interventions, technologies, hospitals, and other service delivery platforms. They are working in multiple countries, including the US, India, and South Africa.\nTheir cost-effectiveness work has revealed some hidden connections. For example, a 2010 report showed improving girls' education in poor countries is the most effective way to reduce child mortality, which was a surprise for some people.\n\nAn effort launched in 2011 called Access, Bottlenecks, Costs, and Equity (ABCE) involves collecting evidence and analyzing data to improve the cost-effectiveness and equity of health systems in Colombia, Ghana, India, Kenya, Lebanon, Uganda, and Zambia. The project examines four components that affect health care delivery: access (to health facilities), bottlenecks (limitations on the supply side), costs, and equity (across populations). The work includes in-depth facility surveys and inventories across a range of service delivery platforms; additional data is collected in countries with high HIV/AIDS burdens through exit interviews and chart extraction.\n\nA 2013 report concluded that neonatal and maternal mortality in Ghana could be best improved not with sophisticated maternity care but with better transportation infrastructure.\n\nThe Population Health Metrics Research Consortium created new methods for tracking health intervention coverage in low-resource settings. The methods have been used to measure mortality, causes of death, and incidence of major illnesses where data are incomplete. Researchers collected data in India, Mexico, the Philippines, and Tanzania.\n\nIHME's work on estimating mortality has been at times controversial. In 2009, IHME published a study on maternal mortality which some advocacy groups tried to suppress – worried that results showing a decline in mortality would make it harder to fund-raise. The WHO also initially disagreed with the new results, but later revised their estimates in agreement with those of IHME.\n\nThe Malaria Control Policy Assessment project evaluates the effectiveness of malaria-control interventions in Uganda and Zambia by analyzing their effect on child mortality and producing estimates at the national and local levels.\n\nIHME conducts US research, including estimates of mortality, life expectancy, risk factors, health disparities, and disease prevalence. IHME has compiled national and local health trends and integrated multiple data sources to monitor disparities in chronic diseases.\n\nA 2013 report, the State of US Health, looked at trends in premature deaths due to injury or disease, and demonstrated the major health threat stemming from behavioral risk factors such as poor diet and sedentary lifestyles. It concluded that dietary factors cause more deaths each year than cancer or smoking. The results included life expectancy trends broken down by state and county.\n\nFirst Lady Michelle Obama cited the research in her campaign to improve Americans' diets and increase their level of physical activity.\n\nA paper published in the journal Population Health Metrics in June 2011 showed that life expectancy was rising in some poorer US counties – especially in the South – a surprising result which was widely discussed.\n\nOther research projects include the Salud Mesoamérica 2015 Initiative, which focuses on inequalities in health outcomes and access in southern Mexico and Central America; Gavi Full Country Evaluations, which evaluates immunization programs in Bangladesh, India, Mozambique, Uganda and Zambia; and HealthRise, a partnership with Medtronic Philanthropy to evaluate programs targeting diabetes and heart disease, and sponsor small grants to make improvements.\n\nIn 2014, IHME announced the establishment of the University of Washington Center for Demography and Economics of Aging, funded by the National Institute on Aging (NIA). It is one of 14 NIA Demography Centers at leading universities and policy organizations around the United States.\n\nIn March 2011, IHME launched the Global Health Data Exchange (or GHDx), which indexes and hosts information about microdata, aggregated data, and research results with a focus on health-related and demographic datasets. At launch, the site listed about 1,000 datasets; as of 2015, there are more than 30,000. As part of a partnership with the Centers for Disease Control and Prevention (CDC), GHDx includes 35 years of CDC data on child and maternal health. GHDx uses the Drupal 7 open source content management system and Apache SOLR for search. The site includes visualization and GIS tools, and has been noted by the health and global health communities.\n\nIHME offers two types of global health fellowships, plus master's degrees and PhD programs.\n\nIHME receives core grant funding from the Bill & Melinda Gates Foundation and the state of Washington. The US Centers for Disease Control and Prevention (CDC); Inter-American Development Bank; Gavi, the Vaccine Alliance; the National Heart, Lung and Blood Institute; Kingdom of Saudi Arabia Ministry of Health; Medtronic Philanthropy; and the National Institute on Aging have also contributed funding through project grants and contracts.\n\nInitially, some within the World Health Organization had criticized IHME for trying to do the work that WHO already does. There had also been tension between UNICEF and IHME because a report from the latter showed \"lackluster progress\" on child death rates.\n\nThe 2010 Global Burden of Disease report was criticized for its lack of transparency of methods and data as well as its use of complex statistical methods to fill in data gaps when reliable statistics were unavailable. Thomas Bollyky, a senior fellow at the Council on Foreign Relations, called for more transparency. The report was also criticized for its use of verbal autopsies because many diseases have similar symptoms, leading to potential mistakes.\n\nIgor Rudan and Kit Yee Chan argue that the emergence of IHME introduced competition to the field of global health metrics, which was previously a field where WHO maintained a monopoly: \"The GBD initiative has emerged as a well-organised and rapidly growing collaboration that is now seriously challenging WHO's role in generating global health estimates\".\n\nRudan and Chan also note that IHME \"struggled to generate support, legitimacy, and acceptable for their findings\" after publishing the 2010 Global Burden of Disease Study, due to concerns of lack of transparency, as well as the existence of parallel estimates of disease burden from WHO.\n\nThe World Health Organization did not acknowledge the GBD 2010 estimates.\n\nThe Global Burden of Disease Study (GBD) 2013 expanded collaboration and increased transparency but \"[fell] short of allowing full independent replication of all results\".\n\n\n\n"}
{"id": "51236762", "url": "https://en.wikipedia.org/wiki?curid=51236762", "title": "International Biocontrol Manufacturers' Association", "text": "International Biocontrol Manufacturers' Association\n\nThe International Biocontrol Manufacturers' Association (IBMA) is the worldwide association of the biocontrol industry, with its head office in Brussels. \nThe association sponsors the Annual Biocontrol Industry Meeting held in Basel, Switzerland.\n\nIn 1995, the IBMA was founded in Brighton (England), whose founding president was Bernard Blum. In his honour the Bernard Blum Award was launched in 2015.\n\nThe IBMA presidents have been: Michel Guillon, Denise Munday, Owen Jones and Willem Ravensberg.\n\nThe association sees itself representing the manufacturers of biocontrol products mainly within the European Union, the OECD, and FAO.\n\nIn workshops, the experiences of the members is to be exchanged, in particular at the annual ABIM Congress in Basel.\n\nIn contrast to the chemical crop protection industry (Agricultural Industry Association) the IBMA members produce Bioeffectors, i.e. botanicals, pheromones, invertebrate biocontrol agents and micro-organisms as a basis for plant protection products. These biocontrol products against plant diseases and pests are created that can be used in the organic production of food as well as in IPM production systems.\n\nAlthough the products sold produce general Pflanzenvitalisierung, so the aim of the group is yet to fight specific diseases and pests in plants and food production with biological systems. In European politics promotion of organic vegetable production increases greatly. The organization makes a significant contribution with their members' products.\n\n"}
{"id": "5127022", "url": "https://en.wikipedia.org/wiki?curid=5127022", "title": "International Sanitary Conferences", "text": "International Sanitary Conferences\n\nThe International Sanitary Conferences were a series of 14 conferences, the first of them organized by the French Government in 1851 to standardize international quarantine regulations against the spread of cholera, plague, and yellow fever. In total 14 conferences took place from 1851 to 1938; the conferences played a major role in the formation of the World Health Organization in 1948.\n\nThe outbreak of the Second cholera pandemic in 1829, prompted European Governments to appoint medical missions to investigate the causes of the epidemic. Among others, the Royal Academy of Medicine of Paris in June 1831, sent Auguste Gérardin () and Paul Gaimard on medical mission to Russia, Prussia, and Austria.\n\nLater the Minister of Commerce of France, appointed the Secretary of the Conseil supérieur de la santé, P. de. Ségur-Dupeyron with the task of creating a report on the sanitary regulations\nof the Mediterranean countries. The report published in 1834, pointed to the differing quarantine requirements among the countries, and proposed to convene an international conference to standardise quarantine requirements against exotic diseases.\n\n\nThe first International Sanitary Conference opened in Paris on July 23, 1851. A total of twelve countries participated including Austria, Great Britain, Greece, Portugal, Russia, Spain, France, Turkey and the four Italian Powers of Papal States, Sardinia, Tuscany, and the Two Sicilies; each country being represented by a pair of a physician and a diplomat.\n\nThe Conference revolved around the question of whether or not cholera should be subject to quarantine regulations. The Papal States, Tuscany, the Two Sicilies, Spanish, Greek, and Tuscan delegates supported quarantine measures against cholera with Sardinia, Austria, Britain, and France opposing quarantine measures.\n\nThe Austrian medical delegate, G. M. Menis along with John Sutherland, the British\nmedical delegate and Anthony Perrier, the British diplomatic delegate were most vocal against quarantine measures with the Spanish medical delegate, Pedro F. Monlau () and the Russian medical delegate, Carlos O. R. Rosenberger in the opposite camp.\n\nThe Conference participants agreed on a draft Sanitary Convention and annexed draft International Sanitary\nRegulations consisting of 137 articles.\n\nThe second International Sanitary Conference opened in Paris on April 9, 1859. Except the Kingdom of the Two Sicilies, all twelve countries of the first Conference were present. The conference which lasted for five months, resulted in Austria, France, Great Britain, the Papal States, Portugal, Russia, Sardinia, and Spain signing the slightly amended \"draft convention\" (itself a combination of the convention and the annexed international sanitary\nregulations agreed on the first conference) with Greece and Turkey abstaining.\n\nThe third International Sanitary Conference opened in Constantinople on 13 February 1866 under the initiative of the French Government after the invasion of Europe in 1865 by cholera.\n\nThe fourth International Sanitary Conference opened in Vienna on 1 July 1874.\n\nThe sixth International Sanitary Conference opened in Rome on 20 May 1885 by the Italian government as a result of the reappearance of cholera in Egypt in 1883.\n\nThe eighth International Sanitary Conference opened in Dresden on 11 March 1893 under the initiative of the Austria-Hungarian government with nineteen European countries as participants.\n\nThe ninth International Sanitary Conference opened in Paris on 7 February 1894 with France as its convener and sixteen countries as participants.\n\nThe tenth International Sanitary Conference opened in Venice on 16 February 1897 with Austria-Hungary as its proposer and was the first such conference concerned exclusively with plague.\n\nThe eleventh International Sanitary Conference met in Paris from 10 October to 3 December 1903.\n\nThe twelfth International Sanitary Conference opened in Paris on 7 November 1911 and closed on 17 January 1912 with 41 countries being represented.\n\nThe thirteenth International Sanitary Conference was held in Paris from 10 May to 21 June 1926 with over 50 sovereign states as participants.\n\nThe fourteenth and last International Sanitary Conference was convened by the French Government at the instigation of Egypt on 28 October 1938 with representatives of almost 50 countries as participants.\n\n"}
{"id": "1078772", "url": "https://en.wikipedia.org/wiki?curid=1078772", "title": "Largest naval battle in history", "text": "Largest naval battle in history\n\nThe title of the \"largest naval battle in history\" is disputed between adherents of different criteria which include the numbers of personnel and/or vessels involved in the battle, and the total tonnage of the vessels involved. While battles fought in modern times are comparatively well-documented, the figures from those in pre-Renaissance times are generally believed to be exaggerated by contemporary chroniclers.\n\n\nNotes\n\nBibliography\n"}
{"id": "9318325", "url": "https://en.wikipedia.org/wiki?curid=9318325", "title": "List of longest wooden ships", "text": "List of longest wooden ships\n\nThis is a list of the world's longest wooden ships. The vessels are sorted by ship length including bowsprit, if known.\n\nFinding the world's longest wooden ship is not straightforward since there are several contenders, depending on which definitions are used. For example, some of these ships benefited from substantial iron or even steel components since the flexing of wood members can lead to significant leaking as the wood members become longer. Some of these ships were not very seaworthy, and a few sank either immediately after launch or soon thereafter. Some of the more recent large ships were never able or intended to leave their berths, and function as floating museums. Finally, not all of the claims to the title of the world's longest wooden ship are credible or verifiable.\n\nA further problem is that especially wooden ships have more than one \"length\". The most used measure in length for registering a ship is the \"length of the topmost deck\" – the \"length on deck\" (LOD) – 'measured from leading edge of stem post to trailing edge of stern post on deck level' or the \"length between perpendiculars\" (LPP, LBP) – 'measured from leading edge of stem post to trailing edge of stern post in the construction waterline (CWL)'. In this method of measuring bowsprit including jibboom and out-board part of spanker boom if any have both no effect on the ship's length. The longest length for comparing ships, the total \"overall\" length (LOA) based on sparred length, should be given if known.\n\nThe longest wooden ship ever built, the six-masted New England gaff schooner \"Wyoming\", had a \"total length\" of (measured from tip of jib boom (30 metres) to tip of spanker boom (27 metres) and a \"length on deck\" of . The -difference is due to her extremely long jib boom of her out-board length being .\n\n"}
{"id": "33064684", "url": "https://en.wikipedia.org/wiki?curid=33064684", "title": "List of research institutes in Seattle", "text": "List of research institutes in Seattle\n\nResearch institutes in Seattle include universities, corporations, nonprofit organizations, and other research groups doing research in Seattle.\n\n"}
{"id": "28822519", "url": "https://en.wikipedia.org/wiki?curid=28822519", "title": "National Commission for the Observance of World Population Year 1974", "text": "National Commission for the Observance of World Population Year 1974\n\nNational Commission for the Observance of World Population Year 1974 - the United Nations observed 1974 as \"World Population Year\". President Richard Nixon established the National Commission to aid U.S. participation in this United Nations observance. Neither the Commission nor any of its members participated in the August 1975 international conference held in Bucharest, Romania.\n\n\n\n\n\n\n"}
{"id": "22153", "url": "https://en.wikipedia.org/wiki?curid=22153", "title": "Nuclear power", "text": "Nuclear power\n\nNuclear power is the use of nuclear reactions that release nuclear energy to generate heat, which most frequently is then used in steam turbines to produce electricity in a nuclear power plant. \nNuclear power can be obtained from nuclear fission, nuclear decay and nuclear fusion. \nPresently, the vast majority of electricity from nuclear power is produced by nuclear fission of uranium and plutonium.\nNuclear decay processes are used in niche applications such as radioisotope thermoelectric generators.\nThe possibility of generating electricity from nuclear fusion is still at a research phase with no commercial applications.\nThis article mostly deals with nuclear fission power for electricity generation.\n\nNuclear power is one of the leading low carbon power generation methods of producing electricity.\nIn terms of total life-cycle greenhouse gas emissions per unit of energy generated, nuclear power has emission values comparable or lower than renewable energy.\nFrom the beginning of its commercialization in the 1970s, nuclear power prevented about 1.84 million air pollution-related deaths and the emission of about 64 billion tonnes of carbon dioxide equivalent that would have otherwise resulted from the burning of fossil fuels in thermal power stations.\n\nCivilian nuclear power supplied 2,488 terawatt hours (TWh) of electricity in 2017, equivalent to about 10% of global electricity generation.\nAs of April 2018, there are 449 civilian fission reactors in the world, with a combined electrical capacity of 394 gigawatt (GW). \nAdditionally, there are 58 reactors under construction and 154 reactors planned, with a combined capacity of 63 GW and 157 GW, respectively. Over 300 more reactors are proposed.\nMost of reactors under construction are of generation III reactor design, with the majority in Asia.\n\nThere is a social debate about nuclear power.\nProponents, such as the World Nuclear Association and Environmentalists for Nuclear Energy, contend that nuclear power is a safe, sustainable energy source that reduces carbon emissions.\nOpponents, such as Greenpeace and NIRS, contend that nuclear power poses many threats to people and the environment.\n\nSome accidents have occurred in nuclear power plants. \nThese include the Chernobyl disaster in the Soviet Union in 1986, the Fukushima Daiichi nuclear disaster in Japan in 2011, and the more contained Three Mile Island accident in the United States in 1979.\nThere have also been some nuclear submarine accidents.\nIn terms of lives lost per unit of energy generated, nuclear reactors have caused the lowest number of fatalities per unit of energy generated when compared to the other major energy producing methods.\nCoal, petroleum, natural gas and hydroelectricity each have caused a greater number of fatalities per unit of energy, due to air pollution and accidents.\n\nIn 1932 physicist Ernest Rutherford discovered that when lithium atoms were \"split\" by protons from a proton accelerator, immense amounts of energy were released in accordance with the principle of mass–energy equivalence. However, he and other nuclear physics pioneers Niels Bohr and Albert Einstein believed harnessing the power of the atom for practical purposes anytime in the near future was unlikely, with Rutherford labeling such expectations \"moonshine.\"\n\nThe same year, his doctoral student James Chadwick discovered the neutron, which was immediately recognized as a potential tool for nuclear experimentation because of its lack of an electric charge. Experimentation with bombardment of materials with neutrons led Frédéric and Irène Joliot-Curie to discover induced radioactivity in 1934, which allowed the creation of radium-like elements at much less the price of natural radium. Further work by Enrico Fermi in the 1930s focused on using slow neutrons to increase the effectiveness of induced radioactivity. Experiments bombarding uranium with neutrons led Fermi to believe he had created a new, transuranic element, which was dubbed hesperium.\n\nIn 1938, German chemists Otto Hahn and Fritz Strassmann, along with Austrian physicist Lise Meitner and Meitner's nephew, Otto Robert Frisch, conducted experiments with the products of neutron-bombarded uranium, as a means of further investigating Fermi's claims. \nThey determined that the relatively tiny neutron split the nucleus of the massive uranium atoms into two roughly equal pieces, contradicting Fermi. \nThis was an extremely surprising result: all other forms of nuclear decay involved only small changes to the mass of the nucleus, whereas this process—dubbed \"fission\" as a reference to biology—involved a complete rupture of the nucleus. \nNumerous scientists, including Leó Szilárd, who was one of the first, recognized that if fission reactions released additional neutrons, a self-sustaining nuclear chain reaction could result. Once this was experimentally confirmed and announced by Frédéric Joliot-Curie in 1939, scientists in many countries (including the United States, the United Kingdom, France, Germany, and the Soviet Union) petitioned their governments for support of nuclear fission research, just on the cusp of World War II, for the development of a nuclear weapon.\n\nIn the United States, where Fermi and Szilárd had both emigrated, the discovery of the nuclear chain reaction led to the creation of the first man-made reactor, known as Chicago Pile-1, which achieved criticality on December 2, 1942. \nThis work became part of the Manhattan Project, a massive secret U.S. government military project to make enriched uranium and by building large production reactors to produce (\"breed\") plutonium for use in the first nuclear weapons. \nThe United States would test an atom bomb in July 1945 with the Trinity test, and eventually two such weapons were used in the atomic bombings of Hiroshima and Nagasaki.\n\nIn August 1945, the first widely distributed account of nuclear energy, in the form of the pocketbook \"The Atomic Age\", discussed the peaceful future uses of nuclear energy and depicted a future where fossil fuels would go unused. \nNobel laureate Glenn Seaborg, who later chaired the Atomic Energy Commission, is quoted as saying \"there will be nuclear powered earth-to-moon shuttles, nuclear powered artificial hearts, plutonium heated swimming pools for SCUBA divers, and much more\".\n\nThe United Kingdom, Canada, and the USSR proceeded to research and develop nuclear industries over the course of the late 1940s and early 1950s. \nElectricity was generated for the first time by a nuclear reactor on December 20, 1951, at the EBR-I experimental station near Arco, Idaho, which initially produced about 100 kW. \nWork was also strongly researched in the United States on nuclear marine propulsion, with a test reactor being developed by 1953 (eventually, the USS Nautilus, the first nuclear-powered submarine, would launch in 1955). \nIn 1953, American President Dwight Eisenhower gave his \"Atoms for Peace\" speech at the United Nations, emphasizing the need to develop \"peaceful\" uses of nuclear power quickly. This was followed by the 1954 Amendments to the Atomic Energy Act which allowed rapid declassification of U.S. reactor technology and encouraged development by the private sector.\n\nOn June 27, 1954, the USSR's Obninsk Nuclear Power Plant became the world's first nuclear power plant to generate electricity for a power grid, and produced around 5 megawatts of electric power.\n\nLater in 1954, Lewis Strauss, then chairman of the United States Atomic Energy Commission (U.S. AEC, forerunner of the U.S. Nuclear Regulatory Commission and the United States Department of Energy) spoke of electricity in the future being \"too cheap to meter\". Strauss was very likely referring to hydrogen fusion —which was secretly being developed as part of Project Sherwood at the time—but Strauss's statement was interpreted as a promise of very cheap energy from nuclear fission. The U.S. AEC itself had issued far more realistic testimony regarding nuclear fission to the U.S. Congress only months before, projecting that \"costs can be brought down... [to]... about the same as the cost of electricity from conventional sources...\"\n\nIn 1955 the United Nations' \"First Geneva Conference\", then the world's largest gathering of scientists and engineers, met to explore the technology. In 1957 EURATOM was launched alongside the European Economic Community (the latter is now the European Union). The same year also saw the launch of the International Atomic Energy Agency (IAEA).\n\nThe world's first commercial nuclear power station, Calder Hall at Windscale, England, was opened in 1956 with an initial capacity of 50 MW (later 200 MW). The first commercial nuclear generator to become operational in the United States was the Shippingport Reactor (Pennsylvania, December 1957).\n\nOne of the first organizations to develop nuclear power was the U.S. Navy, for the purpose of propelling submarines and aircraft carriers. The first nuclear-powered submarine, , was put to sea in December 1954. As of 2016, the U.S. Navy submarine fleet is made up entirely of nuclear-powered vessels, with 75 submarines in service. Two U.S. nuclear submarines, and , have been lost at sea. As of 2016 the Russian Navy was estimated to have 61 nuclear submarines in service; eight Soviet and Russian nuclear submarines have been lost at sea. This includes the reactor accident in 1961 which resulted in 8 deaths and more than 30 other people were over-exposed to radiation. \nThe reactor accident in 1968 resulted in 9 fatalities and 83 other injuries. \nMoreover, sank twice, but was raised after each incident. Several serious nuclear and radiation accidents have involved nuclear submarine mishaps.\n\nThe U.S. Army also had a nuclear power program, beginning in 1954. The SM-1 Nuclear Power Plant, at Fort Belvoir, Virginia, was the first power reactor in the United States to supply electrical energy to a commercial grid (VEPCO), in April 1957, before Shippingport. The SL-1 was a U.S. Army experimental nuclear power reactor at the National Reactor Testing Station in eastern Idaho. It underwent a steam explosion and meltdown in January 1961, which killed its three operators. In the Soviet Union at the Mayak Production Association facility there were a number of accidents, including a 1957 explosion that contaminated a huge territory in the eastern Urals and caused numerous deaths and injuries. The Soviet government kept this accident secret for about 30 years. The event was eventually rated at 6 on the seven-level INES scale (third in severity only to the disasters at Chernobyl and Fukushima).\n\nInstalled nuclear capacity initially rose relatively quickly, rising from less than 1 gigawatt (GW) in 1960 to 100 GW in the late 1970s, and 300 GW in the late 1980s. Since the late 1980s worldwide capacity has risen much more slowly, reaching 366 GW in 2005. Between around 1970 and 1990, more than 50 GW of capacity was under construction (peaking at over 150 GW in the late 1970s and early 1980s) — in 2005, around 25 GW of new capacity was planned. More than two-thirds of all nuclear plants ordered after January 1970 were eventually cancelled. A total of 63 nuclear units were canceled in the United States between 1975 and 1980.\n\nDuring the 1970s and 1980s rising economic costs (related to extended construction times largely due to regulatory changes and pressure-group litigation) and falling fossil fuel prices made nuclear power plants then under construction less attractive. In the 1980s (U.S.) and 1990s (Europe), flat load growth and electricity liberalization also made the addition of large new baseload capacity unattractive.\n\nThe 1973 oil crisis had a significant effect on countries, such as France and Japan, which had relied more heavily on oil for electric generation (39% and 73% respectively) to invest in nuclear power.\n\nSome local opposition to nuclear power emerged in the early 1960s, and in the late 1960s some members of the scientific community began to express their concerns. These concerns related to nuclear accidents, nuclear proliferation, high cost of nuclear power plants, nuclear terrorism and radioactive waste disposal. In the early 1970s, there were large protests about a proposed nuclear power plant in Wyhl, Germany. The project was cancelled in 1975 and anti-nuclear success at Wyhl inspired opposition to nuclear power in other parts of Europe and North America. By the mid-1970s anti-nuclear activism had moved beyond local protests and politics to gain a wider appeal and influence, and nuclear power became an issue of major public protest. Although it lacked a single co-ordinating organization, and did not have uniform goals, the movement's efforts gained a great deal of attention. In some countries, the nuclear power conflict \"reached an intensity unprecedented in the history of technology controversies\". \nIn France, between 1975 and 1977, some 175,000 people protested against nuclear power in ten demonstrations. In West Germany, between February 1975 and April 1979, some 280,000 people were involved in seven demonstrations at nuclear sites. Several site occupations were also attempted. In the aftermath of the Three Mile Island accident in 1979, some 120,000 people attended a demonstration against nuclear power in Bonn. In May 1979, an estimated 70,000 people, including then governor of California Jerry Brown, attended a march and rally against nuclear power in Washington, D.C. Anti-nuclear power groups emerged in every country that has had a nuclear power programme.\n\nHealth and safety concerns, the 1979 accident at Three Mile Island, and the 1986 Chernobyl disaster played a part in stopping new plant construction in many countries, although the public policy organization, the Brookings Institution states that new nuclear units, at the time of publishing in 2006, had not been built in the United States because of soft demand for electricity, and cost overruns on nuclear plants due to regulatory issues and construction delays. By the end of the 1970s it became clear that nuclear power would not grow nearly as dramatically as once believed. Eventually, more than 120 reactor orders in the United States were ultimately cancelled and the construction of new reactors ground to a halt. A cover story in the February 11, 1985, issue of \"Forbes\" magazine commented on the overall failure of the U.S. nuclear power program, saying it \"ranks as the largest managerial disaster in business history\".\n\nUnlike the Three Mile Island accident, the much more serious Chernobyl accident did not increase regulations affecting Western reactors since the Chernobyl reactors were of the problematic RBMK design only used in the Soviet Union, for example lacking \"robust\" containment buildings. Many of these RBMK reactors are still in use today. However, changes were made in both the reactors themselves (use of a safer enrichment of uranium) and in the control system (prevention of disabling safety systems), amongst other things, to reduce the possibility of a duplicate accident.\n\nAn international organization to promote safety awareness and professional development on operators in nuclear facilities was created: World Association of Nuclear Operators (WANO).\n\nOpposition in Ireland and Poland prevented nuclear programs there, while Austria (1978), Sweden (1980) and Italy (1987) (influenced by Chernobyl) voted in referendums to oppose or phase out nuclear power. In July 2009, the Italian Parliament passed a law that cancelled the results of an earlier referendum and allowed the immediate start of the Italian nuclear program. \nAfter the Fukushima Daiichi nuclear disaster a one-year moratorium was placed on nuclear power development, followed by a referendum in which over 94% of voters (turnout 57%) rejected plans for new nuclear power.\n\nSince about 2001 the term \"nuclear renaissance\" has been used to refer to a possible nuclear power industry revival, driven by rising fossil fuel prices and new concerns about meeting greenhouse gas emission limits. \nSince commercial nuclear energy began in the mid-1950s, 2008 was the first year that no new nuclear power plant was connected to the grid, although two were connected in 2009.\n\nFollowing the Tōhoku earthquake on 11 March 2011, one of the largest earthquakes ever recorded, and a subsequent tsunami off the coast of Japan, the Fukushima Daiichi Nuclear Power Plant suffered multiple core meltdowns due to failure of the emergency cooling system for lack of electricity supply. This resulted in the most serious nuclear accident since the Chernobyl disaster.\n\nThe Fukushima Daiichi nuclear accident prompted a re-examination of nuclear safety and nuclear energy policy in many countries and raised questions among some commentators over the future of the renaissance.\nGermany approved plans to close all its reactors by 2022, and Italy re-affirmed its ban on nuclear power in a referendum. \nChina, Switzerland, Israel, Malaysia, Thailand, United Kingdom, and the Philippines reviewed their nuclear power programs.\n\nIn 2011 the International Energy Agency halved its prior estimate of new generating capacity to be built by 2035. \nNuclear power generation had the biggest ever fall year-on-year in 2012, with nuclear power plants globally producing 2,346 TWh of electricity, a drop of 7% from 2011. \nThis was caused primarily by the majority of Japanese reactors remaining offline that year and the permanent closure of eight reactors in Germany.\n\nThe Fukushima Daiichi nuclear accident sparked controversy about the importance of the accident and its effect on nuclear's future. \nThe crisis prompted countries with nuclear power to review the safety of their reactor fleet and reconsider the speed and scale of planned nuclear expansions. \nIn 2011, \"The Economist\" opined that nuclear power \"looks dangerous, unpopular, expensive and risky\", and that \"it is replaceable with relative ease and could be forgone with no huge structural shifts in the way the world works\". \nEarth Institute Director Jeffrey Sachs disagreed, claiming combating climate change would require an expansion of nuclear power.\nInvestment banks were also critical of nuclear soon after the accident.\n\nIn September 2011, German engineering giant Siemens announced it will withdraw entirely from the nuclear industry as a response to the Fukushima accident.\n\nIn February 2012, the United States Nuclear Regulatory Commission approved the construction of two additional reactors at the Vogtle Electric Generating Plant, the first reactors to be approved in over 30 years since the Three Mile Island accident.\nIn October 2016, Watts Bar 2 became the first new United States reactor to enter commercial operation since 1996.\n\nIn 2013 Japan signed a deal worth $22 billion, in which Mitsubishi Heavy Industries would build four modern \"Atmea\" reactors for Turkey. \nIn August 2015, following 4 years of near zero fission-electricity generation, Japan began restarting its nuclear reactors, after safety upgrades were completed, beginning with Sendai Nuclear Power Plant.\n\nBy 2015, the IAEA's outlook for nuclear energy had become more promising. \n\"Nuclear power is a critical element in limiting greenhouse gas emissions,\" the agency noted, and \"the prospects for nuclear energy remain positive in the medium to long term despite a negative impact in some countries in the aftermath of the [Fukushima-Daiichi] accident...it is still the second-largest source worldwide of low-carbon electricity. \nAnd the 72 reactors under construction at the start of last year were the most in 25 years.\"\nAccording to the World Nuclear Association, as of 2015 the global trend was for new nuclear power stations coming online to be balanced by the number of old plants being retired.\n\nAs of 2015, 441 reactors had a worldwide net electric capacity of 382,9 GW, with 67 new nuclear reactors under construction.\nOver half of the 67 total being built were in Asia, with 28 in China, where there is an urgent need to control pollution from coal plants.\nEight new grid connections were completed by China in 2015.\n\nAs of 2018, there are over 150 nuclear reactors planned including 50 under construction. However, while investment on upgrades of existing plant and life-time extensions continues, investment in new nuclear is declining, reaching a 5-year-low in 2017. \n\nIn 2015, the International Energy Agency reported that the Fukushima accident had a strongly negative effect on nuclear power, yet nuclear power prospects are positive in the medium to long term mainly thanks to new construction in Asia.\nIn 2016, the U.S. Energy Information Administration projected for its “base case” that world nuclear power generation would increase from 2,344 terawatt hours (TWh) in 2012 to 4,501 TWh in 2040. \nMost of the predicted increase was expected to be in Asia.\n\nThe future of nuclear power varies greatly between countries, depending on government policies. \nSome countries, many of them in Europe, such as Germany, Belgium, and Lithuania, have adopted policies of nuclear power phase-out. \nAt the same time, some Asian countries, such as China and India, have committed to rapid expansion of nuclear power. \nMany other countries, such as the United Kingdom and the United States, have policies in between. \nJapan generated about 30% of its electricity from nuclear power before the Fukushima accident.\nIn 2015 the Japanese government committed to the aim of restarting its fleet of 40 reactors by 2030 after safety upgrades, and to finish the construction of the Generation III Ōma Nuclear Power Plant. \nThis would mean that approximately 20% of electricity would come from nuclear power by 2030.\nAs of 2018, some reactors have restarted commercial operation following inspections and upgrades with new regulations. \nWhile South Korea has a large nuclear power industry, the new government in 2017, partly influenced by a large anti-nuclear movement, committed to halting nuclear development and to gradually phase out nuclear power as reactors that are now operating or under construction close after 40 years of operations.\n\nThe nuclear power industry in western nations have a history of construction delays, cost overruns, plant cancellations, and nuclear safety issues, despite significant government subsidies and support.\nThese problems are related to very strict safety requirements, uncertain regulatory environment, slow rate of construction, and large stretches of time with no nuclear construction and consequent loss of know-how.\nCommentators therefore argue that nuclear power is impractical in western countries because of high costs, popular opposition, and regulatory uncertainty.\nRecent financial problems of western nuclear companies, most prominently the bankruptcy of Westinghouse in March 2017 because of US$9 billion of losses from nuclear construction projects in the United States, suggest a shift to the East, as the dominant exporter and designer of nuclear fuel and reactors.\n\nThe greatest new build activity is occurring in Asian countries like South Korea, India and China. \nIn March 2016, China had 30 reactors in operation, 24 under construction and plans to build more.\n\nIn 2016 the BN-800 sodium cooled fast reactor in Russia, began commercial electricity generation, while plans for a BN-1200 were initially conceived the future of the fast reactor program in Russia awaits the results from MBIR, an under construction multi-loop Generation IV research facility for testing the chemically more inert lead, lead-bismuth and gas coolants, it will similarly run on recycled MOX (mixed uranium and plutonium oxide) fuel. An on-site pyrochemical processing, closed fuel-cycle facility, is planned, to reduce the necessity for a growth in uranium mining and exploration. In 2017 the manufacture program for the reactor commenced with the facility open to collaboration under the \"International Project on Innovative Nuclear Reactors and Fuel Cycle\", it has a construction schedule, that includes an operational start in 2020. As planned, it will be the world's most-powerful research reactor.\n\nIn the United States, licenses of almost half of the operating nuclear reactors have been extended to 60 years. \nThe U.S. NRC and the U.S. Department of Energy have initiated research into Light water reactor sustainability which is hoped will lead to allowing extensions of reactor licenses beyond 60 years, provided that safety can be maintained, to increase energy security and preserve low-carbon generation sources. \nResearch into nuclear reactors that can last 100 years, known as Centurion Reactors, is being conducted.\n\nAccording to the World Nuclear Association, globally during the 1980s one new nuclear reactor started up every 17 days on average, and in the year 2015 it was estimated that this rate could in theory eventually increase to one every 5 days, although no plans exist for that.\n\nJust as many conventional thermal power stations generate electricity by harnessing the thermal energy released from burning fossil fuels, nuclear power plants convert the energy released from the nucleus of an atom via nuclear fission that takes place in a nuclear reactor. When a neutron hits the nucleus of a uranium-235 or plutonium atom, it can split the nucleus into two smaller nuclei. The reaction is called nuclear fission. The fission reaction releases energy and neutrons. The released neutrons can hit other uranium or plutonium nuclei, causing new fission reactions, which release more energy and more neutrons. This is called a chain reaction. The reaction rate is controlled by control rods that absorb excess neutrons. The controllability of nuclear reactors depends on the fact that a small fraction of neutrons resulting from fission are delayed. The time delay between the fission and the release of the neutrons slows down changes in reaction rates and gives time for moving the control rods to adjust the reaction rate.\n\nA fission nuclear power plant is generally composed of a nuclear reactor, in which the nuclear reactions generating heat take place; a cooling system, which removes the heat from inside the reactor; a steam turbine, which transforms the heat in mechanical energy; an electric generator, which transform the mechanical energy into electrical energy.\n\nNuclear fission power stations, excluding the contribution from naval nuclear fission reactors, provided 11% of the world's electricity in 2012, somewhat less than that generated by hydro-electric stations at 16%. \nSince electricity accounts for about 25% of humanity's energy usage with the majority of the rest coming from fossil fuel reliant sectors such as transport, manufacture and home heating, nuclear fission's contribution to the global final energy consumption was about 2.5%. \nThis is a little more than the combined global electricity production from wind, solar, biomass and geothermal power, which together provided 2% of global final energy consumption in 2014.\n\nIn 2013, the IAEA reported that there were 437 operational civil fission-electric reactors in 31 countries, although not every reactor was producing electricity. \nIn addition, there were approximately 140 naval vessels using nuclear propulsion in operation, powered by about 180 reactors.\n\nNuclear power's share of global electricity production has fallen from 16.5% in 1997 to about 10% in 2017, in large part because the economics of nuclear power have become more difficult.\n\nRegional differences in the use of nuclear power are large.\nThe United States produces the most nuclear energy in the world, with nuclear power providing 19% of the electricity it consumes, while France produces the highest percentage of its electrical energy from nuclear reactors—80% as of 2006. \nIn the European Union as a whole nuclear power provides 30% of the electricity. \nNuclear power is the single largest low-carbon electricity source in the United States, and accounts for two-thirds of the European Union's low-carbon electricity. \nNuclear energy policy differs among European Union countries, and some, such as Austria, Estonia, Ireland and Italy, have no active nuclear power stations. \nIn comparison, France has a large number of nuclear reactors in use and nuclear power supplied over 70% of its electricity in 2017.\n\nMany military and some civilian (such as some icebreakers) ships use nuclear marine propulsion. \nA few space vehicles have been launched using nuclear reactors: 33 reactors belong to the Soviet RORSAT series and one was the American SNAP-10A.\n\nInternational research is continuing into additional uses of process heat such as hydrogen production (in support of a hydrogen economy), for desalinating sea water, and for use in district heating systems.\n\nThe nuclear industry consists of a number of companies, organizations, governmental and international bodies.\nThe main fields of the industry include nuclear reactor building and operation; uranium mining and nuclear fuel production; nuclear waste storage and processing; research and development.\nOther components of the nuclear industry include nuclear regulators and nuclear industry national and international associations.\n\nThe economics of new nuclear power plants is a controversial subject, since there are diverging views on this topic, and multibillion-dollar investments depend on the choice of an energy source. \nNuclear power plants typically have high capital costs for building the plant, but low fuel costs. \nComparison with other power generation methods is strongly dependent on assumptions about construction timescales and capital financing for nuclear plants as well as the future costs of fossil fuels and renewables as well as for energy storage solutions for intermittent power sources. \nCost estimates also need to take into account plant decommissioning and nuclear waste storage costs. \nOn the other hand, measures to mitigate global warming, such as a carbon tax or carbon emissions trading, may favor the economics of nuclear power.\n\nAnalysis of the economics of nuclear power must also take into account who bears the risks of future uncertainties. \nTo date all operating nuclear power plants were developed by state-owned or regulated electric utility monopolies where many of the risks associated with construction costs, operating performance, fuel price, accident liability and other factors were borne by consumers rather than suppliers. \nIn addition, because the potential liability from a nuclear accident is so great, the full cost of liability insurance is generally limited/capped by the government, which the U.S. Nuclear Regulatory Commission concluded constituted a significant subsidy. \nMany countries have now liberalized the electricity market where these risks, and the risk of cheaper competitors emerging before capital costs are recovered, are borne by plant suppliers and operators rather than consumers, which leads to a significantly different evaluation of the economics of new nuclear power plants.\n\nAlthough nuclear power plants can vary their output, the electricity is generally less favorably priced when doing so. \nNuclear power plants are therefore typically run as much as possible to keep the cost of the generated electrical energy as low as possible, supplying mostly base-load electricity.\n\nInternationally the price of nuclear plants rose 15% annually in 1970–1990. \nYet, nuclear power has total costs in 2012 of about $96 per megawatt hour (MWh), most of which involves capital construction costs, compared with solar power at $130 per MWh, and natural gas at the low end at $64 per MWh.\nFollowing the 2011 Fukushima Daiichi nuclear disaster, costs are expected to increase for then-operating and new nuclear power plants, due to increased requirements for on-site spent fuel management and elevated design basis threats.\n\nA nuclear reactor is only part of the fuel life-cycle for nuclear power. \nThe process starts with mining (see \"Uranium mining\"). \nUranium mines are underground, open-pit, or in-situ leach mines. \nIn any case, the uranium ore is extracted, usually converted into a stable and compact form such as yellowcake, and then transported to a processing facility. \nHere, the yellowcake is converted to uranium hexafluoride, which is then generally enriched using various techniques. \nSome reactor designs can also use natural uranium without enrichment.\nThe enriched uranium, containing more than the natural 0.7% uranium-235, is generally used to make rods of the proper composition and geometry for the particular reactor that the fuel is destined for. \nIn modern light-water reactors the fuel rods will spend about 3 operational cycles (typically 6 years total now) inside the reactor, generally until about 3% of their uranium has been fissioned, then they will be moved to a spent fuel pool where the short lived isotopes generated by fission can decay away. \nAfter about 5 years in a spent fuel pool the spent fuel is radioactively and thermally cool enough to handle, and it can be moved to dry storage casks or reprocessed.\n\nUranium is a fairly common element in the Earth's crust: it is approximately as common as tin or germanium, and is about 40 times more common than silver. \nUranium is present in trace concentrations in most rocks, dirt, and ocean water, but can be economically extracted only where it is present in high concentrations. \nStill, as of 2011 the world's measured resources of uranium, economically recoverable at the arbitrary price ceiling of 130 USD/kg, were enough to last for between 70 and 100 years.\n\nAccording to the OECD in 2006, there was an expected 85 years worth of uranium in already identified resources at the then-current utilization rates. In 2007, the OECD estimated 670 years of economically recoverable uranium in total conventional resources and phosphate ores assuming the then-current use rate. The OECD's red book of 2011 said that known uranium resources had grown by 12.5% since 2008 due to increased exploration, with this increase translating into greater than a century of uranium available if the rate of use were to continue at the 2011 level.\n\nLight water reactors make relatively inefficient use of nuclear fuel, mostly fissioning only the very rare uranium-235 isotope. Nuclear reprocessing can make this waste reusable. Newer Generation III reactors also achieve a more efficient use of the available resources than the generation II reactors which make up the vast majority of reactors worldwide.\nWith a pure fast reactor fuel cycle with a burn up of all the Uranium and actinides (which presently make up the most hazardous substances in nuclear waste), there is an estimated 160,000 years worth of Uranium in total conventional resources and phosphate ore at the price of 60–100 US$/kg.\n\nUnconventional uranium resources also exist.\nUranium is naturally present in seawater at a concentration of about 3 micrograms per liter, with 4.5 billion tons of uranium considered present in seawater at any time. \nIn 2012 it was estimated that this fuel source could be extracted at 10 times the current price of uranium. \n\nIn 2014, with the advances made in the efficiency of seawater uranium extraction, it was suggested that it would be economically competitive to produce fuel for light water reactors from seawater if the process was implemented at large scale. \nUranium extracted on an industrial scale from seawater would constantly be replenished by both river erosion of rocks and the natural process of uranium dissolved from the surface area of the ocean floor, both of which maintain the solubility equilibria of seawater concentration at a stable level. \nSome commentators have argued that this strengthens the case for Nuclear power to be considered a renewable energy.\n\nAs opposed to light water reactors which use uranium-235 (0.7% of all natural uranium), fast breeder reactors use uranium-238 (99.3% of all natural uranium). In 2006 it was estimated that with seawater extraction, there was likely some five billion years' worth of uranium-238 for use in these power plants.\n\nBreeder technology has been used in several reactors, but the high cost of reprocessing fuel safely, at 2006 technological levels, requires uranium prices of more than US$200/kg before becoming justified economically. \nBreeder reactors are however being pursued as they have the potential to burn up all of the actinides in the present inventory of nuclear waste while also producing power and creating additional quantities of fuel for more reactors via the breeding process.\n\nAs of 2017, there are only two breeder reactors producing commercial power: the BN-600 reactor and the BN-800 reactor, both in Russia.\nThe BN-600, with a capacity of 600 MW, was built in 1980 in Beloyarsk and is planned to produce power until 2025.\nThe BN-800 is an updated version of the BN-600, and started operation in 2014 with a net electrical capacity of 789 MW.\nThe technical design of a yet larger breeder, the BN-1200 reactor was originally scheduled to be finalized in 2013, with construction slated for 2015 but has since been delayed. \n\nThe Phénix breeder reactor in France was powered down in 2009 after 36 years of operation.\nJapan's Monju breeder reactor restarted (having been shut down in 1995) in 2010 for 3 months, but shut down again after equipment fell into the reactor during reactor checkups.\nThe reactor was decommissioned in 2017.\n\nBoth China and India are building breeder reactors. \nThe Indian 500 MWe Prototype Fast Breeder Reactor is in the commissioning phase, with plans to build five more by 2020. \nThe China Experimental Fast Reactor began operating in 2011.\n\nAnother alternative to fast breeders is thermal breeder reactors that use uranium-233 bred from thorium as fission fuel in the thorium fuel cycle.\nThorium is about 3.5 times more common than uranium in the Earth's crust, and has different geographic characteristics.\nThis would extend the total practical fissionable resource base by 450%. \nIndia's three-stage nuclear power programme features the use of a thorium fuel cycle in the third stage, as it has abundant thorium reserves but little uranium.\n\nThe most important waste stream from nuclear power plants is spent nuclear fuel. \nIt is primarily composed of unconverted uranium as well as significant quantities of transuranic actinides (plutonium and curium, mostly). \nIn addition, about 3% of it is fission products from nuclear reactions. \nThe actinides (uranium, plutonium, and curium) are responsible for the bulk of the long-term radioactivity, whereas the fission products are responsible for the bulk of the short-term radioactivity.\n\nHigh-level radioactive waste management concerns management and disposal of highly radioactive materials created during production of nuclear power. The technical issues in accomplishing this are daunting, due to the extremely long periods radioactive wastes remain deadly to living organisms. Of particular concern are two long-lived fission products, Technetium-99 (half-life 220,000 years) and Iodine-129 (half-life 15.7 million years), which dominate spent nuclear fuel radioactivity after a few thousand years. The most troublesome transuranic elements in spent fuel are Neptunium-237 (half-life two million years) and Plutonium-239 (half-life 24,000 years). Consequently, high-level radioactive waste requires sophisticated treatment and management to successfully isolate it from the biosphere. This usually necessitates treatment, followed by a long-term management strategy involving permanent storage, disposal or transformation of the waste into a non-toxic form.\n\nGovernments around the world are considering a range of waste management and disposal options, usually involving deep-geologic placement, although there has been limited progress toward implementing long-term waste management solutions. This is partly because the timeframes in question when dealing with radioactive waste range from 10,000 to millions of years, according to studies based on the effect of estimated radiation doses.\n\nSome proposed nuclear reactor designs however such as the American Integral Fast Reactor and the Molten salt reactor can use the nuclear waste from light water reactors as a fuel, transmutating it to isotopes that would be safe after hundreds, instead of tens of thousands of years. This offers a potentially more attractive alternative to deep geological disposal.\n\nAnother possibility is the use of thorium in a reactor especially designed for thorium (rather than mixing in thorium with uranium and plutonium (i.e. in existing reactors). Used thorium fuel remains only a few hundreds of years radioactive, instead of tens of thousands of years.\n\nSince the fraction of a radioisotope's atoms decaying per unit of time is inversely proportional to its half-life, the relative radioactivity of a quantity of buried human radioactive waste would diminish over time compared to natural radioisotopes (such as the decay chains of 120 trillion tons of thorium and 40 trillion tons of uranium which are at relatively trace concentrations of parts per million each over the crust's 3 * 10 ton mass). For instance, over a timeframe of thousands of years, after the most active short half-life radioisotopes decayed, burying U.S. nuclear waste would increase the radioactivity in the top 2000 feet of rock and soil in the United States (10 million km) by ≈ 1 part in 10 million over the cumulative amount of natural radioisotopes in such a volume, although the vicinity of the site would have a far higher concentration of artificial radioisotopes underground than such an average.\n\nThe nuclear industry also produces a large volume of low-level radioactive waste in the form of contaminated items like clothing, hand tools, water purifier resins, and (upon decommissioning) the materials of which the reactor itself is built. Low-level waste can be stored on-site until radiation levels are low enough to be disposed as ordinary waste, or it can be sent to a low-level waste disposal site.\n\nIn countries with nuclear power, radioactive wastes account for less than 1% of total industrial toxic wastes, much of which remains hazardous for long periods. Overall, nuclear power produces far less waste material by volume than fossil-fuel based power plants. Coal-burning plants are particularly noted for producing large amounts of toxic and mildly radioactive ash due to concentrating naturally occurring metals and mildly radioactive material from the coal. A 2008 report from Oak Ridge National Laboratory concluded that coal power actually results in more radioactivity being released into the environment than nuclear power operation, and that the population effective dose equivalent, or dose to the public from radiation from coal plants is 100 times as much as from the operation of nuclear plants. \nAlthough coal ash is much less radioactive than spent nuclear fuel on a weight per weight basis, coal ash is produced in much higher quantities per unit of energy generated, and this is released directly into the environment as fly ash, whereas nuclear plants use shielding to protect the environment from radioactive materials, for example, in dry cask storage vessels.\n\nDisposal of nuclear waste is often said to be the among the most problematic aspects of the industry. \nPresently, waste is mainly stored at individual reactor sites and there are over 430 locations around the world where radioactive material continues to accumulate. \nSome experts suggest that centralized underground repositories which are well-managed, guarded, and monitored, would be a vast improvement. \nThere is an \"international consensus on the advisability of storing nuclear waste in deep geological repositories\", with the lack of movement of nuclear waste in the 2 billion year old natural nuclear fission reactors in Oklo, Gabon being cited as \"a source of essential information today.\"\n\nThere are no commercial scale purpose built underground high-level waste repositories in operation. However, in Finland the Onkalo spent nuclear fuel repository is under construction. Construction license for the world's first spent fuel repository was granted in 2015. The Waste Isolation Pilot Plant (WIPP) in New Mexico has been taking nuclear waste since 1999 from production reactors, but as the name suggests is a research and development facility. \nIn 2014 a radiation leak caused by violations in the use of chemically reactive packaging brought renewed attention to the need for quality control management, along with some initial calls for more R&D into the alternative methods of disposal for radioactive waste and spent fuel. \nIn 2017, the facility was formally reopened after three years of investigation and cleanup, with the resumption of new storage taking place later that year.\n\nToday's moderated/\"thermal reactors\" primarily run on the once-thru fuel cycle though they can reuse once-thru reactor-grade plutonium to a limited degree in the form of mixed-oxide or MOX fuel, which is a routine commercial practice in most countries outside the US as it increases the sustainability of nuclear fission and lowers the volume of high level nuclear waste. \nReprocessing can potentially recover up to 95% of the remaining uranium and plutonium in spent nuclear fuel, putting it into new mixed oxide fuel. This produces a reduction in long term radioactivity within the remaining waste, since this is largely short-lived fission products, and reduces its volume by over 90%. Reprocessing of civilian fuel from power reactors is currently done in Europe, Russia, Japan, and India. The full potential of reprocessing had not been achieved as of 2013 because it requires breeder reactors, which were not commercially available at that time.\n\nNuclear reprocessing reduces the volume of high-level waste, but by itself does not reduce radioactivity or heat generation and therefore does not eliminate the need for a geological waste repository. Reprocessing has been politically controversial because of the potential to contribute to nuclear proliferation, the potential vulnerability to nuclear terrorism, the political challenges of repository siting (a problem that applies equally to direct disposal of spent fuel), and because of its high cost compared to the once-through fuel cycle. Several different methods for reprocessing been tried, but many have had safety and practicality problems which have led to their discontinuation.\n\nIn the United States, the Obama administration stepped back from President Bush's plans for commercial-scale reprocessing and reverted to a program focused on reprocessing-related scientific research. Reprocessing is not allowed in the U.S. In the United States, spent nuclear fuel is currently all treated as waste. A major recommendation of the Blue Ribbon Commission on America's Nuclear Future was that \"the United States should undertake an integrated nuclear waste management program that leads to the timely development of one or more permanent deep geological facilities for the safe disposal of spent fuel and high-level nuclear waste\".\n\nUranium enrichment produces large amounts of depleted uranium (DU), which consists of U-238 with most of the easily fissile U-235 isotope removed. \nU-238 is a tough metal with several commercial uses including aircraft production, radiation shielding, and armor, as it has a higher density than lead. \nDepleted uranium is also controversially used in munitions; DU penetrators (bullets or APFSDS tips) \"self sharpen\", due to uranium's tendency to fracture along shear bands.\n\nNuclear reactors have three unique characteristics that affect their safety, as compared to other power plants. First, a very large amount of radioactive materials is present in a nuclear reactor. Their release to the environment could be hazardous. Second, a reactor has no \"natural\" power level. Rapid power increase is possible if the chain reaction cannot be controlled. Third, the fission products in the reactor continue to generate a significant amount of decay heat even after the chain reaction has stopped. If the heat cannot be removed from the reactor, the fuel rods may overheat and release radioactive materials. These three characteristics have to be taken into account when designing nuclear reactors. Multiple barriers separate the radioactive materials from the environment. Reactors are designed so that natural feedback mechanisms prevent an uncontrolled increase of the reactor power. Emergency cooling systems can remove the decay heat from the reactor in case the normal cooling systems fail.\n\nSome serious nuclear and radiation accidents have occurred. \nThe severity of nuclear accidents is generally classified using the International Nuclear Event Scale (INES) introduced by the International Atomic Energy Agency (IAEA).\nThe scale ranks anomalous events or accidents on a scale from 0 (a deviation from normal operation that pose no safety risk) to 7 (a major accident with widespread effects). \nThere have been 3 accidents of level 5 or higher in the civilian nuclear power industry, two of which, the Chernobyl accident and the Fukushima accident, are ranked at level 7.\nThe Chernobyl accident in 1986 caused approximately 50 deaths from direct and indirect effects, and many more serious injuries.\nThe exact death toll due to indirect effects of the widespread radiation contamination is difficult to measure, and depends on the assumptions used. \nSome studies put the total death toll of the Chernobyl accident from indirect effects much higher, in the order of thousands of people.\nThe Fukushima Daiichi nuclear accident was caused by the 2011 Tohoku earthquake and tsunami. \nThe accident has not caused any radiation related deaths, but resulted in radioactive contamination of surrounding areas.\nThe difficult Fukushima disaster cleanup will take 40 or more years, and is expected to cost tens of billions of dollars.\nThe Three Mile Island accident in 1979 was a smaller scale accident, rated at INES level 5. \nThere were no direct or indirect deaths caused by the accident.\n\nOther less serious accidents are more common. Benjamin K. Sovacool has reported that worldwide there have been 99 accidents (defined as either resulting in loss of human life or more than $50,000 of property damage) at nuclear power plants. \nFifty-seven accidents have occurred since the Chernobyl disaster, and 57% (56 out of 99) of all nuclear-related accidents have occurred in the United States.\n\nMilitary nuclear-powered submarine mishaps include the K-19 reactor accident (1961), the K-27 reactor accident (1968), and the K-431 reactor accident (1985). \nInternational research is continuing into safety improvements such as passively safe plants, and the possible future use of nuclear fusion.\n\nAccording to Benjamin K. Sovacool, fission energy accidents ranked first among energy sources in terms of their total economic cost, accounting for 41 percent of all property damage attributed to energy accidents. \nAnother analysis presented in the international journal \"Human and Ecological Risk Assessment\" found that coal, oil, Liquid petroleum gas and hydroelectric accidents (primarily due to the Banqiao dam burst) have resulted in greater economic impacts than nuclear power accidents.\n\nNuclear power works under an insurance framework that limits or structures accident liabilities in accordance with the Paris convention on nuclear third-party liability, the Brussels supplementary convention, the Vienna convention on civil liability for nuclear damage and the Price-Anderson Act in the United States.\nIt is often argued that this potential shortfall in liability represents an external cost not included in the cost of nuclear electricity; but the cost is small, amounting to about 0.1% of the levelized cost of electricity, according to a CBO study.\nThese beyond-regular-insurance costs for worst-case scenarios are not unique to nuclear power, as hydroelectric power plants are similarly not fully insured against a catastrophic event such as the Banqiao Dam disaster, where 11 million people lost their homes and from 30,000 to 200,000 people died, or large dam failures in general. As private insurers base dam insurance premiums on limited scenarios, major disaster insurance in this sector is likewise provided by the state.\n\nIn terms of lives lost per unit of energy generated, nuclear power has caused fewer accidental deaths per unit of energy generated than all other major sources of energy generation. \nEnergy produced by coal, petroleum, natural gas and hydropower has caused more deaths per unit of energy generated due to air pollution and energy accidents. \nThis is found when comparing the immediate deaths from other energy sources to both the immediate nuclear related deaths from accidents and also including the latent, or predicted, indirect cancer deaths from nuclear energy accidents. \nWhen the combined immediate and indirect fatalities from nuclear power and all fossil fuels are compared, including fatalities resulting from the mining of the necessary natural resources to power generation and to air pollution, the use of nuclear power has been calculated to have prevented about 1.8 million deaths between 1971 and 2009, by reducing the proportion of energy that would otherwise have been generated by fossil fuels, and is projected to continue to do so.\nFollowing the 2011 Fukushima nuclear disaster, it has been estimated that if Japan had never adopted nuclear power, accidents and pollution from coal or gas plants would have caused more lost years of life.\n\nForced evacuation from a nuclear accident may lead to social isolation, anxiety, depression, psychosomatic medical problems, reckless behavior, even suicide. \nSuch was the outcome of the 1986 Chernobyl nuclear disaster in Ukraine. \nA comprehensive 2005 study concluded that \"the mental health impact of Chernobyl is the largest public health problem unleashed by the accident to date\". \nFrank N. von Hippel, an American scientist, commented on the 2011 Fukushima nuclear disaster, saying that a disproportionate radiophobia, or \"fear of ionizing radiation could have long-term psychological effects on a large portion of the population in the contaminated areas\". \nA 2015 report in \"Lancet\" explained that serious impacts of nuclear accidents were often not directly attributable to radiation exposure, but rather social and psychological effects. \nEvacuation and long-term displacement of affected populations created problems for many people, especially the elderly and hospital patients.\nIn January 2015, the number of Fukushima evacuees was around 119,000, compared with a peak of around 164,000 in June 2012.\n\nTerrorists could target nuclear power plants in an attempt to release radioactive contamination into the community. The United States 9/11 Commission has said that nuclear power plants were potential targets originally considered for the September 11, 2001 attacks. An attack on a reactor's spent fuel pool could also be serious, as these pools are less protected than the reactor core. The release of radioactivity could lead to thousands of near-term deaths and greater numbers of long-term fatalities.\n\nIf nuclear power use is to expand significantly, nuclear facilities will have to be made extremely safe from attacks that could release massive quantities of radioactivity. \nNew reactor designs have features of passive safety, such as the flooding of the reactor core without active intervention by reactor operators. \nHowever, these safety measures have generally been developed and studied with respect to accidents, not to the deliberate reactor attack by a terrorist group. \nThe U.S. Nuclear Regulatory Commission (NRC) does now also require new reactor license applications to consider security during the design stage. \nIn the United States, the NRC carries out \"Force on Force\" (FOF) exercises at all Nuclear Power Plant (NPP) sites at least once every three years. \nIn the United States, plants are surrounded by a double row of tall fences which are electronically monitored. \nThe plant grounds are patrolled by a sizeable force of armed guards.\n\nInsider sabotage is also a threat because insiders can observe and work around security measures. \nSuccessful insider crimes depended on the perpetrators' observation and knowledge of security vulnerabilities. \nA fire caused 5–10 million dollars worth of damage to New York's Indian Point Energy Center in 1971. \nThe arsonist turned out to be a plant maintenance worker. \nSabotage by workers has been reported at many other reactors in the United States: at Zion Nuclear Power Station (1974), Quad Cities Nuclear Generating Station, Peach Bottom Nuclear Generating Station, Fort St. Vrain Generating Station, Trojan Nuclear Power Plant (1974), Browns Ferry Nuclear Power Plant (1980), and Beaver Valley Nuclear Generating Station (1981). Many reactors overseas have also reported sabotage by workers.\n\nMany technologies and materials associated with the creation of a nuclear power program have a dual-use capability, in that they can be used to make nuclear weapons if a country chooses to do so. When this happens a nuclear power program can become a route leading to a nuclear weapon or a public annex to a \"secret\" weapons program. The concern over Iran's nuclear activities is a case in point.\n\nAs of April 2012 there were thirty one countries that have civil nuclear power plants, of which nine have nuclear weapons, with the vast majority of these nuclear weapons states having first produced weapons, before commercial fission electricity stations. \nMoreover, the re-purposing of civilian nuclear industries for military purposes would be a breach of the Non-proliferation treaty, of which 190 countries adhere to.\n\nA fundamental goal for global security is to minimize the nuclear proliferation risks associated with the expansion of nuclear power. \nThe Global Nuclear Energy Partnership is an international effort to create a distribution network in which developing countries in need of energy would receive nuclear fuel at a discounted rate, in exchange for that nation agreeing to forgo their own indigenous develop of a uranium enrichment program. \nThe France-based Eurodif/\"European Gaseous Diffusion Uranium Enrichment Consortium\" is a program that successfully implemented this concept, with Spain and other countries without enrichment facilities buying a share of the fuel produced at the French controlled enrichment facility, but without a transfer of technology. \nIran was an early participant from 1974, and remains a shareholder of Eurodif via Sofidif.\n\nAccording to Benjamin K. Sovacool, a \"number of high-ranking officials, even within the United Nations, have argued that they can do little to stop states using nuclear reactors to produce nuclear weapons\". \nA 2009 United Nations report said that:\nthe revival of interest in nuclear power could result in the worldwide dissemination of uranium enrichment and spent fuel reprocessing technologies, which present obvious risks of proliferation as these technologies can produce fissile materials that are directly usable in nuclear weapons.\n\nOn the other hand, power reactors can also reduce nuclear weapons arsenals when military grade nuclear materials are reprocessed to be used as fuel in nuclear power plants. \nThe Megatons to Megawatts Program, the brainchild of Thomas Neff of MIT, is the single most successful non-proliferation program to date. \nUp to 2005, the Megatons to Megawatts Program had processed $8 billion of high enriched, weapons grade uranium into low enriched uranium suitable as nuclear fuel for commercial fission reactors by diluting it with natural uranium.\nThis corresponds to the elimination of 10,000 nuclear weapons.\nFor approximately two decades, this material generated nearly 10 percent of all the electricity consumed in the United States (about half of all U.S. nuclear electricity generated) with a total of around 7 trillion kilowatt-hours of electricity produced. Enough energy to energize the entire United States electric grid for about two years. In total it is estimated to have cost $17 billion, a \"bargain for US ratepayers\", with Russia profiting $12 billion from the deal. Much needed profit for the Russian nuclear oversight industry, which after the collapse of the Soviet economy, had difficulties paying for the maintenance and security of the Russian Federations highly enriched uranium and warheads.\n\nThe Megatons to Megawatts Program was hailed as a major success by anti-nuclear weapon advocates as it has largely been the driving force behind the sharp reduction in the quantity of nuclear weapons worldwide since the cold war ended. \nHowever without an increase in nuclear reactors and greater demand for fissile fuel, the cost of dismantling and down blending has dissuaded Russia from continuing their disarmament.\nAs of 2013 Russia appears to not be interested in extending the program.\n\nNuclear power is one of the leading low carbon power generation methods of producing electricity, and in terms of total life-cycle greenhouse gas emissions per unit of energy generated, has emission values comparable to or lower than renewable energy.\nA 2014 analysis of the carbon footprint literature by the Intergovernmental Panel on Climate Change (IPCC) reported that the embodied total life-cycle emission intensity of fission electricity has a median value of 12 g eq/kWh which is the lowest out of all commercial baseload energy sources.\nThis is contrasted with coal and fossil gas at 820 and 490 g eq/kWh. \nFrom the beginning of fission-electric power station commercialization in the 1970s, nuclear power prevented the emission of about 64 billion tonnes of carbon dioxide equivalent that would have otherwise resulted from the burning of fossil fuels in thermal power stations.\n\nAccording to the United Nations (UNSCEAR), regular nuclear power plant operation including the nuclear fuel cycle causes radioisotope releases into the environment amounting to 0.0002 millisieverts (mSv) per year of public exposure as a global average. \nThis is small compared to variation in natural background radiation, which averages 2.4 mSv/a globally but frequently varies between 1 mSv/a and 13 mSv/a depending on a person's location as determined by UNSCEAR. \nAs of a 2008 report, the remaining legacy of the worst nuclear power plant accident (Chernobyl) is 0.002 mSv/a in global average exposure (a figure which was 0.04 mSv per person averaged over the entire populace of the Northern Hemisphere in the year of the accident in 1986, although far higher among the most affected local populations and recovery workers).\n\nClimate change causing weather extremes such as heat waves, reduced precipitation levels and droughts can have a significant impact on all thermal power station infrastructure, including large biomass-electric and fission-electric stations alike, if cooling in these power stations, namely in the steam condenser is provided by certain freshwater sources. While many thermal stations use indirect seawater cooling or cooling towers that in comparison use little to no freshwater, those that were designed to heat exchange with rivers and lakes, can run into economic problems.\n\nThis presently infrequent generic problem may become increasingly significant over time. This can force nuclear reactors to be shut down, as happened in France during the 2003 and 2006 heat waves. Nuclear power supply was severely diminished by low river flow rates and droughts, which meant rivers had reached the maximum temperatures for cooling reactors. During the heat waves, 17 reactors had to limit output or shut down. 77% of French electricity is produced by nuclear power and in 2009 a similar situation created a 8GW shortage and forced the French government to import electricity. Other cases have been reported from Germany, where extreme temperatures have reduced nuclear power production only 9 times due to high temperatures between 1979 and 2007. \n\nIf global warming continues, this disruption is likely to increase or alternatively, station operators could instead retro-fit other means of cooling, like cooling towers, despite these frequently being large structures and therefore sometimes unpopular with the public.\n\nThere is an ongoing debate on the relative benefits of nuclear power compared to renewable energy sources for the generation of low-carbon electricity.\nProponents of renewable energy argue that wind power and solar power are already cheaper and safer than nuclear power.\nNuclear power proponents argue that renewable energy sources such as wind and solar do not offer the scalability necessary for a large scale decarbonization of the electric grid, mainly due to their intermittency.\nAlthough the majority of installed renewable energy across the world is currently in the form of hydro power, solar and wind power are growing at a much higher pace, especially in developed countries.\n\nSeveral studies report that it is in principle possible to cover most of energy generation with renewable sources.\nThe Intergovernmental Panel on Climate Change (IPCC) has said that if governments were supportive, and the full complement of renewable energy technologies were deployed, renewable energy supply could account for almost 80% of the world's energy use within forty years with a necessary investment in renewables of about 1% of global GDP annually.\nThis approach could contain greenhouse gas levels to less than 450 parts per million, the safe level beyond which climate change becomes catastrophic and irreversible.\n\nHowever, other studies suggest that solar and wind energy are not cost-effective compared to nuclear power.\nThe Brookings Institution published \"The Net Benefits of Low and No-Carbon Electricity Technologies\" in 2014 which states, after performing an energy and emissions cost analysis, that \"The net benefits of new nuclear, hydro, and natural gas combined cycle plants far outweigh the net benefits of new wind or solar plants\", with the most cost effective low carbon power technology being determined to be nuclear power.\n\nNuclear power is also proposed as a tested and practical way to implement a low-carbon energy infrastructure, as opposed to renewable sources.\nAnalysis in 2015 by professor and chair of Environmental Sustainability Barry W. Brook and his colleagues on the topic of replacing fossil fuels entirely, from the electric grid of the world, has determined that at the historically modest and proven-rate at which nuclear energy was added to and replaced fossil fuels in France and Sweden during each nation's building programs in the 1980s, nuclear energy could displace or remove fossil fuels from the electric grid completely within 10 years, \"allow[ing] the world to meet the most stringent greenhouse-gas mitigation targets.\". \nIn a similar analysis, Brook had earlier determined that 50% of all global energy, that is not solely electricity, but transportation synthetic fuels etc. could be generated within approximately 30 years, if the global nuclear fission build rate was identical to each of these nation's already proven installation rates in units of installed nameplate capacity, GW per year, per unit of global GDP (GW/year/$).\nThis is in contrast to the conceptual studies for a \"100% renewable energy\" world, which would require an orders of magnitude more costly global investment per year, which has no historical precedent, along with far greater land that would have to be devoted to the wind, wave and solar projects, and the inherent assumption that humanity will use less, and not more, energy in the future.\nAs Brook notes, the \"principal limitations on nuclear fission are not technical, economic or fuel-related, but are instead linked to complex issues of societal acceptance, fiscal and political inertia, and inadequate critical evaluation of the real-world constraints facing [the other] low-carbon alternatives.\"\n\nSeveral studies conclude that wind and solar power have costs that are comparable or lower than nuclear power, when considering price per kWh.\nThe cost of constructing established nuclear power reactor designs has followed an increasing trend due to regulations and court cases whereas the levelized cost of electricity (LCOE) is declining for wind and solar power. \nIn 2010 a report from Solar researchers at Duke University found that solar power may be already cheaper than new nuclear power plants. \nHowever they state that if subsidies were removed for solar power, the crossover point would be delayed by years.\nData from the U.S. Energy Information Administration (EIA) in 2011 estimated that in 2016, solar will have a levelized cost of electricity almost twice as expensive as nuclear (21¢/kWh for solar, 11.39¢/kWh for nuclear), and wind somewhat less expensive than nuclear (9.7¢/kWh).\nHowever, the EIA has also cautioned that levelized costs of intermittent sources such as wind and solar are not directly comparable to costs of \"dispatchable\" sources (those that can be adjusted to meet demand), as intermittent sources need costly large-scale back-up power supplies for when the weather changes.\n\nA 2010 study by the Global Subsidies Initiative compared global relative energy subsidies, or government financial aid for the deployment of different energy sources.\nResults show that fossil fuels receive about 1 U.S. cents per kWh of energy they produce, nuclear energy receives 1.7 cents / kWh, renewable energy (excluding hydroelectricity) receives 5.0 cents / kWh and biofuels receive 5.1 cents / kWh in subsidies.\n\nNuclear power is comparable to, and in some cases lower, than many renewable energy sources in terms of lives lost per unit of electricity delivered.\nHowever, as opposed to renewable energy, conventional designs for nuclear reactors produce intensely radioactive spent fuel that needs to be stored or reprocessed.\nA nuclear plant also needs to be disassembled and removed and much of the disassembled nuclear plant needs to be stored as low level nuclear waste for a few decades.\n\nThe financial costs of every nuclear power plant continues for some time after the facility has finished generating its last useful electricity. Once no longer economically viable, nuclear reactors and uranium enrichment facilities are generally decommissioned, returning the facility and its parts to a safe enough level to be entrusted for other uses, such as greenfield status. \nAfter a cooling-off period that may last decades, reactor core materials are dismantled and cut into small pieces to be packed in containers for interim storage or transmutation experiments. The consensus on how to approach the task is one that is relatively inexpensive, but it has the potential to be hazardous to the natural environment as it presents opportunities for human error, accidents or sabotage.\n\nIn the United States a Nuclear Waste Policy Act and Nuclear Decommissioning Trust Fund is legally required, with utilities banking 0.1 to 0.2 cents/kWh during operations to fund future decommissioning. They must report regularly to the Nuclear Regulatory Commission (NRC) on the status of their decommissioning funds. About 70% of the total estimated cost of decommissioning all U.S. nuclear power reactors has already been collected (on the basis of the average cost of $320 million per reactor-steam turbine unit).\n\nIn the United States in 2011, there are 13 reactors that had permanently shut down and are in some phase of decommissioning. With Connecticut Yankee Nuclear Power Plant and Yankee Rowe Nuclear Power Station having completed the process in 2006–2007, after ceasing commercial electricity production circa 1992. \nThe majority of the 15 years, was used to allow the station to naturally cool-down on its own, which makes the manual disassembly process both safer and cheaper.\nDecommissioning at nuclear sites which have experienced a serious accident are the most expensive and time-consuming.\n\nThe nuclear power debate concerns the controversy which has surrounded the deployment and use of nuclear fission reactors to generate electricity from nuclear fuel for civilian purposes. The debate about nuclear power peaked during the 1970s and 1980s, when it \"reached an intensity unprecedented in the history of technology controversies\", in some countries.\n\nProponents of nuclear energy contend that nuclear power is a sustainable energy source that reduces carbon emissions and increases energy security by decreasing dependence on imported energy sources. \nProponents claim that nuclear power produces virtually no conventional air pollution, such as greenhouse gases and smog, in contrast to the main alternative of fossil-fuel power stations. Nuclear power can produce base-load power unlike many renewables which are intermittent energy sources lacking large-scale and cheap ways of storing energy. M. King Hubbert saw oil as a resource that would run out, and proposed nuclear energy as a replacement energy source. \nProponents claim that the risks of storing waste are small and can be further reduced by using the latest technology in newer reactors, and the operational safety record in the Western world is excellent when compared to the other major kinds of power plants.\n\nOpponents believe that nuclear power poses many threats to people and the environment. \nThese threats include the problems of processing, transport and storage of radioactive nuclear waste, the risk of nuclear weapons proliferation and terrorism, as well as health risks and environmental damage from uranium mining. They also contend that reactors themselves are enormously complex machines where many things can and do go wrong; and there have been serious nuclear accidents. Critics do not believe that the risks of using nuclear fission as a power source can be fully offset through the development of new technology. In years past, they also argued that when all the energy-intensive stages of the nuclear fuel chain are considered, from uranium mining to nuclear decommissioning, nuclear power is neither a low-carbon nor an economical electricity source.\n\nArguments of economics and safety are used by both sides of the debate.\n\nBoth fission and fusion appear promising for space propulsion applications, generating higher mission velocities with less reaction mass. This is due to the much higher energy density of nuclear reactions: some 7 orders of magnitude (10,000,000 times) more energetic than the chemical reactions which power the current generation of rockets.\n\nRadioactive decay has been used on a relatively small scale (few kW), mostly to power space missions and experiments by using radioisotope thermoelectric generators such as those developed at Idaho National Laboratory.\n\nCurrent fission reactors in operation around the world are second or third generation systems, with most of the first-generation systems having been already retired. \nResearch into advanced generation IV reactor types was officially started by the Generation IV International Forum (GIF) based on eight technology goals, including to improve nuclear safety, improve proliferation resistance, minimize waste, improve natural resource utilization, the ability to consume existing nuclear waste in the production of electricity, and decrease the cost to build and run such plants. \nMost of these reactors differ significantly from current operating light water reactors, and are generally not expected to be available for commercial construction before 2030.\n\nOne disadvantage of any new reactor technology is that safety risks may be greater initially as reactor operators have little experience with the new design. \nNuclear engineer David Lochbaum has explained that almost all serious nuclear accidents have occurred with what was at the time the most recent technology. \nHe argues that \"the problem with new reactors and accidents is twofold: scenarios arise that are impossible to plan for in simulations; and humans make mistakes\". \nAs one director of a U.S. research laboratory put it, \"fabrication, construction, operation, and maintenance of new reactors will face a steep learning curve: advanced technologies will have a heightened risk of accidents and mistakes. The technology may be proven, but people are not\".\n\nHybrid nuclear power is a proposed means of generating power by use of a combination of nuclear fusion and fission processes. The concept dates to the 1950s, and was briefly advocated by Hans Bethe during the 1970s, but largely remained unexplored until a revival of interest in 2009, due to delays in the realization of pure fusion. When a sustained nuclear fusion power plant is built, it has the potential to be capable of extracting all the fission energy that remains in spent fission fuel, reducing the volume of nuclear waste by orders of magnitude, and more importantly, eliminating all actinides present in the spent fuel, substances which cause security concerns.\n\nNuclear fusion reactions have the potential to be safer and generate less radioactive waste than fission. \nThese reactions appear potentially viable, though technically quite difficult and have yet to be created on a scale that could be used in a functional power plant. \nFusion power has been under theoretical and experimental investigation since the 1950s.\n\nSeveral experimental nuclear fusion reactors and facilities exist. \nThe largest and most ambitious international nuclear fusion project currently in progress is ITER, a large tokamak under construction in France.\nITER is planned to pave the way for commercial fusion power by demonstrating self-sustained nuclear fusion reactions with positive energy gain. \nConstruction of the ITER facility began in 2007, but the project has run into many delays and budget overruns. \nThe facility is now not expected to begin operations until the year 2027 – 11 years after initially anticipated. A follow on commercial nuclear fusion power station, DEMO, has been proposed. There are also suggestions for a power plant based upon a different fusion approach, that of an inertial fusion power plant.\n\nFusion powered electricity generation was initially believed to be readily achievable, as fission-electric power had been. However, the extreme requirements for continuous reactions and plasma containment led to projections being extended by several decades. In 2010, more than 60 years after the first attempts, commercial power production was still believed to be unlikely before 2050.\n\n\n\n"}
{"id": "24958480", "url": "https://en.wikipedia.org/wiki?curid=24958480", "title": "Olympic Broadcasting Services", "text": "Olympic Broadcasting Services\n\nOlympic Broadcasting Services (OBS) is a company which was established by the International Olympic Committee in 2001 in order to serve as the Host Broadcaster organisation for all Olympic Games, Olympic Winter Games and Youth Olympic Games, maintaining the standards of Olympic broadcasting between one edition and the next one.\n\nAs Host Broadcaster, OBS is responsible for delivering the pictures and sounds of the Olympic Games to billions of viewers around the world. It produces and transmits unbiased live radio and television coverage of every sport from every venue. This feed is called the International Signal or the World Feed and is distributed as a service to all broadcast organisations who have purchased the television and radio rights to the Games (known as Rights Holding Broadcasters or RHBs).\n\nIn collaboration with the Local Organising Committee, OBS supervises the development of the necessary infrastructures (including the International Broadcast Centre or IBC which serves as the primary base of the broadcast operation for OBS and the RHBs during the Games) and facilities at the different Olympic venues to ensure the successful broadcast production of the Games. OBS also offers additional services, equipment and supplies to the RHBs to help them produce their unilateral production.\n\nThe 2008 Summer Olympics in Beijing marked the first time OBS was involved as Host Broadcaster. Previously the host broadcaster role was delegated to the local organising committees or to third-party broadcasters, having to rebuild the broadcast operation in each edition.\n\nIts headquarters are in Madrid, Spain.\n\nIts operations began with the 2008 Summer Olympics in Beijing, where Beijing Olympic Broadcasting, a joint venture between OBS and the Beijing Organizing Committee, acted as the host broadcasting consortium and the state television network, China Central Television which is one of the host nation broadcasters of the games.\n\nFor the 2010 Winter Olympics in Vancouver, a wholly owned division, Olympic Broadcasting Services Vancouver was set up. The 2010 Olympics marked the first Games where the host broadcasting facilities were provided solely by OBS.\n\nThe 2012 Olympic Games were broadcast by OBS. More than 5,600+ hours of live sports, ceremonies and Olympic News Channel content were distributed to the Rights Holding Broadcasters. OBS employed 1,000+ HD cameras, including 40 High Super Slow Motion cameras and other innovative specialty equipment such as 3D cameras, Super High Vision cameras and the world’s longest cablecam which stretched 2,340m at the Rowing venue from start to finish.\n\nThe Sochi 2014 Olympic Winter Games represented the largest broadcast operation in history for a Winter Games. OBS deployed more than 450 cameras, including 12 cablecam systems, 31 High Speed Slow Motion (HSSM) cameras and a multicopter/drone used for the first time, to ultimately produce 1300+ hours of television.\n\nIn total, 464 television channels broadcast the Sochi Games, almost double the number from Vancouver, and more digital platforms offered coverage than at any previous Winter Games with 155 websites and 75 apps showing events live from Russia.\n\nThanks to the increased number of channels and digital platforms for Sochi 2014, there were more hours broadcast globally than any previous Winter Games with more than 100,000 hours broadcast around the world, compared with 57,000 for Vancouver 2010.\n\nFor the first time in Olympic history, the amount of digital coverage exceeded traditional television broadcasts with 60,000 hours available on digital platforms, compared with 42,000 hours on television. These were the first predominantly digital Olympic Games and OBS helped fuel the significant increase in digital coverage by launching, for the first time in Sochi, the Olympic Video Player (OVP). Available in 95 countries, the OVP provided a fully integrated data, a news channel, live streams and on-demand video.\n\nRio 2016 represented the most television coverage of any previous Olympic Games, with nearly 350,000 total hours broadcast globally, far exceeding the 200,000 hours that were broadcast for the London 2012 Games. Additionally, coverage was aired across more platforms than ever before, as more than 500 television channels and 250 digital outlets conveyed the Olympic Games around the world.\n\nThe number of hours of coverage available on digital platforms nearly doubled that of traditional television, representing more than two and a half times of what was achieved for London 2012 (218,000 hours versus 81,500 hours), marking a milestone in the history of Olympic broadcasting.\n\nRepresenting the largest host broadcast operation to date, Rio involved more than 7,200 OBS personnel. Further, having developed a production plan to cover all 28 Olympic sports, including new additions Golf and Rugby Sevens, OBS drew on more than 1,000 cameras for the coverage of the Rio Games.\n\nRio also marked the first time Olympic content was available in Virtual Reality (VR). Overall, OBS produced more than 85 hours of live VR coverage, captured by custom-developed 360-degree camera systems, to a total of 14 RHB organisations, representing 31 territories.\n\nOBS and Japanese Rights Holder NHK continued their collaboration on 4K/8K Super Hi-Vision (SHV) technology and produced approximately 100 hours of live coverage for Rio, featuring 22.2-channel surround sound.\n\nPyeongChang 2018 Winter Olympics and Paralympic\n"}
{"id": "23450639", "url": "https://en.wikipedia.org/wiki?curid=23450639", "title": "Outline of the Post-War New World Map", "text": "Outline of the Post-War New World Map\n\nThe Outline of the Post-War New World Map was a map completed before the attack on Pearl Harbor and self-published on February 25, 1942 by Maurice Gomberg of Philadelphia, United States. It shows a proposed political division of the world after World War II in the event of an Allied victory in which the United States of America, the United Kingdom, and the Soviet Union as well as the Republic of China would rule. The map includes a manifesto describing a \"New World Moral Order\", along with quotes from Roosevelt's Four Freedoms speech.\n\nGomberg created the map as a personal project, and little else is known of him. The map has been highlighted by New World Order conspiracy theorists who believe it represents some broader view of the US government, and has also been widely circulated online.\n\nThe map proposes a total of 14 independent sovereign states, 4 of them democracies and 10 of them demilitarized, and 3 \"quarantined\" states (the fate of 2 are to be eventually integrated into sovereign states).\n\nThe United States has 82 states, not including Security Outposts in the Pacific and the Atlantic, gaining all of Canada, Mexico, and Central America, among other places:\n\nStates:\nAlabama - Alberta - Alaska - Arizona - Arkansas - The Bahamas - California (historical Alta (Upper) California) - Colorado - Columbia - Connecticut - Costa Rica - Cuba - Delaware - Florida - Georgia - Greenland - Guatemala (Guatemala and Belize)\n- Haiti (including all of Hispaniola) - Honduras - Idaho - Illinois - Indiana - Iowa - Jamaica - Kansas - Keewatin (pre-1999 Northwest Territories east of the 110° meridian) - Kentucky - Labrador (mainland Newfoundland and Labrador) - Leeward Islands - Louisiana - Lower California (consisting of the Baja California peninsula) - Maine - Mackenzie (pre-1999 Northwest Territories west of the 110° meridian) - Manitoba - Maryland - Martinique - Massachusetts - Mexico (the remainder of Mexico) - Michigan - Minnesota - Mississippi - Missouri - Montana - Nevada - New Brunswick - Newfoundland (Island Newfoundland and Labrador) - New Hampshire - New Jersey - New Mexico - New York - Nicaragua - North Carolina - North Dakota - Nova Scotia - Ohio - Oklahoma - Ontario - Oregon - Panama - Pennsylvania - Prince Edward Island - Puerto Rico - Quebec - Rhode Island - El Salvador - Saskatchewan - South Carolina - South Dakota - Tennessee - Texas - Trinidad - Utah - Vermont - Virginia - Virgin Islands - Washington - West Virginia - Windward Islands - Wisconsin - Wyoming - Yukon\n\nProtectorates:\n- Celebes - Hainan - Halmahera Islands\n- Iceland - Moluccas Islands - Commonwealth of the Philippines - Taiwan\n\nPort \"Peace-security bases\":\nDakar and Freetown on the Atlantic coast of Africa\n\nThe British Commonwealth of Nations is headquartered in the United Kingdom, including England (including Wales) and Scotland, but not Northern Ireland. The Commonwealth includes the Faroe Islands and the former colonies of Madagascar (in early 1942 still a Vichy French colony), Ceylon, the Andaman Islands, Cyprus, Malta, most of Indonesia (in 1942 a Dutch colony occupied by Japan; other parts are given to the US), as well as the then British colonies that are now Singapore and Malaysian Borneo, South Georgia, the Bismarck Archipelago, the Solomon Islands, and the countries of Australia and New Zealand.\n\nPort \"Peace-security bases\":\n\nThe Soviet Union would expand to be far larger than its then-current size, expanding to 24 (later 25) Soviet Socialist Republics (while downgrading preexisting SSR's to Autonomous Soviet Socialist Republics):\n\nSoviet Socialist Republics:\nArmenia - Azerbaijan - Bulgaria - Czech Republic - Estonia - Finland - Georgia - Hungary - Iran - Latvia - Lithuania - Manchuria (Northern Manchuria) - Moldavia (all of Bessarabia) - Mongolia - Poland - Romania - Russia (which includes Kazakhstan and Kirghizia (Kyrgyzstan) - Slovakia - Tajikistan - Turkmenistan - Ukraine - Uzbekistan - White Russia (Byelorussia) - Yugoslavia\n<br>\nAt an unspecified later time, Germany (which includes Austria and former Polish territory formerly part of the Weimar Republic sans East Prussia). Germany is termed \"quarantined Germany\" until full integration\n\nEverything below the Darién Gap, and offshore islands including the Falkland Islands:\n\n- Argentina - Bolivia - Brazil - Chile - Colombia - Ecuador - Guiana - Paraguay - Peru - Uruguay - Venezuela\n\nChina (without Formosa or Hainan) - Inner Mongolia - Indo China (Cambodia, Laos, and Vietnam) - Korea - Malaya - Sinkiang - Thailand - Tibet\n\nBelgium (including Luxembourg) - France (including Monaco and all of Germany west of the Rhine river) - Netherlands - Portugal - San Marino (later included in Italy) - Spain (including Andorra) - Switzerland (including Liechtenstein) - Vatican City (later included in Italy)\n<br>\nAt an unspecified later time, Italy (which is termed \"quarantined Italy\" until full integration)\n\nDenmark (without the Faroe Islands and Greenland) - Norway (including Spitsbergen, without Jan Mayen) - Sweden\n\nBesides the port \"peace-security bases\", areas included are Algeria - Angola - Bechuanaland (Botswana) - Congo (including Burundi) - Dahomey (Benin, including Togo) - Egypt - Equatorial Africa (including Equatorial Guinea, eastern Guinea, and São Tomé and Príncipe) - Eritrea - Ethiopia (including Djibouti) - Gold Coast (Ghana) - Kenya - Liberia - Libya - Morocco - Mozambique (including southern Malawi) - Nigeria - Rhodesia (northern Malawi, Zambia, and Zimbabwe) - Senegal (including the Gambia, western Guinea, and Guinea-Bissau) - Somaliland (Somalia) - South Africa (including Lesotho and Swaziland) - South West Africa (Namibia) - Sudan - Tanganyika (including Rwanda) - Tunisia - Uganda - West Africa (including Sahrawi Arab Democratic Republic/Western Sahara and Sierra Leone, without Benin, Senegal, and Togo)\n\nAden (South Yemen) - Hejaz - Iraq (including Kuwait) - Lebanon - Oman (including Bahrain, Qatar, and United Arab Emirates) - Saudi Arabia - Syria - Yemen (North Yemen)\n\nAfghanistan - Balochistan - Bhutan - Burma - India (including Pakistan without Balochistan) - Nepal\n\nAlbania - Greece\n<br>\nPoint #24 notes the inclusion of Macedonia. that \"Macedonia\" is not clearly defined; the map seems to not include the modern country of that name, but rather labels Macedonia as Greek Macedonia.\n\nConsists of the whole of the island of Ireland\n\nIncludes all of modern Israel, Jordan and Palestine, taking in parts of modern Syria and a slice of northern Saudi Arabia.\n\nAll of Asian Turkey. European Turkey is placed under joint control of the USSR and Turkey - cf. points #27 and #28.\n\nMentioned as \"quarantined Germany\", all of Weimar Republic territory east of the Rhine river but west of the former Polish Corridor, plus Austria, eventually supposed to become a full Soviet Socialist Republic in the Soviet Union\nMentioned as \"quarantined Italy\", all of modern Italy and the Julian March (pre 1941), eventually supposed to become a full state in the United States of Europe\nMentioned as \"quarantined Japan\", all of modern Japan and Iturup, Kunashir, Shikotan, Habomai (but not including Bonin Islands). Later fate presumed to be an independent democracy\n\n\n"}
{"id": "18566277", "url": "https://en.wikipedia.org/wiki?curid=18566277", "title": "Policy laundering", "text": "Policy laundering\n\nPolicy laundering is the disguising of the origins of political decisions, laws, or international treaties. The term is based on the similar money laundering.\n\nOne common method for policy laundering is the use of international treaties which are formulated in secrecy. Afterwards it is not possible to find out who advocated for which part of the treaty. Each person can claim that it was not them who demanded a certain paragraph but that they had to agree to the overall \"compromise\".\n\nExamples that could be considered as \"policy laundering\" are WIPO or the Anti-Counterfeiting Trade Agreement (ACTA).\n\nOne manifestation of policy laundering is claiming a different underlying objective for a policy than is actually the case. The usual reason for politicians following this approach is that the real objective is unpopular with the public. The usual process is to conflate the issue being addressed with an unrelated matter of great public concern. The intervention pursued is presented as addressing an issue of great public concern rather than the underlying objective.\n\nYet another manifestation of policy laundering is to implement legal policy which a subset of legislators desire but would normally not be able to obtain approval through regular means.\n\nAn example of policy laundering where law was enacted and enforced despite both state and federal courts declaring the law unconstitutional is the \"Missouri v. Holland\" case. At that time, Congress attempted to protect migratory birds by statutory law. However, both state and federal courts declared that law unconstitutional. Not to be denied, authorized parties subsequently negotiated and ratified a treaty with Canada to achieve the same purpose. Once the treaty was in place, Congress then passed the Migratory Bird Treaty Act of 1918 to enforce the treaty. In \"Missouri v. Holland\", the United States Supreme Court upheld that the new law was constitutional in order to support the treaty.\n\nIt has been suggested that policy laundering has become common political practice in areas related to terrorism and the erosion of civil liberties. In the air-travel industry, an example of policy laundering might be the requirement for passengers to show photographic identification. This was presented as addressing security concerns, but from the airline's perspective the measure had the important effect of ending unauthorised resale by passengers of unused tickets.\n\n\n"}
{"id": "2379996", "url": "https://en.wikipedia.org/wiki?curid=2379996", "title": "Population health", "text": "Population health\n\nPopulation health has been defined as \"the health outcomes of a group of individuals, including the distribution of such outcomes within the group\". It is an approach to health that aims to improve the health of an entire human population. This concept does not refer to animal or plant populations. It has been described as consisting of three components. These are \"health outcomes, patterns of health determinants, and policies and interventions\". A priority considered important in achieving the aim of Population Health is to reduce health inequities or disparities among different population groups due to, among other factors, the social determinants of health, SDOH. The SDOH include all the factors (social, environmental, cultural and physical) that the different populations are born into, grow up and function with throughout their lifetimes which potentially have a measurable impact on the health of human populations. The Population Health concept represents a change in the focus from the individual-level, characteristic of most mainstream medicine. It also seeks to complement the classic efforts of public health agencies by addressing a broader range of factors shown to impact the health of different populations. The World Health Organization's Commission on Social Determinants of Health, reported in 2008, that the SDOH factors were responsible for the bulk of diseases and injuries and these were the major causes of health inequities in all countries. In the US, SDOH were estimated to account for 70% of avoidable mortality.\n\nFrom a population health perspective, health has been defined not simply as a state free from disease but as \"the capacity of people to adapt to, respond to, or control life's challenges and changes\". The World Health Organization (WHO) defined health in its broader sense in 1946 as \"a state of complete physical, mental, and social well-being and not merely the absence of disease or infirmity.\"\n\nHealthy People 2020 is a web site sponsored by the US Department of Health and Human Services, representing the cumulative effort of 34 years of interest by the Surgeon General's office and others. It identifies 42 topics considered social determinants of health and approximately 1200 specific goals considered to improve population health. It provides links to the current research available for selected topics and identifies and supports the need for community involvement considered essential to address these problems realistically.\n\nRecently, human role has been encouraged by the influence of population growth there has been increasing interest from epidemiologists on the subject of economic inequality and its relation to the health of populations. There is a very robust correlation between socioeconomic status and health. This correlation suggests that it is not only the poor who tend to be sick when everyone else is healthy, heart disease, ulcers, type 2 diabetes, rheumatoid arthritis, certain types of cancer, and premature aging. Despite the reality of the SES Gradient, there is debate as to its cause. A number of researchers (A. Leigh, C. Jencks, A. Clarkwest—see also Russell Sage working papers) see a definite link between economic status and mortality due to the greater economic resources of the better-off, but they find little correlation due to social status differences.\n\nOther researchers such as Richard G. Wilkinson, J. Lynch, and G.A. Kaplan have found that socioeconomic status strongly affects health even when controlling for economic resources and access to health care. Most famous for linking social status with health are the Whitehall studies—a series of studies conducted on civil servants in London. The studies found that, despite the fact that all civil servants in England have the same access to health care, there was a strong correlation between social status and health. The studies found that this relationship stayed strong even when controlling for health-affecting habits such as exercise, smoking and drinking. Furthermore, it has been noted that no amount of medical attention will help decrease the likelihood of someone getting type 1 diabetes or rheumatoid arthritis—yet both are more common among populations with lower socioeconomic status. Lastly, it has been found that amongst the wealthiest quarter of countries on earth (a set stretching from Luxembourg to Slovakia) there is no relation between a country's wealth and general population health—suggesting that past a certain level, absolute levels of wealth have little impact on population health, but relative levels within a country do.\nThe concept of psychosocial stress attempts to explain how psychosocial phenomenon such as status and social stratification can lead to the many diseases associated with the SES gradient. Higher levels of economic inequality tend to intensify social hierarchies and generally degrades the quality of social relations—leading to greater levels of stress and stress related diseases. Richard Wilkinson found this to be true not only for the poorest members of society, but also for the wealthiest. Economic inequality is bad for everyone's health. \nInequality does not only affect the health of human populations. David H. Abbott at the Wisconsin National Primate Research Center found that among many primate species, less egalitarian social structures correlated with higher levels of stress hormones among socially subordinate individuals. Research by Robert Sapolsky of Stanford University provides similar findings.\n\nThere is well-documented variation in health outcomes and health care utilization & costs by geographic variation in the U.S., down to the level of Hospital Referral Regions (defined as a regional health care market, which may cross state boundaries, of which there are 306 in the U.S.). There is ongoing debate as to the relative contributions of race, gender, poverty, education level and place to these variations. The Office of Epidemiology of the Maternal and Child Health Bureau recommends using an analytic approach (Fixed Effects or hybrid Fixed Effects) to research on health disparities to reduce the confounding effects of neighborhood (geographic) variables on the outcomes.\n\nFamily planning programs (including contraceptives, sexuality education, and promotion of safe sex) play a major role in population health. Family planning is one of the most highly cost-effective interventions in medicine. Family planning saves lives and money by reducing unintended pregnancy and the transmission of sexually transmitted infections.\n\nFor example, the United States Agency for International Development lists as benefits of its international family planning program:\n\n\nOne method to improve population health is population health management (PHM), which has been defined as \"the technical field of endeavor which utilizes a variety of individual, organizational and cultural interventions to help improve the morbidity patterns (i.e., the illness and injury burden) and the health care use behavior of defined populations\". PHM is distinguished from disease management by including more chronic conditions and diseases, by use of \"a single point of contact and coordination\", and by \"predictive modeling across multiple clinical conditions\". PHM is considered broader than disease management in that it also includes \"intensive care management for individuals at the highest level of risk\" and \"personal health management... for those at lower levels of predicted health risk\". Many PHM-related articles are published in \"Population Health Management\", the official journal of .\n\nThe following road map has been suggested for helping healthcare organizations navigate the path toward implementing effective population health management:\n\nHealthcare reform is driving change to traditional hospital reimbursement models. Prior to the introduction of the Patient Protection and Affordable Care Act (PPACA), hospitals were reimbursed based on the volume of procedures through fee-for-service models. Under the PPACA, reimbursement models are shifting from volume to value. New reimbursement models are built around pay for performance, a value-based reimbursement approach, which places financial incentives around patient outcomes and has drastically changed the way US hospitals must conduct business to remain financially viable. In addition to focusing on improving patient experience of care and reducing costs, hospitals must also focus on improving the health of populations (IHI Triple Aim).\n\nAs participation in value-based reimbursement models such as accountable care organizations (ACOs) increases, these initiatives will help drive population health. Within the ACO model, hospitals have to meet specific quality benchmarks, focus on prevention, and carefully manage patients with chronic diseases. Providers get paid more for keeping their patients healthy and out of the hospital. Studies have shown that inpatient admission rates have dropped over the past ten years in communities that were early adopters of the ACO model and implemented population health measures to treat \"less sick\" patients in the outpatient setting. A study conducted in the Chicago area showed a decline in inpatient utilization rates across all age groups, which was an average of a 5% overall drop in inpatient admissions.\n\nHospitals are finding it financially advantageous to focus on population health management and keeping people in the community well. The goal of population health management is to improve patient outcomes and increase health capital. Other goals include preventing disease, closing care gaps, and cost savings for providers. In the last few years, more effort has been directed towards developing telehealth services, community-based clinics in areas with high proportion of residents using the emergency department as primary care, and patient care coordinator roles to coordinate healthcare services across the care continuum.\n\nHealth can be considered a capital good; health capital is part of human capital as defined by the Grossman model. Health can be considered both an investment good and consumption good. Factors such as obesity and smoking have negative effects on health capital, while education, wage rate, and age may also impact health capital. When people are healthier through preventative care, they have the potential to live a longer and healthier life, work more and participate in the economy, and produce more based on the work done. These factors all have the potential to increase earnings. Some states, like New York, have implemented statewide initiatives to address population health. In New York state there are 11 such programs. One example is the Mohawk Valley Population Health Improvement Program (http://www.mvphip.org/). These programs work to address the needs of the people in their region, as well as assist their local community based organizations and social services to gather data, address health disparities, and explore evidence-based interventions that will ultimately lead to better health for everyone. Following a similar approach, Cullati et al. developed a theoretical framework for the development and onset of vulnerability in later life based on the concept of \"reserves\". The advantages to use the concept of reserves in interdisciplinary studies, as compared with related concepts such as resources and capital, is to strengthen the importance of constitution and sustainability of reserves (the “use it or lose it” paradigm) and the presence of thresholds, below which functioning becomes challenging. \n\n\n"}
{"id": "58097959", "url": "https://en.wikipedia.org/wiki?curid=58097959", "title": "Sahul (continent)", "text": "Sahul (continent)\n\nSahul was a prehistoric continent that consisted of Australia, New Guinea, Tasmania and Seram.\n\nSahul was partially submerged around 18,000 years ago.\n\nSahul and Sunda were points of early human migrations after leaving Africa.\n"}
{"id": "57980", "url": "https://en.wikipedia.org/wiki?curid=57980", "title": "Shortwave radio", "text": "Shortwave radio\n\nShortwave radio is radio transmission using shortwave radio frequencies. There is no official definition of the band, but the range always includes all of the high frequency band (HF), and generally extends from ; from the high end of the medium frequency band (MF) just above the mediumwave AM broadcast band, to the end of the HF band.\n\nRadio waves in the shortwave band can be reflected or refracted from a layer of electrically charged atoms in the atmosphere called the ionosphere. Therefore, short waves directed at an angle into the sky can be reflected back to Earth at great distances, beyond the horizon. This is called skywave or \"skip\" propagation. Thus shortwave radio can be used for very long distance communication, in contrast to radio waves of higher frequency which travel in straight lines (line-of-sight propagation) and are limited by the visual horizon, about . Shortwave radio is used for broadcasting of voice and music to shortwave listeners over very large areas; sometimes entire continents or beyond. It is also used for military over-the-horizon radar, diplomatic communication, and two-way international communication by amateur radio enthusiasts for hobby, educational and emergency purposes, as well as for long distance aviation and marine communications.\n\nThe widest popular definition of the shortwave frequency interval is the ITU Region 1 (EU+Africa+Russia...) definition, and is the span 1.6–30 MHz, just above the medium wave band, which ends approximately at 1.6 MHz.\n\nThere are also other definitions of the shortwave frequency interval:\n\nThe name \"shortwave\" originated during the early days of radio in the early 20th century, when the radio spectrum was considered divided into long wave (LW), medium wave (MW) and short wave bands based on the wavelength of the radio waves. Shortwave radio received its name because the wavelengths in this band are relatively shorter than 200 m (1,500 kHz) which marked the original upper limit of the medium frequency band first used for radio communications. The broadcast medium wave band now extends above the 200 m/1,500 kHz limit, and the amateur radio 1.8 MHz – 2.0 MHz band (known as the \"top band\") is the lowest-frequency band considered to be 'shortwave'. \n\nEarly long distance radio telegraphy used long waves, below 300 kilohertz (kHz). The drawbacks to this system included a very limited spectrum available for long distance communication, and the very expensive transmitters, receivers and gigantic antennas that were required. It was also difficult to beam the radio wave directionally with long wave, resulting in a major loss of power over long distances. Prior to the 1920s, the shortwave frequencies above 1.5 MHz were regarded as useless for long distance communication and were designated in many countries for amateur use.\n\nGuglielmo Marconi, pioneer of radio, commissioned his assistant Charles Samuel Franklin to carry out a large scale study into the transmission characteristics of short wavelength waves and to determine their suitability for long distance transmissions. Franklin rigged up a large antenna at Poldhu Wireless Station, Cornwall, running on 25 kW of power. In June and July 1923, wireless transmissions were completed during nights on 97 meters from Poldhu to Marconi's yacht \"Elettra\" in the Cape Verde Islands.\n\nIn September 1924, Marconi transmitted daytime and nighttime on 32 meters from Poldhu to his yacht in Beirut. Franklin went on to refine the directional transmission, by inventing the curtain array aerial system. In July 1924, Marconi entered into contracts with the British General Post Office (GPO) to install high speed shortwave telegraphy circuits from London to Australia, India, South Africa and Canada as the main element of the Imperial Wireless Chain. The UK-to-Canada shortwave \"Beam Wireless Service\" went into commercial operation on 25 October 1926. Beam Wireless Services from the UK to Australia, South Africa and India went into service in 1927.\n\nShortwave communications began to grow rapidly in the 1920s, similar to the internet in the late 20th century. By 1928, more than half of long distance communications had moved from transoceanic cables and longwave wireless services to shortwave and the overall volume of transoceanic shortwave communications had vastly increased. Shortwave stations had cost and efficiency advantages over massive longwave wireless installations, however some commercial longwave communications stations remained in use until the 1960s. Long distance radio circuits also reduced the load on the existing transoceanic telegraph cables and hence the need for new cables, although the cables maintained their advantages of high security and a much more reliable and better quality signal than shortwave.\n\nThe cable companies began to lose large sums of money in 1927, and a serious financial crisis threatened the viability of cable companies that were vital to strategic British interests. The British government convened the Imperial Wireless and Cable Conference in 1928 \"to examine the situation that had arisen as a result of the competition of Beam Wireless with the Cable Services\". It recommended and received Government approval for all overseas cable and wireless resources of the Empire to be merged into one system controlled by a newly formed company in 1929, Imperial and International Communications Ltd. The name of the company was changed to Cable and Wireless Ltd. in 1934.\n\nLong-distance cables had a resurgence beginning in 1956 with the laying of TAT-1 across the Atlantic Ocean, the first voice frequency cable on this route. This provided 36 high quality telephone channels and was soon followed by even higher capacity cables all around the world. These sounded the death knell of shortwave radio for commercial communications.\n\nAmateur radio operators also discovered that long-distance communication was possible on shortwave bands. Early long-distance services used surface wave propagation at very low frequencies, which are attenuated along the path at wavelengths shorter than 1,000 meters. Longer distances and higher frequencies using this method meant more signal loss. This, and the difficulties of generating and detecting higher frequencies, made discovery of shortwave propagation difficult for commercial services.\n\nRadio amateurs may have conducted the first successful transatlantic tests in December 1921, operating in the 200 meter mediumwave band (near 1,500 kHz in the modern AM broadcast band) – the shortest wavelength then available to amateurs. In 1922 hundreds of North American amateurs were heard in Europe on 200 meters and at least 20 North American amateurs heard amateur signals from Europe. The first two-way communications between North American and Hawaiian amateurs began in 1922 at 200 meters. Although operation on wavelengths shorter than 200 meters was technically illegal (but tolerated as the authorities mistakenly believed at first that such frequencies were useless for commercial or military use), amateurs began to experiment with those wavelengths using newly available vacuum tubes shortly after World War I.\n\nExtreme interference at the longer edge of the 150–200 meter band – the official wavelengths allocated to amateurs by the Second National Radio Conference in 1923 – forced amateurs to shift to shorter and shorter wavelengths; however, amateurs were limited by regulation to wavelengths longer than 150 meters (2 MHz). A few fortunate amateurs who obtained special permission for experimental communications at wavelengths shorter than 150 meters completed hundreds of long distance two way contacts on 100 meters (3 MHz) in 1923 including the first transatlantic two way contacts.\n\nBy 1924 many additional specially licensed amateurs were routinely making transoceanic contacts at distances of 6,000 miles (9,600 km) and more. On 21 September 1924 several amateurs in California completed two-way contacts with an amateur in New Zealand. On 19 October amateurs in New Zealand and England completed a 90 minute two-way contact nearly halfway around the world. On 10 October the Third National Radio Conference made three shortwave bands available to U.S. amateurs at 80 meters (3.75 MHz), 40 meters (7 MHz) and 20 meters (14 MHz). These were allocated worldwide, while the 10 meter band (28 MHz) was created by the Washington International Radiotelegraph Conference on 25 November 1927. The 15 meter band (21 MHz) was opened to amateurs in the United States on 1 May 1952.\n\nShortwave radio frequency energy is capable of reaching any location on the Earth as it is influenced by ionospheric reflection back to the earth by the ionosphere, (a phenomenon known as \"skywave propagation\"). A typical phenomenon of shortwave propagation is the occurrence of a skip zone where reception fails. With a fixed working frequency, large changes in ionospheric conditions may create skip zones at night.\n\nAs a result of the multi-layer structure of the ionosphere, propagation often simultaneously occurs on different paths,\nscattered by the E or F region and with different numbers of hops, a phenomenon that may be disturbed for certain techniques. Particularly for lower frequencies of the shortwave band, absorption of radio frequency energy in the lowest ionospheric layer, the D layer, may impose a serious limit. This is due to collisions of electrons with neutral molecules, absorbing some of a radio frequency's energy and converting it to heat. Predictions of skywave propagation depend on:\n\nSeveral different types of modulation are used to incorporate information in a short-wave signal.\n\nAmplitude modulation is the simplest type and the most commonly used for shortwave broadcasting. The instantaneous amplitude of the carrier is controlled by the amplitude of the signal (speech, or music, for example). At the receiver, a simple detector recovers the desired modulation signal from the carrier.\n\nSingle sideband transmission is a form of amplitude modulation but in effect filters the result of modulation. An amplitude-modulated signal has frequency components both above and below the carrier frequency. If one set of these components is eliminated as well as the residual carrier, only the remaining set is transmitted. This reduces power in the transmission, as roughly of the energy sent by an AM signal is in the “carrier”, which is not needed to recover the information contained in the signal. It also reduces signal bandwidth, enabling less than one-half the AM signal bandwidth to be used.\n\nThe drawback is the receiver is more complicated, since it must re-create the carrier to recover the signal. Small errors in the detection process greatly affect the pitch of the received signal. As a result, single sideband is not used for music or general broadcast. Single sideband is used for long-range voice communications by ships and aircraft, Citizen's Band, and amateur radio operators. Lower sideband (LSB) is customarilly used below 9 MHz and USB (upper sideband) above 9 MHz.\n\nVestigal sideband transmits the carrier and one complete sideband, but filters out the other sideband. It is a compromise between AM and SSB, enabing simple receivers to be used, but requires almost as much transmitter power as AM. One advantage is only half the bandwidth of an AM signal is used. It can be heard in the transmission of certain radio time signal stations. Vestigial sideband is used for over the air Television Broadcasts both analog and digital.\n\nNarrow-band frequency modulation (NBFM or NFM) is used typically above 20 MHz. Because of the larger bandwidth required, NBFM is commonly used for VHF communication. Regulations limit the bandwidth of a signal transmitted in the HF bands, and the advantages of frequency modulation are greatest if the FM signal has a wide bandwidth. NBFM is limited to short-range transmissions due to the multiphasic distortions created by the ionosphere.\n\nDigital Radio Mondiale (DRM) is a digital modulation for use on bands below 30 MHz. It is a digital signal, like the data modes, below, but is for transmitting audio, like the analog modes above.\n\nContinuous wave (CW) is on-and-off keying of a carrier, used for Morse code communications and Hellschreiber facsimile-based teleprinter transmissions. It is a data mode, although often listed separately.\n\nRadioteletype, fax, digital, slow-scan television, and other systems use forms of frequency-shift keying or audio subcarriers on a shortwave carrier. These generally require special equipment to decode, such as software on a computer equipped with a sound card.\n\nNote that on modern computer-driven systems, digital modes are typically sent by coupling a computer's sound output to the SSB input of a radio.\n\nSome established users of the shortwave radio bands may include:\n\nSporadic or non-traditional users of the shortwave bands may include:\n\n\"See International broadcasting for details on the history and practice of broadcasting to foreign audiences.\"\n\n\"See Shortwave relay station for the actual kinds of integrated technologies used to bring high power signals to listeners.\"\n\nThe World Radiocommunication Conference (WRC), organized under the auspices of the International Telecommunication Union, allocates bands for various services in conferences every few years. The last WRC took place in 2007.\n\nAt WRC-97 in 1997, the following bands were allocated for international broadcasting. AM shortwave broadcasting channels are allocated with a 5 kHz separation for traditional analog audio broadcasting.\n\nAlthough countries generally follow the table above, there may be small differences between countries or regions. For example, in the official bandplan of the Netherlands, the 49 m band starts at 5.95 MHz, the 41 m band ends at 7.45 MHz, the 11 m band starts at 25.67 MHz, and the 120, 90 and 60 m bands are absent altogether. Additionally, international broadcasters sometimes operate outside the normal WRC-allocated bands or use off-channel frequencies. This is done for practical reasons, or to attract attention in crowded bands (60m, 49m, 40m, 41m, 31m, 25m).\n\nThe new digital audio broadcasting format for shortwave DRM operates 10 kHz or 20 kHz channels. There are some ongoing discussions with respect to specific band allocation for DRM, as it mainly transmitted in 10 kHz format.\n\nThe power used by shortwave transmitters ranges from less than one watt for some experimental and amateur radio transmissions to 500 kilowatts and higher for intercontinental broadcasters and over-the-horizon radar. Shortwave transmitting centers often use specialized antenna designs (like the ALLISS antenna technology) to concentrate radio energy at the target area.\n\nShortwave does possess a number of advantages over newer technologies, including the following:\n\nShortwave radio's benefits are sometimes regarded as being outweighed by its drawbacks, including:\n\nThe Asia-Pacific Telecommunity estimates that there are approximately 600 million shortwave broadcast-radio receivers in use in 2002. WWCR claims that there are 1.5 billion shortwave receivers worldwide.\n\nMany hobbyists listen to shortwave broadcasters. In some cases, the goal is to hear as many stations from as many countries as possible \"(DXing)\"; others listen to specialized shortwave utility, or \"ute\", transmissions such as maritime, naval, aviation, or military signals. Others focus on intelligence signals from numbers stations, stations which transmit strange broadcast usually for intelligence operations, or the two way communications by amateur radio operators. Some short wave listeners behave analogously to \"lurkers\" on the Internet, in that they listen only and never make any attempt to send out their own signals. Other listeners participate in clubs, or actively send and receive QSL cards, or become involved with amateur radio and start transmitting on their own.\n\nMany listeners tune the shortwave bands for the programmes of stations broadcasting to a general audience (such as Radio Taiwan International, China Radio International, Voice of America, Radio France Internationale, BBC World Service, Voice of Korea, Radio Free Sarawak etc.). Today, through the evolution of the Internet, the hobbyist can listen to shortwave signals via remotely controlled or web controlled shortwave receivers around the world, even without owning a shortwave radio. Many international broadcasters offer live streaming audio on their websites and a number have closed their shortwave service entirely, or severely curtailed it, in favour of internet transmission.\n\nShortwave listeners, or SWLs, can obtain QSL cards from broadcasters, utility stations or amateur radio operators as trophies of the hobby. Some stations even give out special certificates, pennants, stickers and other tokens and promotional materials to shortwave listeners.\n\nSome musicians have been attracted to the unique aural characteristics of shortwave radio which—due to the nature of amplitude modulation, varying propagation conditions, and the presence of interference—generally has lower fidelity than local broadcasts (particularly via FM stations). Shortwave transmissions often have bursts of distortion, and \"hollow\" sounding loss of clarity at certain aural frequencies, altering the harmonics of natural sound and creating at times a strange \"spacey\" quality due to echoes and phase distortion. Evocations of shortwave reception distortions have been incorporated into rock and classical compositions, by means of delays or feedback loops, equalizers, or even playing shortwave radios as live instruments. Snippets of broadcasts have been mixed into electronic sound collages and live musical instruments, by means of analogue tape loops or digital samples. Sometimes the sounds of instruments and existing musical recordings are altered by remixing or equalizing, with various distortions added, to replicate the garbled effects of shortwave radio reception.\n\nThe first attempts by serious composers to incorporate radio effects into music may be those of the Russian physicist and musician Léon Theremin, who perfected a form of radio oscillator as a musical instrument in 1928 (regenerative circuits in radios of the time were prone to breaking into oscillation, adding various tonal harmonics to music and speech); and in the same year, the development of a French instrument called the Ondes Martenot by its inventor Maurice Martenot, a French cellist and former wireless telegrapher. Karlheinz Stockhausen used shortwave radio and effects in works including \"Hymnen\" (1966–67), \"Kurzwellen\" (1968)—adapted for the Beethoven Bicentennial in \"Opus 1970\" with filtered and distorted snippets of Beethoven pieces—\"Spiral\" (1968), \"Pole\", \"Expo\" (both 1969–70), and \"Michaelion\" (1997).\n\nCypriot composer Yannis Kyriakides incorporated shortwave numbers station transmissions in his 1999 \"ConSPIracy cantata\".\n\nHolger Czukay, a student of Stockhausen, was one of the first to use shortwave in a rock music context. In 1975, German electronic music band Kraftwerk recorded a full length concept album around simulated radiowave and shortwave sounds, entitled \"Radio-Activity\". The The's Radio Cineola monthly broadcasts drew heavily on shortwave radio sound.\n\nThe development of direct broadcasts from satellites has reduced the demand for shortwave receiver hardware, but there are still a great number of shortwave broadcasters. A new digital radio technology, Digital Radio Mondiale (DRM), is expected to improve the quality of shortwave audio from very poor to standards comparable to the FM broadcast band. The future of shortwave radio is threatened by the rise of power line communication (PLC), also known as Broadband over Power Lines (BPL), which uses a data stream transmitted over unshielded power lines. As the BPL frequencies used overlap with shortwave bands, severe distortions can make listening to analog shortwave radio signals near power lines difficult or impossible.\n\nExperts disagree on the future of shortwave. According to Andy Sennitt, former editor of the World Radio TV Handbook, “shortwave is a legacy technology, which is expensive and environmentally unfriendly. A few countries are hanging on to it, but most have faced up to the fact that the glory days of shortwave have gone. Religious broadcasters will still use it because they are not too concerned with listening figures\".\n\nHowever Thomas Witherspoon, editor of shortwave news site SWLingPost.com wrote that “shortwave remains the most accessible international communications medium that still provides listeners with the protection of complete anonymity\". According to Nigel Fry, head of Distribution for the BBC World Service Group, “I still see a place for shortwave in the 21st century, especially for reaching areas of the world that are prone to natural disasters that destroy local broadcasting and Internet infrastructure\".\n\n\n\n"}
{"id": "43150808", "url": "https://en.wikipedia.org/wiki?curid=43150808", "title": "Spy Booth", "text": "Spy Booth\n\nSpy Booth was an artwork by Banksy in Cheltenham, England. The piece has been seen as a critique of the global surveillance disclosures of 2013.\n\nIn 2014, Robin Barton and Bankrobber London helped with the preservation of the artwork, and attempted to broker the removal and sale of the piece. However the artwork was painted onto a Grade II listed building - 153-159 Fairview Road - and the council prevented it from being removed, giving it retrospective listed building consent in 2015 and affording it some protection from removal. Despite this, the artwork was either removed or destroyed in August 2016.\n\nThe GCHQ has used the picture on its website as a symbolic image for its \"what we do\" page.\n"}
{"id": "3870084", "url": "https://en.wikipedia.org/wiki?curid=3870084", "title": "The Globalization of World Politics", "text": "The Globalization of World Politics\n\nThe Globalization of World Politics: An Introduction to International Relations is a book by John Baylis, Patricia Owens, and Steve Smith.\n\nJohn Baylis, Steve Smith and Patricia Owens: Introduction\nThe historical context\nTheories of world politics\nStructures and processes\nInternational issues\nGlobalization in the future\n"}
{"id": "51562654", "url": "https://en.wikipedia.org/wiki?curid=51562654", "title": "Timeline of tuberculosis", "text": "Timeline of tuberculosis\n\nThis is a timeline of tuberculosis, describing especially major discoveries, advances in treatment and major organizations.\n\n"}
{"id": "55897564", "url": "https://en.wikipedia.org/wiki?curid=55897564", "title": "Transnational gangs", "text": "Transnational gangs\n\nTransnational gangs can be described as gangs that are located in multiple countries. When these gangs commit crimes in one country, their plans for the crime can sometimes be put together in another country. These gangs or mara are able to move around efficiently from one place to another. Transnational gangs are not a normal street gang because they are much larger in size and located in more than one country; they are considered to be able to pose a significant threat for the safety of the countries they are located in.\n\nThe Mara Salvatrucha, or the MS-13 gang are located in the United States, Canada, Mexico and El Salvador. The Mara Salvatrucha gang was founded in the 1980s in Los Angeles, California. The original members of the Mara Salvatrucha were refugees from El Salvador that came to the United States . The Barrio 18 or the 18th Street Gang is the Mara Salvatrucha's main rivals.\n\nThe 18th Street Gang, also known as the Barrio 18, are located in the United States, Canada, Central America and Mexico. The 18th Street Gang is a youth gang. The current gang was founded in the 1980s in Los Angeles, California. The 18th Street Gang was originally part of the Clanton 14 Gang, but they divided in the 1980s; the gang was originally started by Mexican immigrants. The Mara Salvatucha are considered the 18th Street Gang's enemies .\n\nThe Barrio Azteca are a prison gang that are located in the United States and Mexico. The Barrio Azteca was founded in 1986 in El Paso, Texas. The prison gang was started by Mexican prisoners that were incarcerated in El Paso. The Sinaloa Cartel is one of the Barrio Azteca's major enemies.\n\nThe Hells Angels are an outlaw motorcycle gang. They are located in the United States, Europe, Canada, Oceania, Africa, Asia, South America and Central America. The gang was founded on March 7, 1948 in Fontana, California and San Bernardino, California. The Hells Angels are considered to be a gang because they fit the definition of a gang; one of the requirements to be considered a gang is to participate in some form of crime. The crimes that the Hells Angels participate in include the transportation, production and distribution of drugs, assault, homicide, motorcycle theft, extortion, money laundering.\n\nThe Black Pistons are an outlaw motorcycle gang. They are located in the United States, Wales, Scotland, Iceland, Australia, England, Norway, Ireland, Belgium, Switzerland, Poland, Germany and Canada. The gang was founded in Germany in 2002 as a support for the Outlaws Motorcycle Club. They are considered a gang because they meet the requirements of a gang, which include committing crimes. The crimes that the Black Pistons commit are theft, assault, intimidation, extortion, fraud and many others.\n"}
{"id": "32147", "url": "https://en.wikipedia.org/wiki?curid=32147", "title": "Union of International Associations", "text": "Union of International Associations\n\nThe Union of International Associations (UIA) is a non-profit non-governmental research institute and documentation center based in Brussels, Belgium, and operating under United Nations mandate. It was founded in 1907 under the name Central Office of International Associations by Henri La Fontaine, the 1913 Nobel Peace Prize laureate, and Paul Otlet, a founding father of what is now called information science.\n\nThe UIA is an independent research institute and a repository for current and historical information on the work of global civil society. It serves two main purposes: to document and promote public awareness of the work of international organizations (both INGOs and IGOs), international meetings, and world problems. The UIA also supports and facilitates the work of international associations through training and networking opportunities.\n\nIt has consultative status with ECOSOC and UNESCO.\n\n\nThe two founders started work setting up the Central Office of International Organisations and then conducting a survey of international organisations with headquarters in Belgium. Then with the help of the sociologist Cyril van Overbergh they extend this research to organisations based elsewhere. After collaborating with Alfred Fried on the production of \"Annuaire de la Vie Internationale\" they produced their own edition without him.\n\n\n"}
{"id": "24353287", "url": "https://en.wikipedia.org/wiki?curid=24353287", "title": "WHO collaborating centres in occupational health", "text": "WHO collaborating centres in occupational health\n\nThe WHO collaborating centres in occupational health constitute a network of institutions put in place by the World Health Organization to extend availability of occupational health coverage in both developed and undeveloped countries. The effort includes 64 collaborating centres that have been designated as such by the WHO director-general. The centres in the network meet triennially to develop work plans for advancing occupational health in key areas. The 2009-2012 work plan includes 220 projects, which relate to 5 objectives and 14 priorities as outlined by a global plan of action for workers' health. \n\nAs director of the U.S. National Institute for Occupational Safety and Health, John Howard is the chairman of the WHO Global Network of Collaborating Centres in Occupational Health. Within the network, activity area managers plan day-to-day activities within projects adopted by the network. Deputy managers monitor activities and evaluate progress of the involved centres.\n\nThe global plan of action sets forth five major objectives:\nUsing these key goals, the activity area managers have set priorities for specific areas of occupational health.\n\nCentres in the network are designated by the WHO director-general. Seven organizations constitute the network's advisory committee:\n\nOther participants working with the centres include the International Labour Organization (ILO), the International Commission on Occupational Health (ICOH), the International Occupational Hygiene Association (IOHA), and the International Ergonomics Association (IEA).\n\nThe collaborating centres have participated in a number of conferences, provided research on occupational safety and health topics, and engaged in varied campaigns and activities such as an inititiative promoting global road safety for workers.\n"}
{"id": "4197326", "url": "https://en.wikipedia.org/wiki?curid=4197326", "title": "Women's World Golf Rankings", "text": "Women's World Golf Rankings\n\nThe Women's World Golf Rankings, also known for sponsorship reasons as the Rolex Rankings, were introduced in February 2006. They are sanctioned by eight women's golf tours and the organisations behind them: Ladies Professional Golf Association (LPGA Tour), Ladies European Tour, Ladies Professional Golfers' Association of Japan (LPGA of Japan Tour), Korea Ladies Professional Golf Association (LPGA of Korea Tour), Australian Ladies Professional Golf (ALPG Tour), Symetra Tour, China Ladies Professional Golf Association Tour, the Ladies European Tour Access Series and also by the Ladies' Golf Union, which administers the Women's British Open and the United States Golf Association which conducts the U.S. Women's Open.\n\nThe idea of introducing a set of women's rankings similar to the Official World Golf Ranking was developed at the May 2004 World Congress of Women's Golf, and was first planned for 2005, but then put back to 2006.\n\nThe rankings are based on performances on the eight major tours (LPGA, JLPGA, KLPGA, LET, ALPG, Symetra Tour, LETAS, CLPGA) over a two-year period. Amateur players are eligible. The system for calculating the rankings is similar to that for the men's Official World Golf Ranking. Players receive points for each good finish on the relevant tours, with the number of points available in each event depending on the strength of the field, as determined by the competitors' existing rankings (when the rankings were introduced rankings were calculated for earlier periods; the first ever set showed notional changes since the previous week). The only exceptions are the five LPGA majors and all Symetra Tour, CLPGA and LETAS events, which have a fixed-point allocation. Rankings are tapered so the recent results are more important.\n\nWhen the rankings were first introduced in February 2006, a player's ranking as calculated in the above description was divided by the number of events played, with a minimum required events of 15 over the previous two years. In addition, players were required to play in a minimum of 15 eligible events over the previous two-year period to be included in the rankings.\n\nOn 2 August 2006 the Rolex Rankings Board and Technical Committee announced following its bi-annual meeting two changes to the ranking formula. \n\nMany commentators saw the latter change as directed at Michelle Wie, who at the time was ranked second in the world despite having competed in only 16 women's professional events in the two-year period. However, the chairman of the Rolex Rankings Technical Committee defended the change as one designed to make the women's rankings more comparable to the Official World Golf Ranking for men, which use a minimum divisor of 40 events.\n\nOn 16 April 2007, another modification in the formula was introduced. Instead of points being awarded on an accumulated 104-week rolling period, with the points awarded in the most recent 13-week period carrying a stronger value, points began to be reduced in 91 equal decrements following week 13 for the remaining 91 weeks of the two-year Rolex Ranking period rather than the seven equal 13 week decrements previously used. This modification did not have an immediate impact on the rankings.\n\nWhen they were introduced the rankings attracted considerable criticism on two grounds. First, it was widely felt that members of the LPGA of Japan Tour were ranked too high, since few of them had competed successfully outside Japan. Second, the minimum of 15 events needed to qualify for a ranking was widely seen as having been selected purely to enable Michelle Wie to be highly ranked because she had played exactly that number in the preceding two years, while every other highly ranked player had played many more events. If the women's rankings used the same system used for the men's rankings – that is a minimum number of events of one but a minimum denominator of 40 to calculate the average points per tournament – Wie would have been just outside the top 10. But under the women's ranking system where only players who had played a minimum number of events were included, if the minimum number of events had been set higher than 15, Wie would not have been ranked at all.\n\nThe August 2006 revised formula addressed the second criticism. The technical committee that administers the rankings urged patience with regard to the first criticism, since the continuing \"strength of the field\" weighting of tournaments may correct the issue without any technical changes being made.\n\nThe rankings are used by each of the sponsoring tours to determine eligibility criteria for certain events. For example, 40 of the 144 places in the Women's British Open are currently awarded on the basis of the rankings—10 to LET members and 30 to LPGA members. Four of the 12 places in the European Solheim Cup team are allocated on the basis of the rankings.\n\nSince 2013, the rankings at the end of each LPGA Tour season in odd-numbered years have determined the eight countries that will compete in the following year's International Crown, a LPGA-sponsored team event scheduled in even-numbered years and first held in 2014. More specifically, the countries whose top four players have the highest cumulative rankings are invited to compete. The individual participants from each qualified country are determined by the rankings immediately prior to the ANA Inspiration (known before 2015 as the Kraft Nabisco Championship) in the year of the event.\n\n\"As of 26 November 2018\"\nChange column indicates change in rank from previous week.\nNotes \n\n\"As of 26 November 2018\"\nActive players are in bold.</small>\n\nAnnika Sörenstam of Sweden topped the first set of rankings, which was released on Tuesday 21 February 2006. Paula Creamer (United States); Michelle Wie (United States); Yuri Fudoh (Japan); and Cristie Kerr (United States) took the other places in the top 5. The top one hundred players in the initial rankings came from the following countries:\n\n\n"}
{"id": "7095889", "url": "https://en.wikipedia.org/wiki?curid=7095889", "title": "World's longest hot dog", "text": "World's longest hot dog\n\nThe current world's longest meat hot dog record holder measured and was manufactured by Novex of Paraguay in 2011. Sara Lee Corp. made a hot dog, long, in commemoration of the 1996 Summer Olympics in Atlanta. \"Guinness World Records\" does not reflect this record in any of its publications as of 2006. Speculation surrounding the 1996-foot record is that although the hot dog was most likely continuous, the bun (an integral part of the hot dog unit) was not. Since October 2017 the town Flensburg, in Germany claimed to have manufactured the World's longest hot dog with .\n\nOn July 15, 2011, a hot dog measuring and weighing approximately was made by Ochsi to obtain the world record. The hot dog bun weighed approximately and was made by Myriam Products. International media were on hand, and supporting documents have been verified by Johanna Hessling, of Guinness. The hot dog was made as the central part of a media event surrounding the 2011 Expo in Asuncion, Paraguay. After the official measurement, the hot dog was cut up and eaten by those present.\n\nOn October 3, 2017 was by local authorities in Flensburg on the seabridge of the suburb Glücksburg a U-shaped hot dog measured with . After the official measurement, the hot dog was also cut up and eaten by those present.\n\n\nCreating a long hot dog is not much of a feat. This is because the hot dog is structurally quite sound, and remarkably flexible. In the August 2006 record breaking attempt, the hot dog was manufactured by Shizuoka Meat Producers, and wound into a large plastic barrel which was easily transported inside a delivery van.\n\nThe limiting factor for breaking this type of record is the bun. The bun, in order to remain in one continuous unit, needs to be baked in its final form. For the All-Japan Bread Association, this meant the connection of the longest conveyor belt possible with the equipment available to them. The dough was assembled in half-meter sections, then pressed together to create a longer tube of dough, which was then fed through the ovens via conveyor, and carried away from the ovens by another conveyor. The key was to make sure that the already-cooked bun did not move at a faster rate than the bun behind it because this would cause the bun to pull apart. The wiener was fed through the oven at the same time to cook it. There also needed to be space outside the oven to store the bun and wiener until the entire bun had been baked. To allow for enough room for this to happen, the ovens and prep area were set up outside the ballroom of the Akasaka Prince Hotel on the loading dock, and the bun and wiener were fed into the ballroom along the conveyor as they exited the oven.\n\nUpon completion, the bun was sliced down the middle by bakers, and spectators were asked to don rubber gloves and first lift the wiener in one piece for photos, and then insert it into the bun. After being topped with mustard and ketchup, the completed hot dog was lifted by the assembled spectators off the conveyor for photos. Finally, the official measurement was completed, and the wiener was in length, with the bun coming in at in length. After photos and video of the official measurement were completed, the hot dog was cut into sections and the assembled spectators each had a piece. However, this only used about of the hot dog.\n"}
{"id": "19244712", "url": "https://en.wikipedia.org/wiki?curid=19244712", "title": "World Development Report", "text": "World Development Report\n\nThe World Development Report (WDR) is an annual report published since 1978 by the International Bank for Reconstruction and Development (IBRD) or World Bank. Each WDR provides in-depth analysis of a specific aspect of economic development. Past reports have considered such topics as agriculture, youth, equity, public services delivery, the role of the state, transition economies, labour, infrastructure, health, the environment, risk management, and poverty. The reports are the Bank's best-known contribution to thinking about development.\n\nThe World Development Report 2019 studies the impact of technology on the nature of work. It is the most-downloaded World Development Report, with more than a million downloads, half of which before its official publication. The study was led by Simeon Djankov and Federica Saliola.\n\n\"The World Development Report 2014 Risk and Opportunity: Managing Risk for Development\" looked at risk management from a development perspective. It argued that managing risks such as job loss, crime, disease, disaster, social unrest, and financial and macroeconomic turbulence responsibly can save lives, avert damages, prevent development setbacks, and unleash opportunities. The report proposed a conceptual framework for thinking about risk and resilience, identified obstacles to better risk management, and recommended numerous avenues for better risk management that can be pursued by individuals, families, communities, enterprises, governments, and the international community.\n\n\"The World Development Report 2011: Conflict, Security, and Development\" looked at conflict as a challenge to economic development. It analyzed the nature, causes and development consequences of modern violence and highlight lessons learned from efforts to prevent or recover from violence.\nThe goal of this WDR was considered to promote new ways of preventing or addressing violent conflict. By drawing on insight and experiences from a host of past and present situations, the report identified promising national and regional initiatives as well as directions for change in international responses, and discuss how lessons can be applied in situations of vulnerability to violent conflict.\nThe World Development Report is published by the World Bank.\n\nThe WDR 2010, on the theme \"Development and Climate Change\", explored how public policy can change to better help people cope with new or worsened risks, how land and water management must adapt to better protect a threatened natural environment while feeding an expanding and more prosperous population, and how energy systems will need to be transformed. The report was seen as a call for action, both for developing countries who are striving to ensure policies are adapted to the realities and dangers of a hotter planet, and for high-income countries who need to undertake ambitious mitigation while supporting developing countries’ efforts.\n\nThe WDR 2009 focused on the theme \"Reshaping Economic Geography\". Rising densities of human settlements, migration and transport to reduce distances to market, and specialization and trade facilitated by fewer international divisions are central to economic development. The transformations along these three dimensions—density, distance, and division—are most noticeable in North America, Western Europe, and Japan, but countries in Asia and Eastern Europe are changing in ways similar in scope and speed.\n\nThe report concludes that these spatial transformations are essential, and should be encouraged. The conclusion is not without controversy. Slum-dwellers now number a billion, but the rush to cities continues. Globalization is believed to benefit many, but not the billion people living in lagging areas of developing nations. High poverty and mortality persist among the world's \"bottom billion\", while others grow wealthier and live longer lives. Concern for these three billion often comes with the prescription that growth must be made spatially balanced. The WDR has a different message: economic growth is seldom balanced, and efforts to spread it out prematurely will jeopardize progress.\n\nThe WDR 2008 addressed \"Agriculture for Development\", calling for greater investment in agriculture in developing countries. The report warned that the sector must be placed at the center of the development agenda if the goals of halving extreme poverty and hunger by 2015 are to be realized.\n\nWhile 75 percent of the world's poor live in rural areas in developing countries, a mere 4 percent of official development assistance goes to agriculture. In Sub-Saharan Africa, a region heavily reliant on agriculture for overall growth, public spending for farming is also only 4 percent of total government spending and the sector is still taxed at relatively high levels. For the poorest people, GDP growth originating in agriculture is about four times more effective in raising incomes of extremely poor people than GDP growth originating outside the sector.\n\n“A dynamic ‘agriculture for development’ agenda can benefit the estimated 900 million rural people in the Developing world who live on less than $1 a day, most of whom are engaged in agriculture,” said Robert B. Zoellick, World Bank Group President. “We need to give agriculture more prominence across the board. At the global level, countries must deliver on vital reforms such as cutting distorting subsidies and opening markets, while civil society groups, especially farmer organizations, need more say in setting the agricultural agenda.”\n\nAccording to the report, agriculture can offer pathways out of poverty if efforts are made to increase productivity in the staple foods sector; connect smallholders to rapidly expanding high-value horticulture, poultry, aquaculture, as well as dairy markets; and generate jobs in the rural nonfarm economy.\n\nThe World Development Report began as a series of annual publications in the year 1978 with its first report titled \"Prospects for Growth and Alleviation of Poverty.\" Since then, it has focused each year on a particular theme that is central to development and the reports present a detailed study of the relevant sectors, applications and toolkits developed. The reports and their titles are as follows:\n\n\n\n"}
{"id": "54729058", "url": "https://en.wikipedia.org/wiki?curid=54729058", "title": "World Mental Health survey initiative", "text": "World Mental Health survey initiative\n\nThe World Mental Health Survey Initiative is a collaborative project by World Health Organization, Harvard University, University of Michigan, and country-based researchers worldwide to coordinate the analysis and implementation of epidemiological surveys of mental and behavioral disorders and substance abuse in all WHO Regions.\n\nIt is estimated that the burden of mental and addictive disorders are among the highest in the world with expected increase over the next decades. However, those estimations are not based on cross-sectional epidemiological surveys, rather, they are mainly based on literature reviews and isolated studies.\nThe WMH Survey Initiative aim is to accurately address the global burden of mental disorders by obtaining accurate cross-sectional information about the prevalences and correlates of mental and behavioral disorders as well as substance abuse, allowing for evaluation of risk factors and study of patterns of service use in order to target appropriate interventions.\n\nCollaborators in this survey come from all WHO regions of the world, with 27 participating countries.\n"}
{"id": "99221", "url": "https://en.wikipedia.org/wiki?curid=99221", "title": "World government", "text": "World government\n\nWorld government or global government is the notion of a common political authority for all of humanity, yielding a global government and a single state that exercises authority over the entire Earth. Such a government could come into existence either through violent and compulsory world domination or through peaceful and voluntary supranational union.\n\nThere has never been a worldwide executive, legislature, judiciary, military, or constitution with global jurisdiction. The United Nations, beyond the United Nations Security Council (which has the ability to issue mandatory resolutions), is limited to a mostly advisory role, and its stated purpose is to foster co-operation between existing national governments rather than exert authority over them.\n\nThe idea and aspiration of world government has been known since the dawn of history. Bronze Age Egyptian Kings aimed to rule \"All That the Sun Encircles\", Mesopotamian Kings \"All from the Sunrise to the Sunset\", and ancient Chinese and Japanese Emperors \"All under Heaven\". These four civilizations developed impressive cultures of Great Unity, or Da Yitong as the Chinese put it. In 113 BC, the Han Dynasty in China erected an Altar of the Great Unity.\n\nPolybius said that the Roman achievement of imposing one Government over the Mediterranean world was a \"marvelous\" achievement, and that the main task of future historians will be to explain how this was done.\n\nThe idea of world government outlived the fall of the Pax Romana for a millennium. Dante in the fourteenth century despairingly appealed to the human race: \"But what has been the condition of the world since that day the seamless robe [of Pax Romana] first suffered mutilation by the claws of avarice, we can read—would that we could not also see! O human race! what tempests must need toss thee, what treasure be thrown into the sea, what shipwrecks must be endured, so long as thou, like a beast of many heads, strivest after diverse ends! Thou art sick in either intellect, and sick likewise in thy affection. Thou healest not thy high understanding by argument irrefutable, nor thy lower by the countenance of experience. Nor dost thou heal thy affection by the sweetness of divine persuasion, when the voice of the Holy Spirit breathes upon thee, \"Behold, how good and how pleasant it is for brethren to dwell together in unity!\"\" (\"De Monarchia\", 16:1)\n\nEarly father of international law, Spanish philosopher Francisco de Vitoria (c. 1483–1546) is considered the \"founder of global political philosophy\". De Vitoria conceived of the \"res publica totius orbis\", or the \"republic of the whole world\". This came at a time when the University of Salamanca was engaged in unprecedented thought concerning human rights, international law, and early economics based on the experiences of the Spanish Empire.\n\n\"De jure belli ac pacis\" (\"On the Law of War and Peace\") is a 1625 book in Latin, written by Hugo Grotius (1583–1645) and published in Paris, on the legal status of war. It is now regarded as a foundational work in international law. Grotius was a philosopher, theologian, playwright, and poet. He is known for coming up with the idea of having an international law, and is still acknowledged today by the American Society of International Law.\n\nImmanuel Kant wrote the essay \" () (1795)\". In his essay, Kant describes three basic requirements for organizing human affairs to permanently abolish the threat of present and future war, and, thereby, help establish a new era of lasting peace throughout the world. Specifically, Kant described his proposed peace program as containing two steps.\n\nThe \"Preliminary Articles\" described the steps that should be taken immediately, or with all deliberate speed:\n\n\nThree Definitive Articles would provide not merely a cessation of hostilities, but a foundation on which to build a peace.\n\n\nThe year of the battle at Jena (1806), when Napoleon overwhelmed Prussia, Fichte in \"Characteristics of the Present Age\" described what he perceived to be a very deep and dominant historical trend:\n\nIn early 19th century Mormon theology, Joseph Smith taught that a theodemocracy would guide and direct the Kingdom of God (Zion) on the earth during the end times. On March 11, 1844, Smith organized a Council of Fifty, who were to work under the direction of the Priesthood authorities of his church, along with a Council of Friends. This group of three organizations was expected to rule as a world government just prior to the Millennium.\n\nIn 1842, the English poet Alfred, Lord Tennyson, published the oft-quoted lines \"Locksley Hall\": \"For I dipt into the future, far as human eye could see / Saw a Vision of the world, and all the wonder that would be /... / Till the war-drum throbb'd no longer / and the battle-flags were furled / In the Parliament of man, the Federation of the world. / There the common sense of most shall hold / a fretful realm in awe / And the kindly earth shall slumber / lapt in universal law\".\n\nPresident Ulysses S. Grant was convinced in 1873: \"Transport, education and rapid development of both spiritual and material relationships by means of steam power and the telegraph, all this will make great changes. I am convinced that the Great Framer of the World will so develop it that it becomes one nation, so that armies and navies are no longer necessary.\"\n\nHe also commented, \"I believe at some future day, the nations of the earth will agree on some sort of congress which will take cognizance of international questions of difficulty and whose decisions will be as binding as the decisions of the Supreme Court are upon us\".\n\nThe first thinker to anticipate a kind of world unity (\"great household of the world\") under the American primacy seems to be British politician William Gladstone. In 1878, he wrote:\n\nIn 1885, Kang Youwei published his \"One World Philosophy\", where he based his vision on the evidence of political expansion which began in the immemorial past and went in his days on. He concludes:\n\nNo factor, he believed, in the long run could resist the \"laws of empires\". Kang Youwei projects the culmination of the ongoing world unification with the final confrontation between the United States and Germany: \"Some day America will take in [all the states of] the American continent and Germany will take in all the [states of] Europe. This will hasten the world along the road to One World.\"\n\nFriedrich Nietzsche in his \"Beyond Good and Evil\" (1886) envisaged: \nThe French demographer, George Vacher de Lapouge, followed K'ang Yu-wei in 1899 with his \"L'Aryen: Son Role Social\". Similarly, he outlined the logistic growth of empires from the Bronze Age till his days, when \"six states govern... three quarters of the globe\", and concluded: \"The moment is close when the struggle for the domination of the world is going to take place.\"\n\nVacher de Lapouge did not bet on Washington and Berlin in the final contest for world domination contrary to K'ang Yu-wei. Like his earlier compatriot, Alexis de Tocqueville, he guessed the Cold War contenders correctly but he went one step further. He estimated the chances of the United States as favorite in the final confrontation:\n\nIn the second half of the 19th century, Bahá'u'lláh founded the Bahá'í Faith, a religion which identified the establishment of world unity and a global federation of nations as a key principle. He envisioned a set of new social structures based on participation and consultation among the world's peoples, including a world legislature, an international court, and an international executive empowered to carry out the decisions of these legislative and judicial bodies. Connected principles of the Bahá'í religion include universal systems of weights and measures, currency unification, and the adoption of a global auxiliary language.\n\nIn \"World Order of Bahá'u'lláh,\" first published in 1938, Shoghi Effendi, great-grandson of Bahá'u'lláh and the Guardian of the Bahá'í Faith from 1921 until his death in 1957, described the anticipated world government of that religion as the \"world's future super-state\" with the Bahá'í Faith as the \"State Religion of an independent and Sovereign Power\".\n\nAccording to Shoghi Effendi, \"The unity of the human race, as envisaged by Bahá'u'lláh, implies the establishment of a world commonwealth in which all nations, races, creeds and classes are closely and permanently united, and in which the autonomy of its state members and the personal freedom and initiative of the individuals that compose them are definitely and completely safeguarded. This commonwealth must, as far as we can visualize it, consist of a world legislature, whose members will, as the trustees of the whole of mankind, ultimately control the entire resources of all the component nations, and will enact such laws as shall be required to regulate the life, satisfy the needs and adjust the relationships of all races and peoples. A world executive, backed by an international Force, will carry out the decisions arrived at, and apply the laws enacted by, this world legislature, and will safeguard the organic unity of the whole commonwealth. A world tribunal will adjudicate and deliver its compulsory and final verdict in all and any disputes that may arise between the various elements constituting this universal system.\"\n\nIn his many scriptures and messages addressed to the most prominent state leaders of his time, Bahá'u'lláh called for world reconciliation, reunification, collective security and the peaceful settlement of disputes. Many of the most fundamental Bahá'í writings address the central issue of world unity, such as the following: \"The earth is but one country and mankind its citizens\". The World Christian Encyclopedia estimated 7.1 million Bahá'ís in the world in 2000, representing 218 countries.\n\nStarting in 1843, International Peace Congresses were held in Europe every two years, but lost their momentum after 1853 due to the renewed outbreak of wars in Europe (Crimea) and North America (American Civil War).\n\nInternational organizations started forming in the late 19th century – the International Committee of the Red Cross in 1863, the Telegraphic Union in 1865 and the Universal Postal Union in 1874. The increase in international trade at the turn of the 20th century accelerated the formation of international organizations, and, by the start of World War I in 1914, there were approximately 450 of them. Support for the idea of establishing international law grew during that period as well. The Institute of International Law was formed in 1873 by the Belgian Jurist Gustave Rolin-Jaequemyns, leading to the creation of concrete legal drafts, for example by the Swiss Johaan Bluntschli in 1866. In 1883, James Lorimer published \"The Institutes of the Law of Nations\" in which he explored the idea of a world government establishing the global rule of law. The first embryonic world parliament, called the Inter-Parliamentary Union, was organized in 1886 by Cremer and Passy, composed of legislators from many countries. In 1904 the Union formally proposed \"an international congress which should meet periodically to discuss international questions\".\n\nIn \"Anticipations\" (1900), H. G. Wells envisaged that \"the great urban region between Chicago and the Atlantic\" will unify the English-speaking states, and this larger English-speaking unit, \"a New Republic dominating the world\", will by the year 2000 become the means \"by which the final peace of the world may be assured forever\". It will be \"a new social Hercules that will strangle the serpents of war and national animosity in his cradle\". Such a synthesis \"of the peoples now using the English tongue, I regard not only as possible, but as a probable, thing\". The New Republic \"will already be consciously and pretty freely controlling the general affairs of humanity before this century closes...\" Its principles and opinions \"must necessarily shape and determine that still ampler future of which the coming hundred years is but the opening phase\". The New Republic must ultimately become a \"World-State\".\n\nThe League of Nations (LoN) was an inter-governmental organization founded as a result of the Treaty of Versailles in 1919–1920. At its largest size from 28 September 1934 to 23 February 1935, it had 58 members. The League's goals included upholding the Rights of Man, such as the rights of non-whites, women, and soldiers; disarmament, preventing war through collective security, settling disputes between countries through negotiation, diplomacy, and improving global quality of life. The diplomatic philosophy behind the League represented a fundamental shift in thought from the preceding hundred years. The League lacked its own armed force and so depended on the Great Powers to enforce its resolutions and economic sanctions and provide an army, when needed. However, these powers proved reluctant to do so. Lacking many of the key elements necessary to maintain world peace, the League failed to prevent World War II. Hitler withdrew Germany from the League of Nations once he planned to take over Europe. The rest of the Axis powers soon followed him. Having failed its primary goal, the League of Nations fell apart. The League of Nations consisted of the Assembly, the Council, and the Permanent Secretariat. Below these were many agencies. The Assembly was where delegates from all member states conferred. Each country was allowed three representatives and one vote.\n\nAccording to Karl Marx's theory of historical materialism, the capitalist epoch depends on the expansion of competing geopolitical markets across the planet, atomizing the global proletariat and thus sustaining economic disparity and rivalry between markets. Eventually, this will be succeeded by a Socialist epoch in which the working class throughout the world will unite to render national distinctiveness meaningless.\n\nAlthough world Communism's long-term goal is a worldwide Communist society that is stateless, which would entail an absence of any government, many anti-Communists (especially during the Cold War) have considered it naive to think that the world revolution advocated by international Communists would lead to world domination by a single government or an alliance of several, yielding a de facto world government of a totalitarian nature.\n\nThe heyday of international Communism was the period from the end of World War I (the revolutions of 1917–23) through the 1950s, before the Sino-Soviet split.\n\nAnticipating environmental movements for world unity, like Global Scenario Group, and such concepts as the Planetary phase of civilization and Spaceship Earth, British Geographer Sir Halford Mackinder wrote in 1931:\nThe ruling Nazi Party of 1933–1945 Germany envisaged the ultimate establishment of a world government under the complete hegemony of the Third Reich. In its move to overthrow the post-World War I Treaty of Versailles Germany had already withdrawn itself from the League of Nations, and it did not intend to join a similar internationalist organization ever again. In his desire and stated political aim of expanding the living space (\"Lebensraum\") of the German people by destroying or driving out \"lesser-deserving races\" in and from other territories dictator Adolf Hitler may have devised an ideological system of self-perpetuating expansionism, in which the expansion of a state's population would require the conquest of more territory which would, in turn, lead to a further growth in population which would then require even more conquests. In 1927, Rudolf Hess relayed to Walter Hewel Hitler's belief that world peace could only be acquired \"when one power, the racially best one, has attained uncontested supremacy\". When this control would be achieved, this power could then set up for itself a world police and assure itself \"the necessary living space... The lower races will have to restrict themselves accordingly\".\n\nDuring its imperial period (1868–1945), the Japanese elaborated a worldview, \"Hakkō ichiu\", translated as \"eight corners of the world under one roof\". This was the idea behind the attempt to establish a Greater Asian Coprosperity Sphere and behind the struggle for world domination.\n\nThe Atlantic Charter was a published statement agreed between the United Kingdom and the United States. It was intended as the blueprint for the postwar world after World War II, and turned out to be the foundation for many of the international agreements that currently shape the world. The General Agreement on Tariffs and Trade (GATT), the post-war independence of British and French possessions, and much more are derived from the Atlantic Charter. The Atlantic charter was made to show the goals of the allied powers during World War II. It first started with the United States and Great Britain, and later all the allies would follow the charter. Some goals include access to raw materials, reduction of trade restrictions, and freedom from fear and wants. The name, The Atlantic Charter, came from a newspaper that coined the title. However, Winston Churchill would use it, and from then on the Atlantic Charter was the official name. In retaliation, the Axis powers would raise their morale and try to work their way into Great Britain. The Atlantic Charter was a stepping stone into the creation of the United Nations.\nU.S. President Harry S. Truman commented: \"We must make the United Nations continue to work, and to be a going concern, to see that difficulties between nations may be settled just as we settle difficulties between States here in the United States. When Kansas and Colorado fall out over the waters in the Arkansas River, they don't go to war over it; they go to the Supreme Court of the United States, and the matter is settled in a just and honorable way. There is not a difficulty in the whole world that cannot be settled in exactly the same way in a world court\". -- President Truman's remarks in Omaha, Nebraska on June 5, 1948, at the dedication of the War Memorial. The cultural moment of the late 1940s was the peak of World Federalism among Americans.\n\nThe years between the conclusion of World War II and 1950, when the Korean War started and the Cold War mindset became dominant in international politics, were the \"golden age\" of the world federalist movement. Wendell Willkie's book \"One World\", first published in 1943, sold over 2 million copies. In another, Emery Reves' book \"The Anatomy of Peace\" (1945) laid out the arguments for replacing the UN with a federal world government and quickly became the \"bible\" of world federalists. The grassroots world federalist movement in the US, led by people such as Grenville Clark, Norman Cousins, Alan Cranston and Robert Hutchins, organized itself into increasingly larger structures, finally forming, in 1947, the United World Federalists (later renamed to World Federalist Association, then Citizens for Global Solutions), claiming membership of 47,000 in 1949.\n\nSimilar movements concurrently formed in many other countries, leading to the formation, at a 1947 meeting in Montreux, Switzerland, of a global coalition, now called World Federalist Movement. By 1950, the movement claimed 56 member groups in 22 countries, with some 156,000 members.\n\nWorld War II (1939–1945) resulted in an unprecedented scale of destruction of lives (over 60 million dead, most of them civilians), and the use of weapons of mass destruction. Some of the acts committed against civilians during the war were on such a massive scale of savagery, they came to be widely considered as crimes against humanity itself. As the war's conclusion drew near, many shocked voices called for the establishment of institutions able to permanently prevent deadly international conflicts. This led to the founding of the United Nations in 1945, which adopted the Universal Declaration of Human Rights in 1948. Many, however, felt that the UN, essentially a forum for discussion and coordination between sovereign governments, was insufficiently empowered for the task. A number of prominent persons, such as Albert Einstein, Winston Churchill, Bertrand Russell and Mohandas K. Gandhi, called on governments to proceed further by taking gradual steps towards forming an effectual federal world government. The United Nations main goal is to work on international law, international security, economic development, human rights, social progress, and eventually world peace. The United Nations replaced the League of Nations in 1945, after World War II. Almost every internationally recognized country is in the U.N.; as it contains 193 member states out of the 196 total nations of the world. The United Nations gather regularly in order to solve big problems throughout the world. There are six official languages: Arabic, Chinese, English, French, Russian and Spanish. The United Nations is also financed by some of the wealthiest nations. The flag shows the Earth from a map that shows all of the populated continents.\n\nA United Nations Parliamentary Assembly (UNPA) is a proposed addition to the United Nations System that would allow for participation of member nations' legislators and, eventually, direct election of United Nations (UN) parliament members by citizens worldwide. The idea was raised at the founding of the League of Nations in the 1920s and again following the end of World War II in 1945, but remained dormant throughout the Cold War. In the 1990s and 2000s, the rise of global trade and the power of world organizations that govern it led to calls for a parliamentary assembly to scrutinize their activity. The Campaign for the Establishment of a United Nations Parliamentary Assembly was formed in 2007 to coordinate pro-UNPA efforts, which as of July 2013 has received the support of over 850 Members of Parliament from over 90 countries worldwide, in addition to over 350 non-governmental organizations and 21 Nobel and Right Livelihood laureates and 16 Heads or former heads of state or government and foreign ministers.\n\nIn France, 1948, Garry Davis began an unauthorized speech calling for a world government from the balcony of the UN General Assembly, until he was dragged away by the guards. Davis renounced his American citizenship and started a Registry of World Citizens. On September 4, 1953, Davis announced from the city hall of Ellsworth, Maine the formation of the \"World Government of World Citizens\" based on 3 \"World Laws\"—One God (or Absolute Value), One World, and One Humanity. Following this declaration, mandated, he claimed, by Article twenty one, Section three of the Universal Declaration of Human Rights, he formed the United World Service Authority in New York City as the administrative agency of the new government. Its first task was to design and begin selling \"World Passports\", which the organisation argues is legitimatised by on Article 13, Section 2 of the UDHR.\n\nThe World Passport is a 45-page document sold by the World Service Authority, a non-profit organization, citing Article 13, Section 2, of the Universal Declaration of Human Rights. World Passports have allegedly been accepted sporadically by some 174 countries, but no immigration authority has a de facto or de jure policy of acceptance with regards to the document. The latest edition of the World Passport, which has been on sale since January 2007, is an MRD (machine readable document) with an alphanumeric code bar enabling computer input plus an embedded \"ghost\" photo for security, printing overcovered with a plastic film. The document is in 7 languages: English, French, Spanish, Russian, Arabic, Simplified Chinese and Esperanto. Two covers are available: \"World Passport\", and \"World Government Passport\" (for registered World Citizens), (\"passport\" is in 7 languages on both covers). Other documents sold by the WSA include a World Birth Certificate, a World Political Asylum Card, a World Marriage Certificate, and a World Identity Card. Each page within the document is numbered and each page has the World Citizen logo in the background. There are two pages for affiliation with companies, organizations, and firms. There are nineteen visa pages in the document. On the back cover there are spaces for personal information such as a person’s home address.\n\nLegal anthropologist E. Adamson Hoebel concluded his treatise on broadening the legal realist tradition to include non-Western nations: \"Whatever the idealist may desire, force and the threat of force are the ultimate power in the determination of international behavior, as in the law within the nation or tribe. But until force and the threat of force in international relations are brought under social control by the world community, by and for the world society, they remain the instruments of social anarchy and not the sanctions of world law. The creation in clear-cut terms of the corpus of world law cries for the doing. If world law, however, is to be realized at all, there will have to be minimum of general agreement as to the nature of the physical and ideational world and the relation of men in society to it. An important and valuable next step will be found in deep-cutting analysis of the major law systems of the contemporary world in order to lay bare their basic postulates – postulates that are too generally hidden; postulates felt, perhaps, by those who live by them, but so much taken for granted that they are rarely expressed or exposed for examination. When this is done – and it will take the efforts of many keen intellects steeped in the law of at least a dozen lands and also aware of the social nexus of the law – then mankind will be able to see clearly for the first time and clearly where the common consensus of the great living social and law systems lies. Here will be found the common postulates and values upon which the world community can build. At the same time the truly basic points of conflict that will have to be worked upon for resolution will be revealed. Law is inherently purposive\".\n\nWhile enthusiasm for multinational federalism in Europe incrementally led, over the following decades, to the formation of the European Union, the onset of the Cold War (1945–1992) eliminated the prospects of any progress towards federation with a more global scope. The movement quickly shrank in size to a much smaller core of activists, and the world government idea all but disappeared from wide public discourse.\n\nFollowing the end of the Cold War in 1992, interest in a federal world government and, more generally, in the global protection of human rights, was renewed. The most visible achievement of the world federalism movement during the 1990s is the Rome Statute of 1998, which led to the establishment of the International Criminal Court in 2002. In Europe, progress towards forming a federal union of European states gained much momentum, starting in 1952 as a trade deal between the German and French people led, in 1992, to the Maastricht Treaty that established the name and enlarged the agreement that the European Union (EU) is based upon. The EU expanded (1995, 2004, 2007, 2013) to encompass, in 2013, over half a billion people in 28 member states. Following the EU's example, the African Union was founded in 2002 and the Union of South American Nations in 2008.\n\n, there is no functioning global international military, executive, legislature, judiciary, or constitution with jurisdiction over the entire planet.\n\nThe Earth is divided geographically and demographically into mutually exclusive territories and political structures called states which are independent and sovereign in most cases. There are numerous bodies, institutions, unions, coalitions, agreements and contracts between these units of authority, but, except in cases where a nation is under military occupation by another, \"all\" such arrangements depend on the continued consent of the participant nations. Countries that violate or do not enforce international laws may be subject to penalty or coercion often in the form of economic limitations such as embargo by cooperating countries, even if the violating country is not part of the United Nations. In this way a countries cooperation in international affairs is voluntary, but non-cooperation still has diplomatic consequences.\n\nAmong the voluntary organizations and international arrangements are:\n\nIn addition to the formal, or semi-formal, international organizations and laws mentioned above, many other mechanisms act to regulate human activities across national borders. In particular, international trade in goods, services and currencies (the \"global market\") has a tremendous impact on the lives of people in almost all parts of the world, creating deep interdependency amongst nations (see globalization). Trans-national (or multi-national) corporations, some with resources exceeding those available to most governments, govern activities of people on a global scale. The rapid increase in the volume of trans-border digital communications and mass-media distribution (e.g., Internet, satellite television) has allowed information, ideas, and opinions to rapidly spread across the world, creating a complex web of international coordination and influence, mostly outside the control of any formal organizations or laws. A proactive form of globalization is emerging, spawned by international corporations that wish to loosen trade restrictions. It is the global financial firms that have been the most eager proponents of this expansion. A group of advocates from different parts of the world had been pushing for an integrated global society as envisioned in the Globalist Manifesto which is the foundation of globalism ideology.\n\nThe only union generally recognized as having achieved the status of a supranational union is the European Union.\n\nThere are a number of other regional organizations that, while not supranational unions, have adopted or intend to adopt policies that may lead to a similar sort of integration in some respects.\n\n\nOther organisations that have also discussed greater integration include:\n\n\nThe most relevant model for the incremental establishment of a global federation may be the European Union (EU), which politically unites a large group of widely diverse (and some formerly hostile) nations spread over a large geographical area and encompassing over 500 million people. Although the EU is still evolving, it already has many attributes of a federal government such as open internal borders, a directly elected parliament, a court system, an official currency (Euro), and a centralized economic policy. A treaty change would be needed to allow for enlargement of the Union beyond the European continent.\n\nThe EU's example is being followed by the African Union, the Union of South American Nations, the Organization of Central American States, and the Association of Southeast Asian Nations. A multitude of regional associations, aggregating most nations of the world, are at different stages of development towards a growing extent of economic, and sometimes political, integration. The European Union consists of twenty-eight European states. It has developed a \"single market\" which allows people of different countries to travel from state to state without a passport. This also includes the same policies when it comes to trading. The European Union is said to have 26% of the world's money. Not all EU member states use the Euro; the United Kingdom, for example, retains the pound sterling. Where the Euro is in place, it allows easy access for the free circulation of trade goods. Tariffs are also the same for each country allowing no unfair practices within the union.\n\nThe North Atlantic Treaty Organization (NATO) is an intergovernmental military alliance based on the North Atlantic Treaty which was signed on 4 April 1949. The organization constitutes a system of collective defence whereby its member states agree to mutual defense in response to an attack by any external party. NATO's headquarters are in Brussels, Belgium, one of the 28 member states across North America and Europe, the newest of which, Albania and Croatia, joined in April 2009. An additional 22 countries participate in NATO's \"Partnership for Peace\", with 15 other countries involved in institutionalized dialogue programs. The combined military spending of all NATO members constitutes over 70% of the world's defence spending.\n\nThe Caribbean Community (CARICOM), is an organization of 15 Caribbean nations and dependencies. CARICOM's main purpose is to promote economic integration and cooperation among its members, to ensure that the benefits of integration are equitably shared and to coordinate foreign policy. Its major activities involve coordinating economic policies and development planning; devising and instituting special projects for the less-developed countries within its jurisdiction; operating as a regional single market for many of its members CARICOM Single Market and Economy (CSME); and handling regional trade disputes.\n\nSince the establishment of CARICOM by the mainly English Creole-speaking parts of the Caribbean region CARICOM has become multilingual in practice with the addition of Dutch speaking Suriname on 4 July 1995 (although the lingua franca in Suriname is Sranan Tongo, which is an English-based Creole like the languages spoken in much of the rest of CARICOM) and Haiti, where French and Haitian Creole are spoken, on 2 July 2002. In 2001, the heads of government signed a Revised Treaty of Chaguaramas in Trinidad and Tobago, clearing the way for the transformation of the idea for a Common Market aspect of CARICOM into instead a Caribbean Single Market and Economy. Part of the revised treaty among member states includes the establishment and implementation of the Caribbean Court of Justice (CCJ).\n\nThe African Union (AU) is an organisation consisting of all the 55 African states of the continent and African waters. Established on July 9, 2002, the AU was formed as a successor to the amalgamated African Economic Community (AEC) and the Organisation of African Unity (OAU). Eventually, the AU aims to have a single currency and a single integrated defence force, as well as other institutions of state, including a cabinet for the AU Head of State. The purpose of the union is to help secure Africa's democracy, human rights, and a sustainable economy, especially by bringing an end to intra-African conflict and creating an effective common market.\n\nProjects for improved economic and political cooperation are also happening at a regional level with the Arab Maghreb Union, the Economic Community of West African States, the Economic Community of Central African States the Southern African Development Community and the East African Community.\nASEAN ( ), the Association of Southeast Asian Nations, is a geo-political and economic organization of 10 countries located in Southeast Asia, which was formed on August 8, 1967 by Indonesia, Malaysia, the Philippines, Singapore, and Thailand as a display of solidarity against communist expansion in Vietnam and insurgency within their own borders. Its claimed aims include the acceleration of economic growth, social progress, cultural development among its members, and the promotion of regional peace. All members later founded the Asia Cooperation Dialogue, which aims to unite the entire continent.\nThe Shanghai Cooperation Organisation (SCO) is an intergovernmental organization which was founded on June 14, 2001 by the leaders of the People's Republic of China, Russia, Kazakhstan, Kyrgyzstan, Tajikistan and Uzbekistan. Except for Uzbekistan, these countries had been members of the Shanghai Five; after the inclusion of Uzbekistan in 2001, the members renamed the organization.\nThe Commonwealth of Independent States is comparable to a confederation similar to the original European Community. Although the CIS has few supranational powers, it is more than a purely symbolic organization, possessing coordinating powers in the realm of trade, finance, lawmaking, and security. It has also promoted cooperation on democratization and cross-border crime prevention. As a regional organization, CIS participates in UN peacekeeping forces. Some of the members of the CIS have established the Eurasian Economic Community with the aim of creating a full-fledged common market.\nThe Arab League is a regional organization of Arab states in Southwest Asia, and North and Northeast Africa. It was formed in Cairo on March 22, 1945 with six members: Egypt, Iraq, Transjordan (renamed Jordan after 1946), Lebanon, Saudi Arabia, and Syria. Yemen joined as a member on May 5, 1945. The Arab League currently has 22 members, which also include, Algeria, Bahrain, Comoros, Djibouti, Kuwait, Libya, Mauritania, Morocco, Oman, Palestine, Qatar, Somalia, Sudan, Tunisia and the United Arab Emirates.\nIt has also been proposed to reform the Arab League into an Arab Union. The Arab League currently is the most important organization in the region.\nThe Union of South American Nations, modeled on the European Union, was founded between 2006 and 2008. It incorporates all the independent states of South America. These states are Argentina, Bolivia, Brazil, Chile, Colombia, Ecuador, Guyana, Paraguay, Peru, Suriname, Uruguay, and Venezuela.\n\nThe South Asian Association for Regional Cooperation (SAARC) is an economic and political organization of eight countries in Southern Asia. In terms of population, its sphere of influence is the largest of any regional organization: almost 1.5 billion people, the combined population of its member states. It was established on December 8, 1985 by India, Pakistan, Bangladesh, Sri Lanka, Nepal, Maldives and Bhutan. In April 2007, at the Association's 14th summit, Afghanistan became its eighth member.\nThe Organisation of Islamic Cooperation (OIC) is an international organisation with a permanent delegation to the United Nations. It groups 57 member states, from the Middle East, Africa, Central Asia, Caucasus, Balkans, Southeast Asia and South Asia. The organization claims it represents the Global Islamic World (\"ummah\"). The official languages of the organisation are Arabic, English and French.\n\nSince the 19th century, many Muslims have aspired to uniting the Muslim \"ummah\" to serve their common political, economic and social interests. Despite the presence of secularist, nationalist and socialist ideologies in modern Muslim states, they have cooperated to form the Organisation of Islamic Cooperation. The formation of the OIC happened in the backdrop of the loss of Muslim holy sites in Jerusalem. The final cause sufficiently compelled leaders of Muslim nations to meet in Rabat to establish the OIC on September 25, 1969.\n\nAccording to its charter, the OIC aims to preserve Islamic social and economic values; promote solidarity amongst member states; increase cooperation in social, economic, cultural, scientific, and political areas; uphold international peace and security; and advance education, particularly in the fields of science and technology.\n\nOn August 5, 1990, 45 foreign ministers of the OIC adopted the Cairo Declaration on Human Rights in Islam to serve as a guidance for the member states in the matters of human rights in as much as they are compatible with the Sharia, or Quranic Law.\n\nThe Turkic Council is an international organization comprising Turkic countries. Since 1992, the \"Turkic Language Speaking Countries Summit\" has been organizing amongst the Turkic countries. On October 3, 2009, four of these countries signed the Nahcivan Agreement. The organizational center is İstanbul. Additionally, the Joint Administration of Turkic Arts and Culture was founded in Almaty in 1992 and the \"Turkic Countries Parliamentarian Assembly\" was founded in Baku in 1998. All of these organizations were coopted into the Turkic Council. The Turkic Council has an operational style similar to organization like the Arab League. The member countries are Azerbaijan, Kazakhstan, Kyrgyzstan and Turkey. The remaining two Turkic states, Turkmenistan and Uzbekistan are not currently official members of the council. However, due to their neutral stance, they participate in international relations and are strongly predicted to be future members of the council. The idea of setting up this cooperative council was first put forward by Kazakh President Nursultan Nazarbayev back in 2006.\n\n\n\n\n\n\n"}
{"id": "43349892", "url": "https://en.wikipedia.org/wiki?curid=43349892", "title": "World revolution", "text": "World revolution\n\nWorld revolution is the Marxist concept of overthrowing capitalism in all countries through the conscious revolutionary action of the organized working class. These revolutions would not necessarily occur simultaneously, but where and when local conditions allowed a revolutionary party to successfully replace bourgeois ownership and rule, and install a workers' state based on social ownership of the means of production. In most Marxist schools, such as Trotskyism, the essentially international character of the class struggle and the necessity of global scope are critical elements and a chief explanation of the failure of socialism in one country.\n\nThe end goal of such internationally oriented revolutionary socialism is to achieve world socialism, and later, stateless communism.\n\nThe October Revolution of 1917 in Russia sparked a revolutionary wave of socialist and communist uprisings across Europe, most notably the German Revolution, the Hungarian Revolution, Biennio Rosso and the revolutionary war in Finland with the short lived Finnish Socialist Workers' Republic, which made large gains and met with considerable success in the early stages; see also Revolutions of 1917-23.\n\nParticularly in the years 1918-1919, it seemed plausible that capitalism would soon be swept from the European continent forever. Given the fact that European powers controlled the majority of Earth's land surface at the time, such an event could have meant the end of capitalism not just in Europe, but everywhere. Additionally, the Comintern, founded in March 1919, began as an independent international organization of communists from various countries around the world that evolved after the Russian Civil War into an essentially Soviet-sponsored agency responsible for coordinating the revolutionary overthrow of capitalism worldwide.\nWith the prospect of world revolution so close at hand, Marxists were dominated by a feeling of overwhelming optimism, which in the end proved to be quite premature. The European revolutions were crushed one by one, until eventually the Russian revolutionaries found themselves to be the only survivors. Since they had been relying on the idea that an underdeveloped and agrarian country like Russia would be able to build socialism with help from successful revolutionary governments in the more industrialized parts of Europe, they found themselves in a crisis once it became clear that no such help would arrive; see \"Socialism in one country\".\n\nAfter those events and up until the present day, the international situation never came quite so close to a world revolution again.\nAs fascism grew in Europe in the 1930s, instead of immediate revolution, the Comintern opted for a Popular Front with liberal capitalists against fascism; then, at the height of World War II in 1943, the Comintern was disbanded on the request of the Soviet Union's Western allies.\n\nA new upsurge of revolutionary feeling swept across Europe in the aftermath of World War II, though it was not as strong as the one triggered by World War I which resulted in failed (in the socialist sense) revolution in Germany and a successful one (for seventy years) in Russia. Communist parties in countries such as Greece, France, and Italy had acquired significant prestige and public support due to their activity as leaders of anti-fascist resistance movements during the war; as such, they also enjoyed considerable success at the polls and regularly finished second in elections in the late 1940s. However, none managed to finish in first and form a government. Communist parties in Eastern Europe, meanwhile, though they did win elections at around the same time, Western media criticized the lack of liberal democratic elements in their rise to power. Nonetheless, Communist movements in Eastern Europe proliferated, even with some local cases independent of the USSR, such as the Yugoslav Partisans, who also were integral in repelling fascism during World War II.\n\nRevolts across the world in the 1960s and early 1970s, coupled with the Chinese Cultural Revolution, the establishment of the New Left together with the Civil Rights Movement, the militancy of the Black Panther Party and similar armed/insurrectionary \"Liberation Front\" groups around the globe, and even a bit of a resurgence in the labor movement for a time once again made it seem to some as though world revolution was not only possible, but actually imminent; thus, there was a common expression, \"The East is Red, and the West is Ready\". However, this radical left spirit ebbed by the mid-1970s, and in 1980s and 1990s there was a return to certain right-wing, economically conservative ideologies (spearheaded, among other examples, by Thatcherism in the United Kingdom and Reaganomics in the United States) and also free-market reforms in China and in Vietnam.\n\nWithin Marxist theory, Lenin's concept of the labor aristocracy and his description of imperialism, andseparately, but not necessarily unrelatedlyTrotsky's theories regarding the deformed workers' state, offer several explanations as to why the world revolution has not occurred to the present day. Many groups still explicitly pursue the goal of worldwide communist revolution, calling it the truest expression of proletarian internationalism.\n\n"}
