{"id": "38227740", "url": "https://en.wikipedia.org/wiki?curid=38227740", "title": "1889–90 flu pandemic", "text": "1889–90 flu pandemic\n\nThe 1889–1890 flu pandemic (October 1889 – December 1890, with recurrences March – June 1891, November 1891 – June 1892, winter 1893–1894 and early 1895) was a deadly influenza pandemic that killed about 1 million people worldwide. The outbreak was dubbed \"Asiatic flu\" or \"Russian flu\" (not to be confused with the 1977–1978 epidemic caused by Influenza A/USSR/90/77 H1N1, which was also called Russian flu). For some time the virus strain responsible was conjectured (but not proven) to be Influenza A virus subtype H2N2. More recently, the strain was asserted to be Influenza A virus subtype H3N8.\n\nModern transport infrastructure assisted the spread of the 1889 influenza. The 19 largest European countries, including the Russian Empire, had 202,887 km of railroads and transatlantic travel by boat took less than six days (not significantly different than current travel time by air, given the time scale of the global spread of a pandemic).\n\nThe pandemic was first recorded in Saint Petersburg, Russia in December 1889. In four months it had spread throughout the Northern Hemisphere. Deaths peaked in Saint Petersburg on December 1, 1889, and in the United States during the week of January 12, 1890. The median time between the first reported case and peak mortality was five weeks.\n\nResearchers have tried for many years to identify the subtypes of Influenza A responsible for the 1889–1890, 1898–1900 and 1918 epidemics. Initially, this work was primarily based on \"seroarcheology\"—the detection of antibodies to influenza infection in the sera of elderly people—and it was thought that the 1889–1890 pandemic was caused by Influenza A subtype H2, the 1898–1900 epidemic by subtype H3, and the 1918 pandemic by subtype H1. With the confirmation of H1N1 as the cause of the 1918 flu pandemic following identification of H1N1 antibodies in exhumed corpses, reanalysis of seroarcheological data has indicated that Influenza A subtype H3 (possibly the H3N8 subtype), is the most likely cause for the 1889–1890 pandemic.\n\n\n"}
{"id": "17048535", "url": "https://en.wikipedia.org/wiki?curid=17048535", "title": "Angiostrongylus cantonensis", "text": "Angiostrongylus cantonensis\n\nAngiostrongylus cantonensis is a parasitic nematode (roundworm) that causes angiostrongyliasis, the most common cause of eosinophilic meningitis in Southeast Asia and the Pacific Basin. The nematode commonly resides in the pulmonary arteries of rats, giving it the common name rat lungworm. Snails are the primary intermediate hosts, where larvae develop until they are infectious.\n\nHumans are incidental hosts of this roundworm, and may become infected through ingestion of larvae in raw or undercooked snails or other vectors, or from contaminated water and vegetables. The larvae are then transported via the blood to the central nervous system, where they are the most common cause of eosinophilic meningitis, a serious condition that can lead to death or permanent brain and nerve damage. Angiostrongyliasis is an infection of increasing public health importance, as globalization contributes to the geographic spread of the disease.\n\nFirst described by the renowned Chinese parasitologist Hsin-Tao Chen (1904–1977) in 1935, after examining Cantonese rat specimens, the nematode \"Angiostrongylus cantonensis\" was identified in the cerebrospinal fluid of a patient with eosinophilic meningitis by Nomura and Lim in Taiwan in 1944. They noted that raw food eaten by the patient may have been contaminated by rats. In 1955, Mackerass and Sanders identified the lifecycle of the worm in rats, defining snails and slugs as the intermediate hosts and noting the path of transmission through the blood, brain, and lungs in rats.\n\n\"A. cantonensis\" is a helminth of the phylum Nematoda, order Strongylida, and superfamily Metastrongyloidea. Nematodes are roundworms characterized by a tough outer cuticle, unsegmented bodies, and a fully developed gastrointestinal tract. The order Strongylida includes hookworms and lungworms. Metastrongyloidea are characterized as 2-cm-long, slender, threadlike worms that reside in the lungs of the definitive host. \"Angiostrongylus costaricensis\" is a closely related worm that causes intestinal angiostrongyliasis in Central and South America.\n\nFollowing World War II, \"A. cantonensis\" spread throughout Southeast Asia and Western Pacific Islands, including Australia, Melanesia, Micronesia, and Polynesia. Cases were soon reported in New Caledonia, the Philippines, Rarotonga, Saipan, Sumatra, Taiwan, and Tahiti. In the 1960s, even more cases were reported from the region from locations such as Cambodia, Guam, Hawaii, Java, Thailand, Sarawak, Vietnam, and the New Hebrides (Vanuatu).\n\nIn 1961, an epidemiological study of eosinophilic meningitis in humans was conducted by Rosen, Laigret, and Bories, who hypothesized that the parasite causing these infections was carried by fish. However, Alicata noted that raw fish was consumed by large numbers of people in Hawaii without apparent consequences, and patients presenting with meningitis symptoms had a history of eating raw snails or prawns in the weeks before presenting with symptoms. This observation, along with epidemiology and autopsy of infected brains, confirmed \"A. cantonensis\" infection in humans as the cause of the majority of eosinophilic meningitis cases in Southeast Asia and the Pacific Islands.\n\nSince then, cases of \"A. cantonensis\" infestations have appeared in American Samoa, Australia, Hong Kong, Bombay, Fiji, Hawaii, Honshu, India, Kyushu, New Britain, Okinawa, Ryukyu Islands, Western Samoa, and most recently mainland China. Other sporadic occurrences of the parasite in its rat hosts have been reported in Cuba, Egypt, Louisiana, Madagascar, Nigeria, New Orleans, and Puerto Rico.\n\nIn 2013, \"A. cantonensis\" was confirmed present in Florida, USA, where its range and prevalence are expanding. In 2018, a case was found in a New Yorker, who had visited Hawaii.\n\nIn recent years, the parasite has been shown to be proliferating at an alarming rate due to modern food-consumption trends and global transportation of food products. Scientists are calling for a more thorough study of the epidemiology of \"A. cantonensis\", stricter food-safety policies, and the increase of knowledge on how to properly consume products commonly infested by the parasite, such as snails and slugs that act as intermediate hosts or those that act as paratenic hosts, such as fish, frogs, or freshwater prawns. Ingestion of food items that can be contaminated by the mucus excretions of intermediate or paratenic hosts, such as snails and slugs or by the feces of rats that act as definitive hosts, can lead to infection of \"A. cantonensis\". The most common route of infection of \"A. cantonesis\" in humans is by ingestion of either intermediate or paratenic hosts of the larvae. Unwashed fruits and vegetables, especially romaine lettuce, can be contaminated with snail and slug mucus or can result in accidental ingestion of these intermediate and paratenic hosts. These items need to be properly washed and handled to prevent accidental ingestion of \"A. cantonensis\" larvae or the larvae-containing hosts. The best mechanism of prevention of \"A. cantonesis\" outbreak is to institute an aggressive control of snail and slug population, proper cooking of intermediate and paratenic hosts such as fish, freshwater prawn, frogs, mollusks, and snails along with proper food-handling techniques. The common prevention techniques for diarrheal illness is very effective in preventing \"A. cantonensis\" infection. Not much is known about why it targets the brain in humans, but a chemically induced chemotaxis has been implicated recently. Acetylcholine has been previously reported to enhance motility of this worm via nicotinic acetylcholine receptors. Experimental assays in animal models are needed to validate a chemically induced chemotaxis by use of anticholinergic drugs to prevent cerebral infection following infections by \"A. cantonesis\".\n\nIntermediate hosts of larvae of for \"A. cantonensis\" include:\n\nDefinitive host of \"A. cantonensis\" include wild rodents, especially the brown rat (\"Rattus norvegicus\") and the black rat (\"Rattus rattus\").\n\nParatenic hosts of \"A. cantonensis\" include: predatory land flatworm \"Platydemus manokwari\" and amphibians \"Bufo asiaticus\", \"Rana catesbeiana\", \"Rhacophorus leucomystax\" and \"Rana limnocharis\".\n\nIn 2004, a captive yellow-tailed black cockatoo (\"Calyptorhynchus funereus\") and two free-living tawny frogmouths (\"Podargus strigoides\") suffering neurological symptoms were shown to have the parasite. They were the first avian hosts discovered for the organism.\n\nThe presence of parasitic worms burrowed in the neural tissue of the human central nervous system will cause obvious complications. All of the following will result in damage to the CNS:\n\n\nAlthough the clinical disease caused by \"Angiostrongylus\" invasion into the central nervous system is commonly referred to as \"eosinophilic meningitis\", the actual pathophysiology is of a meningoencephalitis with invasion not just of the meninges, or superficial lining of the brain, but also deeper brain tissue. Initial invasion through the lining of the brain, the meninges, may cause a typical inflammation of the meninges and a classic meningitis picture of headache, stiff neck, and often fever. The parasites subsequently invade deeper into the brain tissue, causing specific localizing neurologic symptoms depending on where in the brain parenchyma they migrate. Neurologic findings and symptoms wax and wane as initial damage is done by the physical in-migration of the worms and secondary damage is done by the inflammatory response to the presence of dead and dying worms. This inflammation can lead in the short term to paralysis, bladder dysfunction, visual disturbance, and coma and in the long term to permanent nerve damage, mental retardation, nerve damage, permanent brain damage, or death.\n\nEosinophilic meningitis is commonly defined by the increased number of eosinophils in the cerebrospinal fluid (CSF). In most cases, eosinophil levels rise to 10 or more eosinophils per μl in the CSF, accounting for at least 10% of the total CSF leukocyte (white blood cell) count. The chemical analysis of the CSF typically resembles the findings in \"aseptic meningitis\" with slightly elevated protein levels, normal glucose levels, and negative bacterial cultures. Presence of a significantly decreased glucose on CSF analysis is an indicator of severe meningoencephalitis and may indicate a poor medical outcome. Initial CSF analysis early in the disease process may occasionally show no increase of eosinophils, only to have classical increases in eosinophils in subsequent CSF analysis. Caution should be advised in using eosinophilic meningitis as the only criterion for diagnosing angiostrongylus infestation in someone with classic symptoms, as the disease evolves with the migration of the worms into the CNS.\n\nEosinophils are specialized white blood cells of the granulocytic cell line which contain granules in their cytoplasm. These granules contain proteins that are toxic to parasites. When these granules degranulate, or break down, chemicals are released that combat parasites such as \"A. cantonensis\". Eosinophils, which are located throughout the body, are guided to sites of inflammation by chemokines when the body is infested with parasites such as \"A. cantonensis\". Once at the site of inflammation, type 2 cytokines are released from helper T cells, which communicate with the eosinophils, signaling them to activate. Once activated, eosinophils can begin the process of degranulation, releasing their toxic proteins in the fight against the foreign parasite.\n\nAccording to a group case study, the most common symptoms in mild eosinophilic meningitis tend to be headache (with 100% of people in the study suffering from this symptom), photophobia or visual disturbance (92%), neck stiffness (83%), fatigue (83%), hyperesthesias (75%), vomiting (67%), and paresthesias (50%). Incubation period is often 3 weeks, but can be 3–36 days and even 80 days.\n\nPossible clinical signs and symptoms of mild and severe eosinophilic meningitis are:\n\nThe severity and clinical course of \"Angiostrongylus\" disease depends significantly on the ingested load of third-stage larvae, creating great variability from case to case, making clinical trials difficult to design, and effectiveness of treatments difficult to discern. Typical conservative medical management including analgesics and sedatives provide minimal relief for the headaches and hyperesthesias. Removing cerebrospinal fluid at regular 3- to 7-day intervals is the only proven method of significantly reducing intracranial pressure and can be used for symptomatic treatment of headaches. This process may be repeated until improvement is shown. There is growing evidence of moderate quality that suggests corticosteroid therapy using prednisolone or dexamethasone has beneficial effect in treating the CNS symptoms related to \"A. cantonensis\" infections. Although early research did not show treatment with antihelminthic agents (parasite-killing drugs) such as thiobendazole or albendazole effective in improving the clinical course of the illness, a number of recent studies from Thailand and China show that the combination of glucocorticoids and antihelminthics is safe and decreases the duration of headaches and the number of patients who had significant headache. Although the addition of antihelminthic agents for management of \"A. cantonensis\" infection has a theoretic risk of precipitating a neurologic crisis by releasing an overwhelming load of antigens through simultaneous death of the larvae, no study has shown this to exist in the clinical setting. Additionally, the failure to kill parasites before they attempt to migrate out of the CNS increases the risk of mechanical damage by migrating larvae. Although combination therapy using albendazole and prednisolone has no significant advantage compared to treatment using prednisolone alone in mild cases, the treatment with antihelminthics is demonstrably safe and may have significant benefit for patients with high parasite loads at risk for permanent disability or death. \nThe diagnosis of disease caused by \"A. cantonensis\" infestation is often difficult and relies heavily on the history of a likely ingestion of a commonly infested host and the presence of typical features of the disease. The presumptive diagnosis is particularly strong when eosinophilic meningoencephalitis can be confirmed. The diagnosis of eosinophilic meningitis can be arrived at through detection of elevated cranial pressure and increased numbers of eosinophils. The diagnosis of the cause of eosinophilic meningitis and the presence of \"A. cantonensis\" is remarkably more difficult. A spinal tap, or a sample of CSF, must be taken to search for \"A. cantonensis\" worms or larvae. \"A. cantonensis\" is undetectable in the CSF of more than half of the infected individuals. Current methods of detecting specific antigens associated with \"A. cantonensis\" are also unreliable. Consequently, alternative approaches to detect antigen-antibody reactions are being explored, such as immuno-PCR. A rapid dot-blot ELISA test is also available for quick, effective, and economical on-site diagnosis of \"A. cantonensis\".\n\n"}
{"id": "13973661", "url": "https://en.wikipedia.org/wiki?curid=13973661", "title": "Boundaries between the continents of Earth", "text": "Boundaries between the continents of Earth\n\nThe boundaries between the continents of Earth are generally a matter of geographical convention. Several slightly different conventions are in use. The number of continents is most commonly considered seven but may range as low as four when the Americas and Afro-Eurasia are each considered a single continent. According to the definition of a continent in the strict sense, an island cannot be part of any continent, but by convention and in practice most major islands are associated with a continent.\n\nThere are three overland boundaries subject to definition:\n\nWhile the isthmus between Asia and Africa and that between North and South America are today navigable, via the Suez and Panama canals, respectively, diversions and canals of human origin generally are not accepted on their own accord as continent-defining boundaries; the Suez Canal happens to traverse the isthmus between the Mediterranean Sea and Red Sea, dividing Asia and Africa. The remaining boundaries concern the association of islands and archipelagos with specific continents, notably:\n\n\nThe European and African mainlands are non-contiguous, and the delineation between these continents is thus merely a question of which islands are to be associated with which continent. At its nearest point, Morocco and the European portion of Spain are separated by only .\n\nThe Portuguese Atlantic island possession of the Azores is from Europe and from Africa, and is usually grouped with Europe if grouped with any continent. By contrast, the Canary and Madeira islands off the Atlantic coast of Morocco are much closer to, and usually grouped with, Africa (the Canary Islands are only from the African coast at their closest point, while Madeira is from Africa and from Europe).\n\nThe Mediterranean island nation of Malta is approximately from the coast of Sicily in Europe - much closer than the distance to the closest African coast. The nearby Italian island of Lampedusa is from Sicily while just from the African coast; similarly, Pantelleria is from Sicily and just from the African coast. All of these Mediterranean islands are actually located on the African plate, and may be considered part of the continent of Africa. However, for political and historical reasons, maps generally display them as part of Europe.\n\nThe boundary between Europe and Asia is unusual among continental boundaries because of its largely mountain-and-river-based characteristics north and east of the Black Sea. The reason is historical, the division of Europe and Asia going back to the early Greek geographers.\nIn the modern sense of the term \"continent\", Eurasia is more readily identifiable as a \"continent\", and Europe has occasionally been described as a subcontinent of Eurasia.\n\nThe threefold division of the Old World into Europe, Asia and Africa has been in use since the 6th century BC, due to Greek geographers such as Anaximander and Hecataeus. \n\nAnaximander placed the boundary between Asia and Europe along the Phasis River (the modern Rioni) in the Caucasus (from its mouth by Poti on the Black Sea coast, through the Surami Pass and along the Kura River to the Caspian Sea), a convention still followed by Herodotus in the 5th century BC.\nAs geographic knowledge of the Greeks increased during the Hellenistic period, this archaic convention was revised, and the boundary between Europe and Asia was now considered to be the Tanais (the modern Don River). This is the convention used by Roman era authors such as Posidonius, Strabo and Ptolemy.\n\nThroughout the Middle Ages and into the 18th century, the traditional division of the landmass of Eurasia into two continents, Europe and Asia, followed Ptolemy, with the boundary following the Turkish Straits, the Black Sea, the Kerch Strait, the Sea of Azov and the Don (known in antiquity as the Tanais). But maps produced during the 16th to 18th centuries tended to differ in how to continue the boundary beyond the Don bend at Kalach-na-Donu (where it is closest to the Volga, now joined with it by the Volga–Don Canal), into territory not described in any detail by the ancient geographers.\n\nPhilip Johan von Strahlenberg in 1725 was the first to depart from the classical Don boundary by drawing the line along the Volga, following the Volga north until the Samara Bend, along Obshchy Syrt (the drainage divide between Volga and Ural) and then north along Ural Mountains. The mapmakers continued to differ on the boundary between the lower Don and Samara well into the 19th century. The published by the Russian Academy of Sciences has the boundary follow the Don beyond Kalach as far as Serafimovich before cutting north towards Arkhangelsk, while other 18th- to 19th-century mapmakers such as John Cary followed Strahlenberg's prescription. To the south, the Kuma–Manych Depression was identified circa 1773 by a German naturalist, Peter Simon Pallas, as a valley that, once upon a time, connected the Black Sea and the Caspian Sea, and subsequently was proposed as a natural boundary between continents.\n\nBy the mid-19th century, there were three main conventions, one following the Don, the Volga–Don Canal and the Volga, the other following the Kuma–Manych Depression to the Caspian and then the Ural River, and the third abandoning the Don altogether, following the Greater Caucasus watershed to the Caspian. The question was still treated as a controversy in geographical literature of the 1860s, with Douglas Freshfield advocating the Caucasus crest boundary as the best possible, citing support from various modern geographers.\n\nIn Russia and the Soviet Union, the boundary along the Kuma–Manych Depression was the most commonly used as early as 1906. In 1958, the Soviet Geographical Society formally recommended that the boundary between the Europe and Asia be drawn in textbooks from Baydaratskaya Bay, on the Kara Sea, along the eastern foot of Ural Mountains, then following the Ural River until the Mugodzhar Hills, and then the Emba River; and Kuma–Manych Depression, thus placing the Caucasus entirely in Asia and the Urals entirely in Europe. However, most geographers in the Soviet Union favoured the boundary along the Caucasus crest and this became the standard convention in the latter 20th century, although the Kuma–Manych boundary remained in use in some 20th-century maps.\n\nThe modern border between Asia and Europe remains a historical and cultural construct, defined only by convention. The modern border follows the Aegean Sea, the Dardanelles-Sea of Marmara-Bosphorus (together known as the Turkish Straits), the Black Sea, along the watershed of the Greater Caucasus, the northwestern portion of the Caspian Sea and along the Ural River and Ural Mountains to the Kara Sea, as mapped and listed in most atlases including that of the National Geographic Society and as described in the World Factbook. According to this definition, Georgia and Azerbaijan both have most of their territory in Asia, although each has small parts of their northern borderlands north of the Greater Caucasus watershed and thus in Europe.\n\nThough most geographic sources assign the area south of the Caucasus Mountain crest to Southwest or West Asia, no definition is entirely satisfactory, with it often becoming a matter of self-identification. Cultural influences in the area originate from both Asia and Europe. While geographers rarely define continents primarily politically, Georgia and to a lesser extent Armenia and Azerbaijan are increasingly in the 21st century politically oriented towards Europe, but Armenia has a great cultural diaspora to the south, and Azerbaijan shares a cultural affinity with Iranian Azerbaijan as well as with the Turkic countries of Central Asia.\n\nThe Turkish city Istanbul lies in on both sides of the Bosporus (one of the Turkish Straits), making it a transcontinental city. Russia and Turkey are transcontinental countries with territory in both Europe and Asia by any definition except that of Eurasia as a single continent. While Russia is historically a European country with a history of imperial conquests in Asia, the situation for Turkey is inverse, as that of an Asian country with imperial conquests in Europe. Kazakhstan is also a transcontinental country by this definition, its West Kazakhstan and Atyrau provinces extending on either side of the Ural River.\nThis Ural River delineation is the only segment not to follow a major mountain range or wide water body, both of which often truly separate populations. However, the Ural River is the most common division used by authorities, is the most prominent natural feature in the region, and is the \"most satisfactory of those (options) proposed\" which include the Emba River, a much smaller stream cutting further into Central Asian Kazakhstan. The Ural River bridge in Orenburg is even labeled with permanent monuments carved with the word \"Europe\" on one side, \"Asia\" on the other.\n\nThe Kuma–Manych Depression (more precisely, the Manych River, the Kuma–Manych Canal and the Kuma River) remains cited less commonly as one possible natural boundary in contemporary sources. This definition peaked in prominence in the 19th century, however it has declined in usage since then, as it places traditionally European areas of Russia such as Stavropol, Krasnodar, and even areas just south of Rostov-on-Don in Asia.\n\nA lesser known definition for country grouping, is the definition used for statistical purposes by the United Nations Statistics Division (UNSD):\n\nAccording to UNSD, the aforementioned \"assignment of countries or areas to specific groupings is for statistical convenience and does not imply any assumption regarding political or other affiliation of countries or territories\". Furthermore, the UNSD classification often differs from those of other United Nations organizations. For instance, while UNSD includes Georgia and Cyprus in Western Asia, the United Nations Industrial Development Organization and UNESCO include both countries in Europe.\nThe Council of Europe includes the Eurasian countries of Armenia, Azerbaijan, Cyprus, Georgia, Russia, and Turkey. It notes that\n\n[T]wo Council of Europe member States, Turkey and Russia, belong geographically to both Europe and Asia and are therefore Eurasian. Strictly speaking, the three South Caucasus States, Armenia, Azerbaijan and Georgia are located in Asia, yet their membership of political Europe is no longer in doubt.\nCyprus is an island of the Mediterranean located close to Asia Minor, so that it is usually associated with Asia and/or the Middle East, as in the World Factbook and the United Nations geoscheme, but the Republic of Cyprus was nevertheless admitted to the Council of Europe in 1961 and joined the EU in 2004. The northern part of the island functions as the unrecognized (except by Turkey) Turkish Republic of Northern Cyprus.\n\nThe Greek North Aegean Islands and the Dodecanese lie on the coast of the Asian part of Turkey (on the Asian continental shelf).\n\nEurope and North America are separated by the North Atlantic.\nIn terms of associating islands with either continent, the boundary is usually drawn between Greenland and Iceland. The Norwegian islands of Jan Mayen and Svalbard in the Arctic Ocean are usually associated with Europe. Iceland and the Azores are protrusions of the Mid-Atlantic Ridge and are associated with and peopled from Europe, even though they have areas on the North American Plate. (Definitions of \"continents\" are a physical and cultural construct dating back centuries, long before the advent or even knowledge of plate tectonics; thus, defining a \"continent\" falls into the realm of physical and cultural geography, while continental plate definitions fall under plate tectonics in the realm of geology.)\n\nThe geographical notion of a continent stands in opposition to islands and archipelagos.\nNevertheless, there are some islands that are considered part of Europe in a political sense.\nThis most notably includes the British Isles (part of the European continental shelf and during the Ice Age of the continent itself), besides the islands of the North Sea, the Baltic Sea and the Mediterranean which are part of the territory of a country situated on the European mainland, and usually also the island states of Iceland and Malta.\n\nRussia's Vaygach Island and Novaya Zemlya extend northward from the northern end of the Ural Mountains and are a continuation of that chain into the Arctic Ocean. While Novaya Zemlya was variously grouped with Europe or with Asia in 19th-century maps it is now usually grouped with Europe, the continental boundary considered to join the Arctic Ocean along the southern shore of the Kara Sea. The Russian Arctic archipelago of Franz Josef Land farther north is also associated with Europe.\n\nEurope ends in the west at the Atlantic Ocean, although Iceland and the Azores archipelago (in the Atlantic, between Europe and North America) are usually considered European, as is the Norwegian Svalbard archipelago in the Arctic Ocean. Greenland is geographically part of North America, but politically associated with Europe as it is part of the Kingdom of Denmark, although it has extensive home rule and EU law no longer applies there.\n\nHistorically in Greco-Roman geography, \"Africa\" meant Ancient Libya, and its eastern extent was taken to be around Marmarica, at the \"Catabathmus Magnus\", placing Egypt in Asia entirely.\nThe idea of Egypt being an \"African\" country seems to develop in around the mid-19th century; the term \"Africa\" was classically reserved for what is now known as the Maghreb, to the explicit exclusion of Egypt, but with the exploration of Africa the shape of the African landmass (and Egypt's \"natural\" inclusion in that landmass) became apparent. In 1806, William George Browne still titled his travelogue \"Travels in Africa, Egypt, and Syria\". Similarly, James Bruce in 1835 published \"Travels through part of Africa, Syria, Egypt, and Arabia\". On the other hand,\nas early as 1670 John Ogilby under the title \"Africa\" published \"an accurate Description of the Regions of Egypt, Barbary, Libya, and Billedulgerid, the Land of Negroes, Guinea, Æthiopia, and the Abyssines, with all the adjacent Islands, either in the Mediterranean, Atlantic, Southern, or Oriental Seas, belonging thereunto\".\n\nThe usual line taken to divide Africa from Asia today is at the Isthmus of Suez, the narrowest gap between the Mediterranean and Gulf of Suez, the route today followed by the Suez Canal. This makes the Sinai Peninsula geographically Asian, and Egypt a transcontinental country. Less than 2% of Egyptian population live in the Sinai, and hence Egypt, even though technically transcontinental, is usually considered an African country entirely and not partly Asian.\n\nBut when discussing the geopolitical region of the Middle East and North Africa, Egypt is usually grouped with the Western Asian countries as part of the Middle East, while Egypt's western neighbor Libya is grouped with the remaining North African countries as the Maghreb. However, they are both members of the Arab League as well as the African Union.\n\nThe Seychelles, Mauritius, and Comoros are island nations in the Indian Ocean associated with Africa. The island of Socotra may be considered African as it lies on this continent's shelf, but is part of Yemen, an Asian country.\n\nThe border between North America and South America is at some point on the Isthmus of Panama. The most common demarcation in atlases and other sources follows the Darién Mountains watershed divide along the Colombia-Panama border where the isthmus meets the South American continent. Virtually all atlases list Panama as a state falling entirely within North America and/or Central America.\n\nOften most of the Caribbean islands are considered part of North America, but Aruba, Bonaire, Curaçao and Trinidad and Tobago lie on the continental shelf of South America. On the other hand, the Venezuelan Isla Aves and the Colombian San Andrés and Providencia lie on the North American shelf.\n\nThe Bering Strait and Bering Sea separate the landmasses of Asia and North America, as well as forming the international boundary between Russia and the United States. This national and continental boundary separates the Diomede Islands in the Bering Strait, with Big Diomede in Russia and Little Diomede in the US. The Aleutian Islands are an island chain extending westward from the Alaska Peninsula toward Russia's Komandorski Islands and Kamchatka Peninsula. Most of them are always associated with North America, except for the westernmost Near Islands group, which is on Asia's continental shelf beyond the North Aleutians Basin and on rare occasions could be associated with Asia, which could then allow the U.S. state of Alaska to be considered a transcontinental state.\n\nSt. Lawrence Island in the northern Bering Sea belongs to Alaska and may be associated with either continent but is almost always considered part of North America, as with the Rat Islands in the Aleutian chain. At their nearest points, Alaska and Russia are separated by only .\n\nThe Galápagos Islands and Malpelo Island in the eastern Pacific Ocean are possessions of Ecuador and Colombia, respectively, and associated with South America. The uninhabited French possession of Clipperton Island off the Mexican coast is associated with North America.\n\nEaster Island, a territory of Chile, is considered to be in Oceania, though politically it is associated with South America.\n\nThe United States of America controls numerous territories in Oceania, including the state of Hawaii and the territories of Guam, the Northern Mariana Islands and American Samoa.\n\nThe Malay Archipelago is usually divided between Asia and Australasia, most commonly along the anthropologic Melanesian line or Weber's Line. Indonesia controls the western half of New Guinea, geographically part of Australasia. The eastern half of the island is part of Papua New Guinea which is considered to be part of Oceania. Indonesia is commonly referred to as one of the Southeast Asian countries. East Timor, an independent state that was formerly a territory of Indonesia, which is geographically part of Asia, is classified by the United Nations as part of the \"South-Eastern Asia\" block. It is expected to join the Association of Southeast Asian Nations, having been involved as an ASEAN Regional Forum member since independence, and has participated in the Southeast Asian Games since 2003. Occasionally, all of the Malay Archipelago is included in Oceania, although this is extremely rare, especially as most of the archipelago lies on the Asian continental shelf.\n\nThe Commonwealth of Australia includes island possessions in Oceania and islands closer to Indonesia than the Australian mainland.\n\nAntarctica along with its outlying islands have no permanent population. All land claims south of 60°S latitude are held in abeyance by the Antarctic Treaty System.\n\nThe South Georgia and the South Sandwich Islands are closer to Antarctica than to any other continent. However, they are politically associated with the inhabited Falkland Islands which are closer to South America. Furthermore, Argentina, a South American country, maintains its irredentist claims on the islands. The continental shelf boundary separates the two island groups.\n\nThe Prince Edward Islands are located between Africa and Antarctica, and are the territory of South Africa, an African country. The Australian Macquarie Island and the New Zealand Antipodes Islands, Auckland Islands, and Campbell Islands, are all located between the Oceanian countries of Australia and New Zealand and Antarctica.\n\nAustralia's Heard Island and McDonald Islands and the French Kerguelen Islands are located on the Kerguelen Plateau, on the Antarctic continental plate. The French Crozet Islands, Île Amsterdam, Île Saint-Paul, and the Norwegian Bouvet Island are also located on the Antarctic continental plate, and are not often associated with other continents.\n\n"}
{"id": "58889745", "url": "https://en.wikipedia.org/wiki?curid=58889745", "title": "Bryum argenteum", "text": "Bryum argenteum\n\nBryum argenteum, the silvergreen bryum moss or silvery thread moss, is a species of moss in the family Bryaceae. It is one of the most common urban mosses of inner cities and can be easily recognized without a microscope.\nThe species is silvery-green or whitish-green colored when dry. This is because the broadly ovate shaped single leaflets in the tip do not form chlorophyll. The costa extends beyond the middle of the leaf. In damp, undisturbed locations, the branches may also form a more horizontal growth habit. The upper cells of the leaf surface are elongated rhomboid shaped. The capsule of the sporophyte is short cylindrical, appears broader at the base and is dark red to black colored.\n\nIt has a high ability to tolerate drought and pollution of urban environments. \"B. argenteum\" is considered a desiccation tolerant species that can withstand total drying. While it is a common characteristic in mosses, \"B. argenteum\" was one of the first bryophytes experimentally determined to be desiccation tolerant.\n\nAn adaptable plant, it has a cosmopolitan distribution and is found in Europe, North America, the deserts of Australia and in Antarctica. \n\nIt thrives in areas of high anthropogenic activity, growing on rocks, in gaps of paving stones, on asphalt, and on roadsides. It grows especially well in inner cities or in industrial areas. Being a nitrogen loving species, it is also found on nitrophilic soils in urban areas. It is found growing among lawns as well as in other moss communities.\n\nThe species is often spread by vegetative fragments clinging to the shoes of people and the feet or hooves of animals.\nAnother method of spread is in the production and sale of liners. Liners infested with \"B. argentem\", often in association with \"Marchantia polymorpha\", are commonly grown in one region of the country, transported to another region to continue growth, and are shipped to a retail location before being planted. Plants have the potential to pick up or disperse these species at each point of transfer.\n"}
{"id": "46619228", "url": "https://en.wikipedia.org/wiki?curid=46619228", "title": "Circumnavigation world record progression", "text": "Circumnavigation world record progression\n\nThis is a list of the fastest non-orbital circumnavigation made by a person or team.\n\n"}
{"id": "4561442", "url": "https://en.wikipedia.org/wiki?curid=4561442", "title": "Cosmopolitan distribution", "text": "Cosmopolitan distribution\n\nIn biogeography, a taxon is said to have a cosmopolitan distribution if its range extends across all or most of the world in appropriate habitats. Such a taxon is said to exhibit cosmopolitanism or cosmopolitism. The opposite extreme is endemism.\n\nThe term pandemism also is in use, but not all authors are consistent in the sense in which they use the term; some speak of pandemism mainly in referring to diseases and pandemics, and some as a term intermediate between endemism and cosmopolitanism, in effect regarding pandemism as subcosmopolitanism. This means near cosmopolitanism, but with major gaps in the distribution, say, complete absence from Australia. Terminology varies, and there is some debate whether the true opposite of endemism is pandemism or cosmopolitism.\n\nThe term \"cosmopolitan distribution\" usually should not be taken literally, because it often is applied loosely in various contexts. Commonly the intention is not to include polar regions, extreme altitudes, oceans, deserts, or small, isolated islands. For example, the housefly is nearly as cosmopolitan as any animal species, but it is neither oceanic nor polar in its distribution. Similarly, the term \"cosmopolitan weed\" implies no more than that the plant in question occurs on all continents except Antarctica; it is not meant to suggest that the species is present in all regions of every continent.\n\nAnother concept in biogeography is that of oceanic cosmopolitanism and endemism. Although there is a temptation to regard the World Ocean as a medium without biological boundaries, this is far from reality; many physical and biological barriers interfere with either the spread or continued residence of many species. For example, temperature gradients prevent free migration of tropical species between the Atlantic and Indian-plus-Pacific oceans, even though there is open passage past continental masses such as the Americas and Africa/Eurasia. Again, as far as many species are concerned, the Southern Ocean and the Northern marine regions are completely isolated from each other by the intolerable temperatures of the tropical regions. In the light of such considerations, it is no surprise to find that endemism and cosmopolitanism are quite as marked in the oceans as on land.\n\nAnother aspect of cosmopolitanism is that of ecological limitations. A species that is apparently cosmopolitan because it occurs in all oceans might in fact occupy only littoral zones, or only particular ranges of depths, or only estuaries, for example. Analogously, terrestrial species might be present only in forests, or mountainous regions, or sandy arid regions or the like. Such distributions might be patchy, or extended, but narrow. Factors of such a nature are taken widely for granted, so they seldom are mentioned explicitly in mentioning cosmopolitan distributions.\n\nCosmopolitanism of a particular species or variety should not be confused with cosmopolitanism of higher taxa. For example, the family Myrmeleontidae is cosmopolitan in the sense that every continent except Antarctica is home to some indigenous species within the Myrmeleontidae, but nonetheless no one species, nor even genus, of the Myrmeleontidae is cosmopolitan. Conversely, partly as a result of human introduction of unnatural apiculture to the New World, \"Apis mellifera\" probably is the only cosmopolitan member of its family; the rest of the family Apidae have modest distributions.\n\nEven where a cosmopolitan population is recognised as a single species, such as indeed \"Apis mellifera\", there generally will be variation between regional sub-populations. Such variation commonly is at the level of subspecies, varieties or morphs, whereas some variation is too slight or inconsistent for formal recognition.\n\nFor an example of subspecific variation, consider the so-called \"African killer bee\", which is the subspecies \"Apis mellifera scutellata\", and the Cape bee, which is the subspecies \"Apis mellifera capensis\"; both of them are in the same cosmopolitan species \"Apis mellifera\", but their ranges barely overlap.\n\nOther cosmopolitan species, such as the osprey and house sparrow, present similar examples, but in yet other species there are less familiar complications: some migratory birds such as the Arctic tern occur from the Arctic to the Southern Ocean, but at any one season of the year they are likely to be largely in passage or concentrated at only one end of the range. Also, some such species breed only at one end of the range. Seen purely as an aspect of cosmopolitanism, such distributions could be seen as temporal, seasonal variations.\n\nOther complications of cosmopolitanism on a planet too large for local populations to interbreed routinely with each other, lead to genetic effects such as ring species, for example in the \"Larus\" gulls. They also lead to the formation of clines such as in Drosophila.\n\nCosmopolitan distributions can be observed both in extinct and extant species. For example, \"Lystrosaurus\" was cosmopolitan in the Early Triassic after a mass extinction.\n\nIn the modern world, the killer whale has a cosmopolitan distribution, extending over most of the Earth's oceans. The wasp \"Copidosoma floridanum\" is another example, as it is found around the world. Other examples include humans, cats, dogs, orchids, the foliose lichen \"Parmelia sulcata\", and the mollusc genus \"Mytilus\". The term can also apply to some diseases. It may result from a broad range of environmental tolerances or from rapid dispersal compared to the time needed for evolution.\n\n"}
{"id": "41413797", "url": "https://en.wikipedia.org/wiki?curid=41413797", "title": "Countess of Dufferin Fund", "text": "Countess of Dufferin Fund\n\nThe Countess of Dufferin Fund was established by Hariot Hamilton-Temple-Blackwood, Marchioness of Dufferin and Ava, more commonly known as Lady Dufferin, in 1885 and was dedicated to improving women’s healthcare in India. The Fund was founded after Queen Victoria gave Lady Dufferin the task of improving healthcare for women in India. The Fund provided scholarships for women to be educated in the medical field as doctors, hospital assistants, nurses, and midwives. It also financed the construction of female hospitals, dispensaries, and female only wards in preexisting hospitals. The Fund marks the beginning of Western medicine for women in India and global health as a diplomatic concern.\n\nDuring the 19th century there was a major push in India to improve healthcare for women, especially maternal health. Lying-in hospitals were built as well as training and teaching hospitals. Many hospitals were also constructing wards for women and learning to treat female-specific diseases.\n\nIn 1885, Lady Dufferin set up the Fund after being contacted by Queen Victoria who gave her the task of helping the suffering women of India. Queen Victoria had been recently contacted by Elizabeth Bielby, a missionary in India who focused on women’s health. During Beilby’s mission, she had treated the Maharani of Puna who gave her a message to relay to the Queen of England. The message said that “the women of India suffer when they are sick.” In response, Queen Victoria wrote back to the Maharani saying: Lady Dufferin then started the Fund after being summoned to Windsor Castle by the Queen who gave her the task of improving healthcare and education for the women of India. A visit from Dr. Mary Scharlieb, the first female British doctor to practice in India, also mobilized the Queen to act on women’s poor health and suffering in India. She met with Queen Victoria and expressed a similar message as the Maharni’s: the dire situation of Indian women.\n\nLady Dufferin established the Fund in 1885 and immediately began creating projects and channeling money towards women’s health and teaching in India. The Countess of Dufferin Fund is also known as “The National Association for Supplying Medical Aid to the Women of India” and the “Lady Dufferin Fund.” This Fund marked one of the first diplomatic pushes to improve global health in the world, and the introduction of western medicine for women in India.\n\nThe Fund had three primary goals: providing medical tuition, medical relief, and female nurses and midwives to assist in hospitals and private homes. The Fund supplied scholarships for the medical education (medical tuition) of women in India. The education of traditional Indian midwives, called dias, was a major goal of the Fund because many western doctors observed the dais’s practices and found their traditions to be harmful. For example, the dais’s would massage the abdomen of the mother to speed up labor however that tradition caused uterine prolapse, a widespread issue amongst Indian women at the time. Because the dias’ methods were viewed as violent and extremely harmful, the Fund put forth money to educate them on successful ways to help women before, during, and after childbirth. The Fund also provided medical relief by establishing dispensaries and cottage hospitals for women and children under female superintendence. In addition, it opened female wards in existing hospitals also under female management as well as all women hospitals called zenana hospitals. The Fund also supplied trained female nurses and midwives in hospitals and in private homes.\n\nThe Fund financed treatment and teaching hospitals in Bihar, Calcutta, Madras, Karachi, Delhi, Bombay and in many of the United Provinces (roughly present day Uttar Pradesh and Uttarakhand). Most notably, the Fund sponsored the Lady Aitchison Hospital in Lahore, India. The Lady Aitchison Hospital, also known as the Aitchison Memorial Hospital, was a major center for training nurses and tradition midwives like the dias. Many of the hospitals the Fund financed are still functioning today. For example, the Lady Dufferin Hospital in Karachi is the largest solely female dedicated hospital today in Pakistan.\n\nThe Fund’s major financial basis was donations. Many saw this as a source of instability because donations were based on the popularity of Lady Dufferin and her husband as well as the favors expected by the donors in return. The administration of the Fund consisted of a central committee of members of the Viceroy’s Council and Home Department. It also included many influential Englishmen and Indians such as the Maharja Sir Jotendro Mohun Tagore, Sir Syed Ahmed Khan, and Sir Dinshaw Maneckji Petit.\n\nThere were three major criticisms of the Fund: its teaching, effectiveness, and integrity. Many believed the Fund was inefficient. Some argued that they inadequately taught doctors and employed subpar medical practitioners. By October 1908, only 43 completely qualified women medical professionals were working under the Fund however only 11 held university degrees. The British Medical Journal wrote in 1908 that, “The Government appears to have a perfect delight in swamping the country with unqualified medical practitioners.\" The Fund was also criticized as ineffective for placing male doctors in Zenana hospitals. Zenana women’s traditions forbade them from seeing, so they could be treated by the doctors the Fund provided. In addition, the Fund was also criticized for not giving the women they were educating enough reason to stay with learning medicine. The Fund paid for their education however their salaries were not high enough so it made more financial sense for the women to marry before they could give back to the hospital that educated them. The Fund set up this cycle of educating women who would then work for them, however, it was ineffective in some cases because the women would not stick with the medical profession for financial reasons. Because of the many criticisms of ineffectiveness, some of the Fund’s highest critics like The British Medical Journal called for a reorganization of the Fund. Some also believed vanity, not philanthropy, was the source of motivation for establishing the Fund. They criticized both Lady Dufferin for starting the Fund for her personal image and Queen Victoria for supporting the Fund for Britain’s international image.\n\nThe Fund continued even after Lady Dufferin’s term ended. Lady Lansdowne, who succeeded Lady Dufferin, continued to put work into the Fund which was passed down from vicereine to vicereine until 1947. In 1947, India gained independence from Great Britain and the Fund was taken over by the Central Indian Government by the Countess of Dufferin’s Fund Act, 1957. Once the Fund was taken over by the Central Government, it became obsolete. In 2005 a bill was passed repealing the Countess of Dufferin’s Fund Act, 1957, for unclear reasons.\n\n"}
{"id": "747259", "url": "https://en.wikipedia.org/wiki?curid=747259", "title": "Dependency theory", "text": "Dependency theory\n\nDependency theory is the notion that resources flow from a \"periphery\" of poor and underdeveloped states to a \"core\" of wealthy states, enriching the latter at the expense of the former. It is a central contention of dependency theory that poor states are impoverished and rich ones enriched by the way poor states are integrated into the \"world system\".\n\nThe theory arose as a reaction to modernization theory, an earlier theory of development which held that all societies progress through similar stages of development, that today's underdeveloped areas are thus in a similar situation to that of today's developed areas at some time in the past, and that, therefore, the task of helping the underdeveloped areas out of poverty is to accelerate them along this supposed common path of development, by various means such as investment, technology transfers, and closer integration into the world market. Dependency theory rejected this view, arguing that underdeveloped countries are not merely primitive versions of developed countries, but have unique features and structures of their own; and, importantly, are in the situation of being the weaker members in a world market economy.\n\nDependency theory no longer has many proponents as an overall theory, though some writers have argued for its continuing relevance as a conceptual orientation to the global division of wealth.\n\nDependency theory originates with two papers published in 1949 – one by Hans Singer, one by Raúl Prebisch – in which the authors observe that the terms of trade for underdeveloped countries relative to the developed countries had deteriorated over time: the underdeveloped countries were able to purchase fewer and fewer manufactured goods from the developed countries in exchange for a given quantity of their raw materials exports. This idea is known as the Prebisch–Singer thesis. Prebisch, an Argentine economist at the United Nations Commission for Latin America (UNCLA), went on to conclude that the underdeveloped nations must employ some degree of protectionism in trade if they were to enter a self-sustaining development path. He argued that import-substitution industrialisation (ISI), not a trade-and-export orientation, was the best strategy for underdeveloped countries. The theory was developed from a Marxian perspective by Paul A. Baran in 1957 with the publication of his \"The Political Economy of Growth\". Dependency theory shares many points with earlier, Marxist, theories of imperialism by Rosa Luxemburg and Vladimir Lenin, and has attracted continued interest from Marxists. Some authors identify two main streams in dependency theory: the Latin American Structuralist, typified by the work of Prebisch, Celso Furtado, and Aníbal Pinto at the United Nations Economic Commission for Latin America (ECLAC, or, in Spanish, CEPAL); and the American Marxist, developed by Paul A. Baran, Paul Sweezy, and Andre Gunder Frank.\n\nUsing the Latin American dependency model, the Guyanese Marxist historian Walter Rodney, in his book \"How Europe Underdeveloped Africa\", described in 1972 an Africa that had been consciously exploited by European imperialists, leading directly to the modern underdevelopment of most of the continent.\n\nThe theory was popular in the 1960s and 1970s as a criticism of modernization theory, which was falling increasingly out of favor because of continued widespread poverty in much of the world. It was used to explain the causes of overurbanization, a theory that urbanization rates outpaced industrial growth in several developing countries.\n\nThe Latin American Structuralist and the American Marxist schools had significant differences but agreed on some basic points:[B]oth groups would agree that at the core of the dependency relation between center and periphery lays [lies] the inability of the periphery to develop an autonomous and dynamic process of technological innovation. Technology – the Promethean force unleashed by the Industrial Revolution – is at the center of stage. The Center countries controlled the technology and the systems for generating technology. Foreign capital could not solve the problem, since it only led to limited transmission of technology, but not the process of innovation itself. Baran and others frequently spoke of the international division of labour – skilled workers in the center; unskilled in the periphery – when discussing key features of dependency.\n\nBaran placed surplus extraction and capital accumulation at the center of his analysis. Development depends on a population's producing more than it needs for bare subsistence (a surplus). Further, some of that surplus must be used for capital accumulation – the purchase of new means of production – if development is to occur; spending the surplus on things like luxury consumption does not produce development. Baran noted two predominant kinds of economic activity in poor countries. In the older of the two, plantation agriculture, which originated in colonial times, most of the surplus goes to the landowners, who use it to emulate the consumption patterns of wealthy people in the developed world; much of it thus goes to purchase foreign-produced luxury items –automobiles, clothes, etc. – and little is accumulated for investing in development. The more recent kind of economic activity in the periphery is industry—but of a particular kind. It is usually carried out by foreigners, although often in conjunction with local interests. It is often under special tariff protection or other government concessions. The surplus from this production mostly goes to two places: part of it is sent back to the foreign shareholders as profit; the other part is spent on conspicuous consumption in a similar fashion to that of the plantation aristocracy. Again, little is used for development. Baran thought that political revolution was necessary to break this pattern.\n\nIn the 1960s, members of the Latin American Structuralist school argued that there is more latitude in the system than the Marxists believed. They argued that it allows for partial development or \"dependent development\"–development, but still under the control of outside decision makers. They cited the partly successful attempts at industrialisation in Latin America around that time (Argentina, Brazil, Mexico) as evidence for this hypothesis. They were led to the position that dependency is not a relation between commodity exporters and industrialised countries, but between countries with different degrees of industrialisation. In their approach, there is a distinction made between the economic and political spheres: economically, one may be developed or underdeveloped; but even if (somewhat) economically developed, one may be politically autonomous or dependent. More recently, Guillermo O'Donnell has argued that constraints placed on development by neoliberalism were lifted by the military coups in Latin America that came to promote development in authoritarian guise (O'Donnell, 1982).\n\nThe importance of multinational corporations and state promotion of technology were emphasised by the Latin American Structuralists.\n\nFajnzybler has made a distinction between systemic or authentic competitiveness, which is the ability to compete based on higher productivity, and spurious competitiveness, which is based on low wages.\n\nThe third-world debt crisis of the 1980s and continued stagnation in Africa and Latin America in the 1990s caused some doubt as to the feasibility or desirability of \"dependent development\".\n\nThe \"sine qua non\" of the dependency relationship is not the difference in technological sophistication, as traditional dependency theorists believe, but rather the difference in financial strength between core and peripheral countries–particularly the inability of peripheral countries to borrow in their own currency. He believes that the hegemonic position of the United States is very strong because of the importance of its financial markets and because it controls the international reserve currency – the US dollar. He believes that the end of the Bretton Woods international financial agreements in the early 1970s considerably strengthened the United States' position because it removed some constraints on their financial actions.\n\n\"Standard\" dependency theory differs from Marxism, in arguing against internationalism and any hope of progress in less developed nations towards industrialization and a liberating revolution. Theotonio dos Santos described a \"new dependency\", which focused on both the internal and external relations of less-developed countries of the periphery, derived from a Marxian analysis. Former Brazilian President Fernando Henrique Cardoso (in office 1995–2002) wrote extensively on dependency theory while in political exile during the 1960s, arguing that it was an approach to studying the economic disparities between the centre and periphery. Cardoso summarized his version of dependency theory as follows:\n\nThe analysis of development patterns in the 1990s and beyond is complicated by the fact that capitalism develops not smoothly, but with very strong and self-repeating ups and downs, called cycles. Relevant results are given in studies by Joshua Goldstein, Volker Bornschier, and Luigi Scandella.\n\nWith the economic growth of India and some East Asian economies, dependency theory has lost some of its former influence. It still influences some NGO campaigns, such as Make Poverty History and the fair trade movement.\n\nTwo other early writers relevant to dependency theory were François Perroux and Kurt Rothschild. Other leading dependency theorists include Herb Addo, Walden Bello, Ruy Mauro Marini, Enzo Faletto, Armando Cordova, Ernest Feder, Pablo González Casanova, Keith Griffin, Kunibert Raffer, Paul Israel Singer, and Osvaldo Sunkel. Many of these authors focused their attention on Latin America; the leading dependency theorist in the Islamic world is the Egyptian economist Samir Amin.\n\nTausch, based on works of Amin from 1973 to 1997, lists the following main characteristics of periphery capitalism:\n\nThe American sociologist Immanuel Wallerstein refined the Marxist aspect of the theory and expanded on it, to form world-systems theory. This postulates a third category of countries, the \"semi-periphery\", intermediate between the core and periphery. Wallerstein believed in a tri-modal rather than a bi-modal system because he viewed the world-systems as more complicated than a simplistic classification as either core or periphery nations. To Wallerstein, many nations do not fit into one of these two categories, so he proposed the idea of a semi-periphery as an in between state within his model. In this model, the semi-periphery is industrialized, but with less sophistication of technology than in the core; and it does not control finances. The rise of one group of semi-peripheries tends to be at the cost of another group, but the unequal structure of the world economy based on unequal exchange tends to remain stable. Tausch traces the beginnings of world-systems theory to the writings of the Austro-Hungarian socialist Karl Polanyi after the First World War, but its present form is usually associated with the work of Wallerstein.\n\nDependency theory has also been associated with Johan Galtung's structural theory of imperialism.\n\nDependency theorists hold that short-term spurts of growth notwithstanding, long-term growth in the periphery will be imbalanced and unequal, and will tend towards high negative current account balances. Cyclical fluctuations also have a profound effect on cross-national comparisons of economic growth and societal development in the medium and long run. What seemed like spectacular long-run growth may in the end turn out to be just a short run cyclical spurt after a long recession. Cycle time plays an important role. Giovanni Arrighi believed that the logic of accumulation on a world scale shifts over time, and that the 1980s and beyond once more showed a deregulated phase of world capitalism with a logic, characterized - in contrast to earlier regulatory cycles - by the dominance of financial capital.\n\nIt is argued that, at this stage, the role of unequal exchange in the entire relationship of dependency cannot be underestimated. Unequal exchange is given if double factorial terms of trade of the respective country are < 1.0 (Raffer, 1987, Amin, 1975).\n\nThe former ideological head of the Blekingegade Gang and political activist Torkil Lauesen argues in his book \"The Global Perspective\" that political theory and practice stemming from dependency theory are more relevant than ever. He postulates that the conflict between countries in the core and countries in the periphery has been ever-intensifying and that the world is at the onset of a resolution of the core-periphery contradiction – that humanity is \"in for an economic and political rollercoaster ride\".\n\nEconomic policies based on dependency theory has been criticized by free-market economists such as Peter Bauer and Martin Wolf and others:\n\n\nMarket economists cite a number of examples in their arguments against dependency theory. The improvement of India's economy after it moved from state-controlled business to open trade is one of the most often cited (\"see also\" economy of India, \"The Commanding Heights\"). India's example seems to contradict dependency theorists' claims concerning comparative advantage and mobility, as much as its economic growth originated from movements such as outsourcing – one of the most mobile forms of capital transfer. South Korea and North Korea provide another example of trade-based development vs. autocratic self-sufficiency. Following the Korean War, North Korea pursued a policy of import substitution industrialization as suggested by dependency theory, while South Korea pursued a policy of export-oriented industrialization as suggested by comparative advantage theory. In 2013, South Korea's per capita GDP was 18 times that of North Korea. In Africa, states which have emphasized import-substitution development, such as Zimbabwe, have typically been among the worst performers, while the continent's most successful non-oil based economies, such as Egypt, South Africa, and Tunisia, have pursued trade-based development.\n\nAccording to economic historian Robert C. Allen, dependency theory's claims are \"debatable\", and that the protectionism that was implemented in Latin America as a solution ended up failing. The countries incurred too much debt and Latin America went into a recession. One of the problems was that the Latin American countries simply had too small national markets to be able to efficiently produce complex industrialized goods, such as automobiles.\n\n\n\n"}
{"id": "21316814", "url": "https://en.wikipedia.org/wiki?curid=21316814", "title": "Earth System Governance Project", "text": "Earth System Governance Project\n\nThe Earth System Governance Project is a long-term, interdisciplinary social science research programme originally developed under the auspices of the International Human Dimensions Programme on Global Environmental Change. It started in January 2009.\n\nThe Earth System Governance Project currently consists of a network of ca. 300 active and about 2,300 indirectly involved scholars from all continents. The project has evolved into the largest social science research network in the area of governance and global environmental change. The Earth System Governance Project Office is hosted at Lund University, Sweden.\n\nThe Earth System Governance Project aims to contribute to science on the large, complex challenges of governance in an era of rapid and large-scale environmental change. The project seeks to create a better understanding of the role of institutions, organizations and governance mechanisms by which humans regulate their relationship with the natural environment. The Earth System Governance Project aims to integrate governance research at all levels. The project aims to examine problems of the ‘global commons’, but also local problems from air pollution to the preservation of waters, waste treatment or desertification and soil degradation. However, due to natural interdependencies local environmental pollution can be transformed into changes of the global system that affect other localities. Therefore, the Earth System Governance Project looks at institutions and governance processes both local and globally.\n\nThe Earth System Governance Project is a scientific effort, but also aims to assist policy responses to the pressing problems of earth system transformation \n\nThe Earth System Governance Project organizes its research according to a conceptual framework guided by five analytical problems. These are the problems of the overall \"architecture\" of earth system governance, of \"agency\" beyond the state and of the state, of the \"adaptiveness\" of governance mechanisms and processes, of their \"accountability\" and legitimacy and of modes of \"allocation and access\" in earth system governance.\n\nThe concept of Earth System Governance is defined as: \n\nIn 2001, the four then active global change research programmes (DIVERSITAS, International Geosphere-Biosphere Programme, World Climate Research Programme, and International Human Dimensions Programme on Global Environmental Change) agreed to intensify co-operation through setting up an overarching Earth System Science Partnership. The research communities represented in this Partnership contend in the 2001 Amsterdam Declaration on Global Change that the earth system now operates ‘well outside the normal state exhibited over the past 500,000 years’ and that ‘human activity is generating change that extends well beyond natural variability—in some cases, alarmingly so— and at rates that continue to accelerate.’ To cope with this challenge, the four global change research programmes have called ‘urgently’ for strategies for Earth System management’.\n\nIn March 2007, in response to the 2001 Amsterdam Declaration, the Scientific Committee of the International Human Dimensions Programme on Global Environmental Change (IHDP), the overarching social science programme in the field, mandated the drafting of the Science Plan of the Earth System Governance Project by a newly appointed Scientific Planning Committee. The Earth System Governance Project builds on the results of an earlier long-term research programme, the IHDP core project Institutional Dimensions of Global Environmental Change (IDGEC). In 2008, the Earth System Governance Project was officially launched. \n\nIn 2009, the Science and Implementation Plan of the Earth System Governance Project was published. In the science and implementation plan, the conceptual problems, cross-cutting themes, flagship projects, and its policy relevance are outlined in detail. The Science Plan was written by an international, interdisciplinary Scientific Planning Committee chaired by Prof. Frank Biermann, which drew on a consultative process that started in 2004. Several working drafts of this Science Plan have been presented and discussed at a series of international events and conferences, and numerous scholars in the field, as well as practitioners, have offered suggestions, advice, and critique.\n\nSince then, the project has evolved into a broader research alliance that builds on an international network of research centers, lead faculty and research fellows. After the termination of the IHDP in 2014, the activities of the Earth System Governance research alliance are supported by an international steering group of representatives of the main Earth System Governance Research Centres and the global group of lead faculty and research fellows.\n\nFor its activities and implementation, the Earth System Governance Project relies on a global network of experts from different academic and cultural backgrounds. The research network consists of different groups of scientific experts. The Earth System Governance Project operates under the direction of a \"Scientific Steering Group\" chaired by Frank Biermann. The role of the Scientific Steering Committee is to guide the implementation of the Earth System Governance Science Plan. The \"Lead Faculty\" of the Earth System Governance Project is a group of individual scientists who take over (shared) responsibility for the development of research on particular analytical problems. \"Earth System Governance Fellows\" are scientists who link their own research projects with the broader themes and questions raised by the Earth System Governance Science and Implementation Plan.\n\nAn important element in the project organisation is the global alliance of research centres that brings together the VU University Amsterdam; the Australian National University; Chiang Mai University; Colorado State University; Lund University; University of East Anglia; University of Oldenburg; the Stockholm Resilience Centre; the University of Toronto; the Tokyo Institute of Technology and Yale University. In addition, strong networks on earth system governance research exist in China, Latin America, Central and Eastern Europe, and Russia.\n\nSince 2007, the Project has organized major scientific conferences addressing the topics of governance and global environmental change, including:\n\n\nThe network of researchers affiliated with the Earth System Governance Project has brought out many reports and books, and has published in journals such as International Environmental Agreements: Politics, Law and Economics; Ecological Economics; Global Environmental Change; Environmental Science & Policy Global Environmental Politics and Current Opinion in Environmental Sustainability Recurring research topics of the Earth System Governance Project are water governance, climate governance and fragmentation of global environmental governance.\n\nA related MIT Press Book series is designed to address the research challenge of earth system governance. Additionally, the Project publishes regular Working Papers, which are peer-reviewed online publications that broadly address questions raised by the Project’s Science and Implementation Plan.\n\nSeveral special issues of topics related to earth system governance have been published in scientific journals over the last years.\n\nEarth system governance as a research object is quickly emerging, and as a consequence, the number of education programmes on bachelor, master and doctoral level related to earth system governance steadily increases. A number of institutes and universities currently collaborate in a Global Alliance of Earth System Governance Research Centres, including:\n\n\nA substantial number of the workshops and other events of the project are capacity-building activities. The project also organizes, endorses and provides teaching to summer schools and capacity building events and programs. In addition, members of the Scientific Steering Group and staff of the International Project Office give guest lectures around the world.\n\nThe Earth System Governance Project organizes Task Forces, international networks of senior and early career scholars with a series of working groups focused on particular ideas or idea clusters. There are currently two active Task Forces:\n\nThis Task Force aims to explore key concepts with regard to Earth System Governance, such as planetary boundaries, green economy, resilience and the Anthropocene. It aims to critically examine and further refine these novel governance ideas. \n\nThis Task Force seeks aims to advance quantitative earth system governance research by promoting new international research collaborations, fostering interaction and dialogue among existing research projects, and developing architectures to promote the building and sharing of datasets.\n\nIn 2011, the Earth System Governance Project launched an initiative on International Environmental Governance. This initiative aims to provide a forum for discussion of current and ongoing research on international environmental governance and the institutional framework for sustainable development, in the period leading up to the 2012 United Nations Conference on Sustainable Development in Rio de Janeiro, also known as ‘Rio + 20’. In addition, the initiative aims to target decision-makers and to contribute not just to a better understanding but also to actual improvements in international environmental governance towards an institutional framework that enables sustainable development.\n\nThere is widespread support for the Earth System Governance Project in the scientific community, which is reflected in the size of the research network and in various publications by experts. However, criticisms of the Earth System Governance Project have also been made. \n\nIn an internal report of the International Human Dimensions Programme it is stated that the steering group of the Earth System Governance Project is too much dominated by experts from OECD countries. Since then, the Earth System Governance Project has actively sought ways to involve experts from different regions of the world. \n\nThe idea of earth system governance has also been criticized for being too top-down, for placing too much emphasis on global governance structures. According to Mike Hulme, earth system governance represents an attempt to ‘geopolitically engineer’ our way out of the climate crisis. He questions whether the climate is governable and argues that it is way too optimistic and even hubristic to attempt to control the global climate by universal governance regimes. This interpretation of the novel concept, however, has been rejected by other scholars as being too narrow and misleading \n\n\n\n"}
{"id": "21902683", "url": "https://en.wikipedia.org/wiki?curid=21902683", "title": "Earth system science", "text": "Earth system science\n\nEarth system science (ESS) is the application of systems science to the Earth sciences. In particular, it considers interactions between the Earth's \"spheres\"—atmosphere, hydrosphere, cryosphere, geosphere, pedosphere, biosphere, and, even, the magnetosphere—as well as the impact of human societies on these components. At its broadest scale, Earth system science brings together researchers across both the natural and social sciences, from fields including ecology, economics, geology, glaciology, meteorology, oceanography, paleontology, sociology, and space science. Like the broader subject of systems science, Earth system science assumes a holistic view of the dynamic interaction between the Earth's spheres and their many constituent subsystems, the resulting organization and time evolution of these systems, and their stability or instability. Subsets of Earth system science include systems geology and systems ecology, and many aspects of Earth system science are fundamental to the subjects of physical geography and climate science.\n\nThe Science Education Resource Center, Carleton College, offers the following description: \"Earth system science embraces chemistry, physics, biology, mathematics and applied sciences in transcending disciplinary boundaries to treat the Earth as an integrated system. It seeks a deeper understanding of the physical, chemical, biological and human interactions that determine the past, current and future states of the Earth. Earth system science provides a physical basis for understanding the world in which we live and upon which humankind seeks to achieve sustainability\".\n\nFor millennia, humans have speculated how the physical and living elements on the surface of the Earth combine, with gods and goddesses frequently posited to embody specific elements. The notion that the Earth, itself, is alive was a regular theme of Greek philosophy and religion. Early scientific interpretations of the Earth system began in the field of geology, initially in the Middle East and China, and largely focused on aspects such as the age of the Earth and the large-scale processes involved in mountain and ocean formation. As geology developed as a science, understanding of the interplay of different facets of the Earth system increased, leading to the inclusion of factors such as the Earth's interior, planetary geology and living systems.\n\nIn many respects, the foundational concepts of Earth system science can be seen in the holistic interpretations of nature promoted by the 19th century geographer Alexander von Humboldt. In the 20th century, Vladimir Vernadsky (1863–1945) saw the functioning of the biosphere as a geological force generating a dynamic disequilibrium, which in turn promoted the diversity of life. In the mid-1960s, James Lovelock first postulated a regulatory role for the biosphere in feedback mechanisms within the Earth system. Initially named the \"Earth Feedback hypothesis\", Lovelock later renamed it the Gaia hypothesis, and subsequently further developed the theory with American evolutionary theorist Lynn Margulis during the 1970s. In parallel, the field of systems science was developing across numerous other scientific fields, driven in part by the increasing availability and power of computers, and leading to the development of climate models that began to allow the detailed and interacting simulations of the Earth's weather and climate. Subsequent extension of these models has led to the development of \"Earth system models\" (ESMs) that include facets such as the cryosphere and the biosphere.\n\nAs an integrative field, Earth system science assumes the histories of a vast range of scientific disciplines, but as a discrete study it evolved in the 1980s, particularly at NASA, where a committee called the Earth System Science Committee was formed in 1983. The earliest reports of NASA's ESSC, \"Earth System Science: Overview\" (1986), and the book-length \"Earth System Science: A Closer View\" (1988), constitute a major landmark in the formal development of Earth system science. Early works discussing Earth system science, like these NASA reports, generally emphasized the increasing human impacts on the Earth system as a primary driver for the need of greater integration among the life and geo-sciences, making the origins of Earth system science parallel to the beginnings of global change studies and programs.\n\nClimatology and climate change have been central to Earth system science since its inception, as evidenced by the prominent place given to climate change in the early NASA reports discussed above. The Earth's climate system is a prime example of an emergent property of the whole planetary system which cannot be fully understood without regarding it as a single integrated entity. It is also a property of the system where human impacts have been growing rapidly in recent decades, lending immense importance to the successful development and advancement of Earth system science research. As just one example of the centrality of climatology to the field, leading American climatologist Michael E. Mann is the Director of one of the earliest centers for Earth system science research, the Earth System Science Center at Pennsylvania State University, and its mission statement reads, \"the Earth System Science Center (ESSC) maintains a mission to describe, model, and understand the Earth's climate system\".\n\nThe Gaia hypothesis posits that living systems interact with physical components of the Earth system to form a self-regulating whole that maintains conditions that are favourable for life. Developed initially by James Lovelock, the hypothesis attempts to account for key features of the Earth system, including the long period (several billion years) of relatively favourable climatic conditions against a backdrop of steadily increasing solar radiation. Consequently, the Gaia hypothesis has important implications for Earth system science, as noted by NASA's Director for Planetary Science, James Green, in October 2010: \"Dr. Lovelock and Dr. Margulis played a key role in the origins of what we now know as Earth system science\".\n\nAlthough the Gaia hypothesis and Earth system science take an interdisciplinary approach to studying systems operations on a planetary-scale, they are not synonymous with one another. A number of potential Gaian feedback mechanisms have been proposed—such as the CLAW hypothesis—but the hypothesis does not have universal support within the scientific community, though it remains an active research topic.\n\nEarth system science can be studied at a postgraduate level at some universities, with notable programs at such institutions as the University of California, Irvine, University of Pennsylvania, and Stanford University. In general education, the American Geophysical Union, in cooperation with the Keck Geology Consortium and with support from five divisions within the National Science Foundation, convened a workshop in 1996, \"to define common educational goals among all disciplines in the Earth sciences\". In its report, participants noted that, \"The fields that make up the Earth and space sciences are currently undergoing a major advancement that promotes understanding the Earth as a number of interrelated systems\". Recognizing the rise of this systems approach, the workshop report recommended that an Earth system science curriculum be developed with support from the National Science Foundation. In 2000, the Earth System Science Education Alliance was begun, and currently includes the participation of 40+ institutions, with over 3,000 teachers having completed an ESSEA course as of fall 2009\".\n"}
{"id": "1765418", "url": "https://en.wikipedia.org/wiki?curid=1765418", "title": "Ecosystem ecology", "text": "Ecosystem ecology\n\nEcosystem ecology is the integrated study of living (biotic) and non-living (abiotic) components of ecosystems and their interactions within an ecosystem framework. This science examines how ecosystems work and relates this to their components such as chemicals, bedrock, soil, plants, and animals.\n\nEcosystem ecology examines physical and biological structures and examines how these ecosystem characteristics interact with each other. Ultimately, this helps us understand how to maintain high quality water and economically viable commodity production. A major focus of ecosystem ecology is on functional processes, ecological mechanisms that maintain the structure and services produced by ecosystems. These include primary productivity (production of biomass), decomposition, and trophic interactions.\n\nStudies of ecosystem function have greatly improved human understanding of sustainable production of forage, fiber, fuel, and provision of water. Functional processes are mediated by regional-to-local level climate, disturbance, and management. Thus ecosystem ecology provides a powerful framework for identifying ecological mechanisms that interact with global environmental problems, especially global warming and degradation of surface water.\n\nThis example demonstrates several important aspects of ecosystems:\n\nThese characteristics also introduce practical problems into natural resource management. Who will manage which ecosystem? Will timber cutting in the forest degrade recreational fishing in the stream? These questions are difficult for land managers to address while the boundary between ecosystems remains unclear; even though decisions in one ecosystem will affect the other. We need better understanding of the interactions and interdependencies of these ecosystems and the processes that maintain them before we can begin to address these questions.\n\nEcosystem ecology is an inherently interdisciplinary field of study. An individual ecosystem is composed of populations of organisms, interacting within communities, and contributing to the cycling of nutrients and the flow of energy. The ecosystem is the principal unit of study in ecosystem ecology.\n\nPopulation, community, and physiological ecology provide many of the underlying biological mechanisms influencing ecosystems and the processes they maintain. Flowing of energy and cycling of matter at the ecosystem level are often examined in ecosystem ecology, but, as a whole, this science is defined more by subject matter than by scale. Ecosystem ecology approaches organisms and abiotic pools of energy and nutrients as an integrated system which distinguishes it from associated sciences such as biogeochemistry.\n\nBiogeochemistry and hydrology focus on several fundamental ecosystem processes such as biologically mediated chemical cycling of nutrients and physical-biological cycling of water. Ecosystem ecology forms the mechanistic basis for regional or global processes encompassed by landscape-to-regional hydrology, global biogeochemistry, and earth system science.\n\nEcosystem ecology is philosophically and historically rooted in terrestrial ecology. The ecosystem concept has evolved rapidly during the last 100 years with important ideas developed by Frederic Clements, a botanist who argued for specific definitions of ecosystems and that physiological processes were responsible for their development and persistence. Although most of Clements ecosystem definitions have been greatly revised, initially by Henry Gleason and Arthur Tansley, and later by contemporary ecologists, the idea that physiological processes are fundamental to ecosystem structure and function remains central to ecology.\n\nIn this model, energy flows through the whole system were dependent on biotic and abiotic interactions of each individual component (species, inorganic pools of nutrients, etc.). Later work demonstrated that these interactions and flows applied to nutrient cycles, changed over the course of succession, and held powerful controls over ecosystem productivity. Transfers of energy and nutrients are innate to ecological systems regardless of whether they are aquatic or terrestrial. Thus, ecosystem ecology has emerged from important biological studies of plants, animals, terrestrial, aquatic, and marine ecosystems.\n\nEcosystem services are ecologically mediated functional processes essential to sustaining healthy human societies. Water provision and filtration, production of biomass in forestry, agriculture, and fisheries, and removal of greenhouse gases such as carbon dioxide (CO) from the atmosphere are examples of ecosystem services essential to public health and economic opportunity. Nutrient cycling is a process fundamental to agricultural and forest production.\n\nHowever, like most ecosystem processes, nutrient cycling is not an ecosystem characteristic which can be “dialed” to the most desirable level. Maximizing production in degraded systems is an overly simplistic solution to the complex problems of hunger and economic security. For instance, intensive fertilizer use in the midwestern United States has resulted in degraded fisheries in the Gulf of Mexico. Regrettably, a “Green Revolution” of intensive chemical fertilization has been recommended for agriculture in developed and developing countries. These strategies risk alteration of ecosystem processes that may be difficult to restore, especially when applied at broad scales without adequate assessment of impacts. Ecosystem processes may take many years to recover from significant disturbance.\n\nFor instance, large-scale forest clearance in the northeastern United States during the 18th and 19th centuries has altered soil texture, dominant vegetation, and nutrient cycling in ways that impact forest productivity in the present day. An appreciation of the importance of ecosystem function in maintenance of productivity, whether in agriculture or forestry, is needed in conjunction with plans for restoration of essential processes. Improved knowledge of ecosystem function will help to achieve long-term sustainability and stability in the poorest parts of the world.\n\nBiomass productivity is one of the most apparent and economically important ecosystem functions. Biomass accumulation begins at the cellular level via photosynthesis. Photosynthesis requires water and consequently global patterns of annual biomass production are correlated with annual precipitation. Amounts of productivity are also dependent on the overall capacity of plants to capture sunlight which is directly correlated with plant leaf area and N content.\n\nNet primary productivity (NPP) is the primary measure of biomass accumulation within an ecosystem. Net primary productivity can be calculated by a simple formula where the total amount of productivity is adjusted for total productivity losses through maintenance of biological processes:\n\nNPP is difficult to measure but a new technique known as eddy co-variance has shed light on how natural ecosystems influence the atmosphere. Figure 4 shows seasonal and annual changes in CO concentration measured at Mauna Loa, Hawaii from 1987 to 1990. CO concentration steadily increased, but within-year variation has been greater than the annual increase since measurements began in 1957.\n\nThese variations were thought to be due to seasonal uptake of CO during summer months. A newly developed technique for assessing ecosystem NPP has confirmed seasonal variation are driven by seasonal changes in CO uptake by vegetation. This has led many scientists and policy makers to speculate that ecosystems can be managed to ameliorate problems with global warming. This type of management may include reforesting or altering forest harvest schedules for many parts of the world.\n\nDecomposition and nutrient cycling are fundamental to ecosystem biomass production. Most natural ecosystems are nitrogen (N) limited and biomass production is closely correlated with N turnover.\nTypically external input of nutrients is very low and efficient recycling of nutrients maintains productivity. Decomposition of plant litter accounts for the majority of nutrients recycled through ecosystems (Figure 3). Rates of plant litter decomposition are highly dependent on litter quality; high concentration of phenolic compounds, especially lignin, in plant litter has a retarding effect on litter decomposition. More complex C compounds are decomposed more slowly and may take many years to completely breakdown. Decomposition is typically described with exponential decay and has been related to the mineral concentrations, especially manganese, in the leaf litter.\nGlobally, rates of decomposition are mediated by litter quality and climate. Ecosystems dominated by plants with low-lignin concentration often have rapid rates of decomposition and nutrient cycling (Chapin et al. 1982). Simple carbon (C) containing compounds are preferentially metabolized by decomposer microorganisms which results in rapid initial rates of decomposition, see Figure 5A, models that depend on constant rates of decay; so called “k” values, see Figure 5B. In addition to litter quality and climate, the activity of soil fauna is very important \n\nHowever, these models do not reflect simultaneous linear and non-linear decay processes which likely occur during decomposition. For instance, proteins, sugars and lipids decompose exponentially, but lignin decays at a more linear rate Thus, litter decay is inaccurately predicted by simplistic models.\n\nA simple alternative model presented in Figure 5C shows significantly more rapid decomposition that the standard model of figure 4B. Better understanding of decomposition models is an important research area of ecosystem ecology because this process is closely tied to nutrient supply and the overall capacity of ecosystems to sequester CO from the atmosphere.\n\nTrophic dynamics refers to process of energy and nutrient transfer between organisms. Trophic dynamics is an important part of the structure and function of ecosystems. Figure 3 shows energy transferred for an ecosystem at Silver Springs, Florida. Energy gained by primary producers (plants, P) is consumed by herbivores (H), which are consumed by carnivores (C), which are themselves consumed by “top- carnivores”(TC).\n\nOne of the most obvious patterns in Figure 3 is that as one moves up to higher trophic levels (i.e. from plants to top-carnivores) the total amount of energy decreases. Plants exert a “bottom-up” control on the energy structure of ecosystems by determining the total amount of energy that enters the system.\n\nHowever, predators can also influence the structure of lower trophic levels from the top-down. These influences can dramatically shift dominant species in terrestrial and marine systems The interplay and relative strength of top-down vs. bottom-up controls on ecosystem structure and function is an important area of research in the greater field of ecology.\n\nTrophic dynamics can strongly influence rates of decomposition and nutrient cycling in time and in space. For example, herbivory can increase litter decomposition and nutrient cycling via direct changes in litter quality and altered dominant vegetation. Insect herbivory has been shown to increase rates of decomposition and nutrient turnover due to changes in litter quality and increased frass inputs. \nHowever, insect outbreak does not always increase nutrient cycling. Stadler showed that C rich honeydew produced during aphid outbreak can result in increased N immobilization by soil microbes thus slowing down nutrient cycling and potentially limiting biomass production. North atlantic marine ecosystems have been greatly altered by overfishing of cod. Cod stocks crashed in the 1990s which resulted in increases in their prey such as shrimp and snow crab Human intervention in ecosystems has resulted in dramatic changes to ecosystem structure and function. These changes are occurring rapidly and have unknown consequences for economic security and human well-being.\n\nThe biosphere has been greatly altered by the demands of human societies. Ecosystem ecology plays an important role in understanding and adapting to the most pressing current environmental problems. Restoration ecology and ecosystem management are closely associated with ecosystem ecology. Restoring highly degraded resources depends on integration of functional mechanisms of ecosystems.\n\nWithout these functions intact, economic value of ecosystems is greatly reduced and potentially dangerous conditions may develop in the field. For example, areas within the mountainous western highlands of Guatemala are more susceptible to catastrophic landslides and crippling seasonal water shortages due to loss of forest resources. In contrast, cities such as Totonicapán that have preserved forests through strong social institutions have greater local economic stability and overall greater human well-being.\n\nThis situation is striking considering that these areas are close to each other, the majority of inhabitants are of Mayan descent, and the topography and overall resources are similar. This is a case of two groups of people managing resources in fundamentally different ways. Ecosystem ecology provides the basic science needed to avoid degradation and to restore ecosystem processes that provide for basic human needs.\n"}
{"id": "55668685", "url": "https://en.wikipedia.org/wiki?curid=55668685", "title": "Edward Snowden asylum in Russia", "text": "Edward Snowden asylum in Russia\n\nEdward Snowden asylum in Russia is part of the aftermath from the global surveillance disclosures made by Edward Snowden. On June 23, 2013, Snowden flew from Hong Kong to Moscow's Sheremetyevo Airport. Noting that his U.S. passport had been cancelled, Russian authorities restricted him to the airport terminal. On August 1, after 39 days in the transit section, Snowden left the airport. He was granted temporary asylum in Russia for one year. On August 7, 2014, six days after Snowden's one-year temporary asylum expired, his Russian lawyer announced that Snowden had received a three-year residency permit. It allowed him to travel freely within Russia and to go abroad for up to three months. Snowden was not granted permanent political asylum, which would require a separate process.\n\nRussia first received information about Snowden when he was in Hong Kong China. At that time, they were told that a person who wanted to fight against human right violations wanted to seek asylum in Russia. In 2017, during \"The Putin Interviews\" with the Director Oliver Stone, the Russian president Vladimir Putin described how Russia got involved in the Snowden saga. During that time, Rusisia did not want to get involved as it already had a strained relationship with the United states which it did not wish to exacerbate. Thereafter they learnt that Snowden was on a plane bound for Moscow, to transfer to another plane bound for Latin America. Most of this information was received through informal channels including information leaded to the press. While he was int he plane, his destination countries grew reluctant to allow him in, and Snowden was thus stuck in the transit area of Moscow international airport. While in the airport, U.S.authorities asked Russia to extradite Snowden. However this was not possible as Russia had proposed a treaty on cooperation in legal matters, requiring mutual extradition of criminals, which U.S. had not agreed upon. Further, United States had never extradited any Russian criminal who had taken asylum in USA, hence Snowden's extradition would have been unprecedented. Snowden had not committed a crime as per Russian law.\n\nSnowden left the Moscow airport on August 1 after 39 days in the transit section. He was granted temporary asylum in Russia for one year, with extensions possible. According to his Russian lawyer, Snowden went to an undisclosed location for security reasons. The White House stated that it was \"extremely disappointed,\" and cancelled a previously scheduled meeting with Russian President Vladimir Putin. Additionally, Republican U.S. Senator Lindsey Graham urged President Obama to boycott the 2014 Winter Olympics in Sochi, but House Speaker John Boehner, also a Republican, rejected that idea as \"dead wrong.\"\n\nIn late July 2013, Lonnie Snowden said he believed his son would be better off staying in Russia, and didn't believe he would receive a fair trial in the U.S. In mid-October, he visited his son in Moscow, later telling the press that he was pleased with Edward's situation, and still believed Russia was the best choice for his asylum, saying he wouldn't have to worry about people \"rushing across the border to render him.\" Lonnie Snowden commented that his son was living comfortably in Russia and found Moscow \"modern and sophisticated.\" Edward Snowden's Russian lawyer, Anatoly Kucherena, announced on October 31 that his client had found a website maintenance job at one of Russia's largest websites, but declined to identify the site. Jesselyn Radack, one of Snowden's American lawyers, said she was unaware of any new job. Asked about this by \"The Moscow Times\" in June 2014, \"The Guardian\" correspondent Luke Harding replied, \"Kucherena is completely unreliable as a source. We [\"The Guardian\"] did the rounds of Russian IT companies when he made that claim last year and none of them—none of the big ones, at least—confirmed this.\"\n\nFormer CIA analyst Ray McGovern, who had traveled to Russia to give Snowden a whistleblower award, said that Snowden gave no storage devices such as hard drives or USB flash drives to Russia or China, and had carried four blank laptops with him to Hong Kong and Moscow as a diversion. U.S. officials said they assumed that any classified materials downloaded by Snowden had fallen into the hands of China and Russia, though they acknowledged they had no proof of this. In an October 2013 interview, Snowden maintained that he did not bring any classified material into Russia \"because it wouldn't serve the public interest.\" He added, \"There's a zero percent chance the Russians or Chinese have received any documents.\" In June 2015, however, \"The Sunday Times\" reported that British government officials anonymously claimed to the paper that Russia and China had cracked an encrypted cache of files taken by Snowden, forcing the withdrawal of British spies from live operations.<ref name=\"ST 14/06/15\"></ref> The BBC also stated that their sources told them British intelligence assets had been moved as a precaution after the Snowden leaks. Glenn Greenwald charged that the report contained fabrications and did nothing more than quote anonymous British officials; he said parts were removed from the original post without \"The Times\" saying it did so.\nWikiLeaks released video of Snowden on October 11 taken during the Sam Adams Award reception in Moscow, his first public appearance in three months. Former U.S. government officials attending the ceremony said they saw no evidence Snowden was under the control of Russian security services. The whistleblower group said he was in good spirits, looked well, and still believes he was right to release the NSA documents. In the video, Snowden said \"people all over the world are coming to realize\" that the NSA's surveillance programs put people in danger, hurt the U.S. and its economy, and \"limit our ability to speak and think and live and be creative, to have relationships and associate freely\" as well as putting people \"at risk of coming into conflict with our own government.\"\n\nOn October 31, German lawmaker Hans-Christian Ströbele traveled to Moscow to meet with Snowden, whom he invited to testify before the German parliament to assist investigations into NSA surveillance of German Chancellor Angela Merkel's phone since 2002. After the visit, Snowden indicated a willingness to testify, though not from Moscow as Germany requested. Snowden said he would rather give testimony before the U.S. Congress, his second choice being Berlin.\n\nAlso in October, Glenn Greenwald stated that the U.S. revoked Snowden's passport while he was in transit to Latin America and threatened other countries that might offer safe passage. WikiLeaks representative Sarah Harrison, who accompanied Snowden from Hong Kong to Moscow, left Russia in early November after waiting until she felt confident he had situated himself and was free from government interference.\n\nOn December 17, 2013, Snowden wrote an open letter to the people of Brazil offering to assist the Brazilian government in investigating allegations of U.S. spying, and added that he continued to seek, and would require, asylum. Snowden wrote, \"Until a country grants permanent political asylum, the U.S. government will continue to interfere with my ability to speak ... going so far as to force down the Presidential Plane of Evo Morales to prevent me from traveling to Latin America!\" Brazil had been in an uproar since Snowden revealed that the U.S. was spying on Brazilian President Dilma Rousseff, her senior advisors, and Brazil's national oil company, Petrobras. Rousseff and officials of the Brazilian foreign ministry said in response that they could not consider asylum for Snowden because they had not received any formal request. A representative of the foreign ministry said that a fax requesting asylum had been sent to the Brazilian embassy in Moscow in July but it had not been signed and could not be authenticated. David Miranda, the Brazilian partner of Glenn Greenwald, launched an Internet petition urging the Brazilian president to consider offering Snowden asylum.\n\nSnowden met with Barton Gellman of \"The Washington Post\" six months after the disclosure for an exclusive interview spanning 14 hours, his first since being granted temporary asylum. Snowden talked about his life in Russia as \"an indoor cat,\" reflected on his time as an NSA contractor, and discussed at length the revelations of global surveillance and their reverberations. Snowden said, \"In terms of personal satisfaction, the mission's already accomplished ... I already won. As soon as the journalists were able to work, everything that I had been trying to do was validated.\" He commented \"I am not trying to bring down the NSA, I am working to improve the NSA ... I am still working for the NSA right now. They are the only ones who don't realize it.\" On the accusation from former CIA and NSA director Michael Hayden that he had defected, Snowden stated, \"If I defected at all, I defected from the government to the public.\" In 2014, Snowden said that he lives \"a surprisingly open life\" in Russia and that he is recognized when he goes to computer stores.\n\nAccording to BuzzFeed, in January 2014 an anonymous Pentagon official said he wanted to kill Snowden. \"I would love to put a bullet in his head,\" said the official, calling Snowden \"single-handedly the greatest traitor in American history.\" Members of the intelligence community also expressed their violent hostility. \"In a world where I would not be restricted from killing an American,\" said an NSA analyst, \"I personally would go and kill him myself.\" A State Department spokesperson condemned the threats.\n\nOn \"Meet the Press\" in late January 2014, speculation arose from top U.S. officials in the House and Senate Intelligence Committees that Snowden might have been assisted by Russian intelligence, prompting a rare interview during which Snowden spoke in his defense. He told \"The New Yorker\" \"this 'Russian spy' push is absurd,\" adding that he \"clearly and unambiguously acted alone, with no assistance from anyone, much less a government.\"<ref name=\"Mayer/New Yorker\"></ref> Investigations by the NSA and the FBI found no evidence that Snowden received any aid. Days later, U.S. Senator Dianne Feinstein stated that she had seen no evidence that Snowden is a Russian spy. Germany's \"Der Spiegel\" suggested the accusations were part of a smear campaign by U.S. officials. The accusations did not faze Snowden, who said \"outlets report statements that the speakers themselves admit are sheer speculation.\"\n\nIn late January 2014, U.S. attorney general Eric Holder, in an interview with MSNBC, indicated that the U.S. could allow Snowden to return from Russia under negotiated terms, saying he was prepared to engage in conversation with him, but that full clemency would be going too far.\n\nSnowden's first television interview aired January 26, 2014, on Germany's NDR. In April 2014, he appeared on video from an undisclosed location during President Putin's live annual Q&A exchange with the public. Snowden asked whether Russia intercepted, stored or analyzed individuals' communications. Putin replied, \"Russia uses surveillance techniques for spying on individuals only with the sanction of a court order. This is our law, and therefore there is no mass surveillance in our country.\" Benjamin Wittes in \"The New Republic\" described the exchange as \"a highly-scripted propaganda stunt for Vladimir Putin\". Snowden insisted his question was designed to hold the Russian president accountable. In an op-ed for \"The Guardian\", Snowden said his question was intended \"to mirror the now infamous exchange in US Senate intelligence committee hearings between senator Ron Wyden and the director of national intelligence, James Clapper, about whether the NSA collected records on millions of Americans, and to invite either an important concession or a clear evasion.\" Snowden called Putin's response \"evasive\". A few days later, \"The Daily Beast\" reported that Snowden himself \"instantly regretted\" asking Putin the \"softball question\", which was crafted with several of his key advisers, and that he was mortified by the reaction. ACLU attorney Ben Wizner, one of Snowden's closest advisers, told the \"Beast\" that Snowden hadn't realized how much his appearance with Putin would be seen as a Kremlin propaganda victory. \"I know this is hard to believe,\" Wizner acknowledged. \"I know if I was just watching from afar, I'd think, 'Wow, they forced him to do this.' But it's not true. He just fucking did it.\" Asked six months later about the incident, Snowden conceded, \"Yeah, that was terrible! Oh, Jesus, that blew up in my face. ... And in the United States, what I did appearing at that Putin press conference was not worth the price.\"\n\nIn March 2014, the international advocacy group European Digital Rights (EDRi) said that the European Parliament, in adopting a Data Protection Reform Package, rejected amendments that would have dropped charges against Snowden and granted him asylum or refugee status.\n\nIn May 2014, NBC's Brian Williams presented the first interview for American television. In June, \"The Washington Post\" reported that during his first year of Russian asylum, Snowden had received \"tens of thousands of dollars in cash awards and appearance fees from privacy organizations and other groups,\" fielded inquiries about book and movie projects, and was considering taking a position with a South African foundation that would support work on security and privacy issues. \"Any moment that he decides that he wants to be a wealthy person,\" said Snowden's attorney Ben Wizner, \"that route is available to him,\" although the U.S. government could attempt to seize such proceeds.\n\nAlso in May, the German Parliamentary Committee investigating the NSA spying scandal unanimously decided to invite Snowden to testify as a witness. In September, opposition parties in the German parliament filed constitutional complaints to force the government to let Snowden testify in Berlin. Snowden had refused a proposed video conference from Moscow, saying he wants to testify only in Berlin and asking for safe conduct.\n\nOn July 13, 2014, \"The Guardian\" published its first story based on an exclusive, seven-hour interview newly conducted with Snowden in a Moscow city centre hotel. Snowden condemned the Data Retention and Investigatory Powers Bill announced to the UK's House of Commons on July 10 bolstering the state's right to keep personal data held by Internet and phone companies. Snowden said it was very unusual for a public body to pass such emergency legislation except during total war. \"I mean we don't have bombs falling. We don't have U-boats in the harbor. It defies belief.\" The \"Daily Mail\" reported that Snowden had \"caused fury\" by attacking Britain. \"His critics said the new surveillance Bill was being pushed through Parliament today largely because of his treachery in leaking Britain's spy secrets.\" On July 13 and 17, \"The Guardian\" posted video clips, of about 2 minutes and 14 minutes in length, excerpted from the full interview. On July 18, \"The Guardian\" published a nearly 10,000-word edited transcript of their Snowden interview. A year after arriving in Moscow, Snowden said he is still learning Russian. He keeps late and solitary hours, effectively living on U.S. time. He does not drink, cooks for himself but doesn't eat much. \"I don't live in absolute secrecy,\" he says. \"I live a pretty open life—but at the same time I don't want to be a celebrity.\" He does not work for a Russian organization, yet is financially secure thanks to substantial savings from his years as a well-paid contractor and more recently numerous awards and speaking fees from around the world.\n\nOn August 7, 2014, six days after Snowden's one-year temporary asylum expired, his Russian lawyer, Anatoly Kucherena, announced that Snowden had received a three-year residency permit. It allowed him to travel freely within Russia and to go abroad for up to three months. Kucherena explained that Snowden had not been granted permanent political asylum, which required a separate process.\n\nIn May 2015, Snowden's lawyer Ben Wizner said that Snowden's main source of income was speaking fees, which sometimes exceeded $10,000 per appearance. In November 2015, Snowden said that he does not intend to play any role in Russian politics and wants to devote his focus to U.S. issues. During a panel event, he said, \"people say I live in Russia, but that's actually a little bit of a misunderstanding. I live on the Internet.\"\n\nIn the waning days of the Obama administration, former CIA Director Michael Morell suggested that Russia should extradite Snowden to the United States as a \"gift\" to Donald Trump. The comment drew harsh criticism by the Russian Foreign Ministry, which noted that Snowden had been granted an extension of his stay until 2020, and said what Morell proposed would be a betrayal.\n\nA senior U.S. official said in February 2017 that Russia was considering extraditing Snowden in order to \"curry favor\" with President Donald Trump. Snowden cited the comment as evidence that he was not a Russian spy.\n"}
{"id": "1749638", "url": "https://en.wikipedia.org/wiki?curid=1749638", "title": "Encyclopedia of World Problems and Human Potential", "text": "Encyclopedia of World Problems and Human Potential\n\nThe Encyclopedia of World Problems and Human Potential is published by the Union of International Associations (UIA). It is available online since 2000, and was previously available as a CD-ROM and as a three-volume book. The online Encyclopedia is currently in a redevelopment phase.\n\nThe \"Encyclopedia\" was started in 1972 and now comprises more than 100,000 entries and 700,000 links, as well as 500 pages of introductory notes and commentaries. The Encyclopedia collects information on problems, strategies, values, concepts of human development, and various intellectual resources.\n\nThe \"Encyclopedia of World Problems and Human Potential\" is made up from data gathered from many sources. Those data are grouped into various databases which constitute the backbone of the \"Encyclopedia\". The databases are searchable; query results may be seen as lists or as various visualizations.\n\n\n• Basic universal problems include danger, lack of information, social injustice, war, environmental degradation. \n• Cross-sectoral problems include animal suffering, irresponsible nationalism, soil degradation. \n• Detailed problems include detention of mothers, epidemics, white-collar crime.\n• Emanations of other problems include terrorism targeted against tourists, injustice of mass trials, threatened species of Caudata. \n• Fuzzy exceptional problems include blaming victims, pacifism, unconstrained free trade.\n• Very specific problems include blue baby, tomato mottle virus, costly uniforms.\n• Problems under consideration include feminist backlash, mudslide.\n• Suspect problems include threatened species of Zapus hudsonius preblei, uncommitted volunteer workers.\n\n• Abstract fundamental strategies include compromising, transcending, providing.\n• Basic universal strategies include eliminating discrimination, combating desertification, reducing unemployment.\n• Cross-sectoral strategies include orienting economic policy toward social need, managing crises. \n• Detailed strategies include establishing national government NGO departments, using psychological warfare. \n• Emanations of other strategies include lifting restrictions on human rights advocacy, reviewing provisions of the UN Charter. \n• Exceptional strategies include begging, rechanneling expenditures on defence, advocating nihilism.\n• Very specific strategies include working with young people, undertaking public works. \n• Unconfirmed strategies include abolishing zoos, ventilating air through buildings. \n• Provisional strategies include developing chest radiology, preserving internal political borders. \n• Strategy polarities include deepening-shallowing, intuiting-reasoning, supporting-opposing. \n• Strategy roles include advisor, traitor, confessor.\n• Strategy types or complexes include communication, judgement, time.\n\n• Constructive values include peace, harmony, beauty. \n• Destructive values include conflict, depravity, ugliness.\n• Value polarities include agreement-disagreement, freedom-restraint, pleasure-displeasure. \n• Value clusters include feeling complex, interaction complex, communication complex.\n\n• Concepts of human development include vocational training, benevolence, emancipation of the self.\n• Modes of awareness include compassion, sense of shame, conviction, sense of humor.\n\n• Communication: Forms of presentation include animation, statistical indicators, prophecy. \n• Metaphors include ball games, sexual intercourse, personification, stick and carrot processes.\n• Patterns (Christopher Alexander) include encirclement, internal connectedness between domains, partially isolated contexts.\n• Symbols include birds, food-related objects, sacred calendar.\n• Transformative conferencing includes aggressive participant type, lecture, team roles.\n• Transformative metaphors (I Ching) include creativity, receptivity, inexperience. \n\n\nThe \"Encyclopedia\" online databases consist of over 100,000 entries (also called profiles) and 700,000 links. An entry, for instance War, may include the following elements:\n1) name, alternative names, nature or definition, background or context, incidence (for problems) or implementation (for strategies), claim of importance, counter-claim, quotations or aphorisms (for values);\n2) links to the same database entries that are more general (broader), more specific (narrower), related (in some as yet unspecified manner), preceding (aggravating or reducing problems, constraining or facilitating strategies, prior modes of awareness), following (aggravated or reduced problems, constrained or facilitated strategies, subsequent modes of awareness);\n3) cross-reference links, mainly between entries in the \"Problems\", \"Strategies\", \"Values\", and \"Development\" databases;\n4) links to entries in other UIA databases, mainly the \"International Organizations\" database;\n5) reference links to entries in the \"Bibliography (issues)\" database;\n6) links to relevant websites.\n\nThe \"Encyclopedia of World Problems and Human Potential\" contains nearly 500 pages of introductory notes and commentaries. Some of them just provide readers with usual information about the work content and its organization. Most of them, however, represent extensive reports on the exploratory work done by the editors in eight projects (also called research areas, or sections). Here are those projects, with illustrative examples of key ideas figuring in the notes and commentaries.\n\nA first objective of the editors in that project is to collect and present information on the following topics: the problems with which humanity perceives itself to be faced; the organizational, human, and intellectual resources it believes it has at its disposal; the values by which it is believed any change should be guided; the concepts of human development considered to be either the means or the end of any such social transformation. A second objective is to clarify the conceptual challenge of interrelating such plentiful and disparate or even contradictory information. A third objective is to enable alternation between viewpoints from different cultures, ideologies, beliefs and even \"facts\", as a way for individuals and societies to become empowered with an appropriate response to the problematic conditions of the moment.\n\nIt is the disagreement amongst the advocates of different approaches to problems or solutions which hinders the formation of any consensual strategy and the mobilization of adequate resources. That is why the \"Encyclopedia\" uses an approach that is as general and minimally structured as is feasible without losing coherence and utility. The intent is first to contribute to clarify the nature, extent, and interrelationships of problems and solutions. Even the distinction between problems and solutions is not always clear. For instance, housing an increasing number of people is a solution that may aggravate the problem of urban overcrowding, and the death of individuals is a problem that contributes to the solution of reducing ecological impact of overpopulation.\n\nThe \"Encyclopedia\" databases are much about how problems, strategies, values, development concepts, and organizations are linked together. As a result, the possibility of focusing on feedback loops has proven to be an important feature of the \"Encyclopedia\", and a program has been carried out to identify \"vicious problem loops\". A vicious problem loop is a chain of problems, each aggravating the next, and with the last looping back to aggravate the first in the chain. Here is an example: Man-made disasters, Vulnerability of ecosystem niches, Natural environment degradation, Shortage of natural resources, Unbridled competition for scarce resources, Man-made disasters. Solutions that focus on only one problem in a chain may fail or even be harmful, because the cycle has the capacity to regenerate itself, and also because several cycles may interlock, forming tangled skeins of interlinked global problems. The loop detection program detected more than 50,000 loops (of up to 9 elements) in more than 12,000 problem profiles. It is thought that a similar work could be done about mutually facilitating or constraining strategy loops, so as to constitute a dynamic response to aggravating or reducing loops of problems through a circle of matching strategies.\n\nThat project endeavors to present all the phenomena in society that are perceived negatively by groups transcending national frontiers. Those phenomena constitute a challenge to creative remedial action. Groups are strongly motivated by the problems that infringe their values and arouse their indignation. As such, problems are a major stimulus driving the development of society. Although there is agreement that problems are numerous and that many are really serious, little effort has been made to determine how many problems there are. Likewise, while it is becoming increasingly evident that problems interact with one another, and constitute complex networks or systems, little effort has been made to map that complexity. The perceptions documented in that project raise useful questions concerning the nature and existence of problems, especially when other groups consider that one perception or another is irrelevant, misleading or misinformed. An aim of that research area, then, is to assemble information whose significance is collectively repressed, displaced onto some less threatening problems, or projected in the form of blame onto some other social group.\n\nViews concerning problems are extremely varied. Several pages in the notes and commentaries deal with that variety. Problems are agenda items for assemblies or conferences; action targets for organizations; issues for political parties or governments; events or topics for the media; markets for businesses; sins for religions; puzzles for sciences. Problems can be viewed as synonymous with chaos and disorder, or as elements in an ordered array; as static or dynamic entities; as discrete or continuous phenomena; as objective things or subjective experiences; as directly experienceable phenomena or as indirect implications of seemingly innocent phenomena; as inherently comprehensible or incomprehensible entities; as the results of due processes or as spontaneous phenomena. For many people in the West problems may be considered as artifacts of concerned minds, about which reason, principles, or history are relevant, while in the East to conceive of life as presenting problems to be solved may be seen as a misconception of life. Other pages of notes and commentaries deal extensively with the variety of points of view under headings such as \"Approaches to problems\", \"Beyond the problem-lobby mindset\", or \"Problem perception and levels of awareness\".\n\nThat project aims at identifying the complete range of strategies perceived by constituencies acting at the international level.\n\nThe conventional way of addressing any problem situation is to elaborate a strategy, but given the number, variety and interrelationships of the problems, it is uncertain whether any conventional strategy could be adequate. In general, many groups have \"answers\" to the current crisis. The proponents of each such answer naturally attach special importance to their own as being of crucial relevance at this time, or even as being the only appropriate basis for a viable world society in the future. However, that focus on \"answer production\", a vital moving force in society, obscures the manner in which such answers, in the absence of integration between them, undermine each other’s significance.\n\nIt appears to the editors that the elements of the strategic challenge at this time include:\nThe strategic problem therefore is how to ensure that the appropriate organizational resources emerge, and are supported with appropriate conceptual tools, in response to emerging problem complexes. But it would seem that this must be achieved without organizing such response – for to the extent that any part of the network is organized, other parts will develop (and probably should develop) which favor alternative approaches. The challenge is therefore to clarify the conditions of a network strategy, i.e. an approach which facilitates or catalyses (rather than organizes) the development of organizational networks in response to problem networks, in the light of values perceived in various parts of the social system.\n\nMany pages of notes and commentaries describe in details various approaches to global strategies, and their limits. Such are \"Strategic ecosystem: beyond \"The Plan\"\", \"Governance\" (a series of pages on reports from the Club of Rome, the Commission on Global Governance, and four others groups), \"Strategic denial: action inhibition\", \"Post-crisis opportunities: range of strategies\", and \"Post-crisis opportunities: strategies in chaos\". A long series of pages explores how to \"move beyond the unimodal answer and recognize that because each form of action has both strengths and weaknesses, the key to a more effectively multimodal answer lies in finding how to interrelate the various unimodal answers so that they correct for each others weaknesses and counteract each others excesses.” But, it must also be asked, is integrated action of any type feasible at this time? The exploration begins with \"Strategic appropriateness: questionable answers\", and finishes with \"Action implications: consensus, uncertainty and action formulation\". Conditions for progress in strategy-making are more explicitly brought up in pages such as \"Strategic ecosystem: integrating constraint and opposition\", and \"Post-crisis opportunities: in quest of radical coherence\".\n\nThat project aims at registering a complete range of values with which people identify, to which they are attracted or which they reject as abhorrent. The notion of wisdom is explored as a way, an art, of dealing with value dilemmas. For instance, \"Complexity: understanding value systems\" is a text that looks at values through a positive interpretation, a negative interpretation, a paradoxical negative interpretation of the positive, and a paradoxical positive interpretation of the negative. Another text, \"Insights: wisdom and requisite variety\", gives a list of several sources of wisdom which, in interrelation, may be required in a value system to ensure the long-term viability of a complex society.\n\nThe purpose of that project is to provide profiles of human development approaches and modes of awareness, and their relationships, as perceived by different beliefs systems, disciplines, religions, and cultures. Much of the material in this section is about the limitations of language in expressing levels of significance beyond that which can be effectively captured by words, so that, seemingly, what we need to understand may only be expressible in a \"language\" that we do not know! That paradox is explored in a page entitled \"Language and the reconstruction of reality\". Other challenges relative to human potential and development are explored in pages such as \"Phases of human development through challenging problems\", or \"Barriers to transcendent insight and social transformation\".\n\nThe purpose of that project is to review the range of communication possibilities of metaphor, pattern and symbol. New conceptual tools are required to configure very large quantities of information into patterns that are both memorable and meaningful, and metaphor is often the only means to deal comprehensibly with complexity. Moreover, exploring “new ways of thinking” in the light of enhanced mental imagery (or mental model) appears indispensable inasmuch as furthering “mobilization of public opinion” and the “political will to change” is dependent upon insights that are too complex to be easily communicable. For instance, limitations of dualistic thinking are well-known and holistic approaches may represent more desirable alternatives, but how is it possible to implement such alternatives? The page \"Challenge: transcending the \"switch\" metaphor\" deals with that question.\n\nThe purpose of that project is to assemble descriptions of the range of conceptual approaches which are considered integrative and which are held by some international constituencies to provide a key for strategic response to the global problematique. Buzzwords like \"global\", \"networking\" and \"systematic\" are often used as magical \"words-of-power\". Nevertheless, in a society characterized by specialization, fragmentation, disparateness, or opposition, integrative approaches until now have proved inadequate or too difficult to implement. In order to go beyond that difficulty, it seems necessary to creatively introduce novelties, such as a science or art of disagreement that could clarify how to \"disagree intelligently\" rather than do so in a mindless manner requiring some form of violent or repressive reaction to eliminate the disagreement as soon as possible. There is a wide variety of initiatives pertaining to integrative knowledge and transdisciplinarity, and a page like \"Significance: previous, parallel or related initiatives\" presents several of them. With regard to interdisciplinary relationships between organizations, problems, strategies, values and human development, there is the \"Integrative Matrix of Human Preoccupations\" which has been developed by the editors and which allows to deal with all those elements in an exploratory fashion.\n\nThe purpose of that project is to provide a context for the presentation of new approaches to the challenges highlighted in the other projects. The emphasis is on configuring information in new ways, through a variety of accessible techniques, so as to allow easier navigation through complexity, and so as to evoke imaginative insights in response to such complexity. The \"Overview\" page presents about forty of those approaches or techniques, including interactive database use, q-analysis, information visualization, confidence artistry, tensegrity organization, I Ching, transformative conferencing, or marriage between poetry and policy-making.\n\nThe project was originally conceived in 1972 by James Wellesley-Wesley, who provided financial support through the foundation Mankind 2000, and Anthony Judge, by whom the work was orchestrated.\n\nWork on the first edition started with funds from Mankind 2000, matching those of the UIA. The publisher Klaus Saur, of Munich, provided funds, in conjunction with those from the UIA, for work on the 2nd, 3rd, and 4th editions. Seed funding for the third volume of the 4th edition was also provided on behalf of Mankind 2000. In the nineties, seed funding was provided, again on behalf of Mankind 2000, for computer equipment which subsequently allowed the UIA to develop a large website and make progressively available for free the \"Encyclopedia\" databases as from the 1994–1995 edition. In turn, this proven knowledge management capacity enabled the UIA, on the initiative of Nadia McLaren, a consultant ecologist who has been a primary editor for the \"Encyclopedia\", to successfully instigate two multi-partner projects funded by the European Union, with matching funds from the UIA. The work done through those two projects, \"Ecolynx: Information Context for Biodiversity Conservation\" (mainly) and \"Interactive Health Ecology Access Links\", eventually resulted in what amounted to a fifth, web-based, edition of the \"Encyclopedia\" in 2000. In their own ways, two other persons in particular effectively supported the project over the years: Robert Jungk of Mankind 2000, and Christian de Laet of the UIA.\n\nThe \"Encyclopedia\" was the fruit of a continuing processing of documents gathered from many of the thousands of the international organizations profiled in the \"Yearbook of International Organizations\". Many such bodies regularly produce a wide range of material on the areas of their concern, many regularly send documents to the UIA, and many, when requested more specifically, supplied documents for the \"Encyclopedia\". The following organizations provided documents in the greatest quantity: FAO, ILO, UNICEF, UNESCO, UNCTD, WHO, Commonwealth Secretariat, Council of Europe, OECD, World Bank group. Furthermore, the United Nations Library in Geneva facilitated access to other material over two decades. The Institute of Cultural Affairs International was contractually associated at one point to the edition and other aspects of the \"Encyclopedia\" project. The \"Goals, Processes and Indicators of Development\" project (led by Johan Galtung) of the United Nations University, in which Anthony Judge participated on behalf of the UIA between 1978 and 1982, was an experience of learning and research that had a significant impact on the editorial content of the \"Encyclopedia\". Another noticeable influence came from futures studies, with which Judge has long been associated. He reports in \"Encyclopedia Illusions\" how the narrow focus of the Club of Rome on a few socio-economic aspects of futures research prompted the much vaster exploration concerning world problems and human potential.\n\nAnthony Judge was the architect and managing editor of the \"Encyclopedia\". He was also the main author of the notes and commentaries. The principal editors over the years have been, for different editions, Jon Jenkins and Maureen Jenkins (who had also worked at the Institute of Cultural Affairs), Owen Victor, Jacqueline Nebel, Nadia McLaren, and Tomáš Fülöpp. There were also enthusiastic editorial contributions from volunteers. All people related to the UIA who worked directly on one or more of the five \"Encyclopedia\" editions figure on a list that can be found online under the heading \"Associates of the Union of Intelligible Associations\". This is because in 2005, following disagreement over the partnership contract, Anthony Judge, as Executive Secretary of Mankind 2000, reframed the \"Encyclopedia\" as having been a strategic initiative of the Union of Intelligible Associations.\nTomáš Fülöpp continued maintaining and improving \"Encyclopedia\" databases at the UIA until January 2012.\n\n\nThere has been several reviews of the \"Encyclopedia\". One of the harshest criticisms came from the American Library Association in 1987: \"The board considers the \"Encyclopedia of World Problems and Human Potential\" a problematic monument to idiosyncrasy, confusion, and obfuscation that certainly is not worth purchasing at any price.\" Similarly, The Guardian was extremely critical in a review article published in 1992, to which Anthony Judge recently responded via Transcend Media Service on the occasion of the publication in The Wall Street Journal of a page-one sympathetic review of the \"Encyclopedia\" initiative, in December 2012. The work itself is keen on presenting, in various places, disclaimers, reservations or warning texts that anticipate criticisms and explain the strengths and weaknesses of its approaches, including the failure to advocate a position, or the sometimes excessive complexity in its methods or language. Most reviews are laudatory, however. Richard Slaughter emphasized that the significance of the work is not its size or the scope of its references, impressive though these are. It is rather in the nature of what has been attempted. The accompanying notes and commentaries, he said, are good enough to be published separately because they contain highly cogent observations on the \"global problematique\", commentaries on the work of numerous great thinkers from a wide variety of fields, and an impressive array of insights about the epistemology, symbolism, metaphysics, metaphors and linguistic representations of the subject. As far as practice is concerned, the highest commendation perhaps is to be found in the words of Elise Boulding: \"Any one of us (...) can actively become a part in the world problem solving process by using this encyclopedia.\"\n\n\n\n"}
{"id": "13876896", "url": "https://en.wikipedia.org/wiki?curid=13876896", "title": "FIDE world rankings", "text": "FIDE world rankings\n\nThe \"Fédération Internationale des Échecs\" (FIDE) governs international chess competition. Each month, FIDE publishes the lists \"Top 100 Players\", \"Top 100 Women\", \"Top 100 Juniors\" and \"Top 100 Girls\", as well as rankings of countries according to the average rating of their top 10 players and top 10 female players. The Elo rating system is used.\n\nThe top 20 players on 1 November 2018 were ranked as follows:\n<section begin=topplayers />\n<section end=topplayers />\n\nThe top 20 females were ranked on 1 November 2018 as follows:\n<section begin=topwomen />\n<section end=topwomen />\n\nJuniors are considered to be players who remain under the age of 21 years for the duration of the current calendar year.\n\nThe top 20 positions were ranked on 1 November 2018 as follows:\n\nGirls are considered to be female players who will remain under the age of 21 years for the duration of the current calendar year.\n\nThe top 20 positions were ranked on 1 November 2018 as follows:\nFIDE publishes two lists ranking countries. The first ranks them according to the average rating of their top 10 players, while the second ranks them according to the average rating of their top 10 female players. The top 20 positions in the former list were ranked on 1 October 2018 as follows:\n\nThe top 20 countries by average rating of the top 10 female players were ranked on 1 October 2018 as follows:\n\n"}
{"id": "24060108", "url": "https://en.wikipedia.org/wiki?curid=24060108", "title": "Faith and Globalisation Initiative", "text": "Faith and Globalisation Initiative\n\nThe Faith and Globalisation Initiative (FGI) is an international group of universities created in 2008 by former British prime minister Tony Blair and his Faith Foundation.\nThe Faith and Globalisation Initiative is \"bringing together some of the world’s leading research Universities to form a global network focusing on the emerging field of faith and globalisation\".\n\nIn 2008 Yale University was the first university the Foundation started working with and in 10 months it expanded the network to include the National University of Singapore, Durham University and McGill University. Two years later the Foundation developed an associate university programme which seeks to foster the study of faith and globalisation in a broad range of higher education institutions.\n\nThe institutions were selected on the basis of their ability to contribute to the Initiative, but also to ensure that they have a geographic and cultural spread that lends multiple perspectives to the discipline.\n\nKey objectives of the FGI are the following:\n\nAs of January 2011, the participating members of the Faith and Globalisation Network of Universities are:\n\nLead Universities:\n\nAssociate Universities:\n\n"}
{"id": "47893942", "url": "https://en.wikipedia.org/wiki?curid=47893942", "title": "Feed My Starving Children", "text": "Feed My Starving Children\n\nFeed My Starving Children is a Christian non-profit organization that coordinates the packaging and distribution of food to people in developing nations. Founded in 1987, it has reached out to more than 70 countries.\n\nRichard Proudfit, a Minneapolis business man and philanthropist, founded the organization after visiting Honduras after a hurricane. Proudfit witnessed dying starving children all around him and was moved to start Feed My Starving Children in 1987. Proudfit risked his life in war zones around the world to feed starving children. Proudfit passed away November 13th, 2018. Together with his second foundation Kids against hunger the two organizations feed over 1 billion children annually. Proudfit received the Jefferson Award for Public Service in 2012joining the ranks of Bill Gates and Paul Newman.\n\nThe organization recruits volunteers including school children to assist in packing. They also employ paid staff to supervise the operations.\n\n"}
{"id": "42877090", "url": "https://en.wikipedia.org/wiki?curid=42877090", "title": "Gaststätte Röhrl", "text": "Gaststätte Röhrl\n\nThe Gaststätte Röhrl (Röhrl restaurant) is a restaurant with beer garden in Eilsbrunn in the district of Regensburg (Germany). Since 1658 it is continuously operated and owned by the Röhrl family.\n\nIn November 2010 the Guinness Book of Records introduced the restaurant as the oldest continuously operated restaurant in the world, conducting business for more than three and half centuries.\n\nThe restaurant is located on the western edge of Eilsbrunn, opposite the parish church of St. Wolfgang.\n\nThe oldest part of the restaurant, the main building is a two-storey building with garett hip roof and the taproom behind segmental arch windows on the ground floor. This component was built before 1800, maybe early as 1665 as the inscription \"MDCLXV\" suggests. Approximately 50 guests can be accommodated; the decor is simple and largely obtained in the first half of the 20th century according to their time of origin. Above the entrance stands a large dormer with a pulley from the roof.\n\nA two-storey gabled roof construction from 1839 connects to the main building. In the early 20th century another saddleback roof building for a festival hall with space for 250 guests was erected; the Art Nouveau door at the entrance to the old building was originally part of this component. The beer garden hosts further 400 guests.\n\nThe property is under conservation.\n\nThe restaurant is operated in the eleventh generation by members of the family Röhrl.\n\nIn 1658 the family got the restaurant by marriage of Andreas Röhrl (app. 1636–1706) with Susanna Hofmeister, the innkeeper Georg Hofmeister's daughter. Röhrl was henceforth brewer and landlord of Eilsbrunn. Married twice he left the business to his son Joachim (1676-1737). The year \"MDCLXV\" on the entrance facade suggests that a conversion or new construction of the property was done in 1665. After the death of the fifth Röhrl male in a row, his widow took over the business. In 1839 she reconstructed the building and set up an extension. She later bequeathed the property to her youngest son. A picture in the guest room shows her grandson and successor to her son Johann Nepomuk Röhrl. The opening of the nearby railroad made the area a popular tourist destination for visitors even from other parts of Germany, so that a large festival hall and guest rooms (now discontinued) were erected.\n\nAfter the death of another Johann Nepomuk Röhrl, taking over the inn after World War II, the daughter Antonie Kolbe took over the Gaststätte Röhrl. In 1971 the brewery was shut down. Since 2006 the inn is directed by her nephew Muk Röhrl, a skilled cook and businessman.\n\nToday the beer sold in the restaurant is mainly produced by the Röhrl brewery in Straubing. This brewery was founded by Josef Röhrl, the first Johann Nepomuk's brother, in 1881.\n\n\n"}
{"id": "22163671", "url": "https://en.wikipedia.org/wiki?curid=22163671", "title": "Genoese map", "text": "Genoese map\n\nThe Genoese map is a 1457 world map. The map relied extensively on the account of the traveler to Asia Niccolo da Conti, rather than the usual source of Marco Polo. The author is not known, but is a more modern development than the Fra Mauro world map, with fairly good proportions given to each continents. The map also depicts a three-masted European ship in the Indian Ocean, something which had not occurred yet at the time.\n\nA Genoese flag in the upper northwest corner of the map establishes this map’s origin, along with the coat of arms of the Spinolas, a prominent Genoese mercantile family. Niccolò de'Conti was from a noble mercantile family; at an early age he decided to follow in the family tradition by establishing a lucrative trading operation in the East.\n\nThe Genoese map’s sea monsters reflect the cartographer’s interest in exotic wonders, which is everywhere in evidence on the map, and typical of the scientific outlook of the early modern period, which was driven by curiosity and took a great interest in marvels. The demon-like monster in particular is evidence of the cartographer’s research in recent travel literature to find sea monsters for his map.\n\nThis map was done in rich color and was not made particularly used for anything but for display.They say this map was sent to the Portuguese court in 1474 and then to Columbus and this is the map that he used to travel the India sea to the Atlantic but was never proven. The map is now the property of the Italian government and is to be found in the Biblioteca Nazionale Centrale of Florence however the map was not taken care of due to the way it’s been handled throughout the years.\n\nThe ships that could carry a thousand men—six hundred seamen and four hundred soldiers. The larger vessels also carried small boats, which were used, as Marco Polo states, “to lay out the anchors, catch fish, bring supplies aboard, and the like. When the ship is under sail, she carries these boats slung to her side.” Many of the vessels had as many as four decks, and even the smaller ones, fifty or sixty cabins. Vegetables, we are told, were sometimes grown on board.\n\nThe oval form is not unknown among medieval maps. Hugh of Saint Victor had described the world as being the shape of Noah’s Ark, and Ranulf Higden world maps were oval. A standard way of describing the earth was to compare it to an egg. The main purpose of the analogy seems to have been to describe the various spheres surrounding the earth (egg white, shell), but the idea of an egg shape could have been derived from these works. Another possibility is that the oval form represents the \"mandorla\", or nimbus, which surrounded Christ in many medieval works of art.\n\n\n"}
{"id": "1366094", "url": "https://en.wikipedia.org/wiki?curid=1366094", "title": "Glenn Hauser", "text": "Glenn Hauser\n\nGlenn Hauser (born April 12, 1945 in Berkeley, California) is an internationally known American DXer and radio host from Enid, Oklahoma. He produces and presents a weekly 30-minute program, \"World Of Radio\", heard on a number of non-commercial AM and FM stations throughout the U.S. and worldwide on shortwave.\n\nHauser began his broadcasting career on Radio Canada International during the late 1970s, providing DX tips on Sunday nights, and his tips also appeared on Radio Nederland's \"DX Juke Box\" program. He wrote for \"Popular Electronics\" and \"Modern Electronics\", and published \"Review of International Broadcasting\".\n\n\"World Of Radio\" debuted in 1980 on WUOT-FM in Knoxville, Tennessee, moving to shortwave two years later. The half-hour program consists of Hauser reading news about radio around the world in a characteristic monotone. Although \"World of Radio\" focuses on shortwave news, it covers all aspects of broadcasting. Most items are contributed by listeners to the program or DX publications.\n\nHauser also produced \"Mundo Radial\", a Spanish edition of \"World of Radio\", from January 2002 to November 2007.\n\nHauser introduced \"Review of International Broadcasting\" in February 1977. The magazine published 154 issues, with columns such as \"Listener Insights on Programming,\" \"Radio Equipment Forum,\" \"DX Listening Digest,\" \"The Media Mind\" and \"Satellite Watch.\" Contributors included David Newkirk, Loren Cox and Juan Carlos Codina, and \"RIB\" also featured columns from the BBC, John Norfolk and Alan Roe. It was published monthly during the 1970s and 1980s, later decreasing to quarterly and semiannually before ceasing publication in October 1997. \"RIB\"s successor, \"DX Listening Digest\", went online in 1999.\n\nHauser is a political liberal and an agnostic, which occasionally puts him at odds with the fundamentalist-dominated American shortwave scene which carries \"World of Radio\".\n\n"}
{"id": "35306935", "url": "https://en.wikipedia.org/wiki?curid=35306935", "title": "Global Internet usage", "text": "Global Internet usage\n\nGlobal Internet usage refers to the number of people who use the Internet worldwide, which can be displayed using tables, charts, maps and articles which contain more detailed information on a wide range of usage measures.\n\nAs of June 2018, 55.1% of the world's population has internet access. In 2015, the International Telecommunication Union estimated about 3.2 billion people, or almost half of the world's population, would be online by the end of the year. Of them, about 2 billion would be from developing countries, including 89 million from least developed countries.\n\nThe Web Index is a composite statistic designed and produced by the World Wide Web Foundation. It provides a multi-dimensional measure of the World Wide Web’s contribution to development and human rights globally. It covers 86 countries as of 2014, the latest year for which the index has been compiled. It incorporates indicators that assess the areas of universal access, freedom and openness, relevant content, and empowerment, which indicate economic, social, and political impacts of the Web.\n\nThe Carna Botnet was a botnet of 420,000 devices created by hackers to measure the extent of the Internet in what the creators called the \"Internet Census of 2012\". \n\n\n"}
{"id": "13305402", "url": "https://en.wikipedia.org/wiki?curid=13305402", "title": "Global brain", "text": "Global brain\n\nThe global brain is a neuroscience-inspired and futurological vision of the planetary information and communications technology network that interconnects all humans and their technological artifacts. As this network stores ever more information, takes over ever more functions of coordination and communication from traditional organizations, and becomes increasingly intelligent, it increasingly plays the role of a brain for the planet Earth.\n\nProponents of the global brain hypothesis claim that the Internet increasingly ties its users together into a single information processing system that functions as part of the collective nervous system of the planet. The intelligence of this network is collective or distributed: it is not centralized or localized in any particular individual, organization or computer system. Therefore, no one can command or control it. Rather, it self-organizes or emerges from the dynamic networks of interactions between its components. This is a property typical of complex adaptive systems.\n\nThe World-wide web in particular resembles the organization of a brain with its webpages (playing a role similar to neurons) connected by hyperlinks (playing a role similar to synapses), together forming an associative network along which information propagates. This analogy becomes stronger with the rise of social media, such as Facebook, where links between personal pages represent relationships in a social network along which information propagates from person to person.\nSuch propagation is similar to the spreading activation that neural networks in the brain use to process information in a parallel, distributed manner.\n\nAlthough some of the underlying ideas were already expressed by Nikola Tesla in the late 19th century and were written about by many others before him, the term “global brain” was coined in 1982 by Peter Russell in his book \"The Global Brain\". How the Internet might be developed to achieve this was set out in 1986. The first peer-reviewed article on the subject was published by Gottfried Mayer-Kress in 1995, while the first algorithms that could turn the world-wide web into a collectively intelligent network were proposed by Francis Heylighen and Johan Bollen in 1996.\n\nReviewing the strands of intellectual history that contributed to the global brain hypothesis, Francis Heylighen distinguishes four perspectives: \"“organicism”\", \"“encyclopedism”\", \"“emergentism”\" and \"“evolutionary cybernetics”\". He asserts that these developed in relative independence but now are converging in his own scientific re-formulation.\n\nIn the 19th century, the sociologist Herbert Spencer saw society as a social organism and reflected about its need for a nervous system. Entomologist William Wheeler developed the concept of the ant colony as a spatially extended organism, and in the 1930s he coined the term superorganism to describe such an entity. This concept was later adopted by thinkers such as Gregory Stock in his book Metaman and Joel de Rosnay to describe planetary society as a superorganism.\n\nThe mental aspects of such an organic system at the planetary level were perhaps first broadly elaborated by palaeontologist and Jesuit priest Pierre Teilhard de Chardin. In 1945, he described a coming “planetisation” of humanity, which he saw as the next phase of accelerating human “socialisation”. Teilhard described both socialization and planetization as irreversible, irresistible processes of \"macrobiological development\" culminating in the emergence of a noosphere, or global mind (see Emergentism below).\n\nThe more recent living systems theory describes both organisms and social systems in terms of the \"critical subsystems\" (\"organs\") they need to contain in order to survive, such as an internal transport system, a resource reserve, and a decision-making system. This theory has inspired several thinkers, including Peter Russell and Francis Heylighen to define the global brain as the network of information processing subsystems for the planetary social system.\n\nIn the perspective of encyclopedism, the emphasis is on developing a universal knowledge network. The first systematic attempt to create such an integrated system of the world's knowledge was the 18th century \"Encyclopédie\" of Denis Diderot and Jean le Rond d'Alembert. However, by the end of the 19th century, the amount of knowledge had become too large to be published in a single synthetic volume. To tackle this problem, Paul Otlet founded the science of documentation, now called information science. In the 1930s he envisaged a World Wide Web-like system of associations between documents and telecommunication links that would make all the world's knowledge available immediately to anybody. H. G. Wells proposed a similar vision of a collaboratively developed world encyclopedia that would be constantly updated by a global university-like institution. He called this a World Brain, as it would function as a continuously updated memory for the planet, although the image of humanity acting informally as a more organic global brain is a recurring motif in other of his works.\n\nTim Berners-Lee, the inventor of the World Wide Web, too, was inspired by the free-associative possibilities of the brain for his invention. The brain can link different kinds of information without any apparent link otherwise; Berners-Lee thought that computers could become much more powerful if they could imitate this functioning, i.e. make links between any arbitrary piece of information. The most powerful implementation of encyclopedism to date is Wikipedia, which integrates the associative powers of the world-wide-web with the collective intelligence of its millions of contributors, approaching the ideal of a global memory. The Semantic web, also first proposed by Berners-Lee, is a system of protocols to make the pieces of knowledge and their links readable by machines, so that they could be used to make automatic inferences, thus providing this brain-like network with some capacity for autonomous \"thinking\" or reflection.\n\nThis approach focuses on the emergent aspects of the evolution and development of complexity, including the spiritual, psychological, and moral-ethical aspects of the global brain, and is at present the most speculative approach. The global brain is here seen as a natural and emergent process of planetary evolutionary development. Here again Pierre Teilhard de Chardin attempted a synthesis of science, social values, and religion in his The Phenomenon of Man, which argues that the \"telos\" (drive, purpose) of universal evolutionary process is the development of greater levels of both complexity and consciousness. Teilhard proposed that if life persists then planetization, as a biological process producing a global brain, would necessarily also produce a global mind, a new level of planetary consciousness and a technologically supported network of thoughts which he called the \"noosphere\". Teilhard's proposed technological layer for the noosphere can be interpreted as an early anticipation of the Internet and the Web.\n\nPhysicist and philosopher Peter Russell elaborates a similar view, and stresses the importance of personal spiritual growth, in order to build and to achieve synergy with the spiritual dimension of the emerging superorganism. This approach is most popular in New Age circles, which emphasize growth in consciousness rather than scientific modelling or the implementation of technological and social systems.\n\nSystems theorists and cyberneticists commonly describe the emergence of a higher order system in evolutionary development as a “metasystem transition” (a concept introduced by Valentin Turchin) or a “major evolutionary transition”. Such a metasystem consists of a group of subsystems that work together in a coordinated, goal-directed manner. It is as such much more powerful and intelligent than its constituent systems. Francis Heylighen has argued that the global brain is an emerging metasystem with respect to the level of individual human intelligence, and investigated the specific evolutionary mechanisms that promote this transition\n\nIn this scenario, the Internet fulfils the role of the network of “nerves” that interconnect the subsystems and thus coordinates their activity. The cybernetic approach makes it possible to develop mathematical models and simulations of the processes of self-organization through which such coordination and collective intelligence emerges.\n\nIn 1994 Kevin Kelly, in his popular book \"\", posited the emergence of a \"hive mind\" from a discussion of cybernetics and evolutionary biology.\n\nIn 1996, Francis Heylighen and Ben Goertzel founded the Global Brain group, a discussion forum grouping most of the researchers that had been working on the subject of the global brain to further investigate this phenomenon. The group organized the first international conference on the topic in 2001 at the Vrije Universiteit Brussel.\n\nAfter a period of relative neglect, the Global Brain idea has recently seen a resurgence in interest, in part due to talks given on the topic by Tim O'Reilly, the Internet forecaster who popularized the term Web 2.0, and Yuri Milner, the social media investor. In January 2012, the Global Brain Institute (GBI) was founded at the Vrije Universiteit Brussel to develop a mathematical theory of the “brainlike” propagation of information across the Internet. In the same year, Thomas W. Malone and collaborators from the MIT Center for Collective Intelligence have started to explore how the global brain could be “programmed” to work more effectively, using mechanisms of collective intelligence. The complexity scientist Dirk Helbing and his NervousNet group have recently started developing a \"Planetary Nervous System\", which includes a \"Global Participatory Platform\", as part of the large-scale FuturICT project, thus preparing some of the groundwork for a Global Brain.\n\nIn July 2017 Elon Musk founded the company Neuralink, which aims to create a Neural Lace, which is a concept invented by the novelist Iain M. Banks and basically refers to a machine interface woven into the brain, to allow the user to access all available human information. A core driver behind this business idea is Mr Musk’s argument, that human beings soon have to embrace brain implants to stay relevant in a world which, he believes, will soon be dominated by artificial intelligence. The firm raised $27m from 12 Investors in 2017 .\n\nA common criticism of the idea that humanity would become directed by a global brain is that this would reduce individual diversity and freedom, and lead to mass surveillance. This criticism is inspired by totalitarian forms of government, as exemplified by George Orwell's character of \"Big Brother\". It is also inspired by the analogy between collective intelligence or swarm intelligence and insect societies, such as beehives and ant colonies, in which individuals are essentially interchangeable. In a more extreme view, the global brain has been compared with the Borg, the race of collectively thinking cyborgs conceived by the Star Trek science fiction franchise.\n\nGlobal brain theorists reply that the emergence of distributed intelligence would lead to the exact opposite of this vision. The reason is that effective collective intelligence requires diversity of opinion, decentralization and individual independence, as demonstrated by James Surowiecki in his book The Wisdom of Crowds. Moreover, a more distributed form of decision-making would decrease the power of governments, corporations or political leaders, thus increasing democratic participation and reducing the dangers of totalitarian control.\n\n\n\n\nFor more references, check the GBI bibliography:\n\n"}
{"id": "1940832", "url": "https://en.wikipedia.org/wiki?curid=1940832", "title": "Global governance", "text": "Global governance\n\nGlobal governance or world governance is a movement towards political cooperation among transnational actors, aimed at negotiating responses to problems that affect more than one state or region. Institutions of global governance—the United Nations, the International Criminal Court, the World Bank, etc.—tend to have limited or demarcated power to enforce compliance. The modern question of world governance exists in the context of globalization and globalizing regimes of power: politically, economically and culturally. In response to the acceleration of worldwide interdependence, both between human societies and between humankind and the biosphere, the term \"global governance\" may name the process of designating laws, rules, or regulations intended for a global scale.\n\nGlobal governance is not a singular system. There is no \"world government\" but the many different regimes of global \"governance\" do have commonalities:\n\nThe term world governance is broadly used to designate all regulations intended for organization and centralization of human societies on a global scale. The Forum for a new World Governance defines world governance simply as \"collective management of the planet\".\n\nTraditionally, \"government\" has been associated with \"governing,\" or with political authority, institutions, and, ultimately, control. \"Governance\" denotes a process through which institutions coordinate and control independent social relations, and that have the ability to enforce, by force, their decisions. However, authors like James Rosenau have also used \"governance\" to denote the regulation of interdependent relations in the absence of an overarching political authority, such as in the international system. Some now speak of the development of \"global public policy\".\n\nAdil Najam, a scholar on the subject at the Pardee School of Global Studies, Boston University has defined global governance simply as \"the management of global processes in the absence of global government.\" According to Thomas G. Weiss, director of the Ralph Bunche Institute for International Studies at the Graduate Center (CUNY) and editor (2000–05) of the journal \"\", \"'Global governance'—which can be good, bad, or indifferent—refers to concrete cooperative problem-solving arrangements, many of which increasingly involve not only the United Nations of states but also 'other UNs,' namely international secretariats and other non-state actors.\" In other words, global governance refers to the way in which global affairs are managed.\n\nThe definition is flexible in scope, applying to general subjects such as global security and order or to specific documents and agreements such as the World Health Organization's Code on the Marketing of Breast Milk Substitutes. The definition applies whether the participation is bilateral (e.g. an agreement to regulate usage of a river flowing in two countries), function-specific (e.g. a commodity agreement), regional (e.g. the Treaty of Tlatelolco), or global (e.g. the Non-Proliferation Treaty). These \"cooperative problem-solving arrangements\" may be formal, taking the shape of laws or formally constituted institutions for a variety of actors (such as state authorities, intergovernmental organizations (IGOs), non-governmental organizations (NGOs), private sector entities, other civil society actors, and individuals) to manage collective affairs. They may also be informal (as in the case of practices or guidelines) or ad hoc entities (as in the case of coalitions).\n\nHowever, a single organization may take the nominal lead on an issue, for example the World Trade Organization (WTO) in world trade affairs. Therefore, global governance is thought to be an international process of consensus-forming which generates guidelines and agreements that affect national governments and international corporations. Examples of such consensus would include WHO policies on health issues.\n\nIn short, global governance may be defined as \"the complex of formal and informal institutions, mechanisms, relationships, and processes between and among states, markets, citizens and organizations, both inter- and non-governmental, through which collective interests on the global plane are articulated, Duties, obligations and privileges are established, and differences are mediated through educated professionals.\"\n\nTitus Alexander, author of \"Unravelling Global Apartheid, an Overview of World Politics\", has described the current institutions of global governance as a system of global apartheid, with numerous parallels with minority rule in the formal and informal structures of South Africa before 1991.\n\nThe dissolution of the Soviet Union in 1991 marked the end of a long period of international history based on a policy of balance of powers. Since this historic event, the planet has entered a phase of geostrategic breakdown. The national-security model, for example, while still in place for most governments, is gradually giving way to an emerging collective conscience that extends beyond the restricted framework it represents.\n\nThe post-Cold War world of the 1990s saw a new paradigm emerge based on a number of issues:\n\n\nGlobal governance can be roughly divided into four stages:\n\nWorld authorities including international organizations and corporations achieve deference to their agenda through different means. Authority can derive from institutional status, expertise, moral authority, capacity, or perceived competence.\n\nIn its initial phase, world governance was able to draw on themes inherited from geopolitics and the theory of international relations, such as peace, defense, geostrategy, diplomatic relations, and trade relations. But as globalization progresses and the number of interdependences increases, the global level is also highly relevant to a far wider range of subjects. Following are a number of examples.\n\n\"The crisis brought about by the accelerated pace and the probably irreversible character of the effect of human activities on nature requires collective answers from governments and citizens. Nature ignores political and social barriers, and the global dimension of the crisis cancels the effects of any action initiated unilaterally by state governments or sectoral institutions, however powerful they may be. Climate change, ocean and air pollution, nuclear risks and those related to genetic manipulation, the reduction and extinction of resources and biodiversity, and above all a development model that remains largely unquestioned globally are all among the various manifestations of this accelerated and probably irreversible effect.\n\nThis effect is the factor, in the framework of globalization, that most challenges a system of states competing with each other to the exclusion of all others: among the different fields of global governance, environmental management is the most wanting in urgent answers to the crisis in the form of collective actions by the whole of the human community. At the same time, these actions should help to model and strengthen the progressive building of this community.\"\n\nProposals in this area have discussed the issue of how collective environmental action is possible. Many multilateral, environment-related agreements have been forged in the past 30 years, but their implementation remains difficult. There is also some discussion on the possibility of setting up an international organization that would centralize all the issues related to international environmental protection, such as the proposed World Environment Organization (WEO). The United Nations Environment Program (UNEP) could play this role, but it is a small-scale organization with a limited mandate. The question has given rise to two opposite views: the European Union, especially France and Germany, along with a number of NGOs, is in favor of creating a WEO; the United Kingdom, the USA, and most developing countries prefer opting for voluntary initiatives.\n\nThe International Institute for Sustainable Development proposes a \"reform agenda\" for global environmental governance. The main argument is that there seems to exist an unspoken but powerful consensus on the essential objectives of a system of global environmental governance. These goals would require top-quality leadership, a strong environmental policy based on knowledge, effective cohesion and coordination, good management of the institutions constituting the environmental governance system, and spreading environmental concerns and actions to other areas of international policy and action.\n\nThe focus of environmental issues shifted to climate change from 1992 onwards. Due to the transboundary nature of climate change, various calls have been made for a World Environment Organisation (WEO) (sometimes referred to as a Global Environment Organisation) to tackle this global problem on a global scale. At present, a single worldwide governing body with the powers to develop and enforce environmental policy does not exist. The idea for the creation of a WEO was discussed thirty years ago but is receiving fresh attention in the light of arguably disappointing outcomes from recent, ‘environmental mega-conferences’(e.g.Rio Summit and Earth Summit 2002).\n\nInternational environmental organisations do exist. The United Nations Environmental Programme (UNEP), created in 1972, coordinates the environmental activity of countries in the UN. UNEP and similar international environmental organisations are seen as not up to the task. They are criticised as being institutionally weak, fragmented, lacking in standing and providing non-optimal environmental protection. It has been stated that the current decentralised, poorly funded and strictly intergovernmental regime for global environmental issues is sub-standard. However, the creation of a WEO may threaten to undermine some of the more effective aspects of contemporary global environmental governance; notably its fragmented nature, from which flexibility stems. This also allows responses to be more effective and links to be forged across different domains. Even though the environment and climate change are framed as global issues, Levin states that ‘it is precisely at this level that government institutions are least effective and trust most delicate’ while Oberthur and Gehring argue that it would offer little more than institutional restructuring for its own sake.\n\nMany proposals for the creation of a WEO have emerged from the trade and environment debate. It has been argued that instead of creating a WEO to safeguard the environment, environmental issues should be directly incorporated into the World Trade Organization (WTO). The WTO has “had success in integrating trade agreements and opening up markets because it is able to apply legal pressure to nation states and resolve disputes”. Greece and Germany are currently in discussion about the possibility of solar energy being used to repay some of Greece’s debt after their economy crashed in 2010. This exchange of resources, if it is accepted, is an example of increased international cooperation and an instance where the WTO could embrace energy trade agreements. If the future holds similar trade agreements, then an environmental branch of the WTO would surely be necessary. However critics of a WTO/WEO arrangement say that this would neither concentrate on more directly addressing underlying market failures, nor greatly improve rule-making.\n\nThe creation of a new agency, whether it be linked to the WTO or not, has now been endorsed by Renato Ruggiero, the former head of the World Trade Organization (WTO), as well as by the new WTO director-designate, Supachai Panitchpakdi. The debate over a global institutional framework for environmental issues will undoubtedly rumble on but at present there is little support for any one proposal.\n\nThe 2008 financial crisis may have undermined faith that laissez-faire capitalism will correct all serious financial malfunctioning on its own, as well as belief in the presumed independence of the economy from politics. It has been stated that, lacking in transparency and far from democratic, international financial institutions may be incapable of handling financial collapses. There are many who believe free-market capitalism may be incapable of forming the economic policy of a stable society, as it has been theorised that it can exacerbate inequalities.\n\nNonetheless, the debate on the potential failings of the system has led the academic world to seek solutions. According to Tubiana and Severino, \"refocusing the doctrine of international cooperation on the concept of public goods offers the possibility . . . of breaking the deadlock in international negotiations on development, with the perception of shared interests breathing new life into an international solidarity that is running out of steam.\"\n\nJoseph Stiglitz argues that a number of global public goods should be produced and supplied to the populations, but are not, and that a number of global externalities should be taken into consideration, but are not. On the other hand, he contends, the international stage is often used to find solutions to completely unrelated problems under the protection of opacity and secrecy, which would be impossible in a national democratic framework.\n\nOn the subject of international trade, Susan George states that \". . . in a rational world, it would be possible to construct a trading system serving the needs of people in both North and South. . . . Under such a system, crushing third world debt and the devastating structural adjustment policies applied by the World Bank and the IMF would have been unthinkable, although the system would not have abolished capitalism.\"\n\nBuilding a responsible world governance that would make it possible to adapt the political organization of society to globalization implies establishing a democratic political legitimacy at every level: local, national, regional and global.\n\nObtaining this legitimacy requires rethinking and reforming, all at the same time:\n\nThe political aspect of world governance is discussed in greater detail in the section Problems of World Governance and Principles of Governance\n\nArmed conflicts have changed in form and intensity since the Berlin wall came down in 1989. The events of 9/11, the wars in Afghanistan and in Iraq, and repeated terrorist attacks all show that conflicts can repercuss well beyond the belligerents directly involved. The major powers and especially the United States, have used war as a means of resolving conflicts and may well continue to do so. If many in the United States believe that fundamentalist Muslim networks are likely to continue to launch attacks, in Europe nationalist movements have proved to be the most persistent terrorist threat. The Global War on Terrorism arguably presents a form of emerging global governance in the sphere of security with the United States leading cooperation among the Western states, non-Western nations and international institutions. Beyer argues that participation in this form of 'hegemonic governance' is caused both by a shared identity and ideology with the US, as well as cost-benefit considerations. Pesawar school attack 2014 is a big challenge to us. Militants from the Pakistani Taliban have attacked an army-run school in Peshawar, killing 141 people, 132 of them children, the military say.\n\nAt the same time, civil wars continue to break out across the world, particularly in areas where civil and human rights are not respected, such as Central and Eastern Africa and the Middle East. These and other regions remain deeply entrenched in permanent crises, hampered by authoritarian regimes, many of them being supported by the United States, reducing entire swathes of the population to wretched living conditions. The wars and conflicts we are faced with have a variety of causes: economic inequality, social conflict, religious sectarianism, Western imperialism, colonial legacies, disputes over territory and over control of basic resources such as water or land. They are all illustrations a deep-rooted crisis of world governance.\n\nThe resulting bellicose climate imbues international relations with competitive nationalism and contributes, in rich and poor countries alike, to increasing military budgets, siphoning off huge sums of public money to the benefit of the arms industry and military-oriented scientific innovation, hence fueling global insecurity. Of these enormous sums, a fraction would be enough to provide a permanent solution for the basic needs of the planet's population hence practically eliminating the causes of war and terrorism.\n\nAndrée Michel argues that the arms race is not only proceeding with greater vigor, it is the surest means for Western countries to maintain their hegemony over countries of the South. Following the break-up of the Eastern bloc countries, she maintains, a strategy for the manipulation of the masses was set up with a permanent invention of an enemy (currently incarnated by Iraq, Iran, Libya, Syria, and North Korea) and by kindling fear and hate of others to justify perpetuating the Military–industrial complex and arms sales. The author also recalls that the \"Big Five\" at the UN who have the veto right are responsible for 85% of arms sales around the world.\n\nProposals for the governance of peace, security, and conflict resolution begin by addressing prevention of the causes of conflicts, whether economic, social, religious, political, or territorial. This requires assigning more resources to improving people's living conditions—health, accommodation, food, and work—and to education, including education in the values of peace, social justice, and unity and diversity as two sides of the same coin representing the global village.\n\nResources for peace could be obtained by regulating, or even reducing military budgets, which have done nothing but rise in the past recent years. This process could go hand in hand with plans for global disarmament and the conversion of arms industries, applied proportionally to all countries, including the major powers. Unfortunately, the warlike climate of the last decade has served to relegate all plans for global disarmament, even in civil-society debates, and to pigeonhole them as a long-term goal or even a Utopian vision. This is definitely a setback for the cause of peace and for humankind, but it is far from being a permanent obstacle.\n\nInternational institutions also have a role to play in resolving armed conflicts. Small international rapid deployment units could intervene in these with an exclusive mandate granted by a reformed and democratic United Nations system or by relevant regional authorities such as the European Union. These units could be formed specifically for each conflict, using armies from several countries as was the case when the UNIFIL was reinforced during the 2006 Lebanon War. On the other hand, no national army would be authorized to intervene unilaterally outside its territory without a UN or regional mandate.\n\nAnother issue that is worth addressing concerns the legitimate conditions for the use of force and conduct during war. Jean-Réné Bachelet offers an answer with the conceptualization of a military ethics corresponding to the need for a \"principle of humanity.\" The author defines this principle as follows: \"All human beings, whatever their race, nationality, gender, age, opinion, or religion, belong to one same humanity, and every individual has an inalienable right to respect for his life, integrity, and dignity.\"\n\nThe World Trade Organization's (WTO) agenda of liberalizing public goods and services are related to culture, science, education, health, living organisms, information, and communication. This plan has been only partially offset by the alter-globalization movement, starting with the events that took place at the 1999 Seattle meeting, and on a totally different and probably far more influential scale in the medium and long term, by the astounding explosion of collaborative practices on the Internet. However, lacking political and widespread citizen support as well as sufficient resources, civil society has not so far been able to develop and disseminate alternative plans for society as a whole on a global scale, even though plenty of proposals and initiatives have been developed, some more successful than others, to build a fairer, more responsible, and more solidarity-based world in all of these areas.\n\nAbove all, each country tries to impose their values and collective preferences within international institutions such like WTO or UNESCO, particularly in the Medias sector. This is an excellent opportunity to promote their soft power, for instance with the promotion of the cinema\n\nAs far as science is concerned, \"[r]esearch increasingly bows to the needs of financial markets, turning competence and knowledge into commodities, making employment flexible and informal, and establishing contracts based on goals and profits for the benefit of private interests in compliance with the competition principle. The directions that research has taken in the past two decades and the changes it has undergone have drastically removed it from its initial mission (producing competence and knowledge, maintaining independence) with no questioning of its current and future missions. Despite the progress, or perhaps even as its consequence, humankind continues to face critical problems: poverty and hunger are yet to be vanquished, nuclear arms are proliferating, environmental disasters are on the rise, social injustice is growing, and so on.\n\nNeoliberal commercialization of the commons favors the interests of pharmaceutical companies instead of the patients', of food-processing companies instead of the farmers' and consumers'. Public research policies have done nothing but support this process of economic profitability, where research results are increasingly judged by the financial markets. The system of systematically patenting knowledge and living organisms is thus being imposed throughout the planet through the 1994 WTO agreements on intellectual property. Research in many areas is now being directed by private companies.\"\n\nOn the global level, \"[i]nstitutions dominating a specific sector also, at every level, present the risk of reliance on technical bodies that use their own references and deliberate in an isolated environment. This process can be observed with the 'community of patents' that promotes the patenting of living organisms, as well as with authorities controlling nuclear energy. This inward-looking approach is all the more dangerous that communities of experts are, in all complex technical and legal spheres, increasingly dominated by the major economic organizations that finance research and development.\"\n\nOn the other hand, several innovative experiments have emerged in the sphere of science, such as: conscience clauses and citizens' panels as a tool for democratizing the production system: science shops and community-based research. Politically committed scientists are also increasingly organizing at the global level.\n\nAs far as education is concerned, the effect of commoditization can be seen in the serious tightening of education budgets, which affects the quality of general education as a public service. The Global Future Online report reminds us that \". . . at the half-way point towards 2015 \"(author's note: the deadline for the Millennium Goals)\", the gaps are daunting: 80 million children (44 million of them girls) are out of school, with marginalized groups (26 million disabled and 30 million conflict-affected children) continuing to be excluded. And while universal access is critical, it must be coupled with improved learning outcomes—in particular, children achieving the basic literacy, numeracy and life skills essential for poverty reduction.\"\n\nIn addition to making the current educational system available universally, there is also a call to improve the system and adapt it to the speed of changes in a complex and unpredictable world. On this point, Edgar Morin asserts that we must \"[r]ethink our way of organizing knowledge. This means breaking down the traditional barriers between disciplines and designing new ways to reconnect that which has been torn apart.\" The UNESCO report drawn up by Morin contains \"seven principles for education of the future\": detecting the error and illusion that have always parasitized the human spirit and human behavior; making knowledge relevant, i.e. a way of thinking that makes distinctions and connections; teaching the human condition; teaching terrestrial identity; facing human and scientific uncertainties and teaching strategies to deal with them; teaching understanding of the self and of others, and an ethics for humankind.\n\nThe exponential growth of new technologies, the Internet in particular, has gone hand in hand with the development over the last decade of a global community producing and exchanging goods. This development is permanently altering the shape of the entertainment, publishing, and music and media industries, among others. It is also influencing the social behavior of increasing numbers of people, along with the way in which institutions, businesses, and civil society are organized. Peer-to-peer communities and collective knowledge-building projects such as Wikipedia have involved millions of users around the world. There are even more innovative initiatives, such as alternatives to private copyright such as Creative Commons, cyber democracy practices, and a real possibility of developing them on the sectoral, regional, and global levels.\n\nRegional players, whether regional conglomerates such as Mercosur and the European Union, or major countries seen as key regional players such as China, the United States, and India, are taking a growing interest in world governance. Examples of discussion of this issue can be found in the works of: Martina Timmermann \"et al.\", \"Institutionalizing Northeast Asia: Regional Steps toward Global Governance\"; Douglas Lewis, \"Global Governance and the Quest for Justice - Volume I: International and Regional Organizations\"; Olav Schram Stokke, \"Examining the Consequences of International Regimes,\" which discusses Northern, or Arctic region building in the context of international relations; Jeffery Hart and Joan Edelman Spero, \"Globalization and Global Governance in the 21st Century,\" which discusses the push of countries such as Mexico, Brazil, India, China, Taiwan, and South Korea, \"important regional players\" seeking \"a seat at the table of global decision-making\"; Dr. Frank Altemöller, “International Trade: Challenges for Regional and Global Governance: A comparison between Regional Integration Models in Eastern Europe and Africa – and the role of the WTO”, and many others.\n\nInterdependence among countries and regions hardly being refutable today, regional integration is increasingly seen not only as a process in itself, but also in its relation to the rest of the world, sometimes turning questions like \"What can the world bring to my country or region?\" into \"What can my country or region bring to the rest of the world?\" Following are a few examples of how regional players are dealing with these questions.\n\nOften seen as a problem to be solved rather than a people or region with an opinion to express on international policy, Africans and Africa draw on a philosophical tradition of community and social solidarity that can serve as inspiration to the rest of the world and contribute to building world governance. One example is given by Sabelo J. Ndlovu-Gathseni when he reminds us of the relevance of the Ubuntu concept, which stresses the interdependence of human beings.\n\nAfrican civil society has thus begun to draw up proposals for governance of the continent, which factor in all of the dimensions: local, African, and global. Examples include proposals by the network \"Dialogues sur la gouvernance en Afrique\" for \"the construction of a local legitimate governance,\" state reform \"capable of meeting the continent's development challenges,\" and \"effective regional governance to put an end to Africa's marginalization.\"\n\nForeign-policy proposals announced by President Barack Obama include restoring the Global Poverty Act, which aims to contribute to meeting the UN Millennium Development Goals to reduce by half the world population living on less than a dollar a day by 2015. Foreign aid is expected to double to 50 billion dollars. The money will be used to help build educated and healthy communities, reduce poverty and improve the population's health.\n\nIn terms of international institutions, The White House Web site advocates reform of the World Bank and the IMF, without going into any detail.\n\nBelow are further points in the Obama-Biden plan for foreign policy directly related to world governance:\n\nThe 21st century has seen the arrival of a new and diverse generation of left-wing governments in Latin America. This has opened the door to initiatives to launch political and governance renewal. A number of these initiatives are significant for the way they redefine the role of the state by drawing on citizen participation, and can thus serve as a model for a future world governance built first and foremost on the voice of the people. The constituent assemblies in Ecuador and Bolivia are fundamental examples of this phenomenon.\n\nIn Ecuador, social and indigenous movements were behind the discussions that began in 1990 on setting up a constituent assembly. In the wake of Rafael Correa's arrival at the head of the country in November 2006, widespread popular action with the slogan \"que se vayan todos\" (let them all go away) succeeded in getting all the political parties of congress to accept a convocation for a referendum on setting up the assembly.\n\nIn April 2007, Rafael Correa's government organized a consultation with the people to approve setting up a constituent assembly. Once it was approved, 130 members of the assembly were elected in September, including 100 provincial members, 24 national members and 6 for migrants in Europe, Latin America and the USA. The assembly was officially established in November. Assembly members belonged to traditional political parties as well as the new social movements. In July 2008, the assembly completed the text for the new constitution and in September 2008 there was a referendum to approve it. Approval for the new text won out, with 63.9% of votes for compared to 28.1% of votes against and a 24.3% abstention rate.\n\nThe new constitution establishes the rule of law on economic, social, cultural and environmental rights (ESCER). It transforms the legal model of the social state subject to the rule of law into a \"constitution of guaranteed well-being\" (\"Constitución del bienestar garantizado\") inspired by the ancestral community ideology of \"good living\" propounded by the Quechuas of the past, as well as by 21st century socialist ideology. The constitution promotes the concept of food sovereignty by establishing a protectionist system that favors domestic production and trade. It also develops a model of public aid for education, health, infrastructures and other services.\n\nIn addition, it adds to the three traditional powers, a fourth power called the Council of Citizen Participation and Social Control, made up of former constitutional control bodies and social movements, and mandated to assess whether public policies are constitutional or not.\n\nThe new Bolivian constitution was approved on 25 January 2009 by referendum, with 61.4% votes in favor, 38.6% against and a 90.2% turnout. The proposed constitution was prepared by a constituent assembly that did not only reflect the interests of political parties and the elite, but also represented the indigenous peoples and social movements. As in Ecuador, the proclamation of a constituent assembly was demanded by the people, starting in 1990 at a gathering of indigenous peoples from the entire country, continuing with the indigenous marches in the early 2000s and then with the Program Unity Pact (\"Pacto de Unidad Programático\") established by family farmers and indigenous people in September 2004 in Santa Cruz.\n\nThe constitution recognizes the autonomy of indigenous peoples, the existence of a specific indigenous legal system, exclusive ownership of forest resources by each community and a quota of indigenous members of parliament. It grants autonomy to counties, which have the right to manage their natural resources and elect their representatives directly. The \"latifundio\" system has been outlawed, with maximum ownership of 5,000 hectares allowed per person. Access to water and sanitation are covered by the constitution as human rights that the state has to guarantee, as well as other basic services such as electricity, gas, postal services, and telecommunications that can be provided by either the state or contracting companies. The new constitution also establishes a social and community economic model made up of public, private, and social organizations, and cooperatives. It guarantees private initiative and freedom of enterprise, and assigns public organizations the task of managing natural resources and related processes as well as developing public services covered by the constitution. National and cooperative investment is favored over private and international investment.\nThe \"unitary plurinational\" state of Bolivia has 36 official indigenous languages along with Spanish. Natural resources belong to the people and are administered by the state. The form of democracy in place is no longer considered as exclusively representative and/or based on parties. Thus, \"the people deliberate and exercise government via their representatives and the constituent assembly, the citizen legislative initiative and the referendum . . .\" and \"popular representation is exercised via the political parties, citizen groups, and indigenous peoples.\" This way, \"political parties, and/or citizen groups and/or indigenous peoples can present candidates directly for the offices of president, vice-president, senator, house representative, constituent-assembly member, councilor, mayor, and municipal agent. The same conditions apply legally to all. . . .\"\n\nAlso in Latin America: \"Amazonia . . . is an enormous biodiversity reservoir and a major climate-regulation agent for the planet but is being ravaged and deteriorated at an accelerated pace; it is a territory almost entirely devoid of governance, but also a breeding place of grassroots organization initiatives.\". \"Amazonia can be the fertile field of a true school of 'good' governance if it is looked after as a common and valuable good, first by Brazilians (65% of Amazonia is within Brazilian borders) and the people of the South American countries surrounding it, but also by all the Earth's inhabitants.\"\nAccordingly, \"[f]rom a world-governance perspective, [Amazonia] is in a way an enormous laboratory. Among other things, Amazonia enables a detailed examination of the negative effects of productivism and of the different forms of environmental packaging it can hide behind, including 'sustainable development.' Galloping urbanization, Human Rights violations, the many different types of conflicts (14 different types of conflicts have been identified within the hundreds of cases observed in Amazonia), protection of indigenous populations and their active participation in local governance: these are among the many Amazonian challenges also affecting the planet as a whole, not to mention the environment. The hosts of local initiatives, including among the indigenous populations, are however what may be most interesting in Amazonia in that they testify to the real, concrete possibility of a different form of organization that combines a healthy local economy, good social cohesion, and a true model of sustainable development—this time not disguised as something else. All of this makes Amazonia 'a territory of solutions.'\"\n\nAccording to Arnaud Blin, the Amazonian problem helps to define certain fundamental questions on the future of humankind. First, there is the question of social justice: \"[H]ow do we build a new model of civilization that promotes social justice? How do we set up a new social architecture that allows us to live together?\" The author goes on to refer to concepts such as the concept of \"people's territory \" or even \"life territory\" rooted in the indigenous tradition and serving to challenge private property and social injustice. He then suggests that the emerging concept of the \"responsibility to protect,\" following up on the \"right of humanitarian intervention\" and until now used to try to protect populations endangered by civil wars, could also be applied to populations threatened by economic predation and to environmental protection.\n\nThe growing interest in world governance in Asia represents an alternative approach to official messages, dominated by states' nationalist visions. An initiative to develop proposals for world governance took place in Shanghai in 2006, attended by young people from every continent. The initiative produced ideas and projects that can be classified as two types: the first and more traditional type, covering the creation of a number of new institutions such as an International Emissions Organization, and a second more innovative type based on organizing network-based systems. For example, a system of cooperative control on a worldwide level among states and self-organization of civil society into networks using new technologies, a process that should serve to set up a \"Global Calling-for-Help Center\" or a new model based on citizens who communicate freely, share information, hold discussions, and seek consensus-based solutions. They would use the Internet and the media, working within several types of organizations: universities, NGOs, local volunteers and civil-society groups.\n\nGiven the demographic importance of the continent, the development of discussion on governance and practices in Asia at the regional level, as well as global-level proposals, will be decisive in the years ahead in the strengthening of global dialog among all sorts of stakeholders, a dialog that should produce a fairer world order.(See Kishore Mahbubani).\n\nAccording to Michel Rocard, Europe does not have a shared vision, but a collective history that allows Europeans to opt for projects for gradual political construction such as the European Union. Drawing on this observation, Rocard conceives of a European perspective that supports the development of three strategies for constructing world governance: reforming the UN, drawing up international treaties to serve as the main source of global regulations, and \"the progressive penetration of the international scene by justice.\"\n\nRocard considers that there are a number of \"great questions of the present days\" including recognition by all nations of the International Criminal Court, the option of an international police force authorized to arrest international criminals, and the institution of judicial procedures to deal with tax havens, massively polluting activities, and states supporting terrorist activities. He also outlines \"new problems\" that should foster debate in the years to come on questions such as a project for a Declaration of Interdependence, how to re-equilibrate world trade and WTO activities, and how to create world regulations for managing collective goods (air, drinking water, oil, etc.) and services (education, health, etc.).\n\nMartin Ortega similarly suggests that the European Union should make a more substantial contribution to global governance, particularly through concerted action in international bodies. European states, for instance, should reach an agreement on the reform of the United Nations Security Council.\n\nIn 2011, the European Strategy and Policy Analysis System (ESPAS), an inter-institutional pilot project of the European Union which aims to assist EU policy formulation through the identification and critical analysis of long-term global trends, highlighted the importance of expanding global governance over the next 20 years.\n\nIt is too soon to give a general account of the view of world-governance stakeholders, although interest in world governance is on the rise on the regional level, and we will certainly see different types of stakeholders and social sectors working to varying degrees at the international level and taking a stand on the issue in the years to come.\n\nThe World Parliamentary Forum, open to members of parliament from all nations and held every year at the same time as the World Social Forum, drew up a declaration at the sixth forum in Caracas in 2006. The declaration contains a series of proposals that express participants' opinion on the changes referred to.\n\nThe European Commission referred to global governance in its White Paper on European Governance. It contends that the search for better global governance draws on the same set of shared challenges humanity is currently facing. These challenges can be summed up by a series of goals: sustainable development, security, peace and equity (in the sense of \"fairness\").\n\nThe freedom of thought enjoyed by non-state stakeholders enables them to formulate truly alternative ideas on world-governance issues, but they have taken little or no advantage of this opportunity.\n\nPierre Calame believes that \"[n]on-state actors have always played an essential role in global regulation, but their role will grow considerably in this, the beginning of the twenty-first Century . . . Non-state actors play a key role in world governance in different domains . . . To better understand and develop the non-state actors' role, it should be studied in conjunction with the general principles of governance.\" \"Non-state actors, due to their vocation, size, flexibility, methods of organization and action, interact with states in an equal manner; however this does not mean that their action is better adapted.\"\n\nOne alternative idea encapsulated by many not-for-profit organisations relates to ideas in the 'Human Potential Movement' and might be summarised as a mission statement along these lines: 'To create an accepted framework for all humankind, that is self-regulating and which enables every person to achieve their fullest potential in harmony with the world and its place in existence.'\n\nSince the Rio Earth Summit in 1992, references to the universal collective of humanity have begun using the term 'humankind' rather than 'mankind', given the gender neutral quality of the former.\n\n'Self-regulation' is meant to invoke the concept of regulation which includes rule-making such as laws, and related ideas e.g. legal doctrine as well as other frameworks. However its scope is wider than this and intended to encompass cybernetics which allows for the study of regulation in as many varied contexts as possible from the regulation of gene expression to the Press Complaints Commission for example.\n\nSince 2005, religious leaders from a diverse array of faith traditions have engaged in dialogue with G8 leaders around issues of global governance and world risk. Drawing on the cultural capital of diverse religious traditions, they seek to strengthen democratic norms by influencing political leaders to include the interests of the most vulnerable when they make their decisions. Some have argued that religion is a key to transforming or fixing global governance.\n\nSeveral stakeholders have produced lists of proposals for a new world governance that is fairer, more responsible, solidarity-based, interconnected and respectful of the planet's diversity. Some examples are given below.\n\nJoseph E. Stiglitz proposes a list of reforms related to the internal organization of international institutions and their external role in the framework of global-governance architecture. He also deals with global taxation, the management of global resources and the environment, the production and protection of global knowledge, and the need for a global legal infrastructure.\n\nA number of other proposals are contained in the World Governance Proposal Paper: giving concrete expression to the principle of responsibility; granting civil society greater involvement in drawing up and implementing international regulations; granting national parliaments greater involvement in drawing up and implementing international regulations; re-equilibrating trade mechanisms and adopting regulations to benefit the southern hemisphere; speeding up the institution of regional bodies; extending and specifying the concept of the commons; redefining proposal and decision-making powers in order to reform the United Nations; developing independent observation, early-warning, and assessment systems; diversifying and stabilizing the basis for financing international collective action; and engaging in a wide-reaching process of consultation, a new Bretton Woods for the United Nations.\n\nThis list provides more examples of proposals:\n\nDr. Rajesh Tandon, president of the FIM (Montreal International Forum) and of PRIA (Participatory Research in Asia), prepared a framework document entitled \"Democratization of Global Governance for Global Democracy: Civil Society Visions and Strategies (G05) conference.\" He used the document to present five principles that could provide a basis for civil society actions: \"Global institutions and agenda should be subjected to democratic political accountability.\"\n\nVijaya Ramachandran, Enrique Rueda-Sabater and Robin Kraft also define principles for representation of nations and populations in the system of global governance. They propose a \"Two Percent Club\" that would provide for direct representation of nations with at least two percent of global population or global GDP; other nations would be represented within international fora through regional blocs.\n\nIn the light of the unclear meaning of the term \"global governance\" as a concept in international politics, some authors have proposed defining it not in substantive, but in disciplinary and methodological terms. For these authors, global governance is better understood as an analytical concept or optic that provides a specific perspective on world politics different from that of conventional international relations theory. Thomas G. Weiss and Rorden Wilkinson have even argued that global governance has the capacity to overcome some of the fragmentation of international relations as a discipline particularly when understood as a set of questions about the governance of world orders.\n\nSome universities, including those offering courses in international relations, have begun to establish degree programmes in global governance.\n\nThere are those who believe that world architecture depends on establishing a system of world governance. However, the equation is currently becoming far more complicated: Whereas the process used to be about regulating and limiting the individual power of states to avoid disturbing or overturning the status quo, the issue for today's world governance is to have a collective influence on the world's destiny by establishing a system for regulating the many interactions that lie beyond the province of state action. The political homogenization of the planet that has followed the advent of what is known as liberal democracy in its many forms should make it easier to establish a world governance system that goes beyond market laissez-faire and the democratic peace originally formulated by Immanuel Kant, which constitutes a sort of geopolitical laissez-faire.\n\nAnother view regarding the establishment of global governance is based on the difficulties to achieve equitable development at the world scale. \"To secure for all human beings in all parts of the world the conditions allowing a decent and meaningful life requires enormous human energies and far-reaching changes in policies. The task is all the more demanding as the world faces numerous other problems, each related to or even part of the development challenge, each similarly pressing, and each calling for the same urgent attention. But, as Arnold Toynbee has said, 'Our age is the first generation since the dawn of history in which mankind dares to believe it practical to make the benefits of civilization available to the whole human race'.\"\n\nBecause of the heterogeneity of preferences, which are enduring despite globalization, are often perceived as an implacable homogenization process. Americans and Europeans provide a good example of this point: on some issues they have differing common grounds in which the division between the public and private spheres still exist. Tolerance for inequalities and the growing demand for redistribution, attitudes toward risk, and over property rights vs human rights, set the stage. In certain cases, globalization even serves to accentuate differences rather than as a force for homogenization. Responsibility must play its part with respect to regional and International governments, when balancing the needs of its citizenry.\n\nWith the growing emergence of a global civic awareness, comes opposition to globalization and its effects. A rapidly growing number of movements and organizations have taken the debate to the international level. Although it may have limitations, this trend is one response to the increasing importance of world issues, that effect the planet.\n\nPierre Jacquet, Jean Pisani-Ferry, and Laurence Tubiana argue that \"[t]o ensure that decisions taken for international integration are sustainable, it is important that populations see the benefits, that states agree on their goals and that the institutions governing the process are seen as legitimate. These three conditions are only partially being met. Taklya\"\n\nThe authors refer to a \"crisis of purpose\" and international institutions suffering from \"imbalance\" and inadequacy. They believe that for these institutions, \"a gap has been created between the nature of the problems that need tackling and an institutional architecture which does not reflect the hierarchy of today's problems. For example, the environment has become a subject of major concern and central negotiation, but it does not have the institutional support that is compatible with its importance.\"\n\nGlobal governance is not world government, and even less democratic globalization. In fact, global governance would not be necessary, were there a world government. Domestic governments have monopolies on the use of force—the power of enforcement. Global governance refers to the political interaction that is required to solve problems that affect more than one state or region when there is no power to enforce compliance. Problems arise, and networks of actors are constructed to deal with them in the absence of an international analogue to a domestic government. This system has been termed disaggregated sovereignty.\n\nImproved global problem solving need not involve the establishment of additional powerful formal global institutions. It does involve building consensus on norms and practices. One such area, currently under construction, is the development and improvement of accountability mechanisms. For example, the UN Global Compact brings together companies, UN agencies, labor organizations, and civil society to support universal environmental and social principles. Participation is entirely voluntary, and there is no enforcement of the principles by an outside regulatory body. Companies adhere to these practices both because they make economic sense, and because stakeholders, especially shareholders, can monitor their compliance easily. Mechanisms such as the Global Compact can improve the ability of affected individuals and populations to hold companies accountable. However, corporations participating in the UN Global Compact have been criticized for their merely minimal standards, the absence of sanction-and-control measures, their lack of commitment to social and ecological standards, minimal acceptance among corporations around the world, and the high cost involved in reporting annually to small and medium-sized business\n\nBitcoin & Beyond: Blockchains, Globalization, and Global Governance workshop brings together an interdisciplinary group of researchers to examine the implications that blockchains pose for globalization and global governance.\n\nOne effect of globalization is the increasing regulation of businesses in the global marketplace. Jan Aart Scholte asserts, however, that these changes are inadequate to meet the needs: \"Along with the general intensified globalization of social relations in contemporary history has come an unprecedented expansion of regulatory apparatuses that cover planetary jurisdictions and constituencies. On the whole, however, this global governance remains weak relative to pressing current needs for global public policy. Shortfalls in moral standing, legal foundations, material delivery, democratic credentials and charismatic leadership have together generated large legitimacy deficits in existing global regimes.\"\n\nProposals and initiatives have been developed by various sources to set up networks and institutions operating on a global scale: political parties, unions, regional authorities, and members of parliament in sovereign states.\n\nOne of the conditions for building a world democratic governance should be the development of platforms for citizen dialogue on the legal formulation of world governance and the harmonization of objectives.\n\nThis legal formulation could take the form of a Global Constitution. According to Pierre Calame and Gustavo Marin, \"[a] Global Constitution resulting from a process for the institution of a global community will act as the common reference for establishing the order of rights and duties applicable to United Nations agencies and to the other multilateral institutions, such as the International Monetary Fund, the World Bank, and the World Trade Organization.\" As for formulating objectives, the necessary but insufficient ambition of the United Nations Millennium Development Goals, which aim to safeguard humankind and the planet, and the huge difficulties in implementing them, illustrates the inadequacy of institutional initiatives that do not have popular support for having failed to invite citizens to take part in the elaboration process.\n\nFurthermore, the Global Constitution \"must clearly express a limited number of overall objectives that are to be the basis of global governance and are to guide the common action of the U.N. agencies and the multilateral institutions, where the specific role of each of these is subordinated to the pursuit of these common objectives.\"\n\nCalame proposes the following objectives:\n\nIs the UN capable of taking on the heavy responsibility of managing the planet's serious problems? More specifically, can the UN reform itself in such a way as to be able to meet this challenge? At a time when the financial crisis of 2008 is raising the same questions posed by the climate disasters of previous years regarding the unpredictable consequences of disastrous human management, can international financial institutions be reformed in such a way as to go back to their original task, which was to provide financial help to countries in need?\n\nLack of political will and citizen involvement at the international level has also brought about the submission of international institutions to the \"neoliberal\" agenda, particularly financial institutions such as the World Bank, the International Monetary Fund, and the World Trade Organization (WTO). Pierre Calame gives an account of this development, while Joseph E. Stiglitz points out that the need for international institutions like the IMF, the World Bank, and the WTO has never been so great, but people's trust in them has never been so low.\n\nOne of the key aspects of the United Nations reform is the problem of the representativeness of the General Assembly. The Assembly operates on the principle of \"one state, one vote,\" so that states of hugely varying sizes have the same effect on the vote, which distorts representativeness and results in a major loss of credibility. Accordingly, \"the General Assembly has lost any real capacity to influence. This means that the mechanisms for action and consultation organized by rich countries have the leading role.\"\n\nGustave Massiah advocates defining and implementing a radical reform of the UN. The author proposes building new foundations that can provide the basis for global democracy and the creation of a Global Social Contract, rooted in the respect and protection of civil, political, economic, social, and cultural rights, as well as in the recognition of the strategic role of international law.\n\nThere is the jurisdictional gap, between the increasing need for global governance in many areas - such as health - and the lack of an authority with the power, or jurisdiction, to take action.\nMoreover, the gap of incentive between the need for international cooperation and the motivation to undertake it. The incentive gap is said to be closing as globalization provides increasing impetus for countries to cooperate. However, there are concerns that, as Africa lags further behind economically, its influence on global governance processes will diminish. At last, the participation gap, which refers to the fact that international cooperation remains primarily the affair of governments, leaving civil society groups on the fringes of policy-making. On the other hand, globalization of communication is facilitating the development of global civil society movements.\n\nInadequate global institutions, agreements or networks as well as political and national interests may impede global governance and lead to failures. Such are the consequence of ineffective global governance processes. Qin calls it a necessity to \"reconstruct ideas for effective global governance and sustainable world order, which should include the principles of pluralism, partnership, and participation\" for a change to this phenomenon. The 2012 Global Risks Report places global governance failure at the center of gravity in its geopolitical category.\n\nStudies of global governance are conducted at several academic institutions such as the LSE Department of International Relations (with a previous institution LSE Global Governance closed as a formal research centre of the LSE on 31 July 2011), the Leuven Centre for Global Governance Studies, the Global Governance Programme at the European University Institute, and the Center for Global Governance at Columbia Law School.\n\nJournals dedicated to the studies of global governance include the Chinese Journal of Global Governance, the Global Policy Journal at Durham University, , and Kosmos Journal for Global Transformation.\n\n\n\n"}
{"id": "46313", "url": "https://en.wikipedia.org/wiki?curid=46313", "title": "Globalization", "text": "Globalization\n\nGlobalization or globalisation is the process of interaction and integration between people, companies, and governments worldwide. Globalization has grown due to advances in transportation and communication technology. With increased global interactions comes the growth of international trade, ideas, and culture. Globalization is primarily an economic process of interaction and integration that's associated with social and cultural aspects. However, conflicts and diplomacy are also large parts of the history of globalization, and modern globalization.\n\nEconomically, globalization involves goods and services, and the economic resources of capital, technology, and data. The steam locomotive, steamship, jet engine, and container ships are some of the advances in the means of transport while the rise of the telegraph and its modern offspring, the Internet and mobile phones show development in telecommunications infrastructure. All of these improvements have been major factors in globalization and have generated further interdependence of economic and cultural activities around the globe.\n\nThough many scholars place the origins of globalization in modern times, others trace its history long before the European Age of Discovery and voyages to the New World, some even to the third millennium BC. Large-scale globalization began in the 1820s. In the late 19th century and early 20th century, the connectivity of the world's economies and cultures grew very quickly. The term \"globalization\" is recent, only establishing its current meaning in the 1970s.\n\nIn 2000, the International Monetary Fund (IMF) identified four basic aspects of globalization: trade and transactions, capital and investment movements, migration and movement of people, and the dissemination of knowledge. Further, environmental challenges such as global warming, cross-boundary water, air pollution, and over-fishing of the ocean are linked with globalization. Globalizing processes affect and are affected by business and work organization, economics, socio-cultural resources, and the natural environment. Academic literature commonly subdivides globalization into three major areas: economic globalization, cultural globalization, and political globalization.\nThe term \"globalization\" derives from the word \"globalize\", which refers to the emergence of an international network of economic systems. One of the earliest known usages of the term as a noun was in a 1930 publication entitled \"Towards New Education\", where it denoted a holistic view of human experience in education. The term 'globalization' had been used in its economic sense at least as early as 1981, and in other senses since at least as early as 1944. Theodore Levitt is credited with popularizing the term and bringing it into the mainstream business audience in the later half of the 1980s. Since its inception, the concept of globalization has inspired competing definitions and interpretations. Its antecedents date back to the great movements of trade and empire across Asia and the Indian Ocean from the 15th century onward.\nDue to the complexity of the concept, various research projects, articles, and discussions often stay focused on a single aspect of globalization.\n\nSociologists Martin Albrow and Elizabeth King define globalization as \"all those processes by which the people of the world are incorporated into a single world society.\" In \"The Consequences of Modernity\", Anthony Giddens writes: \"Globalization can thus be defined as the intensification of worldwide social relations which link distant localities in such a way that local happenings are shaped by events occurring many miles away and vice versa.\" In 1992, Roland Robertson, professor of sociology at the University of Aberdeen and an early writer in the field, described globalization as \"the compression of the world and the intensification of the consciousness of the world as a whole.\"\n\nIn \"Global Transformations\", David Held and his co-writers state:\nHeld and his co-writers' definition of globalization in that same book as \"transformation in the spatial organization of social relations and transactions—assessed in terms of their extensity, intensity, velocity and impact—generating transcontinental or inter-regional flows\" was called \"probably the most widely-cited definition\" in the 2014 DHL Global Connectiveness Index.\n\nSwedish journalist Thomas Larsson, in his book \"The Race to the Top: The Real Story of Globalization\", states that globalization:\nPaul James defines globalization with a more direct and historically contextualized emphasis:\n\nGlobalization is the extension of social relations across world-space, defining that world-space in terms of the historically variable ways that it has been practiced and socially understood through changing world-time.\n\nManfred Steger, professor of global studies and research leader in the Global Cities Institute at RMIT University, identifies four main empirical dimensions of globalization: economic, political, cultural, and ecological. A fifth dimension—the ideological—cutting across the other four. The ideological dimension, according to Steger, is filled with a range of norms, claims, beliefs, and narratives about the phenomenon itself.\n\nJames and Steger stated that the concept of globalization \"emerged from the intersection of four interrelated sets of 'communities of practice' (Wenger, 1998): academics, journalists, publishers/editors, and librarians.\" They note the term was used \"in education to describe the global life of the mind\"; in international relations to describe the extension of the European Common Market; and in journalism to describe how the \"American Negro and his problem are taking on a global significance\". They have also argued that four different forms of globalization can be distinguished that complement and cut across the solely empirical dimensions. According to James, the oldest dominant form of globalization is embodied globalization, the movement of people. A second form is agency-extended globalization, the circulation of agents of different institutions, organizations, and polities, including imperial agents. Object-extended globalization, a third form, is the movement of commodities and other objects of exchange. He calls the transmission of ideas, images, knowledge, and information across world-space disembodied globalization, maintaining that it is currently the dominant form of globalization. James holds that this series of distinctions allows for an understanding of how, today, the most embodied forms of globalization such as the movement of refugees and migrants are increasingly restricted, while the most disembodied forms such as the circulation of financial instruments and codes are the most deregulated.\n\nThe journalist Thomas L. Friedman popularized the term \"flat world\", arguing that globalized trade, outsourcing, supply-chaining, and political forces had permanently changed the world, for better and worse. He asserted that the pace of globalization was quickening and that its impact on business organization and practice would continue to grow.\n\nEconomist Takis Fotopoulos defined \"economic globalization\" as the opening and deregulation of commodity, capital, and labor markets that led toward present neoliberal globalization. He used \"political globalization\" to refer to the emergence of a transnational élite and a phasing out of the nation-state. Meanwhile, he used \"cultural globalization\" to reference the worldwide homogenization of culture. Other of his usages included \"ideological globalization\", \"technological globalization\", and \"social globalization\".\n\nLechner and Boli (2012) define globalization as more people across large distances becoming connected in more and different ways.\n\n\"Globophobia\" is used to refer to the fear of globalization, though it can also mean the fear of balloons.\n\nThere are both distal and proximate causes which can be traced in the historical factors affecting globalization. Large-scale globalization began in the 19th century.\n\nArchaic globalization conventionally refers to a phase in the history of globalization including globalizing events and developments from the time of the earliest civilizations until roughly the 1600s. This term is used to describe the relationships between communities and states and how they were created by the geographical spread of ideas and social norms at both local and regional levels.\n\nIn this schema, three main prerequisites are posited for globalization to occur. The first is the idea of Eastern Origins, which shows how Western states have adapted and implemented learned principles from the East. Without the spread of traditional ideas from the East, Western globalization would not have emerged the way it did. The second is distance. The interactions of states were not on a global scale and most often were confined to Asia, North Africa, the Middle East, and certain parts of Europe. With early globalization, it was difficult for states to interact with others that were not within a close proximity. Eventually, technological advances allowed states to learn of others' existence and thus another phase of globalization can occur. The third has to do with inter-dependency, stability, and regularity. If a state is not dependent on another, then there is no way for either state to be mutually affected by the other. This is one of the driving forces behind global connections and trade; without either, globalization would not have emerged the way it did and states would still be dependent on their own production and resources to work. This is one of the arguments surrounding the idea of early globalization. It is argued that archaic globalization did not function in a similar manner to modern globalization because states were not as interdependent on others as they are today.\n\nAlso posited is a \"multi-polar\" nature to archaic globalization, which involved the active participation of non-Europeans. Because it predated the Great Divergence of the nineteenth century, where Western Europe pulled ahead of the rest of the world in terms of industrial production and economic output, archaic globalization was a phenomenon that was driven not only by Europe but also by other economically developed Old World centers such as Gujarat, Bengal, coastal China, and Japan.\nThe German historical economist and sociologist Andre Gunder Frank argues that a form of globalization began with the rise of trade links between Sumer and the Indus Valley Civilization in the third millennium B.C.E. This archaic globalization existed during the Hellenistic Age, when commercialized urban centers enveloped the axis of Greek culture that reached from India to Spain, including Alexandria and the other Alexandrine cities. Early on, the geographic position of Greece and the necessity of importing wheat forced the Greeks to engage in maritime trade. Trade in ancient Greece was largely unrestricted: the state controlled only the supply of grain.\n\nTrade on the Silk Road was a significant factor in the development of civilizations from China, Indian subcontinent, Persia, Europe, and Arabia, opening long-distance political and economic interactions between them. Though silk was certainly the major trade item from China, common goods such as salt and sugar were traded as well; and religions, syncretic philosophies, and various technologies, as well as diseases, also traveled along the Silk Routes. In addition to economic trade, the Silk Road served as a means of carrying out cultural trade among the civilizations along its network. The movement of people, such as refugees, artists, craftsmen, missionaries, robbers, and envoys, resulted in the exchange of religions, art, languages, and new technologies.\n\n\"Early modern-\" or \"proto-globalization\" covers a period of the history of globalization roughly spanning the years between 1600 and 1800. The concept of \"proto-globalization\" was first introduced by historians A. G. Hopkins and Christopher Bayly. The term describes the phase of increasing trade links and cultural exchange that characterized the period immediately preceding the advent of high \"modern globalization\" in the late 19th century. This phase of globalization was characterized by the rise of maritime European empires, in the 16th and 17th centuries, first the Portuguese and Spanish Empires, and later the Dutch and British Empires. In the 17th century, world trade developed further when chartered companies like the British East India Company (founded in 1600) and the Dutch East India Company (founded in 1602, often described as the first multinational corporation in which stock was offered) were established.\n\nEarly modern globalization is distinguished from modern globalization on the basis of expansionism, the method of managing global trade, and the level of information exchange. The period is marked by such trade arrangements as the East India Company, the shift of hegemony to Western Europe, the rise of larger-scale conflicts between powerful nations such as the Thirty Years' War, and the rise of newfound commodities—most particularly slave trade. The Triangular Trade made it possible for Europe to take advantage of resources within the Western Hemisphere. The transfer of animal stocks, plant crops, and epidemic diseases associated with Alfred W. Crosby's concept of the Columbian Exchange also played a central role in this process. European, Muslim, Indian, Southeast Asian, and Chinese merchants were all involved in early modern trade and communications, particularly in the Indian Ocean region.\n\nAccording to economic historians Kevin H. O'Rourke, Leandro Prados de la Escosura, and Guillaume Daudin, several factors promoted globalization in the period 1815-1870: \nDuring the 19th century, globalization approached its form as a direct result of the Industrial Revolution. Industrialization allowed standardized production of household items using economies of scale while rapid population growth created sustained demand for commodities. In the 19th century, steamships reduced the cost of international transport significantly and railroads made inland transportation cheaper. The transport revolution occurred some time between 1820 and 1850. More nations embraced international trade. Globalization in this period was decisively shaped by nineteenth-century imperialism such as in Africa and Asia. The invention of shipping containers in 1956 helped advance the globalization of commerce.\n\nAfter World War II, work by politicians led to the agreements of the Bretton Woods Conference, in which major governments laid down the framework for international monetary policy, commerce, and finance, and the founding of several international institutions intended to facilitate economic growth by lowering trade barriers. Initially, the General Agreement on Tariffs and Trade (GATT) led to a series of agreements to remove trade restrictions. GATT's successor was the World Trade Organization (WTO), which provided a framework for negotiating and formalizing trade agreements and a dispute resolution process. Exports nearly doubled from 8.5% of total gross world product in 1970 to 16.2% in 2001. The approach of using global agreements to advance trade stumbled with the failure of the Doha Development Round of trade negotiation. Many countries then shifted to bilateral or smaller multilateral agreements, such as the 2011 South Korea–United States Free Trade Agreement.\n\nSince the 1970s, aviation has become increasingly affordable to middle classes in developed countries. Open skies policies and low-cost carriers have helped to bring competition to the market. In the 1990s, the growth of low-cost communication networks cut the cost of communicating between different countries. More work can be performed using a computer without regard to location. This included accounting, software development, and engineering design.\n\nStudent exchange programs became popular after World War II, and are intended to increase the participants' understanding and tolerance of other cultures, as well as improving their language skills and broadening their social horizons. Between 1963 and 2006 the number of students studying in a foreign country increased 9 times.\n\nIn the late 19th and early 20th century, the connectedness of the world's economies and cultures grew very quickly. This slowed down from the 1910s onward due to the World Wars and the Cold War, but picked up again in the 1980s and 1990s. The revolutions of 1989 and subsequent liberalization in many parts of the world resulted in a significant expansion of global interconnectedness. The migration and movement of people can also be highlighted as a prominent feature of the globalization process. In the period between 1965 and 1990, the proportion of the labor force migrating approximately doubled. Most migration occurred between the developing countries and least developed countries (LDCs). As economic integration intensified workers moved to areas with higher wages and most of the developing world oriented toward the international market economy. The collapse of the Soviet Union not only ended the Cold War's division of the world- it also left the United States its sole policeman and an unfettered advocate of free market. It also resulted in the growing prominence of attention focused on the movement of diseases, the proliferation of popular culture and consumer values, the growing prominence of international institutions like the UN, and concerted international action on such issues as the environment and human rights. Other developments as dramatic were the Internet has become influential in connecting people across the world. , more than 2.4 billion people—over a third of the world's human population—have used the services of the Internet. Growth of globalization has never been smooth. One influential event was the late 2000s recession, which was associated with lower growth (in areas such as cross-border phone calls and Skype usage) or even temporarily negative growth (in areas such as trade) of global interconnectedness. The DHL Global Connectedness Index studies four main types of cross-border flow: trade (in both goods and services), information, people (including tourists, students, and migrants), and capital. It shows that the depth of global integration fell by about one-tenth after 2008, but by 2013 had recovered well above its pre-crash peak. The report also found a shift of economic activity to emerging economies.\n\nGlobalized society offers a complex web of forces and factors that bring people, cultures, markets, beliefs, and practices into increasingly greater proximity to one another.\n\nEconomic globalization is the increasing economic interdependence of national economies across the world through a rapid increase in cross-border movement of goods, services, technology, and capital. Whereas the globalization of business is centered around the diminution of international trade regulations as well as tariffs, taxes, and other impediments that suppresses global trade, economic globalization is the process of increasing economic integration between countries, leading to the emergence of a global marketplace or a single world market. Depending on the paradigm, economic globalization can be viewed as either a positive or a negative phenomenon. Economic globalization comprises: Globalization of production; which refers to the obtention of goods and services from a particular source from different locations around the globe to benefit from difference in cost and quality. Likewise, it also comprises globalization of markets; which is defined as the union of different and separate markets into a massive global marketplace. Economic globalization also includes competition, technology, and corporations and industries.\n\nCurrent globalization trends can be largely accounted for by developed economies integrating with less developed economies by means of foreign direct investment, the reduction of trade barriers as well as other economic reforms, and, in many cases, immigration.\n\nInternational standards have made trade in goods and services more efficient. An example of such standard is the intermodal container. Containerization dramatically reduced transport of its costs, supported the post-war boom in international trade, and was a major element in globalization. International Organization for Standardization is an international standard-setting body composed of representatives from various national standards organizations.\n\nA multinational corporation or worldwide enterprise is an organization that owns or controls production of goods or services in one or more countries other than their home country. It can also be referred as an international corporation, a transnational corporation, or a stateless corporation.\n\nA free-trade area is the region encompassing a trade bloc whose member countries have signed a free-trade agreement (FTA). Such agreements involve cooperation between at least two countries to reduce trade barriers import quotas and tariffs and to increase trade of goods and services with each other.\nIf people are also free to move between the countries, in addition to a free-trade agreement, it would also be considered an open border.\nArguably the most significant free-trade area in the world is the European Union, a politico-economic union of member states that are primarily located in Europe. The EU has developed European Single Market through a standardised system of laws that apply in all member states. EU policies aim to ensure the free movement of people, goods, services, and capital within the internal market,\n\nTrade facilitation looks at how procedures and controls governing the movement of goods across national borders can be improved to reduce associated cost burdens and maximise efficiency while safeguarding legitimate regulatory objectives.\n\nGlobal trade in services is also significant. For example, in India, business process outsourcing has been described as the \"primary engine of the country's development over the next few decades, contributing broadly to GDP growth, employment growth, and poverty alleviation\".\n\nWilliam I. Robinson's theoretical approach to globalization is a critique of Wallerstein's World Systems Theory. He believes that the global capital experienced today is due to a new and distinct form of globalization which began in the 1980s. Robinson argues not only are economic activities expanded across national boundaries but also there is a transnational fragmentation of these activities. One important aspect of Robinson's globalization theory is that production of goods are increasingly global. This means that one pair of shoes can be produced by six different countries, each contributing to a part of the production process.\n\nCultural globalization refers to the transmission of ideas, meanings, and values around the world in such a way as to extend and intensify social relations. This process is marked by the common consumption of cultures that have been diffused by the Internet, popular culture media, and international travel. This has added to processes of commodity exchange and colonization which have a longer history of carrying cultural meaning around the globe. The circulation of cultures enables individuals to partake in extended social relations that cross national and regional borders. The creation and expansion of such social relations is not merely observed on a material level. Cultural globalization involves the formation of shared norms and knowledge with which people associate their individual and collective cultural identities. It brings increasing interconnectedness among different populations and cultures.\n\nCross-cultural communication is a field of study that looks at how people from differing cultural backgrounds communicate, in similar and different ways among themselves, and how they endeavour to communicate across cultures. Intercultural communication is a related field of study.\n\nCultural diffusion is the spread of cultural items—such as ideas, styles, religions, technologies, languages etc.\nCultural globalization has increased cross-cultural contacts, but may be accompanied by a decrease in the uniqueness of once-isolated communities. For example, sushi is available in Germany as well as Japan, but Euro-Disney outdraws the city of Paris, potentially reducing demand for \"authentic\" French pastry. Globalization's contribution to the alienation of individuals from their traditions may be modest compared to the impact of modernity itself, as alleged by existentialists such as Jean-Paul Sartre and Albert Camus. Globalization has expanded recreational opportunities by spreading pop culture, particularly via the Internet and satellite television.\n\nReligions were among the earliest cultural elements to globalize, being spread by force, migration, evangelists, imperialists, and traders. Christianity, Islam, Buddhism, and more recently sects such as Mormonism are among those religions which have taken root and influenced endemic cultures in places far from their origins.\nGlobalization has strongly influenced sports. For example, the modern Olympic Games has athletes from more than 200 nations participating in a variety of competitions. The FIFA World Cup is the most widely viewed and followed sporting event in the world, exceeding even the Olympic Games; a ninth of the entire population of the planet watched the 2006 FIFA World Cup Final.\n\nThe term globalization implies transformation. Cultural practices including traditional music can be lost or turned into a fusion of traditions. Globalization can trigger a state of emergency for the preservation of musical heritage. Archivists may attempt to collect, record, or transcribe repertoires before melodies are assimilated or modified, while local musicians may struggle for authenticity and to preserve local musical traditions. Globalization can lead performers to discard traditional instruments. Fusion genres can become interesting fields of analysis.\n\nMusic has an important role in economic and cultural development during globalization. Music genres such as jazz and reggae began locally and later became international phenomena. Globalization gave support to the world music phenomenon by allowing music from developing countries to reach broader audiences. Though the term \"World Music\" was originally intended for ethnic-specific music, globalization is now expanding its scope such that the term often includes hybrid subgenres such as \"world fusion\", \"global fusion\", \"ethnic fusion\", and worldbeat.\nBourdieu claimed that the perception of consumption can be seen as self-identification and the formation of identity. Musically, this translates into each individual having their own musical identity based on likes and tastes. These likes and tastes are greatly influenced by culture, as this is the most basic cause for a person's wants and behavior. The concept of one's own culture is now in a period of change due to globalization. Also, globalization has increased the interdependency of political, personal, cultural, and economic factors.\n\nA 2005 UNESCO report showed that cultural exchange is becoming more frequent from Eastern Asia, but that Western countries are still the main exporters of cultural goods. In 2002, China was the third largest exporter of cultural goods, after the UK and US. Between 1994 and 2002, both North America's and the European Union's shares of cultural exports declined while Asia's cultural exports grew to surpass North America. Related factors are the fact that Asia's population and area are several times that of North America. Americanization is related to a period of high political American clout and of significant growth of America's shops, markets and objects being brought into other countries.\n\nSome critics of globalization argue that it harms the diversity of cultures. As a dominating country's culture is introduced into a receiving country through globalization, it can become a threat to the diversity of local culture. Some argue that globalization may ultimately lead to Westernization or Americanization of culture, where the dominating cultural concepts of economically and politically powerful Western countries spread and cause harm to local cultures.\n\nGlobalization is a diverse phenomenon which relates to a multilateral political world and to the increase of cultural objects and markets between countries. The Indian experience particularly reveals the plurality of the impact of cultural globalization.\n\nTransculturalism is defined as \"seeing oneself in the other\". Transcultural is in turn described as \"extending through all human cultures\" or \"involving, encompassing, or combining elements of more than one culture\".\n\nIn general, globalization may ultimately reduce the importance of nation states. Supranational institutions such as the European Union, the WTO, the G8 or the International Criminal Court replace or extend national functions to facilitate international agreement. This could ultimately lead to a global union, based on the European Union model.\n\nIntergovernmentalism is a term in political science with two meanings. The first refers to a theory of regional integration originally proposed by Stanley Hoffmann; the second treats states and the national government as the primary factors for integration.\nMulti-level governance is an approach in political science and public administration theory that originated from studies on European integration. Multi-level governance gives expression to the idea that there are many interacting authority structures at work in the emergent global political economy. It illuminates the intimate entanglement between the domestic and international levels of authority.\n\nSome people are citizens of multiple nation-states. Multiple citizenship, also called dual citizenship or multiple nationality or dual nationality, is a person's citizenship status, in which a person is concurrently regarded as a citizen of more than one state under the laws of those states.\n\nIncreasingly, non-governmental organizations influence public policy across national boundaries, including humanitarian aid and developmental efforts. Philanthropic organizations with global missions are also coming to the forefront of humanitarian efforts; charities such as the Bill and Melinda Gates Foundation, Accion International, the Acumen Fund (now Acumen) and the Echoing Green have combined the business model with philanthropy, giving rise to business organizations such as the Global Philanthropy Group and new associations of philanthropists such as the Global Philanthropy Forum. The Bill and Melinda Gates Foundation projects include a current multibillion-dollar commitment to funding immunizations in some of the world's more impoverished but rapidly growing countries. The Hudson Institute estimates total private philanthropic flows to developing countries at US$59 billion in 2010.\n\nAs a response to globalization, some countries have embraced isolationist policies. For example, the North Korean government makes it very difficult for foreigners to enter the country and strictly monitors their activities when they do. Aid workers are subject to considerable scrutiny and excluded from places and regions the government does not wish them to enter. Citizens cannot freely leave the country.\n\nScholars also occasionally discuss other, less common dimensions of globalization, such as environmental globalization (the internationally coordinated practices and regulations, often in the form of international treaties, regarding environmental protection) or military globalization (growth in global extent and scope of security relationships). Those dimensions, however, receive much less attention the three described above, as academic literature commonly subdivides globalization into three major areas: economic globalization, cultural globalization and political globalization.\n\nAn essential aspect of globalization is movement of people, and state-boundary limits on that movement have changed across history. The movement of tourists and business people opened up over the last century. As transportation technology improved, travel time and costs decreased dramatically between the 18th and early 20th century. For example, travel across the Atlantic ocean used to take up to 5 weeks in the 18th century, but around the time of the 20th century it took a mere 8 days. Today, modern aviation has made long-distance transportation quick and affordable.\n\nTourism is travel for pleasure. The developments in technology and transport infrastructure, such as jumbo jets, low-cost airlines, and more accessible airports have made many types of tourism more affordable. International tourist arrivals surpassed the milestone of 1 billion tourists globally for the first time in 2012.\nA visa is a conditional authorization granted by a country to a foreigner, allowing them to enter and temporarily remain within, or to leave that country. Some countries – such as those in the Schengen Area – have agreements with other countries allowing each other's citizens to travel between them without visas. The World Tourism Organization announced that the number of tourists who require a visa before traveling was at its lowest level ever in 2015.\n\nImmigration is the international movement of people into a destination country of which they are not natives or where they do not possess citizenship in order to settle or reside there, especially as permanent residents or naturalized citizens, or to take-up employment as a migrant worker or temporarily as a foreign worker.\nAccording to the International Labour Organization, there were an estimated 232 million international migrants in the world (defined as persons outside their country of origin for 12 months or more) and approximately half of them were estimated to be economically active (i.e. being employed or seeking employment). International movement of labor is often seen as important to economic development. For example, freedom of movement for workers in the European Union means that people can move freely between member states to live, work, study or retire in another country.\nGlobalization is associated with a dramatic rise in international education. More and more students are seeking higher education in foreign countries and many international students now consider overseas study a stepping-stone to permanent residency within a country. The contributions that foreign students make to host nation economies, both culturally and financially has encouraged major players to implement further initiatives to facilitate the arrival and integration of overseas students, including substantial amendments to immigration and visa policies and procedures.\n\nA transnational marriage is a marriage between two people from different countries. A variety of special issues arise in marriages between people from different countries, including those related to citizenship and culture, which add complexity and challenges to these kinds of relationships.\nIn an age of increasing globalization, where a growing number of people have ties to networks of people and places across the globe, rather than to a current geographic location, people are increasingly marrying across national boundaries. Transnational marriage is a by-product of the movement and migration of people.\n\nBefore electronic communications, long-distance communications relied on mail. Speed of global communications was limited by the maximum speed of courier services (especially horses and ships) until the mid-19th century. The electric telegraph was the first method of instant long-distance communication. For example, before the first transatlantic cable, communications between Europe and the Americas took weeks because ships had to carry mail across the ocean. The first transatlantic cable reduced communication time considerably, allowing a message and a response in the same day. Lasting transatlantic telegraph connections were achieved in the 1865–1866. The first wireless telegraphy transmitters were developed in 1895.\n\nThe Internet has been instrumental in connecting people across geographical boundaries. For example, Facebook is a social networking service which has more than 1.65 billion monthly active users .\n\nGlobalization can be spread by Global journalism which provides massive information and relies on the internet to interact, \"makes it into an everyday routine to investigate how people and their actions, practices, problems, life conditions etc. in different parts of the world are interrelated. possible to assume that global threats such as climate change precipitate the further establishment of global journalism.\"\n\nOne index of globalization is the \"KOF Index of Globalization\", which measures three important dimensions of globalization: economic, social, and political. Another is the A.T. Kearney / Foreign Policy Magazine Globalization Index.\nMeasurements of economic globalization typically focus on variables such as trade, Foreign Direct Investment (FDI), Gross Domestic Product (GDP), portfolio investment, and income. However, newer indices attempt to measure globalization in more general terms, including variables related to political, social, cultural, and even environmental aspects of globalization.\n\nReactions to processes contributing to globalization have varied widely with a history as long as extraterritorial contact and trade. Philosophical differences regarding the costs and benefits of such processes give rise to a broad-range of ideologies and social movements. Proponents of economic growth, expansion and development, in general, view globalizing processes as desirable or necessary to the well-being of human society.\n\nAntagonists view one or more globalizing processes as detrimental to social well-being on a global or local scale; this includes those who social or natural sustainability of long-term and continuous economic expansion, the social structural inequality caused by these processes, and the colonial, imperialistic, or hegemonic ethnocentrism, cultural assimilation and cultural appropriation that underlie such processes.\n\nGlobalization tends to bring people into contact with foreign people and cultures. Xenophobia is the fear of that which is perceived to be foreign or strange. Xenophobia can manifest itself in many ways involving the relations and perceptions of an ingroup towards an outgroup, including a fear of losing identity, suspicion of its activities, aggression, and desire to eliminate its presence to secure a presumed purity.\n\nCritiques of globalization generally stem from discussions surrounding the impact of such processes on the planet as well as the human costs. They challenge directly traditional metrics, such as GDP, and look to other measures, such as the Gini coefficient or the Happy Planet Index, and point to a \"multitude of interconnected fatal consequences–social disintegration, a breakdown of democracy, more rapid and extensive deterioration of the environment, the spread of new diseases, increasing poverty and alienation\" which they claim are the unintended consequences of globalization. Others point out that, while the forces of globalization have led to the spread of western-style democracy, this has been accompanied by an increase in inter-ethnic tension and violence as free market economic policies combine with democratic processes of universal suffrage as well as an escalation in militarization to impose democratic principles and as a means to conflict resolution.\n\nA 2005 study by Peer Fiss and Paul Hirsch found a large increase in articles negative towards globalization in the years prior. In 1998, negative articles outpaced positive articles by two to one. The number of newspaper articles showing negative framing rose from about 10% of the total in 1991 to 55% of the total in 1999. This increase occurred during a period when the total number of articles concerning globalization nearly doubled.\n\nA number of international polls have shown that residents of Africa and Asia tend to view globalization more favorably than residents of Europe or North America. In Africa, a Gallup poll found that 70% of the population views globalization favorably. The BBC found that 50% of people believed that economic globalization was proceeding too rapidly, while 35% believed it was proceeding too slowly.\n\nIn 2004, Philip Gordon stated that \"a clear majority of Europeans believe that globalization can enrich their lives, while believing the European Union can help them take advantage of globalization's benefits while shielding them from its negative effects.\" The main opposition consisted of socialists, environmental groups, and nationalists. Residents of the EU did not appear to feel threatened by globalization in 2004. The EU job market was more stable and workers were less likely to accept wage/benefit cuts. Social spending was much higher than in the US. In a Danish poll in 2007, 76% responded that globalization is a good thing.\n\nFiss, \"et al.\", surveyed US opinion in 1993. Their survey showed that, in 1993, more than 40% of respondents were unfamiliar with the concept of globalization. When the survey was repeated in 1998, 89% of the respondents had a polarized view of globalization as being either good or bad. At the same time, discourse on globalization, which began in the financial community before shifting to a heated debate between proponents and disenchanted students and workers. Polarization increased dramatically after the establishment of the WTO in 1995; this event and subsequent protests led to a large-scale anti-globalization movement.\nInitially, college educated workers were likely to support globalization. Less educated workers, who were more likely to compete with immigrants and workers in developing countries, tended to be opponents. The situation changed after the financial crisis of 2007. According to a 1997 poll 58% of college graduates said globalization had been good for the US. By 2008 only 33% thought it was good. Respondents with high school education also became more opposed.\n\nAccording to Takenaka Heizo and Chida Ryokichi, there was a perception in Japan that the economy was \"Small and Frail\". However, Japan was resource-poor and used exports to pay for its raw materials. Anxiety over their position caused terms such as \"internationalization\" and \"globalization\" to enter everyday language. However, Japanese tradition was to be as self-sufficient as possible, particularly in agriculture.\n\nMany in developing countries see globalization as a positive force that lifts them out of poverty. Those opposing globalization typically combine environmental concerns with nationalism. Opponents consider governments as agents of neo-colonialism that are subservient to multinational corporations. Much of this criticism comes from the middle class; the Brookings Institution suggested this was because the middle class perceived upwardly mobile low-income groups as threatening to their economic security.\n\nThe literature analysing the economics of free trade is extremely rich with extensive work having been done on the theoretical and empirical effects. Though it creates winners and losers, the broad consensus among economists is that free trade is a large and unambiguous net gain for society. In a 2006 survey of American economists (83 responders), \"87.5% agree that the U.S. should eliminate remaining tariffs and other barriers to trade\" and \"90.1% disagree with the suggestion that the U.S. should restrict employers from outsourcing work to foreign countries.\"\n\nQuoting Harvard economics professor N. Gregory Mankiw, \"Few propositions command as much consensus among professional economists as that open world trade increases economic growth and raises living standards.\" In a survey of leading economists, none disagreed with the notion that \"freer trade improves productive efficiency and offers consumers better choices, and in the long run these gains are much larger than any effects on employment.\" Most economists would agree that although increasing returns to scale might mean that certain industry could settle in a geographical area without any strong economic reason derived from comparative advantage, this is not a reason to argue against free trade because the absolute level of output enjoyed by both \"winner\" and \"loser\" will increase with the \"winner\" gaining more than the \"loser\" but both gaining more than before in an absolute level.\n\nIn the book \"The End of Poverty\", Jeffrey Sachs discusses how many factors can affect a country's ability to enter the world market, including government corruption; legal and social disparities based on gender, ethnicity, or caste; diseases such as AIDS and malaria; lack of infrastructure (including transportation, communications, health, and trade); unstable political landscapes; protectionism; and geographic barriers. Jagdish Bhagwati, a former adviser to the U.N. on globalization, holds that, although there are obvious problems with overly rapid development, globalization is a very positive force that lifts countries out of poverty by causing a virtuous economic cycle associated with faster economic growth. However, economic growth does not necessarily mean a reduction in poverty; in fact, the two can coexist. Economic growth is conventionally measured using indicators such as GDP and GNI that do not accurately reflect the growing disparities in wealth. Additionally, Oxfam International argues that poor people are often excluded from globalization-induced opportunities \"by a lack of productive assets, weak infrastructure, poor education and ill-health;\" effectively leaving these marginalized groups in a poverty trap. Economist Paul Krugman is another staunch supporter of globalization and free trade with a record of disagreeing with many critics of globalization. He argues that many of them lack a basic understanding of comparative advantage and its importance in today's world.\nThe flow of migrants to advanced economic countries has been claimed to provide a means through which global wages converge. An IMF study noted a potential for skills to be transferred back to developing countries as wages in those a countries rise. Lastly, the dissemination of knowledge has been an integral aspect of globalization. Technological innovations (or technological transfer) is conjectured to benefit most the developing and least developing countries (LDCs), as for example in the adoption of mobile phones.\n\nThere has been a rapid economic growth in Asia after embracing market orientation-based economic policies that encourage private property rights, free enterprise and competition. In particular, in East Asian developing countries, GDP per head rose at 5.9% a year from 1975 to 2001 (according to 2003 Human Development Report of UNDP). Like this, the British economic journalist Martin Wolf says that incomes of poor developing countries, with more than half the world's population, grew substantially faster than those of the world's richest countries that remained relatively stable in its growth, leading to reduced international inequality and the incidence of poverty.\n\nCertain demographic changes in the developing world after active economic liberalization and international integration resulted in rising general welfare and, hence, reduced inequality. According to Wolf, in the developing world as a whole, life expectancy rose by four months each year after 1970 and infant mortality rate declined from 107 per thousand in 1970 to 58 in 2000 due to improvements in standards of living and health conditions. Also, adult literacy in developing countries rose from 53% in 1970 to 74% in 1998 and much lower illiteracy rate among the young guarantees that rates will continue to fall as time passes. Furthermore, the reduction in fertility rate in the developing world as a whole from 4.1 births per woman in 1980 to 2.8 in 2000 indicates improved education level of women on fertility, and control of fewer children with more parental attention and investment. Consequently, more prosperous and educated parents with fewer children have chosen to withdraw their children from the labor force to give them opportunities to be educated at school improving the issue of child labor. Thus, despite seemingly unequal distribution of income within these developing countries, their economic growth and development have brought about improved standards of living and welfare for the population as a whole.\nPer capita gross domestic product (GDP) growth among post-1980 globalizing countries accelerated from 1.4 percent a year in the 1960s and 2.9 percent a year in the 1970s to 3.5 percent in the 1980s and 5.0 percent in the 1990s. This acceleration in growth seems even more remarkable given that the rich countries saw steady declines in growth from a high of 4.7 percent in the 1960s to 2.2 percent in the 1990s. Also, the non-globalizing developing countries seem to fare worse than the globalizers, with the former's annual growth rates falling from highs of 3.3 percent during the 1970s to only 1.4 percent during the 1990s. This rapid growth among the globalizers is not simply due to the strong performances of China and India in the 1980s and 1990s—18 out of the 24 globalizers experienced increases in growth, many of them quite substantial.\n\nThe globalization of the late 20th and early 21st centuries has led to the resurfacing of the idea that the growth of economic interdependence promotes peace. This idea had been very powerful during the globalization of the late 19th and early 20th centuries, and was a central doctrine of classical liberals of that era, such as the young John Maynard Keynes (1883–1946).\n\nSome opponents of globalization see the phenomenon as a promotion of corporate interests. They also claim that the increasing autonomy and strength of corporate entities shapes the political policy of countries. They advocate global institutions and policies that they believe better address the moral claims of poor and working classes as well as environmental concerns. Economic arguments by fair trade theorists claim that unrestricted free trade benefits those with more financial leverage (i.e. the rich) at the expense of the poor.\n\nGlobalization allows corporations to outsource manufacturing and service jobs from high cost locations, creating economic opportunities with the most competitive wages and worker benefits. Critics of globalization say that it disadvantages poorer countries. While it is true that free trade encourages globalization among countries, some countries try to protect their domestic suppliers. The main export of poorer countries is usually agricultural productions. Larger countries often subsidize their farmers (e.g., the EU's Common Agricultural Policy), which lowers the market price for foreign crops.\n\nDemocratic globalization is a movement towards an institutional system of global democracy that would give world citizens a say in political organizations. This would, in their view, bypass nation-states, corporate oligopolies, ideological Non-governmental organizations (NGO), political cults and mafias. One of its most prolific proponents is the British political thinker David Held. Advocates of democratic globalization argue that economic expansion and development should be the first phase of democratic globalization, which is to be followed by a phase of building global political institutions. Dr. Francesco Stipo, Director of the United States Association of the Club of Rome, advocates unifying nations under a world government, suggesting that it \"should reflect the political and economic balances of world nations. A world confederation would not supersede the authority of the State governments but rather complement it, as both the States and the world authority would have power within their sphere of competence\". Former Canadian Senator Douglas Roche, O.C., viewed globalization as inevitable and advocated creating institutions such as a directly elected United Nations Parliamentary Assembly to exercise oversight over unelected international bodies.\n\nGlobal civics suggests that civics can be understood, in a global sense, as a social contract between global citizens in the age of interdependence and interaction. The disseminators of the concept define it as the notion that we have certain rights and responsibilities towards each other by the mere fact of being human on Earth. World citizen has a variety of similar meanings, often referring to a person who disapproves of traditional geopolitical divisions derived from national citizenship. An early incarnation of this sentiment can be found in Socrates, whom Plutarch quoted as saying: \"I am not an Athenian, or a Greek, but a citizen of the world.\" In an increasingly interdependent world, world citizens need a compass to frame their mindsets and create a shared consciousness and sense of global responsibility in world issues such as environmental problems and nuclear proliferation.\n\nBaha'i-inspired author Meyjes, while favoring the single world community and emergent global consciousness, warns of globalization as a cloak for an expeditious economic, social, and cultural Anglo-dominance that is insufficiently inclusive to inform the emergence of an optimal world civilization. He proposes a process of \"universalization\" as an alternative.\n\nCosmopolitanism is the proposal that all human ethnic groups belong to a single community based on a shared morality. A person who adheres to the idea of cosmopolitanism in any of its forms is called a cosmopolitan or cosmopolite. A cosmopolitan community might be based on an inclusive morality, a shared economic relationship, or a political structure that encompasses different nations. The cosmopolitan community is one in which individuals from different places (e.g. nation-states) form relationships based on mutual respect. For instance, Kwame Anthony Appiah suggests the possibility of a cosmopolitan community in which individuals from varying locations (physical, economic, etc.) enter relationships of mutual respect despite their differing beliefs (religious, political, etc.).\n\nCanadian philosopher Marshall McLuhan popularized the term \"Global Village\" beginning in 1962. His view suggested that globalization would lead to a world where people from all countries will become more integrated and aware of common interests and shared humanity.\n\nMilitary cooperation – Past examples of international cooperation exist. One example is the security cooperation between the United States and the former Soviet Union after the end of the Cold War, which astonished international society. Arms control and disarmament agreements, including the Strategic Arms Reduction Treaty (see START I, START II, START III, and New START) and the establishment of NATO's Partnership for Peace, the Russia NATO Council, and the G8 Global Partnership against the Spread of Weapons and Materials of Mass Destruction, constitute concrete initiatives of arms control and de-nuclearization. The US–Russian cooperation was further strengthened by anti-terrorism agreements enacted in the wake of 9/11.\n\nEnvironmental cooperation – One of the biggest successes of environmental cooperation has been the agreement to reduce chlorofluorocarbon (CFC) emissions, as specified in the Montreal Protocol, in order to stop ozone depletion. The most recent debate around nuclear energy and the non-alternative coal-burning power plants constitutes one more consensus on what not to do. Thirdly, significant achievements in IC can be observed through development studies.\n\nAnti-globalization, or counter-globalization, consists of a number of criticisms of globalization but, in general, is critical of the globalization of corporate capitalism. The movement is also commonly referred to as the alter-globalization movement, anti-globalist movement, anti-corporate globalization movement, or movement against neoliberal globalization. Opponents of globalization argue that there is unequal power and respect in terms of international trade between the developed and underdeveloped countries of the world. The diverse subgroups that make up this movement include some of the following: trade unionists, environmentalists, anarchists, land rights and indigenous rights activists, organizations promoting human rights and sustainable development, opponents of privatization, and anti-sweatshop campaigners.\n\nIn \"The Revolt of the Elites and the Betrayal of Democracy\", Christopher Lasch analyzes the widening gap between the top and bottom of the social composition in the United States. For him, our epoch is determined by a social phenomenon: the revolt of the elites, in reference to \"The revolt of the masses\" (1929) of the Spanish philosopher José Ortega y Gasset. According to Lasch, the new elites, i.e. those who are in the top 20% in terms of income, through globalization which allows total mobility of capital, no longer live in the same world as their fellow-citizens. In this, they oppose the old bourgeoisie of the nineteenth and twentieth centuries, which was constrained by its spatial stability to a minimum of rooting and civic obligations.\nGlobalization, according to the sociologist, has turned elites into tourists in their own countries. The de-nationalisation of business enterprise tends to produce a class who see themselves as \"world citizens, but without accepting ... any of the obligations that citizenship in a polity normally implies\". Their ties to an international culture of work, leisure, information – make many of them deeply indifferent to the prospect of national decline. Instead of financing public services and the public treasury, new elites are investing their money in improving their voluntary ghettos: private schools in their residential neighborhoods, private police, garbage collection systems. They have \"withdrawn from common life\".\nComposed of those who control the international flows of capital and information, who preside over philanthropic foundations and institutions of higher education, manage the instruments of cultural production and thus fix the terms of public debate. So, the political debate is limited mainly to the dominant classes and political ideologies lose all contact with the concerns of the ordinary citizen. The result of this is that no one has a likely solution to these problems and that there are furious ideological battles on related issues. \nHowever, they remain protected from the problems affecting the working classes: the decline of industrial activity, the resulting loss of employment, the decline of the middle class, increasing the number of the poor, the rising crime rate, growing drug trafficking, the urban crisis.\n\nD.A. Snow et al. contend that the anti-globalization movement is an example of a new social movement, which uses tactics that are unique and use different resources than previously used before in other social movements.\n\nOne of the most infamous tactics of the movement is the Battle of Seattle in 1999, where there were protests against the World Trade Organization's Third Ministerial Meeting. All over the world, the movement has held protests outside meetings of institutions such as the WTO, the International Monetary Fund (IMF), the World Bank, the World Economic Forum, and the Group of Eight (G8). Within the Seattle demonstrations the protesters that participated used both creative and violent tactics to gain the attention towards the issue of globalization.\n\nCapital markets have to do with raising and investing money in various human enterprises. Increasing integration of these financial markets between countries leads to the emergence of a global capital marketplace or a single world market. In the long run, increased movement of capital between countries tends to favor owners of capital more than any other group; in the short run, owners and workers in specific sectors in capital-exporting countries bear much of the burden of adjusting to increased movement of capital.\n\nThose opposed to capital market integration on the basis of human rights issues are especially disturbed by the various abuses which they think are perpetuated by global and international institutions that, they say, promote neoliberalism without regard to ethical standards. Common targets include the World Bank (WB), International Monetary Fund (IMF), the Organisation for Economic Co-operation and Development (OECD) and the World Trade Organization (WTO) and free trade treaties like the North American Free Trade Agreement (NAFTA), Free Trade Area of the Americas (FTAA), the Multilateral Agreement on Investment (MAI) and the General Agreement on Trade in Services (GATS). In light of the economic gap between rich and poor countries, movement adherents claim free trade without measures in place to protect the under-capitalized will contribute only to the strengthening the power of industrialized nations (often termed the \"North\" in opposition to the developing world's \"South\").\n\nCorporatist ideology, which privileges the rights of corporations (artificial or juridical persons) over those of natural persons, is an underlying factor in the recent rapid expansion of global commerce. In recent years, there have been an increasing number of books (Naomi Klein's 2000 \"No Logo\", for example) and films (\"e.g. The Corporation\" & \"Surplus\") popularizing an anti-corporate ideology to the public.\n\nA related contemporary ideology, consumerism, which encourages the personal acquisition of goods and services, also drives globalization. Anti-consumerism is a social movement against equating personal happiness with consumption and the purchase of material possessions. Concern over the treatment of consumers by large corporations has spawned substantial activism, and the incorporation of consumer education into school curricula. Social activists hold materialism is connected to global retail merchandizing and supplier convergence, war, greed, anomie, crime, environmental degradation, and general social malaise and discontent. One variation on this topic is activism by \"postconsumers\", with the strategic emphasis on moving \"beyond\" addictive consumerism.\n\nThe global justice movement is the loose collection of individuals and groups—often referred to as a \"movement of movements\"—who advocate fair trade rules and perceive current institutions of global economic integration as problems. The movement is often labeled an anti-globalization movement by the mainstream media. Those involved, however, frequently deny that they are anti-globalization, insisting that they support the globalization of communication and people and oppose only the global expansion of corporate power. The movement is based in the idea of social justice, desiring the creation of a society or institution based on the principles of equality and solidarity, the values of human rights, and the dignity of every human being. Social inequality within and between nations, including a growing global digital divide, is a focal point of the movement. Many nongovernmental organizations have now arisen to fight these inequalities that many in Latin America, Africa and Asia face. A few very popular and well known non-governmental organizations (NGOs) include: War Child, Red Cross, Free The Children and CARE International. They often create partnerships where they work towards improving the lives of those who live in developing countries by building schools, fixing infrastructure, cleaning water supplies, purchasing equipment and supplies for hospitals, and other aid efforts.\n\nThe economies of the world have developed unevenly, historically, such that entire geographical regions were left mired in poverty and disease while others began to reduce poverty and disease on a wholesale basis. From around 1980 through at least 2011, the GDP gap, while still wide, appeared to be closing and, in some more rapidly developing countries, life expectancies began to rise. If we look at the Gini coefficient for world income, since the late 1980s, the gap between some regions has markedly narrowed—between Asia and the advanced economies of the West, for example—but huge gaps remain globally. Overall equality across humanity, considered as individuals, has improved very little. Within the decade between 2003 and 2013, income inequality grew even in traditionally egalitarian countries like Germany, Sweden and Denmark. With a few exceptions—France, Japan, Spain—the top 10 percent of earners in most advanced economies raced ahead, while the bottom 10 percent fell further behind. By 2013, a tiny elite of multibillionaires, 85 to be exact, had amassed wealth equivalent to all the wealth owned by the poorest half (3.5 billion) of the world's total population of 7 billion.\n\nCritics of globalization argue that globalization results in weak labor unions: the surplus in cheap labor coupled with an ever-growing number of companies in transition weakened labor unions in high-cost areas. Unions become less effective and workers their enthusiasm for unions when membership begins to decline. They also cite an increase in the exploitation of child labor: countries with weak protections for children are vulnerable to infestation by rogue companies and criminal gangs who exploit them. Examples include quarrying, salvage, and farm work as well as trafficking, bondage, forced labor, prostitution and pornography.\n\nWomen often participate in the workforce in precarious work, including export-oriented employment. Evidence suggests that while globalization has expanded women's access to employment, the long-term goal of transforming gender inequalities remains unmet and appears unattainable without regulation of capital and a reorientation and expansion of the state's role in funding public goods and providing a social safety net. Furthermore, the intersectionality of gender, race, class, and more remain overlooked when assessing the impact of globalization.\n\nIn 2016, a study published by the IMF posited that neoliberalism, the ideological backbone of contemporary globalized capitalism, has been \"oversold\", with the benefits of neoliberal policies being \"fairly difficult to establish when looking at a broad group of countries\" and the costs, most significantly higher income inequality within nations, \"hurt the level and sustainability of growth.\"\n\nBeginning in the 1930s, opposition arose to the idea of a world government, as advocated by organizations such as the World Federalist Movement (WFM). Those who oppose global governance typically do so on objections that the idea is unfeasible, inevitably oppressive, or simply unnecessary. In general, these opponents are wary of the concentration of power or wealth that such governance might represent. Such reasoning dates back to the founding of the League of Nations and, later, the United Nations.\n\nEnvironmentalism is a broad philosophy, ideology and social movement regarding concerns for environmental conservation and improvement of the health of the environment. Environmentalist concerns with globalization include issues such as global warming, climate change, global water supply and water crises, inequity in energy consumption and energy conservation, transnational air pollution and pollution of the world ocean, overpopulation, world habitat sustainability, deforestation, biodiversity and species extinction.\n\nOne critique of globalization is that natural resources of the poor have been systematically taken over by the rich and the pollution promulgated by the rich is systematically dumped on the poor. Some argue that Northern corporations are increasingly exploiting resources of less wealthy countries for their global activities while it is the South that is disproportionately bearing the environmental burden of the globalized economy. Globalization is thus leading to a type of\" environmental apartheid\".\n\nHelena Norberg-Hodge, the director and founder of Local Futures/International Society for Ecology and Culture, criticizes globalization in many ways. In her book \"\", Norberg-Hodge claims that \"centuries of ecological balance and social harmony are under threat from the pressures of development and globalization.\" She also criticizes the standardization and rationalization of globalization, as it does not always yield the expected growth outcomes. Although globalization takes similar steps in most countries, scholars such as Hodge claim that it might not be effective to certain countries and that globalization has actually moved some countries backward instead of developing them.\n\nA related area of concern is the pollution haven hypothesis, which posits that, when large industrialized nations seek to set up factories or offices abroad, they will often look for the cheapest option in terms of resources and labor that offers the land and material access they require (see Race to the bottom). This often comes at the cost of environmentally sound practices. Developing countries with cheap resources and labor tend to have less stringent environmental regulations, and conversely, nations with stricter environmental regulations become more expensive for companies as a result of the costs associated with meeting these standards. Thus, companies that choose to physically invest in foreign countries tend to (re)locate to the countries with the lowest environmental standards or weakest enforcement.\n\nThe globalization of food production is associated with a more efficient system of food production. This is because crops are grown in countries with optimum growing conditions. This improvement causes an increase in the world's food supply which encourages improved food security.\n\nNorway's limited crop range advocates globalization of food production and availability. The northern-most country in Europe requires trade with other countries to ensure population food demands are met. The degree of self-sufficiency in food production is around 50% in Norway.\n\n"}
{"id": "24367869", "url": "https://en.wikipedia.org/wiki?curid=24367869", "title": "IKF World Korfball Ranking", "text": "IKF World Korfball Ranking\n\nThe IKF World Korfball Ranking is the ranking for national korfball teams, done by the International Korfball Federation.\n\n"}
{"id": "21874341", "url": "https://en.wikipedia.org/wiki?curid=21874341", "title": "ITF Rankings", "text": "ITF Rankings\n\nThe ITF Rankings are the current rankings of national teams by the International Tennis Federation in both men's and women's tennis. The ITF produces two sets of rankings—the ITF Davis Cup Nations Ranking for male national teams, and the ITF Fed Cup Nations Ranking for female national teams. Both sets of rankings measure the success of all nations participating in both competitions.\n\nThe ITF Davis Cup Nations Ranking was launched at the end of 2001 and the ITF Fed Cup Nations Ranking was introduced a year later. Both rankings are updated following every World Group round and are used for seeding the highest ranked teams in the draws for each group in the competitions' structures.\n\nThe ITF Davis Cup and Fed Cup rankings are based in a rolling four year cumulative system. However, the points total for each nation is calculated following a weighted sum formula, in which recent results are weighted more heavily. After each World Group round, the ranking period adjusts, and points earned in the last year period have a weighting factor of 100% in the points total. At the same time, the weighting factor for the points earned until the same round in the previous three years is reduced to 75% (for points earned one to two years ago), 50% (for points earned two to three years ago) and 25% (for points earned three to four years ago).\n\nRanking points are awarded only to the winning nation of a competition tie at every round. Victories in World Group rounds are worth more points than those in Zone Groups, and ties at the later rounds of the competition are progressively worth more points. Bonus points are also awarded for a nation that defeats a higher-ranked nation, but only if the latter nation is ranked in the top 64 for the Davis Cup, or in the top 75 for the Fed Cup. Unique to the Davis Cup, there is an additional bonus for a nation that wins a tie in the opponent's home ground: a 25% bonus is added to the total of round points and ranking bonus points (if any). At the Fed Cup only, nations that win by walkover are awarded round points but no bonus points, and no points are awarded for consolation events.\n\nThe current ranking points and bonus points distribution tables for the Davis Cup are shown below:\n\n\nThe current ranking points and bonus points distribution tables for the Fed Cup are shown below:\n\n"}
{"id": "4426463", "url": "https://en.wikipedia.org/wiki?curid=4426463", "title": "Indian Century", "text": "Indian Century\n\nThe Indian Century (or India's Century) is the possibility that the 21st century will be dominated by India, similarly to how the 20th century is often called the American Century, and the 19th century as Pax Britannica (British Peace). The phrase is used particularly in the assertion that the economy of India could overtake the economy of the United States and economy of China as the largest national economy in the world, a position it held from 1 to 1500 A.D. and in 1700 A.D.\n\nIndia has created North–South Transport Corridor as an alternative to One Belt, One Road policy initiative of China (PRC), to link in with Iran, Russia, the Caucasus, and Central Asia. In 2017, India and Japan joined together to form Asia-Africa Growth Corridor, to better integrate the economies of South, Southeast, and East Asia with Oceania and Africa.\n\nAccording to the report named \"Indian Century: Defining India's Place in a Rapidly Changing Global Economy\" by IBM Institute for Business Value, India is predicted to be among the world’s highest-growth nations over the coming years.\n\nOne of the key factors includes its populous democracy. As per United Nations report, India will overtake China to become the world's most populous nation by 2022.\n\nEconomists and Researchers at Harvard University have projected India’s 7% projected annual growth rate through 2024 would continue to put it ahead of China, making India the fastest growing economy in the world. In 2017, Center for International Development at Harvard University, published a research study, projecting that India has emerged as the economic pole of global growth by surpassing China and is expected to maintain its lead over the coming decade.\n\nIndia is generally considered an emerging power due to its large and stable population, and its rapidly growing economic and military sectors.\n\n"}
{"id": "104718", "url": "https://en.wikipedia.org/wiki?curid=104718", "title": "International broadcasting", "text": "International broadcasting\n\nInternational broadcasting is broadcasting that is deliberately aimed at a foreign, rather than a domestic, audience. It usually is broadcast by means of longwave, mediumwave, or (more usually) shortwave radio, but in recent years has also used direct satellite broadcasting and the internet as means of reaching audiences.\n\nAlthough radio and television programs do travel outside national borders, in many cases reception by foreigners is accidental. However, for purposes of propaganda, transmitting religious beliefs, keeping in touch with colonies or expatriates, education, improving trade, increasing national prestige, or promoting tourism and goodwill, broadcasting services have operated external services since the 1920s.\n\nInternational broadcasting, in a limited extent, began during World War I, when German and British stations broadcast press communiqués using Morse code. With the severing of Germany's undersea cables, the wireless telegraph station in Nauen was the country's sole means of long-distance communication.\n\nThe US Navy Radio Service radio station in New Brunswick, Canada, transmitted the 'Fourteen Points' by wireless to Nauen in 1917. In turn, Nauen station broadcast the news of the abdication of Kaiser Wilhelm II on November 10, 1918.\n\nGuglielmo Marconi pioneered the use of short wave radio for long distance transmissions in the early 1920s. Using a system of parabolic reflector antennae, Marconi's assistant, Charles Samuel Franklin, rigged up a large antenna at Poldhu Wireless Station, Cornwall, running on 25 kW of power. In June and July 1923, wireless transmissions were completed during nights on 97 meters from Poldhu to Marconi's yacht \"Elettra\" in the Cape Verde Islands. High speed shortwave telegraphy circuits were then installed from London to Australia, India, South Africa and Canada as the main element of the Imperial Wireless Chain from 1926.\n\nThe Dutch began conducting experiments in the shortwave frequencies in 1925 from Eindhoven. The radio station PCJJ began the first international broadcasting on March 11, 1927 with programmes in Dutch for colonies in the Dutch West Indies and Dutch East Indies and in German, Spanish and English for the rest of the world. The popular Happy Station show was inaugurated in 1928.\n\nIn 1927, Marconi also turned his attention toward long distance broadcasting on shortwave. His first such broadcasts took place to commemorate Armistice Day in the same year. He continued running a regular international broadcast that was picked up around the world, with programming from the 2LO station, then run by the BBC. The success of this operation caught the BBC's attention, and rented out a shortwave transmitting station in Chelmsford, with the callsign G5SW, to Marconi. The BBC Empire Service was finally inaugurated on December 19, 1932, with transmissions aimed towards Australia and New Zealand.\n\nOther notable early international broadcasters included Vatican Radio (February 12, 1931), Radio Moscow, the official service of the Soviet Union (this has since been renamed the Voice of Russia, following the collapse of the Soviet Union). Clarence W. Jones started transmitting on Christmas Day, 1931 from Christian missionary radio station HCJB in Quito, Ecuador. Broadcasting in South Asia was launched in 1925 in Ceylon - Radio Ceylon, now the Sri Lanka Broadcasting Corporation is the oldest in the region.\nShortwave broadcasting from Nauen in Germany to the USA, Central and South America, and the Far East began in 1926. A second station, Zeesen, was added in 1931. In January 1932, the German Reichspost assumed control of the Nauen station and added to its shortwave and longwave capacity. Once Adolf Hitler assumed power in 1933, shortwave, under the \"Auslandsrundfunk\" (Foreign Radio Section), was regarded as a vital element of Nazi propaganda.\n\nGerman shortwave hours were increased from two hours a day to 18 per day, and eventually twelve languages were broadcast on a 24-hour basis, including English. A 100 kilowatt transmitter and antenna complex was built at Zeesen, near Berlin. Specialty target programming to the United States began in 1933, to South Africa, South America, and East Asia in 1934, and South Asia and Central America in 1938. German propaganda was organized under Joseph Goebbels, and played a key role in the German annexation of Austria and the Munich Crisis of 1938.\n\nIn 1936, the International Radio Union recognized Vatican Radio as a \"special case\" and authorized its broadcasting without any geographical limits. On December 25, 1937, a Telefunken 25-kW transmitter and two directional antennas were added. Vatican Radio broadcast over 10 frequencies.\n\nDuring the Spanish Civil War, the Nationalist forces received a powerful Telefunken transmitter as a gift of Nazi Germany to aid their propaganda efforts, and until 1943 Radio Nacional de España collaborated with the Axis powers to retransmit in Spanish news from the official radio stations of Germany and Italy.\n\nDuring the Second World War, Russian, German, British, and Italian international broadcasting services expanded. In 1942, the United States initiated its international broadcasting service, the Voice of America. In the Pacific theater, General Douglas MacArthur used shortwave radio to keep in touch with the citizens of the Japanese-occupied Philippine Islands.\n\nSeveral announcers who became well known in their countries included British Union of Fascists member William Joyce, who was one of the two \"Lord Haw-Haw\"s; Frenchmen Paul Ferdonnet and André Olbrecht, called \"the traitors of [Radio] Stuttgart\"; and Americans Frederick William Kaltenbach, \"Lord Hee-Haw\", and Mildred Gillars, one of the two announcers called \"Axis Sally\". Listeners to German programs often tuned in for curiosity's sake—at one time, German radio had half a million listeners in the U.S.--but most of them soon lost interest. Japan had \"Tokyo Rose\", who broadcast Japanese propaganda in English, along with American music to help ensure listeners.\n\nDuring World War II, Vatican Radio's news broadcasts were banned in Germany. During the war, the radio service operated in four languages.\n\nThe British launched Radio SEAC from Colombo, Ceylon (Sri Lanka) during World War II. The station broadcast radio programs to the allied armed forces across the region from their headquarters in Ceylon.\n\nFollowing the war and German partition, each Germany developed its own international broadcasting station: Deutsche Welle, using studios in Cologne, West Germany, and Radio Berlin International (RBI) in East Germany. RBI's broadcasts ceased shortly before the reunification of Germany on October 3, 1990, and Deutsche Welle took over its transmitters and frequencies.\n\nThe Cold War led to increased international broadcasting (and jamming), as Communist and non-Communist states attempted to influence each other's domestic population. Some of the most prominent Western broadcasters were the Voice of America, the BBC World Service, and the (covertly) CIA-backed Radio Free Europe/Radio Liberty. The Soviet Union's most prominent service was Radio Moscow (now the Voice of Russia) and China used Radio Peking (then Radio Beijing, now China Radio International). In addition to the U.S.-Soviet cold war, the Chinese-Russian border dispute led to an increase of the numbers of transmitters aimed at the two nations, and the development of new techniques such as playing tapes backwards for reel-to-reel recorders.\n\nWest Germany resumed regular shortwave broadcasts using Deutsche Welle on May 3, 1953. Its Julich transmitter site began operation in 1956, with eleven 100-kW Telefunken transmitters. The Wertachtal site was authorized in 1972 and began with four 500-kW transmitters. By 1989, there were 15 transmitters, four of which relayed the Voice of America. Meanwhile, in East Germany, the Nauen site began transmitting Radio DDR, later Radio Berlin International, on October 15, 1959.\nIn addition to these states, international broadcast services grew in Europe and the Middle East. Under the presidency of Gamal Nasser, Egyptian transmitters covered the Arab world; Israel's service, Kol Yisrael, served both to present the Israeli point of view to the world and to serve the Jewish diaspora, particularly behind the Iron Curtain.\n\nRadio RSA, as part of the South African Broadcasting Corporation, was established in 1966 to promote the image of South Africa internationally and reduce criticism of apartheid. It continued in 1992, when the post-apartheid government renamed it Channel Africa.\n\nIronically, the isolationist Albania under Enver Hoxha, virtually a hermit kingdom, became one of the most prolific international broadcasters during the latter decades of the Cold War, with Radio Tirana one of the top five broadcasters in terms of hours of programming produced.\n\nEstimated total programme hours per week of some external broadcasters\nAt the end of the Cold War, many international broadcasters cut back on hours and foreign languages broadcast, or reemphasized other language services. For example, in 1984, Radio Canada International broadcast in English, French, German, Spanish, Czech/Slovak, Hungarian, Polish, Russian, and Ukrainian. In 2005, RCI broadcast in English, Chinese, Arabic, Russian, and Spanish. There is a bigger trend towards TV (e.g. BBC World News, NHK World, CCTV-9) and news websites. Some services, such as Swiss Radio International, left shortwave altogether and exist in Internet form. In addition, new standards, such as Digital Radio Mondiale, are being introduced, as well as sending programs over the Web to be played back later, as \"podcasts\".\n\nInternational broadcasting using the traditional audio-only method will not cease any time soon due to its cost efficiencies. However, international broadcasting via television is considered more strategically important at least since the early 2000s.\n\nThe BBC World Service was the first broadcaster to consider setting up a satellite television news and information channel as far back as 1976, but ceded being the first to CNN (that had primary access to Canada soon after launch). The defunct BBC World Service Antigua Relay Station was built in 1976, but its setup costs were not known to have been part of the BBCWS decision processes at the time.\n\nIn the early 1990s, many international (as well as domestic) 24-hour news and information channels launched as part of the post-Cold War prosperity bubble. There was another burst of global news channels launching in the late 2000s as part the developing world trying to catch up with the developed world in this area.\n\nBroadcasters in one country have several reasons to reach out to an audience in other countries. The examples given below are not meant to be exhaustive, but are illustrative.\n\nOne clear reason is for ideological, or propaganda reasons. Many government-owned stations portray their nation in a positive, non-threatening way. This could be to encourage business investment and/or tourism to the nation. Another reason is to combat a negative image produced by other nations or internal dissidents, or insurgents. Radio RSA, the broadcasting arm of the apartheid South African government, is an example of this. A third reason is to promote the ideology of the broadcaster. For example, a program on Radio Moscow from the 1960s to the 1980s was \"What is Communism?\"\n\nA second reason is to advance a nation's foreign policy interests and agenda by disseminating its views on international affairs or on the events in particular parts of the world. During the Cold War the American Radio Free Europe and Radio Liberty and Indian Radio AIR were founded to broadcast news from \"behind the Iron Curtain\" that was otherwise being censored and promote dissent and occasionally, to disseminate disinformation. Currently the US operates similar services aimed at Cuba and the People's Republic of China.\n\nThe BBC World Service, the Voice of America, All India Radio and other western broadcasters have emphasized news broadcasts, particularly to countries that are experiencing repression or civil unrest and whose populations are unable to obtain news from non-government sources. In the case of emergencies, a nation may broadcast special programs overseas to inform listeners what is occurring. During Iraqi missile strikes on Israel during the 1991 Gulf War, Kol Israel relayed its domestic service on its shortwave service.\n\nBesides ideological reasons, many stations are run by religious broadcasters and are used to provide religious education, religious music, or worship service programs. For example, Vatican Radio, established in 1931, broadcasts such programs. Another station, such as HCJB or Trans World Radio will carry brokered programming from evangelists. In the case of the Broadcasting Services of the Kingdom of Saudi Arabia, both governmental and religious programming is provided.\n\nStations also broadcast to international audiences for cultural reasons. Often a station has an official mandate to keep expatriates in touch with the home country. Many broadcasters often relay their national domestic service on shortwave for that reason. Other reasons include teaching a foreign language, such as Radio Exterior de España's Spanish class, \"Un idioma sin fronteras\", or the Voice of America's broadcasts in Special English. In the case of major broadcasters such as the BBC World Service or Radio Australia, there is also an educational outreach.\n\nAn additional reason for international broadcasting is to maintain contact with a country's citizens travelling abroad or expatriates who have emigrated and share news from home as well as cultural programming. This role of external shortwave broadcasting has declined as advances in communications have allowed expatriates to read news from home and listen and watch to domestic broadcasts in their own language via the internet and satellite. A number of international services such as the original BBC Empire Service, Radio Netherlands, France's Poste Colonial (now Radio France International) and others were founded in part with the goal of helping draw overseas empires closer to the mother country and provide closer cultural and communication connections between the home country and its colonies, a role that became largely obsolete due to decolonization.\n\n\nBecause of this many broadcasters are discovering they can reach a wider audience through other methods (particularly the internet and satellite television) and are cutting back on (or even entirely dropping) shortwave.\n\nAn international broadcaster has several options for reaching a foreign audience:\n\nAn international broadcaster such as the BBC, Radio France International or Germany's Deutsche Welle, may use all the above methods. Several international broadcasters, such as Swiss Radio International, have abandoned shortwave broadcasting altogether, relying on Internet transmissions only. Others, such as the BBC World Service, have abandoned shortwave transmissions to North America, relying on local relays, the Internet, and satellite transmissions\n\nMost radio receivers in the world receive the mediumwave band (530 kHz to 1710 kHz), which at night is capable of reliable reception from 150 to 2,500 km distance from a transmitter. Mediumwave is used heavily all over the world for international broadcasting on a formal and informal basis.\n\nIn addition, many receivers used in Europe and Russia can receive the longwave broadcast band (150 to 280 kHz), which provides reliable long-distance communications over continental distances.\n\nShortwave receivers are capable of receiving shortwave transmissions (2,000 to 30,000 kHz or 2 to 30 MHz). Depending on time of day, season of year, solar weather and Earth's geomagnetic field, a signal might reach around the world.\n\nIn previous decades shortwave (and sometimes high-powered mediumwave) transmission was regarded as the main (and often the \"only\") way in which broadcasters could reach an international audience. In recent years the proliferation of technologies such as satellite broadcasting, the Internet, and rebroadcasts of programming on AM and FM within target nations has meant that this is no longer necessarily the case.\n\nTransmitter output power has increased since 1920. Higher transmitter powers do guarantee better reception in the target area. Higher transmitter power in most cases counteracts the lesser effects of jamming.\n\nInternational stations generally use special directional antennas to aim the signal toward the intended audience and increase the effective power in that direction. Use of such antennas for international broadcasting began in the mid-1930s and became prominent by the 1950s. By using antennas which focus most of their energy in one direction, a modern station may achieve the equivalent, in that direction, of tens of millions of watts of radio power.\n\nSome international broadcasters have become available via Digital Audio Broadcasting (DAB) in Europe in the 1990s, and in a similar limited way in the Americas via in-band FM (IBOC) DAB systems in the US in the 2000s. This is a popular method to reach listeners in cars that would otherwise not be accessible during that part of the day. However, in terms of the global international broadcasting audience the DAB listener base is very small—one can assume that it is less than 2% of the listener base globally.\n\nInternational broadcasting via 24 hour TV news channels has its origins in North America in the early 1980s. CNN technically was the first 24-hour international news channel as it was made available in Canada soon after launch. The BBC World Service considered setting up a global TV news channel as far back as 1975, but abandoned the idea for internal reasons.\n\nNotwithstanding a large number of international 24-hour television news and information broadcasters, the television percentage of viewers is still fairly small when compared to global radio listener numbers.\n\nThe rural populations of Sub-Saharan Africa and South Asia (as well as East Asia) have radio listener bases that are far larger than the largest international TV broadcaster could hope for, yet they could be considered underserved since the end of the Cold War (when these regions had more radio broadcasts targeted at them).\n\nMany international television broadcasters (as well as domestic television broadcasters) have set up accounts on streaming video sites like YouTube to allow their news and information broadcasts to be globally distributed. The viewer numbers for these sites may seem huge. Cable, TVRO and terrestrial television broadcasters probably have 100 to 1,000 times larger audiences for their international broadcasting content.\n\nInternational broadcasters known to maintain their own streaming video sites (not authoritative):\n\n\nMany international broadcasters (television or radio) can reach \"unreachable\" audiences via email and RSS feeds. This is not at all unusual, as the first commonly agreed international broadcast was a Morse Code telegram transmitted from US President Wilson to the German Kaiser (mid-1918) via a high powered longwave transmitter on the US East Coast (this important event in international broadcasting history was described in depth in the IEEE \"The History of International Broadcasting\" first volume). As Morse Code is considered to be a data format, with email and RSS merely being refinements of the technology it can be said that international broadcasting has a deep relationship with modern-day datacasting.\n\nThe reach of RSS and email for international broadcasters is not really known that well, especially considering that emails get forwarded. The numbers for active RSS and email audiences are probably 5 to 20 times larger than for streaming video. It may take into the 2010s to get meaningful numbers with respect to the size of these audiences for assorted technical reasons related to the RSS and email technologies.\n\nEmail and RSS feeds can traverse telecommunications barriers that streaming video cannot, thus the larger expected audience numbers. The global economic downturn of 2008-2009 will probably increase the email and RSS audience sizes as fewer people will be able to afford high speed internet connections in North America, Western Europe and the Asia-Pacific regions.\n\nAn international broadcaster may have the technical means of reaching a foreign audience, but unless the foreign audience has a reason to listen, the effectiveness of the broadcaster is in question.\n\nOne of the most common foreign audiences consists of expatriates, who cannot listen to radio or watch television programs from home. Another common audience is radio hobbyists, who attempt to listen to as many countries as possible and obtain verification cards or letters (\"QSLs\"). These audiences send letters and in response few radio stations write them back. These kind of Listeners often take part in weekly and monthly quizzes and contests started by many radio stations. A third audience consists of journalists, government officials, and key businesspersons, who exert a disproportionate influence on a state's foreign or economic policy.\n\nA fourth, but less publicized audience, consists of intelligence officers and agents who monitor broadcasts for both open-source intelligence clues to the broadcasting state's policies and for hidden messages to foreign agents operating in the receiving country. The BBC started its monitoring service in Caversham, Reading in 1936 (now BBC Monitoring). In the United States, the DNI Open Source Center (formerly the Central Intelligence Agency's Foreign Broadcast Information Service) provides the same service. Copies of OSC/FBIS reports can be found in many U.S. libraries that serve as government depositories. In addition, a number of hobbyists listen and report \"spook\" transmissions.\n\nWithout these four audiences, international broadcasters face difficulty in getting funding. In 2001, for example, the BBC World Service stopped transmitting shortwave broadcasts to North America, and other international broadcasters, such as YLE Radio Finland, stopped certain foreign-language programs.\n\nHowever, international broadcasting has been successful when a country does not provide programming wanted by a wide segment of the population. In the 1960s, when there was no BBC service playing rock and roll, Radio Television Luxembourg (RTL) broadcast rock and roll, including bands such as the Beatles, into the United Kingdom. Similar programming came from an unlicensed, or \"pirate\" station, Radio Caroline, which broadcast from a ship in the international waters of the North Sea.\n\nIn many cases, governments do not want their citizens listening to international broadcasters. In Nazi Germany, a major propaganda campaign, backed by law and prison sentences, attempted to discourage Germans from listening to such stations. The practice was made illegal in 1939. In addition, the German government sold a cheap, 76-Reichsmark \"People's Receiver\", as well as an even cheaper 35-Reichsmark receiver, that could not pick up distant signals well.\n\nThe idea was copied by Stalin's Soviet Union, which had a nearly identical copy manufactured in the Tesla factory in Czechoslovakia.\nIn North Korea, all receivers are sold with fixed frequencies, tuned to local stations.\n\nThe most common method of preventing reception is jamming, or broadcasting a signal on the same frequencies as the international broadcaster. Germany jammed the BBC European service during the Second World War. Russian and Eastern European jammers were aimed against Radio Free Europe, other Western broadcasters, and against Chinese broadcasters during the nadir of Sino-Soviet relations. In 2002, the Cuban government jammed the Voice of America's Radio Martí program and the Chinese government jammed Radio Free Asia, Voice of America, Radio Taiwan International as well broadcasts made by adherents of Falun Gong.\n\nNorth Korea restricts most people to a single fixed frequency mediumwave receiver; those who met political requirements and whose work absolutely required familiarity with events abroad were allowed shortwave receivers. Another method of reaching people with government radio programming, but not foreign programming, is the use of radio broadcasting by direct broadcasting to loudspeakers.\nDavid Jackson, director of the Voice of America, noted \"The North Korean government doesn't jam us, but they try to keep people from listening through intimidation or worse. But people figure out ways to listen despite the odds. They're very resourceful.\"\n\nYet another method of preventing reception involves moving a domestic station to the frequency used by the international broadcaster. During the Batista government of Cuba, and during the Castro years, Cuban medium-wave stations broadcast on the frequencies of popular South Florida stations. In October 2002, Iraq changed frequencies of two stations to block the Voice of America's Radio Sawa program.\n\nJamming can be defeated by using very efficient transmitting antennas, carefully choosing the transmitted frequency, changing transmitted frequency often, using single sideband, and properly aiming the receiving antenna.\n\nFor a list of international broadcasters, see List of international broadcasters.\n\n\nGraef 2005<br>\nGraef, Robert. \"Bicycling to Amersfoort: A World War II Memoir\". 2005, iUniverse. \n\nHorwitz 2001<br>\nHorwitz, Robert Britt. \"Communication and Democratic Reform in South Africa\". 2001, Cambridge University Press .\n\nHughes and Mann 2002<br>\nHughes, Matthew, and Chris Mann. \"Inside Hitler's Germany: Life Under the Third Reich\". 2002, Brassey's. \n\nLevillain 2002<br>\nLevillain, Philippe. \"The Papacy: An Encyclopedia\". Translated by John O'Malley. Routledge, 2002. \n\nMartin 2006<br>\nMartin, Bradley K. \"Under the Loving Care of the Fatherly Leader: North Korea and the Kim Dynasty\". 2006, Macmillan. \n\nWood 2000<br>\nWood, James. \"History of International Broadcasting\". 2000, IET. \n\n"}
{"id": "5205784", "url": "https://en.wikipedia.org/wiki?curid=5205784", "title": "List of largest universities and university networks by enrollment", "text": "List of largest universities and university networks by enrollment\n\nThis list of largest universities by enrollment in the world includes total active enrollment across all campuses, as well as off-campus study. The enrollment numbers listed are the sum of undergraduate and graduate students in active enrollment. The universities included below confer degrees of bachelor-level or higher, and either share a central board of governance and a single chancellor or president, or confer degrees with the same institution name.\n\nMany of these universities, particularly those in the United States, are actually systems of separate university campuses, and may not accurately represent a comparable student body. For example, the enrollment listed for the University of California is the population of the entire student body in the University of California system, which is composed of several individual campuses statewide. All University of California campuses are entitled \"University of California\" and then denoted further by the campus location, such as \"University of California, Irvine\". Other states organize their public universities differently in ways that further complicate any direct comparisons.\n\n"}
{"id": "11803445", "url": "https://en.wikipedia.org/wiki?curid=11803445", "title": "Montia fontana", "text": "Montia fontana\n\nMontia fontana, commonly known as blinks or water blinks, water chickweed or annual water miner's lettuce, is a herbaceous annual plant of the genus \"Montia\". It is a common plant that can be found in wet environments around the globe, from the tropics to the Arctic. It is quite variable in morphology, taking a variety of forms. It is sometimes aquatic.\n\nMontia fontana is divided into four subspecies, subsp. fontana, subsp. amporitana, subsp. chondrosperma and subsp. variabilis\n\n"}
{"id": "6324816", "url": "https://en.wikipedia.org/wiki?curid=6324816", "title": "Mutual recognition agreement", "text": "Mutual recognition agreement\n\nA mutual recognition agreement (MRA) is an international agreement by which two or more countries agree to recognize one another's conformity assessments.\nA mutual recognition arrangement is an international arrangement based on such an agreement.\n\nMRAs have become increasingly common since the formation of the World Trade Organization in 1995. They have been forged within and among various trade blocs, including APEC and the European Union.\n\nMRAs are most commonly applied to goods, such as various quality control MRAs. However, the term is sometimes applied to agreements on the recognition of professional qualifications as well.\n\nAccreditation Bodies, under the International Accreditation Forum use the term \"Multilateral Recognition Agreements\" in a similar sense.\n\n\n"}
{"id": "20842544", "url": "https://en.wikipedia.org/wiki?curid=20842544", "title": "Official Women's Squash World Ranking", "text": "Official Women's Squash World Ranking\n\nThe Official Women's Squash World Ranking is the official world ranking for women's squash. The ranking is to rate the performance level of female professional squash player. It is also a merit-based method used for determining entry and seeding in women's squash tournaments. The rankings are produced monthly. The current world number one is Nour El Sherbini of Egypt, who replaced Laura Massaro in May 2016.\n\nPlayers competing in PSA tournaments earn ranking points according to how far they get in the draw. The points available depend on the prize money and the draw size. The monthly rankings (issued on the 1st of the month) are used in selecting entries to tournaments and in determining the seeds.\n\nThe total number of points a player earns in a year (52 weeks) is divided by the number of tournaments played (a minimum of eight are required) to give a ranking average. Where a player has played more than 8 tournaments the best scores may be selected (i.e., the lowest are not included).\n\nFor example, a player who has competed in 13 events will have selected her best 10 scores, which will be accumulated and divided by 10.\n\nPlayers competing in PSA World Tour Events earn ranking points according to the prize money, classification of the event, and the final position in the draw the player reaches.\n\nThe total number of points a player accumulates in any year (52-week period) is divided by the number of tournaments played (minimum 8 tournaments in 52 weeks) to give an average score:\n\nNote: The monthly ranking for the women's squash (world ranking) is taken directly from the Professional Squash Association (PSA) official website.\n\nThe following is a list of players who have achieved the world number one position since April 1983 (active players in green):\n\n\"Last update: April, 2017\"\n\nnajmi\n\nNote: \n1) Natalie Grinham changed her nationality in 2008.\n\n\n\n"}
{"id": "23527766", "url": "https://en.wikipedia.org/wiki?curid=23527766", "title": "Ohio State University Health Sciences Center for Global Health", "text": "Ohio State University Health Sciences Center for Global Health\n\nThe Health Sciences Center for Global Health (HSCGH) at The Ohio State University (OSU) is a collaborative program among the OSU Colleges of Dentistry, Medicine, Nursing, Optometry, Pharmacy, Public Health, School of Health and Rehabilitation Sciences and Veterinary Medicine. The HSCGH is led jointly by the Colleges of Medicine (COM) and Public Health (CPH).\n\nThe HSCGH was created to increase student interest in global careers, prepare students for those careers and to promote, develop and coordinate interdisciplinary global health education and research throughout the health sciences colleges and the larger community. The Board of Trustees approved the creation of the HSCGH in July 2007.\n\nThe National Institutes of Health (NIH) Fogarty Framework Grant was awarded to OSU in September 2008. The NIH John E. Fogarty International Center grant supports the creation of new, multidisciplinary educational programs as well as an administrative infrastructure to support activities.\n\n\nThe Graduate Interdisciplinary Specialization in Global Health (GISGH) is a university-wide program that offers current OSU graduate and professional students advanced educational opportunities in the field of global health. The goal of the GISGH is to help prepare graduates to be active participants in the advancement of global health through academic enrichment, service-learning, and research pertaining to issues of global health. The specialization's core course, Introduction to Global Health, focuses on the basic components of population health, while the electives allow students to pursue topics across the other health sciences colleges for a truly interdisciplinary experience.\n\nDiane L. Gorgas, MD, a professor of Emergency Medicine at The Ohio State University’s Wexner Medical Center. She currently serves as the Executive Director of the Office of Global Health. and of OSU's Health Sciences Center for Global Health. She is nationally involved as an item writer and case developer and case administrator for the American Board of Emergency Medicine (ABEM) and sits on the Emergency Medicine Review Committee for the Accreditation Council for Graduate Medical Education (ACGME). She was the Residency Training Program Director in Emergency Medicine for many years, and has a long standing interest in and study of educational methods. Her other associated research interests include global health, emotional intelligence, competency assessment and learning styles. Dr. Gorgas currently directs the OSU Greif Neonatal Survival program, which works to improve the lives of mothers and infants in low-income countries through self-sustaining education and training programs to increase the in-country capacity of healthcare workers.\n\nPamela Potter serves as the administrative director for the Health Sciences Center for Global Health at The Ohio State University and in that role provides oversight of the daily administration and operation of the center. She is also the associate director of the Office of Global Health in the College of Medicine. Prior to her role at OSU, she served as the Chief of Staff to the Executive Dean for the Georgetown University School of Medicine.\n\n"}
{"id": "55509387", "url": "https://en.wikipedia.org/wiki?curid=55509387", "title": "Overseas Countries and Territories Association", "text": "Overseas Countries and Territories Association\n\nOverseas Countries and Territories Association (OCTA; , PTOM) is an international organisation founded on November 17, 2000 during the conference of prime ministers of overseas countries and territories in Brussels, Belgium. It includes almost all special member state territories of European Union whose purpose is to improve economic development in overseas countries and territories and cooperation with the European Union. It currently has 22 members. On 25 June 2008, a Cooperation Treaty between the EU and OCTA was signed in Brussels. Current chairmen is the Premier of Turks and Caicos Islands, Sharlene Cartwright Robinson.\n\nSince 2011, the chairmen are chosen annually and their function is to head the organization and elect an Executive Committee. Previous chairmen are:\n\nThe members of OCTA are:\nThe forum between OCTA, European Union and Member States has been held since 2003 in Brussels (Belgium) and in an OCT alternatively, so far there have been fifteen annual forums here:\n\n\n"}
{"id": "34291649", "url": "https://en.wikipedia.org/wiki?curid=34291649", "title": "Pacific Health Summit", "text": "Pacific Health Summit\n\nThe goal of the Pacific Health Summit is to connect science, industry, and policy for a healthier world. Traditionally, the main work of the Summit has been an annual meeting, where top decision makers convene to discuss how to realize the dream of a healthier future through the effective utilization of scientific advances, combined with industrial innovation and appropriate policies. In autumn of 2012 on the heels of its eight major conference, the Summit shifted its focus from an annual meeting to more targeted work that builds on the past themes and concrete outcomes. As it has since 2005, the Summit will continue to provide a year-round forum for world leaders to grapple with problems and solutions, share best practices, and forge effective collaborations.\n\nThe first Pacific Health Summit was held in Seattle, Washington in 2005 with foundational support from the Bill & Melinda Gates Foundation and the Russell Family Foundation. It was the co-creation of 2001 Nobel Prize in physiology or medicine winner Leland H. Hartwell, businessman and philanthropist George F. Russell Jr., Co-chair of the Bill & Melinda Gates Foundation William H. Gates Sr., and Founding Director of the National Bureau of Asian Research’s Center for Health and Aging Michael Birt. NBR has been the Secretariat of the Summit since the inaugural 2005 conference. \n\nBirt, founding Executive Director of the Summit, stepped down from his role as NBR’s Center for Health and Aging Director in 2009, and from his role as Executive Director in 2012, handing the mantle to Claire Topal, the Summit's Managing Director, who ran the Summit and managed the team from 2009-2012. She now serves as Senior Advisor for International Health to NBR. Nualchan Sakchalathorn, the Summit’s Project Director, served on the Summit team from 2007-2012.\n\nBuilding on Bill Gates Sr.'s strong personal support, in 2007 Tachi Yamada, then President of Global Health at the Bill & Melinda Gates Foundation, took on a decisive leadership role and formally established the Foundation as the Summit's third co-presenting organization. \n\nIn 2008, the Wellcome Trust joined the Summit as the fourth official co-presenting organization, and Trust Director, Sir Mark Walport, joined our Executive Committee. Both Sir William Castell, Chairman of the Wellcome Trust, who has participated in the Summit since its first year, and Sir Mark provided crucial leadership as the Summit began its rotation in London for the annual meeting.\n\nPeter Neupert, then Corporate Vice President for Health Solutions Strategy for Microsoft, and Craig Mundie, Chief Research and Strategy Officer of Microsoft, consistently provided a private sector perspective to the Summit's strategic discussions. Additionally, GE Healthcare, through Bill Castell in 2005, has always provided critical advice and perspective, as well as the critical founding sponsorship for the annual meeting. \n\nOut of this initial foundation of leadership, the Summit grew into one of the world's premier global health gatherings every year. In 2012, eight years after the inaugural meeting, which was never designed to take place in perpetuity, global health is in an exciting new place. The Summit’s interactive format has proliferated, and decision-makers across all sectors and geographies are collaborating on all the critical global health issues the Summit sought to address: health technology, pandemic flu, MDR-TB, vaccines, malnutrition, maternal and newborn health, and many more. While the Summit is proud of eight years of transformational conversations, countless new friendships, and exciting partnerships, there is still much work to do – and so much momentum on which to build. NBR is looking forward and excited to build on the Summit’s legacy in the years to come.\n\nThe Summit has been a catalyst for partnerships, and the setting of several global health announcements. In 2007, during a speech at the Summit, Margaret Chan, Director-General of the World Health Organization, publicized “a new initiative to establish a world stockpile of vaccines to prepare for the threat of pandemic influenza.” At the Summit in 2009, Sanofi bolstered that stockpile with 100 million donated doses of flu vaccine. \nOther partnerships furthered by, or formed at, the Summit have helped to lead to the establishment of the MSD Wellcome Trust Hilleman Laboratories, the Access to Nutrition Index, the Critical Path to TB Drug Regimens, and a cervical cancer vaccination deal between Merck & Co. and Qiagen. \nAdditionally, the denial of a US visa for 2009 Summit participant Paul Thorn of the Tuberculosis Survival Project, due to his HIV positive status, became the impetus behind the repeal of a US travel restriction law on individuals carrying the HIV/AIDs virus.\n\nThe Summit Secretariat, the Center for Health and Aging at The National Bureau of Asian Research, publishes reports, videos, and photos of Summit sessions and workshops. The organization also produces expert interviews and thought pieces with Summit participants on past themes and current global health topics. Prior to each Summit, the Center publishes a ‘Calls for Collaboration’ report. The publication contains submissions from organizations inviting Summit participants to partner and collaborate around specific areas of need.\n\n\n"}
{"id": "36055387", "url": "https://en.wikipedia.org/wiki?curid=36055387", "title": "Planetary consciousness", "text": "Planetary consciousness\n\nPlanetary consciousness is the idea that human beings are members of a planetary society of Earth as much as they are members of their nations, provinces, districts, islands, cities or villages.\n\nIn his 1906 book \"American Character\", author Brander Matthews mentions the idea of a \"league of nations\" and a \"planetary consciousness\", believing it would be created by American politicians in the coming centuries. Key planetary consciousness events of the 20th century include the creation of the League of Nations, the signing of Kellogg-Briand Pact, the creation of the United Nations, and the creation of the Bretton Woods system. Democratic globalization advocate Abhay Kumar points to the International Corporation of Assigned Names and Numbers (ICANN) board of directors election in 2000, which were conducted globally, as the first example of global democracy. In September 2001, Ervin László and the Dalai Lama wrote an essay titled \"Manifesto on Planetary Consciousness\", which was adopted at a meeting at the Hungarian Academy of Sciences in Budapest. Its introduction begins:\n\nAndreas Bummel, CEO of the Committee for a Democratic UN, says, \"The first step into the direction of a world parliament would be the establishment of a Parliamentary Assembly at the United Nations\".\n\nAdvocacy for the idea of planetary consciousness is based on the technological advancements made by the mankind in the fields of transport and telecommunications during the 20th century and in the first decade of the 21st century. Kumar claims that these technological advancements have turned the whole planet into an interdependent economic, political and communication community. He specifically cites the invention of the Internet and the mobile phones as key technological achievements of the 20th century which brought humans into more continuous interconnected communication. He believes that these inventions will lead to a second Renaissance and global democracy, just as the Gutenberg press in 1439 led to the first Renaissance, the Age of Enlightenment, and Nation states. Bummel describes planetary consciousness as integral, insofar as it does not conflict with other levels of social identity, but instead is a holistic perspective on humanity and the planet as a whole. Steven Kull writes that while nation states are reluctant to work cooperatively, individuals seem more willing.\n\nAuthor Shashi Tharoor feels that an Earth Anthem sung by people across the world can inspire planetary consciousness and global citizenship among people.\n\n"}
{"id": "18994022", "url": "https://en.wikipedia.org/wiki?curid=18994022", "title": "Prehistory", "text": "Prehistory\n\nHuman prehistory is the period between the use of the first stone tools 3.3 million years ago by hominins and the invention of writing systems. The earliest writing systems appeared 5,300 years ago, but it took thousands of years for writing to be widely adopted and it was not used in some human cultures until the 19th century or even until present. The end of prehistory therefore came at very different dates in different places, and the term is less often used in discussing societies where prehistory ended relatively recently.\n\nSumer in Mesopotamia, the Indus valley civilization and ancient Egypt were the first civilizations to develop their own scripts, and to keep historical records; this took place already during the early Bronze Age. Neighboring civilizations were the first to follow. Most other civilizations reached the end of prehistory during the Iron Age. The three-age system of division of prehistory into the Stone Age, followed by the Bronze Age and Iron Age, remains in use for much of Eurasia and North Africa, but is not generally used in those parts of the world where the working of hard metals arrived abruptly with contact with Eurasian cultures, such as the Americas, Oceania, Australasia and much of Sub-Saharan Africa. These areas also, with some exceptions in Pre-Columbian civilizations in the Americas, did not develop complex writing systems before the arrival of Eurasians, and their prehistory reaches into relatively recent periods; for example 1788 is usually taken as the end of the prehistory of Australia. \n\nThe period when a culture is written about by others, but has not developed its own writing is often known as the protohistory of the culture. By definition, there are no written records from human prehistory, so dating of prehistoric materials is crucial. Clear techniques for dating were not well-developed until the 19th century.\n\nThis article is concerned with human prehistory, the time since behaviorally and anatomically modern humans first appeared until the beginning of recorded history. Earlier periods are also called \"prehistoric\"; there are separate articles for the overall history of the Earth and the history of life before humans.\n\n\nThe notion of \"prehistory\" began to surface during the Enlightenment in the work of antiquarians who used the word 'primitive' to describe societies that existed before written records. The first use of the word prehistory in English, however, occurred in the \"Foreign Quarterly Review\" in 1836.\n\nThe use of the geologic time scale for pre-human time periods, and of the three-age system for human prehistory, is a system that emerged during the late nineteenth century in the work of British, German and Scandinavian archeologists, antiquarians and anthropologists.\n\nThe main source for prehistory is archaeology, but some scholars are beginning to make more use of evidence from the natural and social sciences. This view has been articulated by advocates of deep history.\n\nThe primary researchers into human prehistory are archaeologists and physical anthropologists who use excavation, geologic and geographic surveys, and other scientific analysis to reveal and interpret the nature and behavior of pre-literate and non-literate peoples. Human population geneticists and historical linguists are also providing valuable insight for these questions. Cultural anthropologists help provide context for societal interactions, by which objects of human origin pass among people, allowing an analysis of any article that arises in a human prehistoric context. Therefore, data about prehistory is provided by a wide variety of natural and social sciences, such as paleontology, biology, archaeology, palynology, geology, archaeoastronomy, comparative linguistics, anthropology, molecular genetics and many others.\n\nHuman prehistory differs from history not only in terms of its chronology but in the way it deals with the activities of archaeological cultures rather than named nations or individuals. Restricted to material processes, remains and artifacts rather than written records, prehistory is anonymous. Because of this, reference terms that prehistorians use, such as Neanderthal or Iron Age are modern labels with definitions sometimes subject to debate.\n\nThe concept of a \"Stone Age\" is found useful in the archaeology of most of the world, though in the archaeology of the Americas it is called by different names and begins with a Lithic stage, or sometimes Paleo-Indian. The sub-divisions described below are used for Eurasia, and not consistently across the whole area. \n\n\"Palaeolithic\" means \"Old Stone Age\", and begins with the first use of stone tools. The Paleolithic is the earliest period of the Stone Age.\n\nThe early part of the Palaeolithic is called the Lower Palaeolithic, which predates \"Homo sapiens\", beginning with \"Homo habilis\" (and related species) and with the earliest stone tools, dated to around 2.5 million years ago. Evidence of control of fire by early humans during the Lower Palaeolithic Era is uncertain and has at best limited scholarly support. The most widely accepted claim is that \"H. erectus\" or \"H. ergaster\" made fires between 790,000 and 690,000 BP (before the present period) in a site at Bnot Ya'akov Bridge, Israel. The use of fire enabled early humans to cook food, provide warmth, and have a light source at night.\n\nEarly \"Homo sapiens\" originated some 200,000 years ago, ushering in the Middle Palaeolithic. Anatomic changes indicating modern language capacity also arise during the Middle Palaeolithic. During the Middle Palaeolithic Era, there is the first definitive evidence of human use of fire. Sites in Zambia have charred bone and wood that have been dated to 61,000 B.P. The systematic burial of the dead, music, early art, and the use of increasingly sophisticated multi-part tools are highlights of the Middle Paleolithic.\n\nThroughout the Palaeolithic, humans generally lived as nomadic hunter-gatherers. Hunter-gatherer societies tended to be very small and egalitarian, though hunter-gatherer societies with abundant resources or advanced food-storage techniques sometimes developed sedentary lifestyles with complex social structures such as chiefdoms, and social stratification. Long-distance contacts may have been established, as in the case of Indigenous Australian \"highways\" known as songlines.\n\nThe \"Mesolithic\", or \"Middle Stone Age\" (from the Greek \"mesos\", \"middle\", and \"lithos\", \"stone\") was a period in the development of human technology between the Palaeolithic and Neolithic periods of the Stone Age.\n\nThe Mesolithic period began at the end of the Pleistocene epoch, some 10,000 BP, and ended with the introduction of agriculture, the date of which varied by geographic region. In some areas, such as the Near East, agriculture was already underway by the end of the Pleistocene, and there the Mesolithic is short and poorly defined. In areas with limited glacial impact, the term \"Epipalaeolithic\" is sometimes preferred.\n\nRegions that experienced greater environmental effects as the last ice age ended have a much more evident Mesolithic era, lasting millennia. In Northern Europe, societies were able to live well on rich food supplies from the marshlands fostered by the warmer climate. Such conditions produced distinctive human behaviours that are preserved in the material record, such as the Maglemosian and Azilian cultures. These conditions also delayed the coming of the Neolithic until as late as 4000 BCE (6,000 BP) in northern Europe.\n\nRemains from this period are few and far between, often limited to middens. In forested areas, the first signs of deforestation have been found, although this would only begin in earnest during the Neolithic, when more space was needed for agriculture.\n\nThe Mesolithic is characterized in most areas by small composite flint tools — microliths and microburins. Fishing tackle, stone adzes and wooden objects, e.g. canoes and bows, have been found at some sites. These technologies first occur in Africa, associated with the Azilian cultures, before spreading to Europe through the Ibero-Maurusian culture of Northern Africa and the Kebaran culture of the Levant. Independent discovery is not always ruled out.\n\n\"Neolithic\" means \"New Stone Age.\" Although there were several species of human beings during the Paleolithic, by the Neolithic only \"Homo sapiens sapiens\" remained. (\"Homo floresiensis\" may have survived right up to the very dawn of the Neolithic, about 12,200 years ago.) This was a period of primitive technological and social development. It began about 10,200 BCE in some parts of the Middle East, and later in other parts of the world and ended between 4,500 and 2,000 BCE. The Neolithic is a progression of behavioral and cultural characteristics and changes, including the use of wild and domestic crops and of domesticated animals.\n\nEarly Neolithic farming was limited to a narrow range of plants, both wild and domesticated, which included einkorn wheat, millet and spelt, and the keeping of dogs, sheep and goats. By about 6,900–6,400 BCE, it included domesticated cattle and pigs, the establishment of permanently or seasonally inhabited settlements, and the use of pottery. The Neolithic period saw the development of early villages, agriculture, animal domestication, tools and the onset of the earliest recorded incidents of warfare. The Neolithic era commenced with the beginning of farming, which produced the \"Neolithic Revolution\". It ended when metal tools became widespread (in the Copper Age or Bronze Age; or, in some geographical regions, in the Iron Age).The term \"Neolithic\" is commonly used in the Old World, as its application to cultures in the Americas and Oceania that did not fully develop metal-working technology raises problems.\n\nSettlements became more permanent with some having circular houses with single rooms made of mudbrick. Settlements might have a surrounding stone wall to keep domesticated animals in and protect the inhabitants from other tribes. Later settlements have rectangular mud-brick houses where the family lived together in single or multiple rooms. Burial findings suggest an ancestor cult where people preserved skulls of the dead. The Vinča culture may have created the earliest system of writing. The megalithic temple complexes of Ġgantija are notable for their gigantic structures. Although some late Eurasian Neolithic societies formed complex stratified chiefdoms or even states, states evolved in Eurasia only with the rise of metallurgy, and most Neolithic societies on the whole were relatively simple and egalitarian. Most clothing appears to have been made of animal skins, as indicated by finds of large numbers of bone and antler pins which are ideal for fastening leather. Wool cloth and linen might have become available during the later Neolithic, as suggested by finds of perforated stones that (depending on size) may have served as spindle whorls or loom weights.\n\nIn Old World archaeology, the \"Chalcolithic\", \"Eneolithic\" or \"Copper Age\" refers to a transitional period where early copper metallurgy appeared alongside the widespread use of stone tools. During this period, some weapons and tools were made of copper. This period was still largely Neolithic in character. It is a phase of the Bronze Age before it was discovered that adding tin to copper formed the harder bronze. The Copper Age was originally defined as a transition between the Neolithic and the Bronze Age. However, because it is characterized by the use of metals, the Copper Age is considered a part of the Bronze Age rather than the Stone Age.\n\nAn archaeological site in Serbia contains the oldest securely dated evidence of copper making at high temperature, from 7,500 years ago. The find in June 2010 extends the known record of copper smelting by about 800 years, and suggests that copper smelting may have been invented in separate parts of Asia and Europe at that time rather than spreading from a single source. The emergence of metallurgy may have occurred first in the Fertile Crescent, where it gave rise to the Bronze Age in the 4th millennium BCE (the traditional view), though finds from the Vinča culture in Europe have now been securely dated to slightly earlier than those of the Fertile Crescent. Timna Valley contains evidence of copper mining 9,000 to 7,000 years ago. The process of transition from Neolithic to Chalcolithic in the Middle East is characterized in archaeological stone tool assemblages by a decline in high quality raw material procurement and use. North Africa and the Nile Valley imported its iron technology from the Near East and followed the Near Eastern course of Bronze Age and Iron Age development. However the Iron Age and Bronze Age occurred simultaneously in much of Africa.\n\nThe Bronze Age is the earliest period in which some civilizations have reached the end of prehistory, by introducing written records. The Bronze Age or parts thereof are thus considered to be part of prehistory only for the regions and civilizations who adopted or developed a system of keeping written records during later periods. The invention of writing coincides in some areas with the early beginnings of the Bronze Age. Soon after the appearance of writing, people started creating texts including written accounts of events and records of administrative matters.\n\nThe term Bronze Age refers to a period in human cultural development when the most advanced metalworking (at least in systematic and widespread use) included techniques for smelting copper and tin from naturally occurring outcroppings of ores, and then combining them to cast bronze. These naturally occurring ores typically included arsenic as a common impurity. Copper/tin ores are rare, as reflected in the fact that there were no tin bronzes in Western Asia before 3000 BCE. The Bronze Age forms part of the three-age system for prehistoric societies. In this system, it follows the Neolithic in some areas of the world.\n\nWhile copper is a common ore, deposits of tin are rare in the Old World, and often had to be traded or carried considerable distances from the few mines, stimulating the creation of extensive trading routes. In many areas as far apart as China and England, the valuable new material was used for weapons but for a long time apparently not available for agricultural tools. Much of it seems to have been hoarded by social elites, and sometimes deposited in extravagant quantities, from Chinese ritual bronzes and Indian copper hoards to European hoards of unused axe-heads.\n\nBy the end of the Bronze Age large states, which are often called empires, had arisen in Egypt, China, Anatolia (the Hittites) and Mesopotamia, all of them literate.\n\nThe Iron Age is not part of prehistory for all civilizations who had introduced written records during the Bronze Age. Most remaining civilizations did so during the Iron Age, often through conquest by the empires, which continued to expand during this period. For example, in most of Europe conquest by the Roman Empire means that the term Iron Age is replaced by \"Roman\", \"Gallo-Roman\" and similar terms after the conquest.\n\nIn archaeology, the Iron Age refers to the advent of ferrous metallurgy. The adoption of iron coincided with other changes in some past cultures, often including more sophisticated agricultural practices, religious beliefs and artistic styles, which makes the archaeological Iron Age coincide with the \"Axial Age\" in the history of philosophy. Although iron ore is common, the metalworking techniques necessary to use iron are very different from those needed for the metal used earlier, and iron was slow-spreading and for long mainly used for weapons, while bronze remained typical for tools, as well as art.\n\nAll dates are approximate and conjectural, obtained through research in the fields of anthropology, archaeology, genetics, geology, or linguistics. They are all subject to revision due to new discoveries or improved calculations. BP stands for \"Before Present (1950).\" BCE stands for Before Common Era\".\n\n\n\n\n\n\n"}
{"id": "4584893", "url": "https://en.wikipedia.org/wiki?curid=4584893", "title": "Revolutions of 1989", "text": "Revolutions of 1989\n\nThe Revolutions of 1989 formed part of a revolutionary wave in the late 1980s and early 1990s that resulted in the end of communist rule in Central and Eastern Europe and beyond. The period is sometimes called the Autumn of Nations, a play on the term Spring of Nations that is sometimes used to describe the Revolutions of 1848.\n\nThe events of the full-blown revolution first began in Poland in 1989 and continued in Hungary, East Germany, Bulgaria, Czechoslovakia and Romania. One feature common to most of these developments was the extensive use of campaigns of civil resistance, demonstrating popular opposition to the continuation of one-party rule and contributing to the pressure for change. Romania was the only Eastern Bloc country whose citizens overthrew its Communist regime violently. Protests in Tiananmen Square (April–June 1989) failed to stimulate major political changes in China, but influential images of courageous defiance during that protest helped to precipitate events in other parts of the globe. On 4 June 1989, the trade union Solidarity won an overwhelming victory in a partially free election in Poland, leading to the peaceful fall of Communism in that country in the summer of 1989. Also in June 1989, Hungary began dismantling its section of the physical Iron Curtain, leading to an exodus of East Germans through Hungary, which destabilised East Germany. This led to mass demonstrations in cities such as Leipzig and subsequently to the fall of the Berlin Wall in November 1989, which served as the symbolic gateway to German reunification in 1990.\n\nThe Soviet Union dissolved in December 1991, resulting in eleven new countries (Armenia, Azerbaijan, Belarus, Georgia, Kazakhstan, Kyrgyzstan, Moldova, Russia, Tajikistan, Turkmenistan, Ukraine and Uzbekistan) which had declared their independence from the Soviet Union in the course of the year while the Baltic states (Estonia, Latvia and Lithuania) regained their independence in September 1991. The rest of the Soviet Union, which constituted the bulk of the area, became the Russian Federation in December 1991. Albania and Yugoslavia abandoned Communism between 1990 and 1992. By 1992, Yugoslavia had split into five successor states, namely Bosnia and Herzegovina, Croatia, Macedonia, Slovenia and the Federal Republic of Yugoslavia, which was later renamed Serbia and Montenegro in 2003 and eventually split in 2006 into two states, namely Serbia and Montenegro. Serbia was then further split with the breakaway of the partially recognised state of Kosovo in 2008. Czechoslovakia dissolved three years after the end of Communist rule, splitting peacefully into the Czech Republic and Slovakia in 1992. The impact of these events made itself felt in several Socialist countries. Communism was abandoned in countries such as Cambodia (1991), Ethiopia (1990), Mongolia (which in 1990 democratically re-elected a Communist government that ran the country until 1996) and South Yemen (1990).\n\nDuring the adoption of varying forms of market economy, there was a general decline in living standards for many former Communist countries. Political reforms were varied, but in only four countries were Communist parties able to retain a monopoly on power, namely China, Cuba, Laos and Vietnam (North Korea went through a constitutional change in 2009 that made it nominally no longer Communist, but still \"de facto\" organised on Stalinist lines). Many communist and socialist organisations in the West turned their guiding principles over to social democracy and democratic socialism. Communist parties in Italy and San Marino suffered and the reformation of the Italian political class took place in the early 1990s. In South America, the Pink tide had instead begun, starting with Venezuela in 1999 and sweeping through the early 2000s. The European political landscape changed drastically, with several former Eastern Bloc countries joining NATO and the European Union, resulting in stronger economic and social integration with Western Europe and the United States.\n\nSocialism had been gaining momentum among working class citizens of the world since the 19th century. These culminated in the early 20th century when several states and colonies formed their own communist parties. Many of the countries involved had hierarchical structures with monarchic governments and aristocratic social structures with an established nobility. Socialism was undesirable within the circles of the ruling classes (which had begun to include industrial business leaders) in the late 19th/early 20th century states; as such, communism was repressed. Its champions suffered persecution while people were discouraged from adopting it. This had been the practice even in states which identified as exercising a multi-party system.\n\nThe Russian Revolution of 1917 saw the first communist state in the Union of Soviet Socialist Republics (USSR), when the Bolsheviks overthrew the provisional government.\n\nDuring the period between the world wars, communism had been on the rise in many parts of the world, especially in towns and cities. This led to a series of purges in many countries to stifle the movement. Violent resistance to this repression led to an increase in support for communism in Central and Eastern Europe.\n\nIn the early stages of World War II, both Nazi Germany and the USSR invaded and occupied the countries of Eastern Europe after the Molotov–Ribbentrop Pact. Germany then turned against and invaded the USSR: the battles of this Eastern Front were the largest in history. The USSR joined with the Allies and in conferences at Tehran and Yalta, the Allies agreed that Central and Eastern Europe would be in the \"Soviet sphere of political influence.\". The USSR fought the Germans to a standstill and finally began driving them back, reaching Berlin before the end of the war. Nazi ideology was violently anti-communist, and the Nazis brutally suppressed communist movements in the countries it occupied. Communists played a large part in the resistance to the Nazis in these countries. As the Soviets forced the Germans back, they assumed temporary control of these devastated areas.\n\nAfter World War II, the Soviets ensured that communists loyal to Moscow took power in the countries it occupied. The Soviets retained troops throughout these territories. The Cold War saw these states, bound together by the Warsaw Pact, have continuing tensions with the capitalist west, bound together by NATO. The Chinese Revolution established communism in China in 1949.\n\nDuring the Hungarian Revolution of 1956, a spontaneous nationwide anti-authoritarian revolt, the Soviet Union invaded Hungary to assert control. Similarly, in 1968, the USSR repressed the Prague Spring by organizing the Warsaw Pact invasion of Czechoslovakia.\n\nLabour turmoil in Poland during 1980 had led to the formation of the independent trade union, Solidarity, led by Lech Wałęsa, which over time became a political force. On 13 December 1981, Polish Prime Minister Wojciech Jaruzelski started a crackdown on Solidarity by declaring martial law in Poland, suspending the union, and temporarily imprisoning all of its leaders.\n\nAlthough several Eastern bloc countries had attempted some abortive, limited economic and political reform since the 1950s (e.g. the Hungarian Revolution of 1956 and Prague Spring of 1968), the ascension of reform-minded Soviet leader Mikhail Gorbachev in 1985 signaled the trend toward greater liberalization. During the mid-1980s, a younger generation of Soviet apparatchiks, led by Gorbachev, began advocating fundamental reform in order to reverse years of Brezhnev stagnation. After decades of growth, the Soviet Union was now facing a period of severe economic decline and needed Western technology and credits to make up for its increasing backwardness. The costs of maintaining its military, the KGB, subsidies to foreign client states etc., further strained the moribund Soviet economy.\n\nThe first signs of major reform came in 1986 when Gorbachev launched a policy of \"glasnost\" (openness) in the Soviet Union, and emphasized the need for \"perestroika\" (economic restructuring). By the spring of 1989, the Soviet Union had not only experienced lively media debate, but had also held its first multi-candidate elections in the newly established Congress of People's Deputies. While glasnost ostensibly advocated openness and political criticism, these were only permitted within a narrow spectrum dictated by the state. The general public in the Eastern bloc was still subject to secret police and political repression.\n\nGorbachev urged his Central and Southeast European counterparts to imitate \"perestroika\" and \"glasnost\" in their own countries. However, while reformists in Hungary and Poland were emboldened by the force of liberalization spreading from the east, other Eastern bloc countries remained openly skeptical and demonstrated aversion to reform. Believing Gorbachev's reform initiatives would be short-lived, hardline communist rulers like East Germany's Erich Honecker, Bulgaria's Todor Zhivkov, Czechoslovakia's Gustáv Husák and Romania's Nicolae Ceauşescu obstinately ignored the calls for change. \"When your neighbor puts up new wallpaper, it doesn't mean you have to too,\" declared one East German politburo member.\n\nBy the late 1980s, people in the Caucasus and Baltic states were demanding more autonomy from Moscow, and the Kremlin was losing some of its control over certain regions and elements in the Soviet Union. In November 1988, the Estonian Soviet Socialist Republic issued a declaration of sovereignty, which would eventually lead to other states making similar declarations of autonomy.\n\nThe Chernobyl disaster in April 1986 had major political and social effects that catalyzed or at least partially caused the revolutions of 1989. One political result of the disaster was the greatly increased significance of the new Soviet policy of glasnost. It is difficult to establish the total economic cost of the disaster. According to Gorbachev, the Soviet Union spent 18 billion rubles (the equivalent of US$18 billion at that time) on containment and decontamination, virtually bankrupting itself.\n\nIn February 1986, in one of the first peaceful, mass-movement revolutions against a dictatorship, the People Power Revolution in the Philippines peacefully overthrew dictator Ferdinand Marcos and inaugurated Cory Aquino as president.\n\nThe domino effect of the revolutions of 1989 affected other regimes as well. The South African apartheid regime and Pinochet's military dictatorship in Chile were gradually dismantled during the 1990s as the West withdrew their funding and diplomatic support. Argentina, Ghana, Indonesia, Nicaragua, South Korea, Suriname, Republic of China (Taiwan), and North and South Yemen, among many others, elected democratic governments.\n\nExact tallies of the number of democracies vary depending on the criteria used for assessment, but by some measures by the late 1990s there were well over 100 democracies in the world, a marked increase in just a few decades.\n\nThroughout the mid-1980s, Solidarity persisted solely as an underground organization, supported by the Catholic Church. However, by the late 1980s, Solidarity became sufficiently strong to frustrate Jaruzelski's attempts at reform, and nationwide strikes in 1988 forced the government to open dialogue with Solidarity. On 9 March 1989, both sides agreed to a bicameral legislature called the National Assembly. The already existing Sejm would become the lower house. The Senate would be elected by the people. Traditionally a ceremonial office, the presidency was given more powers (Polish Round Table Agreement).\n\nBy 1989, the Soviet Union had repealed the Brezhnev Doctrine in favor of non-intervention in the internal affairs of its Warsaw Pact allies, termed the Sinatra Doctrine in a joking reference to the Frank Sinatra song \"My Way\". Poland became the first Warsaw Pact country to break free of Soviet domination.\n\nNew Chinese leader Deng Xiaoping (1982–1987) developed the concept of socialism with Chinese characteristics and local market economy around 1984, but the policy stalled.\n\nThe first Chinese student demonstrations, which directly preceded the Beijing protests of 1989, took place in December 1986 in Hefei. The students called for campus elections, the chance to study abroad and greater availability of Western pop culture. Their protests took advantage of the loosening political atmosphere and included rallies against the slow pace of reform. Hu Yaobang, a protégé of Deng Xiaoping and a leading advocate of reform, was blamed for the protests and forced to resign as the CCP general secretary in January 1987. In the \"Anti Bourgeois Liberalization Campaign\", Hu would be further denounced.\n\nThe Tiananmen Square protests were sparked by the death of Hu Yaobang on 15 April 1989. By the eve of Hu's state funeral, some 100,000 students had gathered at Tiananmen Square to observe it; however, no leaders emerged from the Great Hall. The movement lasted for seven weeks.\n\nGorbachev's visit to China on 15 May during the protests brought many foreign news agencies to Beijing, and their sympathetic portrayals of the protesters helped galvanize a spirit of liberation among the Central, South-East and Eastern Europeans who were watching. The Chinese leadership, particularly Communist Party general secretary Zhao Ziyang, having begun earlier than the Soviets to radically reform the economy, was open to political reform, but not at the cost of a potential return to the disorder of the Cultural Revolution.\n\nThe movement lasted from Hu's death on 15 April until tanks rolled into Tiananmen Square on 4 June 1989. In Beijing, the military response to the protest by the PRC government left many civilians in charge of clearing the square of the dead and severely injured. The exact number of casualties is not known and many different estimates exist.\n\nOn 7 July 1989, President Mikhail Gorbachev implicitly renounced the use of force against other Soviet-bloc nations. Speaking to members of the 23-nation Council of Europe, Mr. Gorbachev made no direct reference to the so-called Brezhnev Doctrine, under which Moscow has asserted the right to use force to prevent a Warsaw Pact member from leaving the Communist fold, but stated 'Any interference in domestic affairs and any attempts to restrict the sovereignty of states—friends, allies or any others—are inadmissible.\n\nA wave of strikes hit Poland in April and May 1988, and a second wave began on 15 August that year when a strike broke out at the July Manifesto coal mine in Jastrzębie-Zdrój, the workers demanding the re-legalisation of Solidarity. Over the next few days, sixteen other mines went on strike followed by a number of shipyards, including on 22 August, the Gdansk Shipyard, famous as the epicentre of the 1980 industrial unrest that spawned Solidarity. On 31 August 1988 Lech Wałęsa, the leader of Solidarity, was invited to Warsaw by the Communist authorities, who had finally agreed to talks. On 18 January 1989 at a stormy session of the Tenth Plenary Session of the ruling United Workers' Party, General Wojciech Jaruzelski, the First Secretary, managed to get party backing for formal negotiations with Solidarity leading to its future legalisation, although this was achieved only by threatening the resignation of the entire party leadership if thwarted. On 6 February 1989 formal Round Table discussions began in the Hall of Columns in Warsaw. On 4 April 1989 the historic Round Table Agreement was signed legalising Solidarity and setting up partly free parliamentary elections to be held on 4 June 1989 (incidentally, the day following the midnight crackdown on Chinese protesters in Tiananmen Square). A political earthquake followed. The victory of Solidarity surpassed all predictions. Solidarity candidates captured all the seats they were allowed to compete for in the Sejm, while in the Senate they captured 99 out of the 100 available seats (with the one remaining seat taken by an independent candidate). At the same time, many prominent Communist candidates failed to gain even the minimum number of votes required to capture the seats that were reserved for them.\n\nOn 15 August 1989, the Communists' two longtime coalition partners, the United People's Party (ZSL) and the Democratic Party (SD), broke their alliance with the PZPR and announced their support for Solidarity. The last Communist Prime Minister of Poland, General Czesław Kiszczak, said he would resign to allow a non-Communist to form an administration. As Solidarity was the only other political grouping that could possibly form a government, it was virtually assured that a Solidarity member would become prime minister. On 19 August 1989, in a stunning watershed moment, Tadeusz Mazowiecki, an anti-Communist editor, Solidarity supporter, and devout Catholic, was nominated as Prime Minister of Poland and the Soviet Union voiced no protest. Five days later, on 24 August 1989, Poland's Parliament ended more than 40 years of one-party rule by making Mazowiecki the country's first non-Communist Prime Minister since the early postwar years. In a tense Parliament, Mazowiecki received 378 votes, with 4 against and 41 abstentions. On 13 September 1989, a new non-Communist government was approved by parliament, the first of its kind in the Eastern Bloc. On 17 November 1989 the statue of Felix Dzerzhinsky, Polish founder of the Cheka and symbol of Communist oppression, was torn down in Bank Square, Warsaw. On 29 December 1989 the Sejm amended the constitution to change the official name of the country from the People's Republic of Poland to the Republic of Poland. The communist Polish United Workers' Party dissolved itself on 29 January 1990 and transformed itself into the Social Democracy of the Republic of Poland.\n\nIn 1990, Jaruzelski resigned as Poland's president and was succeeded by Wałęsa, who won the 1990 presidential elections held in two rounds on 25 November and 9 December. Wałęsa's inauguration as president on 21 December 1990 is thought by many to be the formal end of the Communist People's Republic of Poland and the beginning of the modern Republic of Poland. The Warsaw Pact was dissolved on 1 July 1991. On 27 October 1991 the first entirely free Polish parliamentary elections since 1945 took place. This completed Poland's transition from Communist Party rule to a Western-style liberal democratic political system. The last Russian troops left Poland on 18 September 1993.\n\nFollowing Poland's lead, Hungary was next to switch to a non-Communist government. Although Hungary had achieved some lasting economic reforms and limited political liberalization during the 1980s, major reforms only occurred following the replacement of János Kádár as General Secretary of the Communist Party on 23 May 1988 with Károly Grósz. On 24 November 1988 Miklós Németh was appointed Prime Minister. On 12 January 1989, the Parliament adopted a \"democracy package\", which included trade union pluralism; freedom of association, assembly, and the press; a new electoral law; and a radical revision of the constitution, among others. On 29 January 1989, contradicting the official view of history held for more than 30 years, a member of the ruling Politburo, Imre Pozsgay, declared that Hungary's 1956 rebellion was a popular uprising rather than a foreign-instigated attempt at counterrevolution.\nMass demonstrations on 15 March, the National Day, persuaded the regime to begin negotiations with the emergent non-Communist political forces. Round Table talks began on 22 April and continued until the Round Table agreement was signed on 18 September. The talks involved the Communists (MSzMP) and the newly emerging independent political forces Fidesz, the Alliance of Free Democrats (SzDSz), the Hungarian Democratic Forum (MDF), the Independent Smallholders' Party, the Hungarian People's Party, the Endre Bajcsy-Zsilinszky Society, and the Democratic Trade Union of Scientific Workers. At a later stage the Democratic Confederation of Free Trade Unions and the Christian Democratic People's Party (KDNP) were invited. It was at the talks that a number of Hungary's future political leaders emerged, including László Sólyom, József Antall, György Szabad, Péter Tölgyessy and Viktor Orbán.\n\nOn 2 May 1989, the first visible cracks in the Iron Curtain appeared when Hungary began dismantling its long border fence with Austria. This increasingly destabilized the GDR and Czechoslovakia over the summer and autumn as thousands of their citizens illegally crossed over to the West through the Hungarian-Austrian border. On 1 June 1989 the Communist Party admitted that former Prime Minister Imre Nagy, hanged for treason for his role in the 1956 Hungarian uprising, was executed illegally after a show trial. On 16 June 1989 Nagy was given a solemn funeral on Budapest's largest square in front of crowds of at least 100,000, followed by a hero's burial.\n\nThe Round Table agreement of 18 September encompassed six draft laws that covered an overhaul of the Constitution, establishment of a Constitutional Court, the functioning and management of political parties, multiparty elections for National Assembly deputies, the penal code and the law on penal procedures (the last two changes represented an additional separation of the Party from the state apparatus). The electoral system was a compromise: about half of the deputies would be elected proportionally and half by the majoritarian system. A weak presidency was also agreed upon, but no consensus was attained on who should elect the president (parliament or the people) and when this election should occur (before or after parliamentary elections). On 7 October 1989, the Communist Party at its last congress re-established itself as the Hungarian Socialist Party. In a historic session from 16 to 20 October, the parliament adopted legislation providing for multi-party parliamentary elections and a direct presidential election, which took place on March 24, 1990. The legislation transformed Hungary from a People's Republic into the Republic of Hungary, guaranteed human and civil rights, and created an institutional structure that ensured separation of powers among the judicial, legislative, and executive branches of government. On 23 October 1989, on the 33rd anniversary of the 1956 Revolution, the Communist regime in Hungary was formally abolished. The Soviet military occupation of Hungary, which had persisted since World War II, ended on 19 June 1991.\n\nOn 2 May 1989, Hungary started dismantling its barbed-wire border with Austria, opening a large hole through the Iron Curtain to the West that was used by a growing number of East Germans. By the end of September 1989, more than 30,000 East Germans had escaped to the West before the GDR denied travel to Hungary, leaving the CSSR (Czechoslovakia) as the only neighboring state where East Germans could escape to. Thousands of East Germans tried to reach the West by occupying the West German diplomatic facilities in other Central and Eastern European capitals, notably the Prague Embassy and the Hungarian Embassy where thousands camped in the muddy garden from August to November waiting for German political reform. The GDR closed the border to the CSSR on 3 October, thereby isolating itself from all neighbors. Having been shut off from their last chance for escape, an increasing number of East Germans participated in the Monday demonstrations in Leipzig on 4, 11, and 18 September, each attracting 1,200 to 1,500 demonstrators; many were arrested and beaten. However, the people refused to be intimidated. On 25 September, the protests attracted 8,000 demonstrators.\n\nAfter the fifth successive Monday demonstration in Leipzig on 2 October attracted 10,000 protesters, Socialist Unity Party (SED) leader Erich Honecker issued a \"shoot and kill\" order to the military. Communists prepared a huge police, militia, Stasi, and work-combat troop presence and there were rumors a Tiananmen Square-style massacre was being planned for the following Monday's demonstration on 9 October.\n\nOn 6 and 7 October, Mikhail Gorbachev visited East Germany to mark the 40th anniversary of the German Democratic Republic, and urged the East German leadership to accept reform. A famous quote of his is rendered in German as \"Wer zu spät kommt, den bestraft das Leben\" (\"He who is too late is punished by life\"). However, Honecker remained opposed to internal reform, with his regime even going so far as forbidding the circulation of Soviet publications that it viewed as subversive.\n\nIn spite of rumors that the Communists were planning a massacre on 9 October, 70,000 citizens demonstrated in Leipzig that Monday, and the authorities on the ground refused to open fire. This victory of the people facing down the Communists' guns encouraged more citizens to take to the streets. The following Monday, 16 October, 120,000 people demonstrated on the streets of Leipzig.\n\nErich Honecker had hoped that the Soviet troops stationed in the GDR, as by the Warsaw Pact, would restore the communist government and suppress the civilian protests. By 1989 the Soviet government deemed it impractical for the Soviet Union to continue asserting its control over the Eastern Bloc, and so it took a neutral stance regarding the events happening in East Germany. Soviet troops stationed in eastern Europe were under strict instructions from the Soviet leadership not to intervene in the political affairs of the Eastern Bloc nations and had to remain in their barracks. Faced with ongoing civil unrest, the SED deposed Honecker on 18 October and replaced him with the number-two-man in the regime, Egon Krenz. However, the demonstrations kept growing and on Monday 23 October the Leipzig protesters numbered 300,000 and remained as large the following week. The border to Czechoslovakia was opened again on 1 November, but the Czechoslovak authorities soon let all East Germans travel directly to West Germany without further bureaucratic ado, thus lifting their part of the Iron Curtain on 3 November. On 4 November the authorities decided to authorize a demonstration in Berlin and were faced with the Alexanderplatz demonstration where half a million citizens converged on the capital demanding freedom in the biggest protest the GDR ever witnessed. Unable to stem the ensuing flow of refugees to the West through Czechoslovakia, the East German authorities eventually caved in to public pressure by allowing East German citizens to enter West Berlin and West Germany directly, via existing border points, on 9 November 1989, without having properly briefed the border guards. Triggered by the erratic words of regime spokesman Günter Schabowski in a TV press conference, stating that the planned changes were in effect \"immediately, without delay,\" hundreds of thousands of people took advantage of the opportunity. The guards were quickly overwhelmed by the growing crowds of people demanding to be let out into West Berlin. After receiving no feedback from their superiors, the guards, unwilling to use force, relented and opened the gates to West Berlin. Soon new crossing points were forced open in the Berlin Wall by the people, and sections of the wall were literally torn down as this symbol of oppression was overwhelmed. The bewildered guards were unaware of what was happening and meekly stood by as the East Germans took to the wall with hammers and chisels.\n\nOn 13 November, GDR Prime Minister Willi Stoph and his entire cabinet resigned. A new government was formed under a considerably more liberal Communist, Hans Modrow. On 1 December, the Volkskammer removed the SED's leading role from the constitution of the GDR. On 3 December Krenz resigned as leader of the SED; he resigned as head of state three days later. On 7 December Round Table talks opened between the SED and other political parties. On 16 December 1989, the SED was dissolved and refounded as the SED-PDS, abandoning Marxism-Leninism and becoming a mainstream democratic socialist party.\n\nOn 15 January 1990, the Stasi's headquarters was stormed by protesters. Modrow became the de facto leader of East Germany until free elections were held on 18 March 1990—the first held in that part of Germany since 1933. The SED, renamed the Party of Democratic Socialism, was heavily defeated. Lothar de Maizière of the East German Christian Democratic Union became Prime Minister on 4 April 1990 on a platform of speedy reunification with the West. The two Germanies were reunified on 3 October 1990.\n\nThe Kremlin's willingness to abandon such a strategically vital ally marked a dramatic shift by the Soviet superpower and a fundamental paradigm change in international relations, which until 1989 had been dominated by the East-West divide running through Berlin itself. The last Russian troops left the territory of the former GDR, now part of a reunited Federal Republic of Germany, on 1 September 1994.\n\nThe \"Velvet Revolution\" was a non-violent revolution in Czechoslovakia that saw the overthrow of the Communist government. On 17 November 1989 (Friday), riot police suppressed a peaceful student demonstration in Prague, although controversy continues over whether anyone died that night. That event sparked a series of popular demonstrations from 19 November to late December. By 20 November the number of peaceful protesters assembled in Prague had swelled from 200,000 the previous day to an estimated half-million. Five days later, the Letná Square protest held 800,000 people. On 24 November, the entire Communist Party leadership, including general secretary Miloš Jakeš, resigned. A two-hour general strike, involving all citizens of Czechoslovakia, was successfully held on 27 November.\n\nWith the collapse of other Communist governments, and increasing street protests, the Communist Party of Czechoslovakia announced on 28 November 1989 that it would relinquish power and dismantle the single-party state. Barbed wire and other obstructions were removed from the border with West Germany and Austria in early December. On 10 December, President Gustáv Husák appointed the first largely non-Communist government in Czechoslovakia since 1948, and resigned. Alexander Dubček was elected speaker of the federal parliament on 28 December and Václav Havel the President of Czechoslovakia on 29 December 1989. In June 1990 Czechoslovakia held its first democratic elections since 1946. On 27 June 1991 the last Soviet troops were withdrawn from Czechoslovakia.\n\nIn October and November 1989, demonstrations on ecological issues were staged in Sofia, where demands for political reform were also voiced. The demonstrations were suppressed, but on 10 November 1989 (the day after the Berlin Wall was breached) Bulgaria's long-serving leader Todor Zhivkov was ousted by his Politburo. He was succeeded by a considerably more liberal Communist, former foreign minister Petar Mladenov. Moscow apparently approved the leadership change, as Zhivkov had been opposed to Gorbachev's policies. The new regime immediately repealed restrictions on free speech and assembly, which led to the first mass demonstration on 17 November, as well as the formation of anti-communist movements. Nine of them united as the Union of Democratic Forces (UDF) on 7 December. The UDF was not satisfied with Zhivkov's ouster, and demanded additional democratic reforms, most importantly the removal of the constitutionally mandated leading role of the Bulgarian Communist Party.\n\nMladenov announced on 11 December 1989 that the Communist Party would abandon its monopoly on power, and that multiparty elections would be held the following year. In February 1990, the Bulgarian legislature deleted the portion of the constitution about the \"leading role\" of the Communist Party. Eventually, it was decided that a round table on the Polish model would be held in 1990 and elections held by June 1990. The round table took place from 3 January to 14 May 1990, at which an agreement was reached on the transition to democracy. The Communist Party abandoned Marxism–Leninism in April 1990 and renamed itself as the Bulgarian Socialist Party. In June 1990 the first free elections since 1931 were held, won by the Bulgarian Socialist Party.\n\nAfter having suppressed the Braşov Rebellion in 1987, Nicolae Ceauşescu was re-elected for another five years as leader of the Romanian Communist Party (PCR) in November 1989, signalling that he intended to ride out the anti-Communist uprisings sweeping the rest of Europe. As Ceauşescu prepared to go on a state visit to Iran, his Securitate ordered the arrest and exile of a local Hungarian Calvinist minister, László Tőkés, on 16 December, for sermons offending the regime. Tőkés was seized, but only after serious rioting erupted. Timişoara was the first city to react on 16 December and civil unrest continued for five days.\n\nReturning from Iran, Ceauşescu ordered a mass rally in his support outside Communist Party headquarters in Bucharest on 21 December. However, to his shock the crowd booed and jeered him as he spoke. Years of repressed dissatisfaction boiled to the surface throughout the Romanian populace and even among elements in Ceauşescu's own government, and the demonstrations spread throughout the country.\n\nAt first the security forces obeyed Ceauşescu's orders to shoot protesters. However, on the morning of 22 December, the Romanian military suddenly changed sides. This came after it was announced that defense minister Vasile Milea had committed suicide after being unmasked as a traitor. Believing Milea had actually been murdered, the rank-and-file soldiers went over virtually \"en masse\" to the revolution. Army tanks began moving towards the Central Committee building with crowds swarming alongside them. The rioters forced open the doors of the Central Committee building in an attempt to capture Ceauşescu and his wife, Elena, coming within a few meters of the couple. However, they managed to escape via a helicopter waiting for them on the roof of the building. The revolution resulted in 1,104 deaths. Unlike its kindred parties in the Warsaw Pact, the PCR simply melted away; no present-day Romanian party claiming to be its successor has ever been elected to the legislature since the change of system.\n\nAlthough elation followed the flight of the Ceauşescus, uncertainty surrounded their fate. On Christmas Day, Romanian television showed the Ceauşescus facing a hasty trial, and then undergoing summary execution. An interim National Salvation Front Council led by Ion Iliescu took over and announced elections for April 1990, the first free elections held in Romania since 1937. However, they were postponed until 20 May 1990. Over 1,000 people died during the Romanian Revolution, out of which 100 where children and the youngest was only one month. The Romanian dictator, Nicolae Ceauşescu, and his wife, Elena Ceauşescu, were executed by firing squad after a very brief trial. The Romanian Revolution was the bloodiest of the revolutions of 1989.\n\nMongolia declared independence in 1911 after the collapse of the Qing dynasty. The Mongolian People's Party took power in 1921 and the party renamed itself the Mongolian People's Revolutionary Party. During the years, Mongolia was closely aligned with the Soviet Union. After Yumjaagiin Tsedenbal left in 1984, the new leadership under Jambyn Batmönkh implemented economic reforms, but failed to appeal to those who, in late 1989, wanted broader changes, which led to the \"Mongolian Revolution\", a democratic peaceful revolution that started with demonstrations and hunger strikes that ended 70-years of socialism and eventually moved towards democracy. It was spearheaded by mostly younger people demonstrating on Sükhbaatar Square in the capital Ulaanbaatar. It ended with the authoritarian government resigning without bloodshed. Some of the main organizers were Tsakhiagiin Elbegdorj, Sanjaasürengiin Zorig, Erdeniin Bat-Üül, and Bat-Erdeniin Batbayar.\n\nDuring the period of the morning of 10 December 1989, the first public demonstration occurred in front of the Youth Cultural Center in the capital of Ulaanbaatar. There, Elbegdorj announced the creation of the Mongolian Democratic Union. There the Democratic Union-first pro-democracy movement in Mongolia was born. The protesters called for Mongolia to adopt perestroika and glasnost. Dissident leaders demanded free elections and economic reform, but within the context of a \"human democratic socialism\". The protesters injected a nationalist element into the protests by using traditional Mongolian script—which most Mongolians could not read—as a symbolic repudiation of the political system which had imposed the Mongolian Cyrillic alphabet. In late December 1989, demonstrations increased when news came of Garry Kasparov's interview to \"Playboy\", suggesting that the Soviet Union could improve its economic health by selling Mongolia to China. On 14 January 1990, the protesters, having grown from three hundred to some 1,000, met on square in front of Lenin Museum which was named as Freedom Square since then in Ulaanbaatar. A demonstration on Sükhbaatar Square on 21 January (in weather of -30 C) followed. Protesters carried banners alluding to Chinggis Khaan (also referred to Genghis Khan), rehabilitating a figure which Soviet schooling neglected to praise.\n\nIn subsequent months of 1990, activists continued to organize demonstrations, rallies, protests and hunger strikes, as well as teachers' and workers' strikes. Activists had growing support from Mongolians, both in the capital and the countryside and the union's activities led to other calls for democracy all over the country. After numerous demonstrations of many thousands of people in the capital city as well as provincial centers, on 4 March 1990, the MDU and three other reform organizations held a joint outdoor mass meeting, inviting the government to attend. The government sent no representative to what became a demonstration of over 100,000 people demanding democratic change. This culminated with Jambyn Batmönkh, chairman of Politburo of MPRP's Central Committee decided to dissolve the Politburo and to resign on 9 March 1990.\n\nMongolia's first free, multi-party elections for a bicameral parliament took place on 29 July 1990. Parties ran for 430 seats in the Great Hural. Opposition parties were not able to nominate enough candidates. The opposition nominated 346 candidates for the 430 seats in the Great Hural (upper house). The Mongolian People's Revolutionary Party MPRP won 357 seats in the Great Hural and 31 out of 53 seats in the Small Hural (which was later abolished) as well. The MPRP enjoyed a strong position in the countryside. The State Great Khural first met on 3 September 1990 and elected a president (MPRP), vice president (Social Democrat) who was also a chairman of the Baga Hural, prime minister (MPRP), and 50 members to the Baga Hural (lower house). In November 1991, the People's Great Hural began discussion on a new constitution, which entered into force on 12 February 1992. In addition, the new constitution restructured the legislative branch of government, creating a unicameral legislature, the State Great Hural (SGH). The MPRP retained its majority, but lost the 1996 elections. The final Russian troops, which had stationed in Mongolia in 1966, fully withdrew in December 1992.\n\nThe Socialist Federal Republic of Yugoslavia was not a part of the Warsaw Pact but pursued its own version of \"Communism\" under Josip Broz Tito. It was a multi-ethnic state which Tito was able to maintain through a doctrine of \"Brotherhood and unity\", but tensions between ethnicities began to escalate with the so-called Croatian Spring of 1970–71, a movement for greater Croatian autonomy, which was suppressed. In 1974 there followed constitutional changes, and the 1974 Yugoslav Constitution devolved some of the federal powers to the constituent republics and provinces. After Tito's death in 1980 ethnic tensions grew, first in Albanian-majority SAP Kosovo with the 1981 protests in Kosovo. In the late 1980s Serbian leader Slobodan Milošević used the Kosovo crisis to stoke up Serb nationalism and attempt to consolidate and dominate the country, which alienated the other ethnic groups.\n\nParallel to the same process, SR Slovenia witnessed a policy of gradual liberalization since 1984, somewhat similar to the Soviet Perestroika. This provoked tensions between the League of Communists of Slovenia on one side, and the central Yugoslav Party and the federal army on the other side. By the late 1980s, many civil society groups were pushing towards democratization, while widening the space for cultural plurality. In 1987 and 1988, a series of clashes between the emerging civil society and the Communist regime culminated with the so-called Slovene Spring, a mass movement for democratic reforms. The Committee for the Defence of Human Rights was established as the platform of all major non-Communist political movements. By early 1989, several anti-Communist political parties were already openly functioning, challenging the hegemony of the Slovenian Communists. Soon, the Slovenian Communists, pressured by their own civil society, came into conflict with the Serbian Communist leadership.\n\nIn January 1990, an extraordinary Congress of the League of Communists of Yugoslavia was called in order to settle the disputes among its constituent parties. Faced with being completely outnumbered, the Slovenian and Croatian Communists walked out of the Congress on 23 January 1990, thus effectively bringing to an end the Yugoslav Communist Party. Both parties of the two western republics negotiated free multi-party elections with their own opposition movements.\n\nOn 8 April 1990, the democratic and anti-Yugoslav DEMOS coalition won the elections in Slovenia, while on 24 April 1990 the Croatian elections witnessed the landslide victory of the nationalist Croatian Democratic Union (HDZ) led by Franjo Tuđman. The results were much more balanced in Bosnia and Herzegovina and Macedonia in November 1990, while the parliamentary and presidential elections of December 1990 in Serbia and Montenegro consolidated the power of Milošević and his supporters. Free elections on the level of the federation were never carried out.\n\nThe Slovenian and Croatian leaderships started preparing plans for secession from the federation, while the Serbs of Croatia organized the so-called Log Revolution, an insurrection that would lead to the creation of the breakaway region of SAO Krajina. In the Slovenian independence referendum on 23 December 1990, 88.5% of residents voted for independence. In the Croatian independence referendum on 2 May 1991, 93.24% voted for independence.\n\nThe escalating ethnic and national tensions were exacerbated by the drive for independence and led to the following Yugoslav wars:\n\nIn addition, the insurgency in the Preševo Valley (1999–2001) and the insurgency in the Republic of Macedonia (2001) are also often discussed in the same context.\n\nIn the People's Socialist Republic of Albania, Enver Hoxha, who led Albania for four decades, died on 11 April 1985. His successor, Ramiz Alia, began to gradually open up the regime from above. In 1989, the first revolts started in Shkodra and spread in other cities. Eventually, the existing regime introduced some liberalization, including measures in 1990 providing for freedom to travel abroad. Efforts were begun to improve ties with the outside world. March 1991 elections—the first free elections in Albania since 1923, and only the third free elections in the country's history—left the former Communists in power, but a general strike and urban opposition led to the formation of a coalition cabinet including non-Communists. Albania's former Communists were routed in elections held in March 1992, amid economic collapse and social unrest.\n\nThe Malta Summit consisted of a meeting between U.S. President George H. W. Bush and U.S.S.R. leader Mikhail Gorbachev, taking place between 2–3 December 1989, just a few weeks after the fall of the Berlin Wall, a meeting which contributed to the end of the Cold War partially as a result of the broader pro-democracy movement. It was their second meeting following a meeting that included then President Ronald Reagan, in New York in December 1988. News reports of the time referred to the Malta Summit as the most important since 1945, when British Prime Minister Winston Churchill, Soviet premier Joseph Stalin and U.S. President Franklin D. Roosevelt agreed on a post-war plan for Europe at the Yalta Conference.\n\nBetween June 1989 and April 1991, every Communist or former Communist Central and Eastern European or Asian country—and in the case of the USSR and Yugoslavia every constituent republic—held competitive parliamentary elections for the first time in many decades. Some elections were only partly free, others fully democratic. The chronology below gives the details of these historic elections and the date is the first day of voting as several elections were split over several days for run-off contests:\n\nOn 1 July 1991, the Warsaw Pact was officially dissolved at a meeting in Prague. At a summit later that same month, Gorbachev and Bush declared a US–Soviet strategic partnership, decisively marking the end of the Cold War. President Bush declared that US–Soviet cooperation during the 1990–1991 Gulf War had laid the groundwork for a partnership in resolving bilateral and world problems.\n\nAs the Soviet Union rapidly withdrew its forces from Central and Southeast Europe, the spillover from the 1989 upheavals began reverberating throughout the Soviet Union itself. Agitation for self-determination led to first Lithuania, and then Estonia, Latvia and Armenia declaring independence. However, the Soviet central government demanded the revocation of the declarations and threatened military action and economic sanctions. The government even went as far as controversially sending Red Army troops to the streets of the Lithuanian capital, Vilnius, to suppress the separatist movements in January 1991, causing the deaths of 14 people.\n\nDisaffection in other Soviet republics, such as Georgia and Azerbaijan, was countered by promises of greater decentralization. More open elections led to the election of candidates opposed to Communist Party rule.\n\n\"Glasnost\" had inadvertently released the long-suppressed national sentiments of all peoples within the borders of the multinational Soviet state. These nationalist movements were further strengthened by the rapid deterioration of the Soviet economy, whose ramshackle foundations were exposed with the removal of Communist discipline. Gorbachev's reforms had failed to improve the economy, with the old Soviet command structure completely breaking down. One by one, the constituent republics created their own economic systems and voted to subordinate Soviet laws to local laws. In 1990, the Communist Party was forced to surrender its seven-decade monopoly of political power when the Supreme Soviet rescinded the clause in the Soviet Constitution that guaranteed its sole authority to rule. Gorbachev's policies caused the Communist Party to lose its grip over the media. Details of the Soviet Union's past were quickly being declassified. This caused many to distrust the 'old system' and push for greater autonomy and independence.\n\nAfter a referendum confirmed the preservation of the Soviet Union but in a looser form, a group of Soviet hard-liners represented by Vice-President Gennadi Yanayev launched a coup attempting to overthrow Gorbachev in August 1991. Boris Yeltsin, then president of the Russian SFSR, rallied the people and much of the army against the coup and the effort collapsed. Although restored to power, Gorbachev's authority had been irreparably undermined. Gorbachev resigned as General Secretary of the Communist Party following the coup, and the Supreme Soviet dissolved the Party and banned all Communist activity on Soviet soil. Just a few weeks later, the government granted the Baltic states their independence on 6 September.\n\nOver the next three months, one republic after another declared independence, mostly out of fear of another coup. Also during this time, the Soviet government was rendered useless as the new Russian government began taking over what remained of it, including the Kremlin. The penultimate step came on 1 December, when voters in the second most powerful republic, Ukraine, overwhelmingly voted to secede from the Soviet Union in a referendum. This ended any realistic chance of keeping the Soviet Union together. On 8 December, Yeltsin met with his counterparts from Ukraine and Belarus and signed the Belavezha Accords, declaring that the Soviet Union had ceased to exist. Gorbachev denounced this as illegal, but he had long since lost any ability to influence events outside of Moscow.\n\nTwo weeks later, 11 of the remaining 12 republics—all except Georgia—signed the Alma-Ata Protocol, which confirmed the Soviet Union had been effectively dissolved and replaced by a new voluntary association, the Commonwealth of Independent States. Bowing to the inevitable, Gorbachev resigned as Soviet president on 25 December, and the Supreme Soviet ratified the Belavezha Accords the next day, legally dissolving itself and the Soviet Union as a political entity. By the end of 1991, the few Soviet institutions that hadn't been taken over by Russia had dissolved. The Soviet Union was officially disbanded, breaking up into fifteen constituent parts, thereby ending the world's largest and most influential Socialist state, and leaving to China that position. A constitutional crisis dissolved into violence in Moscow as the Russian Army was called in to reestablish order.\n\nEstonia, Latvia and Lithuania implemented democratic reforms and achieved independence from the Soviet Union.\n\nThe Singing Revolution is a commonly used name for events between 1987 and 1991 that led to the restoration of the independence of Estonia, Latvia and Lithuania. The term was coined by an Estonian activist and artist, Heinz Valk, in an article published a week after the 10–11 June 1988 spontaneous mass night-singing demonstrations at the Tallinn Song Festival Grounds. Estonia declared its sovereignty from the Soviet Union on 16 November 1988. Lithuania followed on 18 May 1989 and Latvia on 28 July 1989. Lithuania declared full independence on 11 March 1990 and on 30 March, Estonia announced the start of a transitional period to independence, followed by Latvia on 4 May. These declarations were met with force from the Soviet Union in early 1991, in confrontations known as the \"January Events\" in Lithuania and \"The Barricades\" in Latvia. The Baltic states contended that their incorporation into the Soviet Union had been illegal under both international law and their own law, and they were reasserting an independence that still legally existed.\n\nSoon after the launching of the August coup, Estonia and Latvia declared full independence. By the time the coup was foiled, the USSR was no longer unified enough to mount a forceful resistance, and it recognized the independence of the Baltic states on 6 September.\n\n\n\nIn Chechnya, using tactics partly copied from the Baltics, anti-Communist coalition forces led by former Soviet general Dzhokhar Dudayev staged a largely bloodless revolution, and ended up forcing the resignation of the Communist republican president. Dudayev was elected in a landslide in the following election and in November 1991 he proclaimed Checheno-Ingushetia's independence as the Republic of Ichkeria. Ingushetia voted to leave the union with Chechnya, and was allowed to do so (thus it became the Chechen Republic of Ichkeria). Due to his desire to exclude Moscow from all oil deals, Yeltsin backed a failed coup against him in 1993. In 1994, Chechnya, with only marginal recognition (one country: Georgia, which was revoked soon after the coup landing Shevardnadze in power), was invaded by Russia, spurring the First Chechen War. The Chechens, with considerable assistance from the populations of both former-Soviet countries and from Sunni Muslim countries repelled this invasion and a peace treaty was signed in 1997. However, Chechnya became increasingly anarchic, largely due to the both political and physical destruction of the state during the invasion, and general Shamil Basaev, having evaded all control by the central government, conducted raids into neighboring Dagestan, which Russia used as pretext for reinvading Ichkeria. Ichkeria was then reincorporated into Russia as Chechnya again, though insurgency continues.\n\n\nRussia was involved in a number of conflicts, including the Nagorno-Karabakh War, the War of Transnistria, the 1991–1992 South Ossetia War, the First Chechen War, the War in Abkhazia, the Ossetian–Ingush conflict, and the Crimea and Donbass conflicts in Ukraine.\n\nReforms in the Soviet Union and its allied countries also saw dramatic changes to Communist and Socialist states outside of Europe.\n\n\n\n\n\n\nMany Soviet-supported political parties and militant groups around the world suffered from demoralization and loss of financing.\n\nConcurrently, many anti-Communist authoritarian states, formerly supported by the US, gradually saw a transition to democracy.\n\nCountries that emerged into socialist-styled governments beyond 1991.\n\nDecommunization is a process of overcoming the legacies of the Communist state establishments, culture, and psychology in the post-Communist states.\n\nDecommunization was largely limited or non-existent. Communist parties were not outlawed and their members were not brought to trial. Just a few places even attempted to exclude members of communist secret services from decision-making. In a number of countries the Communist party simply changed its name and continued to function.\n\nIn several European countries, however, endorsing or attempting to justify crimes committed by Nazi or Communist regimes will be punishable by up to 3 years of imprisonment.\n\nState run enterprises in socialist countries had little or no interest in producing what customers wanted which resulted in shortages of goods and services. In the early 1990s, the general view was that there was no precedent for moving from socialism to capitalism\", and only some elderly people remembered how a market economy worked. As result the view that Central, Southeastern and Eastern Europe would stay poor for decades was common.\n\nThere was a temporary fall of output in the official economy and an increase in black market economic activity.\nCountries implemented different reform programs. One example, generally regarded as successful was the \"shock therapy\" Balcerowicz Plan in Poland. Eventually the official economy began to grow.\n\nIn a 2007 paper, Oleh Havrylyshyn categorized the speed of reforms in the Soviet Bloc:\n\nThe 2004 enlargement of the European Union included the Czech Republic, Estonia, Hungary, Latvia, Lithuania, Poland, Slovakia, and Slovenia. The 2007 enlargement of the European Union included Romania and Bulgaria, and Croatia joined the EU in 2013. The same countries have also become NATO members. In Mongolia, however, its economy was reformed in a similar fashion to the Eastern European counterparts.\n\nChinese economic liberalization started since 1978 have helped lift millions of people out of poverty, bringing the poverty rate down from 53% of the population in the Mao era to 12% in 1981. Deng's economic reforms are still being followed by the CPC today and by 2001 the poverty rate became only 6% of the population.\n\nEconomic liberalization in Vietnam was initiated in 1986, following the Chinese example.\n\nEconomic liberalization in India was initiated in 1991.\n\nHarvard University Professor Richard B. Freeman has called the effect of reforms \"The Great Doubling\". He calculated that the size of the global workforce doubled from 1.46 billion workers to 2.93 billion workers. An immediate effect was a reduced ratio of capital to labor. In the long, term China, India, and the former Soviet bloc will save and invest and contribute to the expansion of the world capital stock.\n\nCompared with the efforts of the other former constituents of the Soviet bloc and the Soviet Union, decommunization in Russia has been restricted to half-measures, if conducted at all. As of 2008, nearly half of Russians viewed Stalin positively, and many supported restoration of his previously dismantled monuments. Neo-Stalinist material such as describing Stalin's mass murder campaigns as \"entirely rational\" has been pushed into Russian textbooks.\n\nIn 1992, President Yeltsin's government invited Vladimir Bukovsky to serve as an expert to testify at the CPSU trial by Constitutional Court of Russia, where the Communists were suing Yeltsin for banning their party. The respondent's case was that the CPSU itself had been an unconstitutional organization. To prepare for his testimony, Bukovsky requested and was granted access to a large number of documents from Soviet archives (then reorganized into TsKhSD). Using a small handheld scanner and a laptop computer, he managed to secretly scan many documents (some with high security clearance), including KGB reports to the Central Committee, and smuggle the files to the West. The event that many expected would be another Nuremberg Trial and the beginnings of reconciliation with the Communist past, ended up in half-measures: while the CPSU was found unconstitutional, the Communists were allowed to form new parties in the future. Bukovsky expressed his deep disappointment with this in his writings and interviews: \"Having failed to finish off conclusively the Communist system, we are now in danger of integrating the resulting monster into our world. It may not be called Communism anymore, but it retained many of its dangerous characteristics... Until the Nuremberg-style tribunal passes its judgment on all the crimes committed by Communism, it is not dead and the war is not over.\"\n\nThe events caught many by surprise. Predictions of the Soviet Union's impending demise had been often dismissed.\n\nBartlomiej Kaminski's book \"The Collapse of State Socialism\" argued that the state Socialist system has a lethal paradox, saying that \"policy actions designed to improve performance only accelerate its decay\".\n\nBy the end of 1989, revolts had spread from one capital to another, ousting the regimes imposed on Central, South-East and Eastern Europe after World War II. Even the isolationist Stalinist regime in Albania was unable to stem the tide. Gorbachev's abrogation of the Brezhnev Doctrine was perhaps the key factor that enabled the popular uprisings to succeed. Once it became evident that the feared Soviet Army would not intervene to crush dissent, the Central, South-East and Eastern European regimes were exposed as vulnerable in the face of popular uprisings against the one-party system and power of secret police.\n\nCoit D. Blacker wrote in 1990 that the Soviet leadership \"appeared to have believed that whatever loss of authority the Soviet Union might suffer in Central and South-East Europe would be more than offset by a net increase in its influence in western Europe.\" Nevertheless, it is unlikely that Gorbachev ever intended for the complete dismantling of Communism and the Warsaw Pact. Rather, Gorbachev assumed that the Communist parties of Central and South-East Europe could be reformed in a similar way to the reforms he hoped to achieve in the CPSU. Just as \"perestroika\" was aimed at making the Soviet Union more efficient economically and politically, Gorbachev believed that the Comecon and Warsaw Pact could be reformed into more effective entities. However, Alexander Yakovlev, a close advisor to Gorbachev, would later state that it would have been \"absurd to keep the system\" in Central and South-East Europe. Yakovlev had come to the conclusion that the Soviet-dominated Comecon could not work on non-market principles and that the Warsaw Pact had \"no relevance to real life.\"\n\n\n\n\n\n"}
{"id": "266344", "url": "https://en.wikipedia.org/wiki?curid=266344", "title": "Space debris", "text": "Space debris\n\nInitially, the term space debris referred to the natural debris found in the solar system: asteroids, comets, and meteoroids. However, with the 1979 beginning of the NASA Orbital Debris Program, the term also refers to the debris (alt. space waste or space garbage) from the mass of defunct, artificially created objects in space, especially Earth orbit. These include old satellites and spent rocket stages, as well as the fragments from their disintegration and collisions. \n\nAs of December 2016, five satellite collisions have generated space debris. Space debris is also known as \"orbital debris\", \"space junk\", \"space waste\", \"space trash\", \"space litter\" or \"space garbage\".\n, the United States Strategic Command tracked a total of 17,852 artificial objects in orbit above the Earth, including 1,419 operational satellites. However, these are just objects large enough to be tracked. , more than 170 million bits of debris smaller than , about 670,000 pieces of debris 1–10 cm, and around 29,000 larger pieces were estimated to be in orbit around the earth. Collisions with debris have become a hazard to spacecraft; they cause damage akin to sandblasting, especially to solar panels and optics like telescopes or star trackers that cannot be covered with a ballistic Whipple shield (unless it is transparent).\n\nBelow Earth-altitude, pieces of debris are denser than meteoroids; most are dust from solid rocket motors, surface erosion debris like paint flakes, and frozen coolant from RORSAT (nuclear-powered satellites). \nFor comparison, the International Space Station orbits in the range, and the 2009 satellite collision and 2007 antisat test occurred at altitude. The ISS has Whipple shielding; however, known debris with a collision chance over 1/10,000 are avoided by maneuvering the station.\n\nThe Kessler syndrome, a runaway chain reaction of collisions exponentially increasing the amount of debris, has been hypothesized to ensue beyond a critical density. This could affect useful polar-orbiting bands, increases the cost of protection for spacecraft missions and could destroy live satellites. Whether Kessler syndrome is already underway has been debated. The measurement, mitigation, and potential removal of debris are conducted by some participants in the space industry.\n\nThere are estimated to be over 51 million pieces of debris smaller than as of July 2013. There are approximately 670,000 pieces from one to ten cm. The current count of large debris (defined as 10 cm across or larger) is 29,000. The technical measurement cutoff is c. . Over 98 percent of the 1,900 tons of debris in low Earth orbit (as of 2002) was accounted for by about 1,500 objects, each over . Total mass is mostly constant despite addition of many smaller objects, since they reenter the atmosphere sooner. Using a 2008 figure of 8,500 known items, it is estimated at .\n\nIn LEO there are few \"universal orbits\" which keep spacecraft in particular rings (in contrast to GEO, a single widely used orbit). The closest are sun-synchronous orbits that keep a constant angle between the Sun and the orbital plane; they are polar, meaning they cross over the polar regions. LEO satellites orbit in many planes, up to 15 times a day, causing frequent approaches between objects (the density of objects is much higher in LEO).\n\nOrbits are further changed by perturbations (which in LEO include unevenness of the Earth's gravitational field), and collisions can occur from any direction. For these reasons, the Kessler syndrome applies mostly to the LEO region; impacts occur at up to 16 km/s (twice the orbital speed) if head-on – the 2009 satellite collision occurred at 11.7 km/s, creating much spall in the critical size range. These can cross other orbits and lead to a cascade effect. A large-enough collision (e.g. between a space station and a defunct satellite) could make low Earth orbit impassable.\n\nManned missions are mostly at and below, where air drag helps clear zones of fragments. Atmospheric expansion as a result of space weather raises the critical altitude by increasing drag; in the 90s, it was a factor in reduced debris density. Another was fewer launches by Russia; the USSR made most of their launches in the 1970s and 1980s.\n\nAt higher altitudes, where air drag is less significant, orbital decay takes longer. Slight atmospheric drag, lunar perturbations, Earth's gravity perturbations, solar wind and solar radiation pressure can gradually bring debris down to lower altitudes (where it decays), but at very high altitudes this may take millennia. Although high-altitude orbits are less commonly used than LEO and the onset of the problem is slower, the numbers progress toward the critical threshold more quickly.\n\nMany communications satellites are in geostationary orbits (GEO), clustering over specific targets and sharing the same orbital path. Although velocities are low between GEO objects, when a satellite becomes derelict (such as Telstar 401) it assumes a geosynchronous orbit; its orbital inclination increases about .8° and its speed increases about per year. Impact velocity peaks at about . Orbital perturbations cause longitude drift of the inoperable spacecraft and precession of the orbital plane. Close approaches (within 50 meters) are estimated at one per year. The collision debris pose less short-term risk than from an LEO collision, but the satellite would likely become inoperable. Large objects, such as solar-power satellites, are especially vulnerable to collisions.\n\nAlthough the ITU now requires proof a satellite can be moved out of its orbital slot at the end of its lifespan, studies suggest this is insufficient. Since GEO orbit is too distant to accurately measure objects under , the nature of the problem is not well known. Satellites could be moved to empty spots in GEO, requiring less maneuvring and making it easier to predict future motion. Satellites or boosters in other orbits, especially stranded in geostationary transfer orbit, are an additional concern due to their typically high crossing velocity.\n\nDespite efforts to reduce risk, spacecraft collisions have occurred. The European Space Agency telecom satellite Olympus-1 was struck by a meteoroid on 11 August 1993 and eventually moved to a graveyard orbit. On 29 March 2006, the Russian Express-AM11 communications satellite was struck by an unknown object and rendered inoperable; its engineers had enough contact time with the satellite to send it into a graveyard orbit.\n\nIn 1958, the United States launched Vanguard I into a medium Earth orbit (MEO). , it, and the upper stage of its launch rocket, are the oldest surviving man-made space objects still in orbit. In a catalog of known launches until July 2009, the Union of Concerned Scientists listed 902 operational satellites from a known population of 19,000 large objects and about 30,000 objects launched.\n\nAn example of additional dead satellite debris are the remains of the 1970s/80s Soviet RORSAT naval surveillance satellite program. The satellite's BES-5 nuclear reactor were cooled with a coolant loop of sodium-potassium alloy, creating a potential problem when the satellite reached end of life. While many satellites were nominally boosted into medium-altitude graveyard orbits, not all were. Even satellites which had been properly moved to a higher orbit had an eight-percent probability of puncture and coolant release over a 50-year period. The coolant freezes into droplets of solid sodium-potassium alloy, forming additional debris.\n\nThese events continue to occur. For example, in February 2015, the USAF Defense Meteorological Satellite Program Flight 13 (DMSP-F13) exploded on orbit, creating at least 149 debris objects, which were expected to remain in orbit for decades.\n\nAccording to Edward Tufte's book \"Envisioning Information\", space debris includes a glove lost by astronaut Ed White on the first American space-walk (EVA); a camera lost by Michael Collins near Gemini 10; a thermal blanket lost during STS-88; garbage bags jettisoned by Soviet cosmonauts during Mir's 15-year life, a wrench and a toothbrush. Sunita Williams of STS-116 lost a camera during an EVA. During an STS-120 EVA to reinforce a torn solar panel, a pair of pliers was lost, and in an STS-126 EVA, Heidemarie Stefanyshyn-Piper lost a briefcase-sized tool bag.\n\nIn characterizing the problem of space debris, it was learned that much debris was due to rocket upper stages (e.g. the Inertial Upper Stage) which end up in orbit, and break up due to decomposition of unvented unburned fuel. However, a major known impact event involved an (intact) Ariane booster. Although NASA and the United States Air Force now require upper-stage passivation, other launchers do not.\nLower stages, like the Space Shuttle's solid rocket boosters or Apollo program's Saturn IB launch vehicles, do not reach orbit.\n\nOn 11 March 2000 a Chinese Long March 4 CBERS-1 upper stage exploded in orbit, creating a debris cloud.\nA Russian Briz-M booster stage exploded in orbit over South Australia on 19 February 2007. Launched on 28 February 2006 carrying an Arabsat-4A communications satellite, it malfunctioned before it could use up its propellant. Although the explosion was captured on film by astronomers, due to the orbit path the debris cloud has been difficult to measure with radar. By 21 February 2007, over 1,000 fragments were identified. A 14 February 2007 breakup was recorded by Celestrak. Eight breakups occurred in 2006, the most since 1993. Another Briz-M broke up on 16 October 2012 after a failed 6 August Proton-M launch. The amount and size of the debris was unknown. A Long March 7 rocket booster created a fireball visible from portions of Utah, Nevada, Colorado, Idaho and California on the evening of 27 July 2016; its disintegration was widely reported on social media.\n\nA past debris source was the testing of anti-satellite weapons (ASATs) by the U.S. and Soviet Union during the 1960s and 1970s. North American Aerospace Defense Command (NORAD) files only contained data for Soviet tests, and debris from U.S. tests were only identified later. By the time the debris problem was understood, widespread ASAT testing had ended; the U.S. Program 437 was shut down in 1975.\n\nThe U.S. restarted their ASAT programs in the 1980s with the Vought ASM-135 ASAT. A 1985 test destroyed a satellite orbiting at , creating thousands of debris larger than . Due to the altitude, atmospheric drag decayed the orbit of most debris within a decade. A \"de facto\" moratorium followed the test.\n\nChina's government was condemned for the military implications and the amount of debris from the 2007 anti-satellite missile test, the largest single space debris incident in history (creating over 2,300 pieces golf-ball size or larger, over 35,000 or larger, and one million pieces or larger). The target satellite orbited between and , the portion of near-Earth space most densely populated with satellites. Since atmospheric drag is low at that altitude the debris is slow to return to Earth, and in June 2007 NASA's Terra environmental spacecraft maneuvered to avoid impact from the debris.\n\nOn 20 February 2008, the U.S. launched an SM-3 missile from the USS \"Lake Erie\" to destroy a defective U.S. spy satellite thought to be carrying of toxic hydrazine propellant. The event occurred at about , and the resulting debris has a perigee of or lower. The missile was aimed to minimize the amount of debris, which (according to Pentagon Strategic Command chief Kevin Chilton) had decayed by early 2009.\n\nThe vulnerability of satellites to debris and the possibility of attacking LEO satellites to create debris clouds, has triggered speculation that it is possible for countries unable to make a precision attack. An attack on a satellite of 10 tonnes or more would heavily damage the LEO environment.\n\nSpace junk is a threat to active satellites and spaceships. The Earth's orbit may even become impassable as the risk of collision grows too high.\n\nAlthough spacecraft are protected by Whipple shields, solar panels, which are exposed to the Sun, wear from low-mass impacts. These produce a cloud of plasma which is an electrical risk to the panels.\n\nSatellites are believed to have been destroyed by micrometeorites and orbital debris (MMOD). The earliest suspected loss was of Kosmos 1275, which disappeared on 24 July 1981 (a month after launch). Kosmos contained no volatile propellant, therefore, there appeared to be nothing internal to the satellite which could have caused the destructive explosion which took place. However the case has not been proven and another hypothesis forwarded is that the battery exploded. Tracking showed it broke up, into 300 new objects.\n\nMany impacts have been confirmed since. Olympus-1 was struck by a meteoroid on 11 August 1993, and left adrift. On 24 July 1996, the French microsatellite Cerise was hit by fragments of an Ariane-1 H-10 upper-stage booster which exploded in November 1986. On 29 March 2006, the Russian Ekspress AM11 communications satellite was struck by an unknown object and rendered inoperable; its engineers had sufficient time in contact with the spacecraft to send it to a parking orbit out of GEO. On October 13, 2009, Terra suffered a single battery cell failure anomaly and a battery heater control anomaly which were likely the result of an MMOD strike. On March 12, 2010, Aura lost power from one-half of one of its 11 solar panels and this was also attributed to an MMOD strike. On May 22, 2013 GOES-13 was hit by an MMOD which caused it to lose track of the stars that it uses to maintain attitude. It took nearly a month for the spacecraft to return to operation.\n\nThe first major satellite collision occurred on 10 February 2009 at 16:56 UTC. The deactivated Kosmos 2251 and the operational Iridium 33 collided, over northern Siberia. The relative speed of impact was about , or about . Both satellites were destroyed, with accurate estimates of the number of debris unavailable. On 22 January 2013 BLITS (a Russian laser-ranging satellite) was struck by debris suspected to be from the 2007 Chinese anti-satellite missile test, changing its orbit and spin rate.\n\nSatellites frequently have to perform Collision Avoidance Maneuvers and managers have to monitor debris as part of maneuver planning. For example, in January 2017, the European Space Agency planned to alter orbit of one of its $319 million Swarm mission spacecrafts, based on data from the US Joint Space Operations Center, to end the risk of collision from Cosmos-375, an old Russian satellite. Cosmos-375, which was destroyed by Soviet operators when its mission was complete, had previously threatened to impact the International Space Station in 2011.\n\nFrom the early Space Shuttle missions, NASA used NORAD to monitor the Shuttle's orbital path for debris. In the 1980s, this used much of its capacity. The first collision-avoidance maneuver occurred during STS-48 in September 1991, a seven-second thruster burn to avoid debris from Kosmos 955. Similar maneuvers followed on missions 53, 72 and 82.\n\nOne of the first events to publicize the debris problem occurred on \"Challenger\"'s second flight, STS-7. A fleck of paint struck its front window, creating a pit over wide. On STS-59 in 1994, \"Endeavour\"'s front window was pitted about half its depth. Minor debris impacts increased from 1998.\n\nWindow chipping and minor damage to thermal protection system tiles (TPS) was already common by the 1990s. The Shuttle was later flown tail-first to take the debris load mostly on the engines and rear cargo bay (not used in orbit or during descent, and less critical for post-launch operation). When flying to the ISS, the two connected spacecraft were flipped around so the better-armored station shielded the orbiter.\nNASA's study concluded that debris accounted for half of the overall risk to the Shuttle. Executive-level decision to proceed was required if catastrophic impact was likelier than 1 in 200. On a normal (low-orbit) mission to the ISS the risk was c. 1 in 300, but STS-125 (the Hubble repair mission) at was initially calculated at a 1-in-185 risk (due to the 2009 satellite collision). A re-analysis with better debris numbers reduced the estimated risk to 1 in 221, and the mission went ahead.\n\nDebris incidents continued on later Shuttle missions. During STS-115 in 2006 a fragment of circuit board bored a small hole through the radiator panels in \"Atlantis\"' cargo bay. On STS-118 in 2007 debris blew a bullet-like hole through \"Endeavour\"s radiator panel.\n\nImpact wear was notable on Mir, the Soviet space station, since it remained in space for long periods with its original module panels.\n\nAlthough the ISS uses Whipple shielding to protect itself from minor debris, portions (notably its solar panels) cannot be protected easily. In 1989, the ISS panels were predicted to degrade c. 0.23% in four years, and they were overdesigned by 1%. A maneuver is performed if \"there is a greater than one-in-10,000 chance of a debris strike\". , there have been sixteen maneuvers in the fifteen years the ISS had been in orbit.\n\nThe crew sheltered in the Soyuz on three occasions due to late debris-proximity warnings. In addition to the sixteen firings and three Soyuz-capsule shelter orders, one attempted maneuver failed (due to not having the several days' warning necessary to upload the manoeuvre timeline to the station's computer). A March 2009 close call involved debris believed to be a piece of the Kosmos 1275 satellite. In 2013, the ISS did not maneuver to avoid debris, after a record four debris maneuvers the previous year.\n\nAlthough most manned space activity takes place at altitudes below , a Kessler syndrome cascade in that region would rain down into lower altitudes and the decay time scale is such that \"the resulting [low Earth orbit] debris environment is likely to be too hostile for future space use\".\n\nIn a Kessler syndrome, satellite lifetimes would be measured in years or months. New satellites could be launched through the debris field into higher orbits or placed in lower orbits (where decay removes the debris), but the utility of the region between is the reason for its amount of debris.\n\nAlthough most debris burns up in the atmosphere, larger objects can reach the ground intact. According to NASA, an average of one cataloged piece of debris has fallen back to Earth each day for the past 50 years. Despite their size, there has been no significant property damage from the debris.\n\nIn 1969 five sailors on a Japanese ship were injured by space debris. In 1997 an Oklahoma woman, Lottie Williams, was injured when she was hit in the shoulder by a piece of blackened, woven metallic material confirmed as part of the propellant tank of a Delta II rocket which launched a U.S. Air Force satellite the year before.\n\nThe original re-entry plan for Skylab called for the station to remain in space for eight to ten years after its final mission in February 1974. High solar activity expanded the upper atmosphere, resulting in higher-than-expected drag and bringing its orbit closer to Earth than planned. On 11 July 1979 Skylab re-entered the Earth's atmosphere and disintegrated, raining debris along a path over the southern Indian Ocean and Western Australia.\n\nOn 12 January 2001, a Star 48 Payload Assist Module (PAM-D) rocket upper stage re-entered the atmosphere after a \"catastrophic orbital decay\", crashing in the Saudi Arabian desert. It was identified as the upper-stage rocket for NAVSTAR 32, a GPS satellite launched in 1993.\n\nIn the 2003 \"Columbia\" disaster, large parts of the spacecraft reached the ground and entire equipment systems remained intact. More than 83,000 pieces, along with the remains of the six astronauts, were recovered in an area from three to 10 miles around Hemphill in Sabine County, TX. More pieces were found in a line from west Texas to east Louisiana, with the westernmost piece found in Littlefield, TX and the easternmost found southwest of Mora, LA. Although there is significant evidence that debris fell in Nevada, Utah, and New Mexico, debris was only found in Texas, Arkansas and Louisiana. In a rare case of property damage, a foot-long metal bracket smashed through the roof of a dentist office. NASA warned the public to avoid contact with the debris because of the possible presence of hazardous chemicals. 15 years after the failure, people were still sending in pieces with the last,as of February 1, 2018, found in the spring of 2017.\n\nOn 27 March 2007, airborne debris from a Russian spy satellite was seen by the pilot of a LAN Airlines Airbus A340 carrying 270 passengers whilst flying over the Pacific Ocean between Santiago and Auckland. The debris was within of the aircraft.\n\nRadar and optical detectors such as lidar are the main tools for tracking space debris. Although objects under have reduced orbital stability, debris as small as 1 cm can be tracked, however determining orbits to allow re-acquisition is difficult. Most debris remain unobserved. The NASA Orbital Debris Observatory tracked space debris with a liquid mirror transit telescope. FM Radio waves can detect debris, after reflecting off them onto a receiver. Optical tracking may be a useful early-warning system on spacecraft.\n\nThe U.S. Strategic Command keeps a catalog of known orbital objects, using ground-based radar and telescopes, and a space-based telescope (originally to distinguish from hostile missiles). The 2009 edition listed about 19,000 objects. Other data come from the ESA Space Debris Telescope, TIRA, the Goldstone, Haystack, and EISCAT radars and the Cobra Dane phased array radar, to be used in debris-environment models like the ESA Meteoroid and Space Debris Terrestrial Environment Reference (MASTER).\n\nReturned space hardware is a valuable source of information on the directional distribution and composition of the (sub-millimetre) debris flux. The LDEF satellite deployed by mission STS-41-C \"Challenger\" and retrieved by STS-32 \"Columbia\" spent 68 months in orbit to gather debris data. The EURECA satellite, deployed by STS-46 \"Atlantis\" in 1992 and retrieved by STS-57 \"Endeavour\" in 1993, was also used for debris study.\n\nThe solar arrays of Hubble were returned by missions STS-61 \"Endeavour\" and STS-109 \"Columbia\", and the impact craters studied by the ESA to validate its models. Materials returned from Mir were also studied, notably the Mir Environmental Effects Payload (which also tested materials intended for the ISS).\n\nA debris cloud resulting from a single event is studied with scatter plots known as Gabbard diagrams, where the perigee and apogee of fragments are plotted with respect to their orbital period. Gabbard diagrams of the early debris cloud prior to the effects of perturbations, if the data were available, are reconstructed. They often include data on newly observed, as yet uncatalogued fragments. Gabbard diagrams can provide important insights into the features of the fragmentation, the direction and point of impact.\n\nAn average of about one tracked object per day has been dropping out of orbit for the past 50 years, averaging almost three objects per day at solar maximum (due to the heating and expansion of the Earth's atmosphere), but one about every three days at solar minimum, usually 5½ yr later. In addition to natural atmospheric effects, corporations, academics and government agencies have proposed plans and technology to deal with space debris, but , most of these are theoretical, and there is no extant business plan for debris reduction.\n\nA number of scholars have also observed that institutional factors—political, legal, economic and cultural \"rules of the game\"—are the greatest impediment to the cleanup of near-Earth space. There is no commercial incentive, since costs aren't assigned to polluters, but a number of suggestions have been made. However, effects to date are limited. In the US, governmental bodies have been accused of backsliding on previous commitments to limit debris growth, \"let alone tackling the more complex issues of removing orbital debris.\"\n\nUpper stage passivation (e.g. of Delta boosters) by releasing residual propellants reduces debris from orbital explosions; however not all boosters implement this. Although there is no international treaty minimizing space debris, the United Nations Committee on the Peaceful Uses of Outer Space (COPUOS) published voluntary guidelines in 2007. As of 2008, the committee is discussing international \"rules of the road\" to prevent collisions between satellites.\nBy 2013, various legal regimes existed, typically instantiated in the launch licenses that are required for a launch in all spacefaring nations.\n\nThe U.S. has a set of standard practices for civilian (NASA) and military (DoD and USAF) orbital-debris mitigation, as has the European Space Agency. In 2007, the ISO began preparing an international standard for space-debris mitigation. Germany and France have posted bonds to safeguard property from debris damage.\n\nWhen originally proposed in 2015, the OneWeb constellation, initially planned to have ~700 satellites anticipated on orbit after 2018, would only state that they would re-enter the atmosphere within 25 years of retirement.\nBy October 2017, both OneWeb—and also SpaceX, with their large Starlink constellation—had filed documents with the US FCC with more aggressive space debris mitigation plans. Both companies committed to a deorbit plan for post-mission satellites which will explicitly move the satellites into orbits where they will reenter the Earth's atmosphere within approximately one year following end-of-life.\n\nWith a \"one-up, one-down\" launch-license policy for Earth orbits, launchers would rendezvous with, capture and de-orbit a derelict satellite from approximately the same orbital plane. Another possibility is the robotic refueling of satellites. Experiments have been flown by NASA, and SpaceX is developing large-scale on-orbit propellant transfer technology and tanker spacecraft.\n\nAnother approach to debris mitigation is to explicitly design the mission architecture to always leave the rocket second-stage in an elliptical geocentric orbit with a low-perigee, thus ensuring rapid orbital decay and avoiding long-term orbital debris from spent rocket bodies. Such missions require the use of a small kick stage to circularize the orbit, but the kick stage itself may be designed with the excess-propellant capability to be able to self-deorbit.\n\nAlthough the ITU requires geostationary satellites to move to a graveyard orbit at the end of their lives, the selected orbital areas do not sufficiently protect GEO lanes from debris. Rocket stages (or satellites) with enough propellant may make a direct, controlled de-orbit, or if this would require too much propellant, a satellite may be brought to an orbit where atmospheric drag would cause it to eventually de-orbit. This was done with the French Spot-1 satellite, reducing its atmospheric re-entry time from a projected 200 years to about 15 by lowering its altitude from to about .\n\nPassive methods of increasing the orbital decay rate of spacecraft debris have been proposed. Instead of rockets, an electrodynamic tether could be attached to a spacecraft at launch; at the end of its lifetime, the tether would be rolled out to slow the spacecraft. Other proposals include a booster stage with a sail-like attachment and a large, thin, inflatable balloon envelope.\n\nA consensus of speakers at a meeting in Brussels on 30 October 2012 organized by the Secure World Foundation (a U.S. think tank) and the French International Relations Institute reported that removal of the largest debris would be required to prevent the risk to spacecraft becoming unacceptable in the foreseeable future (without any addition to the inventory of dead spacecraft in LEO). Removal costs and legal questions about ownership and the authority to remove defunct satellites have stymied national or international action. Current space law retains ownership of all satellites with their original operators, even debris or spacecraft which are defunct or threaten active missions.\n\nA well-studied solution uses a remotely controlled vehicle to rendezvous with, capture and return debris to a central station.\nOne such system is Space Infrastructure Servicing, a commercially developed refueling depot and service spacecraft for communications satellites in geosynchronous orbit originally scheduled for a 2015 launch. The SIS would be able to \"push dead satellites into graveyard orbits.\" The Advanced Common Evolved Stage family of upper stages is being designed with a high leftover-propellant margin (for derelict capture and de-orbit) and in-space refueling capability for the high delta-v required to de-orbit heavy objects from geosynchronous orbit. A tug-like satellite to drag debris to a safe altitude for it to burn up in the atmosphere has been researched. When debris is identified the satellite creates a difference in potential between the debris and itself, then using its thrusters to move itself and the debris to a safer orbit.\n\nA variation of this approach is for the remotely controlled vehicle to rendezvous with debris, capture it temporarily to attach a smaller de-orbit satellite and drag the debris with a tether to the desired location. The \"mothership\" would then tow the debris-smallsat combination for atmospheric entry or move it to a graveyard orbit. One such system is the proposed Busek ORbital DEbris Remover (ORDER), which would carry over 40 SUL (satellite on umbilical line) de-orbit satellites and propellant sufficient for their removal.\nOn 7 January 2010 Star, Inc. reported that it received a contract from the Space and Naval Warfare Systems Command for a feasibility study of the ElectroDynamic Debris Eliminator (EDDE) propellantless spacecraft for space-debris removal.\nIn February 2012 the Swiss Space Center at École Polytechnique Fédérale de Lausanne announced the Clean Space One project, a nanosatellite demonstration project for matching orbit with a defunct Swiss nanosatellite, capturing it and de-orbiting together. The mission has seen several evolutions to reach a pac-man inspired capture model.\n\nThe laser broom uses a ground-based laser to ablate the front of the debris, producing a rocket-like thrust which slows the object. With continued application, the debris would fall enough to be influenced by atmospheric drag. During the late 1990s, the U.S. Air Force's Project Orion was a laser-broom design. Although a test-bed device was scheduled to launch on a Space Shuttle in 2003, international agreements banning powerful laser testing in orbit limited its use to measurements. The Space Shuttle \"Columbia\" disaster postponed the project and according to Nicholas Johnson, chief scientist and program manager for NASA's Orbital Debris Program Office, \"There are lots of little gotchas in the Orion final report. There's a reason why it's been sitting on the shelf for more than a decade.\"\n\nThe momentum of the laser-beam photons could directly impart a thrust on the debris sufficient to move small debris into new orbits out of the way of working satellites. NASA research in 2011 indicates that firing a laser beam at a piece of space junk could impart an impulse of per second, and keeping the laser on the debris for a few hours per day could alter its course by per day. One drawback is the potential for material degradation; the energy may break up the debris, adding to the problem. A similar proposal places the laser on a satellite in Sun-synchronous orbit, using a pulsed beam to push satellites into lower orbits to accelerate their reentry. A proposal to replace the laser with an Ion Beam Shepherd has been made, and other proposals use a foamy ball of aerogel or a spray of water,\ninflatable balloons,\nelectrodynamic tethers,\nboom electroadhesion,\nand dedicated anti-satellite weapons.\n\nOn 28 February 2014, Japan's Japan Aerospace Exploration Agency (JAXA) launched a test \"space net\" satellite. The launch was an operational test only. In December 2016 the country sent a space junk collector via Kounotori 6 to the ISS by which JAXA scientists experiment to pull junk out of orbit using a tether. The system failed to extend a 700-meter tether from a space station resupply vehicle that was returning to Earth. On 6 February the mission was declared a failure and leading researcher Koichi Inoue told reporters that they \"believe the tether did not get released\".\n\nSince 2012, the European Space Agency has designed a mission to remove large space debris from orbit. The mission, e.Deorbit, is scheduled for launch during 2023 with an objective to remove debris heavier than from LEO. Several capture techniques are being studied, including a net, a harpoon and a combination robot arm and clamping mechanism.\n\nHolger Krag of the European Space Agency states that as of 2017 there is no binding international regulatory framework with no progress occurring at the respective UN body in Vienna.\n\nIn 1946 during the Giacobinid meteor shower, Helmut Landsberg collected several small magnetic particles that were apparently associated with the shower. Fred Whipple was intrigued by this and wrote a paper that demonstrated that particles of this size were too small to maintain their velocity when they encountered the upper atmosphere. Instead, they quickly decelerated and then fell to Earth unmelted. In order to classify these sorts of objects, he coined the term \"micro-meteorite\".\n\nWhipple, in collaboration with Fletcher Watson of the Harvard Observatory, led an effort to build an observatory to directly measure the velocity of the meteors that could be seen. At the time the source of the micro-meteorites was not known. Direct measurements at the new observatory were used to locate the source of the meteors, demonstrating that the bulk of material was left over from comet tails, and that none of it could be shown to have an extra-solar origin. Today it is understood that meteoroids of all sorts are leftover material from the formation of the Solar System, consisting of particles from the interplanetary dust cloud or other objects made up from this material, like comets.\n\nThe early studies were based on optical measurements only. In 1957, Hans Pettersson conducted one of the first direct measurements of the fall of space dust on the Earth, estimating it to be 14,300,000 tons per year. This suggested that the meteoroid flux in space was much higher than the number based on telescope observations. Such a high flux presented a very serious risk to missions deeper in space, specifically the high-orbiting Apollo capsules. To determine whether the direct measurement was accurate, a number of additional studies followed, including the Pegasus satellite program. These showed that the rate of meteors passing into the atmosphere, or flux, was in line with the optical measurements, at around 10,000 to 20,000 tons per year.\n\nWhipple's work pre-dated the space race and it proved useful when space exploration started only a few years later. His studies had demonstrated that the chance of being hit by a meteoroid large enough to destroy a spacecraft was extremely remote. However, a spacecraft would be almost constantly struck by micrometeorites, about the size of dust grains.\n\nWhipple had already developed a solution to this problem in 1946. Originally known as a \"meteor bumper\" and now termed the Whipple shield, this consists of a thin foil film held a short distance away from the spacecraft's body. When a micrometeoroid strikes the foil, it vaporizes into a plasma that quickly spreads. By the time this plasma crosses the gap between the shield and the spacecraft, it is so diffused that it is unable to penetrate the structural material below. The shield allows a spacecraft body to be built to just the thickness needed for structural integrity, while the foil adds little additional weight. Such a spacecraft is lighter than one with panels designed to stop the meteoroids directly.\n\nFor spacecraft that spend the majority of their time in orbit, some variety of the Whipple shield has been almost universal for decades. Later research showed that ceramic fibre woven shields offer better protection to hypervelocity (~7 km/s) particles than aluminium shields of equal weight. Another modern design uses multi-layer flexible fabric, as in NASA's design for its never-flown TransHab expandable space habitation module,\nand the Bigelow Expandable Activity Module, which was launched in April 2016 and attached to the ISS for two years of orbital testing.\n\nTo avoid artificial space debris, many—but not all—research satellites are launched on elliptical orbits with perigees inside Earth's atmosphere so they will destroy themselves. Willy Ley predicted in 1960 that \"In time, a number of such accidentally too-lucky shots will accumulate in space and will have to be removed when the era of manned space flight arrives\". After the launch of Sputnik 1 in 1957, the North American Aerospace Defense Command (NORAD) began compiling a database (the Space Object Catalog) of all known rocket launches and objects reaching orbit: satellites, protective shields and upper- and lower-stage booster rockets. NASA published modified versions of the database in two-line element set, and during the early 1980s the CelesTrak bulletin board system re-published them.\nThe trackers who fed the database were aware of other objects in orbit, many of which were the result of in-orbit explosions. Some were deliberately caused during 1960s anti-satellite weapon (ASAT) testing, and others were the result of rocket stages blowing up in orbit as leftover propellant expanded and ruptured their tanks. To improve tracking, NORAD employee John Gabbard kept a separate database. Studying the explosions, Gabbard developed a technique for predicting the orbital paths of their products, and Gabbard diagrams (or plots) are now widely used. These studies were used to improve the modelling of orbital evolution and decay.\n\nWhen the NORAD database became publicly available during the 1970s, NASA scientist Donald J. Kessler applied the technique developed for the asteroid-belt study to the database of known objects. In 1978 Kessler and Burton Cour-Palais co-authored \"Collision Frequency of Artificial Satellites: The Creation of a Debris Belt\", demonstrating that the process controlling asteroid evolution would cause a similar collision process in LEO in decades rather than billions of years. They concluded that by about 2000, space debris would outpace micrometeoroids as the primary ablative risk to orbiting spacecraft.\n\nAt the time, it was widely thought that drag from the upper atmosphere would de-orbit debris faster than it was created. However, Gabbard was aware that the number and type of objects in space were under-represented in the NORAD data and was familiar with its behaviour. In an interview shortly after the publication of Kessler's paper, Gabbard coined the term \"Kessler syndrome\" to refer to the accumulation of debris; it became widely used after its appearance in a 1982 \"Popular Science\" article, which won the Aviation-Space Writers Association 1982 National Journalism Award.\n\nThe lack of hard data about space debris prompted a series of studies to better characterize the LEO environment. In October 1979, NASA provided Kessler with funding for further studies. Several approaches were used by these studies.\n\nOptical telescopes or short-wavelength radar was used to measure the number and size of space objects, and these measurements demonstrated that the published population count was at least 50% too low. Before this, it was believed that the NORAD database accounted for the majority of large objects in orbit. Some objects (typically, U.S. military spacecraft) were found to be omitted from the NORAD list, and others were not included because they were considered unimportant. The list could not easily account for objects under in size—in particular, debris from exploding rocket stages and several 1960s anti-satellite tests.\n\nReturned spacecraft were microscopically examined for small impacts, and sections of Skylab and the Apollo Command/Service Module which were recovered were found to be pitted. Each study indicated that the debris flux was higher than expected and debris was the primary source of collisions in space. LEO already demonstrated the Kessler syndrome.\n\nIn 1978 Kessler found that 42 percent of cataloged debris was the result of 19 events, primarily explosions of spent rocket stages (especially U.S. Delta rockets). He discovered this by first identifying those launches that were described having a large number of objects associated with a payload, then researching the literature to determine the rockets used in the launch. In 1979, this finding resulted in establishment of the NASA Orbital Debris Program after a briefing to NASA senior management, overturning the previously held belief that most unknown debris was from old ASAT tests, but from US upper stage rocket explosions and could be easily managed by depleting the unused fuel following the payload injection the upper stage Delta rocket. Beginning in 1986, when it was discovered that other international agencies were possibly experiencing the same type of problem, NASA expanded its program to include international agencies, the first being the European Space Agency. A number of other Delta components in orbit (Delta was a workhorse of the U.S. space program) had not yet exploded.\n\nDuring the 1980s, the U.S. Air Force conducted an experimental program to determine what would happen if debris collided with satellites or other debris. The study demonstrated that the process differed from micrometeoroid collisions, with large chunks of debris created which would become collision threats.\n\nIn 1991, Kessler published \"Collisional cascading: The limits of population growth in low Earth orbit\" with the best data then available. Citing the USAF conclusions about creation of debris, he wrote that although almost all debris objects (such as paint flecks) were lightweight, most of its mass was in debris about or heavier. This mass could destroy a spacecraft on impact, creating more debris in the critical-mass area. According to the National Academy of Sciences:\n\nA 1-kg object impacting at 10 km/s, for example, is probably capable of catastrophically breaking up a 1,000-kg spacecraft if it strikes a high-density element in the spacecraft. In such a breakup, numerous fragments larger than 1 kg would be created.\n\nKessler's analysis divided the problem into three parts. With a low-enough density, the addition of debris by impacts is slower than their decay rate and the problem is not significant. Beyond that is a critical density, where additional debris leads to additional collisions. At densities beyond this critical mass production exceeds decay, leading to a cascading chain reaction reducing the orbiting population to small objects (several cm in size) and increasing the hazard of space activity. This chain reaction is known as the Kessler syndrome.\n\nIn an early 2009 historical overview, Kessler summed up the situation:\n\nAggressive space activities without adequate safeguards could significantly shorten the time between collisions and produce an intolerable hazard to future spacecraft. Some of the most environmentally dangerous activities in space include large constellations such as those initially proposed by the Strategic Defense Initiative in the mid-1980s, large structures such as those considered in the late-1970s for building solar power stations in Earth orbit, and anti-satellite warfare using systems tested by the USSR, the U.S., and China over the past 30 years. Such aggressive activities could set up a situation where a single satellite failure could lead to cascading failures of many satellites in a period much shorter than years.\n\nDuring the 1980s, NASA and other U.S. groups attempted to limit the growth of debris. One effective solution was implemented by McDonnell Douglas on the Delta booster, by having the booster move away from its payload and vent any propellant remaining in its tanks. This eliminated the pressure buildup in the tanks which caused them to explode in the past. Other countries were slower to adopt this measure and, due especially to a number of launches by the Soviet Union, the problem grew throughout the decade.\n\nA new battery of studies followed as NASA, NORAD and others attempted to better understand the orbital environment, with each adjusting the number of pieces of debris in the critical-mass zone upward. Although in 1981 (when Schefter's article was published) the number of objects was estimated at 5,000, new detectors in the Ground-based Electro-Optical Deep Space Surveillance system found new objects. By the late 1990s, it was thought that most of the 28,000 launched objects had already decayed and about 8,500 remained in orbit. By 2005 this was adjusted upward to 13,000 objects, and a 2006 study increased the number to 19,000 as a result of an ASAT test and a satellite collision. In 2011, NASA said that 22,000 objects were being tracked.\n\nThe growth in the number of objects as a result of the late-1990s studies sparked debate in the space community on the nature of the problem and the earlier dire warnings. According to Kessler's 1991 derivation and 2001 updates, the LEO environment in the altitude range should be cascading. However, only one major incident has occurred: the 2009 satellite collision between Iridium 33 and Cosmos 2251. The lack of obvious short-term cascading has led to speculation that the original estimates overstated the problem. According to Kessler a cascade would not be obvious until it was well advanced, which might take years.\n\nA 2006 NASA model suggested that if no new launches took place the environment would retain the then-known population until about 2055, when it would increase on its own. Richard Crowther of Britain's Defence Evaluation and Research Agency said in 2002 that he believed the cascade would begin about 2015. The National Academy of Sciences, summarizing the professional view, noted widespread agreement that two bands of LEO space—900 to and —were already past critical density.\n\nIn the 2009 European Air and Space Conference, University of Southampton researcher Hugh Lewis predicted that the threat from space debris would rise 50 percent in the next decade and quadruple in the next 50 years. , more than 13,000 close calls were tracked weekly.\n\nA 2011 report by the U.S. National Research Council warned NASA that the amount of orbiting space debris was at a critical level. According to some computer models, the amount of space debris \"has reached a tipping point, with enough currently in orbit to continually collide and create even more debris, raising the risk of spacecraft failures\". The report called for international regulations limiting debris and research of disposal methods.\n\nThe plot of episode 4 (\"Conflict\") of Gerry Anderson's 1970 TV series \"UFO\" includes routine missions for the disposal of spent satellites by bombing.\n\n\"Salvage 1\" (1979 TV series) deals humorously with a scrap dealer who establish a space junk salvage company.\n\n\"Planetes\" is a manga (1999-2004) and anime series (2003-2004) that gives focus on a team which is responsible for the collection and disposal of space debris. The DVDs for the TV series include interviews with NASA's Orbital Debris Program Office.\n\nIn 2009, Rhett & Link wrote a song called \"Space Junk\" and made an accompanying music video for the TV series \"Brink\". The lyrics refer to two men tasked to clean up debris such as satellites and expended rockets.\n\n\"Gravity\" is a 2013 survival film, directed by Alfonso Cuaron, about a disaster on a space mission caused by Kessler syndrome.\n\n\n\n"}
{"id": "43150808", "url": "https://en.wikipedia.org/wiki?curid=43150808", "title": "Spy Booth", "text": "Spy Booth\n\nSpy Booth was an artwork by Banksy in Cheltenham, England. The piece has been seen as a critique of the global surveillance disclosures of 2013.\n\nIn 2014, Robin Barton and Bankrobber London helped with the preservation of the artwork, and attempted to broker the removal and sale of the piece. However the artwork was painted onto a Grade II listed building - 153-159 Fairview Road - and the council prevented it from being removed, giving it retrospective listed building consent in 2015 and affording it some protection from removal. Despite this, the artwork was either removed or destroyed in August 2016.\n\nThe GCHQ has used the picture on its website as a symbolic image for its \"what we do\" page.\n"}
{"id": "9836566", "url": "https://en.wikipedia.org/wiki?curid=9836566", "title": "Stephen Williams (Radio Luxembourg)", "text": "Stephen Williams (Radio Luxembourg)\n\nStephen Williams (31 March 1908 - 23 November 1994) was a British radio announcer, presenter and producer, and a pioneer of commercial radio for the UK.\n\nBorn in London and educated at Trinity College, Cambridge, as a young boy he was already, in his words, a \"wireless fanatic\": he said, \"I was able to listen proudly to the debut of the BBC on 14 November 1922, and from the moment I heard the announcer say \"This is 2LO calling, 2LO, the London station of the British Broadcasting Company\", I was seized with an ambition to have a job like his.\"\n\nDuring his university vacation in 1928 he got a job as announcer on a \"broadcasting yacht\" sponsored by the Daily Mail newspaper group. This vessel went round the coast of Britain, transmitting music on records and advertisements for the Daily Mail, from just outside territorial waters, an early precursor of the 1960s \"pirate radio\" ships..\n\nThe broadcasting yacht had been the idea of the paper's Circulation and Publicity Director, Valentine Smith, who soon transferred to the Sunday Referee, where he gave Williams a job with the idea of involving the paper in commercial broadcasting. They were soon in contact with Captain Leonard F. Plugge, who was starting the International Broadcasting Company (IBC).\n\nAt the beginning of 1932, Williams was sent to France to join Max Staniforth at the IBC's new Radio Normandy service, broadcasting to the south of England.\n\nRecordings of two commercials read by Stephen Williams on Radio Normandy in 1932 are said to survive.\n\nStephen Williams moved on to a rival company to IBC, Radio Publicity, which started broadcasting to the UK from Radio Paris, then a much more powerful station than Radio Normandy, which rapidly gained a large British audience. But French listeners complained that their most popular station was now too dominated by English programmes, so Radio Publicity turned to the newly created Radio Luxembourg, where it was able to gain the sole concession for English programmes.\n\nIn December 1933 Williams thus became the first English radio presenter in Luxembourg as well as serving as manager of the station.\n\nShortly before his death in 1994, Williams gave an interview to Roger Bickerton about his work at Radio Luxembourg which was published in \"The Historic Record and AV Collector\", Issues 39,40 and 41, April, June & October 1996.\n\nRadio Luxembourg closed down on the outbreak of World War II in September 1939. Stephen Williams resumed his duties there when the station restarted in 1946. He left Luxembourg in 1948, and worked until 1975 as a freelance broadcaster.\n\nWhen, on 1 January 1992, Radio Luxembourg's English service closed down as a terrestrial radio station, the last words heard, \"Good luck, good listening ... and goodbye\" were spoken by 83-year-old Stephen Williams, who had been the first person ever to say on the air \"This is Radio Luxembourg\" over 58 years earlier.\n\nWilliams was awarded the Order of Merit by the Grand Duke of Luxembourg in 1992.\n\nHe collected a large archive of material related to Radio Luxembourg, much of which his widow has donated to the Centre for Luxembourg Studies at Sheffield University.\n"}
{"id": "3870084", "url": "https://en.wikipedia.org/wiki?curid=3870084", "title": "The Globalization of World Politics", "text": "The Globalization of World Politics\n\nThe Globalization of World Politics: An Introduction to International Relations is a book by John Baylis, Patricia Owens, and Steve Smith.\n\nJohn Baylis, Steve Smith and Patricia Owens: Introduction\nThe historical context\nTheories of world politics\nStructures and processes\nInternational issues\nGlobalization in the future\n"}
{"id": "35528221", "url": "https://en.wikipedia.org/wiki?curid=35528221", "title": "The Task Force for Global Health", "text": "The Task Force for Global Health\n\nThe Task Force for Global Health is an international, nonprofit organization that works to improve health of people most in need, primarily in developing countries. Founded in 1984 by global health pioneer Dr. William Foege, The Task Force consists of eight programs focused on neglected tropical diseases, vaccines, field epidemiology, public health informatics, and health workforce development. Those programs include the African Health Workforce Project, the Center for Vaccine Equity, Children Without Worms, International Trachoma Initiative, Mectizan Donation Program, Neglected Tropical Diseases Support Center, Public Health Informatics Institute, and TEPHINET. The Task Force works in partnership with ministries of health and hundreds of organizations, including major pharmaceutical companies that donate billions of dollars annually in essential medicines. Major funders include the Bill & Melinda Gates Foundation, CDC, WHO, Robert Wood Johnson Foundation, de Beaumont Foundation, United States Agency for International Development, Sightsavers, Pfizer, Merck & Co., Johnson & Johnson, and GlaxoSmithKline. The Task Force is affiliated with Emory University, headquartered in Decatur, Georgia, a town in metro Atlanta, and has regional offices in Guatemala and Ethiopia. The Task Force currently supports work in 154 countries.\n\nThe Task Force for Global Health received the 2016 Conrad N. Hilton Humanitarian Prize during a symposium titled \"The Future of Humanitarian Action\" held at the Waldorf Astoria in New York City. The Task Force was selected by a panel of independent international jurors for having made \"contributions to improving the health of people living in extreme poverty.\".\n\nThe organization was co-founded by global health pioneer and former CDC Director, Dr. William Foege and two of his former CDC colleagues, Carol Walters and Bill Watson. It was founded in 1984 as The Task Force for Child Survival. The Task Force was initially launched to foster collaboration among leading health and development agencies. Under the leadership of Dr. Foege, The Task Force brought together World Bank Group, The Rockefeller Foundation, The United Nations Development Programme, WHO, and UNICEF, WHO to raise childhood immunization rates. In 1984, only 20 percent of children worldwide were receiving immunizations and 12,000 children, mostly in the world's poorest countries, were dying every day. By 1990, The Task Force had raised childhood immunization rates to 80 percent globally. Since then, The Task Force has used its strength and credibility in collaboration to positively affect a broad range of health issues affecting the world's poor. In 2015, The Task Force celebrated 30 years of contributions to global health at an event that included World Bank Group President Jim Yong Kim.\n\nThe Task Force works with hundreds of partners to control and eliminate neglected tropical diseases and increase access to medicines and vaccines for multi-drug-resistant tuberculosis, poliomyelitis, influenza, and cholera. Beginning with the Mectizan Donation Program, The Task Force is credited with working with the pharmaceutical industry to donate billions of dollars annually in essential medicines for the control and elimination of neglected tropical diseases.\n\nCollaboration, health equity, and social justice are the cornerstones of all Task Force programs. The organization is a major partner in the global effort to eliminate three neglected tropical diseases by 2025—blinding trachoma, river blindness, and lymphatic filariasis—which collectively threaten hundreds of millions of people each year with blindness, disfigurement, and death.\n\nInformation and laboratory technologies are vital tools in The Task Force's work to control and eliminate diseases and increase access to quality health care for people in developing countries. Using a smartphone-based data collection system, The Task Force maps the prevalence of neglected tropical diseases (NTDs) to determine where interventions should be implemented. It uses portable molecular technology and tablet-based systems to detect and diagnose NTDs within populations. It also uses diverse technologies to help developing countries manage their healthcare workforce in order to meet the health needs of their populations.\n\nIn 2015, The Task Force's Public Health Informatics Institute was named a partner on a new Bill & Melinda Gates Foundation-funded initiative called the Child Health and Mortality Prevention Surveillance Program (CHAMPS) that aims to understand and ultimately address the causes of death for children under 5 in developing countries.\n\nIn 2016, the Task Force helped launch a program called Digital Bridge which is developing an electronic case reporting system to improve information exchange between the public health and healthcare sectors.\n\nIn 2016, The Task Force reached an agreement to purchase a DeKalb County government building in downtown Decatur for a larger headquarters. The Task Force has begun examining how it might help address the growing epidemic of non-communicable diseases (NCDs) in developing countries.\n"}
{"id": "1286212", "url": "https://en.wikipedia.org/wiki?curid=1286212", "title": "The World (archipelago)", "text": "The World (archipelago)\n\nThe World or The World Islands, located in Dubai, (Arabic: جزر العالم; \"Juzur al-Ālam\") is an artificial archipelago of various small islands constructed in the rough shape of a world map, located in the waters of the Persian Gulf, off the coast of Dubai, United Arab Emirates. The World islands are composed mainly of sand dredged from Dubai's shallow coastal waters, and are one of several artificial island developments in Dubai. The World's developer is Nakheel Properties, and the project was originally conceived by Sheikh Mohammed bin Rashid Al Maktoum, the ruler of Dubai. The actual construction was done by two Dutch (joint venture) specialist companies, Van Oord and Boskalis. The same companies also created the Palm Jumeirah.\n\nConstruction of the 300 islands began in 2003, only to halt due to the 2008 financial crisis. Though 60 percent of the islands had been sold off to private contractors back in 2008, development on most of these islands has failed to initiate. As of July 2012, the Lebanon Island was developed and was the only island that had so far been developed commercially, being used for private corporate events and public parties. As of late 2013, only two of the islands had been developed. In January 2014, Kleindienst Group announced the launch of \"The Heart of Europe\" project; by February 2014, one of Kleindienst Group's brands - JK Properties - announced in their monthly newsletter that the project was \"well underway\". The first of these series of islands will be Europe, Sweden and Germany with development led by Kleindienst Group.\n\nIslands in the project range from in area. Distances between islands average ; they are constructed from of sand and 386 million tons of rock. Designed by Creative Kingdom Dubai, the development is an area that covers and is surrounded by an oval-shaped breakwater island. Roughly of shoreline was created. The World's overall development costs were estimated at $13 billion CAD in 2005.\n\nThe archipelago consists of seven sets of islands; Europe, Africa, Asia, North America, South America, Antarctica, and Oceania. Each artificial islands are named for their representative regions, including those representing countries, landmarks, and regions such as the United Kingdom, California, Mount Everest, Australia, New Mexico, Upernavik, Buenos Aires, New York, Mexico, St. Petersburg and India.\n\nThe project was unveiled in May 2003 by Sheikh Mohammed and dredging began four months later in September 2003. By January 2008, 60% of the islands were sold, 20 of which were bought in the first four months of 2007. On 10 January 2008 the final stone on the breakwater was laid, completing development of the archipelago. As of July 2012, a second island, the Lebanon Island was developed and was 'the only island that has so far been developed commercially, is used for private corporate events and public parties.' \n\nThe Times Online reported in September 2009 that work on The World had been suspended due to the effects of the global financial crisis.\nAnd in February 2010 the Daily Mail reported that the islands had started sinking back into the sea. This was later denied by Nakheel and independent technical reports as wholly inaccurate. Despite the denial, The Daily Telegraph reported in January 2011 that an independent company, Penguin Marine, provided verification on the erosion of the islands and the silting of the passageways between the islands. Due to finance and technical problems, Penguin Marine, the company contracted to provide transportation to the archipelago, is attempting to get out of the annual fees of $1.6 million paid to Nakheel properties.\n\nAs of early 2011, only one of the islands had been occupied by a building (a show home) on it, and commercial or residential properties were not currently being constructed on any of the other islands. Property prices in the Emirates had fallen 58 percent from their peak in the fourth quarter of 2008.\nThe world economic recovery from the Great Recession has resulted in a rebound for the Dubai real estate market: it has been reported that \"residential prices [in Dubai] rose by 17.9% from August 2012 to 2013, while rents soared by 14.9% in the same period.\" \n\nIrish investor/businessman John O'Dolan, who purchased the \"Ireland\" island, committed suicide in February 2009, after his consortium fell into financial difficulty.\n\nThe World was supposed to be serviced by four major transportation hubs linked by waterways. Land parcels are supposedly zoned for various uses: estate, mid density, high density, resorts and commercial. A Dubai Infinity Holdings construction planner has stated that developers have been negotiating with Nakheel about temporary siting of a cement batching plant on one of the islands to supply subdivided construction.\n\nThe plan was for utilities to be routed under water, with water plants at each of the hubs pumping fresh water to the islands. Power was to be supplied by the Dubai Grid and distributed through underwater cables, however as of February 2015 no cables had been laid, so that developers currently have to provide their own power from diesel generators. Waste water and refuse systems are an individual concern for each island.\n\nNakheel Group is itself further developing a resort named Coral Island over 20 islands that make up the North American part of The World. The low-rise development will include a marina and hotel village.\nThe second largest confirmed development is the purchase of 14 islands that make up Australia and New Zealand by Investment Dar of Kuwait. The islands are being terraformed to be developed as a resort named OQYANA.\n\nIrish business consortium Larionovo had plans to develop the Ireland island into an Irish-themed resort. The plans include a large internal marina, apartments and villas, a gym, hotel, and an Irish-themed pub. In July 2007 it was announced that the Ireland Island would feature a recreation of Northern Ireland's Giant's Causeway. However, on 25 November 2008 a provisional liquidator was appointed to Larionovo. The islands of Great Britain and Moscow on The World were acquired by Premier Real Estate Bureau in the Summer of 2008. News was leaked in a Daily Mail article of January 2009, refuting claims that Great Britain was owned by Richard Branson, Rod Stewart or John O'Dolan.\n\nIn April 2008, Salya Corporation announced that it had acquired the islands of Finland and Brunei in The World and planned to develop them into fashion-themed resorts. Salya spent about Dh800 million ($218 million USD) to purchase the islands and plans to spend a further Dh2.4 billion ($654 million USD) on development. Brunei Island will be turned into a Fashion TV resort and Finland Island will be turned into a fashion community called FTV palace.\n\nSafi Qurashi, the seven-time multi-millionaire entrepreneur at the head of Premier, and his business partner Mustafa Nagri, paid an estimated $64 million USD for the piece of land; he was later convicted for non-payment of cheques and sentenced to seven years in jail. \nHowever, on appeal he was later found not guilty and released from prison in July 2012 when he was declared innocent of two of the three charges. and On the final charges the civil court final judgment showed he owed no money, was a victim of fraud and vindicated him completely by awarding 10.8 Million USD to be paid back to him by his former partner who had defrauded him. and Safi Qurashi is still the owner of GB Island and continues to live and run his businesses in Dubai and is still confident of developing the Island of GB into a unique destination.\n\nJosef Kleindienst and his firm JK Properties are developing The Heart of Europe, a collection of seven islands (Germany, Netherlands, Sweden, St. Petersburg, Main Europe, Switzerland and Monaco) in the European section of the World, into an island luxury resort. The resort is meant to create a fully immersive European experience, with outdoor snow, and stores accepting only the EURO as a currency.\n\n\n\n\n\n"}
{"id": "8890266", "url": "https://en.wikipedia.org/wiki?curid=8890266", "title": "Tube Challenge", "text": "Tube Challenge\n\nThe Tube Challenge is the competition for the fastest time to travel to all London Underground stations, tracked as a Guinness World Record since 1960. The goal is to visit all the stations on the system, not necessarily all the lines; participants may connect between stations on foot, or by using other forms of public transport.\n\n, the record for fastest completion was held by Andi James (Finland) and Steve Wilson (UK), who completed the challenge in 15 hours, 45 minutes and 38 seconds on 21 May 2015.\n\nThe first recorded challenge took place in 1959. Although many people have attempted the challenge and held the record since, they have not always been credited in the record books. In the earlier days of the challenge, participants were permitted to use private forms of transport (such as a car or bike) to move between stations. This led to times of less than 16 hours in some earlier records, and Guinness later changed the rules to ban private transport.\n\nThe following is a list of record holders that have appeared in the printed edition of the \"Guinness Book of Records\". The record did not appear in the book until its eighth edition.\nBetween the 1960s and 1990s the record regularly appeared in the \"Guinness Book of Records\", initially listed under \"Underground Railways – circuit of\", but later just under \"Railways\" and then \"Trains\". Since the change of publishing style of the book from the 2001 edition onwards, the record – although frequently broken – has only once appeared in printed form, in the 2008 edition. More recent records have tended to be published online instead. Since the record has not regularly been published in the book, there have been two broad configurations on the system – one for 275 stations, and one for 270 once the East London Line was no longer part of the network.\n\nOn 3 April 2002 Jack Welsby set a new record time for 275 stations by traversing the system in 19 hours, 18 minutes and 45 seconds. Welsby made just one attempt, starting his route at Heathrow and finishing at Amersham.\n\nThis time was beaten on 4 May 2004 by Geoff Marshall and Neil Blake who achieved a new record time of 18 hours 35 minutes and 43 seconds. Their attempt began on the first train out of Amersham on the Metropolitan Line and ended at Upminster, and it took Guinness World Records four months to ratify it. A previous attempt had been broadcast on TV as part of \"The Tube\" TV series and another attempt had been televised as part of an ITV1 programme \"Metroland: Race Around the Underground\" on 16 October 2003.\n\nAlthough this time stood for two years before being beaten by just five seconds, it was not until Håkan Wolgé and Lars Andersson (both from Sweden) set a new record time for 275 stations that it appeared in the \"Guinness World Records\" Book again, in the 2008 edition. They set a new record of 18 hours, 25 minutes and 3 seconds, on 26 September 2006.\n\nChanges to the total number of stations meant that the record was 'reset' and broken three more times over a two-year period until Wood Lane station opened in October 2008, and the network settled at 270 stations.\n\nThe first holders of the 270-station record were Andi James, Martin Hazel and Steve Wilson who, on 14 December 2009, achieved a record time of 16 hours, 44 minutes and 16 seconds. TfL used this route four years later as part of the Art on the Underground labyrinth project to mark the 150th anniversary of the London Underground, installing permanent designs at stations in the same order that the world record route had taken, and later appeared in an \"Information Capital\" article.\n\nThe record remained unbeaten for 17 months, until Marc Gawley from Denton, Greater Manchester, set a new time of 16 hours, 29 minutes and 57 seconds on 21 April 2011. As a fast marathon runner, he revealed that he did not use any buses on the day, preferring instead to make all his connections on foot. Gawley's record was beaten 37 days later, when James and Wilson completed the challenge in just 44 seconds under Gawley's time, setting a new record of 16 hours, 29 minutes and 13 seconds on 27 May 2011.\n\nThis record stood for over two years until August 2013, before being broken by previous record holder Geoff Marshall who along with Anthony Smith, completed the challenge in 16 hours, 20 minutes and 27 seconds, the record time was then published for the first time in seven years in the \"Guinness World Records\" in the 2015 edition.\n\nClive Burgess and Ronan McDonald set a new Guinness world record time of 16 hours, 14 minutes and 10 seconds on 21 February 2015. The record was broken later that year, on 21 May, by previous record holders Andi James and Steve Wilson, in a time of 15 hours 45 minutes 38 seconds.\n\nAttempts to travel the network have been linked to charities such as Children in Need and Comic Relief. A charity attempt known as \"Tube Relief\" was organised, following the 7 July 2005 London bombings, to raise money for the London Bombings Relief Charitable Fund. Fifty-one people rode the entire tube network for the day, raising over £10,000 towards the official charity fund. A Sue Ryder charity event took place in November 2011, when ten teams competed against each other to have their photo taken outside as many of the 270 stations as possible. Former record holder Geoff Marshall subsequently organised a mass-participant event in 2014, called \"Walk The Tube\", which has become an annual event, raising tens of thousands of pounds in the process.\n\n\n"}
{"id": "1582335", "url": "https://en.wikipedia.org/wiki?curid=1582335", "title": "World-systems theory", "text": "World-systems theory\n\nWorld-systems theory (also known as world-systems analysis or the world-systems perspective) is a multidisciplinary, macro-scale approach to world history and social change which emphasizes the world-system (and not nation states) as the primary (but not exclusive) unit of social analysis.\n\n\"World-system\" refers to the inter-regional and transnational division of labor, which divides the world into core countries, semi-periphery countries, and the periphery countries. Core countries focus on higher skill, capital-intensive production, and the rest of the world focuses on low-skill, labor-intensive production and extraction of raw materials. This constantly reinforces the dominance of the core countries. Nonetheless, the system has dynamic characteristics, in part as a result of revolutions in transport technology, and individual states can gain or lose their core (semi-periphery, periphery) status over time. This structure is unified by the division of labour. It is a world-economy rooted in a capitalist economy. For a time, certain countries become the world hegemon; during the last few centuries, as the world-system has extended geographically and intensified economically, this status has passed from the Netherlands, to the United Kingdom and (most recently) to the United States.\n\nImmanuel Wallerstein has developed the best-known version of world-systems analysis, beginning in the 1970s. Wallerstein traces the rise of the capitalist world-economy from the \"long\" 16th century (c. 1450–1640). The rise of capitalism, in his view, was an accidental outcome of the protracted crisis of feudalism (c. 1290–1450). Europe (the West) used its advantages and gained control over most of the world economy and presided over the development and spread of industrialization and capitalist economy, indirectly resulting in unequal development.\n\nThough other commentators refer to Wallerstein's project as world-systems \"theory\", he consistently rejects that term. For Wallerstein, world-systems analysis is a mode of analysis that aims to transcend the structures of knowledge inherited from the 19th century, especially the definition of capitalism, the divisions within the social sciences, and those between the social sciences and history. For Wallerstein, then, world-systems analysis is a \"knowledge movement\" that seeks to discern the \"totality of what has been paraded under the labels of the... human sciences and indeed well beyond\". \"We must invent a new language,\" Wallerstein insists, to transcend the illusions of the \"three supposedly distinctive arenas\" of society, economy and politics. The trinitarian structure of knowledge is grounded in another, even grander, modernist architecture, the distinction of biophysical worlds (including those within bodies) from social ones: \"One question, therefore, is whether we will be able to justify something called social science in the twenty-first century as a separate sphere of knowledge.\" Many other scholars have contributed significant work in this \"knowledge movement\".\n\nWorld-systems theory traces emerged in the 1970s. Its roots can be found in sociology, but it has developed into a highly interdisciplinary field.\nWorld-systems theory was aiming to replace modernization theory, which Wallerstein criticised for three reasons:\n\nThere are three major predecessors of world-systems theory: the Annales school, the Marxist tradition, and the dependence theory. The Annales School tradition (represented most notably by Fernand Braudel) influenced Wallerstein to focusing on long-term processes and geo-ecological regions as unit of analysis. Marxism added a stress on social conflict, a focus on the capital accumulation process and competitive class struggles, a focus on a relevant totality, the transitory nature of social forms and a dialectical sense of motion through conflict and contradiction.\n\nWorld-systems theory was also significantly influenced by dependency theory, a neo-Marxist explanation of development processes.\n\nOther influences on the world-systems theory come from scholars such as Karl Polanyi, Nikolai Kondratiev and Joseph Schumpeter (particularly their research on business cycles and the concepts of three basic modes of economic organization: reciprocal, redistributive, and market modes, which Wallerstein reframed into a discussion of mini systems, world empires, and world economies).\n\nWallerstein sees the development of the capitalist world economy as detrimental to a large proportion of the world's population. Wallerstein views the period since the 1970s as an \"age of transition\" that will give way to a future world system (or world systems) whose configuration cannot be determined in advance.\n\nWorld-systems thinkers include Samir Amin, Giovanni Arrighi, Andre Gunder Frank, and Immanuel Wallerstein, with major contributions by Christopher Chase-Dunn, Beverly Silver, Volker Bornschier, Janet Abu Lughod, Thomas D. Hall, Kunibert Raffer, Theotonio dos Santos, Dale Tomich, Jason W. Moore and others. In sociology, a primary alternative perspective is World Polity Theory, as formulated by John W. Meyer.\n\nWorld-systems analysis builds upon but also differs fundamentally from dependency theory. While accepting world inequality, the world market and imperialism as fundamental features of historical capitalism, Wallerstein broke with orthodox dependency theory's central proposition. For Wallerstein, core countries do not exploit poor countries for two basic reasons.\n\nFirstly, core capitalists exploit workers in all zones of the capitalist world economy (not just the periphery) and therefore, the crucial redistribution between core and periphery is surplus value, not \"wealth\" or \"resources\" abstractly conceived. Secondly, core states do not exploit poor states, as dependency theory proposes, because capitalism is organised around an inter-regional and transnational division of labor rather than an international division of labour.\n\nDuring the Industrial Revolution, for example, English capitalists exploited slaves (unfree workers) in the cotton zones of the American South, a peripheral region within a semiperipheral country, United States.\n\nFrom a largely Weberian perspective, Fernando Henrique Cardoso described the main tenets of dependency theory as follows:\n\n\nDependency and world system theory propose that the poverty and backwardness of poor countries are caused by their peripheral position in the international division of labor. Since the capitalist world system evolved, the distinction between the central and the peripheral nations has grown and diverged. In recognizing a tripartite pattern in division of labor, world-systems analysis criticized dependency theory with its bimodal system of only cores and peripheries.\n\nThe best-known version of the world-systems approach was developed by Immanuel Wallerstein. Wallerstein notes that world-systems analysis calls for an unidisciplinary historical social science and contends that the modern disciplines, products of the 19th century, are deeply flawed because they are not separate logics, as is manifest for example in the \"de facto\" overlap of analysis among scholars of the disciplines. Wallerstein offers several definitions of a world-system, defining it in 1974 briefly:\n\nHe also offered a longer definition:\n\nIn 1987, Wallerstein again defined it:\n\nWallerstein characterises the world system as a set of mechanisms, which redistributes surplus value from the \"periphery\" to the \"core\". In his terminology, the \"core\" is the developed, industrialized part of the world, and the \"periphery\" is the \"underdeveloped\", typically raw materials-exporting, poor part of the world; the \"market\" being the means by which the \"core\" exploits the \"periphery\".\n\nApart from them, Wallerstein defines four temporal features of the world system. \"Cyclical rhythms\" represent the short-term fluctuation of economy, and \"secular trends\" mean deeper long run tendencies, such as general economic growth or decline. The term \"contradiction\" means a general controversy in the system, usually concerning some short term versus long term tradeoffs. For example, the problem of underconsumption, wherein the driving down of wages increases the profit for capitalists in the short term, but in the long term, the decreasing of wages may have a crucially harmful effect by reducing the demand for the product. The last temporal feature is the \"crisis\": a crisis occurs if a constellation of circumstances brings about the end of the system.\n\nIn Wallerstein's view, there have been three kinds of historical systems across human history: \"mini-systems\" or what anthropologists call bands, tribes, and small chiefdoms, and two types of world systems, one that is politically unified and the other is not (single state world empires and multi-polity world economies). World systems are larger, and are ethnically diverse. Modernity is unique in being the first and only fully capitalist world economy to have emerged around 1450 to 1550 and to have geographically expanded across the entire planet, by about 1900. Not being political unified, many political units are included within the world system loosely tied together in an interstate system. Efficient division of labor is the unifying element of the different units, and it is also a function of capitalism, a system based on competition between free producers using free labor with free commodities, 'free' meaning available for sale and purchase on a market. More specifically, it can be described as focusing on endless accumulation of capital; in other words, accumulation of capital in order to accumulate more capital. Such capitalism has a mutually dependent relationship with the world economy since it provides the efficient division of labour, the unifying element of the world economy, through the process of accumulating wealth. Likewise, such capitalism is dependent on the world economy since the latter provides a large market and a multiplicity of states, enabling capitalists to choose to work with states helping their interests.\n\nWorld-systems theory asks several key questions:\n\n\nSome questions are more specific to certain subfields; for example, Marxists would concern themselves whether world-systems theory is a useful or unhelpful development of Marxist theories.\n\nWorld-systems analysis argues that capitalism, as a historical system, has always integrated a variety of labor forms within a functioning division of labor (world economy). Countries do not have economies but are part of the world economy. Far from being separate societies or worlds, the world economy manifests a tripartite division of labor, with core, semiperipheral and peripheral zones. In the core zones, businesses, with the support of states they operate within, monopolise the most profitable activities of the division of labor.\n\nThere are many ways to attribute a specific country to the core, semi-periphery, or periphery. Using an empirically based sharp formal definition of \"domination\" in a two-country relationship, Piana in 2004 defined the \"core\" as made up of \"free countries\" dominating others without being dominated, the \"semi-periphery\" as the countries that are dominated (usually, but not necessarily, by core countries) but at the same time dominating others (usually in the periphery) and \"periphery\" as the countries dominated. Based on 1998 data, the full list of countries in the three regions, together with a discussion of methodology, can be found.\n\nThe late 18th and early 19th centuries marked a great turning point in the development of capitalism in that capitalists achieved state society power in the key states, which furthered the industrial revolution marking the rise of capitalism. World-systems analysis contends that capitalism as a historical system formed earlier and that countries do not \"develop\" in stages, but the system does, and events have a different meaning as a phase in the development of historical capitalism, the emergence of the three ideologies of the national developmental mythology (the idea that countries can develop through stages if they pursue the right set of policies): conservatism, liberalism, and radicalism.\n\nProponents of world-systems analysis see the world stratification system the same way Karl Marx viewed class (ownership versus nonownership of the means of production) and Max Weber viewed class (which, in addition to ownership, stressed occupational skill level in the production process). The core nations primarily own and control the major means of production in the world and perform the higher-level production tasks. The periphery nations own very little of the world's means of production (even when they are located in periphery nations) and provide less-skilled labour. Like a class system with a nation, class positions in the world economy result in an unequal distribution of rewards or resources. The core nations receive the greatest share of surplus production, and periphery nations receive the smallest share. Furthermore, core nations are usually able to purchase raw materials and other goods from non-core nations at low prices and demand higher prices for their exports to non-core nations. Chirot (1986) lists the five most important benefits coming to core nations from their domination of periphery nations:\n\n\nAccording to Wallerstein, the unique qualities of the modern world system include its capitalistic nature, its truly global nature, and the fact that it is a world economy that has not become politically unified into a world empire.\n\n\nThroughout the history of the modern world system, there has been a group of core nations competing with one another for access to the world's resources, economic dominance and hegemony over periphery nations. Occasionally, there has been one core nation with clear dominance over others. According to Immanuel Wallerstein, a core nation is dominant over all the others when it has a lead in three forms of economic dominance over a period of time:\n\n\nMilitary dominance is also likely after a nation reaches these three rankings. However, it has been posited that throughout the modern world system, no nation has been able to use its military to gain economic dominance. Each of the past dominant nations became dominant with fairly small levels of military spending and began to lose economic dominance with military expansion later on. Historically, cores were found in Northwestern Europe (England, France, Netherlands) but were later in other parts of the world (such as the United States, Canada, and Australia).\n\n\nHistorically, peripheries were found outside Europe, such as in Latin America and today in sub-Saharan Africa.\n\nSemi-peripheral nations are those that are midway between the core and periphery. Thus, they have to keep themselves from falling into the category of peripheral nations and at the same time, they strive to join the category of core nations. Therefore, they tend to apply protectionist policies most aggressively among the three categories of nations. They tend to be countries moving towards industrialization and more diversified economies. These regions often have relatively developed and diversified economies but are not dominant in international trade. They tend to export more to peripheral nations and import more from core nations in trade. According to some scholars, such as Chirot, they are not as subject to outside manipulation as peripheral societies; but according to others (Barfield), they have \"periperial-like\" relations to the core. While in the sphere of influence of some cores, semiperipheries also tend to exert their own control over some peripheries. Further, semi-peripheries act as buffers between cores and peripheries and thus \"...partially deflect the political pressures which groups primarily located in peripheral areas might otherwise direct against core-states\" and stabilise the world system.\n\nSemi-peripheries can come into existence from developing peripheries and declining cores. Historically, two examples of semiperipheral nations would be Spain and Portugal, which fell from their early core positions but still managed to retain influence in Latin America. Those countries imported silver and gold from their American colonies but then had to use it to pay for manufactured goods from core countries such as England and France. In the 20th century, nations like the \"settler colonies\" of Australia, Canada and New Zealand had a semiperipheral status. In the 21st century, nations like Brazil, Russia, India, Israel, China, South Korea and South Africa (BRICS) are usually considered semiperipheral.\n\nExternal areas are those that maintain socially necessary divisions of labor independent of the capitalist world economy.\n\nBefore the 16th century, Europe was dominated by feudal economies. European economies grew from mid-12th to 14th century but from 14th to mid 15th century, they suffered from a major crisis. Wallerstein explains this crisis as caused by the following:\n\nAs a response to the failure of the feudal system, Europe embraced the capitalist system. Europeans were motivated to develop technology to explore and trade around the world, using their superior military to take control of the trade routes. Europeans exploited their initial small advantages, which led to an accelerating process of accumulation of wealth and power in Europe.\n\nWallerstein notes that never before had an economic system encompassed that much of the world, with trade links crossing so many political boundaries. In the past, geographically large economic systems existed but were mostly limited to spheres of domination of large empires (such as the Roman Empire); development of capitalism enabled the world economy to extend beyond individual states. International division of labor was crucial in deciding what relationships exists between different regions, their labor conditions and political systems. For classification and comparison purposes, Wallerstein introduced the categories of core, semi-periphery, periphery, and external countries. Cores monopolized the capital-intensive production, and the rest of the world could provide only workforce and raw resources. The resulting inequality reinforced existing unequal development.\n\nAccording to Wallerstein there have only been three periods in which a core nation dominated in the modern world-system, with each lasting less than one hundred years. In the initial centuries of the rise of Europe, Northwestern Europe constituted the core, Mediterranean Europe the semiperiphery, and Eastern Europe and the Western hemisphere (and parts of Asia) the periphery. Around 1450, Spain and Portugal took the early lead when conditions became right for a capitalist world-economy. They led the way in establishing overseas colonies. However, Portugal and Spain lost their lead, primarily by becoming overextended with empire-building. It became too expensive to dominate and protect so many colonial territories around the world.\nThe first nation to gain clear dominance was the Netherlands in the 17th century, after its revolution led to a new financial system that many historians consider revolutionary. An impressive shipbuilding industry also contributed to their economic dominance through more exports to other countries. Eventually, other countries began to copy the financial methods and efficient production created by the Dutch. After the Dutch gained their dominant status, the standard of living rose, pushing up production costs.\n\nDutch bankers began to go outside of the country seeking profitable investments, and the flow of capital moved, especially to England. By the end of the 17th century, conflict among core nations increased as a result of the economic decline of the Dutch. Dutch financial investment helped England gain productivity and trade dominance, and Dutch military support helped England to defeat France, the other country competing for dominance at the time.\nIn the 19th century, Britain replaced the Netherlands as the hegemon. As a result of the new British dominance, the world system became relatively stable again during the 19th century. The British began to expand globally, with many colonies in the New World, Africa, and Asia. The colonial system began to place a strain on the British military and, along with other factors, led to an economic decline. Again there was a great deal of core conflict after the British lost their clear dominance. This time it was Germany, and later Italy and Japan that provided the new threat.\n\nIndustrialization was another ongoing process during British dominance, resulting in the diminishing importance of the agricultural sector. In the 18th century, Britain was Europe's leading industrial and agricultural producer; by 1900, only 10% of England's population was working in the agricultural sector.\n\nBy 1900, the modern world system appeared very different from that of a century earlier in that most of the periphery societies had already been colonised by one of the older core nations. In 1800, the old European core claimed 35% of the world's territory, but by 1914, it claimed 85% of the world's territory, with the Scramble for Africa closing out the imperial era. If a core nation wanted periphery areas to exploit as had done the Dutch and British, these periphery areas had to be taken from another core nation, which the US did by way of the Spanish–American War, and Germany, and then Japan and Italy, attempted to do in the leadup to World War II. The modern world system was thus geographically global, and even the most remote regions of the world had all been integrated into the global economy.\n\nAs countries vied for core status, so did the United States. The American Civil War led to more power for the Northern industrial elites, who were now better able to pressure the government for policies helping industrial expansion. Like the Dutch bankers, British bankers were putting more investment toward the United States. The US had a small military budget compared to other industrial nations at the time.\n\nThe US began to take the place of the British as a new dominant nation after World War I. With Japan and Europe in ruins after World War II, the US was able to dominate the modern world system more than any other country in history, while the USSR and to a lesser extent China were viewed as primary threats. At its height, US economic reach accounted for over half of the world's industrial production, owned two thirds of the gold reserves in the world and supplied one third of the world's exports.\n\nHowever, since the end of the Cold War, the future of US hegemony has been questioned by some scholars, as its hegemonic position has been in decline for a few decades. By the end of the 20th century, the core of the wealthy industrialized countries was composed of Western Europe, the United States, Japan and a rather limited selection of other countries. The semiperiphery was typically composed of independent states that had not achieved Western levels of influence, while poor former colonies of the West formed most of the periphery.\n\nWorld-systems theory has attracted criticisms from its rivals; notably for being too focused on economy and not enough on culture and for being too core-centric and state-centric. William I. Robinson has criticized world-systems theory for its nation-state centrism, state-structuralist approach, and its inability to conceptualize the rise of globalization. Robinson suggests that world-systems theory doesn't account for emerging transnational social forces and the relationships forged between them and global institutions serving their interests. These forces operate on a global, rather than state system and cannot be understood by Wallerstein's nation-centered approach.\n\nAccording to Wallerstein himself, critique of the world-systems approach comes from four directions: the positivists, the orthodox Marxists, the state autonomists, and the culturalists. The positivists criticise the approach as too prone to generalization, lacking quantitative data and failing to put forth a falsifiable proposition. Orthodox Marxists find the world-systems approach deviating too far from orthodox Marxist principles, such as by not giving enough weight to the concept of social class. The state autonomists criticize the theory for blurring the boundaries between state and businesses. Further, the positivists and the state autonomists argue that state should be the central unit of analysis. Finally, the culturalists argue that world-systems theory puts too much importance on the economy and not enough on the culture. In Wallerstein's own words:\n\nOne of the fundamental conceptual problems of the world-system theory is that the assumptions that define its actual conceptual units are social systems. The assumptions, which define them, need to be examined as well as how they are related to each other and how one changes into another. The essential argument of the world-system theory is that in the 16th century a capitalist world economy developed, which could be described as a world system. The following is a theoretical critique concerned with the basic claims of world-system theory:\n\"There are today no socialist systems in the world-economy any more than there are feudal systems because there is only one world system. It is a world-economy and it is by definition capitalist in form.\" (Wallerstein 1979)\n\nRobert Brenner has pointed out that the prioritization of the world market means the neglect of local class structures and class struggles:\n\"They fail to take into account either the way in which these class structures themselves emerge as the outcome of class struggles whose results are incomprehensible in terms merely of market forces.\" (Brenner 1982) Robert Brenner: Director of the Center for Social Theory and Comparative History at UCLA\n\nAnother criticism is that of reductionism made by Theda Skocpol: she believes the interstate system is far from being a simple superstructure of the capitalist world economy:\n\"The international states system as a transnational structure of military competition was not originally created by capitalism. Throughout modern world history, it represents an analytically autonomous level [... of] world capitalism, but [is] not reducible to it.\" (Skocpol 1979)\n\nA concept that we can perceive as critique and mostly as renewal is the concept of coloniality (Anibal Quijano, 2000, Nepantla, Coloniality of power, eurocentrism and Latin America ). Issued from the think tank of the group \"modernity/coloniality\" () in Latin America, it re-uses the concept of world working division and core/periphery system in its system of coloniality. But criticizing the \"core-centric\" origin of World-system and its only economical development, \"coloniality\" allows further conception of how power still processes in a colonial way over worldwide populations (Ramon Grosfogel, \"the epistemic decolonial turn\" 2007 ):\" by \"colonial situations\" I mean the cultural, political, sexual, spiritual, epistemic and economic oppression/exploitation of subordinate racialized/ethnic groups by dominant racialized/ethnic groups with or without the existence of colonial administration\". Coloniality covers, so far, several fields such as coloniality of gender (Maria Lugones), coloniality of \"being\" (Maldonado Torres), coloniality of knowledge (Walter Mignolo) and Coloniality of power (Anibal Quijano).\n\nNew developments in world systems research include studies on the cyclical processes. More specifically, it refers to the cycle of leading industries or products (ones that are new and have an important share of the overall world market for commodities), which is equal to dissolution of quasi-monopolies or other forms of partial monopolies achieved by core nations. Such forms of partial monopolies are achievable through ownership of leading industries or products, which require technological capabilities, patents, restrictions on imports and/or exports, government subsidies, etc. Such capabilities are most often found in core nations, which accumulate capital through achieving such quasi-monopolies with leading industries or products.\n\nAs capital is accumulated, employment and wage also increase, creating a sense of prosperity. This leads to increased production, and sometimes even overproduction, causing price competition to arise. To lower production costs, production processes of the leading industries or products are relocated to semi-peripheral nations. When competition increases and quasi-monopolies cease to exist, their owners, often core nations, move on to other new leading industries or products, and the cycle continues.\n\nOther new developments include the consequences of the dissolution of the Soviet Union, the roles of gender and the culture, studies of slavery and incorporation of new regions into the world system and the precapitalist world systems. Arguably, the greatest source of renewal in world-systems analysis since 2000 has been the synthesis of world-system and environmental approaches. Key figures in the \"greening\" of world-systems analysis include Minqi Li, Jason W. Moore, Andreas Malm, Stephen Bunker, Alf Hornborg, and Richard York.\n\nWallerstein traces the origin of today's world-system to the \"long 16th century\" (a period that began with the discovery of the Americas by Western European sailors and ended with the English Revolution of 1640). And, according to Wallerstein, globalization, or the becoming of the world's system, is a process coterminous with the spread and development of capitalism over the past 500 years.\n\nJanet Abu Lughod argues that a pre-modern world system extensive across Eurasia existed in the 13th century prior to the formation of the modern world-system identified by Wallerstein. Janet Abu Lughod contends that the Mongol Empire played an important role in stitching together the Chinese, Indian, Muslim and European regions in the 13th century, before the rise of the modern world system. In debates, Wallerstein contends that Lughod's system was not a \"world-system\" because it did not entail integrated production networks, but it was instead a vast trading network.\n\nAndre Gunder Frank goes further and claims that a global world system that includes Asia, Europe and Africa has existed since the 4th millennium BCE. The centre of this system was in Asia, specifically China. Andrey Korotayev goes even further than Frank and dates the beginning of the world system formation to the 10th millennium BCE and connects it with the start of the Neolithic Revolution in the Middle East. According to him, the centre of this system was originally in Western Asia.\n\nWallerstein's theories are widely recognized throughout the world. In the United States, one of the hubs of world-systems research is at the Fernand Braudel Center for the Study of Economies, Historical Systems and Civilizations, at Binghamton University. Among the most important related periodicals are the \"Journal of World-Systems Research\", published by the American Sociological Association's Section on the Political Economy of the World System (PEWS), and the \"Review\", published the Braudel Center. \n\nEdythe E. Weeks asserts the proposition that it may be possible to consider, and apply critical insights, to prevent future patterns from emerging in ways to repeat outcomes harmful to humanity. (See \"Outer Space Development, Space Law and International Relations: A Method for Elucidating Seeds\" (Cambridge Scholars Publishing, 2012)). Her current research, as a Fulbright Specialist, further suggests that new territories such as the Antarctic Peninsula, Antarctica, the Arctic and various regions of outer space, including low Earth orbit, the geostationary orbit, Near Earth orbit are currently in the process of colonization. By applying lessons learned from our past, we can change the future towards a direction less likely to be widely criticized.\n\nMuhammed Asadi suggests that the modern World System is highly militarized and a counterpart of the US permanent war economy where a global division of labor based on military Keynesian stabilization exists concomitant with economic accumulation. He calls these countries, militarized states, whose superior economic growth stabilizes the World System run by the command states (counterpart to Wallerstein's Core but includes military and political domination in addition to financial and trade domination) just like military spending in the US stabilizes the US economy. Militarization and wars are therefore encouraged by the Command States and facilitated by them. Militarized States have a life cycle in which destruction is almost inevitable and since their economic growth stabilizes the dominant economies it seldom translates into personal economic development \n\n\n\n"}
{"id": "6872117", "url": "https://en.wikipedia.org/wiki?curid=6872117", "title": "World Englishes", "text": "World Englishes\n\nWorld Englishes is a term for emerging localized or indigenized varieties of English, especially varieties that have developed in territories influenced by the United Kingdom or the United States. The study of World Englishes consists of identifying varieties of English used in diverse sociolinguistic contexts globally and analyzing how sociolinguistic histories, multicultural backgrounds and contexts of function influence the use of English in different regions of the world.\n\nThe issue of World Englishes was first raised in 1978 to examine concepts of regional Englishes globally. Pragmatic factors such as appropriateness, comprehensibility and interpretability justified the use of English as an international and intra-national language. In 1988, at a Teachers of English to Speakers of Other Languages (TESOL) conference in Honolulu, Hawaii, the International Committee of the Study of World Englishes (ICWE) was formed. In 1992, the ICWE formally launched the International Association for World Englishes (IAWE) at a conference of \"World Englishes Today\", at the University of Illinois, USA. There is now an academic journal devoted to the study of this topic, titled \"World Englishes\".\n\nCurrently, there are approximately 75 territories where English is spoken either as a first language (L1) or as an unofficial or institutionalized second language (L2) in fields such as government, law and education. It is difficult to establish the total number of Englishes in the world, as new varieties of English are constantly being developed and discovered.\n\nThe notions of World English and World Englishes are far from similar, although the terms are often mistakenly used interchangeably. \"World English\" refers to the English language as a lingua franca used in business, trade, diplomacy and other spheres of global activity, while \"World Englishes\" refers to the different varieties of English and English-based creoles developed in different regions of the world. Alternatively, the term \"Global Englishes\" has been used by scholars in the field to emphasise the more recent spread of English due to globalization, which has resulted in increased usage of English as a lingua franca.\n\nEnglish is a West Germanic language that originated from the Anglo-Frisian dialects brought by Germanic invaders into Britain. Initially, Old English was a diverse group of dialects, reflecting the varied origins of the Anglo-Saxon kingdoms of England. Eventually, one of these dialects, Late West Saxon, came to dominate.\n\nThe original Old English language was then influenced by two further waves of invasion: the first by speakers of the Scandinavian branch of the Germanic language family, who conquered and colonized parts of Britain in the 8th and 9th centuries; the second by the Normans in the 11th century, who spoke Old Norman and ultimately developed a Norman variety called Anglo-Norman. For two centuries after the Norman Conquest, French became the language of everyday life among the upper classes in England. Although the language of the masses remained English, the bilingual character of England in this period was thus formed.\n\nDuring the Middle English period, France and England experienced a process of separation. This period of conflicting interests and feelings of resentment was later termed the Hundred Years' War. By the beginning of the 14th century, English had regained universal use and become the principal tongue of all England, but not without having undergone significant change.\n\nDuring the Renaissance, patriotic feelings regarding English brought about the recognition of English as the national language of England. The language was advocated as acceptable for learned and literary use. With the Great Vowel Shift, the language in this period matured to a standard and differed significantly from the Middle English period, becoming recognizably \"modern\".\n\nBy the 18th century, three main forces were driving the direction of the English language: (1) to reduce the language to rule and effect a standard of correct usage; (2) to refine the language by removing supposed defects and introducing certain improvements; and (3) to fix English permanently in the desired form. This desire for system and regularity in the language contrasted with the individualism and spirit of independence characterized by the previous age.\n\nBy the 19th century, the expansion of the British Empire, as well as global trade, had led to the spread of English around the world. The rising importance of some of England's larger colonies and former colonies, such as the rapidly developing United States, enhanced the value of the English varieties spoken in these regions, encouraging the belief, among the local populations, that their distinct varieties of English should be granted equal standing with the standard of Great Britain.\n\nThe first diaspora involved relatively large-scale migrations of mother-tongue English speakers from England, Scotland and Ireland predominantly to North America and the Caribbean, Australia, South Africa and New Zealand. Over time, their own English dialects developed into modern American, Canadian, West Indian, South African, Australian, and New Zealand Englishes. In contrast to the English of Great Britain, the varieties spoken in modern North America and Caribbean, South Africa, Australia, and New Zealand have been modified in response to the changed and changing sociolinguistic contexts of the migrants, for example being in contact with indigenous Native American, Khoisan and Bantu, Aboriginal or Maori populations in the colonies.\n\nThe second diaspora was the result of the colonization of Asia and Africa, which led to the development of 'New Englishes', the second-language varieties of English. In colonial Africa, the history of English is distinct between West and East Africa. English in West Africa began with trade. particularly the slave trade. English soon gained official status in what are today Gambia, Sierra Leone, Ghana, Nigeria and Cameroon, and some of the pidgin and creoles which developed from English contact, including Krio (Sierra Leone) and Cameroon Pidgin, have large numbers of speakers now.\n\nAs for East Africa, extensive British settlements were established in what are now Kenya, Uganda, Tanzania, Malawi, Zambia and Zimbabwe, where English became a crucial language of the government, education and the law. From the early 1960s, the six countries achieved independence in succession; but English remained the official language and had large numbers of second language speakers in Uganda, Zambia, Zimbabwe and Malawi (along with Chewa).\n\nEnglish was formally introduced to the sub-continent of South Asia (India, Bangladesh, Pakistan, Sri Lanka, Nepal and Bhutan) during the second half of the eighteenth century. In India, English was given status through the implementation of Macaulay 'Minute' of 1835, which proposed the introduction of an English educational system in India. Over time, the process of 'Indianisation' led to the development of a distinctive national character of English in the Indian sub-continent.\n\nBritish influence in South-East Asia and the South Pacific began in the late eighteenth century, involving primarily the territories now known as Singapore, Malaysia and Hong Kong. Papua New Guinea, also a British protectorate, exemplified the English-based pidgin - Tok Pisin.\n\nThe Americans came late in South-East Asia but their influence spread like wildfire as their reforms on education in the Philippines progressed in their less than half a century colonization of the islands. English has been taught since the American period and is one of the official languages of the Philippines. Ever since English became the official language, a localized variety gradually emerged - Philippine English. Lately, linguist Wilkinson Daniel Wong Gonzales argued that this variety has in itself more varieties, suggesting that we move towards Philippine Englishes paradigm to progress further in Schneider's dynamic model after gathering evidences of such happening.\n\nNowadays, English is also learnt in other countries in neighbouring areas, most notably in Taiwan, Japan and Korea, with the latter two having begun to consider the possibility of making English their official second language.\n\nThe spread of English around the world is often discussed in terms of three distinct groups of users, where English is used respectively as:\n\n\n The most influential model of the spread of English is Braj Kachru's model of World Englishes. In this model the diffusion of English is captured in terms of three Concentric Circles of the language: The Inner Circle, the Outer Circle, and the Expanding Circle.\n\nThe Inner Circle refers to English as it originally took shape and was spread across the world in the first diaspora. In this transplantation of English, speakers from England carried the language to Australia, New Zealand and North America. The Inner Circle thus represents the traditional historical and sociolinguistic bases of English in regions where it is now used as a primary language: the United Kingdom, the United States, Australia, New Zealand, Ireland, anglophone Canada and South Africa, and some of the Caribbean territories. English is the native language or mother tongue of most people in these countries. The total number of English speakers in the inner circle is as high as 380 million, of whom some 120 million are outside the United States.\n\nThe Outer Circle of English was produced by the second diaspora of English, which spread the language through imperial expansion by Great Britain in Asia and Africa. In these regions, English is not the native tongue, but serves as a useful lingua franca between ethnic and language groups. Higher education, the legislature and judiciary, national commerce and so on may all be carried out predominantly in English. This circle includes India, Nigeria, Bangladesh, Pakistan, Malaysia, Tanzania, Kenya, non-Anglophone South Africa, the Philippines (colonized by the US) and others. The total number of English speakers in the outer circle is estimated to range from 150 million to 300 million. Singapore, while in the Outer Circle, may be drifting into the Inner Circle as English becomes more often used as a home language (see Languages of Singapore), much as Ireland did earlier. Countries where most people speak an English-based creole and retain standard English for official purposes, such as Jamaica and Papua New Guinea, are also in the Outer Circle.\n\nFinally, the Expanding Circle encompasses countries where English plays no historical or governmental role, but where it is nevertheless widely used as a medium of international communication. This includes much of the rest of the world's population not categorized above, including territories such as China, Russia, Japan, non-Anglophone Europe (especially the Netherlands and Nordic countries), South Korea, Egypt and Indonesia. The total in this expanding circle is the most difficult to estimate, especially because English may be employed for specific, limited purposes, usually in a business context. The estimates of these users range from 100 million to one billion.\n\nThe inner circle (UK, US etc.) is 'norm-providing'; that means that English language norms are developed in these countries. The outer circle (mainly New Commonwealth countries) is 'norm-developing'. The expanding circle (which includes much of the rest of the world) is 'norm-dependent', because it relies on the standards set by native speakers in the inner circle.\n\nEdgar Werner Schneider tries to avoid a purely geographical and historical approach evident in the 'circles' models and incorporates sociolinguistic concepts pertaining to acts of identity.\nHe outlines five characteristic stages in the spread of English:\n\nPhase 1 - Foundation: This is the initial stage of the introduction of English to a new territory over an extended period of time. Two linguistic processes are operative at this stage: (a) language contact between English and indigenous languages; (b) contact between different dialects of English of the settlers which eventually results in a new stable dialect (see koiné). At this stage, bilingualism is marginal. A few members of the local populace may play an important role as interpreters, translators and guides. Borrowings are limited to lexical items; with local place names and terms for local fauna and flora being adopted by the English.\n\nPhase 2 - Exonormative stabilization: At this stage, the settler communities tend to stabilize politically under British rule. English increases in prominence and though the colloquial English is a colonial koiné, the speakers look to England for their formal norms. Local vocabulary continues to be adopted. Bilingualism increases amongst the indigenous population through education and increased contacts with English settlers. Knowledge of English becomes an asset, and a new indigenous elite develops.\n\nPhase 3 - Nativisation: According to Schneider, this is the stage at which a transition occurs as the English settler population starts to accept a new identity based on present and local realities, rather than sole allegiance to their 'mother country'. By this time, the indigenous strand has also stabilized an L2 system that is a synthesis of substrate effects, interlanguage processes and features adopted from the settlers' koiné English. Neologisms stabilize as English is made to adapt to local sociopolitical and cultural practices.\n\nPhase 4 - Endonormative stabilization: This stage is characterized by the gradual acceptance of local norms, supported by a new locally rooted linguistic self-confidence. By this time political events have made it clear that the settler and indigenous strands are inextricably bound in a sense of nationhood independent of Britain. Acceptance of local English(es) expresses this new identity. National dictionaries are enthusiastically supported, at least for new lexis (and not always for localized grammar). Literary creativity in local English begins to flourish.\n\nPhase 5 - Differentiation: At this stage there is a change in the dynamics of identity as the young nation sees itself as less defined by its differences from the former colonial power as a composite of subgroups defined on regional, social and ethnic lines. Coupled with the simple effects of time in effecting language change (with the aid of social differentiation) the new English koiné starts to show greater differentiation.\n\nThe oldest map of the spread of English is Strevens's world map of English. His world map, even predating that of Kachru's three circles, showed that since American English became a separate variety from British English, all subsequent Englishes have had affinities with either one or the other.\n\nMcArthur's \"wheel model\" has an idealized central variety called \"World Standard English,\" which is best represented by \"written international English.\" The next circle is made of regional standards or standards that are emerging. Finally, the outer layer consists of localized varieties which may have similarities with the regional standards or emerging standards.\n\nAlthough the model is neat, it raises several problems. Firstly, the three different types of English — ENL, ESL and EFL, are conflated in the second circle. Secondly, the multitude of Englishes in Europe are also missing in this layer. Finally, the outside layer includes pidgins, creoles and L2 Englishes. Most scholars would argue that English pidgins and creoles do not belong to one family: rather they have overlapping multiple memberships.\n\nManfred Görlach's and McArthur's models are reasonably similar. Both exclude English varieties in Europe. As Görlach does not include EFLs at all, his model is more consistent, though less comprehensive. Outside the circle are mixed varieties (pidgins, creoles and mixed languages involving English), which are better categorized as having partial membership.\n\nIn Modiano's model of English, the center consists of users of English as an International Language, with a core set of features which are comprehensible to the majority of native and competent non-native speakers of English. The second circle consists of features which may become internationally common or may fall into obscurity. Finally, the outer area consists of five groups (American English, British English, other major varieties, local varieties, foreign varieties) each with features peculiar to their own speech community and which are unlikely to be understood by most members of the other four groups.\n\nThe World Englishes paradigm is not static, and neither are rapidly changing realities of language use worldwide. The use of English in the Outer and Expanding Circle societies (refer to Kachru's Three Circles of English) continues its rapid spread, while at the same time new patterns of language contact and variety differentiation emerge. The different varieties range from English in the Inner circle societies such as the United States, Canada, South Africa, Australia and New Zealand, to the Outer circle post-colonial societies of Asia and Africa.\nThe World Englishes initiative, in recognizing and describing the New Englishes of the Caribbean, Africa and Asia, has been partly motivated by a consideration of the local linguistic factors and partly by a consideration of the wider cultural and political contexts of language acquisition and use. This, in turn, has involved the creative rewriting of discourses towards a recognition of pluralism and multiple possibilities for scholarship. The notion of varieties in this context is similarly dynamic, as new contexts, new realities, new discourses, and new varieties continue to emerge.\n\nThe terms \"language\" and \"dialect\" are not easily defined concepts. It is often suggested that languages are autonomous, while dialects are heteronomous. It is also said that dialects, in contrast with languages, are mutually intelligible, though this is not always the case. Dialects are characteristically spoken, do not have a codified form and are used only in certain domains.\nIn order to avoid the difficult dialect-language distinction, linguists tend to prefer a more neutral term, \"variety\", which covers both concepts and is not clouded by popular usage. This term is generally used when discussing World Englishes.\n\nTwo scenarios have been advanced about English's future status as the major world language: it will ultimately fragment into a large number of mutually unintelligible varieties (in effect, languages), or it will converge so that differences across groups of speakers are largely eliminated.\n\nIf English is, numerically speaking, the language of 'others', then the center of gravity of the language is almost certain to shift in the direction of the 'others'. In the words of Widdowson, there is likely to be a paradigm shift from one of language distribution to one of language spread:\nIn this new paradigm, English spreads and adapts according to the linguistic and cultural preferences of its users in the Outer and Expanding circles (refer to Kachru's Three Circles of English). However, if English is genuinely to become the language of 'others', then the 'others' have to be accorded – or perhaps more likely, accord themselves – at least the same English language rights as those claimed by mother-tongue speakers.\n\nThe other potential shift in the linguistic center of gravity is that English could lose its international role altogether, or come to share it with a number of equals. Although this would not happen mainly as a result of native-speaker resistance to the spread of non-native speaker Englishes and the consequent abandoning of English by large numbers of non-native speakers, the latter could play a part.\n\nAs evidence that English may eventually give way to another language (or languages) as the world's lingua franca, David Crystal cites Internet data:\n\nOn the other hand, there are at least 1500 languages present on the internet now and that figure is likely to increase. Nevertheless, Crystal predicts that English will retain its dominant presence.\n\n"}
{"id": "32927", "url": "https://en.wikipedia.org/wiki?curid=32927", "title": "World War II", "text": "World War II\n\nWorld War II (often abbreviated to WWII or WW2), also known as the Second World War, was a global war that lasted from 1939 to 1945. The vast majority of the world's countries—including all the great powers—eventually formed two opposing military alliances: the Allies and the Axis. A state of total war emerged, directly involving more than 100 million people from over 30 countries. The major participants threw their entire economic, industrial, and scientific capabilities behind the war effort, blurring the distinction between civilian and military resources. World War II was the deadliest conflict in human history, marked by 50 to 85 million fatalities, most of whom were civilians in the Soviet Union and China. It included massacres, the genocide of the Holocaust, strategic bombing, premeditated death from starvation and disease, and the only use of nuclear weapons in war.\n\nJapan, which aimed to dominate Asia and the Pacific, was at war with China by 1937, though neither side had declared war on the other. World War II is generally said to have begun on 1 September 1939, with the invasion of Poland by Germany and subsequent declarations on Germany by France and the United Kingdom. From late 1939 to early 1941, in a series of campaigns and treaties, Germany conquered or controlled much of continental Europe, and formed the Axis alliance with Italy and Japan. Under the Molotov–Ribbentrop Pact of August 1939, Germany and the Soviet Union partitioned and annexed territories of their European neighbours, Poland, Finland, Romania and the Baltic states. Following the onset of campaigns in North Africa and East Africa, and the fall of France in mid 1940, the war continued primarily between the European Axis powers and the British Empire. War in the Balkans, the aerial Battle of Britain, the Blitz, and the long Battle of the Atlantic followed. On 22 June 1941, the European Axis powers launched an invasion of the Soviet Union, opening the largest land theatre of war in history. This Eastern Front trapped the Axis, most crucially the German Wehrmacht, into a war of attrition. In December 1941, Japan launched a surprise attack on the United States and European colonies in the Pacific Ocean. Following an immediate U.S. declaration of war against Japan, supported by one from Great Britain, the European Axis powers quickly declared war on the U.S. in solidarity with their Japanese ally. Rapid Japanese conquests over much of the Western Pacific ensued, perceived by many in Asia as liberation from Western dominance and resulting in the support of several armies from defeated territories.\n\nThe Axis advance in the Pacific halted in 1942 when Japan lost the critical Battle of Midway; later, Germany and Italy were defeated in North Africa and then, decisively, at Stalingrad in the Soviet Union. Key setbacks in 1943, which included a series of German defeats on the Eastern Front, the Allied invasions of Sicily and Italy, and Allied victories in the Pacific, cost the Axis its initiative and forced it into strategic retreat on all fronts. In 1944, the Western Allies invaded German-occupied France, while the Soviet Union regained its territorial losses and turned toward Germany and its allies. During 1944 and 1945 the Japanese suffered major reverses in mainland Asia in South Central China and Burma, while the Allies crippled the Japanese Navy and captured key Western Pacific islands.\n\nThe war in Europe concluded with an invasion of Germany by the Western Allies and the Soviet Union, culminating in the capture of Berlin by Soviet troops, the suicide of Adolf Hitler and the German unconditional surrender on 8 May 1945. Following the Potsdam Declaration by the Allies on 26 July 1945 and the refusal of Japan to surrender under its terms, the United States dropped atomic bombs on the Japanese cities of Hiroshima and Nagasaki on 6 and 9 August respectively. With an invasion of the Japanese archipelago imminent, the possibility of additional atomic bombings, the Soviet entry into the war against Japan and its invasion of Manchuria, Japan announced its intention to surrender on 15 August 1945, cementing total victory in Asia for the Allies. Tribunals were set up by fiat by the Allies and war crimes trials were conducted in the wake of the war both against the Germans and the Japanese.\n\nWorld War II changed the political alignment and social structure of the globe. The United Nations (UN) was established to foster international co-operation and prevent future conflicts; the victorious great powers—China, France, the Soviet Union, the United Kingdom, and the United States—became the permanent members of its Security Council. The Soviet Union and United States emerged as rival superpowers, setting the stage for the nearly half-century long Cold War. In the wake of European devastation, the influence of its great powers waned, triggering the decolonisation of Africa and Asia. Most countries whose industries had been damaged moved towards economic recovery and expansion. Political integration, especially in Europe, emerged as an effort to end pre-war enmities and create a common identity.\n\nThe start of the war in Europe is generally held to be 1 September 1939, beginning with the German invasion of Poland; the United Kingdom and France declared war on Germany two days later. The dates for the beginning of war in the Pacific include the start of the Second Sino-Japanese War on 7 July 1937, or even the Japanese invasion of Manchuria on 19 September 1931.\n\nOthers follow the British historian A. J. P. Taylor, who held that the Sino-Japanese War and war in Europe and its colonies occurred simultaneously, and the two wars merged in 1941. This article uses the conventional dating. Other starting dates sometimes used for World War II include the Italian invasion of Abyssinia on 3 October 1935. The British historian Antony Beevor views the beginning of World War II as the Battles of Khalkhin Gol fought between Japan and the forces of Mongolia and the Soviet Union from May to September 1939.\n\nThe exact date of the war's end is also not universally agreed upon. It was generally accepted at the time that the war ended with the armistice of 14 August 1945 (V-J Day), rather than the formal surrender of Japan, which was on 2 September 1945 that officially ended the war in Asia. A peace treaty with Japan was signed in 1951. A treaty regarding Germany's future allowed the reunification of East and West Germany to take place in 1990 and resolved most post-World War II issues. No formal peace treaty between Japan and the Soviet Union was ever signed.\n\nWorld War I had radically altered the political European map, with the defeat of the Central Powers—including Austria-Hungary, Germany, Bulgaria and the Ottoman Empire—and the 1917 Bolshevik seizure of power in Russia, which eventually led to the founding of the Soviet Union. Meanwhile, the victorious Allies of World War I, such as France, Belgium, Italy, Romania and Greece, gained territory, and new nation-states were created out of the collapse of Austria-Hungary and the Ottoman and Russian Empires.\n\nTo prevent a future world war, the League of Nations was created during the 1919 Paris Peace Conference. The organisation's primary goals were to prevent armed conflict through collective security, military and naval disarmament, and settling international disputes through peaceful negotiations and arbitration.\n\nDespite strong pacifist sentiment after World War I, its aftermath still caused irredentist and revanchist nationalism in several European states. These sentiments were especially marked in Germany because of the significant territorial, colonial, and financial losses incurred by the Treaty of Versailles. Under the treaty, Germany lost around 13 percent of its home territory and all of its overseas possessions, while German annexation of other states was prohibited, reparations were imposed, and limits were placed on the size and capability of the country's armed forces.\n\nThe German Empire was dissolved in the German Revolution of 1918–1919, and a democratic government, later known as the Weimar Republic, was created. The interwar period saw strife between supporters of the new republic and hardline opponents on both the right and left. Italy, as an Entente ally, had made some post-war territorial gains; however, Italian nationalists were angered that the promises made by the United Kingdom and France to secure Italian entrance into the war were not fulfilled in the peace settlement. From 1922 to 1925, the Fascist movement led by Benito Mussolini seized power in Italy with a nationalist, totalitarian, and class collaborationist agenda that abolished representative democracy, repressed socialist, left-wing and liberal forces, and pursued an aggressive expansionist foreign policy aimed at making Italy a world power, promising the creation of a \"New Roman Empire\".\n\nAdolf Hitler, after an unsuccessful attempt to overthrow the German government in 1923, eventually became the Chancellor of Germany in 1933. He abolished democracy, espousing a radical, racially motivated revision of the world order, and soon began a massive rearmament campaign. Meanwhile, France, to secure its alliance, allowed Italy a free hand in Ethiopia, which Italy desired as a colonial possession. The situation was aggravated in early 1935 when the Territory of the Saar Basin was legally reunited with Germany and Hitler repudiated the Treaty of Versailles, accelerated his rearmament programme, and introduced conscription.\n\nThe United Kingdom, France and Italy formed the Stresa Front in April 1935 in order to contain Germany, a key step towards military globalization; however, that June, the United Kingdom made an independent naval agreement with Germany, easing prior restrictions. The Soviet Union, concerned by Germany's goals of capturing vast areas of Eastern Europe, drafted a treaty of mutual assistance with France. Before taking effect though, the Franco-Soviet pact was required to go through the bureaucracy of the League of Nations, which rendered it essentially toothless. The United States, concerned with events in Europe and Asia, passed the Neutrality Act in August of the same year.\n\nHitler defied the Versailles and Locarno treaties by remilitarising the Rhineland in March 1936, encountering little opposition due to appeasement. In October 1936, Germany and Italy formed the Rome–Berlin Axis. A month later, Germany and Japan signed the Anti-Comintern Pact, which Italy would join in the following year.\n\nThe Kuomintang (KMT) party in China launched a unification campaign against regional warlords and nominally unified China in the mid-1920s, but was soon embroiled in a civil war against its former Chinese Communist Party allies and new regional warlords. In 1931, an increasingly militaristic Empire of Japan, which had long sought influence in China as the first step of what its government saw as the country's right to rule Asia, used the Mukden Incident as a pretext to launch an invasion of Manchuria and establish the puppet state of Manchukuo.\n\nToo weak to resist Japan, China appealed to the League of Nations for help. Japan withdrew from the League of Nations after being condemned for its incursion into Manchuria. The two nations then fought several battles, in Shanghai, Rehe and Hebei, until the Tanggu Truce was signed in 1933. Thereafter, Chinese volunteer forces continued the resistance to Japanese aggression in Manchuria, and Chahar and Suiyuan. After the 1936 Xi'an Incident, the Kuomintang and communist forces agreed on a ceasefire to present a united front to oppose Japan.\n\nThe Second Italo–Ethiopian War was a brief colonial war that began in October 1935 and ended in May 1936. The war began with the invasion of the Ethiopian Empire (also known as Abyssinia) by the armed forces of the Kingdom of Italy (\"Regno d'Italia\"), which was launched from Italian Somaliland and Eritrea. The war resulted in the military occupation of Ethiopia and its annexation into the newly created colony of Italian East Africa (\"Africa Orientale Italiana\", or AOI); in addition it exposed the weakness of the League of Nations as a force to preserve peace. Both Italy and Ethiopia were member nations, but the League did little when the former clearly violated Article X of the League's Covenant. The United Kingdom and France supported imposing sanctions on Italy for the invasion, but they were not fully enforced and failed to end the Italian invasion. Italy subsequently dropped its objections to Germany's goal of absorbing Austria.\n\nWhen civil war broke out in Spain, Hitler and Mussolini lent military support to the Nationalist rebels, led by General Francisco Franco. The Soviet Union supported the existing government, the Spanish Republic. Over 30,000 foreign volunteers, known as the International Brigades, also fought against the Nationalists. Both Germany and the Soviet Union used this proxy war as an opportunity to test in combat their most advanced weapons and tactics. The Nationalists won the civil war in April 1939; Franco, now dictator, remained officially neutral during World War II but generally favoured the Axis. His greatest collaboration with Germany was the sending of volunteers to fight on the Eastern Front.\n\nIn July 1937, Japan captured the former Chinese imperial capital of Peking after instigating the Marco Polo Bridge Incident, which culminated in the Japanese campaign to invade all of China. The Soviets quickly signed a non-aggression pact with China to lend materiel support, effectively ending China's prior co-operation with Germany. From September to November, the Japanese attacked Taiyuan, engaged the Kuomintang Army around Xinkou, and fought Communist forces in Pingxingguan. Generalissimo Chiang Kai-shek deployed his best army to defend Shanghai, but, after three months of fighting, Shanghai fell. The Japanese continued to push the Chinese forces back, capturing the capital Nanking in December 1937. After the fall of Nanking, tens of thousands if not hundreds of thousands of Chinese civilians and disarmed combatants were murdered by the Japanese.\n\nIn March 1938, Nationalist Chinese forces won their first major victory at Taierzhuang but then the city of Xuzhou was taken by Japanese in May. In June 1938, Chinese forces stalled the Japanese advance by flooding the Yellow River; this manoeuvre bought time for the Chinese to prepare their defences at Wuhan, but the city was taken by October. Japanese military victories did not bring about the collapse of Chinese resistance that Japan had hoped to achieve; instead the Chinese government relocated inland to Chongqing and continued the war.\n\nIn the mid-to-late 1930s, Japanese forces in Manchukuo had sporadic border clashes with the Soviet Union and Mongolia. The Japanese doctrine of Hokushin-ron, which emphasised Japan's expansion northward, was favoured by the Imperial Army during this time. With the Japanese defeat at Khalkin Gol in 1939, the ongoing Second Sino-Japanese War and ally Nazi Germany pursuing neutrality with the Soviets, this policy would prove difficult to maintain. Japan and the Soviet Union eventually signed a Neutrality Pact in April 1941, and Japan adopted the doctrine of Nanshin-ron, promoted by the Navy, which took its focus southward, eventually leading to its war with the United States and the Western Allies.\n\nIn Europe, Germany and Italy were becoming more aggressive. In March 1938, Germany annexed Austria, again provoking little response from other European powers. Encouraged, Hitler began pressing German claims on the Sudetenland, an area of Czechoslovakia with a predominantly ethnic German population. Soon the United Kingdom and France followed the counsel of British Prime Minister Neville Chamberlain and conceded this territory to Germany in the Munich Agreement, which was made against the wishes of the Czechoslovak government, in exchange for a promise of no further territorial demands. Soon afterwards, Germany and Italy forced Czechoslovakia to cede additional territory to Hungary, and Poland annexed Czechoslovakia's Zaolzie region.\n\nAlthough all of Germany's stated demands had been satisfied by the agreement, privately Hitler was furious that British interference had prevented him from seizing all of Czechoslovakia in one operation. In subsequent speeches Hitler attacked British and Jewish \"war-mongers\" and in January 1939 secretly ordered a major build-up of the German navy to challenge British naval supremacy. In March 1939, Germany invaded the remainder of Czechoslovakia and subsequently split it into the German Protectorate of Bohemia and Moravia and a pro-German client state, the Slovak Republic. Hitler also delivered the 20 March 1939 ultimatum to Lithuania, forcing the concession of the Klaipėda Region.\n\nGreatly alarmed and with Hitler making further demands on the Free City of Danzig, the United Kingdom and France guaranteed their support for Polish independence; when Italy conquered Albania in April 1939, the same guarantee was extended to Romania and Greece. Shortly after the Franco-British pledge to Poland, Germany and Italy formalised their own alliance with the Pact of Steel. Hitler accused the United Kingdom and Poland of trying to \"encircle\" Germany and renounced the Anglo-German Naval Agreement and the German–Polish Non-Aggression Pact.\n\nThe situation reached a general crisis in late August as German troops continued to mobilise against the Polish border. In August 23, when tripartite negotiations about a military alliance between France, the United Kingdom and Soviet Union stalled, the Soviet Union signed a non-aggression pact with Germany. This pact had a secret protocol that defined German and Soviet \"spheres of influence\" (western Poland and Lithuania for Germany; eastern Poland, Finland, Estonia, Latvia and Bessarabia for the Soviet Union), and raised the question of continuing Polish independence. The pact neutralized the possibility of Soviet opposition to a campaign against Poland and assured that Germany would not have to face the prospect of a two-front war, as it had in World War I. Immediately after that, Hitler ordered the attack to proceed on 26 August, but upon hearing that the United Kingdom had concluded a formal mutual assistance pact with Poland, and that Italy would maintain neutrality, he decided to delay it.\n\nIn response to British requests for direct negotiations to avoid war, Germany made demands on Poland, which only served as a pretext to worsen relations. On 29 August, Hitler demanded that a Polish plenipotentiary immediately travel to Berlin to negotiate the handover of Danzig, and to allow a plebiscite in the Polish Corridor in which the German minority would vote on secession. The Poles refused to comply with the German demands, and on the night of 30–31 August in a violent meeting with the British ambassador Neville Henderson, Ribbentrop declared that Germany considered its claims rejected.\n\nOn 1 September 1939, Germany invaded Poland after having staged several false flag border incidents as a pretext to initiate the attack. The Battle of Westerplatte is often described as the first battle of the war. The United Kingdom responded with an ultimatum to Germany to cease military operations, and on 3 September, after the ultimatum was ignored, France, the United Kingdom, Australia, and New Zealand declared war on Germany. This alliance was joined by South Africa (6 September) and Canada (10 September). The alliance provided no direct military support to Poland, outside of a cautious French probe into the Saarland. The Western Allies also began a naval blockade of Germany, which aimed to damage the country's economy and war effort. Germany responded by ordering U-boat warfare against Allied merchant and warships, which would later escalate into the Battle of the Atlantic.\n\nOn 8 September, German troops reached the suburbs of Warsaw. The Polish counter offensive to the west halted the German advance for several days, but it was outflanked and encircled by the \"Wehrmacht\". Remnants of the Polish army broke through to besieged Warsaw. On 17 September 1939, after signing a cease-fire with Japan, the Soviets invaded Eastern Poland under a pretext that the Polish state had ostensibly ceased to exist. On 27 September, the Warsaw garrison surrendered to the Germans, and the last large operational unit of the Polish Army surrendered on 6 October. Despite the military defeat, the Polish government never surrendered. A significant part of Polish military personnel evacuated to Romania and the Baltic countries; many of them would fight against the Axis in other theatres of the war. The Polish government in exile also established an Underground State and a resistance movement; in particular the Polish partisan Home Army would grow to become one of the war's largest resistance movements.\n\nGermany annexed the western and occupied the central part of Poland, and the Soviet Union annexed its eastern part; small shares of Polish territory were transferred to Lithuania and Slovakia. On 6 October, Hitler made a public peace overture to the United Kingdom and France, but said that the future of Poland was to be determined exclusively by Germany and the Soviet Union. The proposal was rejected, and Hitler ordered an immediate offensive against France, which would be postponed until the spring of 1940 due to bad weather.\n\nThe Soviet Union forced the Baltic countries—Estonia, Latvia and Lithuania, the states that were in the Soviet \"sphere of influence\" under the Molotov-Ribbentrop pact—to sign \"mutual assistance pacts\" that stipulated stationing Soviet troops in these countries. Soon after, significant Soviet military contingents were moved there. Finland refused to sign a similar pact and rejected ceding part of its territory to the Soviet Union. The Soviet Union invaded Finland in November 1939, and the Soviet Union was expelled from the League of Nations. Despite overwhelming numerical superiority, Soviet military success was modest, and the Finno-Soviet war ended in March 1940 with minimal Finnish concessions.\n\nIn June 1940, the Soviet Union forcibly annexed Estonia, Latvia and Lithuania, and the disputed Romanian regions of Bessarabia, Northern Bukovina and Hertza. Meanwhile, Nazi-Soviet political rapprochement and economic co-operation gradually stalled, and both states began preparations for war.\n\nIn April 1940, Germany invaded Denmark and Norway to protect shipments of iron ore from Sweden, which the Allies were attempting to cut off. Denmark capitulated after a few hours, and Norway was conquered within two months despite Allied support. British discontent over the Norwegian campaign led to the appointment of Winston Churchill as Prime Minister on 10May 1940.\n\nOn the same day, Germany launched an offensive against France. To circumvent the strong Maginot Line fortifications on the Franco-German border, Germany directed its attack at the neutral nations of Belgium, the Netherlands, and Luxembourg. The Germans carried out a flanking manoeuvre through the Ardennes region, which was mistakenly perceived by Allies as an impenetrable natural barrier against armoured vehicles. By successfully implementing new blitzkrieg tactics, the \"Wehrmacht\" rapidly advanced to the Channel and cut off the Allied forces in Belgium, trapping the bulk of the Allied armies in a cauldron on the Franco-Belgian border near Lille. The United Kingdom was able to evacuate a significant number of Allied troops from the continent by early June, although abandoning almost all of their equipment.\n\nOn 10 June, Italy invaded France, declaring war on both France and the United Kingdom. The Germans turned south against the weakened French army, and Paris fell to them on 14June. Eight days later France signed an armistice with Germany; it was divided into German and Italian occupation zones, and an unoccupied rump state under the Vichy Regime, which, though officially neutral, was generally aligned with Germany. France kept its fleet, which the United Kingdom attacked on 3July in an attempt to prevent its seizure by Germany.\n\nThe Battle of Britain began in early July with Luftwaffe attacks on shipping and harbours. The United Kingdom rejected Hitler's ultimatum, and the German air superiority campaign started in August but failed to defeat RAF Fighter Command. Due to this the proposed German invasion of Britain was postponed indefinitely on 17September. The German strategic bombing offensive intensified with night attacks on London and other cities in the Blitz, but failed to significantly disrupt the British war effort and largely ended in May 1941.\n\nUsing newly captured French ports, the German Navy enjoyed success against an over-extended Royal Navy, using U-boats against British shipping in the Atlantic. The British Home Fleet scored a significant victory on 27May 1941 by sinking the German battleship \"Bismarck\".\n\nIn November 1939, the United States was taking measures to assist China and the Western Allies, and amended the Neutrality Act to allow \"cash and carry\" purchases by the Allies. In 1940, following the German capture of Paris, the size of the United States Navy was significantly increased. In September the United States further agreed to a trade of American destroyers for British bases. Still, a large majority of the American public continued to oppose any direct military intervention in the conflict well into 1941. In December 1940 Roosevelt accused Hitler of planning world conquest and ruled out any negotiations as useless, calling for the United States to become an \"arsenal of democracy\" and promoting Lend-Lease programmes of aid to support the British war effort. The United States started strategic planning to prepare for a full-scale offensive against Germany.\n\nAt the end of September 1940, the Tripartite Pact formally united Japan, Italy and Germany as the Axis Powers. The Tripartite Pact stipulated that any country, with the exception of the Soviet Union, which attacked any Axis Power would be forced to go to war against all three. The Axis expanded in November 1940 when Hungary, Slovakia and Romania joined. Romania and Hungary would make major contributions to the Axis war against the Soviet Union, in Romania's case partially to recapture territory ceded to the Soviet Union.\n\nIn early June 1940 the Italian \"Regia aeronautica\" attacked and besieged Malta, a British possession. In late summer through early autumn Italy conquered British Somaliland and made an incursion into British-held Egypt. In October Italy attacked Greece, but the attack was repulsed with heavy Italian casualties; the campaign ended within days with minor territorial changes. Germany started preparation for an invasion of the Balkans to assist Italy, to prevent the British from gaining a foothold there, which would be a potential threat for Romanian oil fields, and to strike against the British dominance of the Mediterranean.\n\nIn December 1940, British Empire forces began counter-offensives against Italian forces in Egypt and Italian East Africa. The offensives were highly successful; by early February 1941 Italy had lost control of eastern Libya, and large numbers of Italian troops had been taken prisoner. The Italian Navy also suffered significant defeats, with the Royal Navy putting three Italian battleships out of commission by a carrier attack at Taranto and neutralising several more warships at the Battle of Cape Matapan.\n\nItalian defeats prompted Germany to deploy an expeditionary force to North Africa, and at the end of March 1941 Rommel's Afrika Korps launched an offensive which drove back the Commonwealth forces. In under a month, Axis forces advanced to western Egypt and besieged the port of Tobruk.\n\nBy late March 1941 Bulgaria and Yugoslavia signed the Tripartite Pact. However, the Yugoslav government was overthrown two days later by pro-British nationalists. Germany responded with simultaneous invasions of both Yugoslavia and Greece, commencing on 6 April 1941; both nations were forced to surrender within the month. The airborne invasion of the Greek island of Crete at the end of May completed the German conquest of the Balkans. Although the Axis victory was swift, bitter and large-scale partisan warfare subsequently broke out against the Axis occupation of Yugoslavia, which continued until the end of the war.\n\nIn the Middle East, in May Commonwealth forces quashed an uprising in Iraq which had been supported by German aircraft from bases within Vichy-controlled Syria. Between June and July they invaded and occupied the French possessions Syria and Lebanon, with the assistance of the Free French.\n\nWith the situation in Europe and Asia relatively stable, Germany, Japan, and the Soviet Union made preparations. With the Soviets wary of mounting tensions with Germany and the Japanese planning to take advantage of the European War by seizing resource-rich European possessions in Southeast Asia, the two powers signed the Soviet–Japanese Neutrality Pact in April 1941. By contrast, the Germans were steadily making preparations for an attack on the Soviet Union, massing forces on the Soviet border.\n\nHitler believed that the United Kingdom's refusal to end the war was based on the hope that the United States and the Soviet Union would enter the war against Germany sooner or later. He therefore decided to try to strengthen Germany's relations with the Soviets, or failing that to attack and eliminate them as a factor. In November 1940, negotiations took place to determine if the Soviet Union would join the Tripartite Pact. The Soviets showed some interest, but asked for concessions from Finland, Bulgaria, Turkey, and Japan that Germany considered unacceptable. On 18 December 1940, Hitler issued the directive to prepare for an invasion of the Soviet Union.\n\nOn 22 June 1941, Germany, supported by Italy and Romania, invaded the Soviet Union in Operation Barbarossa, with Germany accusing the Soviets of plotting against them. They were joined shortly by Finland and Hungary. The primary targets of this surprise offensive were the Baltic region, Moscow and Ukraine, with the ultimate goal of ending the 1941 campaign near the Arkhangelsk-Astrakhan line, from the Caspian to the White Seas. Hitler's objectives were to eliminate the Soviet Union as a military power, exterminate Communism, generate \"Lebensraum\" (\"living space\") by dispossessing the native population and guarantee access to the strategic resources needed to defeat Germany's remaining rivals.\n\nAlthough the Red Army was preparing for strategic counter-offensives before the war, \"Barbarossa\" forced the Soviet supreme command to adopt a strategic defence. During the summer, the Axis made significant gains into Soviet territory, inflicting immense losses in both personnel and materiel. By the middle of August, however, the German Army High Command decided to suspend the offensive of a considerably depleted Army Group Centre, and to divert the 2nd Panzer Group to reinforce troops advancing towards central Ukraine and Leningrad. The Kiev offensive was overwhelmingly successful, resulting in encirclement and elimination of four Soviet armies, and made possible further advance into Crimea and industrially developed Eastern Ukraine (the First Battle of Kharkov).\n\nThe diversion of three quarters of the Axis troops and the majority of their air forces from France and the central Mediterranean to the Eastern Front prompted the United Kingdom to reconsider its grand strategy. In July, the UK and the Soviet Union formed a military alliance against Germany The British and Soviets invaded neutral Iran to secure the Persian Corridor and Iran's oil fields. In August, the United Kingdom and the United States jointly issued the Atlantic Charter.\n\nBy October Axis operational objectives in Ukraine and the Baltic region were achieved, with only the sieges of Leningrad and Sevastopol continuing. A major offensive against Moscow was renewed; after two months of fierce battles in increasingly harsh weather the German army almost reached the outer suburbs of Moscow, where the exhausted troops were forced to suspend their offensive. Large territorial gains were made by Axis forces, but their campaign had failed to achieve its main objectives: two key cities remained in Soviet hands, the Soviet capability to resist was not broken, and the Soviet Union retained a considerable part of its military potential. The \"blitzkrieg\" phase of the war in Europe had ended.\n\nBy early December, freshly mobilised reserves allowed the Soviets to achieve numerical parity with Axis troops. This, as well as intelligence data which established that a minimal number of Soviet troops in the East would be sufficient to deter any attack by the Japanese Kwantung Army, allowed the Soviets to begin a massive counter-offensive that started on 5 December all along the front and pushed German troops west.\n\nIn 1939, the United States had renounced its trade treaty with Japan, and beginning with an aviation gasoline ban in July 1940, Japan became subject to increasing economic pressure. During this time, Japan launched its first attack against Changsha, a strategically important Chinese city, but was repulsed by late September. Despite several offensives by both sides, the war between China and Japan was stalemated by 1940. To increase pressure on China by blocking supply routes, and to better position Japanese forces in the event of a war with the Western powers, Japan invaded and occupied northern Indochina. Afterwards, the United States embargoed iron, steel and mechanical parts against Japan.\n\nChinese nationalist forces launched a large-scale counter-offensive in early 1940. In August, Chinese communists launched an offensive in Central China; in retaliation, Japan instituted harsh measures in occupied areas to reduce human and material resources for the communists. Continued antipathy between Chinese communist and nationalist forces culminated in armed clashes in January 1941, effectively ending their co-operation. In March, the Japanese 11th army attacked the headquarters of the Chinese 19th army but was repulsed during Battle of Shanggao. In September, Japan attempted to take the city of Changsha again and clashed with Chinese nationalist forces.\n\nGerman successes in Europe encouraged Japan to increase pressure on European governments in Southeast Asia. The Dutch government agreed to provide Japan some oil supplies from the Dutch East Indies, but negotiations for additional access to their resources ended in failure in June 1941. In July 1941 Japan sent troops to southern Indochina, thus threatening British and Dutch possessions in the Far East. The United States, United Kingdom and other Western governments reacted to this move with a freeze on Japanese assets and a total oil embargo. At the same time, Japan was planning an invasion of the Soviet Far East, intending to capitalise off the German invasion in the west, but abandoned the operation after the sanctions.\n\nSince early 1941 the United States and Japan had been engaged in negotiations in an attempt to improve their strained relations and end the war in China. During these negotiations Japan advanced a number of proposals which were dismissed by the Americans as inadequate. At the same time the United States, the United Kingdom, and the Netherlands engaged in secret discussions for the joint defence of their territories, in the event of a Japanese attack against any of them. Roosevelt reinforced the Philippines (an American protectorate scheduled for independence in 1946) and warned Japan that the United States would react to Japanese attacks against any \"neighboring countries\".\n\nFrustrated at the lack of progress and feeling the pinch of the American-British-Dutch sanctions, Japan prepared for war. On 20 November a new government under Hideki Tojo presented an interim proposal as its final offer. It called for the end of American aid to China and for lifting the embargo on the supply of oil and other resources to Japan. In exchange Japan promised not to launch any attacks in Southeast Asia and to withdraw its forces from southern Indochina. The American counter-proposal of 26 November required that Japan evacuate all of China without conditions and conclude non-aggression pacts with all Pacific powers. That meant Japan was essentially forced to choose between abandoning its ambitions in China, or seizing the natural resources it needed in the Dutch East Indies by force; the Japanese military did not consider the former an option, and many officers considered the oil embargo an unspoken declaration of war.\n\nJapan planned to rapidly seize European colonies in Asia to create a large defensive perimeter stretching into the Central Pacific. The Japanese would then be free to exploit the resources of Southeast Asia while exhausting the over-stretched Allies by fighting a defensive war. To prevent American intervention while securing the perimeter, it was further planned to neutralise the United States Pacific Fleet and the American military presence in the Philippines from the outset. On 7 December 1941 (8 December in Asian time zones), Japan attacked British and American holdings with near-simultaneous offensives against Southeast Asia and the Central Pacific. These included an attack on the American fleets at Pearl Harbor and the Philippines, landings in Thailand and Malaya, and the Battle of Hong Kong.\n\nThese attacks led the United States, United Kingdom, China, Australia and several other states to formally declare war on Japan, whereas the Soviet Union, being heavily involved in large-scale hostilities with European Axis countries, maintained its neutrality agreement with Japan. Germany, followed by the other Axis states, declared war on the United States in solidarity with Japan, citing as justification the American attacks on German war vessels that had been ordered by Roosevelt.\n\nOn 1 January 1942, the Allied Big Four—the Soviet Union, China, the United Kingdom and the United States—and 22 smaller or exiled governments issued the Declaration by United Nations, thereby affirming the Atlantic Charter, and agreeing to not to sign a separate peace with the Axis powers.\n\nDuring 1942, Allied officials debated on the appropriate grand strategy to pursue. All agreed that defeating Germany was the primary objective. The Americans favoured a straightforward, large-scale attack on Germany through France. The Soviets were also demanding a second front. The British, on the other hand, argued that military operations should target peripheral areas to wear out German strength, leading to increasing demoralisation, and bolster resistance forces. Germany itself would be subject to a heavy bombing campaign. An offensive against Germany would then be launched primarily by Allied armour without using large-scale armies. Eventually, the British persuaded the Americans that a landing in France was infeasible in 1942 and they should instead focus on driving the Axis out of North Africa.\n\nAt the Casablanca Conference in early 1943, the Allies reiterated the statements issued in the 1942 Declaration by the United Nations, and demanded the unconditional surrender of their enemies. The British and Americans agreed to continue to press the initiative in the Mediterranean by invading Sicily to fully secure the Mediterranean supply routes. Although the British argued for further operations in the Balkans to bring Turkey into the war, in May 1943, the Americans extracted a British commitment to limit Allied operations in the Mediterranean to an invasion of the Italian mainland and to invade France in 1944.\n\nBy the end of April 1942, Japan and its ally Thailand had almost fully conquered Burma, Malaya, the Dutch East Indies, Singapore, and Rabaul, inflicting severe losses on Allied troops and taking a large number of prisoners. Despite stubborn resistance by Filipino and US forces, the Philippine Commonwealth was eventually captured in May 1942, forcing its government into exile. On 16 April, in Burma, 7,000 British soldiers were encircled by the Japanese 33rd Division during the Battle of Yenangyaung and rescued by the Chinese 38th Division. Japanese forces also achieved naval victories in the South China Sea, Java Sea and Indian Ocean, and bombed the Allied naval base at Darwin, Australia. In January 1942, the only Allied success against Japan was a Chinese victory at Changsha. These easy victories over unprepared US and European opponents left Japan overconfident, as well as overextended.\n\nIn early May 1942, Japan initiated operations to capture Port Moresby by amphibious assault and thus sever communications and supply lines between the United States and Australia. The planned invasion was thwarted when an Allied task force, centred on two American fleet carriers, fought Japanese naval forces to a draw in the Battle of the Coral Sea. Japan's next plan, motivated by the earlier Doolittle Raid, was to seize Midway Atoll and lure American carriers into battle to be eliminated; as a diversion, Japan would also send forces to occupy the Aleutian Islands in Alaska. In mid-May, Japan started the Zhejiang-Jiangxi Campaign in China, with the goal of inflicting retribution on the Chinese who aided the surviving American airmen in the Doolittle Raid by destroying air bases and fighting against the Chinese 23rd and 32nd Army Groups. In early June, Japan put its operations into action, but the Americans, having broken Japanese naval codes in late May, were fully aware of the plans and order of battle, and used this knowledge to achieve a decisive victory at Midway over the Imperial Japanese Navy.\n\nWith its capacity for aggressive action greatly diminished as a result of the Midway battle, Japan chose to focus on a belated attempt to capture Port Moresby by an overland campaign in the Territory of Papua. The Americans planned a counter-attack against Japanese positions in the southern Solomon Islands, primarily Guadalcanal, as a first step towards capturing Rabaul, the main Japanese base in Southeast Asia.\n\nBoth plans started in July, but by mid-September, the Battle for Guadalcanal took priority for the Japanese, and troops in New Guinea were ordered to withdraw from the Port Moresby area to the northern part of the island, where they faced Australian and United States troops in the Battle of Buna-Gona. Guadalcanal soon became a focal point for both sides with heavy commitments of troops and ships in the battle for Guadalcanal. By the start of 1943, the Japanese were defeated on the island and withdrew their troops. In Burma, Commonwealth forces mounted two operations. The first, an offensive into the Arakan region in late 1942, went disastrously, forcing a retreat back to India by May 1943. The second was the insertion of irregular forces behind Japanese front-lines in February which, by the end of April, had achieved mixed results.\n\nDespite considerable losses, in early 1942 Germany and its allies stopped a major Soviet offensive in central and southern Russia, keeping most territorial gains they had achieved during the previous year. In May the Germans defeated Soviet offensives in the Kerch Peninsula and at Kharkov, and then launched their main summer offensive against southern Russia in June 1942, to seize the oil fields of the Caucasus and occupy Kuban steppe, while maintaining positions on the northern and central areas of the front. The Germans split Army Group South into two groups: Army Group A advanced to the lower Don River and struck south-east to the Caucasus, while Army Group B headed towards the Volga River. The Soviets decided to make their stand at Stalingrad on the Volga.\n\nBy mid-November, the Germans had nearly taken Stalingrad in bitter street fighting. The Soviets began their second winter counter-offensive, starting with an encirclement of German forces at Stalingrad, and an assault on the Rzhev salient near Moscow, though the latter failed disastrously. By early February 1943, the German Army had taken tremendous losses; German troops at Stalingrad had been forced to surrender, and the front-line had been pushed back beyond its position before the summer offensive. In mid-February, after the Soviet push had tapered off, the Germans launched another attack on Kharkov, creating a salient in their front line around the Soviet city of Kursk.\n\nExploiting poor American naval command decisions, the German navy ravaged Allied shipping off the American Atlantic coast. By November 1941, Commonwealth forces had launched a counter-offensive, Operation Crusader, in North Africa, and reclaimed all the gains the Germans and Italians had made. In North Africa, the Germans launched an offensive in January, pushing the British back to positions at the Gazala Line by early February, followed by a temporary lull in combat which Germany used to prepare for their upcoming offensives. Concerns the Japanese might use bases in Vichy-held Madagascar caused the British to invade the island in early May 1942. An Axis offensive in Libya forced an Allied retreat deep inside Egypt until Axis forces were stopped at El Alamein. On the Continent, raids of Allied commandos on strategic targets, culminating in the disastrous Dieppe Raid, demonstrated the Western Allies' inability to launch an invasion of continental Europe without much better preparation, equipment, and operational security.\n\nIn August 1942, the Allies succeeded in repelling a second attack against El Alamein and, at a high cost, managed to deliver desperately needed supplies to the besieged Malta. A few months later, the Allies commenced an attack of their own in Egypt, dislodging the Axis forces and beginning a drive west across Libya. This attack was followed up shortly after by Anglo-American landings in French North Africa, which resulted in the region joining the Allies. Hitler responded to the French colony's defection by ordering the occupation of Vichy France; although Vichy forces did not resist this violation of the armistice, they managed to scuttle their fleet to prevent its capture by German forces. The Axis forces in Africa withdrew into Tunisia, which was conquered by the Allies in May 1943.\n\nIn June 1943 the British and Americans began a strategic bombing campaign against Germany with a goal to disrupt the war economy, reduce morale, and \"de-house\" the civilian population. The firebombing of Hamburg was among the first attacks in this campaign, inflicting significant casualties and considerable losses on infrastructure of this important industrial center.\n\nAfter the Guadalcanal Campaign, the Allies initiated several operations against Japan in the Pacific. In May 1943, Canadian and US forces were sent to eliminate Japanese forces from the Aleutians. Soon after, the United States, with support from Australian and New Zealand forces, began major operations to isolate Rabaul by capturing surrounding islands, and breach the Japanese Central Pacific perimeter at the Gilbert and Marshall Islands. By the end of March 1944, the Allies had completed both of these objectives, and had also neutralised the major Japanese base at Truk in the Caroline Islands. In April, the Allies launched an operation to retake Western New Guinea.\n\nIn the Soviet Union, both the Germans and the Soviets spent the spring and early summer of 1943 preparing for large offensives in central Russia. On 4 July 1943, Germany attacked Soviet forces around the Kursk Bulge. Within a week, German forces had exhausted themselves against the Soviets' deeply echeloned and well-constructed defences, and for the first time in the war Hitler cancelled the operation before it had achieved tactical or operational success. This decision was partially affected by the Western Allies' invasion of Sicily launched on 9 July, which, combined with previous Italian failures, resulted in the ousting and arrest of Mussolini later that month.\n\nOn 12 July 1943, the Soviets launched their own counter-offensives, thereby dispelling any chance of German victory or even stalemate in the east. The Soviet victory at Kursk marked the end of German superiority, giving the Soviet Union the initiative on the Eastern Front. The Germans tried to stabilise their eastern front along the hastily fortified Panther–Wotan line, but the Soviets broke through it at Smolensk and by the Lower Dnieper Offensives.\n\nOn 3 September 1943, the Western Allies invaded the Italian mainland, following Italy's armistice with the Allies. Germany with the help of fascists responded by disarming Italian forces that were in many places without superior orders, seizing military control of Italian areas, and creating a series of defensive lines. German special forces then rescued Mussolini, who then soon established a new client state in German-occupied Italy named the Italian Social Republic, causing an Italian civil war. The Western Allies fought through several lines until reaching the main German defensive line in mid-November.\n\nGerman operations in the Atlantic also suffered. By May 1943, as Allied counter-measures became increasingly effective, the resulting sizeable German submarine losses forced a temporary halt of the German Atlantic naval campaign. In November 1943, Franklin D. Roosevelt and Winston Churchill met with Chiang Kai-shek in Cairo and then with Joseph Stalin in Tehran. The former conference determined the post-war return of Japanese territory and the military planning for the Burma Campaign, while the latter included agreement that the Western Allies would invade Europe in 1944 and that the Soviet Union would declare war on Japan within three months of Germany's defeat.\n\nFrom November 1943, during the seven-week Battle of Changde, the Chinese forced Japan to fight a costly war of attrition, while awaiting Allied relief. In January 1944, the Allies launched a series of attacks in Italy against the line at Monte Cassino and tried to outflank it with landings at Anzio.\n\nOn 27 January 1944, Soviet troops launched a major offensive that expelled German forces from the Leningrad region, thereby ending the longest and most lethal siege in history. The following Soviet offensive was halted on the pre-war Estonian border by the German Army Group North aided by Estonians hoping to re-establish national independence. This delay slowed subsequent Soviet operations in the Baltic Sea region. By late May 1944, the Soviets had liberated Crimea, largely expelled Axis forces from Ukraine, and made incursions into Romania, which were repulsed by the Axis troops. The Allied offensives in Italy had succeeded and, at the expense of allowing several German divisions to retreat, on 4 June, Rome was captured.\nThe Allies had mixed success in mainland Asia. In March 1944, the Japanese launched the first of two invasions, an operation against British positions in Assam, India, and soon besieged Commonwealth positions at Imphal and Kohima. In May 1944, British forces mounted a counter-offensive that drove Japanese troops back to Burma, and Chinese forces that had invaded northern Burma in late 1943 besieged Japanese troops in Myitkyina. The second Japanese invasion of China aimed to destroy China's main fighting forces, secure railways between Japanese-held territory and capture Allied airfields. By June, the Japanese had conquered the province of Henan and begun a new attack on Changsha in the Hunan province.\n\nOn 6 June 1944 (known as D-Day), after three years of Soviet pressure, the Western Allies invaded northern France. After reassigning several Allied divisions from Italy, they also attacked southern France. These landings were successful, and led to the defeat of the German Army units in France. Paris was liberated on 25 August by the local resistance assisted by the Free French Forces, both led by General Charles de Gaulle, and the Western Allies continued to push back German forces in western Europe during the latter part of the year. An attempt to advance into northern Germany spearheaded by a major airborne operation in the Netherlands failed. After that, the Western Allies slowly pushed into Germany, but failed to cross the Ruhr river in a large offensive. In Italy, Allied advance also slowed due to the last major German defensive line.\n\nOn 22 June, the Soviets launched a strategic offensive in Belarus (\"Operation Bagration\") that destroyed the German Army Group Centre almost completely. Soon after that, another Soviet strategic offensive forced German troops from Western Ukraine and Eastern Poland. The Soviet advance prompted resistance forces in Poland to initiate several uprisings against the German occupation. However, the largest of these, in Warsaw and a national uprising in Slovakia, did not receive Soviet support and were subsequently suppressed by the Germans. The Red Army's strategic offensive in eastern Romania cut off and destroyed the considerable German troops there and triggered a successful coup d'état in Romania and in Bulgaria, followed by those countries' shift to the Allied side.\n\nIn September 1944, Soviet troops advanced into Yugoslavia and forced the rapid withdrawal of German Army Groups E and F in Greece, Albania and Yugoslavia to rescue them from being cut off. By this point, the Communist-led Partisans under Marshal Josip Broz Tito, who had led an increasingly successful guerrilla campaign against the occupation since 1941, controlled much of the territory of Yugoslavia and engaged in delaying efforts against German forces further south. In northern Serbia, the Red Army, with limited support from Bulgarian forces, assisted the Partisans in a joint liberation of the capital city of Belgrade on 20 October. A few days later, the Soviets launched a massive assault against German-occupied Hungary that lasted until the fall of Budapest in February 1945. Unlike impressive Soviet victories in the Balkans, bitter Finnish resistance to the Soviet offensive in the Karelian Isthmus denied the Soviets occupation of Finland and led to a Soviet-Finnish armistice on relatively mild conditions, although Finland was forced to fight their former allies.\n\nBy the start of July 1944, Commonwealth forces in Southeast Asia had repelled the Japanese sieges in Assam, pushing the Japanese back to the Chindwin River while the Chinese captured Myitkyina. In September 1944, Chinese force captured the Mount Song to reopen the Burma Road. In China, the Japanese had more successes, having finally captured Changsha in mid-June and the city of Hengyang by early August. Soon after, they invaded the province of Guangxi, winning major engagements against Chinese forces at Guilin and Liuzhou by the end of November and successfully linking up their forces in China and Indochina by mid-December.\n\nIn the Pacific, US forces continued to press back the Japanese perimeter. In mid-June 1944, they began their offensive against the Mariana and Palau islands, and decisively defeated Japanese forces in the Battle of the Philippine Sea. These defeats led to the resignation of the Japanese Prime Minister, Hideki Tojo, and provided the United States with air bases to launch intensive heavy bomber attacks on the Japanese home islands. In late October, American forces invaded the Filipino island of Leyte; soon after, Allied naval forces scored another large victory in the Battle of Leyte Gulf, one of the largest naval battles in history.\n\nOn 16 December 1944, Germany made a last attempt on the Western Front by using most of its remaining reserves to launch a massive counter-offensive in the Ardennes and along the French–German border to split the Western Allies, encircle large portions of Western Allied troops and capture their primary supply port at Antwerp to prompt a political settlement. By January, the offensive had been repulsed with no strategic objectives fulfilled. In Italy, the Western Allies remained stalemated at the German defensive line. In mid-January 1945, the Soviets and Poles attacked in Poland, pushing from the Vistula to the Oder river in Germany, and overran East Prussia. On 4 February, Soviet, British and US leaders met for the Yalta Conference. They agreed on the occupation of post-war Germany, and on when the Soviet Union would join the war against Japan.\n\nIn February, the Soviets entered Silesia and Pomerania, while Western Allies entered western Germany and closed to the Rhine river. By March, the Western Allies crossed the Rhine north and south of the Ruhr, encircling the German Army Group B. In early March, in attempts to protect her last oil reserves in Hungary and to retake Budapest, Germany launched the last major offensive, that was directed against Soviet troops near the lake Balaton. It two weeks, the offensive had been repulsed, the Soviets advanced to Vienna, and captured the city. In early April, Soviet troops captured Königsberg, while the Western Allies finally pushed forward in Italy and swept across western Germany capturing Hamburg and Nuremberg. American and Soviet forces met at the Elbe river on 25 April, leaving several unoccupied pockets in southern Germany and around Berlin.\n\nSoviet and Polish forces stormed and captured Berlin in late April. In Italy, German forces surrendered on 29 April. On 30 April, the Reichstag was captured, signalling the military defeat of Nazi Germany, Berlin garrison surrendered on 2 May.\n\nSeveral changes in leadership occurred during this period. On 12 April, President Roosevelt died and was succeeded by Harry S. Truman. Benito Mussolini was killed by Italian partisans on 28 April. Two days later, Hitler committed suicide in besieged Berlin, and he was succeeded by Grand Admiral Karl Dönitz.\n\nTotal and unconditional surrender was signed on 7 and 8 May, to be effective by the end of 8 May. German Army Group Centre resisted in Prague until 11 May.\n\nIn the Pacific theatre, American forces accompanied by the forces of the Philippine Commonwealth advanced in the Philippines, clearing Leyte by the end of April 1945. They landed on Luzon in January 1945 and recaptured Manila in March. Fighting continued on Luzon, Mindanao, and other islands of the Philippines until the end of the war. Meanwhile, the United States Army Air Forces launched a massive firebombing campaign of strategic cities in Japan in an effort to destroy Japanese war industry and civilian morale. A devastating bombing raid of 9–10 March was the deadliest conventional bombing raid in the history. \n\nIn May 1945, Australian troops landed in Borneo, over-running the oilfields there. British, American, and Chinese forces defeated the Japanese in northern Burma in March, and the British pushed on to reach Rangoon by 3 May. Chinese forces started a counterattack in the Battle of West Hunan that occurred between 6 April and 7 June 1945. American naval and amphibious forces also moved towards Japan, taking Iwo Jima by March, and Okinawa by the end of June. At the same time, American submarines cut off Japanese imports, drastically reducing Japan's ability to supply its overseas forces.\n\nOn 11 July, Allied leaders met in Potsdam, Germany. They confirmed earlier agreements about Germany, and reiterated the demand for unconditional surrender of Japan, specifically stating that \"the alternative for Japan is prompt and utter destruction\". During this conference, the United Kingdom held its general election, and Clement Attlee replaced Churchill as Prime Minister.\n\nThe Allied call for unconditional surrender was rejected by the Japanese government, which believed it would be capable of negotiating for more favourable surrender terms. In early August, the USAAF dropped atomic bombs on the Japanese cities of Hiroshima and Nagasaki. Between the two bombings, the Soviets, pursuant to the Yalta agreement, invaded Japanese-held Manchuria and quickly defeated the Kwantung Army, which was the largest Japanese fighting force, thereby persuading previously adamant Imperial Army leaders to accept surrender terms. The Red Army also captured the southern part of Sakhalin Island and the Kuril Islands. On 15 August 1945, Japan surrendered, with the surrender documents finally signed at Tokyo Bay on the deck of the American battleship USS \"Missouri\" on 2 September 1945, ending the war.\n\nThe Allies established occupation administrations in Austria and Germany. The former became a neutral state, non-aligned with any political bloc. The latter was divided into western and eastern occupation zones controlled by the Western Allies and the Soviet Union. A denazification programme in Germany led to the prosecution of Nazi war criminals in the Nuremberg trials and the removal of ex-Nazis from power, although this policy moved towards amnesty and re-integration of ex-Nazis into West German society.\n\nGermany lost a quarter of its pre-war (1937) territory. Among the eastern territories, Silesia, Neumark and most of Pomerania were taken over by Poland, and East Prussia was divided between Poland and the Soviet Union, followed by the expulsion to Germany of the nine million Germans from these provinces, as well as three million Germans from the Sudetenland in Czechoslovakia. By the 1950s, one-fifth of West Germans were refugees from the east. The Soviet Union also took over the Polish provinces east of the Curzon line, from which 2 million Poles were expelled; north-east Romania, parts of eastern Finland, and the three Baltic states were incorporated into the Soviet Union.\n\nIn an effort to maintain world peace, the Allies formed the United Nations, which officially came into existence on 24 October 1945, and adopted the Universal Declaration of Human Rights in 1948 as a common standard for all member nations. The great powers that were the victors of the war—France, China, the United Kingdom, the Soviet Union and the United States—became the permanent members of the UN's Security Council. The five permanent members remain so to the present, although there have been two seat changes, between the Republic of China and the People's Republic of China in 1971, and between the Soviet Union and its successor state, the Russian Federation, following the dissolution of the Soviet Union in 1991. The alliance between the Western Allies and the Soviet Union had begun to deteriorate even before the war was over.\n\nGermany had been \"de facto\" divided, and two independent states, the Federal Republic of Germany and the German Democratic Republic, were created within the borders of Allied and Soviet occupation zones. The rest of Europe was also divided into Western and Soviet spheres of influence. Most eastern and central European countries fell into the Soviet sphere, which led to establishment of Communist-led regimes, with full or partial support of the Soviet occupation authorities. As a result, East Germany, Poland, Hungary, Romania, Czechoslovakia, and Albania became Soviet satellite states. Communist Yugoslavia conducted a fully independent policy, causing tension with the Soviet Union.\n\nPost-war division of the world was formalised by two international military alliances, the United States-led NATO and the Soviet-led Warsaw Pact. The long period of political tensions and military competition between them, the Cold War, would be accompanied by an unprecedented arms race and proxy wars.\n\nIn Asia, the United States led the occupation of Japan and administrated Japan's former islands in the Western Pacific, while the Soviets annexed Sakhalin and the Kuril Islands. Korea, formerly under Japanese rule, was divided and occupied by the Soviet Union in the North and the United States in the South between 1945 and 1948. Separate republics emerged on both sides of the 38th parallel in 1948, each claiming to be the legitimate government for all of Korea, which led ultimately to the Korean War.\n\nIn China, nationalist and communist forces resumed the civil war in June 1946. Communist forces were victorious and established the People's Republic of China on the mainland, while nationalist forces retreated to Taiwan in 1949. In the Middle East, the Arab rejection of the United Nations Partition Plan for Palestine and the creation of Israel marked the escalation of the Arab–Israeli conflict. While European powers attempted to retain some or all of their colonial empires, their losses of prestige and resources during the war rendered this unsuccessful, leading to decolonisation.\n\nThe global economy suffered heavily from the war, although participating nations were affected differently. The United States emerged much richer than any other nation, leading to a baby boom, and by 1950 its gross domestic product per person was much higher than that of any of the other powers, and it dominated the world economy. The UK and US pursued a policy of industrial disarmament in Western Germany in the years 1945–1948. Because of international trade interdependencies this led to European economic stagnation and delayed European recovery for several years.\n\nRecovery began with the mid-1948 currency reform in Western Germany, and was sped up by the liberalisation of European economic policy that the Marshall Plan (1948–1951) both directly and indirectly caused. The post-1948 West German recovery has been called the German economic miracle. Italy also experienced an economic boom and the French economy rebounded. By contrast, the United Kingdom was in a state of economic ruin, and although receiving a quarter of the total Marshall Plan assistance, more than any other European country, it continued in relative economic decline for decades.\n\nThe Soviet Union, despite enormous human and material losses, also experienced rapid increase in production in the immediate post-war era. Japan experienced incredibly rapid economic growth, becoming one of the most powerful economies in the world by the 1980s. China returned to its pre-war industrial production by 1952.\n\nEstimates for the total number of casualties in the war vary, because many deaths went unrecorded. Most suggest that some 60 million people died in the war, including about 20 million military personnel and 40 million civilians.\nMany of the civilians died because of deliberate genocide, massacres, mass-bombings, disease, and starvation.\n\nThe Soviet Union lost around 27 million people during the war, 8.7 million military and 19 million civilian deaths. A quarter of the people in the Soviet Union were wounded or killed. Germany sustained 5.3 million military losses, mostly on the Eastern Front and during the final battles in Germany.\n\nOf the total number of deaths in World War II, approximately 85 per cent—mostly Soviet and Chinese—were on the Allied side. Many of these deaths were caused by war crimes committed by German and Japanese forces in occupied territories. An estimated 11 to 17 million civilians died as a direct or as an indirect result of Nazi racist policies, including mass killing of around 6 million Jews, along with Roma, homosexuals, at least 1.9 million ethnic Poles and millions of other Slavs (including Russians, Ukrainians and Belarusians), and other ethnic and minority groups. Between 1941 and 1945, over 200,000 ethnic Serbs, along with gypsies and Jews, were persecuted and murdered by the Axis-aligned Croatian Ustaše in Yugoslavia. Also, over 100,000 Poles were massacred by the Ukrainian Insurgent Army in the Volhynia massacres, between 1943 and 1945.\n\nIn Asia and the Pacific, between 3 million and more than 10 million civilians, mostly Chinese (estimated at 7.5 million), were killed by the Japanese occupation forces. The most infamous Japanese atrocity was the Nanking Massacre, in which fifty to three hundred thousand Chinese civilians were raped and murdered. Mitsuyoshi Himeta reported that 2.7 million casualties occurred during the \"Sankō Sakusen\". General Yasuji Okamura implemented the policy in Heipei and Shantung.\n\nAxis forces employed biological and chemical weapons. The Imperial Japanese Army used a variety of such weapons during its invasion and occupation of China (\"see Unit 731\") and in early conflicts against the Soviets. Both the Germans and Japanese tested such weapons against civilians, and sometimes on prisoners of war.\n\nThe Soviet Union was responsible for the Katyn massacre of 22,000 Polish officers, and the imprisonment or execution of thousands of political prisoners by the NKVD, along with mass civilian deportations to Siberia, in the Baltic states and eastern Poland annexed by the Red Army.\n\nThe mass-bombing of cities in Europe and Asia has often been called a war crime, although no positive or specific customary international humanitarian law with respect to aerial warfare existed before or during World War II. The USAAF firebombed a total of 67 Japanese cities, killing 393,000 civilians and destroying 65% of built-up areas.\n\nThe German government led by Adolf Hitler and the Nazi Party was responsible for the Holocaust (killing approximately 6 million Jews), as well as for killing 2.7 million ethnic Poles and 4 million others who were deemed \"unworthy of life\" (including the disabled and mentally ill, Soviet prisoners of war, Romani, homosexuals, Freemasons, and Jehovah's Witnesses) as part of a programme of deliberate extermination. Soviet POWs were kept in especially unbearable conditions, and, although their extermination was not an official goal, 3.6 million Soviet POWs out of 5.7 died in Nazi camps during the war. In addition to concentration camps, death camps were created in Nazi Germany to exterminate people at an industrial scale. Nazi Germany extensively used forced labourers; about 12 million Europeans from German occupied countries were used as a slave work force in German agriculture and war economy.\n\nThe Soviet Gulag became a \"de facto\" system of deadly camps during 1942–43, when wartime privation and hunger caused numerous deaths of inmates, including foreign citizens of Poland and other countries occupied in 1939–40 by the Soviet Union, as well as Axis POWs. By the end of the war, most Soviet POWs liberated from Nazi camps and many repatriated civilians were detained in special filtration camps where they were subjected to NKVD evaluation, and a significant part of them was sent to the Gulag as real or perceived Nazi collaborators.\n\nJapanese prisoner-of-war camps, many of which were used as labour camps, also had high death rates. The International Military Tribunal for the Far East found the death rate of Western prisoners was 27.1 per cent (for American POWs, 37 per cent), seven times that of POWs under the Germans and Italians. While 37,583 prisoners from the UK, 28,500 from the Netherlands, and 14,473 from the United States were released after the surrender of Japan, the number of Chinese released was only 56.\n\nAt least five million Chinese civilians from northern China and Manchukuo were enslaved between 1935 and 1941 by the East Asia Development Board, or \"Kōain\", for work in mines and war industries. After 1942, the number reached 10 million. In Java, between 4 and 10 million \"rōmusha\" (Japanese: \"manual labourers\"), were forced to work by the Japanese military. About 270,000 of these Javanese labourers were sent to other Japanese-held areas in South East Asia, and only 52,000 were repatriated to Java.\n\nIn Europe, occupation came under two forms. In Western, Northern, and Central Europe (France, Norway, Denmark, the Low Countries, and the annexed portions of Czechoslovakia) Germany established economic policies through which it collected roughly 69.5 billion reichmarks (27.8 billion US dollars) by the end of the war; this figure does not include the sizeable plunder of industrial products, military equipment, raw materials and other goods. Thus, the income from occupied nations was over 40 per cent of the income Germany collected from taxation, a figure which increased to nearly 40 per cent of total German income as the war went on.\n\nIn the East, the intended gains of \"Lebensraum\" were never attained as fluctuating front-lines and Soviet scorched earth policies denied resources to the German invaders. Unlike in the West, the Nazi racial policy encouraged extreme brutality against what it considered to be the \"inferior people\" of Slavic descent; most German advances were thus followed by mass executions. Although resistance groups formed in most occupied territories, they did not significantly hamper German operations in either the East or the West until late 1943.\n\nIn Asia, Japan termed nations under its occupation as being part of the Greater East Asia Co-Prosperity Sphere, essentially a Japanese hegemony which it claimed was for purposes of liberating colonised peoples. Although Japanese forces were originally welcomed as liberators from European domination in some territories, their excessive brutality turned local public opinion against them within weeks. During Japan's initial conquest it captured of oil (~5.5×10 tonnes) left behind by retreating Allied forces, and by 1943 was able to get production in the Dutch East Indies up to , 76 per cent of its 1940 output rate.\n\nIn Europe, before the outbreak of the war, the Allies had significant advantages in both population and economics. In 1938, the Western Allies (United Kingdom, France, Poland and British Dominions) had a 30 per cent larger population and a 30 per cent higher gross domestic product than the European Axis powers (Germany and Italy); if colonies are included, it then gives the Allies more than a 5:1 advantage in population and nearly 2:1 advantage in GDP. In Asia at the same time, China had roughly six times the population of Japan, but only an 89 per cent higher GDP; this is reduced to three times the population and only a 38 per cent higher GDP if Japanese colonies are included.\n\nThe United States provided about two-thirds of all the ordnance used by the Allies in terms of warships, transports, warplanes, artillery, tanks, trucks, and ammunition. Though the Allies' economic and population advantages were largely mitigated during the initial rapid blitzkrieg attacks of Germany and Japan, they became the decisive factor by 1942, after the United States and Soviet Union joined the Allies, as the war largely settled into one of attrition. While the Allies' ability to out-produce the Axis is often attributed to the Allies having more access to natural resources, other factors, such as Germany and Japan's reluctance to employ women in the labour force, Allied strategic bombing, and Germany's late shift to a war economy contributed significantly. Additionally, neither Germany nor Japan planned to fight a protracted war, and were not equipped to do so. To improve their production, Germany and Japan used millions of slave labourers; Germany used about 12 million people, mostly from Eastern Europe, while Japan used more than 18 million people in Far East Asia.\n\nAircraft were used for reconnaissance, as fighters, bombers, and ground-support, and each role was advanced considerably. Innovation included airlift (the capability to quickly move limited high-priority supplies, equipment, and personnel); and of strategic bombing (the bombing of enemy industrial and population centres to destroy the enemy's ability to wage war). Anti-aircraft weaponry also advanced, including defences such as radar and surface-to-air artillery. The use of the jet aircraft was pioneered and, though late introduction meant it had little impact, it led to jets becoming standard in air forces worldwide. Although guided missiles were being developed, they were not advanced enough to reliably target aircraft until some years after the war.\n\nAdvances were made in nearly every aspect of naval warfare, most notably with aircraft carriers and submarines. Although aeronautical warfare had relatively little success at the start of the war, actions at Taranto, Pearl Harbor, and the Coral Sea established the carrier as the dominant capital ship in place of the battleship. In the Atlantic, escort carriers proved to be a vital part of Allied convoys, increasing the effective protection radius and helping to close the Mid-Atlantic gap. Carriers were also more economical than battleships because of the relatively low cost of aircraft and their not requiring to be as heavily armoured. Submarines, which had proved to be an effective weapon during the First World War, were anticipated by all sides to be important in the second. The British focused development on anti-submarine weaponry and tactics, such as sonar and convoys, while Germany focused on improving its offensive capability, with designs such as the Type VII submarine and wolfpack tactics. Gradually, improving Allied technologies such as the Leigh light, hedgehog, squid, and homing torpedoes proved victorious.\n\nLand warfare changed from the static front lines of trench warfare of World War I, which had relied on improved artillery that outmatched the speed of both infantry and cavalry, to increased mobility and combined arms. The tank, which had been used predominantly for infantry support in the First World War, had evolved into the primary weapon. In the late 1930s, tank design was considerably more advanced than it had been during World War I, and advances continued throughout the war with increases in speed, armour and firepower. At the start of the war, most commanders thought enemy tanks should be met by tanks with superior specifications. This idea was challenged by the poor performance of the relatively light early tank guns against armour, and German doctrine of avoiding tank-versus-tank combat. This, along with Germany's use of combined arms, were among the key elements of their highly successful blitzkrieg tactics across Poland and France. Many means of destroying tanks, including indirect artillery, anti-tank guns (both towed and self-propelled), mines, short-ranged infantry antitank weapons, and other tanks were used. Even with large-scale mechanisation, infantry remained the backbone of all forces, and throughout the war, most infantry were equipped similarly to World War I. The portable machine gun spread, a notable example being the German MG34, and various submachine guns which were suited to close combat in urban and jungle settings. The assault rifle, a late war development incorporating many features of the rifle and submachine gun, became the standard postwar infantry weapon for most armed forces.\n\nMost major belligerents attempted to solve the problems of complexity and security involved in using large codebooks for cryptography by designing ciphering machines, the most well known being the German Enigma machine. Development of SIGINT (\"sig\"nals \"int\"elligence) and cryptanalysis enabled the countering process of decryption. Notable examples were the Allied decryption of Japanese naval codes and British Ultra, a pioneering method for decoding Enigma benefiting from information given to the United Kingdom by the Polish Cipher Bureau, which had been decoding early versions of Enigma before the war. Another aspect of military intelligence was the use of deception, which the Allies used to great effect, such as in operations Mincemeat and Bodyguard.\n\nOther technological and engineering feats achieved during, or as a result of, the war include the world's first programmable computers (Z3, Colossus, and ENIAC), guided missiles and modern rockets, the Manhattan Project's development of nuclear weapons, operations research and the development of artificial harbours and oil pipelines under the English Channel.\n\n"}
{"id": "9058630", "url": "https://en.wikipedia.org/wiki?curid=9058630", "title": "World energy consumption", "text": "World energy consumption\n\nWorld energy consumption is the total energy used by the entire human civilization. Typically measured per year, it involves all energy harnessed from every energy source applied towards humanity's endeavours across every single industrial and technological sector, across every country. It does not include energy from food, and the extent to which direct biomass burning has been accounted for is poorly documented. Being the power source metric of civilization, World Energy Consumption has deep implications for humanity's socio-economic-political sphere.\n\nInstitutions such as the International Energy Agency (IEA), the U.S. Energy Information Administration (EIA), and the European Environment Agency (EEA) record and publish energy data periodically. Improved data and understanding of World Energy Consumption may reveal systemic trends and patterns, which could help frame current energy issues and encourage movement towards collectively useful solutions.\n\nClosely related to energy consumption is the concept of total primary energy supply (TPES), which - on a global level - is the sum of energy production minus storage changes. Since changes of energy storage over the year are minor, TPES values can be used as an estimator for energy consumption. However, TPES ignores conversion efficiency, overstating forms of energy with poor conversion efficiency (e.g. coal, gas and nuclear) and understating forms already accounted for in converted forms (e.g. photovoltaic or hydroelectricity). The IEA estimates that, in 2013, total primary energy supply (TPES) was 1.575 × 10 Wh (= 157.5 PWh, 157,500 TWh, 5.67 × 10 joules, or 13,541 Mtoe) or about 18 TW-year. From 2000–2012 coal was the source of energy with the largest growth. The use of oil and natural gas also had considerable growth, followed by hydropower and renewable energy. Renewable energy grew at a rate faster than any other time in history during this period. The demand for nuclear energy decreased, in part due to nuclear disasters (e.g. Three Mile Island 1979, Chernobyl 1986, and Fukushima 2011).\n\nIn 2011, expenditures on energy totalled over 6 trillion USD, or about 10% of the world gross domestic product (GDP). Europe spends close to one-quarter of the world's energy expenditures, North America close to 20%, and Japan 6%.\nWorld total primary energy supply (TPES), or \"primary energy\" differs from the world final energy consumption because much of the energy that is acquired by humans is lost as other forms of energy during the process of its refinement into usable forms of energy and its transport from its initial place of supply to consumers. For instance, when oil is extracted from the ground it must be refined into gasoline, so that it can be used in a car, and transported over long distances to gas stations where it can be used by consumers. World final energy consumption refers to the fraction of the world's primary energy that is used in its final form by humanity.\n\nAlso, one needs to bear in mind that there are different qualities of energy. Heat, especially at a relatively low temperature, is low-quality energy, whereas electricity is high-quality energy. It takes around 3 kWh of heat to produce 1 kWh of electricity. But by the same token, a kilowatt-hour of this high-quality electricity can be used to pump several kilowatt-hours of heat into a building using a heat pump. And electricity can be used in many ways in which heat cannot. So the \"loss\" of energy incurred when generating electricity is not the same as a loss due, say, to resistance in power lines\n\nIn 2014, world primary energy supply amounted to 155,481 terawatt-hour (TWh) or 13,541 Mtoe, while the world final energy consumption was 109,613 TWh or about 29.5% less than the total supply. World final energy consumption includes products as lubricants, asphalt and petrochemicals which have chemical energy content but are not used as fuel. This non-energy use amounted to \n9,723 TWh (836 Mtoe) in 2015.\n\nThe United States Energy Information Administration (EIA) regularly publishes a report on world consumption for most types of primary energy resources. For 2013, estimated world energy consumption was 5.67 × 10 joules, or 157,481 TWh. According to the IEA the total world energy consumption in past years was 143,851 TWh in 2008, 133,602 TWh in 2005, 117,687 TWh in 2000, and 102,569 TWh in 1990. In 2012 approximately 22% of world energy was consumed in North America, 5% was consumed South and Central America, 23% was consumed in Europe and Eurasia, 3% was consumed in Africa, and 40% was consumed in the Asia Pacific region.\n\nThe total amount of electricity consumed worldwide was 19,504 TWh in 2013, 16,503 TWh in 2008, 15,105 TWh in 2005, and 12,116 TWh in 2000. \nBy the end of 2014, the total installed electricity generating capacity worldwide was nearly 6.142 TW (million MW) which only includes generation connected to local electricity grids. \nIn addition there is an unknown amount of heat and electricity consumed off-grid by isolated villages and industries. \nIn 2014, the share of world energy consumption for electricity generation by source was coal at 40.8%, natural gas at 21.6%, nuclear at 10.6%, hydro at 16.4%, other sources (solar, wind, geothermal, biomass, etc.) at 6.3% and oil at 4.3%. \nCoal and natural gas were the most used energy fuels for generating electricity. \nThe world's electricity consumption was 18,608 TWh in 2012. \nThis figure is about 18% smaller than the generated electricity, due to grid losses, storage losses, and self-consumption from power plants (gross generation). \nCogeneration (CHP) power stations use some of the heat that is otherwise wasted for use in buildings or in industrial processes.\n\nIn 2016 while total world energy came from 80% fossil fuels, 10% biofuels, 5% nuclear and 5% renewable (hydro, wind, solar, geothermal), only 18% of that total world energy was in the form of electricity. Most of the other 82% was used for heat and transportation.\n\nRecently there has been a large increase in international agreements and national Energy Action Plans, such as the EU 2009 Renewable Energy Directive, to increase the use of renewable energy due to the growing concerns about pollution from energy sources that come from fossil fuels such as oil, coal, and natural gas. One such initiative was the United Nations Development Programme's World Energy Assessment in 2000 that highlighted many challenges humanity would have to overcome in order to shift from fossil fuels to renewable energy sources. From 2000–2012 renewable energy grew at a rate higher than any other point in history, with a consumption increase of 176.5 million tonnes of oil. During this period, oil, coal, and natural gas continued to grow and had increases that were much higher than the increase in renewable energy. The following figures illustrate the growth in consumption of fossil fuels such as oil, coal, and natural gas as well as renewable sources of energy during this period.\n\nThe energy consumption growth in the G20 slowed down to 2% in 2011, after the strong increase of 2010. The economic crisis is largely responsible for this slow growth. For several years now, the world energy demand is characterized by the bullish Chinese and Indian markets, while developed countries struggle with stagnant economies, high oil prices, resulting in stable or decreasing energy consumption.\n\nAccording to IEA data from 1990 to 2008, the average energy use per person increased 10% while world population increased 27%. Regional energy use also grew from 1990 to 2008: the Middle East increased by 170%, China by 146%, India by 91%, Africa by 70%, Latin America by 66%, the USA by 20%, the EU-27 block by 7%, and world overall grew by 39%.\n\nIn 2008, total worldwide primary energy consumption was 132,000 terawatt-hours (TWh) or 474 exajoules (EJ). In 2012, primary energy demand increased to 158,000 TWh (567 EJ).\n\nEnergy consumption in the G20 increased by more than 5% in 2010 after a slight decline of 2009. In 2009, world energy consumption decreased for the first time in 30 years by 1.1%, or about 130 million tonnes of oil equivalent (Mtoe), as a result of the financial and economic crisis, which reduced world GDP by 0.6% in 2009.\n\nThis evolution is the result of two contrasting trends: Energy consumption growth remained vigorous in several developing countries, specifically in Asia (+4%). Conversely, in OECD, consumption was severely cut by 4.7% in 2009 and was thus almost down to its 2000 levels. In North America, Europe and the CIS, consumptions shrank by 4.5%, 5% and 8.5% respectively due to the slowdown in economic activity. China became the world's largest energy consumer (18% of the total) since its consumption surged by 8% during 2009 (up from 4% in 2008). Oil remained the largest energy source (33%) despite the fact that its share has been decreasing over time. Coal posted a growing role in the world's energy consumption: in 2009, it accounted for 27% of the total.\n\nMost energy is used in the country of origin, since it is cheaper to transport final products than raw materials. In 2008, the share export of the total energy production by fuel was: oil 50% (1,952/3,941 Mt), gas 25% (800/3,149 bcm) and hard coal 14% (793/5,845 Mt).\n\nMost of the world's high energy resources are from the conversion of the sun's rays to other energy forms after being incident upon the planet. Some of that energy has been preserved as fossil energy, some is directly or indirectly usable; for example, via solar PV/thermal, wind, hydro- or wave power. The total solar irradiance is measured by satellite to be roughly 1361 watts per square meter \"(see solar constant)\", though it fluctuates by about 6.9% during the year due to the Earth's varying distance from the sun. This value, after multiplication by the cross-sectional area intercepted by the Earth, is the total rate of solar energy received by the planet; about half, 89,000 TW, reaches the Earth's surface.\n\nThe estimates of remaining non-renewable worldwide energy resources vary, with the remaining fossil fuels totaling an estimated 0.4  yottajoule (YJ) or 4 × 10 joules, and the available nuclear fuel such as uranium exceeding 2.5 YJ. Fossil fuels range from 0.6 to 3 YJ if estimates of reserves of methane clathrates are accurate and become technically extractable. The total power flux from the sun intercepting the Earth is 5.5 YJ per year, though not all of this is available for human consumption. The IEA estimates for the world to meet global energy demand for the two decades from 2015 to 2035 it will require investment of $48 trillion and \"credible policy frameworks.\"\n\nAccording to IEA (2012) the goal of limiting warming to 2 °C is becoming more difficult and costly with each year that passes. If action is not taken before 2017, CO emissions would be locked-in by energy infrastructure existing in 2017. Fossil fuels are dominant in the global energy mix, supported by $523 billion subsidies in 2011, up almost 30% on 2010 and six times more than subsidies to renewables.\n\nGlobal warming emissions resulting from energy production are an environmental problem. Efforts to resolve this include the Kyoto Protocol (1997) and the Paris Agreement (2015), international governmental agreements aiming to reduce harmful climate impacts, which a number of nations have signed. Limiting global temperature increase to 2 degrees Celsius, thought to be a risk by the SEI, is now doubtful.\n\nTo limit global temperature to a hypothetical 2 degrees Celsius rise would demand a 75% decline in carbon emissions in industrial countries by 2050, if the population is 10 billion in 2050. Across 40 years, this averages to a 2% decrease every year. In 2011, the emissions of energy production continued rising regardless of the consensus of the basic problem. Hypothetically, according to Robert Engelman (Worldwatch institute), in order to prevent collapse, human civilization would have to stop increasing emissions within a decade regardless of the economy or population (2009).\n\nGreenhouse gases are not the only emissions of energy production and consumption. Large amounts of pollutants such as sulphurous oxides (SO), nitrous oxides (NO), and particulate matter (PM) are produced from the combustion of fossil fuels and biomass; the World Health Organization estimates that 7 million premature deaths are caused each year by air pollution. Biomass combustion is a major contributor. In addition to producing air pollution like fossil fuel combustion, most biomass has high CO emissions.\n\nThe twentieth century saw a rapid twenty-fold increase in the use of fossil fuels. Between 1980 and 2006, the worldwide annual growth rate was 2%. According to the US Energy Information Administration's 2006 estimate, the estimated 471.8 EJ total consumption in 2004, was divided as given in the table above, with fossil fuels supplying 86% of the world's energy:\n\nIn 2000, China accounted for 28% of world coal consumption, other Asia consumed 19%, North America 25% and the EU 14%. The single greatest coal-consuming country is China. Its share of the world coal production was 28% in 2000 and rose to 48% in 2009. In contrast to China's ~70% increase in coal consumption, world coal use increased 48% from 2000 to 2009. In practice, the majority of this growth occurred in China and the rest in other Asia. China's energy consumption is mostly driven by the industry sector, the majority of which comes from coal consumption.\n\nWorld annual coal production increased 1,905 Mt or 32% in 6 years in 2011 compared to 2005, of which over 70% was in China and 8% in India. Coal production was in 2011 7,783 Mt, and 2009 6,903 Mt, equal to 12.7% production increase in two years.\n\nIf production and consumption of coal continue at the rate as in 2008, proven and economically recoverable world reserves of coal would last for about 150 years. This is much more than needed for an irreversible climate catastrophe. Coal is the largest source of carbon dioxide emissions in the world. According to James Hansen the single most important action needed to tackle the climate crisis is to reduce CO emissions from coal. Indonesia and Australia exported together 57.1% of the world coal export in 2011. China, Japan, South Korea, India and Taiwan had 65% share of all the world coal import in 2011.\n\nCoal fueled the industrial revolution in the 18th and 19th century. With the advent of the automobile, aeroplanes and the spreading use of electricity, oil became the dominant fuel during the twentieth century. The growth of oil as the largest fossil fuel was further enabled by steadily dropping prices from 1920 until 1973. After the oil shocks of 1973 and 1979, during which the price of oil increased from 5 to 45 US dollars per barrel, there was a shift away from oil. Coal, natural gas, and nuclear became the fuels of choice for electricity generation and conservation measures increased energy efficiency. In the U.S. the average car more than doubled the number of miles per gallon. Japan, which bore the brunt of the oil shocks, made spectacular improvements and now has the highest energy efficiency in the world. From 1965 to 2008, the use of fossil fuels has continued to grow and their share of the energy supply has increased. From 2003 to 2008, coal was the fastest growing fossil fuel.\n\nIt is estimated that between 100 and 135 billion tonnes of oil has been consumed between 1850 and the present.\n\nIn 2009, the world use of natural gas grew 31% compared to 2000. 66% of this growth was outside EU, North America, Latin America, and Russia. Others include the Middle East, Asia, and Africa. The gas supply increased also in the previous regions: 8.6% in the EU and 16% in the North America 2000–2009.\n\nAs of 1 July 2016, the world had 444 operable grid-electric nuclear power reactors with 62 others under construction. Since commercial nuclear energy began in the mid 1950s, 2008 was the first year that no new nuclear power plant was connected to the grid, although two were connected in 2009.\n\nAnnual generation of nuclear power has been on a slight downward trend since 2007, decreasing 1.8% in 2009 to 2558 TWh, and another 1.6% in 2011 to 2518 TWh, despite increases in production from most countries worldwide, because those increases were more than offset by decreases in Germany and Japan. Nuclear power met 11.7% of the world's electricity demand in 2011. Source: IEA/OECD\n\nRenewable energy is generally defined as energy that comes from resources that are not significantly depleted by their use, such as sunlight, wind, rain, tides, waves and geothermal heat. Renewable energy is gradually replacing conventional fuels in four distinct areas: electricity generation, hot water/space heating, motor fuels, and rural (off-grid) energy services.\n\nBased on REN21's 2014 report, renewables contributed 19 percent to our energy consumption and 22 percent to our electricity generation in 2012 and 2013, respectively. This energy consumption is divided as 9% coming from traditional biomass, 4.2% as heat energy (non-biomass), 3.8% hydro electricity and 2% electricity from wind, solar, geothermal, and biomass. Worldwide investments in renewable technologies amounted to more than US$214 billion in 2013, with countries like China and the United States heavily investing in wind, hydro, solar and biofuels. Renewable energy resources exist over wide geographical areas, in contrast to other energy sources, which are concentrated in a limited number of countries. Rapid deployment of renewable energy and energy efficiency is resulting in significant energy security, climate change mitigation, and economic benefits. In international public opinion surveys there is strong support for promoting renewable sources such as solar power and wind power. At the national level, at least 30 nations around the world already have renewable energy contributing more than 20 percent of energy supply. National renewable energy markets are projected to continue to grow strongly in the coming decade and beyond.\n\nThe following table shows increasing nameplate capacity, and has capacity factors that range from 11% for solar, to 40% for hydropower.\n\nFrom 2000 to 2013 the total renewable energy use has increased 6,450 TWh and total energy use 40,500 TWh.\n\nHydroelectricity is the term referring to electricity generated by hydropower; the production of electrical power through the use of the kinetic energy of falling or flowing water. In 2015 hydropower generated 16.6% of the world's total electricity and 70% of all renewable electricity, which continues the rapid rate of increase experienced between 2003 and 2009. Hydropower is produced in 150 countries, with the Asia-Pacific region generating 32 percent of global hydropower in 2010. China is the largest hydroelectricity producer, with of production in 2010, representing around 17% of domestic electricity use. There are now three hydroelectricity plants larger than 10 GW: the Three Gorges Dam in China, Itaipu Dam in Brazil, and Guri Dam in Venezuela. Nine of the worlds top 10 renewable electricity producers are primarily hydroelectric, one is wind.\n\nMarine energy, also known as \"ocean energy\" and \"marine and hydrokinetic energy\" (MHK) includes tidal and wave power and is a relatively new sector of renewable energy, with most projects still in the pilot phase, but the theoretical potential is equivalent to 4–18 million tonne of oil equivalent (toe). MHK development in U.S. and international waters includes projects using devices such as, wave energy converters in open coastal areas with significant waves, tidal turbines placed in coastal and estuarine areas, in-stream turbines in fast-moving rivers, ocean current turbines in areas of strong marine currents, and ocean thermal energy converters in deep tropical waters.\n\nWind power is growing at the rate of 17% annually, with a worldwide installed capacity of 432,883 megawatts (MW) at the end of 2015, and is widely used in Europe, Asia, and the United States. Several countries have achieved relatively high levels of wind power penetration, such as 21% of stationary electricity production in Denmark, 18% in Portugal, 16% in Spain, 14% in Ireland and 9% in Germany in 2010. As of 2011, 83 countries around the world are using wind power on a commercial basis. Continuing strong growth, by 2016 wind generated 3% of global power annually.\n\nSolar energy, radiant light and heat from the sun, has been harnessed by humans since ancient times using a range of ever-evolving technologies. Solar energy technologies include solar heating, solar photovoltaics, concentrated solar power and solar architecture, which can make considerable contributions to solving some of the most urgent problems the world now faces. The International Energy Agency projected that solar power could provide \"a third of the global final energy demand after 2060, while CO emissions would be reduced to very low levels.\" Solar technologies are broadly characterized as either passive solar or active solar depending on the way they capture, convert and distribute solar energy. Active solar techniques include the use of photovoltaic systems and solar thermal collectors to harness the energy. Passive solar techniques include orienting a building to the Sun, selecting materials with favorable thermal mass or light dispersing properties, and designing spaces that naturally circulate air. From 2012 to 2016 solar capacity tripled and now provides 1.3% of global energy.\n\nGeothermal energy is used commercially in over 70 countries. In 2004, of electricity was generated from geothermal resources, and an additional of geothermal energy was used directly, mostly for space heating. In 2007, the world had a global capacity for of electricity generation and an additional of direct heating, including extraction by geothermal heat pumps. Heat pumps are small and widely distributed, so estimates of their total capacity are uncertain and range up to .\n\nUntil the beginning of the nineteenth century biomass was the predominant fuel, today it has only a small share of the overall energy supply. Electricity produced from biomass sources was estimated at 44 GW for 2005. Biomass electricity generation increased by over 100% in Germany, Hungary, the Netherlands, Poland, and Spain. A further 220 GW was used for heating (in 2004), bringing the total energy consumed from biomass to around 264 GW. The use of biomass fires for cooking is excluded. World production of bioethanol increased by 8% in 2005 to reach , with most of the increase in the United States, bringing it level to the levels of consumption in Brazil. Biodiesel increased by 85% to , making it the fastest growing renewable energy source in 2005. Over 50% is produced in Germany.\n\nEnergy consumption is loosely correlated with gross national product and climate, but there is a large difference even between the most highly developed countries, such as Japan and Germany with an energy consumption rate of 6 kW per person and the United States with an energy consumption rate of 11.4 kW per person. In developing countries, particularly those that are sub-tropical or tropical such as India, the per person energy use rate is closer to 0.7 kW. Bangladesh has the lowest consumption rate with 0.2 kW per person.\n\nThe US consumes 25% of the world's energy with a share of global GDP at 22% and a share of the world population at 4.59%. The most significant growth of energy consumption is currently taking place in China, which has been growing at 5.5% per year over the last 25 years. Its population of 1.3 billion people (19.6% of the world population) is consuming energy at a rate of 1.6 kW per person.\n\nOne measurement of efficiency is energy intensity. This is a measure of the amount of energy it takes a country to produce a dollar of gross domestic product.\n\nSaudi Arabia, Russia and the United States accounted for 34% of oil production in 2011. Saudi Arabia, Russia and Nigeria accounted for 36% of oil export in 2011.\n\nThe table to the right shows the amounts of energy consumed worldwide in 2012 by four sectors, according to the Energy Information Administration of the US Department of Energy:\nOf the total 120 PWh () consumed, 19.4 were in the form of electricity, but this electricity required 61.7 PWh to produce. Thus the total energy consumption was around 160 PWh (ca ). The efficiency of a typical existing power plant is around 38%. The new generation of gas-fired plants reaches a substantially higher efficiency of 55%. Coal is the most common fuel for the world's electricity plants.\n\nAnother report gives different values for the sectors, apparently due to different definitions. According to this, total world energy use per sector in 2008 was industry 28%, transport 27% and residential and service 36%. Division was about the same in the year 2000.\n\nThe European Environmental Agency (EEA) measures final energy consumption (does not include energy used in production and lost in transportation) and finds that the transport sector is responsible for 31.8% of final energy consumption, households 26.2%, industry 25.6%, services 13.5% and agriculture 2.9% in 2012. The use of energy is responsible for the majority of greenhouse gas emissions (79%), with the energy sector representing 31%, transport 19%, industry 13%, households 9% and others 7%.\n\nWhile efficient energy use and resource efficiency are growing as public policy issues, more than 70% of coal plants in the European Union are more than 20 years old and operate at an efficiency level of between 32–40%. Technological developments in the 1990s have allowed efficiencies in the range of 40–45% at newer plants. However, according to an impact assessment by the European Commission, this is still below the best available technological (BAT) efficiency levels of 46–49%. With gas-fired power plants the average efficiency is 52% compared to 58–59% with best available technology (BAT), and gas and oil boiler plants operate at average 36% efficiency (BAT delivers 47%). According to that same impact assessment by the European Commission, raising the efficiency of all new plants and the majority of existing plants, through the setting of authorisation and permit conditions, to an average generation efficiency of 51.5% in 2020 would lead to a reduction in annual consumption of of natural gas and of coal.\n\n\n\n"}
{"id": "28682776", "url": "https://en.wikipedia.org/wiki?curid=28682776", "title": "Zero world government", "text": "Zero world government\n\nZero world government refers to a hypothetical future in which national governments cease to exist or to matter, as a result of globalization and a worldwide rejection of politics, as known today. The term contrasts with that of one world government in the sense that rather than there being a world-state, there are no political states in the world.\n\n"}
