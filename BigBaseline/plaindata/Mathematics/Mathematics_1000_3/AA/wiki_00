{"id": "12637741", "url": "https://en.wikipedia.org/wiki?curid=12637741", "title": "AWM/MAA Falconer Lecturer", "text": "AWM/MAA Falconer Lecturer\n\nThe Etta Z. Falconer Lecture is an award and lecture series which honors \"women who have made distinguished contributions to the mathematical sciences or mathematics education\". It is sponsored by the Association for Women in Mathematics and the Mathematical Association of America. The lectures began in 1996 and were named after the mathematician Etta Z. Falconer in 2004 \"in memory of Falconer's profound vision and accomplishments in enhancing the movement of minorities and women into scientific careers\". The recipient presents the lecture at MathFest each summer.\n\nThe Falconer Lecturers have been:\n\n"}
{"id": "44688", "url": "https://en.wikipedia.org/wiki?curid=44688", "title": "Almost everywhere", "text": "Almost everywhere\n\nIn measure theory (a branch of mathematical analysis), a property holds almost everywhere if, in a technical sense, the set for which the property holds takes up nearly all possibilities. The notion of almost everywhere is a companion notion to the concept of measure zero. In the subject of probability, which is largely based in measure theory, the notion is referred to as \"almost surely\".\n\nMore specifically, a property holds almost everywhere if the set of elements for which the property does not hold is a set of measure zero (Halmos 1974), or equivalently if the set of elements for which the property holds is conull. In cases where the measure is not complete, it is sufficient that the set is contained within a set of measure zero. When discussing sets of real numbers, the Lebesgue measure is assumed unless otherwise stated.\n\nThe term \"almost everywhere\" is abbreviated \"a.e.\"; in older literature \"p.p.\" is used, to stand for the equivalent French language phrase \"presque partout\".\n\nA set with full measure is one whose complement is of measure zero. In probability theory, the terms \"almost surely\", \"almost certain\" and \"almost always\" refer to events with probability 1, which are exactly the sets of full measure in a probability space.\n\nOccasionally, instead of saying that a property holds almost everywhere, it is said that the property holds for almost all elements (though the term almost all also has other meanings).\n\nIf formula_1 is a measure space, a property formula_2 is said to hold almost everywhere in formula_3 if there exists a set formula_4 with formula_5, and for formula_6, formula_7 has property formula_2. Another common way of expressing the same thing is to say that \"almost every point satisfies formula_2\" or \"for almost every formula_7, formula_11 holds\".\n\nIt is \"not\" required that the set formula_12 has measure 0; it may not belong to formula_13.\n\n\nAs a consequence of the first two properties, it is often possible to reason about \"almost every point\" of a measure space as though it were an ordinary point rather than an abstraction. This is often done implicitly in informal mathematical arguments. However, one must be careful with this mode of reasoning because of the third bullet above: universal quantification over uncountable families of statements is valid for ordinary points but not for \"almost every point\".\n\nOutside of the context of real analysis, the notion of a property true almost everywhere is sometimes defined in terms of an ultrafilter. An ultrafilter on a set \"X\" is a maximal collection \"F\" of subsets of \"X\" such that:\nA property \"P\" of points in \"X\" holds almost everywhere, relative to an ultrafilter \"F\", if the set of points for which \"P\" holds is in \"F\".\n\nFor example, one construction of the hyperreal number system defines a hyperreal number as an equivalence class of sequences that are equal almost everywhere as defined by an ultrafilter.\n\nThe definition of \"almost everywhere\" in terms of ultrafilters is closely related to the definition in terms of measures, because each ultrafilter defines a finitely-additive measure taking only the values 0 and 1, where a set has measure 1 if and only if it is included in the ultrafilter.\n\n"}
{"id": "677", "url": "https://en.wikipedia.org/wiki?curid=677", "title": "Ambiguity", "text": "Ambiguity\n\nAmbiguity is a type of meaning in which several interpretations are plausible. A common aspect of ambiguity is uncertainty. It is thus an attribute of any idea or statement whose intended meaning cannot be definitively resolved according to a rule or process with a finite number of steps. (The \"ambi-\" part of the term reflects an idea of \"two\", as in \"two meanings\".)\n\nThe concept of ambiguity is generally contrasted with vagueness. In ambiguity, specific and distinct interpretations are permitted (although some may not be immediately obvious), whereas with information that is vague, it is difficult to form any interpretation at the desired level of specificity.\n\nContext may play a role in resolving ambiguity. For example, the same piece of information may be ambiguous in one context and unambiguous in another.\n\nThe lexical ambiguity of a word or phrase pertains to its having more than one meaning in the language to which the word belongs. \"Meaning\" here refers to whatever should be captured by a good dictionary. For instance, the word \"bank\" has several distinct lexical definitions, including \"financial institution\" and \"edge of a river\". Or consider \"apothecary\". One could say \"I bought herbs from the apothecary\". This could mean one actually spoke to the apothecary (pharmacist) or went to the apothecary (pharmacy).\n\nThe context in which an ambiguous word is used often makes it evident which of the meanings is intended. If, for instance, someone says \"I buried $100 in the bank\", most people would not think someone used a shovel to dig in the mud. However, some linguistic contexts do not provide sufficient information to disambiguate a used word.\n\nLexical ambiguity can be addressed by algorithmic methods that automatically associate the appropriate meaning with a word in context, a task referred to as word sense disambiguation.\n\nThe use of multi-defined words requires the author or speaker to clarify their context, and sometimes elaborate on their specific intended meaning (in which case, a less ambiguous term should have been used). The goal of clear concise communication is that the receiver(s) have no misunderstanding about what was meant to be conveyed. An exception to this could include a politician whose \"weasel words\" and obfuscation are necessary to gain support from multiple constituents with mutually exclusive conflicting desires from their candidate of choice. Ambiguity is a powerful tool of political science.\n\nMore problematic are words whose senses express closely related concepts. \"Good\", for example, can mean \"useful\" or \"functional\" (\"That's a good hammer\"), \"exemplary\" (\"She's a good student\"), \"pleasing\" (\"This is good soup\"), \"moral\" (\"a good person\" versus \"the lesson to be learned from a story\"), \"righteous\", etc. \" I have a good daughter\" is not clear about which sense is intended. The various ways to apply prefixes and suffixes can also create ambiguity (\"unlockable\" can mean \"capable of being unlocked\" or \"impossible to lock\").\n\nSyntactic ambiguity arises when a sentence can have two (or more) different meanings because of the structure of the sentence—its syntax. This is often due to a modifying expression, such as a prepositional phrase, the application of which is unclear. \"He ate the cookies on the couch\", for example, could mean that he ate those cookies that were on the couch (as opposed to those that were on the table), or it could mean that he was sitting on the couch when he ate the cookies. \"To get in, you will need an entrance fee of $10 or your voucher and your drivers' license.\" This could mean that you need EITHER ten dollars OR BOTH your voucher and your license. Or it could mean that you need your license AND you need EITHER ten dollars OR a voucher. Only rewriting the sentence, or placing appropriate punctuation can resolve a syntactic ambiguity.\nFor the notion of, and theoretic results about, syntactic ambiguity in artificial, formal languages (such as computer programming languages), see Ambiguous grammar.\n\nSpoken language can contain many more types of ambiguities which are called phonological ambiguities, where there is more than one way to compose a set of sounds into words. For example, \"ice cream\" and \"I scream\". Such ambiguity is generally resolved according to the context. A mishearing of such, based on incorrectly resolved ambiguity, is called a mondegreen.\n\nSemantic ambiguity happens when a sentence contains an ambiguous word or phrase—a word or phrase that has more than one meaning. In \"We saw her duck\" (example due to Richard Nordquist), the word \"duck\" can refer either\n\nLexical ambiguity is contrasted with semantic ambiguity. The former represents a choice between a finite number of known and meaningful context-dependent interpretations. The latter represents a choice between any number of possible interpretations, none of which may have a standard agreed-upon meaning. This form of ambiguity is closely related to vagueness.\n\nLinguistic ambiguity can be a problem in law, because the interpretation of written documents and oral agreements is often of paramount importance.\n\nPhilosophers (and other users of logic) spend a lot of time and effort searching for and removing (or intentionally adding) ambiguity in arguments because it can lead to incorrect conclusions and can be used to deliberately conceal bad arguments. For example, a politician might say, \"I oppose taxes which hinder economic growth\", an example of a glittering generality. Some will think he opposes taxes in general because they hinder economic growth. Others may think he opposes only those taxes that he believes will hinder economic growth. In writing, the sentence can be rewritten to reduce possible misinterpretation, either by adding a comma after \"taxes\" (to convey the first sense) or by changing \"which\" to \"that\" (to convey the second sense) or by rewriting it in other ways. The devious politician hopes that each constituent will interpret the statement in the most desirable way, and think the politician supports everyone's opinion. However, the opposite can also be true – an opponent can turn a positive statement into a bad one if the speaker uses ambiguity (intentionally or not). The logical fallacies of amphiboly and equivocation rely heavily on the use of ambiguous words and phrases.\n\nIn continental philosophy (particularly phenomenology and existentialism), there is much greater tolerance of ambiguity, as it is generally seen as an integral part of the human condition. Martin Heidegger argued that the relation between the subject and object is ambiguous, as is the relation of mind and body, and part and whole.[3] In Heidegger's phenomenology, Dasein is always in a meaningful world, but there is always an underlying background for every instance of signification. Thus, although some things may be certain, they have little to do with Dasein's sense of care and existential anxiety, e.g., in the face of death. In calling his work Being and Nothingness an \"essay in phenomenological ontology\" Jean-Paul Sartre follows Heidegger in defining the human essence as ambiguous, or relating fundamentally to such ambiguity. Simone de Beauvoir tries to base an ethics on Heidegger's and Sartre's writings (The Ethics of Ambiguity), where she highlights the need to grapple with ambiguity: \"as long as philosophers and they [men] have thought, most of them have tried to mask it...And the ethics which they have proposed to their disciples have always pursued the same goal. It has been a matter of eliminating the ambiguity by making oneself pure inwardness or pure externality, by escaping from the sensible world or being engulfed by it, by yielding to eternity or enclosing oneself in the pure moment.\" Ethics cannot be based on the authoritative certainty given by mathematics and logic, or prescribed directly from the empirical findings of science. She states: \"Since we do not succeed in fleeing it, let us, therefore, try to look the truth in the face. Let us try to assume our fundamental ambiguity. It is in the knowledge of the genuine conditions of our life that we must draw our strength to live and our reason for acting\". Other continental philosophers suggest that concepts such as life, nature, and sex are ambiguous. Corey Anton has argued that we cannot be certain what is separate from or unified with something else: language, he asserts, divides what is not, in fact, separate. Following Ernest Becker, he argues that the desire to 'authoritatively disambiguate' the world and existence has led to numerous ideologies and historical events such as genocide. On this basis, he argues that ethics must focus on 'dialectically integrating opposites' and balancing tension, rather than seeking a priori validation or certainty. Like the existentialists and phenomenologists, he sees the ambiguity of life as the basis of creativity.\n\nIn literature and rhetoric, ambiguity can be a useful tool. Groucho Marx's classic joke depends on a grammatical ambiguity for its humor, for example: \"Last night I shot an elephant in my pajamas. How he got in my pajamas, I'll never know\". Songs and poetry often rely on ambiguous words for artistic effect, as in the song title \"Don't It Make My Brown Eyes Blue\" (where \"blue\" can refer to the color, or to sadness).\n\nIn the narrative, ambiguity can be introduced in several ways: motive, plot, character. F. Scott Fitzgerald uses the latter type of ambiguity with notable effect in his novel \"The Great Gatsby\".\n\nChristianity and Judaism employ the concept of paradox synonymously with 'ambiguity'. Many Christians and Jews endorse Rudolf Otto's description of the sacred as 'mysterium tremendum et fascinans', the awe-inspiring mystery which fascinates humans.[dubious – discuss] The orthodox Catholic writer G. K. Chesterton regularly employed paradox to tease out the meanings in common concepts which he found ambiguous or to reveal meaning often overlooked or forgotten in common phrases. (The title of one of his most famous books, Orthodoxy, itself employing such a paradox.)\n\nMetonymy involves the use of the name of a subcomponent part as an abbreviation, or jargon, for the name of the whole object (for example \"wheels\" to refer to a car, or \"flowers\" to refer to beautiful offspring, an entire plant, or a collection of blooming plants). In modern vocabulary, critical semiotics,[9] metonymy encompasses any potentially ambiguous word substitution that is based on contextual contiguity (located close together), or a function or process that an object performs, such as \"sweet ride\" to refer to a nice car. Metonym miscommunication is considered a primary mechanism of linguistic humor.\n\nIn music, pieces or sections which confound expectations and may be or are interpreted simultaneously in different ways are ambiguous, such as some polytonality, polymeter, other ambiguous meters or rhythms, and ambiguous phrasing, or (Stein 2005, p. 79) any aspect of music. The music of Africa is often purposely ambiguous. To quote Sir Donald Francis Tovey (1935, p. 195), \"Theorists are apt to vex themselves with vain efforts to remove uncertainty just where it has a high aesthetic value.\"\n\nIn visual art, certain images are visually ambiguous, such as the Necker cube, which can be interpreted in two ways. Perceptions of such objects remain stable for a time, then may flip, a phenomenon called multistable perception.\nThe opposite of such ambiguous images are impossible objects.\n\nPictures or photographs may also be ambiguous at the semantic level: the visual image is unambiguous, but the meaning and narrative may be ambiguous: is a certain facial expression one of excitement or fear, for instance?\n\nSome languages have been created with the intention of avoiding ambiguity, especially lexical ambiguity. Lojban and Loglan are two related languages which have been created for this, focusing chiefly on syntactic ambiguity as well. The languages can be both spoken and written. These languages are intended to provide a greater technical precision over big natural languages, although historically, such attempts at language improvement have been criticized. Languages composed from many diverse sources contain much ambiguity and inconsistency. The many exceptions to syntax and semantic rules are time-consuming and difficult to learn.\n\nIn computer science, the SI prefixes kilo-, mega- and giga- were historically used in certain contexts to mean either the first three powers of 1024 (1024, 1024 and 1024) contrary to the metric system in which these units unambiguously mean one thousand, one million, and one billion. This usage is particularly prevalent with electronic memory devices (e.g. DRAM) addressed directly by a binary machine register where a decimal interpretation makes no practical sense.\n\nSubsequently, the Ki, Mi, and Gi prefixes were introduced so that binary prefixes could be written explicitly, also rendering k, M, and G \"unambiguous\" in texts conforming to the new standard — this led to a \"new\" ambiguity in engineering documents lacking outward trace of the binary prefixes (necessarily indicating the new style) as to whether the usage of k, M, and G remains ambiguous (old style) or not (new style). Note also that 1 M (where M is ambiguously 1,000,000 or 1,048,576) is \"less\" uncertain than the engineering value 1.0e6 (defined to designate the interval 950,000 to 1,050,000), and that as non-volatile storage devices began to commonly exceed 1 GB in capacity (where the ambiguity begins to routinely impact the second significant digit), GB and TB almost always mean 10 and 10 bytes.\n\nMathematical notation, widely used in physics and other sciences, avoids many ambiguities compared to expression in natural language. However, for various reasons, several lexical, syntactic and semantic ambiguities remain.\n\nThe ambiguity in the style of writing a function should not be confused with a multivalued function, which can (and should) be defined in a deterministic and unambiguous way. Several special functions still do not have established notations. Usually, the conversion to another notation requires to scale the argument or the resulting value; sometimes, the same name of the function is used, causing confusions. Examples of such underestablished functions:\n\nAmbiguous expressions often appear in physical and mathematical texts.\nIt is common practice to omit multiplication signs in mathematical expressions. Also, it is common to give the same name to a variable and a function, for example, formula_1. Then, if one sees formula_2, there is no way to distinguish whether it means formula_1 multiplied by formula_4, or function formula_5 evaluated at argument equal to formula_4. In each case of use of such notations, the reader is supposed to be able to perform the deduction and reveal the true meaning.\n\nCreators of algorithmic languages try to avoid ambiguities. Many algorithmic languages (C++ and Fortran) require the character * as symbol of multiplication. The Wolfram Language used in Mathematica allows the user to omit the multiplication symbol, but requires square brackets to indicate the argument of a function; square brackets are not allowed for grouping of expressions. Fortran, in addition, does not allow use of the same name (identifier) for different objects, for example, function and variable; in particular, the expression f=f(x) is qualified as an error.\n\nThe order of operations may depend on the context. In most programming languages, the operations of division and multiplication have equal priority and are executed from left to right. Until the last century, many editorials assumed that multiplication is performed first, for example, formula_7 is interpreted as formula_8; in this case, the insertion of parentheses is required when translating the formulas to an algorithmic language. In addition, it is common to write an argument of a function without parenthesis, which also may lead to ambiguity.\nSometimes, one uses \"italics\" letters to denote elementary functions.\nIn the scientific journal style, the expression\nformula_9\nmeans\nproduct of variables\nformula_10,\nformula_11,\nformula_12 and\nformula_13, although in a slideshow, it may mean formula_14.\n\nA comma in subscripts and superscripts sometimes is omitted; it is also ambiguous notation.\nIf it is written formula_15, the reader should guess from the context, does it mean a single-index object, evaluated while the subscript is equal to product of variables\nformula_16, formula_12 and formula_18, or it is indication to a trivalent tensor.\nThe writing of formula_15 instead of formula_20 may mean that the writer either is stretched in space (for example, to reduce the publication fees) or aims to increase number of publications without considering readers. The same may apply to any other use of ambiguous notations.\n\nSubscripts are also used to denote the argument to a function, as in formula_21.\nformula_22, which could be understood to mean either formula_23 or formula_24. In addition, formula_25 may mean formula_26, as formula_27 means formula_28 (see tetration).\n\nformula_29, which by convention means formula_30, though it might be thought to mean formula_31, since formula_32 means formula_33.\n\nformula_34, which arguably should mean formula_35 but would commonly be understood to mean formula_36 .\n\nIt is common to define the coherent states in quantum optics with formula_37 and states with fixed number of photons with formula_38. Then, there is an \"unwritten rule\": the state is coherent if there are more Greek characters than Latin characters in the argument, and formula_39photon state if the Latin characters dominate. The ambiguity becomes even worse, if formula_40 is used for the states with certain value of the coordinate, and formula_41 means the state with certain value of the momentum, which may be used in books on quantum mechanics. Such ambiguities easily lead to confusions, especially if some normalized adimensional, dimensionless variables are used. Expression formula_42 may mean a state with single photon, or the coherent state with mean amplitude equal to 1, or state with momentum equal to unity, and so on. The reader is supposed to guess from the context.\n\nSome physical quantities do not yet have established notations; their value (and sometimes even dimension, as in the case of the Einstein coefficients), depends on the system of notations. Many terms are ambiguous. Each use of an ambiguous term should be preceded by the definition, suitable for a specific case. Just like Ludwig Wittgenstein states in Tractatus Logico-Philosophicus: \"... Only in the context of a proposition has a name meaning.\"\n\nA highly confusing term is \"gain\". For example, the sentence \"the gain of a system should be doubled\", without context, means close to nothing.\nIt may mean that the ratio of the output voltage of an electric circuit to the input voltage should be doubled.\nIt may mean that the ratio of the output power of an electric or optical circuit to the input power should be doubled.\nIt may mean that the gain of the laser medium should be doubled, for example, doubling the population of the upper laser level in a quasi-two level system (assuming negligible absorption of the ground-state).\n\nThe term \"intensity\" is ambiguous when applied to light. The term can refer to any of irradiance, luminous intensity, radiant intensity, or radiance, depending on the background of the person using the term.\n\nAlso, confusions may be related with the use of atomic percent as measure of concentration of a dopant, or resolution of an imaging system, as measure of the size of the smallest detail which still can be resolved at the background of statistical noise. See also Accuracy and precision and its talk.\n\nThe Berry paradox arises as a result of systematic ambiguity in the meaning of terms such as \"definable\" or \"nameable\". Terms of this kind give rise to vicious circle fallacies. Other terms with this type of ambiguity are: satisfiable, true, false, function, property, class, relation, cardinal, and ordinal.\n\nIn mathematics and logic, ambiguity can be considered to be an instance of the logical concept of underdetermination—for example, formula_43 leaves open what the value of \"X\" is—while its opposite is a self-contradiction, also called inconsistency, paradoxicalness, or oxymoron, or in mathematics an inconsistent system—such as formula_44, which has no solution.\n\nLogical ambiguity and self-contradiction is analogous to visual ambiguity and impossible objects, such as the Necker cube and impossible cube, or many of the drawings of M. C. Escher.\n\n\n\n"}
{"id": "1525019", "url": "https://en.wikipedia.org/wiki?curid=1525019", "title": "Apostolos Doxiadis", "text": "Apostolos Doxiadis\n\nApostolos K. Doxiadis (; born 1953) is a Greek writer. He is best known for his international bestsellers \"Uncle Petros and Goldbach's Conjecture\" (2000) and \"Logicomix\" (2009).\n\nDoxiadis was born in Australia, where his father, the architect Constantinos Apostolou Doxiadis was working. Soon after his birth, the family returned to Athens, where Doxiadis grew up. Though his earliest interests were in poetry, fiction and the theatre, an intense interest in mathematics led Doxiadis to leave school at age fifteen, to attend Columbia University, in New York, from which he obtained a bachelor's degree in Mathematics in May 1972. He then attended the École Pratique des Hautes Études in Paris from which he got a master's degree, with a thesis on the mathematical modeling of the nervous system. His father’s death and family reasons made him return to Greece in 1975, interrupting his graduate studies. In Greece, although involved for some years with the computer software industry, Doxiadis returned to his childhood and adolescence loves of theatre and the cinema, before becoming a full-time writer.\n\nDoxiadis began to write in Greek. His first published work was \"A Parallel Life\" (\"Βίος Παράλληλος\", 1985), a novella set in the monastic communities of 4th century CE Egypt. His first novel, \"Makavettas\" (\"Μακαβέττας\", 1988), recounted the adventures of a fictional power-hungry colonel at the time of the Greek military junta of 1967–1974. Written in a tongue-in-cheek imitation of Greek folk military memoirs, such as that of Yannis Makriyannis, it follows the plot of Shakespeare’s \"Macbeth\", of which the eponymous hero’s name is a Hellenized form. Doxiadis next novel, \"Uncle Petros and Goldbach’s Conjecture\" (\"Ο Θείος Πέτρος και η Εικασία του Γκόλντμπαχ\", 1992), was the first long work of fiction whose plot takes place in the world of pure mathematics research. The first Greek critics did not find the mathematical themes appealing, and it received mediocre reviews, unlike Doxiadis’s first two works, which were well received. Τhe novella \"The Three Little Men\" (\"Τα Τρία Ανθρωπάκια\", 1998), attempts a modern-day retelling of the tale of a classic fairy-tale.\n\nIn 1998, Doxiadis translated into English, significantly re-working, his third novel, which was published in England in 2000 as \"Uncle Petros and Goldbach's Conjecture\" (UK publisher: Faber and Faber; United States publisher: Bloomsbury USA.) The book became an international bestseller, and has been published to date in more than thirty-five languages. It has received the praise of, among others, Nobel Laureate John Nash, British mathematician Sir Michael Atiyah, critic George Steiner and psychiatrist Oliver Sacks. \"Uncle Petros\" is one of the \"1001 Books You Must Read Before You Die\".\nDoxiadis’ next project, which took over five years to complete, was the graphic novel \"Logicomix\" (2009), a number one bestseller on the New York Times Bestseller List and an international bestseller, already published in over twenty languages. \"Logicomix\" was co-authored with computer scientist Christos Papadimitriou, with art work by Alecos Papadatos (pencils) and Annie Di Donna (color). Renowned comics historian and critic R. C. Harvey, in the \"Comics Journal\", called \"Logicomix\" “a tour-de-force” a “virtuoso performance”, while \"The Sunday Times\"’ Brian Appleyard called it “probably the best and certainly the most extraordinary graphic novel” he has read. \"Logicomix\" is one of Paul Gravett’s \"1001 Comics You Must Read Before you Die.\" \n\nIn the early stage of his career, Doxiadis directed in the professional theatre, in Athens, and worked as translator, translating, among other plays, William Shakespeare’s \"Romeo and Juliet\", \"Hamlet\" and \"Midsummer Night’s Dream\", as well as Eugene O’Neill’s \"Mourning Becomes Electra\".\n\nHe has written two plays for the theatre. The first was a full-length shadow-puppet play \"The Tragical History of Jackson Pollock, Abstract Expressionist\" (1999), in English, of which he also designed and directed the Athens performance. In this play, Doxiadis realized some of his views on “epic theatre”, in other words a theatre based on storytelling. His second play, \"Incompleteness\" (2005), is an imaginary account of the last seventeen days in the life of the great logician Kurt Gödel, which Gödel spent in a Princeton, New Jersey, hospital, refusing to eat out of fear that he was being poisoned. The play was staged in Athens, in 2006, as Dekati Evdomi Nyhta (Seventeenth Night) with the actor Yorgos Kotanidis in the role of Kurt Gödel.\n\nDoxiadis has also written and directed two feature-length films, in Greek, \"Underground Passage\" (\"Υπόγεια Διαδρομή\", 1983) and \"Terirem\" (\"Τεριρέμ\", 1987). The latter won the CICAE (International Confederation of Art Cinemas) prize for Best Film in the 1988 Berlin International Film Festival.\n\nDoxiadis has a lifelong interest in logic, cognitive psychology and rhetoric, as well as the theoretical study of narrative. In 2007, he organized, with mathematician Barry Mazur, a meeting on the theoretical investigation of the relationship of mathematics and narrative, whose proceedings were published as \"Circles Disturbed, The Interplay of Mathematics and Narrative\" (2012). Doxiadis has lectured extensively on his theoretical interests. Doxiadis’ recent work has led him to formulate a theory about the development of deductive proof in Classical Greece, which lays emphasis on influences from pre-existing patterns in narrative and, especially, Archaic Age Poetry.\n\n\"Uncle Petros and Goldbach’s Conjecture\" was the first recipient of the Premio Peano the first international award for books inspired by mathematics and short-listed for the Prix Médicis. \"Logicomix\" has earned numerous awards, among them the Bertrand Russell Society Award, the Royal Booksellers Association Award (the Netherlands), the New Atlantic Booksellers Award (USA), the Prix Tangente (France), the Premio Carlo Boscarato (Italy), the Comicdom Award (Greece). It was chosen as \"Book of the Year\" by \"TIME Magazine\", \"Publishers Weekly\", \"The Washington Post\", \"The Financial Times\", \"The Globe and Mail\", and other publications.\n\n"}
{"id": "32842052", "url": "https://en.wikipedia.org/wiki?curid=32842052", "title": "Argument of a function", "text": "Argument of a function\n\nIn mathematics, an argument of a function is a specific input in the function, also known as an independent variable. When it is clear from the context which argument is meant, the argument is often denoted by the abbreviation \"arg\".\n\nFor example, the binary function formula_1 has two arguments, formula_2 and formula_3, in an ordered pair formula_4. The hypergeometric function is an example of a four-argument function. The number of arguments that a function takes is called the arity of the function. A function that takes a single argument as input (such as formula_5) is called a unary function. A function of two or more variables is considered to have a domain consisting of ordered pairs or tuples of argument values. The argument of a circular function is an angle. The argument of a hyperbolic function is a hyperbolic angle.\n\nA mathematical function has one or more arguments in the form of independent variables designated in the definition, which can also contain parameters. The independent variables are mentioned in the list of arguments that the function takes, whereas the parameters are not. For example, in the logarithmic function formula_6, the base formula_7 is considered a parameter.\n\n\n"}
{"id": "20459000", "url": "https://en.wikipedia.org/wiki?curid=20459000", "title": "Ars inveniendi", "text": "Ars inveniendi\n\nArs inveniendi (Latin for \"art of invention\") is a chief notion of mathesis universalis and implies ascertaining truth through the use of mathematics.\n"}
{"id": "339496", "url": "https://en.wikipedia.org/wiki?curid=339496", "title": "As I was going to St Ives", "text": "As I was going to St Ives\n\n\"As I was going to St Ives\" is a traditional English-language nursery rhyme in the form of a riddle. Its Roud Folk Song Index number is 19772.\n\nThe most common modern version is:\n\nThe following version is found in a manuscript (Harley MS 7316) dating from approximately 1730: \n\nA version very similar to that accepted today was published in the \"Weekly Magazine\" of August 4, 1779:\n\nThe suggestion of polygamy (implicit in the line \"I met a man with seven wives\") is generally absent from the earliest publications, but is present by 1837.\n\nThere are a number of places called St Ives in England and elsewhere. It is generally thought\nthat the rhyme refers to St Ives, Cornwall, when it was a busy fishing port and had many cats to stop the rats and mice destroying the fishing gear, although some people argue it was St Ives, Cambridgeshire as this is an ancient market town and therefore an equally plausible destination.\n\nAll potential answers to this riddle are based on its ambiguity because the riddle only tells us the group has been \"met\" on the journey to St. Ives and gives no further information about its intentions, only those of the narrator. In modern usage, 'to meet someone on the road' may include the sense of 'passed' or 'overtook'; while the older usage may have referred exclusively to those going in opposite directions. As such, the 'correct' answer could be stated as \"at least one, the narrator plus anyone who happens to be travelling in the same direction as him or her\".\n\nIf the group that the narrator meets is assumed \"not\" to be travelling to St. Ives the answer could be \"one\" person going to St. Ives: the narrator. This is the most common assumption, as the purpose of the riddle was most likely to trick the listener into making long winded calculations only to be surprised by the simplicity of the answer.\n\nIf one disregards the 'trick' answer and assumes the narrator overtook the group as they were \"also\" travelling to St. Ives, the most common mathematical answer is 2802: 1 man, 7 wives, 49 sacks, 343 cats, and 2401 kits, plus the narrator (the sum of a geometric series, plus one).\n\nAfter the riddle was published in the August 4, 1779 issue of \"The Weekly Magazine\", as described above, a subsequent edition of that journal contained the following solution, submitted by reader \"Philo-Rhithmus\" of Edinburgh:\n\nA similar problem is found in the Rhind Mathematical Papyrus (Problem 79), dated to around 1650 BC.\nThe papyrus is translated as follows:\nThe problem appears to be an illustration of an algorithm for multiplying numbers. The sequence 7, 7, 7, 7, 7 appears in the right-hand column, and the terms 2,801, 2×2,801, 4×2,801 appear in the left; the sum on the left is 7×2,801 = 19,607, the same as the sum of the terms on the right. The equality of the two geometric sequences can be stated as the equation (2+2+2)(7+7+7+7+7) = 7+7+7+7+7, which relies on the coincidence 2+2+2=7.\n\nNote that the author of the papyrus listed a wrong value for the fourth power of 7; it should be 2,401, not 2,301. However, the sum of the powers (19,607) is correct.\n\nThe problem has been paraphrased by modern commentators as a story problem involving houses, cats, mice, and grain, although in the Rhind Mathematical Papyrus there is no discussion beyond the bare outline stated above. The hekat was of a cubic cubit (approximately ).\n\n"}
{"id": "57184342", "url": "https://en.wikipedia.org/wiki?curid=57184342", "title": "Basin-hopping", "text": "Basin-hopping\n\nIn applied mathematics, Basin-hopping is a global optimization technique that iterates by performing random perturbation of coordinates, performing local optimization, and accepting or rejecting new coordinates based on a minimized function value. The algorithm was described in 1997 by David J. Wales and Jonathan Doye.\n"}
{"id": "26866141", "url": "https://en.wikipedia.org/wiki?curid=26866141", "title": "Black–Karasinski model", "text": "Black–Karasinski model\n\nIn financial mathematics, the Black–Karasinski model is a mathematical model of the term structure of interest rates; see short rate model. It is a one-factor model as it describes interest rate movements as driven by a single source of randomness.\nIt belongs to the class of no-arbitrage models, i.e. it can fit today's zero-coupon bond prices, and in its most general form, today's prices for a set of caps, floors or European swaptions. The model was introduced by Fischer Black and Piotr Karasinski in 1991.\n\nThe main state variable of the model is the short rate, which is assumed to follow the stochastic differential equation (under the risk-neutral measure):\n\nwhere \"dW\" is a standard Brownian motion. The model implies a log-normal distribution for the short rate and therefore the expected value of the money-market account is infinite for any maturity.\n\nIn the original article by Fischer Black and Piotr Karasinski the model was implemented using a binomial tree with variable spacing, but a trinomial tree implementation is more common in practice, typically a lognormal application of the Hull-White Lattice.\n\nThe model is used mainly for the pricing of exotic interest rate derivatives such as American and Bermudan bond options and swaptions, once its parameters have been calibrated to the current term structure of interest rates and to the prices or implied volatilities of caps, floors or European swaptions. Numerical methods (usually trees) are used in the calibration stage as well as for pricing.\n\n\n"}
{"id": "1401020", "url": "https://en.wikipedia.org/wiki?curid=1401020", "title": "Christoffel symbols", "text": "Christoffel symbols\n\nIn mathematics and physics, the Christoffel symbols are an array of numbers describing a metric connection. The metric connection is a specialization of the affine connection to surfaces or other manifolds endowed with a metric, allowing distances to be measured on that surface. In differential geometry, an affine connection can be defined without any reference to a metric, and many additional concepts follow: parallel transport, covariant derivatives, geodesics, etc. also do not require the concept of a metric. However, when a metric is available, these concepts can be directly tied to the \"shape\" of the manifold itself; that shape is determined by how the tangent space is attached to the cotangent space by the metric tensor. Abstractly, one would say that the manifold has an associated (orthonormal) frame bundle, with each \"frame\" being a possible choice of a coordinate frame. An invariant metric implies that the structure group of the frame bundle is the orthogonal group . As a result, such a manifold is necessarily a (pseudo-)Riemannian manifold. The Christoffel symbols provide a concrete representation of the connection of (pseudo-)Riemannian geometry in terms of coordinates on the manifold. Additional concepts, such as parallel transport, geodesics, etc. can then be expressed in terms of Christoffel symbols.\n\nIn general, there are an infinite number of metric connections for a given metric tensor; however, there is one, unique connection, the Levi-Civita connection, that is free of any torsion. It is very common in physics and general relativity to work almost exclusively with the Levi-Civita connection, by working in coordinate frames (called holonomic coordinates) where the torsion vanishes. For example, in Euclidean spaces, the Christoffel symbols describe how the local coordinate bases change from point to point.\n\nAt each point of the underlying -dimensional manifold, for any local coordinate system around that point, the Christoffel symbols are denoted for . Each entry of this array is a real number. Under \"linear\" coordinate transformations on the manifold, the Christoffel symbols transform like the components of a tensor, but under general coordinate transformations (diffeomorphisms) they do not. Most of the algebraic properties of the Christoffel symbols follow from their relationship to the affine connection; only a few follow from the fact that the structure group is the orthogonal group (or the Lorentz group for general relativity).\n\nChristoffel symbols are used for performing practical calculations. For example, the Riemann curvature tensor can be expressed entirely in terms of the Christoffel symbols and their first partial derivatives. In general relativity, the connection plays the role of the gravitational force field with the corresponding gravitational potential being the metric tensor. When the coordinate system and the metric tensor share some symmetry, many of the are zero.\n\nThe Christoffel symbols are named for Elwin Bruno Christoffel (1829–1900).\n\nThe definitions given below are valid for both Riemannian manifolds and pseudo-Riemannian manifolds, such as those of general relativity, with careful distinction being made between upper and lower indices (contra-variant and co-variant indices). The formulas hold for either sign convention, unless otherwise noted.\n\nEinstein summation convention is used in this article, with vectors indicated by bold font. The connection coefficients of the Levi-Civita connection (or pseudo-Riemannian connection) expressed in a coordinate basis are called \"Christoffel symbols\".\n\nGiven a coordinate system for on an -manifold , the tangent vectors\nwhere is the position vector, define what is referred to as the local basis of the tangent space to at each point of its domain. These can be used to define the metric tensor:\n\nand its inverse:\n\nwhich can in turn be used to define the dual basis:\n\nIn Euclidean space, the general definition given below for the Christoffel symbols of the second kind can be proven to be equivalent to:\n\nChristoffel symbols of the first kind can then be found via index juggling:\n\nRearranging, we see that:\n\nIn words, the arrays represented by the Christoffel symbols track how the basis changes from point to point. Symbols of the second kind decompose the change with respect to the basis, while symbols of the first kind decompose it with respect to the dual basis. These expressions fail as definitions when such decompositions are not possible - in particular, when the direction of change does not lie in the tangent space, which can occur on a curved surface. In this form, it easy to see the symmetry of the lower or last two indices:\n\nformula_8 and formula_9,\n\nfrom the definition of formula_10 and the fact that partial derivatives commute (as long as the manifold and coordinate system are well behaved).\n\nThe same numerical values for Christoffel symbols of the second kind also relate to derivatives of the dual basis, as seen in the expression:\n\nwhich we can rearrange as:\n\nThe Christoffel symbols of the first kind can be derived either from the Christoffel symbols of the second kind and the metric,\nor from the metric alone,\n\nAs an alternative notation one also finds\n\nIt is worth noting that .\n\nThe Christoffel symbols of the second kind are the connection coefficients—in a coordinate basis—of the Levi-Civita connection, and since this connection has zero torsion, then in this basis the connection coefficients are symmetric, i.e., . For this reason, a torsion-free connection is often called \"symmetric\".\n\nIn other words, the Christoffel symbols of the second kind\nholds, where is the Levi-Civita connection on taken in the coordinate direction (i.e., ) and where is a local coordinate (holonomic) basis.\n\nThe Christoffel symbols can be derived from the vanishing of the covariant derivative of the metric tensor :\n\nAs a shorthand notation, the nabla symbol and the partial derivative symbols are frequently dropped, and instead a semicolon and a comma are used to set off the index that is being used for the derivative. Thus, the above is sometimes written as\n\nUsing that the symbols are symmetric in the lower two indices, one can solve explicitly for the Christoffel symbols as a function of the metric tensor by permuting the indices and resumming:\n\nwhere is the inverse of the matrix , defined as (using the Kronecker delta, and Einstein notation for summation) . Although the Christoffel symbols are written in the same notation as tensors with index notation, they are not tensors,\nsince they do not transform like tensors under a change of coordinates.\n\nThe Christoffel symbols are most typically defined in a coordinate basis, which is the convention followed here. In other words, the name Christoffel symbols is reserved only for coordinate (i.e., holonomic) frames. However, the connection coefficients can also be defined in an arbitrary (i.e., nonholonomic) basis of tangent vectors by\nExplicitly, in terms of the metric tensor, this is\n\nwhere are the commutation coefficients of the basis; that is,\nwhere are the basis vectors and is the Lie bracket. The standard unit vectors in spherical and cylindrical coordinates furnish an example of a basis with non-vanishing commutation coefficients. The difference between the connection in such a frame, and the Levi-Civita connection is known as the contorsion tensor.\n\nWhen we choose the basis orthonormal: then . This implies that\nand the connection coefficients become antisymmetric in the first two indices:\nwhere\n\nIn this case, the connection coefficients are called the Ricci rotation coefficients.\n\nEquivalently, one can define Ricci rotation coefficients as follows:\nwhere is an orthonormal nonholonomic basis and its \"co-basis\".\n\nLet and be vector fields with components and . Then the th component of the covariant derivative of with respect to is given by\n\nHere, the Einstein notation is used, so repeated indices indicate summation over indices and contraction with the metric tensor serves to raise and lower indices:\n\nKeep in mind that and that , the Kronecker delta. The convention is that the metric tensor is the one with the lower indices; the correct way to obtain from is to solve the linear equations .\n\nThe statement that the connection is torsion-free, namely that\nis equivalent to the statement that—in a coordinate basis—the Christoffel symbol is symmetric in the lower two indices:\n\nThe index-less transformation properties of a tensor are given by pullbacks for covariant indices, and pushforwards for contravariant indices. The article on covariant derivatives provides additional discussion of the correspondence between index-free notation and indexed notation.\n\nThe covariant derivative of a vector field is\n\nThe covariant derivative of a scalar field is just\n\nand the covariant derivative of a covector field is\n\nThe symmetry of the Christoffel symbol now implies\n\nfor any scalar field, but in general the covariant derivatives of higher order tensor fields do not commute (see curvature tensor).\n\nThe covariant derivative of a type (2,0) tensor field is\n\nthat is,\n\nIf the tensor field is mixed then its covariant derivative is\n\nand if the tensor field is of type then its covariant derivative is\n\nTo find the contravariant derivative of a vector field, we must first transform \nit into a covariant derivative using the metric tensor\n\nUnder a change of variable from to , vectors transform as\n\nand so\n\nwhere the overline denotes the Christoffel symbols in the coordinate system. Note that the Christoffel symbol does not transform as a tensor, but rather as an object in the jet bundle. More precisely, the Christoffel symbols can be considered as functions on the jet bundle of the frame bundle of , independent of any local coordinate system. Choosing a local coordinate system determines a local section of this bundle, which can then be used to pull back the Christoffel symbols to functions on , though of course these functions then depend on the choice of local coordinate system.\n\nAt each point, there exist coordinate systems in which the Christoffel symbols vanish at the point. These are called (geodesic) normal coordinates, and are often used in Riemannian geometry.\n\nThe Christoffel symbols find frequent use in Einstein's theory of general relativity, where spacetime is represented by a curved 4-dimensional Lorentz manifold with a Levi-Civita connection. The Einstein field equations—which determine the geometry of spacetime in the presence of matter—contain the Ricci tensor, and so calculating the Christoffel symbols is essential. Once the geometry is determined, the paths of particles and light beams are calculated by solving the geodesic equations in which the Christoffel symbols explicitly appear.\n\n\n"}
{"id": "4576710", "url": "https://en.wikipedia.org/wiki?curid=4576710", "title": "Classification theorem", "text": "Classification theorem\n\nIn mathematics, a classification theorem answers the classification problem \"What are the objects of a given type, up to some equivalence?\". It gives a non-redundant enumeration: each object is equivalent to exactly one class.\n\nA few related issues to classification are the following.\n\n\nThere exist many classification theorems in mathematics, as described below.\n\n\n\n\n"}
{"id": "2667603", "url": "https://en.wikipedia.org/wiki?curid=2667603", "title": "Controversy over Cantor's theory", "text": "Controversy over Cantor's theory\n\nIn mathematical logic, the theory of infinite sets was first developed by Georg Cantor. Although this work has become a thoroughly standard fixture of classical set theory, it has been criticized in several areas by mathematicians and philosophers.\n\nCantor's theorem implies that there are sets having cardinality greater than the infinite cardinality of the set of natural numbers. Cantor's argument for this theorem is presented with one small change. This argument can be improved by using a definition he gave later. The resulting argument uses only five axioms of set theory.\n\nCantor's set theory was controversial at the start, but later became largely accepted. In particular, there have been objections to its use of infinite sets.\n\nCantor's first proof that infinite sets can have different cardinalities was published in 1874. This proof demonstrates that the set of natural numbers and the set of real numbers have different cardinalities. It uses the theorem that a bounded increasing sequence of real numbers has a limit, which can be proved by using Cantor's or Richard Dedekind's construction of the irrational numbers. Because Leopold Kronecker did not accept these constructions, Cantor was motivated to develop a new proof.\n\nIn 1891, he published \"a much simpler proof … which does not depend on considering the irrational numbers.\" His new proof uses his diagonal argument to prove that there exists an infinite set with a larger number of elements (or greater cardinality) than the set of natural numbers N = {1, 2, 3, …}. This larger set consists of the elements (\"x\", \"x\", \"x\", …), where each \"x\" is either \"m\" or \"w\". Each of these elements corresponds to a subset of N—namely, the element (\"x\", \"x\", \"x\", …) corresponds to {\"n\" ∈ N:  \"x\" = \"w\"}. So Cantor's argument implies that the set of all subsets of N has greater cardinality than N. The set of all subsets of N is denoted by \"P\"(N), the power set of N.\n\nCantor generalized his argument to an arbitrary set \"A\" and the set consisting of all functions from \"A\" to {0, 1}. Each of these functions corresponds to a subset of \"A\", so his generalized argument implies the theorem: The power set \"P\"(\"A\") has greater cardinality than \"A\". This is known as Cantor's theorem.\n\nThe argument below is a modern version of Cantor's argument that uses power sets (for his original argument, see Cantor's diagonal argument). By presenting a modern argument, it is possible to see which assumptions of axiomatic set theory are used. The first part of the argument proves that N and \"P\"(N) have different cardinalities:\n\nNext Cantor shows that formula_1 is equinumerous with a subset of formula_2. From this and the fact that formula_2 and formula_1 have different cardinalities, he concludes that formula_2 has greater cardinality than formula_1. This conclusion uses his 1878 definition: If \"A\" and \"B\" have different cardinalities, then either \"B\" is equinumerous with a subset of \"A\" (in this case, \"B\" has less cardinality than \"A\") or \"A\" is equinumerous with a subset of \"B\" (in this case, \"B\" has greater cardinality than \"A\"). This definition leaves out the case where \"A\" and \"B\" are equinumerous with a subset of the other set—that is, \"A\" is equinumerous with a subset of \"B\" and \"B\" is equinumerous with a subset of \"A\". Because Cantor implicitly assumed that cardinalities are linearly ordered, this case cannot occur. After using his 1878 definition, Cantor stated that in an 1883 article he proved that cardinalities are well-ordered, which implies they are linearly ordered. This proof used his well-ordering principle \"every set can be well-ordered\", which he called a \"law of thought\". The well-ordering principle is equivalent to the axiom of choice.\n\nAround 1895, Cantor began to regard the well-ordering principle as a theorem and attempted to prove it. In 1895, Cantor also gave a new definition of \"greater than\" that correctly defines this concept without the aid of his well-ordering principle. By using Cantor's new definition, the modern argument that \"P\"(N) has greater cardinality than N can be completed using weaker assumptions than his original argument:\n\n\nBesides the axioms of infinity and power set, the axioms of separation, extensionality, and pairing were used in the modern argument. For example, the axiom of separation was used to define the diagonal subset formula_64 the axiom of extensionality was used to prove formula_65 and the axiom of pairing was used in the definition of the subset formula_35\n\nInitially, Cantor's theory was controversial among mathematicians and (later) philosophers. As Leopold Kronecker claimed: \"I don't know what predominates in Cantor's theory – philosophy or theology, but I am sure that there is no mathematics there\". Many mathematicians agreed with Kronecker that the completed infinite may be part of philosophy or theology, but that it has no proper place in mathematics. Logician has commented on the energy devoted to refuting this \"harmless little argument\" (i.e. Cantor's diagonal argument) asking, \"what had it done to anyone to make them angry with it?\" Others have also taken issue with Cantor's proof regarding the cardinality of the power set. Mathematician Solomon Feferman has referred to Cantor's theories as “simply not relevant to everyday mathematics.”\n\nBefore Cantor, the notion of infinity was often taken as a useful abstraction which helped mathematicians reason about the finite world; for example the use of infinite limit cases in calculus. The infinite was deemed to have at most a potential existence, rather than an actual existence. \"Actual infinity does not exist. What we call infinite is only the endless possibility of creating new objects no matter how many exist already\". Carl Friedrich Gauss's views on the subject can be paraphrased as: 'Infinity is nothing more than a figure of speech which helps us talk about limits. The notion of a completed infinity doesn't belong in mathematics'. In other words, the only access we have to the infinite is through the notion of limits, and hence, we must not treat infinite sets as if they have an existence exactly comparable to the existence of finite sets.\n\nCantor's ideas ultimately were largely accepted, strongly supported by David Hilbert, amongst others. Hilbert predicted: \"No one will drive us from the paradise which Cantor created for us\". To which Wittgenstein replied \"if one person can see it as a paradise of mathematicians, why should not another see it as a joke?\" The rejection of Cantor's infinitary ideas influenced the development of schools of mathematics such as constructivism and intuitionism.\n\nA common objection to Cantor's theory of infinite number involves the axiom of infinity (which is, indeed, an axiom and not a logical truth). Mayberry has noted that \"… the set-theoretical axioms that sustain modern mathematics are self-evident in differing degrees. One of them—indeed, the most important of them, namely Cantor's Axiom, the so-called Axiom of Infinity—has scarcely any claim to self-evidence at all …\"\n\nAnother objection is that the use of infinite sets is not adequately justified by analogy to finite sets. Hermann Weyl wrote:\nThe difficulty with finitism is to develop foundations of mathematics using finitist assumptions, that incorporates what everyone would reasonably regard as mathematics (for example, that includes real analysis).\n\n\n\n"}
{"id": "168865", "url": "https://en.wikipedia.org/wiki?curid=168865", "title": "Corollary", "text": "Corollary\n\nA corollary ( , ) is a statement that follows readily from a previous statement.\n\nIn mathematics, a corollary is a theorem connected by a short proof to an existing theorem. The use of the term \"corollary\", rather than \"proposition\" or \"theorem\", is intrinsically subjective. Proposition \"B\" is a corollary of proposition \"A\" if \"B\" can be readily deduced from \"A\" or is self-evident from its proof. The importance of the corollary is often considered secondary to that of the initial theorem; \"B\" is unlikely to be termed a corollary if its mathematical consequences are as significant as those of \"A\". Sometimes a corollary has a proof that explains the derivation; sometimes the derivation is considered self-evident.\n\nCharles Sanders Peirce held that the most important division of kinds of deductive reasoning is that between corollarial and theorematic. He argued that, while finally all deduction depends in one way or another on mental experimentation on schemata or diagrams, still in corollarial deduction \"it is only necessary to imagine any case in which the premises are true in order to perceive immediately that the conclusion holds in that case\", whereas theorematic deduction \"is deduction in which it is necessary to experiment in the imagination upon the image of the premise in order from the result of such experiment to make corollarial deductions to the truth of the conclusion.\" He held that corollarial deduction matches Aristotle's conception of direct demonstration, which Aristotle regarded as the only thoroughly satisfactory demonstration, while theorematic deduction (A) is the kind more prized by mathematicians, (B) is peculiar to mathematics, and (C) involves in its course the introduction of a lemma or at least a definition uncontemplated in the thesis (the proposition that is to be proved); in remarkable cases that definition is of an abstraction that \"ought to be supported by a proper postulate.\"\n\n\n"}
{"id": "42074131", "url": "https://en.wikipedia.org/wiki?curid=42074131", "title": "Derived stack", "text": "Derived stack\n\nIn algebraic geometry, a derived stack is, roughly, a stack together with a sheaf of commutative ring spectra. It generalizes a derived scheme. Derived stacks are the \"spaces\" studied in derived algebraic geometry.\n\n"}
{"id": "677191", "url": "https://en.wikipedia.org/wiki?curid=677191", "title": "Differential (mathematics)", "text": "Differential (mathematics)\n\nIn mathematics, differential refers to infinitesimal differences or to the derivatives of functions. The term is used in various branches of mathematics such as calculus, differential geometry, algebraic geometry and algebraic topology.\n\n\nThe notion of a differential motivates several concepts in differential geometry (and differential topology).\n\nDifferentials are also important in algebraic geometry, and there are several important notions.\n\nThe term \"differential\" has also been adopted in homological algebra and algebraic topology, because of the role the exterior derivative plays in de Rham cohomology: in a cochain complex formula_1, the maps (or \"coboundary operators\") \"d\" are often called differentials. Dually, the boundary operators in a chain complex are sometimes called \"codifferentials\".\n\nThe properties of the differential also motivate the algebraic notions of a \"derivation\" and a \"differential algebra\".\n"}
{"id": "21568751", "url": "https://en.wikipedia.org/wiki?curid=21568751", "title": "Equidimensionality", "text": "Equidimensionality\n\nIn mathematics, especially in topology, equidimensionality is a property of a space that the local dimension is the same everywhere.\n\nA topological space \"X\" is said to be equidimensional if for all points \"p\" in \"X\" the dimension at \"p\" that is, dim \"p\"(\"X\") is constant. The Euclidean space is an example of an equidimensional space. The disjoint union of two spaces \"X\" and \"Y\" (as topological spaces) of different dimension is an example of a non-equidimensional space.\n\nAn algebraic variety whose coordinate ring is a Cohen–Macaulay ring is equidimensional.\n"}
{"id": "3862616", "url": "https://en.wikipedia.org/wiki?curid=3862616", "title": "French mathematical seminars", "text": "French mathematical seminars\n\nFrench mathematical seminars have been an important type of institution combining research and exposition, active since the beginning of the twentieth century. \n\nFrom 1909 to 1937, the Séminaire Hadamard has gathered many participants (f. i. André Weil) around the presentation of international research papers and work in progress. The Séminaire Julia focussed on yearly themes and impulsed the Bourbaki movement. The Séminaire Nicolas Bourbaki is the most famous, but is atypical in a number of ways: it attempts to cover, if selectively, the whole of pure mathematics, and its talks are now, by convention, reports and surveys on research by someone not directly involved. More standard is a working group organised around a specialist area, with research talks given and written up 'from the horse's mouth'.\n\nHistorically speaking, the Séminaire Cartan of the late 1940s and early 1950s, around Henri Cartan, was one of the most influential. Publication in those days was by means of the duplicated \"exemplaire\" (limited distribution and not peer-reviewed). The seminar model was tested, almost to destruction, by the SGA series of Alexander Grothendieck.\n\n\n"}
{"id": "7043631", "url": "https://en.wikipedia.org/wiki?curid=7043631", "title": "Generalized inverse", "text": "Generalized inverse\n\nIn mathematics, and in particular, algebra, a generalized inverse of an element \"x\" is an element \"y\" that has some properties of an inverse element but not necessarily all of them. Generalized inverses can be defined in any mathematical structure that involves associative multiplication, that is, in a semigroup. This article describes generalized inverses of a matrix formula_1.\n\nFormally, given a matrix formula_2 and a matrix formula_3, formula_4 is a generalized inverse of formula_1 if it satisfies the condition formula_6.\n\nThe purpose of constructing a generalized inverse of a matrix is to obtain a matrix that can serve as an inverse in some sense for a wider class of matrices than invertible matrices. A generalized inverse exists for an arbitrary matrix, and when a matrix has a regular inverse, this inverse is its unique generalized inverse.\n\nConsider the linear system\n\nwhere formula_1 is an formula_9 matrix and formula_10, the column space of formula_1. If formula_1 is nonsingular (which implies formula_13) then formula_14 will be the solution of the system. Note that, if formula_1 is nonsingular, then\n\nNow suppose formula_1 is rectangular (formula_18), or square and singular. Then we need a right candidate formula_19 of order formula_20 such that for all formula_10,\n\nThat is, formula_23 is a solution of the linear system formula_7. \nEquivalently, we need a matrix formula_19 of order formula_26 such that\n\nHence we can define the generalized inverse or g-inverse as follows: Given an formula_9 matrix formula_1, an formula_20 matrix formula_19 is said to be a generalized inverse of formula_1 if formula_27 The matrix formula_34 has been termed a regular inverse of formula_1 by some authors.\n\nThe Penrose conditions define different generalized inverses for formula_2 and formula_37\n\n\nwhere formula_42 indicates conjugate transpose. If formula_4 satisfies the first condition, then it is a generalized inverse of formula_1. If it satisfies the first two conditions, then it is a reflexive generalized inverse of formula_1. If it satisfies all four conditions, then it is the pseudoinverse of formula_1. A pseudoinverse is sometimes called the Moore–Penrose inverse, after the pioneering works by E. H. Moore and Roger Penrose. \n\nWhen formula_1 is non-singular, any generalized inverse formula_48 and is unique, but in all other cases, there are an infinite number of matrices that satisfy condition (1). However, the Moore–Penrose inverse is unique.\n\nThere are other kinds of generalized inverse:\n\n\nLet\n\nSince formula_68, formula_69 is singular and has no regular inverse. However, formula_69 and formula_71 satisfy conditions (1) and (2), but not (3) or (4). Hence, formula_71 is a reflexive generalized inverse of formula_69.\n\nLet\n\nSince formula_69 is not square, formula_69 has no regular inverse. However, formula_77 is a right inverse of formula_69. The matrix formula_69 has no left inverse.\n\nThe following characterizations are easy to verify:\n\nAny generalized inverse can be used to determine whether a system of linear equations has any solutions, and if so to give all of them. If any solutions exist for the \"n\" × \"m\" linear system\n\nwith vector formula_81 of unknowns and vector formula_82 of constants, all solutions are given by \n\nparametric on the arbitrary vector formula_84, where formula_4 is any generalized inverse of formula_1. Solutions exist if and only if formula_87 is a solution, that is, if and only if formula_88. If \"A\" has full column rank, the bracketed expression in this equation is the zero matrix and so the solution is unique.\n\nIn practical applications it is necessary to identify the class of matrix transformations that must be preserved by a generalized inverse. For example, the Moore-Penrose inverse, formula_89, satisfies the following definition of consistency with respect to transformations involving unitary matrices \"U\" and \"V\":\n\nThe Drazin inverse, formula_91 satisfies the following definition of consistency with respect to similarity transformations involving a nonsingular matrix \"S\":\n\nThe Unit-Consistent (UC) inverse, formula_93, satisfies the following definition of consistency with respect to transformations involving nonsingular diagonal matrices \"D\" and \"E\":\n\nThe fact that the Moore-Penrose inverse provides consistency with respect to rotations (which are orthonormal transformations) explains its widespread use in physics and other applications in which Euclidean distances must be preserved. The UC inverse, by contrast, is applicable when system behavior is expected to be invariant with respect to the choice of units on different state variables, e.g., miles versus kilometers.\n\n\n"}
{"id": "31102294", "url": "https://en.wikipedia.org/wiki?curid=31102294", "title": "Geometric Algebra", "text": "Geometric Algebra\n\nGeometric Algebra is a book written by Emil Artin and published by Interscience Publishers, New York, in 1957. It was republished in 1988 in the Wiley Classics series ().\n\nIn 1962 \"Algèbra Géométrique\", translation into French by M. Lazard, was published by Gauthier-Villars, and reprinted in 1996. () In 1968 a translation into Italian was published in Milan by Feltrinelli. In 1969 a translation into Russian was published in Moscow by Nauka\n\nLong anticipated as the sequel to \"Moderne Algebra\" (1930), which Bartel van der Waerden published as his version of notes taken in a course with Artin, \"Geometric Algebra\" is a research monograph suitable for graduate students studying mathematics. From the Preface:\n\nThe book is illustrated with six geometric configurations in chapter 2, which retraces the path from geometric to field axioms previously explored by Karl von Staudt and David Hilbert.\n\nChapter one is titled \"Preliminary Notions\". The ten sections explicate notions of set theory, vector spaces, homomorphisms, duality, linear equations, group theory, field theory, ordered fields and valuations. On page vii Artin says \"Chapter I should be used mainly as a reference chapter for the proofs of certain isolated theorems.\"\nChapter two is titled \"Affine and Projective Geometry\". Artin posits this challenge to generate algebra (a field \"k\") from geometric axioms:\nThe reflexive variant of parallelism is invoked: parallel lines have either all or none of their points in common. Thus a line is parallel to itself.\n\nAxiom 1 requires a unique line for each pair of distinct points, and a unique point of intersection of non-parallel lines. Axiom 2 depends on a line and a point; it requires a unique parallel \"to\" the line and \"through\" the point. Axiom 3 requires three non-collinear points. Axiom 4a requires a translation to move any point to any other. Axiom 4b requires a dilation at \"P\" to move \"Q\" to \"R\" when the three points are collinear.\n\nArtin writes the line through \"P\" and \"Q\" as \"P\" + \"Q\". To define a \"dilation\" he writes, \"Let two distinct points \"P\" and \"Q\" and their images \"P\"′ and \"Q\"′ be given.\" To suggest the role of incidence in geometry, a dilation is specified by this property: \"If \"l\"′ is the line parallel to \"P\" + \"Q\" which passes through \"P\"′, then \"Q\"′ lies on \"l\"′.\" Of course, if \"P\"′ ≠ \"Q\"′, then this condition implies \"P\" + \"Q\" is parallel to \"P\"′ + \"Q\"′, so that the dilation is an affine transformation.\n\nThe dilations with no fixed points are translations, and the group of translations \"T\" is shown to be an invariant subgroup of the group of dilations. \nFor a dilation \"σ\" and a point \"P\", the \"trace\" is \"P\" + \"σP\". The mappings \"T\" → \"T\" that are trace-preserving homomorphisms are the elements of \"k\". First \"k\" is shown to be an associative ring with 1, then a skew field.\n\nConversely, there is an affine geometry based on any given skew field \"k\". Axioms 4a and 4b are equivalent to Desargues' theorem. When Pappus's hexagon theorem holds in the affine geometry, \"k\" is commutative and hence a field.\n\nChapter three is titled \"Symplectic and Orthogonal Geometry\". It begins with metric structures on vector spaces before defining symplectic and orthogonal geometry and describing their common and special features. There are sections on geometry over finite fields and over ordered fields.\n\nChapter four is on general linear groups. First there is Jean Dieudonne's theory of determinants over \"non-commutative fields\" (division rings). Artin describes GL(\"n, k\") group structure. More details are given about vector spaces over finite fields.\n\nChapter five is \"The Structure of Sympletic and Orthogonal Groups\". It includes sections on elliptic spaces, Clifford algebra, and spinorial norm.\n\nAlice T. Schafer wrote \"Mathematicians will find on many pages ample evidence of the author’s ability to penetrate a subject and to present material in a particularly elegant manner.\" She notes the overlap between Artin's text and Baer's \"Linear Algebra and Projective Geometry\" or Dieudonné's \"La Géometrie des Groupes Classique\".\n\nJean Dieudonné reviewed the book for Mathematical Reviews and placed it on a level with Hilbert's \"Grundlagen der Geometrie\".\n\n"}
{"id": "160990", "url": "https://en.wikipedia.org/wiki?curid=160990", "title": "Infinitesimal", "text": "Infinitesimal\n\nIn mathematics, infinitesimals are things so small that there is no way to measure them. The insight with exploiting infinitesimals was that entities could still retain certain specific properties, such as angle or slope, even though these entities were quantitatively small. The word \"infinitesimal\" comes from a 17th-century Modern Latin coinage \"infinitesimus\", which originally referred to the \"infinite-th\" item in a sequence. \nInfinitesimals are a basic ingredient in the procedures of infinitesimal calculus as developed by Leibniz, including the law of continuity and the transcendental law of homogeneity. In common speech, an infinitesimal object is an object that is smaller than any feasible measurement, but not zero in size—or, so small that it cannot be distinguished from zero by any available means. Hence, when used as an adjective, \"infinitesimal\" means \"extremely small\". To give it a meaning, it usually must be compared to another infinitesimal object in the same context (as in a derivative). Infinitely many infinitesimals are summed to produce an integral.\n\nThe concept of infinitesimals was originally introduced around 1670 by either Nicolaus Mercator or Gottfried Wilhelm Leibniz. Archimedes used what eventually came to be known as the method of indivisibles in his work \"The Method of Mechanical Theorems\" to find areas of regions and volumes of solids. In his formal published treatises, Archimedes solved the same problem using the method of exhaustion. The 15th century saw the work of Nicholas of Cusa, further developed in the 17th century by Johannes Kepler, in particular calculation of area of a circle by representing the latter as an infinite-sided polygon. Simon Stevin's work on decimal representation of all numbers in the 16th century prepared the ground for the real continuum. Bonaventura Cavalieri's method of indivisibles led to an extension of the results of the classical authors. The method of indivisibles related to geometrical figures as being composed of entities of codimension 1. John Wallis's infinitesimals differed from indivisibles in that he would decompose geometrical figures into infinitely thin building blocks of the same dimension as the figure, preparing the ground for general methods of the integral calculus. He exploited an infinitesimal denoted 1/∞ in area calculations.\n\nThe use of infinitesimals by Leibniz relied upon heuristic principles, such as the law of continuity: what succeeds for the finite numbers succeeds also for the infinite numbers and vice versa; and the transcendental law of homogeneity that specifies procedures for replacing expressions involving inassignable quantities, by expressions involving only assignable ones. The 18th century saw routine use of infinitesimals by mathematicians such as Leonhard Euler and Joseph-Louis Lagrange. Augustin-Louis Cauchy exploited infinitesimals both in defining continuity in his \"Cours d'Analyse\", and in defining an early form of a Dirac delta function. As Cantor and Dedekind were developing more abstract versions of Stevin's continuum, Paul du Bois-Reymond wrote a series of papers on infinitesimal-enriched continua based on growth rates of functions. Du Bois-Reymond's work inspired both Émile Borel and Thoralf Skolem. Borel explicitly linked du Bois-Reymond's work to Cauchy's work on rates of growth of infinitesimals. Skolem developed the first non-standard models of arithmetic in 1934. A mathematical implementation of both the law of continuity and infinitesimals was achieved by Abraham Robinson in 1961, who developed non-standard analysis based on earlier work by Edwin Hewitt in 1948 and Jerzy Łoś in 1955. The hyperreals implement an infinitesimal-enriched continuum and the transfer principle implements Leibniz's law of continuity. The standard part function implements Fermat's adequality.\n\nVladimir Arnold wrote in 1990:\n\nThe notion of infinitely small quantities was discussed by the Eleatic School. The Greek mathematician Archimedes (c.287 BC–c.212 BC), in \"The Method of Mechanical Theorems\", was the first to propose a logically rigorous definition of infinitesimals. His Archimedean property defines a number \"x\" as infinite if it satisfies the conditions |\"x\"|>1, |\"x\"|>1+1, |\"x\"|>1+1+1, ..., and infinitesimal if \"x\"≠0 and a similar set of conditions holds for \"x\" and the reciprocals of the positive integers. A number system is said to be Archimedean if it contains no infinite or infinitesimal members.\n\nThe English mathematician John Wallis introduced the expression 1/∞ in his 1655 book \"Treatise on the Conic Sections\". The symbol, which denotes the reciprocal, or inverse, of ∞, is the symbolic representation of the mathematical concept of an infinitesimal. In his \"Treatise on the Conic Sections\" Wallis also discusses the concept of a relationship between the symbolic representation of infinitesimal 1/∞ that he introduced and the concept of infinity for which he introduced the symbol ∞. The concept suggests a thought experiment of adding an infinite number of parallelograms of infinitesimal width to form a finite area. This concept was the predecessor to the modern method of integration used in integral calculus. The conceptual origins of the concept of the infinitesimal 1/∞ can be traced as far back as the Greek philosopher Zeno of Elea, whose Zeno's dichotomy paradox was the first mathematical concept to consider the relationship between a finite interval and an interval approaching that of an infinitesimal-sized interval.\n\nInfinitesimals were the subject of political and religious controversies in 17th century Europe, including a ban on infinitesimals issued by clerics in Rome in 1632.\n\nPrior to the invention of calculus mathematicians were able to calculate tangent lines using Pierre de Fermat's method of adequality and René Descartes' method of normals. There is debate among scholars as to whether the method was infinitesimal or algebraic in nature. When Newton and Leibniz invented the calculus, they made use of infinitesimals, Newton's \"fluxions\" and Leibniz' \"differential\". The use of infinitesimals was attacked as incorrect by Bishop Berkeley in his work \"The Analyst\". Mathematicians, scientists, and engineers continued to use infinitesimals to produce correct results. In the second half of the nineteenth century, the calculus was reformulated by Augustin-Louis Cauchy, Bernard Bolzano, Karl Weierstrass, Cantor, Dedekind, and others using the (ε, δ)-definition of limit and set theory. \nWhile the followers of Cantor, Dedekind, and Weierstrass sought to rid analysis of infinitesimals, and their philosophical allies like Bertrand Russell and Rudolf Carnap declared that infinitesimals are \"pseudoconcepts\", Hermann Cohen and his Marburg school of neo-Kantianism sought to develop a working logic of infinitesimals. The mathematical study of systems containing infinitesimals continued through the work of Levi-Civita, Giuseppe Veronese, Paul du Bois-Reymond, and others, throughout the late nineteenth and the twentieth centuries, as documented by Philip Ehrlich (2006). In the 20th century, it was found that infinitesimals could serve as a basis for calculus and analysis; see hyperreal number.\n\nIn extending the real numbers to include infinite and infinitesimal quantities, one typically wishes to be as conservative as possible by not changing any of their elementary properties. This guarantees that as many familiar results as possible are still available. Typically \"elementary\" means that there is no quantification over sets, but only over elements. This limitation allows statements of the form \"for any number x...\" For example, the axiom that states \"for any number \"x\", \"x\" + 0 = \"x\"\" would still apply. The same is true for quantification over several numbers, e.g., \"for any numbers \"x\" and \"y\", \"xy\" = \"yx\".\" However, statements of the form \"for any \"set\" \"S\" of numbers ...\" may not carry over. Logic with this limitation on quantification is referred to as first-order logic.\n\nThe resulting extended number system cannot agree with the reals on all properties that can be expressed by quantification over sets, because the goal is to construct a non-Archimedean system, and the Archimedean principle can be expressed by quantification over sets. One can conservatively extend any theory including reals, including set theory, to include infinitesimals, just by adding a countably infinite list of axioms that assert that a number is smaller than 1/2, 1/3, 1/4 and so on. Similarly, the completeness property cannot be expected to carry over, because the reals are the unique complete ordered field up to isomorphism.\n\nWe can distinguish three levels at which a nonarchimedean number system could have first-order properties compatible with those of the reals:\n\n\nSystems in category 1, at the weak end of the spectrum, are relatively easy to construct, but do not allow a full treatment of classical analysis using infinitesimals in the spirit of Newton and Leibniz. For example, the transcendental functions are defined in terms of infinite limiting processes, and therefore there is typically no way to define them in first-order logic. Increasing the analytic strength of the system by passing to categories 2 and 3, we find that the flavor of the treatment tends to become less constructive, and it becomes more difficult to say anything concrete about the hierarchical structure of infinities and infinitesimals.\n\nAn example from category 1 above is the field of Laurent series with a finite number of negative-power terms. For example, the Laurent series consisting only of the constant term 1 is identified with the real number 1, and the series with only the linear term \"x\" is thought of as the simplest infinitesimal, from which the other infinitesimals are constructed. Dictionary ordering is used, which is equivalent to considering higher powers of \"x\" as negligible compared to lower powers. David O. Tall refers to this system as the super-reals, not to be confused with the superreal number system of Dales and Woodin. Since a Taylor series evaluated with a Laurent series as its argument is still a Laurent series, the system can be used to do calculus on transcendental functions if they are analytic. These infinitesimals have different first-order properties than the reals because, for example, the basic infinitesimal \"x\" does not have a square root.\n\nThe Levi-Civita field is similar to the Laurent series, but is algebraically closed. For example, the basic infinitesimal x has a square root. This field is rich enough to allow a significant amount of analysis to be done, but its elements can still be represented on a computer in the same sense that real numbers can be represented in floating point.\n\nThe field of transseries is larger than the Levi-Civita field. An example of a transseries is:\n\nwhere for purposes of ordering \"x\" is considered infinite.\n\nConway's surreal numbers fall into category 2. They are a system designed to be as rich as possible in different sizes of numbers, but not necessarily for convenience in doing analysis. Certain transcendental functions can be carried over to the surreals, including logarithms and exponentials, but most, e.g., the sine function, cannot. The existence of any particular surreal number, even one that has a direct counterpart in the reals, is not known a priori, and must be proved.\n\nThe most widespread technique for handling infinitesimals is the hyperreals, developed by Abraham Robinson in the 1960s. They fall into category 3 above, having been designed that way so all of classical analysis can be carried over from the reals. This property of being able to carry over all relations in a natural way is known as the transfer principle, proved by Jerzy Łoś in 1955. For example, the transcendental function sin has a natural counterpart *sin that takes a hyperreal input and gives a hyperreal output, and similarly the set of natural numbers formula_2 has a natural counterpart formula_3, which contains both finite and infinite integers. A proposition such as formula_4 carries over to the hyperreals as formula_5 .\n\nThe superreal number system of Dales and Woodin is a generalization of the hyperreals. It is different from the super-real system defined by David Tall.\n\nIn linear algebra, the dual numbers extend the reals by adjoining one infinitesimal, the new element ε with the property ε = 0 (that is, ε is nilpotent). Every dual number has the form \"z\" = \"a\" + \"b\"ε with \"a\" and \"b\" being uniquely determined real numbers.\n\nOne application of dual numbers is automatic differentiation. This application can be generalized to polynomials in n variables, using the Exterior algebra of an n-dimensional vector space.\n\nSynthetic differential geometry or smooth infinitesimal analysis have roots in category theory. This approach departs from the classical logic used in conventional mathematics by denying the general applicability of the law of excluded middle – i.e., \"not\" (\"a\" ≠ \"b\") does not have to mean \"a\" = \"b\". A \"nilsquare\" or \"nilpotent\" infinitesimal can then be defined. This is a number \"x\" where \"x\" = 0 is true, but \"x\" = 0 need not be true at the same time. Since the background logic is intuitionistic logic, it is not immediately clear how to classify this system with regard to classes 1, 2, and 3. Intuitionistic analogues of these classes would have to be developed first.\n\nCauchy used an infinitesimal formula_6 to write down a unit impulse, infinitely tall and narrow Dirac-type delta function formula_7 satisfying formula_8 in a number of articles in 1827, see Laugwitz (1989). Cauchy defined an infinitesimal in 1821 (Cours d'Analyse) in terms of a sequence tending to zero. Namely, such a null sequence becomes an infinitesimal in Cauchy's and Lazare Carnot's terminology.\n\nModern set-theoretic approaches allow one to define infinitesimals via the ultrapower construction, where a null sequence becomes an infinitesimal in the sense of an equivalence class modulo a relation defined in terms of a suitable ultrafilter. The article by Yamashita (2007) contains a bibliography on modern Dirac delta functions in the context of an infinitesimal-enriched continuum provided by the hyperreals.\n\nThe method of constructing infinitesimals of the kind used in nonstandard analysis depends on the model and which collection of axioms are used. We consider here systems where infinitesimals can be shown to exist.\n\nIn 1936 Maltsev proved the compactness theorem. This theorem is fundamental for the existence of infinitesimals as it proves that it is possible to formalise them. A consequence of this theorem is that if there is a number system in which it is true that for any positive integer \"n\" there is a positive number \"x\" such that 0 < \"x\" < 1/\"n\", then there exists an extension of that number system in which it is true that there exists a positive number \"x\" such that for any positive integer \"n\" we have 0 < \"x\" < 1/\"n\". The possibility to switch \"for any\" and \"there exists\" is crucial. The first statement is true in the real numbers as given in ZFC set theory : for any positive integer \"n\" it is possible to find a real number between 1/\"n\" and zero, but this real number depends on \"n\". Here, one chooses \"n\" first, then one finds the corresponding \"x\". In the second expression, the statement says that there is an \"x\" (at least one), chosen first, which is between 0 and 1/\"n\" for any \"n\". In this case \"x\" is infinitesimal. This is not true in the real numbers (R) given by ZFC. Nonetheless, the theorem proves that there is a model (a number system) in which this is true. The question is: what is this model? What are its properties? Is there only one such model?\n\nThere are in fact many ways to construct such a one-dimensional linearly ordered set of numbers, but fundamentally, there are two different approaches:\n\nIn 1960, Abraham Robinson provided an answer following the first approach. The extended set is called the hyperreals and contains numbers less in absolute value than any positive real number. The method may be considered relatively complex but it does prove that infinitesimals exist in the universe of ZFC set theory. The real numbers are called standard numbers and the new non-real hyperreals are called nonstandard.\n\nIn 1977 Edward Nelson provided an answer following the second approach. The extended axioms are IST, which stands either for Internal set theory or for the initials of the three extra axioms: Idealization, Standardization, Transfer. In this system we consider that the language is extended in such a way that we can express facts about infinitesimals. The real numbers are either standard or nonstandard. An infinitesimal is a nonstandard real number that is less, in absolute value, than any positive standard real number.\n\nIn 2006 Karel Hrbacek developed an extension of Nelson's approach in which the real numbers are stratified in (infinitely) many levels; i.e., in the coarsest level there are no infinitesimals nor unlimited numbers. Infinitesimals are in a finer level and there are also infinitesimals with respect to this new level and so on.\n\nCalculus textbooks based on infinitesimals include the classic \"Calculus Made Easy\" by Silvanus P. Thompson (bearing the motto \"What one fool can do another can\") and the German text \"Mathematik fur Mittlere Technische Fachschulen der Maschinenindustrie\" by R Neuendorff. Pioneering works based on Abraham Robinson's infinitesimals include texts by Stroyan (dating from 1972) and Howard Jerome Keisler (). Students easily relate to the intuitive notion of an infinitesimal difference 1-\"0.999...\", where \"0.999...\" differs from its standard meaning as the real number 1, and is reinterpreted as an infinite terminating extended decimal that is strictly less than 1.\n\nAnother elementary calculus text that uses the theory of infinitesimals as developed by Robinson is \"Infinitesimal Calculus\" by Henle and Kleinberg, originally published in 1979. The authors introduce the language of first order logic, and demonstrate the construction of a first order model of the hyperreal numbers. The text provides an introduction to the basics of integral and differential calculus in one dimension, including sequences and series of functions. In an Appendix, they also treat the extension of their model to the \"hyperhyper\"reals, and demonstrate some applications for the extended model.\n\nIn a related but somewhat different sense, which evolved from the original definition of \"infinitesimal\" as an infinitely small quantity, the term has also been used to refer to a function tending to zero. More precisely, Loomis and Sternberg's \"Advanced Calculus\" defines the function class of infinitesimals, formula_9, as a subset of functions formula_10 between normed vector spaces by formula_11, as well as two related classes formula_12 (see Big-O notation) by formula_13, andformula_14.The set inclusions formula_15generally hold. That the inclusions are proper is demonstrated by the real-valued functions of a real variable formula_16, formula_17, and formula_18: formula_19 but formula_20 and formula_21.As an application of these definitions, a mapping formula_22 between normed vector spaces is defined to be differentiable at formula_23 if there is a formula_24 [i.e, a bounded linear map formula_25] such that formula_26in a neighborhood of formula_6. If such a map exists, it is unique; this map is called the \"differential\" and is denoted by formula_28, coinciding with the traditional notation for the classical (though logically flawed) notion of a differential as an infinitely small \"piece\" of \"F\". This definition represents a generalization of the usual definition of differentiability for vector-valued functions of (open subsets of) Euclidean spaces.\n\nLet formula_29 be a probability space and let formula_30. An array formula_31 of random variables is called infinitesimal if for every formula_32, we have:\nThe notion of infinitesimal array is essential in some central limit theorems and it is easily seen by monotonicity of the expectation operator that any array satisfying Lindeberg's condition is infinitesimal, thus playing an important role in Lindeberg's Central Limit Theorem (a generalization of the central limit theorem).\n\n"}
{"id": "185493", "url": "https://en.wikipedia.org/wiki?curid=185493", "title": "Informal mathematics", "text": "Informal mathematics\n\nInformal mathematics, also called naïve mathematics, has historically been the predominant form of mathematics at most times and in most cultures, and is the subject of modern ethno-cultural studies of mathematics. The philosopher Imre Lakatos in his \"Proofs and Refutations\" aimed to sharpen the formulation of informal mathematics, by reconstructing its role in nineteenth century mathematical debates and concept formation, opposing the predominant assumptions of mathematical formalism. Informality may not discern between statements given by \"inductive reasoning\" (as in approximations which are deemed \"correct\" merely because they are useful), and statements derived by \"deductive reasoning\".\n\n\"Informal mathematics\" means any informal mathematical practices, as used in everyday life, or by aboriginal or ancient peoples, without historical or geographical limitation. Modern mathematics, exceptionally from that point of view, emphasizes formal and strict proofs of all statements from given axioms. This can usefully be called therefore \"formal mathematics\". Informal practices are usually understood intuitively and justified with examples—there are no axioms. This is of direct interest in anthropology and psychology: it casts light on the perceptions and agreements of other cultures. It is also of interest in developmental psychology as it reflects a naïve understanding of the relationships between numbers and things. Another term used for informal mathematics is folk mathematics, which is ambiguous; the mathematical folklore article is dedicated to the usage of that term among professional mathematicians.\n\nThe field of naïve physics is concerned with similar understandings of physics. People use mathematics and physics in everyday life, without really understanding (or caring) how mathematical and physical ideas were historically derived and justified.\n\nThere has long been a standard account of the development of geometry in ancient Egypt, followed by Greek mathematics and the emergence of deductive logic. The modern sense of the term \"mathematics\", as meaning only those systems justified with reference to axioms, is however an anachronism if read back into history. Several ancient societies built impressive mathematical systems and carried out complex calculations based on proofless heuristics and practical approaches. Mathematical facts were accepted on a pragmatic basis. Empirical methods, as in science, provided the justification for a given technique. Commerce, engineering, calendar creation and the prediction of eclipses and stellar progression were practiced by ancient cultures on at least three continents. N.C. Ghosh included Informal Mathematics in the list of Folk Mathematics.\n\n"}
{"id": "57258626", "url": "https://en.wikipedia.org/wiki?curid=57258626", "title": "Jouanolou's trick", "text": "Jouanolou's trick\n\nIn algebraic geometry, Jouanolou's trick is a theorem that asserts, for an algebraic variety \"X\", the existence of a surjection with affine fibers from an affine variety \"W\" to \"X\". The variety \"W\" is therefore homotopy-equivalent to \"X\", but it has the technically advantageous property of being affine. Jouanolou's original statement of the theorem required that \"X\" be quasi-projective over an affine scheme, but this has since been considerably weakened.\n\nJouanolou's original statement was:\n\nBy the definition of a torsor, \"W\" comes with a surjective map to \"X\" and is Zariski-locally on \"X\" an affine space bundle.\n\nJouanolou's proof used an explicit construction. Let \"S\" be an affine scheme and formula_1. Interpret the affine space formula_2 as the space of (\"r\" + 1) × (\"r\" + 1) matrices over \"S\". Within this affine space, there is a subvariety \"W\" consisting of idempotent matrices of rank one. The image of such a matrix is therefore a point in \"X\", and the map formula_3 that sends a matrix to the point corresponding to its image is the map claimed in the statement of the theorem. To show that this map has the desired properties, Jouanolou notes that there is a short exact sequence of vector bundles:\nwhere the first map is defined by multiplication by a basis of sections of formula_5 and the second map is the cokernel. Jouanolou then asserts that \"W\" is a torsor for formula_6.\n\nJouanolou deduces the theorem in general by reducing to the above case. If \"X\" is projective over an affine scheme \"S\", then it admits a closed immersion into some projective space formula_7. Pulling back the variety \"W\" constructed above for formula_7 along this immersion yields the desired variety \"W\" for \"X\". Finally, if \"X\" is quasi-projective, then it may be realized as an open subscheme of a projective \"S\"-scheme. Blow up the complement of \"X\" to get formula_9, and let formula_10 denote the inclusion morphism. The complement of \"X\" in formula_9 is a Cartier divisor, and therefore \"i\" is an affine morphism. Now perform the previous construction for formula_9 and pull back along \"i\".\n\nRobert Thomason observed that, by making a less explicit construction, it was possible to obtain the same conclusion under significantly weaker hypotheses. Thomason's construction first appeared in a paper of Weibel. Thomason's theorem asserts:\n\nHaving an ample family of line bundles was first defined in SGA 6 Exposé II Définition 2.2.4. Any quasi-projective scheme over an affine scheme has an ample family of line bundles, as does any separated locally factorial Noetherian scheme.\n\nThomason's proof abstracts the key features of Jouanolou's. By hypothesis, \"X\" admits a set of line bundles \"L\", ..., \"L\" and sections \"s\", ..., \"s\" whose non-vanishing loci are affine and cover \"X\". Define \"X\" to be the non-vanishing locus of \"s\", and define formula_13 to be the direct sum of \"L\", ..., \"L\". The sections define a morphism of vector bundles formula_14. Define formula_15 to be the cokernel of \"s\". On \"X\", \"s\" is a split monomorphism since it is inverted by the inverse of \"s\". Therefore formula_15 is a vector bundle over \"X\", and because these open sets cover \"X\", formula_15 is a vector bundle.\n\nDefine formula_18 and similarly for formula_19. Let \"W\" be the complement of formula_19 in formula_21. There is an equivalent description of \"W\" as formula_22, and from this description, it is easy to check that it is a torsor for formula_15. Therefore the projection formula_24 is affine. To see that \"W\" is itself affine, apply a criterion of Serre (EGA II 5.2.1(b), EGA IV 1.7.17). Each \"s\" determines a global section \"f\" of \"W\". The non-vanishing locus \"W\" of \"f\" is contained in formula_25, which is affine, and hence \"W\" is affine. The sum of the sections \"f\", ..., \"f\" is 1, so the ideal they generate is the ring of global sections. Serre's criterion now implies that \"W\" is affine.\n\n"}
{"id": "26113571", "url": "https://en.wikipedia.org/wiki?curid=26113571", "title": "Jyotirmimamsa", "text": "Jyotirmimamsa\n\nIn Hindu astronomy, Jyotirmimamsa (analysis of astronomy) is a treatise on the methodology of astronomical studies authored by Nilakantha Somayaji (1444–1544) in around 1504 CE. Nilakantha somayaji was an important astronomer-mathematician of the Kerala school of astronomy and mathematics and was the author of the much celebrated astronomical work titled Tantrasamgraha. This book stresses the necessity and importance of astronomical observations to obtain correct parameters for computations and to develop more and more accurate theories. It even discounts the role of revealed wisdom and divine intuitions in studying astronomical phenomena. Jyotirmimamsa is sometimes cited as proof to establish that modern methodologies of scientific investigations are not unknown to ancient and medieval Indians.\n\nThe nature of the astronomical and mathematical work, the divine intuition, the experimental details of the science, corrections to the planetary parameters, reasons for the corrections for the planetary revolutions, Vedic authority for inference in astronomy, relative accuracy of different systems, and correction through eclipses, true motion, position, etc., of planets are some of the topics discussed in Jyotirmimamsa.\n\nThe following is an outline of the various topics discussed in Jyotirmimamsa.\n\n\n"}
{"id": "352181", "url": "https://en.wikipedia.org/wiki?curid=352181", "title": "List of abstract algebra topics", "text": "List of abstract algebra topics\n\nAbstract algebra is the subject area of mathematics that studies algebraic structures, such as groups, rings, fields, modules, vector spaces, and algebras. The phrase abstract algebra was coined at the turn of the 20th century to distinguish this area from what was normally referred to as algebra, the study of the rules for manipulating formulae and algebraic expressions involving unknowns and real or complex numbers, often now called \"elementary algebra\". The distinction is rarely made in more recent writings.\n\nAlgebraic structures are defined primarily as sets with \"operations\". \n\nStructure preserving maps called \"homomorphisms\" are vital in the study of algebraic objects.\n\nThere are several basic ways to combine algebraic objects of the same type to produce a third object of the same type. These constructions are used throughout algebra.\n\nAdvanced concepts:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepresentation theory\n\n\n\n\n\n"}
{"id": "28157642", "url": "https://en.wikipedia.org/wiki?curid=28157642", "title": "List of aperiodic sets of tiles", "text": "List of aperiodic sets of tiles\n\nIn geometry, a tiling is a partition of the plane (or any other geometric setting) into closed sets (called \"tiles\"), without gaps or overlaps (other than the boundaries of the tiles). A tiling is considered periodic if there exist translations in two independent directions which map the tiling onto itself. Such a tiling is composed of a single fundamental unit or primitive cell which repeats endlessly and regularly in two independent directions. An example of such a tiling is shown in the adjacent diagram (see the image description for more information). A tiling that cannot be constructed from a single primitive cell is called nonperiodic. If a given set of tiles allows only nonperiodic tilings, then this set of tiles is called aperiodic. The tilings obtained from an aperiodic set of tiles are often called aperiodic tilings, though strictly speaking it is the tiles themselves that are aperiodic. (The tiling itself is said to be \"nonperiodic\".)\n\nThe first table explains the abbreviations used in the second table. The second table contains all known aperiodic sets of tiles and gives some additional basic information about each set. This list of tiles is still incomplete.\n\n"}
{"id": "8997770", "url": "https://en.wikipedia.org/wiki?curid=8997770", "title": "List of graphs", "text": "List of graphs\n\nThis partial list of graphs contains definitions of graphs and graph families which are known by particular names, but do not have a Wikipedia article of their own.\n\nFor collected definitions of graph theory terms that do not refer to individual graph types, such as \"vertex\" and \"path\", see Glossary of graph theory. For links to existing articles about particular kinds of graphs, see .\n\nA gear graph, denoted \"G\" is a graph obtained by inserting an extra vertex between each pair of adjacent vertices on the perimeter of a wheel graph \"W\". Thus, \"G\" has 2\"n\"+1 vertices and 3\"n\" edges. Gear graphs are examples of squaregraphs, and play a key role in the forbidden graph characterization of squaregraphs. Gear graphs are also known as cogwheels and bipartite wheels.\n\nA grid graph is a unit distance graph corresponding to the square lattice, so that it is isomorphic to the graph having a vertex corresponding to every pair of integers (\"a\", \"b\"), and an edge connecting (\"a\", \"b\") to (\"a\"+1, \"b\") and (\"a\", \"b\"+1). The finite grid graph \"G\" is an \"m\"×\"n\" rectangular graph isomorphic to the one obtained by restricting the ordered pairs to the range 0 ≤ \"a\" < \"m\", 0 ≤ \"b\" < \"n\". Grid graphs can be obtained as the Cartesian product of two paths: \"G\" = \"P\" × \"P\". Every grid graph is a median graph.\n\nA helm graph, denoted H is a graph obtained by attaching a single edge and node to each node of the outer circuit of a wheel graph W.\n\nA lobster graph is a tree in which all the vertices are within distance 2 of a central path. Compare \"caterpillar\".\n\nThe web graph \"W\" is a graph consisting of \"r\" concentric copies of the cycle graph \"C\", with corresponding vertices connected by \"spokes\". Thus \"W\" is the same graph as \"C\", and \"W\" is a prism.\n\nA web graph has also been defined as a prism graph \"Y\", with the edges of the outer cycle removed.\n\nGallery of named graphs\n"}
{"id": "8339650", "url": "https://en.wikipedia.org/wiki?curid=8339650", "title": "List of mathematic operators", "text": "List of mathematic operators\n\nIn mathematics, an operator or transform is a function from one space of functions to another. Operators occur commonly in engineering, physics and mathematics. Many are integral operators and differential operators.\n\nIn the following \"L\" is an operator\n\nwhich takes a function formula_2 to another function formula_3. Here, formula_4 and formula_5 are some unspecified function spaces, such as Hardy space, \"L\" space, Sobolev space, or, more vaguely, the space of holomorphic functions.\n\n"}
{"id": "5971837", "url": "https://en.wikipedia.org/wiki?curid=5971837", "title": "List of mathematicians (V)", "text": "List of mathematicians (V)\n\n\n\n\n\n\n"}
{"id": "2302006", "url": "https://en.wikipedia.org/wiki?curid=2302006", "title": "List of simple Lie groups", "text": "List of simple Lie groups\n\nIn mathematics, the simple Lie groups were first classified by Wilhelm Killing and later perfected by Élie Cartan. This classification is often referred to as Killing-Cartan classification. \n\nThe list of simple Lie groups can be used to read off the list of simple Lie algebras and Riemannian symmetric spaces. See also the table of Lie groups for a smaller list of groups that commonly occur in theoretical physics, and the Bianchi classification for groups of dimension at most 3. \n\nUnfortunately, there is no universally accepted definition of a simple Lie group. In particular, it is not always defined as a Lie group that is simple as an abstract group. Authors differ on whether a simple Lie group has to be connected, or on whether it is allowed to have a non-trivial center, or on whether R is a simple Lie group. \n\nThe most common definition is that a Lie group is simple if it is connected, non-abelian, and every closed \"connected\" normal subgroup is either the identity or the whole group. In particular, simple groups are allowed to have a non-trivial center, but R is not simple. \n\nIn this article the connected simple Lie groups with trivial center are listed. Once these are known, the ones with non-trivial center are easy to list as follows. Any simple Lie group with trivial center has a universal cover, whose center is the fundamental group of the simple Lie group. The corresponding simple Lie groups with non-trivial center can be obtained as quotients of this universal cover by a subgroup of the center.\n\nThe Lie algebra of a simple Lie group is a simple Lie algebra. This is a one-to-one correspondence between connected simple Lie groups with trivial center and simple Lie algebras of dimension greater than 1. (Authors differ on whether the one-dimensional Lie algebra should be counted as simple.)\n\nOver the complex numbers the semisimple Lie algebras are classified by their Dynkin diagrams, of types \"ABCDEFG\". If \"L\" is a real simple Lie algebra, its complexification is a simple complex Lie algebra, unless \"L\" is already \nthe complexification of a Lie algebra, in which case the complexification of \"L\" is a product of two copies of \"L\". This reduces the problem of classifying the real simple Lie algebras to that of finding all the real forms of each complex simple Lie algebra (i.e., real Lie algebras whose complexification is the given complex Lie algebra). There are always at least 2 such forms: a split form and a compact form, and there are usually a few others. The different real forms correspond to the classes of automorphisms of order at most 2 of the complex Lie algebra.\n\nSymmetric spaces are classified as follows. \n\nFirst, the universal cover of a symmetric space is still symmetric, so we can reduce to the case of simply connected symmetric spaces. (For example, the universal cover of a real projective plane is a sphere.)\n\nSecond, the product of symmetric spaces is symmetric, so we may as well just classify the irreducible simply connected ones (where irreducible means they cannot be written as a product of smaller symmetric spaces). \n\nThe irreducible simply connected symmetric spaces are the real line, and exactly two symmetric spaces corresponding to each \"non-compact\" simple Lie group \"G\",\none compact and one non-compact. The non-compact one is a cover of the quotient of \"G\" by a maximal compact subgroup \"H\", and the compact one is a cover of the quotient of\nthe compact form of \"G\" by the same subgroup \"H\". This duality between compact and non-compact symmetric spaces is a generalization of the well known duality between spherical and hyperbolic geometry.\n\nA symmetric space with a compatible complex structure is called Hermitian. The compact simply connected irreducible Hermitian symmetric spaces fall into 4 infinite families with 2 exceptional ones left over, and each has a non-compact dual. In addition the complex plane is also a Hermitian symmetric space; this gives the complete list of irreducible Hermitian symmetric spaces.\n\nThe four families are the types A III, B I and D I for , D III, and C I, and the two exceptional ones are types E III and E VII of complex dimensions 16 and 27.\n\nformula_1  stand for the real numbers, complex numbers, quaternions, and octonions.\n\nIn the symbols such as \"E\" for the exceptional groups, the exponent −26 is the signature of an invariant symmetric bilinear form that is negative definite on the maximal compact subgroup. It is equal to the dimension of the group minus twice the dimension of a maximal compact subgroup.\n\nThe fundamental group listed in the table below is the fundamental group of the simple group with trivial center. \nOther simple groups with the same Lie algebra correspond to subgroups of this fundamental group (modulo the action of the outer automorphism group).\n\nThe following table lists some Lie groups with simple Lie algebras of small \ndimension. The groups on a given line all have the same Lie algebra. In the dimension 1 case, the groups are abelian and not simple.\n\n"}
{"id": "8385078", "url": "https://en.wikipedia.org/wiki?curid=8385078", "title": "Melnikov distance", "text": "Melnikov distance\n\nOne of the main tools for determining the existence of (or non-existence of) chaos in a perturbed Hamiltonian system is Melnikov theory. In this theory, the distance between the stable and unstable manifolds of the perturbed system is calculated up to the first-order term. Consider a smooth dynamical system formula_1, with formula_2 and formula_3 periodic with period formula_4. Suppose for formula_5 the system has a hyperbolic fixed point x and a homoclinic orbit formula_6 corresponding to this fixed point. Then for sufficiently small formula_7 there exists a \"T\"-periodic hyperbolic solution. The stable and unstable manifolds of this periodic solution intersect transversally. The distance between these manifolds measured along a direction that is perpendicular to the unperturbed homoclinc orbit formula_6 is called the Melnikov distance. If formula_9\ndenotes this distance, then formula_10. The function formula_11 is called the Melnikov function.\n\nMelnikov’s distance can be used to predict chaotic vibrations . In this method, critical amplitude is found by setting the distance between homoclinic orbits and stable manifolds equal to zero. The Melnikov’s method provides necessary but not sufficient condition for chaos.\n"}
{"id": "3667560", "url": "https://en.wikipedia.org/wiki?curid=3667560", "title": "Millennium Mathematics Project", "text": "Millennium Mathematics Project\n\nThe Millennium Mathematics Project (MMP) was set up within the University of Cambridge in England as a joint project between the Faculties of Mathematics and Education in 1999. The MMP aims to support maths education for pupils of all abilities from ages 5 to 19 and promote the development of mathematical skills and understanding, particularly through enrichment and extension activities beyond the school curriculum, and to enhance the mathematical understanding of the general public. The project is currently directed by John Barrow.\n\nThe MMP includes a range of complementary programmes:\n\n\nThe project has also developed a Hands On Maths Roadshow presenting creative methods of exploring mathematics, and in 2004 took on the running of Simon Singh's Enigma schools workshops, exploring maths through cryptography and codebreaking. Both are taken to primary and secondary schools and public venues such as shopping centres across the UK and Ireland. James Grime is the Enigma Project Officer and gives talks in schools and to the general public about the history and mathematics of code breaking - including the demonstration of a genuine World War II Enigma Machine.\n\nIn November 2005, the MMP won the Queen's Anniversary Prize for Higher and Further Education.\n"}
{"id": "25547443", "url": "https://en.wikipedia.org/wiki?curid=25547443", "title": "Nash blowing-up", "text": "Nash blowing-up\n\nIn algebraic geometry, a Nash blowing-up is a process in which, roughly speaking, each singular point is replaced by all the limiting positions of the tangent spaces at the non-singular points. Strictly speaking, if \"X\" is an algebraic variety of pure codimension \"r\" embedded in a smooth variety of dimension \"n\", formula_1 denotes the set of its singular points and formula_2 it is possible to define a map formula_3, where formula_4 is the Grassmannian of \"r\"-planes in \"n\"-space, by formula_5, where formula_6 is the tangent space of \"X\" at \"a\". Now, the closure of the image of this map together with the projection to \"X\" is called the Nash blowing-up of \"X\".\n\nAlthough (to emphasize its geometric interpretation) an embedding was used to define the Nash embedding it is possible to prove that it doesn't depend on it. \n\n\n\n"}
{"id": "58449356", "url": "https://en.wikipedia.org/wiki?curid=58449356", "title": "National Association of Mathematicians", "text": "National Association of Mathematicians\n\nThe National Association of Mathematicians is a professional association for mathematicians in the US, especially African Americans and other minorities. It was founded in 1969.\n\n"}
{"id": "22213", "url": "https://en.wikipedia.org/wiki?curid=22213", "title": "Operator (mathematics)", "text": "Operator (mathematics)\n\nIn mathematics, an operator is generally a mapping that acts on elements of a space to produce other elements of the same space. The most common operators are linear maps, which act on vector spaces. However, when using \"linear operator\" instead of \"linear map\", mathematicians often mean actions on vector spaces of functions, which also preserve other properties, such as continuity. For example, differentiation and indefinite integration are linear operators; operators that are built from them are called differential operators, integral operators or integro-differential operators.\n\nOperator is also used for denoting the symbol of a mathematical operation. This is related with the meaning of \"operator\" in computer programming, see operator (computer programming).\n\nThe most common kind of operator encountered are \"linear operators\". Let \"U\" and \"V\" be vector spaces over a field \"K\". A mapping \"A\": \"U\" → \"V\" is linear if\nfor all x, y in \"U\" and for all \"α, β\" in \"K\". \nThis means that a linear operator preserves vector space operations, in the sense that it does not matter whether you apply the linear operator before or after the operations of addition and scalar multiplication. In more technical words, linear operators are morphisms between vector spaces.\n\nIn finite-dimensional case linear operators can be represented by matrices in the following way. Let formula_2 be a field, and formula_3 and formula_4 be finite-dimensional vector spaces over formula_2. Let us select a basis formula_6 in formula_3 and formula_8 in formula_4. Then let formula_10 be an arbitrary vector in formula_3 (assuming Einstein convention), and formula_12 be a linear operator. Then\nThen formula_14 is the matrix of the operator formula_15 in fixed bases. formula_16 does not depend on the choice of formula_17, and formula_18 iff formula_19. Thus in fixed bases n-by-m matrices are in bijective correspondence to linear operators from formula_3 to formula_4.\n\nThe important concepts directly related to operators between finite-dimensional vector spaces are the ones of rank, determinant, inverse operator, and eigenspace.\n\nLinear operators also play a great role in the infinite-dimensional case. The concepts of rank and determinant cannot be extended to infinite-dimensional matrices. This is why very different techniques are employed when studying linear operators (and operators in general) in the infinite-dimensional case. The study of linear operators in the infinite-dimensional case is known as functional analysis (so called because various classes of functions form interesting examples of infinite-dimensional vector spaces).\n\nThe space of sequences of real numbers, or more generally sequences of vectors in any vector space, themselves form an infinite-dimensional vector space. The most important cases are sequences of real or complex numbers, and these spaces, together with linear subspaces, are known as sequence spaces. Operators on these spaces are known as sequence transformations.\n\nBounded linear operators over Banach space form a Banach algebra in respect to the standard operator norm. The theory of Banach algebras develops a very general concept of spectra that elegantly generalizes the theory of eigenspaces.\n\nLet \"U\" and \"V\" be two vector spaces over the same ordered field (for example, formula_22), and they are equipped with norms. Then a linear operator from \"U\" to \"V\" is called bounded if there exists \"C > 0\" such that\nfor all x in \"U\".\n\nBounded operators form a vector space. On this vector space we can introduce a norm that is compatible with the norms of \"U\" and \"V\":\n\nIn case of operators from \"U\" to itself it can be shown that\n\nAny unital normed algebra with this property is called a Banach algebra. It is possible to generalize spectral theory to such algebras. C*-algebras, which are Banach algebras with some additional structure, play an important role in quantum mechanics.\n\nIn geometry, additional structures on vector spaces are sometimes studied. Operators that map such vector spaces to themselves bijectively are very useful in these studies, they naturally form groups by composition.\n\nFor example, bijective operators preserving the structure of a vector space are precisely the invertible linear operators. They form the general linear group under composition. They \"do not\" form a vector space under the addition of operators, e.g. both \"id\" and \"-id\" are invertible (bijective), but their sum, 0, is not.\n\nOperators preserving the Euclidean metric on such a space form the isometry group, and those that fix the origin form a subgroup known as the orthogonal group. Operators in the orthogonal group that also preserve the orientation of vector tuples form the special orthogonal group, or the group of rotations.\n\nOperators are also involved in probability theory, such as expectation, variance, and covariance.\n\nFrom the point of view of functional analysis, calculus is the study of two linear operators: the differential operator formula_26, and the indefinite integral operator formula_27.\n\nThe Fourier transform is useful in applied mathematics, particularly physics and signal processing. It is another integral operator; it is useful mainly because it converts a function on one (temporal) domain to a function on another (frequency) domain, in a way effectively invertible. No information is lost, as there is an inverse transform operator. In the simple case of periodic functions, this result is based on the theorem that any continuous periodic function can be represented as the sum of a series of sine waves and cosine waves:\nThe tuple \"(a, a, b, a, b, ...)\" is in fact an element of an infinite-dimensional vector space ℓ, and thus Fourier series is a linear operator.\n\nWhen dealing with general function R → C, the transform takes on an integral form:\n\nThe \"Laplace transform\" is another integral operator and is involved in simplifying the process of solving differential equations.\n\nGiven \"f\" = \"f\"(\"s\"), it is defined by:\n\nThree operators are key to vector calculus:\n\nAs an extension of vector calculus operators to physics, engineering and tensor spaces, Grad, Div and Curl operators also are often associated with Tensor calculus as well as vector calculus.\n\n"}
{"id": "2882813", "url": "https://en.wikipedia.org/wiki?curid=2882813", "title": "Parameter space", "text": "Parameter space\n\nIn science, a parameter space is the set of all possible combinations of values for all the different parameters contained in a particular mathematical model. The ranges of values of the parameters may form the axes of a plot, and particular outcomes of the model may be plotted against these axes to illustrate how different regions of the parameter space produce different types of behaviour in the model.\n\nOften the parameters are inputs of a function, in which case the technical term for the parameter space is domain of a function.\n\nParameter spaces are particularly useful for describing families of probability distributions that depend on parameters. More generally in science, the term parameter space is used to describe experimental variables. For example, the concept has been used in the science of soccer in the article \"Parameter space for successful soccer kicks.\" In the study, \"Success rates are determined through the use of four-dimensional parameter space volumes.\"\n\nIn the context of statistics, parameter spaces form the background for parameter estimation.\nAs Ross describes in his book:\n\nThe idea of intentionally truncating the parameter space has also been advanced elsewhere.\n\n\n\n\nParameter space contributed to the liberation of geometry from the confines of three-dimensional space. For instance, the parameter space of spheres in three dimensions, has four dimensions—three for the sphere center and another for the radius. According to Dirk Struik, it was the book \"Neue Geometrie des Raumes\" (1849) by Julius Plücker that showed\nThe requirement for higher dimensions is illustrated by Plücker's line geometry. Struik writes\nThus the Klein quadric describes the parameters of lines in space.\n\n"}
{"id": "40765261", "url": "https://en.wikipedia.org/wiki?curid=40765261", "title": "Point process notation", "text": "Point process notation\n\nIn probability and statistics, point process notation comprises the range of mathematical notation used to symbolically represent random objects known as point processes, which are used in related fields such as stochastic geometry, spatial statistics and continuum percolation theory and frequently serve as mathematical models of random phenomena, representable as points, in time, space or both.\n\nThe notation varies due to the histories of certain mathematical fields and the different interpretations of point processes, and borrows notation from mathematical areas of study such as measure theory and set theory.\n\nThe notation, as well as the terminology, of point processes depends on their setting and interpretation as mathematical objects which under certain assumptions can be interpreted as random sequences of points, random sets of points or random counting measures.\n\nIn some mathematical frameworks, a given point process may be considered as a sequence of points with each point randomly positioned in \"d\"-dimensional Euclidean space R as well as some other more abstract mathematical spaces. In general, whether or not a random sequence is equivalent to the other interpretations of a point process depends on the underlying mathematical space, but this holds true for the setting of finite-dimensional Euclidean space R.\n\nA point process is called \"simple\" if no two (or more points) coincide in location with probability one. Given that often point processes are simple and the order of the points does not matter, a collection of random points can be considered as a random set of points The theory of random sets was independently developed by David Kendall and Georges Matheron. In terms of being considered as a random set, a sequence of random points is a random closed set if the sequence has no accumulation points with probability one\n\nA point process is often denoted by a single letter, for example formula_1, and if the point process is considered as a random set, then the corresponding notation:\n\nis used to denote that a random point formula_3 is an element of (or belongs to) the point process formula_1. The theory of random sets can be applied to point processes owing to this interpretation, which alongside the random sequence interpretation has resulted in a point process being written as:\n\nwhich highlights its interpretation as either a random sequence or random closed set of points. Furthermore, sometimes an uppercase letter denotes the point process, while a lowercase denotes a point from the process, so, for example, the point formula_6 (or formula_7) belongs to or is a point of the point process formula_8, or with set notation, formula_9.\n\nTo denote the number of points of formula_1 located in some Borel set formula_11, it is sometimes written \n\nwhere formula_13 is a random variable and formula_14 is a counting measure, which gives the number of points in some set. In this mathematical expression the point process is denoted by:\n\nformula_1.\n\nOn the other hand, the symbol:\n\nformula_16\n\nrepresents the number of points of formula_1 in formula_11. In the context of random measures, one can write:\n\nformula_19\n\nto denote that there is the set formula_11 that contains formula_21 points of formula_22. In other words, a point process can be considered as a random measure that assigns some non-negative integer-valued measure to sets. This interpretation has motivated a point process being considered just another name for a \"random counting measure\" and the techniques of random measure theory offering another way to study point processes, which also induces the use of the various notations used in integration and measure theory. \n\nThe different interpretations of point processes as random sets and counting measures is captured with the often used notation in which:\n\n\nDenoting the counting measure again with formula_14, this dual notation implies:\n\nIf formula_29 is some measurable function on R, then the sum of formula_30 over all the points formula_31 in formula_32 can be written in a number of ways such as:\n\nwhich has the random sequence appearance, or with set notation as:\n\nor, equivalently, with integration notation as:\n\nwhere formula_36 is the space of all possible counting measures, hence putting an emphasis on the interpretation of formula_1 as a random counting measure. An alternative integration notation may be used to write this integral as:\n\nThe dual interpretation of point processes is illustrated when writing the number of formula_1 points in a set formula_11 as:\n\nwhere the indicator function formula_42 if the point formula_31 is exists in formula_11 and zero otherwise, which in this setting is also known as a Dirac measure. In this expression the random measure interpretation is on the left-hand side while the random set notation is used is on the right-hand side.\n\nThe average or expected value of a sum of functions over a point process is written as:\n\nwhere (in the random measure sense) formula_46 is an appropriate probability measure defined on the space of counting measures formula_36. The expected value of formula_48 can be written as:\n\nwhich is also known as the first moment measure of formula_1. The expectation of such a random sum, known as a \"shot noise process\" in the theory of point processes, can be calculated with .\n\nPoint processes are employed in other mathematical and statistical disciplines, hence the notation may be used in fields such stochastic geometry, spatial statistics or continuum percolation theory, and areas which use the methods and theory from these fields.\n\n"}
{"id": "52031076", "url": "https://en.wikipedia.org/wiki?curid=52031076", "title": "Power law of cache misses", "text": "Power law of cache misses\n\nA power law is a mathematical relationship between two quantities in which one is directly proportional to some power of the other. The power law for cache misses was first established by C. K. Chow in his 1974 paper, supported by experimental data on hit ratios for stack processing by Richard Mattson in 1971. The power law of cache misses can be used to narrow down the cache sizes to practical ranges, given a tolerable miss rate, as one of the early steps while designing the cache hierarchy for a uniprocessor system.\n\nThe power law for cache misses can be stated as\n\nwhere \"M\" is the miss rate for a cache of size \"C\" and \"M\" is the miss rate of a baseline cache. The exponent \"α\" is workload-specific and typically ranges from 0.3 to 0.7.\n\nThe power law can only give an estimate of the miss rate only up to a certain value of cache size. A large enough cache eliminates capacity misses and increasing the cache size further will not reduce the miss rate any further, contrary to the power law's prediction.\n\nThe validity of the power law of cache misses also depends on the size of working memory set in a given process and also on the temporal re-reference pattern of cache blocks in a process. If a process has a small working memory set relative to the cache size, capacity misses are unlikely and the power law does not hold.\n\nAlthough conflict misses reduce as associativity increases, Hartstein et al. showed that the power law holds irrespective of set associativity.\n\nHartstein et al. plotted the number of cache block re-accesses versus their re-reference times for a large number of workloads and found that most also follow an exponential relationship.\n\nwhere \"R\"(\"t\") is the rate of re-referencing. It was found that the exponent \"β\" ranged between 1.7 and 1.3. Theoretically, it was proved that the power laws of cache re-reference and cache miss rate are related by the equation formula_3. This means that for workloads that do not follow the re-reference power law, the power law of cache misses does not hold true.\n\nIn a multilevel cache hierarchy, the miss pattern of the higher level cache becomes the re-reference pattern of the immediate lower level cache. Hartstein et al. found that whereas the cache misses for lower levels do not follow a strict power law, as long as the lower level cache is considerably larger than the higher level cache, the miss rate function can be approximated to the power law.\n\n"}
{"id": "31228704", "url": "https://en.wikipedia.org/wiki?curid=31228704", "title": "Prime factor exponent notation", "text": "Prime factor exponent notation\n\nIn his 1557 work \"The Whetstone of Witte\", British mathematician Robert Recorde proposed an exponent notation by prime factorisation, which remained in use up until the eighteenth century and acquired the name \"Arabic exponent notation\". The principle of Arabic exponents was quite similar to Egyptian fractions; large exponents were broken down into smaller prime numbers. Squares and cubes were so called; prime numbers from five onwards were called \"sursolids\".\n\nAlthough the terms used for defining exponents differed between authors and times, the general system was the primary exponent notation until René Descartes devised the Cartesian exponent notation, which is still used today.\n\nThis is a list of Recorde's terms.\n\nBy comparison, here is a table of prime factors:\n\n\n"}
{"id": "358069", "url": "https://en.wikipedia.org/wiki?curid=358069", "title": "Proof by infinite descent", "text": "Proof by infinite descent\n\nIn mathematics, a proof by infinite descent is a particular kind of proof by contradiction that relies on the least integer principle. One typical application is to show that a given equation has no solutions.\n\nTypically, one shows that if a solution to a problem existed, which in some sense was related to one or more natural numbers, it would necessarily imply that a second solution existed, which was related to one or more 'smaller' natural numbers. This in turn would imply a third solution related to smaller natural numbers, implying a fourth solution, therefore a fifth solution, and so on. However, there cannot be an infinity of ever-smaller natural numbers, and therefore by mathematical induction (repeating the same step) the original premise—that any solution exists— is incorrect: its correctness produces a contradiction.\n\nAn alternative way to express this is to assume one or more solutions or examples exists. Then there must be a smallest solution or example—a minimal counterexample. We then prove that if a smallest solution exists, it must imply the existence of a smaller solution (in some sense)—which again proves that the existence of any solution would lead to a contradiction.\n\nThe earliest uses of the method of infinite descent appear in Euclid's \"Elements\". A typical example is Proposition 31 of Book 7, in which Euclid proves that every composite integer is divided (in Euclid's terminology \"measured\") by some prime number. \n\nThe method was much later developed by Fermat, who coined the term and often used it for Diophantine equations. Two typical examples are showing the non-solvability of the Diophantine equation \"r\" + \"s\" = \"t\" and proving Fermat's theorem on sums of two squares, which states that an odd prime \"p\" can be expressed as a sum of two squares only when \"p\" ≡ 1 (mod 4) (see proof). In some cases, to the modern eye, his \"method of infinite descent\" is an exploitation of the inversion of the doubling function for rational points on an elliptic curve \"E\". The context is of a hypothetical non-trivial rational point on \"E\". Doubling a point on \"E\" roughly doubles the length of the numbers required to write it (as number of digits), so that a \"halving\" a point gives a rational with smaller terms. Since the terms are positive, they cannot decrease forever. In this way Fermat was able to show the non-existence of solutions in many cases of Diophantine equations of classical interest (for example, the problem of four perfect squares in arithmetic progression).\n\nIn the number theory of the twentieth century, the infinite descent method was taken up again, and pushed to a point where it connected with the main thrust of algebraic number theory and the study of L-functions. The structural result of Mordell, that the rational points on an elliptic curve \"E\" form a finitely-generated abelian group, used an infinite descent argument based on \"E\"/2\"E\" in Fermat's style.\n\nTo extend this to the case of an abelian variety \"A\", André Weil had to make more explicit the way of quantifying the size of a solution, by means of a height function – a concept that became foundational. To show that \"A\"(\"Q\")/2\"A\"(\"Q\") is finite, which is certainly a necessary condition for the finite generation of the group \"A\"(\"Q\") of rational points of \"A\", one must do calculations in what later was recognised as Galois cohomology. In this way, abstractly-defined cohomology groups in the theory become identified with \"descents\" in the tradition of Fermat. The Mordell–Weil theorem was at the start of what later became a very extensive theory.\n\nThe proof that the square root of 2 () is irrational (i.e. cannot be expressed as a fraction of two whole numbers) was discovered by the ancient Greeks, and is perhaps the earliest known example of a proof by infinite descent. Pythagoreans discovered that the diagonal of a square is incommensurable with its side, or in modern language, that the square root of two is irrational. Little is known with certainty about the time or circumstances of this discovery, but the name of Hippasus of Metapontum is often mentioned. For a while, the Pythagoreans treated as an official secret the discovery that the square root of two is irrational, and, according to legend, Hippasus was murdered for divulging it. The square root of two is occasionally called \"Pythagoras' number\" or \"Pythagoras' Constant\", for example .\n\nThe ancient Greeks, not having algebra, worked out a geometric proof by infinite descent (John Horton Conway presented another geometric proof (no. 8 ' ' ' ) by infinite descent that may be more accessible). The following is an algebraic proof along similar lines:\n\nSuppose that were rational. Then it could be written as\n\nfor two natural numbers, and . Then squaring would give\n\nso 2 must divide \"p\". Because 2 is a prime number, it must also divide \"p\", by Euclid's lemma. So \"p\" = 2\"r\", for some integer \"r\".\n\nBut then\n\nwhich shows that 2 must divide \"q\" as well. So \"q\" = 2\"s\" for some integer \"s\".\n\nThis gives\n\nTherefore, if could be written as a rational number, it could always be written as a rational number with smaller parts, which itself could be written with yet-smaller parts, \"ad infinitum\". But this is impossible in the set of natural numbers. Since is a real number, which can be either rational or irrational, the only option left is for to be irrational.\n\n(Alternatively, this proves that if were rational, no \"smallest\" representation as a fraction could exist, as any attempt to find a \"smallest\" representation \"p\"/\"q\" would imply a smaller one existed, which is a similar contradiction).\n\nFor positive integer \"k\", suppose that is not an integer, but is rational and can be expressed as ⁄ for natural numbers \"m\" and \"n\", and let \"q\" be the largest integer no greater than . Then\n\nThe numerator and denominator were each multiplied by the expression ( − \"q\")—which is positive but less than 1—and then simplified independently. So two resulting products, say \"m' \" and \"n' \", are themselves integers, which are less than \"m\" and \"n\" respectively. Therefore, no matter what natural numbers \"m\" and \"n\" are used to express , there exist smaller natural numbers \"m' \" < \"m\" and \"n' \" < \"n\" that have the same ratio. But infinite descent on the natural numbers is impossible, so this disproves the original assumption that could be expressed as a ratio of natural numbers.\n\nThe non-solvability of formula_8 in integers is sufficient to show the non-solvability of formula_9 in integers, which is a special case of Fermat's Last Theorem, and the historical proofs of the latter proceeded by more broadly proving the former using infinite descent. The following more recent proof demonstrates both of these impossibilities by proving still more broadly that a Pythagorean triangle cannot have any two of its sides each either a square or twice a square, since there is no smallest such triangle:\n\nSuppose there exists such a Pythagorean triangle. Then it can be scaled down to give a primitive (i.e., with no common factors other than 1) Pythagorean triangle with the same property. Primitive Pythagorean triangles' sides can be written as formula_10 formula_11 formula_12, with \"a\" and \"b\" relatively prime and with \"a+b\" odd and hence \"y\" and \"z\" both odd. The property that \"y\" and \"z\" are each odd means that neither \"y\" nor \"z\" can be twice a square. Furthermore, if \"x\" is a square or twice a square, then each of \"a\" and \"b\" is a square or twice a square. There are three cases, depending on which two sides are postulated to each be a square or twice a square:\n\n\nIn any of these cases, one Pythagorean triangle with two sides each of which is a square or twice a square has led to a smaller one, which in turn would lead to a smaller one, etc.; since such a sequence cannot go on infinitely, the original premise that such a triangle exists must be wrong.\n\nThis implies that the equations\ncannot have non-trivial solutions, since non-trivial solutions would give Pythagorean triangles with two sides being squares.\n\nFor other similar proofs by infinite descent for the \"n\" = 4 case of Fermat's Theorem, see the articles by Grant and Perella and Barbara.\n\n\n"}
{"id": "3710507", "url": "https://en.wikipedia.org/wiki?curid=3710507", "title": "Proof of impossibility", "text": "Proof of impossibility\n\nA proof of impossibility, also known as negative proof, proof of an impossibility theorem, or negative result, is a proof demonstrating that a particular problem cannot be solved, or cannot be solved in general. Often proofs of impossibility have put to rest decades or centuries of work attempting to find a solution. To prove that something is impossible is usually much harder than the opposite task; it is necessary to develop a theory. Impossibility theorems are usually expressible as universal propositions in logic (see universal quantification).\n\nOne of the most famous proofs of impossibility was the 1882 proof of Ferdinand von Lindemann, showing that the ancient problem of squaring the circle cannot be solved, because the number is transcendental (non-algebraic) and only a subset of the algebraic numbers can be constructed by compass and straightedge. Two other classical problems—trisecting the general angle and doubling the cube—were also proved impossible in the nineteenth century.\n\nA problem arising in the sixteenth century was that of creating a general formula using radicals expressing the solution of any polynomial equation of fixed degree \"k\", where \"k\" ≥ 5. In the 1820s, the Abel–Ruffini theorem showed this to be impossible using concepts such as solvable groups from Galois theory, a new subfield of abstract algebra.\n\nAmong the most important proofs of impossibility of the 20th century, were those related to undecidability, which showed that there are problems that cannot be solved in general by any algorithm at all. The most famous is the halting problem.\n\nIn computational complexity theory, techniques like relativization (see oracle machine) provide \"weak\" proofs of impossibility excluding certain proof techniques. Other techniques like proofs of completeness for a complexity class provide evidence for the difficulty of problems by showing them to be just as hard to solve as other known problems that have proved intractable.\n\nOne widely used type of impossibility proof is proof by contradiction. In this type of proof it is shown that if something, such as a solution to a particular class of equations, were possible, then two mutually contradictory things would be true, such as a number being both even and odd. The contradiction implies that the original premise is impossible.\n\nOne type of proof by contradiction is proof by descent. Here it is postulated that something is possible, such as a solution to a class of equations, and that therefore there must be a smallest solution; then starting from the allegedly smallest solution, it is shown that a smaller solution can be found, contradicting the premise that the former solution was the smallest one possible. Thus the premise that a solution exists must be false.\n\nThis method of proof can also be interpreted slightly differently, as the method of \"infinite descent\". One postulates that a positive integer solution exists, whether or not it is the smallest one, and one shows that based on this solution a smaller solution must exist. But by mathematical induction it follows that a still smaller solution must exist, then a yet smaller one, and so on for an infinite number of steps. But this contradicts the fact that one cannot find smaller and smaller positive integers indefinitely; the contradiction implies that the premise that a solution exists is wrong.\n\nThere are two alternative methods of proving wrong a conjecture that something is impossible: by counterexample (constructive proof) and by logical contradiction (non-constructive proof).\n\nThe obvious way to disprove an impossibility conjecture by providing a single counterexample. For example, Euler proposed that at least \"n\" different \"n\" powers were necessary to sum to yet another \"n\" power. The conjecture was disproved in 1966 with a counterexample involving a count of only four different 5th powers summing to another fifth power:\nA proof by counterexample is a constructive proof.\n\nIn contrast, a non-constructive proof that something is \"not\" impossible proceeds by showing it is logically contradictory for \"all\" possible counterexamples to be invalid: At least \"one\" of the items on a list of possible counterexamples must actually be a valid counterexample to the impossibility conjecture. For example, a conjecture that it is impossible for an irrational power raised to an irrational power to be rational was disproved by showing that one of two possible counterexamples must be a valid counterexample, without showing which one it is.\n\nThe proof by Pythagoras (or more likely one of his students) about 500 BCE has had a profound effect on mathematics. It shows that the square root of 2 cannot be expressed as the ratio of two integers (counting numbers). The proof bifurcated \"the numbers\" into two non-overlapping collections—the rational numbers and the irrational numbers. This bifurcation was used by Cantor in his diagonal method, which in turn was used by Turing in his proof that the \"Entscheidungsproblem\" (the decision problem of Hilbert) is undecidable.\n\nProofs followed for various square roots of the primes up to 17.\n\nThere is a famous passage in Plato's \"Theaetetus\" in which it is stated that Teodorus (Plato's teacher) proved the irrationality of\ntaking all the separate cases up to the root of 17 square feet ... .\nA more general proof now exists that:\n\nThat is, it is impossible to express the \"m\"th root of an integer \"N\" as the ratio of two integers \"a\" and \"b\" that share no common prime factor except in cases in which \"b\" = 1.\n\nThree famous questions of Greek geometry were how:\n\n\nFor more than 2,000 years unsuccessful attempts were made to solve these problems; at last, in the 19th century it was proved that the desired constructions are logically impossible.\n\nA fourth problem of the ancient Greeks was to construct an equilateral polygon with a specified number \"n\" of sides, beyond the basic cases \"n\" = 3, 4, 5 that they knew how to construct.\n\nAll of these are problems in Euclidean construction, and Euclidean constructions can be done only if they involve only Euclidean numbers (by definition of the latter) (Hardy and Wright p. 159). Irrational numbers can be Euclidean. A good example is the irrational number the square root of 2. It is simply the length of the hypotenuse of a right triangle with legs both one unit in length, and it can be constructed with straightedge and compass. But it was proved centuries after Euclid that Euclidean numbers cannot involve any operations other than addition, subtraction, multiplication, division, and the extraction of square roots.\n\nBoth trisecting the general angle and doubling the cube require taking cube roots, which are not constructible numbers by compass and straightedge.\n\nformula_2 is not a Euclidean number ... and therefore it is impossible to construct, by Euclidean methods a length equal to the circumference of a circle of unit diameter\n\nA proof exists to demonstrate that any Euclidean number is an algebraic number—a number that is the solution to some polynomial equation. Therefore, because formula_2 was proved in 1882 to be a transcendental number and thus by definition not an algebraic number, it is not a Euclidean number. Hence the construction of a length formula_2 from a unit circle is impossible, and the circle cannot be squared.\n\nThe Gauss-Wantzel theorem showed in 1837 that constructing an equilateral \"n\"-gon is impossible for most values of \"n\".\n\nNagel and Newman consider the question raised by the parallel postulate to be \"...perhaps the most significant development in its long-range effects upon subsequent mathematical history\" (p. 9).\n\nThe question is: can the axiom that two parallel lines \"...will not meet even 'at infinity'\" (footnote, ibid) be derived from the other axioms of Euclid's geometry? It was not until work in the nineteenth century by \"... Gauss, Bolyai, Lobachevsky, and Riemann, that the impossibility of deducing the parallel axiom from the others was demonstrated. This outcome was of the greatest intellectual importance. ...a \"proof\" can be given of the \"impossibility of proving\" certain propositions [in this case, the parallel postlate] within a given system [in this case, Euclid's first four postulates]\". (p. 10)\n\nFermat's Last Theorem was conjectured by Pierre de Fermat in the 1600s, states the impossibility of finding solutions in positive integers for the equation formula_5 with formula_6. Fermat himself gave a proof for the \"n\" = 4 case using his technique of infinite descent, and other special cases were subsequently proved, but the general case was not proved until 1994 by Andrew Wiles.\n\nThis profound paradox presented by Jules Richard in 1905 informed the work of Kurt Gödel (cf Nagel and Newman p. 60ff) and Alan Turing. A succinct definition is found in \"Principia Mathematica\":\nKurt Gödel considered his proof to be “an analogy” of Richard's paradox, which he called “\"Richard's antinomy\"”. See more below about Gödel's proof.\n\nAlan Turing constructed this paradox with a machine and proved that this machine could not answer a simple question: will this machine be able to determine if any machine (including itself) will become trapped in an unproductive ‘infinite loop’ (i.e. it fails to continue its computation of the diagonal number).\n\nTo quote Nagel and Newman (p. 68), \"Gödel's paper is difficult. Forty-six preliminary definitions, together with several important preliminary theorems, must be mastered before the main results are reached\" (p. 68). In fact, Nagel and Newman required a 67-page introduction to their exposition of the proof. But if the reader feels strong enough to tackle the paper, Martin Davis observes that \"This remarkable paper is not only an intellectual landmark, but is written with a clarity and vigor that makes it a pleasure to read\" (Davis in Undecidable, p. 4). It is recommended that most readers see Nagel and Newman first.\n\nSo what did Gödel prove? In his own words:\n\nGödel compared his proof to \"Richard's antinomy\" (an \"antinomy\" is a contradiction or a paradox; for more see Richard's paradox):\n\n\nA number of similar undecidability proofs appeared soon before and after Turing's proof:\n\n\nFor an exposition suitable for non-specialists see Beltrami p. 108ff. Also see Franzen Chapter 8 pp. 137–148, and Davis pp. 263–266. Franzén's discussion is significantly more complicated than Beltrami's and delves into Ω—Gregory Chaitin's so-called \"halting probability\". Davis's older treatment approaches the question from a Turing machine viewpoint. Chaitin has written a number of books about his endeavors and the subsequent philosophic and mathematical fallout from them.\n\nA string is called \"(algorithmically) random\" if it cannot be produced from any shorter computer program. While most strings are random, no particular one can be proved so, except for finitely many short ones:\n\nBeltrami observes that \"Chaitin's proof is related to a paradox posed by Oxford librarian G. Berry early in the twentieth century that asks for 'the smallest positive integer that cannot be defined by an English sentence with fewer than 1000 characters.' Evidently, the shortest definition of this number must have at least 1000 characters. However, the sentence within quotation marks, which is itself a definition of the alleged number is less than 1000 characters in length!\" (Beltrami, p. 108)\n\nThe question \"Does any arbitrary \"Diophantine equation\" have an integer solution?\" is undecidable.That is, it is impossible to answer the question for all cases.\n\nFranzén introduces Hilbert's tenth problem and the MRDP theorem (Matiyasevich-Robinson-Davis-Putnam theorem) which states that \"no algorithm exists which can decide whether or not a Diophantine equation has \"any\" solution at all\". MRDP uses the undecidability proof of Turing: \"... the set of solvable Diophantine equations is an example of a computably enumerable but not decidable set, and the set of unsolvable Diophantine equations is not computably enumerable\" (p. 71).\n\nIn political science, Arrow's impossibility theorem states that it is impossible to devise a voting system that satisfies a set of five specific axioms. This theorem is proved by showing that four of the axioms together imply the opposite of the fifth.\n\nIn economics, Holmström's theorem is an impossibility theorem proving that no incentive system for a team of agents can satisfy all of three desirable criteria.\n\nIn natural science, impossibility assertions (like other assertions) come to be widely accepted as overwhelmingly probable rather than considered proved to the point of being unchallengeable. The basis for this strong acceptance is a combination of extensive evidence of something not occurring, combined with an underlying theory, very successful in making predictions, whose assumptions lead logically to the conclusion that something is impossible.\n\nTwo examples of widely accepted impossibilities in physics are perpetual motion machines, which violate the law of conservation of energy, and exceeding the speed of light, which violates the implications of special relativity. Another is the uncertainty principle of quantum mechanics, which asserts the impossibility of simultaneously knowing both the position and the momentum of a particle. Also Bell's theorem: no physical theory of local hidden variables can ever reproduce all of the predictions of quantum mechanics.\n\nWhile an impossibility assertion in science can never be absolutely proved, it could be refuted by the observation of a single counterexample. Such a counterexample would require that the assumptions underlying the theory that implied the impossibility be re-examined.\n\n\n"}
{"id": "2598499", "url": "https://en.wikipedia.org/wiki?curid=2598499", "title": "Psychologism", "text": "Psychologism\n\nPsychologism is a philosophical position, according to which psychology plays a central role in grounding or explaining some other, non-psychological type of fact or law.\n\nThe \"Oxford English Dictionary\" defines \"psychologism\" as: \"The view or doctrine that a theory of psychology or ideas forms the basis of an account of metaphysics, epistemology, or meaning; (sometimes) spec. the explanation or derivation of mathematical or logical laws in terms of psychological facts.\" Psychologism in epistemology, the idea that its problems \"can be solved satisfactorily by the psychological study of the development of mental processes\", was argued in John Locke's \"An Essay Concerning Human Understanding\" (1690).\n\nOther forms of psychologism are logical psychologism and mathematical psychologism. Logical psychologism is a position in logic (or the philosophy of logic) according to which logical laws and mathematical laws are grounded in, derived from, explained or exhausted by psychological facts or laws. Psychologism in the philosophy of mathematics is the position that mathematical concepts and/or truths are grounded in, derived from or explained by psychological facts or laws.\n\nThe word was coined by Johann Eduard Erdmann as \"Psychologismus\", being translated into English as \"psychologism\".\n\nJohn Stuart Mill was accused by Edmund Husserl of being an advocate of a type of logical psychologism, although this may not have been the case. So were many nineteenth-century German philosophers such as Christoph von Sigwart, Benno Erdmann, Theodor Lipps, Gerardus Heymans, Wilhelm Jerusalem, and , as well as a number of psychologists, past and present (e.g., Wilhelm Wundt and Gustave Le Bon).\n\nPsychologism was notably criticized by Gottlob Frege in his anti-psychologistic work \"The Foundations of Arithmetic\", and many of his works and essays, including his review of Husserl's \"Philosophy of Arithmetic\". Husserl, in the first volume of his \"Logical Investigations\", called \"The Prolegomena of Pure Logic\", criticized psychologism thoroughly and sought to distance himself from it. Frege's arguments were largely ignored, while Husserl's were widely discussed.\n\nIn \"Psychologism and Behaviorism\", Ned Block takes psychologism as the position that \"whether behavior is intelligent behavior depends on the character of the internal information processing that produces it.\" This is in contrast to a behavioral view which would state that intelligence can be ascribed to a being solely via observing its behavior. This latter type of behavioral view is strongly associated with the Turing test.\n\n\n"}
{"id": "35411073", "url": "https://en.wikipedia.org/wiki?curid=35411073", "title": "Raymond Clare Archibald", "text": "Raymond Clare Archibald\n\nRaymond Clare Archibald (7 October 1875 – 26 July 1955) was a prominent Canadian-American mathematician. He is known for his work as a historian of mathematics, his editorships of mathematical journals and his contributions to the teaching of mathematics.\n\nRaymond Clare Archibald was born in South Branch, Stewiacke, Nova Scotia on 7 October 1875. He was the son of Abram Newcomb Archibald (1849—1883) and Mary Mellish Archibald (1849—1901). He was the fourth cousin twice removed of the famous Canadian-American astronomer and mathematician Simon Newcomb (1835—1909).\n\nArchibald graduated in 1894 from Mount Allison College with B.A. degree in mathematics and teacher's certificate in violin. After teaching mathematics and violin for a year at the Mount Allison Ladies’ College he went to Harvard where he received a B.A. 1896 and a M.A. in 1897. He then traveled to Europe where he attended the University of Berlin during 1898 and received a Ph.D.cum laude from the University of Strassburg in 1900. His advisor was Karl Theodor Reye and title of his dissertation was The Cardioide and Some of its Related Curves.\n\nHe returned to Canada in 1900 and taught mathematics and violin at the Mount Allison Ladies’ College until 1907. After a one-year appointment at Acadia University he accepted an invitation of join the mathematics department at Brown University. He stayed at Brown for the rest of his career becoming a Professor Emeritus in 1943. While at Brown he created one of the finest mathematical libraries in the western hemisphere.\n\nArchibald returned to Mount Allison in 1954 to curate the Mary Mellish Archibald Memorial Library, the library he had founded in 1905 to honor his mother. At his death the library contained 23,000 volumes, 2,700 records, and 70,000 songs in American and English poetry and drama.\n\nRaymond Clare Archibald was a world-renowned historian of mathematics with a lifelong concern for the teaching of mathematics in secondary schools. At the presentation of his portrait to Brown University the head of the mathematics department, Professor Clarence Raymond Adams (1898–1965) said of him:\n\n\"The instincts of the bibliophile were also his from early years. Possessing a passion for accurate detail, systematic by nature and blessed with a memory that was the marvel of his friends, he gradually acquired a knowledge of mathematical books and their values which has scarcely been equalled. This knowledge and an untiring energy he dedicated to the upbuilding of the mathematical library at Brown University. From modest beginnings he has developed this essential equipment of the mathematical investigator to a point where it has no superior, in completeness and in convenience for the user.\"\n\nArchibald received honorary degrees from the University of Padua (LL.D., 1922), Mount Allison University (LL.D., 1923) and from Brown University (M.A. ad eundem, 1943).\n\n\nArchibald’s bibliography contains over 1,000 entries. He contributed to over 20 different journals, mathematical, scientific, educational and literary. The following are the books of which he is an author:\n\n\n\n"}
{"id": "24860178", "url": "https://en.wikipedia.org/wiki?curid=24860178", "title": "Revolutions in Mathematics", "text": "Revolutions in Mathematics\n\nRevolutions in Mathematics is a collection of essays in the history and philosophy of mathematics.\n\n\nThe book was reviewed by Pierre Kerszberg for \"Mathematical Reviews\" and by Michael S. Mahoney for \"American Mathematical Monthly\". Mahoney says \"The title should have a question mark.\" He sets the context by referring to paradigm shifts that characterize scientific revolutions as described by Thomas Kuhn in his book \"The Structure of Scientific Revolutions\". According to Michael Crowe in chapter one, revolutions never occur in mathematics. Mahoney explains how mathematics grows upon itself and does not discard earlier gains in understanding with new ones, such as happens in biology, physics, or other sciences. A nuanced version of revolution in mathematics is described by Caroline Dunmore who sees change at the level of \"meta-mathematical values of the community that define the telos and methods of the subject, and encapsulate general beliefs about its value.\" On the other hand, reaction to innovation in mathematics is noted, resulting in \"clashes of intellectual and social values\".\n\n"}
{"id": "4233115", "url": "https://en.wikipedia.org/wiki?curid=4233115", "title": "Scottish Book", "text": "Scottish Book\n\nThe Scottish Book () was a thick notebook used by mathematicians of the Lwów School of Mathematics in Poland for jotting down problems meant to be solved. The notebook was named after the \"Scottish Café\" where it was kept.\n\nOriginally, the mathematicians who gathered at the cafe would write down the problems and equations directly on the cafe's marble table tops, but these would be erased at the end of each day, and so the record of the preceding discussions would be lost. The idea for the book was most likely originally suggested by Stefan Banach, or his wife, Łucja, who purchased a large notebook and left it with the proprietor of the cafe.\n\nThe Scottish Café () was the café in Lwów (now \"Lviv\") where, in the 1930s and 1940s, mathematicians from the Lwów School collaboratively discussed research problems, particularly in functional analysis and topology.\n\nStanislaw Ulam recounts that the tables of the café had marble tops, so they could write in pencil, directly on the table, during their discussions. To keep the results from being lost, and after becoming annoyed with their writing directly on the table tops, Stefan Banach's wife provided the mathematicians with a large notebook, which was used for writing the problems and answers and eventually became known as the \"Scottish Book\". The book—a collection of solved, unsolved, and even probably unsolvable problems—could be borrowed by any of the guests of the café. Solving any of the problems was rewarded with prizes, with the most difficult and challenging problems having expensive prizes (during the Great Depression and on the eve of World War II), such as a bottle of fine brandy.\n\nFor problem 153, which was later recognized as being closely related to Stefan Banach's \"basis problem\", Stanisław Mazur offered the prize of a live goose. This problem was solved only in 1972 by Per Enflo, who was presented with the live goose in a ceremony that was broadcast throughout Poland.\n\nThe café building used to house the at the street address of 27 Taras Shevchenko Prospekt. The original cafe was renovated in May 2014 and contains a copy of the Scottish Book.\n\nA total of 193 problems were written down in the book. Stanisław Mazur contributed a total of 43 problems, 24 of them as a single author and 19 together with Stefan Banach. Banach himself wrote 14, plus another 11 with Stanislaw Ulam and Mazur. Ulam wrote 40 problems and additional 15 ones with others.\n\nDuring the Soviet occupation of Lwów, several Russian mathematicians visited the city and also added problems to the book.\n\nHugo Steinhaus contributed the last one in May 1941 (other sources give March 1941), which involved a question about the likely distribution of matches within a matchbox—a problem motivated by Banach's habit of chain smoking cigarettes—shortly before the German attack on the Soviet Union.\n\nAfter World War II, an English translation annotated by Ulam was published by Los Alamos National Laboratory in 1957. After World War II, Steinhaus at the University of Wrocław revived the tradition of the Scottish book by initiating \"The New Scottish Book\".\n\nThe following mathematicians were associated with the Lwów School of Mathematics or contributed to \"The Scottish Book\":\n\n\n"}
{"id": "35194349", "url": "https://en.wikipedia.org/wiki?curid=35194349", "title": "Siegel parabolic subgroup", "text": "Siegel parabolic subgroup\n\nIn mathematics, the Siegel parabolic subgroup, named after Carl Ludwig Siegel, is the parabolic subgroup of the symplectic group with abelian radical, given by the matrices of the symplectic group whose lower left quadrant is 0 (for the standard symplectic form).\n"}
{"id": "3571350", "url": "https://en.wikipedia.org/wiki?curid=3571350", "title": "Socle (mathematics)", "text": "Socle (mathematics)\n\nIn mathematics, the term socle has several related meanings.\n\nIn the context of group theory, the socle of a group \"G\", denoted soc(\"G\"), is the subgroup generated by the minimal normal subgroups of \"G\". It can happen that a group has no minimal non-trivial normal subgroup (that is, every non-trivial normal subgroup properly contains another such subgroup) and in that case the socle is defined to be the subgroup generated by the identity. The socle is a direct product of minimal normal subgroups.\n\nAs an example, consider the cyclic group Z with generator \"u\", which has two minimal normal subgroups, one generated by \"u\" (which gives a normal subgroup with 3 elements) and the other by \"u\" (which gives a normal subgroup with 2 elements). Thus the socle of Z is the group generated by \"u\" and \"u\", which is just the group generated by \"u\".\n\nThe socle is a characteristic subgroup, and hence a normal subgroup. It is not necessarily transitively normal, however.\n\nIf a group G is a finite solvable group, then the socle can be expressed as a product of elementary abelian p-groups. Thus, in this case, it is just a product of copies of Z/pZ for various p where the same p may occur multiple times in the product.\n\nIn the context of module theory and ring theory the socle of a module \"M\" over a ring \"R\" is defined to be the sum of the minimal nonzero submodules of \"M\". It can be considered as a dual notion to that of the radical of a module. In set notation,\n\nEquivalently,\n\nThe socle of a ring \"R\" can refer to one of two sets in the ring. Considering \"R\" as a right \"R\" module, soc(\"R\") is defined, and considering \"R\" as a left \"R\" module, soc(\"R\") is defined. Both of these socles are ring ideals, and it is known they are not necessarily equal.\n\n\nIn the context of Lie algebras, a socle of a symmetric Lie algebra is the eigenspace of its structural automorphism which corresponds to the eigenvalue −1. (A symmetric Lie algebra decomposes into the direct sum of its socle and cosocle.)\n\n\n"}
{"id": "571280", "url": "https://en.wikipedia.org/wiki?curid=571280", "title": "Stratification (mathematics)", "text": "Stratification (mathematics)\n\nStratification has several usages in mathematics.\n\nIn mathematical logic, stratification is any consistent assignment of numbers to predicate symbols guaranteeing that a unique formal interpretation of a logical theory exists. Specifically, we say that a set of clauses of the form formula_1 is stratified if and only if\nthere is a stratification assignment S that fulfills the following conditions:\n\n\nThe notion of stratified negation leads to a very effective operational semantics for stratified programs in terms of the stratified least fixpoint, that is obtained by iteratively applying the fixpoint operator to each \"stratum\" of the program, from the lowest one up.\nStratification is not only useful for guaranteeing unique interpretation of Horn clause\ntheories. It has also been used by W.V. Quine (1937) to address Russell's paradox, which undermined Frege's central work \"Grundgesetze der Arithmetik\" (1902).\n\nIn New Foundations (NF) and related set theories, a formula formula_4 in the language of first-order logic with equality and membership is said to be\nstratified if and only if there is a function\nformula_5 which sends each variable appearing in formula_4 (considered as an item of syntax) to\na natural number (this works equally well if all integers are used) in such a way that\nany atomic formula formula_7 appearing in formula_4 satisfies formula_9 and any atomic formula formula_10 appearing in formula_4 satisfies formula_12.\n\nIt turns out that it is sufficient to require that these conditions be satisfied only when\nboth variables in an atomic formula are bound in the set abstract formula_13\nunder consideration. A set abstract satisfying this weaker condition is said to be\nweakly stratified.\n\nThe stratification of New Foundations generalizes readily to languages with more\npredicates and with term constructions. Each primitive predicate needs to have specified\nrequired displacements between values of formula_5 at its (bound) arguments\nin a (weakly) stratified formula. In a language with term constructions, terms themselves\nneed to be assigned values under formula_5, with fixed displacements from the\nvalues of each of their (bound) arguments in a (weakly) stratified formula. Defined term\nconstructions are neatly handled by (possibly merely implicitly) using the theory\nof descriptions: a term formula_16 (the x such that formula_4) must\nbe assigned the same value under formula_5 as the variable x.\n\nA formula is stratified if and only if it is possible to assign types to all variables appearing\nin the formula in such a way that it will make sense in a version TST of the theory of\ntypes described in the New Foundations article, and this is probably the best way\nto understand the stratification of New Foundations in practice.\n\nThe notion of stratification can be extended to the lambda calculus; this is found\nin papers of Randall Holmes.\n\nIn singularity theory, there is a different meaning, of a decomposition of a topological space \"X\" into disjoint subsets each of which is a topological manifold (so that in particular a \"stratification\" defines a partition of the topological space). This is not a useful notion when unrestricted; but when the various strata are defined by some recognisable set of conditions (for example being locally closed), and fit together manageably, this idea is often applied in geometry. Hassler Whitney and René Thom first defined formal conditions for stratification. See Whitney stratification and topologically stratified space.\n\nSee stratified sampling.\n"}
{"id": "3371340", "url": "https://en.wikipedia.org/wiki?curid=3371340", "title": "String art", "text": "String art\n\nString art, or pin and thread art, is characterized by an arrangement of colored thread strung between points to form geometric patterns or representational designs such as a ship's sails, sometimes with other artist material comprising the remainder of the work. Thread, wire, or string is wound around a grid of nails hammered into a velvet-covered wooden board. Though straight lines are formed by the string, the slightly different angles and metric positions at which strings intersect gives the appearance of Bézier curves (as in the mathematical concept of envelope of a family of straight lines). Quadratic Bézier curve are obtained from strings based on two intersecting segments. Other forms of string art include Spirelli, which is used for cardmaking and scrapbooking, and curve stitching, in which string is stitched through holes.\n\nString art has its origins in the 'curve stitch' activities invented by Mary Everest Boole at the end of the 19th century to make mathematical ideas more accessible to children. It was popularised as a decorative craft in the late 1960s through kits and books.\n\nA computational form of String art that can produce photo-realistic artwork was introduced by Petros Vrellis, in 2016.\n\n\n\n"}
{"id": "47962742", "url": "https://en.wikipedia.org/wiki?curid=47962742", "title": "Tally marks", "text": "Tally marks\n\nTally marks, also called hash marks, are a unary numeral system. They are a form of numeral used for counting. They are most useful in counting or tallying ongoing results, such as the score in a game or sport, as no intermediate results need to be erased or discarded.\n\nHowever, because of the length of large numbers, tallies are not commonly used for static text. Notched sticks, known as tally sticks, were also historically used for this purpose.\n\nCounting aids other than body parts appear in the Upper Paleolithic. The oldest tally sticks date to between 35,000 and 25,000 years ago, in the form of notched bones found in the context of the European Aurignacian to Gravettian and in Africa's Late Stone Age.\n\nThe so-called \"Wolf bone\" is a prehistoric artifact discovered in 1937 in Czechoslovakia during excavations at Vestonice, Moravia, led by Karl Absolon. Dated to the Aurignacian, approximately 30,000 years ago, the bone is marked with 55 marks which may be tally marks. The head of an ivory Venus figurine was excavated close to the bone.\n\nThe Ishango bone, found in the Ishango region of the present-day Democratic Republic of Congo, is dated to over 20,000 years old. Upon discovery, it was thought to portray a series of prime numbers. In the book \"How Mathematics Happened: The First 50,000 Years\", Peter Rudman argues that the development of the concept of prime numbers could only have come about after the concept of division, which he dates to after 10,000 BC, with prime numbers probably not being understood until about 500 BC. He also writes that \"no attempt has been made to explain why a tally of something should exhibit multiples of two, prime numbers between 10 and 20, and some numbers that are almost multiples of 10.\" Alexander Marshack examined the Ishango bone microscopically, and concluded that it may represent a six-month lunar calendar.\n\nTally marks are typically clustered in groups of five for legibility. The cluster size 5 has the advantages of (a) easy conversion into decimal for higher arithmetic operations and (b) avoiding error, as humans can far more easily correctly identify a cluster of 5 than one of 10.\n\nRoman numerals, the Chinese numerals for one through three (一 二 三), and rod numerals were derived from tally marks, as possibly was the ogham script.\n\nBase 1 arithmetic notation system is an unary positional system similar to tally marks. It is rarely used as a practical base for counting due to its difficult readability. It is made by the concatenation of zero.\n\nThe numbers 1, 2, 3, 4, 5, ... would be represented in this system as\n\nBase 1 notation is widely used in type numbers of flour, the higher number represents a higher grind.\n"}
{"id": "33065815", "url": "https://en.wikipedia.org/wiki?curid=33065815", "title": "ΔP", "text": "ΔP\n\nΔ (Delta P) is a mathematical term used to illustrate a change (Δ) in pressure ().\n\n\nAs used in the Darcy–Weisbach equation — Given that the head loss \"h\" expresses the pressure loss \"Δp\" as the height of a column of fluid,\n\nwhere ρ is the density of the fluid, the Darcy–Weisbach equation can also be written in terms of pressure loss:\n\nIn general, compliance is defined by the change in volume (ΔV) versus the associated change in pressure (ΔP), or ΔV/ΔP. During mechanical ventilation, compliance can be influenced by 3 key physiologic factors:\n\nLung compliance is influenced by a variety of primary abnormalities of lung parenchyma, both chronic and acute. Airway resistance is typically increased by bronchospasm and airway secretions. Chest wall compliance can be decreased by fixed abnormalities (e.g. kyphoscoliosis, morbid obesity) or more variable problems driven by patient agitation while intubated.\n\nCalculating Compliance on minute volume (V: ΔV is always defined by tidal volume (V), but ΔP is different for the measurement of dynamic vs. static compliance.\n\nwhere PIP = peak inspiratory pressure (the maximum pressure during inspiration), and PEEP = positive end expiratory pressure. Alterations in airway resistance, lung compliance and chest wall compliance influence C.\n\nwhere P = plateau pressure. P is measured at the end of inhalation and prior to exhalation using an inspiratory hold maneuver. During this maneuver, airflow is transiently (~0.5 sec) discontinued, which eliminates the effects of airway resistance. P is never > PIP and is typically < 3-5 cmHO lower than PIP when airway resistance is normal.\n\n"}
