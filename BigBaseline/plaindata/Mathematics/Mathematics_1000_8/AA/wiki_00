{"id": "12637741", "url": "https://en.wikipedia.org/wiki?curid=12637741", "title": "AWM/MAA Falconer Lecturer", "text": "AWM/MAA Falconer Lecturer\n\nThe Etta Z. Falconer Lecture is an award and lecture series which honors \"women who have made distinguished contributions to the mathematical sciences or mathematics education\". It is sponsored by the Association for Women in Mathematics and the Mathematical Association of America. The lectures began in 1996 and were named after the mathematician Etta Z. Falconer in 2004 \"in memory of Falconer's profound vision and accomplishments in enhancing the movement of minorities and women into scientific careers\". The recipient presents the lecture at MathFest each summer.\n\nThe Falconer Lecturers have been:\n\n"}
{"id": "12216711", "url": "https://en.wikipedia.org/wiki?curid=12216711", "title": "Abel's binomial theorem", "text": "Abel's binomial theorem\n\nAbel's binomial theorem, named after Niels Henrik Abel, is a mathematical identity involving sums of binomial coefficients. It states the following:\n\n"}
{"id": "644032", "url": "https://en.wikipedia.org/wiki?curid=644032", "title": "Adjoint", "text": "Adjoint\n\nIn mathematics, the term adjoint applies in several situations. Several of these share a similar formalism: if \"A\" is adjoint to \"B\", then there is typically some formula of the type\n\nSpecifically, adjoint or adjunction may mean:\n"}
{"id": "49322650", "url": "https://en.wikipedia.org/wiki?curid=49322650", "title": "Algorismus (Norse text)", "text": "Algorismus (Norse text)\n\nAlgorismus is a short treatise on mathematics, written in Old Icelandic. It is the oldest text on mathematics in a Scandinavian language and survives in the early fourteenth-century manuscript Hauksbók. It is probably a translation from Latin into Old Norse of some pages included in more ancient books such as \"Carmen de Algorismo\" by De Villa Dei of 1200, \"Liber Abaci\" by Fibonacci of 1202, and \"Algorismus Vulgaris\" by De Sacrobosco of 1230.\n"}
{"id": "44990517", "url": "https://en.wikipedia.org/wiki?curid=44990517", "title": "Amari distance", "text": "Amari distance\n\nThe Amari distance is a measure between two nonsingular matrices, useful for checking for convergence in independent component analysis algorithms and for comparing solutions.\n"}
{"id": "40343255", "url": "https://en.wikipedia.org/wiki?curid=40343255", "title": "Carl B. Allendoerfer Award", "text": "Carl B. Allendoerfer Award\n\nThe Carl B. Allendoerfer Award is presented annually by the Mathematical Association of America (MAA) for \"expository excellence published in \"Mathematics Magazine\".\" it is named after mathematician Carl B. Allendoerfer who was president of the MAA 1959–60.\n\nRecipients of the Carl B. Allendoerfer Award have included:\n"}
{"id": "10993199", "url": "https://en.wikipedia.org/wiki?curid=10993199", "title": "Cebeci–Smith model", "text": "Cebeci–Smith model\n\nThe Cebeci–Smith model is a 0-equation eddy viscosity model used in computational fluid dynamics analysis of turbulent boundary layer flows. The model gives eddy viscosity, formula_1, as a function of the local boundary layer velocity profile. The model is suitable for high-speed flows with thin attached boundary-layers, typically present in aerospace applications. Like the Baldwin-Lomax model, this model is not suitable for cases with large separated regions and significant curvature/rotation effects. Unlike the Baldwin-Lomax model, this model requires the determination of a boundary layer edge.\n\nThe model was developed by Tuncer Cebeci and Apollo M. O. Smith, in 1967.\n\nIn a two-layer model, the boundary layer is considered to comprise two layers: inner (close to the surface) and outer. The eddy viscosity is calculated separately for each layer and combined using:\n\nwhere formula_3 is the smallest distance from the surface where formula_4 is equal to formula_5.\n\nThe inner-region eddy viscosity is given by:\n\nwhere\n\nwith the von Karman constant formula_8 usually being taken as 0.4, and with\n\nThe eddy viscosity in the outer region is given by:\n\nwhere formula_11, formula_12 is the displacement thickness, given by\n\nand \"F\" is the Klebanoff intermittency function given by\n\n\n"}
{"id": "780886", "url": "https://en.wikipedia.org/wiki?curid=780886", "title": "Characterization (mathematics)", "text": "Characterization (mathematics)\n\nIn mathematics, the statement that \"Property \"P\" characterizes object \"X\"\" means that not only does \"X\" have property \"P\", but that \"X\" is the \"only\" thing that has property \"P\". In other words, \"P\" is a defining property of \"X\". It is also common to find statements such as \"Property \"Q\" characterises \"Y\" up to isomorphism\". The first type of statement says in different words that the extension of \"P\" is a singleton set. The second says that the extension of \"Q\" is a single equivalence class (for isomorphism, in the given example — depending on how \"up to\" is being used, some other equivalence relation might be involved).\n\n\n"}
{"id": "42392462", "url": "https://en.wikipedia.org/wiki?curid=42392462", "title": "Chasles' theorem (kinematics)", "text": "Chasles' theorem (kinematics)\n\nIn kinematics, Chasles' theorem, or Mozzi–Chasles' theorem, says that the most general rigid body displacement can be produced by a translation along a line (called its screw axis or Mozzi axis) followed (or preceded) by a rotation about an axis parallel to that line.\n\nThe proof that a spatial displacement can be decomposed into a rotation and slide around and along a line is attributed to the astronomer and mathematician Giulio Mozzi (1763), in fact the screw axis is traditionally called asse di Mozzi in Italy. However, most textbooks refer to a subsequent similar work by Michel Chasles dating 1830. Several other scholars contemporaries of M. Chasles obtained the same or similar results around that time, including G. Giorgini, Cauchy, Poinsot, Poisson and Rodrigues. An account of the 1763 proof by Giulio Mozzi and some of its history can be found here.\n\nMozzi considers a rigid body undergoing first a rotation about an axis passing through the center of mass and then a translation of displacement D in an arbitrary direction. Any rigid motion can be accomplished in this way due to a theorem by Euler on the existence of an axis of rotation. \nThe displacement D of the center of mass can be decomposed into components parallel and perpendicular to the axis. The perpendicular (and parallel) component acts on all points of the rigid body but Mozzi shows that for some points the previous rotation acted exactly with an opposite displacement, so those points are translated parallel to the axis of rotation. These points lie on the Mozzi axis through which the rigid motion can be accomplished through a screw motion.\n\nAnother elementary proof of Mozzi–Chasles' theorem was given by E. T. Whittaker in 1904. Suppose \"A\" is to be transformed into \"B\". Whittaker suggests that line \"AK\" be selected parallel to the axis of the given rotation, with \"K\" the foot of a perpendicular from \"B\". The appropriate screw displacement is about an axis parallel to \"AK\" such that \"K\" is moved to \"B\". The method corresponds to Euclidean plane isometry where a composition of rotation and translation can be replaced by rotation about an appropriate center. In Whittaker's terms, \"A rotation about any axis is equivalent to a rotation through the same angle about any axis parallel to it, together with a simple translation in a direction perpendicular to the axis.\"\n\n"}
{"id": "39614877", "url": "https://en.wikipedia.org/wiki?curid=39614877", "title": "Chern Prize (ICCM)", "text": "Chern Prize (ICCM)\n\nThe Chern Prize in Mathematics was established in 2001 in honor of Professor Shiing-Shen Chern. The Chern Prize is presented every three years at the International Congress of Chinese Mathematicians to Chinese mathematicians and those of Chinese descent for \"exceptional contributions to mathematical research or to public service activities in support of mathematics\". Winners are selected by a committee of mathematicians to recognize the achievements of mathematicians of Chinese descent. In 2010, a special commemorative event was held in Beijing in addition to the normal award presentation to celebrate the centennial of Professor Chern's birth.\n\n"}
{"id": "1979078", "url": "https://en.wikipedia.org/wiki?curid=1979078", "title": "Color model", "text": "Color model\n\nA color model is an abstract mathematical model describing the way colors can be represented as tuples of numbers, typically as three or four values or color components. When this model is associated with a precise description of how the components are to be interpreted (viewing conditions, etc.), the resulting set of colors is called \"color space.\" This section describes ways in which human color vision can be modeled.\n\nOne can picture this space as a region in three-dimensional Euclidean space if one identifies the \"x\", \"y\", and \"z\" axes with the stimuli for the long-wavelength (\"L\"), medium-wavelength (\"M\"), and short-wavelength (\"S\") light receptors. The origin, (\"S\",\"M\",\"L\") = (0,0,0), corresponds to black. White has no definite position in this diagram; rather it is defined according to the color temperature or white balance as desired or as available from ambient lighting. The human color space is a horse-shoe-shaped cone such as shown here (see also CIE chromaticity diagram below), extending from the origin to, in principle, infinity. In practice, the human color receptors will be saturated or even be damaged at extremely high light intensities, but such behavior is not part of the CIE color space and neither is the changing color perception at low light levels (see: Kruithof curve). \nThe most saturated colors are located at the outer rim of the region, with brighter colors farther removed from the origin. As far as the responses of the receptors in the eye are concerned, there is no such thing as \"brown\" or \"gray\" light. The latter color names refer to orange and white light respectively, with an intensity that is lower than the light from surrounding areas. One can observe this by watching the screen of an overhead projector during a meeting: one sees black lettering on a white background, even though the \"black\" has in fact not become darker than the white screen on which it is projected before the projector was turned on. The \"black\" areas have not actually become darker but appear \"black\" relative to the higher intensity \"white\" projected onto the screen around it. See also color constancy.\n\nThe human tristimulus space has the property that additive mixing of colors corresponds to the adding of vectors in this space. This makes it easy to, for example, describe the possible colors (gamut) that can be constructed from the red, green, and blue primaries in a computer display.\n\nOne of the first mathematically defined color spaces is the CIE XYZ color space (also known as CIE 1931 color space), created by the International Commission on Illumination in 1931. These data were measured for human observers and a 2-degree field of view. In 1964, supplemental data for a 10-degree field of view were published.\n\nNote that the tabulated sensitivity curves have a certain amount of arbitrariness in them. The shapes of the individual X, Y and Z sensitivity curves can be measured with a reasonable accuracy. However, the overall luminosity function (which in fact is a weighted sum of these three curves) is subjective, since it involves asking a test person whether two light sources have the same brightness, even if they are in completely different colors. Along the same lines, the relative magnitudes of the X, Y, and Z curves are arbitrarily chosen to produce equal areas under the curves. One could as well define a valid color space with an X sensitivity curve that has twice the amplitude. This new color space would have a different shape. The sensitivity curves in the CIE 1931 and 1964 xyz color space are scaled to have equal areas under the curves.\n\nSometimes XYZ colors are represented by the luminance, Y, and chromaticity coordinates \"x\" and \"y\", defined by:\n\nMathematically, \"x\" and \"y\" are projective coordinates and the colors of the chromaticity diagram occupy a region of the real projective plane. Because the CIE sensitivity curves have equal areas under the curves, light with a flat energy spectrum corresponds to the point (\"x\",\"y\") = (0.333,0.333).\n\nThe values for \"X\", \"Y\", and \"Z\" are obtained by integrating the product of the spectrum of a light beam and the published color-matching functions.\n\nMedia that transmit light (such as television) use additive color mixing with primary colors of red, green, and blue, each of which stimulates one of the three types of the eye's color receptors with as little stimulation as possible of the other two. This is called \"RGB\" color space. Mixtures of light of these primary colors cover a large part of the human color space and thus produce a large part of human color experiences. This is why color television sets or color computer monitors need only produce mixtures of red, green and blue light. See Additive color.\n\nOther primary colors could in principle be used, but with red, green and blue the largest portion of the human color space can be captured. Unfortunately there is no exact consensus as to what loci in the chromaticity diagram the red, green, and blue colors should have, so the same RGB values can give rise to slightly different colors on different screens.\n\nIt is possible to achieve a large range of colors seen by humans by combining cyan, magenta, and yellow transparent dyes/inks on a white substrate. These are the \"subtractive\" primary colors. Often a fourth ink, black, is added to improve reproduction of some dark colors. This is called the \"CMY\" or \"CMYK\" color space.\n\nThe cyan ink absorbs red light but transmits green and blue, the magenta ink absorbs green light but transmits red and blue, and the yellow ink absorbs blue light but transmits red and green. The white substrate reflects the transmitted light back to the viewer. Because in practice the CMY inks suitable for printing also reflect a little bit of color, making a deep and neutral black impossible, the K (black ink) component, usually printed last, is needed to compensate for their deficiencies. Use of a separate black ink is also economically driven when a lot of black content is expected, e.g. in text media, to reduce simultaneous use of the three colored inks. The dyes used in traditional color photographic prints and slides are much more perfectly transparent, so a K component is normally not needed or used in those media.\nA number of color models exist in which colors are fit into conic, cylindrical or spherical shapes, with neutrals running from black to white in a central axis, and hues corresponding to angles around that axis. Arrangements of this type date back to the 18th century, and continue to be developed in the most modern and scientific models.\n\nDifferent color theorists have each designed unique color solids. Many are in the shape of a sphere, whereas others are warped three-dimensional ellipsoid figures—these variations being designed to express some aspect of the relationship of the colors more clearly. The color spheres conceived by Phillip Otto Runge and Johannes Itten are typical examples and prototypes for many other color solid schematics. The models of Runge and Itten are basically identical, and form the basis for the description below.\n\nPure, saturated hues of equal brightness are located around the equator at the periphery of the color sphere. As in the color wheel, contrasting (or complementary) hues are located opposite each other. Moving toward the center of the color sphere on the equatorial plane, colors become less and less saturated, until all colors meet at the central axis as a neutral gray. Moving vertically in the color sphere, colors become lighter (toward the top) and darker (toward the bottom). At the upper pole, all hues meet in white; at the bottom pole, all hues meet in black. \n\nThe vertical axis of the color sphere, then, is gray all along its length, varying from black at the bottom to white at the top. All pure (saturated) hues are located on the surface of the sphere, varying from light to dark down the color sphere. All impure (unsaturated hues, created by mixing contrasting colors) comprise the sphere's interior, likewise varying in brightness from top to bottom.\n\nHSL and HSV are both cylindrical geometries, with hue, their angular dimension, starting at the red primary at 0°, passing through the green primary at 120° and the blue primary at 240°, and then wrapping back to red at 360°. In each geometry, the central vertical axis comprises the \"neutral\", \"achromatic\", or \"gray\" colors, ranging from black at lightness 0 or value 0, the bottom, to white at lightness 1 or value 1, the top.\n\nMost televisions, computer displays, and projectors produce colors by combining red, green, and blue light in varying intensities—the so-called RGB additive primary colors. However, the relationship between the constituent amounts of red, green, and blue light and the resulting color is unintuitive, especially for inexperienced users, and for users familiar with subtractive color mixing of paints or traditional artists’ models based on tints and shades.\n\nIn an attempt to accommodate more traditional and intuitive color mixing models, computer graphics pioneers at PARC and NYIT developed the HSV model in the mid-1970s, formally described by Alvy Ray Smith in the August 1978 issue of \"Computer Graphics\". In the same issue, Joblove and Greenberg described the HSL model—whose dimensions they labeled \"hue\", \"relative chroma\", and \"intensity\"—and compared it to HSV. Their model was based more upon how colors are organized and conceptualized in human vision in terms of other color-making attributes, such as hue, lightness, and chroma; as well as upon traditional color mixing methods—e.g., in painting—that involve mixing brightly colored pigments with black or white to achieve lighter, darker, or less colorful colors.\n\nThe following year, 1979, at SIGGRAPH, Tektronix introduced graphics terminals using HSL for color designation, and the Computer Graphics Standards Committee recommended it in their annual status report. These models were useful not only because they were more intuitive than raw RGB values, but also because the conversions to and from RGB were extremely fast to compute: they could run in real time on the hardware of the 1970s. Consequently, these models and similar ones have become ubiquitous throughout image editing and graphics software since then.\n\nAnother influential older cylindrical color model is the early-20th-century Munsell color system. Albert Munsell began with a spherical arrangement in his 1905 book \"A Color Notation\", but he wished to properly separate color-making attributes into separate dimensions, which he called \"hue\", \"value\", and \"chroma\", and after taking careful measurements of perceptual responses, he realized that no symmetrical shape would do, so he reorganized his system into a lumpy blob.\n\nMunsell’s system became extremely popular, the de facto reference for American color standards—used not only for specifying the color of paints and crayons, but also, e.g., electrical wire, beer, and soil color—because it was organized based on perceptual measurements, specified colors via an easily learned and systematic triple of numbers, because the color chips sold in the \"Munsell Book of Color\" covered a wide gamut and remained stable over time (rather than fading), and because it was effectively marketed by Munsell’s Company. In the 1940s, the Optical Society of America made extensive measurements, and adjusted the arrangement of Munsell colors, issuing a set of \"renotations\". The trouble with the Munsell system for computer graphics applications is that its colors are not specified via any set of simple equations, but only via its foundational measurements: effectively a lookup table. Converting from requires interpolating between that table’s entries, and is extremely computationally expensive in comparison with converting from or which only requires a few simple arithmetic operations.\n\nIn densitometry, a model quite similar to the hue defined above is used for describing colors of CMYK process inks. In 1953, Frank Preucil developed two geometric arrangements of hue, the \"Preucil hue circle\" and the \"Preucil hue hexagon\", analogous to our \"H\" and \"H\", respectively, but defined relative to idealized cyan, yellow, and magenta ink colors. The \"Preucil \"hue error\"\" of an ink indicates the difference in the \"hue circle\" between its color and the hue of the corresponding idealized ink color. The \"grayness\" of an ink is , where \"m\" and \"M\" are the minimum and maximum among the amounts of idealized cyan, magenta, and yellow in a density measurement.\n\nThe Swedish Natural Color System (NCS), widely used in Europe, takes a similar approach to the Ostwald bicone at right. Because it attempts to fit color into a familiarly shaped solid based on \"phenomenological\" instead of photometric or psychological characteristics, it suffers from some of the same disadvantages as HSL and HSV: in particular, its lightness dimension differs from perceived lightness, because it forces colorful yellow, red, green, and blue into a plane.\n\nThe International Commission on Illumination (CIE) developed the XYZ model for describing the colors of light spectra in 1931, but its goal was to match human visual metamerism, rather than to be perceptually uniform, geometrically. In the 1960s and 70s, attempts were made to transform XYZ colors into a more relevant geometry, influenced by the Munsell system. These efforts culminated in the 1976 CIELUV and CIELAB models. The dimensions of these models— and , respectively—are cartesian, based on the opponent process theory of color, but both are also often described using polar coordinates— and , respectively—where \"L\"* is lightness, \"C\"* is chroma, and \"h\"* is hue angle. Officially, both CIELAB and CIELUV were created for their color difference metrics ∆\"E\"* and ∆\"E\"*, particularly for use defining color tolerances, but both have become widely used as color order systems and color appearance models, including in computer graphics and computer vision. For example, gamut mapping in ICC color management is usually performed in CIELAB space, and Adobe Photoshop includes a CIELAB mode for editing images. CIELAB and CIELUV geometries are much more perceptually relevant than many others such as RGB, HSL, HSV, YUV/YIQ/YCbCr or XYZ, but are not perceptually perfect, and in particular have trouble adapting to unusual lighting conditions.\n\nThe HCL color space seems to be synonymous with CIELCH.\n\nThe CIE’s most recent model, CIECAM02 (CAM stands for \"color appearance model\"), is more theoretically sophisticated and computationally complex than earlier models. Its aims are to fix several of the problems with models such as CIELAB and CIELUV, and to explain not only responses in carefully controlled experimental environments, but also to model the color appearance of real-world scenes. Its dimensions \"J\" (lightness), \"C\" (chroma), and \"h\" (hue) define a polar-coordinate geometry.\n\nThere are various types of color systems that classify color and analyse their effects. The American Munsell color system devised by Albert H. Munsell is a famous classification that organises various colors into a color solid based on hue, saturation and value. Other important color systems include the Swedish Natural Color System (NCS), the Optical Society of America's Uniform Color Space (OSA-UCS), and the Hungarian Coloroid system developed by Antal Nemcsics from the Budapest University of Technology and Economics. Of those, the NCS is based on the opponent-process color model, while the Munsell, the OSA-UCS and the Coloroid attempt to model color uniformity. The American Pantone and the German RAL commercial color-matching systems differ from the previous ones in that their color spaces are not based on an underlying color model.\n\nWe also use \"color model\" to indicate a model or mechanism of color vision for explaining how color signals are processed from visual cones to ganglion cells. For simplicity, we call these models color mechanism models. The classical color mechanism models are Young–Helmholtz's trichromatic model and Hering's opponent-process model. Though these two theories were initially thought to be at odds, it later came to be understood that the mechanisms responsible for color opponency receive signals from the three types of cones and process them at a more complex level.\n\nVertebrate animals were primitively tetrachromatic. They possessed four types of cones—long, mid, short wavelength cones, and ultraviolet sensitive cones. Today, fish, amphibians, reptiles and birds are all tetrachromatic. Placental mammals lost both the mid and short wavelength cones. Thus, most mammals do not have complex color vision—they are dichromatic but they are sensitive to ultraviolet light, though they cannot see its colors. Human trichromatic color vision is a recent evolutionary novelty that first evolved in the common ancestor of the Old World Primates. Our trichromatic color vision evolved by duplication of the long wavelength sensitive opsin, found on the X chromosome. One of these copies evolved to be sensitive to green light and constitutes our mid wavelength opsin. At the same time, our short wavelength opsin evolved from the ultraviolet opsin of our vertebrate and mammalian ancestors.\n\nHuman red-green color blindness occurs because the two copies of the red and green opsin genes remain in close proximity on the X chromosome. Because of frequent recombination during meiosis, these gene pairs can get easily rearranged, creating versions of the genes that do not have distinct spectral sensitivities.\n\n\n\n"}
{"id": "6626644", "url": "https://en.wikipedia.org/wiki?curid=6626644", "title": "Comparison theorem", "text": "Comparison theorem\n\nA comparison theorem is any of a variety of theorems that compare properties of various mathematical objects.\n\nIn the theory of differential equations, comparison theorems assert particular properties of solutions of a differential equation (or of a system thereof) provided that an auxiliary equation/inequality (or a system thereof) possesses a certain property. See also Lyapunov comparison principle\n\n\nIn Riemannian geometry it is a traditional name for a number of theorems that compare various metrics and provide various estimates in Riemannian geometry. \n\n\n"}
{"id": "45715624", "url": "https://en.wikipedia.org/wiki?curid=45715624", "title": "Compound of octahedra", "text": "Compound of octahedra\n\nA compound of octahedra may be:\n"}
{"id": "488133", "url": "https://en.wikipedia.org/wiki?curid=488133", "title": "Correspondence (mathematics)", "text": "Correspondence (mathematics)\n\nIn mathematics and mathematical economics, correspondence is a term with several related but distinct meanings.\n\n\n\n"}
{"id": "42074131", "url": "https://en.wikipedia.org/wiki?curid=42074131", "title": "Derived stack", "text": "Derived stack\n\nIn algebraic geometry, a derived stack is, roughly, a stack together with a sheaf of commutative ring spectra. It generalizes a derived scheme. Derived stacks are the \"spaces\" studied in derived algebraic geometry.\n\n"}
{"id": "5708669", "url": "https://en.wikipedia.org/wiki?curid=5708669", "title": "Dowker notation", "text": "Dowker notation\n\nIn the mathematical field of knot theory, the Dowker notation, also called the Dowker–Thistlethwaite notation or code, for a knot is a sequence of even integers. The notation is named after Clifford Hugh Dowker and Morwen Thistlethwaite, who refined a notation originally due to Peter Guthrie Tait. \n\nTo generate the Dowker notation, traverse the knot using an arbitrary starting point and direction. Label each of the n crossings with the numbers 1, ..., 2\"n\" in order of traversal (each crossing is visited and labelled twice), with the following modification: if the label is an even number and the strand followed crosses over at the crossing, then change the sign on the label to be a negative. When finished, each crossing will be labelled a pair of integers, one even and one odd. The Dowker notation is the sequence of even integer labels associated with the labels 1, 3, ..., 2\"n\" − 1 in turn.\n\nFor example, a knot diagram may have crossings labelled with the pairs (1, 6) (3, −12) (5, 2) (7, 8) (9, −4) and (11, −10). The Dowker notation for this labelling is the sequence: 6 −12 2 8 −4 −10.\n\nA knot can be recovered from a Dowker sequence, but the recovered knot may differ from the original by being a reflection or (more generally) by having any connected sum component reflected in the line between its entry/exit points – the Dowker notation is unchanged by these reflections. Knots tabulations typically consider only prime knots and disregard chirality, so this ambiguity does not affect the tabulation.\n\nThe ménage problem, posed by Tait, concerns counting the number of different number sequences possible in this notation.\n\n\n"}
{"id": "22697171", "url": "https://en.wikipedia.org/wiki?curid=22697171", "title": "Georg Cantor's first set theory article", "text": "Georg Cantor's first set theory article\n\nGeorg Cantor published his first set theory article in 1874, and it contains the first theorems of transfinite set theory, which studies infinite sets and their properties. One of these theorems is \"Cantor's revolutionary discovery\" that the set of all real numbers is uncountably, rather than countably, infinite. This theorem is proved using Cantor's first uncountability proof, which differs from the more familiar proof using his diagonal argument. The title of the article, \"On a Property of the Collection of All Real Algebraic Numbers\" (\"Ueber eine Eigenschaft des Inbegriffes aller reellen algebraischen Zahlen\"), refers to its first theorem: the set of real algebraic numbers is countable. In 1879, Cantor modified his uncountability proof by using the topological notion of a set being dense in an interval.\n\nCantor's 1874 article also contains a proof of the existence of transcendental numbers. As early as 1930, mathematicians have disagreed on whether this proof is constructive or non-constructive. Books as recent as 2014 and 2015 indicate that this disagreement has not been resolved. Since Cantor's proof either constructs transcendental numbers or does not, an analysis of his article can determine whether his proof is constructive or non-constructive. Cantor's correspondence with Richard Dedekind shows the development of his ideas and reveals that he had a choice between two proofs, one that uses the uncountability of the real numbers and one that does not.\n\nHistorians of mathematics have examined Cantor's article and the circumstances in which it was written. For example, they have discovered that Cantor was advised to leave out his uncountability theorem in the article he submitted; he added it during proofreading. They have traced this and other facts about the article to the influence of Karl Weierstrass and Leopold Kronecker. Historians have also studied Dedekind's contributions to the article, including his contributions to the theorem on the countability of the real algebraic numbers. In addition, they have looked at the article's legacy, which includes the impact that the uncountability theorem and the concept of countability have had on mathematics.\n\nCantor's article is short, less than four and a half pages. It begins with a discussion of the real algebraic numbers and a statement of his first theorem: The set of real algebraic numbers can be put into one-to-one correspondence with the set of positive integers. Cantor restates this theorem in terms more familiar to mathematicians of his time: The set of real algebraic numbers can be written as an infinite sequence in which each number appears only once.\n\nCantor's second theorem works with a closed interval [\"a\", \"b\"], which is the set of real numbers ≥ \"a\" and ≤ \"b\". The theorem states: Given any sequence of real numbers \"x\", \"x\", \"x\", … and any interval [\"a\", \"b\"], there is a number in [\"a\", \"b\"] that is not contained in the given sequence. Hence, there are infinitely many such numbers.\n\nThe first part of this theorem implies the \"Hence\" part. For example, let [0, 1] be the interval, and consider its pairwise disjoint subintervals …. Applying the first part of the theorem to each subinterval produces infinitely many numbers in [0, 1] that are not contained in the given sequence.\n\nCantor observes that combining his two theorems yields a new proof of Liouville's theorem that every interval [\"a\", \"b\"] contains infinitely many transcendental numbers.\n\nCantor then remarks that his second theorem is:\nThis remark contains Cantor's uncountability theorem, which only states that an interval [\"a\", \"b\"] cannot be put into one-to-one correspondence with the set of positive integers. It does not state that this interval is an infinite set of larger cardinality than the set of positive integers. Cardinality is defined in Cantor's next article, which was published in 1878.\n\nCantor only states his uncountability theorem. He does not use it in any proofs.\n\nTo prove that the set of real algebraic numbers is countable, define the \"height\" of a polynomial of degree \"n\" with integer coefficients as: \"n\" − 1 + |\"a\"| + |\"a\"| + … + |\"a\"|, where \"a\", \"a\", …, \"a\" are the coefficients of the polynomial. Order the polynomials by their height, and order the real roots of polynomials of the same height by numeric order. Since there are only a finite number of roots of polynomials of a given height, these orderings put the real algebraic numbers into a sequence. Cantor went a step further and produced a sequence in which each real algebraic number appears just once. He did this by only using polynomials that are irreducible over the integers. The table below contains the beginning of Cantor's enumeration.\n\nOnly the first part of Cantor's second theorem needs to be proved. It states: Given any sequence of real numbers \"x\", \"x\", \"x\", … and any interval [\"a\", \"b\"], there is a number in [\"a\", \"b\"] that is not contained in the given sequence. We simplify Cantor's proof by using open intervals. The open interval (\"a\", \"b\") is the set of real numbers greater than \"a\" and less than \"b\".\n\nTo find a number in [\"a\", \"b\"] that is not contained in the given sequence, construct two sequences of real numbers as follows: Find the first two numbers of the given sequence that are in (\"a\", \"b\"). Denote the smaller of these two numbers by \"a\" and the larger by \"b\". Similarly, find the first two numbers of the given sequence that are in (\"a\", \"b\"). Denote the smaller by \"a\" and the larger by \"b\". Continuing this procedure generates a sequence of intervals (\"a\", \"b\"), (\"a\", \"b\"), (\"a\", \"b\"), … such that each interval in the sequence contains all succeeding intervals—that is, it generates a sequence of nested intervals. This implies that the sequence \"a\", \"a\", \"a\", … is increasing and the sequence \"b\", \"b\", \"b\", … is decreasing.\n\nEither the number of intervals generated is finite or infinite. If finite, let (\"a\", \"b\") be the last interval. If infinite, take the limits \"a\" = lim \"a\" and \"b\" = lim \"b\". Since \"a\" < \"b\" for all \"n\", either \"a\" = \"b\" or \"a\" < \"b\". Thus, there are three cases to consider:\n\nThe proof is complete since, in all cases, at least one real number in [\"a\", \"b\"] has been found that is not contained in the given sequence.\n\nCantor's proofs are constructive and have been used to write a computer program that generates the digits of a transcendental number. This program applies Cantor's construction to a sequence containing all the real algebraic numbers between 0 and 1. The article that discusses this program gives some of its output, which shows how the construction generates a transcendental.\n\nAn example illustrates how Cantor's construction works. Consider the sequence: , , , , , , , , , … This sequence is obtained by ordering the rational numbers in (0, 1) by increasing denominators, ordering those with the same denominator by increasing numerators, and omitting reducible fractions. The table below shows the first five steps of the construction. The table's first column contains the intervals (\"a\", \"b\"). The second column lists the terms visited during the search for the first two terms in (\"a\", \"b\"). These two terms are in red.\n\nSince the sequence contains all the rational numbers in (0, 1), the construction generates an irrational number, which turns out to be  − 1.\n\nIn 1879, Cantor published a new uncountability proof that modifies his 1874 proof. He first defines the topological notion of a point set \"P\" being \"everywhere dense in an interval\" (which is quite often shortened to \"dense in an interval\"):\n\nWe will use \"a\", \"b\", \"c\", \"d\" rather than α, β, γ, δ. Cantor assumes that an interval [\"c\", \"d\"] satisfies \"d\" > \"c\".\n\nSince our discussion of Cantor's 1874 proof was simplified using by open intervals rather than closed intervals, the same simplification is used here. This requires an equivalent definition of everywhere dense: A set \"P\" is everywhere dense in the interval [\"a\", \"b\"] if and only if every subinterval (\"c\", \"d\") of [\"a\", \"b\"] contains at least one point of \"P\".\n\nCantor did not specify how many points of \"P\" a subinterval (\"c\", \"d\") must contain. He did not need to specify this because assuming that every subinterval contains at least one point of \"P\" implies that they contain infinitely many points of \"P\". This is proved by generating a sequence of points belonging to both \"P\" and (\"c\", \"d\"). Since \"P\" is dense in [\"a\", \"b\"], the subinterval (\"c\", \"d\") contains at least one point \"x\" of \"P\". Now consider the subinterval (\"x\", \"d\"). It contains at least one point \"x\" of \"P\", which satisfies \"x\" > x. In general, after generating \"x\", the subinterval (x, \"d\") is used to obtain the point \"x\", which satisfies \"x\" > \"x\". The points \"x\" are all unique and belong to both \"P\" and (\"c\", \"d\").\n\nCantor's 1879 proof is the same as his 1874 proof except for a new proof of first part of his second theorem: Given any sequence \"P\" of real numbers \"x\", \"x\", \"x\", … and any interval [\"a\", \"b\"], there is a number in [\"a\", \"b\"] that is not contained in the sequence \"P\". The new proof has only two cases.\n\nIn the first case, \"P\" is not dense in [\"a\", \"b\"]. By definition, \"P\" is dense if and only if for all , there is an \"x\" ∈ \"P\" such that . Taking the negation of each side of the \"if and only if\" produces: \"P\" is not dense in [\"a\", \"b\"] if and only if there exists a such that for all \"x\" ∈ \"P\", we have . Thus, every number in (\"c\", \"d\") is not contained in the sequence \"P\". This case handles cases 1 and 3 of Cantor's 1874 proof.\n\nIn the second case, \"P\" is dense in [\"a\", \"b\"]. The denseness of \"P\" is used to recursively define a nested sequence of intervals that excludes all elements of \"P\". The definition begins with\n\"a\" = \"a\" and \"b\" = \"b\". The definition's inductive case starts with the interval (\"a\", \"b\"), which because of the denseness of \"P\" contains infinitely many elements of \"P\". From these elements of \"P\", we take the two with smallest indices and denote the least of these two numbers by \"a\" and the greatest by \"b\".\nCantor proved that for all \"n\": . We proved this in a previous section.\n\nThe sequence \"a\" is increasing and bounded above by \"b\", so it has a limit \"A\", which satisfies \"a\" < \"A\". The sequence \"b\" is decreasing and bounded below by \"a\", so it has a limit \"B\", which satisfies \"B\" < \"b\". Also, \"a\" < \"b\" implies \"A\" ≤ \"B\". Therefore, . If \"A\" < \"B\", then for every \"n\": \"x\" ∉ (\"A\", \"B\") because \"x\" is not in the larger interval (\"a\", \"b\"). This contradicts \"P\" being dense in [\"a\", \"b\"]. Therefore, \"A\" = \"B\". Since for all \"n\": but , the limit \"A\" is a real number that is not contained in the sequence \"P\". This case handles case 2 of Cantor's 1874 proof.\n\nCantor's new proof first takes care of the easy case of the sequence \"P\" not being dense in the interval. Then it deals with the more difficult case of \"P\" being dense. This division into cases not only indicates which sequences are most difficult to handle, but it also reveals the important role denseness plays in the proof.\n\nIn the Example of Cantor's construction, each successive nested interval excludes rational numbers for two different reasons. It will exclude the finitely many rationals visited in the search for the first two rationals within the interval (these two rationals will have the least indices). These rationals are then used to form an interval that excludes the rationals visited in the search along with infinitely many more rationals. However, it still contains infinitely many rationals since our sequence of rationals is dense in [0, 1]. Forming this interval from the two rationals with the least indices guarantees that this interval excludes an initial segment of our sequence that contains at least two more elements than the preceding initial segment. Since the denseness of our sequence guarantees that this process never ends, all rationals will be excluded. Because of the ordering of the rationals in our sequence, the intersection of the nested intervals is the set  − 1}.\n\nThe development leading to Cantor's 1874 article appears in the correspondence between Cantor and Richard Dedekind. On November 29, 1873, Cantor asked Dedekind whether the collection of positive integers and the collection of positive real numbers \"can be corresponded so that each individual of one collection corresponds to one and only one individual of the other?\" Cantor added that collections having such a correspondence include the collection of positive rational numbers, and collections of the form (\"a\") where \"n\", \"n\", . . . , \"n\", and \"ν\" are positive integers.\n\nDedekind replied that he was unable to answer Cantor's question, and said that it \"did not deserve too much effort because it has no particular practical interest.\" Dedekind also sent Cantor a proof that the set of algebraic numbers is countable.\nOn December 2, Cantor responded that his question does have interest: \"It would be nice if it could be answered; for example, provided that it could be answered \"no\", one would have a new proof of Liouville's theorem that there are transcendental numbers.\"\n\nOn December 7, Cantor sent Dedekind a proof by contradiction that the set of real numbers is uncountable. Cantor starts by assuming the real numbers can be written as a sequence. Then he applies a construction to this sequence to produce a real number not in the sequence, thus contradicting his assumption. The letters of December 2 and 7 lead to a non-constructive proof of the existence of transcendental numbers.\n\nOn December 9, Cantor announced the theorem that allowed him to construct transcendental numbers as well as prove the uncountability of the set of real numbers:\n\nThis is the second theorem in Cantor's article. It comes from realizing that his construction can be applied to any sequence, not just to sequences that supposedly enumerate the real numbers. So Cantor had a choice between two proofs that demonstrate the existence of transcendental numbers: one proof is constructive, but the other is not. We now compare the proofs assuming that we have a sequence consisting of all the real algebraic numbers.\n\nThe constructive proof applies Cantor's construction to this sequence and the interval [\"a\", \"b\"] to produce a transcendental number in this interval.\n\nThe non-constructive proof uses two proofs by contradiction:\n\nCantor chose to publish the constructive proof, which not only produces a transcendental number but is also shorter and avoids two proofs by contradiction. The non-constructive proof from Cantor's correspondence is simpler than the one above because it works with all the real numbers rather than the interval [\"a\", \"b\"]. This eliminates the subsequence step and all occurrences of [\"a\", \"b\"] in the second proof by contradiction.\n\nThe correspondence containing Cantor's non-constructive reasoning was published in 1937. By then, other mathematicians had rediscovered its non-constructive proof. As early as 1921, this proof was attributed to Cantor and criticized for not producing any transcendental numbers. In that year, Oskar Perron stated: \"… Cantor's proof for the existence of transcendental numbers has, along with its simplicity and elegance, the great disadvantage that it is only an existence proof; it does not enable us to actually specify even a single transcendental number.\"\nSome mathematicians have attempted to correct this misunderstanding of Cantor's work. In 1930, the set theorist Abraham Fraenkel stated that Cantor's method is \"… a method that incidentally, contrary to a widespread interpretation, is fundamentally constructive and not merely existential.\" In 1972, Irving Kaplansky wrote: \"It is often said that Cantor's proof is not 'constructive,' and so does not yield a tangible transcendental number. This remark is not justified. If we set up a definite listing of all algebraic numbers … and then apply the diagonal procedure …, we get a perfectly definite transcendental number (it could be computed to any number of decimal places).\"\n\nThe disagreement about Cantor's proof occurs because two groups of mathematicians are talking about different proofs: the constructive one that Cantor published and the non-constructive one that was later rediscovered. The opinion that Cantor's proof is non-constructive appears in some books that were quite successful as measured by the length of time new editions or reprints appeared—for example: Eric Temple Bell's \"Men of Mathematics\" (1937; still being reprinted), Godfrey Hardy and E. M. Wright's \"An Introduction to the Theory of Numbers\" (1938; 2008 6th edition), Garrett Birkhoff and Saunders Mac Lane's \"A Survey of Modern Algebra\" (1941; 1997 5th edition), and Michael Spivak's \"Calculus\" (1967; 2008 4th edition). Since these books view Cantor's proof as non-constructive, they do not mention his constructive proof. On the other hand, the quotations above from Fraenkel and Kaplansky show that they knew Cantor's work can be used non-constructively. The disagreement about Cantor's proof shows no sign of being resolved: since 2014, at least two books have appeared stating that Cantor's proof is constructive, and at least four have appeared stating that his proof does not construct any (or a single) transcendental.\n\nAsserting that Cantor gave a non-constructive proof can lead to erroneous statements about the history of mathematics. In \"A Survey of Modern Algebra,\" Birkhoff and Mac Lane state: \"Cantor's argument for this result [Not every real number is algebraic] was at first rejected by many mathematicians, since it did not exhibit any specific transcendental number.\" Birkhoff and Mac Lane are talking about the non-constructive proof. Cantor's proof produces transcendental numbers, and there appears to be no evidence that his argument was rejected. Even Leopold Kronecker, who had strict views on what is acceptable in mathematics and who could have delayed publication of Cantor's article, did not delay it. In fact, applying Cantor's construction to the sequence of real algebraic numbers produces a limiting process that Kronecker accepted—namely, it determines a number to any required degree of accuracy.\n\nHistorians of mathematics have discovered the following facts about Cantor's article \"On a Property of the Collection of All Real Algebraic Numbers\":\n\n\nTo explain these facts, historians have pointed to the influence of Cantor's former professors, Karl Weierstrass and Leopold Kronecker. Cantor discussed his results with Weierstrass on December 23, 1873. Weierstrass was first amazed by the concept of countability, but then found the countability of the set of real algebraic numbers useful. Cantor did not want to publish yet, but Weierstrass felt that he must publish at least his results concerning the algebraic numbers.\n\nFrom his correspondence, it appears that Cantor only discussed his article with Weierstrass. However, Cantor told Dedekind: \"The restriction which I have imposed on the published version of my investigations is caused in part by local circumstances …\" Cantor biographer Joseph Dauben believes that \"local circumstances\" refers to Kronecker who, as a member of the editorial board of \"Crelle's Journal\", had delayed publication of an 1870 article by Eduard Heine, one of Cantor's colleagues. Cantor would submit his article to \"Crelle's Journal\".\n\nWeierstrass advised Cantor to leave his uncountability theorem out of the article he submitted, but Weierstrass also told Cantor that he could add it as a marginal note during proofreading, which he did. It appears in a remark at the end of the article's introduction. The opinions of Kronecker and Weierstrass both played a role here. Kronecker did not accept infinite sets, and it seems that Weierstrass did not accept that two infinite sets could be so different, with one being countable and the other not. Weierstrass changed his opinion later. Without the uncountability theorem, the article needed a title that did not refer to this theorem. Cantor chose \"Ueber eine Eigenschaft des Inbegriffes aller reellen algebraischen Zahlen\" (\"On a Property of the Collection of All Real Algebraic Numbers\"), which refers to the countability of the set of real algebraic numbers, the result that Weierstrass found useful.\n\nKronecker's influence appears in the proof of Cantor's second theorem. Cantor used Dedekind's version of the proof except he left out why the limits \"a\" = lim \"a\" and \n\"b\" = lim \"b\" exist. Dedekind had used his \"principle of continuity\" to prove they exist. This principle (which is equivalent to the least upper bound property of the real numbers) comes from Dedekind's construction of the real numbers, a construction Kronecker did not accept.\n\nCantor restricted his first theorem to the set of real algebraic numbers even though Dedekind had sent him a proof that handled all algebraic numbers. Cantor did this for expository reasons and because of \"local circumstances.\" This restriction simplifies the article because the second theorem works with real sequences. Hence, the construction in the second theorem can be applied directly to the enumeration of the real algebraic numbers to produce \"an effective procedure for the calculation of transcendental numbers.\" This procedure would be acceptable to Weierstrass.\n\nSince 1856, Dedekind had developed theories involving infinitely many infinite sets—for example: ideals, which he used in algebraic number theory, and Dedekind cuts, which he used to construct the real numbers. This work enabled him to understand and contribute to Cantor's work.\n\nDedekind's first contribution concerns the theorem that the set of real algebraic numbers is countable. Cantor is usually given credit for this theorem, but the mathematical historian José Ferreirós calls it \"Dedekind's theorem.\" Their correspondence reveals what each mathematician contributed to the theorem.\n\nIn his letter introducing the concept of countability, Cantor stated without proof that the set of positive rational numbers is countable, as are sets of the form (\"a\") where \"n\", \"n\", …, \"n, and \"ν\" are positive integers. Cantor's second result uses indexed numbers: a set of the form (\"a\") is the range of a function from the \"ν\" indices to the set of real numbers. His second result implies his first: let \"ν\" = 2 and \"a\" = . The function can be quite general—for example, \"a\" = (where R is the set of real numbers) and the set of irrational numbers have the same cardinality as R.\n\nIn 1883, Cantor extended the natural numbers with his infinite ordinals. This extension was necessary for his work on the Cantor–Bendixson theorem. Cantor discovered other uses for the ordinals—for example, he used sets of ordinals to produce an infinity of sets having different infinite cardinalities. His work on infinite sets together with Dedekind's set-theoretical work created set theory.\n\nThe concept of countability led to countable operations and objects that are used in various areas of mathematics. For example, in 1878, Cantor introduced countable unions of sets. In the 1890s, Émile Borel used countable unions in his theory of measure, and René Baire used countable ordinals to define his classes of functions. Building on the work of Borel and Baire, Henri Lebesgue created his theories of measure and integration, which were published from 1899 to 1901.\n\nCountable models are used in set theory. In 1922, Thoralf Skolem proved that if conventional axioms of set theory are consistent, then they have a countable model. Since this model is countable, its set of real numbers is countable. This consequence is called Skolem's paradox, and Skolem explained why it does not contradict Cantor's uncountability theorem: although there is a one-to-one correspondence between this set and the set of positive integers, no such one-to-one correspondence is a member of the model. Thus the model considers its set of real numbers to be uncountable, or more precisely, the first-order sentence that says the set of real numbers is uncountable is true within the model. In 1963, Paul Cohen used countable models to prove his independence theorems.\n\n\n"}
{"id": "23270711", "url": "https://en.wikipedia.org/wiki?curid=23270711", "title": "George Szekeres Medal", "text": "George Szekeres Medal\n\nThe George Szekeres Medal is awarded by the Australian Mathematical Society for outstanding research contributions over a fifteen-year period. This award, established in 2001, is given biennially in even-numbered years for work that has been carried out primarily in Australia.\n\nThis medal commemorates the work of the late George Szekeres, FAA, for his achievements in number theory, combinatorics, analysis, and relativity.\n"}
{"id": "43131303", "url": "https://en.wikipedia.org/wiki?curid=43131303", "title": "Historical dynamics", "text": "Historical dynamics\n\nHistorical dynamics broadly includes the scientific modeling of history. This might also be termed computer modeling of history, historical simulation, or simulation of history - allowing for an extensive range of techniques in simulation and estimation. Historical dynamics does not exist as a separate science, but there are individual efforts such as long range planning, population modeling, economic forecasting, demographics, global modeling, country modeling, regional planning, urban planning and many others in the general categories of computer modeling, planning, forecasting, and simulations.\n\nSome examples of \"large\" history where historical dynamics simulations would be helpful include; global history, large structures, , long duration history, philosophy of history, Eurasian history, comparative history, long-range environmental history, world systems theory, non-Western political and economic development, and historical demography.\nWith the rise of technologies like wikis, and internet-wide search engines, some historical and social data can be mined to constrain models of history and society. Data from social media sites, and busy sites, can be mined for human patterns of action. These can provide more and more realistic behavioral models for individuals and groups of any size. Agent-based models and microsimulations of human behavior can be embedded in larger historical simulations. Related subfields are behavioral economics and human behavioral ecology.\n\nIn every sector of human activity, there are extensive databases for transportation data, urban development, health statistics, education data, social data, economic data—along with many projections. See , , , and .\n\nSome examples of database activity include Asian Development Bank statistics, World Bank data, and the International Monetary Fund data.\n\nTime series analysis and econometrics are well established fields for the analysis of trends and forecasting; but, survey data and microdatasets can also be used in forecasts and simulations.\n\nThe United Nations and other organizations routinely project the population of individual countries and regions of the world decades into the future. These demographic models are used by other organizations for projecting demand for services in all sectors of each economy.\n\n\nEach country often has their corresponding modeling groups for each of these major sectors. These can be grouped in separate articles according to sector. Groups include government departments, international aid agencies, as well as nonprofit and non-governmental organizations.\n\nA broad class of models used for economic and social modeling of countries and sectors are the Computable general equilibrium (CGE) model - also called applied general equilibrium models. In the context of time based simulations and policy analysis, see dynamic stochastic general equilibrium models.\n\nPartly because of the controversy over global climate change, there is an extensive network of global climate models, and related social and economic models. These seek to estimate, not only the change in climate and its physical effects, but also the impact on human society and the natural environment. See global economic models, social model, microsimulation, climate model, global climate models, and general circulation model.\n\nThe relationship between the environment and society is examined through environmental social science. human ecology, political ecology, and ecology, in general, can be areas where computer and mathematical modeling over time can be relevant to historical simulation.\n\nWeb-based historical simulations, simulations of history, interactive historical simulations, are increasingly popular for entertainment and educational purposes. The field is expanding rapidly and no central index seems to be available. Another example is \n\nSeveral computer games allow players to interact with the game to model societies over time. The Civilization (series) is one example. Others include Age of Empires, Rise of Nations, Spore, Colonization, Alpha Centauri, Call to Power, and . A longer list of games in historical context, which might include degrees of simulation, are found at .\n\nMilitary simulation is a well-developed field and increasingly accessible on the internet.\n\nComputer models for simulating society fall under artificial society, social simulation, computational sociology, computational social science, and mathematical sociology. There is an interdisciplinary Journal of Artificial Societies and Social Simulation for computer simulation of social processes. The European Social Simulation Association promotes social simulation research in Europe; it is the publisher of JASSS. There is a corresponding Computational Social Science Society of the Americas., and a Pan-Asian Association for Agent-based Approach in Social Systems Sciences. PAAA lists some related Japanese associations.\n\nThe SimSoc (Simulated Society tool) is in its fifth edition.\n\nThere has been extensive research in urban planning, environmental planning and related fields: regional planning, land-use planning, transportation planning, urban studies, and regional science. Journals for these fields are listed at List of planning journals.\n\nSimCity is a game for simulations of artificial cities. It has spawned a range of \"sim\" games. The planning groups try to simulate changes in real cities. The game groups allow experiments with artificial cities. And the two are merging in such efforts as Vizicities\n\nThe profiling of industries is well developed, and most industries make forecasts and plans. See industrial history, history of steel, history of mining, history of construction, history of the petroleum industry, and many other histories of specific industries. See cyclical industrial dynamics for modeling of industries in the sense of \"historical dynamics of industries\". Some related terms are industrial planning, history of industry, industrial evolution, technology change, and technology forecasting. An example of \"history friendly\" industrial models. from the journal, Industrial and Corporate Change.\n\nEconomy-wide models must take into account the interactions between industry and the rest of the economy. See Input–output model, economic planning, and social accounting matrix for some relevant techniques.\n\nMany of the techniques from futures studies are applicable to historical dynamics. Whether projecting forward from a point in the past to the present for validation studies, or projecting backwards from the present into the past - many of the techniques are useful. Likewise, simulations of the past, or alternative pasts, provide a groundwork of techniques for futures studies.\n\n"}
{"id": "15682063", "url": "https://en.wikipedia.org/wiki?curid=15682063", "title": "Homological dimension", "text": "Homological dimension\n\nHomological dimension may refer to the global dimension of a ring. It may also refer to any other concept of dimension that is defined in terms of homological algebra, which includes:\n"}
{"id": "192123", "url": "https://en.wikipedia.org/wiki?curid=192123", "title": "Index of accounting articles", "text": "Index of accounting articles\n\nThis page is an index of accounting topics.\n\nAccounting ethics - Accounting information system - Accounting research - Activity-Based Costing - Assets\n\nBalance sheet\n- Big Four auditors\n- Bond\n- Bookkeeping\n- Book value\n\nCash-basis accounting\n- Cash-basis versus accrual-basis accounting\n- Cash flow statement\n- Certified General Accountant\n- Certified Management Accountants\n- Certified Public Accountant\n- Chartered accountant\n- Chart of accounts\n- Common stock\n- Comprehensive income\n- Construction accounting\n- Convention of conservatism\n- Convention of disclosure\n- Cost accounting\n- Cost of capital\n- Cost of goods sold\n- Creative accounting\n- Credit\n- Credit note\n- Current asset\n- Current liability\n\nDebitcapital reserve\n- Debit note\n- Debt\n- Deficit (disambiguation)\n- Depreciation\n- Diluted earnings per share\n- Dividend\n- Double-entry bookkeeping system\n- Dual aspect\n\nE-accounting\n- EBIT\n- EBITDA\n- Earnings per share\n- Engagement Letter\n- Entity concept\n- Environmental accounting\n- Expense\n- Equity\n- Equivalent Annual Cost\n\nFinancial Accounting Standards Board\n- Financial accountancy\n- Financial audit\n- Financial reports\n- Financial statements\n- Fixed assets\n- Fixed assets management\n- Forensic accounting\n- Fraud deterrence\n- Free cash flow\n- Fund accounting\n\nGain\n- General ledger\n- Generally Accepted Accounting Principles\n- Going concern\n- Goodwill\n- Governmental Accounting Standards Board\n\nHistorical cost - History of accounting\n\nIncome\n- Income statement\n- Institute of Chartered Accountants in England and Wales\n- Institute of Chartered Accountants of Scotland\n- Institute of Management Accountants\n- Intangible asset\n- Interest\n- Internal audit\n- International Accounting Standards Board\n- International Accounting Standards Committee\n- International Accounting Standards\n- International Federation of Accountants\n- International Financial Reporting Standards\n- Inventory\n- Investment\n- Invoices\n- Indian Accounting Standards\n\nJob costing\n- Journal\n\nLean accounting\n- Ledger\n- Liability\n- Long-term asset\n- Long-term liabilities\n- Loss on sale of residential property\n\nMaker-checker\n- Management accounting\n- Management Assertions\n- Mark-to-market accounting\n- Matching principle\n- Materiality\n- Money measurement concept\n- Mortgage loan\n\nNegative assurance\n- Net income\n- Notes to the Financial Statements\n\nOBERAC\n- Online Accounting\n- Operating expense\n- Ownership equity\n\nPayroll\n- Petty cash\n- Philosophy of Accounting\n- Preferred stock\n- P/E ratio\n- Positive accounting\n- Positive assurance\n- PricewaterhouseCoopers\n- Profit and loss account\n- Pro-forma amount\n- Production accounting\n- Project accounting\n\nRetained earnings\n- Revenue\n- Revenue recognition\n\nSecurity\n- Sales journal\n- Social accounting\n- Spreadsheet\n- Statement of changes in equity\n- Statutory accounting principles\n- Stock option\n- Stock split\n- Stock\n- Shareholder\n- Shareholders' equity\n- South African Institute of Chartered Accountants\n- Sunk cost\n- Society of Accounting Education\n\nThroughput accounting\n- Trade credit\n- Treasury stock\n- Trial balance\n\nUK generally accepted accounting principles\n- Unified Ledger Accounting\n- U.S. Securities and Exchange Commission\n- US generally accepted accounting principles\n- Work sheet\n- Write off\n\n"}
{"id": "14230769", "url": "https://en.wikipedia.org/wiki?curid=14230769", "title": "Integraph", "text": "Integraph\n\nAn Integraph is a mechanical analog computing device for plotting the integral of a graphically defined function.\n\nIt was invented independently about 1880 by the British physicist Sir Charles Vernon Boys and by Bruno Abdank-Abakanowicz, a Polish-Lithuanian mathematician/electrical engineer from the Russian Empire. Abakanowicz's design was constructed by Coradi of Zurich.\n\nThe input to the integraph is a tracing point that is moved to trace the input curve. The output is defined by the path a disk that rolls along the paper without slipping. The mechanism sets the angle of the output disk based on the position of the input curve: if the input is zero, the disk is angled to roll straight, parallel to the x axis on the Cartesian plane. If the input is above zero the disk is angled slightly toward the positive y direction, such that the y value of its position increases as it rolls in that direction. If the input is below zero, the disk is angled the other way such that its y position decreases as it rolls.\n\nThe hardware consists of a rectangular carriage which moves left to right on rollers. Two sides of the carriage run parallel to the x axis. The other two sides are parallel to the y axis. Along the trailing vertical (y axis) rail slides a smaller carriage holding a tracing point. Along the leading vertical rail slides a second smaller carriage to which is affixed a small, sharp disc, which rests and rolls (but does not slide) on the graphing paper. The trailing carriage is connected both with a point in the center of the carriage and the disc on the leading rail by a system of sliding crossheads and wires, such that the tracing point must follow the disc's tangential path.\n\nThe integraph plots (traces) the \"integral curve\"\nwhen we are given the \"differential curve\",\n\nThe mathematical basis of the mechanism depends on the following considerations: For any point of the differential curve, construct the auxiliary triangle with vertices and . The hypotenuse of this right triangle intersects the -axis making an angle the value of whose tangent is . This hypotenuse is parallel to the tangent line of the integral curve at that corresponds to . \n\nThe integraph may be used to obtain a quadrature of the circle. If the differential curve is the unit circle, the integral curve intersects the lines at points that are equally spaced at a distance of /2.\n\n\nGauthier-Villars, 1886 available at Google Books\n"}
{"id": "239290", "url": "https://en.wikipedia.org/wiki?curid=239290", "title": "John Wallis", "text": "John Wallis\n\nJohn Wallis (; 3 December 1616 – 8 November 1703) was an English clergyman and mathematician who is given partial credit for the development of infinitesimal calculus. Between 1643 and 1689 he served as chief cryptographer for Parliament and, later, the royal court. He is credited with introducing the symbol ∞ to represent the concept of infinity. He similarly used 1/∞ for an infinitesimal.\n\nJohn Wallis was born in Ashford, Kent, the third of five children of Reverend John Wallis and Joanna Chapman. He was initially educated at a school in Ashford but moved to James Movat's school in Tenterden in 1625 following an outbreak of plague. Wallis was first exposed to mathematics in 1631, at Martin Holbeach's school in Felsted; he enjoyed maths, but his study was erratic, since \"mathematics, at that time with us, were scarce looked on as academical studies, but rather mechanical\" (Scriba 1970).\n\nAs it was intended he should be a doctor, he was sent in 1632 to Emmanuel College, Cambridge. While there, he kept an \"act\" on the doctrine of the circulation of the blood; that was said to have been the first occasion in Europe on which this theory was publicly maintained in a disputation. His interests, however, centred on mathematics. He received his Bachelor of Arts degree in 1637 and a Master's in 1640, afterwards entering the priesthood. From 1643 to 1649, he served as a nonvoting scribe at the Westminster Assembly. He was elected to a fellowship at Queens' College, Cambridge in 1644, from which he had to resign following his marriage.\n\nThroughout this time, Wallis had been close to the Parliamentarian party, perhaps as a result of his exposure to Holbeach at Felsted School. He rendered them great practical assistance in deciphering Royalist dispatches. The quality of cryptography at that time was mixed; despite the individual successes of mathematicians such as François Viète, the principles underlying cipher design and analysis were very poorly understood. Most ciphers were ad hoc methods relying on a secret algorithm, as opposed to systems based on a variable key. Wallis realised that the latter were far more secure – even describing them as \"unbreakable\", though he was not confident enough in this assertion to encourage revealing cryptographic algorithms. He was also concerned about the use of ciphers by foreign powers, refusing, for example, Gottfried Leibniz's request of 1697 to teach Hanoverian students about cryptography.\n\nReturning to London – he had been made chaplain at St Gabriel Fenchurch in 1643 – Wallis joined the group of scientists that was later to evolve into the Royal Society. He was finally able to indulge his mathematical interests, mastering William Oughtred's \"Clavis Mathematicae\" in a few weeks in 1647. He soon began to write his own treatises, dealing with a wide range of topics, which he continued for the rest of his life.\n\nWallis joined the moderate Presbyterians in signing the remonstrance against the execution of Charles I, by which he incurred the lasting hostility of the Independents. In spite of their opposition he was appointed in 1649 to the Savilian Chair of Geometry at Oxford University, where he lived until his death on 28 October 1703 (O.S.). In 1661, he was one of twelve Presbyterian representatives at the Savoy Conference.\n\nBesides his mathematical works he wrote on theology, logic, English grammar and philosophy, and he was involved in devising a system for teaching a deaf boy to speak at Littlecote House. William Holder had earlier taught a deaf man, Alexander Popham, to speak \"plainly and distinctly, and with a good and graceful tone\". Wallis later claimed credit for this, leading Holder to accuse Wallis of \"rifling his Neighbours, and adorning himself with their spoyls\".\n\nWallis made significant contributions to trigonometry, calculus, geometry, and the analysis of infinite series. In his \"Opera Mathematica\" I (1695) he introduced the term \"continued fraction\".\n\nWallis rejected as absurd the now usual idea of a negative number as being less than nothing, but accepted the view that it is something greater than infinity. (The argument that negative numbers are greater than infinity involves the quotient formula_1 and considering what happens as \"x\" approaches and then crosses the point \"x\" = 0 from the positive side.) Despite this he is generally credited as the originator of the idea of the number line, in which numbers are represented geometrically in a line with the negative numbers represented by lengths opposite in direction to lengths of positive numbers.\n\nIn 1655, Wallis published a treatise on conic sections in which they were defined analytically. This was the earliest book in which these curves are considered and defined as curves of the second degree. It helped to remove some of the perceived difficulty and obscurity of René Descartes' work on analytic geometry.\nIn the \"Treatise on the Conic Sections\" Wallis popularised the symbol ∞ for infinity. He wrote, “I suppose any plane (following the \"Geometry of Indivisibles\" of Cavalieri) to be made up of an infinite number of parallel lines, or as I would prefer, of an infinite number of parallelograms of the same altitude; (let the altitude of each one of these be an infinitely small part 1/∞ of the whole altitude, and let the symbol ∞ denote Infinity) and the altitude of all to make up the altitude of the figure.”\n\n\"Arithmetica Infinitorum\", the most important of Wallis's works, was published in 1656. In this treatise the methods of analysis of Descartes and Cavalieri were systematised and extended, but some ideas were open to criticism. He began, after a short tract on conic sections, by developing the standard notation for powers, extending them from positive integers to rational numbers:\n\nLeaving the numerous algebraic applications of this discovery, he next proceeded to find, by integration, the area enclosed between the curve \"y\" = \"x\", the axis of \"x\", and any ordinate \"x\" = \"h\", and he proved that the ratio of this area to that of the parallelogram on the same base and of the same height is 1/(\"m\" + 1), extending Cavalieri's quadrature formula. He apparently assumed that the same result would be true also for the curve \"y\" = \"ax\", where \"a\" is any constant, and \"m\" any number positive or negative, but he discussed only the case of the parabola in which \"m\" = 2 and the hyperbola in which \"m\" = −1. In the latter case, his interpretation of the result is incorrect. He then showed that similar results may be written down for any curve of the form\n\nand hence that, if the ordinate \"y\" of a curve can be expanded in powers of \"x\", its area can be determined: thus he says that if the equation of the curve is \"y\" = \"x\" + \"x\" + \"x\" + ..., its area would be \"x\" + x/2 + \"x\"/3 + ... He then applied this to the quadrature of the curves \"y\" = (\"x\" − \"x\"), \"y\" = (\"x\" − \"x\"), \"y\" = (\"x\" − \"x\"), etc., taken between the limits \"x\" = 0 and \"x\" = 1. He shows that the areas are, respectively, 1, 1/6, 1/30, 1/140, etc. He next considered curves of the form \"y\" = \"x\" and established the theorem that the area bounded by this curve and the lines \"x\" = 0 and \"x\" = 1 is equal to the area of the rectangle on the same base and of the same altitude as \"m\" : \"m\" + 1. This is equivalent to computing\n\nHe illustrated this by the parabola, in which case \"m\" = 2. He stated, but did not prove, the corresponding result for a curve of the form \"y\" = \"x\".\n\nWallis showed considerable ingenuity in reducing the equations of curves to the forms given above, but, as he was unacquainted with the binomial theorem, he could not effect the quadrature of the circle, whose equation is formula_11, since he was unable to expand this in powers of \"x\". He laid down, however, the principle of interpolation. Thus, as the ordinate of the circle formula_11 is the geometrical mean of the ordinates of the curves formula_13 and formula_14, it might be supposed that, as an approximation, the area of the semicircle formula_15 which is formula_16 might be taken as the geometrical mean of the values of\n\nthat is, 1 and formula_18; this is equivalent to taking formula_19 or 3.26... as the value of π. But, Wallis argued, we have in fact a series formula_20... and therefore the term interpolated between 1 and formula_21 ought to be chosen so as to obey the law of this series. This, by an elaborate method that is not described here in detail, leads to a value for the interpolated term which is equivalent to taking\n(which is now known as the Wallis product).\n\nIn this work also the formation and properties of continued fractions are discussed, the subject having been brought into prominence by Brouncker's use of these fractions.\n\nA few years later, in 1659, Wallis published a tract containing the solution of the problems on the cycloid which had been proposed by Blaise Pascal. In this he incidentally explained how the principles laid down in his \"Arithmetica Infinitorum\" could be used for the rectification of algebraic curves and gave a solution of the problem to rectify (i.e., find the length of) the semicubical parabola \"x\" = \"ay\", which had been discovered in 1657 by his pupil William Neile. Since all attempts to rectify the ellipse and hyperbola had been (necessarily) ineffectual, it had been supposed that no curves could be rectified, as indeed Descartes had definitely asserted to be the case. The logarithmic spiral had been rectified by Evangelista Torricelli and was the first curved line (other than the circle) whose length was determined, but the extension by Neile and Wallis to an algebraic curve was novel. The cycloid was the next curve rectified; this was done by Christopher Wren in 1658.\n\nEarly in 1658 a similar discovery, independent of that of Neile, was made by van Heuraët, and this was published by van Schooten in his edition of Descartes's \"Geometria\" in 1659. Van Heuraët's method is as follows. He supposes the curve to be referred to rectangular axes; if this be so, and if (\"x\", \"y\") be the coordinates of any point on it, and \"n\" be the length of the normal, and if another point whose coordinates are (\"x\", η) be taken such that η : \"h\" = \"n\" : \"y\", where \"h\" is a constant; then, if \"ds\" be the element of the length of the required curve, we have by similar triangles \"ds\" : \"dx\" = \"n\" : \"y\". Therefore, \"h ds\" = η \"dx\". Hence, if the area of the locus of the point (\"x\", η) can be found, the first curve can be rectified. In this way van Heuraët effected the rectification of the curve \"y\" = \"ax\" but added that the rectification of the parabola \"y\" = \"ax\" is impossible. since it requires the quadrature of the hyperbola. The solutions given by Neile and Wallis are somewhat similar to that given by van Heuraët, though no general rule is enunciated, and the analysis is clumsy. A third method was suggested by Fermat in 1660, but it is inelegant and laborious.\n\nThe theory of the collision of bodies was propounded by the Royal Society in 1668 for the consideration of mathematicians. Wallis, Christopher Wren, and Christian Huygens sent correct and similar solutions, all depending on what is now called the conservation of momentum; but, while Wren and Huygens confined their theory to perfectly elastic bodies (elastic collision), Wallis considered also imperfectly elastic bodies (inelastic collision). This was followed in 1669 by a work on statics (centres of gravity), and in 1670 by one on dynamics: these provide a convenient synopsis of what was then known on the subject.\n\nIn 1685 Wallis published \"Algebra\", preceded by a historical account of the development of the subject, which contains a great deal of valuable information. The second edition, issued in 1693 and forming the second volume of his \"Opera\", was considerably enlarged. This algebra is noteworthy as containing the first systematic use of formulae. A given magnitude is here represented by the numerical ratio which it bears to the unit of the same kind of magnitude: thus, when Wallis wants to compare two lengths he regards each as containing so many units of length. This perhaps will be made clearer by noting that the relation between the space described in any time by a particle moving with a uniform velocity is denoted by Wallis by the formula\n\nwhere \"s\" is the number representing the ratio of the space described to the unit of length; while the previous writers would have denoted the same relation by stating what is equivalent to the proposition\n\nHe is usually credited with the proof of the Pythagorean theorem using similar triangles. However, Thabit Ibn Qurra (AD 901), an Arab mathematician, had produced a generalisation of the Pythagorean theorem applicable to all triangles six centuries earlier. It is a reasonable conjecture that Wallis was aware of Thabit's work.\n\nWallis was also inspired by the works of Islamic mathematician Sadr al-Tusi, the son of Nasir al-Din al-Tusi, particularly by al-Tusi's book written in AD 1298 on the parallel postulate. The book was based on his father's thoughts which presented one of the earliest arguments for a non-Euclidean hypothesis equivalent to the parallel postulate. After reading this, Wallis then wrote about his ideas as he developed his own thoughts about the postulate, trying to prove it also with similar triangles.\n\nHe found that Euclid's fifth postulate is equivalent to the one currently named \"Wallis postulate\" after him. This postulate states that \"On a given finite straight line it is always possible to construct a triangle similar to a given triangle\". This result was encompassed in a trend trying to deduce Euclid's fifth from the other four postulates which today is known to be impossible. Unlike other authors, he realised that the unbounded growth of a triangle was not guaranteed by the four first postulates.\n\nAnother aspect of Wallis's mathematical skills was his ability to do mental calculations. He slept badly and often did mental calculations as he lay awake in his bed. One night he calculated in his head the square root of a number with 53 digits. In the morning he dictated the 27-digit square root of the number, still entirely from memory. It was a feat that was considered remarkable, and Henry Oldenburg, the Secretary of the Royal Society, sent a colleague to investigate how Wallis did it. It was considered important enough to merit discussion in the \"Philosophical Transactions\" of the Royal Society of 1685.\n\nA long-running debate between Wallis and Thomas Hobbes arose in the mid-1650s, when mathematicians criticised errors in the work \"De corpore\" by Hobbes. It continued into the 1670s, having gathered in the later claims of Hobbes on squaring the circle, and the wider beliefs on both sides.\n\nWallis translated into Latin works of Ptolemy, Bryennius, and Porphyrius's commentary on Ptolemy. He also published three letters to Henry Oldenburg concerning tuning. He approved of equal temperament that was being used in England's organs.\n\nHis \"Institutio logicae\", published in 1687, was very popular. The \"Grammatica linguae Anglicanae\" was a work on English grammar, that remained in print well into the eighteenth century. He also published on theology.\n\nOn 14 March 1645 he married Susanna Glynde (16?? – 16 March 1687), They had three children:\n\n\n\n"}
{"id": "794872", "url": "https://en.wikipedia.org/wiki?curid=794872", "title": "List of Boolean algebra topics", "text": "List of Boolean algebra topics\n\nThis is a list of topics around Boolean algebra and propositional logic.\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "150144", "url": "https://en.wikipedia.org/wiki?curid=150144", "title": "List of letters used in mathematics and science", "text": "List of letters used in mathematics and science\n\nLatin and Greek letters are used in mathematics, science, engineering, and other areas where mathematical notation is used as symbols for constants, special functions, and also conventionally for variables representing certain quantities. \n\n\n"}
{"id": "5971797", "url": "https://en.wikipedia.org/wiki?curid=5971797", "title": "List of mathematicians (B)", "text": "List of mathematicians (B)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "5971828", "url": "https://en.wikipedia.org/wiki?curid=5971828", "title": "List of mathematicians (R)", "text": "List of mathematicians (R)\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "634754", "url": "https://en.wikipedia.org/wiki?curid=634754", "title": "List of partial differential equation topics", "text": "List of partial differential equation topics\n\nThis is a list of partial differential equation topics.\n\n\n\n\n"}
{"id": "1606990", "url": "https://en.wikipedia.org/wiki?curid=1606990", "title": "Logical harmony", "text": "Logical harmony\n\nLogical harmony, a name coined by Michael Dummett, is a supposed constraint on the rules of inference that can be used in a given logical system.\n\nThe logician Gerhard Gentzen proposed that the meanings of logical connectives could be given by the rules for introducing them into discourse. For example, if one believes that \"the sky is blue\" and one also believes that \"grass is green\", then one can introduce the connective \"and\" as follows: \"The sky is blue AND grass is green.\" Gentzen's idea was that having rules like this is what gives meaning to one's words, or at least to certain words. The idea has also been associated with Wittgenstein's dictum that in many cases we can say, \"meaning is use\". Most contemporary logicians prefer to think that the introduction rules and the elimination rules for an expression are equally important. In this case, \"and\" is characterized by the following rules:\nAn apparent problem with this was pointed out by Arthur Prior: Why can't we have an expression (call it \"tonk\") whose introduction rule is that of OR (from \"p\" to \"p tonk q\") but whose elimination rule is that of AND (from \"p tonk q\" to \"q\")? This lets us deduce anything at all from any starting point. Prior suggested that this meant that inferential rules could \"not\" determine meaning. He was answered by Nuel Belnap, that even though introduction and elimination rules can constitute meaning, not just any pair of such rules will determine a meaningful expression—they must meet certain constraints, such as not allowing us to deduce any new truths in the old vocabulary. These constraints are what Dummett was referring to.\n\nHarmony, then, refers to certain constraints that a proof theory must let hold between introduction and elimination rules for it to be meaningful, or in other words, for its inference rules to be meaning-constituting.\n\nThe application of harmony to logic may be considered a special case; it makes sense to talk of harmony with respect to not only inferential systems, but also conceptual systems in human cognition, and to type systems in programming languages.\n\nSemantics of this form has not provided a very great challenge to that sketched in Tarski's semantic theory of truth, but many philosophers interested in reconstituting the semantics of logic in a way that respects Ludwig Wittgenstein's \"meaning is use\" have felt that harmony holds the key.\n\n\n"}
{"id": "7315901", "url": "https://en.wikipedia.org/wiki?curid=7315901", "title": "Milü", "text": "Milü\n\nThe name Milü (; \"close ratio\"), also known as Zulü (Zu's ratio), is given to an approximation to (pi) found by Chinese mathematician and astronomer, Zǔ Chōngzhī (祖沖之). Using Liu Hui's algorithm (which is based on the areas of regular polygons approximating a circle), Zu famously computed to be between 3.1415926 and 3.1415927 and gave two rational approximations of , and , naming them respectively Yuelü 约率 (approximate ratio) and Milü.\n\nThe accuracy of Milü to the true value of can be explained using the continued fraction expansion of, the first few terms of which are formula_2. A property of continued fractions is that truncating the expansion of a given number at any point will give the \"best rational approximation\" to the number. To obtain Milü, truncate the continued fraction expansion of immediately before the term 292; that is, is approximated by the finite continued fraction formula_3, which is equivalent to Milü. Since 292 is an unusually large term in a continued fraction expansion, this convergent will be very close to the true value of .\n\nAn easy mnemonic helps memorize this useful fraction by writing down each of the first three odd numbers twice: 1 1 3 3 5 5, then dividing the decimal number represented by the last 3 digits by the decimal number given by the first three digits. Alternatively, ≈ .\n\nZu's contemporary calendarist and mathematician He Chengtian () invented a fraction interpolation method called \"harmonization of the divisor of the day\" to obtain a closer approximation by iteratively adding the numerators and denominators of a \"weak\" fraction and a \"strong\" fraction. Zu Chongzhi's approximation ≈ can be obtained with He Chengtian's method.\n\n\n"}
{"id": "35200984", "url": "https://en.wikipedia.org/wiki?curid=35200984", "title": "Minimal K-type", "text": "Minimal K-type\n\nIn mathematics, a minimal K-type is a representation of a maximal compact subgroup \"K\" of a semisimple Lie group \"G\" that is in some sense the smallest representation of \"K\" occurring in a Harish-Chandra module of \"G\". Minimal K-types were introduced by as part of an algebraic description of the Langlands classification.\n"}
{"id": "1719992", "url": "https://en.wikipedia.org/wiki?curid=1719992", "title": "Non-perturbative", "text": "Non-perturbative\n\nIn mathematics and physics, a non-perturbative function or process is one that cannot be accurately described by perturbation theory. An example is the function\n\nformula_1.\n\nThe Taylor series at x = 0 for this function is exactly zero to all orders in perturbation theory, but the function is non-zero if \"x\" ≠ 0.\n\nThe implication of this for physics is that there are some phenomena which are impossible to understand by perturbation theory, regardless of how many orders of perturbation theory we use. Instantons are an example.\n\nTherefore, in theoretical physics, a non-perturbative solution or theory is one that does not require perturbation theory to explicate, or does not simply describe the dynamics of perturbations around some fixed background. For this reason, non-perturbative solutions and theories yield insights into areas and subjects perturbative methods cannot reveal.\n\n"}
{"id": "44052223", "url": "https://en.wikipedia.org/wiki?curid=44052223", "title": "Orthomorphism", "text": "Orthomorphism\n\nIn abstract algebra, an orthomorphism is a certain kind of mapping from a group into itself. Let \"G\" be a group, and let \"θ\" be a permutation of \"G\". Then \"θ\" is an orthomorphism of \"G\" if the mapping \"f\" defined by \"f\"(\"x\") = \"x\" \"θ\"(\"x\") is also a permutation of \"G\". A permutation \"φ\" of \"G\" is a complete mapping if the mapping \"g\" defined by \"g\"(\"x\") = \"xφ\"(\"x\") is also a permutation of \"G\". Orthomorphisms and complete mappings are closely related. \n"}
{"id": "5847302", "url": "https://en.wikipedia.org/wiki?curid=5847302", "title": "Outline of algebraic structures", "text": "Outline of algebraic structures\n\nIn mathematics, there are many types of algebraic structures which are studied. Abstract algebra is primarily the study of specific algebraic structures and their properties. Algebraic structures may be viewed in different ways, however the common starting point of algebra texts is that an algebraic object incorporates one or more sets with one or more binary operations or unary operations satisfying a collection of axioms.\n\nAnother branch of mathematics known as universal algebra studies algebraic structures in general. From the universal algebra viewpoint, most structures can be divided into varieties and quasivarieties depending on the axioms used. Some axiomatic formal systems that are neither varieties nor quasivarieties, called \"nonvarieties\", are sometimes included among the algebraic structures by tradition.\n\nConcrete examples of each structure will be found in the articles listed.\n\nAlgebraic structures are so numerous today that this article will inevitably be incomplete. In addition to this, there are sometimes multiple names for the same structure, and sometimes one name will be defined by disagreeing axioms by different authors. Most structures appearing on this page will be common ones which most authors agree on. Other web lists of algebraic structures, organized more or less alphabetically, include Jipsen and PlanetMath. These lists mention many structures not included below, and may present more information about some structures than is presented here.\n\nAlgebraic structures appear in most branches of mathematics, and one can encounter them in many different ways.\n\nIn full generality, an algebraic structure may use any number of sets and any number of axioms in its definition. The most commonly studied structures, however, usually involve only one or two sets and one or two binary operations. The structures below are organized by how many sets are involved, and how many binary operations are used. Increased indentation is meant to indicate a more exotic structure, and the least indented levels are the most basic.\n\nThe following structures consist of a set with a binary operation. The most common structure is that of a \"group\". Other structures involve weakening or strengthening the axioms for groups, and may additionally use unary operations.\n\n\nThe main types of structures with one set having two binary operations are \"rings\" and \"lattices\". The axioms defining many of the other structures are modifications of the axioms for rings and lattices. One major difference between rings and lattices is that their two operations are related to each other in different ways. In ring-like structures, the two operations are linked by the distributive law; in lattice-like structures, the operations are linked by the absorption law.\n\n\nThe following structures have the common feature of having two sets, \"A\" and \"B\", so that there is a binary operation from \"A\"×\"A\" into \"A\" and another operation from \"A\"×\"B\" into \"A\".\n\n\nMany structures here are actually hybrid structures of the previously mentioned ones.\n\n\nThere are many examples of mathematical structures where algebraic structure exists alongside non-algebraic structure.\n\n\nSome algebraic structures find uses in disciplines outside of abstract algebra. The following is meant to demonstrate some specific applications in other fields.\n\nIn Physics:\n\nIn Mathematical logic:\n\nIn Computer science:\n\nA monograph available free online:\n"}
{"id": "387878", "url": "https://en.wikipedia.org/wiki?curid=387878", "title": "Outline of probability", "text": "Outline of probability\n\nProbability is a measure of the likeliness that an event will occur. Probability is used to quantify an attitude of mind towards some proposition of whose truth we are not certain. The proposition of interest is usually of the form \"A specific event will occur.\" The attitude of mind is of the form \"How certain are we that the event will occur?\" The certainty we adopt can be described in terms of a numerical measure and this number, between 0 and 1 (where 0 indicates impossibility and 1 indicates certainty), we call probability. Probability theory is used extensively in statistics, mathematics, science and philosophy to draw conclusions about the likelihood of potential events and the underlying mechanics of complex systems.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "13508423", "url": "https://en.wikipedia.org/wiki?curid=13508423", "title": "Pan-African Congress of Mathematicians", "text": "Pan-African Congress of Mathematicians\n\nThe Pan-African Congress of Mathematicians (PACOM) is an international congress of mathematics, held under the auspices of the African Mathematical Union.\n\n\n"}
{"id": "4921531", "url": "https://en.wikipedia.org/wiki?curid=4921531", "title": "Patlak plot", "text": "Patlak plot\n\nA Patlak plot (sometimes called Gjedde–Patlak plot, Patlak–Rutland plot, or Patlak analysis) is a graphical analysis technique based on the compartment model that uses linear regression to identify and analyze pharmacokinetics of tracers involving irreversible uptake, such as in the case of deoxyglucose. It is used for the evaluation of nuclear medicine imaging data after the injection of a radioopaque or radioactive tracer.\n\nThe method is model-independent because it does not depend on any specific compartmental model configuration for the tracer, and the minimal assumption is that the behavior of the tracer can be approximated by two compartments – a \"central\" (or reversible) compartment that is in rapid equilibrium with plasma, and a \"peripheral\" (or irreversible) compartment, where tracer enters without ever leaving during the time of the measurements. The amount of tracer in the region of interest is accumulating according to the equation:\n\nwhere formula_2 represents time after tracer injection, formula_3 is the amount of tracer in region of interest, formula_4 is the concentration of tracer in plasma or blood, formula_5 is the clearance determining the rate of entry into the peripheral (irreversible) compartment, and formula_6 is the distribution volume of the tracer in the central compartment. The first term of the right-hand side represents tracer in the peripheral compartment, and the second term tracer in the central compartment.\n\nBy dividing both sides by formula_4, one obtains:\n\nThe unknown constants formula_5 and formula_6 can be obtained by linear regression from a graph of formula_11 against formula_12.\n\n\n"}
{"id": "43844668", "url": "https://en.wikipedia.org/wiki?curid=43844668", "title": "Princeton Lectures in Analysis", "text": "Princeton Lectures in Analysis\n\nThe Princeton Lectures in Analysis is a series of four mathematics textbooks, each covering a different area of mathematical analysis. They were written by Elias M. Stein and Rami Shakarchi and published by Princeton University Press between 2003 and 2011. They are, in order, \"Fourier Analysis: An Introduction\"; \"Complex Analysis\"; \"Real Analysis: Measure Theory, Integration, and Hilbert Spaces\"; and \"Functional Analysis: Introduction to Further Topics in Analysis\".\n\nStein and Shakarchi wrote the books based on a sequence of intensive undergraduate courses Stein began teaching in the spring of 2000 at Princeton University. At the time Stein was a mathematics professor at Princeton and Shakarchi was a graduate student in mathematics. Though Shakarchi graduated in 2002, the collaboration continued until the final volume was published in 2011. The series emphasizes the unity among the branches of analysis and the applicability of analysis to other areas of mathematics.\n\nThe \"Princeton Lectures in Analysis\" has been identified as a well written and influential series of textbooks, suitable for advanced undergraduates and beginning graduate students in mathematics.\n\nThe first author, Elias M. Stein, is a mathematician who has made significant research contributions to the field of mathematical analysis. Before 2000 he had authored or co-authored several influential advanced textbooks on analysis.\n\nBeginning in the spring of 2000, Stein taught a sequence of four intensive undergraduate courses in analysis at Princeton University, where he was a mathematics professor. At the same time he collaborated with Rami Shakarchi, then a graduate student in Princeton's math department studying under Charles Fefferman, to turn each of the courses into a textbook. Stein taught Fourier analysis in that first semester, and by the fall of 2000 the first manuscript was nearly finished. That fall Stein taught the course in complex analysis while he and Shakarchi worked on the corresponding manuscript. Paul Hagelstein, then a postdoctoral scholar in the Princeton math department, was a teaching assistant for this course. In spring 2001, when Stein moved on to the real analysis course, Hagelstein started the sequence anew, beginning with the Fourier analysis course. Hagelstein and his students used Stein and Shakarchi's drafts as texts, and they made suggestions to the authors as they prepared the manuscripts for publication. The project received financial support from Princeton University and from the National Science Foundation.\n\nShakarchi earned his Ph.D. from Princeton in 2002 and moved to London to work in finance. Nonetheless he continued working on the books, even as his employer, Lehman Brothers, collapsed in 2008. The first two volumes were published in 2003. The third followed in 2005, and the fourth in 2011. Princeton University Press published all four.\n\nThe volumes are split into seven to ten chapters each. Each chapter begins with an epigraph providing context for the material and ends with a list of challenges for the reader, split into Exercises, which range in difficulty, and more difficult Problems. Throughout the authors emphasize the unity among the branches of analysis, often referencing one branch within another branch's book. They also provide applications of the theory to other fields of mathematics, particularly partial differential equations and number theory.\n\n\"Fourier Analysis\" covers the discrete, continuous, and finite Fourier transforms and their properties, including inversion. It also presents applications to partial differential equations, Dirichlet's theorem on arithmetic progressions, and other topics. Because Lebesgue integration is not introduced until the third book, the authors use Riemann integration in this volume. They begin with Fourier analysis because of its central role within the historical development and contemporary practice of analysis.\n\n\"Complex Analysis\" treats the standard topics of a course in complex variables as well as several applications to other areas of mathematics. The chapters cover the complex plane, Cauchy's integral theorem, meromorphic functions, connections to Fourier analysis, entire functions, the gamma function, the Riemann zeta function, conformal maps, elliptic functions, and theta functions.\n\n\"Real Analysis\" begins with measure theory, Lebesgue integration, and differentiation in Euclidean space. It then covers Hilbert spaces before returning to measure and integration in the context of abstract measure spaces. It concludes with a chapter on Hausdorff measure and fractals.\n\n\"Functional Analysis\" has chapters on several advanced topics in analysis: L spaces, distributions, the Baire category theorem, probability theory including Brownian motion, several complex variables, and oscillatory integrals.\n\nThe books \"received rave reviews indicating they are all outstanding works written with remarkable clarity and care.\" Reviews praised the exposition, identified the books as accessible and informative for advanced undergraduates or graduate math students, and predicted they would grow in influence as they became standard references for graduate courses. William Ziemer wrote that the third book omitted material he expected to see in an introductory graduate text but nonetheless recommended it as a reference.\n\nPeter Duren compared Stein and Shakarchi's attempt at a unified treatment favorably with Walter Rudin's textbook \"Real and Complex Analysis\", which Duren calls too terse. On the other hand, Duren noted that this sometimes comes at the expense of topics that reside naturally within only one branch. He mentioned in particular geometric aspects of complex analysis covered in Lars Ahlfors's textbook but noted that Stein and Shakarchi also treat some topics Ahlfors skips.\n\n\n"}
{"id": "44672530", "url": "https://en.wikipedia.org/wiki?curid=44672530", "title": "Quadratic integrate and fire", "text": "Quadratic integrate and fire\n\nThe quadratic integrate and fire (QIF) model is a biological neuron model and a type of integrate-and-fire neuron which describes action potentials in neurons. In contrast to physiologically accurate but computationally expensive neuron models like the Hodgkin–Huxley model, the QIF model seeks only to produce action potential-like patterns and ignores subtleties like gating variables, which play an important role in generating action potentials in a real neuron. However, the QIF model is incredibly easy to implement and compute, and relatively straightforward to study and understand, thus has found ubiquitous use in computational neuroscience .\n\nA quadratic integrate and fire neuron is defined by the autonomous differential equation,\n\nwhere formula_2 is a real positive constant. Note that a solution to this differential equation is the tangent function, which blows up in finite time. Thus a \"spike\" is said to have occurred when the solution reaches positive infinity, and the solution is reset to negative infinity.\n\nWhen implementing this model in computers, a threshold crossing value (formula_3) and a reset value (formula_4) is assigned, so that when the solution rises above the threshold, formula_5, the solution is immediately reset to formula_4\n"}
{"id": "35411073", "url": "https://en.wikipedia.org/wiki?curid=35411073", "title": "Raymond Clare Archibald", "text": "Raymond Clare Archibald\n\nRaymond Clare Archibald (7 October 1875 – 26 July 1955) was a prominent Canadian-American mathematician. He is known for his work as a historian of mathematics, his editorships of mathematical journals and his contributions to the teaching of mathematics.\n\nRaymond Clare Archibald was born in South Branch, Stewiacke, Nova Scotia on 7 October 1875. He was the son of Abram Newcomb Archibald (1849—1883) and Mary Mellish Archibald (1849—1901). He was the fourth cousin twice removed of the famous Canadian-American astronomer and mathematician Simon Newcomb (1835—1909).\n\nArchibald graduated in 1894 from Mount Allison College with B.A. degree in mathematics and teacher's certificate in violin. After teaching mathematics and violin for a year at the Mount Allison Ladies’ College he went to Harvard where he received a B.A. 1896 and a M.A. in 1897. He then traveled to Europe where he attended the University of Berlin during 1898 and received a Ph.D.cum laude from the University of Strassburg in 1900. His advisor was Karl Theodor Reye and title of his dissertation was The Cardioide and Some of its Related Curves.\n\nHe returned to Canada in 1900 and taught mathematics and violin at the Mount Allison Ladies’ College until 1907. After a one-year appointment at Acadia University he accepted an invitation of join the mathematics department at Brown University. He stayed at Brown for the rest of his career becoming a Professor Emeritus in 1943. While at Brown he created one of the finest mathematical libraries in the western hemisphere.\n\nArchibald returned to Mount Allison in 1954 to curate the Mary Mellish Archibald Memorial Library, the library he had founded in 1905 to honor his mother. At his death the library contained 23,000 volumes, 2,700 records, and 70,000 songs in American and English poetry and drama.\n\nRaymond Clare Archibald was a world-renowned historian of mathematics with a lifelong concern for the teaching of mathematics in secondary schools. At the presentation of his portrait to Brown University the head of the mathematics department, Professor Clarence Raymond Adams (1898–1965) said of him:\n\n\"The instincts of the bibliophile were also his from early years. Possessing a passion for accurate detail, systematic by nature and blessed with a memory that was the marvel of his friends, he gradually acquired a knowledge of mathematical books and their values which has scarcely been equalled. This knowledge and an untiring energy he dedicated to the upbuilding of the mathematical library at Brown University. From modest beginnings he has developed this essential equipment of the mathematical investigator to a point where it has no superior, in completeness and in convenience for the user.\"\n\nArchibald received honorary degrees from the University of Padua (LL.D., 1922), Mount Allison University (LL.D., 1923) and from Brown University (M.A. ad eundem, 1943).\n\n\nArchibald’s bibliography contains over 1,000 entries. He contributed to over 20 different journals, mathematical, scientific, educational and literary. The following are the books of which he is an author:\n\n\n\n"}
{"id": "48347082", "url": "https://en.wikipedia.org/wiki?curid=48347082", "title": "Scope (logic)", "text": "Scope (logic)\n\nIn logic, the scope of a quantifier or a quantification is the range in the formula where the quantifier \"engages in\". It is put right after the quantifier, often in parentheses. Some authors describe this as including the variable put right after the forall or exists symbol. In the formula , for example, (or ) is the scope of the quantifier (or ).\n\nA variable in the formula is free, if and only if it does not occur in the scope of any quantifier for that variable. A term is free for a variable in the formula (i.e. free to substitute that variable that occurs free), if and only if that variable does not occur free in the scope of any quantifier for any variable in the term.\n\n"}
{"id": "17056775", "url": "https://en.wikipedia.org/wiki?curid=17056775", "title": "Software calculator", "text": "Software calculator\n\nA software calculator is a calculator that has been implemented as a computer program, rather than as a physical hardware device.\n\nThey are among the simpler interactive software tools, and, as such, they:\n\nAs a \"calculator\", rather than a computer, they usually:\n\nSoftware calculators are available for many different platforms, and they can be:\n\nComputers as we know them today first emerged in the 1940s and 1950s. The software that they ran was naturally used to perform calculations, but it was specially designed for a substantial application that was not limited to simple calculations. For example, the LEO computer was designed to run business application software such as payroll.\n\nSoftware specifically to perform calculations as its main purpose was first written in the 1960s, and the first software package for general calculations to obtain widespread use was released in 1978. This was VisiCalc and it was called an \"interactive visible calculator\", but it was actually a spreadsheet, and these are now not normally known simply as calculators.\n\nThe Unix version released in 1979, V7 Unix, contained a command-line accessible calculator.\n\nCalculators have been used since ancient times and until the advent of software calculators they were physical, hardware machines. The most recent hardware calculators are electronic hand-held devices with buttons for digits and operations, and a small window for inputs and results.\n\nThe first software calculators imitated these hardware calculators by implementing the same functionality with mouse-operated, rather than finger-operated, buttons. Such software calculators first emerged in the 1980s as part of the original Macintosh operating system (System 1) and the Windows operating system (Windows 1.0).\n\nSome software calculators directly simulate one of the hardware calculators, by presenting an image that looks like the calculator, and by providing the same functionality.\n\nThere is now a very wide range of software calculators, and searching the Internet produces very large numbers of programs that are called \"calculators\".\n\nThe results include numerical calculators that apply arithmetic operations or mathematical functions to numbers, and that produce numerical results or graphs of numerical functions, plus some non-numerical tools and games that are also called calculators. \n\nMany of the results are calculators that do not imitate or simulate hardware calculators, but that take advantage of the greater power of computer software to implement alternative types of calculators. Software calculators are provided on the Internet which are customizable to use any conceivable algebraic expression. These user-customizable software calculators can also be used in conjunction with formula or equation creation capabilities so that the software calculator can now be created to perform all possible mathematical functions. No longer limited to a set of trigonometric and simple algebraic expressions, versions of the software calculator are now tailored to any and all topical applications.\n\nEvery type of hardware calculator has been implemented in software, including conversion, financial, graphing, programmable and scientific calculators.\n\nOther numerical calculators that do not imitate hardware calculators include:\n\nWindows-based calculators present a dialog box that allows users to enter data, rather than data \"and\" operations, and they have a built-in formula that is automatically applied to this data. There are many examples of such calculators in finance, mathematics, science and other disciplines.\n\nThere are software calculators that contain operations relevant to a specific application area and profession, including automotive, construction and electrical engineering.\n\nNon-numerical calculators include life-style and scientific calculators:\n\nThere are some software games that are called calculators, including:\n\nThere are many interactive software packages that provide user-accessible calculation features, but that are not normally called \"calculators\", because the calculation features play only a supporting role rather than being an end in themselves. These include:\n\nSpreadsheets are not normally called \"calculators\" because their main purpose is to organise data in rows and columns, and to automatically update the values of possibly many dependent cells when the value in another cell changes. The calculation features are only used in a supporting role to specify the values in some cells.\n\nComputer algebra systems are not normally called \"calculators\" because their main purpose is to perform symbolic manipulation of mathematical expressions that can contain variables and complex operations, such as integration. However, the expressions can be basic calculations that do not use variables, and that are simply evaluated, as with a calculator.\n\nDatabases are not normally called \"calculators\" because their main purpose is data entry and storage, plus reporting against this data. The calculation features are only used in a supporting role to specify the values in some fields.\n\n"}
{"id": "18619097", "url": "https://en.wikipedia.org/wiki?curid=18619097", "title": "Steinhaus longimeter", "text": "Steinhaus longimeter\n\nThe Steinhaus longimeter, patented by the professor Hugo Steinhaus, is an instrument used to measure the lengths of curves on maps. It is a transparent sheet of three grids, turned against each other by 30 degrees, each consisting of perpendicular lines spaced at equal distances 3.82 mm. The measurement is done by counting crossings of the curve with grid lines. The number of crossings is the approximate length of the curve in millimetres.\n\n\n\n"}
{"id": "305463", "url": "https://en.wikipedia.org/wiki?curid=305463", "title": "Steinhaus–Moser notation", "text": "Steinhaus–Moser notation\n\nIn mathematics, Steinhaus–Moser notation is a notation for expressing certain extremely large numbers. It is an extension of Steinhaus's polygon notation.\n\netc.: written in an ()-sided polygon is equivalent with \"the number inside nested -sided polygons\". In a series of nested polygons, they are associated inward. The number inside two triangles is equivalent to inside one triangle, which is equivalent to raised to the power of .\n\nSteinhaus defined only the triangle, the square, and the circle , which is equivalent to the pentagon defined above.\n\nSteinhaus defined:\n\nMoser's number is the number represented by \"2 in a megagon\", where a megagon is a polygon with \"mega\" sides, not to be confused with the megagon, with one million sides.\n\nAlternative notations:\n\nA mega, ②, is already a very large number, since ② =\nsquare(square(2)) = square(triangle(triangle(2))) =\nsquare(triangle(2)) = \nsquare(triangle(4)) =\nsquare(4) =\nsquare(256) =\ntriangle(triangle(triangle(...triangle(256)...))) [256 triangles] =\ntriangle(triangle(triangle(...triangle(256)...))) [255 triangles] ~\ntriangle(triangle(triangle(...triangle(3.2 × 10)...))) [254 triangles] =\n\nUsing the other notation:\n\nmega = M(2,1,5) = M(256,256,3)\n\nWith the function formula_7 we have mega = formula_8 where the superscript denotes a functional power, not a numerical power.\n\nWe have (note the convention that powers are evaluated from right to left):\nSimilarly:\netc.\n\nThus:\n\nRounding more crudely (replacing the 257 at the end by 256), we get mega ≈ formula_17, using Knuth's up-arrow notation.\n\nAfter the first few steps the value of formula_18 is each time approximately equal to formula_19. In fact, it is even approximately equal to formula_20 (see also approximate arithmetic for very large numbers). Using base 10 powers we get:\n\nIt has been proven that in Conway chained arrow notation,\n\nand, in Knuth's up-arrow notation,\n\nTherefore, Moser's number, although incomprehensibly large, is vanishingly small compared to Graham's number:\n\n\n"}
{"id": "394508", "url": "https://en.wikipedia.org/wiki?curid=394508", "title": "Séminaire de Géométrie Algébrique du Bois Marie", "text": "Séminaire de Géométrie Algébrique du Bois Marie\n\nIn mathematics, the Séminaire de Géométrie Algébrique du Bois Marie (SGA) was an influential seminar run by Alexander Grothendieck. It was a unique phenomenon of research and publication outside of the main mathematical journals that ran from 1960 to 1969 at the IHÉS near Paris. (The name came from the small wood on the estate in Bures-sur-Yvette where the IHÉS was located from 1962.) The seminar notes were eventually published in twelve volumes, all except one in the Springer Lecture Notes in Mathematics series.\n\nThe material has a reputation of being hard to read for a number of reasons. More elementary or foundational parts were relegated to the EGA series of Grothendieck and Jean Dieudonné, causing long strings of logical dependencies in the statements. The style is very abstract and makes heavy use of category theory. Moreover, an attempt was made to achieve maximally general statements, while assuming that the reader is aware of the motivations and concrete examples.\n\nThe original notes to SGA were published in fascicles by the IHÉS, most of which went through two or three revisions. These were published as the seminar proceeded, beginning in the early 60's and continuing through most of the decade. They can still be found in large math libraries, but distribution was limited. In the late 60's and early 70's, the original seminar notes were comprehensively revised and rewritten to take into account later developments. In addition, a new volume, SGA 4½, was compiled by Pierre Deligne and published in 1977; it contains simplified and new results by Deligne within the scope of SGA4 as well as some material from SGA5, which had not yet appeared at that time. The revised notes, except for SGA2, were published by Springer in its \"Lecture Notes in Mathematics\" series.\n\nAfter a dispute with Springer, Grothendieck refused the permission for reprints of the series. While these later revisions were more widely distributed than the original fascicles, they are still uncommon outside of libraries.\n\nReferences to SGA typically mean the later, revised editions and not the original fascicles; some of the originals were labelled by capital letters, thus for example S.G.A.D. = SGA3 and S.G.A.A. = SGA4.\n\nThe volumes of the SGA series are the following:\n\n\nIn the 1990s it became obvious that the lack of availability of the SGA was becoming more and more of a problem to researchers and graduate students in algebraic geometry: not only are the copies in book form too few for the growing number of researchers, but they are also difficult to read because of the way they are typeset (on an electric typewriter, with mathematical formulae written by hand). Thus, under the impetus of various mathematicians from several countries, a project was formed of re-publishing SGA in a more widely available electronic format and using LaTeX for typesetting; also, various notes are to be added to correct for minor mistakes or obscurities. The result should be published by the Société Mathématique de France. Legal permission to reprint the works was obtained from every author except Alexander Grothendieck himself, who could not be contacted; it was decided to proceed without his explicit agreement on the grounds that his refusal for the SGA to be re-published by Springer-Verlag was an objection against Springer and not one of principle.\n\nAs a first step, the entire work was scanned and made available on-line (see the links section below) by Frank Calegari, Jim Borger and William Stein. The job of typesetting the text anew and proofreading it was then distributed among dozens of volunteers (most of them junior French mathematicians, because of the required fluency in French and knowledge of algebraic geometry), starting with SGA1 in late 2001.\n\nThe coordinating editor for the work on SGA1 was Bas Edixhoven from University of Leiden (at the time University of Rennes): the first version was available on the arXiv.org e-print archive on June 20, 2002, and the proof-read version was uploaded on January 4, 2004, and later published in book form by the Société Mathématique de France. Work on SGA2 was started in 2004 with Yves Laszlo as coordinating editor. The LaTeX source file is available on the arXiv.org e-print archive; SGA2 appeared in print in late 2005 by the Société Mathématique de France (see https://web.archive.org/web/20091130171320/http://smf.emath.fr/Publications/DocumentsMathematiques/).\n\nLaszlo has also edited SGA4 and recently Philippe Gille and Patrick Polo have uploaded TeXed version of SGA3. In January 2010, however, Grothendieck requested that work cease on republishing SGA. In late 2014 work on republishing SGA resumed and it was restored to the Grothendieck circle site.\n\n\n\n\n\n\n\n"}
{"id": "8434205", "url": "https://en.wikipedia.org/wiki?curid=8434205", "title": "Table of mathematical symbols by introduction date", "text": "Table of mathematical symbols by introduction date\n\nThe following table lists many specialized symbols commonly used in mathematics, ordered by their introduction date. \n\n\n"}
{"id": "132729", "url": "https://en.wikipedia.org/wiki?curid=132729", "title": "Tuple", "text": "Tuple\n\nIn mathematics, a tuple is a finite ordered list (sequence) of elements. An -tuple is a sequence (or ordered list) of elements, where is a non-negative integer. There is only one 0-tuple, an empty sequence, or empty tuple, as it is referred to. An -tuple is defined inductively using the construction of an ordered pair.\n\nMathematicians usually write tuples by listing the elements within parentheses \"formula_1\" and separated by commas; for example, formula_2 denotes a 5-tuple. Sometimes other symbols are used to surround the elements, such as square brackets \"[ ]\" or angle brackets \"< >\". Braces \"{ }\" are only used in defining arrays in some programming languages such as Java and Visual Basic, but not in mathematical expressions, as they are the standard notation for sets. The term \"tuple\" can often occur when discussing other mathematical objects, such as vectors.\n\nIn computer science, tuples come in many forms. In dynamically typed languages, such as Lisp, lists are commonly used as tuples. Most typed functional programming languages implement tuples directly as product types, tightly associated with algebraic data types, pattern matching, and destructuring assignment. Many programming languages offer an alternative to tuples, known as record types, featuring unordered elements accessed by label. A few programming languages combine ordered tuple product types and unordered record types into a single construct, as in C structs and Haskell records. Relational databases may formally identify their rows (records) as \"tuples\".\n\nTuples also occur in relational algebra; when programming the semantic web with the Resource Description Framework (RDF); in linguistics; and in philosophy.\n\nThe term originated as an abstraction of the sequence: single, double, triple, quadruple, quintuple, sextuple, septuple, octuple, ..., ‑tuple, ..., where the prefixes are taken from the Latin names of the numerals. The unique 0‑tuple is called the null tuple. A 1‑tuple is called a singleton, a 2‑tuple is called an ordered pair and a 3‑tuple is a triple or triplet. can be any nonnegative integer. For example, a complex number can be represented as a 2‑tuple, a quaternion can be represented as a 4‑tuple, an octonion can be represented as an 8‑tuple and a sedenion can be represented as a 16‑tuple.\n\nAlthough these uses treat \"‑tuple\" as the suffix, the original suffix was \"‑ple\" as in \"triple\" (three-fold) or \"decuple\" (ten‑fold). This originates from medieval Latin \"plus\" (meaning \"more\") related to Greek ‑πλοῦς, which replaced the classical and late antique \"‑plex\" (meaning \"folded\"), as in \"duplex\".\n\nThe general rule for the identity of two -tuples is\n\nThus a tuple has properties that distinguish it from a set.\n\nThere are several definitions of tuples that give them the properties described in the previous section.\n\nIf we are dealing with sets, an -tuple can be regarded as a function, , whose domain is the tuple's implicit set of element indices, , and whose codomain, , is the tuple's set of elements. Formally:\nwhere:\nIn slightly less formal notation this says:\n\nAnother way of modeling tuples in Set Theory is as nested ordered pairs. This approach assumes that the notion of ordered pair has already been defined; thus a 2-tuple \nThis definition can be applied recursively to the -tuple:\n\nThus, for example:\n\nA variant of this definition starts \"peeling off\" elements from the other end:\nThis definition can be applied recursively:\n\nThus, for example:\n\nUsing Kuratowski's representation for an ordered pair, the second definition above can be reformulated in terms of pure set theory:\n\nIn this formulation:\n\nIn discrete mathematics, especially combinatorics and finite probability theory, -tuples arise in the context of various counting problems and are treated more informally as ordered lists of length . -tuples whose entries come from a set of elements are also called \"arrangements with repetition\", \"permutations of a multiset\" and, in some non-English literature, \"variations with repetition\". The number of -tuples of an -set is . This follows from the combinatorial rule of product. If is a finite set of cardinality , this number is the cardinality of the -fold Cartesian power . Tuples are elements of this product set.\n\nIn type theory, commonly used in programming languages, a tuple has a product type; this fixes not only the length, but also the underlying types of each component. Formally:\nand the projections are term constructors:\n\nThe tuple with labeled elements used in the relational model has a record type. Both of these types can be defined as simple extensions of the simply typed lambda calculus.\n\nThe notion of a tuple in type theory and that in set theory are related in the following way: If we consider the natural model of a type theory, and use the Scott brackets to indicate the semantic interpretation, then the model consists of some sets formula_29 (note: the use of italics here that distinguishes sets from types) such that:\nand the interpretation of the basic terms is:\n\nThe -tuple of type theory has the natural interpretation as an -tuple of set theory:\nThe unit type has as semantic interpretation the 0-tuple.\n\n\n"}
{"id": "37842037", "url": "https://en.wikipedia.org/wiki?curid=37842037", "title": "WIRIS", "text": "WIRIS\n\nWIRIS is a set of proprietary HTML-based JavaScript tools which can author and edit mathematical formulas, execute mathematical problems and show mathematical graphics on the Cartesian coordinate system. WIRIS equation editor is a native browser application, with a light server-side, that supports both MathML and LaTeX.\n"}
{"id": "46586008", "url": "https://en.wikipedia.org/wiki?curid=46586008", "title": "Weyl's tile argument", "text": "Weyl's tile argument\n\nIn philosophy, the Weyl's tile argument (named after Hermann Weyl) is an argument against the notion that physical space is discrete, or composed of a number of finite sized units (or tiles). The argument purports to show a distance function approximating Pythagoras' theorem on a discrete space cannot be defined and, since the Pythagorean theorem has been confirmed to be approximately true in nature, physical space is not discrete. While academic debate continues, counterarguments have been proposed in the literature.\n\nA demonstration of Weyl's argument proceeds by constructing a rectangular tiling of the plane representing a discrete space. A discretized triangle, n units tall and n units long, can be constructed on the tiling. The hypotenuse of the resulting triangle will be n tiles long. However, by the pythagorean theorem, a corresponding triangle in a continuous space—a triangle whose height and length are n -- will have a hypotenuse measuring n√2 units long. To show that the former result does not converge to the latter for arbitrary values of n, one can examine the percent difference between the two results: = 1-. Since n cancels out, the two results never converge, even in the limit of large n. The argument can be constructed for more general triangles, but, in each case, the result is the same. Thus, a discrete space does not even approximate the pythagorean theorem.\n\nIn response, Kris McDaniel has argued the Weyl Tile argument depends on accepting the Size Thesis, according to which the distance between two points is given by the number of tiles between the two points. However, as McDaniel points out, the size thesis is not accepted for continuous spaces. Thus, we might have reason not to accept the size thesis for discrete spaces.\n\nNonetheless, if a discrete space is constructed by a rectangular tiling of the plane and the Size Thesis is accepted, the Euclidean metric will be inappropriate for measuring distances on the resulting space. Instead, the so-called Hamming metric should be utilized. Computer scientists interested in the distance between two strings and mathematical biologists interested in the distance between two genetic sequences employ the versions of the Hamming metric in each of their respective disciplines.\n"}
{"id": "499002", "url": "https://en.wikipedia.org/wiki?curid=499002", "title": "Zenzizenzizenzic", "text": "Zenzizenzizenzic\n\nZenzizenzizenzic is an obsolete form of mathematical notation representing the eighth power of a number (that is, the zenzizenzizenzic of \"x\" is \"x\"), dating from a time when powers were written out in words rather than as superscript numbers. This term was suggested by Robert Recorde, a 16th-century Welsh writer of popular mathematics textbooks, in his 1557 work \"The Whetstone of Witte\" (although his spelling was \"zenzizenzizenzike\"); he wrote that it \"doeth represent the square of squares squaredly\".\n\nAt the time Recorde proposed this notation, there was no easy way of denoting the powers of numbers other than squares and cubes. The root word for Recorde's notation is zenzic, which is a German spelling of the medieval Italian word \"censo\", meaning \"squared\". Since the square of a square of a number is its fourth power, Recorde used the word zenzizenzic (spelled by him as \"zenzizenzike\") to express it. Some of the terms had prior use in Latin \"zenzicubicus\", \"zensizensicus\" and \"zensizenzum\". Similarly, as the sixth power of a number is equal to the square of its cube, Recorde used the word \"zenzicubike\" to express it; a more modern spelling, zenzicube, is found in Samuel Jeake's \"Logisticelogia\". Finally, the word \"zenzizenzizenzic\" denotes the square of the square of a number's square, which is its eighth power: in modern notation,\n\nRecorde proposed three mathematical terms by which any power (that is, index or exponent) greater than 1 could be expressed: \"zenzic\", i.e. squared; \"cubic\"; and \"sursolid\", i.e. raised to a prime number greater than three, the smallest of which is five. Sursolids were as follows: 5 was the first; 7, the second; 11, the third; 13, the fourth; etc.\n\nTherefore, a number raised to the power of six would be \"zenzicubic\", a number raised to the power of seven would be the second sursolid, hence \"bissursolid\" (not a multiple of two and three), a number raised to the twelfth power would be the \"zenzizenzicubic\" and a number raised to the power of ten would be \"the square of the (first) sursolid\". The fourteenth power was the square of the second sursolid, and the twenty-second was the square of the third sursolid.\n\nCuriously, Jeake's text appears to designate a written exponent of 0 as being equal to an \"absolute number, as if it had no Mark\", thus using the notation x to refer to x alone, while a written exponent of 1, in his text, denotes \"the Root of any number\", thus using the notation x to refer to what is now known to be x.\n\nThe word, as well as the system, is obsolete except as a curiosity; the Oxford English Dictionary has only one citation for it.\nAs well as being a mathematical oddity, it survives as a linguistic oddity: \"zenzizenzizenzic\" has more Zs than any other word in the OED.\n\nSamuel Jeake the Younger gives \"zenzizenzizenzizenzike\" (the square of the square of the square of the square) in a table in \"A Compleat Body of Arithmetick\":\n\n\n"}
