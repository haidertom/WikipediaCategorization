{"id": "50607069", "url": "https://en.wikipedia.org/wiki?curid=50607069", "title": "Amino acid score", "text": "Amino acid score\n\nAmino acid score, in combination with protein digestibility, is the method used to determine if a protein is complete. PDCAAS and DIAAS are the two major protein standards which determine the completeness of proteins by their unique composition of essential amino acids.\n"}
{"id": "7157316", "url": "https://en.wikipedia.org/wiki?curid=7157316", "title": "Attack rate", "text": "Attack rate\n\nIn epidemiology, the attack rate is the biostatistical measure of frequency of morbidity, or speed of spread, in an at risk population. It is used in hypothetical predictions and during actual outbreaks of disease. An at risk population is defined as one that has no immunity to the attacking pathogen which can be either a novel pathogen or an established pathogen. It is used to project the number of victims to expect during an epidemic. This aids in marshalling resources for delivery of medical care as well as production of vaccines and/or anti-viral and anti-bacterial medicines. The rate is arrived at by taking the number of new cases in the population at risk and dividing by the number of persons at risk in the population.\n\nformula_1\n\nRates are determined from the beginning of the outbreak to its end. The term should probably not be described as a rate because its time dimension is uncertain. While the duration of an epidemic can be predicted given other variables such as early intervention, it cannot be known in absolute terms. In epidemiology, a rate requires a defined unit change (in this instance, time) over which the rate applies. For this reason, it is often referred to as an attack ratio.\n\n\n"}
{"id": "42766304", "url": "https://en.wikipedia.org/wiki?curid=42766304", "title": "Child health in Uganda", "text": "Child health in Uganda\n\nChildren in Uganda are regularly exposed to many preventable health risks. According to the WHO, the country ranks 175th out of 193 eligible countries in life expectancy. The country also ranks 168 out of 188 in infant mortality rates, with a lower rank reflecting lower infant mortality. There are many cultural factors influencing the current health status of Uganda including the negative stigmas associated with sex, and the wood-burning stoves. The former of these has resulted in a severe lack in education and communication necessary to improve the health and well-being of children.\n\nHIV/AIDS is likely the leading health risk facing Ugandan children; it affects many facets of their physical and mental health in a variety of ways. It is the leading cause of death in Uganda, as reported by the Center for Disease Control (CDC) in 2010.\n\nThe CDC has been fairly active in the country, working in cooperation with government organizations as well as a number of other partners. Their work has been on multiple fronts including door to door HIV counseling and testing. Despite these and many other efforts, there are poor rates of treatment of children. Of the 190,000 HIV-positive children in Uganda, only 35,500 received Antiretroviral medication (ARV). Uganda is not alone in this, in 21 high burden African countries, only 34 percent of eligible children receive ARVs, compared to 68 percent of adults.\n\nIn addition, many of the children that receive medication have been found to lack necessary diligence in their drug therapy routine. Many children find the medication unpleasant and are not even aware of their HIV status. Part of this can be attributed to lapses in communication. For example, it is common practice not to inform children of their HIV status until they reach 13 years of age. Sexual lifestyles are typically frowned upon in Uganda, particularly for women, which contributes to a poor dissemination of sexual related health information.\n\nResearch has shown that efforts to improve health and awareness of parents and guardians, as well as the communities, of children with HIV/AIDS could be an effective way to improve treatment. Increased education and awareness can help with communication breakdowns and access to resources. These efforts can also help decrease mother-to-child transmissions.\n\nIt is estimated that 91,000 infants are born each year to HIV-positive women. Only 51.6 percent of these women receive any sort of mother-to-child HIV prevention and about 24 percent of all 110,000 new HIV infections in Uganda in 2009 were a result of mother-to-child transmission. A study published by the World Health Organization (WHO) found that antiretroviral therapy (ART) is a very effective management strategy, in terms of efficacy as well as cost, for prevention of mother-to-child transmissions. In addition, often material support for parents/guardians can be an effective strategy in improving care and treatment of children, including funding for food, clothing, and educational expenses.\n\nTo date, most of Uganda's policies to combat AIDS have focused on abstinence and fidelity, both preventative measures while little action has been taken around youth education. The main tool of this strategy is the controversial ABC campaign (Abstinence, Be faithful, and use Condoms). While initially believed to be a successful approach, the effectiveness of this strategy is currently inconclusive as more recent studies have found that increased condom use and deaths have been responsible for the decreases in HIV infections.\n\nMalnutrition plagues much of Uganda's youth. According to a study by the World Food Programme (WFP), roughly one third of Ugandan children have stunting, a permanent condition resulting from lack of proper nutrition during the first 5 years of life. Consequences of this have been found to be very costly to the Ugandan government and economy, with estimated losses totaling at US $899 million annually, or 5 percent of the country's GDP.\n\nWhile many efforts are currently in place in Uganda to distribute vaccinations to children, it is still a very serious health concern. About 2 million deaths each year in Uganda are a result of vaccine preventable diseases. Tuberculosis is one example of these, which was found to be the 4th leading cause of death in Uganda in 2010 according to the CDC. In 2001, it was found that 63% of children less than one year old had either failed to complete their vaccination schedule or not had any vaccinations at all. A 2012 study found that vaccination rates can be improved by providing additional support to mothers to enable them to make use of immunization services.\n\nTraditionally in Uganda, as in most developing countries, open word-burning stoves are commonly used for cooking and to heat homes. It has been estimated that 95 percent of Ugandans rely on wood or charcoal for cooking.\n\nOne health issue facing female children specifically in Uganda as well as many other developing countries is the inability to afford sanitary pads. Besides the obvious health and sanitation concerns, this problem also often has harmful effects on education. Evaluations by the Kasiisi Project, a non-profit organization working in rural Western Uganda, found that girls will often skip school or drop out altogether as a result of menstruation and insufficient resources and facilities associated with it.\n\nIn 2008, Janet Museveni launched the Road Map campaign in an effort to coordinate efforts to lower maternal and neonatal death rates in Uganda.\n"}
{"id": "3141410", "url": "https://en.wikipedia.org/wiki?curid=3141410", "title": "Child mortality", "text": "Child mortality\n\nChild mortality, also known as child death, refers to the death of children under the age of 14 and encompasses neonatal mortality, under-5 mortality, and mortality of children aged 5–14. Many child deaths go unreported for a variety of reasons, including lack of death registration and lack of data on child migrants. Without accurate data on child deaths, we cannot fully discover and combat the greatest risks to a child's life.\n\nReduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals. Rapid progress has resulted in a significant decline in preventable child deaths since 1990, with the global under-5 mortality rate declining by over half between 1990 and 2016. While in 1990, 12.6 million children under age five died, in 2016 that number fell to 5.6 million children. However, despite advances, there are still 15,000 under-five deaths per day from largely preventable causes. About 80 per cent of these occur in sub-Saharan Africa and South Asia, and just 6 countries account for half of all under-five deaths: India, Nigeria, Pakistan, the Democratic Republic of the Congo, Ethiopia and China. 45% of these children died during the first 28 days of life.\n\nChild mortality refers to number of child deaths under the age of 5 per 1000 live births. However, the child mortality could be simplified into more specific terms such as prenatal, perinatal, Neonatal, infancy and under 5. Prenatal: child death before the birth, Perinatal: child death before one week of birth, Neonatal: child death before 28 days of birth, Infancy: child death before 1st birthday, and child mortality under 5 refer to any deaths from birth to the 5th birthday.\n\nPerinatal mortality rate: Number of child deaths within first week of birth/ total number of birth\n\nNeonatal mortality rate: number of child deaths within first 28 days of life/ total number of birth\n\nInfancy mortality rate: number of child deaths within first 12 months of life/ total number of birth\n\nUnder 5 mortality rates: number of child deaths within 5th birthday/ total number of birth\n\nThe leading causes of death of children under five include:\n\n\nThere is variation of child mortality around the world; countries that are in the second or third stage of the Demographic Transition Mode (DTM) have higher rates of child mortality than countries in the fourth or fifth state of the DTM. Chad infant mortality is about 96 per 1,000 live births. And developed country such as Japan infant mortality is about 2.2 per 1,000 live births. In 2010, there were estimated to 7.6 million child deaths around the world and most of it occurred in less developed countries and 4.7 million died from infection and disorder. Child mortality isn’t only caused by infection and disorder, it is also caused by premature birth, birth defect, new born infection, birth complication, and disease like malaria, sepsis, and diarrhea. In less developed countries, malnutrition is the main source of child mortality. Pneumonia, diarrhea and malaria together are the cause of 1 out of every 3 child deaths before the age of 5 and nearly half of under-five deaths globally are attributable to under nutrition.\n\nChild survival is a field of public health concerned with reducing child mortality. Child survival \ninterventions are designed to address the most common causes of child deaths that occur, which include diarrhea, pneumonia, malaria, and neonatal conditions. Of the portion of children under the age of 5 alone, an estimated 5.6 million children die each year mostly from such preventable causes.\n\nThe child survival strategies and interventions are in line with the fourth Millennium Development Goals (MDGs) which focused on reducing child mortality by 2/3 of children under five before the year 2015. In 2015, the MDGs were replaced with the Sustainable Development Goals (SDGs), which aim to end these deaths by 2030. In order to achieve SDG targets, progress must be accelerated in more than 1/4 of all countries (most of which are in sub-Saharan Africa) in order to achieve targets for under-5 mortality, and in 60 countries (many in sub-Saharan Africa and South Asia) to achieve targets for neonatal mortality. Without accelerated progress, 60 million children under age 5 will die between 2017 and 2030, about half of which would be newborns.\n\nTwo-thirds of child deaths are preventable. Most of the children who die each year could be saved by low-tech, evidence-based, cost-effective measures such as vaccines, antibiotics, micronutrient supplementation, insecticide-treated bed nets, improved family care and breastfeeding practices, and oral rehydration therapy. Empowering women, removing financial and social barriers to accessing basic services, developing innovations that make the supply of critical services more available to the poor and increasing local accountability of health systems are policy interventions that have allowed health systems to improve equity and reduce mortality.\n\nIn developing countries, child mortality rates related to respiratory and diarrheal diseases can be reduced by introducing simple behavioral changes, such as handwashing with soap. This simple action can reduce the rate of mortality from these diseases by almost 50 per cent.\n\nProven, cost-effective interventions can save the lives of millions of children per year. The UN Vaccine division as of 2014 supported 36% of the world's children in order to best improve their survival chances, yet still, low-cost immunization interventions do not reach 30 million children despite success in reducing polio, tetanus, and measles. Measles and tetanus still kill more than 1 million children under 5 each year. Vitamin A supplementation costs only $0.02 cents for each capsule and given 2-3 times a year will prevent blindness and death. Although vitamin A supplementation has been shown to reduce all-cause mortality by 12 to 24 per cent, only 70 per cent of targeted children were reached in 2015. Between 250,000 and 500,000 children become blind every year, with 70 percent of them dying within 12 months. Oral rehydration therapy (ORT) is an effective treatment for lost liquids through diarrhea; yet only 4 in 10 (44 per cent) of children ill with diarrhea are treated with ORT.\n\nEssential newborn care - including immunizing mothers against tetanus, ensuring clean delivery practices in a hygienic birthing environment, drying and wrapping the baby immediately after birth, providing necessary warmth, and promoting immediate and continued breastfeeding, immunization, and treatment of infections with antibiotics - could save the lives of 3 million newborns annually. Improved sanitation and access to clean drinking water can reduce childhood infections and diarrhea. Over 30% of the world's population does not have access to basic sanitation, and 844 million people use unsafe sources of drinking water.\n\nAgencies promoting and implementing child survival activities worldwide include UNICEF and non-governmental organizations; major child survival donors worldwide include the World Bank, the British Government's Department for International Development, the Canadian International Development Agency and the United States Agency for International Development. In the United States, most non-governmental child survival agencies belong to the CORE Group, a coalition working, through collaborative action, to save the lives of young children in the world's poorest countries.\n\nChild mortality has been dropping as each country reaches a high stage of DTM. From 2000 to 2010, child mortality has dropped from 9.6 million to 7.6 million. In order to reduce child mortality rates, there needs to be better education, higher standards of healthcare and more caution in childbearing. Child mortality could be reduced by attendance of professionals at birth and by breastfeeding and through access to clean water, sanitation, and immunization. In 2016, the world average was 41 (4.1%), down from 93 (9.3%) in 1990. This is equivalent to 5.6 million children less than five years old dying in 2016.\n\nHuge disparities in under-5 mortality rates exist. Globally, the risk of a child dying in the country with the highest under-5 mortality rate is about 60 times higher than in the country with the lowest under-5 mortality rate. Sub-Saharan Africa remains the region with the highest under-5 mortality rates in the world: All six countries with rates above 100 deaths per 1,000 live births are in sub-Saharan Africa.\n\nFurthermore, approximately 80% of under-5 deaths occur in only two regions: sub-Saharan Africa and South Asia. 6 countries account for half of the global under-5 deaths, namely, India, Nigeria, Pakistan, the Democratic Republic of the Congo, Ethiopia and China. India and Nigeria alone account for almost a third (32 per cent) of the global under-five deaths.\n\nLikewise, there are disparities between wealthy and poor households in developing countries. According to a Save the Children paper, children from the poorest households in India are three times more likely to die before their fifth birthday than those from the richest households.\n\nThe child survival rate of nations varies with factors such as fertility rate and income distribution; the change in distribution shows a strong correlation between child survival and income distribution as well as fertility rate, where increasing child survival allows the average income to increase as well as the average fertility rate to decrease.\n\n\n"}
{"id": "7472359", "url": "https://en.wikipedia.org/wiki?curid=7472359", "title": "Chronic care", "text": "Chronic care\n\nChronic care refers to medical care which addresses pre-existing or long term illness, as opposed to acute care which is concerned with short term or severe illness of brief duration. Chronic medical conditions include asthma, diabetes, emphysema, chronic bronchitis, congestive heart disease, cirrhosis of the liver, hypertension and depression. Without effective treatment chronic conditions may lead to disability.\n\nThe incidence of chronic disease has increased as mortality rates have decreased. It is estimated that by 2030 half of the population of the USA will have one or more chronic conditions.\n\nConditions, injuries and diseases which were previously fatal can now be treated with chronic care. Chronic care aims to maintain wellness by keeping symptoms in remission while balancing treatment regimes and quality of life. Many of the core functions of primary health care are central to chronic care. Chronic care is complex in nature because it may extend over a pro-longed period of time, requires input from a diverse set of health professionals, various medications and possibly monitoring equipment.\n\nAccording to 2008 figures from the Centers for Disease Control and Prevention chronic medical care accounts for more than 75% of health care spending in the US. In response to the increased government expenditure in dealing with chronic care policy makers are searching for effective interventions and strategies. These strategies can broadly be described within four categories. These are disease prevention and early detection, new providers, settings and qualifications, disease management programs and integrated care models.\n\nOne of the major problems from a health care system which is poorly coordinated for sufferers of chronic conditions is the incidence of patients receiving conflicting advice from different providers. Patients will often be given prescriptions for medication that adversely interact with\none another. One recent study estimated that more than 20% of older patients in the USA took at least one medication which could negatively impact another condition. This is referred to as therapeutic competition.\n\nEffective chronic care requires an information platform to track patients' status and ensure appropriate treatments are given.\n\nThere is a recognised gap between treatment guidelines and current practice for chronic care. Individualised treatment plans are critical in treating chronic conditions because patients will place varying important on health outcomes. For example, some patients will fore-go complex, inconvenient medication regimes at the expense of quality of life.\n\nOne of the greatest challenges in this field of health care is dealing with the co-existence of multiple disorders, which is called multi-morbidity. There are few incentives within current health care systems to coordinate care across multiple providers and varying services. A 2001 survey by Mathematica Policy Research found that physicians feel they have inadequate training to deal with multiple chronic conditions. An increase in the number of chronic conditions correlates with an increase in the number of inappropriate hospitalizations. Self-management can be challenging because recommended activities for one condition may be made difficult because of another condition.\n\nA nurse has to be qualified to handle all the needs of a chronic client and has to be an advocate to put the case of the chronically ill across to the health administration, hospital board or their families.\n\nA variety of specialists such as surgeons, dietitians, nutritionists, and occupational therapists have to be in attendance for the maximum benefit of the client. Someone suffering from chronic pain for a long time may need the help of a psychiatrist. Everyday activities that the physically fit see as normal may be a Herculean feat for the chronically ill and they need all the support that they can get. The nurse may be privy to some of these help that the chronically ill can benefit from. They need to be proactive and put these patients in contact with these help but also sensitive enough to give their client the freedom to decline any help if they think that they do not need it.\n\nChronic pain might also get the person to start questioning their faith and/or wanting to have a deeper spiritual experience because of their pain and suffering.\n\nThe patient also needs to take time to participate in some fun activities. They may need to check out of the facility/hospital or get out of the house occasionally preventing an association of hospitals with pain. This further helps the patients keep their sanity and keeps them psychologically sound.\n\nThey may need a nurse who is qualified in palliative care. Some may be dying and they need respect and dignity as they die in pain. They also need a nurse who is non-judgmental and one who is also compassionate and caring. The family has to be involved to help the client better manage the pain. One very important quality is co-ordinating the best care for the client and some amount of diplomacy and empathy.\n\nIn some cases, such as with diabetes or sleep apnea, the treatment is long term and difficult for patients to understand and comply with. In these cases chronic care management is highly recommended to help the patient learn about the consequences of refusing treatment and how to best follow treatment.\n\n"}
{"id": "5374", "url": "https://en.wikipedia.org/wiki?curid=5374", "title": "Condom", "text": "Condom\n\nA condom is a sheath-shaped barrier device, used during sexual intercourse to reduce the probability of pregnancy or a sexually transmitted infection (STI). There are both male and female condoms. With proper use—and use at every act of intercourse—women whose partners use male condoms experience a 2% per-year pregnancy rate. With typical use the rate of pregnancy is 18% per-year. Their use greatly decreases the risk of gonorrhea, chlamydia, trichomoniasis, hepatitis B, and HIV/AIDS. They also to a lesser extent protect against genital herpes, human papillomavirus (HPV), and syphilis.\nThe male condom is rolled onto an erect penis before intercourse and works by blocking semen from entering the body of a sexual partner. Male condoms are typically made from latex and less commonly from polyurethane or lamb intestine. Male condoms have the advantages of ease of use, easy to access, and few side effects. In those with a latex allergy a polyurethane or other synthetic version should be used. Female condoms are typically made from polyurethane and may be used multiple times.\nCondoms as a method of preventing STIs have been used since at least 1564. Rubber condoms become available in 1855, followed by latex condoms in the 1920s. They are on the World Health Organization's List of Essential Medicines, the most effective and safe medicines needed in a health system. The wholesale cost in the developing world is about 0.03 to 0.08 USD each. In the United States condoms usually cost less than 1.00 USD. Globally less than 10% of those using birth control are using the condom. Rates of condom use are higher in the developed world. In United Kingdom the condom is the second most common method of birth control (22%) while in the United States it is the third most common (15%). About six to nine billion are sold a year.\n\nThe effectiveness of condoms, as of most forms of contraception, can be assessed two ways. \"Perfect use\" or \"method\" effectiveness rates only include people who use condoms properly and consistently. \"Actual use\", or \"typical use\" effectiveness rates are of all condom users, including those who use condoms incorrectly or do not use condoms at every act of intercourse. Rates are generally presented for the first year of use. Most commonly the Pearl Index is used to calculate effectiveness rates, but some studies use decrement tables.\n\nThe typical use pregnancy rate among condom users varies depending on the population being studied, ranging from 10 to 18% per year. The perfect use pregnancy rate of condoms is 2% per year. Condoms may be combined with other forms of contraception (such as spermicide) for greater protection.\n\nCondoms are widely recommended for the prevention of sexually transmitted infections (STIs). They have been shown to be effective in reducing infection rates in both men and women. While not perfect, the condom is effective at reducing the transmission of organisms that cause AIDS, genital herpes, cervical cancer, genital warts, syphilis, chlamydia, gonorrhea, and other diseases. Condoms are often recommended as an adjunct to more effective birth control methods (such as IUD) in situations where STD protection is also desired.\n\nAccording to a 2000 report by the National Institutes of Health (NIH), consistent use of latex condoms reduces the risk of HIV/AIDS transmission by approximately 85% relative to risk when unprotected, putting the seroconversion rate (infection rate) at 0.9 per 100 person-years with condom, down from 6.7 per 100 person-years. Analysis published in 2007 from the University of Texas Medical Branch and the World Health Organization found similar risk reductions of 80–95%.\n\nThe 2000 NIH review concluded that condom use significantly reduces the risk of gonorrhea for men. A 2006 study reports that proper condom use decreases the risk of transmission of human papillomavirus (HPV) to women by approximately 70%. Another study in the same year found consistent condom use was effective at reducing transmission of herpes simplex virus-2 also known as genital herpes, in both men and women.\n\nAlthough a condom is effective in limiting exposure, some disease transmission may occur even with a condom. Infectious areas of the genitals, especially when symptoms are present, may not be covered by a condom, and as a result, some diseases like HPV and herpes may be transmitted by direct contact. The primary effectiveness issue with using condoms to prevent STDs, however, is inconsistent use.\n\nCondoms may also be useful in treating potentially precancerous cervical changes. Exposure to human papillomavirus, even in individuals already infected with the virus, appears to increase the risk of precancerous changes. The use of condoms helps promote regression of these changes. In addition, researchers in the UK suggest that a hormone in semen can aggravate existing cervical cancer, condom use during sex can prevent exposure to the hormone.\n\nCondoms may slip off the penis after ejaculation, break due to improper application or physical damage (such as tears caused when opening the package), or break or slip due to latex degradation (typically from usage past the expiration date, improper storage, or exposure to oils). The rate of breakage is between 0.4% and 2.3%, while the rate of slippage is between 0.6% and 1.3%. Even if no breakage or slippage is observed, 1–3% of women will test positive for semen residue after intercourse with a condom.\n\n\"Double bagging\", using two condoms at once, is often believed to cause a higher rate of failure due to the friction of rubber on rubber. This claim is not supported by research. The limited studies that have been done found that the simultaneous use of multiple condoms decreases the risk of condom breakage.\n\nDifferent modes of condom failure result in different levels of semen exposure. If a failure occurs during application, the damaged condom may be disposed of and a new condom applied before intercourse begins – such failures generally pose no risk to the user. One study found that semen exposure from a broken condom was about half that of unprotected intercourse; semen exposure from a slipped condom was about one-fifth that of unprotected intercourse.\n\nStandard condoms will fit almost any penis, with varying degrees of comfort or risk of slippage. Many condom manufacturers offer \"snug\" or \"magnum\" sizes. Some manufacturers also offer custom sized-to-fit condoms, with claims that they are more reliable and offer improved sensation/comfort. Some studies have associated larger penises and smaller condoms with increased breakage and decreased slippage rates (and vice versa), but other studies have been inconclusive.\n\nIt is recommended for condoms manufacturers to avoid very thick or very thin condoms, because they are both considered less effective. Some authors encourage users to choose thinner condoms \"for greater durability, sensation, and comfort\", but others warn that \"the thinner the condom, the smaller the force required to break it\".\n\nExperienced condom users are significantly less likely to have a condom slip or break compared to first-time users, although users who experience one slippage or breakage are more likely to suffer a second such failure. An article in \"Population Reports\" suggests that education on condom use reduces behaviors that increase the risk of breakage and slippage. A Family Health International publication also offers the view that education can reduce the risk of breakage and slippage, but emphasizes that more research needs to be done to determine all of the causes of breakage and slippage.\n\nAmong people who intend condoms to be their form of birth control, pregnancy may occur when the user has sex without a condom. The person may have run out of condoms, or be traveling and not have a condom with them, or simply dislike the feel of condoms and decide to \"take a chance\". This type of behavior is the primary cause of typical use failure (as opposed to method or perfect use failure).\n\nAnother possible cause of condom failure is sabotage. One motive is to have a child against a partner's wishes or consent. Some commercial sex workers from Nigeria reported clients sabotaging condoms in retaliation for being coerced into condom use. Using a fine needle to make several pinholes at the tip of the condom is believed to significantly impact on their effectiveness. Cases of such condom sabotage have occurred.\n\nThe use of latex condoms by people with an allergy to latex can cause allergic symptoms, such as skin irritation. In people with severe latex allergies, using a latex condom can potentially be life-threatening. Repeated use of latex condoms can also cause the development of a latex allergy in some people. Irritation may also occur due to spermicides that may be present.\n\nMale condoms are usually packaged inside a foil or plastic wrapper, in a rolled-up form, and are designed to be applied to the tip of the penis and then unrolled over the erect penis. It is important that some space be left in the tip of the condom so that semen has a place to collect; otherwise it may be forced out of the base of the device. Most condoms have a teat end for this purpose. After use, it is recommended the condom be wrapped in tissue or tied in a knot, then disposed of in a trash receptacle. Condoms are used to reduce the likelihood of pregnancy during intercourse and to reduce the likelihood of contracting sexually-transmitted infections (STIs). Condoms are also used during fellatio to reduce the likelihood of contracting STIs.\n\nSome couples find that putting on a condom interrupts sex, although others incorporate condom application as part of their foreplay. Some men and women find the physical barrier of a condom dulls sensation. Advantages of dulled sensation can include prolonged erection and delayed ejaculation; disadvantages might include a loss of some sexual excitement. Advocates of condom use also cite their advantages of being inexpensive, easy to use, and having few side effects.\n\nIn 2012 proponents gathered 372,000 voter signatures through a citizens' initiative in Los Angeles County to put Measure B on the 2012 ballot. As a result, Measure B, a law requiring the use of condoms in the production of pornographic films, was passed. This requirement has received much criticism and is said by some to be counter-productive, merely forcing companies that make pornographic films to relocate to other places without this requirement. Producers claim that condom use depresses sales.\n\nCondoms are often used in sex education programs, because they have the capability to reduce the chances of pregnancy and the spread of some sexually transmitted diseases when used correctly. A recent American Psychological Association (APA) press release supported the inclusion of information about condoms in sex education, saying \"\"comprehensive sexuality education programs... discuss the appropriate use of condoms\", and \"promote condom use for those who are sexually active\".\"\n\nIn the United States, teaching about condoms in public schools is opposed by some religious organizations. Planned Parenthood, which advocates family planning and sex education, argues that no studies have shown abstinence-only programs to result in delayed intercourse, and cites surveys showing that 76% of American parents want their children to receive comprehensive sexuality education including condom use.\n\nCommon procedures in infertility treatment such as semen analysis and intrauterine insemination (IUI) require collection of semen samples. These are most commonly obtained through masturbation, but an alternative to masturbation is use of a special \"collection condom\" to collect semen during sexual intercourse.\n\nCollection condoms are made from silicone or polyurethane, as latex is somewhat harmful to sperm. Many men prefer collection condoms to masturbation, and some religions prohibit masturbation entirely. Also, compared with samples obtained from masturbation, semen samples from collection condoms have higher total sperm counts, sperm motility, and percentage of sperm with normal morphology. For this reason, they are believed to give more accurate results when used for semen analysis, and to improve the chances of pregnancy when used in procedures such as intracervical or intrauterine insemination. Adherents of religions that prohibit contraception, such as Catholicism, may use collection condoms with holes pricked in them.\n\nFor fertility treatments, a collection condom may be used to collect semen during sexual intercourse where the semen is provided by the woman's partner. Private sperm donors may also use a collection condom to obtain samples through masturbation or by sexual intercourse with a partner and will transfer the ejaculate from the collection condom to a specially designed container. The sperm is transported in such containers, in the case of a donor, to a recipient woman to be used for insemination, and in the case of a woman's partner, to a fertility clinic for processing and use. However, transportation may reduce the fecundity of the sperm. Collection condoms may also be used where semen is produced at a sperm bank or fertility clinic.\n\n\"Condom therapy\" is sometimes prescribed to infertile couples when the female has high levels of antisperm antibodies. The theory is that preventing exposure to her partner's semen will lower her level of antisperm antibodies, and thus increase her chances of pregnancy when condom therapy is discontinued. However, condom therapy has not been shown to increase subsequent pregnancy rates.\n\nCondoms excel as multipurpose containers and barriers because they are waterproof, elastic, durable, and (for military and espionage uses) will not arouse suspicion if found.\n\nOngoing military utilization began during World War II, and includes covering the muzzles of rifle barrels to prevent fouling, the waterproofing of firing assemblies in underwater demolitions, and storage of corrosive materials and garrotes by paramilitary agencies.\n\nCondoms have also been used to smuggle alcohol, cocaine, heroin, and other drugs across borders and into prisons by filling the condom with drugs, tying it in a knot and then either swallowing it or inserting it into the rectum. These methods are very dangerous and potentially lethal; if the condom breaks, the drugs inside become absorbed into the bloodstream and can cause an overdose.\n\nMedically, condoms can be used to cover endovaginal ultrasound probes, or in field chest needle decompressions they can be used to make a one-way valve.\n\nCondoms have also been used to protect scientific samples from the environment, and to waterproof microphones for underwater recording.\n\nMost condoms have a reservoir tip or teat end, making it easier to accommodate the man's ejaculate. Condoms come in different sizes, from snug to larger, and shapes. Width often varies from 49 mm to 56 mm. Sizes from 45 mm to 60 mm, however exist.\n\nThey also come in a variety of surfaces intended to stimulate the user's partner. Condoms are usually supplied with a lubricant coating to facilitate penetration, while flavored condoms are principally used for oral sex. As mentioned above, most condoms are made of latex, but polyurethane and lambskin condoms also exist.\n\nMale condoms have a tight ring to form a seal around the penis while female condoms usually have a large stiff ring to prevent them from slipping into the body orifice. The Female Health Company produced a female condom that was initially made of polyurethane, but newer versions are made of nitrile. Medtech Products produces a female condom made of latex.\n\nLatex has outstanding elastic properties: Its tensile strength exceeds 30 MPa, and latex condoms may be stretched in excess of 800% before breaking. In 1990 the ISO set standards for condom production (ISO 4074, Natural latex rubber condoms), and the EU followed suit with its CEN standard (Directive 93/42/EEC concerning medical devices). Every latex condom is tested for holes with an electric current. If the condom passes, it is rolled and packaged. In addition, a portion of each batch of condoms is subject to water leak and air burst testing.\n\nWhile the advantages of latex have made it the most popular condom material, it does have some drawbacks. Latex condoms are damaged when used with oil-based substances as lubricants, such as petroleum jelly, cooking oil, baby oil, mineral oil, skin lotions, suntan lotions, cold creams, butter or margarine. Contact with oil makes latex condoms more likely to break or slip off due to loss of elasticity caused by the oils. Additionally, latex allergy precludes use of latex condoms and is one of the principal reasons for the use of other materials. In May 2009 the U.S. Food and Drug Administration granted approval for the production of condoms composed of Vytex, latex that has been treated to remove 90% of the proteins responsible for allergic reactions. An allergen-free condom made of synthetic latex (polyisoprene) is also available.\n\nThe most common non-latex condoms are made from polyurethane. Condoms may also be made from other synthetic materials, such as AT-10 resin, and most recently polyisoprene.\n\nPolyurethane condoms tend to be the same width and thickness as latex condoms, with most polyurethane condoms between 0.04 mm and 0.07 mm thick.\n\nPolyurethane can be considered better than latex in several ways: it conducts heat better than latex, is not as sensitive to temperature and ultraviolet light (and so has less rigid storage requirements and a longer shelf life), can be used with oil-based lubricants, is less allergenic than latex, and does not have an odor. Polyurethane condoms have gained FDA approval for sale in the United States as an effective method of contraception and HIV prevention, and under laboratory conditions have been shown to be just as effective as latex for these purposes.\n\nHowever, polyurethane condoms are less elastic than latex ones, and may be more likely to slip or break than latex, lose their shape or bunch up more than latex, and are more expensive.\n\nPolyisoprene is a synthetic version of natural rubber latex. While significantly more expensive, it has the advantages of latex (such as being softer and more elastic than polyurethane condoms) without the protein which is responsible for latex allergies. Like polyurethane condoms, polyisoprene condoms are said to do a better job of transmitting body heat. Unlike polyurethane condoms, they cannot be used with an oil-based lubricant.\n\nCondoms made from sheep intestines, labeled \"lambskin\", are also available. Although they are generally effective as a contraceptive by blocking sperm, it is presumed that they are likely less effective than latex in preventing the transmission of agents that cause STDs, because of pores in the material. This is based on the idea that intestines, by their nature, are porous, permeable membranes, and while sperm are too large to pass through the pores, viruses—such as HIV, herpes, and genital warts—are small enough to pass through. However, there are to date no clinical data confirming or denying this theory. Some believe that lambskin condoms provide a more \"natural\" sensation, and they lack the allergens that are inherent to latex, but because of their lesser protection against infection, other hypoallergenic materials such as polyurethane are recommended for latex-allergic users and/or partners. Lambskin condoms are also significantly more expensive than other types and as slaughter by-products they are also not vegetarian.\n\nSome latex condoms are lubricated at the manufacturer with a small amount of a nonoxynol-9, a spermicidal chemical. According to Consumer Reports, condoms lubricated with spermicide have no additional benefit in preventing pregnancy, have a shorter shelf life, and may cause urinary-tract infections in women. In contrast, application of separately packaged spermicide \"is\" believed to increase the contraceptive efficacy of condoms.\n\nNonoxynol-9 was once believed to offer additional protection against STDs (including HIV) but recent studies have shown that, with frequent use, nonoxynol-9 may increase the risk of HIV transmission. The World Health Organization says that spermicidally lubricated condoms should no longer be promoted. However, it recommends using a nonoxynol-9 lubricated condom over no condom at all. , nine condom manufacturers have stopped manufacturing condoms with nonoxynol-9 and Planned Parenthood has discontinued the distribution of condoms so lubricated.\n\nTextured condoms include studded and ribbed condoms which can provide extra sensations to both partners. The studs or ribs can be located on the inside, outside, or both; alternatively, they are located in specific sections to provide directed stimulation to either the g-spot or frenulum. Many textured condoms which advertise \"mutual pleasure\" also are bulb-shaped at the top, to provide extra stimulation to the penis. Some women experience irritation during vaginal intercourse with studded condoms.\n\nThe anti-rape condom is another variation designed to be worn by women. It is designed to cause pain to the attacker, hopefully allowing the victim a chance to escape.\n\nA collection condom is used to collect semen for fertility treatments or sperm analysis. These condoms are designed to maximize sperm life.\n\nSome condom-like devices are intended for entertainment only, such as glow-in-the dark condoms. These novelty condoms may not provide protection against pregnancy and STDs.\n\nThe prevalence of condom use varies greatly between countries. Most surveys of contraceptive use are among married women, or women in informal unions. Japan has the highest rate of condom usage in the world: in that country, condoms account for almost 80% of contraceptive use by married women. On average, in developed countries, condoms are the most popular method of birth control: 28% of married contraceptive users rely on condoms. In the average less-developed country, condoms are less common: only 6–8% of married contraceptive users choose condoms.\n\nWhether condoms were used in ancient civilizations is debated by archaeologists and historians. In ancient Egypt, Greece, and Rome, pregnancy prevention was generally seen as a woman's responsibility, and the only well documented contraception methods were female-controlled devices. In Asia before the 15th century, some use of glans condoms (devices covering only the head of the penis) is recorded. Condoms seem to have been used for contraception, and to have been known only by members of the upper classes. In China, glans condoms may have been made of oiled silk paper, or of lamb intestines. In Japan, they were made of tortoise shell or animal horn.\n\nIn 16th-century Italy, anatomist and physician Gabriele Falloppio wrote a treatise on syphilis. The earliest documented strain of syphilis, first appearing in Europe in a 1490s outbreak, caused severe symptoms and often death within a few months of contracting the disease. Falloppio's treatise is the earliest uncontested description of condom use: it describes linen sheaths soaked in a chemical solution and allowed to dry before use. The cloths he described were sized to cover the glans of the penis, and were held on with a ribbon. Falloppio claimed that an experimental trial of the linen sheath demonstrated protection against syphilis.\n\nAfter this, the use of penis coverings to protect from disease is described in a wide variety of literature throughout Europe. The first indication that these devices were used for birth control, rather than disease prevention, is the 1605 theological publication \"De iustitia et iure\" (On justice and law) by Catholic theologian Leonardus Lessius, who condemned them as immoral. In 1666, the English Birth Rate Commission attributed a recent downward fertility rate to use of \"condons\", the first documented use of that word (or any similar spelling). (Other early spellings include \"condam\" and \"quondam\", from which the Italian derivation \"guantone\" has been suggested, from \"guanto\", \"a glove.\")\nIn addition to linen, condoms during the Renaissance were made out of intestines and bladder. In the late 16th century, Dutch traders introduced condoms made from \"fine leather\" to Japan. Unlike the horn condoms used previously, these leather condoms covered the entire penis.\nCasanova in the 18th century was one of the first reported using \"assurance caps\" to prevent impregnating his mistresses.\n\nFrom at least the 18th century, condom use was opposed in some legal, religious, and medical circles for essentially the same reasons that are given today: condoms reduce the likelihood of pregnancy, which some thought immoral or undesirable for the nation; they do not provide full protection against sexually transmitted infections, while belief in their protective powers was thought to encourage sexual promiscuity; and, they are not used consistently due to inconvenience, expense, or loss of sensation.\n\nDespite some opposition, the condom market grew rapidly. In the 18th century, condoms were available in a variety of qualities and sizes, made from either linen treated with chemicals, or \"skin\" (bladder or intestine softened by treatment with sulfur and lye). They were sold at pubs, barbershops, chemist shops, open-air markets, and at the theater throughout Europe and Russia. They later spread to America, although in every place there were generally used only by the middle and upper classes, due to both expense and lack of sex education.\n\nThe early 19th century saw contraceptives promoted to the poorer classes for the first time. Writers on contraception tended to prefer other methods of birth control to the condom. By the late 19th century many feminists expressed distrust of the condom as a contraceptive, as its use was controlled and decided upon by men alone. They advocated instead for methods which were controlled by women, such as diaphragms and spermicidal douches. Other writers cited both the expense of condoms and their unreliability (they were often riddled with holes, and often fell off or broke), but they discussed condoms as a good option for some, and as the only contraceptive that also protected from disease.\n\nMany countries passed laws impeding the manufacture and promotion of contraceptives. In spite of these restrictions, condoms were promoted by traveling lecturers and in newspaper advertisements, using euphemisms in places where such ads were illegal. Instructions on how to make condoms at home were distributed in the United States and Europe. Despite social and legal opposition, at the end of the 19th century the condom was the Western world's most popular birth control method.\nBeginning in the second half of the 19th century, American rates of sexually transmitted diseases skyrocketed. Causes cited by historians include effects of the American Civil War, and the ignorance of prevention methods promoted by the Comstock laws. To fight the growing epidemic, sex education classes were introduced to public schools for the first time, teaching about venereal diseases and how they were transmitted. They generally taught that abstinence was the only way to avoid sexually transmitted diseases. Condoms were not promoted for disease prevention because the medical community and moral watchdogs considered STDs to be punishment for sexual misbehavior. The stigma against victims of these diseases was so great that many hospitals refused to treat people who had syphilis.\nThe German military was the first to promote condom use among its soldiers, beginning in the later 19th century. Early 20th century experiments by the American military concluded that providing condoms to soldiers significantly lowered rates of sexually transmitted diseases. During World War I, the United States and (at the beginning of the war only) Britain were the only countries with soldiers in Europe who did not provide condoms and promote their use.\n\nIn the decades after World War I, there remained social and legal obstacles to condom use throughout the U.S. and Europe. Founder of psychoanalysis Sigmund Freud opposed all methods of birth control on the grounds that their failure rates were too high. Freud was especially opposed to the condom because he thought it cut down on sexual pleasure. Some feminists continued to oppose male-controlled contraceptives such as condoms. In 1920 the Church of England's Lambeth Conference condemned all \"unnatural means of conception avoidance\". London's Bishop Arthur Winnington-Ingram complained of the huge number of condoms discarded in alleyways and parks, especially after weekends and holidays.\n\nHowever, European militaries continued to provide condoms to their members for disease protection, even in countries where they were illegal for the general population. Through the 1920s, catchy names and slick packaging became an increasingly important marketing technique for many consumer items, including condoms and cigarettes. Quality testing became more common, involving filling each condom with air followed by one of several methods intended to detect loss of pressure. Worldwide, condom sales doubled in the 1920s.\n\nIn 1839, Charles Goodyear discovered a way of processing natural rubber, which is too stiff when cold and too soft when warm, in such a way as to make it elastic. This proved to have advantages for the manufacture of condoms; unlike the sheep's gut condoms, they could stretch and did not tear quickly when used. The rubber vulcanization process was patented by Goodyear in 1844. The first rubber condom was produced in 1855. The earliest rubber condoms had a seam and were as thick as a bicycle inner tube. Besides this type, small rubber condoms covering only the glans were often used in England and the United States. There was more risk of losing them and if the rubber ring was too tight, it would constrict the penis. This type of condom was the original \"capote\" (French for condom), perhaps because of its resemblance to a woman's bonnet worn at that time, also called a capote.\n\nFor many decades, rubber condoms were manufactured by wrapping strips of raw rubber around penis-shaped molds, then dipping the wrapped molds in a chemical solution to cure the rubber. In 1912, Polish inventor Julius Fromm developed a new, improved manufacturing technique for condoms: dipping glass molds into a raw rubber solution. Called \"cement dipping\", this method required adding gasoline or benzene to the rubber to make it liquid. Latex, rubber suspended in water, was invented in 1920. Latex condoms required less labor to produce than cement-dipped rubber condoms, which had to be smoothed by rubbing and trimming. The use of water to suspend the rubber instead of gasoline and benzene eliminated the fire hazard previously associated with all condom factories. Latex condoms also performed better for the consumer: they were stronger and thinner than rubber condoms, and had a shelf life of five years (compared to three months for rubber).\n\nUntil the twenties, all condoms were individually hand-dipped by semi-skilled workers. Throughout the decade of the 1920s, advances in the automation of the condom assembly line were made. The first fully automated line was patented in 1930. Major condom manufacturers bought or leased conveyor systems, and small manufacturers were driven out of business. The skin condom, now significantly more expensive than the latex variety, became restricted to a niche high-end market.\n\nIn 1930 the Anglican Church's sanctioned the use of birth control by married couples. In 1931 the Federal Council of Churches in the U.S. issued a similar statement. The Roman Catholic Church responded by issuing the encyclical \"Casti connubii\" affirming its opposition to all contraceptives, a stance it has never reversed. In the 1930s, legal restrictions on condoms began to be relaxed. But during this period Fascist Italy and Nazi Germany increased restrictions on condoms (limited sales as disease preventatives were still allowed). During the Depression, condom lines by Schmid gained in popularity. Schmid still used the cement-dipping method of manufacture which had two advantages over the latex variety. Firstly, cement-dipped condoms could be safely used with oil-based lubricants. Secondly, while less comfortable, these older-style rubber condoms could be reused and so were more economical, a valued feature in hard times. More attention was brought to quality issues in the 1930s, and the U.S. Food and Drug Administration began to regulate the quality of condoms sold in the United States.\n\nThroughout World War II, condoms were not only distributed to male U.S. military members, but also heavily promoted with films, posters, and lectures. European and Asian militaries on both sides of the conflict also provided condoms to their troops throughout the war, even Germany which outlawed all civilian use of condoms in 1941. In part because condoms were readily available, soldiers found a number of non-sexual uses for the devices, many of which continue to this day. After the war, condom sales continued to grow. From 1955–1965, 42% of Americans of reproductive age relied on condoms for birth control. In Britain from 1950–1960, 60% of married couples used condoms. The birth control pill became the world's most popular method of birth control in the years after its 1960 début, but condoms remained a strong second. The U.S. Agency for International Development pushed condom use in developing countries to help solve the \"world population crises\": by 1970 hundreds of millions of condoms were being used each year in India alone.(This number has grown in recent decades: in 2004, the government of India purchased 1.9 billion condoms for distribution at family planning clinics.)\n\nIn the 1960s and 1970s quality regulations tightened, and more legal barriers to condom use were removed. In Ireland, legal condom sales were allowed for the first time in 1978. Advertising, however was one area that continued to have legal restrictions. In the late 1950s, the American National Association of Broadcasters banned condom advertisements from national television: this policy remained in place until 1979.\n\nAfter learning in the early 1980s that AIDS can be a sexually transmitted infection, the use of condoms was encouraged to prevent transmission of HIV. Despite opposition by some political, religious, and other figures, national condom promotion campaigns occurred in the U.S. and Europe. These campaigns increased condom use significantly.\n\nDue to increased demand and greater social acceptance, condoms began to be sold in a wider variety of retail outlets, including in supermarkets and in discount department stores such as Wal-Mart. Condom sales increased every year until 1994, when media attention to the AIDS pandemic began to decline. The phenomenon of decreasing use of condoms as disease preventatives has been called \"prevention fatigue\" or \"condom fatigue\". Observers have cited condom fatigue in both Europe and North America. As one response, manufacturers have changed the tone of their advertisements from scary to humorous.\n\nNew developments continued to occur in the condom market, with the first polyurethane condom—branded Avanti and produced by the manufacturer of Durex—introduced in the 1990s. Worldwide condom use is expected to continue to grow: one study predicted that developing nations would need 18.6 billion condoms by 2015. , condoms are available inside prisons in Canada, most of the European Union, Australia, Brazil, Indonesia, South Africa, and the US states of Vermont (on September 17, 2013, the Californian Senate approved a bill for condom distribution inside the state's prisons, but the bill was not yet law at the time of approval).\n\nThe term \"condom\" first appears in the early 18th century. Its etymology is unknown.\nIn popular tradition, the invention and naming of the condom came to be attributed to an associate of England's King Charles II, one \"Dr. Condom\" or \"Earl of Condom\". There is however no evidence of the existence of such a person, and condoms had been used for over one hundred years before King Charles II ascended to the throne.\n\nA variety of unproven Latin etymologies have been proposed, including \"condon\" (receptacle), \"condamina\" (house), and \"cumdum\" (scabbard or case). It has also been speculated to be from the Italian word \"guantone\", derived from \"guanto\", meaning glove. William E. Kruck wrote an article in 1981 concluding that, \"As for the word 'condom', I need state only that its origin remains completely unknown, and there ends this search for an etymology.\" Modern dictionaries may also list the etymology as \"unknown\".\nOther terms are also commonly used to describe condoms. In North America condoms are also commonly known as \"prophylactics\", or \"rubbers\". In Britain they may be called \"French letters\". Additionally, condoms may be referred to using the manufacturer's name.\n\nSome moral and scientific criticism of condoms exists despite the many benefits of condoms agreed on by scientific consensus and sexual health experts.\n\nCondom usage is typically recommended for new couples who have yet to develop full trust in their partner with regard to STDs. Established couples on the other hand have few concerns about STDs, and can use other methods of birth control such as the pill, which does not act as a barrier to intimate sexual contact. Note that the polar debate with regard to condom usage is attenuated by the target group the argument is directed. Notably the age category and stable partner question are factors, as well as the distinction between heterosexual and homosexuals, who have different kinds of sex and have different risk consequences and factors.\n\nAmong the prime objections to condom usage is the blocking of erotic sensation, or the intimacy that barrier-free sex provides. As the condom is held tightly to the skin of the penis, it diminishes the delivery of stimulation through rubbing and friction. Condom proponents claim this has the benefit of making sex last longer, by diminishing sensation and delaying male ejaculation. Those who promote condom-free heterosexual sex (slang: \"bareback\") claim that the condom puts a prophylactic barrier between partners, diminishing what is normally a highly sensual, intimate, and spiritual connection between partners.\n\nThe Roman Catholic Church opposes all kinds of sexual acts outside of marriage, as well as any sexual act in which the chance of successful conception has been reduced by direct and intentional acts (for example, surgery to prevent conception) or foreign objects (for example, condoms).\n\nThe use of condoms to prevent STI transmission is not specifically addressed by Catholic doctrine, and is currently a topic of debate among theologians and high-ranking Catholic authorities. A few, such as Belgian Cardinal Godfried Danneels, believe the Catholic Church should actively support condoms used to prevent disease, especially serious diseases such as AIDS. However, the majority view—including all statements from the Vatican—is that condom-promotion programs encourage promiscuity, thereby actually increasing STI transmission. This view was most recently reiterated in 2009 by Pope Benedict XVI.\n\nThe Roman Catholic Church is the largest organized body of any world religion. The church has hundreds of programs dedicated to fighting the AIDS epidemic in Africa, but its opposition to condom use in these programs has been highly controversial.\n\nIn a November 2011 interview, Pope Benedict XVI discussed for the first time the use of condoms to prevent STI transmission. He said that the use of a condom can be justified in a few individual cases if the purpose is to reduce the risk of an HIV infection. He gave as an example male prostitutes. There was some confusion at first whether the statement applied only to homosexual prostitutes and thus not to heterosexual intercourse at all. However, Federico Lombardi, spokesman for the Vatican, clarified that it applied to heterosexual and transsexual prostitutes, whether male or female, as well. He did, however, also clarify that the Vatican's principles on sexuality and contraception had not been changed.\n\nMore generally, some scientific researchers have expressed objective concern over certain ingredients sometimes added to condoms, notably talc and nitrosamines. Dry dusting powders are applied to latex condoms before packaging to prevent the condom from sticking to itself when rolled up. Previously, talc was used by most manufacturers, but cornstarch is currently the most popular dusting powder. Talc is known to be toxic if it enters the abdominal cavity (i.e., via the vagina). Cornstarch is generally believed to be safe; however, some researchers have raised concerns over its use as well.\n\nNitrosamines, which are potentially carcinogenic in humans, are believed to be present in a substance used to improve elasticity in latex condoms. A 2001 review stated that humans regularly receive 1,000 to 10,000 times greater nitrosamine exposure from food and tobacco than from condom use and concluded that the risk of cancer from condom use is very low. However, a 2004 study in Germany detected nitrosamines in 29 out of 32 condom brands tested, and concluded that exposure from condoms might exceed the exposure from food by 1.5- to 3-fold.\n\nIn addition, the large-scale use of disposable condoms has resulted in concerns over their environmental impact via littering and in landfills, where they can eventually wind up in wildlife environments if not incinerated or otherwise permanently disposed of first. Polyurethane condoms in particular, given they are a form of plastic, are not biodegradable, and latex condoms take a very long time to break down. Experts, such as AVERT, recommend condoms be disposed of in a garbage receptacle, as flushing them down the toilet (which some people do) may cause plumbing blockages and other problems. Furthermore, the plastic and foil wrappers condoms are packaged in are also not biodegradable. However, the benefits condoms offer are widely considered to offset their small landfill mass. Frequent condom or wrapper disposal in public areas such as a parks have been seen as a persistent litter problem.\n\nWhile biodegradable, latex condoms damage the environment when disposed of improperly. According to the Ocean Conservancy, condoms, along with certain other types of trash, cover the coral reefs and smother sea grass and other bottom dwellers. The United States Environmental Protection Agency also has expressed concerns that many animals might mistake the litter for food.\n\nIn much of the Western world, the introduction of the pill in the 1960s was associated with a decline in condom use. In Japan, oral contraceptives were not approved for use until September 1999, and even then access was more restricted than in other industrialized nations. Perhaps because of this restricted access to hormonal contraception, Japan has the highest rate of condom usage in the world: in 2008, 80% of contraceptive users relied on condoms.\n\nCultural attitudes toward gender roles, contraception, and sexual activity vary greatly around the world, and range from extremely conservative to extremely liberal. But in places where condoms are misunderstood, mischaracterised, demonised, or looked upon with overall cultural disapproval, the prevalence of condom use is directly affected. In less-developed countries and among less-educated populations, misperceptions about how disease transmission and conception work negatively affect the use of condoms; additionally, in cultures with more traditional gender roles, women may feel uncomfortable demanding that their partners use condoms.\n\nAs an example, Latino immigrants in the United States often face cultural barriers to condom use. A study on female HIV prevention published in the \"Journal of Sex Health Research\" asserts that Latino women often lack the attitudes needed to negotiate safe sex due to traditional gender-role norms in the Latino community, and may be afraid to bring up the subject of condom use with their partners. Women who participated in the study often reported that because of the general machismo subtly encouraged in Latino culture, their male partners would be angry or possibly violent at the woman's suggestion that they use condoms. A similar phenomenon has been noted in a survey of low-income American black women; the women in this study also reported a fear of violence at the suggestion to their male partners that condoms be used.\n\nA telephone survey conducted by Rand Corporation and Oregon State University, and published in the \"Journal of Acquired Immune Deficiency Syndromes\" showed that belief in AIDS conspiracy theories among United States black men is linked to rates of condom use. As conspiracy beliefs about AIDS grow in a given sector of these black men, consistent condom use drops in that same sector. Female use of condoms was not similarly affected.\n\nIn the African continent, condom promotion in some areas has been impeded by anti-condom campaigns by some Muslim and Catholic clerics. Among the Maasai in Tanzania, condom use is hampered by an aversion to \"wasting\" sperm, which is given sociocultural importance beyond reproduction. Sperm is believed to be an \"elixir\" to women and to have beneficial health effects. Maasai women believe that, after conceiving a child, they must have sexual intercourse repeatedly so that the additional sperm aids the child's development. Frequent condom use is also considered by some Maasai to cause impotence. Some women in Africa believe that condoms are \"for prostitutes\" and that respectable women should not use them. A few clerics even promote the idea that condoms are deliberately laced with HIV. In the United States, possession of many condoms has been used by police to accuse women of engaging in prostitution. The Presidential Advisory Council on HIV/AIDS has condemned this practice and there are efforts to end it.\n\nIn March 2013, technology mogul Bill Gates offered a US$100,000 grant through his foundation for a condom design that \"significantly preserves or enhances pleasure\" to encourage more males to adopt the use of condoms for safer sex. The grant information states: \"The primary drawback from the male perspective is that condoms decrease pleasure as compared to no condom, creating a trade-off that many men find unacceptable, particularly given that the decisions about use must be made just prior to intercourse. Is it possible to develop a product without this stigma, or better, one that is felt to enhance pleasure?\". The project has been named the \"Next Generation Condom\" and anyone who can provide a \"testable hypothesis\" is eligible to apply.\n\nMiddle-Eastern couples who have not had children, because of the strong desire and social pressure to establish fertility as soon as possible within marriage, rarely use condoms.\n\nIn 2017, India restricted TV advertisements for condoms to between the hours of 10PM to 6AM. Family planning advocates were against this, saying it was liable to \"undo decades of progress on sexual and reproductive health\".\n\nOne analyst described the size of the condom market as something that \"boggles the mind\". Numerous small manufacturers, nonprofit groups, and government-run manufacturing plants exist around the world. Within the condom market, there are several major contributors, among them both for-profit businesses and philanthropic organizations. Most large manufacturers have ties to the business that reach back to the end of the 19th century.\n\nA spray-on condom made of latex is intended to be easier to apply and more successful in preventing the transmission of diseases. , the spray-on condom was not going to market because the drying time could not be reduced below two to three minutes.\n\nThe Invisible Condom, developed at Université Laval in Quebec, Canada, is a gel that hardens upon increased temperature after insertion into the vagina or rectum. In the lab, it has been shown to effectively block HIV and herpes simplex virus. The barrier breaks down and liquefies after several hours. , the invisible condom is in the clinical trial phase, and has not yet been approved for use.\n\nAlso developed in 2005 is a condom treated with an erectogenic compound. The drug-treated condom is intended to help the wearer maintain his erection, which should also help reduce slippage. If approved, the condom would be marketed under the Durex brand. , it was still in clinical trials. In 2009, Ansell Healthcare, the makers of Lifestyle condoms, introduced the X2 condom lubricated with \"Excite Gel\" which contains the amino acid l-arginine and is intended to improve the strength of the erectile response.\n\n"}
{"id": "2596487", "url": "https://en.wikipedia.org/wiki?curid=2596487", "title": "Diamond plate", "text": "Diamond plate\n\nDiamond plate, also known as checker plate, tread plate and Durbar floor plate, is a type of metal stock with a regular pattern of raised diamonds or lines on one side, with the reverse side being featureless. Diamond plate is usually steel, stainless steel or aluminum. Steel types are normally made by hot rolling, although modern manufacturers also make a raised and pressed diamond design.\n\nThe added texture reduces the risk of slipping, making diamond plate a solution for stairs, catwalks, walkways, and ramps in industrial settings. Its non-skid properties mean that diamond plate is frequently used on the interior of ambulances and on the footplates of firetrucks. Additional applications include truck beds and trailer floors. \n\nDiamond plate can also be used decoratively, particularly highly polished aluminum variants. Manufactured in plastic, diamond plate is marketed as an interlocking tile system to be installed on garage floors, trailers, and exercise rooms.\n\nDiamond plate may be used for surface protection against damage from foot traffic or harmful chemicals. Manufactured with polymer variants, inter-locking diamond plate tile is used in areas with high surface-erosive traffic.\n\nTata Steel marketed the plate as Durbar Plate.\n\n\"Diamond plate\" can also refer to similar anti-slip textures.\n\n"}
{"id": "51850608", "url": "https://en.wikipedia.org/wiki?curid=51850608", "title": "Digital therapeutics", "text": "Digital therapeutics\n\nDigital therapeutics, a subset of digital health, is a health discipline and treatment option that utilizes a digital and often online health technologies to treat a medical or psychological condition. The treatment relies on behavioral and lifestyle changes usually spurred by a collection of digital impetuses. Because of the digital nature of the methodology, data can be collected and analyzed as both a progress report and a preventative measure. Treatments are being developed for the prevention and management of a wide variety of diseases and conditions, including type II diabetes, congestive heart failure, obesity, Alzheimer's disease, dementia, asthma, substance abuse, ADHD, panic attacks, anxiety, depression, and several others. Digital therapeutics often employ strategies rooted in cognitive behavioral therapy.\n\nAlthough digital therapeutics can be employed in numerous ways, the term can broadly be defined as a treatment or therapy that utilizes digital and often Internet-based health technologies to spur changes in patient behavior. The use of digital products to improve health outcomes dates as far back as 2000. The term itself has been in use since around 2012. The first mention of the term in a peer-reviewed research publication was in 2015, in which Dr. Cameron Sepah formally defined the field as: \"Digital therapeutics are evidence-based behavioral treatments delivered online that can increase accessibility and effectiveness of health care.\" Digital therapeutics can be used as a standalone therapy or in conjunction with more conventional treatments like pharmacological or in-person therapy. As of 2018, digital therapeutics continues to be an evolving field that medical professionals, students, and patients are beginning to utilize.\n\nIt is often used as a preventive measure for patients who are at risk of developing more serious conditions. For instance, a patient with prediabetes may be prescribed digital therapeutics as a method to change their diet and behavior that could otherwise lead to a diabetes diagnosis. Digital therapeutics can also be used as a treatment option for existing conditions. For instance, a patient with type II diabetes can use digital therapeutics to manage the disease more effectively.\n\nThe methodology uses a variety of digital implements to help manage, monitor, and prevent illnesses in at-risk patients. These include mobile devices and technologies, apps, sensors, desktop computers, and various Internet of Things devices. These implements can collect a wide variety of data, ranging from big to small. Digital therapeutics can theoretically collect a high volume of data from a variety of sources. It also collects \"smaller\" data, \"capturing personalized physiological parameters, behavior patterns and social and geographical patterns that can be recorded from multiple digital sources.\"\n\nDigital therapeutics can be used for a variety of conditions. There is no single methodology used in the practice of digital therapeutics. It uses methods rooted in cognitive behavioral therapy to spur patients to make lifestyle changes. The method can be used to manage and prevent numerous conditions, including type II diabetes, Alzheimer's disease, dementia, congestive heart failure, chronic obstructive pulmonary disease, asthma, lung disease, obesity, substance abuse, ADHD, insomnia, panic attacks, anxiety, depression, and others.\n\nMethodologies can be as simple as sending notifications designed to alter behavior to patients who are at risk of obesity or diabetes and as complex as administering an ingestible radio tag that communicates with an external sensor to monitor the efficacy of a given medication. Diabetes and obesity prevention and management is a major focus in the field of digital therapeutics. Connected devices like insulin pumps, blood glucose meters, and wearable gadgets can all send data to a unified system. The therapy also uses self-reported data like diet or other lifestyle factors. It is also often used to monitor the potential for heart and lung conditions and change behaviors like smoking, poor diet, or a lack of exercise.\n\nDigital therapeutics can also be used to treat patients with psychological and neurological disorders. For example, patients with disorders like ADHD, depression, and anxiety can receive cognitive behavioral therapy via their mobile devices. One study looked at the efficacy of avatar-based therapeutic interventions to reduce depressive symptoms. Another study demonstrated that a 4-week at-home treatment eliminated or reduced panic attacks.\n\nThe general consensus among researchers in the field of digital therapeutics is that the discipline requires more clinical data and investigation to be fully evaluated. A variety of studies have been conducted to evaluate the efficacy and impact of behavior change techniques that utilize a digital platform, however. In a meta-analysis of 85 such studies comprising a total sample size of over 43,000 participants, researchers discovered that digital therapeutics have a \"statistically small but significant effect on health-related behavior.\" The study also showed that a broader use of theory, behavior change techniques, and modes of delivery (especially regular notifications) improved the efficacy of a given program.\n\nIndividual studies have also showed some benefits for patients. For instance, a diabetes prevention program using digital therapeutics saw participants lose an average of 4.7% of baseline body weight after 1 year (4.2% after 2 years) and undergo a 0.38% reduction in A1c levels after 1 year (0.43% after 2 years). Another weight loss pilot program using digital therapeutics reported a mean weight loss of 13.5 pounds (or 7.3% of baseline) with a significant average drop in both systolic and diastolic blood pressure (18.6 mmHg and 6.4 mmHg respectively). The study also saw a slight but statistically insignificant drop in total cholesterol, LDL, triglycerides, and A1c.\n\n"}
{"id": "8774042", "url": "https://en.wikipedia.org/wiki?curid=8774042", "title": "Environmental health officer", "text": "Environmental health officer\n\nEnvironmental Health Officers (also known as Public Health Inspectors or Environmental Health Practitioners) are responsible for carrying out measures for protecting public health, including administering and enforcing legislation related to environmental health and providing support to minimize health and safety hazards. Environmental Health Practitioners are multi-skilled in many areas with individuals being highly trained, usually to degree level, and often requiring additional professional training, professional competency assessment and continuing professional development in order to continue to practise in the field.\nThey are involved in a variety of activities, for example inspecting food facilities, investigating public health nuisances, and implementing disease control, conducting work place safety assessments and accident investigation. Environmental health officers are focused on prevention, consultation, investigation, and education of the community regarding health risks and maintaining a safe environment.\n\nEHOs bring to the position an understanding of microbiology, risk assessment, environmental science and technology, food science, knowledge of the built environment as well as the skills and knowledge related to the tracking and control of communicable disease, investigation of environmental health related incidents and criminal investigations. They therefore must also have strong investigative skills and a thorough understanding of the application of legislation related to public health, the built environment, pollution control and workplace safety. Working in partnership with Government Ministries (such as Health, Agriculture and Environment), local municipalities, businesses, community groups, other agencies and individual members of the community, the EHO plays a major role in protecting public health. They are allowed with a permit to select what to inspect.\n\nSome past/historic titles include inspector of nuisances, sanitarian, and sanitary inspector. Other titles that currently exist include environmental health specialist/practitioner/professional, public health officer, health officer, health inspector, and health official. The legal title used will depend on the definitions found in local legislation/jurisdiction.\n\nEnvironmental health professionals are usually employed by local government or state health authorities to advise on and enforce public health standards. However, many are employed in the private sector the military and other third sector agencies such as charities and NGOs.\n\nThe following represents jobs that can be found in either the public or private sectors:\n\nThe common identifier of environmental health personnel is that they are responsible for the identification, evaluation and management of risks to human health from factors in the environment, whether on behalf of government agencies or commercial and industrial concerns.\n\nA Public Health Inspector (also known as an Environmental Health Officer) investigates health hazards in a wide variety of settings, and will take action to mitigate or eliminate the hazards. Usually the public perception of a health inspector is someone who examines restaurants and ensures they maintain sanitary standards for food safety set by the regulating authority. However, public health inspectors have much broader job duties, including inspecting swimming pools, substandard housing conditions, public schools, day cares, nursing homes, and personal service establishments such as tattoo parlours. Depending on their jurisdiction, Registered Environmental Health Officers often permit and inspect wells, private water systems, and individual subsurface sewage disposal (septic) systems. Other tasks include: campground inspections, tanning salon inspections, beauty salon inspections, correctional facility inspections and mobile home park inspection. The public health inspector (environmental health officer) also plays a vital role in community projects such as those concerning health promotion, tobacco reduction, healthy built environments/healthy communities, food security, and emergency preparedness.\nThey may also respond to complaints such as animal bites, garbage complaints, odor complaints, or sewage overflows. Due to their educational background they can provide information and referrals with regards to; lead, radon, mold, and emerging diseases such as West Nile Virus and Avian Flu. The field also overlaps with hazardous materials (Hazmat) and many Hazmat responders are also Licensed Environmental Health Practitioners or Registered Environmental Health Specialists.\n\nEnvironmental health officers work with many different people in a variety of environments. Their jobs often involve considerable fieldwork, and some travel frequently. Many environmental health officers work long and often irregular hours. They inspect pools, childcare centers, restaurants, septic systems, and many other types of establishments that relate to health and safety.\n\nEnvironmental health officers may be exposed to many of the same physically strenuous conditions and hazards as industrial employees, and the work may be performed in unpleasant, stressful, and dangerous working conditions. They may find themselves in an adversarial role if the management of an organization disagrees with the recommendations for ensuring a safe working environment.\n\nThe field of environmental health can be traced back to the 1840s in England. Edwin Chadwick, a Poor Law Commissioner, conducted an inquiry into the causes of poverty which concluded that people often became poor because of ill health due to a bad environment. He believed that improving sanitation was the key to breaking this vicious cycle.\n\nChadwick led a vigorous campaign for change which eventually won over the establishment, resulting in the Public Health Act 1848. The Act provided for the appointment of Inspectors of Nuisances – the forerunners of today’s environmental health practitioners – in areas of need.\n\nThe Association of Public Sanitary Inspectors – the organisation which was to become the United Kingdom's Chartered Institute of Environmental Health – was established in 1883. Over subsequent decades, the role of environmental health practitioners changed and grew, with standards of qualification rising until, in the 1960s, it became a graduate profession. The grant of a Royal Charter in 1984 set the seal on this enhanced role and status. As a result of changing roles, the titles have changed over the decades from inspector of nuisances -> sanitary inspector -> public health inspector / environmental health officer (see Inspector of Nuisances below). This is also true internationally, as the titles have changed to reflect the advanced education and roles of environmental health officers today.\n\nAn Inspector of Nuisances was the title of an office in several English-speaking jurisdictions. In many jurisdictions this term is now archaic, the position and/or term having been replaced by others. In the United Kingdom from the mid 19th century this office was generally associated with public health and sanitation.\n\nThe first Inspector of Nuisances appointed by a UK local authority Health Committee was Thomas Fresh in Liverpool in 1844. Both the 1855 Nuisances Removal and Diseases Prevention Act and the Metropolis Management Act 1855 defined such an office but with the title of 'Sanitary Inspector'. In local authorities that had established a Board of Health, the title was 'Inspector of Nuisances'. Eventually the title was standardized across all UK local authorities as 'Sanitary Inspector'. An Act of Parliament later changed the title to 'Public Health Inspector'. Similar offices were established across the British Empire.\n\nThe nearest modern equivalent of this position in the UK is an Environmental Health Officer. This title being adopted by local authorities on the recommendation of Central Government after the Local Government Act 1972. Today, Registered UK Environmental Health Officers working in non-enforcement roles (e.g. in the private sector) may prefer to use the generic term 'Environmental Health Practitioner'.\n\nIn the United States, a modern example of an officer with the title 'Inspector of Nuisances' but not the public health role is found in Section 3767[7] of the Ohio Revised Code which defines such a position to investigate nuisances, where this term broadly covers establishments in which lewdness and alcohol are found. Whereas in the United States the environmental health officer role in local authorities is taken by officers with the titles 'Registered Environmental Health Specialist' or 'Registered Sanitarian' depending on the jurisdiction. The role in the US Public Health Service is undertaken by Commissioned (uniformed) 'Environmental Health Officers'.\n\nEnvironmental health is a graduate career in most countries. The minimum requirements in most countries include an approved university degree program, field training and professional certification & registration.\n\nEnvironmental Health Australia accredits Australian Environmental Health Degree and Graduate Diploma programs in accordance with the Environmental Health Australia Accreditation Policy to ensure course content meets nationally consistent requirements for practice as an EHO anywhere in Australia. As at 1 July 2009 there are EHA-accredited Universities in every State and the Northern Territory.\n\nThe current requirement to become an authorised officer under the Food Act 1984 in Victoria are defined by the Secretary of the Department of Health and Human Services. A range of undergraduate and graduate qualifications from Victoria, interstate and overseas are acceptable.\n\nThe Health Act 1911 (as amended) defines the role of 'environmental health officer', and empowers the Executive Director, Public Health to appoint EHOs to local government health authorities and as public health officials employed by State government. The Executive Director, Public Health is advised by the Western Australia Environmental Health Officer Professional Review Board on Environmental Health Graduate and Postgraduate qualifications that are deemed suitable to allow practice in Western Australia, and the qualifications are published from time to time in the Government Gazette.\n\nCurrently Curtin University of Technology and Edith Cowan University offer Environmental Health degrees in Western Australia which are also accredited by Environmental Health Australia.\n\nEntrants to the profession must have either a BAppSc Health Protection or BHSc Environmental Health. Alternatively, suitably qualified science graduates can obtain a graduate diploma in environmental health.\n\nTo become an Environmental Health Officer it is necessary to hold an environmental health degree approved by the Department of Health & Children. The study of Environmental Health in Ireland also requires students to undertake a period of professional practice with the Health Service Executive. Following the period of professional practice, competence must then be demonstrated through an experiential learning logbook and oral examination.\n\nEHOs often hold at least an undergraduate (or postgraduate) qualification recognised by (in England, Wales and Northern Ireland) the Environmental Health Registration Board. \nSimilar provisions exist in Scotland, where the profession is regulated by The Royal Environmental Health Institute of Scotland.\nFollowing the educational requirements and practical training period, competence must then be demonstrated through an experiential learning logbook and oral examination before registration is granted.\n\nEnvironmental Health Officers/Public Health Inspectors have a university degree in environmental health and a national professional certificate – the Certificate in Public Health Inspection (Canada), CPHI(C). \n\nPublic Health Inspectors are highly trained individuals whose training include a bachelor's degree in environmental health followed by certification by the Canadian Institute of Public Health Inspectors (CIPHI). To become nationally certified, public health inspectors must complete a field training practicum, submit a number of reports and pass the Institute's exam. Some inspectors have additional training in areas such as biology, toxicology and epidemiology.\n\nOnly six schools in Canada offer degree programs approved by the CIPHI as meeting the educational component for certification: British Columbia Institute of Technology, Cape Breton University, Concordia University of Edmonton, Conestoga College Institute of Technology and Advanced Learning, First Nations University of Canada, and Ryerson University. These programs are generally four years long, however fast-track programs are available in some schools for those who have completed a previous science degree.\n\nPublic Health Inspectors appointed by the Department of Health, must have passed the Public Health Inspectors Examination conducted by the Department of Health to joined the service as a Public Health Inspector Grade III, thereafter they receive training to a Diploma level.\n\n\n"}
{"id": "292340", "url": "https://en.wikipedia.org/wiki?curid=292340", "title": "Flavonoid", "text": "Flavonoid\n\nFlavonoids (or bioflavonoids) (from the Latin word \"flavus\" meaning yellow, their color in nature) are a class of plant and fungus secondary metabolites.\n\nChemically, flavonoids have the general structure of a 15-carbon skeleton, which consists of two phenyl rings (A and B) and a heterocyclic ring (C). This carbon structure can be abbreviated C6-C3-C6. According to the IUPAC nomenclature,\nthey can be classified into:\n\nThe three flavonoid classes above are all ketone-containing compounds, and as such, are anthoxanthins (flavones and flavonols). This class was the first to be termed \"bioflavonoids\". The terms \"flavonoid\" and \"bioflavonoid\" have also been more loosely used to describe non-ketone polyhydroxy polyphenol compounds which are more specifically termed flavanoids. The three cycle or heterocycles in the flavonoid backbone are generally called ring A, B and C. Ring A usually shows a phloroglucinol substitution pattern.\n\nFlavonoids are widely distributed in plants, fulfilling many functions. Flavonoids are the most important plant pigments for flower coloration, producing yellow or red/blue pigmentation in petals designed to attract pollinator animals. In higher plants, flavonoids are involved in UV filtration, symbiotic nitrogen fixation and floral pigmentation. They may also act as chemical messengers, physiological regulators, and cell cycle inhibitors. Flavonoids secreted by the root of their host plant help \"Rhizobia\" in the infection stage of their symbiotic relationship with legumes like peas, beans, clover, and soy. Rhizobia living in soil are able to sense the flavonoids and this triggers the secretion of Nod factors, which in turn are recognized by the host plant and can lead to root hair deformation and several cellular responses such as ion fluxes and the formation of a root nodule. In addition, some flavonoids have inhibitory activity against organisms that cause plant diseases, e.g. \"Fusarium oxysporum\".\n\nOver 5000 naturally occurring flavonoids have been characterized from various plants. They have been classified according to their chemical structure, and are usually subdivided into the following subgroups (for further reading see):\n\nAnthoxanthins are divided into two groups:\n\nFlavanones\nFlavanonols\n\nInclude flavan-3-ols (flavanols), flavan-4-ols and flavan-3,4-diols.\n\n\n\n\nFlavonoids (specifically flavanoids such as the catechins) are \"the most common group of polyphenolic compounds in the human diet and are found ubiquitously in plants\". Flavonols, the original bioflavonoids such as quercetin, are also found ubiquitously, but in lesser quantities. The widespread distribution of flavonoids, their variety and their relatively low toxicity compared to other active plant compounds (for instance alkaloids) mean that many animals, including humans, ingest significant quantities in their diet. Foods with a high flavonoid content include parsley, onions, blueberries and other berries, black tea, green tea and oolong tea, bananas, all citrus fruits, \"Ginkgo biloba\", red wine, sea-buckthorns, buckwheat, and dark chocolate (with a cocoa content of 70% or greater). Further information on dietary sources of flavonoids can be obtained from the US Department of Agriculture flavonoid database.\n\nParsley, both fresh and dried, contains flavones.\n\nBlueberries are a dietary source of anthocyanidins.\n\nBlack tea is a rich source of dietary flavan-3-ols.\n\nThe citrus flavonoids include hesperidin (a glycoside of the flavanone hesperetin), quercitrin, rutin (two glycosides of the flavonol quercetin), and the flavone tangeritin.\n\nFlavonoids exist naturally in cocoa, but because they can be bitter, they are often removed from chocolate, even dark chocolate. Although flavonoids are present in milk chocolate, milk may interfere with their absorption; however this conclusion has been questioned.\n\nPeanut (red) skin contains significant polyphenol content, including flavonoids.\n\nFood composition data for flavonoids were provided by the USDA database on flavonoids. In the United States NHANES survey, mean flavonoid intake was 190 mg/d in adults, with flavan-3-ols as the main contributor. In the European Union, based on data from EFSA, mean flavonoid intake was 140 mg/d, although there were considerable differences between individual countries.\n\nThe main type of flavonoids consumed in the EU and USA were flavan-3-ols, mainly from tea, while intake of other flavonoids was considerably lower.\n\nThough there is ongoing research into the potential health benefits of individual flavonoids, neither the Food and Drug Administration (FDA) nor the European Food Safety Authority (EFSA) has approved any health claim for flavonoids or approved any flavonoids as pharmaceutical drugs. Moreover, several companies have been cautioned by the FDA over misleading health claims.\n\nFlavonoids have been shown to have a wide range of biological and pharmacological activities in \"in vitro\" studies. Examples include anti-allergic, anti-inflammatory, antioxidant, anti-microbial (antibacterial, antifungal, and antiviral), anti-cancer, and anti-diarrheal activities. Flavonoids have also been shown to inhibit topoisomerase enzymes and to induce DNA mutations in the mixed-lineage leukemia (\"MLL\") gene in \"in vitro\" studies. However, in most of the above cases no follow up \"in vivo\" or clinical research has been performed, leaving it impossible to say if these activities have any beneficial or detrimental effect on human health. Biological and pharmacological activities which have been investigated in greater depth are described below.\n\nResearch at the Linus Pauling Institute and the European Food Safety Authority shows that flavonoids are poorly absorbed in the human body (less than 5%), with most of what is absorbed being quickly metabolized and excreted. These findings suggest that flavonoids have negligible systemic antioxidant activity, and that the increase in antioxidant capacity of blood seen after consumption of flavonoid-rich foods is not caused directly by flavonoids, but is due to production of uric acid resulting from flavonoid depolymerization and excretion.\n\nInflammation has been implicated as a possible origin of numerous local and systemic diseases, such as cancer, cardiovascular disorders, diabetes mellitus, and celiac disease.\n\nPreliminary studies indicate that flavonoids may affect anti-inflammatory mechanisms via their ability to inhibit reactive oxygen or nitrogen compounds. Flavonoids have also been proposed to inhibit the pro-inflammatory activity of enzymes involved in free radical production, such as cyclooxygenase, lipoxygenase or inducible nitric oxide synthase, and to modify intracellular signaling pathways in immune cells, or in brain cells after a stroke.\n\nProcyanidins, a class of flavonoids, have been shown in preliminary research to have anti-inflammatory mechanisms including modulation of the arachidonic acid pathway, inhibition of gene transcription, expression and activity of inflammatory enzymes, as well as secretion of anti-inflammatory mediators.\n\nClinical studies investigating the relationship between flavonoid consumption and cancer prevention/development are conflicting for most types of cancer, probably because most studies are retrospective in design and use a small sample size. Two apparent exceptions are gastric carcinoma and smoking-related cancers. Dietary flavonoid intake is associated with reduced gastric carcinoma risk in women, and reduced aerodigestive tract cancer risk in smokers.\n\nAmong the most intensively studied of general human disorders possibly affected by dietary flavonoids, preliminary cardiovascular disease research has revealed the following mechanisms under investigation in patients or normal subjects:\n\nListed on the clinical trial registry of the US National Institutes of Health (July 2016) are 48 human studies completed or underway to study the dietary effects of plant flavonoids on cardiovascular diseases.\n\nHowever, population-based studies have failed to show a strong beneficial effect which might be due to the considerably lower intake in the habitual diet of those investigated.\n\nFlavonoids have been shown to have (a) direct antibacterial activity, (b) synergistic activity with antibiotics, and (c) the ability to suppress bacterial virulence factors in numerous \"in vitro\" and a limited number of \"in vivo\" studies. Noteworthy among the \"in vivo\" studies is the finding that oral quercetin protects guinea pigs against the Group 1 carcinogen \"Helicobacter pylori\". Researchers from the European Prospective Investigation into Cancer and Nutrition have speculated this may be one reason why dietary flavonoid intake is associated with reduced gastric carcinoma risk in European women. Additional \"in vivo\" and clinical research is needed to determine if flavonoids could be used as pharmaceutical drugs for the treatment of bacterial infection, or whether dietary flavonoid intake offers any protection against infection.\n\nFlavonoid synthesis in plants is induced by light color spectrums at both high and low energy radiations. Low energy radiations are accepted by phytochrome, while high energy radiations are accepted by carotenoids, flavins, cryptochromes in addition to phytochromes. The photomorphogenic process of phytochome-mediated flavonoid biosynthesis has been observed in \"Amaranthus\", barley, maize, \"Sorghum\" and turnip. Red light promotes flavonoid synthesis.\n\nSeveral recent research articles have demonstrated the efficient production of flavonoid molecules from genetically engineered microorganisms.\n\nFour pieces of magnesium filings are added to the ethanolic extract followed by few drops of concentrated hydrochloric acid. A pink or red colour indicates the presence of flavonoid. Colours varying from orange to red indicated flavones, red to crimson indicated flavonoids, crimson to magenta indicated flavonones.\n\nAbout 5 mg of the compound is dissolved in water, warmed and filtered. 10% aqueous sodium hydroxide is added to 2 ml of this solution. This produces a yellow coloration. A change in color from yellow to colorless on addition of dilute hydrochloric acid is an indication for the presence of flavonoids.\n\nA colorimetric assay based upon the reaction of A-rings with the chromogen p-dimethylaminocinnamaldehyde (DMACA) has been developed for flavanoids in beer that can be compared with the vanillin procedure.\n\nLamaison and Carnet have designed a test for the determination of the total flavonoid content of a sample (AlCI method). After proper mixing of the sample and the reagent, the mixture is incubated for 10 minutes at ambient temperature and the absorbance of the solution is read at 440 nm. Flavonoid content is expressed in mg/g of quercetin.\n\nImmobilized \"Candida antarctica\" lipase can be used to catalyze the regioselective acylation of flavonoids.\n\n\n\n\n"}
{"id": "54372951", "url": "https://en.wikipedia.org/wiki?curid=54372951", "title": "GESTIS Substance Database", "text": "GESTIS Substance Database\n\nGESTIS Substance Database is a freely accessible online information system on chemical compounds. It is maintained by the Institut für Arbeitsschutz der Deutschen Gesetzlichen Unfallversicherung (IFA, Institute for Occupational Safety and Health of the German Social Accident Insurance). Information on occupational medicine and first aid is compiled by Henning Heberer and his team (TOXICHEM, Leuna).\n\nThe database contains information for the safe handling of hazardous substances and other chemical substances at work:\n\nThe available information relates to about 9,400 substances. Data are updated immediately after publication of new official regulations or after the issue of new scientific results.\n\nA mobile version of the GESTIS Substance Database, suitable for smartphones and tablets, is also available.\n\n"}
{"id": "23100954", "url": "https://en.wikipedia.org/wiki?curid=23100954", "title": "Global Forum for Health Research", "text": "Global Forum for Health Research\n\nThe Global Forum for Health Research is an international foundation headquartered in Geneva, Switzerland established in 1997 to increase the amount of research into global health issues. It coined the phrase 10/90 gap to identify the observation that only 10% of the world's health research spending is targeted at 90% of present health problems.\n\nThe Global Forum is a partner to the World Health Organization. In her keynote address to the Forum in 1999 Gro Harlem Brundtland, then Director–General of WHO, declared that the Global Forum was key in the involvement of all the various levels, sectors and disciplines of \"development agencies, the research community, health workers and end–users\".\n\nThe Global Forum represents all the parties interested in health research: governments, non-governmental organizations (NGOs), United Nations agencies, research centers, universities, and the pharmaceutical industry. It is run by a governing council and provides support to programmes of research that benefit the developing world. It draws attention to global health research aims with an annual forum that draws together international health researchers and policy makers.\n\nThe Global Forums take place in a different international location each year: Geneva, Bangkok, Arusha, Mexico City, Mumbai, Cairo. The 11th was in Beijing in 2007, the 12th in Bamako, Mali in 2008 and Cuba hosted the 2009 Forum.\n\nAs a non-profit foundation the Global Forum is currently funded by the World Bank, the World Health Organization; the governments of Brazil, Canada, Ireland, Mexico, Norway, Switzerland; and private philanthropy groups including the Rockefeller Foundation.\n\n\n"}
{"id": "44573945", "url": "https://en.wikipedia.org/wiki?curid=44573945", "title": "Health Score", "text": "Health Score\n\nHealth Score is a scoring system used by several mobile health companies in various ways to track an individual's health via Quantified Self and the help of mobile applications, social networking and elements of gamification. According to them when tracked over time, it offers a good directional indicator of how the users health and well-being is evolving over time. The scoring engine varies considerably from one company to another, and in some cases, the scoring engine is trademarked and/or patented, such as in the case of Dacadoo. Health is invisible and therefore, all health scores in use have one thing in common: they want to capture and measure health and wellness and make it visible.\n\nHealth is invisible and intangible. The basic premise of a health scoring concept is that what you can measure, you can manage. If you can measure health and wellness good enough as an indicator, then you can start working with it. None of the available health scores is in medical diagnosis, they're all lifestyle-products where the health score in use is to be understood as an indicator, a number that helps you to work with it.\nThe score typically moves up or down indicating improvement, when it moves up, and vice versa. The simpler health scores available are more static in nature and provide a number based on some inputs provided. The more sophisticated health scores are dynamic and function in real-time, moving (such as exercise, nutrition, stress and sleep) change.\nMost health scores claim they are based on scientific data. The simpler models use one or a few models, the more sophisticated health scores claim to include a vast amount of models and person-years of clinical data.\n\nSome health scores use in addition to static questionnaires also dynamic and ongoing data, such as captured and tracked by fitness or activity trackers or applications for smartphones, For instance, exercise can be tracked automatically by using a mobile app for smartphones to track the activity, or by using fitness tracking apps or devices from the supplier of the health score solution, or by connecting popular fitness tracking apps such as RunKeeper and activity tracking devices such as Fitbit or UP Jawbone step counters, etc.\nIn the past, available information was limited and lifestyle adjustments were largely made only once a health problem was detected, and then under the guidance of healthcare professionals. Today due partly to the availability of electronic mass media there is a trend among the population to maintain their health on their own terms. This seems to be precipitating a shift away from the reactive model of health to a more proactive approach where the individual works towards the maintenance of their wellness before problems arise. This shift in attitudes is said to have broad implications for both public health and individual companies. Improved health would logically lead to reduced healthcare costs and increase workplace productivity.\n\nA wide array of technologies are now available that allow data to be collected on various components of wellness many of them using a variant of the Health Scoring system. Devices for measuring physical attributes, such as blood pressure, blood glucose, and total cholesterol are also commonly used by patients with chronic diseases such as diabetes or hypertension. Furthermore, devices that can be used by healthy individuals to monitor exercise and energy expenditure are increasingly popular, and range from simple heart rate monitors or step counters to more elaborate computerized exercise machines. These tools provide data on the user’s performance and many can upload the data to further systems to be processed. Undoubtedly, the largest growth area has been in apps, facilitated by the widespread use of tablets and smartphones. Although some of these apps may be gimmicks, many are said to be validated genuine tools to assist in improving health and wellness.\n\nSome of the Health Score using companies such as Fitocracy have grown to over one million users or more by focusing progress based on what's known as gamification as well as by celebrity exposure with the likes of Arnold Schwarzenegger promoting their products.\n\nThe large majority of offerings with health scores is in the lifestyle segment and not in medical diagnosis, therefore prospective clinical trials to scientifically prove whether a score is accurate or not, are often missing.\n\nA single integer measuring wellness and health outcomes is subject to many unknown variables and incomplete data.\n\n"}
{"id": "25125448", "url": "https://en.wikipedia.org/wiki?curid=25125448", "title": "Health care in Antigua and Barbuda", "text": "Health care in Antigua and Barbuda\n\nHealth care in Antigua and Barbuda is provided through four institutions maintained for the care of the sick and aged. Holberton Hospital, with 135 beds, is the only public acute care facility. The only private hospital is Adelin Medical Center. Other facilities include the Fiennes Institute for the aged, with 100 beds,\nand the Mental Hospital, with 150 beds. In addition, 9 health centers and 18 dispensaries are located throughout the country. As of 2004, there were an estimated 17 physicians, 328 nurses, and 18 dentists per 100,000 people.\n\nGaston Browne said in November 2018 that the health sector stood out like a jewel in the list of the country’s accomplishment since independence.\n\nThe infant mortality rate in 2005 was estimated at 22 per 1,000 live births, up from 12 in 1998. The average life expectancy was 71.9 years in 2005. As of 1995, 100% of the population was immunized against diphtheria, pertussis, and tetanus and 94% against measles, mumps, and rubella. The leading causes of death included cancer, cardiovascular disease, and trauma.\n\nBy the end of 2003, 271 cases of HIV/AIDS had been reported. As of that year, the annual incidence of AIDS was 209 per million people. The government approved a national policy on HIV/AIDS and other sexually transmitted diseases in 1997.\n"}
{"id": "8695082", "url": "https://en.wikipedia.org/wiki?curid=8695082", "title": "Health policy", "text": "Health policy\n\nHealth policy can be defined as the \"decisions, plans, and actions that are undertaken to achieve specific healthcare goals within a society\". According to the World Health Organization, an explicit health policy can achieve several things: it defines a vision for the future; it outlines priorities and the expected roles of different groups; and it builds consensus and informs people.\n\nThere are many categories of health policies, including global health policy, public health policy, mental health policy, health care services policy, insurance policy, personal healthcare policy, pharmaceutical policy, and policies related to public health such as vaccination policy, tobacco control policy or breastfeeding promotion policy. They may cover topics of financing and delivery of healthcare, access to care, quality of care, and health equity.\n\nHealth-related policy and its implementation is complex. Conceptual models can help show the flow from health-related policy development to health-related policy and program implementation and to health systems and health outcomes. Policy should be understood as more than a national law or health policy that supports a program or intervention. Operational policies are the rules, regulations, guidelines, and administrative norms that governments use to translate national laws and policies into programs and services. The policy process encompasses decisions made at a national or decentralized level (including funding decisions) that affect whether and how services are delivered. Thus, attention must be paid to policies at multiple levels of the health system and over time to ensure sustainable scale-up. A supportive policy environment will facilitate the scale-up of health interventions.\n\nThere are many topics in the politics and evidence that can influence the decision of a government, private sector business or other group to adopt a specific policy. Evidence-based policy relies on the use of science and rigorous studies such as randomized controlled trials to identify programs and practices capable of improving policy relevant outcomes. Most political debates surround personal health care policies, especially those that seek to reform healthcare delivery, and can typically be categorized as either philosophical or economic. Philosophical debates center around questions about individual rights, ethics and government authority, while economic topics include how to maximize the efficiency of health care delivery and minimize costs.\n\nThe modern concept of healthcare involves access to medical professionals from various fields as well as medical technology, such as medications and surgical equipment. It also involves access to the latest information and evidence from research, including medical research and health services research.\n\nIn many countries it is left to the individual to gain access to healthcare goods and services by paying for them directly as out-of-pocket expenses, and to private sector players in the medical and pharmaceutical industries to develop research. Planning and production of health human resources is distributed among labour market participants.\n\nOther countries have an explicit policy to ensure and support access for all of its citizens, to fund health research, and to plan for adequate numbers, distribution and quality of health workers to meet healthcare goals. Many governments around the world have established universal health care, which takes the burden of healthcare expenses off of private businesses or individuals through pooling of financial risk. There are a variety of arguments for and against universal healthcare and related health policies. Healthcare is an important part of health systems and therefore it often accounts for one of the largest areas of spending for both governments and individuals all over the world.\n\nMany countries and jurisdictions integrate a human rights philosophy in directing their healthcare policies. The World Health Organization reports that every country in the world is party to at least one human rights treaty that addresses health-related rights, including the right to health as well as other rights that relate to conditions necessary for good health. The United Nations' Universal Declaration of Human Rights (UDHR) asserts that medical care is a right of all people:\n\nIn some jurisdictions and among different faith-based organizations, health policies are influenced by the perceived obligation shaped by religious beliefs to care for those in less favorable circumstances, including the sick. Other jurisdictions and non-governmental organizations draw on the principles of humanism in defining their health policies, asserting the same perceived obligation and enshrined right to health. In recent years, the worldwide human rights organization Amnesty International has focused on health as a human right, addressing inadequate access to HIV drugs and women's sexual and reproductive rights including wide disparities in maternal mortality within and across countries. Such increasing attention to health as a basic human right has been welcomed by the leading medical journal \"The Lancet\".\n\nThere remains considerable controversy regarding policies on who would be paying the costs of medical care for all people and under what circumstances. For example, government spending on healthcare is sometimes used as a global indicator of a government's commitment to the health of its people. On the other hand, one school of thought emerging from the United States rejects the notion of health care financing through taxpayer funding as incompatible with the (considered no less important) right of the physician's professional judgment, and the related concerns that government involvement in overseeing the health of its citizens could erode the right to privacy between doctors and patients. The argument furthers that universal health insurance denies the right of individual patients to dispose of their own income as per their own will.\n\nAnother issue in the rights debate is governments' use of legislation to control competition among private medical insurance providers against national social insurance systems, such as the case in Canada's national health insurance program. Laissez-faire supporters argue that this erodes the cost-effectiveness of the health system, as even those who can afford to pay for private healthcare services drain resources from the public system. The issue here is whether investor-owned medical insurance companies or health maintenance organizations are in a better position to act in the best interests of their customers compared to government regulation and oversight. Another claim in the United States perceives government over-regulation of the healthcare and insurance industries as the effective end of charitable home visits from doctors among the poor and elderly.\n\nMany types of health policies exist focusing on the financing of healthcare services to spread the economic risks of ill health. These include publicly funded health care (through taxation or insurance, also known as single-payer systems), mandatory or voluntary private health insurance, and complete capitalization of personal health care services through private companies, among others. The debate is ongoing on which type of health financing policy results in better or worse quality of healthcare services provided, and how to ensure allocated funds are used effectively, efficiently and equitably.\n\nThere are many arguments on both sides of the issue of public versus private health financing policies:\n\nClaims that publicly funded healthcare improves the quality and efficiency of personal health care delivery:\n\nClaims that privately funded healthcare leads to greater quality and efficiencies in personal health care:\n\nHealth policy options extend beyond the financing and delivery of personal health care, to domains such as medical research and health workforce planning, both domestically and internationally.\n\nMedical research can be both the basis for defining evidence-based health policy, and the subject of health policy itself, particularly in terms of its sources of funding. Those in favor of government policies for publicly funded medical research posit that removing profit as a motive will increase the rate of medical innovation. Those opposed argue that it will do the opposite, because removing the incentive of profit removes incentives to innovate and inhibits new technologies from being developed and utilized.\n\nThe existence of sound medical research does not necessarily lead to evidence-based policymaking. For example, in South Africa, whose population sets the record for HIV infections, previous government policy limiting funding and access for AIDS treatments met with strong controversy given its basis on a refusal to accept scientific evidence on the means of transmission. A change of government eventually led to a change in policy, with new policies implemented for widespread access to HIV services. Another issue relates to intellectual property, as illustrated by the case of Brazil, where debates have arisen over government policy authorizing the domestic manufacture of antiretroviral drugs used in the treatment of HIV/AIDS in violation of drug patents.\n\nSome countries and jurisdictions have an explicit policy or strategy to plan for adequate numbers, distribution and quality of health workers to meet healthcare goals, such as to address physician and nursing shortages. Elsewhere, workforce planning is distributed among labour market participants as a laissez-faire approach to health policy. Evidence-based policies for workforce development are typically based on findings from health services research.\n\nMany governments and agencies include a health dimension in their foreign policy in order to achieve global health goals. Promoting health in lower income countries has been seen as instrumental to achieve other goals on the global agenda, including:\n\nGlobal health policy encompasses the global governance structures that create the policies underlying public health throughout the world. In addressing global health, global health policy \"implies consideration of the health needs of the people of the whole planet above the concerns of particular nations.\" Distinguished from both international health policy (agreements among sovereign states) and comparative health policy (analysis of health policy across states), global health policy institutions consist of the actors and norms that frame the global health response.\n\n"}
{"id": "35443480", "url": "https://en.wikipedia.org/wiki?curid=35443480", "title": "Hierarchy of hazard controls", "text": "Hierarchy of hazard controls\n\nHierarchy of hazard control is a system used in industry to minimize or eliminate exposure to hazards. It is a widely accepted system promoted by numerous safety organizations. This concept is taught to managers in industry, to be promoted as standard practice in the workplace. Various illustrations are used to depict this system, most commonly a triangle.\n\nThe hazard controls in the hierarchy are, in order of decreasing effectiveness:\n\nPhysically removed the hazard—is the most effective hazard control. For example, if employees must work high above the ground, the hazard can be eliminated by moving the piece they are working on to ground level to eliminate the need to work at heights.\n\nSubstitution, the second most effective hazard control, involves replacing something that produces a hazard (similar to elimination) with something that does not produce a hazard—for example, replacing lead-based paint with titanium white. To be an effective control, the new product must not produce another hazard. Because airborne dust can be hazardous, if a product can be purchased with a larger particle size, the smaller product may effectively be substituted with the larger product.\n\nThe third most effective means of controlling hazards is engineered controls. These do not eliminate hazards, but rather isolate people from hazards. Capital costs of engineered controls tend to be higher than less effective controls in the hierarchy, however they may reduce future costs. For example, a crew might build a work platform rather than purchase, replace, and maintain fall arrest equipment. \"Enclosure and isolation\" creates a physical barrier between personnel and hazards, such as using remotely controlled equipment. Fume hoods can remove airborne contaminants as a means of engineered control.\n\nAdministrative controls are changes to the way people work. Examples of administrative controls include procedure changes, employee training, and installation of signs and warning labels (such as those in the Workplace Hazardous Materials Information System). Administrative controls do not remove hazards, but limit or prevent people's exposure to the hazards, such as completing road construction at night when fewer people are driving.\n\nPersonal protective equipment (PPE) includes gloves, Nomex/Uniform, respirators, hard hats, safety glasses, high-visibility clothing, and safety footwear. PPE is the least effective means of controlling hazards because of the high potential for damage to render PPE ineffective. Additionally, some PPE, such as respirators, increase physiological effort to complete a task and, therefore, may require medical examinations to ensure workers can use the PPE without risking their health.\n\nThe hierarchy of controls is a core component of Prevention through Design, the concept of applying methods to minimize occupational hazards early in the design process. Prevention through Design emphasizes addressing hazards at the top of the hierarchy of controls (mainly through elimination and substitution) at the earliest stages of project development.\n\n\n"}
{"id": "55542260", "url": "https://en.wikipedia.org/wiki?curid=55542260", "title": "Husband stitch", "text": "Husband stitch\n\nThe husband stitch or husband's stitch, also known as the daddy stitch, husband's knot and vaginal tuck, is a purported surgical procedure in which one or more sutures than necessary are used to repair a woman's perineum after it has been torn or cut during childbirth. The claimed purpose is to tighten the opening of the vagina and thereby enhance the pleasure of her male sex partner during penetrative intercourse. Evidence for benefits is lacking.\n\nWhile repair of the perineum may be medically necessary, an \"extra\" stitch is not, and may cause discomfort or pain. Use of the term in the medical literature can be traced to \"Transactions of the Texas State Medical Association\" in 1885. There is also a reference to it in \"What Women Want to Know\" (1958), a book co-written by an American gynaecologist.\n\nIt appears that no studies exist to determine whether the procedure occurs and how many women have been affected. Some medical practitioners view reports about the procedure as an urban legend. One writer suggests that it might be a joke made by men to relieve tension after their partners have given birth.\n\nA short story by Carmen Maria Machado, \"The Husband Stitch\", first published in 2014 by \"Granta\", describes a woman undergoing the procedure.\n\n"}
{"id": "12315477", "url": "https://en.wikipedia.org/wiki?curid=12315477", "title": "Indoor mold", "text": "Indoor mold\n\nMold (American English) or mould (British English), also sometimes referred to as mildew, is a fungal growth that develops on wet materials. Mold is a natural part of the environment and plays an important part in nature by breaking down dead organic matter such as fallen leaves and dead trees; indoors, mold growth should be avoided. Mold reproduce by means of tiny spores. The spores are like seeds, but invisible to the naked eye, that float through the air and deposit on surfaces. When the temperature, moisture, and available nutrient conditions are correct, the spores can form into new mold colonies where they are deposited. There are many types of mold, but all require moisture and a food source for growth.\n\nMold are ubiquitous, and mold spores are a common component of household and workplace dust. In large amounts they can be a health hazard to humans, potentially causing allergic reactions and respiratory problems.\n\nSome mold produce mycotoxins that can pose serious health risks to humans and animals. \"Toxic mold\" refers to mold which produce mycotoxins, such as \"Stachybotrys chartarum\". Exposure to high levels of mycotoxins can lead to neurological problems and death. Prolonged exposure (for example, daily exposure) can be particularly harmful.\n\nSymptoms of mold exposure may include nasal and sinus congestion; runny nose, eye irritation; itchy, red, watery eyes, respiratory problems, such as wheezing and difficulty breathing, chest tightness, cough, throat irritation, skin irritation (such as a rash), headache, and persistent sneezing. Immune-compromised people and people with chronic lung illnesses, such as obstructive lung disease, may get serious infections in their lungs when they are exposed to mold. These people should stay away from areas that are likely to have mold, such as compost piles, cut grass, and wooded areas.\n\nInfants may develop respiratory symptoms as a result of exposure to \"Penicillium\", a fungal genus. Signs of mold-related respiratory problems in an infant include a persistent cough or wheeze. Increased exposure increases the probability of developing respiratory symptoms during the first year of life. Studies have indicated a correlation between the probability of developing asthma and exposure to \"Penicillium\".\n\nMold exposure has a variety of health effects, and sensitivity to mold varies. Exposure to mold may cause throat irritation, nasal stuffiness, eye irritation, cough and wheezing and skin irritation in some cases. Exposure to mold may heighten sensitivity, depending on the time and nature of exposure. People with chronic lung diseases are at higher risk for mold allergies, and will experience more severe reactions when exposed to mold. Damp indoor environments correlate with upper-respiratory-tract symptoms, such as coughing and wheezing in people with asthma.\n\nMold is found everywhere and can grow on almost any substance when moisture is present. They reproduce by spores, which are carried by air currents. When spores land on a moist surface suitable for life, they begin to grow. Mold is normally found indoors at levels which do not affect most healthy individuals.\n\nBecause common building materials are capable of sustaining mold growth and mold spores are ubiquitous, mold growth in an indoor environment is typically related to water or moisture and may be caused by incomplete drying of flooring materials (such as concrete). Flooding, leaky roofs, building-maintenance or indoor-plumbing problems can lead to interior mold growth. Water vapor commonly condenses on surfaces cooler than the moisture-laden air, enabling mold to flourish. This moisture vapor passes through walls and ceilings, typically condensing during the winter in climates with a long heating season. Floors over crawl spaces and basements, without vapor barriers or with dirt floors, are mold-prone. The \"doormat test\" detects moisture from concrete slabs without a sub-slab vapor barrier. Some materials, such as polished concrete, do not support mold growth.\n\nSignificant mold growth requires moisture and food sources and a substrate capable of sustaining growth. Common building materials, such as plywood, drywall, furring strips, carpets, and carpet padding provide food for mold. In carpet, invisible dust and cellulose are food sources. After water damage to a building, mold grows in walls and then becomes dormant until subsequent high humidity; suitable conditions reactivate mold. Mycotoxin levels are higher in buildings which have had a water incident.\n\nMold is detectable by smell and signs of water damage on walls or ceiling and can grow in places invisible to the human eye. It may be found behind wallpaper or paneling, on the inside of ceiling tiles, the back of drywall, or the underside of carpets or carpet padding. Piping in walls may also be a source of mold, since they may leak (causing moisture and condensation).\n\nSpores need three things to grow into mold: nutrients - cellulose (the cell wall of green plants) is a common food for indoor spores; moisture - To begin the decaying process caused by mold; time -mold growth begins from 24 hours to 10 days after the provision of growing conditions.\n\nMold colonies can grow inside buildings, and the chief hazard is the inhalation of mycotoxins. After a flood or major leak, mycotoxin levels are higher even after a building has dried out.\n\nFood sources for mold in buildings include cellulose-based materials such as wood, cardboard and the paper facing on drywall and organic matter such as soap, fabrics and dust-containing skin cells. If a house has mold, the moisture may originate in the basement or crawl space, a leaking roof or a leak in plumbing pipes. Insufficient ventilation may accelerate moisture buildup. Visible mold colonies may form where ventilation is poorest and on perimeter walls (because they are nearest the dew point).\n\nIf there are mold problems in a house only during certain times of the year, the house is probably too airtight or too drafty. Mold problems occur in airtight homes more frequently in the warmer months (when humidity is high inside the house, and moisture is trapped), and occur in drafty homes more frequently in the colder months (when warm air escapes from the living area and condenses). If a house is artificially humidified during the winter, this can create conditions favorable to mold. Moving air may prevent mold from growing, since it has the same desiccating effect as low humidity. Mold grow best in warm temperatures, , although growth may occur between .\n\nRemoving one of the three requirements for mold reduces (or eliminates) new mold growth: moisture; food for the mold spores (for example, dust or dander); and warmth since mold generally does not grow in cold environments.\n\nHVAC systems can produce all three requirements for mold growth. The air conditioning system creates a difference in temperature, encouraging condensation. The high rate of dusty air movement through an HVAC system may furnish ample food for mold. Since the air-conditioning system is not always running, warm conditions are the final component for mold growth.\n\nAn observation of the indoor environment should be conducted before any sampling is performed. The area should be surveyed for odors indicating mold or bacterial growth, moisture sources, such as stagnant water or leaking pipes, and water-damaged building materials. This can include moving furniture, lifting (or removing) carpets, checking behind wallpaper or paneling, checking ventilation ductwork and exposing wall cavities. Efforts typically focus on areas where there are signs of liquid moisture or water vapor (humidity), or where moisture problems are suspected. Often, quick decisions about the immediate safety and health of the environment can be made by these observations before sampling is even needed. The United States Environmental Protection Agency (EPA) does not generally recommend sampling unless an occupant of the space has symptoms. In most cases, if visible mold growth is present, sampling is unnecessary. Sampling should be performed by a trained professional with specific experience in mold-sampling protocols, sampling methods and the interpretation of findings. It should be done only to make a particular determination, such as airborne spore concentration or identifying a particular species.\n\nBefore sampling, a subsequent course of action should be determined.\n\nIn the U.S., sampling and analysis should follow the recommendations of the Occupational Safety and Health Administration (OSHA), National Institute for Occupational Safety and Health (NIOSH), the EPA and the American Industrial Hygiene Association (AIHA).\n\nTypes of samples include air, surface, bulk, and swab. Air is the most common form of sampling to assess mold levels. Indoor and outdoor air are sampled, and their mold-spore levels compared. Air sampling often identifies hidden mold. Surface sampling measures the number of mold spores deposited on indoor surfaces, collected on tape or in dust. Bulk removal of material from the contaminated area is used to identify and quantify the mold in the sample. With swab, a cotton swab is rubbed across the area being sampled, often a measured area, and subsequently sent to the mold testing laboratory. Final results indicate mold levels and species located in the suspect area.\n\nMultiple types of sampling are recommended by the AIHA, since each has limitations; for example, air samples will not identify a hidden mold source and a tape sample cannot determine the level of contamination in the air.\n\nThe first step in solving an indoor mold problem is to remove the moisture source; new mold will begin to grow on moist, porous surfaces within 24 to 48 hours. There are a number of ways to prevent mold growth. Some cleaning companies specialize in fabric restoration, removing mold (and mold spores) from clothing to eliminate odor and prevent further damage to garments.\n\nThe effective way to clean mold is to use detergent solutions which physically remove mold. Many commercially available detergents marketed for mold cleanup include an EPA-approved antifungal agent.\n\nSignificant mold growth may require professional mold remediation to remove the affected building materials and eradicate the source of excess moisture. In extreme cases of mold growth in buildings, it may be more cost-effective to condemn the building than to reduce mold to safe levels. Before doing any work yourself or even hiring someone to do it for you, check your state laws. Mold remediation professionals may need a special license. Licensed General Contractors are exempt from obtaining a license and are free to perform remediation.\n\nThe goals of remediation are to remove (or clean) contaminated materials, preventing fungi (and fungi-contaminated dust) from entering an occupied (or non-contaminated) area while protecting workers performing the abatement.\n\nThe purpose of cleanup is to eliminate mold and remove contaminated materials. Killing mold with a biocide is insufficient, since chemicals and proteins causing reactions in humans to remain in dead mold. The following methods are used.\n\nEquipment used in mold remediation includes: moisture meter: measures drying of damaged materials; Humidity gauge: often paired with a thermometer; borescope: Camera at the end of a flexible snake, illuminating potential mold problems inside walls, ceilings and crawl spaces; digital camera: Documents findings during assessment; personal protective equipment (PPE): Respirators, gloves, impervious suit, and eye protection; thermographic camera: Infrared thermal-imaging cameras identify secondary moisture sources.\n\nDuring mold remediation in the U.S., the level of contamination dictates the protection level for remediation workers. Contamination levels have been enumerated as I, II, III, and IV:\n\n\nAfter remediation, the premises should be reevaluated to ensure success.\n\nAccording to the EPA, residential mold may be prevented and controlled by cleaning and repairing roof gutters, to prevent moisture seepage into the home; keeping air-conditioning drip pans clean and drainage lines clear; monitoring indoor humidity; drying areas of moisture or condensation and removing their sources; treating exposed structural wood or wood framing with an EPA-approved fungicidal encapsulation coating after pre-cleaning (particularly homes with a crawl space, unfinished basement or a poorly-ventilated; attic).\n\n\n"}
{"id": "2442097", "url": "https://en.wikipedia.org/wiki?curid=2442097", "title": "Jengu", "text": "Jengu\n\nA jengu (plural miengu) is a water spirit in the traditional beliefs of the Sawa ethnic groups of Cameroon, particularly the Duala, Bakweri, and related Sawa peoples. Among the Bakweri, the name is liengu (plural: maengu). Miengu are similar to Mami Wata spirits. \n\nThe miengus appearance differs from people to people, but they are typically said to be beautiful, mermaid-like figures with long hair and beautiful gap-teeth. They live in rivers and the sea and bring good fortune to those who worship them. They can also cure disease and act as intermediaries between worshippers and the world of spirits. For this reason, a jengu cult has long enjoyed popularity among the Duala peoples. Among the Bakweri, this cult is also an important part of a young girl's rite of passage into womanhood.\n\nJengu may refer to a single spirit, as well. In some traditions, this spirit replaces the class of miengu spirits, while in others, it acts as their leader. Among the Isubu, for example, this spirit is called Jengu.\n\nBakweri belief talks of a female spirit named Mojili or Mojele. Mojili became the progenitor of the miengu when she lost a bet with Moto, the ancestor of mankind, over who could build the longer-lasting fire. Moto won the right to stay in the village, but Mojili was forced to flee to the sea. The Bakweri still worship Mojili as the ruler of the miengu. In fact, her name is so powerful, that many believe that children under seven may die if they hear it uttered. By extension of this tale, the miengu are said to be the wives of the rats, as the ancestor of the rats also lost the bet and fled to the forest.\n\nAnother Bakweri tradition names this spirit Liengu la Mwanja and makes her the consort of Efasa-Moto, spirit of Mount Fako (Mount Cameroon). Long ago, the two formed an understanding that Efasa-Moto would live on the mountain, while Liengu la Mwanja would inhabit the sea. When lava from Mount Fako's 1992 eruption made it all the way to the ocean, many hailed it as a sign that the spirit was visiting his wife.\n\nThe Duala and related groups hold the jengu cult in high importance. The cult may have originated with peoples further west, possibly the Ijo, and then passed from people to people, reaching the Batanga at its most eastward extent. In the earliest days, jengu-worship centred on the water spirits as the source of four boons: crayfish, the end of the rainy season in one of the world's wettest regions, victory in the pirogue races, and protection from epidemics of disease. Among the Duala proper, membership was originally reserved to \"free\" (pure-blooded) Duala, a stipulation that even excluded members of the prestigious Akwa clan due to one of their ancestors being a Bassa woman. Observations by European traders and explorers prove that jengu-worship was well established by the early 19th century. Early missionaries largely failed in their attempts to suppress it.\n\nThe cult is still active in Cameroon's Littoral and Southwest Provinces. Both males and females are eligible to join, though this openness may be a fairly recent development. Jengu-worship is primarily male among the Duala proper, but among the Bakweri, on the other hand, the cult is primarily for women.\n\nJengu worship centres on a secret society led by an individual known as the \"ekale\". This person traditionally wears a mask at all meetings, though this practice all but died out by the mid-20th century. Anyone can supplicate the miengu, however, and the simplest rituals involve nothing more than prayers or sacrifices to the deities before fishing or traveling by water.\n\nEarly jengu worshippers performed rituals in pirogues on the Wouri River, its tributaries and estuary, and on nearby islands. The person would first dress in ceremonial garb, a cape, skirt, and headdress of raffia fronds, and carry palm fronds and wooden paddles. He would then summon the miengu and offer them oblations of food and drink. He might also visit a jengu shrine further up the Wouri.\n\nMuch jengu worship is related to healing and medicine, and the miengu are called upon when mainstream healing fails. For example, a jengu doctor can treat a patient by first sacrificing a cock and goat. He then administers a vomit-inducing medicine and waves a small stool over the patient's head. The one treated must then follow a series of taboos. Among the Bakweri, this rite is known as \"Liengu la Vafea\". \n\nThe highest-profile miengu ceremony today is the annual Ngondo celebration in Douala, first held in 1949. The night before the fête's culmination, members of the jengu cult hold a private ceremony at Jebale Island on the Wouri. There they sacrifice to the water spirits and prepare a package of gifts. The next day, this offering is presented to the miengu during a public ceremony on a beach near Douala. One cult member dives into the sea with the gift and stays down as long as possible. Afterward, he returns with a message from the miengu about the year to come.\n\nThe climax of the ngondo festival is the jengu cult. Wherein the traditional diver goes into the river under supervision of the traditional rulers. This undisclosed custodian of tradition, accompanied by a woman and two men, embarks on a ritual boat. He will then submerge himself in the middle of the river and stay underneath the water for three to ten minutes. It is believed that he visits the kingdom of their ancestors (spirits) beneath the waters. He returns with news of the successor of the ngondo presidency and a coded message from the gods of the land in a calabash. One mystery of this ritual is that the calabash, which the diver holds as he re-emerges from underneath the river, is dry.\n\nThe rites observed by the Bakweri people of Mount Cameroon serve as an example of similar rituals among other coastal groups. \n\nToward the coast, the Bakweri practice two major induction rituals. In the \"Liengu la Ndiva\", cult members take a seizure or collapse as a sign that a young girl is ready for induction. A cult member then speaks to her in a secret liengu language, and if she seems to understand any of it, a traditional healer begins the initiation rites. The girl must live in seclusion for several months, during which she must follow a strict set of taboos and may see visions of spirits. She also receives a secret name and teaching in the secret liengu language. Eventually, the healer releases her into the custody of a group of strong men and a number of women singing in the liengu language. The men take turns carrying her until she reaches the middle of a stream. There, the healer plunges her in, inducting her into the cult. Meanwhile, other cult members attempt to capture a crab from the waters, as this animal represents the liengu spirit. The new member's taboos remain, however, and she must live in seclusion for several more months. Finally, the cult holds a feast in her honour, and the initiation comes to an end. The entire process takes the better part of a year.\n\nAn alternate Bakweri initiation ritual is the \"Liengu la Mongbango\". If a young girl disappears into the bush, her female relatives try to track her down by singing to her in the liengu language and carrying cult insignia made of wicker. When they find her, they hide her away for several months (outsiders may visit, however). Afterward, the cult prepares a feast for the girl. She and her sponsor then go alone into the forest. The initiate dresses in traditional regalia of fern fronds and rubs her body with red camwood. She is then led back to the village tied to the middle of a long rope. Two groups play a tug of war over her until the rope breaks, and she collapses. The cult members call to her nine times in the liengu language, which causes her to stand back up. After a few more weeks of taboos, a traditional healer bathes her in a stream, and her initiation ends. This process also takes most of a year.\n\n"}
{"id": "8873167", "url": "https://en.wikipedia.org/wiki?curid=8873167", "title": "Joseph LaDou", "text": "Joseph LaDou\n\nJoseph LaDou (born 1938) is an occupational and environmental medicine physician who practiced in Silicon Valley during the early years of the semiconductor and computer industries. He was appointed the first Chief of the University of California, San Francisco (MC) Division of Occupational and Environmental Medicine , and was co-director of the residency program there from 1982-1991. \n\nLaDou was the founding editor of the \"International Journal of Occupational and Environmental Health\", serving in that capacity from 1992-2005. And was director of the International Center for Occupational Medicine at UCSF.\n\nFrom 1983 to 2002, in addition to his other responsibilities, LaDou was Director, \"Advances in Occupational and Environmental Medicine\", a continuing medical education course that trained more than 3,000 physicians (500 from developing countries) in occupational medicine.\n\nLaDou's study of the global migration of hazardous industries has led to efforts to control occupational and environmental hazards. As one example, his study of asbestos in developing countries led to a call for an international ban on asbestos mining and use in commercial products.\n\nAmong LaDou's notable publications:\n\n"}
{"id": "43312937", "url": "https://en.wikipedia.org/wiki?curid=43312937", "title": "Late preterm infant", "text": "Late preterm infant\n\nLate preterm infants are infants born at a gestational age between weeks and weeks. They have higher morbidity and mortality rates than term infants (gestational age ≥37 weeks) due to their relative physiologic and metabolic immaturity, even though they are often the size and weight of some term infants. \"Late preterm\" has replaced \"near term\" to describe this group of infants, since near term incorrectly implies that these infants are \"almost term\" and only require routine neonatal care.\n\nIn 2005, late-preterm births accounted for more than 70% of all preterm births (<37 weeks’ gestation), or approximately 377,000 infants. In fact, much of the increase in the preterm birth rate in recent years can be attributed to increases in late-preterm births.\n\nSeveral important factors that may predispose late-preterm infants to medical conditions associated with immaturity:\n\nAt 34–35 weeks, the brain weight is only about that of a full-term baby. This may lead to an increased risk of:\n\nLate preterm infants have immature gastrointestinal function and feeding difficulties that predispose them to in increase in enterohepatic circulation, decreased stool frequency, dehydration, and hyperbilirubinemia. Feeding during the birth hospitalization may be transiently successful, but not sustained after discharge. Feeding difficulties are associated with relatively low oromotor tone, function, and neural maturation also predispose these infants to dehydration and hyperbilirubinemia.\n\nLate Preterm Infants have an increased risk of being underweight and stunted at 12 and 24 months of age versus term infants.\n\nProper nutrition is essential for normal growth, optimal neurologic and cognitive development, immune protection, and long term health.\n\nThe last trimester of pregnancy the fetus is expressing active amino acid transport, calcium, lipid transfer, and glucose facilitated diffusion. Delivery of the premature infant requires higher energy expenditure, but with inadequate intake the infant will have negative nitrogen balance. There are higher needs for Calcium, Phosphorus, and Vitamin D.\n\nFor every 10 kcal/kg increase in energy intake in the first week of life, there is a 4.6 points increase in MDI (Mental Development Index) at 18 months. For every 1 g/kg increase in protein intake in the first week of life, 8.2 point increase in MDI at 18 months.\n\n\nFactors such as hemodynamic stability, severe IUGR, respiratory, abdominal exam, whether feeding cues are present, and stable glucose could all effect the timing of nutrition. Some preterm infants will be NPO (nil per os). If infants are unable to start oral or enteral intake intravenous fluids may begin with amino acids or total parenteral nutrition.\n\nAccording to the American Academy of Pediatrics section on breastfeeding recommendations are all infants should receive human milk.\n\nUse caution when fortifying single nutrients to prevent alteration of protein/energy ratio. Center for Disease Control (CDC) recommends that sterile formulas and fortifiers be used when mom is not available. Powdered formula and HMF may be contaminants. Start with the mom's diet during breastfeeding. Mom should be eating adequate calories, protein, B vitamins and DHA.\n\nColostrum production can range from 26-56 mL the first day to 113-185 mL for day two. Although colostrum production is not voluminous, it can still meet the needs of the newborn.\n\n\n\n"}
{"id": "11412059", "url": "https://en.wikipedia.org/wiki?curid=11412059", "title": "Lawh-i-Tibb", "text": "Lawh-i-Tibb\n\nLawh-i-Tibb, Tablet to a Physician or Tablet of Medicine is a tablet of Bahá'u'lláh to Áqá Mírzá Muhammad-Ridáy-i-Tabib-i-Yazdí, a doctor of the old school of medicine. It was written in Akká between 1870 and 1875.\n\nIn this tablet, Bahá'u'lláh gives advice on eating habits and emotions, and the need for medical treatment. It includes a well-known healing prayer by Bahá'u'lláh:\n\n\n"}
{"id": "1817722", "url": "https://en.wikipedia.org/wiki?curid=1817722", "title": "Lipedema", "text": "Lipedema\n\nLipedema is a disorder where there is enlargement of both legs due to deposits of fat under the skin. Typically it gets worse over time, pain may be present, and sufferers bruise easily. In severe cases the trunk and upper body may be involved. Lipedema is commonly misdiagnosed. \nThe cause is unknown but is believed to involve genetics and hormonal factors. It often runs in families. Risk factors include being overweight or obese. Other conditions that may present similarly include obesity, lipohypertrophy, chronic venous insufficiency, and lymphedema.\nA number of treatments may be useful including physiotherapy and exercise. Physiotherapy may help to preserve mobility for a little longer than would otherwise be the case. Exercise, only as much as the patient is able to do without causing damage to the joints, may help with overall fitness but will not prevent progression of the disease. While surgery can remove fat tissue it can also damage lymphatic vessels. Treatment does not typically result in complete resolution. It is estimated to affect up to 11% of women. Onset is typically during puberty, pregnancy, or menopause.\n\nLipedema can be underdiagnosed due the difficulty in differentiating it from other edemas and obesity, or clinicians failing to make themselves aware of the disease. Trayes 2013 published some tools including tables and a flow chart that can be used to diagnose lipedema and other edemas.\n\nLipedema / Dercum’s Disease Differentiation\nThese conditions may co-exist. Dercum’s Disease is characterized by painful lipomas around the body.\n\nA number of treatments may be useful including physiotherapy and light exercise which does not put undue stress on the lymphatic system. While surgery can remove fat tissue it can also damage lymphatic vessels. Treatment does not typically result in complete resolution.\n\nThe use of surgery to treat the condition is controversial. Options include liposuction and lipectomy.\n\nThe studies of highest quality involve tumescent or super tumescent anesthesia and vibrating liposuction, powered, cannula used with lymph sparing techniques. The treatment of lipedema with tumescent liposuction requires multiple procedures. In the United States Health Insurance do not generally pay for liposuction for lipedema, making it expensive. Liposuction under general anesthesia, without tumescent anesthesia, can be damaging and is not recommended for the treatment.\n\nComplications include depression, anxiety, and pain.\n\nEstimates of the incidence of lipedema vary widely, and range as high as 11% of the post-pubertal female population, with estimates of 17 million women in the US, and 370 million women worldwide affected. \"11% of adult women\" is often cited but that is unsubstantiated.\n\nAlthough first identified in the United States, at the Mayo Clinic in 1940, lipedema is barely known in that country – to physicians or to the patients who have the disease. Lipedema often is confused with obesity, and a significant number of patients currently diagnosed as obese are believed to have lipedema, either instead of or in addition to obesity.\n\n"}
{"id": "49470944", "url": "https://en.wikipedia.org/wiki?curid=49470944", "title": "List of countries and dependencies by number of physicians", "text": "List of countries and dependencies by number of physicians\n"}
{"id": "49541051", "url": "https://en.wikipedia.org/wiki?curid=49541051", "title": "List of countries by body mass index", "text": "List of countries by body mass index\n\nThis page serves as a partial list of countries by adult mean body weight and incidence of obese and overweight populations as calculated by body mass index (BMI). \n\nThe data for 2014 was first published by the World Health Organization in 2015.\n\nMean body mass index (BMI) provides a simplified measure of the comparative weight of populations on a country by country basis. BMI calculates a person's mass (weight) divided by the square of their height. An individual with a BMI of 25 kg/m or more is considered overweight. An individual with a BMI of 30 kg/m or more is considered obese.\n\nThe data highlighted on this page comes from World Health Organization statistics for adult (18 years old and older) populations. Mean BMI data is shown separately for males and females, as well as a combined figure. Mean data highlights the central tendency of the population data and is but one method of calculating relative body weight between populations.\n\nThere are significant limitations to the usefulness of comparative BMI data cited by both the medical community and statisticians. BMI data has significant weaknesses in terms of scalability and in accounting for variations in physical characteristics. \n\nData published in 2015.\n\nData published in 2017.\n\nData published in 2015.\n"}
{"id": "403159", "url": "https://en.wikipedia.org/wiki?curid=403159", "title": "List of health departments and ministries", "text": "List of health departments and ministries\n\nMost executive governments in the world are divided into departments or ministries. In most such cases, there is a department or ministry responsible for health.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "19723", "url": "https://en.wikipedia.org/wiki?curid=19723", "title": "MUMPS", "text": "MUMPS\n\nMUMPS (\"Massachusetts General Hospital Utility Multi-Programming System\"), or M, is a general-purpose computer programming language originally designed in 1966 for the healthcare industry. Its differentiating feature is its \"built-in\" database, enabling high-level access to disk storage using simple symbolic program variables and subscripted arrays; similar to the variables used by most languages to access main memory.\n\nIt continues to be used today by many large hospitals and banks to provide high-throughput transaction data processing.\n\nMUMPS was developed by Neil Pappalardo, Robert Greenes, and Curt Marble in Dr. Octo Barnett's animal lab at the Massachusetts General Hospital (MGH) in Boston during 1966 and 1967.\n\nThe original MUMPS system was, like Unix a few years later, built on a spare DEC PDP-7. Octo Barnett and Neil Pappalardo were also involved with MGH's planning for a Hospital Information System, obtained a backward compatible PDP-9, and began using MUMPS in the admissions cycle and laboratory test reporting. MUMPS was then an interpreted language, yet even then, incorporated a hierarchical database file system to standardize interaction with the data.\n\nSome aspects of MUMPS can be traced from Rand Corporation's JOSS through BBN's TELCOMP and STRINGCOMP. The MUMPS team deliberately chose to include portability between machines as a design goal. Another feature, not widely supported for machines of the era, in operating systems or in computer hardware, was multitasking, which was also built into the language itself.\n\nThe portability was soon useful, as MUMPS was shortly adapted to a DEC PDP-15, where it lived for some time. MUMPS was developed with the support of a government research grant, and so MUMPS was released to the public domain (no longer a requirement for grants), and was soon ported to a number of other systems including the popular DEC PDP-8, the Data General Nova and the DEC PDP-11 and the Artronix PC12 minicomputer. Word about MUMPS spread mostly through the medical community, and by the early 1970s was in widespread use, often being locally modified for their own needs.\n\nBy the early 1970s, there were many and varied implementations of MUMPS on a range of hardware platforms. The most widespread was DEC's MUMPS-11 on the PDP-11, and MEDITECH's MIIS. In 1972, many MUMPS users attended a conference which standardized the then-fractured language, and created the MUMPS Users Group and MUMPS Development Committee (MDC) to do so. These efforts proved successful; a standard was complete by 1974, and was approved, on September 15, 1977, as ANSI standard, X11.1-1977. At about the same time DEC launched DSM-11 (Digital Standard MUMPS) for the PDP-11. This quickly dominated the market, and became the reference implementation of the time. Also, InterSystems sold ISM-11 for the PDP-11 (which was identical to DSM-11).\n\nDuring the early 1980s several vendors brought MUMPS-based platforms that met the ANSI standard to market. The most significant were:\n\nOther companies developed important MUMPS implementations:\n\nThis period also saw considerable MDC activity. The second revision of the ANSI standard for MUMPS (X11.1-1984) was approved on November 15, 1984.\n\n\n\nThe US Department of Veterans Affairs (formerly the Veterans Administration) was one of the earliest major adopters of the MUMPS language. Their development work (and subsequent contributions to the free MUMPS application codebase) was an influence on many medical users worldwide. In 1995, the Veterans Affairs' patient Admission/Tracking/Discharge system, Decentralized Hospital Computer Program (DHCP) was the recipient of the Computerworld Smithsonian Award for best use of Information Technology in Medicine. In July 2006, the Department of Veterans Affairs (VA) / Veterans Health Administration (VHA) was the recipient of the Innovations in American Government Award presented by the Ash Institute of the John F. Kennedy School of Government at Harvard University for its extension of DHCP into the Veterans Health Information Systems and Technology Architecture (VistA). Nearly the entire VA hospital system in the United States, the Indian Health Service, and major parts of the Department of Defense CHCS hospital system use MUMPS databases for clinical data tracking. In 2015 the Department of Defense awarded a 10 year contract to Leidos, Cerner, and Accenture to replace CHCS. In 2017 the Veterans Health Administration (VHA) announced that it would replace VistA with Cerner by 2024 or 2025. That contract did not affect the 2015 VHA contract for an online appointment scheduling from Epic, so the VHA will continue to use MUMPS. \n\nOther healthcare IT companies using MUMPS include Epic, MEDITECH, GE Healthcare (formerly IDX Systems and Centricity), AmeriPath (part of Quest Diagnostics), Care Centric, Allscripts, Coventry Healthcare, EMIS, and Sunquest Information Systems (formerly Misys Healthcare). Many reference laboratories, such as DASA, Quest Diagnostics, and Dynacare, use MUMPS software written by or based on Antrim Corporation code. Antrim was purchased by Misys Healthcare (now Sunquest Information Systems) in 2001.\n\nMUMPS is also widely used in financial applications. MUMPS gained an early following in the financial sector and is in use at many banks and credit unions. It is used by Ameritrade, the largest online trading service in the US, with over 12 billion transactions per day, as well as by the Bank of England and Barclays Bank, among others.\n\nSince 2005, the use of MUMPS has been either in the form of GT.M or InterSystems Caché. The latter is being aggressively marketed by InterSystems and has had success in penetrating new markets, such as telecommunications, in addition to existing markets. The European Space Agency announced on May 13, 2010 that it will use the InterSystems Caché database to support the Gaia mission. This mission aims to map the Milky Way with unprecedented precision.\n\nMUMPS is a language intended for and designed to build database applications. Secondary language features were included to help programmers make applications using minimal computing resources. The original implementations were interpreted, though modern implementations may be fully or partially compiled. Individual \"programs\" run in memory \"partitions\". Early MUMPS memory partitions were limited to 2048 bytes so aggressive abbreviation greatly aided multi-programming on severely resource limited hardware, because more than one MUMPS job could fit into the very small memories extant in hardware at the time. The ability to provide multi-user systems was another language design feature. The word \"Multi-Programming\" in the acronym points to this. Even the earliest machines running MUMPS supported multiple jobs running at the same time. With the change from mini-computers to micro-computers a\nfew years later, even a \"single user PC\" with a single 8-bit CPU and 16K or 64K of memory could support multiple users, who could connect to it from (non-graphical) video display terminals.\n\nSince memory was tight originally, the language design for MUMPS valued very terse code. Thus, every MUMPS command or function name could be abbreviated from one to three letters in length, e.g. Quit (exit program) as Q, $P = $Piece function, R = Read command, $TR = $Translate function. Spaces and end-of-line markers are significant in MUMPS because line scope promoted the same terse language design. Thus, a single line of program code could express, with few characters, an idea for which other programming languages could require 5 to 10 times as many characters. Abbreviation was a common feature of languages designed in this period (e.g., FOCAL-69, early BASICs such as Tiny BASIC, etc.). An unfortunate side effect of this, coupled with the early need to write minimalist code, was that MUMPS programmers routinely did not comment code and used extensive abbreviations. This meant that even an expert MUMPS programmer could not just skim through a page of code to see its function but would have to\nanalyze it line by line.\n\nDatabase interaction is transparently built into the language. The MUMPS language provides a hierarchical database made up of persistent sparse arrays, which is implicitly \"opened\" for every MUMPS application. All variable names prefixed with the caret character (\"^\") use permanent (instead of RAM) storage, will maintain their values after the application exits, and will be visible to (and modifiable by) other running applications. Variables using this shared and permanent storage are called \"Globals\" in MUMPS, because the scoping of these variables is \"globally available\" to all jobs on the system. The more recent and more common use of the name \"global variables\" in other languages is a more limited scoping of names, coming from the fact that unscoped variables are \"globally\" available to any programs running in the same process, but not shared among multiple processes. The MUMPS Storage mode (i.e. Globals\nstored as persistent sparse arrays), gives the MUMPS database the characteristics of a document-oriented database.\n\nAll variable names which are not prefixed with caret character (\"^\") are temporary and private. Like global variables, they also have a hierarchical storage model, but are only \"locally available\" to a single job, thus they are called \"locals\". Both \"globals\" and \"locals\" can have child nodes (called \"subscripts\" in MUMPS terminology). Subscripts are not limited to numerals—any ASCII character or group of characters can be a subscript identifier. While this is not uncommon for modern languages such as Perl or JavaScript, it was a highly unusual feature in the late 1970s. This capability was not universally implemented in MUMPS systems before the 1984 ANSI standard, as only canonically numeric subscripts were required by the standard to be allowed. Thus, the variable named 'Car' can have\nsubscripts \"Door\", \"Steering Wheel\" and \"Engine\", each of which can contain a value and have subscripts of their own. The variable ^Car(\"Door\") could have a nested variable subscript of \"Color\" for example. Thus, you could say\n\nto modify a nested child node of ^Car. In MUMPS terms, \"Color\" is the 2nd subscript of the variable ^Car (both the names of the child-nodes and the child-nodes themselves are likewise called subscripts). Hierarchical variables are similar to objects with properties in many object oriented languages. Additionally, the MUMPS language design requires that all subscripts of variables are automatically kept in sorted order. Numeric subscripts (including floating-point numbers) are stored from lowest to highest. All non-numeric subscripts are stored in alphabetical order following the numbers. In MUMPS terminology, this is \"canonical order\". By using only non-negative integer subscripts, the MUMPS programmer can emulate the arrays data type from other languages. Although MUMPS does not natively offer a full set of DBMS features such as mandatory schemas, several DBMS systems have been built on top of it that provide\napplication developers with flat-file, relational and network database features.\n\nAdditionally, there are built-in operators which treat a delimited string (e.g., comma-separated values) as an array. Early MUMPS programmers would often store a structure of related information as a delimited string, parsing it after it was read in; this saved disk access time and offered considerable speed advantages on some hardware.\n\nMUMPS has no data types. Numbers can be treated as strings of digits, or strings can be treated as numbers by numeric operators (\"coerced\", in MUMPS terminology). Coercion can have some odd side effects, however. For example, when a string is coerced, the parser turns as much of the string (starting from the left) into a number as it can, then discards the rest. Thus the statement codice_1 is evaluated as codice_2 in MUMPS.\n\nOther features of the language are intended to help MUMPS applications interact with each other in a multi-user environment. Database locks, process identifiers, and atomicity of database update transactions are all required of standard MUMPS implementations.\n\nIn contrast to languages in the C or Wirth traditions, some space characters between MUMPS statements are significant. A single space separates a command from its argument, and a space, or newline, separates each argument from the next MUMPS token. Commands which take no arguments (e.g., codice_3) require two following spaces. The concept is that one space separates the command from the (nonexistent) argument, the next separates the \"argument\" from the next command. Newlines are also significant; an codice_4, codice_3 or codice_6 command processes (or skips) everything else till the end-of-line. To make those statements control multiple lines, you must use the codice_7 command to create a code block.\n\nA simple Hello world program in MUMPS might be:\n\nand would be run from the MUMPS command line with the command codice_8. Since MUMPS allows commands to be strung together on the same line, and since commands can be abbreviated to a single letter, this routine could be made more compact:\n\nThe 'codice_9' after the text generates a newline.\n\nANSI X11.1-1995 gives a complete, formal description of the language; an annotated version of this standard is available online.\n\nData types: There is one universal datatype, which is implicitly coerced to string, integer, or floating-point datatypes as context requires.\n\nBooleans (called \"truthvalues\" in MUMPS): In IF commands and other syntax that has expressions evaluated as conditions, any string value is evaluated as a numeric value, and if that is a nonzero value, then it is interpreted as True. codice_10 yields 1 if a is less than b, 0 otherwise.\n\nDeclarations: None. All variables are dynamically created at the first time a value is assigned.\n\nLines: are important syntactic entities, unlike their status in languages patterned on C or Pascal. Multiple statements per line are allowed and are common. The scope of any IF, ELSE, and FOR command is \"the remainder of current line.\"\n\nCase sensitivity: Commands and intrinsic functions are case-insensitive. In contrast, variable names and labels are case-sensitive. There is no special meaning for upper vs. lower-case and few widely followed conventions. The percent sign (%) is legal as first character of variables and labels.\n\nPostconditionals: execution of almost any command can be controlled by following it with a colon and a truthvalue expression. codice_11 sets A to \"FOO\" if N is less than 10; codice_12 performs PRINTERR if N is greater than 100. This construct provides a conditional whose scope is less than a full line.\n\nAbbreviation: You can abbreviate nearly all commands and native functions to one, two, or three characters.\n\nReserved words: None. Since MUMPS interprets source code by context, there is no need for reserved words. You may use the names of language commands as variables. There has been no contest such as the International Obfuscated C Code Contest for MUMPS, despite the potential of examples such as the following, perfectly legal, MUMPS code:\n\nMUMPS can be made more obfuscated by using the contracted operator syntax, as shown in this terse example derived from the example above:\n\nArrays: are created dynamically, stored as B-trees, are sparse (i.e. use almost no space for missing nodes), can use any number of subscripts, and subscripts can be strings or numeric (including floating point). Arrays are always automatically stored in sorted order, so there is never any occasion to sort, pack, reorder, or otherwise reorganize the database. Built in functions such as $DATA, $ORDER, $NEXT(deprecated) and $QUERY functions provide efficient examination and traversal of the fundamental array structure, on disk or in memory.\n\nLocal arrays: variable names not beginning with caret (i.e. \"^\") are stored in memory by process, are private to the creating process, and expire when the creating process terminates. The available storage depends on implementation. For those implementations using partitions, it is limited to the partition size, (A small partition might be 32K). For other implementations, it may be several megabytes.\n\nGlobal arrays: codice_13. These are stored on disk, are available to all processes, and are persistent when the creating process terminates. Very large globals (for example, hundreds of gigabytes) are practical and efficient in most implementations. This is MUMPS' main \"database\" mechanism. It is used instead of calling on the operating system to create, write, and read files.\n\nIndirection: in many contexts, codice_14 can be used, and effectively substitutes the contents of VBL into another MUMPS statement. codice_15 sets the variable ABC to 123. codice_16 performs the subroutine named REPORT. This substitution allows for lazy evaluation and late binding as well as effectively the operational equivalent of \"pointers\" in other languages.\n\nPiece function: This breaks variables into segmented pieces guided by a user specified separator string (sometimes called a \"delimiter\"). Those who know awk will find this familiar. codice_17 means the \"third caret-separated piece of STRINGVAR.\" The piece function can also appear as an assignment (SET command) target.\n\ncodice_18 yields \"std\".\n\nAfter\ncodice_19 causes X to become \"office@world.std.com\" (note that $P is equivalent to $PIECE and could be written as such).\n\nOrder function: This function treats its input as a structure, and finds the next index that exists which has the same structure except for the last subscript. It returns the sorted value that is ordered after the one given as input. (This treats the array reference as a content-addressable data rather than an address of a value)\n\ncodice_20 yields 6, codice_21 yields 10, codice_22 yields 10, codice_23 yields 15, codice_24 yields \"\".\n\nHere, the argument-less \"For\" repeats until stopped by a terminating \"Quit\". This line prints a table of i and stuff(i) where i is successively 6, 10, and 15.\n\nFor iterating the database, the Order function returns the next key to use.\n\nMulti-User/Multi-Tasking/Multi-Processor: MUMPS supports multiple simultaneous users and processes even when the underlying operating system does not (e.g., MS-DOS). Additionally, there is the ability to specify an environment for a variable, such as by specifying a machine name in a variable (as in codice_25), which can allow you to access data on remote machines.\n\nSome aspects of MUMPS syntax differ strongly from that of more modern languages, which can cause confusion. Whitespace is not allowed within expressions, as it ends a statement: codice_26 is an error, and must be written codice_27. All operators have the same precedence and are left-associative (codice_28 evaluates to 50). The operators for \"less than or equal to\" and \"greater than or equal to\" are codice_29 and codice_30 (that is, the boolean negation operator codice_31 plus a strict comparison operator).\n\nMUMPS lacks a while statement; a GOTO statement can be used to simulate one. By default, the IF, ELSE, and FOR statements use the rest of the line as their block. The DO statement allows one of them to span multiple lines; periods (codice_32) are used to indent the lines in a DO block. The ELSE statement does not need a corresponding IF, as it operates by inspecting the value in the builtin system variable codice_33.\n\nMUMPS scoping rules are more permissive than other modern languages. Declared local variables are scoped using the stack. A routine can normally see all declared locals of the routines below it on the call stack, and routines cannot prevent routines they call from modifying their declared locals. By contrast, undeclared variables (variables created by using them, rather than declaration) are in scope for all routines running in the same process, and remain in scope until the program exits.\n\nAll of the following positions can be, and have been, supported by knowledgeable people at various times:\n\nSome of the contention arose in response to strong M advocacy on the part of one commercial interest, InterSystems, whose chief executive disliked the name MUMPS and felt that it represented a serious marketing obstacle. Thus, favoring M to some extent became identified as alignment with InterSystems. The dispute also reflected rivalry between organizations (the M Technology Association, the MUMPS Development Committee, the ANSI and ISO Standards Committees) as to who determines the \"official\" name of the language. Some writers have attempted to defuse the issue by referring to the language as \"M[UMPS]\", square brackets being the customary notation for optional syntax elements. A leading authority, and the author of an open source MUMPS implementation, Professor Kevin O'Kane, uses only 'MUMPS'.\n\nThe most recent standard (ISO/IEC 11756:1999, re-affirmed on 25 June 2010), still mentions both M and MUMPS as officially accepted names.\n\nMassachusetts General Hospital registered \"MUMPS\" as a trademark with the USPTO on November 28, 1971, and renewed it on November 16, 1992 - but let it expired on August 30, 2003.\n\nMUMPS invites comparison with the Pick operating system. Similarities include:\n\n\n\n\n"}
{"id": "53716092", "url": "https://en.wikipedia.org/wiki?curid=53716092", "title": "Mental health inequality", "text": "Mental health inequality\n\nMental health inequality refers to the differences in quality of mental health and mental health care for different identities and populations. Mental health can be defined as well-being and/or the absence of clinically defined mental illness. There are social economic factors that influence individuals or groups of people of a certain demographic. This can be a factor to mental health care access. Inequalities may include presence of mental health, access to mental health care, quality of mental health care, and mental health outcomes between populations with different race, ethnicity, sexual orientation, sex, gender, socioeconomic statuses, education level, and geographic location.\n\nSocial determinants of health are factors such as economic status, education level, demographics, where you live and genetics that can influence one's health. Due to experiences certain populations are much more susceptible to mental disorders or illnesses. Traumatic experiences can develop by the lack of resources of the determinants of health. Not having employment or being from a certain area where those resources are limited trigger some of the most common mental disorders. ( Depression, anxiety, bipolar, psychological stress) Mental health within itself leads to the inequality among the social determinants of health. The economic level of one's life is a factor to their life expectancy and mental health. For example lung cancer is by far the most preventable disease yet the rates of consumption of tobacco just increase. Ironically the consumers are those with mental disorders.\n\nWhile education and mental health seem mutually exclusive, there is a significant parallel between the inequities. Educational disparities can be defined as unjust or unfair differences in educational outcomes that can be a result of difference in treatment of certain minority groups in schools, varying socioeconomic statuses, and varying educational needs. These disparities in education can ultimately lead to issues of mental health. When this happens, less privileged groups get looped into the cascading effects of inequality.\n\nThe disparities that arise in education do not happen by chance. There are definitely predictors that factor into these inequalities. Some common ones are socioeconomic status, immigrant status, and ethnic/racial status. Socioeconomic status plays a large role in the difference in access to educational resources. School districts are split geographically. Because the current funding for public schools comes from local property taxes, there is more incentive for high-status individuals to narrow the boundaries to not include lower income families from their school districts. Because each school district is then only encompassing one socioeconomic group, the programs and quality are affected. This is where we begin to see the dramatic differences between school districts. While some schools offer amazing guidance departments, advanced classes, and phenomenal facilities, other areas struggle to find qualified and motivated teachers to teach basic classes. Although public education is something that is supposed to be a right for all, an individual's socioeconomic status can greatly affect the quality of that education.\n\nAn individual's immigration status also affects the quality of education received. While there are some immigrant groups which do well after immigrating to the United States, many do not have the same level of success. There are many barriers that prevent the academic success of immigrant children. These barriers include but are not limited to the fact that most parents of immigrant children do not understand the United States educational system, inadequate English as a Second Language programs, and segregation. There are also differences in outcomes across immigrant generation, with first-generation immigrants performing better than subsequent generations. This is termed the immigrant paradox. These issues along with the psychological effects of acculturation (e.g., adapting to a whole new country, language, and culture) amplify educational inequality.\n\nDisparities in education are the insufficiency of resources that are included but limited. These disparities usually targets socially excluded communities with low income. Statistics are used when measuring grades, GPA, test scores, and dropout rates to determine the success of students. Disparities as such affect somones mental health by creating a system in which a person could never succeed.\n\nFurther research observes that those minority races living in areas of low-poverty have more and easier access to mental health services than those in high-poverty neighborhoods. There is a pattern of people in high-poverty areas being unable escape this cycle. Due to these conditions, inequality remains and they are unable to gain access to mental health care which can be very beneficial to those who may be suffering from stress due to lack of resources and money.\n\nMany minorities including African Americans, Hispanics, and Asian Americans inhabit these poverty filled neighborhoods due to factors being not in their favor in certain aspects of society. These neighborhoods lack resources such as offices with psychiatrists or health clinics with good doctors who are trained to help those in need of mental health care. It would also be beneficial to make specific services just for those in high-poverty neighborhoods who lack the resources so we can encourage those in need to get the help that they deserve. With adjustments made to meet these circumstances, the spatial disparities can be lowered and allow those who need the help to get it.\n\nThere is inequality in mental health care access for different races and ethnicities. It is known through much research that even poor minorities have less access to mental health care than poor non-Latino whites. In addition, it is also known that blacks have even less of a chance to access to mental health services and care than those who are white. Many of these minorities may confront an issue directly resulting in the search for mental health care support, yet they don't have the same access as other people.\n\nAfter surveying people of different races over years we observe that African Americans, Hispanics, and Asian Americans gain less access to the same type of mental services that non-minority whites get access to. With this research there was a piece that stated:\n\n\"This theory postulates that Whites have a greater propensity to avoid living in poverty communities because they are more likely to enjoy social and economic advantages. Only seriously mentally ill Whites suffer from steep downward mobility and come to reside in high-poverty neighborhoods\" (Julian Chun-Chung Chow, Kim Jaffee, and Lonnie Snowden).\n\nThis has been a problem for minority races that need the same services. It is an issue because African Americans, Hispanics, and Asian Americans need the services more in certain areas due to how biologically certain minority races are more likely to be diagnosed with a mental illness than whites.\n\nSexuality plays a large role in the prediction of mental illnesses and overall mental health. Those who identify as lesbian, gay, bisexual, transgender, and/or queer have a higher risk of having mental health issues, most likely as a result of the continued discrimination and victimization they receive at the hands of others. Members of this population are confronted with derogatory and hateful comments, whether through face-to-face communication or through social media, which affects their self-worth and confidence, leading to anxiety, depression, thoughts of suicide, suicide attempts, and suicide. These mental health effects are most commonly seen among adolescents, however, they are also prevalent among adults of all ages. The sources of discrimination and victimization that the LGBTQ population suffers from can be both external and internal. While parts of society today are not accepting of the LGBTQ community and make public statements to advertise their discontent, an identifying LGBTQ can also have low confidence and a lack of self-worth that furthers these negative mental health effects.\n\nThe most notable predictor of mental health illnesses among the LGBTQ population is family acceptance. Those of the LGBTQ population who receive little or no family support and acceptance are three times more likely to have thoughts of suicide than those who do have a strong family support system behind them. Oftentimes, the lack of familial support is more conducive of detrimental behaviors, such as drug and illegal substance abuse, which can cause further harm to the individual. Multiple aspects of lifestyles, including religion, can affect family support. Those who have strong family ties to religion may be less likely to seek support and help from family members due to fear of a lack of acceptance within the family, as well as within the religious community.\n\nWhile gender differences among those with mental health disorders are an underdeveloped field of study, there are gender specific aspects to life that cause disparities. Gender is often a determinant of the amount of power one has over factors in their life, such as socioeconomic status and social position, and the stressors that go along with these factors. The location of genders and sex within the social construct can be a great determinant of risks and predictors of mental health disorders. These disparities in gender can correlate to the disparities in the types of mental health disorders that individuals have. While all genders and sexes are at risk of a large variety of mental health illnesses, some illnesses and disorders are more common among one sex than another. Women are twice as likely as men to be diagnosed with forms of depression, whereas men are three times more likely to be given a diagnosis of a social anxiety disorder than women.\n\nSex can also be a determinant of other aspects of mental health as well. The time of onset of symptoms can be different dependent on one's sex. Women are more likely to show signs of mental illnesses, such as depression, earlier and at a younger age than men. Many believe this to be a correlation with the onset time of puberty. As a result of social stigmatisms and stereotypes within society, women are also more likely to be prescribed mood-altering medications, whereas men are more likely to be prescribed medications for addictions. Further research on the mental health disparities among sex and gender is needed in order to gain a deeper knowledge of the predictors of mental health and the possible differences in treatments.\n\nOver the past decade, many of the disparities regarding mental health stem from differences in racial/ethnic groups. Mental illness is one of the highest health burdens for minority groups.\n\nIn many minority groups, certain mental illnesses are under and over diagnosed. For example, schizophrenia is over diagnosed in African Americans while mood disorders, depression, and anxiety are under diagnosed. This is due to a variety of reasons. The recognition of mental illness is often thought of in conjunction with stereotypes regarding African Americans. Those who present symptoms exhibiting depression and mood swings may be mistaken as stereotypically violent.\n\nWhile the diagnosis of these minority groups is vastly different, the care they receive also varies between whites and minority groups. This is not only due to external factors and facilities but also the way in which these minority groups choose to proceed with treatment. African Americans generally do receive care from lower quality facilities, but they are also more likely than whites to terminate treatment prematurely.\n\nFinally, health care plans are also a major contributor to the inequities in mental health care access. Provider discrimination involves health care providers unfairly using stereotypes to decide how to distribute diagnoses. Physicians often rely on common stereotypes of individuals in deciding treatment, which ultimately leads to minority groups not getting the specialized treatment required to diagnose and treat mental illness.\n\nThere is a growing unmet need for mental health services and equity in the quality of these services. While these services often advertise themselves as being a support system and caregiver for any and all who need treatment or support, oftentimes certain aspects of an individual's life, such as race, ethnicity, and sexual orientation, will determine the type of care that they are given.\n\nDue to a growing level of socioeconomic inequality among races, African Americans are less likely to have access to mental health care and are more likely to have lesser quality care when they do find it. African Americans and Hispanics are more likely to be uninsured or have Medicaid, limiting the amount and type of access that they have mental health outpatient sources. In one study, of all those who received mental health care, minority populations reported a higher degree of unmet needs and dissatisfaction with the services they were given (12.5% of whites, 25.4% of African Americans, and 22.6% of Hispanics reported poor care).\n\nThe LGBTQ population, while still open to the same disparities as racial minority groups, is often confronted with the problem of being denied mental health treatment because of the gender they identify as or their sexual orientation. In a study conducted by The National Center for Transgender Equality and the National Gay and Lesbian Task Force, 19% of the LGBTQ sample reported being denied the healthcare they needed. In addition, 28% of the sample reported being harassed or even physically assaulted during the health visit. While denial of treatment and harassment during treatment are large causes of the disparities among mental health care quality, the lack of knowledge is also of concern among the LGBTQ population. As it is such a newly developing field of study, there is very little knowledge or research conducted that relate specifically to LGBTQ health and healthcare. Because of this, about 50% of the LGBTQ population report having to teach aspects of their health and treatment to the health care providers.\n\nBecause mental health inequality is largely due to disparities in health insurance, ways to improve mental health equity must come from changes in healthcare policies. While much of mental health disparities comes from improving access to healthcare for the underprivileged. The biggest reason why people are not obtaining mental health care is because they cannot afford it. Also, changing the content of healthcare literature to include mental health is equally important. The United States has made massive strides to break down the stigmas surrounding mental health. Given that, mental health is still not considered to be a main part of basic health care plans. In order for individuals to receive the treatment necessary for mental illness, it must be acknowledged as an illness.\n\n"}
{"id": "13305310", "url": "https://en.wikipedia.org/wiki?curid=13305310", "title": "Mindset Network", "text": "Mindset Network\n\nMindset Network is a non-profit organisation formed in 2002 to educate and improve health in South Africa. It develops, sources, distributes and uses digital content. Its multimedia content is distributed via broadcast television, IP based satellite datacast, the web, distributable media (hard drives, DVDs and CDs) and mobile networks.\n\nMindset has 3 programmes. Learn and Cabanga are for secondary and primary schools respectively, while Health is for the South African health sector. Mindset is developing a Livelihoods channel for developing the skills of out-of-school youth.\n\nMindset Learn, the original programme, is for Grades 10 to 12 at South African high schools. It covers Mathematics, Physical Science, English and Information Technology.\n\nMindset Cabanga, with support from USAID, is a programme for Grades 4 and 5 covering Mathematics, Natural Science and Technology.\n\nMindset Health is about treating HIV/AIDS. The programme reaches patients in clinic and hospital waiting rooms, and health care providers.\n\n"}
{"id": "57819966", "url": "https://en.wikipedia.org/wiki?curid=57819966", "title": "Minnesota Department of Health", "text": "Minnesota Department of Health\n\nThe Minnesota Department of Health (MDH) is the state health agency of the State of Minnesota in the United States. The department has four offices in Saint Paul and seven outside of the Twin Cities metropolitan area: Bemidji, Duluth, Fergus Falls, Mankato, Marshall, Rochester, and St. Cloud.\n\nThe agency is responsible for Minnesotans' public health, including disease control and prevention, environmental health, public policy, and regulation of health care providers.\n"}
{"id": "429680", "url": "https://en.wikipedia.org/wiki?curid=429680", "title": "National Institute for Health and Care Excellence", "text": "National Institute for Health and Care Excellence\n\nThe National Institute for Health and Care Excellence (NICE) is an executive non-departmental public body of the Department of Health in the United Kingdom, which publishes guidelines in four areas: \n\nThese appraisals are based primarily on evaluations of efficacy and cost-effectiveness in various circumstances.\n\nIt serves both the English NHS and the Welsh NHS. It was set up as the National Institute for Clinical Excellence in 1999, and on 1 April 2005 joined with the Health Development Agency to become the new National Institute for Health and Clinical Excellence (still abbreviated as NICE). Following the Health and Social Care Act 2012, NICE was renamed the National Institute for Health and Care Excellence on 1 April 2013 reflecting its new responsibilities for social care, and changed from a special health authority to an Executive Non-Departmental Public Body (ENDPB).\n\nNICE was established in an attempt to end the so-called postcode lottery of healthcare in England and Wales, where treatments that were available depended upon the NHS Health Authority area in which the patient happened to live, but it has since acquired a high reputation internationally as a role model for the development of clinical guidelines. One aspect of this is the explicit determination of cost–benefit boundaries for certain technologies that it assesses. NICE also plays an important role in pioneering technology assessment in other healthcare systems through NICE International, established in May 2008 to help cultivate links with foreign governments.\n\nThe notion of an Institute to determine the clinical effectiveness of interventions first emerged at the end of John Major's Conservative Government as moves elsewhere were being made to set professionally agreed standards for clinical care. In 1996, the UK National Screening Committee (NSC) had been established by Sir Kenneth Calman and Muir Gray (now Sir Muir Gray) by the Policy Team led by Dr Tim Riley and latterly Sir Charles Nightingale for the Department of Health. The NSC aimed to ensure that evidence-based medicine informed policy making on what national screening programmes were approved for funding and what quality assurance mechanisms should be in place. This was a timely action as concerns over screening quality had emerged in breast cancer screening services came under question at Exeter in 1997 and followed in the wake of the 1995 Calman-Hine Report.\n\nThe idea of what was originally termed a National Institute for Clinical Excellence took root when Labour came to power having in 1997. Frank Dobson became Secretary of State and was supported by a team of Ministers keen on introducing clinical and health outcome measures to achieve improvements in the quality and delivery of care. The team included Alan Milburn, Baroness Margaret Jay, and Tessa Jowell. The name and mission was agreed in a meeting between the Ministerial team, Dr Tim Riley and Dr Felicity Harvey shortly after the election and it was agreed that NICE should be described in the first policy white paper, The New NHS: Modern, Dependable 1997. Riley led the team that developed the policy for NICE and which managed the legislation through Parliament in addition to formalising the new institute as a Special Health Authority. Riley joined Sir Michael Rawlins (the then recently appointed Chair of NICE) at the Health Select Committee in February 1999 where questions were raised as to whether NICE was just a means to \"ration\" healthcare. Sir Michael Rawlins presented a compelling case that positioned NICE as a standards setting body first and foremost. \nHowever, the reality was that although NICE was principally aimed at aligning professional standards through clinical guidelines and audit, the acceptability of drugs, devices and technological interventions in defining those standards, could not be ignored and so the concept of a \"fourth hurdle\" for drugs accessing the NHS market was invoked. This controversial policy shift meant that NICE was critical for decisions on drug reimbursement. Indeed, the first drug appraisal by NICE was on the drug Relenza which was turned down amidst criticisms from Glaxo-Wellcome that the appraisal had been fast tracked. Later, this policy development whereby the criteria for decision making, the role of costs, and the degree to which decisions of NICE and the secretary of state would be binding on clinicians was analysed by Andrew Dillon, Trevor Gibbs, Tim Riley, and Trevor A. Sheldon.\n\nSince January 2005, the NHS in England and Wales has been legally obliged to provide funding for medicines and treatments recommended by NICE's technology appraisal board. This was at least in part as a result of well-publicised postcode lottery anomalies in which certain less-common treatments were funded in some parts of the UK but not in others due to local decision making in the NHS.\n\nBefore an appraisal, the Advisory Committee on Topic Selection (ACTS) draws up a list of potential topics of clinical significance for appraisal. The Secretary of State for Health or the Welsh Assembly must then refer any technology so that the appraisal process can be formally initiated. Once this has been done NICE works with the Department of Health to draw up the scope of the appraisal.\n\nNICE then invites consultee and commentator organisations to take part in the appraisal. A consultee organisation would include patient groups, organisations representing health care professionals and the manufacturers of the product undergoing appraisal. Consultees submit evidence during the appraisal and comment on the appraisal documents. Commentator organisations include the manufacturers of products to which the product undergoing appraisal is being compared. They comment on the documents that have been submitted and drawn up but do not actually submit information themselves.\n\nAn independent academic centre then draws together and analyses all of the published information on the technology under appraisal and prepares an assessment report. This can be commented on by the Consultees and Commentators. Comments are then taken into account and changes made to the assessment report to produce an evaluation report. An independent Appraisal Committee then looks at the evaluation report, hears spoken testimony from clinical experts, patient groups and carers. They take their testimony into account and draw up a document known as the 'appraisal consultation document'. This is sent to all consultees and commentators who are then able to make further comments. Once these comments have been taken into account the final document is drawn up called the 'final appraisal determination'. This is submitted to NICE for approval.\n\nThe process aims to be fully independent of government and lobbying power, basing decisions fully on clinical and cost-effectiveness. There have been concerns that lobbying by pharmaceutical companies to mobilise media attention and influence public opinion are attempts to influence the decision-making process. A fast-track assessment system has been introduced to reach decisions where there is most pressure for a conclusion.\n\nNICE carries out assessments of the most appropriate treatment regimes for different diseases. This must take into account both desired medical outcomes (i.e. the best possible result for the patient) and also economic arguments regarding differing treatments.\n\nNICE has set up several National Collaborating Centres bringing together expertise from the royal medical colleges, professional bodies and patient/carer organisations which draw up the guidelines. The centres are the National Collaborating Centre for Cancer, the National Clinical Guideline Centre, the National Collaborating Centre for Women and Children´s Health, and the National Collaborating Centre for Mental Health.\n\nThe National Collaborating Centre appoints a Guideline Development Group whose job it is to work on the development of the clinical guideline. This group consists of medical professionals, representatives of patient and carer groups and technical experts. They work together to assess the evidence for the guideline topic (e.g. clinical trials of competing products) before preparing a draft guideline. There are then two consultation periods in which stakeholder organisations are able to comment on the draft guideline. After the second consultation period, an independent Guideline Review Panel reviews the guideline and stakeholder comments and ensures that these comments have been taken into account. The Guideline Development Group then finalises the recommendations and the National Collaboration Centre produces the final guideline. This is submitted to NICE to formally approve the guideline and issue the guidance to the NHS. To date NICE has produced more than 200 different guidelines.\n\nIn October 2014 Andy Burnham said that a Labour government could reduce variation in access to drugs and procedures by making it mandatory for commissioners to follow NICE clinical guidelines. \"We need to look at how you strengthen NICE. Where they have said something is effective and affordable, on what basis does a local commissioner withhold that from somebody? I’m not comfortable with that. I don’t support that.\"\n\nNICE has a service called Clinical Knowledge Summaries (CKS) which provides primary care practitioners with a readily accessible summary of the current evidence base and practical guidance.\n\nUnder the Health and Social Care Act 2012, NICE was given responsibility for developing guidance and quality standards for social care, using an evidence-based model. This is being delivered by the NICE Collaborating Centre for Social Care (NCCSC), which is hosted by the Social Care Institute for Excellence (SCIE) and 4 partner organisations - Research in Practice, Research in Practice for Adults, Personal Social Services Research Unit and the EPPI-Centre.\n\nNICE receives referrals for social care guidance from the Department of Health and the Department for Education, and commission the guidance from the NCCSC. NICE, along with the NCCSC, carries out a scoping exercise with a scoping group and with input from key stakeholders, at both a workshop and a public consultation, to ensure the guidance to be produced is focused and achievable. A chairperson and members of the Guidance Development Group are appointed, and pose review questions which will enable systematic evidence reviews to take place, thus delivering the guidance and subsequent recommendations. Service user and carer involvement takes place throughout, as well as public consultation on the draft guidance.\n\nThe Guidance Development Group then finalises the recommendations and the NCCSC produces the final guideline. This is submitted to NICE for formal approval and publication. The entire process from pre-scoping to publication takes approximately 24 months. The guidance is then available to NICE standing committees to develop a quality standard on the topic. The quality standard is developed using the guidance and other accredited sources, to produce high-level concise statements that can be used for quality improvement by social care providers and commissioners, as well as setting out what service users and carers can expect of high quality social care services.\n\nThe NCCSC is unique within NICE, in that it is the only collaborating centre to have responsibility for the adoption and dissemination support for guidance and quality standards in the social care arena. Drawing on the expertise of SCIE and their partners within the sector, each of the guidance products and quality standards have a needs assessment carried out to determine the requirements for tools to help embed the guidance and quality standards within the sector. These can include tailored versions of guidance for specific audiences, costing and commissioning tools and even training and learning packages.\n\nAs of August 2013, NICE and the NCCSC had scheduled guidance delivery for five topics: domiciliary care, older adults with long-term conditions, transition between health and social care settings, transition from children's to adults' services and child abuse and neglect.\n\nAs with any system financing health care, the NHS has a limited budget and a vast number of potential spending options. Choices must be made as to how this limited budget is spent. Economic evaluations are carried out within a health technology assessment framework to compare the cost-effectiveness of alternative activities and to consider the opportunity cost associated with their decisions. By choosing to spend the finite NHS budget upon those treatment options that provide the most efficient results, society can ensure it does not lose out on possible health gains through spending on inefficient treatments and neglecting those that are more efficient.\n\nNICE attempts to assess the cost–effectiveness of potential expenditures within the NHS to assess whether or not they represent 'better value' for money than treatments that would be neglected if the expenditure took place. It assesses the cost–effectiveness of new treatments by analysing the cost and benefit of the proposed treatment relative to the next best treatment that is currently in use.\n\nNICE guidance supports the use of quality-adjusted life years (QALY) as the primary outcome for quantifying the expected health benefits associated with a given treatment regime. By comparing the present value (see discounting) of expected QALY flows with and without treatment, or relative to another treatment, the net/relative health benefit derived from such a treatment can be derived. When combined with the relative cost of treatment, this information can be used to estimate an incremental cost-effectiveness ratio (ICER), which is considered in relation to NICE's threshold willingness-to-pay value.\n\nAs a guideline rule, NICE accepts as cost-effective those interventions with an incremental cost-effectiveness ratio of less than £20,000 per QALY and that there should be increasingly strong reasons for accepting as cost-effective interventions with an incremental cost-effectiveness ratio of over a threshold of £30,000 per QALY.\n\nOver the years, there has been great controversy as to what value this threshold should be set at. Initially, there was no fixed number. But the appraisal teams created a consensus amount of about £30,000. However, in November 2008 Alan Johnson, the then Secretary of State, announced that for end-of-life cancer drugs the threshold could be increased above £30,000. \nThe first drug to go through the new process was Lenalidomide, whose ICER was £43,800.\n\nThe following example from NICE explains the QALY principle and the application of the cost per QALY calculation.\n\nA patient has a life-threatening condition and is expected to live on average for 1 year receiving the current best treatment which costs the NHS £3,000. A new drug becomes available that will extend the life of the patient by three months and improve his or her quality of life, but the new treatment will cost the NHS more than three times as much at £10,000. Patients score their perceived quality of life on a scale from 0 to 1 with 0 being worst possible health and 1 being best possible health. On the standard treatment, quality of life is rated with a score of 0.4 but it improves to 0.6 with the new treatment. Patients on the new treatment on average live an extra 3 months, so 1.25 years in total. The quality of life gained is the product of \"life span\" and \"quality rating\" with the new treatment less the same calculation for the old treatment, i.e. (1.25 x 0.6) less (1.0 x 0.4) = 0.35 QALY. The marginal cost of the new treatment to deliver this extra gain is £7,000 so the cost per quality life year gained is £7000/0.35 or £20,000. This is within the £20,000-£30,000 that is suggested by NICE to be the limit for drugs to be cost-effective.\n\nIf the patient was expected to live only one month extra and instead of three then NICE would issue a recommendation not to fund. The patient's Primary Care Trust could still decide to fund the new treatment, but if not, the patient would then have two choices. He or she could opt to take the free NHS standard treatment, or he or she may decide to pay out of pocket to obtain the benefit of the new treatment from a different health care provider. If the person has a private health insurance policy the person could check to see whether the private insurance provider will fund the new treatment. About 8% of the population has some private health insurance from an employer or trade association and 2% pay from their own resources.\n\nTheoretically, it might be possible to draw up a table of all possible treatments sorted by increasing the cost per quality-adjusted life year gained. Those treatments with lowest cost per quality-adjusted life year gained would appear at the top of the table and deliver the most benefit per value spent and would be easiest to justify funding for. Those where the delivered benefit is low and the cost is high would appear at the bottom of the list. Decision makers would, theoretically, work down the table, adopting services that are the most cost effective. The point at which the NHS budget is exhausted would reveal the shadow price, the threshold lying between the CQG gained of the last service that is funded and that of the next most cost effective service that is not funded.\n\nIn practice this exercise is not done, but an assumed shadow price has been used by NICE for many years in its assessments to determine which treatments the NHS should and should not fund. NICE states that for drugs the cost per QALY should not normally exceed £30,000 but that there is not a hard threshold, though research has shown that any threshold is \"somewhat higher\" than being in the range £35,000 - £40,000.\n\nThe House of Commons Health Select Committee, in its report on NICE, stated in 2008 that \"the (...) cost-per-QALY it uses to decide whether a treatment is cost-effective is of serious concern. The threshold it employs is not based on empirical research and is not directly related to the NHS budget, nor is it at the same level as that used by Primary Care Trusts (PCTs) in providing treatments not assessed by NICE, which tends to be lower. Some witnesses, including patient organisations and pharmaceutical companies, thought NICE should be more generous in the cost per QALY threshold it uses, and should approve more products. On the other hand, some PCTs struggle to implement NICE guidance at the current threshold and other witnesses argued that a lower level should be used. However, there are many uncertainties about the thresholds used by PCTs.\" It went on to recommend that \"an independent body should determine the threshold used when making judgements of the value of drugs to the NHS.\"\n\nThe work that NICE is involved in attracts the attention of many groups, including doctors, the pharmaceutical industry, and patients. NICE is often associated with controversy, because the need to make decisions at a national level can conflict with what is (or is believed to be) in the best interests of an individual patient.\n\nApproved cancer drugs and treatments such as radiotherapy and chemotherapy are funded by the NHS without any financial contribution being taken from the patient. Where NICE has approved a treatment, the NHS must fund it. But not all treatments have been assessed by NICE and these treatments are usually dependent on local NHS decision making. In the case of cancer the Cancer Drugs Fund was set up in 2011 after complaints about NICE decisions on new and expensive cancer drugs with limited benefits. Treatment for fertility problems are approved but not always funded by clinical commissioning groups and they may cap the number of rounds.\n\nNICE has been criticised for being too slow to reach decisions. On one occasion, the Royal National Institute of Blind People said it was outraged over its delayed decision for further guidance regarding two drugs for macular degeneration that are already approved for use in the NHS. However the Department of Health said that it had 'made it clear to PCTs that funding for treatments should not be withheld simply because guidance from NICE is unavailable'.\n\nSome of the more controversial NICE decisions have concerned donepezil, galantamine, rivastigmine (review) and memantine for the treatment of Alzheimer's disease and bevacizumab, sorafenib, sunitinib and temsirolimus for renal cell carcinoma. All these are drugs with a high cost per treatment and NICE has either rejected or restricted their use in the NHS on the grounds that they are not cost-effective.\n\nA Conservative shadow minister once criticized NICE for spending more on communications than assessments. In its defence, NICE said the majority of its communications budget was spent informing doctors about which drugs had been approved and new guidelines for treatments and that the actual cost of assessing new drugs for the NHS includes money spent on NICE's behalf by the Department of Health. When these were added to NICE's own costs, the total cost of the technology appraisal programme far outstrips the cost of NICE communications.\n\nA report from the University of York Centre for Health Economics written by Karl Claxton in February 2015 suggested that the maximum threshold, currently around £30,000 a year, for judging a medicine cost-effective should be more than halved. They found that any intervention costing more than £13,000 per Quality-adjusted life year risked causing more harm than good by denying cost effective treatment to other patients.\n\nThe institute's approach to the introduction of new oral therapy for Hepatitis C has been criticised. Sofosbuvir was approved in 2015. It costs about £30,000 for 12 weeks treatment. NHS England established 22 Operational Delivery Networks to roll out delivery and proposes to fund 10,000 courses of treatment in 2016-17. Each has been given a “run rate” of how many patients they are allowed to treat. This is the NHS’ single biggest new treatment investment this year. In the North East London network patients with cirrhosis or fibrosis go to the front of the queue and three new patients at the Grahame Hayton Unit at the Royal London Hospital start treatment each month. Those without such complications may faced considerable delays before they start treatment.\n\n\n"}
{"id": "46559303", "url": "https://en.wikipedia.org/wiki?curid=46559303", "title": "Non-specific effect of vaccines", "text": "Non-specific effect of vaccines\n\nNon-specific effects of vaccines (also called \"heterologous effects\" or \"off-target effects\") are effects which go beyond the specific protective effects against the targeted diseases. Non-specific effects can be strongly beneficial, increasing protection against non-targeted infections, but also at times negative, increasing susceptibility to non-targeted infections. This depends on both the vaccine and the sex of the infant.\n\nAll live attenuated vaccines studied so far (BCG vaccine, measles vaccine, oral polio vaccine, smallpox vaccine) have been shown to reduce mortality more than can be explained by prevention of the targeted infections. In contrast, inactivated vaccines (diphtheria-tetanus-pertussis vaccine (DTP), hepatitis B vaccine, inactivated polio vaccine) may increase overall mortality despite providing protection against the target diseases.\n\nThese effects may be long-lasting, at least up to the time point where a new type of vaccine is given. The non-specific effects can be very pronounced, with significant effects on overall mortality and morbidity. In a situation with herd immunity to the target disease, the non-specific effects can be more important for overall health than the specific vaccine effects.\n\nThe non-specific effects should not be confused with the side effects of vaccines (such as local reactions at the side of vaccination or general reactions such as fever, head ache or rash, which usually resolve within days to weeks – or in rare cases anaphylaxis). Rather, non-specific effects represent a form of general immunomodulation, with important consequences for the immune system's ability to handle subsequent challenges.\n\nIt is estimated that millions of child deaths in low income countries could be prevented every year if the non-specific effects of vaccines were taken into consideration in immunization programs.\n\nThe hypothesis that vaccines have non-specific effects was formulated in the early 1990s by Peter Aaby at the Bandim Health Project in West Africa.\n\nThe first indication of the importance of the non-specific effects of vaccines came in a series of randomized controlled trials (RCTs) in the late 1980s. It was tested whether a high-titer (high-dose) measles vaccine (HTMV) given at 4–6 months of age was as effective against measles infection as the standard measles vaccine (MV) given at 9 months of age. Early administration of the HTMV prevented measles infection just as effectively as did the standard MV given at 9 months of age.\n\nHowever, early administration of the HTMV was associated with twofold \"higher\" overall mortality among females (there was no difference in mortality for males). In other words, the girls given HTMV died more often despite having the same protection against measles as the infants given standard MV. The discovery forced WHO to withdraw the HTMV in 1992. It was later discovered that it was not the HTMV, but rather a subsequent inactivated vaccine (DTP or IPV for different children), that caused the increase in female mortality. Although the mechanism was different than initially thought, this finding represents unexpected effects of a change in the vaccine program not attributable to the disease-specific protection provided by the vaccines.\n\nThis first observation that vaccines could protect against the target disease but at the same time affect mortality after infection with other pathogens, in a sex-differential manner, led to several further studies showing that other vaccines might also have such nonspecific effects.\n\nNumerous observational studies and randomised trials (RCTs) have found that the impact on mortality of live and inactivated vaccines differ markedly. All live vaccines studied so far (BCG, measles vaccine, oral polio vaccine (OPV) and smallpox vaccine) have been shown to reduce mortality more than can be explained by prevention of the targeted infection(s). In contrast, inactivated vaccines (diphtheria-tetanus-pertussis (DTP), hepatitis B, inactivated polio vaccine) may have deleterious effects in spite of providing target disease protection.\n\nThe live attenuated BCG vaccine developed against tuberculosis has been shown to have strong beneficial effects on the ability to combat non-tuberculosis infections.\n\nSeveral studies have suggested that BCG vaccination may reduce atopy, particularly when given early in life. Furthermore, in multiple observational studies BCG vaccination has been shown to provide beneficial effects on overall mortality. These observations encouraged randomised controlled trials to examine BCG vaccination's beneficial non-specific effects on overall health. Since BCG vaccination is recommended to be given at birth in countries that have a high incidence of tuberculosis it would have been unethical to randomize children into 'BCG' vs. 'no BCG' groups. However, many low-income countries delay BCG vaccination for low-birth-weight (LBW) infants; this offered the opportunity to directly test the effect of BCG on overall mortality.\n\nIn the first two randomised controlled trials receipt of BCG+OPV at birth vs. OPV only ('delayed BCG') was associated with strong reductions in neonatal mortality; these effects were seen as early as 3 days after vaccination. BCG protected against sepsis as well as respiratory infections. \nAmong BCG vaccinated children, those who develop a BCG scar or a positive skin test (TST) are less likely to develop sepsis and exhibit an overall reduction in child mortality of around 50%.\n\nIn a recent WHO-commissioned review based on five clinical trials and nine observational studies, it was concluded that \"the results indicated a beneficial effect of BCG on overall mortality in the first 6–12 months of life. Relevant follow-up in some of the trials was short, and all of the observational studies were regarded as being at risk of bias, so the confidence in the findings was rated as very low according to the GRADE criteria and \"There was a suggestion that BCG vaccination may be more beneficial the earlier it is given\". Furthermore, \"estimated effects are in the region of a halving of mortality risk\" and \"any effect of BCG vaccine on all-cause mortality is not likely to be attributable to any great extent to fewer deaths from tuberculosis (i.e. to a specific effect of BCG vaccine against tuberculosis)\". Based on the evidence, the WHO's Strategic Group of Experts on Immunization concluded that \"the non-specific effects on all-cause mortality warrant further research\".\n\nStandard titer measles vaccine is recommended at 9 months of age in low-income countries where measles infection is endemic and often fatal. Many observational studies have shown that measles-vaccinated children have substantially lower mortality than can be explained by the prevention of measles-related deaths. Many of these observational studies were natural experiments, such as studies comparing the mortality before and after the introduction of measles vaccine and other studies where logistical factors rather than maternal choice determined whether a child was vaccinated or not.\n\nThese findings were later supported in randomized trials from 2003 to 2009 in Guinea-Bissau. An intervention group of children given standard titer measles vaccine at 4.5 and 9 month of age had a 30% reduction in all-cause mortality compared to the children in the control group, which were only vaccinated against measles at 9 month of age.\n\nIn a recent WHO-commissioned review based on four randomized trials and 18 observational studies, it was concluded that \"There was consistent evidence of a beneficial effect of measles vaccine, although all observational studies were assessed as being at risk of bias and the GRADE rating was of low confidence. There was an apparent difference between the effect in girls and boys, with girls benefitting more from measles vaccination\", and furthermore \"estimated effects are in the region of a halving of mortality risk\" and \"if these effects are real then they are not fully explained by deaths that were established as due to measles\". Based on the evidence, the WHO's Strategic Advisory Group of Experts on Immunization concluded that \"the non-specific effects on all-cause mortality warrant further research\".\n\nDTP vaccine against diphtheria, tetanus and pertussis does not seem to have the same beneficial effects as BCG, measles vaccine, OPV and smallpox vaccine, and in fact opposite effects are observed. The negative effects are seen as long as DTP vaccine is the most recent vaccine. BCG or measles vaccine given after DTP reverses the negative effects of DTP. The negative effects are seen mostly in females.\n\nThe negative effects are found in several observational studies. However, six WHO-commissioned studies concluded that there were strong beneficial effects of DTP on overall mortality. However, controversy ensued as these studies had important methodological shortcomings. For example, the WHO-commissioned studies had counted \"no information about vaccination\" as \"unvaccinated\", and they had retrospectively updated vaccine information from surviving children, while no similar update could be made for dead children, creating a so-called \"survival bias\" which will always produce highly beneficial effect estimates for the most recent vaccine.\n\nIn a recent WHO-commissioned review of DTP based on ten observational studies, it was concluded that, \"the findings were inconsistent, with a majority of the studies indicating a detrimental effect of DTP, and two studies indicating a beneficial effect. All of the studies were regarded as being at risk of bias, so the confidence in the findings was rated as very low according to the GRADE criteria.\"\n\nFurthermore, \"three observational studies provided a suggestion that simultaneous administration of BCG and DTP may be preferable to the recommended schedule of BCG before DTP; and there was suggestion that mortality risk may be higher when DTP is given with, or after, measles vaccine compared with when it is given before measles vaccine (from five, and three, observational studies, respectively). These results are consistent with hypotheses that DTP vaccine may have detrimental effects on mortality, although a majority of the evidence was generated by a group centred in Guinea-Bissau who have often written in defence of such a hypothesis.\"\n\nWhen smallpox vaccine was introduced in the early 19s century, there were anecdotal descriptions of non-specific beneficial effects. In the second half of the 20th century the potential for beneficial non-specific effects of smallpox vaccine was reviewed, and new evidence on \"para-immune effects\" was added. More recent studies have focused on the phasing out of smallpox vaccine in the 1970s and compared vaccinated and unvaccinated cohorts.\nSmallpox vaccine leaves a very characteristic scar. In low-income countries, having a smallpox vaccine scar has been associated with reductions of more than 40% in overall mortality among adults; in high-income countries smallpox vaccination has been associated with a tendency for reduced risk of asthma, and significantly reduced risk of malignant melanoma and infectious disease hospitalizations. There are no studies that contradict these observations. However it should be noted that no randomized trials testing the effect of smallpox vaccine on overall mortality and morbidity have been conducted.\n\nNon-specific effects are frequently different in males and females. There are accumulating data illustrating that males and females may respond differently to vaccination, both in terms of the quality and quantity of the immune response. If true, then we must consider whether vaccination schedules should differ for males and females, or as has been suggested \"should we treat the sexes differently in order to treat them equally?\"\n\nThe non-specific effects of vaccines can be boosted or diminished when other immunomodulating health interventions such as other vaccines, or vitamins, are provided.\n\nThe beneficial NSEs of live vaccines are stronger with earlier vaccination, possibly due to maternal antibodies. Boosting with live vaccines also seems to enhance the beneficial effects.\n\nThe non-specific effects were primarily observed in low-income countries with high infectious disease burdens, but they may not be limited to these areas. Recent Danish register-based studies have shown that the live attenuated measles-mumps-rubella vaccine (MMR) protects against hospital admissions with infectious diseases and specifically getting ill by respiratory syncytial virus.\n\nThe findings from the epidemiological studies on the non-specific effects of vaccines pose a challenge to the current understanding of vaccines, and how they affect the immune system, and also question whether boys and girls have identical immune systems and should receive the same treatment.\n\nThe mechanisms for these effects are unclear. It is not known how vaccination induces rapid beneficial or harmful changes in the general susceptibility to infectious diseases, but the following mechanisms are likely to be involved.\n\nIt is well known from animal studies that infections, apart from inducing pathogen-specific T-cells, also induce cross-reactive T-cells through epitope sharing, so-called heterologous immunity. Heterologous T-cell immunity can lead to improved clearance of a subsequent cross-reactive challenge, but it may also lead to increased morbidity. This mechanism may explain why DTP could have negative effects.\n\nIt would, however, not explain effects occurring shortly after vaccination, as for instance the rapidly occurring beneficial effects of BCG vaccine, as the heterologous effect would only be expected to be present after some weeks, as the adaptive immune response need time to develop. Also, it is difficult to explain why the effect would vanish once a child receives a new vaccine.\n\nThe concept that not only plants and insects, but also humans have innate immune memory may provide new clues to why vaccines have non-specific effects. Studies into BCG have recently revealed that BCG induces epigenetic changes in the monocytes in adults, leading to increased pro-inflammatory cytokine production upon challenges with unrelated mitogens and pathogens (trained innate immunity).\n\nIn SCID mice that have no adaptive immune system, BCG reduced mortality from an otherwise lethal candida infection. The effects of BCG presented when tested after 2 weeks, but would be expected to occur rapidly after vaccination, and hence might be able to explain the very rapid protection against neonatal septicaemia seen after BCG vaccine.\n\nTrained innate immunity may also explain the generally increased resistance against broad disease categories, such as fevers and lower respiratory tract infections; such effects would be difficult to explain merely by shared epitopes, unless such epitopes were almost universally common on pathogens.\n\nLastly, it is plausible that the effects are reversible by a different vaccine. Hence, trained innate immunity may provide a biological mechanism for the observed non-specific effects of vaccines.\n\nIn 2000 Aaby and colleagues presented data from Guinea-Bissau which suggested that DTP vaccination could, under some circumstances (e.g. absence of pertussis) be associated with increases in overall mortality, at least until children received measles vaccine. In response, WHO sponsored the analysis of a variety of data sets in other populations to test the hypothesis. None of these studies replicated the observation of increased mortality associated with DTP vaccination. WHO subsequently concluded, that the evidence was sufficient to reject the hypothesis for an increased nonspecific mortality following DTP vaccination.\n\nHowever, Aaby and colleagues subsequently pointed out that the studies which failed to show any mortality increase associated with DTP vaccination used methods of analysis that can introduce a bias against finding such an effect.\n\nIn these studies, data on childhood vaccinations were typically collected in periodic surveys, and the information on vaccinations, which occurred between successive home visits, was updated at the time of the second visit. The person-time at risk in unvaccinated and vaccinated states was then divided up according to the date of vaccination during the time interval between visits. This method opens up a potential bias, insofar as the updating of person time at risk from unvaccinated to vaccinated is only possible for children who survive to the second follow-up. Those who die between visits typically do not have vaccinations between the first visit and death recorded, and thus they will tend to be allocated as deaths in unvaccinated children – thus incorrectly inflating the mortality rate among unvaccinated children.\n\nThis bias has been described before, but in different contexts, as the distinction between 'landmark' and 'retrospective updating' analysis of cohort data. The retrospective updating method can lead to a considerable bias in vaccine studies, biasing observed mortality rate ratios towards zero (a large effect), whereas the landmark method leads to a non-specific misclassification and biases the mortality rate ratio towards unity(no effect).\n\nAn additional problem with the literature on the nonspecific effects of vaccines has been the variety and unexpected nature of the hypotheses which have appeared (in particular relating to sex-specific effects), which has meant that it has not always been clear whether some apparent 'effects' were the result of post hoc analyses or whether they were reflections of a priori hypotheses.\n\nThis was discussed at length at a review of the work of Aaby and his colleagues in Copenhagen in 2005. The review was convened by the Danish National Research Foundation and the Novo Nordisk Foundation who have sponsored much of the work of Aaby and his colleagues. An outcome of the review was the explicit formulation of a series of testable hypotheses, agreed by the Aaby group. It was hoped that independent investigators would design and conduct studies powered to confirm or refute these hypotheses.\n\nAlso, the two foundations sponsored a workshop on the analysis of vaccine effects, which was held in London in 2008. The workshop resulted in three papers. The proceedings were forwarded to WHO which subsequently concluded that it would \"keep a watch on the evidence of nonspecific effects of vaccination\".\n\nIn 2013, WHO established a working group tasked with reviewing the evidence for the non-specific effects of BCG, measles and DTP vaccines. Two independent reviews were conducted, an immunological review and an epidemiological review. The results were presented at the April 2014 meeting of WHO's Strategic Gourp of Experts on Immunizations (SAGE). WHO/SAGE concluded that further research into the potential NSEs of vaccines was warranted.\n\nIt would have major consequences for child survival if the non-specific effects of vaccines were taken into consideration in immunization programs: BCG and MV should be given to all children as early as possible; restrictive policies for opening multi-dose vials of BCG and MV should be abandoned.\n\nContrary to current WHO-recommendations, the age of MV should not be raised when measles infection is under control; DTP should not be given simultaneously with MV or after MV; and a booster dose of DTP is likely to have a negative effect on child survival. Finally, eradicating a disease and stopping a live vaccine with beneficial NSEs is likely to have negative effects for the overall health of the affected population.\n\nDr. Frank Shann from Australia recently assessed the consequences of changing the current EPI schedule to an alternative schedule taking non-specific effects into account, and concluded: \"If all neonates in high-mortality regions were given BCG at birth, and the revised immunization schedule ... were adopted, with extra doses of measles vaccine at 14 weeks and 19 months (at a cost of only US $0.60/dose delivered), ~1 million (30%) of the 3.2 million neonatal deaths each year might be prevented in developing countries, and 1.5 million (30%) of the 4.8 million deaths between 1 month and 5 years of age might be prevented\". Furthermore: \"This very large reduction in mortality in children <5 years of age would be achieved at a low cost using only vaccines that are already in the routine EPI schedule\".\n\nIn 2008, Danish crime novel author Sissel-Jo Gazan (author of the Danish crime novel \"Dinosaur Feather\") became interested in the work of the Bandim Health Project and based her science crime novel \"The Arc of the Swallow\" (\"Svalens Graf\") on the research into non-specific effects of vaccines.\n\nThe novel was published in Danish in 2013; it was on the best-seller list for months and won the Readers' Prize 2014 in Denmark. It was published in English in the UK on November 6, 2014 and in the US on April 7, 2015.\n\n"}
{"id": "20251567", "url": "https://en.wikipedia.org/wiki?curid=20251567", "title": "Nosokinetics", "text": "Nosokinetics\n\nNosokinetics is the science/subject of measuring and modelling the process of care in health and social care systems.\" Nosokinetics\" brings together the Greek words for \"noso\": disease and \"kinetics\": movement.\n\nBlack box models are currently used to plan changes in health and social care systems. These input-output models overlook the process of inpatient care, as a result suboptimal decisions are made. Nosokinetics, (analogous to Pharmacokinetics), seeks to develop dynamic methods which measure and model the process of inpatient care. The aim is to develop a scientific base to underpin the planning of sustainable health and social care systems.\nNosokinetics is a new \"science\" that was established in the UK in the early 1990s by Prof Peter H Millard after publishing his PhD thesis. In 2004 Nosokinetics group newsletter was established.\n\nProf Peter H Millard writes about Nosokinetics : \"If the random forces of wind and tide can make such a beautiful statue (referring to an iceberg), how much better could mankind do if a new science was developed which explains the complex processes of health and social care. Until new methods of planning health and social care services to meet the needs of an ageing population are introduced, service delivery will stumble on from crisis to crisis. The world population is ageing and sustainable systems of health care need to be developed.\"\n\nHe has established the nosokinetics group of interested researchers. The group collaborates to organize conferences and disseminates news of nosokinetics and other researchers' research and practical use of modelling to enhance decision making in health and social care systems.\n\nThe Nosokinetics Group has succeeded in attracting a lot of researchers. Nosokinetics interested people are present in many countries including Australia, UK & Egypt. They are from different disciplines ranging from health care providers to management scientists. The news related to nosokinetics is shared to the network through the bimonthly newsletter \"Nosokinetics News\" which helps to communicate papers, conferences and events of interest to the Nosokinetics network.\n"}
{"id": "24301504", "url": "https://en.wikipedia.org/wiki?curid=24301504", "title": "Nutrition analysis", "text": "Nutrition analysis\n\nNutrition analysis refers to the process of determining the nutritional content of foods and food products. The process can be performed through a variety of certified methods.\n\nTraditionally, food companies would send food samples to laboratories for physical testing. \nTypical analysis includes:\nMoisture (water) by loss of mass at 102 °C,\nProtein by analysis of total nitrogen, either by Dumas or Kjeldahl methods,\nTotal fat, traditionally by a solvent extraction, but often now by secondary methods such as NMR,\nCrude ash (total inorganic matter) by combustion at 550C,\nEstimated dietary fibre by various AOAC methods such as 985.29,\nSodium (and thereby Salt) either by flame photometry, AA or ICP-OES,\nTotal sugars, normally by a liquid chromatography technique, such as IC-HPAED or HPLC-RI,\nFatty acids by GC-FID,\nCarbohydrates and energy values are normally calculated from these analytical values.\n\nSoftware is available as an alternative to laboratory nutrition analysis. This software typically utilizes a database of ingredients that have previously been laboratory tested. The user can input ingredient data by matching their ingredients to ingredients found in the database; the analysis can then be calculated.\n\nIn recent years, web-based nutrition analysis software services have become more popular. Online nutrition analysis allows users to access online databases and draw from certified ingredients to produce instant nutrition information.\n\nAnother emerging trend is the use of nutritional analysis services that do a complete analysis of any recipe by using their proprietary database. Users provide recipes, cooking methods and serving sizes. In turn, the service provides a complete nutritional analysis.\n\nIn the United States, nutrition information is required on packaged retail foods in the form of nutrition facts panels as a result of food labeling regulations. In recent years, many restaurants have begun posting nutrition information as a result of both customer demand and menu-labeling laws.\n\nThe Patient Protection and Affordable Care Act, signed into law March 23, 2010, includes a provision that creates a national, uniform nutrition-disclosure standard for food service establishments.\n\nThe nutrition-disclosure provision requires chain restaurants, similar retail food establishments and vending machines with 20 or more locations to provide specific nutrition labeling information. Those establishments must post calories on menus, menu boards and drive-thru boards. Buffets, salad bars and other self-service items are also included and will be required to provide caloric information adjacent to the item.\n\nRecently many state and local menu-labeling laws have been passed requiring restaurants to post nutrition information on menus and menu boards, or have it readily available upon customer request. Restaurants have had to perform nutrition analysis in order to generate nutrition information and conform to these laws. More recently national legislation has been introduced that would set a national standard for menu labeling, the most popular of which is the LEAN act.\n"}
{"id": "1843196", "url": "https://en.wikipedia.org/wiki?curid=1843196", "title": "Nutritional genomics", "text": "Nutritional genomics\n\nNutritional genomics is a science studying the relationship between human genome, nutrition and health. People in the field work toward developing an understanding of how the whole body responds to a food via systems biology, as well as single gene/single food compound relationships.\n\nNutritional science originally emerged as a field that studied individuals lacking certain nutrients and the subsequent effects, such as the disease scurvy which results from a lack of vitamin C. As other diseases closely related to diet (but not deficiency), such as obesity, became more prevalent, nutritional science expanded to cover these topics as well.<ref name=Neeha2013/ Nutritional research typically focuses on preventative measure, trying to identify what nutrients or foods will raise or lower risks of diseases and damage to the human body.\n\nFor example, Prader-Willi syndrome, a disease whose most distinguishing factor is insatiable appetite, has been specifically linked to an epigenetic pattern in which the paternal copy in the chromosomal region is erroneously deleted, and the maternal loci is inactivated by over methylation. Yet, although certain disorders may be linked to certain single nucleotide polymorphisms (SNPs) or other localized patterns, variation within a population may yield many more polymorphisms.\n\nObesity is one of the most widely studied topics in nutritional genomics. Due to genetic variations among individuals, each person could respond to diet differently. By exploring the interaction between dietary pattern and genetic factors, the field aims to suggest dietary changes that could prevent or reduce obesity.\n\nThere appear to be some SNPs that make it more likely that a person will gain weight from a high fat diet; for people with AA genotype in the FTO gene showed a higher BMI compared those with TT genotype when having high fat or low carbohydrate dietary intake. The APO B SNP rs512535 is another diet-related variation; the A/G heterozygous genotype was found to have association with obesity (in terms of BMI and waist circumference) and for individuals with habitual high fat diet (>35% of energy intake), while individuals with GG homozygotes genotype are likely to have a higher BMI compared to AA allele carriers. However, this difference is not found in low fat consuming group (<35% of energy intake).\n\n"}
{"id": "25627242", "url": "https://en.wikipedia.org/wiki?curid=25627242", "title": "Online patient education", "text": "Online patient education\n\nOnline patient education, also known as online patient engagement, is a method of providing medical information and education to patients using learning management systems delivered through the Internet. It is a type of computer-based instruction and includes web seminars, downloadable materials, interactive learning courses, and audio/visual presentations. Generally, online patient education is supplemented with in-person consultations tailored to each individual.\n\nHealth professionals use online patient education to prepare patients for medical procedures, administer intake and informed consent paperwork, educate patients about health conditions, provide information about preventive care, encourage healthy behavior and lifestyle changes, etc. Health insurance companies use online patient education to inform patients about coverage policies. \n\nOnline patient education is gaining popularity as home Internet access becomes more common and medical practices increasingly utilize digital technologies. Patients either view online patient education programs and materials in a medical office or from their homes or other remote locations with Internet access. Content may include interactive features such as quizzes, live question and answer sessions (in moderated web seminars), and the ability to complete and submit forms.\n\nAny education delivered verbally by a healthcare provider to a single patient or group of patients can be considered as On Location patient education. Although this is still the most commonly used patient education method it is time consuming, can have consistency problems, and relies heavily on the individual patient ability to absorb, understand, and retain the verbal information.\n\nThe second most common method. Any information brochure at a healthcare provider office falls under this category. The benefits of printed materials is that patients can refer back to the information\n\nPatient education that is made available by a healthcare provider via his/her website, specific portal, or EHR. Web based education can be provided in an Asynchronous and Synchronous styles.\n\nEducating patients with online technology can be advantageous for both medical practices and patients because it gives health care providers the opportunity to create comprehensive educational materials that are consistently presented, rather than relying on face-to-face meetings in which information is presented by a staff member. Patients need not possess advanced computer/web skills to use this method of learning. A survey of 3200 patients revealed that even patients who are not computer literate are satisfied with online patient education as means of learning about medical care.\n\n"}
{"id": "32301237", "url": "https://en.wikipedia.org/wiki?curid=32301237", "title": "Partner services", "text": "Partner services\n\nPartner services is a public health term which refers to the health intervention given to a client's intimate partners when a client goes to a health care provider requesting health care. \n\nPartner notification is a type of partner service, wherein if someone has a contagious disease, the health care provider finding the problem will try to notify that person's partners that they have been exposed to infection. It is a form of contact tracing.\n\nPartner services are important because in some cases a person's health problems are partially caused or sustained by other people. A common example would be that a person visits a doctor because he has an infectious disease. If that disease is also contagious, then that person's close associates may also have the disease. If a physician were to only treat the person who initially requests treatment, then the disease may remain in the community. Instead, principles of partner services dictate that health care should treat all members of a group which transmits infection.\n\nPartner services are frequently discussed in the treatment of sexually transmitted infections (STI). If one person has a sexually transmitted infection, then any sexual partner that person has is at risk to get that infection. A common practice after identifying a person who has an STI is to ask that person to identify any sexual partners so that the clinic can contact them and arrange for them to receive STI testing, treatment, and counseling.\n\nAnother example is the case in which two people are in an intimate relationship, such as a marriage. One partner may be dissatisfied with the relationship and seek counseling. In this case, the counselor may advise that if the other partner in the relationship does not also participate in counseling then improvement in the relationship might be difficult. In this case, the counselor would assist the person making the complaint in arranging partner services.\n\nPublic health offices are often directed to offer partner services for sexually transmitted infections, including the following: \n\nMental health professionals often recommend partner services when clients express interest in treatment for many problems, including the following:\n\nThe intention is that often a person will benefit from the support of close friends, family, and significant others when getting treatment for a mental problem.\n\nPartner services help the original client have better health, and improve the health of that client's close associates, and benefit the community by relieving the burden of retaining an infectious reservoir of endemic health problems.\n\n"}
{"id": "27543342", "url": "https://en.wikipedia.org/wiki?curid=27543342", "title": "Passive drinking", "text": "Passive drinking\n\nPassive drinking, like passive smoking, refers to the damage done to others as a result of drinking alcoholic beverages. These include the unborn fetus and children of parents who drink excessively, drunk drivers, accidents, domestic violence and alcohol-related sexual assaults\n\nOn 2 February 2010 Eurocare, the European Alcohol Policy Alliance, organised a seminar on “The Social Cost of Alcohol : Passive drinking”. On 21 May 2010 the World Health Organization reached a consensus at the World Health Assembly on a resolution to confront the harmful use of alcohol.\n\n"}
{"id": "10147095", "url": "https://en.wikipedia.org/wiki?curid=10147095", "title": "Pharmaceutical publication planning", "text": "Pharmaceutical publication planning\n\nPharmaceutical publication planning is the activity of planning the dissemination of scientific and clinical data on a drug to healthcare professionals at scientific congresses and medical society meetings and in peer reviewed medical journals.\n\nPharmaceutical publication planning involves developing a detailed plan that outlines the timely presentation of verified scientific and clinical data to appropriate types of healthcare professionals such as physicians, pharmacists, nurses, as a drug undergoes clinical trials and after it is marketed. Because of scientific and therapeutic advances, pharmaceutical publication planning has become a well-established and important function by pharmaceutical companies in order to educate healthcare professionals accordingly about new drugs and marketed drugs with new clinical uses or safety information. \n\nWithin pharmaceutical companies, publication planning is usually overseen by medical or clinical affairs professionals. In this effort, pharmaceutical companies frequently use the assistance of medical communication agencies with publication planning expertise and professional medical writers.\n\nMedical communication agencies include a broad range of organizations, including those that focus largely or exclusively on publication planning. When developing and executing a publication plan on behalf of a pharmaceutical or biotechnology client, medical communication agencies employ professional publication strategists, scientific medical directors, medical writers and project managers. Working as a team, this group of individuals delves deep into their client's scientific discoveries, and propose the most effective and efficient ways to spread the word about new potential therapies to physicians and other healthcare providers. \n\nThere has been some discussion in the media regarding disclosure as it pertains to the use of professional medical writers in this endeavor. Some agencies and professional organizations focused on publication planning have been and continue to develop and refine ethical guidelines and standards for disclosure and transparency.\n\nProfessional organizations for individuals involved in pharmaceutical publication planning include the International Society of Medical Publication Professionals (ISMPP) and The International Publication Planning Association (TIPPA). The purpose of these organizations is to create a forum where individuals involved with pharmaceutical publication planning and biomedical publications can meet and share knowledge and experience. They serve to promote career opportunities and professional development of individuals involved with pharmaceutical publication planning, as well as to promote standards of excellence in ethical professional medical writing and the biomedical publication process in disseminating scientific and clinical data on pharmaceutical products. \n\nIn 2009, ISMPP began a certification program for publication planning professionals.\n\n"}
{"id": "52292768", "url": "https://en.wikipedia.org/wiki?curid=52292768", "title": "Police officer safety and health", "text": "Police officer safety and health\n\nThere are numerous issues affecting the safety and health of police officers, including line of duty deaths and occupational stress.\n\nLine of duty deaths are deaths which occur while an officer is conducting his or her appointed duties. Despite the increased risk of being a victim of a homicide, automobile accidents are the most common cause of officer deaths. Officers are more likely to be involved in traffic accidents because of their large amount of time spent conducting vehicle patrols, or directing traffic, as well as their work outside their vehicles alongside or on the roadway, or in dangerous pursuits. Officers killed by suspects make up a smaller proportion of deaths. In the U.S. in 2005, 156 line of duty deaths were recorded of which 44% were from assaults on officers, 35% vehicle related (only 3% during vehicular pursuits) and the rest from other causes: heart attacks during arrests/foot/vehicular pursuits, falling from heights during foot chases, diseases contracted either from suspects' body fluids or, more rarely, from window period emergency blood transfusions received after motor vehicle accidents, shootings, stabbings, accidental gun discharges or falls that result in blood loss.\n\nPolice officers who die in the line of duty, especially those who die from the actions of suspects or in accidents or heart attacks, are often given elaborate funerals, attended by large numbers of fellow officers. Their families may also be entitled to special pensions. Fallen officers are often remembered in public memorials, such as the National Law Enforcement Officers Memorial in the U.S., the National Police Memorial in the U.K. and the Scottish Police Memorial, at the Scottish Police College.\n\nIn the United Kingdom, in the 10 years from April 2000 there were 143 line of duty deaths: 54 in road accidents travelling to or from duty, 46 in road accidents on duty, 23 from natural causes on duty, 15 from criminal acts, and 5 in other accidents. In Great Britain, police do not normally carry firearms. Officers in Northern Ireland are routinely armed.\n\nThe Singapore Police Force registered just over 100 deaths in a century up to the year 2000. There have been 28 New Zealand police officers killed by criminals since 1890.\n\nThe actual presence of stress in police work is well documented and evidenced by certain statistics. Researchers typically use suicide, divorce and alcoholism rates as three key indexes of stress in a group of people. These factors paint a compelling picture of police officers demonstrating signs of significant stress, for example:\n\n\nAs one would expect, being a police officer or having a career in criminal justice in any capacity will bring on stress. It is important to know how to cope positively to ensure you are always successful and safe. Some things that can help are avoiding negative treatments (drugs/alcohol), seeking additional help if one cannot handle the stress alone, and most importantly to stay healthy and happy.\n\nMany people turn to negative solutions when presented with stress and that is never good. What I mean by this is drugs, alcohol, or even something as simple as having a poor diet. There is a myth in society today that some drugs can take away stress and that is why they get so widely abused, however, some drugs just make one forget about their problems while others make people more susceptible to stress. Marijuana is one of the most widely abused drugs in the world, and people use this drug thinking it will make all their problems go away. However, when one comes out of their “high” the stressors are still present and there has been nothing done to help solve them.\n\nTo avoid encountering stress here are some things one can do. Get a sufficient amount of sleep every night, waking up tired and in a bad mood increases the chances of becoming stressed. Physical exercise and a healthy diet are also crucial. If the body is healthy then the mind is more likely to be healthy. Having a life outside of one’s career can help greatly as well. Spending time with friends or family outside of one’s job can also help manage stress by taking one’s mind off whatever situation is disturbing them. Finally, perhaps the most important tool when dealing with stress is knowing what is worth becoming stressed out about. Focus on aspects of life that can be controlled, and do not worry as much about factors that are out of control.\n\nIf one is struggling with stress to the point where it is affecting every day activity, then seeking out council from a professional is a good option. Speaking and expressing oneself is a very effective treatment for stress. Understandably, not everyone can get access to professional help whether it be because of finances or just not enough time. For those people it can also be helpful to journal thoughts, goals, or anything that will help express how one feels. Also, being patient is key, nobody will solve all their problems in a short amount of time. It is imperative to give yourself time to heal from any situation that gives one stress and then come back and focus on why that particular instance is causing so many problems.\n\nWhen one hears “stress” a negative connotation is automatically attached to the word, although not all stress is bad. It can be a very good thing when used properly. Without being a little stressed out every now and then one would not be motivated to accomplish anything. The trick is finding the balance of healthy stress and how much is too overwhelming. The information above is a great start to coping and eventually overcoming stress. It is impossible to avoid stress entirely, but if one uses these tips it becomes easier and easier to manage with time.\n\nHans Selye, the foremost researcher in stress in the world, said that police work is \"the most stressful occupation in America even surpassing the formidable stresses of air traffic control.\"\n\nOther researchers, though, claim that police officers are more psychologically healthy than the general population. Police officers are increasingly more educated, more likely to engage in a regular program of exercise and to consume less alcohol and tobacco, and increasingly family-oriented. Healthy behavior patterns typically observed at entry training usually continue throughout the career of an officer. Even though the presence of occupation related stress seems to be well documented, it is highly controversial. Many within the law enforcement industry claim the propagation of incorrect suicide, divorce, and substance abuse statistics comes from people or organizations with political or social agendas, and that the presence of these beliefs within the industry makes it hard for health workers to help police officers in need of treatment to deal with the fear of negative consequences from police work which is necessary to enable police officers to develop a healthy expectancy of success in treatment.\n\n\nEven though the presence of occupational stresses appear to be well documented, though not without controversy, the causes of workplace stress are comparatively unclear or even a matter of conjecture.\n\nAlthough individual policemen and institutional public relations typically cite the risks of being killed in the line of duty as the predominant source of stress for individual policemen, there is significant controversy regarding the causes of personal workplace stress due to the fact that the actual risk of being killed is so small relative to other occupations.\n\nIt is charged that the myth of the high risks of occupational mortality connected with police work is often propagated by the law enforcement community as part of its institutional advancement and a central element in its public relations. Actual homicides of police are comparatively rare, but the reports of such incidents are typically reported in the press along with quotes by police officials or police officer family members stressing the notion that police officers 'put their lives on the line for the public' or 'risk their lives everyday', making it look like individual policemen routinely place themselves in mortal danger for low pay and little recognition, and that the view of police work as 'combat' is the source of police occupational stress indications.\n\nAnother explanation often advanced is the idea that police officers will undergo some traumatic experience in their police work that they never recover from, leading to suicide, divorce, etc. However, since the effects of such traumatic stresses is readily recognized, there are usually proactive programs in place to help individual police officers deal with the psychological effects of a traumatic event. Unfortunately, there is some evidence that such programs are actually ineffective, especially group therapies, may re-traumatize the participant, weaken coping mechanisms, and contribute to the development of post traumatic stress disorder (PTSD).\n\nObservations where police officers and other emergency workers, such as firemen, experience the same traumatic event, it is more likely that the police officer will have difficulty dealing with the long term emotional effects of the traumatic event. On this observation, some of the academic literature suggests that along these lines the causes of occupational stress is more complex for police officers. Stress in police work is often present in other occupations, but not in an ongoing capacity. One line of thinking is that the individual stresses of police work produce a condition of chronic stress. Police officers encounter stressors in call after call which sap their emotional strength. Debilitation from this daily stress accumulates making officers more vulnerable to traumatic incidents and normal pressures of life. The weakening process is often too slow to see; neither a person nor his friends are aware of the damage being done. The effects of chronic stresses is two-fold:\n\n\nThe daily work of a police officer involves certain paradoxes and conflicts which may be difficult to deal with, the predominant examples are\n\n\n\nA more anecdotal view looks at specific sources of stress in police work. The sources of stress most often actually cited are:\n\n\nOther more academic studies have produced similar lists, but may include items that the more anecdotal surveys do not reveal, such as 'exposure to neglected, battered, or dead children.'\n\nAgain, the actual fear of occupational death or physical harm is not high on the list of stress sources.\n\nThere have been numerous academic studies on the specific sources of police stress, and most conclude organizational culture and workload as the key issues in officer stress. Traumatic events are usually concluded to not be of sufficient scope or prevalence to account for prevalence of suicide, divorce, and substance abuse abnormalities.\n\n"}
{"id": "23094450", "url": "https://en.wikipedia.org/wiki?curid=23094450", "title": "Quantitative risk assessment software", "text": "Quantitative risk assessment software\n\nQuantitative risk assessment (QRA) software and methodologies give quantitative estimates of risks, given the parameters defining them. They are used in the financial sector, the chemical process industry, and other areas.\n\nIn financial terms, quantitative risk assessments include a calculation of the single loss expectancy of monetary value of an asset.\n\nIn the chemical process and petrochemical industries a QRA is primarily concerned with determining the potential loss of life (PLL) caused by undesired events. Specialist software can be used to model the effects of such an event, and to help calculate the potential loss of life. Some organisations use the risk outputs to assess the implied cost to avert a fatality (ICAF) which can be used to set quantified criteria for what is an unacceptable risk and what is tolerable.\n\nFor the explosives industry, QRA can be used for many explosive risk applications. It is especially useful for site risk analysis when reliance on quantity distance (QD) tables is not feasible. \n\nThe following products have been superseded, or are no longer available:\n\nSome of the QRA software models described above must be used in isolation: for example the results from a consequence model cannot be used directly in a risk model. Other QRA software programs link different calculation modules together automatically to facilitate the process. Some of the software is proprietary and can only be used within certain organisations.\n\nDue to the large amount of data processing required by QRA calculations, the usual approach has been to use two-dimensional ellipses to represent hazard zones such as the area around an explosion which poses a 10% chance of fatality. Similarly, a pragmatic approach is used in the simplification of dispersion results. Typically a flat terrain, unobstructed world is used to determine the behaviour of a dispersing cloud and/or a vaporizing pool. This presents problems when the effects of non-flat terrain or the complex geometry of process plants would no doubt affect the behaviour of a dispersing cloud. Though they have limitations, the 2D hazard zone and simplified approach to 3D dispersion modelling allow the handling of large volumes of risk results with known assumptions to assist in decision-making. The trade-off shifts as computer processing power increases.\n\nThe modeling of the consequences of hazardous events in a true 3D manner may require a different approach, for example using a computational fluid dynamics method to study cloud dispersion over hilly terrain. The creation of CFD models requires significantly more investment of time on the part of the modeling analyst (because of the increased complexity of the modeling), which may not be justified in all cases.\n\nOne major limitation of QRA in the safety field is that it is focussed primarily on the loss of containment of hazardous fluids and what happens when they are released. This renders QRA somewhat unworkable in hazardous industries that do not focus on fluid containment yet are still subject to catastrophic events (e.g. aviation, pharmaceuticals, mining, water treatment, etc.) This has led to the development of a risk process that draws on the experience of organisations and their employees to produce risk assessments that produce potential loss of life (PLL) outputs without fault and event tree modelling. This process is probably most commonly known by the name \nSQRA which was the first methodology to enter the marketplace in the late 1990s but is perhaps more accurately described by the term Experience-based Quantification (EBQ). Today there is a choice of software with which to undertake this methodology and it has been used extensively in the mining industry on a global basis.\n\nIn an effort to be more fair and to avoid adding to already high imprisonment rates in the US, courts across America have started using quantitative risk assessment software when trying to make decisions about releasing people on bail and sentencing, which are based on their history and other attributes. It analyzed recidivism risk scores calculated by one of the most commonly used tools, the Northpointe COMPAS system, and looked at outcomes over two years, and found that only 61% of those deemed high risk actually committed additional crimes during that period and that African-American defendants were far more likely to be given high scores that white defendants. These results are part of larger questions being raised in the field of machine ethics with regard to the risks of perpetuating patterns of discrimination via the use of big data and machine learning across many fields.\n\nRAM Analysis\nRisk Based Inspection Software\nConsequence Analysis\n\nQualitative Risk Assessment \n\nlinks to various government regulations\n\n"}
{"id": "854081", "url": "https://en.wikipedia.org/wiki?curid=854081", "title": "Regeneration (biology)", "text": "Regeneration (biology)\n\nIn biology, regeneration is the process of renewal, restoration, and growth that makes genomes, cells, organisms, and ecosystems resilient to natural fluctuations or events that cause disturbance or damage. Every species is capable of regeneration, from bacteria to humans. Regeneration can either be complete where the new tissue is the same as the lost tissue, or incomplete where after the necrotic tissue comes fibrosis. At its most elementary level, regeneration is mediated by the molecular processes of gene regulation. Regeneration in biology, however, mainly refers to the morphogenic processes that characterize the phenotypic plasticity of traits allowing multi-cellular organisms to repair and maintain the integrity of their physiological and morphological states. Above the genetic level, regeneration is fundamentally regulated by asexual cellular processes. Regeneration is different from reproduction. For example, hydra perform regeneration but reproduce by the method of budding.\n\nThe hydra and the planarian flatworm have long served as model organisms for their highly adaptive regenerative capabilities. Once wounded, their cells become activated and start to remodel tissues and organs back to the pre-existing state. The Caudata (\"urodeles\"; salamanders and newts), an order of tailed amphibians, is possibly the most adept vertebrate group at regeneration, given their capability of regenerating limbs, tails, jaws, eyes and a variety of internal structures. The regeneration of organs is a common and widespread adaptive capability among metazoan creatures. In a related context, some animals are able to reproduce asexually through fragmentation, budding, or fission. A planarian parent, for example, will constrict, split in the middle, and each half generates a new end to form two clones of the original.\n\nEchinoderms (such as the sea star), crayfish, many reptiles, and amphibians exhibit remarkable examples of tissue regeneration. The case of autotomy, for example, serves as a defensive function as the animal detaches a limb or tail to avoid capture. After the limb or tail has been autotomized, cells move into action and the tissues will regenerate. Limited regeneration of limbs occurs in most fishes and salamanders, and tail regeneration takes place in larval frogs and toads (but not adults). The whole limb of a salamander or a triton will grow again and again after amputation. In reptiles, chelonians, crocodilians and snakes are unable to regenerate lost parts, but many (not all) kinds of lizards, geckos and iguanas possess regeneration capacity in a high degree. Usually, it involves dropping a section of their tail and regenerating it as part of a defense mechanism. While escaping a predator, if the predator catches the tail, it will disconnect.\n\nEcosystems can be regenerative. Following a disturbance, such as a fire or pest outbreak in a forest, pioneering species will occupy, compete for space, and establish themselves in the newly opened habitat. The new growth of seedlings and community assembly process is known as regeneration in ecology.\n\nPattern formation in the morphogenesis of an animal is regulated by genetic induction factors that put cells to work after damage has occurred. Neural cells, for example, express growth-associated proteins, such as GAP-43, tubulin, actin, an array of novel neuropeptides, and cytokines that induce a cellular physiological response to regenerate from the damage. Many of the genes that are involved in the original development of tissues are reinitialized during the regenerative process. Cells in the primordia of zebrafish fins, for example, express four genes from the homeobox \"msx\" family during development and regeneration.\n\n\"Strategies include the rearrangement of pre-existing tissue, the use of adult somatic stem cells and the dedifferentiation and/or transdifferentiation of cells, and more than one mode can operate in different tissues of the same animal. All these strategies result in the re-establishment of appropriate tissue polarity, structure and form.\" During the developmental process, genes are activated that serve to modify the properties of cell as they differentiate into different tissues. Development and regeneration involves the coordination and organization of populations cells into a blastema, which is \"a mound of stem cells from which regeneration begins\". Dedifferentiation of cells means that they lose their tissue-specific characteristics as tissues remodel during the regeneration process. This should not be confused with the transdifferentiation of cells which is when they lose their tissue-specific characteristics during the regeneration process, and then re-differentiate to a different kind of cell.\n\nArthropods are known to regenerate appendages following loss or autotomy. Regeneration among arthropods is restricted by molting such that hemimetabolous insects are capable of regeneration only until their final molt whereas most crustaceans can regenerate throughout their lifetimes. Molting cycles are hormonally regulated in arthropods, although premature molting can be induced by autotomy. Mechanisms underlying appendage regeneration in hemimetabolous insects and crustaceans is highly conserved. During limb regeneration species in both taxa form a blastema following autotomy with regeneration of the excised limb occurring during proecdysis. Arachnids, including scorpions, are known to regenerate their venom, although the content of the regenerated venom is different than the original venom during its regeneration, as the venom volume is replaced before the active proteins are all replenished.\n\nMany annelids (segmented worms) are capable of regeneration. For example, \"Chaetopterus variopedatus\" and \"Branchiomma nigromaculata\" can regenerate both anterior and posterior body parts after latitudinal bisection. The relationship between somatic and germline stem cell regeneration has been studied at the molecular level in the annelid \"Capitella teleta\". Leeches, however, appear incapable of segmental regeneration. Furthermore, their close relatives, the branchiobdellids, are also incapable of segmental regeneration. However, certain individuals, like the lumbriculids, can regenerate from only a few segments. Segmental regeneration in these animals is epimorphic and occurs through blastema formation. Segmental regeneration has been gained and lost during annelid evolution, as seen in oligochaetes, where head regeneration has been lost three separate times.\n\nAlong with epimorphosis, some polychaetes like \"Sabella pavonina\" experience morphallactic regeneration. Morphallaxis involves the de-differentiation, transformation, and re-differentation of cells to regenerate tissues. How prominent morphallactic regeneration is in oligochaetes is currently not well understood. Although relatively under-reported, it is possible that morphallaxis is a common mode of inter-segment regeneration in annelids. Following regeneration in \"L. variegatus\", past posterior segments sometimes become anterior in the new body orientation, consistent with morphallaxis.\n\nFollowing amputation, most annelids are capable of sealing their body via rapid muscular contraction. Constriction of body muscle can lead to infection prevention. In certain species, such as \"Limnodrilus\", autolysis can be seen within hours after amputation in the ectoderm and mesoderm. Amputation is also thought to cause a large migration of cells to the injury site, and these form a wound plug.\n\nTissue regeneration is widespread among echinoderms and has been well documented in starfish \"(Asteroidea)\", sea cucumbers \"(Holothuroidea)\", and sea urchins \"(Echinoidea).\" Appendage regeneration in echinoderms has been studied since at least the 19th century. In addition to appendages, some species can regenerate internal organs and parts of their central nervous system. In response to injury starfish can autotomize damaged appendages. Autotomy is the self-amputation of a body part, usually an appendage.  Depending on severity, starfish will then go through a four-week process where the appendage will be regenerated. Some species must retain mouth cells in order to regenerate an appendage, due to the need for energy. The first organs to regenerate, in all species documented to date, are associated with the digestive tract. Thus, most knowledge about visceral regeneration in holothurians concerns this system.\n\nRegeneration research using Planarians began in the late 1800s and was popularized by T.H. Morgan at the beginning of the 20th century. Alejandro Sanchez-Alvarado and Philip Newmark transformed planarians into a model genetic organism in the beginning of the 20th century to study the molecular mechanisms underlying regeneration in these animals. Planarians exhibit an extraordinary ability to regenerate lost body parts. For example, a planarian split lengthwise or crosswise will regenerate into two separate individuals. In one experiment, T.H. Morgan found that a piece corresponding to 1/279th of a planarian or a fragment with as few as 10,000 cells can successfully regenerate into a new worm within one to two weeks. After amputation, stump cells form a blastema formed from neoblasts, pluripotent cells found throughout the planarian body. New tissue grows from neoblasts with neoblasts comprising between 20 and 30% of all planarian cells. Recent work has confirmed that neoblasts are totipotent since one single neoblast can regenerate an entire irradiated animal that has been rendered incapable of regeneration. In order to prevent starvation a planarian will use their own cells for energy, this phenomenon is known as de-growth.\n\nLimb regeneration in the axolotl and newt has been extensively studied and researched. Urodele amphibians, such as salamanders and newts, display the highest regenerative ability among tetrapods. As such, they can fully regenerate their limbs, tail, jaws, and retina via epimorphic regeneration leading to functional replacement with new tissue. Salamander limb regeneration occurs in two main steps. First, the local cells dedifferentiate at the wound site into progenitor to form a blastema. Second, the blastemal cells will undergo proliferation, patterning, differentiation and growth using similar genetic mechanisms that deployed during embryonic development. Ultimately, blastemal cells will generate all the cells for the new structure.\nAfter amputation, the epidermis migrates to cover the stump in 1–2 hours, forming a structure called the wound epithelium (WE). Epidermal cells continue to migrate over the WE, resulting in a thickened, specialized signaling center called the apical epithelial cap (AEC). Over the next several days there are changes in the underlying stump tissues that result in the formation of a blastema (a mass of dedifferentiated proliferating cells). As the blastema forms, pattern formation genes – such as HoxA and HoxD – are activated as they were when the limb was formed in the embryo. The positional identity of the distal tip of the limb (i.e. the autopod, which is the hand or foot) is formed first in the blastema. Intermediate positional identities between the stump and the distal tip are then filled in through a process called intercalation. Motor neurons, muscle, and blood vessels grow with the regenerated limb, and reestablish the connections that were present prior to amputation. The time that this entire process takes varies according to the age of the animal, ranging from about a month to around three months in the adult and then the limb becomes fully functional. Researchers at Australian Regenerative Medicine Institute at Monash University, have published that when macrophages, which eat up material debris, were removed, salamanders lost their ability to regenerate and formed scarred tissue instead.\n\nIn spite of the historically few researchers studying limb regeneration, remarkable progress has been made recently in establishing the neotenous amphibian the axolotl (\"Ambystoma mexicanum\") as a model genetic organism. This progress has been facilitated by advances in genomics, bioinformatics, and somatic cell transgenesis in other fields, that have created the opportunity to investigate the mechanisms of important biological properties, such as limb regeneration, in the axolotl. The Ambystoma Genetic Stock Center (AGSC) is a self-sustaining, breeding colony of the axolotl supported by the National Science Foundation as a Living Stock Collection. Located at the University of Kentucky, the AGSC is dedicated to supplying genetically well-characterized axolotl embryos, larvae, and adults to laboratories throughout the United States and abroad. An NIH-funded NCRR grant has led to the establishment of the Ambystoma EST database, the Salamander Genome Project (SGP) that has led to the creation of the first amphibian gene map and several annotated molecular data bases, and the creation of the research community web portal.\n\nAnurans can only regenerate their limbs during embryonic development. Once the limb skeleton has developed regeneration does not occur (Xenopus can grow a cartilaginous spike after amputation). Reactive oxygen species (ROS) appear to be required for a regeneration response in the anuran larvae. ROS production is essential to activate the Wnt signaling pathway, which has been associated with regeneration in other systems. Limb regeneration in salamanders occurs in two major steps. First, adult cells de-differentiate into progenitor cells which will replace the tissues they are derived from. Second, these progenitor cells then proliferate and differentiate until they have completely replaced the missing structure.\n\n\"Hydra\" is a genus of freshwater polyp in the phylum Cnidaria with highly proliferative stem cells that gives them the ability to regenerate their entire body. Any fragment larger than a few hundred epithelial cells that is isolated from the body has the ability to regenerate into a smaller version of itself. The high proportion of stem cells in the hydra supports its efficient regenerative ability.\n\nRegeneration among hydra occurs as foot regeneration arising from the basal part of the body, and head regeneration, arising from the apical region. Regeneration tissues that are cut from the gastric region contain polarity, which allows them to distinguish between regenerating a head in the apical end and a foot in the basal end so that both regions are present in the newly regenerated organism. Head regeneration requires complex reconstruction of the area, while foot regeneration is much simpler, similar to tissue repair. In both foot and head regeneration, however, there are two distinct molecular cascades that occur once the tissue is wounded: early injury response and a subsequent, signal-driven pathway of the regenerating tissue that leads to cellular differentiation. This early-injury response includes epithelial cell stretching for wound closure, the migration of interstitial progenitors towards the wound, cell death, phagocytosis of cell debris, and reconstruction of the extracellular matrix.\n\nRegeneration in hydra has been defined as morphallaxis, the process where regeneration results from remodeling of existing material without cellular proliferation. If a hydra is cut into two pieces, the remaining severed sections form two fully functional and independent hydra, approximately the same size as the two smaller severed sections. This occurs through the exchange and rearrangement of soft tissues without the formation of new material.\n\nOwing to a limited literature on the subject, birds are believed to have very limited regenerative abilities as adults. Some studies on roosters have suggested that birds can adequately regenerate some parts of the limbs and depending on the conditions in which regeneration takes place, such as age of the animal, the inter-relationship of the injured tissue with other muscles, and the type of operation, can involve complete regeneration of some musculoskeletal structure. Werber and Goldschmidt (1909) found that the goose and duck were capable of regenerating their beaks after partial amputation and Sidorova (1962) observed liver regeneration via hypertrophy in roosters. Birds are also capable of regenerating the hair cells in their cochlea following noise damage or ototoxic drug damage. Despite this evidence, contemporary studies suggest reparative regeneration in avian species is limited to periods during embryonic development. An array of molecular biology techniques have been successful in manipulating cellular pathways known to contribute to spontaneous regeneration in chick embryos. For instance, removing a portion of the elbow joint in a chick embryo via window excision or slice excision and comparing joint tissue specific markers and cartilage markers showed that window excision allowed 10 out of 20 limbs to regenerate and expressed joint genes similarly to a developing embryo. In contrast, slice excision did not allow the joint to regenerate due to the fusion of the skeletal elements seen by an expression of cartilage markers.\n\nSimilar to the physiological regeneration of hair in mammals, birds can regenerate their feathers in order to repair damaged feathers or to attract mates with their plumage. Typically, seasonal changes that are associated with breeding seasons will prompt a hormonal signal for birds to begin regenerating feathers. This has been experimentally induced using thyroid hormones in the Rhode Island Red Fowls.\n\nMammals are capable of cellular and physiological regeneration, but have generally poor reparative regenerative ability across the group. Examples of physiological regeneration in mammals include epithelial renewal (e.g., skin and intestinal tract), red blood cell replacement, antler regeneration and hair cycling. Male deer lose their antlers annually during the months of January to April then through regeneration are able to regrow them as an example of physiological regeneration. A deer antler is the only appendage of a mammal that can be regrown every year. While reparative regeneration is a rare phenomenon in mammals, it does occur. A well-documented example is regeneration of the digit tip distal to the nail bed. Reparative regeneration has also been observed in rabbits, pikas and African spiny mice. In 2012, researchers discovered that two species of African Spiny Mice, \"Acomys kempi\" and \"Acomys percivali\", were capable of completely regenerating the autotomically released or otherwise damaged tissue. These species can regrow hair follicles, skin, sweat glands, fur and cartilage. In addition to these two species, subsequent studies demonstrated that \"Acomys cahirinus\" could regenerate skin and excised tissue in the ear pinna.\n\nDespite these examples, it is generally accepted that adult mammals have limited regenerative capacity compared to most vertebrate embryos/larvae, adult salamanders and fish. But the regeneration therapy approach of Robert O. Becker, using electrical stimulation, has shown promising results for rats and mammals in general.\n\nSome researchers have also claimed that the MRL mouse strain exhibits enhanced regenerative abilities. Work comparing the differential gene expression of scarless healing MRL mice and a poorly-healing C57BL/6 mouse strain, identified 36 genes differentiating the healing process between MRL mice and other mice. Study of the regenerative process in these animals is aimed at discovering how to duplicate them in humans, such as deactivation of the p21 gene. However, recent work has shown that MRL mice actually close small ear holes with scar tissue, rather than regeneration as originally claimed.\n\nMRL mice are not protected against myocardial infarction; heart regeneration in adult mammals (neocardiogenesis) is limited, because heart muscle cells are nearly all terminally differentiated. MRL mice show the same amount of cardiac injury and scar formation as normal mice after a heart attack. However, recent studies provide evidence that this may not always be the case, and that MRL mice can regenerate after heart damage. \n\nThe regrowth of lost tissues or organs in the human body is being researched. Some tissues such as skin regrow quite readily; others have been thought to have little or no capacity for regeneration, but ongoing research suggests that there is some hope for a variety of tissues and organs. Human organs that have been regenerated include the bladder, vagina and the penis.\n\nAs are all metazoans, humans are capable of physiological regeneration (i.e. the replacement of cells during homeostatic maintenance that does not necessitate injury). For example, the regeneration of red blood cells via erythropoiesis occurs through the maturation of erythrocytes from hematopoietic stem cells in the bone marrow, their subsequent circulation for around 90 days in the blood stream, and their eventual cell-death in the spleen. Another example of physiological regeneration is the sloughing and rebuilding of a functional endometrium during each menstrual cycle in females in response to varying levels of circulating estrogen and progesterone.\n\nHowever, humans are limited in their capacity for reparative regeneration, which occurs in response to injury. One of the most studied regenerative responses in humans is the hypertrophy of the liver following liver injury. For example, the original mass of the liver is re-established in direct proportion to the amount of liver removed following partial hepatectomy, which indicates that signals from the body regulate liver mass precisely, both positively and negatively, until the desired mass is reached. This response is considered cellular regeneration (a form of compensatory hypertrophy) where the function and mass of the liver is regenerated through the proliferation of existing mature hepatic cells (mainly hepatocytes), but the exact morphology of the liver is not regained. This process is driven by growth factor and cytokine regulated pathways. The normal sequence of inflammation and regeneration does not function accurately in cancer. Specifically, cytokine stimulation of cells leads to expression of genes that change cellular functions and suppress the immune response.\n\nAdult neurogenesis is also a form of cellular regeneration. For example, hippocampal neuron renewal occurs in normal adult humans at an annual turnover rate of 1.75% of neurons. Cardiac myocyte renewal has been found to occur in normal adult humans, and at a higher rate in adults following acute heart injury such as infarction. Even in adult myocardium following infarction, proliferation is only found in around 1% of myocytes around the area of injury, which is not enough to restore function of cardiac muscle. However, this may be an important target for regenerative medicine as it implies that regeneration of cardiomyocytes, and consequently of myocardium, can be induced.\n\nAnother example of reparative regeneration in humans is fingertip regeneration, which occurs after phalange amputation distal to the nail bed (especially in children) and rib regeneration, which occurs following osteotomy for scoliosis treatment (though usually regeneration is only partial and may take up to 1 year).\n\nThe ability and degree of regeneration in reptiles differs among the various species, but the most notable and well-studied occurrence is tail-regeneration in lizards. In addition to lizards, regeneration has been observed in the tails and maxillary bone of crocodiles and adult neurogenesis has also been noted. Tail regeneration has never been observed in snakes. Lizards possess the highest regenerative capacity as a group. Following autotomous tail loss, epimorphic regeneration of a new tail proceeds through a blastema-mediated process that results in a functionally and morphologically similar structure.\n\nStudies have shown that some chondrichthyans can regenerate rhodopsin by cellular regeneration, micro RNA organ regeneration, teeth physiological teeth regeneration, and reparative skin regeneration. Rhodopsin regeneration has been studied in skates and rays. After complete photo-bleaching, rhodopsin can completely regenerate within 2 hours in the retina. White bamboo sharks can regenerate at least two-thirds of their liver and this has been linked to three micro RNAs, xtr-miR-125b, fru-miR-204, and has-miR-142-3p_R-. In one study two thirds of the liver was removed and within 24 hours more than half of the liver had undergone hypertrophy. Leopard sharks routinely replace their teeth every 9–12 days and this is an example of physiological regeneration. This can occur because shark teeth are not attached to a bone, but instead are developed within a bony cavity. It has been estimated that the average shark loses about 30,000 to 40,000 teeth in a lifetime. Some sharks can regenerate scales and even skin following damage. Within two weeks of skin wounding the mucus is secreted into the wound and this initiates the healing process. One study showed that the majority of the wounded area was regenerated within 4 months, but the regenerated area also showed a high degree of variability.\n\n\n\n"}
{"id": "706186", "url": "https://en.wikipedia.org/wiki?curid=706186", "title": "Reproductive rights", "text": "Reproductive rights\n\nReproductive rights are legal rights and freedoms relating to reproduction and reproductive health that vary amongst countries around the world. The World Health Organization defines reproductive rights as follows:\n\nReproductive rights rest on the recognition of the basic right of all couples and individuals to decide freely and responsibly the number, spacing and timing of their children and to have the information and means to do so, and the right to attain the highest standard of sexual and reproductive health. They also include the right of all to make decisions concerning reproduction free of discrimination, coercion and violence.\n\nWomen's reproductive rights may include some or all of the following: the right to legal and safe abortion; the right to birth control; freedom from coerced sterilization and contraception; the right to access good-quality reproductive healthcare; and the right to education and access in order to make free and informed reproductive choices. Reproductive rights may also include the right to receive education about sexually transmitted infections and other aspects of sexuality, and protection from practices such as female genital mutilation (FGM).\n\nReproductive rights began to develop as a subset of human rights at the United Nation's 1968 International Conference on Human Rights. The resulting non binding Proclamation of Tehran was the first international document to recognize one of these rights when it stated that: \"Parents have a basic human right to determine freely and responsibly the number and the spacing of their children.\" States, though, have been slow in incorporating these rights in internationally legally binding instruments. Thus, while some of these rights have already been recognized in hard law, that is, in legally binding international human rights instruments, others have been mentioned only in non binding recommendations and, therefore, have at best the status of soft law in international law, while a further group is yet to be accepted by the international community and therefore remains at the level of advocacy.\n\nIssues related to reproductive rights are some of the most vigorously contested rights' issues worldwide, regardless of the population's socioeconomic level, religion or culture.\n\nThe issue of reproductive rights is frequently presented as being of vital importance in discussions and articles by population concern organizations such as Population Matters.\n\nReproductive rights are a subset of sexual and reproductive health and rights.\n\nIn 1945, the United Nations Charter included the obligation \"to promote... universal respect for, and observance of, human rights and fundamental freedoms for all without discrimination as to race, sex, language, or religion\". However, the Charter did not define these rights. Three years later, the UN adopted the Universal Declaration of Human Rights (UDHR), the first international legal document to delineate human rights; the UDHR does not mention reproductive rights. Reproductive rights began to appear as a subset of human rights in the 1968 Proclamation of Tehran, which states: \"Parents have a basic human right to determine freely and responsibly the number and the spacing of their children\".\n\nThis right was affirmed by the UN General Assembly in the 1969 Declaration on Social Progress and Development which states \"The family as a basic unit of society and the natural environment for the growth and well-being of all its members, particularly children and youth, should be assisted and protected so that it may fully assume its responsibilities within the community. Parents have the exclusive right to determine freely and responsibly the number and spacing of their children.\" The 1975 UN International Women's Year Conference echoed the Proclamation of Tehran.\n\nThe twenty-year \"Cairo Programme of Action\" was adopted in 1994 at the International Conference on Population and Development (ICPD) in Cairo. The non-binding Programme of Action asserted that governments have a responsibility to meet individuals' reproductive needs, rather than demographic targets. It recommended that family planning services be provided in the context of other reproductive health services, including services for healthy and safe childbirth, care for sexually transmitted infections, and post-abortion care. The ICPD also addressed issues such as violence against women, sex trafficking, and adolescent health. The Cairo Program is the first international policy document to define reproductive health, stating:\nReproductive health is a state of complete physical, mental and social well-being and not merely the absence of disease or infirmity, in all matters relating to the reproductive system and its functions and processes. Reproductive health therefore implies that people are able to have a satisfying and safe sex life and that they have the capability to reproduce and the freedom to decide if, when and how often to do so. Implicit in this last condition are the right of men and women to be informed [about] and to have access to safe, effective, affordable and acceptable methods of family planning of their choice, as well as other methods for regulation of fertility which are not against the law, and the right of access to appropriate health-care services that will enable women to go safely through pregnancy and childbirth and provide couples with the best chance of having a healthy infant [para. 72].\n\nUnlike previous population conferences, a wide range of interests from grassroots to government level were represented in Cairo. 179 nations attended the ICPD and overall eleven thousand representatives from governments, NGOs, international agencies and citizen activists participated. The ICPD did not address the far-reaching implications of the HIV/AIDS epidemic. In 1999, recommendations at the ICPD+5 were expanded to include commitment to AIDS education, research, and prevention of mother-to-child transmission, as well as to the development of vaccines and microbicides.\n\nThe Cairo Programme of Action was adopted by 184 UN member states. Nevertheless, many Latin American and Islamic states made formal reservations to the programme, in particular, to its concept of reproductive rights and sexual freedom, to its treatment of abortion, and to its potential incompatibility with Islamic law.\n\nImplementation of the Cairo Programme of Action varies considerably from country to country. In many countries, post-ICPD tensions emerged as the human rights-based approach was implemented. Since the ICPD, many countries have broadened their reproductive health programs and attempted to integrate maternal and child health services with family planning. More attention is paid to adolescent health and the consequences of unsafe abortion. Lara Knudsen observes that the ICPD succeeded in getting feminist language into governments' and population agencies' literature, but in many countries the underlying concepts are not widely put into practice. In two preparatory meetings for the ICPD+10 in Asia and Latin America, the United States, under the George W. Bush Administration, was the only nation opposing the ICPD's Programme of Action.\n\nThe 1995 Fourth World Conference on Women in Beijing, in its non-binding Declaration and Platform for Action, supported the Cairo Programme's definition of reproductive health, but established a broader context of reproductive rights:\nThe human rights of women include their right to have control over and decide freely and responsibly on matters related to their sexuality, including sexual and reproductive health, free of coercion, discrimination and violence. Equal relationships between women and men in matters of sexual relations and reproduction, including full respect for the integrity of the person, require mutual respect, consent and shared responsibility for sexual behavior and its consequences [para. 96]. The Beijing Platform demarcated twelve interrelated critical areas of the human rights of women that require advocacy. The Platform framed women's reproductive rights as \"indivisible, universal and inalienable human rights.\"\n\nThe Yogyakarta Principles on the Application of International Human Rights Law in relation to Sexual Orientation and Gender Identity, proposed by a group of experts in November 2006 but not yet incorporated by States in international law, declares in its Preamble that \"the international community has recognized the rights of persons to decide freely and responsibly on matters related to their sexuality, including sexual and reproductive health, free from coercion, discrimination, and violence.\" In relation to reproductive health, Principle 9 on \"The Right to Treatment with Humanity while in Detention\" requires that \"States shall... <nowiki>[p]rovide</nowiki> adequate access to medical care and counseling appropriate to the needs of those in custody, recognizing any particular needs of persons on the basis of their sexual orientation and gender identity, including with regard to reproductive health, access to HIV/AIDS information and therapy and access to hormonal or other therapy as well as to gender-reassignment treatments where desired.\" Nonetheless, African, Caribbean and Islamic Countries, as well as the Russian Federation, have objected to the use of these principles as Human Rights standards.\n\nState abuses against reproductive rights have happened both under right-wing and left-wing governments. Such abuses include attempts to forcefully increase the birth rate - one of the most notorious natalist policies of the 20th century was that which occurred in communist Romania in the period of 1967-1990 during communist leader Nicolae Ceaușescu, who adopted a very aggressive natalist policy which included outlawing abortion and contraception, routine pregnancy tests for women, taxes on childlessness, and legal discrimination against childless people - as well as attempts to decrease the fertility rate - China's one child policy (1978-2015). State mandated forced marriage was also practiced by authoritarian governments as a way to meet population targets: the Khmer Rouge regime in Cambodia systematically forced people into marriages, in order to increase the population and continue the revolution. Some governments have implemented eugenic policies of forced sterilizations of 'undesirable' population groups. Such policies were carried out against ethnic minorities in Europe and North America in the 20th century, and more recently in Latin America against the Indigenous population in the 1990s; in Peru, President Alberto Fujimori (in office from 1990 to 2000) has been accused of genocide and crimes against humanity as a result of a sterilization program put in place by his administration targeting indigenous people (mainly the Quechuas and the Aymaras).\n\nThe Istanbul convention, the first legally binding instrument in Europe in the field of violence against women and domestic violence prohibits forced sterilization and forced abortion:\n\nSince most existing legally binding international human rights instruments do not explicitly mention sexual and reproductive rights, a broad coalition of NGOs, civil servants, and experts working in international organizations have been promoting a reinterpretation of those instruments to link the realization of the already internationally recognized human rights with the realization of reproductive rights. An example of this linkage is provided by the 1994 Cairo Programme of Action: \nReproductive rights embrace certain human rights that are already recognized in national laws, international human rights documents and other relevant United Nations consensus documents. These rights rest on the recognition of the basic right of all couples and individuals to decide freely and responsibly the number, spacing and timing of their children and to have the information and means to do so, and the right to attain the highest standard of sexual and reproductive health. It also includes the right of all to make decisions concerning reproduction free of discrimination, coercion and violence as expressed in human rights documents. In the exercise of this right, they should take into account the needs of their living and future children and their responsibilities towards the community.\nSimilarly, Amnesty International has argued that the realisation of reproductive rights is linked with the realisation of a series of recognised human rights, including the right to health, the right to freedom from discrimination, the right to privacy, and the right not to be subjected to torture or ill-treatment. \n\nThe World Health Organization states that:\n\nHowever, not all states have accepted the inclusion of reproductive rights in the body of internationally recognized human rights. At the Cairo Conference, several states made formal reservations either to the concept of reproductive rights or to its specific content. Ecuador, for instance, stated that: \nWith regard to the Programme of Action of the Cairo International Conference on Population and Development and in accordance with the provisions of the Constitution and laws of Ecuador and the norms of international law, the delegation of Ecuador reaffirms, inter alia, the following principles embodied in its Constitution: the inviolability of life, the protection of children from the moment of conception, freedom of conscience and religion, the protection of the family as the fundamental unit of society, responsible paternity, the right of parents to bring up their children and the formulation of population and development plans by the Government in accordance with the principles of respect for sovereignty. Accordingly, the delegation of Ecuador enters a reservation with respect to all terms such as \"regulation of fertility\", \"interruption of pregnancy\", \"reproductive health\", \"reproductive rights\" and \"unwanted children\", which in one way or another, within the context of the Programme of Action, could involve abortion.\nSimilar reservations were made by Argentina, Dominican Republic, El Salvador, Honduras, Malta, Nicaragua, Paraguay, Peru and the Holy See. Islamic Countries, such as Brunei, Djibouti, Iran, Jordan, Kuwait, Libya, Syria, United Arab Emirates, and Yemen made broad reservations against any element of the programme that could be interpreted as contrary to the Sharia. Guatemala even questioned whether the conference could legally proclaim new human rights.\n\nThe United Nations Population Fund (UNFPA) and the World Health Organization (WHO) advocate for reproductive rights with a primary emphasis on women's rights. In this respect the UN and WHO focus on a range of issues from access to family planning services, sex education, menopause, and the reduction of obstetric fistula, to the relationship between reproductive health and economic status.\n\nThe reproductive rights of women are advanced in the context of the right to freedom from discrimination and the social and economic status of women. The group Development Alternatives with Women for a New Era (DAWN) explained the link in the following statement:\nControl over reproduction is a basic need and a basic right for all women. Linked as it is to women's health and social status, as well as the powerful social structures of religion, state control and administrative inertia, and private profit, it is from the perspective of poor women that this right can best be understood and affirmed. Women know that childbearing is a social, not a purely personal, phenomenon; nor do we deny that world population trends are likely to exert considerable pressure on resources and institutions by the end of this century. But our bodies have become a pawn in the struggles among states, religions, male heads of households, and private corporations. Programs that do not take the interests of women into account are unlikely to succeed...\n\nWomen's reproductive rights have long retained key issue status in the debate on overpopulation.\n\"The only ray of hope I can see – and it's not much – is that wherever women are put in control of their lives, both politically and socially; where medical facilities allow them to deal with birth control and where their husbands allow them to make those decisions, birth rate falls. Women don't want to have 12 kids of whom nine will die.\" \"David Attenborough\n\nAccording to OHCHR: \"Women’s sexual and reproductive health is related to multiple human rights, including the right to life, the right to be free from torture, the right to health, the right to privacy, the right to education, and the prohibition of discrimination\".\n\nAttempts have been made to analyse the socioeconomic conditions that affect the realisation of a woman's reproductive rights. The term reproductive justice has been used to describe these broader social and economic issues. Proponents of reproductive justice argue that while the right to legalized abortion and contraception applies to everyone, these choices are only meaningful to those with resources, and that there is a growing gap between access and affordability.\n\nMen's reproductive rights have been claimed by various organizations, both for issues of reproductive health, and other rights related to sexual reproduction.\n\nThree international issues in men's reproductive health are sexually transmitted diseases, cancer and exposure to toxins.\n\nRecently men's reproductive right with regards to paternity have become subject of debate in the U.S. The term \"male abortion\" was coined by Melanie McCulley, a South Carolina attorney, in a 1998 article. The theory begins with the premise that when a woman becomes pregnant she has the option of abortion, adoption, or parenthood; it argues, in the context of legally recognized gender equality, that in the earliest stages of pregnancy the putative (alleged) father should have the right to relinquish all future parental rights and financial responsibility, leaving the informed mother with the same three options. This concept has been supported by a former president of the feminist organization National Organization for Women, attorney Karen DeCrow. The feminist argument for male reproductive choice contends that the uneven ability to choose experienced by men and women in regards to parenthood is evidence of a state-enforced coercion favoring traditional sex roles.\n\nIn 2006, the National Center for Men brought a case in the US, \"Dubay v. Wells\" (dubbed by some \"\"Roe v. Wade\" for men\"), that argued that in the event of an unplanned pregnancy, when an unmarried woman informs a man that she is pregnant by him, he should have an opportunity to give up all paternity rights and responsibilities. Supporters argue that this would allow the woman time to make an informed decision and give men the same reproductive rights as women. In its dismissal of the case, the U.S. Court of Appeals (Sixth Circuit) stated that \"the Fourteenth Amendment does not deny to [the] State the power to treat different classes of persons in different ways.\"\n\nThe opportunity to give men the right for a Paper Abortion is heavily discussed.\n\nIntersex, in humans and other animals, is a variation in sex characteristics including chromosomes, gonads, or genitals that do not allow an individual to be distinctly identified as male or female. Such variation may involve genital ambiguity, and combinations of chromosomal genotype and sexual phenotype other than XY-male and XX-female. Intersex persons are often subjected to involuntary \"sex normalizing\" surgical and hormonal treatments in infancy and childhood, often also including sterilization.\n\nUN agencies have begun to take note. On 1 February 2013, Juan E Mendés, the UN Special Rapporteur on torture and other cruel, inhuman or degrading treatment or punishment, issued a statement condemning non-consensual surgical intervention on intersex people. His report stated, \"Children who are born with atypical sex characteristics are often subject to irreversible sex assignment, involuntary sterilization, involuntary genital normalizing surgery, performed without their informed consent, or that of their parents, \"in an attempt to fix their sex\", leaving them with permanent, irreversible infertility and causing severe mental suffering\". In May 2014, the World Health Organization issued a joint statement on \"Eliminating forced, coercive and otherwise involuntary sterilization, An interagency statement\" with the OHCHR, UN Women, UNAIDS, UNDP, UNFPA and UNICEF. The report references the involuntary surgical \"sex-normalising or other procedures\" on \"intersex persons\". It questions the medical necessity of such treatments, patients' ability to consent, and a weak evidence base. The report recommends a range of guiding principles to prevent compulsory sterilization in medical treatment, including ensuring patient autonomy in decision-making, ensuring non-discrimination, accountability and access to remedies.\n\nIn many jurisdictions minors require parental consent or parental notification in order to access various reproductive services, such as contraception, abortion, gynecological consultations, testing for STDs etc. The requirement that minors have parental consent/notification for testing for HIV/AIDS is especially controversial, particularly in areas where the disease is endemic, and it is a sensitive subject. Balancing minors' rights versus parental rights is considered an ethical problem in medicine and law, and there have been many court cases on this issue in the US. An important concept recognized since 1989 by the Convention on the Rights of the Child is that of the evolving capacities of a minor, namely that minors should, in accordance with their maturity and level of understanding, be involved in decisions that affect them.\n\nYouth are often denied equal access to reproductive health services because health workers view adolescent sexual activity as unacceptable, or see sex education as the responsibility of parents. Providers of reproductive health have little accountability to youth clients, a primary factor in denying youth access to reproductive health care. In many countries, regardless of legislation, minors are denied even the most basic reproductive care, if they are not accompanied by parents: in India, for instance, in 2017, a 17-year-old girl who was rejected by her family due to her pregnancy, was also rejected by hospitals and gave birth in the street. In recent years the lack of reproductive rights for adolescents has been a concern of international organizations, such as UNFPA.\n\nMandatory involvement of parents in cases where the minor has sufficient maturity to understand their situation is considered by health organization as a violation of minor's rights and detrimental to their health. The World Health Organization has criticized parental consent/notification laws:\n\nDiscrimination in health care settings takes many forms and is often manifested when an individual or group is denied access to health care services that are otherwise available to others. It can also occur through denial of services that are only needed by certain groups, such as women. Examples include specific individuals or groups being subjected to physical and verbal abuse or violence; involuntary treatment; breaches of confidentiality and/or denial of autonomous decision-making, such as the requirement of consent to treatment by parents, spouses or guardians; and lack of free and informed consent. [...] Laws and policies must respect the principles of autonomy in health care decision-making; guarantee free and informed consent, privacy and confidentiality; prohibit mandatory HIV testing; prohibit screening procedures that are not of benefit to the individual or the public; and ban involuntary treatment and mandatory third-party authorization and notification requirements.\"\nAccording to UNICEF: \"When dealing with sexual and reproductive health, the obligation\nto inform parents and obtain their consent becomes a significant barrier with consequences for adolescents’ lives and for public health in general.\" One specific issue which is seen as a form of hypocrisy of legislators is that of having a higher age of medical consent for the purpose of reproductive and sexual health than the age of sexual consent - in such cases the law allows youth to engage in sexual activity, but does not allow them to consent to medical procedures that may arise from being sexually active; UNICEF states that \"On sexual and reproductive health matters, the minimum age of medical consent should never be higher than the age of sexual consent.\"\n\nMany unintended pregnancies stem from traditional contraceptive methods or no contraceptive measures.\n\nYouth sexual education in Uganda is relatively low. Comprehensive sex education is not generally taught in schools; even if it was, the majority of young people do not stay in school after the age of fifteen, so information would be limited regardless.\n\nAfrica experiences high rates of unintended pregnancy, along with high rates of HIV/AIDS. Young women aged 15–24 are eight times more likely to have HIV/AIDS than young men. Sub-Saharan Africa is the world region most affected by HIV/AIDS, with approximately 25 million people living with HIV in 2015. Sub-Saharan Africa accounts for two-thirds of the global total of new HIV infections.\n\nAttempted abortions and unsafe abortions are a risk for youth in Africa. On average, there are 2.4 million unsafe abortions in East Africa, 1.8 million in Western Africa, over 900,000 in Middle Africa, and over 100,000 in Southern Africa each year.\n\nIn Uganda, abortion is illegal except to save the mother's life. However, 78% of teenagers report knowing someone who has had an abortion and the police do not always prosecute everyone who has an abortion. An estimated 22% of all maternal deaths in the area stem from illegal, unsafe abortions.\n\nOver 85% of European women (all ages) have used some form of birth control in their lives. Europeans as an aggregate report using the pill and condoms as the most commonly used contraceptives.\n\nFamily planning has become prominent throughout the region and most taboos concerning sexuality have been lifted or diminished. Youth sexual and reproductive health centers have been established across most of the region. In Sweden, approximately 80% of girls and 17% of boys have visited these youth centers, which provide all or nearly all services youth need at little to no charge. Sweden has the highest percentage of lifetime contraceptive use, with 96% of its inhabitants claiming to have used birth control at some point in their life. Sweden also has a high self-reported rate of postcoital pill use. A 2007 anonymous survey of Swedish 18-year-olds showed that three out of four youth were sexually active, with 5% reporting having had an abortion and 4% reporting the contraction of an STI. Similar centers exist in Estonia, Finland, and Portugal.\n\nViews on sexual practice vary throughout the region. For example, in the United Kingdom (UK), sex among youth is generally looked down upon and seen as a problem in need of solution. In the Netherlands, sex between youth is viewed as normal and therefore not discussed in terms of solutions, but rather in terms of ensuring safe practices. That being said, the UK tends to focus on stopping sexual behavior, while the Netherlands focuses on building self-esteem and healthy relationships.\n\nLatin America has come to international attention due to its harsh anti-abortion laws. Latin America is home to some of the few countries of the world with a complete ban on abortion, without an exception for saving maternal life. In some of these countries, particularity in Central America, the enforcement of such laws is very aggressive: El Salvador and Nicaragua have drawn international attention for strong enforcement of their complete bans on abortion. In 2017, Chile relaxed its total ban, allowing abortion to be performed when the woman’s life is in danger, when a fetus is unviable, or in cases of rape.\n\nIn Ecuador, education and class play a large role in the definition of which young women become pregnant and which do not - 50% of young women who are illiterate get pregnant, compared to 11% of girls with secondary education. The same is true for poorer individuals - 28% become impregnated while only 11% of young women in wealthier households do. Furthermore, access to reproductive rights, including contraceptives, are limited, due to age and the perception of female morality. Health care providers often discuss contraception theoretically, not as a device to be used on a regular basis. Decisions concerning sexual activity often involve secrecy and taboos, as well as a lack of access to accurate information. Even more telling, young women have much easier access to maternal healthcare than they do to contraceptive help, which helps explain high pregnancy rates in the region.\n\nRates of adolescent pregnancy in Latin America number over a million each year.\n\nAmong sexually experienced teenagers, 78% of teenage females and 85% of teenage males used contraception the first time they had sex; 86% and 93% of these same females and males, respectively, reported using contraception the last time they had sex. The male condom is the most commonly used method during first sex, although 54% of young women in the United States rely upon the pill.\n\nYoung people in the U.S. are no more sexually active than individuals in other developed countries, but they are significantly less knowledgeable about contraception and safe sex practices. As of 2006, only twenty states required sex education in schools - of these, only ten required information about contraception. On the whole, less than 10% of American students receive sex education that includes topical coverage of abortion, homosexuality, relationships, pregnancy, and STI prevention. Abstinence-only education was used throughout much of the United States in the 1990s and early 2000s. Based upon the moral principle that sex outside of marriage is unacceptable, the programs often misled students about their rights to have sex, the consequences, and prevention of pregnancy and STIs.\n\nAbortion in the United States is legal since the United States Supreme Court decision \"Roe v. Wade\" which decriminalised abortion nationwide in 1973, and established a minimal period during which abortion is legal (with more or fewer restrictions throughout the pregnancy). That basic framework, modified in \"Planned Parenthood v. Casey\" (1992), remains nominally in place, although the effective availability of abortion varies significantly from state to state, as many counties have no abortion providers. \"Planned Parenthood v. Casey\" held that a law cannot place legal restrictions imposing an undue burden for \"the purpose or effect of placing a substantial obstacle in the path of a woman seeking an abortion of a nonviable fetus.\" Abortion is a controversial political issue, and regular attempts to restrict it occur in most states. One such case, originating in Texas, led to the Supreme Court case of \"Whole Woman's Health v. Hellerstedt\" (2016) in which several Texas restrictions were struck down.\n\nOne of the reasons why reproductive rights are poor in many places, is that the vast majority of the population does not know what the law is. Not only are ordinary people uninformed, but so are medical doctors. A study in Brazil on medical doctors found considerable ignorance and misunderstanding of the law on abortion (which is severely restricted, but not completely illegal). In Ghana, abortion, while restricted, is permitted on several grounds, but only 3% of pregnant women and 6% of those seeking an abortion were aware of the legal status of abortion. In Nepal, abortion was legalized in 2002, but a study in 2009 found that only half of women knew that abortion was legalized. Many people also do not understand the laws on sexual violence: in Hungary, where marital rape was made illegal in 1997, in a study in 2006, 62% of people did not know that marital rape was a crime. The United Nations Development Programme states that, in order to advance gender justice, \"Women must know their rights and be able to access legal systems\", and the 1993 UN Declaration on the Elimination of Violence Against Women states at Art. 4 (d) [...] \"States should also inform women of their rights in seeking redress through such mechanisms\".\n\nAddressing issues of gender-based violence is crucial for attaining reproductive rights. The United Nations Population Fund refers to \"\"Equality and equity for men and women, to enable individuals to make free and informed choices in all spheres of life, free from discrimination based on gender\" and \"Sexual and reproductive security, including freedom from sexual violence and coercion, and the right to privacy,\"\" as part of achieving reproductive rights, and states that the right to liberty and security of the person which is fundamental to reproductive rights obliges states to:\n\nThe WHO states:\n\nAmnesty International writes that:\n\nOne key issue for achieving reproductive rights is criminalization of sexual violence. If a woman is not protected from forced sexual intercourse, she is not protected from forced pregnancy, namely pregnancy from rape. In order for a woman to be able to have reproductive rights, she must have the right to choose with whom and when to reproduce; and first of all, decide whether, when, and under what circumstances to be sexually active. In many countries, these rights of women are not respected, because women do not have a choice in regard to their partner, with forced marriage and child marriage being common in parts of the world; and neither do they have any rights in regard to sexual activity, as many countries do not allow women to refuse to engage in sexual intercourse when they do not want to (because marital rape is not criminalized in those countries) or to engage in consensual sexual intercourse if they want to (because sex outside marriage is illegal in those countries). In addition to legal barriers, there are also social barriers, because in many countries a complete sexual subordination of a woman to her husband is expected (for instance, in one survey 74% of women in Mali said that a husband is justified to beat his wife if she refuses to have sex with him), while sexual/romantic relations disapproved by family members, or generally sex outside marriage, can result in serious violence, such as honor killings.\n\nAccording to the CDC, \"HIV stands for human immunodeficiency virus. It weakens a person’s immune system by destroying important cells that fight disease and infection. No effective cure exists for HIV. But with proper medical care, HIV can be controlled.\" HIV amelioration is an important aspect of reproductive rights because the virus can be transmitted from mother to child during pregnancy or birth, or via breast milk.\n\nThe WHO states that: \"All women, including those with HIV, have the right “to decide freely and responsibly on the number and spacing of their children and to have access to the information, education and means to enable them to exercise these rights”\". The reproductive rights of people living with HIV, and their health, are very important. The link between HIV and reproductive rights exists in regard to four main issues:\n\nThe WHO states that the reproductive rights and health of girls in child marriages are negatively affected.\nThe UNPF calls child marriage a \"human rights violation\" and states that in developing countries, one in every three girls is married before reaching age 18, and one in nine is married under age 15. A forced marriage is a marriage in which one or more of the parties is married without his or her consent or against his or her will. The Istanbul convention, the first legally binding instrument in Europe in the field of violence against women and domestic violence, requires countries which ratify it to prohibit forced marriage (Article 37) and to ensure that forced marriages can be easily voided without further victimization (Article 32).\n\nSexual violence in armed conflict is sexual violence committed by combatants during armed conflict, war, or military occupation often as spoils of war; but sometimes, particularly in ethnic conflict, the phenomenon has broader sociological motives. It often includes gang rape. Rape is often used as a tactic of war and a threat to international security. Sexual violence in armed conflict is a violation of reproductive rights, and often leads to forced pregnancy and sexually transmitted infections. Such sexual violations affect mostly women and girls, but rape of men can also occur, such as in Democratic Republic of the Congo.\n\nMaternal death is defined by the World Health Organization (WHO) as \"the death of a woman while pregnant or within 42 days of termination of pregnancy, irrespective of the duration and site of the pregnancy, from any cause related to or aggravated by the pregnancy or its management but not from accidental or incidental causes.\" It is estimated that in 2015, about 303,000 women died during and following pregnancy and childbirth, and 99% of such deaths occur in developing countries.\n\nBirth control, also known as contraception and fertility control, is a method or device used to prevent pregnancy. Birth control has been used since ancient times, but effective and safe methods of birth control only became available in the 20th century. Planning, making available, and using birth control is called family planning. Some cultures limit or discourage access to birth control because they consider it to be morally, religiously, or politically undesirable. \n\nAll birth control methods meet opposition, especially religious opposition, in some parts of the world. Opposition does not only target modern methods, but also 'traditional' ones : for example, the Quiverfull movement, a conservative Christian ideology, encourages the maximization of procreation, and opposes all forms of birth control, including natural family planning.\n\nAccording to a study by WHO and the Guttmacher Institute worldwide, 25 million unsafe abortions (45% of all abortions) occurred every year between 2010 and 2014. 97% of unsafe abortions occur in developing countries in Africa, Asia and Latin America. By contrast, most abortions that take place in Western and Northern Europe and North America are safe.\n\nThe Committee on the Elimination of Discrimination against Women considers the criminalization of abortion a \"violations of women’s sexual and reproductive health and rights\" and a form of \"gender based violence\"; paragraph 18 of its \"General recommendation No. 35 on gender based violence against women, updating general recommendation No. 19\" states that: \"Violations of women’s sexual and reproductive health and rights, such as forced sterilizations, forced abortion, forced pregnancy, criminalisation of abortion, denial or delay of safe abortion and post abortion care, forced continuation of pregnancy, abuse and mistreatment of women and girls seeking sexual and reproductive health information, goods and services, are forms of gender based violence that, depending on the circumstances, may amount to torture or cruel, inhuman or degrading treatment.\" The same \"General Recommendation\" also urges countries at paragraph 31 to [...] In particular, repeal:\na) Provisions that allow, tolerate or condone forms of gender based violence against women, including [...] legislation that criminalises abortion\".\n\nAn article from the World Health Organization calls safe, legal abortion a \"fundamental right of women, irrespective of where they live\" and unsafe abortion a \"silent pandemic\". The article states \"ending the silent pandemic of unsafe abortion is an urgent public-health and human-rights imperative.\" It also states \"access to safe abortion improves women’s health, and vice versa, as documented in Romania during the regime of President Nicolae Ceaușescu\" and \"legalisation of abortion on request is a necessary but insufficient step toward improving women’s health\" citing that in some countries, such as India where abortion has been legal for decades, access to competent care remains restricted because of other barriers. WHO’s Global Strategy on Reproductive Health, adopted by the World Health Assembly in May 2004, noted: “As a preventable cause of maternal mortality and morbidity, unsafe abortion must be dealt with as part of the MDG on improving maternal health and other international development goals and targets.\" The WHO's Development and Research Training in Human Reproduction (HRP), whose research concerns people's sexual and reproductive health and lives, has an overall strategy to combat unsafe abortion that comprises four inter-related activities:\n\nThe UN has estimated in 2017 that repealing anti-abortion laws would save the lives of nearly 50,000 women a year. Unsafe abortions take place primarily in countries where abortion is illegal, but also occur in countries where it is legal, but women cannot access it because of various reasons (conscientious objectors among doctors, high prices, lack of knowledge that abortion is legal). Indeed, there are countries where the law is liberal, but in practice it is very difficult to have an abortion, due to most doctors being conscientious objectors. The fact that is some countries where abortion is legal it is \"de facto\" very difficult to have access to one is controversial; the UN in its 2017 resolution on \"Intensification of efforts to prevent and eliminate all forms of violence against women and girls: domestic violence\" urged states to guarantee access to \"safe abortion where such services are permitted by national law\". Safe and legal abortion services are often very difficult to access by women from rural areas or from lower socioeconomic backgrounds. In 2008, Human Rights Watch stated that \"In fact, even where abortion is permitted by law, women often have severely limited access to safe abortion services because of lack of proper regulation, health services, or political will\" and estimated that \"Approximately 13 percent of maternal deaths worldwide are attributable to unsafe abortion—between 68,000 and 78,000 deaths annually.\"\n\nThe Maputo Protocol, which was adopted by the African Union in the form of a protocol to the African Charter on Human and Peoples' Rights, states at Article 14 (Health and Reproductive Rights) that: \"(2). States Parties shall take all appropriate measures to: [...] c) protect the reproductive rights of women by authorising medical abortion in cases of sexual assault, rape, incest, and where the continued pregnancy endangers the mental and physical health of the mother or the life of the mother or the foetus.\" The Maputo Protocol is the first international treaty to recognize abortion, under certain conditions, as a woman's human right.\n\nThe \"General comment No. 36 (2018) on article 6 of the International Covenant on Civil and Political Rights, on the right to life\", adopted by the Human Rights Committee in 2018, defines, for the first time ever, a human right to abortion - in certain circumstances (however these UN general comments are considered soft law, and, as such, not legally binding).\n\n\"Although States parties may adopt measures designed to regulate voluntary terminations of pregnancy, such measures must not result in violation of the right to life of a pregnant woman or girl, or her other rights under the Covenant. Thus, restrictions on the ability of women or girls to seek abortion must not, inter alia, jeopardize their lives, subject them to physical or mental pain or suffering which violates article 7, discriminate against them or arbitrarily interfere with their privacy. \"States parties must provide safe, legal and effective access to abortion where the life and health of the pregnant woman or girl is at risk, and where carrying a pregnancy to term would cause the pregnant woman or girl substantial pain or suffering, most notably where the pregnancy is the result of rape or incest or is not viable.\" [8] In addition, States parties may not regulate pregnancy or abortion in all other cases in a manner that runs contrary to their duty to ensure that women and girls do not have to undertake unsafe abortions, and they should revise their abortion laws accordingly. [9] For example, they should not take measures such as criminalizing pregnancies by unmarried women or apply criminal sanctions against women and girls undergoing abortion [10] or against medical service providers assisting them in doing so, since taking such measures compel women and girls to resort to unsafe abortion. States parties should not introduce new barriers and should remove existing barriers [11] that deny effective access by women and girls to safe and legal abortion [12], including barriers caused as a result of the exercise of conscientious objection by individual medical providers. [13]\"\n\nWhen negotiating the Cairo Programme of Action at the 1994 International Conference on Population and Development (ICPD), the issue was so contentious that delegates eventually decided to omit any recommendation to legalize abortion, instead advising governments to provide proper post-abortion care and to invest in programs that will decrease the number of unwanted pregnancies.\n\nOn April 18, 2008 the Parliamentary Assembly of the Council of Europe, a group comprising members from 47 European countries, adopted a resolution calling for the decriminalization of abortion within reasonable gestational limits and guaranteed access to safe abortion procedures. The nonbinding resolution was passed on April 16 by a vote of 102 to 69.\n\nDuring and after the ICPD, some interested parties attempted to interpret the term ‘reproductive health’ in the sense that it implies abortion as a means of family planning or, indeed, a right to abortion. These interpretations, however, do not reflect the consensus reached at the Conference.\nFor the European Union, where legislation on abortion is certainly less restrictive than elsewhere, the Council Presidency has clearly stated that the Council’s commitment to promote ‘reproductive health’ did not include the promotion of abortion. Likewise, the European Commission, in response to a question from a Member of the European Parliament, clarified:\n\n\"“The term ‘reproductive health’ was defined by the United Nations (UN) in 1994 at the Cairo International Conference on Population and Development. All Member States of the Union endorsed the Programme of Action adopted at Cairo. The Union has never adopted an alternative definition of ‘reproductive health’ to that given in the Programme of Action, which makes no reference to abortion.”\"\n\nWith regard to the U.S., it should be noted that, only a few days prior to the Cairo Conference, the head of the U.S. delegation, Vice President Al Gore, had stated for the record:\n\n\"“Let us get a false issue off the table: the US does not seek to establish a new international right to abortion, and we do not believe that abortion should be encouraged as a method of family planning.”\"\n\nSome years later, the position of the U.S. Administration in this debate was reconfirmed by U.S. Ambassador to the UN, Ellen Sauerbrey, when she stated at a meeting of the UN Commission on the Status of Women that: \"“nongovernmental organizations are attempting to assert that Beijing in some way creates or contributes to the creation of an internationally recognized fundamental right to abortion”\". She added: \"“There is no fundamental right to abortion. And yet it keeps coming up largely driven by NGOs trying to hijack the term and trying to make it into a definition”\".\n\nCollaborative research from the Institute of Development Studies states that \"access to safe abortion is a matter of human rights, democracy and public health, and the denial of such access is a major cause of death and impairment, with significant costs to [international] development\". The research highlights the inequities of access to safe abortion both globally and nationally and emphasises the importance of global and national movements for reform to address this. The shift by campaigners of reproductive rights from an issue-based agenda (the right to abortion), to safe, legal abortion not only as a human right, but bound up with democratic and citizenship rights, has been an important way of reframing the abortion debate and reproductive justice agenda.\n\nMeanwhile, the European Court of Human Rights complicated the question even more through a landmark judgment (case of \"A. B. and C. v. Ireland\"), in which it is stated that the denial of abortion for health and/or well-being reasons is an interference with an individuals right to respect for private and family life under Article 8 of the European Convention on Human Rights, an interference which in some cases can be justified.\n\nA desire to achieve certain population targets has resulted throughout history in severely abusive practices, in cases where governments ignored human rights and enacted aggressive demographic policies. In the 20th century, several authoritarian governments have sought either to increase or to decrease the births rates, often through forceful intervention. One of the most notorious natalist policies is that which occurred in communist Romania in the period of 1967-1990 during communist leader Nicolae Ceaușescu, who adopted a very aggressive natalist policy which included outlawing abortion and contraception, routine pregnancy tests for women, taxes on childlessness, and legal discrimination against childless people. Ceaușescu's policy resulted in over 9,000 women who died due to illegal abortions, large numbers of children put into Romanian orphanages by parents who couldn't cope with raising them, street children in the 1990s (when many orphanages were closed and the children ended on the streets), and overcrowding in homes and schools. The irony of Ceaușescu's aggressive natalist policy was a generation that may not have been born would eventually lead the Romanian Revolution which would overthrow and have him executed.\n\nIn stark opposition with Ceaușescu's natalist policy was China's one child policy, in effect from 1978 to 2015, which included abuses such as forced abortions. This policy has also been deemed responsible for the common practice of sex selective abortion which led to an imbalanced sex ratio in the country.\n\nFrom the 1970s to 1980s, tension grew between women's health activists who advance women's reproductive rights as part of a human rights-based approach on the one hand, and population control advocates on the other. At the 1984 UN World Population Conference in Mexico City population control policies came under attack from women's health advocates who argued that the policies' narrow focus led to coercion and decreased quality of care, and that these policies ignored the varied social and cultural contexts in which family planning was provided in developing countries. In the 1980s the HIV/AIDS epidemic forced a broader discussion of sex into the public discourse in many countries, leading to more emphasis on reproductive health issues beyond reducing fertility. The growing opposition to the narrow population control focus led to a significant departure in the early 1990s from past population control policies. In the United States, abortion opponents have begun to foment conspiracy theories about reproductive rights advocates, accusing them of advancing a racist agenda of eugenics, and of trying to reduce the African American birth rate in the U.S.\n\nFemale genital mutilation (FGM) is defined as \"all procedures that involve partial or total removal of the external female genitalia, or other injury to the female genital organs for non-medical reasons.\" The procedure has no health benefits, and can cause severe bleeding and problems urinating, cysts, infections, and complications in childbirth and increased risk of newborn deaths. It is performed for traditional, cultural or religious reasons in many parts of the world, especially in Africa. The Istanbul Convention prohibits FGM (Article 38).\n\nBride kidnapping or marriage by abduction, is the practice whereby a woman or girl is abducted for the purpose of a forced marriage. Bride kidnapping has been practiced historically in many parts of the world, and it continues to occur today in some places, especially in Central Asia and the Caucasus, in countries such as Kyrgyzstan, Tajikistan, Kazakhstan, Turkmenistan, Uzbekistan and Armenia, as well as in Ethiopia. Bride kidnapping is often preceded or followed by rape (which may result in pregnancy), in order to force the marriage - a practice also supported by \"marry-your-rapist law\" (laws regarding sexual violence, abduction or similar acts, whereby the perpetrator avoids prosecution or punishment if he marries the victim). Abducting of women may happen on an individual scale or on a mass scale. Raptio is a Latin term referring to the large-scale abduction of women, usually for marriage or sexual slavery, particularity during wartime.\n\nBride price, also called bridewealth, is money, property, or other form of wealth paid by a groom or his family to the parents of the woman he marries. The practice of bride price sometimes leads to parents selling young daughters into marriage and to trafficking.Bride price is common across Africa. Such forced marriages often lead to sexual violence, and forced pregnancy. In northern Ghana, for example, the payment of bride price signifies a woman's requirement to bear children, and women using birth control are at risks of threats and coercion.\n\nThe 1956 Supplementary Convention on the Abolition of Slavery, the Slave Trade, and Institutions and Practices Similar to Slavery defines \"institutions and practices similar to slavery\" to include:\n\nc) Any institution or practice whereby:\n\nLaws in many countries and states require sperm donors to be either anonymous or known to the recipient, or the laws restrict the number of children each donor may father. Although many donors choose to remain anonymous, new technologies such as the Internet and DNA technology have opened up new avenues for those wishing to know more about the biological father, siblings and half-siblings.\n\nEthnic minority women have often been victims of forced sterilization programs, such as Amerindian women in parts of Latin America of Roma women.\n\nIn Peru, President Alberto Fujimori (in office from 1990 to 2000) has been accused of genocide and crimes against humanity as a result of the \"Programa Nacional de Población\", a sterilization program put in place by his administration. During his presidency, Fujimori put in place a program of forced sterilizations against indigenous people (mainly the Quechuas and the Aymaras), in the name of a \"public health plan\", presented on July 28, 1995. \n\nDuring the 20th century, forced sterilization of Roma women in European countries, especially in former Communist countries, was practiced, and there are allegations that these practices continue unofficially in some countries, such as Czech Republic, Bulgaria, Hungary and Romania. In V. C. vs. Slovakia, the European Court for Human Rights ruled in favor of a Roma woman who was the victim of forced sterilization in a state hospital in Slovakia in 2000.\n\nForced sterilization in the United States was practiced starting with the 19th century. The United States during the Progressive era, ca. 1890 to 1920, was the first country to concertedly undertake compulsory sterilization programs for the purpose of eugenics. Thomas C. Leonard, professor at Princeton University, describes American eugenics and sterilization as ultimately rooted in economic arguments and further as a central element of Progressivism alongside wage controls, restricted immigration, and the introduction of pension programs. The heads of the programs were avid proponents of eugenics and frequently argued for their programs which achieved some success nationwide mainly in the first half of the 20th Century.\n\nCompulsory sterilization has been practiced historically in parts of Canada. Two Canadian provinces (Alberta and British Columbia) performed compulsory sterilization programs in the 20th century with eugenic aims. Canadian compulsory sterilization operated via the same overall mechanisms of institutionalization, judgment, and surgery as the American system. However, one notable difference is in the treatment of non-insane criminals. Canadian legislation never allowed for punitive sterilization of inmates.\n\nThe Sexual Sterilization Act of Alberta was enacted in 1928 and repealed in 1972. In 1995, Leilani Muir sued the Province of Alberta for forcing her to be sterilized against her will and without her permission in 1959. Since Muir’s case, the Alberta government has apologized for the forced sterilization of over 2,800 people. Nearly 850 Albertans who were sterilized under the Sexual Sterilization Act were awarded C$142 million in damages.\n\nThe Catholic Church is opposed to artificial contraception, abortion, and sexual intercourse outside marriage. This belief dates back to the first centuries of Christianity. While Roman Catholicism is not the only religion with such views, its religious doctrine is very powerful in influencing countries where most of the population is Catholic, and the few countries of the world with complete bans on abortion are Catholic-majority countries, and in Europe strict restrictions on abortion exist in the Catholic majority countries of Malta (complete ban), Ireland, Andorra, San Marino, Liechtenstein and to a lesser extent Poland and Monaco.\n\nSome of the countries of Central America, notably El Salvador, have also come to international attention due to very forceful enforcement of the anti-abortion laws. El Salvador has received repeated criticism from the UN. The Office of the UN High Commissioner for Human Rights (OHCHR) named the law \"one of the most draconian abortion laws in the world\", and urged liberalization, and Zeid bin Ra'ad, the United Nations High Commissioner for Human Rights, stated that he was \"appalled that as a result of El Salvador’s absolute prohibition on abortion, women are being punished for apparent miscarriages and other obstetric emergencies, accused and convicted of having induced termination of pregnancy\".\n\nCriticism surrounds certain forms of anti-abortion activism. Anti-abortion violence is a serious issue in some parts of the world, especially in North America. It is recognized as single-issue terrorism. Numerous organizations have also recognized anti-abortion extremism as a form of Christian terrorism.\n\nIncidents include vandalism, arson, and bombings of abortion clinics, such as those committed by Eric Rudolph (199698), and murders or attempted murders of physicians and clinic staff, as committed by James Kopp (1998), Paul Jennings Hill (1994), Scott Roeder (2009), Michael F. Griffin (1993), and Peter James Knight (2001).\nSince 1978, in the US, anti-abortion violence includes at least 11 murders of medical staff, 26 attempted murders, 42 bombings, and 187 arsons.\n\nSome opponents of legalized abortion view the term \"reproductive rights\" as a euphemism to sway emotions in favor of abortion. National Right to Life has referred to \"reproductive rights\" as a \"fudge term\" and \"the code word for \"abortion\" rights.\"\n\n\n\n"}
{"id": "24410331", "url": "https://en.wikipedia.org/wiki?curid=24410331", "title": "Self-perceived quality-of-life scale", "text": "Self-perceived quality-of-life scale\n\nThe self-perceived quality-of-life scale is a psychological assessment instrument which is based on a comprehensive theory of the self-perceived quality of life (SPQL) and provides a multi-faceted measurement of health-related and non-health-related aspects of well-being. The scale has become an instrument of choice for monitoring quality of life in some clinical populations, for example, it was adopted by the Positively Sound network for women living with HIV.\n\nThe improvement of mental disorders may have an effect on multiple domains of an individual's life which could be captured only through a comprehensive measurement. For example, the treatment of a phobia may reduce fear (mental health index), which could lead to the improvement of social relations (social relations index) and, in turn, performance at work, resulting in an increase in salary (financial index). Hence, in order to detect all implications of a treatment (e.g., for a phobia), a comprehensive measurement across multiple domains of an individual's life is needed. The SPQL scale can provide such a comprehensive measurement.\n\nThe scale is designed in an electronic format. The software calculates scores automatically; this allows for advanced quantification methods. The automatic calculations and quantification methods allowed undertaking a comprehensive approach for assessing SPQL from multiple facets. A multi-facet approach, in turn, provided a comprehensive evaluation of the effectiveness of mental health interventions (through pre- and post tests).\n\nThe scale emerged from synthesis of existing theories including: (a) subjective well-being, (b) developmental life-stages, (c) different categories of human needs, (d) quality of life, and (e) subjective evaluation processes. The scale consists of three axes: Subjective well-being, positive and negative affect, and fulfillment of needs. See a model diagram below.\n\nThe scale can (a) identify possible side effects of psychiatric or psychological interventions which could occur in multiple domains of an individual’s life, (b) detect the occurrence of relapses, (c) assist in evaluating the progress of recovery, (d) measure the effects of various non-normative positive and negative events (e.g., divorce, promotion at work, becoming a parent) on an individual’s life as a whole and trace the course of their development, (e) evaluate an individual’s SPQL throughout the lifespan, (f) predict depression, anxiety, and mood, and (g) assess the effectiveness of interventions intended to enhance well-being and improve quality of life on an individual level.\n\nThis scale could be used by individual mental health professionals to evaluate the progress of treatment. This is useful for clients as well because they themselves are able to compare their initial scores with scores after intervention. Because the scale is available online, clients are able to complete the questionnaire outside of the therapy sessions. The scale also could be used in medical settings to assess how medical treatment affects a patient’s life overall and in specific aspects over time, as well as allow detecting psychological side effects. The scale could be of use to insurers because it would help in evaluating the effectiveness of mental health interventions.\n\nIt is safe to postulate that all people want to have a good life. Although the meaning of “a good life” may vary from culture to culture and from individual to individual, this meaning revolves around the same aspects of life across cultures. What actually varies between cultures and individuals is the availability of certain aspects of a good life, the subjective significance people assign to these aspects, and the way people evaluate these aspects of a good life.\n\nEverything we do or do not do, wish or do not wish, and have or do not have has an explicit or an implicit relevance to how good or not good we perceive our lives to be. Because the preference for a good life over a bad life underlies all facets of our lives, understanding what constitutes and influences a good life on an individual level has a significant value for all people.\n\nDuring the past several decades researchers investigated the concept of “the good life” based on three theoretical approaches:\n\nThe comprehensive scale of the good life, the Self-Perceived Quality of Life (SPQL) scale, overcame the limitations of prior approaches by integrating measurements of SWB, QOL, and functionality on an individual level, and by utilizing innovative quantification methods. The scale focused on how individuals evaluate their lives and compare these measurements with the average good life of others. The SPQL scale includes well-being, emotions, and physical and mental health indices. The SPQL scale has implications for evaluating the effectiveness of a wide range of interventions intended to improve mental health and well-being.\n\nThe SPQL construct consists of three axes, each compounded from several variables:\n\nBecause fluctuations within SPQL are likely to occur over time, a single-occasion measurement will not provide a comprehensive assessment. In order to capture a more comprehensive picture of SPQL, the SWB variable (axis) was measured retrospectively throughout three major life stages of adult human development: Early-adulthood, mid-adulthood, and late-adulthood (see SPQL model diagram).\n\nAs people approach a life stage in their development, they face developmental tasks that they need to master in order for the transition to the next life stage to be successful. The cycle of transition from one life stage to another is marked by three phases:\nTo a lesser degree, cycles of transitions occur continually within major life stages on annual and even on daily bases.\n\nA curve of SWB throughout the lifespan can reflect the experience of an individual's good life. Ideally, all three SPQL axes should be evaluated for each life stage. However, this would make a questionnaire too long. Although the SPQL scale measures only one SPQL axis (SWB) for each life stage, the developed theoretical framework discusses the evaluation of all three SPQL axes throughout the major life stages. Thus, the framework can support the development of a next version of the scale that would accomplish this goal. Future research could explore possibilities for reducing the number of the evaluated scale items and include questions that will evaluate all three SPQL axes throughout the major life stages.\n\nParticipants' responses on the inventories for each of the three SPQL axes (see Appendixes) provided the data for the psychometric validation of the scale and for the quantitative analyses that allowed measuring the good life. The theoretical framework for the first two axes was based on the existing theories of SWB, positive affect and negative affect, and mood. The theoretical framework for the third axis was based on theories that conceptually differentiate between different categories of needs. Different categories of needs, in turn, are sorted into four general categories of needs composing the third axis. The measurement of an individual’s level of functionality across social, psychological, and health factors was integrated in the third axis. This integration was accomplished through evaluating the strength and fulfillment of an individual’s needs for optimal functioning across these factors.\n\nThe subjective well-being (SWB) baseline is maintained by psychological and biological homeostasis. Measurement of overall happiness determined the SWB baseline. A higher SWB baseline indicates a higher SPQL. People who have experienced more positive and less negative intense experiences during their lives (i.e., transient deviations), have a higher SPQL. Intense experiences were assessed through measuring the frequency and intensity of nonnormative transient subjective experiences of happiness/unhappiness that deviate from the SWB baseline throughout time.\n\nPeople who have experienced more positive and less negative subjective affective experiences (SAE) during their lives (i.e., transient deviations), have a higher SPQL. The average of positive and negative SAE was used to measure overall SAE.\n\nIndividuals with the same score on SWB can differ in their evaluations of standards of living even if their objective life circumstances are alike. Accordingly, their self-perceived QOL may vary. Hence, in order to capture a more accurate measurement of SPQL, the strength and degree of fulfillment of a wide range of human needs and preferences for life circumstances was evaluated. However, felt needs are not the only kind of needs that a person may have. If a need is satisfied it may not be felt as intensely as an unsatisfied need of lesser importance in terms of overall happiness. Thus, the strength with which a need is felt at a certain point in time does not necessarily indicate that it makes a greater contribution to the overall SPQL than other needs, which are felt less intensely or unfelt at all at that point in time because they are satisfied. Hence, the strength of individual preferences and needs was evaluated not only through questions such as “how important is fulfillment of this need to your overall happiness?” but also with questions such as “if this need were unfulfilled, how would it affect your overall happiness?”\n\nConceptual model for axis III fulfillment of needs. In order to measure fulfillment of needs, a broad range of human needs was sorted into four conceptually distinct categories that are (a) contingent on corresponding stages of cognitive and moral development, (b) constitute major components of self-concept, and (c) correspond to the neural activity in different clusters of anatomical brain regions. Because sometimes the same anatomical brain regions are involved in different ways in neural activity associated with the four categories of needs, implicated brain regions will be distinguished based on their dominance in related processes, and based on the chronological maturation of the dominant regions.\n\n\nBecause according to the SPQL theory an individual's motivations ensue from the idiosyncratic cluster of the four categories of needs, these four categories are proposed to compound an individual’s motivational framework (MF). In the following discussion, disparate preferences and needs will be referred to as motivational units (MU). Motivational units have two dimensions, importance of MU to the SPQL (strength) and the degree of fulfillment. The strength of a motivational unit (MU) was determined by evaluating the capacity for the fulfillment or unfulfillment of the MU to skew the SWB baseline.\n"}
{"id": "38526066", "url": "https://en.wikipedia.org/wiki?curid=38526066", "title": "Systems medicine", "text": "Systems medicine\n\nSystems medicine is an interdisciplinary field of study that looks at the systems of the human body as part of an integrated whole, incorporating biochemical, physiological, and environment interactions. Systems medicine draws on systems science and systems biology, and considers complex interactions within the human body in light of a patient's genomics, behavior and environment.\n\nThe earliest uses of the term \"systems medicine\" appeared in 1992, in an article on systems medicine and pharmacology by B.J. Zeng and in a paper on systems biomedicine by T. Kamada.\n\nAn important topic in systems medicine and systems biomedicine is the development of computational models that describe disease progression and the effect of therapeutic interventions. \n\nMore recent approaches include the redefinition of disease phenotypes based on common mechanisms rather than symptoms. These provide then therapeutic targets including network pharmacology and drug repurposing. Since 2018, there is a dedicated scientific journal, Systems Medicine, published by Marie-Ann Liebert and with Jan Baumbach and Harald Schmidt as co-editors in chief. \n"}
{"id": "1551797", "url": "https://en.wikipedia.org/wiki?curid=1551797", "title": "Texas Medication Algorithm Project", "text": "Texas Medication Algorithm Project\n\nThe Texas Medication Algorithm Project (TMAP) is a controversial decision-tree medical algorithm, the design of which was based on the expert opinions of mental health specialists. It has provided and rolled out a set of psychiatric management guidelines for doctors treating certain mental disorders within Texas' publicly funded mental health care system, along with manuals relating to each of them. The algorithms commence after diagnosis and cover pharmacological treatment (hence \"Medication Algorithm\").\n\nTMAP was initiated in the fall of 1997 and the initial research covered around 500 patients.\n\nTMAP arose from a collaboration that began in 1995 between the Texas Department of Mental Health and Mental Retardation (TDMHMR), pharmaceutical companies, and the University of Texas Southwestern. The research was supported by the National Institute of Mental Health, the Robert Wood Johnson Foundation, the Meadows Foundation, the Lightner-Sams Foundation, the Nanny Hogan Boyd Charitable Trust, TDMHMR, the Center for Mental Health Services, the Department of Veterans Affairs, the Health Services Research and Development Research Career Scientist Award, the United States Pharmacopoeia Convention Inc. and Mental Health Connections.\n\nNumerous companies that invent and develop antipsychotic medications provided use of their medications and furnished funding for the project. Companies did not participate in the production of the guidelines. \n\nIn 2004 TMAP was mentioned as an example of a successful project in a paper regarding implementing mental health screening programs throughout the United States, by the President George W. Bush's New Freedom Commission on Mental Health, which looks to expand the program federally. The President had previously been Governor of Texas, in the period when TMAP was implemented. Similar programs have been implemented in about a dozen States, according to a 2004 report in the \"British Medical Journal\".\n\nSimilar algorithms with similar prescribing advice have been produced elsewhere, for instance at the Maudsley Hospital, London.\n\n"}
{"id": "889672", "url": "https://en.wikipedia.org/wiki?curid=889672", "title": "Tropical disease", "text": "Tropical disease\n\nTropical diseases are diseases that are prevalent in or unique to tropical and subtropical regions. The diseases are less prevalent in temperate climates, due in part to the occurrence of a cold season, which controls the insect population by forcing hibernation. However, many were present in northern Europe and northern America in the 17th and 18th centuries before modern understanding of disease causation. The initial impetus for tropical medicine was to protect the health of colonialists, notably in India under the British Raj. Insects such as mosquitoes and flies are by far the most common disease carrier, or vector. These insects may carry a parasite, bacterium or virus that is infectious to humans and animals. Most often disease is transmitted by an insect \"bite\", which causes transmission of the infectious agent through subcutaneous blood exchange. Vaccines are not available for most of the diseases listed here, and many do not have cures.\n\nHuman exploration of tropical rainforests, deforestation, rising immigration and increased international air travel and other tourism to tropical regions has led to an increased incidence of such diseases.\n\nIn 1975 the Special Programme for Research and Training in Tropical Diseases (TDR) was established to focus on neglected infectious diseases which disproportionately affect poor and marginalized populations in developing regions of Africa, Asia, Central America and South America. It was established at the World Health Organization, which is the executing agency, and is co-sponsored by the United Nations Children's Fund, United Nations Development Programme, the World Bank and the World Health Organization.\n\nTDR's vision is to foster an effective global research effort on infectious diseases of poverty in which disease endemic countries play a pivotal role. It has a dual mission of developing new tools and strategies against these diseases, and to develop the research and leadership capacity in the countries where the diseases occur. The TDR secretariat is based in Geneva, Switzerland, but the work is conducted throughout the world through many partners and funded grants.\n\nSome examples of work include helping to develop new treatments for diseases, such as ivermectin for onchocerciasis (river blindness); showing how packaging can improve use of artemesinin-combination treatment (ACT) for malaria; demonstrating the effectiveness of bednets to prevent mosquito bites and malaria; and documenting how community-based and community-led programmes increases distribution of multiple treatments. TDR history\n\nThe current TDR disease portfolio includes the following entries:\n\n\nAdditional neglected tropical diseases include:\n\nSome tropical diseases are very rare, but may occur in sudden epidemics, such as the Ebola hemorrhagic fever, Lassa fever and the Marburg virus. There are hundreds of different tropical diseases which are less known or rarer, but that, nonetheless, have importance for public health.\n\nThe so-called \"exotic\" diseases in the tropics have long been noted both by travelers, explorers, etc., as well as by physicians. One obvious reason is that the hot climate present during all the year and the larger volume of rains directly affect the formation of breeding grounds, the larger number and variety of natural reservoirs and animal diseases that can be transmitted to humans (zoonosis), the largest number of possible insect vectors of diseases. It is possible also that higher temperatures may favor the replication of pathogenic agents both inside and outside biological organisms. Socio-economic factors may be also in operation, since most of the poorest nations of the world are in the tropics. Tropical countries like Brazil, which have improved their socio-economic situation and invested in hygiene, public health and the combat of transmissible diseases have achieved dramatic results in relation to the elimination or decrease of many endemic tropical diseases in their territory.\n\nClimate change, global warming caused by the greenhouse effect, and the resulting increase in global temperatures, are possibly causing tropical diseases and vectors to spread to higher altitudes in mountainous regions, and to higher latitudes that were previously spared, such as the Southern United States, the Mediterranean area, etc. For example, in the Monteverde cloud forest of Costa Rica, global warming enabled Chytridiomycosis, a tropical disease, to flourish and thus force into decline amphibian populations of the Monteverde Harlequin frog. Here, global warming raised the heights of orographic cloud formation, and thus produced cloud cover that would facilitate optimum growth conditions for the implicated pathogen, B. dendrobatidis.\n\nSome of the strategies for controlling tropical diseases include: \n\n\n\n\n"}
{"id": "56295168", "url": "https://en.wikipedia.org/wiki?curid=56295168", "title": "Urethrovaginal fistula", "text": "Urethrovaginal fistula\n\nA urethrovaginal fistula is an abnormal passageway between the urethra and the vagina. It results in urinary incontinence as urine continually leaves the vagina. It can occur as an obstetrical complication, catheter insertion injury or a surgical injury.\n"}
{"id": "22836947", "url": "https://en.wikipedia.org/wiki?curid=22836947", "title": "Wellbeing of Women", "text": "Wellbeing of Women\n\nWellbeing of Women is a charity dedicated to improving the health of women and babies. It raises money to invest in medical research and the development of specialist doctors and nurses working in the field of reproductive health. Every year the charity invests in research projects and allocates funds towards the training of doctors and midwives. The charity also disseminates information on women's reproductive health.\n\nThe charity is based in London, and consists of: a team of staff and volunteers; a board of trustees headed up by Sir Victor Blank; and a Research Advisory Committee.\n\nThe charity was established in 1964 by eminent obstetrician Professor Will Nixon, who was touched by the grief of a young man whose wife died during childbirth. It was originally called The Childbirth Research Centre. He gathered a group of illustrious founder members including Lord Brain, a neurologist who cared for Winston Churchill on his deathbed in 1965; Sir John Peel, the surgeon-gynaecologist to the Queen; Professor Dugald Baird and Sir George Pinker, an obstetrician who delivered nine royal babies including Princes William and Harry. The founders’ aim was to reduce the number of women and babies who died during pregnancy and childbirth.\n\nAn early donation established that a deficiency in folic acid was a factor in malformed babies. Pregnant women across the world now take folic acid supplements.\n\nThe charity also funded crucial research into epidurals which means that millions of women now benefit from a relatively pain-free birth.\n\nIn 1972 the charity was renamed Birthright.\n\nResearch projects they funded created the ground rules that mean many thousands of women have safe laser treatment to treat cervical cancer. They also enabled breakthroughs into monitoring babies in the womb. One early pieces of research into the diagnosis of Down’s Syndrome in pregnant women helped make the amniocentesis test more accurate. The charity also discovered a link between smoking and pre-eclampsia and babies being born underweight.\n\nHRH Diana, Prince of Wales, became the patron of Birthright in 1984.\n\nShe was devoted to the charity, explaining: \"To long for a baby and not to be able to have one must be devastating. I don't know how I would cope with that. And if my work for Birthright can alleviate that suffering for just one couple, it will have been all worthwhile.\"\n\nDuring her time as patron, the charity funded work into IVF and also investigated HPV, the virus that causes cervical cancer leading to the cervical cancer screening programme. The charity’s research into recurrent miscarriage also meant that, out of a research group of 2000 women who had been told they would never have children, 79% went on to have babies. Professor Stuart Campbell of King’s College, London, received funding from the charity for a project that developed an ultrasound that would identify babies at risk of stillbirth by finding out if they had abnormal blood flow.\n\nDuring the 1990s, the charity funded research which discovered that ultrasound could be used to detect abnormalities in early pregnancy. This resulted in pre-natal screening for Down's Syndrome. The charity enabled breakthroughs in IVF, by funding research into the optimum time for embryo transfer, and by looking at how eggs mature in the ovary. This was described at the time as ‘the biggest advance in fertility treatment’. They also funded research into gynaecological cancers; contraception; and the bone density of post-menopausal women.\n\nThe charity was renamed ‘Wellbeing of Women’, in 2004.\n\nWellbeing of Women partnered with 100 Women in Hedge Funds to fund a project which advanced our understanding of the genetics of Cerebral Palsy. The charity also funded research that helped reverse brain damage in newborn babies and a project that helped women suffering from recurrent miscarriage go on to have a successful pregnancy, by identifying ‘Natural Killer cells’ in the mother’s immune system.\n\nIn 2007, then British Prime Minister's wife Sarah Brown became patron of Wellbeing of Women.\n\nIn 2008, Wellbeing of Women was announced as one of the beneficiary charities of the Lord Mayor’s Appeal, along with ORBIS. Prince William was Patron of the appeal. Funds raised from the appeal enabled Wellbeing of Women to establish the Baby Bio Bank, a unique international resource storing genetic data from ‘family trios’ of mother, father and baby. This bank of genetic information will facilitate on-going research into the persistent complications of pregnancy and birth, including miscarriage, premature birth and pre-eclampsia.\n\nIn March 2013, Wellbeing of Women launched a major new partnership with PwC. PwC are long term sponsors of two of Wellbeing of Women's flagship events - the Annual Women's Lunch Debate and Annual Celebrity Cricket Match – but in 2013 broadened and increased their support of the charity, by supporting two Wellbeing of Women funded researchers.\n\nWellbeing of Women has an ongoing partnership with BHS. Karren Brady designed a collection of workwear dresses to be sold at BHS in aid of the charity in 2012, and in 2013, Emma Forbes launched another collection of dresses to be sold in aid of the charity.\n\nIn December 2011, in the run-up to the 2012 Summer Olympics in Stratford, London, Clara Maidment shot a charity calendar in aid of Wellbeing of Women. Twelve British female sporting celebrities who posed in the lingerie of Nichole de Carle, wearing jewellery by Salima Hughes and Coster Diamonds.\n\nWellbeing of Women runs a series of Literary Lunches at Fortnum & Mason, which feature a prominent author in conversation with Eve Pollard OBE or Baroness Jenkin of Kennington. Previous authors have included PD James, Barbara Taylor Bradford, Penny Vincenzi, Julian Fellowes and Ffion Hague.\n\nThey also run a series called 'An Audience with...' at Fortnum and Mason.\n\nWellbeing of Women is the beneficiary charity of the Inspirational Women of the Year Awards, which are run in association with the Daily Mail, and in 2012 were sponsored by Sanctuary Spa.\n\nOn 12 October 2011, the Right Reverened Vincent Nichols gave the first annual Sir George Pinker Memorial Address.\n\n"}
