{"id": "53238020", "url": "https://en.wikipedia.org/wiki?curid=53238020", "title": "Abstract Meaning Representation", "text": "Abstract Meaning Representation\n\nAbstract Meaning Representation (AMR) is a semantic representation language. AMR graphs are rooted, labeled, directed, acyclic graphs (DAGs), comprising whole sentences. They are intended to abstract away from syntactic representations, in the sense that sentences which are similar in meaning should be assigned the same AMR, even if they are not identically worded. By nature, the AMR language is biased towards English – it is not meant to function as an international auxiliary language.\n"}
{"id": "27700571", "url": "https://en.wikipedia.org/wiki?curid=27700571", "title": "Abstraction (linguistics)", "text": "Abstraction (linguistics)\n\nThe term abstraction has a number of uses in the field of linguistics. It can denote a process (also called object abstraction) in the development of language, whereby terms become used for concepts further removed from the objects to which they were originally attached. It can also denote a process applied by linguists themselves, whereby phenomena are considered without the details that are not relevant to the desired level of analysis.\n\nObject abstraction, or simply \"abstraction\", is a concept wherein terms for objects become used for more abstract concepts, which in some languages develop into further abstractions such as verbs and grammatical words (grammaticalisation). \nAbstraction is common in human language, though it manifests in different ways for different languages. In language acquisition, children typically learn object words first, and then develop from that vocabulary an understanding of the alternate uses of such words.\n\nFor example, the word \"book\" refers objectively to a physical object constructed with bound pages, but in abstraction refers to a particular literary creation —regardless of how many physical copies of the \"book\" there are, it is one \"book.\" The word \"book\" then developed more abstract uses, such as in keeping a record (bookkeeping), or to keep a record of betting (booking), or as a verb for entering persons into a record (\"to book\"). Words may then be further abstracted and even have embedded puns, such as in 'to make history of oneself' (\"he booked\").\n\nAn early example of this kind of study came from John Horne Tooke, who in his conversational \"The Diversions of Purley\" (1786), proposed that the abstract word through came to English through both sound change and derivation from the Gothic:\nTooke was incorrect about \"through,\" but his insights about the way words migrated via geography, language, sound change, and meaning were innovative, and fundamentally correct.\n\nThe relation among syntax, semantics, and pragmatics has also been cashed out in terms of what could be called an \"abstraction hierarchy.\" For instance, Rudolf Carnap in his \"Introduction to Semantics\" (1942, Harvard University Press) writes:\n\nIf… explicit reference is made to the speaker, or, to put it in more general terms, to the user of a language, then we assign it to the field of pragmatics. (Whether in this case reference to designata is made or not makes no difference for this classification.) If we abstract from the user of the language and analyze only the expressions and their designata, we are in the field of semantics. And if, finally, we abstract from the designata also and analyze only the relations between the expressions, we are in (logical) syntax. The whole science of language, consisting of the three parts mentioned, is called semiotic. (p. 9)\n\nA related statement was made a few years earlier by Carnap's fellow American philosopher Charles W. Morris, PhD student of the sociologist and pragmatist philosopher George Herbert Mead, and heavily influenced by the pragmatist and founder of (analytical) semiotics, Charles Sanders Peirce: \n\"Syntactics, as the study of the syntactical relations of signs to one another in abstraction from the relations of signs to objects [i.e., semantics] or to interpreters [i.e., pragmatics], is the best developed of all the branches of semiotic.\" (p. 13)\nThe relation between abstraction and Morris' influential trichotomy is a matter of ongoing discussion.\n\nA kind of abstraction commonly considered in linguistics is the \"phoneme\", which abstracts speech sounds in such a way as to neglect details that cannot serve to differentiate meaning. Other analogous kinds of abstractions (sometimes called \"emic units\") include morphemes, graphemes and lexemes.\n"}
{"id": "569", "url": "https://en.wikipedia.org/wiki?curid=569", "title": "Anthropology", "text": "Anthropology\n\nAnthropology is the study of humans and human behavior and societies in the past and present. Social anthropology and cultural anthropology study the norms and values of societies. Linguistic anthropology studies how language affects social life. Biological or physical anthropology studies the biological development of humans.\n\nArchaeology, which studies past human cultures through investigation of physical evidence, is thought of as a branch of anthropology in the United States and Canada, while in Europe, it is viewed as a discipline in its own right or grouped under other related disciplines, such as history.\n\nThe abstract noun \"anthropology\" is first attested in reference to history. Its present use first appeared in Renaissance Germany in the works of Magnus Hundt and Otto Casmann. Their New Latin ' derived from the combining forms of the Greek words \"ánthrōpos\" (, \"human\") and \"lógos\" (, \"study\"). (Its adjectival form appeared in the works of Aristotle.) It began to be used in English, possibly via French ', by the early 18th century.\n\nIn 1647, the Bartholins, founders of the University of Copenhagen, defined \" as follows:\n\nAnthropology, that is to say the science that treats of man, is divided ordinarily and with reason into Anatomy, which considers the body and the parts, and Psychology, which speaks of the soul.\n\nSporadic use of the term for some of the subject matter occurred subsequently, such as the use by Étienne Serres in 1839 to describe the natural history, or paleontology, of man, based on comparative anatomy, and the creation of a chair in anthropology and ethnography in 1850 at the National Museum of Natural History (France) by Jean Louis Armand de Quatrefages de Bréau. Various short-lived organizations of anthropologists had already been formed. The Société Ethnologique de Paris, the first to use Ethnology, was formed in 1839. Its members were primarily anti-slavery activists. When slavery was abolished in France in 1848 the Société was abandoned.\n\nMeanwhile, the Ethnological Society of New York, currently the American Ethnological Society, was founded on its model in 1842, as well as the Ethnological Society of London in 1843, a break-away group of the Aborigines' Protection Society. These anthropologists of the times were liberal, anti-slavery, and pro-human-rights activists. They maintained international connections.\n\nAnthropology and many other current fields are the intellectual results of the comparative methods developed in the earlier 19th century. Theorists in such diverse fields as anatomy, linguistics, and Ethnology, making feature-by-feature comparisons of their subject matters, were beginning to suspect that similarities between animals, languages, and folkways were the result of processes or laws unknown to them then. For them, the publication of Charles Darwin's \"On the Origin of Species\" was the epiphany of everything they had begun to suspect. Darwin himself arrived at his conclusions through comparison of species he had seen in agronomy and in the wild.\n\nDarwin and Wallace unveiled evolution in the late 1850s. There was an immediate rush to bring it into the social sciences. Paul Broca in Paris was in the process of breaking away from the Société de biologie to form the first of the explicitly anthropological societies, the Société d'Anthropologie de Paris, meeting for the first time in Paris in 1859. When he read Darwin, he became an immediate convert to \"Transformisme\", as the French called evolutionism. His definition now became \"the study of the human group, considered as a whole, in its details, and in relation to the rest of nature\".\n\nBroca, being what today would be called a neurosurgeon, had taken an interest in the pathology of speech. He wanted to localize the difference between man and the other animals, which appeared to reside in speech. He discovered the speech center of the human brain, today called Broca's area after him. His interest was mainly in Biological anthropology, but a German philosopher specializing in psychology, Theodor Waitz, took up the theme of general and social anthropology in his six-volume work, entitled \"Die Anthropologie der Naturvölker\", 1859–1864. The title was soon translated as \"The Anthropology of Primitive Peoples\". The last two volumes were published posthumously.\n\nWaitz defined anthropology as \"the science of the nature of man\". By nature he meant matter animated by \"the Divine breath\"; i.e., he was an animist. Following Broca's lead, Waitz points out that anthropology is a new field, which would gather material from other fields, but would differ from them in the use of comparative anatomy, physiology, and psychology to differentiate man from \"the animals nearest to him\". He stresses that the data of comparison must be empirical, gathered by experimentation. The history of civilization, as well as ethnology, are to be brought into the comparison. It is to be presumed fundamentally that the species, man, is a unity, and that \"the same laws of thought are applicable to all men\".\n\nWaitz was influential among the British ethnologists. In 1863 the explorer Richard Francis Burton and the speech therapist James Hunt broke away from the Ethnological Society of London to form the Anthropological Society of London, which henceforward would follow the path of the new anthropology rather than just ethnology. It was the 2nd society dedicated to general anthropology in existence. Representatives from the French \"Société\" were present, though not Broca. In his keynote address, printed in the first volume of its new publication, \"The Anthropological Review\", Hunt stressed the work of Waitz, adopting his definitions as a standard. Among the first associates were the young Edward Burnett Tylor, inventor of cultural anthropology, and his brother Alfred Tylor, a geologist. Previously Edward had referred to himself as an ethnologist; subsequently, an anthropologist.\n\nSimilar organizations in other countries followed: The Anthropological Society of Madrid (1865), the American Anthropological Association in 1902, the Anthropological Society of Vienna (1870), the Italian Society of Anthropology and Ethnology (1871), and many others subsequently. The majority of these were evolutionist. One notable exception was the Berlin Society for Anthropology, Ethnology, and Prehistory (1869) founded by Rudolph Virchow, known for his vituperative attacks on the evolutionists. Not religious himself, he insisted that Darwin's conclusions lacked empirical foundation.\n\nDuring the last three decades of the 19th century, a proliferation of anthropological societies and associations occurred, most independent, most publishing their own journals, and all international in membership and association. The major theorists belonged to these organizations. They supported the gradual osmosis of anthropology curricula into the major institutions of higher learning. By 1898 the American Association for the Advancement of Science was able to report that 48 educational institutions in 13 countries had some curriculum in anthropology. None of the 75 faculty members were under a department named anthropology.\n\nThis meager statistic expanded in the 20th century to comprise anthropology departments in the majority of the world's higher educational institutions, many thousands in number. Anthropology has diversified from a few major subdivisions to dozens more. Practical Anthropology, the use of anthropological knowledge and technique to solve specific problems, has arrived; for example, the presence of buried victims might stimulate the use of a forensic archaeologist to recreate the final scene. The organization has reached global level. For example, the World Council of Anthropological Associations (WCAA), \"a network of national, regional and international associations that aims to promote worldwide communication and cooperation in anthropology\", currently contains members from about three dozen nations.\n\nSince the work of Franz Boas and Bronisław Malinowski in the late 19th and early 20th centuries, \"social\" anthropology in Great Britain and \"cultural\" anthropology in the US have been distinguished from other social sciences by its emphasis on cross-cultural comparisons, long-term in-depth examination of context, and the importance it places on participant-observation or experiential immersion in the area of research. Cultural anthropology, in particular, has emphasized cultural relativism, holism, and the use of findings to frame cultural critiques. This has been particularly prominent in the United States, from Boas' arguments against 19th-century racial ideology, through Margaret Mead's advocacy for gender equality and sexual liberation, to current criticisms of post-colonial oppression and promotion of multiculturalism. Ethnography is one of its primary research designs as well as the text that is generated from anthropological fieldwork.\n\nIn Great Britain and the Commonwealth countries, the British tradition of social anthropology tends to dominate. In the United States, anthropology has traditionally been divided into the four field approach developed by Franz Boas in the early 20th century: \"biological\" or \"physical\" anthropology; \"social\", \"cultural\", or \"sociocultural\" anthropology; and archaeology; plus anthropological linguistics. These fields frequently overlap but tend to use different methodologies and techniques.\n\nEuropean countries with overseas colonies tended to practice more ethnology (a term coined and defined by Adam F. Kollár in 1783). It is sometimes referred to as sociocultural anthropology in the parts of the world that were influenced by the European tradition.\n\nAnthropology is a global discipline involving humanities, social sciences and natural sciences. Anthropology builds upon knowledge from natural sciences, including the discoveries about the origin and evolution of \"Homo sapiens\", human physical traits, human behavior, the variations among different groups of humans, how the evolutionary past of \"Homo sapiens\" has influenced its social organization and culture, and from social sciences, including the organization of human social and cultural relations, institutions, social conflicts, etc. Early anthropology originated in Classical Greece and Persia and studied and tried to understand observable cultural diversity. As such, anthropology has been central in the development of several new (late 20th century) interdisciplinary fields such as cognitive science, global studies, and various ethnic studies.\n\nAccording to Clifford Geertz,\nSociocultural anthropology has been heavily influenced by structuralist and postmodern theories, as well as a shift toward the analysis of modern societies. During the 1970s and 1990s, there was an epistemological shift away from the positivist traditions that had largely informed the discipline. During this shift, enduring questions about the nature and production of knowledge came to occupy a central place in cultural and social anthropology. In contrast, archaeology and biological anthropology remained largely positivist. Due to this difference in epistemology, the four sub-fields of anthropology have lacked cohesion over the last several decades.\n\nSociocultural anthropology draws together the principle axes of cultural anthropology and social anthropology. Cultural anthropology is the comparative study of the manifold ways in which people \"make sense\" of the world around them, while social anthropology is the study of the \"relationships\" among individuals and groups. Cultural anthropology is more related to philosophy, literature and the arts (how one's culture affects the experience for self and group, contributing to a more complete understanding of the people's knowledge, customs, and institutions), while social anthropology is more related to sociology and history. In that, it helps develop an understanding of social structures, typically of others and other populations (such as minorities, subgroups, dissidents, etc.). There is no hard-and-fast distinction between them, and these categories overlap to a considerable degree.\n\nInquiry in sociocultural anthropology is guided in part by cultural relativism, the attempt to understand other societies in terms of their own cultural symbols and values. Accepting other cultures in their own terms moderates reductionism in cross-cultural comparison. This project is often accommodated in the field of ethnography. Ethnography can refer to both a methodology and the product of ethnographic research, i.e. an ethnographic monograph. As a methodology, ethnography is based upon long-term fieldwork within a community or other research site. Participant observation is one of the foundational methods of social and cultural anthropology. Ethnology involves the systematic comparison of different cultures. The process of participant-observation can be especially helpful to understanding a culture from an emic (conceptual, vs. etic, or technical) point of view.\n\nThe study of kinship and social organization is a central focus of sociocultural anthropology, as kinship is a human universal. Sociocultural anthropology also covers economic and political organization, law and conflict resolution, patterns of consumption and exchange, material culture, technology, infrastructure, gender relations, ethnicity, childrearing and socialization, religion, myth, symbols, values, etiquette, worldview, sports, music, nutrition, recreation, games, food, festivals, and language (which is also the object of study in linguistic anthropology).\n\nComparison across cultures is a key element of method in sociocultural anthropology, including the industrialized (and de-industrialized) West. Cultures in the Standard Cross-Cultural Sample (SCCS) of world societies are:\n\nBiological anthropology and physical anthropology are synonymous terms to describe anthropological research focused on the study of humans and non-human primates in their biological, evolutionary, and demographic dimensions. It examines the biological and social factors that have affected the evolution of humans and other primates, and that generate, maintain or change contemporary genetic and physiological variation. \n\nArchaeology is the study of the human past through its material remains. Artifacts, faunal remains, and human altered landscapes are evidence of the cultural and material lives of past societies. Archaeologists examine this material remains in order to deduce patterns of past human behavior and cultural practices. Ethnoarchaeology is a type of archaeology that studies the practices and material remain of living human groups in order to gain a better understanding of the evidence left behind by past human groups, who are presumed to have lived in similar ways.\n\nLinguistic anthropology (not to be confused with anthropological linguistics) seeks to understand the processes of human communications, verbal and non-verbal, variation in language across time and space, the social uses of language, and the relationship between language and culture. It is the branch of anthropology that brings linguistic methods to bear on anthropological problems, linking the analysis of linguistic forms and processes to the interpretation of sociocultural processes. Linguistic anthropologists often draw on related fields including sociolinguistics, pragmatics, cognitive linguistics, semiotics, discourse analysis, and narrative analysis.\n\nOne of the central problems in the anthropology of art concerns the universality of 'art' as a cultural phenomenon. Several anthropologists have noted that the Western categories of 'painting', 'sculpture', or 'literature', conceived as independent artistic activities, do not exist, or exist in a significantly different form, in most non-Western contexts. To surmount this difficulty, anthropologists of art have focused on formal features in objects which, without exclusively being 'artistic', have certain evident 'aesthetic' qualities. Boas' \"Primitive Art\", Claude Lévi-Strauss' \"The Way of the Masks\" (1982) or Geertz's 'Art as Cultural System' (1983) are some examples in this trend to transform the anthropology of 'art' into an anthropology of culturally specific 'aesthetics'.\n\nMedia anthropology (also known as the anthropology of media or mass media) emphasizes ethnographic studies as a means of understanding producers, audiences, and other cultural and social aspects of mass media. The types of ethnographic contexts explored range from contexts of media production (e.g., ethnographies of newsrooms in newspapers, journalists in the field, film production) to contexts of media reception, following audiences in their everyday responses to media. Other types include cyber anthropology, a relatively new area of internet research, as well as ethnographies of other areas of research which happen to involve media, such as development work, social movements, or health education. This is in addition to many classic ethnographic contexts, where media such as radio, the press, new media, and television have started to make their presences felt since the early 1990s.\n\nEthnomusicology is an academic field encompassing various approaches to the study of music (broadly defined), that emphasize its cultural, social, material, cognitive, biological, and other dimensions or contexts instead of or in addition to its isolated sound component or any particular repertoire.\n\nVisual anthropology is concerned, in part, with the study and production of ethnographic photography, film and, since the mid-1990s, new media. While the term is sometimes used interchangeably with ethnographic film, visual anthropology also encompasses the anthropological study of visual representation, including areas such as performance, museums, art, and the production and reception of mass media. Visual representations from all cultures, such as sandpaintings, tattoos, sculptures and reliefs, cave paintings, scrimshaw, jewelry, hieroglyphics, paintings, and photographs are included in the focus of visual anthropology.\n\nEconomic anthropology attempts to explain human economic behavior in its widest historic, geographic and cultural scope. It has a complex relationship with the discipline of economics, of which it is highly critical. Its origins as a sub-field of anthropology begin with the Polish-British founder of anthropology, Bronisław Malinowski, and his French compatriot, Marcel Mauss, on the nature of gift-giving exchange (or reciprocity) as an alternative to market exchange. Economic Anthropology remains, for the most part, focused upon exchange. The school of thought derived from Marx and known as Political Economy focuses on production, in contrast. Economic anthropologists have abandoned the primitivist niche they were relegated to by economists, and have now turned to examine corporations, banks, and the global financial system from an anthropological perspective.\n\nPolitical economy in anthropology is the application of the theories and methods of Historical Materialism to the traditional concerns of anthropology, including, but not limited to, non-capitalist societies. Political economy introduced questions of history and colonialism to ahistorical anthropological theories of social structure and culture. Three main areas of interest rapidly developed. The first of these areas was concerned with the \"pre-capitalist\" societies that were subject to evolutionary \"tribal\" stereotypes. Sahlin's work on hunter-gatherers as the \"original affluent society\" did much to dissipate that image. The second area was concerned with the vast majority of the world's population at the time, the peasantry, many of whom were involved in complex revolutionary wars such as in Vietnam. The third area was on colonialism, imperialism, and the creation of the capitalist world-system. More recently, these political economists have more directly addressed issues of industrial (and post-industrial) capitalism around the world.\n\nApplied anthropology refers to the application of the method and theory of anthropology to the analysis and solution of practical problems. It is a \"complex of related, research-based, instrumental methods which produce change or stability in specific cultural systems through the provision of data, initiation of direct action, and/or the formulation of policy\". More simply, applied anthropology is the practical side of anthropological research; it includes researcher involvement and activism within the participating community. It is closely related to development anthropology (distinct from the more critical anthropology of development).\n\nAnthropology of development tends to view development from a \"critical\" perspective. The kind of issues addressed and implications for the approach simply involve pondering why, if a key development goal is to alleviate poverty, is poverty increasing? Why is there such a gap between plans and outcomes? Why are those working in development so willing to disregard history and the lessons it might offer? Why is development so externally driven rather than having an internal basis? In short, why does so much planned development fail?\n\n\"Kinship\" can refer both to \"the study of\" the patterns of social relationships in one or more human cultures, or it can refer to \"the patterns of social relationships\" themselves. Over its history, anthropology has developed a number of related concepts and terms, such as \"descent\", \"descent groups\", \"lineages\", \"affines\", \"cognates\", and even \"fictive kinship\". Broadly, kinship patterns may be considered to include people related both by descent (one's social relations during development), and also relatives by marriage.\n\nFeminist anthropology is a four field approach to anthropology (archeological, biological, cultural, linguistic) that seeks to reduce male bias in research findings, anthropological hiring practices, and the scholarly production of knowledge. Anthropology engages often with feminists from non-Western traditions, whose perspectives and experiences can differ from those of white European and American feminists. Historically, such 'peripheral' perspectives have sometimes been marginalized and regarded as less valid or important than knowledge from the western world. Feminist anthropologists have claimed that their research helps to correct this systematic bias in mainstream feminist theory. Feminist anthropologists are centrally concerned with the construction of gender across societies. Feminist anthropology is inclusive of birth anthropology as a specialization. \n\nThe first African-American female anthropologist and Caribbeanist is said to be Vera Mae Green who studied ethnic and family relations in the Caribbean as well as the United States, and thereby tried to improve the way black life, experiences, and culture were studied.\n\nMedical anthropology is an interdisciplinary field which studies \"human health and disease, health care systems, and biocultural adaptation\". It is believed that William Caudell was the first to discover the field of medical anthropology. Currently, research in medical anthropology is one of the main growth areas in the field of anthropology as a whole. It focuses on the following six basic fields:\nOther subjects that have become central to medical anthropology worldwide are violence and social suffering (Farmer, 1999, 2003; Beneduce, 2010) as well as other issues that involve physical and psychological harm and suffering that are not a result of illness. On the other hand, there are fields that intersect with medical anthropology in terms of research methodology and theoretical production, such as \"cultural psychiatry\" and \"transcultural psychiatry\" or \"ethnopsychiatry\".\n\nNutritional anthropology is a synthetic concept that deals with the interplay between economic systems, nutritional status and food security, and how changes in the former affect the latter. If economic and environmental changes in a community affect access to food, food security, and dietary health, then this interplay between culture and biology is in turn connected to broader historical and economic trends associated with globalization. Nutritional status affects overall health status, work performance potential, and the overall potential for economic development (either in terms of human development or traditional western models) for any given group of people.\n\nPsychological anthropology is an interdisciplinary subfield of anthropology that studies the interaction of cultural and mental processes. This subfield tends to focus on ways in which humans' development and enculturation within a particular cultural group—with its own history, language, practices, and conceptual categories—shape processes of human cognition, emotion, perception, motivation, and mental health. It also examines how the understanding of cognition, emotion, motivation, and similar psychological processes inform or constrain our models of cultural and social processes.\n\nCognitive anthropology seeks to explain patterns of shared knowledge, cultural innovation, and transmission over time and space using the methods and theories of the cognitive sciences (especially experimental psychology and evolutionary biology) often through close collaboration with historians, ethnographers, archaeologists, linguists, musicologists and other specialists engaged in the description and interpretation of cultural forms. Cognitive anthropology is concerned with what people from different groups know and how that implicit knowledge changes the way people perceive and relate to the world around them.\n\nTranspersonal anthropology studies the relationship between altered states of consciousness and culture. As with transpersonal psychology, the field is much concerned with altered states of consciousness (ASC) and transpersonal experience. However, the field differs from mainstream transpersonal psychology in taking more cognizance of cross-cultural issues—for instance, the roles of myth, ritual, diet, and texts in evoking and interpreting extraordinary experiences.\n\nPolitical anthropology concerns the structure of political systems, looked at from the basis of the structure of societies. Political anthropology developed as a discipline concerned primarily with politics in stateless societies, a new development started from the 1960s, and is still unfolding: anthropologists started increasingly to study more \"complex\" social settings in which the presence of states, bureaucracies and markets entered both ethnographic accounts and analysis of local phenomena. The turn towards complex societies meant that political themes were taken up at two main levels. Firstly, anthropologists continued to study political organization and political phenomena that lay outside the state-regulated sphere (as in patron-client relations or tribal political organization). Secondly, anthropologists slowly started to develop a disciplinary concern with states and their institutions (and on the relationship between formal and informal political institutions). An anthropology of the state developed, and it is a most thriving field today. Geertz' comparative work on \"Negara\", the Balinese state, is an early, famous example.\n\nLegal anthropology or anthropology of law specializes in \"the cross-cultural study of social ordering\". Earlier legal anthropological research often focused more narrowly on conflict management, crime, sanctions, or formal regulation. More recent applications include issues such as human rights, legal pluralism, and political uprisings.\n\nPublic anthropology was created by Robert Borofsky, a professor at Hawaii Pacific University, to \"demonstrate the ability of anthropology and anthropologists to effectively address problems beyond the discipline – illuminating larger social issues of our times as well as encouraging broad, public conversations about them with the explicit goal of fostering social change\".\n\nCyborg anthropology originated as a sub-focus group within the American Anthropological Association's annual meeting in 1993. The sub-group was very closely related to STS and the Society for the Social Studies of Science. Donna Haraway's 1985 \"Cyborg Manifesto\" could be considered the founding document of cyborg anthropology by first exploring the philosophical and sociological ramifications of the term. Cyborg anthropology studies humankind and its relations with the technological systems it has built, specifically modern technological systems that have reflexively shaped notions of what it means to be human beings.\n\nDigital anthropology is the study of the relationship between humans and digital-era technology, and extends to various areas where anthropology and technology intersect. It is sometimes grouped with sociocultural anthropology, and sometimes considered part of material culture. The field is new, and thus has a variety of names with a variety of emphases. These include techno-anthropology, digital ethnography, cyberanthropology, and virtual anthropology.\n\nEcological anthropology is defined as the \"study of cultural adaptations to environments\". The sub-field is also defined as, \"the study of relationships between a population of humans and their biophysical environment\". The focus of its research concerns \"how cultural beliefs and practices helped human populations adapt to their environments, and how their environment across space and time. The contemporary perspective of environmental anthropology, and arguably at least the backdrop, if not the focus of most of the ethnographies and cultural fieldworks of today, is political ecology. Many characterize this new perspective as more informed with culture, politics and power, globalization, localized issues, century anthropology and more. The focus and data interpretation is often used for arguments for/against or creation of policy, and to prevent corporate exploitation and damage of land. Often, the observer has become an active part of the struggle either directly (organizing, participation) or indirectly (articles, documentaries, books, ethnographies). Such is the case with environmental justice advocate Melissa Checker and her relationship with the people of Hyde Park.\n\nEthnohistory is the study of ethnographic cultures and indigenous customs by examining historical records. It is also the study of the history of various ethnic groups that may or may not exist today. Ethnohistory uses both historical and ethnographic data as its foundation. Its historical methods and materials go beyond the standard use of documents and manuscripts. Practitioners recognize the utility of such source material as maps, music, paintings, photography, folklore, oral tradition, site exploration, archaeological materials, museum collections, enduring customs, language, and place names.\n\nThe anthropology of religion involves the study of religious institutions in relation to other social institutions, and the comparison of religious beliefs and practices across cultures. Modern anthropology assumes that there is complete continuity between magical thinking and religion, and that every religion is a cultural product, created by the human community that worships it.\n\nUrban anthropology is concerned with issues of urbanization, poverty, and neoliberalism. Ulf Hannerz quotes a 1960s remark that traditional anthropologists were \"a notoriously agoraphobic lot, anti-urban by definition\". Various social processes in the Western World as well as in the \"Third World\" (the latter being the habitual focus of attention of anthropologists) brought the attention of \"specialists in 'other cultures'\" closer to their homes. There are two main approaches to urban anthropology: examining the types of cities or examining the social issues within the cities. These two methods are overlapping and dependent of each other. By defining different types of cities, one would use social factors as well as economic and political factors to categorize the cities. By directly looking at the different social issues, one would also be studying how they affect the dynamic of the city.\n\nAnthrozoology (also known as \"human–animal studies\") is the study of interaction between living things. It is an interdisciplinary field that overlaps with a number of other disciplines, including anthropology, ethology, medicine, psychology, veterinary medicine and zoology. A major focus of anthrozoologic research is the quantifying of the positive effects of human-animal relationships on either party and the study of their interactions. It includes scholars from a diverse range of fields, including anthropology, sociology, biology, and philosophy.\n\nBiocultural anthropology is the scientific exploration of the relationships between human biology and culture. Physical anthropologists throughout the first half of the 20th century viewed this relationship from a racial perspective; that is, from the assumption that typological human biological differences lead to cultural differences. After World War II the emphasis began to shift toward an effort to explore the role culture plays in shaping human biology.\n\nEvolutionary anthropology is the interdisciplinary study of the evolution of human physiology and human behaviour and the relation between hominins and non-hominin primates. Evolutionary anthropology is based in natural science and social science, combining the human development with socioeconomic factors. Evolutionary anthropology is concerned with both biological and cultural evolution of humans, past and present. It is based on a scientific approach, and brings together fields such as archaeology, behavioral ecology, psychology, primatology, and genetics. It is a dynamic and interdisciplinary field, drawing on many lines of evidence to understand the human experience, past and present.\n\nForensic anthropology is the application of the science of physical anthropology and human osteology in a legal setting, most often in criminal cases where the victim's remains are in the advanced stages of decomposition. A forensic anthropologist can assist in the identification of deceased individuals whose remains are decomposed, burned, mutilated or otherwise unrecognizable. The adjective \"forensic\" refers to the application of this subfield of science to a court of law.\n\nPaleoanthropology combines the disciplines of paleontology and physical anthropology. It is the study of ancient humans, as found in fossil hominid evidence such as petrifacted bones and footprints.\n\nContemporary anthropology is an established science with academic departments at most universities and colleges. The single largest organization of anthropologists is the American Anthropological Association (AAA), which was founded in 1903. Its members are anthropologists from around the globe.\n\nIn 1989, a group of European and American scholars in the field of anthropology established the European Association of Social Anthropologists (EASA) which serves as a major professional organization for anthropologists working in Europe. The EASA seeks to advance the status of anthropology in Europe and to increase visibility of marginalized anthropological traditions and thereby contribute to the project of a global anthropology or world anthropology.\n\nHundreds of other organizations exist in the various sub-fields of anthropology, sometimes divided up by nation or region, and many anthropologists work with collaborators in other disciplines, such as geology, physics, zoology, paleontology, anatomy, music theory, art history, sociology and so on, belonging to professional societies in those disciplines as well.\n\nAs the field has matured it has debated and arrived at ethical principles aimed at protecting both the subjects of anthropological research as well as the researchers themselves, and professional societies have generated codes of ethics.\n\nAnthropologists, like other researchers (especially historians and scientists engaged in field research), have over time assisted state policies and projects, especially colonialism.\n\nSome commentators have contended:\n\nAs part of their quest for scientific objectivity, present-day anthropologists typically urge cultural relativism, which has an influence on all the sub-fields of anthropology. This is the notion that cultures should not be judged by another's values or viewpoints, but be examined dispassionately on their own terms. There should be no notions, in good anthropology, of one culture being better or worse than another culture.\n\nEthical commitments in anthropology include noticing and documenting genocide, infanticide, racism, mutilation (including circumcision and subincision), and torture. Topics like racism, slavery, and human sacrifice attract anthropological attention and theories ranging from nutritional deficiencies to genes to acculturation have been proposed, not to mention theories of colonialism and many others as root causes of Man's inhumanity to man. To illustrate the depth of an anthropological approach, one can take just one of these topics, such as \"racism\" and find thousands of anthropological references, stretching across all the major and minor sub-fields.\n\nAnthropologists' involvement with the U.S. government, in particular, has caused bitter controversy within the discipline. Franz Boas publicly objected to US participation in World War I, and after the war he published a brief expose and condemnation of the participation of several American archaeologists in espionage in Mexico under their cover as scientists.\n\nBut by the 1940s, many of Boas' anthropologist contemporaries were active in the allied war effort against the Axis Powers (Nazi Germany, Fascist Italy, and Imperial Japan). Many served in the armed forces, while others worked in intelligence (for example, Office of Strategic Services and the Office of War Information). At the same time, David H. Price's work on American anthropology during the Cold War provides detailed accounts of the pursuit and dismissal of several anthropologists from their jobs for communist sympathies.\n\nAttempts to accuse anthropologists of complicity with the CIA and government intelligence activities during the Vietnam War years have turned up surprisingly little. Many anthropologists (students and teachers) were active in the antiwar movement. Numerous resolutions condemning the war in all its aspects were passed overwhelmingly at the annual meetings of the American Anthropological Association (AAA).\n\nProfessional anthropological bodies often object to the use of anthropology for the benefit of the state. Their codes of ethics or statements may proscribe anthropologists from giving secret briefings. The Association of Social Anthropologists of the UK and Commonwealth (ASA) has called certain scholarship ethically dangerous. The AAA's current 'Statement of Professional Responsibility' clearly states that \"in relation with their own government and with host governments ... no secret research, no secret reports or debriefings of any kind should be agreed to or given.\"\n\nAnthropologists, along with other social scientists, are working with the US military as part of the US Army's strategy in Afghanistan. The \"Christian Science Monitor\" reports that \"Counterinsurgency efforts focus on better grasping and meeting local needs\" in Afghanistan, under the \"Human Terrain System\" (HTS) program; in addition, HTS teams are working with the US military in Iraq. In 2009, the American Anthropological Association's Commission on the Engagement of Anthropology with the US Security and Intelligence Communities released its final report concluding, in part, that, \"When ethnographic investigation is determined by military missions, not subject to external review, where data collection occurs in the context of war, integrated into the goals of counterinsurgency, and in a potentially coercive environment – all characteristic factors of the HTS concept and its application – it can no longer be considered a legitimate professional exercise of anthropology. In summary, while we stress that constructive engagement between anthropology and the military is possible, CEAUSSIC suggests that the AAA emphasize the incompatibility of HTS with disciplinary ethics and practice for job seekers and that it further recognize the problem of allowing HTS to define the meaning of \"anthropology\" within DoD.\"\n\nBefore WWII British 'social anthropology' and American 'cultural anthropology' were still distinct traditions. After the war, enough British and American anthropologists borrowed ideas and methodological approaches from one another that some began to speak of them collectively as 'sociocultural' anthropology.\n\nThere are several characteristics that tend to unite anthropological work. One of the central characteristics is that anthropology tends to provide a comparatively more holistic account of phenomena and tends to be highly empirical. The quest for holism leads most anthropologists to study a particular place, problem or phenomenon in detail, using a variety of methods, over a more extensive period than normal in many parts of academia.\n\nIn the 1990s and 2000s, calls for clarification of what constitutes a culture, of how an observer knows where his or her own culture ends and another begins, and other crucial topics in writing anthropology were heard. These dynamic relationships, between what can be observed on the ground, as opposed to what can be observed by compiling many local observations remain fundamental in any kind of anthropology, whether cultural, biological, linguistic or archaeological.\n\nBiological anthropologists are interested in both human variation and in the possibility of human universals (behaviors, ideas or concepts shared by virtually all human cultures). They use many different methods of study, but modern population genetics, participant observation and other techniques often take anthropologists \"into the field,\" which means traveling to a community in its own setting, to do something called \"fieldwork.\" On the biological or physical side, human measurements, genetic samples, nutritional data may be gathered and published as articles or monographs.\n\nAlong with dividing up their project by theoretical emphasis, anthropologists typically divide the world up into relevant time periods and geographic regions. Human time on Earth is divided up into relevant cultural traditions based on material, such as the Paleolithic and the Neolithic, of particular use in archaeology. Further cultural subdivisions according to tool types, such as Olduwan or Mousterian or Levalloisian help archaeologists and other anthropologists in understanding major trends in the human past. Anthropologists and geographers share approaches to culture regions as well, since mapping cultures is central to both sciences. By making comparisons across cultural traditions (time-based) and cultural regions (space-based), anthropologists have developed various kinds of comparative method, a central part of their science.\n\nBecause anthropology developed from so many different enterprises (see History of anthropology), including but not limited to fossil-hunting, exploring, documentary film-making, paleontology, primatology, antiquity dealings and curatorship, philology, etymology, genetics, regional analysis, ethnology, history, philosophy, and religious studies, it is difficult to characterize the entire field in a brief article, although attempts to write histories of the entire field have been made.\n\nSome authors argue that anthropology originated and developed as the study of \"other cultures\", both in terms of time (past societies) and space (non-European/non-Western societies). For example, the classic of urban anthropology, Ulf Hannerz in the introduction to his seminal \"Exploring the City: Inquiries Toward an Urban Anthropology\" mentions that the \"Third World\" had habitually received most of attention; anthropologists who traditionally specialized in \"other cultures\" looked for them far away and started to look \"across the tracks\" only in late 1960s.\n\nNow there exist many works focusing on peoples and topics very close to the author's \"home\". It is also argued that other fields of study, like History and Sociology, on the contrary focus disproportionately on the West.\n\nIn France, the study of Western societies has been traditionally left to sociologists, but this is increasingly changing, starting in the 1970s from scholars like Isac Chiva and journals like \"Terrain\" (\"fieldwork\"), and developing with the center founded by Marc Augé (\"Le Centre d'anthropologie des mondes contemporains\", the Anthropological Research Center of Contemporary Societies).\n\nSince the 1980s it has become common for social and cultural anthropologists to set ethnographic research in the North Atlantic region, frequently examining the connections between locations rather than limiting research to a single locale. There has also been a related shift toward broadening the focus beyond the daily life of ordinary people; increasingly, research is set in settings such as scientific laboratories, social movements, governmental and nongovernmental organizations and businesses.\n\n\n\n\n"}
{"id": "3788923", "url": "https://en.wikipedia.org/wiki?curid=3788923", "title": "Anthropology of art", "text": "Anthropology of art\n\nAnthropology of art is a sub-field in social anthropology dedicated to the study of art in different cultural contexts. The anthropology of art focuses on historical, economic and aesthetic dimensions in non-Western art forms, including what is known as 'tribal art'.\n\nFranz Boas, one of the pioneers of modern anthropology, conducted many field studies of the arts, helping create a foundation to the field. His book, \"Primitive Art\" (1927), summarizes his main insights into so-called 'primitive' art forms, with a detailed case study on the arts of the Northwest Pacific Coast. The famous anthropologist Claude Lévi-Strauss took Boas' analyses further in his book \"The Way of the Masks\", where he traced changes in the plastic form of Northwest Pacific masks to patterns of intercultural interaction among the indigenous peoples of the coast.\n\nOne of the central problems in the anthropology of art concerns the universality of 'art' as a cultural phenomenon. Several anthropologists have noted that the Western categories of 'painting', 'sculpture', or 'literature', conceived as independent artistic activities, do not exist, or exist in a significantly different form, in most non-Western contexts. Thus, there is no consensus on a single, cross-cultural definition of 'art' in anthropology. To surmount this difficulty, anthropologists of art have focused on formal features in objects which, without exclusively being 'artistic', have certain evident 'aesthetic' qualities. Boas' \"Primitive Art\", Claude Lévi-Strauss' \"The Way of the Masks\" (1982) or Geertz's 'Art as Cultural System' (1983) are some examples in this trend to transform the anthropology of 'art' into an anthropology of culturally-specific 'aesthetics'. More recently, in his book \"Art and Agency\", Alfred Gell proposed a new definition of 'art' as a complex system of intentionality, where artists produce art objects to effect changes in the world, including (but not restricted to) changes in the aesthetic perceptions of art audiences. Gell's ideas have stirred a large controversy in the anthropology of art in the 2000s.\n\n\n\n"}
{"id": "77695", "url": "https://en.wikipedia.org/wiki?curid=77695", "title": "Antithesis", "text": "Antithesis\n\nAntithesis (Greek for \"setting opposite\", from \"against\" and \"placing\") is used in writing or speech either as a proposition that contrasts with or reverses some previously mentioned proposition, or when two opposites are introduced together for contrasting effect.\n\nAntithesis can be defined as \"a figure of speech involving a seeming contradiction of ideas, words, clauses, or sentences within a balanced grammatical structure. Parallelism of expression serves to emphasize opposition of ideas\".\n\nAn antithesis must always contain two ideas within one statement. The ideas may not be structurally opposite, but they serve to be functionally opposite when comparing two ideas for emphasis.\n\nAccording to Aristotle, the use of an antithesis makes the audience better understand the point the speaker is trying to make. Further explained, the comparison of two situations or ideas makes choosing the correct one simpler. Aristotle states that antithesis in rhetoric is similar to syllogism due to the presentation of two conclusions within a statement.\n\nAntitheses are used to strengthen an argument by using either exact opposites or simply contrasting ideas, but can also include both. They typically make a sentence more memorable for the reader or listener through balance and emphasis of the words.\n\nIn rhetoric, antithesis is a figure of speech involving the bringing out of a contrast in the ideas by an obvious contrast in the words, clauses, or sentences, within a parallel grammatical structure. \n\nThe term \"antithesis\" in rhetoric goes back to the 4th century BC, for example Aristotle, \"Rhetoric\", 1410a, in which he gives a series of examples.\n\nAn antithesis can be a simple statement contrasting two things, using a parallel structure:\n\n\nOften there is a double antithesis, as in the following proverb, where \"man\" is opposed to \"God\", and \"proposes\" is contrasted with \"disposes\":\n\n\nAnother type is of the form \"not A, but B\" (negative-positive), in which the point made is emphasised by first being contrasted with its negative:\n\n\nAnother type involves a chiasmus (AB, BA word order), in which the contrasted words switch places:\n\n\nThe negative-positive antithesis and the chiasmus-antithesis can be combined, as in the following sentence:\n\nSome other examples of antithesis are:\n\n\n\"Matthew's Antitheses\" is the traditional name given to a section of the Sermon on the Mount where Jesus takes six well known prescriptions of the Mosaic Law and calls his followers to do more than the Law requires. Protestant scholars since the Reformation have generally believed that Jesus was setting his teaching over against false interpretations of the Law current at the time. \"Antithesis\" was the name given by Marcion of Sinope to a manifesto in which he contrasted the Old Testament with the New Testament and defined what came to be known as Marcionism.\n\nIn dialectics (any formal system of reasoning that arrives at the truth by the exchange of logical arguments) antithesis is the juxtaposition of contrasting ideas, usually in a balanced way. The logical arguments are said to be stated in the order thesis, antithesis, synthesis.\n\nAlthough this style of philosophical discussion (stating a point of view, then its opposite, and finally drawing a conclusion) was commonly used by ancient philosophers, the use of the trio \"thesis, antithesis, synthesis\" itself to describe it goes back only to the 18th century, to a work published in 1794 by the German philosopher Johann Gottlieb Fichte.\n\nThe phrase is sometimes incorrectly stated to originate from the German philosopher Hegel. However, Hegel never actually used the trio of terms except once in a lecture, in which he reproached Immanuel Kant for having \"everywhere posited thesis, antithesis, synthesis\".\n\n"}
{"id": "51316845", "url": "https://en.wikipedia.org/wiki?curid=51316845", "title": "Comedy of intrigue", "text": "Comedy of intrigue\n\nThe comedy of intrigue, also known as the comedy of situation, is a genre of comedy in which dramatic action is prioritised over the development of character, complicated strategems and conspiracies drive the plot, and farcical humour and contrived or ridiculous dramatic situations are often employed. Characterisation tends to be defined only vaguely and the plot gives the illusion of dynamic, constant movement. The German philosopher Hegel argued that characters pursue their aims in such comedies via the use of deception. The genre was first developed in the theatre of classical Rome by Plautus and Terence. Examples of comedies of intrigue include Niccolò Machiavelli's \"The Mandrake\" (1524), the anonymous Italian play \"The Deceived Ones\" (1531), Shakespeare's \"The Merchant of Venice\" (c. 1596) and \"Much Ado About Nothing\", Thomas Heywood's \"The Wise Woman of Hoxton\" (c. 1604), Molière's \"Scapin the Schemer\" (1671), and the plays of Aphra Behn and Thomas D'Urfey.\n\n\n"}
{"id": "30722649", "url": "https://en.wikipedia.org/wiki?curid=30722649", "title": "Declamation", "text": "Declamation\n\nDeclamation (from the Latin: declamatio for \"declaration\") is an artistic form of public speaking. It is a dramatic oration designed to present through articulation, emphasis and gesture the full sense of the message being imparted.\n\nIn Ancient Rome, declamation was a genre of ancient rhetoric and a mainstay of the Roman higher education system. It was separated into two component subgenres, the \"controversia\", speeches of defense or prosecution in fictitious court cases, and the \"suasoria\", in which the speaker advised a historical or legendary figure as to a course of action. Roman declamations survive in four corpora: the compilations of Seneca the Elder and Calpurnius Flaccus, as well as two sets of \"controversiae\", the \"Major Declamations\" and \"Minor Declamations\" spuriously attributed to Quintilian.\n\nDeclamation had its origin in the form of preliminary exercises for Greek students of rhetoric: works from the Greek declamatory tradition survive in works such as the collections of Sopater and Choricius of Gaza. Of the remaining Roman declamations the vast majority are \"controversiae\"; only one book of \"suasoriae\" survive, that being in Seneca the Elder's collection. The \"controversia\" as they currently exist normally consist of several elements: an imaginary law, a theme which introduced a tricky legal situation, and an argument which records a successful or model speech on the topic. It was normal for students to employ illustrative \"exempla\" from Roman history and legend (such as were collected in the work of Valerius Maximus) to support their case. Important points were often summed up via pithy epigrammatic statements (\"sententiae\"). Common themes include ties of fidelity between fathers and sons, heroes and tyrants in the archaic city, and conflicts between rich and poor men.\n\nAs a critical part of rhetorical education, declamation's influence was widespread in Roman elite culture. In addition to its didactic role, it is also attested as a performative genre: public declamations were visited by such figures as Pliny the Elder, Asinius Pollio, Maecenas, and the emperor Augustus. The poet Ovid is recorded by Seneca the Elder as being a star declaimer, and the works of the satirists Martial and Juvenal, as well as the historian Tacitus, reveal a substantial declamatory influence.\n\nLater examples of declamation can be seen in the work of the sixth century AD bishop and author Ennodius.\n\nIn the eighteenth century, a classical revival of the art of public speaking, often referred to as The Elocution Movement occurred in Britain. While elocution focused on the voice—articulation, diction, and pronunciation—declamation focused on delivery. Rather than a narrow focus on rhetoric, or persuasion, practitioners involved in the movement focused on improving speech and gesture to convey the full sentiment of the message. Traditionally, practitioners of declamation served in the clergy, legislature or law, but by the nineteenth century, the practice had extended to theatrical and reformist venues. Initially, the aim was to improve the standard of oral communication, as high rates of illiteracy made it imperative for churches, courts and parliaments, to rely on the spoken word. Through modification of inflection and phrasing, along with appropriate gestures, speakers were taught to convey the meaning and persuade the audience, rather than deliver monotonous litanies. \n\nBy the mid-nineteenth century, reformers were using the \"art of declamation\" to publicly address vice and provide moral guidance. In the Americas, missionary-run schools focused on teaching former slaves the art of public speaking to enable them to elevate others of their race as teachers and ministers. Using drama as a tool to teach, reformers hoped to standardize the spoken word, while creating a sense of national pride. Studies and presentation of declamation flourished in Latin America and particularly in the African-American and Afro-Caribbean communities through the first third of the twentieth century. Practitioners attempted to interpret their orations to convey the emotions and feeling behind the writer's words to the audience, rather than simply recite them. In the twentieth century, among black practitioners, topical focus often was on the irony of their lives in a post-slavery world, recognizing that they had gained freedom but were not free to express themselves. Presentation involved utilization of African rhythms from dance and music, and local dialect, as a form of social protest.\n\n\n\n"}
{"id": "17572785", "url": "https://en.wikipedia.org/wiki?curid=17572785", "title": "Distributed language", "text": "Distributed language\n\nDistributed language represents an externalist perspective on human cognition. Instead of tracing communication to individual knowledge of a symbolic system, language-activity is taken to sustain the human world. Extending work by Humberto Maturana, priority is given to how face-to-face interaction draws on multimodal activity or languaging .[1] As people language together, they gain the skills and knowledge needed to participate in a range of activities in which wordings play a part. Over time, these activities construct and maintain language as a whole. Distributed language thus links a biological theory of the origin of language to distributed cognition. Human cognitive and communicative abilities arise as people do things together while drawing on material, linguistic and other resources. Language activity is constrained by biology, circumstances, and collective ways of life. While bodies sustain coordination, our lived realities are extended by the resources of a partly shared collective world. Thus, language cannot be separated from the artifacts and institutions or the behaviour of the living beings who undertake collaborative (and solo) tasks. This distributed perspective challenges the mainstream view that language use can be explained by individual competencies and microsocial rules. To ascribe 'language' to individual organisms is, on the distributed perspective, an error. Building on cognitive science, the perspective challenges cognitive internalism by presenting language as a prime case of embodied and culturally embedded cognition. It emphasizes that the heterogeneity of human language does much to shape people, mind and society.\n\n\n\n"}
{"id": "42472514", "url": "https://en.wikipedia.org/wiki?curid=42472514", "title": "Epochalism", "text": "Epochalism\n\nEpochalism is an attitude of respect for the progressive spirit of the age and for social and technological advancement, which was contrasted by Clifford Geertz with what he termed the (essentialist) valorisation of traditional values. He viewed this distinction as a central social polarity pervading developing nations.\n\nMore broadly, the term used has been used to describe the post-Fordist, postmodern belief that the current era or epoch represents a fundamental clean break with the past; is something unique in human history; and due to this radical change, previous rules will no longer apply.\n\nEpochalism in the developing world can be seen purely as a progressive force, favouring movement toward secularisation and industrial advance, as opposed to a regressive return to the traditional values of community and Gemeinschaft. However, in practice the situation is likely to be more complicated: nationalist struggles for independence have often relied on essentialist appeals to authentic ethnic communities and cultural practices, as well as to epochalism, in order to free themselves from dependence on a Western model/Western control.\n\nThe rapid rise of the World Wide Web led many digerati to see it as an unprecedented human phenomenon, wholly divorced from all past experience. Evgeny Morozov used the term epochalism to describe the prevalent 21st-century belief that \"one is living in truly exceptional times – an intellectual fallacy I call 'epochalism. Previous technological advances, as with the age of railways or the age of broadcasting, had of course made very similar claims for themselves; and A. E. Housman a century before had denounced the mind \"which commands no outlook upon the past or the future, but believes that the fashion of the present, unlike all fashions heretofore, will endure perpetually\". \n\nLate modernity however, with its shortening of awareness of time-spans and its focus on the present, makes the short-sightedness of epochalism - with what Morozov saw as its dark fetishism of Internet-based solutions - an increasingly plausible intellectual posture.\n\n"}
{"id": "303486", "url": "https://en.wikipedia.org/wiki?curid=303486", "title": "Ethnolinguistics", "text": "Ethnolinguistics\n\nEthnolinguistics (sometimes called cultural linguistics) is a field of linguistics that studies the relationship between language and culture and how different ethnic groups perceive the world. It is the combination between ethnology and linguistics. The former refers to the way of life of an entire community: all the characteristics that distinguish one community from the other. Such characteristics make the cultural aspects of a community or a society.\n\nEthnolinguists study the way perception and conceptualization influences language and show how that is linked to different cultures and societies. An example is how spatial orientation is expressed in various cultures. In many societies, words for the cardinal directions \"east\" and \"west\" are derived from terms for sunrise/sunset. The nomenclature for cardinal directions of Inuit speakers of Greenland, however, is based on geographical landmarks such as the river system and one's position on the coast. Similarly, the Yurok lack the idea of cardinal directions; they orient themselves with respect to their principal geographic feature, the Klamath River.\n\nCultural Linguistics is a related branch of linguistics that explores the relationship between language and cultural conceptualisations. Cultural Linguistics draws on and expands the theoretical and analytical advancements in cognitive science (including complexity science and distributed cognition) and anthropology. Cultural linguistics examines how various features of human languages encode cultural conceptualisations, including cultural schemas, cultural categories, and cultural metaphors. In , language is viewed as deeply entrenched in the group-level, cultural cognition of communities of speakers. Thus far, the approach of Cultural Linguistics has been adopted in several areas of applied linguistic research, including intercultural communication, second language learning, Teaching English as an International Language, and World Englishes.\n\n\n"}
{"id": "2067118", "url": "https://en.wikipedia.org/wiki?curid=2067118", "title": "Folk play", "text": "Folk play\n\nFolk plays such as Hoodening, Guising, Mummers Play and Soul Caking are generally verse sketches performed in countryside pubs in European countries, private houses or the open air, at set times of the year such as the Winter or Summer solstices or Christmas and New Year. Many have long traditions, although they are frequently updated to retain their relevance for modern audiences.\n\n"}
{"id": "17157119", "url": "https://en.wikipedia.org/wiki?curid=17157119", "title": "Friendship", "text": "Friendship\n\nFriendship is a relationship of mutual affection between people. Friendship is a stronger form of interpersonal bond than an association. Friendship has been studied in academic fields such as communication, sociology, social psychology, anthropology, and philosophy. Various academic theories of friendship have been proposed, including social exchange theory, equity theory, relational dialectics, and attachment styles.\n\nAlthough there are many forms of friendship, some of which may vary from place to place, certain characteristics are present in many types of such bonds. Such characteristics include affection; kindness, love, virtue, sympathy, empathy, honesty, altruism, loyalty, mutual understanding and compassion, enjoyment of each other's company, trust, and the ability to be oneself, express one's feelings to others, and make mistakes without fear of judgment from the friend.\n\nThe understanding of friendship in children tends to be more heavily focused on areas such as common activities, physical proximity, and shared expectations. These friendships provide opportunity for playing and practicing self-regulation. Most children tend to describe friendship in terms of things like sharing, and children are more likely to share with someone they consider to be a friend. As children mature, they become less individualized and are more aware of others. They gain the ability to empathize with their friends, and enjoy playing in groups. They also experience peer rejection as they move through the middle childhood years. Establishing good friendships at a young age helps a child to be better acclimated in society later on in their life.\n\nBased upon the reports of teachers and mothers, 75% of preschool children had at least one friend. This figure rose to 78% through the fifth grade, as measured by co-nomination as friends, and 55% had a mutual best friend. About 15% of children were found to be chronically friendless, reporting periods without mutual friends at least six months.\n\nPotential benefits of friendship include the opportunity to learn about empathy and problem solving.\nCoaching from parents can be useful in helping children to make friends. Eileen Kennedy-Moore describes three key ingredients of children's friendship formation: (1) openness, (2) similarity, and (3) shared fun. Parents can also help children understand social guidelines they haven't learned on their own. Drawing from research by Robert Selman and others, Kennedy-Moore outlines developmental stages in children's friendship, reflecting an increasing capacity to understand others' perspectives: \"I Want It My Way\", \"What's In It For Me?\", \"By the Rules\", \"Caring and Sharing\", and \"Friends Through Thick and Thin.\"\n\nIn adolescence, friendships become \"more giving, sharing, frank, supportive, and spontaneous.\" Adolescents tend to seek out peers who can provide such qualities in a reciprocal relationship, and to avoid peers whose problematic behavior suggest they may not be able to satisfy these needs. Relationships begin to maintain a focus on shared values, loyalty, and common interests, rather than physical concerns like proximity and access to play things that more characterize childhood.\n\nA study performed at the University of Texas at Austin examined over 9,000 American adolescents to determine how their engagement in problematic behavior (such as stealing, fighting, and truancy) was related to their friendships. Findings indicated that adolescents were less likely to engage in problem behavior when their friends did well in school, participated in school activities, avoided drinking, and had good mental health. The opposite was found regarding adolescents who did engage in problematic behavior. Whether adolescents were influenced by their friends to engage in problem behavior depended on how much they were exposed to those friends, and whether they and their friendship groups \"fit in\" at school.\n\nA study by researchers from Purdue University found that friendships formed during post-secondary education last longer than friendships formed earlier.\n\nFriendship in adulthood provides companionship, affection, as well as emotional support, and contributes positively to mental well-being and improved physical health.\n\nAdults may find it particularly difficult to maintain meaningful friendships in the workplace. \"The workplace can crackle with competition, so people learn to hide vulnerabilities and quirks from colleagues. Work friendships often take on a transactional feel; it is difficult to say where networking ends and real friendship begins.\" Most adults value the financial security of their jobs more than friendship with coworkers.\n\nThe majority of adults have an average of two close friends. Numerous studies with adults suggest that friendships and other supportive relationships do enhance self-esteem.\n\nOlder adults continue to report high levels of personal satisfaction in their friendships as they age, and even as the overall number of friends tends to decline. This satisfaction is associated with an increased ability to accomplish activities of daily living, as well as a reduced decline in cognitive abilities, decreased instances of hospitalization, and better outcomes related to rehabilitation. The overall number of reported friends in later life may be mediated by increased lucidity, better speech and vision, and marital status.\n\nAs on review phrased it:\n\nResearch within the past four decades has now consistently found that older adults reporting the highest levels of happiness and general well being also report strong, close ties to numerous friends.\n\nAs family responsibilities and vocational pressures lessen, friendships become more important. Among the elderly, friendships can provide links to the larger community, serve as a protective factor against depression and loneliness, and compensate for potential losses in social support previously given by family members. Especially for people who cannot go out as often, interactions with friends allow for continued societal interaction. Additionally, older adults in declining health who remain in contact with friends show improved psychological well-being.\n\nChildren with attention deficit hyperactivity disorder (ADHD) may have difficulty forming and maintaining friendships, due to a limited ability to build social skills through observational learning, difficulties attending to social cues, and because of the social impacts of impulsive behavior and a greater tendency to engage in behavior that may be seen as disruptive by their peers. In a 2007 review, no treatment was identified which effectively address peer functioning in children with ADHD, and treatments which addressed other aspects of the disorder were not found to eliminate issues related to peer functioning.\n\nCertain symptoms of autism spectrum disorders can interfere with the formation of interpersonal relations, such as a preference for routine actions, resistance to change, obsession with particular interests or rituals, and a lack of social skills. Children with autism have been found to be more likely to be close friends of one person, rather than having groups of friends. Additionally, they are more likely to be close friends of other children with some sort of a disability. A sense of parental attachment aids in the quality of friendships in children with autism spectrum disorders; a sense of attachment with one's parents compensates for a lack of social skills that would usually inhibit friendships.\n\nA study done by Frankel et al. showed that parental intervention and instruction plays an important role in such children developing friendships. Along with parental intervention, school professionals play an important role in teaching social skills and peer interaction. Paraprofessionals, specifically one-on-one aides and classroom aides, are often placed with children with autism spectrum disorders in order to facilitate friendships and guide the child in making and maintaining substantial friendships.\n\nAlthough lessons and training may help peers of children with autism, bullying is still a major concern in social situations. According to Anahad O'Connor of \"The New York Times\", bullying is most likely to occur against children with autism spectrum disorders who have the most potential to live independently. Such children are more at risk because they have as many of the rituals and lack of social skills as children with full autism, but they are more likely to be mainstreamed in school, since they are on the higher-functioning end of the autism spectrum. Children with autism have more difficulty attending to social cues, and so may not always recognize when they are being bullied.\n\nChildren with Down syndrome have increased difficulty forming friendships. They experience a language delay causing them to have a harder time playing with other children. Most children with Down syndrome may prefer to watch other students and play \"alongside\" a friend but not \"with\" them, mostly because they understand more than they can outwardly express. In preschool years, children with Down syndrome can benefit from the classroom setting, surrounded by other children and less dependent on adult aid. Children with this disability benefit from a variety of interactions with both adults and children. At school, ensuring an inclusive environment in the classroom can be difficult, but proximity to close friends can be crucial for social development.\n\nStudies have found that strong social supports improve a persons's prospects for good health and longevity. Conversely, loneliness and a lack of social supports have been linked to an increased risk of heart disease, viral infections, and cancer, as well as higher mortality rates overall. Two researchers have even termed friendship networks a \"behavioral vaccine\" that boosts both physical and mental health. \n\nThere is a large body of research linking friendship and health, but the precise reasons for the connection remain unclear. Most of the studies in this area are large prospective studies that follow people over time, and while there may be a correlation between the two variables (friendship and health status), researchers still do not know if there is a cause and effect relationship, such as the notion that good friendships actually improve health. A number of theories have attempted to explain this link. These theories have included that good friends encourage their friends to lead more healthy lifestyles; that good friends encourage their friends to seek help and access services when needed; that good friends enhance their friends' coping skills in dealing with illness and other health problems; and that good friends actually affect physiological pathways that are protective of health.\n\nThe lack of friendship has been found to play a role in increasing risk of suicidal ideation among female adolescents, including having more friends who were not themselves friends with one another. However, no similar effect was observed for males. Having few or no friends is a major indicator in the diagnosis of a range of mental disorders.\n\nHigher friendship quality directly contributes to self-esteem, self-confidence, and social development. A World Happiness Database study found that people with close friendships are happier, although the absolute number of friends did not increase happiness.Other studies have suggested that children who have friendships of a high quality may be protected against the development of certain disorders, such as anxiety and depression. Conversely, having few friends is associated with dropping out of school, as well as aggression, and adult crime. Peer rejection is also associated with lower later aspiration in the workforce, and participation in social activities, while higher levels of friendship was associated with higher adult self-esteem.\n\nThe dissolution of a friendship may be viewed as a personal rejection, or may be the result of natural changes over time, as friends grow more distant both physically and emotionally. The disruption of friendships has been associated with increased guilt, anger and depression, and may be highly stressful events, especially in childhood. However, potential negative effects can be mitigated if the dissolution of a friendship is replaced with another close relationship.\n\nFriends tend to be more similar to one another in terms of age, gender, behavior, substance abuse, personal disposition, and academic performance. In ethnically diverse countries, there is broad evidence that children and adolescents tend to form friendships with others of the same race or ethnicity, beginning in preschool, and peaking in middle or late childhood.\n\nIn general, female-female friendship interactions among children tend to be more focused on interpersonal connections and mutual support, while male-male interaction tends to be more focused on social status, and may actively discourage the expression of emotional needs. Females report more anxiety, jealousy, and relational victimization and less stability related to their friendships, and males report higher levels of physical victimization. Although males and females tend to report comparative levels of satisfaction with their friendships.\n\nAmong older adults, women tend to be more socially adept than their male peers, and many older men may rely upon a female companion, such as a spouse, in order to compensate for their comparative lack of social skills.\n\nFriendship is also found among animals of higher intelligence, such as higher mammals and some birds. Cross-species friendships are common between humans and domestic animals. Cross-species friendships may also occur between two non-human animals, such as dogs and cats. Research by McLennan measured the heart rates of cattle, and showed that the cows were more stressed when alone or with an unfamiliar cow than they were with friends, lending support to the idea that cows are social animals, capable of forming close bonds with each other.\n\n\n"}
{"id": "24849606", "url": "https://en.wikipedia.org/wiki?curid=24849606", "title": "Globalization and women in China", "text": "Globalization and women in China\n\nThe study of the impact of globalization on women in China examines the role and status of Chinese women relative to the political and cultural changes that have taken place in the 20th century as a consequence of globalization. Globalization refers to the interaction and integration of people, products, cultures and governments between various nations around the globe; this is fostered by trade, investment, and information technology. Globalization affected women's rights and the gender hierarchy in China, in aspects of domestic life such as marriage and primogeniture, as well as in the workplace. These changes altered the quality of life and the availability of opportunities to women at different junctures throughout the modern globalization process.\n\nThe dynamics of gender inequity are related with the ideological principles held by the ruling political regime. The imperial era was dominated by the social paradigm of Confucianism, which was a pervasive philosophy throughout the Orient. Confucian ideals emphasized morality, character, social relationship, and the status quo. Confucius preached \"jen\" (humanity) and the equality and educability of all people; Neo-Confucianists and Imperial leaders used his beliefs in social hierarchy, particularly in the family setting, for the physical and social oppression of women. As the Chinese government began to re-assimilate themselves into the global community in the late 19th to early 20th century, it shifted away from conventional Confucian ideals and women's role in society changed as well. After Mao Zedong established the People's Republic of China in 1949, a change in traditional gender roles came about. Mao's death marked the beginning of the current communist administration, and an influx of international communications in the areas of commerce, politics and social ideals. Since the 1980s, under the new communist party, the women's rights movement has gained momentum and has become a national issue as well as a sign of modernization.\n\nIn rural areas, women traditionally work alongside their family to produce crops like tea and rice. In urban areas, women work in factories, living away from home. Most of these factory workers are young girls who send their income to their families. To help maintain the rights of women in factories, labor unions and organizations were built. In their homes, women take care of their children and cook.\n\nWestern scholarship has historically used ideas of subordinance and victimization to characterize traditional Chinese womanhood. These beliefs were largely constructed on the basis of ideological and political agendas, and were widely accepted despite their ethnocentrism. Early European writings pertaining to Chinese women were produced by missionaries and ethnologists at the conclusion of the 19th century. The goal of the missionaries was to \"civilize China,\" and highlighting weakness and victimization provided for the continuance of their work. This belief prompted scholars to use female subordination as a means to validate Western ideas about Chinese culture and Confucian principles.\n\nIn the 1970s, as the feminist movements were forming, they began to affect the literature surrounding women in China. Studies on Chinese women from this period were concerned with women's liberation, and were sympathetic to the feminist movement. This sentiment largely influenced the topics and methodology of the research. With this shift in perspective, the focus of discourse remained on subordination, patriarchal oppression, and victimization. These studies examined such issues as foot binding and the chastity of widows. Literature formulated by feminist writers did nothing to dispel the myth of the weak, subservient woman. These works provided a new bias that had not before been articulated. Feminists believed that Chinese women were a part of a \"universally subordinated womanhood\". This line of thinking illustrates the cultural superiority inherently felt by Western women. Writings on Chinese woman rarely account for differences in time, ethnicity, class, region or age, preferring to describe the status of women as a static, unitary fixture of Chinese culture, despite the political and geographic boundaries that defined different regions and the economic and social changes that occurred throughout history.\n\nFrom the Han Dynasty (206 BC-220 CE) until the modern period (1840–1919), scholars and rulers developed a male-dominated patriarchal society in China. Patriarchy is a social and philosophical system where men are considered as superior to women, and thus men should have more power in decision-making than women. Confucianism was at the root of the development of the patriarchal society in China, and emphasized the distinctions between the sexes and the roles they have within the family. These ideologies continued through the Tang dynasty (618-907), and girls were taught from a very young age to be submissive to their fathers, then to their husbands, and later to their sons. During the Song Dynasty (960-1297), Confucian scholars further developed the patriarchal tradition with more restrictions for females, including foot binding for girls at a very young age.\n\nThe traditional Chinese marriage system benefitted men more than women. This effect could be seen in monogamy, concubinage, divorce, and the heritage of lineage and property through males. After the Spring and Autumn Period, elite men could take primary and secondary wives, concubines, and maids. Ancient Chinese women were denied the right to choose their marriages. Generally, traditional Chinese marriage was organized by the parents of the groom and bride in order to obtain alliances between the two families to ensure the continuance of the family line. The prime mission of a married woman, regardless of her social status, was to bear at least one son in order to carry on the family name. Therefore, women were only valued for their reproduction functions. Three types of marriage dominated in Ancient China. The first traditional Chinese marriage type, which originated in the primitive society, was called a \"capture marriage,\" in which the groom would go to his prospective bride's house at dusk to \"kidnap\" her. The second type was called a \"purchase marriage,\" in which women were paid for by their husbands. Once women were purchased, they became their husband's possession and could be traded or sold. The third type was the \"arranged marriage,\" which could be traced back to the Warring States, emphasized the necessity of parental control and matchmaking institutions. Matchmakers acted as go-betweens for both families. If there was not a matchmaker, the marriage could be deemed unacceptable and could be dissolved. Once two people were married, the wife would leave her family, live with the husband's family, and be obedient to her in-laws as if they were her own parents.\n\nDuring the Chou Dynasty, the upper class considered daughters-in-law as commodities of the husband's parents, not the husbands. This meant that wives had to be subservient to parents-in-law. They were expected to have impeccable manners, including refraining from coughing and sneezing in the presence of their husbands' parents. Wives could not leave their rooms or accept gifts from relatives without permission. Refusal to turn gifts over to parents-in-law lead to physical abuse and expulsion from the family. In addition, wives were required to serve in-laws, including helping them bathe, arranging their bedding, and cooking. People placed a strong emphasis on food preparation in Ancient China. Cooking was one of the most time-consuming tasks for wives because of traditional rituals and high expectations for the taste and appeal of food.\n\nThe \"New Culture\" movement began in China around 1916 following the unsuccessful activities of the 1911 Revolution to establish a republican government, and continued through the 1920s. The May Fourth Movement, which took place on May 4, 1919, was a demonstration led by students at the National Peking University against the government, in which they protested the abolition of Confucianism and changes in the traditional value system. Many believed that the solution to China's problems would be to adopt Western notions of equality and democracy. Since the movement stressed group efforts and propaganda, women were involved in numerous collective tasks such as publication, drama production, and fund raising, which helped them gain more social contact with men and win respect.\n\nChinese modern heterosexual monogamous marriage was officially established with the Marriage Law of 1950 after the founding of the People's Republic of China. The New Marriage Law declared the abolition of the feudal marriage system, which included arranged and forced marriage, male superiority, and the disregard for the interests of children. This law also asserted the rights to divorce and embraced the free-choice marriage. Although progress has been made, Chinese women are restricted by the heteronormative and hypergamous marriage system. Currently, all Chinese women are still expected to marry a man with superior educational and economic status in their early or mid-twenties. Many well-educated and well-paid urban professional women tend to delay their partner seeking and marriage, which results in a supposed revival of tradition – parental matchmaking. Since Chinese parents generally do not \"use a daughter's marriage to build a family network or maintain a household's social status\" anymore, this matchmaking is not a forced marriage; it is a suggestion intended to benefit their daughters.\n\nAs a result of these reforms, the roles of wives have changed for both rural and urban women. Today, a wife's role is to support her husband and children, not serve her in-laws. Mothers-in-law have less authority, and married couples are able to have more intimate relationships. Since the one-child policy was established, urban wives have devoted their time to raising \"'the perfect only child,'\" so they now exert more effort creating their own families than serving in-laws. Despite this focus on children, patrilocal residence increased again towards the end of the twentieth century. Urban parents have stayed close to their sons to help them find jobs, housing, and services. Rural women have also gained more autonomy, including the freedom to voice their opinions and desires. Wives in the wealthy countryside have demanded construction of mansions for neolocal residences.\n\nFoot binding is the process in which the arch of a woman's feet is broken and the toes are wrapped up against the foot to create a smaller looking foot with an acute arch. These \"fists of flesh\" were seen as attractive and arousing for men and the practice was passed down as a prerequisite to marriage from mother to daughter across generations. The process of foot binding was painful and often confined women to their rooms. Few lower class women were able to have their feet bound because they needed to be able to walk normally to accomplish house work. Bound feet came to be an indication of high class and wealth for women. Chinese male reformers during the imperialism period recognized the liberation of the Chinese women as something necessary for their own sake. The humiliation that China had gone through on an international level was turned on the Chinese \"women\". Naturally, the foot binding was recognized as \"national shame,\" and people found it as a serious problem to be disappeared, thus raging anti-footbinding campaigns in the 1890s to the 1900s. Moreover, the new government that came in after the 1911 revolution banned foot binding practice. Thus, it started to disappear in the coastal areas in 1900 to 1920. However, the practice was still popular within the interior areas of China till the 1930s and even in the 1950s.\n\nUnder Confucianism the typical family was patriarchal because men had the capability to pass on the family name and carry on the lineage of the ancestors; women were expected to be subservient. Adoption of Western family values in the twentieth century challenged traditional Chinese values. Nationalism contributed to the changes of customs and status of women. Nationalist revolutionary Qiu Jin promoted feminism through various essays and speeches, as well as through her \"Chinese Women's Journal\". Jin chastised wife beating, female infanticide, arranged marriages, and foot binding. She eventually began teaching at a girls' school. Around this time, many other schools for girls opened in China. This led to increased job opportunities for women in the 1920s.\n\nLater, as the Communist regime changed the structure of Chinese society through economic reform, the structure of the Chinese family was altered. \"The Four Olds\" (\"sijiu\") – old ideas, old habits, old customs, old cultures – were discouraged and were replaced by Communist ideology, particularly during the Cultural Revolution. The economy was shifted to total government control with few chances to own private property and communal property. Collectivization destroyed \"clan-based\" systems and had a great effect on motivation of workers and family loyalties.\n\nThe traditional social structure was further degraded by the Cultural Revolution. The Red Guards turned members of a family against one another as they sought out \"class enemies\" to be sent for \"re-education,\" ultimately resulting in a loss of family ties. Women were elevated to equal status as men through a series of laws which prohibited practices such as arranged marriages, concubinages, dowries, and child betrothals. Under these marriage laws, women enjoyed joint property in marriage and could file for a divorce.\n\nAs a result of Communist rule in China, the social status of women improved greatly. Women were empowered to work outside the home. Communist rule also brought about the end of practices such as foot binding, child marriages, prostitution, and arranged marriages. China has seen a decrease in domestic violence due to government-supported grassroots programs to counter these practices. Women in rural areas remain largely uneducated.\n\nDuring the reform period, the Communist regime in China regulated birth control. The government shaped policies with the intention to develop population science “through selective absorption of Western science and technology.” In 1979, the Planned Birth Policy was implemented. The Chinese government only allowed one child per Han family, with more children allowed to non-Han families. Since this planned birth policy was implemented based on local laws rather than on a national population law, the level of birth restriction differed in urban and rural areas. In families reliant on farming for income, the household is the fundamental unit of production, so many rural families would rather pay the hefty fines for excess birth.\n\nIn 2011, city couples who both came from one-child families were allowed to have a second child, while couples in rural areas could have a second if just one of them came from a one-child family. In 2013, the further revision of the Planned Birth Policy allowed couples in which either parent had no siblings to have two children. In 2015, China allowed all couples to have two children, abolishing its decades-long one-child policy for urban families.\n\nAnother instance of population control is the prevalence of female infanticide. People in rural areas practiced female infanticide and selective neglect due to a preference of sons over daughters. Since the 1980s, roughly 200,000 female infants would be killed per year because of the preference for male children and the advancement in technologies such as ultrasound, which help to find out the sex of the fetus. In addition to female infanticide, girls are being unregistered or are abandoned by their families, which stops them from receiving education and legal benefits the government offered. These methods of controlling population have resulted in a huge gender gap in China.\n\nIn the imperial era, women experienced physical restrictions that limited their social positions. They held jobs that required minimal physical activity like domestic chores and producing textiles to sell or use.\n\nDuring Mao's rule (1949–1976), Chinese women were needed for their manual labor for farming and for urban industrialization. To compensate for their hard work, they were provided access to education and politics. The Chinese government supported women's education. The percentage of girls attending school was 96.2% compared to below 20% before the People's Republic (1949). The Chinese government has tried to decrease the number of women illiterates while promoting adult and vocational schools. The percentage number of illiterates has gone down from 90% in 1949 and 32% from 1993. In the first 30 years of Communist rule women's discrimination was decreasing, but they did not have jobs that had real decision-making power.\n\nThe Chinese government has made great efforts to achieve a high level of economic status for women. Since 1949, with the founding of the People' Republic, the rate for employed women has risen. Chinese women account for 44% of the work force and 34.5% account for the women's work force in the world.\n\nThe key role women have in farming is to maintain ownership of the main sources of production in rural areas. In traditional China, women were not allowed to own land or property. Land was inherited through the sons, and if there was no son in the family, it was taken by a close male relative. In less populated areas, women do more agricultural work than men because of shifting cultivation. In more populated areas, men do more work than women because extensive plough cultivation is used. Female involvement is high in the double-cropping rice area. Other types of work women perform in the countryside include pig and poultry rearing, spinning, weaving, basket-making, and other handicrafts. This type of work supplements agricultural income.\nChina's economic policies laid the basis of the industrialization drive in export-oriented development, and its reliance on low-wage manufacturing to produce consumer goods for the world market. Young migrant women left their homes in rural settings to work in urban industrial areas. Work included export-oriented industrialization, manufacturing in electronics and toy assembly, sewing in garment production, and mixed assembly and sewing in the footwear industry. Hong Kong and Shenzhen were cities established as centers of export-oriented industrialization, and migrant women workers have made up 70% of Shenzhen's three million people.\n\nPrivate sector employers are reluctant to hire women because Chinese law requires that the employer cover maternity leave and childbirth costs. However, certain industries prefer female workers for assumed benefits. For example, the beauty economy, which is defined as \"a marketplace in which young, attractive women are used to promote commercial products and services,\" includes the sales industry. The development of the sales industry has increased job opportunities for women, but women are also restricted to these gendered professions.\n\nA recent phenomenon, the migration of rural Chinese workers began in 1984 when the Regulations of Permanent Residence Registration became less punitive and allowed people to move to find employment. People left rural areas to escape poverty, and females left due to the lack of local opportunities for women. In the cities, women could find new, low-paid factory-based jobs that did not require highly skilled workers. According to national statistics, the ratio of male to female migrant workers averages 2:1, and an estimated 30-40 million of the migrant women work in the cities, namely Hong Kong and Shenzhen.\n\nIn the Nanshan district of Shenzhen, females comprised 80% of the workforce and had an average age of 23. Young female workers are preferred over older females or males for several reasons. First, as married women are less mobile, female migrant workers are younger and more likely to be single than their male counterparts. Young rural women are preferred for these jobs primarily because they are less likely to get pregnant, and are able and willing to withstand longer working hours, have \"nimble fingers, and will be less experienced in asking for their statutory rights. In many cases, migrant women sign contracts stating that they will not get pregnant within their period of employment.\"\n\nIn the interest of the family, rural females are sent to find urban employment over male counterparts, mainly to supplement familial income at home and to support the males, who are more likely to attend college. The male standard of education in China is higher, particularly when a family is under financial stress, females are more likely to drop out of school to generate income for the family. Because females have lesser impact on the family's long-term financial stability, their rights for opportunities development are consequently unequal. This inequality also reinforces emotional motivations for migration. Many women migrate to find personal fulfillment. Stereotypes in China that developed as a result of globalization portray rural women as \"‘backward’\" and urban women as \"‘modern’\". Many people associate modernity with maturity, so rural women migrate to cities to be perceived as mature. Migrant women also appreciate the knowledge they obtain (including political- and self-awareness) while living in cities. Some women even report desiring to leave villages as a result of boredom with rural life. Ideas perpetuated due to globalization simultaneously increased women's intentions to become independent; many migrant workers desire lives separate from those of their families’.\n\nThis new system allowed rural residents to migrate, it did not allow them to change their residence or accept any benefits in the cities. This resulted in a growing population of migrant laborers without the minimal benefits of residency including medical care, housing, or education. Many migrant women do not trust the government to protect their rights. Today, up to 90% of migrants work without contracts, in violation of the Chinese labour law.\n\nThe freedom to display femininity and gender equality seem incompatible in Chinese society. Gender equality appeared prevailing only when women were restricted to desexualization in the Mao era. Opening up policy guarantees women's freedom for resexualization, but it simultaneously brings back gender inequality.\n\nWomen factory workers are known as \"dagongmei\" (working girls). They are traditionally young women migrants who experience a segmented labor market in informal and low-wage employment sectors. Workers in export-oriented factories receive minimum wage and minimum overtime pay, they pay for meals and lodging at the factory, and they pay fines for breaking factory rules. The average daily wage, for a 12-hour day in a toy factory, in the mid-1990s was $1.10 USD for migrant women workers in Shenzhen. Although migrant workers in China still earn low wages, their average income has increased over the past several years. In 2008, the average daily income for migrant workers in China was equivalent to $6.48 USD. In 2014, the average daily income was equivalent to $13.86 USD.\n\nThese conditions create \"maximum surplus appropriation\"; workers' daily lives revolve around factory production and are dependent on the economic conditions. The state disallows local unionization and has the All-China Federation of Trade Unions (ACFTU) as the legitimate forum of worker representation. Without the right to form unions and with the state sanctioned ACFTU, migrant women workers find it hard to effectively gain suitable rights and treatment from the factory management. The 2003 statistics from the People's University show 90% of migrants work without contracts, directly violating the Chinese Labour Law. According to the ACFTU, migrant workers are owed over 100 billion Yuan in back wages.\n\nOrganizations are now attempting to assist and empower female migrant workers through training and education on their labor-related rights. Legal clinics have begun to assist female migrants in filing claims against employers and local labor bureaus. One case of female worker exploitation in the Hua Yi garment factory in Beijing resulted in mistreatment by management as well as withholding pay for at least 24 women. After filing complaints, in collaboration with the Center for Women's Law Studies and Legal Services of Beijing University, the women received 170,000 Yuan in back wages and compensation.\n\nRelations between workers and employers represent both the immediate need of manufacturing plants for large quantities of low wage laborers, and the insecurities young workers face in relocating long distances to life in factory dormitories. Hiring single young women serve needs of management. The employment of young females allow management to exhibit maximum control and authority over the labor force. Compared to older women and male workers, young single women are susceptible to the authority and demands of management. The common manipulation of \"factory as family\" by owners and managers suggests how workers hold a subliminal status within the factory environment. Uneven power relations inside the factory result in demands from management for personal services from women workers, from hair washing to sex.\n\n"}
{"id": "1219810", "url": "https://en.wikipedia.org/wiki?curid=1219810", "title": "Historic preservation", "text": "Historic preservation\n\nHistoric preservation (US), heritage preservation or heritage conservation (UK), is an endeavour that seeks to preserve, conserve and protect buildings, objects, landscapes or other artifacts of historical significance.\nThis term refers specifically to the preservation of the built environment, and not to preservation of, for example, primeval forests or wilderness.\n\nIn England, antiquarian interests were a familiar gentleman's pursuit since the mid 17th century, developing in tandem with the rise in scientific curiosity. Fellows of the Royal Society were often also Fellows of the Society of Antiquaries.\n\nMany historic sites were damaged as the railways began to spread across the UK; including Trinity Hospital and its church in Edinburgh, Furness Abbey, Berwick and Northampton Castle, and the ancient walls of York, Chester and Newcastle. In 1833 Berkhamsted Castle became the first historic site in England officially protected by statute under the London and Birmingham Railway Acts of 18331837, though the new railway line in 1834 did demolish the castle's gatehouse and outer earthworks to the south.\nAnother early preservation event also occurred at Berkhamsted. In 1866, Lord Brownlow who lived at Ashridge, tried to enclose the adjoining Berkhamsted Common with steel fences in an attempt to claim it as part of his estate. In England from early Anglo-Saxon times, Common land was an area of land which the local community could use as a resource. Across England between 1660 and 1845, 7 million acres of Common land had been enclosed by private land owners by application to parliament. On the night of 6 March 1866, Augustus Smith MP led gangs of local folk and hired men from London's East End in direct action to break the enclosure fences and protect Berkhamsted Common for the people of Berkhamsted in what became known nationally as the Battle of Berkhamsted Common. In 1870, Sir Robert Hunter (later co-founder of the National Trust in 1895) and the Commons Preservation Society succeed in legal action that ensured protection of Berkhamsted Common and other open spaces threatened with enclosure. In 1926 the common was acquired by the National Trust.\n\nBy the mid 19th century, much of Britain's unprotected cultural heritage was being slowly destroyed. Even well-meaning archaeologists like William Greenwell excavated sites with virtually no attempt at their preservation, Stonehenge came under increasing threat by the 1870s. Tourists were chipping off parts of the stones or carving their initials into the rock. The private owners of the monument decided to sell the land to the London and South-Western Railway as the monument was \"not the slightest use to anyone now\". John Lubbock, an MP and botanist emerged as the champion of the country's national heritage. In 1872 he personally bought private land that housed ancient monuments in Avebury, Silbury Hill and elsewhere, from the owners who were threatening to have them cleared away to make room for housing. Soon, he began campaigning in Parliament for legislation to protect monuments from destruction. This finally led to the legislative milestone under the Liberal government of William Gladstone of the Ancient Monuments Protection Act 1882. The first government appointed inspector for this job was the archaeologist Augustus Pitt-Rivers. This legislation was regarded by conservative political elements as a grave assault on the individual rights of property of the owner, and consequently, the inspector only had the power to identify endangered landmarks and offer to purchase them from the owner with his consent. The Act only covered ancient monuments and explicitly did not cover historic buildings or structures. In 1877 the Society for the Protection of Ancient Buildings was founded by the Arts and Crafts designer William Morris to prevent the destruction of historic buildings, followed by the National Trust in 1895 that bought estates from their owners for preservation.\n\nThe Ancient Monuments Protection Act 1882 had only given legal protection to prehistoric sites, such as ancient tumuli. The Ancient Monuments Protection Act 1900 took this further by empowering the government's Commissioners of Work and local County Councils to protect a wider range of properties. Further updates were made in 1910.\nTattershall Castle, Lincolnshire, a medieval manor house had been put up for sale in 1910 with its greatest treasures, the huge medieval fireplaces, still intact. However, when an American bought the house they were ripped out and packaged up for shipping. The former viceroy of India, George Curzon, 1st Marquess Curzon of Kedleston, was outraged at this cultural destruction and stepped in to buy back the castle and reinstall the fireplaces. After a nationwide hunt for them they were finally found in London and returned. He restored the castle and left it to the National Trust on his death in 1925. His experience at Tattershall influenced Lord Curzon to push for tougher heritage protection laws in Britain, which saw passage as the Ancient Monuments Consolidation and Amendment Act 1913.\n\nThe new structure involved the creation of the Ancient Monuments Board to oversee the protection of such monuments. Powers were given for the board, with Parliamentary approval, to issue preservation orders to protect monuments, and extended the public right of access to these. The term \"monument\" was extended to include the lands around it, allowing the protection of the wider landscape.\n\nThe National Trust was founded in 1894 by Octavia Hill, Sir Robert Hunter, and Hardwicke Canon Rawnsley as the first organisation of its type in the world. Its formal purpose is: The preservation for the benefit of the Nation of lands and tenements (including buildings) of beauty or historic interest and, as regards lands, for the preservation of their natural aspect, features and animal and plant life. Also the preservation of furniture, pictures and chattels of any description having national and historic or artistic interest.\n\nIn the early days, the Trust was concerned primarily with protecting open spaces and a variety of threatened buildings; its first property was Alfriston Clergy House and its first nature reserve was Wicken Fen. Its first archaeological monument was White Barrow. The focus on country houses and gardens, which now comprise the majority of its most visited properties, came about in the mid 20th century, when it was realised that the private owners of many of these properties were no longer able to afford to maintain them.\n\nThe Town and Country Planning Act 1944 and the Town and Country Planning Act 1990 took steps toward historic preservation on an unprecedented scale. Concern about the demolition of historic buildings arose in institutions such as the pressure group the Society for the Preservation of Historic Buildings, which appealed against demolition and neglect on a case by case basis.\n\nEnglish Heritage formed in 1983, is a registered charity that looks after the National Heritage Collection in England. This comprises over 400 of England's historic buildings, monuments and sites spanning more than 5,000 years of history. Within its portfolio are Stonehenge, Dover Castle, Tintagel Castle and the best preserved parts of Hadrian's Wall.\n\nOriginally English Heritage was the operating name of an executive non-departmental public body of the British Government, officially titled the Historic Buildings and Monuments Commission for England, that ran the national system of heritage protection and managed a range of historic properties. It was created to combine the roles of existing bodies that had emerged from a long period of state involvement in heritage protection. In 1999 the organisation merged with the Royal Commission on the Historical Monuments of England and the National Monuments Record (England), bringing together resources for the identification and survey of England's historic environment. On 1 April 2015, English Heritage was divided into two parts: Historic England, which inherited the statutory and protection functions of the old organisation, and the new English Heritage Trust, a charity that would operate the historic properties, and which took on the English Heritage operating name and logo. The British government gave the new charity an £80 million grant to help establish it as an independent trust, although the historic properties remained in the ownership of the state.\n\nIn the United States one of the first historic preservation efforts was the\nWashington's Headquarters State Historic Site, in Newburgh, New York. This property has the distinction of being the first-ever property designated and operated as a historic site by a U.S. state, having been so since 1850.\n\nAnother early historic preservation undertaking was that of George Washington's Mount Vernon in 1858. Founded in 1889, the Richmond, Virginia-based Preservation Virginia (formerly known as the Association for the Preservation of Virginia Antiquities) was the United States' first statewide historic preservation group. The American Scenic and Historic Preservation Society was formed in 1895 as the first American organization of its kind in the United States that did not limit its activities to a single historic place or object. The Society operated as a national organization to: protect the natural scenery and the preservation of historic landmarks; to preserve landmarks and records of the past or present; to erect memorials and promote appreciation of the scenic beauty of America.\n\nCharles E. Peterson was an influential figure in the mid-20th century establishing the Historic American Buildings Survey (HABS), advising on the establishment of Independence National Historical Park, helping with the first graduate degree program in historic preservation in the United States at Columbia University, and author.\n\nThe architectural firm of Simons & Lapham (Albert Simons and Samuel Lapham) was an influential supporter of the nation's first historic preservation ordinance in Charleston, South Carolina in 1930, affording that city a regulatory means by which to prevent the destruction of its historic building stock. In 1925, efforts to preserve the historic buildings of the French Quarter in New Orleans led to the creation of the Vieux Carré Commission and later, to the adoption of a historic preservation ordinance.\n\nThe US National Trust for Historic Preservation, another privately funded non-profit organization, began in 1949 with a handful of structures and has developed goals that provide \"leadership, education, advocacy, and resources to save America's diverse historic places and revitalize our communities\" according to the Trust's mission statement. In 1951 the Trust assumed responsibility for its first museum property, Woodlawn Plantation in northern Virginia. Twenty-eight sites in all have subsequently become part of the National Trust, representing the cultural diversity of American history. In New York City, the destruction of Pennsylvania Station in 1964 shocked many nationwide into supporting preservation. The 1960s proved advantageous with new laws and international agreements extending preservation \"from ancient monuments to whole districts and buildings a few decades old.\" On an international level, the New York-based World Monuments Fund was founded in 1965 to preserve historic sites all over the world.\n\nUnder the direction of James Marston Fitch, the first advanced-degree historic preservation program began at Columbia University in 1964. It became the model on which most other graduate historic preservation programs were created. Many other programs were to follow before 1980: M.A. in Preservation Planning from Cornell (1975); M.S. in Historic Preservation from the University of Vermont (1975); M.S. in Historic Preservation Studies from Boston University (1976); M.S. in Historic Preservation from Eastern Michigan University (1979) and M.F.A. in Historic Preservation was one of the original programs at Savannah College of Art & Design. James Marston Fitch also offered guidance and support towards the founding of the Master of Preservation Studies Degree within the Tulane School of Architecture in 1996. The M.Sc. in Building Conservation degree program is offered by the School of Architecture at Rensselaer Polytechnic Institute in Troy, New York. In 2005, Clemson University and the College of Charleston created an M.S. degree program based in Charleston, SC. The first undergraduate programs (B.A.) appeared in 1977 from Goucher College and Roger Williams University (then called Roger Williams College), followed by Mary Washington College in 1979. there were more than fifty historic preservation programs offering certificates, associate, bachelor's, and master's degrees in the United States.\n\nIn Canada, the phrase \"heritage preservation\" is sometimes seen as a specific approach to the treatment of historic places and sites, rather than a general concept of conservation. \"Conservation\" is taken as the more general term, referring to all actions or processes that are aimed at safeguarding the character-defining elements of a cultural resource so as to retain its heritage value and extend its physical life.\n\nHistoric objects in Canada may be granted special designation by any of the three levels of government: the central government, the provincial governments, or a municipal government.\nThe Heritage Canada Foundation acts as Canada's lead advocacy organisation for heritage buildings and landscapes.\nVictor de Stuers is widely considered the man who started historic preservation in the Netherlands. In 1875 the first national department for conservation was established and de Stuers was appointed as the first legal secretary at the Ministry of Home Affairs as chief of the brand new Department of Arts and Sciences. He was the driving force behind \"Monumentenzorg\" (Foundation for Historic Preservation), helped found the \"Rijksmuseum\" (National Museum) and the \"Rijksarchief\" (National Archives).\n\nHowever, it was not until the 20th century that there was national legislation on historic preservation. In 1961 the (“Monuments Act”) was passed. It defined that any physical building or space that was at least fifty years old and “which are of general interest because of their beauty, their meaning to science or their social value” and must thus be preserved. In 1988 this Act was replaced by the \"\" (“Monuments Act 1988”) and in 2015 by the \"\" (“Heritage Law”).\n\nIn 1973, the NGO \"Monumentenwacht\" (“Monument Watch”) was founded with the purpose of providing preventative measures of maintenance for historic buildings. As the majority of the historic preservation programs in the Netherlands, this program is decentralized, managed on the provincial level. Owners of heritage buildings can subscribe to the services of Monumentenwacht and receive regular visits for inspection. The costs are covered through a combination of national and provincial subsidies.\n\nA special kind of preservation that takes place in the Netherlands is the preservation of maritime heritage. Maritime trade was the Dutch specialty which shaped much of their culture and as a country that is 50% under sea level the Dutch history is closely intertwined with water. There are maritime museums in both Amsterdam and Rotterdam that tell the story of the Dutch maritime heritage, but there is not much legal documentation on how to preserve it. For example, according to Sarah Dromgoole, shipwrecks from The Dutch East India Company are found all around the world, which are still property of the Netherlands, but the Dutch government rarely takes responsibility for this property that is found outside of their territory.\n\nIn Macedonia, historic preservation falls under the overarching category of cultural heritage preservation according to the Law on Protection of Cultural Heritage (Закон за заштита на културното наследство). According to this law, which the Macedonian Parliament approved in March 2004, there are three types of cultural heritage: immovable, movable, and intangible. Historical preservation is represented by the protection of monuments and monumental entireties under immovable cultural heritage, and historical items under movable cultural heritage.\n\nAlthough this Law was the first nation-wide establishment of regulations for historic preservation since the Republic of Macedonia gained independence from Yugoslavia on September 8, 1991, several organizations throughout the 20th century have encompassed efforts of historic preservation.\n\nThe “Central office for protection of cultural monuments and natural rarities of the Socialist Republic of Macedonia” has existed since 1949. In 1960, the Central Office was renamed to “National office for protection of cultural monuments”, and granted the status of an independent cultural institution, with authority to execute activities of historic preservation. After the establishment of the Law on Protection of Cultural Heritage in 2004, the Ministry of Culture once again renamed the office to “National center for conservation” and narrowed down its responsibilities to dealing solely with preservation of immovable cultural heritage.\n\nOther organizations which have contributed to the efforts of historic preservation are the Macedonian National Committee of ICOMOS and the NI Institute for Protection of Monuments of Culture and Museum-Ohrid.\n\nThe International Council on Monuments and Sites (ICOMOS) established their branch in Macedonia in 1995 through the initiative of 43 conservationists from Macedonia. The guiding principles of the Macedonian National Committee of ICOMOS are raising the national consciousness about the importance of historic and cultural heritage, decentralization of the discourse about heritage, and effective monitoring of the status of cultural and historic heritage in the country.\n\nThe NI Institute for Protection of Monuments of Culture and Museum - Ohrid is the second oldest institutions for historical preservation established in 1952. In 1956 the Institute was granted authority to protect movable and immovable cultural and historic heritage in the Ohrid region. The Institute has since executed numerous efforts for historic preservation, most notably aiding the recognition of the city of Ohrid as a UNESCO site of cultural heritage in 1979.\n\nToday, the main authority for historic preservation is the Cultural Heritage Protection Office (Управа за заштита на културно наследство). The Office is an independent governmental organization under the Ministry of Culture, divided into three departments:\n\nIn Israel, there are currently two laws concerning historic preservation, Antiquities Law of the State of Israel (1978) and Planning and Building Law (1965). Both laws were adapted from the British law that was implemented during the British Mandate of Palestine.\n\nHowever, these laws are not comprehensive and limited in scope: the Antiquities Law only applies itself to buildings or artifacts dated before 1700 BC. So while efforts discovering and protecting anything older than 1700 BC are well protected, anything from later historical periods is not under the protection of this law. The Planning and Building Law discusses the overall management and regulation of land use in Israel. It has been through several changes and amendments specifically regarding preservation, but over the years it hasn't been enforced and many historical sites were destroyed, as the state was prioritizing developmental and economic interests.\n\nDuring the 1960s, the issue of preservation was gaining public awareness, and as a response to the destruction of Herzliya Hebrew Gymnasium (one of the first educational institutions in Israel) in 1959, a wave of shock and anger led to extensive public debate.\n\nIn 1984, The Council for Conservation of Heritage Sites in Israel was established, at the recommendation of the Knesset and the Committee of Education. Its aims include locating remains of historic settlements, protect and conserve them as well as developing conservation principles that are specific to Israel’s historic situations and are aligned with international standards. The council used to operate under the Society for the Protection of Nature in Israel but in 2008 registers as an independent non-profit. Today, it is the organization responsible for the most historical preservation endeavors as well as efforts to add amendments to existing laws to provide a comprehensive and effective framework for preservation in Israel.\n\nA different, separate effort in preservation comes from the Israeli Defense Force (IDF). The IDF surveyed 94 military bases and found that about 80 of them include sites worth preserving, and for each of these bases there is a preservation plan. The IDF is working towards maintaining these building as well as communicating their value to the soldiers in these bases. Buildings include Knights Templar sites, old military bases used by the British or German or buildings from the Ottoman period.\n\nA historic district in the United States is a group of buildings, properties, or sites that have been designated by one of several entities on different levels as historically or architecturally significant. Buildings, structures, objects and sites within a historic district are normally divided into two categories, contributing and non-contributing. Districts greatly vary in size, some having hundreds of structures while others have just a few.\n\nThe U.S. federal government designates historic districts through the U.S. Department of Interior, under the auspices of the National Park Service. Federally designated historic districts are listed on the National Register of Historic Places. Historic districts allows rural areas to preserve their characters through historic preservation programs. These include \"Main Street\" programs that can be used to redevelop rural downtowns. Using historic preservation programs as an economic development tool for local governments in rural areas has enabled some of those areas to take advantage of their history and develop a tourism market that in turn provides funds for maintaining an economic stability that these areas would not have seen otherwise.\n\nA similar concept exists in the United Kingdom: a Conservation area is designated in accordance with the Planning (Listed Buildings and Conservation Areas) Act 1990 in order to protect a zone in which there are buildings of architectural or cultural heritage interest.\n\nIn 1835, the English poet William Wordsworth described the Lake District as a \"sort of national property, in which every man has a right and interest who has an eye to perceive and a heart to enjoy.\"\n\nIt was, however, the United States that led the world in the creation of National Parks, areas of unspoiled natural wilderness, where the intrusion of civilization are intentionally minimal.\n\nThe department of the interior designated several areas of Morristown, New Jersey as the first historic park in the United States national park system. It became designated as the Morristown National Historical Park. The community had permanent settlements that date to 1715, is termed the military capital of the American Revolution, and contains many designations of sites and locations. The park includes three major sites in Morristown.\n\nIn the United Kingdom, James Bryce the ambassador to the US praised the system of National Parks and campaigned to have them introduced in Great Britain. Little came of it until mounting public pressure during the early 20th century from the Ramblers' Association and other groups led to the National Parks and Access to the Countryside Act 1949.\n\nAccording to UNESCO’s 1972 World Heritage Convention, landscapes and sites of outstanding universal value can be designated as World Heritage Sites. The World Heritage Convention encompasses historic preservation under the category of “cultural heritage”. According to Article 1 of the Convention, monuments, groups of buildings, and sites “which are of outstanding universal value from the point of view of history, art or science” are to be designated cultural heritage.\n\nA requirement of such designation is that the designating nation has appropriate legal, scientific, technical, administrative and financial measures in place to identify, protect, conserve, present, and rehabilitate world heritage sites. However, according to Article 6 of the Convention, while sovereignty of the State where the site is located is not to be compromised, the State acknowledges that protection of heritage sites is a duty of the entire international community.\n\nThe World Heritage convention’s counterpart, The World Heritage Committee, is the body responsible for the practical implementation of the Convention as well as managing and deciding how to use the World Heritage Fund. The Committee also gets to have the final say when determining whether a property will be included in the World Heritage List.\n\nThe Committee meets once a year and includes representatives from 21 states that are part of the States Parties. Yearly reports are available to the public on the World Heritage website and include outlines of decisions made, outcomes, working documents and various reports.\n\nAlthough preservation efforts can have benefits for the owners of historical buildings, such as tax cuts and subsidies, there are also drawbacks.\n\nOne such drawback is that after a neighborhood has been designated to be historically preserved, there is less construction. On the long term this can affect the value of property and investment in housing, both in the neighborhood itself and the neighborhoods directly surrounding it.\n\nA second concern that has been raised is that buildings that need to be historically preserved are sometimes still inhabited. In some cases their inability to make changes to the building can lead to dangerous or unhealthy situations for residents.\n\nIt is not true that nothing could be changed or renovated, but the owner of the building would need to ask permission at the appropriate preservation society, slowing the process down severely. The exact policies are country dependent.\n\n\nAlthough volunteers continue to play a large role in historic preservation activities, the field has seen an increased level of professionalization. Today, there are many career options in historic preservation in the public, non-profit and private sectors. Institutes of secondary education (universities, colleges, etc.) in the United States offer both certificate and degree (A.A.S, B.A., B.F.A., B.S., M.A., M.F.A., M.D.S, M.H.P., M.S., and PhD) programs in historic preservation. Some pupils—at schools with such programmes available—choose to enroll in \"joint degree\" programs, earning a degree in historic preservation along with one in another, related subject, often an MArch, MUP or JD degree.\n\nPossible career fields include:\n\n\n"}
{"id": "55455444", "url": "https://en.wikipedia.org/wiki?curid=55455444", "title": "History of anthropology by country", "text": "History of anthropology by country\n\nAnthropology is the study of various aspects of humans within past and present societies. This study is practiced in multiple countries, each of whom has their own history of how anthropology has developed in their respective countries.\n\nAnthropology in Latin America is a well established discipline that has existed for over 100 years. The countries that are summarized in this section include Mexico, Brazil, Argentina, the Andean region, Costa Rica, and Colombia. Latin America anthropologists established their discipline in conjunction with American and European anthropologists, and revised their disciplines to study cultural phenomena through their own perspectives, independent of American and European thought. \n\nAndean anthropology’s roots began during the turn of the 20th century, containing social movements between two groups in Peru, and from academia within the United States. The mestizo (non-native) and indigenous intellectuals known as indigenistas competed for political and intellectual space and recognition in Peru. Indigenous intellectuals advocated for interculturalidad, where indigenous thought could occupy Peruvian society as its own entity and not become blended as a singular national identity that the mestizaje proposed.\n\nThe mestizaje perspective sought to modernize Peru and model their society similar to the United States. José María Arguedas was a writer and ethnographer in Peru, who classified himself as an indigenous intellectual that challenged Western thought and ideology. John Victor Murra, an anthropologist teaching in the United States collaborated with Arguedas. Their collaboration stemmed from Murra’s travels in 1952 to the Latin American region when he was working under the anthropologist Sidney Mintz as a PhD student. Indigenistas were active in social and political movements in Latin America and collaborated with people inside of the United States, but still sought to be independent from Western thought.\n\nIn 1936, the American Anthropological Association initiated studies in Latin America on how to incorporate indigenous people in Latin American society, termed acculturation studies, and in 1935, the Social Science Research Council, the American Council of Learned Societies, and the Committee on Latin American studies worked to benefit the interests of the United States. The Peruvian government funded anthropological institutions beginning in the 1940s, and the establishment of the Instiuto de Etnologia y Arqueologia and a Peruvian sector in the Instituto Indigneista Interamericano followed. By the 1960s Peruvian governmental funding decreased, and became reliant upon the United States for funding. The indigenous incorporation into the goal of a singular society was termed cholification by the Peruvian sociologist Anibal Quijano. In the 1990s during the Neo-liberal era, indigenous thought became more recognized with political conflicts in the Andean region, and interculturalidad was pursued again for Andean states to recognize the diversity of the people that occupied them.\n\nSocial Anthropology was established in Argentina in 1957. It was first institutionalized at the University of Buenos Aires. Before the institutionalization of social anthropology, the discipline largely focused on historical studies. Rosana Guber attributes the introduction of social anthropology to Esther Hermitte who was a history professor at the Ethnographic Museum in Argentina. It was during her trips to the University of Chicago that she was introduced to social anthropology, and so it was the west who influenced the institutionalization of social anthropology in Argentina. In 1965, students began to ask for a discipline separate from sociology, and that was not focused primarily on indigenous people. There was a movement around this time that called for a greater understanding of the changes modern society was going through, especially during and after the 1966 Revolución Argentina. Later, in 1974, students and faculty within departments that were studying social movements and change suffered kidnappings and murders by the Argentine AntiCommunist Alliance. The current status of Argentinian anthropology is still deeply rooted in western influence.\n\nAnthropology in Brazil was institutionalized in 1930 at the beginning of the Vargas Era. Later during the 1950s and 1960s, Brazil was experiencing political authoritarianism. As a result, anthropology began to address inter-ethnic friction. In the 1970s anthropologists began to consider nearby urban studies as a topic of research. The 1980s kicked off a more modern type of anthropology where anthropologists began to look at themselves as “the other”. Brazil did not have an issue of alterity or exoticism, because it existed within its own borders. Brazil began to value exoticism and viewed it as the acknowledgement of cultural diversity according to . In general, the overall current goal for Brazilian anthropology was to better the future for modernization by enlightening modern political elite and identifying relevant topics for investigation. Some of Brazil’s main anthropological institutions are the University of Brazil, Universidade Federal do Rio de Janeiro, and the Brazilian Association of Anthropology.\n\nAnthropology in Colombia was institutionalized during the mid-1940s. Between the 1950s-70’s, Colombian anthropologists sought to integrate into national society and began to deal with terms like culture, integration, and assimilation. However, during the 1970s, this early understanding of anthropology was opposed and anthropologists began to confront terms such as national integration because they felt it was loaded with other issues like racial supremacy. Emerging social movements encouraged this new way of thinking because it recognized the rights of peasant and ethnic populations as well as the influence of Marxism. Anthropologists continued this way of thinking through the 1980s although a larger influence from militant anthropology became apparent. By militant anthropology, Myriam Jimeno refers to anthropologists who often debate and participate, but write very little. The goal of this type of anthropology was to alter the symbols of national identity and to accompany new ethnic movements in finding representation. Anthropologists and ethnic groups aimed to challenge the way indigenous groups were being ostracized by cultural hegemony. Later on in 1991, Colombia underwent a process of constitutional reform and development in attempt to recognize more cultural and ethnic rights. Some of its current most influential institutions are the Colombian Institute of Anthropology and History, the Colombian National University, and the National Institute of Ethnology.\n\nCosta Rican anthropology was institutionalized in 1967 under political influence. According to Margarita Bolaños Arquín, increasing notions of nationalism and anti imperialism led to the institutionalization of social sciences in Costa Rica. During the 1960s, around the time of institutionalization, social scientists' primary focus was on the birth and implications of social movements, as well as the consequences of modernization in rural areas. Later, French Structural Marxism influenced the social sciences to take an interest in the study of class structures. Over time, anthropology in Costa Rica was highly criticized in its struggle to find its identity. Caught in a sort of balancing act between western and Latin American practice, anthropology in Costa Rica eventually learned to take the criticisms of other anthropologies and made a name for itself with a focus on gender studies, identity studies, and developmental problems. To legitimize their discipline, anthropology contributed to other sciences such as linguistics, agriculture, and psychology. However, during the 1980s Costa Rica endured a recession, and anthropological institutions were under threat. During this time, globalization was becoming increasingly popular and while during the recession of the 1980s Costa Rica was not seen as a power player, at the start of the 1990s, the country could now participate in ways that were productive. It was not until around the 1990s that anthropologists regained the opportunity to research and, after such political and economic turmoil, there was much to question. Throughout the 1990s the focus of anthropology and other disciplines such as sociology continued to research in rural areas but shifted their research to the survival of the poor during tough economic times.\n\nManuel Gamio, the first Mexican anthropologist, earned his PhD in 1921, having studied under Franz Boas. The first anthropology department was established in 1938. Indigenous population studies known as indigenism, are an integral part of Mexican anthropology, and became popular during the presidency of Lázaro Cardenas, serving from 1934-1940. The National Institute of Anthropology and History was established by President Lázaro Cárdenas in 1939, and remains a prominent place of anthropological study in Latin America. The nation-building interests of incorporating the indigenous population into the Mexican state also led to the establishment of the Inter-American Indian Institute in 1942, in Mexico City, along with the establishment of the academic journal, America Indígena. Marxist theory was predominantly used to analyze social phenomena, and was combined with social evolution theory that viewed Mexico in three historical time phases: pre-Hispanic, Colonial, and Modern.\n\nIn the 1970s, Gonzalo Aguirre Beltrán, an anthropologist who was formerly a medical doctor worked for the federal government and promoted critical anthropology in Mexico that used Marxist theory and rejected imperialistic practices from the United States. Mexico’s urban populations began to increase in the 1970s, which became another topic of study for anthropologists. In the 1980s, Gramscian Marxism became the theoretical center, and studies included rural and urban populations, and labor. Institutions of anthropology have continued to increase since the 1980s, offering undergraduate and graduate degrees. Neo-liberal market transformations in the 1990s have affected anthropological training presently, as students may find careers not only in the universities, but non-governmental organizations.\n\nAsia includes the countries China, Japan, Philippines, and Siberia. Anthropology in Asia has been influenced by Western anthropological ideologies through colonial contact, historically. While the discipline of anthropology is historically built from nation-building and colonization from core countries, language and publishing barriers, funding opportunities and political status all influence the structure of anthropological research in each Asian country. Anthropology in the social and cultural perspective have not always had a strong tradition in Asian anthropology, but ethnography, ethnology, and folklore often have dominant roots within the discipline.\n\nChinese anthropology was founded by scholar Cai Yuanpei. Cai Yuanpei was a scholar educated at the University of Leipzig, and he brought both Western influence and standardization into the discipline of anthropology in China. The first department of anthropology was founded in 1928 with Cai Yuanpei’s creation of Academia Sinica in Beijing. At Academia Sinica, physical anthropology and archaeology held focus.\n\nFranz Boas also brought Western influence to China, and British functionalism would make a lasting impact on Chinese anthropology. In addition to Cai Yuanpei, Wu Wenzao was one of the most influential proponents of Western-influenced anthropology, and he took classes under Ruth Benedict (one of Boas’ students that would be influential in the field of anthropology on her own overall). Wu began teaching at Yenjing University in 1929, where he would influence students such as Fei Xiaotong and Lin Yaohua, who would go on to be important in the scene of Chinese anthropology. Chinese Ethnological Association created in 1934, but its progress was halted by China’s involvement in World War II in 1937.\n\nWorld War II pushed back the institutional development of anthropology in China until the late 1940s. With this revitalization, Chinese anthropologists began to look inwards at themselves for subjects of study. This inward focus led anthropologists of the time to attempt to use anthropology to better Chinese society. 1940-late 1950s was a time of Soviet influence in China, followed by 1957-1977 and Mao Zedong’s era of the People's Republic of China. During this time, Maoist aims supplemented ethnology and Chinese national identity creation.\n\nPost-1978 was a time of reform in China following the end of Mao Zedong's leadership. Academia was reconstructed, and anthropology subsequently saw a revival during this time. Exchanges between foreign faculty and students helped to globalize Chinese anthropology and bring in other perspectives. Liang Zhaotong was an advocate for the revival of social and cultural anthropology, but for this to happen, anthropology had to be seen as a useful tool for improvements in the field of the social sciences and society. Anthropology was held in lower regard than ethnology in China due to the ideology of Mao Zedong, and anthropologists left anthropology for other disciplines in social science, such as sociology, which subsequently saw a large period of development in the 1980s. This lower regard for anthropology also caused the field to receive less attention and less funding from the public and Chinese institutions.\n\nThe Chinese Academy of Social Sciences (CASS) and the State Education Committee founded the Chinese Anthropological Association in 1981 (now part of the East Asian Anthropological Association). Today, anthropology in China is still influenced by its history of being less practical and less important in the field of social sciences. This causes a lack of public interest and awareness in Chinese anthropology in favor of more “professional” disciplines, such as medicine, business, law, etc.\n\nThe creation of anthropology in Japan was a response to the research of Edward Morse, the first professor of Zoology at Tokyo Imperial University, where he discovered signs of cannibalism in Japan. Japanese nationalism motivated Japanese peoples to study themselves rather than being subjects of study by outsiders. This motivation led to the formation of Anthropological Society of Tokyo in 1886. Tsuboi Shôgorô was a leading member of this group, and he is named one of the founding fathers of Japanese anthropology. In 1892, he became the first professor of anthropology at Tokyo Imperial University.\n\nIn 1895, the Japanese colonial empire was marked by the annexation of Taiwan and led to an increase in domestic ethnographers in this region. Torii Ryūzō was Tsuboi's successor and greatly attributed data and photographs of Taiwan during this time period. His own research abroad redirected peoples' focus from themselves, Japanese folklore-studies, to the colonial Others. The expansion Japanese imperialism drove Ryūzō's research of others. This shift in research subjects created a separate discipline, ethnology or 'race studies.'\n\nIn 1934, Japanese Society of Ethnology (\"Nihon Minzokugakkai\") was formed, which separated Japanese folklore and ethnological studies from comparative ethnology.\n\nIn 1968, the Eighth Congress of the International Union of Anthropological and Ethnological Sciences (IUAES) was held in Japan.\n\nIn 2004, in response to the IUAES, the Japanese Society of Ethnology changed its name to the Japanese Society of Cultural Anthropology; this is one of the largest organizations at 2,000 members.\n\nConsidered to be a semi-peripheral country in comparison to the West, Japan is home to the largest number of anthropologists in Asia as well as the largest center for anthropological research in Asia. Japan's history resembles a colonial power in East Asia. Currently, language and audience discrepancies hinder open conversations between Japanese and American anthropologies. Since Western academic anthropologists publish in English, their local and global audience is essentially one. In Japan, writing for a global audience requires publishing in English. While Japanese scholars are knowledgeable about Western anthropological theories and trends, institutional factors deter Japanese anthropologists to publish in English; a more extensive peer review process can delay publication approval for years resulting in outdated empirical data. Japanese academics prefer to publish in university in-house journals where there is a much shorter delay in publication approval. A local audience means publishing in Japanese and increasing the gap between world anthropologies.\n\nThe movement of indigenization of anthropology in the Philippines challenges foreign-adopted Western concepts, theories and methods. To understand the viewpoints of this process, indigenization can be examined as a historical process, a perspective of native concepts, and as both a problem and solution created by colonial or neocolonial educational curriculum.\n\nFrom 1560-1898, the Philippines was under Spanish colonial regime. During this time, Spanish colonizers established society through theologoical orthodoxy. They valued their own written history over the Philippines' native traditions, and oral tradition was undermined by colonization.\n\nFrom 1898-1941, the second period of colonization by the United States took place. Ethnographic knowledge was established as the basis of integration of indigenous elements into mainstream Philippine society. In 1914, anthropology curriculum was established at the University of the Philippines, and three years later, an anthropology department was created. In 1921, the anthropology department at the University of Philippines merged with the sociology department.\n\nDuring the post-war era (1946-1968), student activism, national pride and identity reinforced the process of decolonization; the University of the Philippines was at the forefront of this movement. Filipino scholars increasingly pursued graduate programs in the United States anthropology departments. This created an issue that will be discussed further.\n\nFrom 1970-1986, social and political consciousness in the Philippines marked a revolutionary period. The country adopted conflict models; Marxist ideology was more suitable for the Philippines that was in a crisis state. In the late 1970s, the Philippine Folklore Society was formed. This growth of folklore studies was due to the further development of indigenization in the Philippines. In 1977, The Philippine Anthropological Society (Ugnayan ng Agham Tao or UGAT) was founded.\n\nAfter 1986, this period was marked by a heightened cultural consciousness. President Corazon Aquino promoted culture through creation of the National Commission for Culture and Arts (NCCA).\n\nThe distance between native and foreign anthropologists is a conflict in the Philippines. While most scholars receive formal education in Western societies, they often return \"home\" and view their native society through a foreign, Westernized lens they were conditioned and educated by. Native anthropologists are hindered by a perspective based on bias. Interests, training, values, and field exposure can result in differences between foreign and native anthropologists. It is important to recognize these different angles, politics of representation, and ethnographic authority in order to successful observe others as well as our own societies. Another challenge in anthropology in the Philippines is discussed by Filipino anthropologist, Carlos Jr. P Tatel, about funding for research on governmental and regional levels. He explains that anthropology proposals for funding often deviate from original plan in order to fit the agendas of agencies who grant travel and research funding.\n\nSiberia as a territory was important in the development of Russian anthropology due to its position of alterity within Russia. Siberia and the people of Northern Russia were points of great interest throughout various periods in Russian history as it tried to better understand its own people.\n\nThe beginnings of ethnographic research in Siberia were heavily influenced by anthropology in Germany and ideas of Russian nationalism in the 19th century. The expedition led by Franz Boas, the Jesup North Pacific Expedition from 1897-1902, helped to bring international attention to the concept of doing anthropology in Siberia in relation to Russian anthropology in addition to bringing Boas’ anthropological perspective into Russia. Also on this expedition were Vladimir Bogoraz, Vladimir Jochelson, and Leo Sternberg, who would be known as the founding fathers of Siberian studies, and influential ethnographers in Russia.\n\nThe nationalistic undercurrent in Russia at the time of the beginnings of researching Siberia as a place of intrigue was reflected in the Russians' attitude towards the people in Siberia. The impetus to study Siberians was rooted in the idea that one day the people in the area would all assimilate to Russian culture, and due to this, the current culture of the people should be documented and recorded. Russian ideologies heavily influenced the research field in Siberia, and studying Russian and Siberian history was an easier route for research due to the uncertainty of what would be acceptable to study under the Russian government in the 19th and 20th centuries. Under Soviet Russia in the early 20th century, ethnology moved toward a more lstructural and functionalist view, with the goal of generally understanding human culture. When Joseph Stalin came into power, this view shifted as Stalin aimed to homogenize Russian culture and identity. Ethnologists were employed by the state with a focus on understanding, regulating, and standardizing the different ethnic groups of Russia.\n\nCentral and Eastern Europe includes the countries of Austria, Croatia, Slovenia, Switzerland, Belarus, Bulgaria, Czech Republic, and Hungary among many others. Anthropological study is active in many places Europe through research centers, academic societies, and universities on a range of topics. One of the biggest problems facing anthropologists in Central and Eastern Europe is the need to define themselves as a discipline separate from any other.\n\nAnthropology in central European countries has its roots in Germany. The establishment of anthropology within central Europe has been a slow process that involved first understanding what the discipline was and then determining how it fit within each country's individual ideals.\n\nAustrian anthropology has close ties to Germany and is generally intertwined with German-speaking countries. As such, the history of anthropology in Austria is foggy until the marked institutionalization of the discipline. The Anthropological Society in Vienna (ASV) was the first anthropological institution in Austria. It was established on February 13, 1870 and is a non-profit organization. The “new anthropology” approach was the ASV’s foundation and Bernd Weiler’s term for anthropology that existed post-publication of Charles Darwin’s \"On the Origin of Species\". Anthropology within academia was postponed until 1919 when the Institute of Anthropology and Ethnography was created at the University of Vienna. The institute was divided into two later, making the Anthropological Institute and Institute for Ethnology. In 2005, the Anthropological Institute became the Department of Anthropology and is the only anthropology department that exists within the country.\n\nA notable anthropologist is Richard Thurnwald who was an Austrian-born German anthropologist and sociologist. He was multilingual in Arabic, Turkish, Serbian, and Russian and a professor at universities in the United States and Germany during the early 1900s Thurnwald was also the editor of various journals, including the one he originated, called Journal of Popular Psychology and Sociology, which was later renamed Sociologus. His wife continued publishing the journal despite his death in 1954. His work included the study of kinship, social structure, superstratification, feudalism, kingship, cities, and states, and western colonial expansion.\n\nAnother important figure was Pater Wilhelm Schmidt who was a German-born ordained Roman Catholic priest, anthropologist, and linguist. Anthropos is a journal he created in 1906 and the Anthropos Institute is an institution he founded in 1931. He relocated both to Switzerland in 1938 due to his distaste for Hitler's ideals. He was a professor at the Universities of Vienna and Freiburg, had published extensively, and his research topics included family, religion, language, and culture.\n\nKarl Franzens University of Graz’s humanities department includes the Institute for Cultural Anthropology and European Ethnology which offers bachelors, masters, and doctoral degrees in Anthropology. The key topics of research the institution is involved in include “city, governmentality, limit and difference, mobilities, visual culture, material culture, museum, religiousness, and science research as well as subject-oriented methodologies.” \n\nWeltmuseum Wien is an ethnographic museum located in Vienna that serves to display cultural diversity. Weltmuseum Wien, translated ‘World Museum Vienna’, opened in 1928 and houses worldwide artifacts, not including Europe, from as early as the 1500s. The museum’s previous title was the Museum of Ethnology and it recently reopened after closing for renovations in 2014.\n\nCroatian anthropology started with a focus more on natural and medical topics because it wasn’t embraced as a human-centered scientific discipline. In 1973, various European anthropologists met for the first time to discuss the making of a European Association for Anthropology. It wasn’t until the fourth meeting in Zagreb, on October 7, 1976, that the board members established the European Anthropological Association. The initial meeting triggered a chain reaction development of anthropology within Croatia because, meanwhile, in 1974, the Croatian Physicians Assembly established the section for biological anthropology. Soon after, the Croatian Anthropological Society was created in 1977 along with its journal, titled \"Collegium Antropologicum\". Finally, in 1992, the Institute for Anthropological Research was established at the University of Zagreb.\n\nAnthropology in Slovenia has been greatly influenced by surrounding nations due to the country's small size. There was a shift in language after World War II that caused German language to be controversial so English began being taught to children which later resulted in students being more interested in an ethnographic college curriculum. The University of Ljubljana started offering anthropology courses in 1933 which were taught by Božo Škerlj as the first college professor to teach the subject in Slovenia. Later, he created a chair in anthropology at the University of Ljubljana in 1946 that was eventually placed within the biology department; but, within a few years of his death in 1961, the subject became questioned which resulted in its being terminated. However, social anthropology was already part of the sociology curriculum which was established earlier in the 1960s. It wasn't until the 1990s that this branch of anthropology became an official program offered to graduate students.\n\nBožo Škerlj was an Austrian-born anthropologist who studied physical anthropology in Prague. He was initially interested in German physical anthropology but, at the time of World War II, decided to focus on cultural anthropology instead. His work reflected a combination of the two topics.\n\nAnother important figure in Slovene anthropology is Niko Županić who was born in 1876. He was the creator of the Slovene Ethnographic Museum, which opened in 1923, and the museum’s corresponding journal, \"Etnolog\", that began in 1926. His educational background was in physical anthropology, archaeology, and history and, in 1940, he became a professor for the ethnology and ethnography department at the University of Ljubljana. Niko Županić died on September 11, 1961.\n\nThe Slovene Anthropological Society has been active since its founding in 1992 and arranges an international science conference every three years called Škerlj's days. The society's journal is named Anthropological Notebooks. The articles inside are preferred to be unique to the journal and they're published in English language.\n\nThe discipline of anthropology in Switzerland, like Austria, is closely tied to Germany and German-speaking countries in general. Swiss anthropology originated with studying folklore, also known as volkskunde, and ethnology, or völkerkunde. Between 1912 and 1916, ethnographic museums held seminars in ethnology and folklore and were the beginning of anthropology being taught in Switzerland.\n\nJohann Jakob Bachofen, born in 1815, was a professor at the University of Basel, criminal court judge, member of city legislative council, and an anthropological writer. He came from a wealthy family and was well educated in law, Philology, history and ancient history. A popular, influential publication of his, titled Das Mutterrecht, explored past societies with the idea that matriarchy came before patriarchy. Initially it was rejected but was later printed in 1861. Bachofen published many works but none were accepted until well after his death in 1887.\n\nAnthropology in Eastern Europe varies in is roots, but many of the different anthropologies share a common interest in folklore and human populations. Eastern European anthropologists, official and non official, tend to focus on studying local issues and staying out of international affairs. The anthropological trend in Eastern Europe is a turn toward the social sciences and anthropology after separation from the Soviet Union.\n\nThe first Belarus postgraduate training program with anthropology was in February 1965 and was at the Institute of Art, Ethnography and Folklore of the Academy of Sciences of the BSSR.\n\nAfter separating from the Soviet Union, Belarus went through a period of state development that lasted from about 1990 to 1994. During this time, the focus was on nation-building. This required both an institutional and ideological change from the time when Belarus was under Soviet rule. A policy of “Belarusisation” was implemented in order to bring back culture and language that was understood to be native to Belarus. In 1971, anthropological research focused on the characteristics of populations within Belarus, looking at perceived internal “others”. In the 1980s, anthropologists were looking at the genetic structure of human populations based on demographics and environment, along with a study of Belarus’s child population. Belarusian anthropologists also looked outside of Belarus through the Research Institute and Museum of Anthropology from Moscow State University in order to study the Chukchi, Eskimos, Kazakhs, and Khakas peoples.\n\nOne important figure in Belarusian anthropology was L.I. Tegako, who is cited as being one of its founders in the National Academy of Sciences of Belarus. She began research on ethnic health issues in the 1960s, which is one of the first instances of an official sort of anthropology in Belarus. Her teacher was V.P. Alekseev of Russia. From her research, she concluded that “Belarusians manage to stay within variations which are typical for Caucasian race.” Tegako took part in much of the work in the 1980s on both the genetic structure of human populations and the child studies. She also led twenty expeditions outside of Belarus.\n\nLidiya Ivanovana is also an important character in Belarusian anthropology. She obtained her PhD in Russia in 1990 with a dissertation that looked at populations in Belarus. Her work was the first to take a multi-dimensional approach involving different types of materials from several different populations within Belarus. Ivanovana is attributed as having contributed many of the anthropological methods used in Belarus.\n\nAnthropology appeared in an official status in Bulgaria in late 1989 due to the fall of the communist regime and is thought to be a product of democratization of society. The first departments to include something like anthropology were departments of ethnology, which were concerned with ethnography and folklore, and were worked in to the departments of philology or history. Anthropology itself was introduced at New Bulgarian University (NBU) as a priority, but they had to combine with a discipline recognized by the state, which like in many other cases, was the department of sociology with the degree being a sociology one. It wasn’t until around 2004 that anthropology got its own department with its own degree in Bulgaria.\n\nOne of Bulgarian anthropology’s main focuses at first was to carve out their own niche as a discipline, especially considering that Bulgarian anthropologists come from a variety of backgrounds. They were also left with ideas from the socialist period and the fall of communism. There was also focus on the changing social conditions from the period of transition after the fall of communism. There was push for democratization in Bulgaria, and anthropology became something of a symbol for that change. Despite this, there was still polarization on methods and ideology within the new discipline based on debates about Soviet versus Western styles of education, which were understood to be ideological opposites. The shift was eventually toward Western ideas. Bulgarian anthropologists tend to focus on research within their own borders, but also research in Balkans. Despite the branching out of Bulgaria, there are a limited number of field-research sites, a limited number of subjects, and a limited number of methods taken advantage of by Bulgarian anthropologists. Much attention is paid to community formation, complex societies, power, polity, statehood, nationalism, myth, ritual, religion, marriage, kinship, ethnicity, nation-hood, magic, medicine, and multiculturality.\n\nThe Czech Republic takes a constructivist approach to anthropology (closely connected to ethnology), which they take a positivist approach to. Ethnology is taken to be trying to get at objective truth, where anthropology is getting at social constructs and beliefs. Despite this split between ideas of ethnology and anthropology in the Czech Republic, anthropology is not yet a fully established discipline. After the split from communism in 1989, there was a turn to socio-cultural anthropology in the way of ideology, but it was inconsistent. Some academics saw it as the same thing as ethnology, while others thought of it as a different research field with different methods and traditions, which resulted in the difficulty of establishing anthropology as a discipline. Many argue for there being a real epistemological difference between the two approaches.\n\nHungarian anthropology is a defined discipline with its own departments and methods, though there is still overlap between anthropology and other related departments, like history and sociology. Hungarian anthropology places a premium on verifying sociological and anthropological results with scientific data.\n\nIn 1963, the \"Ethnographic Research Group\", which was attached to the Hungarian Academy of Sciences was founded. It was led by Gyula Ortutay and had twenty-two participating members. The research focused on Hungarian folklore, but the group also looked at peasant economy, social institutions, and Siberian tribal society. If a senior member had an interest outside of Hungary, then that was also a permissible research topic. Cultural Anthropological departments were established at the University of Budapest in 1990 and the University of Miskolc in 1993.\n\nThere are many places to publish anthropological works within Hungary. The majority of the work is published in languages other than Hungarian and appear mostly in European periodicals. Many of the works do not appear in American anthropological journals due to a gap in how things are understood between the two anthropological fields. Many Hungarian anthropologists believe that the methods and problems that they need to consider are within their own borders or within their own region. They tend to stay out of international problems and direct their funding toward internal concerns.\n\nBela C. Maday points out that communication is not a strong suit for Hungarian anthropologists, which makes communicating ideas with core anthropologists, like those from the U.S. or Western Europe, difficult, but there has been much dispute on this point.\n\nThe beginnings of anthropology in Russia can be traced back to the establishment of the Russian Academy of Sciences under Peter the Great in 1725. Following the Academy of Sciences, many museums were also created with the impetus for studying culture, including the Ethnographic Bureau of the Russian Geographical Society in the mid-19th century. The 1840s also saw the creation of physical anthropology and archaeology as sub-disciplines of anthropology. In 1864 the first university department for anthropology in Russia was created at Moscow University. The first specialized journal for Russian anthropology, (trans.) The Ethnographic Review (Etnograficheskoe obozrenie), was created in 1889. As Russia did not have state-supplemented funding in the 19th century, much of the financial support came from aristocrats such as Count Aleksey Uvarov and Prince V. N. Tenishev.\n\nIn the early 20th century, St. Petersburg and Moscow would be centers for the development of anthropology—focused on ethnology and ethnography—with the formation of the Department of Ethnology in Leningrad (1928), Museum of Anthropology and Ethnography (1924), the publication of the journal \"Ethnography\" (1926), the Anuchin Institute of Anthropology at the University of Moscow (1922), etc. Anthropology in Russia was also influenced by Western anthropological perspectives, such as Franz Boas.\n\nFollowing the Communist Party takeover, Russia began to favor ethnology over anthropology. Ethnology was the study of different ethnic groups within the state, which supported the push for homogenization and national unification of the Russian state. Marxist theory replaced Western anthropological theory, and various university departments were closed as Russia experienced an ideological reconstruction. In the mid-20th century, with undercurrents of the Cold War, social and cultural anthropology were rejected from ethnographic study, but ethnography was re-institutionalized and strengthened in universities and institutions across Russia.\n\nIn the latter half of the 20th century, Russian ethnography to other parts of the world in which Soviet influence was strong, such as Eastern Europe. The Perestroika in 1985 led to another bout of reconstruction for anthropology, and Russian science in general. Institutes were renamed and reconfigured to match this new trend. Social anthropology also began to make a comeback, leading to identity problems for social anthropology as a discipline in a country with such a strong ethnographic tradition that had excluded it for years.\n\nThe 1990s, a time of great social and political change for Russia with the end of the USSR, were a time for critical introspective views on the recent past. With this, Russian anthropology turned towards more contemporary interests, where it still is today. Even with these contemporary interests, Russian anthropology still finds itself heavily influenced by the ethnology of its past and attempting to reconcile what it means to be a “social” anthropologist in this environment.\n\nThe discipline of anthropology is not new to the Arab world. While there were no established anthropological institutions until the 20th century, scholars such as Abu Rayhan al-Biruni and Ibn Khaldun, are recognized for their contribution to the discipline as early as the 10th century. Egypt, Palestine, and the Persian Gulf region have received most of the scholarly attention, with a particular focus on nationalism and the state. The Arab youth are a growing area of interest for anthropologists in the Arab world. Comparatively little research is done in Algeria, Tunisia, Libya, the Sudan, Syria, Jordan, and Iraq. This is in part a result of accessibility and the conditions of the states. That status of anthropology in the Arab world would be labeled as peripheral in relation to anthropology in other regions of the world.\n\nThe man known as the father of Iranian Anthropology was named Sadegh Hedayat (1903-1951). His focus was on folklore. In 1937, an institute of ethnology was founded in Iran, which then closed in 1941. It then reopened with the rise to power of Mohammed Reza Shah. From 1956 to 1959, it published a journal titled \"Majalle-ye Mardomshenasi\" (Journal of Anthropology). In 1957, the first anthropological elective course offered at a college level in Iran began at the University of Tehran.\n\nIn the past, there was not as much of an emphasis placed on receiving degrees from foreign universities. Similarly, international research was also not highly valued. International study and research, however, has begun gaining more and more importance within the departments of anthropology in Iran. Anthropology in Iran suffers from a poor reputation in the public sphere. It is considered to be a weak discipline, according to Iranian anthropologist, Soheila Shahshahani. Perhaps because of this, most students of the social sciences tend to choose other disciplines, such as law, management, and psychology. As society changes, more attention is being paid to the field. Today, ethnographic research in the area focused on internal subjects, such as the pastoralists living in the arid areas around Iran. These studies continue today, but other fields of interest have started to emerge. A new focus on small town life and rural areas has recently developed. Professor Shahshanani states that the weakness of current anthology in Iran is the lack of theoretical work done by its practitioners. She also goes on to say that these issues could be solved by getting Iranian anthropologists who have trained elsewhere to come back and practice in Iran.\n\nThe department of sociology at the American University of Beirut was the first to offer an anthropology course, which is listed in its 1950-51 catalogue. The department of anthropology was officially founded in the 1970s, and saw 33 students graduate with a Master of Arts degree in anthropology throughout that decade. The Lebanese Civil War, which lasted from 1975-1990, interfered with the development of the department and anthropology at the university saw a decline as a direct result. During this time, the new department of social and behavioral sciences (SBS) which already encompassed sociology, psychology, and communication, absorbed the anthropology department.\n\nDuring the 1980s, records show just one student having graduated with a Master of Arts degree in anthropology, while there were none in the 1990s. There were three anthropologists on the faculty throughout this time. Among them were Fuad Khuri, Martha Mundy, and Gerald Obermeyer.\n\nA survey conducted in 1989 by Seteney Shami, a 1976 graduate of the BA program in anthropology at the American University in Beirut, sought to learn more about the teachings of anthropology at universities in the Arab world. Her findings suggested that the role of the discipline in the Arab world were minimal. In an academic report that came out in 2006, anthropologists at the same university claim to have found little evidence in the local community of any significant changes since.\n\nToday's anthropology graduates in Lebanon have opportunities to work with local NGOs. However, for those interested in pursuing anthropology as a discipline, the West still stands as the one destination for that. Anthropology departments at the American University in Beirut, and in Lebanon, are stifled by war.\n\nAs a destination for anthropologists to do research, Lebanon is among the top spots for emerging scholars in the Arab world.\n\nPalestine has seen an increase in research conducted in the territory and among the Paletinian communities in Isarel, as well as refugee camps in neighboring countries.\n\nThe history of Palestinian anthropology can be marked by four modes of ethnographic engagement: Biblical Palestine, Oriental Palestine, Absent Palestine, and Post-Structural Palestine.\n\nBiblical Palestine refers to the main method of ethnographic engagement of Palestine which took place in the first decades of the 20th century. Led predominately by Europeans, their interest was motivated by the use of the Bible as a legitimizing text to influence the region. Early work consisted of European writers fetishizing and romanticizing the land and the people based on the Biblical figures.\n\nOriental Palestine, a term coined by a Palestinian scholar (find scholar, cite) was the leading mode of engagement throughout the first four decades of the 20th century. It was marked by a sense of urgency to document Palestine as a source of Europe's beginnings. Through this lens, a narrative was offered that challenged the colonial British vision of Palestinian history which saw the Arabs there as \"transient and ephemeral\". It was also marked by a sense of duty among others to capture the traditional fabric of Palestine before it's dissolution, which appeared evident at the time due to the events surrounding the rise of Zionism.\n\nAbsent Palestine follows immediately after the demise of Palestine in 1948, and can only be fully understood in terms of the success of Zionism. In this sense, the state of Palestine was eclipsed by the narrative of Israel as a place offering a safe haven to endangered refugees from Europe. This ethnographic silence of Palestinians is seen as the turning point in Israel's image of modernity.\n\nPost-Structural Palestine is the current main method of ethnographic engagement. It is known primarily for its stance that challenges and brings to question Israel's efforts to repress Palestinian nationalism. The movement has seen a rising trend in which the Palestinian subject is explored for their national identity, rather than silenced.\n\nAnthropology as a discipline in Turkey can trace its roots back to 1925. Developing in an nationalistic atmosphere, The Anthropology Institute, otherwise known as The Center for Anthropological Research in Turkey, was established on that year within the Faculty of Medicine at the University of Istanbul. From 1925 to the 1960s, the main topics of research centered around studies of rural and village life, with a focus on nation building. In the 1960s, a series of military coups occurred, causing considerable changes to the field and to academia itself. It was not until the year 1997 that the first official department of anthropology was established in Turkey, at the private Yeditepe University in Istanbul. As of 2010, 6 of the 53 state universities in Turkey offered training in anthropology. In contrast to this, only one of the 24 private universities offer similar training. The first anthropological association in Turkey was founded in 1992.\n\nMany Anthropologists investigate the tribal system in Saudi Arabia. Anthropology was not popular in many countries; however, the Universities in Saudi Arabia are adopting Anthropology. \n\nAnthropological studies, which are concerned with the privacy of the UAE community with a tribal background are rare and limited.\nTribes are the most form of UAE. Many anthropologists are interested in investigating the form of tribes. Many of the Arab states of the Persian Gulf are also based on the tribal system.\n\nIn Qatar and Bahrain, anthropology was not as popular as other fields, like many other countries in the Persian Gulf region. Anthropology is expanding in educational aspect. Many anthropologists are also concerned on the structure of the tribes in the Arab countries in the Persian Gulf region (Gardner).\n\nWithin the Arab-majority countries, Egypt, has established itself among the other Arab-majority countries as the main hub for anthropologists in the region, with Cairo being the center for most of this attention. The rest of the country remains relatively understudied. Increased attention to Cairo can be attributed to the rise of anthropological interest in cities, particularly to the diverse interdisciplinary scholarship.\n\nThe centrality of Middle East area studies is largely responsible for the increase in anthropological attention towards Egypt. In addition to this is the accessibility of institutional support for US scholars.\n\nAs of the early 21st century, the relationship of Egypt with anthropology remains under question. Egyptian anthropologist, Hania Sholkamy, remarks that there are four main points that shape this ongoing relationship: the relationship of methods to theory, the relationship between methods and their analysis, the relationship of culture to its determinants, and the relationship between having data and being able to evaluate it.\n\nThe discipline of anthropology is in a constant state of judgment within Egypt, particularly when compared with the discipline of demography. The qualitative data more common in demography is given more attention than the theoretical and analytical methods associated with anthropology.\n\nIn Morocco, topics of anthropological research include the ethnicization of Jews, the construction of ethnicity among Berber, Arab, and Haratine groups through agricultural practices, and how Berber ethnicities are politicized in ways that create raced and gendered notions of homeland.\n\nThe region of Africa has had a long history of being colonized by others in economic and cultural ways, which is why the study of anthropology in Africa is a relatively new discipline that is usually grouped with historical work. Before becoming a discipline in the region, Western anthropologists came to the area to study and conduct ethnographies pertaining to the native culture of those who inhabited the area. Anthropologists in African academia are still on looking for what anthropology means to them. While anthropology was initially used by states to gain knowledge about local cultures, it was later seen as a way to help them. After the recognition of its importance many universities and associations have institutionalized departments, journals and conferences to carry out this work. This article includes the history, development, and future of African Anthropology in different regions.\n\nAnthropological study in Kenya, like many other parts of Africa, was dominated by foreign British academia. They were focused on studying the “other” and understanding them for state purposes. This era is known as the pre-independence period. There were very little local anthropologists after independence in 1963 until the 70s. The post-colonial era was filled with distrust for the subject of anthropology because of its link to previous colonizers. The East African Anthropological Association (EAAA) was founded in 2001 archaeology. This association was used to promote and unify anthropologists in East Africa and work towards a common goal. The EAAA was working to develop better programs in universities and create local opportunities for meetings within anthropological communities. It works with the Pan African Anthropological Association as well as many others in order to come up with ways to improve the country that they live in.\n\nThe growth and development of anthropology in Kenya was largely due to colonialism of the late nineteenth and early twentieth centuries, but as an actual discipline in the region, it wasn’t well developed until the 1980s. In 1938, the subject of anthropology became locally known through Jomo Kenyatta, who wrote and published \"Facing Mt. Kenya\", which was the first time any article was published from a native’s perspective. The methodology of anthropology in Kenya is neither strictly Kenyan, nor is it strictly Euro-American, but rather a combination of the various methods between the nations. Due to the variety of methods that were being taught worldwide, as well as the education development in Kenya, it was decided to create formal training for the discipline. There’s evidence of this from their two major universities of the University of Nairobi and Moi University. The University of Nairobi tended to disciplines of archaeology and anthropology, but taught them as separate departments, similar to England’s separation of the departments; and Moi University tended to the same disciplines of archaeology and anthropology, but taught the disciplines together in the same department of Anthropology, as is taught in the U.S.\n\nThe majority of British, as well as German, anthropologists dominated Kenya with their studies focusing solely on the groups of people who were considered to be distinct, or “otherly”. While some anthropologists studied these groups in order to achieve dominance over them, other anthropologists reasoned studying the communities for educational purposes before their culture no longer existed due to colonizing. Thus, causing a means for Kenya anthropologists to disassociate with colonialism because of its harsh effects on Africans and their culture. This forced the local anthropologists to rethink about socio-cultural studies, including their own discipline and how it aided in colonialism. Even Jomo Kenyatta, who had benefited from his education and studies, was struggling with the decision on whether to associate with the discipline anymore.\n\nLouis Leakey aided in bringing archaeology and physical anthropology to light in Kenya. He work as a curator in the Coryndon Memorial Museum, which is an important establishment that helps to keep excavation sites accessible, such as Koobi Fora, Olorgesailie, and the Hyrax Hill, to both local and foreign archaeologists. In the 1950s, alongside his wife, Leakey found various primate fossils, including those of Australopithecus Boisei (1959), Homo Habilis (1964), and Kenyapithecus (1967). In 1960, he established the Institute of Primate Research (IPR) which helped in comprehending human evolution and biomedical research for health challenges in Africa, such as HIV/AIDS.\n\nSince the discipline of anthropology was associated with colonialism, the nation-state of Kenya did not identify with its trajectories and could not support it. It wasn’t until Daniel Arap Moi, who succeeded Jomo as president, made culture a central means for socio-economic aspects, making anthropology slowly begin to gain popularity again among locals due to its national cultural ethos. In 1965, the University of Nairobi established its Institute for Development Studies which contained two aspects of social science and cultural divisions. The social science aspect of the department went on to develop its own Institute of Development Studies, which carried out economic development but through a multidisciplinary approach. The cultural divisions aspect used resources that informed university students, as well as regionally, from a cultural instruction perspective. In 1970, the two subjects came together and were known as the Institute of African Studies (IAS), in which students researched in African archaeology, history, social anthropology, musicology, linguistics, oral literature, traditional arts, crafts, and social systems; this institute even contributed to some of the top scholars such as musicologists P.N. Kavyu and , historians H.S.K. Mwaniki and William R. Ochieng’, and writers Okot p’Bitek and Taban lo Liyong. In 1986, the IAS had established its first anthropology training program, providing courses of medical, linguistic, economic, and ecological anthropology and material culture (Amuyunzu-Nyamongo, 2006).\n\nThe future of the discipline of anthropology consists of research projects dedicated to resolving health issues, such as malaria and HIV/AIDS, so it’s not a surprise that most anthropologists in Kenya today are either medical anthropologists or those anthropologists who study medical issues. Many of these local anthropologists are sought out for help by national non-government health organizations, like United State Agency for International Development, Family Health International, Engenderhealth, PATH, Population Council, African Population and Health Research Center, African Medical Research Foundation, the World Health Organization and the Ford Foundation. Kenyan anthropologists do not conduct research for personal needs, but for needs of their nation-state and those funding agencies that they provide information to for health resolutions. In response to this upcoming need, universities are developing programs, like Anthropology in Developing Countries, Applied Anthropology, Medical Anthropology, and Anthropology and Infectious Diseases, that educate for cultural developmental skills.\n\nBefore Cameroon was split by the British and French in 1915 it was under the control of the German government since 1884. Very little Anthropological work was done until this time when the state recognized how useful knowing more about its people would be. Phyllis Kaberry and Elizabeth Chilver were two prominent researchers in West African area in the min-1900s. Kaberry, a trained anthropologist from England, studied women in a local tribe from the \"grassfields\" of Cameroon. She also co-wrote several books and papers on topics concerning female roles in specific African cultures. In 1973 the first institute in Cameroon with an anthropology department was established. In 1978 departments that were seen as not practical were starting to be eliminated. After closing, reopening, and hiding within other departments, Anthropology was finally on the rise in the early 1990s.\n\nThe University of Yaoundé-I is a main institution in the area providing students with opportunities to gain degrees in Anthropology. Other Institutions of importance are the University of Ngaoundere and the University of Buea which in 1992 added anthropology departments. Both of these universities produce scholars from the local communities and they promote research that is of common interest to the area. Language being a barrier in academia until its independence, in 1960, where universities were fashioned in the European style of education systems. The University of Buea, a public university, offered the subjects in the English language which increased the number of local students that attend. Largely associated with sociology, the first person to gain a PhD in Social Anthropology from Cameroon was Paul Nkwi in 1975. In 1993, a B.A. in anthropology could be received form the University of Yaoundé.\n\nA stepping-stone organization was CODESRIA, which was an organization that helped develop and promote anthropology as an institution. It facilitated the establishment of the Pan African Anthropological Association (PAAA) in the 80s. The PAAA is cooperative movement that unified Anthropologists from all over Africa. Its goal was to make anthropology known again as a useful and essential department that Africa needed. This association is holding conferences annually, starting in 1989, to advance Anthropology and find ways to solve problems for the future. Some dominant research topics in the area are witchcraft, chiefdoms, health, violence and ethno-history. The PAAA started encouraging communication of cross disciplines to benefit Africa as a whole by discovering new ways of resolving issues. A leading journal in Africa is the African Anthropology, now known as The African Anthropologist, allows research from all over Africa to be shared and more easily accessible.\n\nThe history of the discipline of anthropology in South Africa comes from the result of political and ideological interpretations of the research there. In the 1920s, the South African Association for the Advancement of Science was established, and it was here that anthropology was known. Presentations were given by archeologists, linguists, anthropologists, and ethnologists; there was also a South African Journal of Science that many researchers published in as well. During the years of the 1940s to the 1990s, anthropology grew to be less popular due to the apartheid period, which in educators had strict guidelines as to what they could and couldn’t teach in the classroom, and they were not permitted to teach anything else but that particular curriculum.\n\nAnthropological studies and research were offered at sixteen different universities, in which sociocultural anthropology and archaeology were offered within the discipline, and in another department, linguistics, African studies, and Gender studies were linked in the discipline. Instead of using the word or teaching anthropology, the universities, more specifically Stellenbosch University, taught \"volkekunde\", which means knowledge about people, and it was first known from pre-WWII German passage that was written by Völkerkunde. This expansion of the discipline was also known as ethnology or cultural anthropology, and it was paired with aspects of the apartheid period. This caused a division between social anthropology and volkekunde, as well as Afrikaans-medium universities and English-medium universities, respectively.\n\nStellenbosch University (an Afrikaan-medium university) had established its first anthropological department due to Werner Eiselen, who was the Permanent Secretary in the National Department of Native Affairs, as well as being a developer of the concept of apartheid, with Hendrik Verwoerd being his partner. There were then new universities that were built in the 1960s, specifically for black students, which led to the continuation of the two types of universities within the area. The professors who obtained jobs at the new universities had a background that dealt with a volkekunde style of teaching anthropology. This entire movement didn’t appeal to those who identified themselves as social anthropologists in the discipline.\n\nEven with this division of the methods to anthropological research, there was a mutual respect and influence for social anthropological studies that were being conducted by researchers in the U.K., as well as the U.S. Most students were moving on to proceed in getting their doctoral degrees preferred to attend the University of Cambridge, due to its influence of academia through anthropologists who were South African natives, such as Meyer Fortes, Isaac Schapera, and Max Gluckman. South African anthropologists, such as Jean Comaroff and John Comaroff and Namibian-born Rob Gordon, who began their studies in their home region of South Africa, and more specifically at the Afrikaans-medium University of Stellenbosch, also had influence with the U.S. in their research.\n\nIn the 1960s, South African anthropologists made the decision to start leaving their country for careers and research studies because of the apartheid methods, the inequality within their societies, and there was an increase in the violence that was surrounding the region. In 1967, a committee was formed in order to begin negotiating anthropological conferences that were held at the University of South Africa, which added to the separation and tension of the social anthropologists and those who studied volkekunde. Ten years later, black anthropologists started to attend these conferences, and this made the volkekunde group to initiate another new conference that was only to host research projects to those studying ethnology; this new conference was known in the Afrikaans language as \"Vereniging van Afrikaanse Volkekundiges\", which is translated to mean Association of Afrikaans Ethnologists. This conference excluded entry to those who did not speak the original Afrikaans language of South Africa, or the regional state area, and it continued to have majority and favor until the 1980s when the social anthropologists decided to have their own conference as well.\n\nThe Association for Anthropology in Southern Africa (AASA) was established in 1987 excluded membership into the group for those who believed in the apartheid concepts. Before anyone could become members of the conference, they were to sign a document, or a contract, saying that they reject any and all apartheid theories and concepts. Regardless of this new conference, the methods of volkekunde remained to be prominent in the discipline of anthropology, though during the 1980s, the anthropology department of then known Rand Afrikaans University, which was one of the newer White Afrikaans-medium universities in the area, officially denounced volkekunde as their way of research, in fact, the entire teaching department of this discipline turned their backs to apartheid concepts entirely. Later on, Stellenbosch University, which was where the first volkekunde department to be established, was closed down in the mid-1990s. A few years afterward, the discipline of social anthropology was introduced within the Department of Sociology.\n\nThe new association of Anthropology South Africa was a cause to link the two distinguished branches of volkekunde and social anthropology. Its first annual conference was in 2001. In 2004, it became one of the founding members of the World Council of Anthropology Associations in Brazil. There aren’t very many volkekundiges, or ethnologists, who have membership within the ASnA, nor do most of them attend any of the conferences that are held. A majority of those who do attend the annual conference are young, predominantly black, postgraduate anthropologists, but there are also a growing number of faculty members from the South African University anthropology programs who participate as well. Though the faculty participation numbers are growing, the overall number of memberships within the ASnA fluctuate from year to year. This is due to postgraduates, who are members only having a membership for a year or two in order to obtain their dissertations. There is also a close link between membership and conference attendance, meaning that since the conferences are held in venues that are less accessible or less desirable, this doesn’t attract many anthropologists to participate and fewer people sign up for memberships.\n\nSome of the topics of research for sociocultural anthropologists in South Africa consist of medical anthropology, mostly concerning the HIV/AIDS pandemic in the region, development anthropology, urbanism, science and natural resources, conflict, violence and policing, human rights, identity politics and belonging, and popular culture. There isn’t much attention paid to subjects, such as economic anthropology, state formation, and religion and religious movements.\n\nAnthropologists at South African universities mostly publish to edited volumes and special theme collections in interdisciplinary and disciplinary journals in their own country, as well as internationally. One significant publication venue for South African anthropologists is the journal formerly known as the volkekunde’s Tydskrif van Suid Afrikaanse Volkekunde, which translates to Journal of South African Ethnology. The journal changed its name to Anthropology Southern Africa in 2002.\n\nAnthropologists, who studied in Africa and began their research from basic curiosities, cannot be of aid to how the discipline stays in existence. Anthropology thrived from outside and inside perspectives of the same region or aspect of culture; having a missions civilisatrice perspective divided observer and participant, instead of taking into consideration the culture within the region from the perspectives of those who have lived there. The aspect of not being able, or not wanting to, collaborate with natives from the country was due to the Malinowskian model. Researchers developed their own personal objectives and reasoning to what and who they were observing in the field. This caused an explicit division of Africa into several regions based on finding and observing the exotic “Other” from various basis of culture, race, and location. The concept of reflexivity helped anthropologists to realize that their personal needs and reasoning for research correlated with the aspect of seeing people differently instead of similarly. There was no insight from those who had inhabited the continent for centuries, and the country is not well represented. There was not a lot of support for methods that contradicted what had already been practiced and known within the discipline.\n\nUniversally, there were various debates about the methodology of the discipline in relation to folklore, co-production with aid of natives, and boundaries within the field. These aspects had not been taken into consideration when observing the region. Anthropology surviving in Africa were due to not observing Africa explicitly as scientific (racially or geographically), not seeing African identities and cultures as scientific, redefining the Malinowskian model, and making the methods of fieldwork and participant observation more flexible. Native anthropologists called for creative diversity and outsider anthropologists to observe themselves and how they contributed to the professional collaboration with those who were native to the region. This methodology or concept did not replace outside methods, but correlated the two methods together in knowledge about culture.\n"}
{"id": "46187677", "url": "https://en.wikipedia.org/wiki?curid=46187677", "title": "History of human migration", "text": "History of human migration\n\nHuman migration is the movement by people from one place to another with the intention of settling temporarily or permanently in the new location. It typically involves movements over long distances and from one country or region to another. \n\nHistorically, early human migration includes the peopling of the world, i.e. migration to world regions where there was previously no human habitation, during the Upper Paleolithic. Since the Neolithic, most migrations (except for the peopling of remote regions such as the Arctic or the Pacific), migration was predominantly warlike, consisting of conquest or \"Landnahme\" on the part of expanding populations. Colonialism involves expansion of sedentary populations into previously only sparsely settled territories or territories with no permanent settlements. In the modern period, human migration has primarily taken the form of migration within and between existing sovereign states, either controlled (legal immigration) or uncontrolled and in violation of immigration laws (illegal immigration).\n\nMigration can be voluntary or involuntary. Involuntary migration includes forced displacement (in various forms such as deportation, slave trade, trafficking in human beings) and flight (war refugees, ethnic cleansing).\n\nThe pre-modern migration of human populations begins with the movement of \"Homo erectus\" out of Africa across Eurasia about 1.75 million years ago. \"Homo sapiens\" appears to have occupied all of Africa about 150,000 years ago; some members of this species moved out of Africa 70,000 years ago (or, according to more recent studies, as early as 125,000 years ago into Asia, and even as early as 270,000 years ago), and had spread across Australia, Asia and Europe by 40,000 BC.Migration to the Americas took place 20,000 to 15,000 years ago. By 2000 years ago humans had established settlements in most of the Pacific Islands. Major population-movements notably include those postulated as associated with the Neolithic Revolution and with Indo-European expansion. The Early Medieval Great Migrations including Turkic expansion have left significant traces. In some places, such as Turkey and Azerbaijan, there was a substantial cultural transformation after the migration of relatively small elite populations. Historians see elite-migration parallels in the Roman and Norman conquests of Britain, while \"the most hotly debated of all the British cultural transitions is the role of migration in the relatively sudden and drastic change from Romano-Britain to Anglo-Saxon Britain\", which may be explained by a possible \"substantial migration of Anglo-Saxon Y chromosomes into Central England (contributing 50%–100% to the gene pool at that time).\"\n\nEarly humans migrated due to many factors, such as changing climate and landscape and inadequate food-supply. The evidence indicates that the ancestors of the Austronesian peoples spread from the South Chinese mainland to the island of Taiwan around 8,000 years ago. Evidence from historical linguistics suggests that seafaring peoples migrated from Taiwan, perhaps in distinct waves separated by millennia, to the entire region encompassed by the Austronesian languages. Scholars believe that this migration began around 6,000 years ago. Indo-Aryan migration from the Indus Valley to the plain of the River Ganges in Northern India is presumed to have taken place in the Middle to Late Bronze Age, contemporary with the Late Harappan phase in India (around 1700 to 1300 BC). From 180 BC, a series of invasions from Central Asia followed in the northwestern Indian subcontinent, including those led by the Indo-Greeks, Indo-Scythians,Indo-Parthians and Kushans.\n\nFrom 728 BC, the Greeks began 250 years of expansion, settling colonies in several places, including Sicily and Marseille. Europe provides evidence of two major migration movements: the Celtic peoples in the first millennium BC, and the later Migration Period of the first millennium AD from the North and East. Both may be examples of general cultural change sparked by primarily elite and warrior migration. A smaller migration (or sub-migration) involved the Magyars moving into Pannonia (modern-day Hungary) in the 9th century AD. Turkic peoples spread from their homeland in modern Turkestan across most of Central Asia into Europe and the Middle East between the 6th and 11th centuries AD. Recent research suggests that Madagascar was uninhabited until Austronesian seafarers from Indonesia arrived during the 5th and 6th centuries AD. Subsequent migrations from both the Pacific and Africa further consolidated this original mixture, and Malagasy people emerged.\n\nBefore the expansion of the Bantu languages and their speakers, the southern half of Africa is believed to have been populated by Pygmies and Khoisan-speaking people, whose descendants today occupy the arid regions around the Kalahari Desert and the forests of Central Africa. By about 1000 AD, Bantu migration had reached modern-day Zimbabwe and South Africa. The Banu Hilal and Banu Ma'qil were a collection of Arab Bedouin tribes from the Arabian Peninsula who migrated westwards via Egypt between the 11th and 13th centuries. Their migration strongly contributed to the Arabisation and Islamisation of the western Maghreb, which was until then dominated by Berber tribes. Ostsiedlung was the medieval eastward migration and settlement of Germans. The 13th century was the time of the great Mongol and Turkic migrations across Eurasia.\n\nBetween the 11th and 18th centuries, numerous migrations took place in Asia. The Vatsayan Priests migrated from the eastern Himalaya hills to Kashmir during the Shan invasion in the 13th century. They settled in the lower Shivalik Hills in the 13th century to sanctify the manifest goddess. In the Ming occupation, the Vietnamese started expanded southward in the 11th century; this is known in Vietnamese as nam tiến (southward expansion). Manchuria was separated from China proper by the Inner Willow Palisade, which restricted the movement of the Han Chinese into Manchuria during the early Qing Dynasty (founded in 1636), as the area was off-limits (British English: out of bounds) to the Han until the Qing started colonizing the area with them (late 18th century) later on in the dynasty's rule.\n\nThe Age of Exploration and European colonialism has led to an accelerated pace of migration since Early Modern times. In the 16th century, perhaps 240,000 Europeans entered American ports. In the 19th century over 50 million people left Europe for the Americas alone. The local populations or tribes, such as the Aboriginal people in Canada, Brazil, Argentina, Australia, Japan\nand the United States, were often numerically overwhelmed by incoming settlers.\n\nWhen the pace of migration had accelerated since the 18th century already (including the involuntary slave trade), it would increase further in the 19th century. Manning distinguishes three major types of migration: labor migration, refugee migrations, and urbanization. Millions of agricultural workers left the countryside and moved to the cities causing unprecedented levels of urbanization. This phenomenon began in Britain in the late 18th century and spread around the world and continues to this day in many areas.\n\nIndustrialization encouraged migration wherever it appeared. The increasingly global economy globalized the labour market. The Atlantic slave trade diminished sharply after 1820, which gave rise to self-bound contract labour migration from Europe and Asia to plantations. Overpopulation, open agricultural frontiers, and rising industrial centres attracted voluntary migrants. Moreover, migration was significantly made easier by improved transportation techniques.\n\nRomantic nationalism also rose in the 19th century, and, with it, ethnocentrism. The great European industrial empires also rose. Both factors contributed to migration, as some countries favored their own ethnicity over outsiders and other countries appeared to be considerably more welcoming. For example, the Russian Empire identified with Eastern Orthodoxy, and confined Jews, who were not Eastern Orthodox, to the Pale of Settlement and imposed restrictions. Violence was also a problem. The United States was promoted as a better location, a \"golden land\" where Jews could live more openly. Another effect of imperialism, colonialism, led to the migration of some colonizing parties from \"home countries\" to \"the colonies\", and eventually the migration of people from \"colonies\" to \"home countries\".\n\nTransnational labor migration reached a peak of three million migrants per year in the early twentieth century. Italy, Norway, Ireland and the Guangdong region of China were regions with especially high emigration rates during these years. These large migration flows influenced the process of nation state formation in many ways. Immigration restrictions have been developed, as well as diaspora cultures and myths that reflect the importance of migration to the foundation of certain nations, like the American melting pot. The transnational labor migration fell to a lower level from the 1930s to the 1960s and then rebounded.\n\nThe United States experienced considerable internal migration related to industrialization, including its African American population. \nFrom 1910 to 1970, approximately 7 million African Americans migrated from the rural Southern United States, where blacks faced both poor economic opportunities and considerable political and social prejudice, to the industrial cities of the Northeast, Midwest and West, where relatively well-paid jobs were available. This phenomenon came to be known in the United States as its own Great Migration, although historians today consider the migration to have two distinct phases. The term \"Great Migration\", without a qualifier, is now most often used to refer the first phase, which ended roughly at the time of the Great Depression. \nThe second phase, lasting roughly from the start of U.S. involvement in World War II to 1970, is now called the Second Great Migration. With the demise of legalised segregation in the 1960s and greatly improved economic opportunities in the South in the subsequent decades, millions of blacks have returned to the South from other parts of the country since 1980 in what has been called the New Great Migration.\n\nThe First and Second World Wars, and wars, genocides, and crises sparked by them, had an enormous impact on migration. Muslims moved from the Balkan to Turkey, while Christians moved the other way, during the collapse of the Ottoman Empire. In April 1915 the Ottoman government embarked upon the systematic decimation of its civilian Armenian population. The persecutions continued with varying intensity until 1923 when the Ottoman Empire ceased to exist and was replaced by the Republic of Turkey. The Armenian population of the Ottoman state was reported at about two million in 1915. An estimated one million had perished by 1918, while hundreds of thousands had become homeless and stateless refugees. By 1923 virtually the entire Armenian population of Anatolian Turkey had disappeared. Four hundred thousand Jews had already moved to Palestine in the early twentieth century, and numerous Jews to America, as already mentioned. The Russian Civil War caused some three million Russians, Poles, and Germans to migrate out of the new Soviet Union. Decolonization following the Second World War also caused migrations.\n\nThe Jewish communities across Europe, the Mediterranean and the Middle East were formed from voluntary and involuntary migrants. After the Holocaust (1938 to 1945), there was increased migration to the British Mandate of Palestine, which became the modern state of Israel as a result of the United Nations Partition Plan for Palestine.\n\nProvisions of the Potsdam Agreement from 1945 signed by victorious Western Allies and the Soviet Union led to one of the largest European migrations, and the largest in the 20th century. It involved the migration and resettlement of close to or over 20 million people. The largest affected group were 16.5 million Germans expelled from Eastern Europe westwards. The second largest group were Poles, millions of whom were expelled westwards from eastern Kresy region and resettled in the so-called Recovered Territories (see Allies decide Polish border in the article on the Oder-Neisse line). Hundreds of thousands of Poles, Ukrainians (Operation Vistula), Lithuanians, Latvians, Estonians and some Belarusians were expelled eastwards from Europe to the Soviet Union. Finally, many of the several hundred thousand Jews remaining in Eastern Europe after the Holocaust migrated outside Europe to Israel and the United States.\n\nIn 1947, upon the Partition of India, large populations moved from India to Pakistan and vice versa, depending on their religious beliefs. The partition was created by the Indian Independence Act 1947 as a result of the dissolution of the British Indian Empire. The partition displaced up to 17 million people in the former British Indian Empire, with estimates of loss of life varying from several hundred thousand to a million. Muslim residents of the former British India migrated to Pakistan (including East Pakistan, now Bangladesh), whilst Hindu and Sikh residents of Pakistan and Hindu residents of East Pakistan (now Bangladesh) moved in the opposite direction.\n\nIn modern India, estimates based on industry sectors mainly employing migrants suggest that there are around 100 million circular migrants in India. Caste, social networks and historical precedents play a powerful role in shaping patterns of migration. \n\nResearch by the Overseas Development Institute identifies a rapid movement of labor from slower- to faster-growing parts of the economy. Migrants can often find themselves excluded by urban housing policies, and migrant support initiatives are needed to give workers improved access to market information, certification of identity, housing and education.\n\nIn the riots which preceded the partition in the Punjab region, between 200,000 and 500,000 people were killed in the retributive genocide. U.N.H.C.R. estimates 14 million Hindus, Sikhs and Muslims were displaced during the partition. Scholars call it the largest mass migration in human history: Nigel Smith, in his book \"Pakistan: History, Culture, and Government\", calls it \"history's greatest migration.\"\n\n\n\nBooks\n\nJournals\n\nOnline Books\n\n\n"}
{"id": "2247943", "url": "https://en.wikipedia.org/wiki?curid=2247943", "title": "Home theater in a box", "text": "Home theater in a box\n\nA \"home theater in a box\" (HTIB) is an integrated home theater package which \"bundles\" together a combination DVD or Blu-ray player, a multi-channel amplifier (which includes a surround sound decoder, a radio tuner, and other features), speaker wires, connection cables, a remote control, a set of five or more surround sound speakers (or more rarely, just left and right speakers, a lower-price option known as \"2.1\") and a low-frequency subwoofer cabinet.\nIn 2016,\nthey are manufactured by most makers of consumer electronics. Budget HTIB's with generic or lower-price \"house\" brands (e.g., Best Buy's \"Insignia\" line) may be a \"2.1\" system. Many, however, are a full \"5.1\" system and some higher-end packages even have a 7.1 system. Some popular manufacturers of HTIB's are RCA, Philips, Panasonic, Sony, Yamaha, LG and Samsung, all of which make a variety of mid-price range packages. Bose and Onkyo make higher-end, higher-priced HTIB packages.\n\nHTIBs are marketed as an \"all-in-one\" way for consumers to enjoy the surround sound experience of home cinema, even if they do not want to-or do not have the electronics \"know-how\" to pick out all of the components one-by-one and connect the cables. If a consumer were to buy all of the items individually, they would have to have a basic knowledge of electronics, so they could, for example, ensure that the speakers were of compatible impedance and power-handling for the amplifier. As well, the consumer would have to ensure that they purchased all of the different connection cables, which could include HDMI cables, optical connectors, speaker wire, and RCA connectors.\n\nOn the downside, most HTIBs lack the features and \"tweakability\" of home theater components which are sold separately. For example, while a standalone home theater amplifier may offer extensive equalization options, a HTIB amplifier may simply provide a few factory-set EQ presets. As well, while a standalone home theatre subwoofer may contain a range of sound-shaping circuitry, such as a crossover control, a phase inversion switch, and a parametric equalizer, a HTIB subwoofer system usually has its crossover point set at the factory, which means that the user cannot change it. In some cases, the factory preset crossover point on an HTIB subwoofer may cause it to sound too \"boomy\" in a room.\n\nA typical HTIB generally consists of a central receiver unit which usually contains a DVD player (some systems separate the DVD player into a separate unit), a multi-channel power amplifier and a series of speakers for surround sound use, generally including a subwoofer. Some HTIB systems also have a radio tuner or an Internet-based streaming audio platform (e.g. Spotify). The least expensive systems usually have a passive subwoofer, which is amplified by the receiver unit. HTIB systems do not include a television set or monitor with which to display the visual material or a stand to place the receiver unit on. Beside auxiliary inputs, many of them are equipped today with HDMI with ARC, optical and SPDIF inputs. Some HTIB systems are also equipped with a phono input, to allow the connection of a turntable with magnetic cartridge. However such systems are not suitable for vinyl playing as they are mainly focussed on movies and rarely for high fidelity. Some home theaters are just stereo or 2.1, but even so, they are not intended as hi fi, this is just a marketing strategy.\n\nThere are systems in this class that are sold without a DVD player and are designed to integrate with existing video setups where there is already one, such as a DVD recorder or a DVD/VCR combo unit. The speaker cabinets supplied with most systems in this class are generally fairly small compared to typical stereo speakers, and are meant for wall- or shelf-mounting in tight spaces. There are some systems in this class that are supplied with slim freestanding speakers that stand on the floor. This may be typical of higher-priced systems that are equipped with more powerful amplifiers or most of the \"receiver-only\" packages that do not come with a DVD player.\n\nSome HTIBs use proprietary connectors between components, sometimes even combining several different wires into one connector, to reduce cable clutter and increase the ease of installation. However, this can impede interoperability between different audio/visual devices and makes upgrading certain parts impossible. This may also be used by manufacturers to limit what a consumer can do with a low-end model and encourage them to upgrade should they want more autonomy.\n\nA few manufacturers, notably Sony and Panasonic, have implemented wireless connection technology for the surround speakers in this class of equipment. This technology may be available as standard with some of the high-priced models or may be supplied as an aftermarket kit that only works with selected models in the manufacturer's range. It usually uses a line-level feed over a proprietary wireless link to a separate power amplifier used for the surround-sound channels. This link-receiver and power amplifier can be built into one of the surround speakers or housed in a black box that the surround speakers are connected to. Some higher-end HTIB models offer additional features such as 1080i or 4K ( mainly versions with Blu-ray) video resolution upscaling, a 5-disc platter, HDMI inputs, USB connectivity, Bluetooth support, Wi-fi support, Internet apps, DAB and DAB+, mirroring possibility, iPod dock and a hard disk for recording TV shows.\n\nSome older HTIBs from the 1990s had a built-in VCR, besides a DVD, along with a TV tuner, and a hard disk for recording TV shows.\n"}
{"id": "533017", "url": "https://en.wikipedia.org/wiki?curid=533017", "title": "Horror vacui", "text": "Horror vacui\n\nIn visual art, horror vacui (; from Latin \"fear of empty space\"), also kenophobia (from Greek \"fear of the empty\"), is the filling of the entire surface of a space or an artwork with detail.\n\nThe term is associated with the Italian art critic and scholar Mario Praz, who used it to describe the suffocating atmosphere and clutter of interior design in the Victorian age. Older, and more artistically esteemed examples can be seen on Migration period art objects like the carpet pages of Insular illuminated manuscripts such as the Book of Kells. This feeling of meticulously filling empty spaces also permeates Arabesque Islamic art from ancient times to the present. Another example comes from ancient Greece during the Geometric Age (1100 - 900 BCE), when horror vacui was considered a stylistic element of all art. The mature work of the French Renaissance engraver Jean Duvet consistently exhibits horror vacui.\n\nSome examples of horror vacui in art come from, or are influenced by, the mentally unstable and inmates of psychiatric hospitals, such as Richard Dadd in the 19th century, and many modern examples fall under the category of Outsider Art. Horror vacui may have also had an impact, consciously or unconsciously, on graphic design by artists like David Carson or Vaughan Oliver, and in the underground comix movement in the work of S. Clay Wilson, Robert Crumb, Robert Williams, and on later comic artists such as Mark Beyer. The paintings of Williams, Faris Badwan, Emerson Barrett, Joe Coleman and Todd Schorr are further examples of horror vacui in the modern Lowbrow art movement.\n\nThe entheogen-inspired visionary art of certain indigenous peoples, such as the Huichol yarn paintings and the ayahuasca-inspired art of Pablo Amaringo, often exhibits this style, as does the psychedelic art movement of the 1960s counterculture. Sometimes the patterned art in clothing of indigenous peoples of Middle and South America exhibits horror vacui. For example, the geometric molas of Kuna people and the traditional clothing on Shipibo-Conibo people.\n\nThe artwork in the Where's Wally? series of children's books is a commonly known example of horror vacui, as are many of the small books written or illustrated by the macabre imagination of Edward Gorey.\n\nThe Tingatinga painting style of Dar es Salaam in Tanzania is a contemporary example of horror vacui. Other African artists such as Malangatana of Mozambique (Malangatana Ngwenya) also fill the canvas in this way.\n\nThe arrangement of Ancient Egyptian hieroglyphs suggests an abhorrence of empty space. Signs are repeated or phonetic complements added to prevent gaps.\n\nHorror vacui also strikes mapmakers. In the times of the Discoveries, for instance, it was common for cartographers to fill in the \"Terra incognita\" or the poorly known oceans with monsters or simply with the scale of the map, rather than to leave them blank.\n\nThere is an inverse relationship between \"horror vacui\" and value perception, and commercial designers favour minimalism in shop window displays and advertising to appeal to affluent and well-educated consumers, on the premise that understatement and restraint appeals more to affluent and well-educated audiences.\n\nThe term is also used as an analogy to the Aristotelian idea that a physical vacuum is impossible, and therefore the idea must be rejected. This was widely believed up to the time of Rene Descartes.\n\n"}
{"id": "12721996", "url": "https://en.wikipedia.org/wiki?curid=12721996", "title": "Human figure", "text": "Human figure\n\nIn aesthetics, the human figure or human form in art, sculpture and other art forms involves a study and appreciation of the beauty of the human body in its depiction or presentation. The study involves an appreciation of the body shape, including body postures - sitting, standing or even sleeping, and movements - walking, running, dancing etc. Kant refers to the human figure as the ideal of beauty. The human figure conforms very well to the law that states that form follows function, which is believed to be a result of evolution over thousands of generations.\n\nThe human figure is one of the most enduring themes in the visual arts. Very few art forms are not related to human figure such as music, though it figures in lyrics. A study of the human figure includes a detailed study of the following subjects:\n\n\"Body proportions\" are the study of relation of human body, or in general, animal body, parts to each other and the whole, essential for depiction of the overall figure.\n\nA figure drawing is a study of the human form in its various shapes and postures. It is a study or stylized depiction of the human form, with the line and form of the human figure as the primary objective, rather than the subject person. It is a composed image of the subject in a still position. A life drawing is a work that has been drawn from an observation of a live model. \n\n\n"}
{"id": "46531067", "url": "https://en.wikipedia.org/wiki?curid=46531067", "title": "Identification in rhetoric", "text": "Identification in rhetoric\n\nContemporary rhetoric focuses on cultural contexts and general structures of rhetoric structures. Kenneth Burke is one of the most notable contemporary U.S. rhetoricians who made major contributions to the rhetoric of identification. One of his most foundational ideas is as follows, “rhetoric makes human unity possible, that language use is symbolic action, and that rhetoric is symbolic inducement.” Branching from this, Herrick states that identification in rhetoric is crucial to persuasion, and thus to cooperation, consensus, compromise, and action. Burke believed that the most serious human problem was to be alienated or separated, and rhetoric was to be that problem’s only solution. Much of his work was based on bringing people back together. “Identification is affirmed with earnestness precisely because there is division. Identification is compensatory to division.” Rhetoric’s goal, in regards to identification, is to bring people together of whom have been separated by estrangement or opposition.\n\nKenneth Burke plays an important part in learning and understanding the core values of rhetorical theory in identification. He introduces the notion by taking the Aristotelian approach into a \"world of particulars.\" Burke states that Aristotle treated rhetoric as purely verbal. But there are also areas of overlap. The flexibility of identification that Burke has created expands into elements beyond language. Burke wrote that “identification ranges from the politician who, addressing an audience of farmers, says, ‘I was a farm boy myself,’ through the mysteries of social status, to the mystic’s devout identification with the source of all being.” This symbolic interaction is possible because it recognizes the hidden sources of identification among human beings as symbol users. From this, Burke understands symbols as something that is around constantly, and that choosing to accept and learning to read them accurately is what needs to be understood.\n\nBurke’s theory of identification has been applied and expanded upon in Krista Ratcliffe’s Rhetorical Listening Framework. Ratcliffe proposes the “blurring of Burke’s and Fuss’s theories of identification, what becomes visible is multiple places for rhetorical listening. When applying Burke and Fuss’s theories, Ratcliffe proposes non-identification in cross-cultural communication and feminist pedagogy. Her critique of Western logic is that it is difficult to simultaneously pay attention to both commonalities and differences, but that is where non-identification exists and thus provides a place for rhetorical listening. Burke’s theory is critiqued by Ratcliffe for only focusing on identification; she argues that rhetorical listeners need to be accountable and take into consideration different points of view, which can be done through simultaneous listening to commonalities and differences.\n\nRatcliffe draws upon Diane Fuss because Fuss expands Burke’s theory of identification to gear toward examining the differences in identificaion. Fuss defines Identification as related to the issue of connection between opposite entities, such as the interrelation between self and other, subject and object, and insiders and outsiders. For Fuss, identification is difficult to pinpoint, as the distinction between opposite entities is porous, oftentimes “impossibly confused and finally untenable.” Fuss further builds the connection between identification and disidentification. Fuss defines disidentification as contingent on previous identification with another group, no matter how stereotypical the identification is, while at the same time the identification has receded from the subconscious. Ratcliffe argues that previously identification has been configured as a metaphor, which is manifested in Burke’s consubstantiality and Fuss’s (dis)identification. Ratcliffe notes that metaphor has been used to function as the dominant trope for identification; however, metaphor foregrounds commonalities more than differences. Ratcliff suggests theorizing identification via the use of metonymy to counter the privilege of communality. Intrinsic to the trope of metonymy is an attention to both commonalities and differences.\n\nPractical applications of Burke’s “identification” can be seen in the scholarly effort to reframe identifications. Assembling essays from the fifth Biennial Rhetoric Society of America Conference, Michelle Ballif addresses Ratcliffe’s call for rethinking Burke’s notion of identification “as a place of perpetual reframing that affects who, how, and what can be thought, spoken, written, and imagined.” While some of the essay contributors draw upon Burke’s theory to reinterpret social identifications, others turn to specific social actions to reread Burke’s “identification.” For instance, following Ratcliffe’s critique of Burke’s theory for its lack of attention to difference, Dominic J. Ashby destabilizes Burke’s relatively fixed and teleological construction of identification with “a fluid and contingent notion of self”—that is, “uchi/soto,\" or inside/outside in Japanese rhetoric—highlighting a simultaneous exclusion and inclusion of outsiders through an ongoing unfolding of group dynamics. By way of analyzing the Facebook news feed of “We are all Khaled Said,” Katherine Bridgman expands Burkean identification to “embodiment,” or the mutually coordinated experience between speakers and their audiences triggered by specific circumstances. Along a similar vein, critiquing Burke’s consubstantiality for being sexually indifferent, Janice Odom draws from Irigaray’s feminist theories to reframe identification as a playground of sexual dominance and surrender.\n\n"}
{"id": "44310262", "url": "https://en.wikipedia.org/wiki?curid=44310262", "title": "Indignation (word)", "text": "Indignation (word)\n\nThe word indignation is used to describe strong displeasure at something considered unjust, offensive, insulting or unrighteous.\n\nThe term was coined in France during the 12th Century. It comes from the Latin word \"indignationem\", meaning displeasure. In nominative form, \"indignationem\" is \"indignatio\". \"Indignation\" is a noun of action from the past participle stem of \"indignari\", meaning unworthy, to be angry at, or to be displeased with.\n\nAccording to Cicero’s \"De Inventione\", Book I, “indignation is a kind of speech by which the effect produced is, that great hatred is excited against a man, or dislike of some proceeding is originated.” The goal is for the speaker to create anger projected towards the opponent or the accused such that the speaker is seen more positively than the opponent. One of the features of \"indignatio\" is that it cannot function without a target of displeasure. To successfully employ the technique, the speaker must have a target, an audience with which the speaker identifies, and a desired reaction. If a speaker achieves a reaction from the audience in which they are displeased with his opponent, then the speaker has successfully employed \"indignation\".\n\nAristotle wrote in his Book II, Chapter 9, “indignation is the emotion most directly opposed to pity.” Aristotle also writes “Indignation is pain caused by the sight of undeserved good fortune.” The terms indignation and indignatio are closely related in part by their common negative emotionality and anger. A speaker may successfully employ indignatio and the audience will feel indignation towards the opponent.\n"}
{"id": "25328618", "url": "https://en.wikipedia.org/wiki?curid=25328618", "title": "International Institute for Inter-Religious Dialogue and Diplomacy", "text": "International Institute for Inter-Religious Dialogue and Diplomacy\n\nThe International Institute for Inter-Religious Dialogue and Diplomacy is an affiliated institution of EUCLID (Euclid University). Its main focus is education in the application of diplomatic methods to interreligious dialogue, notably between Christianity and Islam.\n"}
{"id": "2843876", "url": "https://en.wikipedia.org/wiki?curid=2843876", "title": "Isotopic signature", "text": "Isotopic signature\n\nAn isotopic signature (also isotopic fingerprint) is a ratio of non-radiogenic 'stable isotopes', stable radiogenic isotopes, or unstable radioactive isotopes of particular elements in an investigated material. The ratios of isotopes in a sample material are measured by isotope-ratio mass spectrometry against an isotopic reference material. This process is called isotope analysis.\n\nThe atomic mass of different isotopes affect their chemical kinetic behavior, leading to natural isotope separation processes.\n\nFor example, different sources and sinks of methane have different affinity for the C and C isotopes, which allows distinguishing between different sources by the C/C ratio in methane in the air. In geochemistry, paleoclimatology and paleoceanography this ratio is called δC. The ratio is calculated with respect to Pee Dee Belemnite (PDB) standard:\n\nSimilarly, carbon in inorganic carbonates shows little isotopic fractionation, while carbon in materials originated by photosynthesis is depleted of the heavier isotopes. In addition, there are two types of plants with different biochemical pathways; the C3 carbon fixation, where the isotope separation effect is more pronounced, C4 carbon fixation, where the heavier C is less depleted, and Crassulacean Acid Metabolism (CAM) plants, where the effect is similar but less pronounced than with C plants. Isotopic fractionation in plants is caused by physical (slower diffusion of C in plant tissues due to increased atomic weight) and biochemical (preference of C by two enzymes: RuBisCO and phosphoenolpyruvate carboxylase) factors. The different isotope ratios for the two kinds of plants propagate through the food chain, thus it is possible to determine if the principal diet of a human or an animal consists primarily of C plants (rice, wheat, soybeans, potatoes) or C plants (corn, or corn-fed beef) by isotope analysis of their flesh and bone collagen (however, to obtain more accurate determinations, carbon isotopic fractionation must be also taken into account, since several studies have reported significant C discrimination during biodegradation of simple and complex substrates).\nWithin C3 plants processes regulating changes in δC are well understood, particularly at the leaf level, but also during wood formation. Many recent studies combine leaf level isotopic fractionation with annual patterns of wood formation (i.e. tree ring δC) to quantify the impacts of climatic variations and atmospheric composition on physiological processes of individual trees and forest stands. The next phase of understanding, in terrestrial ecosystems at least, seems to be the combination of multiple isotopic proxies to decipher interactions between plants, soils and the atmosphere, and predict how changes in land use will affect climate change.\nSimilarly, marine fish contain more C than freshwater fish, with values approximating the C and C plants respectively.\n\nThe ratio of carbon-13 and carbon-12 isotopes in these types of plants is as follows:\n\nLimestones formed by precipitation in seas from the atmospheric carbon dioxide contain normal proportion of C. Conversely, calcite found in salt domes originates from carbon dioxide formed by oxidation of petroleum, which due to its plant origin is C-depleted. The layer of limestone deposited at the Permian extinction 252 Mya can be identified by the 1% drop in C/C.\n\nThe C isotope is important in distinguishing biosynthetized materials from man-made ones. Biogenic chemicals are derived from biospheric carbon, which contains C. Carbon in artificially made chemicals is usually derived from fossil fuels like coal or petroleum, where the C originally present has decayed below detectable limits. The amount of C currently present in a sample therefore indicates the proportion of carbon of biogenic origin.\n\nNitrogen-15, or N, is often used in agricultural and medical research, for example in the Meselson–Stahl experiment to establish the nature of DNA replication. An extension of this research resulted in development of DNA-based stable-isotope probing, which allows examination of links between metabolic function and taxonomic identity of microorganisms in the environment, without the need for culture isolation. Proteins can be isotopically labelled by cultivating them in a medium containing N as the only source of nitrogen, e.g., in quantitative proteomics such as SILAC.\n\nNitrogen-15 is extensively used to trace mineral nitrogen compounds (particularly fertilizers) in the environment. When combined with the use of other isotopic labels, N is also a very important tracer for describing the fate of nitrogenous organic pollutants. Nitrogen-15 tracing is an important method used in biogeochemistry.\n\nThe ratio of stable nitrogen isotopes, N/N or δN, tends to increase with trophic level, such that herbivores have higher nitrogen isotope values than plants, and carnivores have higher nitrogen isotope values than herbivores. Depending on the tissue being examined, there tends to be an increase of 3-4 parts per thousand with each increase in trophic level. The tissues and hair of vegans therefore contain significantly lower δN than the bodies of people who eat mostly meat. Similarly, a terrestrial diet produces a different signature than a marine-based diet. Isotopic analysis of hair is an important source of information for archaeologists, providing clues about the ancient diets and differing cultural attitudes to food sources.\n\nA number of other environmental and physiological factors can influence the nitrogen isotopic composition at the base of the food web (i.e. in plants) or at the level of individual animals. For example, in arid regions, the nitrogen cycle tends to be more 'open' and prone to the loss of N, increasing δN in soils and plants. This leads to relatively high δN values in plants and animals in hot and arid ecosystems relative to cooler and moister ecosystems. Furthermore, elevated δN have been linked to the preferential excretion of 14N and reutilization of already enriched 15N tissues in the body under prolonged water stress conditions or insufficient protein intake. \n\nδN also provides a diagnostic tool in planetary science as the ratio exhibited in atmospheres and surface materials \"is closely tied to the conditions under which materials form\".\n\nOxygen comes in three variants, but the O is so rare that it is very difficult to detect (~0.04% abundant). The ratio of O/O in water depends on the amount of evaporation the water experienced (as O is heavier and therefore less likely to vaporize). As the vapor tension depends on the concentration of dissolved salts, the O/O ratio shows correlation on the salinity and temperature of water. As oxygen gets built into the shells of calcium carbonate secreting organisms, such sediments prove a chronological record of temperature and salinity of the water in the area.\n\nOxygen isotope ratio in atmosphere varies predictably with time of year and geographic location; e.g. there is a 2% difference between O-rich precipitation in Montana and O-depleted precipitation in Florida Keys. This variability can be used for approximate determination of geographic location of origin of a material; e.g. it is possible to determine where a shipment of uranium oxide was produced. The rate of exchange of surface isotopes with the environment has to be taken in account.\n\nLead consists of four stable isotopes: Pb, Pb, Pb, and Pb. Local variations in uranium/thorium/lead content cause a wide location-specific variation of isotopic ratios for lead from different localities. Lead emitted to the atmosphere by industrial processes has an isotopic composition different from lead in minerals. Combustion of gasoline with tetraethyllead additive led to formation of ubiquitous micrometer-sized lead-rich particulates in car exhaust smoke; especially in urban areas the man-made lead particles are much more common than natural ones. The differences in isotopic content in particles found in objects can be used for approximate geolocation of the object's origin.\n\nHot particles, radioactive particles of nuclear fallout and radioactive waste, also exhibit distinct isotopic signatures. Their radionuclide composition (and thus their age and origin) can be determined by mass spectrometry or by gamma spectrometry. For example, particles generated by a nuclear blast contain detectable amounts of Co and Eu. The Chernobyl accident did not release these particles but did release Sb and Ce. Particles from underwater bursts will consist mostly of irradiated sea salts. Ratios of Eu/Eu, Eu/Eu, and Pu/Pu are also different for fusion and fission nuclear weapons, which allows identification of hot particles of unknown origin.\n\nIn archaeological studies, stable isotope ratios have been used to track diet within the time span formation of analyzed tissues (10-15 years for bone collagen and intra-annual periods for tooth enamel bioapatite) from individuals; \"recipes\" of foodstuffs (ceramic vessel residues); locations of cultivation and types of plants grown (chemical extractions from sediments); and migration of individuals (dental material).\n\nWith the advent of stable isotope ratio mass spectrometry, isotopic signatures of materials find increasing use in forensics, distinguishing the origin of otherwise similar materials and tracking the materials to their common source. For example, the isotope signatures of plants can be to a degree influenced by the growth conditions, including moisture and nutrient availability. In case of synthetic materials, the signature is influenced by the conditions during the chemical reaction. The isotopic signature profiling is useful in cases where other kinds of profiling, e.g. characterization of impurities, are not optimal. Electronics coupled with scintillator detectors are routinely used to evaluate isotope signatures and identify unknown sources.\n\nA study was published demonstrating the possibility of determination of the origin of a common brown PSA packaging tape by using the carbon, oxygen, and hydrogen isotopic signature of the backing polymer, additives, and adhesive.\n\nMeasurement of carbon isotopic ratios can be used for detection of adulteration of honey. Addition of sugars originated from corn or sugar cane (C4 plants) skews the isotopic ratio of sugars present in honey, but does not influence the isotopic ratio of proteins; in an unadulterated honey the carbon isotopic ratios of sugars and proteins should match. As low as 7% level of addition can be detected.\n\nNuclear explosions form Be by a reaction of fast neutrons with C in the carbon dioxide in air. This is one of the historical indicators of past activity at nuclear test sites.\n\nIsotopic fingerprints are used to study the origin of materials in the Solar System. For example, the Moon's oxygen isotopic ratios seem to be essentially identical to Earth's. Oxygen isotopic ratios, which may be measured very precisely, yield a unique and distinct signature for each solar system body. Different oxygen isotopic signatures can indicated the origin of material ejected into space. The Moon's titanium isotope ratio (Ti/Ti) appears close to the Earth's (within 4 ppm). In 2013, a study was released that indicated water in lunar magma was 'indistinguishable' from carbonaceous chondrites and nearly the same as Earth's, based on the composition of water isotopes.\n\nIsotopic fingerprints typical of life, preserved in sediments, have been used to suggest that life existed on the planet already by 3.85 billion years ago.\n\n\n"}
{"id": "32687746", "url": "https://en.wikipedia.org/wiki?curid=32687746", "title": "Josette Rey-Debove", "text": "Josette Rey-Debove\n\nJosette Rey-Debove, born November 16, 1929 in Calais (Pas-de-Calais), France and died February 22, 2005 in Senegal, was a lexicographer and semiologist, wife and colleague of Alain Rey. She was the first female lexicographer in France, and held many prominent posts in this field, where she used her influence to promote feminist changes to French language usage.\n\nA graduate of the University of Sorbonne, with a doctorate of linguistics, she began her career in 1952 as a lecturer of French at the College of Paris. The following year, she became an editor of language dictionaries at the Société du Nouveau Littré. She subsequently worked at Dictionnaires Le Robert, the most prominent publisher of dictionaries in the French language. It was there that she met Alain Rey, whom she married on September 11, 1954.\n\nShe contributed to dictionaries for Dictionnaires Le Robert, collaborating on the Petit Robert for the French language, at Robert des Enfants (the company's division for publishing the Children's Robert dictionaries), then to Dictionnaire du français (foreign language edition) and to Robert Méthodique-Brio. In 1977, she became secretary-general of Dictionnaires Le Robert, a position she held until 1994.\n\nA well-known linguist who promoted feminist changes to French usage, she was named to various commissions to develop the standards of the language : the Commission de la féminisation du vocabulaire au ministère des droits de la femme between 1984 et 1985, the Commission d'expertise pour la réforme de l'orthographe au Conseil supérieur de la langue française in 1989, the Commission d'orientation pour la simplification du language administratif au ministère de la Fonction publique et de la Réforme de l'État in 2001, the Office québécois de la langue française sur la terminologie, la néologie et la méthodologie du travail terminologique during the 1970s.\n\nShe was also a professor of lexicology and semiology at the University Paris III-Sorbonne Nouvelle throughout the 1970s, subsequently at the University Paris VII-Denis Diderot during the 1980s, and at the École des hautes études en sciences sociales beginning in 2002. A friend of many of the members of Oulipo (Bernard Cerquiglini, Paul Fournel), she was their visiting scholar in 1986.\n\n\n\n"}
{"id": "56783575", "url": "https://en.wikipedia.org/wiki?curid=56783575", "title": "Kathryn B. H. Clancy", "text": "Kathryn B. H. Clancy\n\nKathryn Bridges Harley Clancy (also known as Kate Clancy) is an American biological anthropologist who specialises in reproductive health. She is Associate Professor at the University of Illinois, in the Department of Anthropology. Her additional research and policy advocacy work focuses on sexual harassment in science and academia.\n\nClancy's fertility research focuses on menstruation and variability in endometrial function. Clancy's early published research demonstrated that, contrary to previous belief, menstruation does not increase risk for iron-deficiency anemia. Instead, Clancy and colleagues show that a thicker endometrium is associated with greater iron reserves amongst healthy women. Clancy's later studies focus on rural Polish populations. Clancy explores potential variation amongst endometrial function, or the functions of the inner mucous membrane layer of the uterus. Her research finds that endometrial thickness is negatively correlated over the latter phase of the menstrual cycle (the luteal phase).\n\nClancy's research contributes to understandings of fertility variation amongst normal, premenopausal Western women. For example, Swedish women appear to show an increase in endometrial thickness in the early part of the luteal phase, while for Canadian and English women, patterns appear largely stable at similar times. Canadian and Swedish women's endometrial thickness drops at other times, and while for Scottish sample, there is an increase. Clancy and colleagues' research suggests that endometrial thickness should be measured daily to better capture and study this variation.\n\nClancy has also made a broader contribution to the study of human evolutionary biology and ecological stress on ovaries and endometrial function. She finds that immune stress and psychosocial stress impacts on the endometrium's ability to carry a fetus through the mechanism of inflammation.\n\nClancy's later research focuses on primate development. She has also dispelled the myth that women's menstrual cycles can become synchronised due to their close social bonds.\n\nClancy is part of a team of anthropologists who led the Survey of Academic Field Experiences study, also known as SAFE13. The study, co-authored with Robin G. Nelson, Julienne N. Rutherford and Katie Hinde, analysed experiences of sexual harassment and sexual assault in scientific fieldwork sites. The study found the majority of researchers had been exposed to, or experienced, sexual harassment, especially women and junior scientists.\n\nA follow-up study (known as \"SAFE 2\"), led by Nelson, Rutherford, Hinde and Clancy identified systemic patterns that lead to negative fieldwork experiences and harassment. Field sites that have clear codes of conduct and consequences for behaviour are less likely to lead to sexual harassment. Where problems arise, these sites deal with issues swiftly and consistently, leading to higher levels of perceived safety and equality. In fieldwork sites where clear rules and consequences do not exist or are ambiguous, leaders do not take action against harassment. This leads to ongoing alienation and professional retaliation.\n\nThe SAFE13 study and subsequent research and activities (media interviews, conferences and advocacy) have made significant impact on increasing awareness of institutional responses to sexual harassment, as well as policy reform. On 27 February 2018, Clancy, provided testimony to the Subcommittee on Research and Technology Hearing on sexual harassment in science. Clancy testified that creating a safe, harassment-free workplace culture was imperative to improving science.\n\nIn 2017, Clancy led another study on sexual harassment in collaboration with Katharine M. N. Lee, Erica M. Rodgers and Christina Richey. The research involved an online survey of 474 astronomers and planetary scientists. It is the first study of its kind in the physical sciences, and it is the first large study to examine both gender and racial harassment in academic science.\n\nThe study finds that 88% of participants had heard negative language at work, along with other verbal and physical abuse that made them feel unsafe. Women of colour, however, experienced the greatest level of hostility due to their race and gender. They experienced greater incidents of gendered and racialised harassment and were more attuned to noticing other forms of harassment such as homophobia. Forty percent of women of colour feel unsafe at work due to their gender or sex, and 28% due to their race. Women of colour are also more likely to skip educational and professional opportunities, such as meetings and conferences, in an attempt to minimise exposure to hostility and harassment.\n\nThe study received wide media coverage, as it provided evidence on how harassment limits women's career outcomes, especially for racial minority women. Clancy also noted that the study unearths how survivors are re-traumatised by existing reporting systems that have no intermediary level of support in between staying silent and launching a formal report. The study has been commended for showing how racial discrimination compounds experiences of sexual harassment. The study also shows that the impact of harassment contributes to a higher loss of women of colour in science relative to White women scientists. The study raises questions about bystander interventions, given the hostile culture towards women of colour is evident to witnesses, who do not feel empowered to act.\n\nClancy served on the National Academies of Sciences, Engineering, and Medicine's 2018 consensus report entitled \"Sexual Harassment of Women: Climate, Culture, and Consequences in Academic Sciences, Engineering, and Medicine.\"\n\nIn 2006, Clancy worked as a lecturer at Yale University. One year later, she joined Harvard University as Preceptor Faculty and Associate at the Department of Anthropology. She has worked at the University of Illinois since 2008, where she started as a lecturer and now works as an Associate Professor in Anthropology. Clancy currently leads the Clancy Lab group within the Laboratory for Evolutionary Endocrinology at the University of Illinois. She is also Co-Director of the Laboratory.\n\nSince September 2016, Clancy has hosted the Period Podcast, where she discusses issues regarding the science of menstrual cycles. This theme is connected to her early research.\n\nClancy graduated with a Bachelor of Arts degree cum laude from Harvard University in 2001, specialising in Biological Anthropology and Women's Studies. She obtained her PhD in Anthropology from Yale University in 2007.\n"}
{"id": "2094788", "url": "https://en.wikipedia.org/wiki?curid=2094788", "title": "Kozma Prutkov", "text": "Kozma Prutkov\n\nKozma Petrovich Prutkov () is a fictional author invented by Aleksey Konstantinovich Tolstoy and his cousins, three Zhemchuzhnikov brothers, Alexei, Vladimir and Alexander, during the later part of the rule of Nicholas I of Russia.\n\nThe four distinguished satirical poets used this pseudonym as a collective pen name to publish aphorisms, fables, epigrams, satiric, humorous and nonsense verses in the 1850s–1860s, most notably in the literary magazine \"Sovremennik\" (\"The Contemporary\").\n\nAccording to the \"Biographical data on Kozma Prutkov\", Prutkov was born on April 11, 1803 and died on January 13, 1863. He worked for the government of the Russian Empire his entire adult life, and in 1820 entered military service as a Hussar only for the uniform. He worked at the Assay Office (Пробирная Палата) from 1823 until his death, ending up as its director. \n\nSome of his best-known and most-cited quotes include:\n\n"}
{"id": "24598544", "url": "https://en.wikipedia.org/wiki?curid=24598544", "title": "Least objectionable program", "text": "Least objectionable program\n\nThe theory of the least objectionable program (LOP) is a mediological theory explaining television audience behavior. It was developed in the 1960s by then executive of audience measurement at NBC, Paul L. Klein, \n\nIn an article \"Why You Watch What You Watch When You Watch\" (published in \"TV Guide\" in 1971), Klein explained that viewers consume the medium of television rather than television shows, treating the medium as the end of their consumption itself rather than using the set as a means to access specific programs they like the way they might choose a book from a shelf to access the story within. Since the introduction of television, the same percentage of sets are in use on, say, a Thursday evening at a certain hour, year after year, regardless of what content is broadcast. This is because unlike the way people use books, museums, or the cinema as means of consuming desired content, audiences consume television, the medium, as the desired object. TV viewers turn the set on, deciding to \"watch television\", and then seek out something to watch from what is available, flipping around, not until they find \"something they like\" - because television programming is in fact very rarely satisfying, and viewers rarely watch anything they actually like - but until they find something that doesn't offend them enough to make them flip to the next channel. (Viewers almost never turn off the set as a result of finding nothing tolerable and judging every program available boring or otherwise objectionable. Viewers commonly watch programs they describe later as unbearable, everything else on being even more intolerable. A more common response to a whole spectrum of equally unendurable choices than choosing to abandon the medium is to continue to flip frequently until new choices become available.) Thus, for programmers of television channels, Klein recommended understanding that audience attraction was a matter not of pleasing the greatest number of viewers but of offending the fewest (driving the fewest away to the competitors who may repulse them less). The television audience is in a kind of partial trance. A network will do better worrying less about not giving an audience enough to like, to be surprised and delighted by, and to engage their attention, than about avoiding, as Klein said, \"disturbing their reverie\" with something that causes them to change the channel. Thus, even as channel choices proliferate alongside numerous easily accessed out-of-schedule viewing options, successful television programs remain, as they have always been, formulaic, cliché, \"instantly familiar,\" predictable, and monotonous in tone.\n\nIt has been widely suggested that the theory itself is obsolete thanks to high quality shows, top-rated options and viewers' choice of shows whether live or time-shifted alongside the advancements of DVDs and Netflix. \n\n\n"}
{"id": "2643048", "url": "https://en.wikipedia.org/wiki?curid=2643048", "title": "Media transparency", "text": "Media transparency\n\nMedia transparency(or transparent media), sometimes also referred to as media opacity, is a concept that ponders on how and why information subsidies are being produced, distributed and handled by media professionals, including journalists, editors, public relations practitioners, public affairs specialists, and spokespeople. In short, media transparency reflects the relationship between journalists and news sources. \n\nMedia transparency deals with the openness and accountability of the media and can be defined as a transparent exchange of information subsidies based on the ideas of newsworthiness.Media transparency is one of the biggest challenges of contemporary everyday media practices around the world as media outlets and journalists constantly experience pressures from advertisers, information sources, publishers, and other influential groups\n\nNews sources may influence what information is published or not published. Sometimes, published information can also be paid for by news sources, but the end media product (an article, a program, a blog post) does not clearly indicate that the message has been paid or influenced in any way. Such media opacity, or media non-transparency, ruins the trust and transparency between the media and the public and have implications for transparency of new forms of advertising and public relations (such as native advertising and brand journalism).\n\nMedia transparency is a normative concept and is achieved when: 1) there are many competing sources of information; 2) the method of information delivery is known; and 3) funding of media production is disclosed and publicly available.\n\nThe concept has emerged in response to claims of bias in media, and the lack of media transparency can be perceived as a form of corruption. Media transparency is a means to diminish unethical and illegal practices in the relationships between news sources and the media. \n\nIndirect payments and influences were defined as “any type of non-monetary reward to a journalist, editor, or media outlet or the existence of a media policy which dictates, encourages indirect payments or influences the financial success and independence of the media outlet or its employees”\n\nAcademics at the University of Oxford and Warwick Business School, conducting empirical research on the operation and effects of transparent forms of clinical regulation in practice, describe a form of 'spectacular transparency'. They suggest that government policy tends to react to high-profile media 'spectacles', leading to regulatory policy decisions that appear to respond to problems exposed in the media have new perverse effects in practice, which are unseen by regulators or the media.\n\nThe degree to which state agents work to influence video production contradicts the use of those images by news organizations as indexical, objective representations. Because people tend to strongly equate seeing with knowing, video cultivates an inaccurate impression that they are getting the \"full picture\". It has been said that \"what is on the news depends on what can be shown\". The case studies for this project demonstrate that what can be shown is often decided in concern with political agents. Essentially, the way the media presents its information creates an illusion of transparency.\n\n\n\n"}
{"id": "364575", "url": "https://en.wikipedia.org/wiki?curid=364575", "title": "Mock-heroic", "text": "Mock-heroic\n\nMock-heroic, mock-epic or heroi-comic works are typically satires or parodies that mock common Classical stereotypes of heroes and heroic literature. Typically, mock-heroic works either put a fool in the role of the hero or exaggerate the heroic qualities to such a point that they become absurd.\n\nHistorically, the mock-heroic style was popular in 17th century Italy, and in the post-Restoration and Augustan periods in Great Britain.\n\nThe earliest example of the form is the \"Batrachomyomachia\" ascribed to Homer by the Romans and parodying his work, but believed by most modern scholars to be the work of an anonymous poet in the time of Alexander the Great .\n\nA longstanding assumption on the origin of the mock-heroic in the 17th century is that epic and the pastoral genres had become used up and exhausted, and so they got parodically reprised. In the 17th century the epic genre was heavily criticized, because it was felt expressing the traditional values of the feudal society.\nAmong the new genres, closer to the modern feelings and proposing new ideals, the satirical literature was particularly effective in criticizing the old habits and values. Beside the Spanish picaresque novels and the French burlesque novel, in Italy flourished the \"poema eroicomico\". <br>\nIn this country those who still wrote epic poems, following the rules set by Torquato Tasso in his work \"Discorsi del poema eroico\" (\"Discussions about the Epic Poems\") and realized in his masterwork, the \"Jerusalem Delivered\", were felt as antiquated.<br>\nThe new mock-heroic poem accepted the same metre, vocabulary, rhetoric of the epics. However, the new genre turned the old epic upside down about the meaning, setting the stories in more familiar situations, to ridiculize the traditional epics. In this context was created the parody of epic genre.\n\n\"Lo scherno degli dèi\" (\"The Mockery of Gods\") by Francesco Bracciolini, printed in 1618 is often regarded as the first Italian \"poema eroicomico\".\nHowever, the best known of the form is \"La secchia rapita\" (\"The rape of the Bucket\") by Alessandro Tassoni (1622). <br>Other Italian mock-heroic poems were \"La Gigantea\" by Girolamo Amelonghi (1566), the \"Viaggio di Colonia\" (\"Travel to Cologne\") by Antonio Abbondanti (1625), \"L'asino\" (\"The donkey\") by Carlo de' Dottori (1652), \"La Troja rapita\" by Loreto Vittori (1662), \"Il malmantile racquistato\" by Lorenzo Lippi (1688), \"La presa di San Miniato\" by Ippolito Neri (1764).\n\nAlso in Italian dialects were written mock-heroic poems. For example, in Neapolitan dialect the best known work of the form was \"La Vaiasseide\" by Giulio Cesare Cortese (1612).<br> While in Romanesco Giovanni Camillo Peresio wrote \"Il maggio romanesco\" (1688), Giuseppe Berneri published \"Meo Patacca\" in 1695, and, finally, Benedetto Micheli printed \"La libbertà romana acquistata e defesa\" in 1765.\n\nAfter the translation of \"Don Quixote\", by Miguel de Cervantes, English authors began to imitate the inflated language of Romance poetry and narrative to describe misguided or common characters. The most likely genesis for the mock-heroic, as distinct from the picaresque, burlesque, and satirical poem is the comic poem \"Hudibras\" (1662–1674), by Samuel Butler. Butler's poem describes a \"trew blew\" Puritan knight during the Interregnum, in language that imitates Romance and epic poetry. After Butler, there was an explosion of poetry that described a despised subject in the elevated language of heroic poetry and plays. \n\n\"Hudibras\" gave rise to a particular verse form, commonly called the \"Hudibrastic.\" The Hudibrastic is poetry in closed rhyming couplets in iambic tetrameter, where the rhymes are often feminine rhymes or unexpected conjunctions. For example, Butler describes the English Civil War as a time which \"Made men fight like mad or drunk/ For dame religion as for punk/ Whose honesty all durst swear for/ Tho' not one knew why or wherefore\" (\"punk\" meaning a prostitute). The strained and unexpected rhymes increase the comic effect and heighten the parody. This formal indication of satire proved to separate one form of mock-heroic from the others. After Butler, Jonathan Swift is the most notable practitioner of the Hudibrastic, as he used that form for almost all of his poetry.\n\nPoet Laureate John Dryden is responsible for some of the dominance among satirical genres of the mock-heroic in the later Restoration era. While Dryden's own plays would themselves furnish later mock-heroics (specifically, \"The Conquest of Granada\" is satirized in the mock-heroic \"The Author's Farce\" and \"Tom Thumb\" by Henry Fielding, as well as \"The Rehearsal\"), Dryden's \"Mac Flecknoe\" is perhaps the \"locus classicus\" of the mock-heroic form as it would be practiced for a century to come. In that poem, Dryden indirectly compares Thomas Shadwell with Aeneas by using the language of \"Aeneid\" to describe the coronation of Shadwell on the throne of Dullness formerly held by King Flecknoe. The parody of Virgil satirizes Shadwell. Dryden's prosody is identical to regular heroic verse: iambic pentameter closed couplets. The parody is not formal, but merely contextual and ironic. (For an excellent overview of the history of the mock-heroic in the 17th and 18th centuries see \"the English Mock-Heroic poem of the 18th Century\" by Grazyna Bystydzienska, published by Polish Scientific Publishers, 1982.) \n\nAfter Dryden, the form continued to flourish, and there are countless minor mock-heroic poems from 1680 to 1780. Additionally, there were a few attempts at a mock-heroic novel. The most significant later mock-heroic poems were by Alexander Pope. Pope’s \"The Rape of the Lock\" is a noted example of the Mock-Heroic style; indeed, Pope never deviates from mimicking epic poetry such as Homer's \"Iliad\" and Virgil's \"Aeneid\" . The overall form of the poem, written in cantos, follows the tradition of epics, along with the precursory “Invocation of the Muse”; in this case, Pope's Muse is literally the person who prodded him to write the poem, John Caryll: “this verse to Caryll, Muse, is due!” (line 3). Epics always include foreshadowing which is usually given by an otherworldly figure, and Pope mocks tradition through Ariel the sprite, who sees some “dread event” (line 109) impending on Belinda. These epic introductory tendencies give way to the main portion of the story, usually involving a battle of some kind (such as in the \"Iliad\") that follows this pattern: dressing for battle (description of Achilles shield, preparation for battle), altar sacrifice/libation to the gods, some battle change (perhaps involving drugs), treachery (Achilles ankle is told to be his weak spot), a journey to the Underworld, and the final battle. All of these elements are followed eloquently by Pope in that specific order: Belinda readies herself for the card game (which includes a description of her hair and beauty), the Baron makes a sacrifice for her hair (the altar built for love and the deal with Clarissa), the “mock” battle of cards changes in the Baron’s favor, Clarissa’s treachery to her supposed friend Belinda by slipping the Baron scissors, and finally the treatment of the card game as a battle and the Baron’s victory. Pope’s mastery of the Mock-Heroic is clear in every instance. Even the typical apotheosis found in the epics is mimicked in \"The Rape of the Lock\", as “the stars inscribe Belinda’s name!” (line 150). He invokes the same Mock-heroic style in \"The Dunciad\" which also employs the language of heroic poetry to describe menial or trivial subjects. In this mock-epic the progress of Dulness over the face of the earth, the coming of stupidity and tastelessness, is treated in the same way as the coming of civilization is in the \"Aeneid\" (see also the metaphor of \"translatio studii\"). John Gay's \"Trivia\" and \"Beggar's Opera\" were mock-heroic (the latter in opera), and Samuel Johnson's \"London\" is a mock-heroic of a sort.\n\nBy the time of Pope, however, the mock-heroic was giving ground to narrative parody, and authors such as Fielding led the mock-heroic novel into a more general novel of parody. The ascension of the novel drew a slow end to the age of the mock-heroic, which had originated in Cervantes's novel. After Romanticism's flourishing, mock-heroics like Byron's \"Don Juan\" were uncommon.\n\nFinally, the mock-heroic genre spread throughout Europe, in France, in Scotland, in Poland, in Bohemia, in Russia. The most noted mock-heroic poems in French were \"Le Vergile Travesti\" (\"The disguised Vergil\") by Paul Scarron (1648–52) and \"The Maid of Orleans\" by Voltaire (1730). In macaronic Latin enriched with Scottish Gaelic expressions William Drummond of Hawthornden wrote \"Polemo-Middinia inter Vitarvam et Nebernam\" in 1684. The main author of mock-heroic poems in Polish was Ignacy Krasicki, who wrote \"Myszeida\" (\"Mouseiad\") in 1775 and \"Monacomachia\" (\"The War of the Monks\") in 1778. In the same language Tomasz Kajetan Węgierski published \"Organy\" in 1775-77. The Bohemian poet Šebestiàn Hnĕvkovský in 1805 printed two mock-heroic poems: \"Dĕvin\" in Czech and \"Der böhmische Mägderkrieg\" in German. In 1791 the Russian poet N. P. Osipov published (). Ivan Kotliarevsky's mock-epic poem Eneyida (Ukrainian: Енеїда), written in 1798, is considered to be the first literary work published wholly in the modern Ukrainian language.\n\n"}
{"id": "17315507", "url": "https://en.wikipedia.org/wiki?curid=17315507", "title": "New Zealand studies", "text": "New Zealand studies\n\nNew Zealand studies is the academic field of Area studies of New Zealand.\n\nSubfields:\n\nInstitutions in New Zealand:\n\nInstitutions outside New Zealand:\n\nJournals:\n\nMāori studies is the academic field of Cultural studies of the New Zealand Māori.\n\nSubfields\n\nThe main New Zealand universities all have a \"School of Māori Studies\":\n\n\n"}
{"id": "43297766", "url": "https://en.wikipedia.org/wiki?curid=43297766", "title": "Northampton Sekhemka statue", "text": "Northampton Sekhemka statue\n\nThe Northampton Sekhemka statue is an Ancient Egyptian artefact, given by the Marquess of Northampton to Northampton Museum, in or about 1870. The statue dates from the 5th dynasty (c. 2494–2345 BC, making it slightly older than Stonehenge) and depicts Sekhemka the scribe with his wife, Sitmerit. It was the subject of a controversial sale in July 2014, that raised questions of the museum's ownership and the ethics of selling artefacts. The statue was sold to an unidentified buyer for £15.76m, which broke the world record for Ancient Egyptian art at auction. On 1 August 2014, Northampton Museums had their accreditation removed by Arts Council England, which ruled that the sale did not meet the accredited standards for museums in managing their collections.\n\nThe statue depicts Sekhemka sitting in a traditional scribal pose and holding on his knees a partly unrolled papyrus which lists various offerings. He is named in an inscription on the plinth of his statue as \"Inspector of Scribes in the House of Largesse, one revered before the Great God\". His wife Sit-Merit is shown sitting at his feet. The limestone statue is tall with the base from front to rear being . Archaeologist Mike Pitts, editor of \"British Archaeology\", took many detailed colour photographs of the statue whilst it was on display in Christie's prior to auction and has published them on his own blog.\n\nThe statue's provenance is unclear. \"Al-Ahram Weekly\" reports that one account describes the statue as being acquired by Northampton Museum in 1849 from the Ottoman sultan, while another version holds that it was acquired by the 2nd Marquess of Northampton during a trip to Egypt, after which his son offered it to Northampton Museum in the 19th century. T. G. H. James noted in 1961 that Northampton Museum held no precise information regarding the acquisition of the statue, but that it was presented to the museum around 1870 by the 3rd Marquess of Northampton and, based on a record from 1899, it is likely to have been acquired by the 2nd Marquess during a trip to Egypt in 1850.\n\nNorthampton Borough Council claimed that they learned the full value of the Sekhemka statue in 2012 during an insurance assessment, and according to \"The Daily Telegraph\" it \"immediately began making plans to cash it in and use the money for other heritage projects in the region.\" The then leader of Northampton Borough Council, David Mackintosh, told the BBC that the statue had \"been in our ownership for over 100 years and it's never really been the centrepiece of our collection\", and that \"We want to expand our museum and to do that we need to raise the money\". The council proposed to use the amount realized through a sale for funding “the restoration of Delapre Abbey, improvements to the museum service and/or other cultural or heritage projects” but the Museum Association asked that proposed sale be halted pending consultation which \"was needed to establish the financially motivated disposal was 'last resort'\"\n\nThe council stated that when the statue was valued in 2010 it was taken off display because of security concerns, and that it would have required 24-hour guarding. However, Axa Art Insurance Ltd subsequently reported that the cabinet display previously used in Northampton Museum was \"adequate\". The council were also asked \"why, when the Friends of Northampton Museum and Art Gallery offered £8,000 to buy a new cabinet, was the offer not taken up?\" but did not reply to this specific question.\n\nIn October 2012, the council published the results of a petition that was signed by 199 (average of all petitions 193 as of July 2014):\n\nNorthampton Borough Council claimed in January 2013 to have sought the views of the public regarding the proposed sale of the statue, but the form this took was criticised by the Museum Associations ethics committee:\n\nNevertheless, the BBC repeated the council's claim that the consultation indicated that of the 173 replies 51% were in favour and 49% were against the sale. No question in the consultation document asked whether the statue should be sold or not; however, those who participated in the consultation could leave optional narrative comments, and the council used these to claim a small majority in favour of selling the statue. The Save Sekhemka Action Group objected to the methods used in the consultation document:\n\nThe Save Sekhemka Action Group reported that their own survey showed \"overwhelming support for protecting the museum's accredited status and keeping the statue\".\n\nThe \"Northampton Chronicle and Echo\" carried out a Facebook poll in June 2014, and found that the majority wanted to keep the statue.\n\nThe present Lord Northampton originally protested at the decision of Northampton Borough Council to sell the statue. However, the BBC reported that, following negotiations lasting a year, he struck a private deal with the council which resulted in him receiving £6 million from the sale. Northampton Borough Council has refused to release details of the legal arrangement. The Marquess had previously been involved with the controversial attempted sale of the Sevso Treasure.\n\nIn June 2014, the council was asked by a local newspaper: \"Are you prepared to show the documents and agreements made with the Marquess of Northampton to any member of the public who asks to see them? If not, why not?\" and replied \"The details of the agreement are confidential between Lord Northampton and the borough council, but we can confirm that 55% of the sale will go to the council and 45% will go to Lord Northampton.\" The council also stated \"The council’s ownership of Sekhemka has been confirmed following advice from lawyers, who are satisfied we have legal right to proceed with the sale. We do not have any deed specifically relating to Sekhemka.\" After the sale of the statue The Save Sekhemka Action Group questioned why the Marquess of Northampton would be receiving over £5 million from the proceeds since, according to Northampton Borough Council, the council owned the statue.\n\nThe Egyptian Ministry of Antiquities asked the Egyptian Embassy in London to take all legal procedures to stop the sale of the statue. Minister Mamdouh Al-Damati condemned the sale as being incompatible with the values and role of museums worldwide which should spread culture rather than seeking to earn money. He also called on the International Council of Museums (ICOM) to stop the sale on ethical grounds. The Museum Association for the United Kingdom warned the council that it would review Northampton’s membership if it went ahead with the sale. The Arts Council of England said the sale could jeopardise the accreditation status of Northampton Museums and that could in future limit the museum's ability to obtain grant funding. Archaeologist Andy Brockman, who took part in the Save Sekhemka campaign said the sale would \"bring Northampton Council into disrepute\" and that the sale was \"opposed by museum and archaeological professionals who wish to make sure no part of Egypt's cultural history is sold off.\"\n\nICOM CIPEG also expressed concern that the sale might encourage illegal excavation and plundering of Ancient Egyptian antiquities.\n\nIn July 2013, a local politician who opposed the sale of the statue commented: \"I've read there is a curse attached to Sekhemka and if it should fall on anyone, it should fall on this administration for not having the courage to change their minds.\" The day before the sale was scheduled to take place the estate office of the Marquess of Northampton's Castle Ashby caught fire leading to stories about the \"Curse Of Sekhemka\". Fire crews from three counties fought the blaze.\n\nChristie's sold the Sekhemka statue for £15.76 m at an auction on 10 July 2014 to an anonymous buyer. The auction was briefly halted by a protester who called out that “no-one should bid or buy it...stolen property,” while a small, vocal group of Egyptian protesters demonstrated outside. The final auction price was almost £10 m more than Christie's guide price. The price obtained broke the existing world record for an Ancient Egyptian artwork sold at auction.\n\nThe Save Sekhemka Action group described the sale as a \"day of shame for Northampton\", and said that selling the statue had been \"the decision of one man [council leader David Mackintosh], taken against all professional advice locally, nationally and internationally\" The sale was described by the Egyptian Embassy as a \"shameful and unethical act\". Scott Furlong, of Arts Council England, said: \"It is very disappointing that the local authority committed to the sale and entered into an agreement with an auction house before our discussions with them were concluded.\" Northampton council leader David Mackintosh said the council's share of the proceeds would be used to develop the existing museum. The writer Alan Moore also condemned the council's decision to sell the statue.\nThe Art Fund commented the day after the sale:\nThe Arts Council announced that Northampton Museums' accreditation would be reviewed on 24 July 2014:\n\nOn 1 August 2014, Northampton Museums had their accreditation removed by the Arts Council England, who ruled that the sale broke the required standards for museums managing their collections, rendering the museums ineligible for funding from a range of arts grants and funding bodies. The museums are excluded from future participation until at least August 2019. Scott Furlong of the Arts Council commented: \"It is always hugely regrettable when we have to exclude a museum from the Accreditation Scheme. However, it is equally important that we are robust in upholding the standards and principles which underpin the scheme and are shared by the vast majority of museums.\" The leader of Northampton borough council, David Mackintosh said the Arts Council decision was \"disappointing\" and \"puzzling\", and stated \"We are possibly one of the only local authorities in the country with plans for a multimillion pound investment in their museum service.\"\n\nThe Save Sekhemka Action Group commented \"This is indeed a black and shameful day for Northampton's Culture and Heritage\" and that \"it will mean the certain decline of both the Central and Abington Museum since the loss of this statue stops the Museum Service being eligible for outside grants from the Lottery, Arts Council England and other art/cultural grant giving bodies.\" They said that the monetary loss through loss of accreditation is likely to be in excess of the £8m gross the council received from the sale of the statue.\n\nIn November 2014, the Borough Council's bid for a Heritage Lottery Fund grant of £240,400 was rejected. The funding was being sought for an exhibition of designer shoes dating from the 19th century to the present. The council said it was \"disappointed\". The Museums Association decided to ban the council from membership for five years.\n\nIn September 2014, the Friends of Northampton Museums and Art Gallery decided to wind itself up after 55 years' financial and practical service to the town. The sale of the statue was partly to blame for this; the group was against the sale, though some felt it did not fall within the group's functions.\n\nOn 30 March 2015, British culture minister Ed Vaizey placed a four-month temporary export ban on the statue, which had been sold to an unidentified overseas buyer. The Arts Council said there was a chance the statue could be sold to a UK buyer if \"a serious intention to raise funds to purchase the statue is made at the recommended price of £15,732,600 plus VAT.\"\n\nEgyptian Ambassador Ahsraf Elkholy condemned the sale as \"an abuse to the Egyptian archaeology and the cultural property,\" saying that the statue should have been given back to Egypt if the council no longer wanted it.\n\nOn 2 October 2015, Vaizey extended the export ban until 29 March 2016, after hearing of a serious bid to raise funds to save the statue for the UK. Since no-one made a counter-offer during this extension, in April 2016 the ban was lifted.\n\nOn 21 April 2015 the Save Sekhemka Action Group said that they think that a condition of the original Deed of Gift was that the statue should never be sold, making the auction illegal. The group said that they had no intention of trying to buy the statue back but suggest that it is put on display at a major museum. It is also challenging the £6m donation from the sale proceeds to the Marquess of Northampton's family. It will also examine borough council records to determine \"the legal and financial arrangements reached with the Marquis of Northampton\".\n\nThe BBC reported in October 2016 that the statue now is thought to have been exported to the United States. BBC news revealed how the council, which made £8m from the sale, had been warned by lawyers not to sell it for \"financial motives\".\nThe council said it sold the figurine to help fund a £14m extension to its museum and art gallery.\n\n\n"}
{"id": "22348", "url": "https://en.wikipedia.org/wiki?curid=22348", "title": "Opera", "text": "Opera\n\nOpera (; English plural: \"operas\"; Italian plural: \"opere\" ) is a form of theatre in which music has a leading role and the parts are taken by singers. Such a \"work\" (the literal translation of \"opera\") is typically a collaboration between a composer and a librettist and incorporates a number of the performing arts, such as acting, scenery, costume, and sometimes dance or ballet. The performance is typically given in an opera house, accompanied by an orchestra or smaller musical ensemble, which since the early 19th century has been led by a conductor.\n\nOpera is a key part of the Western classical music tradition. Originally understood as an entirely sung piece, in contrast to a play with songs, opera has come to include , including some that include spoken dialogue such as musical theater, \"Singspiel\" and \"Opéra comique\". In traditional number opera, singers employ two styles of singing: recitative, a speech-inflected style and self-contained arias. The 19th century saw the rise of the continuous music drama.\n\nOpera originated in Italy at the end of the 16th century (with Jacopo Peri's mostly lost \"Dafne\", produced in Florence in 1598) and soon spread through the rest of Europe: Heinrich Schütz in Germany, Jean-Baptiste Lully in France, and Henry Purcell in England all helped to establish their national traditions in the 17th century. In the 18th century, Italian opera continued to dominate most of Europe (except France), attracting foreign composers such as George Frideric Handel. Opera seria was the most prestigious form of Italian opera, until Christoph Willibald Gluck reacted against its artificiality with his \"reform\" operas in the 1760s. The most renowned figure of late 18th-century opera is Wolfgang Amadeus Mozart, who began with opera seria but is most famous for his Italian comic operas, especially \"The Marriage of Figaro\" (\"Le nozze di Figaro\"), \"Don Giovanni\", and \"Così fan tutte\", as well as \"Die Entführung aus dem Serail\" (\"The Abduction from the Seraglio\"), and \"The Magic Flute\" (\"Die Zauberflöte\"), landmarks in the German tradition.\n\nThe first third of the 19th century saw the high point of the bel canto style, with Gioachino Rossini, Gaetano Donizetti and Vincenzo Bellini all creating works that are still performed. It also saw the advent of Grand Opera typified by the works of Auber and Meyerbeer. The mid-to-late 19th century was a golden age of opera, led and dominated by Giuseppe Verdi in Italy and Richard Wagner in Germany. The popularity of opera continued through the verismo era in Italy and contemporary French opera through to Giacomo Puccini and Richard Strauss in the early 20th century. During the 19th century, parallel operatic traditions emerged in central and eastern Europe, particularly in Russia and Bohemia. The 20th century saw many experiments with modern styles, such as atonality and serialism (Arnold Schoenberg and Alban Berg), Neoclassicism (Igor Stravinsky), and Minimalism (Philip Glass and John Adams). With the rise of recording technology, singers such as Enrico Caruso and Maria Callas became known to much wider audiences that went beyond the circle of opera fans. Since the invention of radio and television, operas were also performed on (and written for) these mediums. Beginning in 2006, a number of major opera houses began to present live high-definition video transmissions of their performances in cinemas all over the world. Since 2009, complete performances can be downloaded and are live streamed.\n\nThe words of an opera are known as the libretto (literally \"small book\"). Some composers, notably Wagner, have written their own libretti; others have worked in close collaboration with their librettists, e.g. Mozart with Lorenzo Da Ponte. Traditional opera, often referred to as \"number opera\", consists of two modes of singing: recitative, the plot-driving passages sung in a style designed to imitate and emphasize the inflections of speech, and aria (an \"air\" or formal song) in which the characters express their emotions in a more structured melodic style. Vocal duets, trios and other ensembles often occur, and choruses are used to comment on the action. In some forms of opera, such as singspiel, opéra comique, operetta, and semi-opera, the recitative is mostly replaced by spoken dialogue. Melodic or semi-melodic passages occurring in the midst of, or instead of, recitative, are also referred to as arioso. The terminology of the various kinds of operatic voices is described in detail below. During both the Baroque and Classical periods, recitative could appear in two basic forms, each of which was accompanied by a different instrumental ensemble: \"secco\" (dry) recitative, sung with a free rhythm dictated by the accent of the words, accompanied only by \"basso continuo\", which was usually a harpsichord and a cello; or \"accompagnato\" (also known as \"strumentato\") in which the orchestra provided accompaniment. Over the 18th century, arias were increasingly accompanied by the orchestra. By the 19th century, \"accompagnato\" had gained the upper hand, the orchestra played a much bigger role, and Wagner revolutionized opera by abolishing almost all distinction between aria and recitative in his quest for what Wagner termed \"endless melody\". Subsequent composers have tended to follow Wagner's example, though some, such as Stravinsky in his \"The Rake's Progress\" have bucked the trend. The changing role of the orchestra in opera is described in more detail below.\n\nThe Italian word \"opera\" means \"work\", both in the sense of the labour done and the result produced. The Italian word derives from the Latin \"opera\", a singular noun meaning \"work\" and also the plural of the noun \"opus\". According to the Oxford English Dictionary, the Italian word was first used in the sense \"composition in which poetry, dance, and music are combined\" in 1639; the first recorded English usage in this sense dates to 1648.\n\n\"Dafne\" by Jacopo Peri was the earliest composition considered opera, as understood today. It was written around 1597, largely under the inspiration of an elite circle of literate Florentine humanists who gathered as the \"Camerata de' Bardi\". Significantly, \"Dafne\" was an attempt to revive the classical Greek drama, part of the wider revival of antiquity characteristic of the Renaissance. The members of the Camerata considered that the \"chorus\" parts of Greek dramas were originally sung, and possibly even the entire text of all roles; opera was thus conceived as a way of \"restoring\" this situation. \"Dafne,\" however, is lost. A later work by Peri, \"Euridice\", dating from 1600, is the first opera score to have survived to the present day. The honour of being the first opera still to be regularly performed, however, goes to Claudio Monteverdi's \"L'Orfeo\", composed for the court of Mantua in 1607. The Mantua court of the Gonzagas, employers of Monteverdi, played a significant role in the origin of opera employing not only court singers of the concerto delle donne (till 1598), but also one of the first actual \"opera singers\"; Madama Europa.\n\nOpera did not remain confined to court audiences for long. In 1637, the idea of a \"season\" (Carnival) of publicly attended operas supported by ticket sales emerged in Venice. Monteverdi had moved to the city from Mantua and composed his last operas, \"Il ritorno d'Ulisse in patria\" and \"L'incoronazione di Poppea\", for the Venetian theatre in the 1640s. His most important follower Francesco Cavalli helped spread opera throughout Italy. In these early Baroque operas, broad comedy was blended with tragic elements in a mix that jarred some educated sensibilities, sparking the first of opera's many reform movements, sponsored by the Arcadian Academy, which came to be associated with the poet Metastasio, whose libretti helped crystallize the genre of opera seria, which became the leading form of Italian opera until the end of the 18th century. Once the Metastasian ideal had been firmly established, comedy in Baroque-era opera was reserved for what came to be called opera buffa.\nBefore such elements were forced out of opera seria, many libretti had featured a separately unfolding comic plot as sort of an \"opera-within-an-opera.\" One reason for this was an attempt to attract members of the growing merchant class, newly wealthy, but still not as cultured as the nobility, to the public opera houses. These separate plots were almost immediately resurrected in a separately developing tradition that partly derived from the commedia dell'arte, a long-flourishing improvisatory stage tradition of Italy. Just as intermedi had once been performed in between the acts of stage plays, operas in the new comic genre of \"intermezzi\", which developed largely in Naples in the 1710s and '20s, were initially staged during the intermissions of opera seria. They became so popular, however, that they were soon being offered as separate productions.\n\n\"Opera seria\" was elevated in tone and highly stylised in form, usually consisting of \"secco\" recitative interspersed with long \"da capo\" arias. These afforded great opportunity for virtuosic singing and during the golden age of \"opera seria\" the singer really became the star. The role of the hero was usually written for the high-pitched male castrato voice, which was produced by castration of the singer before puberty, which prevented a boy's larynx from being transformed at puberty. Castrati such as Farinelli and Senesino, as well as female sopranos such as Faustina Bordoni, became in great demand throughout Europe as \"opera seria\" ruled the stage in every country except France. Farinelli was one of the most famous singers of the 18th century. Italian opera set the Baroque standard. Italian libretti were the norm, even when a German composer like Handel found himself composing the likes of \"Rinaldo\" and \"Giulio Cesare\" for London audiences. Italian libretti remained dominant in the classical period as well, for example in the operas of Mozart, who wrote in Vienna near the century's close. Leading Italian-born composers of opera seria include Alessandro Scarlatti, Vivaldi and Porpora.\n\nOpera seria had its weaknesses and critics. The taste for embellishment on behalf of the superbly trained singers, and the use of spectacle as a replacement for dramatic purity and unity drew attacks. Francesco Algarotti's \"Essay on the Opera\" (1755) proved to be an inspiration for Christoph Willibald Gluck's reforms. He advocated that \"opera seria\" had to return to basics and that all the various elements—music (both instrumental and vocal), ballet, and staging—must be subservient to the overriding drama. In 1765 Melchior Grimm published \"\", an influential article for the Encyclopédie on lyric and opera librettos. Several composers of the period, including Niccolò Jommelli and Tommaso Traetta, attempted to put these ideals into practice. The first to succeed however, was Gluck. Gluck strove to achieve a \"beautiful simplicity\". This is evident in his first reform opera, \"Orfeo ed Euridice\", where his non-virtuosic vocal melodies are supported by simple harmonies and a richer orchestra presence throughout.\n\nGluck's reforms have had resonance throughout operatic history. Weber, Mozart, and Wagner, in particular, were influenced by his ideals. Mozart, in many ways Gluck's successor, combined a superb sense of drama, harmony, melody, and counterpoint to write a series of comic operas with libretti by Lorenzo Da Ponte, notably \"Le Nozze di Figaro\", \"Don Giovanni\", and \"Così fan tutte\", which remain among the most-loved, popular and well-known operas today. But Mozart's contribution to \"opera seria\" was more mixed; by his time it was dying away, and in spite of such fine works as \"Idomeneo\" and \"La clemenza di Tito\", he would not succeed in bringing the art form back to life again.\n\nThe bel canto opera movement flourished in the early 19th century and is exemplified by the operas of Rossini, Bellini, Donizetti, Pacini, Mercadante and many others. Literally \"beautiful singing\", \"bel canto\" opera derives from the Italian stylistic singing school of the same name. Bel canto lines are typically florid and intricate, requiring supreme agility and pitch control. Examples of famous operas in the bel canto style include Rossini's \"Il barbiere di Siviglia\" and \"La Cenerentola\", as well as Bellini's \"Norma\" and Donizetti's \"Lucia di Lammermoor\".\nFollowing the bel canto era, a more direct, forceful style was rapidly popularized by Giuseppe Verdi, beginning with his biblical opera \"Nabucco\". This opera, and the ones that would follow in Verdi's career, revolutionized Italian opera, changing it from merely a display of vocal fireworks, with Rossini's and Donizetti's works, to dramatic story-telling. Verdi's operas resonated with the growing spirit of Italian nationalism in the post-Napoleonic era, and he quickly became an icon of the patriotic movement for a unified Italy. In the early 1850s, Verdi produced his three most popular operas: \"Rigoletto\", \"Il trovatore\" and \"La traviata\". The first of these, \"Rigoletto\", proved the most daring and revolutionary. In it, Verdi blurs the distinction between the aria and recitative as it never before was, leading the opera to be \"an unending string of duets\". \"La traviata\" was also novel. It tells the story of courtesan, and is often cited as one of the first \"realistic\" operas, because rather than featuring great kings and figures from literature, it focuses on the tragedies of ordinary life and society. After these, he continued to develop his style, composing perhaps the greatest French Grand Opera, \"Don Carlos\", and ending his career with two Shakespeare-inspired works, \"Otello\" and \"Falstaff\", which reveal how far Italian opera had grown in sophistication since the early 19th century. These final two works showed Verdi at his most masterfully orchestrated, and are both incredibly influential, and modern. In \"Falstaff\", Verdi sets the preeminent standard for the form and style that would dominate opera throughout the twentieth century. Rather than long, suspended melodies, \"Falstaff\" contains many little motifs and mottos, that, rather than being expanded upon, are introduced and subsequently dropped, only to be brought up again later. These motifs never are expanded upon, and just as the audience expects a character to launch into a long melody, a new character speaks, introducing a new phrase. This fashion of opera directed opera from Verdi, onward, exercising tremendous influence on his successors Giacomo Puccini, Richard Strauss, and Benjamin Britten.\n\nAfter Verdi, the sentimental \"realistic\" melodrama of verismo appeared in Italy. This was a style introduced by Pietro Mascagni's \"Cavalleria rusticana\" and Ruggero Leoncavallo's \"Pagliacci\" that came to dominate the world's opera stages with such popular works as Giacomo Puccini's \"La bohème\", \"Tosca\", and \"Madama Butterfly\". Later Italian composers, such as Berio and Nono, have experimented with modernism.\n\nThe first German opera was \"Dafne\", composed by Heinrich Schütz in 1627, but the music score has not survived. Italian opera held a great sway over German-speaking countries until the late 18th century. Nevertheless, native forms would develop in spite of this influence. In 1644, Sigmund Staden produced the first \"Singspiel\", \"Seelewig\", a popular form of German-language opera in which singing alternates with spoken dialogue. In the late 17th century and early 18th century, the Theater am Gänsemarkt in Hamburg presented German operas by Keiser, Telemann and Handel. Yet most of the major German composers of the time, including Handel himself, as well as Graun, Hasse and later Gluck, chose to write most of their operas in foreign languages, especially Italian. In contrast to Italian opera, which was generally composed for the aristocratic class, German opera was generally composed for the masses and tended to feature simple folk-like melodies, and it was not until the arrival of Mozart that German opera was able to match its Italian counterpart in musical sophistication.\n\nMozart's \"Singspiele\", \"Die Entführung aus dem Serail\" (1782) and \"Die Zauberflöte\" (1791) were an important breakthrough in achieving international recognition for German opera. The tradition was developed in the 19th century by Beethoven with his \"Fidelio\", inspired by the climate of the French Revolution. Carl Maria von Weber established German Romantic opera in opposition to the dominance of Italian bel canto. His \"Der Freischütz\" (1821) shows his genius for creating a supernatural atmosphere. Other opera composers of the time include Marschner, Schubert and Lortzing, but the most significant figure was undoubtedly Wagner.\n\nWagner was one of the most revolutionary and controversial composers in musical history. Starting under the influence of Weber and Meyerbeer, he gradually evolved a new concept of opera as a \"Gesamtkunstwerk\" (a \"complete work of art\"), a fusion of music, poetry and painting. He greatly increased the role and power of the orchestra, creating scores with a complex web of leitmotifs, recurring themes often associated with the characters and concepts of the drama, of which prototypes can be heard in his earlier operas such as \"Der fliegende Holländer\", \"Tannhäuser\" and \"Lohengrin\"; and he was prepared to violate accepted musical conventions, such as tonality, in his quest for greater expressivity. In his mature music dramas, \"Tristan und Isolde\", \"Die Meistersinger von Nürnberg\", \"Der Ring des Nibelungen\" and \"Parsifal\", he abolished the distinction between aria and recitative in favour of a seamless flow of \"endless melody\". Wagner also brought a new philosophical dimension to opera in his works, which were usually based on stories from Germanic or Arthurian legend. Finally, Wagner built his own opera house at Bayreuth with part of the patronage from Ludwig II of Bavaria, exclusively dedicated to performing his own works in the style he wanted.\n\nOpera would never be the same after Wagner and for many composers his legacy proved a heavy burden. On the other hand, Richard Strauss accepted Wagnerian ideas but took them in wholly new directions, along with incorporating the new form introduced by Verdi. He first won fame with the scandalous \"Salome\" and the dark tragedy \"Elektra\", in which tonality was pushed to the limits. Then Strauss changed tack in his greatest success, \"Der Rosenkavalier\", where Mozart and Viennese waltzes became as important an influence as Wagner. Strauss continued to produce a highly varied body of operatic works, often with libretti by the poet Hugo von Hofmannsthal. Other composers who made individual contributions to German opera in the early 20th century include Alexander von Zemlinsky, Erich Korngold, Franz Schreker, Paul Hindemith, Kurt Weill and the Italian-born Ferruccio Busoni. The operatic innovations of Arnold Schoenberg and his successors are discussed in the section on modernism.\n\nDuring the late 19th century, the Austrian composer Johann Strauss II, an admirer of the French-language operettas composed by Jacques Offenbach, composed several German-language operettas, the most famous of which was \"Die Fledermaus\", which is still regularly performed today. Nevertheless, rather than copying the style of Offenbach, the operettas of Strauss II had distinctly Viennese flavor to them, which have cemented the Strauss II's place as one of the most renowned operetta composers of all time.\n\nIn rivalry with imported Italian opera productions, a separate French tradition was founded by the Italian Jean-Baptiste Lully at the court of King Louis XIV. Despite his foreign origin, Lully established an Academy of Music and monopolised French opera from 1672. Starting with \"Cadmus et Hermione\", Lully and his librettist Quinault created \"tragédie en musique\", a form in which dance music and choral writing were particularly prominent. Lully's operas also show a concern for expressive recitative which matched the contours of the French language. In the 18th century, Lully's most important successor was Jean-Philippe Rameau, who composed five \"tragédies en musique\" as well as numerous works in other genres such as opéra-ballet, all notable for their rich orchestration and harmonic daring. Despite the popularity of Italian opera seria throughout much of Europe during the Baroque period, Italian opera never gained much of a foothold in France, where its own national operatic tradition was more popular instead. After Rameau's death, the German Gluck was persuaded to produce six operas for the Parisian stage in the 1770s. They show the influence of Rameau, but simplified and with greater focus on the drama. At the same time, by the middle of the 18th century another genre was gaining popularity in France: \"opéra comique\". This was the equivalent of the German singspiel, where arias alternated with spoken dialogue. Notable examples in this style were produced by Monsigny, Philidor and, above all, Grétry. During the Revolutionary period, composers such as Méhul and Cherubini, who were followers of Gluck, brought a new seriousness to the genre, which had never been wholly \"comic\" in any case. Another phenomenon of this period was the 'propaganda opera' celebrating revolutionary successes, e.g. Gossec's \"Le triomphe de la République\" (1793).\nBy the 1820s, Gluckian influence in France had given way to a taste for Italian bel canto, especially after the arrival of Rossini in Paris. Rossini's \"Guillaume Tell\" helped found the new genre of Grand Opera, a form whose most famous exponent was another foreigner, Giacomo Meyerbeer. Meyerbeer's works, such as \"Les Huguenots\", emphasised virtuoso singing and extraordinary stage effects. Lighter \"opéra comique\" also enjoyed tremendous success in the hands of Boïeldieu, Auber, Hérold and Adam. In this climate, the operas of the French-born composer Hector Berlioz struggled to gain a hearing. Berlioz's epic masterpiece \"Les Troyens\", the culmination of the Gluckian tradition, was not given a full performance for almost a hundred years.\n\nIn the second half of the 19th century, Jacques Offenbach created operetta with witty and cynical works such as \"Orphée aux enfers\", as well as the opera \"Les Contes d'Hoffmann\"; Charles Gounod scored a massive success with \"Faust\"; and Georges Bizet composed \"Carmen\", which, once audiences learned to accept its blend of Romanticism and realism, became the most popular of all opéra comiques. Jules Massenet, Camille Saint-Saëns and Léo Delibes all composed works which are still part of the standard repertory, examples being Massenet's \"Manon\", Saint-Saëns' \"Samson et Dalila\" and Delibes' \"Lakmé\". Their operas formed another genre, the Opera Lyrique, combined opera comique and grand opera. It is less grandiose than grand opera, but without the spoken dialogue of opera comique. At the same time, the influence of Richard Wagner was felt as a challenge to the French tradition. Many French critics angrily rejected Wagner's music dramas while many French composers closely imitated them with variable success. Perhaps the most interesting response came from Claude Debussy. As in Wagner's works, the orchestra plays a leading role in Debussy's unique opera \"Pelléas et Mélisande\" (1902) and there are no real arias, only recitative. But the drama is understated, enigmatic and completely un-Wagnerian.\n\nOther notable 20th-century names include Ravel, Dukas, Roussel and Milhaud. Francis Poulenc is one of the very few post-war composers of any nationality whose operas (which include \"Dialogues des Carmélites\") have gained a foothold in the international repertory. Olivier Messiaen's lengthy sacred drama \"Saint François d'Assise\" (1983) has also attracted widespread attention.\n\nIn England, opera's antecedent was the 17th-century \"jig\". This was an afterpiece which came at the end of a play. It was frequently libellous and scandalous and consisted in the main of dialogue set to music arranged from popular tunes. In this respect, jigs anticipate the ballad operas of the 18th century. At the same time, the French masque was gaining a firm hold at the English Court, with even more lavish splendour and highly realistic scenery than had been seen before. Inigo Jones became the quintessential designer of these productions, and this style was to dominate the English stage for three centuries. These masques contained songs and dances. In Ben Jonson's \"Lovers Made Men\" (1617), \"the whole masque was sung after the Italian manner, stilo recitativo\". The approach of the English Commonwealth closed theatres and halted any developments that may have led to the establishment of English opera. However, in 1656, the dramatist Sir William Davenant produced \"The Siege of Rhodes\". Since his theatre was not licensed to produce drama, he asked several of the leading composers (Lawes, Cooke, Locke, Coleman and Hudson) to set sections of it to music. This success was followed by \"The Cruelty of the Spaniards in Peru\" (1658) and \"The History of Sir Francis Drake\" (1659). These pieces were encouraged by Oliver Cromwell because they were critical of Spain. With the English Restoration, foreign (especially French) musicians were welcomed back. In 1673, Thomas Shadwell's \"Psyche\", patterned on the 1671 'comédie-ballet' of the same name produced by Molière and Jean-Baptiste Lully. William Davenant produced \"The Tempest\" in the same year, which was the first musical adaption of a Shakespeare play (composed by Locke and Johnson). About 1683, John Blow composed \"Venus and Adonis\", often thought of as the first true English-language opera.\n\nBlow's immediate successor was the better known Henry Purcell. Despite the success of his masterwork \"Dido and Aeneas\" (1689), in which the action is furthered by the use of Italian-style recitative, much of Purcell's best work was not involved in the composing of typical opera, but instead, he usually worked within the constraints of the semi-opera format, where isolated scenes and masques are contained within the structure of a spoken play, such as Shakespeare in Purcell's \"The Fairy-Queen\" (1692) and Beaumont and Fletcher in \"The Prophetess\" (1690) and \"Bonduca\" (1696). The main characters of the play tend not to be involved in the musical scenes, which means that Purcell was rarely able to develop his characters through song. Despite these hindrances, his aim (and that of his collaborator John Dryden) was to establish serious opera in England, but these hopes ended with Purcell's early death at the age of 36.\nFollowing Purcell, the popularity of opera in England dwindled for several decades. A revived interest in opera occurred in the 1730s which is largely attributed to Thomas Arne, both for his own compositions and for alerting Handel to the commercial possibilities of large-scale works in English. Arne was the first English composer to experiment with Italian-style all-sung comic opera, with his greatest success being \"Thomas and Sally\" in 1760. His opera \"Artaxerxes\" (1762) was the first attempt to set a full-blown opera seria in English and was a huge success, holding the stage until the 1830s. Although Arne imitated many elements of Italian opera, he was perhaps the only English composer at that time who was able to move beyond the Italian influences and create his own unique and distinctly English voice. His modernized ballad opera, \"Love in a Village\" (1762), began a vogue for pastiche opera that lasted well into the 19th century. Charles Burney wrote that Arne introduced \"a light, airy, original, and pleasing melody, wholly different from that of Purcell or Handel, whom all English composers had either pillaged or imitated\".\n\nBesides Arne, the other dominating force in English opera at this time was George Frideric Handel, whose \"opera serias\" filled the London operatic stages for decades and influenced most home-grown composers, like John Frederick Lampe, who wrote using Italian models. This situation continued throughout the 18th and 19th centuries, including in the work of Michael William Balfe, and the operas of the great Italian composers, as well as those of Mozart, Beethoven, and Meyerbeer, continued to dominate the musical stage in England.\n\nThe only exceptions were ballad operas, such as John Gay's \"The Beggar's Opera\" (1728), musical burlesques, European operettas, and late Victorian era light operas, notably the Savoy Operas of W. S. Gilbert and Arthur Sullivan, all of which types of musical entertainments frequently spoofed operatic conventions. Sullivan wrote only one grand opera, \"Ivanhoe\" (following the efforts of a number of young English composers beginning about 1876), but he claimed that even his light operas constituted part of a school of \"English\" opera, intended to supplant the French operettas (usually performed in bad translations) that had dominated the London stage from the mid-19th century into the 1870s. London's \"Daily Telegraph\" agreed, describing \"The Yeomen of the Guard\" as \"a genuine English opera, forerunner of many others, let us hope, and possibly significant of an advance towards a national lyric stage\". Sullivan produced a few light operas in the 1890s that were of a more serious nature than those in the G&S series, including \"Haddon Hall\" and \"The Beauty Stone\", but \"Ivanhoe\" (which ran for 155 consecutive performances, using alternating casts—a record until Broadway's \"La bohème\") survives as his only Grand Opera.\n\nIn the 20th century, English opera began to assert more independence, with works of Ralph Vaughan Williams and in particular Benjamin Britten, who in a series of works that remain in standard repertory today, revealed an excellent flair for the dramatic and superb musicality. More recently Sir Harrison Birtwistle has emerged as one of Britain's most significant contemporary composers from his first opera \"Punch and Judy\" to his most recent critical success in The Minotaur. In the first decade of the 21st century, the librettist of an early Birtwistle opera, Michael Nyman, has been focusing on composing operas, including \"Facing Goya\", \"\", and \"Love Counts\". Today composers such as Thomas Adès continue to export English opera abroad.\n\nAlso in the 20th century, American composers like Leonard Bernstein, George Gershwin, Gian Carlo Menotti, Douglas Moore, and Carlisle Floyd began to contribute English-language operas infused with touches of popular musical styles. They were followed by composers such as Philip Glass, Mark Adamo, John Corigliano, Robert Moran, John Coolidge Adams, André Previn and Jake Heggie.\n\nOpera was brought to Russia in the 1730s by the Italian operatic troupes and soon it became an important part of entertainment for the Russian Imperial Court and aristocracy. Many foreign composers such as Baldassare Galuppi, Giovanni Paisiello, Giuseppe Sarti, and Domenico Cimarosa (as well as various others) were invited to Russia to compose new operas, mostly in the Italian language. Simultaneously some domestic musicians like Maksym Berezovsky and Dmitry Bortniansky were sent abroad to learn to write operas. The first opera written in Russian was \"Tsefal i Prokris\" by the Italian composer Francesco Araja (1755). The development of Russian-language opera was supported by the Russian composers Vasily Pashkevich, Yevstigney Fomin and Alexey Verstovsky.\n\nHowever, the real birth of Russian opera came with Mikhail Glinka and his two great operas \"A Life for the Tsar\" (1836) and \"Ruslan and Lyudmila\" (1842). After him, in the 19th century in Russia, there were written such operatic masterpieces as \"Rusalka\" and \"The Stone Guest\" by Alexander Dargomyzhsky, \"Boris Godunov\" and \"Khovanshchina\" by Modest Mussorgsky, \"Prince Igor\" by Alexander Borodin, \"Eugene Onegin\" and \"The Queen of Spades\" by Pyotr Tchaikovsky, and \"The Snow Maiden\" and \"Sadko\" by Nikolai Rimsky-Korsakov. These developments mirrored the growth of Russian nationalism across the artistic spectrum, as part of the more general Slavophilism movement.\n\nIn the 20th century, the traditions of Russian opera were developed by many composers including Sergei Rachmaninoff in his works \"The Miserly Knight\" and \"Francesca da Rimini\", Igor Stravinsky in \"Le Rossignol\", \"Mavra\", \"Oedipus rex\", and \"The Rake's Progress\", Sergei Prokofiev in \"The Gambler\", \"The Love for Three Oranges\", \"The Fiery Angel\", \"Betrothal in a Monastery\", and \"War and Peace\"; as well as Dmitri Shostakovich in \"The Nose\" and \"Lady Macbeth of the Mtsensk District\", Edison Denisov in \"L'écume des jours\", and Alfred Schnittke in \"Life with an Idiot\" and \"Historia von D. Johann Fausten\".\n\nSpain also produced its own distinctive form of opera, known as zarzuela, which had two separate flowerings: one from the mid-17th century through the mid-18th century, and another beginning around 1850. During the late 18th century up until the mid-19th century, Italian opera was immensely popular in Spain, supplanting the native form.\n\nCzech composers also developed a thriving national opera movement of their own in the 19th century, starting with Bedřich Smetana, who wrote eight operas including the internationally popular \"The Bartered Bride\". Antonín Dvořák, most famous for \"Rusalka\", wrote 13 operas; and Leoš Janáček gained international recognition in the 20th century for his innovative works including \"Jenůfa\", \"The Cunning Little Vixen\", and \"Káťa Kabanová\".\n\nIn Russian Eastern Europe, several national operas began to emerge. Ukrainian opera was developed by Semen Hulak-Artemovsky (1813–1873) whose most famous work \"Zaporozhets za Dunayem\" (A Cossack Beyond the Danube) is regularly performed around the world. Other Ukrainian opera composers include Mykola Lysenko (\"Taras Bulba\" and \"Natalka Poltavka\"), Heorhiy Maiboroda, and Yuliy Meitus. At the turn of the century, a distinct national opera movement also began to emerge in Georgia under the leadership Zacharia Paliashvili, who fused local folk songs and stories with 19th-century Romantic classical themes.\nThe key figure of Hungarian national opera in the 19th century was Ferenc Erkel, whose works mostly dealt with historical themes. Among his most often performed operas are \"Hunyadi László\" and \"Bánk bán\". The most famous modern Hungarian opera is Béla Bartók's \"Duke Bluebeard's Castle\".\n\nStanisław Moniuszko's opera \"Straszny Dwór\" (in English \"The Haunted Manor\") (1861–64) represents a nineteenth-century peak of Polish national opera. In the 20th century, other operas created by Polish composers included \"King Roger\" by Karol Szymanowski and \"Ubu Rex\" by Krzysztof Penderecki.\n\nThe first known opera from Turkey (the Ottoman Empire) was \"Arshak II\", which was an Armenian opera composed by an ethnic Armenian composer Tigran Tchoukhajian in 1868 and partially performed in 1873. It was fully staged in 1945 in Armenia.\n\nThe first years of the Soviet Union saw the emergence of new national operas, such as the \"Koroğlu\" (1937) by the Azerbaijani composer Uzeyir Hajibeyov. The first Kyrgyz opera, \"Ai-Churek\", premiered in Moscow at the Bolshoi Theatre on 26 May 1939, during Kyrgyz Art Decade. It was composed by Vladimir Vlasov, Abdylas Maldybaev and Vladimir Fere. The libretto was written by Joomart Bokonbaev, Jusup Turusbekov, and Kybanychbek Malikov. The opera is based on the Kyrgyz heroic epic \"Manas\".\n\nChinese contemporary classical opera, a Chinese language form of Western style opera that is distinct from traditional Chinese opera, has had operas dating back to \"The White Haired Girl\" in 1945.\n\nIn Latin America, opera started as a result of European colonisation. The first opera ever written in the Americas was \"La púrpura de la rosa\", by Tomás de Torrejón y Velasco, although \"Partenope\", by the Mexican Manuel de Zumaya, was the first opera written from a composer born in Latin America (music now lost). The first Brazilian opera for a libretto in Portuguese was \"A Noite de São João\", by Elias Álvares Lobo. However, Antonio Carlos Gomes is generally regarded as the most outstanding Brazilian composer, having a relative success in Italy with its Brazilian-themed operas with Italian librettos, such as \"Il Guarany\". Opera in Argentina developed in the 20th century after the inauguration of Teatro Colón in Buenos Aires—with the opera \"Aurora\", by Ettore Panizza, being heavily influenced by the Italian tradition, due to immigration. Other important composers from Argentina include Felipe Boero and Alberto Ginastera.\n\nPerhaps the most obvious stylistic manifestation of modernism in opera is the development of atonality. The move away from traditional tonality in opera had begun with Richard Wagner, and in particular the Tristan chord. Composers such as Richard Strauss, Claude Debussy, Giacomo Puccini, Paul Hindemith, Benjamin Britten and Hans Pfitzner pushed Wagnerian harmony further with a more extreme use of chromaticism and greater use of dissonance. Another aspect of modernist opera is the shift away from long, suspended melodies, to short quick mottos, as first illustrated by Giuseppe Verdi in his \"Falstaff\". Composers such as Strauss, Britten, Shostakovich and Stravinsky adopted and expanded upon this style.\nOperatic modernism truly began in the operas of two Viennese composers, Arnold Schoenberg and his student Alban Berg, both composers and advocates of atonality and its later development (as worked out by Schoenberg), dodecaphony. Schoenberg's early musico-dramatic works, \"Erwartung\" (1909, premiered in 1924) and \"Die glückliche Hand\" display heavy use of chromatic harmony and dissonance in general. Schoenberg also occasionally used Sprechstimme.\n\nThe two operas of Schoenberg's pupil Alban Berg, \"Wozzeck\" (1925) and \"Lulu\" (incomplete at his death in 1935) share many of the same characteristics as described above, though Berg combined his highly personal interpretation of Schoenberg's twelve-tone technique with melodic passages of a more traditionally tonal nature (quite Mahlerian in character) which perhaps partially explains why his operas have remained in standard repertory, despite their controversial music and plots. Schoenberg's theories have influenced (either directly or indirectly) significant numbers of opera composers ever since, even if they themselves did not compose using his techniques.\n\nComposers thus influenced include the Englishman Benjamin Britten, the German Hans Werner Henze, and the Russian Dmitri Shostakovich. (Philip Glass also makes use of atonality, though his style is generally described as minimalist, usually thought of as another 20th-century development.)\n\nHowever, operatic modernism's use of atonality also sparked a backlash in the form of neoclassicism. An early leader of this movement was Ferruccio Busoni, who in 1913 wrote the libretto for his neoclassical number opera \"Arlecchino\" (first performed in 1917). Also among the vanguard was the Russian Igor Stravinsky. After composing music for the Diaghilev-produced ballets \"Petrushka\" (1911) and \"The Rite of Spring\" (1913), Stravinsky turned to neoclassicism, a development culminating in his opera-oratorio \"Oedipus Rex\" (1927). Stravinsky had already turned away from the modernist trends of his early ballets to produce small-scale works that do not fully qualify as opera, yet certainly contain many operatic elements, including \"Renard\" (1916: \"a burlesque in song and dance\") and \"The Soldier's Tale\" (1918: \"to be read, played, and danced\"; in both cases the descriptions and instructions are those of the composer). In the latter, the actors declaim portions of speech to a specified rhythm over instrumental accompaniment, peculiarly similar to the older German genre of \"Melodrama\". Well after his Rimsky-Korsakov-inspired works \"The Nightingale\" (1914), and \"Mavra\" (1922), Stravinsky continued to ignore serialist technique and eventually wrote a full-fledged 18th-century-style diatonic number opera \"The Rake's Progress\" (1951). His resistance to serialism (an attitude he reversed following Schoenberg's death) proved to be an inspiration for many other composers.\n\nA common trend throughout the 20th century, in both opera and general orchestral repertoire, is the use of smaller orchestras as a cost-cutting measure; the grand Romantic-era orchestras with huge string sections, multiple harps, extra horns, and exotic percussion instruments were no longer feasible. As government and private patronage of the arts decreased throughout the 20th century, new works were often commissioned and performed with smaller budgets, very often resulting in chamber-sized works, and short, one-act operas. Many of Benjamin Britten's operas are scored for as few as 13 instrumentalists; Mark Adamo's two-act realization of \"Little Women\" is scored for 18 instrumentalists.\n\nAnother feature of late 20th-century opera is the emergence of contemporary historical operas, in contrast to the tradition of basing operas on more distant history, the re-telling of contemporary fictional stories or plays, or on myth or legend. \"The Death of Klinghoffer\", \"Nixon in China\", and \"Doctor Atomic\" by John Adams, \"Dead Man Walking\" by Jake Heggie, and \"Anna Nicole\" by Mark-Anthony Turnage exemplify the dramatisation onstage of events in recent living memory, where characters portrayed in the opera were alive at the time of the premiere performance.\n\nThe Metropolitan Opera in the US reports that the average age of its audience is now 60. Many opera companies have experienced a similar trend, and opera company websites are replete with attempts to attract a younger audience. This trend is part of the larger trend of greying audiences for classical music since the last decades of the 20th century. In an effort to attract younger audiences, the Metropolitan Opera offers a student discount on ticket purchases.\n\nSmaller companies in the US have a more fragile existence, and they usually depend on a \"patchwork quilt\" of support from state and local governments, local businesses, and fundraisers. Nevertheless, some smaller companies have found ways of drawing new audiences. Opera Carolina offer discounts and happy hour events to the 21- to 40-year-old demographic. In addition to radio and television broadcasts of opera performances, which have had some success in gaining new audiences, broadcasts of live performances in HD to movie theatres have shown the potential to reach new audiences. Since 2006, the Met has broadcast live performances to several hundred movie screens all over the world.\n\nBy the late 1930s, some musicals began to be written with a more operatic structure. These works include complex polyphonic ensembles and reflect musical developments of their times. \"Porgy and Bess\" (1935), influenced by jazz styles, and \"Candide\" (1956), with its sweeping, lyrical passages and farcical parodies of opera, both opened on Broadway but became accepted as part of the opera repertory. Popular musicals such as \"Show Boat\", \"West Side Story\", \"Brigadoon\", \"\", \"Passion\", \"Evita\", \"The Light in the Piazza\", \"The Phantom of the Opera\" and others tell dramatic stories through complex music and in the 2010s they are sometimes seen in opera houses. \"The Most Happy Fella\" (1952) is quasi-operatic and has been revived by the New York City Opera. Other rock influenced musicals, such as \"Tommy\" (1969) and \"Jesus Christ Superstar\" (1971), \"Les Misérables\" (1980), \"Rent\" (1996), \"Spring Awakening\" (2006), and \"Natasha, Pierre & The Great Comet of 1812\" (2012) employ various operatic conventions, such as through composition, recitative instead of dialogue, and leitmotifs.\n\nA subtle type of sound electronic reinforcement called acoustic enhancement is used in some modern concert halls and theatres where operas are performed. Although none of the major opera houses \"...use traditional, Broadway-style sound reinforcement, in which most if not all singers are equipped with radio microphones mixed to a series of unsightly loudspeakers scattered throughout the theatre\", many use a sound reinforcement system for acoustic enhancement and for subtle boosting of offstage voices, child singers, onstage dialogue, and sound effects (e.g., church bells in \"Tosca\" or thunder effects in Wagnerian operas).\n\nOperatic vocal technique evolved, in a time before electronic amplification, to allow singers to produce enough volume to be heard over an orchestra, without the instrumentalists having to substantially compromise their volume.\n\nSingers and the roles they play are classified by voice type, based on the tessitura, agility, power and timbre of their voices. Male singers can be classified by vocal range as bass, bass-baritone, baritone, tenor and countertenor, and female singers as contralto, mezzo-soprano and soprano. (Men sometimes sing in the \"female\" vocal ranges, in which case they are termed sopranist or countertenor. The countertenor is commonly encountered in opera, sometimes singing parts written for castrati—men neutered at a young age specifically to give them a higher singing range.) Singers are then further classified by size—for instance, a soprano can be described as a lyric soprano, coloratura, soubrette, spinto, or dramatic soprano. These terms, although not fully describing a singing voice, associate the singer's voice with the roles most suitable to the singer's vocal characteristics.\n\nYet another sub-classification can be made according to acting skills or requirements, for example the \"Basso Buffo\" who often must be a specialist in patter as well as a comic actor. This is carried out in detail in the \"Fach\" system of German speaking countries, where historically opera and spoken drama were often put on by the same repertory company.\n\nA particular singer's voice may change drastically over his or her lifetime, rarely reaching vocal maturity until the third decade, and sometimes not until middle age. Two French voice types, \"premiere dugazon\" and \"deuxieme dugazon\", were named after successive stages in the career of Louise-Rosalie Lefebvre (Mme. Dugazon). Other terms originating in the star casting system of the Parisian theatres are \"baryton-martin\" and soprano \"falcon\".\n\nThe soprano voice has typically been used as the voice of choice for the female protagonist of the opera since the latter half of the 18th century. Earlier, it was common for that part to be sung by any female voice, or even a castrato. The current emphasis on a wide vocal range was primarily an invention of the Classical period. Before that, the vocal virtuosity, not range, was the priority, with soprano parts rarely extending above a high A (Handel, for example, only wrote one role extending to a high C), though the castrato Farinelli was alleged to possess a top D (his lower range was also extraordinary, extending to tenor C). The mezzo-soprano, a term of comparatively recent origin, also has a large repertoire, ranging from the female lead in Purcell's \"Dido and Aeneas\" to such heavyweight roles as Brangäne in Wagner's \"Tristan und Isolde\" (these are both roles sometimes sung by sopranos; there is quite a lot of movement between these two voice-types). For the true contralto, the range of parts is more limited, which has given rise to the insider joke that contraltos only sing \"witches, bitches, and britches\" roles. In recent years many of the \"trouser roles\" from the Baroque era, originally written for women, and those originally sung by castrati, have been reassigned to countertenors.\n\nThe tenor voice, from the Classical era onwards, has traditionally been assigned the role of male protagonist. Many of the most challenging tenor roles in the repertory were written during the \"bel canto\" era, such as Donizetti's sequence of 9 Cs above middle C during \"La fille du régiment\". With Wagner came an emphasis on vocal heft for his protagonist roles, with this vocal category described as \"Heldentenor\"; this heroic voice had its more Italianate counterpart in such roles as Calaf in Puccini's \"Turandot\". Basses have a long history in opera, having been used in \"opera seria\" in supporting roles, and sometimes for comic relief (as well as providing a contrast to the preponderance of high voices in this genre). The bass repertoire is wide and varied, stretching from the comedy of Leporello in \"Don Giovanni\" to the nobility of Wotan in Wagner's \"Ring Cycle,\" to the conflicted King Phillip of Verdi's \"Don Carlos\". In between the bass and the tenor is the baritone, which also varies in weight from say, Guglielmo in Mozart's \"Così fan tutte\" to Posa in Verdi's \"Don Carlos\"; the actual designation \"baritone\" was not standard until the mid-19th century.\n\nEarly performances of opera were too infrequent for singers to make a living exclusively from the style, but with the birth of commercial opera in the mid-17th century, professional performers began to emerge. The role of the male hero was usually entrusted to a castrato, and by the 18th century, when Italian opera was performed throughout Europe, leading castrati who possessed extraordinary vocal virtuosity, such as Senesino and Farinelli, became international stars. The career of the first major female star (or prima donna), Anna Renzi, dates to the mid-17th century. In the 18th century, a number of Italian sopranos gained international renown and often engaged in fierce rivalry, as was the case with Faustina Bordoni and Francesca Cuzzoni, who started a fist fight with one another during a performance of a Handel opera. The French disliked castrati, preferring their male heroes to be sung by an haute-contre (a high tenor), of which Joseph Legros (1739–1793) was a leading example.\nThough opera patronage has decreased in the last century in favor of other arts and media (such as musicals, cinema, radio, television and recordings), mass media and the advent of recording have supported the popularity of many famous singers including Maria Callas, Enrico Caruso, Amelita Galli-Curci, Kirsten Flagstad, Juan Arvizu, Nestor Mesta Chayres,\nMario Del Monaco, Risë Stevens, Alfredo Kraus, Franco Corelli, Montserrat Caballé, Joan Sutherland, Birgit Nilsson, Nellie Melba, Rosa Ponselle, Beniamino Gigli, Jussi Björling, Feodor Chaliapin, Cecilia Bartoli, Renée Fleming, Marilyn Horne, Bryn Terfel and \"The Three Tenors\" (Luciano Pavarotti, Plácido Domingo, and José Carreras).\n\nBefore the 1700s, Italian operas used a small string orchestra, but it rarely played to accompany the singers. Opera solos during this period were accompanied by the basso continuo group, which consisted of the harpsichord, \"plucked instruments\" such as lute and a bass instrument. The string orchestra typically only played when the singer was not singing, such as during a singer's \"...entrances and exits, between vocal numbers, [or] for [accompanying] dancing\". Another role for the orchestra during this period was playing an orchestral ritornello to mark the end of a singer's solo. During the early 1700s, some composers began to use the string orchestra to mark certain aria or recitatives \"...as special\"; by 1720, most arias were accompanied by orchestra. Opera composers such as Domenico Sarro, Leonardo Vinci, Giambattista Pergolesi, Leonardo Leo, and Johann Adolf Hasse added new instruments to the opera orchestra and gave the instruments new roles. They added wind instruments to the strings and used orchestral instruments to play instrumental solos, as a way to mark certain arias as special.\n\nThe orchestra has also provided an instrumental overture before the singers come onstage since the 1600s. Peri's \"Euridice\" opens with a brief instrumental ritornello, and Monteverdi's \"L'Orfeo\" (1607) opens with a toccata, in this case a fanfare for muted trumpets. The French overture as found in Jean-Baptiste Lully's operas consist of a slow introduction in a marked \"dotted rhythm\", followed by a lively movement in fugato style. The overture was frequently followed by a series of dance tunes before the curtain rose. This overture style was also used in English opera, most notably in Henry Purcell's \"Dido and Aeneas\". Handel also uses the French overture form in some of his Italian operas such as Giulio Cesare.\n\nIn Italy, a distinct form called \"overture\" arose in the 1680s, and became established particularly through the operas of Alessandro Scarlatti, and spread throughout Europe, supplanting the French form as the standard operatic overture by the mid-18th century. It uses three generally homophonic movements: fast–slow–fast. The opening movement was normally in duple metre and in a major key; the slow movement in earlier examples was short, and could be in a contrasting key; the concluding movement was dance-like, most often with rhythms of the gigue or minuet, and returned to the key of the opening section. As the form evolved, the first movement may incorporate fanfare-like elements and took on the pattern of so-called \"sonatina form\" (sonata form without a development section), and the slow section became more extended and lyrical.\n\nIn Italian opera after about 1800, the \"overture\" became known as the \"sinfonia\". Fisher also notes the term \"Sinfonia avanti l'opera\" (literally, the \"symphony before the opera\") was \"an early term for a sinfonia used to begin an opera, that is, as an overture as opposed to one serving to begin a later section of the work\". In 19th-century opera, in some operas, the overture, \"Vorspiel\", \"Einleitung\", Introduction, or whatever else it may be called, was the portion of the music which takes place before the curtain rises; a specific, rigid form was no longer required for the overture.\n\nThe role of the orchestra in accompanying the singers changed over the 19th century, as the Classical style transitioned to the Romantic era. In general, orchestras got bigger, new instruments were added, such as additional percussion instruments (e.g., bass drum, cymbals, snare drum, etc.). The orchestration of orchestra parts also developed over the 19th century. In Wagnerian operas, the forefronting of the orchestra went beyond the overture. In Wagnerian operas such as \"Tristan\", the orchestra often played the recurrent musical themes or leitmotifs, a role which gave a prominence to the orchestra which \"...elevated its status to that of a prima donna.\" Wagner's operas were scored with unprecedented scope and complexity, adding more brass instruments and huge ensemble sizes: indeed, his score to \"Das Rheingold\" calls for six harps.\n\nAs the role of the orchestra and other instrumental ensembles changed over the history of opera, so did the role of leading the musicians. In the Baroque era, the musicians were usually directed by the harpsichord player, although the French composer Lully is known to have conducted with a long staff. In the 1800s, during the Classical period, the first violinist, also known as the concertmaster, would lead the orchestra while sitting. Over time, some directors began to stand up and use hand and arm gestures to lead the performers. Eventually this role of music director became termed the conductor, and a podium was used to make it easier for all the musicians to see him or her. By the time Wagnerian operas were introduced, the complexity of the works and the huge orchestras used to play them gave the conductor an increasingly important role. Modern opera conductors have a challenging role: they have to direct both the orchestra in the orchestra pit and the singers up on stage.\n\nSince the days of Handel and Mozart, many composers have favored Italian as the language for the libretto of their operas. From the Bel Canto era to Verdi, composers would sometimes supervise versions of their operas in both Italian and French. Because of this, operas such as \"Lucia di Lammermoor\" or \"Don Carlos\" are today deemed canonical in both their French and Italian versions.\n\nTill the mid 1950s, it was acceptable to produce operas in translations even if these had not been authorized by the composer or the original librettists. For example, opera houses in Italy routinely staged Wagner in Italian. After WWII, opera scholarship improved, artists refocused on the original versions, and translations fell out of favor. Knowledge of European languages, especially Italian, French, and German, is today an important part of the training for professional singers.\"The biggest chunk of operatic training is in linguistics and musicianship,\" explains mezzo-soprano Dolora Zajick. \"[I have to understand] not only what I'm singing, but what everyone else is singing. I sing Italian, Czech, Russian, French, German, English.\"\n\nIn the 1980s, supertitles (sometimes called surtitles) began to appear. Although supertitles were first almost universally condemned as a distraction, today many opera houses provide either supertitles, generally projected above the theatre's proscenium arch, or individual seat screens where spectators can choose from more than one language. TV broadcasts typically include subtitles even if intended for an audience who knows well the language (for example, a RAI broadcast of an Italian opera). These subtitles target not only the hard of hearing but the audience generally, since a sung discourse is much harder to understand than a spoken one—even in the ears of native speakers. Subtitles in one or more languages have become standard in opera broadcasts, simulcasts, and DVD editions.\n\nToday, operas are only rarely performed in translation. Exceptions include the English National Opera, the Opera Theater of St. Louis, Opera Theater of Pittsburgh, and Opera South East, which favor English translations. Another exception are opera productions intended for a young audience, such as Humperdinck's \"Hansel and Gretel\" and some productions of Mozart's \"The Magic Flute\".\n\nOutside the US, and especially in Europe, most opera houses receive public subsidies from taxpayers. In Milan, Italy, 60% of La Scala's annual budget of €115 million is from ticket sales and private donations, with the remaining 40% coming from public funds. In 2005, La Scala received 25% of Italy's total state subsidy of €464 million for the performing arts. In the UK, Arts Council England provides funds to Opera North, the Royal Opera House, Welsh National Opera, and English National Opera. Between 2012 and 2015, these four opera companies along with the English National Ballet, Birmingham Royal Ballet and Northern Ballet accounted for 22% of the funds in the Arts Council's national portfolio. During that period, the Council undertook an analysis of its funding for large-scale opera and ballet companies, setting recommendations and targets for the companies to meet prior to the 2015–2018 funding decisions. In February 2015, concerns over English National Opera's business plan led to the Arts Council placing it \"under special funding arrangements\" in what \"The Independent\" termed \"the unprecedented step\" of threatening to withdraw public funding if the Council's concerns were not met by 2017. European public funding to opera has led to a disparity between the number of year-round opera houses in Europe and the United States. For example, \"Germany has about 80 year-round opera houses [as of 2004], while the U.S., with more than three times the population, does not have any. Even the Met only has a seven-month season.\"\n\nA milestone for opera broadcasting in the U.S. was achieved on December 24, 1951, with the live broadcast of \"Amahl and the Night Visitors\", an opera in one act by Gian Carlo Menotti. It was the first opera specifically composed for television in America. Another milestone occurred in Italy in 1992 when \"Tosca\" was broadcast live from its original Roman settings and times of the day: The first act came from the 16th-century Church of Sant'Andrea della Valle at noon on Saturday; the 16th-century Palazzo Farnese was the setting for the second at 8:15 P.M.; and on Sunday at 6 A.M., the third act was broadcast from Castel Sant'Angelo. The production was transmitted via satellite to 105 countries.\n\nMajor opera companies have begun presenting their performances in local cinemas throughout the United States and many other countries. The Metropolitan Opera began a series of live high-definition video transmissions to cinemas around the world in 2006. In 2007, Met performances were shown in over 424 theaters in 350 U.S. cities. \"La bohème\" went out to 671 screens worldwide. San Francisco Opera began prerecorded video transmissions in March 2008. As of June 2008, approximately 125 theaters in 117 U.S. cities carry the showings. The HD video opera transmissions are presented via the same HD digital cinema projectors used for major Hollywood films. European opera houses and festivals including the Royal Opera in London, La Scala in Milan, the Salzburg Festival, La Fenice in Venice, and the Maggio Musicale in Florence have also transmitted their productions to theaters in cities around the world since 2006, including 90 cities in the U.S.\n\nThe emergence of the Internet has also affected the way in which audiences consume opera. In 2009 the British Glyndebourne Festival Opera offered for the first time an online digital video download of its complete 2007 production of \"Tristan und Isolde\". In 2013 season the festival streamed all six of its productions online. In July 2012 the first online community opera was premiered at the Savonlinna Opera Festival. Titled \"Free Will\", it was created by members of the Internet group Opera By You. Its 400 members from 43 countries wrote the libretto, composed the music, and designed the sets and costumes using the Wreckamovie web platform. Savonlinna Opera Festival provided professional soloists, an 80-member choir, a symphony orchestra, and the stage machinery. It was performed live at the festival and streamed live on the internet.\n\nNotes\nMain sources\n\nOther sources\n\n\n\n\n"}
{"id": "39246927", "url": "https://en.wikipedia.org/wiki?curid=39246927", "title": "Orator (Cicero)", "text": "Orator (Cicero)\n\nOrator was written by Marcus Tullius Cicero in the latter part of the year 46 B.C. It is his last work on rhetoric, three years before his death. Describing rhetoric, Cicero addresses previous comments on the five canons of rhetoric: Inventio, Dispositio, Elocutio, Memoria, and Pronuntiatio. In this text, Cicero attempts to describe the perfect orator, in response to Marcus Junius Brutus’ request. \"Orator\" is the continuation of a debate between Brutus and Cicero, which originated in his text \"Brutus\", written earlier in the same year. \n\nThe oldest partial text of \"Orator\" was recovered in the monastery of Mont Saint-Michel and now is located in the library at Avranches. Thirty-seven existing manuscripts have been discovered from this text. Another complete text was discovered in 1421, near Milan in the town of Lodi. These two texts vary considerably between the two manuscripts and modern translators rely on both. \n\nIn 46. B.C, when Cicero wrote \"Orator\", many young Roman men revolted against the stylistic paradigms put forward by Cicero, and from most Roman traditions in general. Cicero writes in a defensive posture to this hostile audience.\n\nIn \"Orator\", Cicero depicts several models for speakers. Cicero states to the Romans the importance of searching and discovering their own sense of rhetoric. “I am sure, the magnificence of Plato did not deter Aristotle from writing, nor did Aristotle with all his marvelous breadth of knowledge put an end to the studies of others” Cicero encouraged the plebeians through his writing, “Moreover, not only were outstanding men not deterred from undertaking liberal pursuits, but even craftsmen did not give up their arts because they were unable to equal the beauty of the picture of Ialysus . . . .” Cicero proposes that rhetoric cannot be confined to one specific group but rather outlines a guide that will lead to the creation of successful orators across Roman society.\n\nIn \"Orator\", Cicero also addressed the accusation lodged by his fellow senators, including Brutus, that he was an “Atticist.” Cicero addresses this claim by saying that he is too independent and bold to be associated with Atticism, producing his own unique style. Cicero claims the perfect orator creates his own “elocutio,” or diction and style, rather than following this movement.\n\nThe three aims of the orator, according to Cicero, are \"\"docere, delectare, et movere\".\" That is: to prove your thesis to the audience, to delight the audience, and to emotionally move the audience. The emotional vividness of poetic language becomes part of the rhetorical tools in service of persuading the audience to your point of view.\n\n"}
{"id": "22417121", "url": "https://en.wikipedia.org/wiki?curid=22417121", "title": "Rabelais and His World", "text": "Rabelais and His World\n\nRabelais and His World (Russian: Творчество Франсуа Рабле и народная культура средневековья и Ренессанса, \"Tvorčestvo Fransua Rable i narodnaja kul'tura srednevekov'ja i Renessansa\"; 1965) is a scholarly work which is considered one of Mikhail Bakhtin's most important texts and now a classic of Renaissance studies. In the work Bakhtin explores \"Gargantua and Pantagruel\" by the French Renaissance writer François Rabelais.\n\nBakhtin argues that for centuries Rabelais’s book has been misunderstood. Bakhtin attempts to redress this and clarify Rabelais's intentions through two methods: recovery of sections of \"Gargantua and Pantagruel\" that were previously either ignored or suppressed, and analysis of the Renaissance social system in order to discover the balance between language that was permitted and language that was not. Through this analysis, Bakhtin pinpoints two important subtexts: \"carnival\" (carnivalesque) which Bakhtin describes as a social institution, and \"grotesque realism,\" which is defined as a literary mode. \n\nThus, in \"Rabelais and His World\" Bakhtin studies the interaction between the social and the literary, as well as the meaning of the body. As written, \"Rabelais and His World\" not only examines the openness of \"Gargantua and Pantagruel\", it also serves as an example of such openness.\n\nBakhtin completed his book on Rabelais (titled \"Rabelais in the History of Realism\") in 1940. After several attempts to get the book published fell through, it was submitted as a dissertation for the Candidate of Sciences degree at the Gorky Institute of World Literature in Moscow. At the dissertation's defense in 1946, all three official opponents were in favor of awarding Bakhtin a higher doctoral degree: the Doctor of Sciences, and their motion was accepted with a narrow majority vote. However, following an assault on the institute published in the press at the time, and after six years of repeated revisions and deliberations, USSR's VAK decided Bakhtin would only receive the Candidate of Sciences degree (roughly equivalent to a research doctorate). The book was eventually published in Russian in 1965, under the title \"Rabelais and Folk Culture of the Middle Ages and Renaissance\". Its 1968 English translation by Hélène Iswolsky was given the title, \"Rabelais and His World\".\n\nFor Bakhtin, \"carnival\" is associated with the collectivity. Those attending a carnival do not merely constitute a crowd; rather the people are seen as a\nwhole, organized in a way that defies socioeconomic and political organization. According to Bakhtin, “[A]ll were considered equal during carnival. Here, in the town square, a special form of free and familiar contact reigned among people who were usually divided by the barriers of caste, property, profession, and age”. The carnival atmosphere holds the lower strata of life most important, as opposed to higher functions (thought, speech, soul) which were usually held dear in the signifying order. At carnival time, the unique sense of time and space causes individuals to feel they are a part of the collectivity, at which point they cease to be themselves. It is at this point that, through costume and mask, an individual exchanges bodies and is renewed. At the same time there arises a heightened awareness of one’s sensual, material, bodily unity and community.\n\nBakhtin’s notion of \"carnival\" is connected with that of the \"grotesque\". In the carnival, usual social hierarchies and proprieties are upended; emphasis is placed on the body in its open dimension, in its connection to the life of the community. This emphasis on the material dimension which links humans, rather than on the differences and separations between them, allows for the consciousness of the historical dimension of human life: for every death, there is a birth, a renewal of the human spirit. This process allows for progress.<br>\nIn the grotesque body, emphasis is placed on the open, the penetrative, and the \"lower stratum.\" The open (the mouth, the anus, the vagina, etc.) and the penetrative (the nose, the penis, etc.) allow exchange between the body and the world (mostly through sex, eating, and drinking), but also to produce degrading material (curses, urine, feces, etc.). The lower stratum (belly, womb, etc.) is the place where renewal happens, where new life is forged, thus connecting degradation to renewal. The grotesque body is one of excess, rebellious to authority and austerity. <br>\nDue to its inscription in time and its emphasis on bodily changes (through eating, evacuation, and sex), the \"grotesque\" has been interpreted by some critics as a dimension of the body that permits to perceive the historicity of man: it is in this reading used as a measuring device.\n\nBakhtin opens this work with a quotation from Alexander Herzen: \"It would be extremely interesting to write the history of laughter\".\n\nOne of the primary expressions of the ancient world's conceptions of laughter is the text that survives in the form of apocryphal letters of Hippocrates about Democritus (Hippocratic Corpus, \"Epistles\" 10–21). The laughter of Democritus had a philosophical character, being directed at the life of man and at all the vain fears and hopes related to the gods and to life after death. Democritus here made of his laughter a complete conception of the world, a certain spiritual premise of the man who has attained maturity and has awakened. Hippocrates finally perfectly agreed with him.\n\n"}
{"id": "43488", "url": "https://en.wikipedia.org/wiki?curid=43488", "title": "Rave", "text": "Rave\n\nA rave (from the verb: \"to rave\") is an organised dance party at a nightclub, outdoor festival, warehouse, or other private property typically featuring performances by DJs, playing a seamless flow of electronic dance music. DJs at rave events play electronic dance music on vinyl, CDs and digital audio from a wide range of genres, including techno, hardcore, house, drum & bass, dubstep, and post-industrial. Occasionally live performers have been known to perform, in addition to other types of performance artists such as go-go dancers and fire dancers. The music is amplified with a large, powerful sound reinforcement system, typically with large subwoofers to produce a deep bass sound. The music is often accompanied by laser light shows, projected coloured images, visual effects and fog machines.\n\nWhile some raves may be small parties held at nightclubs or private homes, some raves have grown to immense size, such as the large festivals and events featuring multiple DJs and dance areas (e.g., the Castlemorton Common Festival in 1992). Some electronic dance music festivals have features of raves, but on a larger, often commercial scale. Raves may last for a long time, with some events continuing for twenty-four hours, and lasting all through the night. Law enforcement raids and anti-rave laws have presented a challenge to the rave scene in many countries. This is due to the association of illegal drugs such as MDMA (often referred to as a \"club drug\" or \"party drug\" along with MDA), LSD, GHB, ketamine, methamphetamine, cocaine, and cannabis. In addition to drugs, raves often make use of non-authorized, secret venues, such as squat parties at unoccupied homes, unused warehouses, or aircraft hangars. These concerns are often attributed to a type of moral panic surrounding rave culture.\n\nIn the late 1950s in London, England the term \"rave\" was used to describe the \"wild bohemian parties\" of the Soho beatnik set. Jazz musician Mick Mulligan, known for indulging in such excesses, had the nickname \"king of the ravers\". In 1958, Buddy Holly recorded the hit \"Rave On,\" citing the madness and frenzy of a feeling and the desire for it never to end. The word \"rave\" was later used in the burgeoning mod youth culture of the early 1960s as the way to describe any wild party in general. People who were gregarious party animals were described as \"ravers\". Pop musicians such as Steve Marriott of The Small Faces and Keith Moon of The Who were self-described \"ravers\".\nPresaging the word's subsequent 1980s association with electronic music, the word \"rave\" was a common term used regarding the music of mid-1960s garage rock and psychedelia bands (most notably The Yardbirds, who released an album in the US called \"Having a Rave Up\"). Along with being an alternative term for partying at such garage events in general, the \"rave-up\" referred to a specific crescendo moment near the end of a song where the music was played faster, more heavily and with intense soloing or elements of controlled feedback. It was later part of the title of an electronic music performance event held on 28 January 1967 at London's Roundhouse titled the \"Million Volt Light and Sound Rave\". The event featured the only known public airing of an experimental sound collage created for the occasion by Paul McCartney of The Beatles – the legendary \"Carnival of Light\" recording.\n\nWith the rapid change of British pop culture from the mod era of 1963–1966 to the hippie era of 1967 and beyond, the term fell out of popular usage. During the 1970s and early 1980s until its resurrection, the term was not in vogue, one notable exception being in the lyrics of the song \"Drive-In Saturday\" by David Bowie (from his 1973 album \"Aladdin Sane\") which includes the line, \"It's a crash course for the ravers.\" Its use during that era would have been perceived as a quaint or ironic use of bygone slang: part of the dated 1960s lexicon along with words such as \"groovy\".\n\nThe perception of the word \"rave\" changed again in the late 1980s when the term was revived and adopted by a new youth culture, possibly inspired by the use of the term in Jamaica.\n\nIn the mid to late 1980s, a wave of psychedelic and other electronic dance music, most notably acid house music, emerged from acid house music parties in the mid-to-late 1980s in the Chicago area in the United States. After Chicago acid house artists began experiencing overseas success, acid house quickly spread and caught on in the United Kingdom within clubs, warehouses and free-parties, first in Manchester in the mid-1980s and then later in London. In the late 1980s, the word \"rave\" was adopted to describe the subculture that grew out of the acid house movement. Activities were related to the party atmosphere of Ibiza, a Mediterranean island in Spain, frequented by British, Italian, Greek, Irish and German youth on vacation, who would hold raves and dance parties.\n\nBy the 1990s, genres such as acid, breakbeat hardcore, hardcore, happy hardcore, gabber, post-industrial and electronica were all being featured at raves, both large and small. There were mainstream events which attracted thousands of people (up to 25,000 instead of the 4,000 that came to earlier warehouse parties). Acid house music parties were first re-branded \"rave parties\" in the media, during the summer of 1989 by Genesis P-Orridge (Neil Andrew Megson) during a television interview; however, the ambience of the rave was not fully formed until the early 1990s. In 1990, raves were held \"underground\" in several cities, such as Berlin, Milan and Patras, in basements, warehouses and forests.\n\nBritish politicians responded with hostility to the emerging rave party trend. Politicians spoke out against raves and began to fine promoters who held unauthorized parties. Police crackdowns on these often unauthorized parties drove the rave scene into the countryside. The word \"rave\" somehow caught on in the UK to describe common semi-spontaneous weekend parties occurring at various locations linked by the brand new M25 London orbital motorway that ringed London and the Home Counties. (It was this that gave the band Orbital their name.) These ranged from former warehouses and industrial sites in London, to fields and country clubs in the countryside.\n\nPrior to the commercialization of the rave scene, when large legal venues became the norm for these events, the location of the rave was kept secret until the night of the event, usually being communicated through answering machine messages, mobile messaging, secret flyers, and websites. This level of secrecy, necessary for avoiding any interference by the police, on account of the illicit drug use, enabled the ravers to use locations they could stay in for ten hours at a time. It promoted the sense of deviance and removal from social control. In the 2000s, this level of secrecy still exists in the underground rave scene. However \"after-hours\" clubs, as well as large outdoor events, create a similar type of alternate atmosphere, but focus much more on vibrant visual effects, such as props and décor. In more recent years, large commercial events are held at the same locations year after year with similar reoccurring themes every year. Events like Electric Daisy Carnival and Tomorrowland are typically held at the same venue that holds mass numbers of people.\n\nSome raves make use of pagan symbolism. Modern raving venues attempt to immerse the raver in a fantasy-like world. Indigenous imagery and spirituality can be characteristic in the Raving ethos. In both the New Moon and Gateway collectives, \"pagan altars are set up, sacred images from primitive cultures decorate the walls, and rituals of cleansing are performed over the turntables and the dance floor\" This type of spatial strategy is an integral part of the raving experience because it sets the initial \"vibe\" in which the ravers will immerse themselves. This said \"vibe\" is a concept in the raver ethos that represents the allure and receptiveness of an environment's portrayed and or innate energy. The landscape is an integral feature in the composition of rave, much like it is in pagan rituals. For example, The Numic Ghost Dancers rituals were held on specific geographical sites, considered to hold powerful natural flows of energy. These sites were later represented in the rhythmic dances, in order to achieve a greater level of connectivity.\n\nThe following is an incomplete list of venues associated with the rave subculture:\nA sense of participation in a group event is among the chief appeals of rave music and dancing to pulsating beats is its immediate outlet. Raving in itself is a syllabus-free dance, whereby the movements are not predefined and the dance is performed randomly, dancers take immediate inspiration from the music, their mood and watching other people dancing. Thus, the electronic, rave and club dances refer to the street dance styles that evolved alongside electronic music culture. Such dances are street dances since they evolved alongside the underground rave and club movements, without the intervention of dance studios. These dances were originated in some 'scenes' around the world, becoming known only to ravers or clubgoers who attempt to these locations. They were originated at some point that certain moves had begun to be performed to several people at those places, creating a completely freestyle, yet still highly complex set of moves, adaptable to every dancer change and dance whatever they want based on these moves. Many rave dancing techniques suggest using your body as an extension of the music, to loosen up, and let the music flow through the body to create a unique form of movement.\n\nA common feature shared by all these dances, alongside with being originated at clubs, raves and music festivals around the world and in different years, is that when YouTube and other social media started to become popular (around 2006), these dances began to be popularized by videos of raves performing them, recording and uploading their videos. Therefore, they began to be practiced outside their places of origin, creating different 'scenes' in several countries. Furthermore, some of these dances began to evolve, and these dance 'scenes' are not totally related to the club/rave scenes they were originated. Also, the way of teaching and learning them have changed. In the past, if someone wanted to learn one of these dances, the person had to go to a club/rave, watch people dancing and try to copy them. Now, with social media, these dances are mostly taught on video tutorials and the culture spreads and grows inside those social media, like Flogger on Fotolog, Rebolation, Sensualize and Free Step on Orkut and Cutting Shapes on Instagram.\n\nDue the lack of studies dedicated to those dances, combined with poor and inaccurate information of them available on the Internet, it is hard to find reliable information.\n\nThe loose, casual and sports clothing was originally adopted by the acid house set earlier on in Ibiza, utilizing easy-to-dance-in attire from hip hop and football/soccer culture. As well as clothing there developed a range of accessories carried by many ravers including: Vicks VapoRub, which ravers find pleasant under the influence of MDMA, pacifiers to satiate the need to grind one's teeth (bruxism) caused by taking MDMA, and glow sticks which adjunct the mild psychedelia of MDMA's effect.\n\nIn the United States and other countries, rave fashion is characterized by colorful clothing and accessories, most notably \"kandi\" jewellery, that fluoresce under ultraviolet light. They contain words or phrases that are unique to the raver and they can choose to trade with each other using \"PLUR\" (Peace, Love, Unity, Respect). In European countries, this kandi culture is much less common. Most raves are illegal and take place outside or in poorly heated warehouses, so keeping warm is a priority. Dreadlocks, dyed hair and mohawks are popular, as are tattoos and piercings. Clothing is vibrant and alternative, often taking inspiration from new-age punk and grunge style. However, there is no set dress code for the illegal rave scene. Some global rave events such as Sensation adopted a strict minimalistic dress policy, either all white or black attire.\n\nSince rave culture has seen such an explosion in the US since 2010 as the rave scene is no longer illegal or underground, raves in the US are now so popular that there are many brands, retailers, and websites selling apparel, costumes, and accessories just for those who go to dress up at raves. This style of attire, along with the entire rave culture, is now spilling out into the mainstream, especially in the US. Sometimes called \"rave fashion\" or \"festival fashion,\" it now includes all kinds of accessories to create unique looks depending on the person and event.\n\nSome ravers participate in one of four light-oriented dances, called \"glowsticking\", \"glowstringing\", \"gloving\", and \"lightshows\". Of the four types of light-orientated dances, gloving in particular has evolved beyond and outside of the rave culture. Other types of light-related dancing include LED lights, flash-lights and blinking strobe lights. LEDs come in various colours with different settings.\nGloving has evolved into a separate dance form that has grown exponentially in the last couple of years. Since then the culture has extended to all ages, ranging from kids in their early teens to college students and more. The traditional Rav'n lights are limited now, but many stores have developed newer, brighter, and more advanced version of lights with a plethora of colors and modes—modes include solid, stribbon, strobe, dops, hyper flash, and other variations.\n\nAmong the various elements of 1970s disco subculture that ravers drew on, in addition to basing their scene around dance music mixed by DJs, ravers also inherited the positive attitude towards using club drugs to \"enhanc[e]...the sensory experience\" of dancing to loud music. However, disco dancers and ravers preferred different drugs. Whereas 1970s disco scene members preferred cocaine and the depressant/sedative Quaaludes, ravers preferred MDMA, 2C-B, amphetamine, morphine and other pills. According to the FBI, raves are one of the most popular venues where club drugs are distributed, and as such feature a prominent drug subculture. Club drugs include MDMA (more commonly known as \"ecstasy\", \"E\" or \"molly\"), 2C-B (more commonly known as \"nexus\"), amphetamine (commonly referred to as \"speed\"), morphine (commonly known as \"morphy\" or \"M\" ), GHB (commonly referred to as \"fantasy\" or \"liquid E\"), cocaine (common short name for \"coke\"), DMT and LSD (commonly referred to as \"lucy\" or \"acid\").\n\n\"Poppers\" is the street name for alkyl nitrites (the most well-known being amyl nitrite), which are inhaled for their intoxicating effects, notably the \"rush\" or \"high\" they can provide. Nitrites originally came as small glass capsules that were popped open, which led to the nickname \"poppers.\" The drug became popular in the US first on the disco/club scene of the 1970s and then at dance and rave venues in the 1980s and 1990s. In the 2000s, synthetic phenethylamines such as 2C-I, 2C-B and DOB have been referred to as club drugs due to their stimulating and psychedelic nature (and their chemical relationship with MDMA). By late 2012, derivates of the psychedelic 2C-X drugs, the NBOMes and especially 25I-NBOMe, had become common at raves in Europe. In the U.S., some law enforcement agencies have branded the subculture as a drug-centric culture, as rave attendees have been known to use drugs such as cannabis, 2CB, and DMT.\n\nGroups that have addressed alleged drug use at raves e.g. the Electronic Music Defense and Education Fund (EM:DEF), The Toronto Raver Info Project (Canada), DanceSafe (USA and Canada), and Eve & Rave (Germany and Switzerland), all of which advocate harm reduction approaches. In 2005, Antonio Maria Costa, Executive Director of the United Nations Office on Drugs and Crime, advocated drug testing on highways as a countermeasure against drug use at raves.\nMuch of the controversy, moral panic and law enforcement attention directed at rave culture and its association with drug use may be due to reports of drug overdoses (particularly MDMA) at raves, concerts and festivals.\n\nIn 2001 Calgary, Alberta became the first major municipality in Canada to pass a bylaw with respect to raves. The intent of the bylaw was to ensure that raves would be safe for participants, and also not unduly disruptive to adjacent neighbourhoods. The bylaw was created in consultation with representatives from the municipality, the province of Alberta, and the rave community.\n\nBy 1988, acid house was making as significant an impact on popular consciousness in Germany and Central Europe as it had in England. In 1989 German DJs Westbam and Dr. Motte established the Ufo Club, an illegal party venue, and co-founded the Love Parade. On 9 November 1989 the Berlin Wall fell, free underground Techno parties mushroomed in East Berlin, and a rave scene comparable to that in the UK was established. East German DJ Paul van Dyk has remarked that the Techno-based rave scene was a major force in re-establishing social connections between East and West Germany during the unification period. In urbanized Germany raves and techno parties often preferred industrial sceneries such as decommissioned power stations, factories, the canalization or former military properties of the cold war.\n\nIn 1991 a number of party venues closed, including Ufo, and the Berlin Techno scene centred itself around three locations close to the foundations of the Berlin Wall: the E-Werk, the Bunker and the now legendary Tresor. In the same period, German DJs began intensifying the speed and abrasiveness of the sound, as an acid-infused techno began transmuting into hardcore. This emerging sound was influenced by Dutch gabber and Belgian hardcore. Other influences on the development of this style were European Electronic Body Music groups of the mid-1980s such as DAF, Front 242, and Nitzer Ebb.\n\nAcross Europe, rave culture was becoming part of a new youth movement. DJs and electronic-music producers such as Westbam proclaimed the existence of a \"raving society\" and promoted electronic music as legitimate competition for rock and roll. Indeed, electronic dance music and rave subculture became mass movements. Since the mid 1990s, raves had tens of thousands of attendees, youth magazines featured styling tips, and television networks launched music magazines on House and Techno music. The annual Love Parade festivals in Berlin and later the Metropolitan Ruhr area repeatedly attracted more than one million party-goers between 1997 and 2010. Dozens of other annual technoparades took place in Germany and Central Europe at that time, the largest ones being Union Move, Generation Move, Reincarnation and Vision Parade as well as Street Parade and Lake Parade in Switzerland. Large commercial raves since the nineties include Mayday, Nature One, Time Warp, SonneMondSterne and Melt!. Beyond Berlin, further centers of the techno and rave scene of the 1990s and 2000s in Germany were Frankfurt (famous clubs were \"Omen\", \"Dorian Gray\", \"Cocoon\" and \"U60311\") and Munich (\"Ultraschall\", \"KW – Das Heizkraftwerk\", \"Natraj Temple\", \"Harry Klein\" and \"Rote Sonne\").\n\nFurther popular venues include \"Stammheim (Aufschwung Ost)\" in Kassel, \"Tunnel Club\" in Hamburg and \"Distillery\" in Leipzig. Since the late 2000s, Berlin is still called the capital of electro music and rave, and techno clubs such as Berghain, Tresor, \"Watergate\" or KitKatClub and the way to party in barely renovated venues, ruins or wooden shacks such as, among many others, Club der Visionaere, \"Wilde Renate\", \"Fiese Remise\" or \"Bar 25\", attracted international media attention. One movie that portraits this scene of the 2000s is Berlin Calling starring Paul Kalkbrenner. In the 2010s, there remains a vivid rave and techno scene throughout the country, including numerous festivals and world-class techno clubs also outside of Berlin, such as for example \"MMA Club (Mixed Munich Arts)\" in Munich, \"Institut für Zukunft\" in Leipzig or \"Robert Johnson\" in Offenbach.\n\nThe UK was finally recognized for its rave culture in the late 1980s and early 1990s. By 1991, organisations such as Fantazia and Raindance were holding massive legal raves in fields and warehouses around the country. The Fantazia party at Castle Donington, July 1992 was an open-air, all-night event. The Vision at Pophams airfield in August 1992 and Universe's Tribal Gathering in 1993 had a more festival feel.\n\nBy the middle of 1992, the scene was slowly changing, with local councils passing by-laws and increasing fees in an effort to prevent or discourage rave organisations from acquiring necessary licences. This meant that the days of the large one-off parties were numbered. By the mid-1990s, the scene had also fragmented into many different styles of dance music, making large parties more expensive to set up and more difficult to promote. The sound driving the big raves of the early 1990s had by the end of 1993 split into two distinct and polarising styles, the darker jungle and the faster happy hardcore. Although many ravers left the scene due to the split, promoters such as ESP Dreamscape and Helter Skelter still enjoyed widespread popularity and capacity attendances with multi-arena events catering to the various genres. Notable events of this period included ESP's outdoor Dreamscape 20 event on 9 September 1995 at Brafield aerodrome fields, Northants and Helter Skelter's Energy 97 outdoor event on 9th Aug 1997 at Turweston Aerodrome, Northants.\n\nThe illegal free party scene also reached its zenith for that time after a particularly large festival, when many individual sound systems such as Bedlam, Circus Warp, DIY, and Spiral Tribe set up near Castlemorton Common. The government acted. Under the \"Criminal Justice and Public Order Act 1994\", the definition of music played at a rave was given as:\n\nSections 63, 64 & 65 of the Act targeted electronic dance music played at raves. The Criminal Justice and Public Order Act empowered police to stop a rave in the open air when a hundred or more people are attending, or where two or more are making preparations for a rave. Section 65 allows any uniformed constable who believes a person is on their way to a rave within a five-mile radius to stop them and direct them away from the area; non-compliant citizens may be subject to a maximum fine not exceeding level 3 on the standard scale (£1000). The Act was officially introduced because of the noise and disruption caused by all night parties to nearby residents, and to protect the countryside. However, some participants in the scene claimed it was an attempt to lure youth culture away from MDMA and back to taxable alcohol. In November 1994, the Zippies staged an act of electronic civil disobedience to protest against the CJB (i.e., Criminal Justice Bill).\n\nAfter 1993, the main outlet for raves in the UK were a number of licensed parties, amongst them Helter Skelter, Life at Bowlers (Trafford Park, Manchester), The Edge (formerly the Eclipse [Coventry]), The Sanctuary (Milton Keynes) and Club Kinetic. In London, itself, there were a few large clubs that staged raves on a regular basis, most notably \"The Laser Dome\", \"The Fridge\", \"The Hippodrome\", \"Club U.K.\", and \"Trade.\" \"The Laser Dome\" featured two separate dance areas, \"Hardcore\" and \"Garage\", as well as over 20 video game machines, a silent-movie screening lounge, replicas of the \"Statue of Liberty\", \"San Francisco Bridge\", and a large glass maze. In Scotland, event promoters Rezerection held large-scale events across the country.\n\nBy 1997, the popularity of weekly Superclub nights had taken over from the old Rave format, with a raft of new club-based genres sweeping in (e.g. Trance, Hard House, Speed and UK garage) alongside the more traditional House sound that had regained popularity. Clubs like Gatecrasher and Cream rose to prominence with dress codes and door policies that were the polar opposite of their rave counterparts; stories of refused entry due to not wearing the right clothing were commonplace, but seemingly did nothing to deter Superclub attendance.\n\nAmerican ravers, following their early UK & European counterparts, have been compared to the hippies of the 1960s due to their shared interest in non-violence and psychedelia. Rave culture incorporated disco culture's same love of dance music spun by DJs, drug exploration, sexual promiscuity, and hedonism. Although disco culture had thrived in the mainstream, the rave culture would make an effort to stay underground to avoid the animosity that was still surrounding disco and dance music. The key motive for remaining underground in many parts of the US had to do with curfew and the standard 2:00 am closing of clubs. It was a desire to keep the party going past legal hours that created the underground direction. Because of the legality, they had to be secretive about time and place.\n\nIn the late 1980s, rave culture began to filter through into North America from English expatriates and from US DJs who would visit Europe. However, rave culture's major expansion in North America is often credited to Frankie Bones, who after spinning a party in an aircraft hangar in England, helped organize some of the earliest American raves in the 1990s in New York City called \"Storm Raves\". Storm Raves had a consistent core audience, fostered by zines by fellow Storm DJ (and co-founder, with Adam X and Frankie Bones, of the US techno record store, Groove Records.). Heather Heart held Under One Sky. Simultaneously in NYC, events were introducing electronic dance music to this city's dance scene. Between 1992 and 1994, promotional groups sprung up across the east coast.\n\nIn the 1990s, San Diego held large raves with audiences of thousands. These festivals were held on Indian reservations and ski resorts during the summer months and were headlined by DJs such as Doc Martin, Dimitri of Deee-lite, Afrika Islam and the Hardkiss brothers from San Francisco. They helped to create the Right to Dance movement—a non violent protest held in San Diego and later in Los Angeles.\n\nFeaturing local San Diego DJs Jon Bishop, Steve Pagan, Alien Tom, Jeff Skot and Mark E. Quark performed at these events. The events used large props and themes. The fairy and pixie craze, with ravers getting fairy tattoos and wearing fairy wings to parties was associated with the region. The percussive group Crash Worship was active here.\n\nIn the late 1980s and early 1990s, there was a boom in rave culture in the San Francisco Bay Area. At first, small underground parties sprung up all over the SOMA district in vacant warehouses, loft spaces, and clubs. The no alcohol rule fueled the ecstasy-driven parties. Small underground raves were just starting out and expanding beyond SF to include the East Bay, the South Bay area including San Jose, Santa Clara, and Santa Cruz beaches.\n\nIn late 1991, raves started to expand across northern California, and cities like Sacramento, Oakland, Silicon Valley (Palo Alto, San Jose). The massive parties were taking place in outdoor fields, airplane hangars and hilltops that surround the valley. San Francisco's early promoters and DJs were from the UK and Europe. Raves took place in some of the SOMA art museum event such as, 'Where the wild things are' in the museum on top of the Sony Metreon, and in the Maritime hall (1998–2002).\n\nBy the end of 1994, a new generation of ravers were attracted by the new sounds. EDM began to become popular. Raves could be found in many different kinds of venues, as opposed to just basements and warehouses. Promoters started to take notice and put together the massives of the late 1990s with many music forms under one roof for 12-hour events. 2000 saw the demise of massive raves as curfews were placed on permits handed out to promoters. Instead of all night and into the next day, parties now had to end at 2 a.m. Smaller, intimate venues continued just like they had from the start and underground raves became the norm. The death of an attendee who had taken MDMA at the Electric Daisy Carnival in 2010 put a negative spin on raves in LA and California.\n\nThrough the mid 1990s and into the 2000s the city of Seattle also shared in the tradition of West Coast rave culture. Though a smaller scene compared to San Francisco, Seattle also had many different rave crews, promoters, Djs, and fans. Candy Raver style, friendship and culture became popular in the West Coast rave scene, both in Seattle and San Francisco. At the peak of West Coast rave, Candy Raver, and massive rave popularity (1996–1999,) it was common to meet groups of ravers, promoters, and Djs who frequently travelled between Seattle and San Francisco, which spread the overall sense of West Coast rave culture and the phenomenon of West Coast \"massives\".\n\nBy 2010, raves were becoming the equivalent of large-scale rock music festivals, but many times even bigger and more profitable. The Electric Daisy Carnival in Las Vegas drew more than 300,000 fans over three days in the summer of 2012, making it the largest EDM music festival in North America. Ultra Music Festival in Miami drew 150,000 fans over three days in 2012 while other raves like Electric Zoo in New York, Beyond Wonderland in LA, Movement in Detroit, Electric Forest in Michigan, Spring Awakening in Chicago, and dozens more now attract hundreds of thousands of \"ravers\" every year. These new EDM-based rave events (now simply referred generically to as \"music festivals\") sell out. Festival attendance at the Electric Daisy Carnival (EDC) increased by 39.1%, or 90,000 attendees from 2011 to 2012. In 2013, EDC had attendance of approximately 345,000 people, a record for the festival. The average ticket for EDC cost over $300 and the event contributed $278 million to the Clark County economy in 2013. This festival takes place at a 1,000-acre complex featuring a half dozen custom built stages, enormous interactive art installations, and hundreds of EDM artists. Insomniac, a US EDM event promoter, holds yearly EDC and other EDM events.\n\nRave parties began in Australia as early as the 1980s and continued well into the late 1990s. They were mobilised versions of the 'warehouse parties', across Britain. Similar to the United States and Britain, raves in Australia were unlicensed and held in spaces normally used for industrial and manufacturing purposes, such as warehouses, factories and carpet showrooms. In addition, suburban locations were also used: basketball gymnasiums, train stations and even circus tents were all common venues. In Sydney, common areas used for outdoor events included Sydney Park, a reclaimed garbage dump in the inner south west of the city, Cataract Park and various other natural, unused locations and bush lands. The raves placed a heavy emphasis on the connection between humans and the natural environment, thus many raves in Sydney were held outdoors, notably the 'Happy Valley' parties (1991–1994), 'Ecology' (1992) and 'Field of Dreams 4' (July 6, 1996). The mid-late 1990s saw a slight decline in rave attendance, attributed to the death of Anna Wood at a licensed inner-city Sydney venue, which was hosting a rave party known as \"Apache\". Wood had taken ecstasy and died in hospital a few days later, leading to extensive media exposure on the correlation of drug culture and its links to the rave scene in Australia.\n\nThe tradition continued in Melbourne, with 'Earthcore' parties. Raves also became less underground as they were in the 1990s, and many were held at licensed venues well into the 2000s. Despite this, rave parties of 1990s size became less common. Nonetheless, the rave scene in Australia experienced a resurgence after 2010. During this period the resurfacing of the \"Melbourne Shuffle\", a Melbourne club/rave dance style, became a YouTube trend and videos were uploaded. The rave subculture in Melbourne was strengthened with the opening of clubs such as Bass Station and Hard Candy and the rise of free party groups such as Melbourne Underground. Melbourne helped keep raving culture alive with young people.\n\nThe following is an incomplete list of notable raves, particularly smaller raves that may not fit the profile of being an electronic dance music festival:\n\nThe following is an incomplete list of notable sound systems:\n\n\n\n"}
{"id": "47955329", "url": "https://en.wikipedia.org/wiki?curid=47955329", "title": "Reqa", "text": "Reqa\n\nReqa () is one of the six scripts of Perso-Arabic calligraphy. Reqa was used for private correspondence on small papers or for nonreligious books and texts. Ibn al-Nadim mentioned in his book Al-Fehrest, that the inventor of Reqa script was Al-Fadl ibn Sahl. The script was one of the most favorite scripts in Ottoman Empire. Reqa became gradually simpler by other calligraphers and was changed to a new script called Ruqʿah, which is now the most common handwritten script in Arab countries.\n"}
{"id": "838807", "url": "https://en.wikipedia.org/wiki?curid=838807", "title": "Restoration (cultural heritage)", "text": "Restoration (cultural heritage)\n\nRestoration is a process that attempts to return cultural heritage to some previous state that the restorer imagines was the \"original\". This was commonly done in the past. However, in the late 20th century a separate concept of conservation-restoration was developed that is more concerned with preserving the work of art for the future, and less with making it look pristine. Restoration is controversial, since it often involves some irreversible change to the original material of the artwork with the goal of making it \"look good.\" The attitude that has developed in recent years with the development of conservation is to attempt to make all restoration reversible.\n\nArt conservation can involve the cleaning and stabilization of art work. Ideally, any process used is reversible, departures from that ideal not being undertaken lightly. Cleaning is not a reversible process and can sometimes be controversial due to fears that cleaning would damage a piece, or on the grounds that damage or residue forms part of the history of a given piece and should not be modified. Michelangelo's statue of David has undergone two cleanings to remove dirt that had accumulated on the statue's surface.\n\nArt restoration is vital to the survival of classical paintings and is part of the scientific application of chemistry. It often involves research to determine the original colors and materials of a work.\n\nThe use of watercolor paints to inpaint damages on fresco is an example of a technique utilized to achieve almost complete reversibility. This is the technique used in the 20 year restoration of Da Vinci's \"The Last Supper\" in Milan. One of the most popular inpainting techniques used today is the Tinted Varnish Treatment. This process is done once the piece is fully cleaned and varnished. This last step in the restoration process is to then go into spots where original paint may be missing, or where patched holes and other irregularities may lie. The restorer then goes in with tinted varnish over the top of the non-tinted varnish. This gives the illusion that the spots have been \"re-painted\", while in fact it is just a spot of tinted varnish. Most commonly \"stippling\" is used while using tinted varnish, in order for light to reflect similar to paint. This is done by using tiny dots in a row for variance.\n\nIn 2014, Harvard Art Museums exhibited murals by Mark Rothko from 1961 and 1962 which had faded due to their original display in a dining room. It restored the works to their original appearance by digitally projecting light carefully calibrated at each pixel from a photograph of the original colors, which made up the difference between the current and original appearance without damaging the material.\n\n\n"}
{"id": "1117658", "url": "https://en.wikipedia.org/wiki?curid=1117658", "title": "Social model of disability", "text": "Social model of disability\n\nThe social model of disability is a reaction to the dominant medical model of disability which in itself is a functional analysis of the body as machine to be fixed in order to conform with normative values. The social model of disability identifies systemic barriers, negative attitudes and exclusion by society (purposely or inadvertently) that mean society is the main contributory factor in disabling people. While physical, sensory, intellectual, or psychological variations may cause individual functional limitation or impairments, these do not have to lead to disability unless society fails to take account of and include people regardless of their individual differences. The origins of the approach can be traced to the 1960s; the specific term emerged from the United Kingdom in the 1980s.\n\nIn 1975, the UK organization Union of the Physically Impaired Against Segregation (UPIAS) claimed: \"In our view it is society which disables physically impaired people. Disability is something imposed on top of our impairments by the way we are unnecessarily isolated and excluded from full participation in society.\"\nIn 1983, the disabled academic Mike Oliver coined the phrase \"social model of disability\" in reference to these ideological developments. Oliver focused on the idea of an individual model (of which the medical was a part) versus a social model, derived from the distinction originally made between impairment and disability by the UPIAS.\n\nThe \"social model\" was extended and developed by academics and activists in Australia, the UK, US and other countries, and extended to include all disabled people, including those who have learning difficulties / learning disabilities / or who are intellectually disabled, or people with emotional, mental health or behavioural problems.\n\nOliver did not intend the \"social model of disability\" to be an all encompassing theory of disability, rather a starting point in reframing how society views disability.\n\nA fundamental aspect of the social model concerns equality. The struggle for equality is often compared to the struggles of other socially marginalized groups. Equal rights are said to give empowerment and the \"ability\" to make decisions and the opportunity to live life to the fullest. A related phrase often used by disability rights campaigners, as with other social activism, is \"Nothing About Us Without Us.\"\n\nThe social model of disability focuses on changes required in society. These might be in terms of:\n\n\nThe social model of disability implies that attempts to change, \"fix\" or \"cure\" individuals, especially when used against the wishes of the patient, can be discriminatory and prejudiced. This attitude, which may be seen as stemming from a medical model and a subjective value system, can harm the self-esteem and social inclusion of those constantly subjected to it (e.g. being told they are not as good or valuable, in an overall and core sense, as others). Some communities have actively resisted \"treatments\", while, for example, defending a unique culture or set of abilities. In the deaf community, sign language is valued even if most people do not know it and some parents argue against cochlear implants for deaf infants who cannot consent to them. People diagnosed as being on the autism spectrum may argue against efforts to change them to be more like others. They argue instead for acceptance of neurodiversity and accommodation to different needs and goals. Some people diagnosed with a mental disorder argue that they are just different and don't necessarily conform. The biopsychosocial model of disease/disability is a holistic attempt by practitioners to address this.\n\nThe social model implies that practices such as eugenics are founded on social values and a prejudiced understanding of the potential and value of those labeled disabled. \"Over 200,000 disabled people were the first victims of the Holocaust.\"\n\nA 1986 article stated: \"It is important that we do not allow ourselves to be dismissed as if we all come under this one great metaphysical category 'the disabled'. The effect of this is a depersonalization, a sweeping dismissal of our individuality, and a denial of our right to be seen as people with our own uniqueness, rather than as the anonymous constituents of a category or group. These words that lump us all together -'the disabled', 'spina bifida', 'tetraplegic', 'muscular dystrophy’, - are nothing more than terminological rubbish bins into which all the important things about us as people get thrown away.\"\n\nThe social model of disability is based on a distinction between the terms \"impairment\" and \"disability.\" Impairment is used to refer to the actual attributes (or lack of attributes), the abnormality, of a person, whether in terms of limbs, organs or mechanisms, including psychological. Disability is used to refer to the restrictions caused by society when it does not give equivalent attention and accommodation to the needs of individuals with impairments.\n\nThe social model also relates to economics. It proposes that people can be disabled by a lack of resources to meet their needs. It addresses issues such as the under-estimation of the potential of people to contribute to society and add economic value to society, if given equal rights and equally suitable facilities and opportunities as others. Economic research on companies that attempt to accommodate disability in their workforce suggest they outperform competitors.\n\nIn Autumn 2001, the UK Office for National Statistics identified that approximately one fifth of the working age population was disabled - 7.1 million disabled people as opposed to 29.8 million able people - and in this analysis also provided insight into some of the reasons why disabled people were unwilling to enter the labour market, such as that the reduction in disability benefits in entering the labour market would not make it worthwhile to enter into employment. A three-pronged approach was suggested: \n\"incentives to work via the tax and benefit system, for example through the Disabled Person’s Tax Credit; helping people back into work, for example via the New Deal for Disabled People; and tackling discrimination in the workplace via anti-discrimination policy. Underpinning this are the Disability Discrimination Act (DDA) 1995 and the Disability Rights Commission.\"\n\nIn the United Kingdom, the Disability Discrimination Act defines disability using the medical model - disabled people are defined as people with certain conditions, or certain limitations on their ability to carry out \"normal day-to-day activities.\" But the requirement of employers and service providers to make \"reasonable adjustments\" to their policies or practices, or physical aspects of their premises, follows the social model. By making adjustments, employers and service providers are removing the barriers that disable - according to the social model, they are effectively removing the person's disability. In 2006, amendments to the act called for local authorities and others to actively promote disability equality. This enforcement came in the shape of the Disability Equality Duty in December 2006. In 2010, The Disability Discrimination Act (1995) was amalgamated into the Equality Act 2010 along with other pertinent discrimination legislation. It extends the law on discrimination to indirect discrimination. For example, if a carer of a person with a disability is discriminated against, this is now also unlawful. Since October 2010, when it came into effect, employers may not legally ask questions about illness or disability at interview for a job or for a referee to comment on such in a reference, except where there is a need to make reasonable adjustments for an interview to proceed. Following an offer of a job, an employer can lawfully ask such questions.\n\nIn the United States, the Americans with Disabilities Act of 1990 (ADA), revision of 2008 effective in January 2009, is a wide-ranging civil rights law that prohibits discrimination based on disability. It affords similar protections against discrimination to Americans with disabilities as the Civil Rights Act of 1964, which made discrimination based on race, religion, sex, national origin, and other characteristics illegal. Certain specific conditions are excluded, such as alcoholism and transsexualism.\n\nIn 2007, the European Court of Justice in the Chacon Navas v Eurest Colectividades SA court case, defined disability narrowly according to a medical definition that excluded temporary illness, when considering the Directive establishing a general framework for equal treatment in employment and occupation (Council Directive 2000/78/EC). The directive did not provide for any definition of disability, despite discourse in policy documents previously in the EU about endorsing the social model of disability. This allowed the Court of Justice to take a narrow medical definition.\n\n\n"}
{"id": "3689073", "url": "https://en.wikipedia.org/wiki?curid=3689073", "title": "Sociology of art", "text": "Sociology of art\n\nThe sociology of art is a subfield of sociology concerned with the social worlds of art and aesthetics.\n\nStudying the sociology of art throughout history is the study of the social history of art, how various societies contributed to the appearance of certain artists.\n\nIn her 1970 book \"Meaning and Expression: Toward a Sociology of Art\", Hanna Deinhard gives these defining features of a sociology of art: \"The point of departure of the sociology of art is the question: How is it possible that works of art, which always originate as products of human activity \"within\" a particular time and society and \"for\" a particular time, society, or function -- even though they are not necessarily produced as 'works of art' -- can live beyond their time and seem expressive and meaningful in completely different epochs and societies? On the other hand, how can the age and society that produced them be recognized in the works?\"\n\nRaymonde Moulin \"The French Art Market\", Rutgers University Press, 1987\n\n"}
{"id": "54953040", "url": "https://en.wikipedia.org/wiki?curid=54953040", "title": "The South Asia Inscriptions Database", "text": "The South Asia Inscriptions Database\n\nSiddham or the Asia Inscriptions Database is an open-access resource for the study of inscriptions from South, Central and South East Asia. Siddham was established by the European Research Council with start-up funding from the project . The first focus of Siddham is Sanskrit epigraphy, mainly of the fourth, fifth and sixth centuries CE, but the platform is designed to accommodate inscriptions from all periods. In South Asia alone, the estimated number of historic inscriptions is 90,000. In its next phases, Siddham will expand to include inscriptions in Tamil, Kannada, Prakrit, Tibetan, Burmese, Pyu and Mon. \n\nIn Sanskrit \"siddhaṃ\" means \"success, accomplished, perfected.\" It was also symbolism and substitution for an \"auspicious sign\" found in the oldest inscriptions of the South Asia. In some cases, siddham is not spelled out, but indicated with a sign such as \"Om\" or a \"srivasta\", and various scholars consider \"siddham\" in inscriptions to be equivalent to these signs.\n\nThis word, written out in characters (such as those shown in the Siddham logo) or represented by a symbol, often stands at the beginning of inscriptions in Indic languages. The term \"Siddham\" is also used as a short name for the Indian script known as siddhamātṛkā.\n\nThe records in Siddham have been prepared in EpiDoc, a tool for structured markup of epigraphic documents in TEI XML. \n\nWithin Siddham, each item is listed firstly as an object -- such as a pillar, sculpture, copper-plate, stone slab and so forth. Each object may carry one or more inscriptions, thus each inscription has been assigned a separate Siddham number. A good example is the Allahabad pillar -- a single object -- which carries many inscriptions, among them those of Aśoka, Samudragupta and Jahāngīr. The inscription of Samdragupta appears in Siddham as IN00001. All material generated for SIDDHAṂ is archived in Zenodo.\n\nThe further example illustrated here is from Salihundam, Gara Mandal, Srikakulam district, Andhra Pradesh, India, a Buddhist place located approximately at 18°20'7\"N 84°2'28\"E. At this site, a series of five votive inscriptions are engraved on the semi-circular threshold of a ruined shrine. In Siddham, the semi-circular stone will carry an object number and each votive record an independent inscription number. The photograph of the inscriptions is archived as Zenodo. http://doi.org/10.5281/zenodo.557032.\n\nTranslations of inscription texts into western languages appear separately in the community called SIDDHAṂ traductions in Zenodo. Each translation is numbered according to the inscription number assigned in Siddham.\n\nEpigraphic documentation involves mapping sites of key dynasties and their inscriptions, especially land-charters recording gifts of land. The mapping undertaken to date can be explored through these links: \n\n\n"}
{"id": "2663709", "url": "https://en.wikipedia.org/wiki?curid=2663709", "title": "Third-person effect", "text": "Third-person effect\n\nThe Third-person effect hypothesis predicts that people tend to perceive that mass media messages have a greater effect on others than on themselves, based on personal biases. The Third-person effect manifests itself through an individual’s overestimation of the effect of a mass communicated message on the generalized other, or an underestimation of the effect of a mass communicated message on themselves.\n\nThese types of perceptions stem from a self-motivated social desirability (not feeling influenced by mass messages promotes self-esteem), a social-distance corollary (choosing to dissociate oneself from the others who may be influenced) and a perceived exposure to a message (others choose to be influenced by persuasive communication). Other names for the effect are \"Third-person perception\" and \"Web Third-person effect\". From 2015 the effect named \"Web Third-person effect\" when it is verified in social media, media websites, blogs and in websites in general.\n\nSociologist W. Phillips Davison, who first articulated the third-person effect hypothesis in 1983, explains that the phenomenon first piqued his interest in 1949 or 1950 upon learning of a Japanese attempt during World War II to dissuade black U.S. soldiers from fighting at Iwo Jima using propaganda. As Davison recounts, the leaflets stressed that the Japanese did not have a quarrel with the black soldiers and that they should give up or desert. Although there was no indication that the leaflets had any effect on the soldiers, the incident preceded a substantial reshuffle among the officers and the unit was withdrawn the next day.\n\nSeveral years later while interviewing West German journalists to determine the influence of the press on foreign policy, Davison asked the journalists to estimate the influence their editorials had on readers. Although no evidence could be found to support their claims, Davison writes that a common response was, “The editorials have little effect on people like you and me, but the ordinary reader is likely to be influenced quite a lot.”\n\nIn both anecdotes, the parties that evaluated the impact of the communication estimated a larger media effect for others than on self. These and other experiences led Davison to articulate what he called the third-person effect hypothesis, which predicts:\n\nIn a case study conducted by Douglas McLeod et al. (1997), the third-person effect was analyzed via participants’ perceptions of being influenced by violent or misogynistic lyrics from rap music. The sample participants were divided up into three groups: one listened to violent rap music, another heard misogynistic rap music and the third group was the control. All lyrics heard were from actual, recorded songs. The study asked subjects to estimate the effects of listening to these types of lyrics on someone’s behaviors, knowledge and attitudes. They were also asked how these lyrics would affect themselves, students at their university, youth in New York or Los Angeles, and the average person. The study found that students found the rap lyrics to be least influential on themselves and more influential on youths in New York or Los Angeles. Simply put, people are more likely to assume everyone else is more easily influenced by messages than themselves. Furthermore, a recent study conducted by Nikos Antonopoulos et al. (2015), found characteristics of what users observe when visiting a media website as well as a prediction model. The influence that this information has over their opinion verifies the existence of Web Third-person effect (WTPE). With the use of an online survey (N = 9150) in all media websites (radio station, television station, portal, newspaper and email-social media) it was proved that the variables that have a greater impact either on others or our friends than ourselves are: The number of users being concurrently online on the same media website, the exact number of users having read each article on a media website as well as the number of users having shared a news article on Facebook, Twitter, or other social networks. Moreover, age is a significant factor that explains the findings and is important to the effect. Additionally, factors that affect the influence of the user generated messages on others than on oneself were found. Furthermore, the more credible the news is perceived to be and when there is not a particular mediated message the WTPE is absent confirming the existing theory.\n\nTo support the third-person effect hypothesis, Davison (1983) conducted four minor and informal surveys. Each survey asked between 25 and 35 participants to estimate the influence of persuasive communication on themselves and others. Participants estimated self-other effects for (1) a campaign theme on gubernatorial vote choice, (2) television advertising on children, (3) the results of early presidential primaries on vote choice, and (4) campaign messages on presidential vote choice. On average they estimated (1) other New York voters were more influenced by campaign themes than they were personally, (2) other children were more influenced by television advertising than they had been personally, (3) others were more influenced by the results of early presidential primaries than they were personally, and (4) others were more influenced by campaign advertisements than they were personally. Although the surveys were informal, they support the hypothesis.\n\nPrice and Tewksbury tested whether the third-person effect was a methodological artifact as a result of asking participants self-other questions in close proximity. Using a three-condition experiment in which they asked participants in the first condition self-only questions, participants in the second condition other-only questions, and participants in the third condition self and other questions, Price and Tewksbury’s results indicate consistent estimates of self and other estimates across conditions. These results, then, indicate the effect is not the result of a methodological artifact.\n\nAccording to Perloff (1999, 2009), two major factors facilitate the third-person effect: judgments of message desirability and perceived social distance (social distance corollary). In their meta-analysis of studies of third-person perception Sun, Pan, and Shen (2008) found that message desirability is the most important moderator of third-person perception. Third-person effects are particularly pronounced when the message is perceived as undesirable—that is, when people infer that “this message may not be so good for me” or “it’s not cool to admit you’re influenced by this media program.” In line with these predictions, people have been found to perceive content that is typically thought to be antisocial to have a larger impact on others than on themselves (e.g., television violence, pornography, antisocial rap music). Indeed, many researchers have found evidence that undesirable messages, such as violent and hateful messages, yield a greater third-person effect.\n\nOn the other hand, when messages are perceived as desirable, people are not so likely to exhibit a third-person effect. According to Perloff (2009), the first-person effect, or reversed third-person effect, is more common for desirable messages and seems to emerge when agreement with the message reflects positively on the self and to some degree when the message touches on topics that are congruent with the orientation of groups with which individuals identify. According to the self-enhancement view, if the third-person effect is driven by a desire to preserve self-esteem, people should be willing to acknowledge effects for communications that are regarded as socially desirable, healthy, or otherwise good for the self. Undergraduates perceived that others will be more influenced than themselves by cigarette ads but they will be more affected by anti-tobacco and drunk-driving PSAs. \nAnother factor that influences the magnitude of the third-person effect is perceived social distance between self and comparison others. In the “social distance corollary,” the disparity of self and other is increased as perceived distance between self and comparison others is increased. Although social distance is not a necessary condition for the third-person effect to occur, increasing the social distance makes the third-person effect larger. In their meta-analysis, Andsager and White (2007) concluded that “Research consistently finds that others who are anchored to self as a point of reference are perceived to be less influenced by persuasive messages than are others who are not defined and, therefore, not anchored to any point of reference at all” (p. 92).\n\nPerloff notes that the majority of third-person effect studies attribute the psychological underpinnings of the effect to either attribution theory or biased optimism.\n\nAttribution theory predicts that actors tend to attribute their actions to situational factors while observers tend to attribute the same actions to dispositional factors. For example, attribution theory predicts that a student who turns in a late assignment may explain to the professor that the tardiness is uncharacteristic and due to a situational factor like an unusual computer problem while the professor might believe the tardiness was due instead to a dispositional factor like the student’s laziness. In the context of the third-person effect hypothesis, then, attribution theory explains why a person may think that he or she understands the underlying persuasive aspects of the message while others’ dispositional flaws prevent them from perceiving those same aspects.\n\nBiased optimism predicts that people tend to judge themselves as less likely than others to experience negative consequences and, conversely, that people tend to judge themselves as more likely than others to experience positive events. In the context of the third-person effect hypothesis, biased optimism explains why people judge themselves as being less likely than others to be affected by persuasion.\n\nIn a critical review and synthesis of the third-person effect hypothesis, Perloff (1999) noted that of the 45 published articles that had tested the phenomenon by 1999, all had found support for the perceptual component of the hypothesis.\n\nOne year later, Paul, Salwen, and Dupagne conducted a meta-analysis of 32 empirical analyses that tested the perceptual component of the third-person effect hypothesis. Their results indicate the perceptual component of the third-person effect hypothesis received robust support (\"r\" = .50), especially compared to meta-analyses of other media effects theories.\n\nPaul, Salwen, and Dupagne (2000) also found three significant moderators of the perceptual component of the third-person effect hypothesis: (1) sampling – samples obtained from nonrandom samples yielded greater third-person effect differences than samples obtained from random samples; (2) respondent – samples obtained from student samples yielded greater third-person effect differences than samples obtained from non-student samples; and (3) message – different types of content (e.g., general media messages, pornography, television violence, commercial advertisements, political content, nonpolitical news, etc.) have differing effects on the size of the obtained third-person perceptions.\n\nMultiple studies have found support for the behavioral component of the third-person effect hypothesis. Possibly because Davison noted that censors seldom admit to have been adversely affected by the information they proscribe, scholars who have found support for the behavioral component have generally operationalized behavior as a willingness to censor content to stop the content from having the perceived negative persuasive impact on others.\n\nSpecifically, scholars have demonstrated that third-person perception predicts willingness to censor pornography, television violence, sexual and violent television in Singapore, cigarette, beer, liquor, and gambling advertising, rap music and the number of users being concurrently online on the same media website, the exact number of users having read each article on a media website as well as the number of users having shared a news article on Facebook, Twitter, or other social networks.\n\nScholars, however, have not found that third-person perception predicts willingness to censor news or political media content including censorship of press coverage of the O.J. Simpson trial, support for an independent commission to regulate political communication, or censorship or a Holocaust-denial advertisement.\n\nScholars have noted that in some situations, people don’t always estimate greater media effects for others than for themselves. Indeed, in certain situations people tend to estimate greater media effects on themselves than on others, and in other situations people tend to estimate similar media effects on self and others. These two phenomena are commonly known as first person and second person effects respectively.\n\nFirst person effects – the estimation of greater media effects on self than others – tends to happen in situations in which people judge it desirable to be influenced by the media message. Innes and Zeitz first documented this phenomenon in 1988 when they noticed that participants exposed to content with a violent message exhibited traditional third-person effects while those exposed to a public service announcement exhibited the reverse. They described this reverse effect, however, only as “something akin to a third person effect” (p. 461).\n\nSeveral years later, Cohen and Davis, who found that people tended to overestimate the effect of attack advertisements for disliked candidates on themselves than on others, coined the term “reverse third-person effect” (p. 687). The same year, Tiedge, Silverblatt, Havice, and Rosenfeld coined the term “first-person effect” to refer to the perceived effects of media on self as being more than on others.\n\nFinally, Gunther & Thorson, in a study that paved the way for extension of the third-person effect hypothesis, demonstrated empirically that the social desirability of the message tended to affect whether participants were likely to exhibit third- or first- person effects. Socially desirable messages, Gunther and Thorson argue, tend to produce first-person effects while messages that are not perceived as desirable to be influenced by tend to produce traditional third-person effects.\n\nOnly a handful of studies have, intentionally or unintentionally, examined the behavioral component of the first-person effect. Of these, only one has specifically examined a relationship between first-person perceptions and behavioral consequences. Day examined the relationship between first-person effects from socially desirable issue advertisements and the likelihood of voting for legislation supporting the issue. Day found a significant relationship between first-person perceptions of the advertisement and the reported likelihood of voting for the legislation.\n"}
{"id": "13718493", "url": "https://en.wikipedia.org/wiki?curid=13718493", "title": "Traditional transmission", "text": "Traditional transmission\n\nTraditional transmission (also called cultural transmission) is a design feature of language that the anthropologist Charles F. Hockett developed to distinguish the features of human language from those of animal communication. He discovered thirteen features that all human languages have. Animals might communicate with some of the thirteen basic design features of language but never with all of them. Traditional transmission is exemplified by the fact that language is learned in social groups. Although there is disagreement about how much linguistic capability humans are born with, it is known that the only way that humans learn language and refine its use as they grow is in social settings.\n"}
{"id": "51493767", "url": "https://en.wikipedia.org/wiki?curid=51493767", "title": "Transparency of media ownership in Europe", "text": "Transparency of media ownership in Europe\n\nTransparency of media ownership refers to the public availability of accurate, comprehensive and up-to-date information about media ownership structures. A legal regime guaranteeing transparency of media ownership makes possible for the public as well as for media authorities to find out who effectively owns, controls and influences the media as well as media influence on political parties or state bodies.\n\nTransparency of media ownership is an essential component of any democratic media system. Experts, European organisations and NGOs agree that transparency of media ownership is crucial for media pluralism and democracy as, for instance, it provides the knowledge to take steps to address media concentration and conflict of interests. Moreover, public knowledge of media owners' identities can prevent abuses of media power, such as corruption in the media system, opaque media privatisation, undue influences over the media, etc., and makes possible that such abuses are recognised, assessed, publicised, debated and prevented. Transparency also ensures that ordinary citizens can be informed about the identity, interests and influences behind contents and news they consume, and that media market can function on a fair basis, especially, for instance, for new entrants in the market. Moreover, transparency of media ownership facilitates the public knowledge on the media environment; makes possible a critical assessment of the contents produced and strengthens debate on the way the media system operates. The importance of transparency of media ownership for any democratic and pluralist society has been broadly recognised by the European Parliament, the European Commission's High-Level Group on Media Freedom and Pluralism and the Council of Europe. In the last years, there has been an unprecedented debate at the global level around company ownership transparency which has been addressed, for example, by the Open Government Partnership and by the G8 governments in a 2014 statement setting the principles on media ownership transparency. In 2016, following the so-called \"Panama Papers\" scandal, the lack of records held by the Panama-based legal firm Mossack Fonseca, transparency of company ownership gained momentum in the public debate.\n\nTo ensure that the public knows who effectively owns and influences the media, national legal frameworks should ensure the disclosure of at least the following essential basic information: name and contact details of the media outlets; constitutional documents; size of shareholdings over a given threshold; name and contact details of direct owners with a given percentage of shareholding; identity of the persons with indirect control or have a significant interest in a given media company; citizenship/residence status of individuals with at least a certain shareholding percentage; country of domicile of company with at least a given shareholding percentage. Importantly, to understand who really owns and controls a specific media outlet it is necessary to check who is beyond the official shareholdings and scrutinise indirect, controlling and beneficial ownership which refers on shares of a media company hold on behalf of another person.\n\nTo be meaningful and easily accessible by the citizens and national media authorities, this information should be updated, searchable, free and reusable.\n\nTransparency of media ownership remains difficult to fulfill in most of European countries. While some EU member States have legislation ensuring transparency of media ownership in compliance to the best international standards, such legislation is still lacking in many member States and in some cases national legislation allows for hidden or indirect media ownership. A recent 2015 resolution by the Parliamentary Assembly of the Council of Europe, notes with concern that media outlets are frequently owned and controlled in an opaque-manner. This is due either to the lack of national transparency provisions or to non-transparent indirect or hidden ownership schemes, often linked to political, economic or religious interests and affiliations.\n\nTransparency of media ownership corroborates some constitutional guarantees and individual rights which are strictly related to the inclusiveness and openness of the democratic process, in particular media pluralism and Freedom of Expression. Even if media ownership transparency is not directly addressed in key international human rights charters, transparency is a basic precondition for the effective exercise of freedom of expression and the right to obtain information enshrined in Article 19 of the International Covenant on Civil and Political Rights, Article 10 of the European Convention on Human Rights (ECHR), and Article 11.1 of the EU Charter of Fundamental Rights. Indeed, access to information is crucial for the good functioning of democratic societies as it enables citizens to make informed decisions and choices on social, political, economic issues affecting personal and collective life. Specifically, transparency of media ownership contributes to make the public to establish who provides the information on which to shape personal and collective choices as, for instance, knowledge of the identity and interests of the messenger can help individuals in appraising the information spread through the media.\n\nGuidelines and milestones on what media ownership transparency might entails can be found in non-binding Council of Europe documents, in particular on the \"Committee of Ministers' Recommendation R(94) 13 on Measures to Promote Media Transparency and Recommendation (2007)2\" on \"Media Pluralism and Diversity of Media Content\". According to this recommendations, to understand who and how effectively owns or control the media the public should be in the condition of accessing the following information:\nAnother non-binding document on media ownership transparency is a 2008 Resolution from the European Parliament which encourages the \"disclosure of ownership of all media outlets to help achieve greater transparency regarding the aims and background of the broadcasters and publishers\".\n\nAccording to experts and organisation advocating for media ownership transparency, such as Access-Info Europe, a human rights NGO dedicated to promoting the right to access to information in Europe, to understand who and how effectively owns or control the media, it is crucial that information provided to comprehend and assess media ownership structures are regularly updated, consistent and searchable. Also, citizens should be able to get information on all types of media actors in a given countries, whether print, broadcast, or online, foreign or domestic.\n\nIn Europe, transparency of media ownership is infrequently addressed directly in domestic constitutions, and even when this happens, as in the case of Italy, Romania or Turkey, constitutional provisions do not impose a specific positive obligation on the state to ensure that citizens have access to information on media ownership. The lack of \"ad hoc\" legal provisions on media ownership transparency is partially explained with the fact that often the existing laws have been established with the aim of fulfilling other regulatory objectives, such as providing information to media regulators or for company law purposes. In many European countries, freedom of information legislation provides the basis for requesting information from competent agencies and public bodies. As a consequence, often media ownership transparency aimed at fulfilling the objective of primarily informing the public on media ownership structure is therefore often a byproduct of other measures.\n\nWhen assessing the state of media ownership transparency, five dimensions should be taken into account to establish who and how controls the media in a given country:\n\n\nOperationally many options are possible to guarantee the disclosure of information on media ownership. A simple approach is to call upon media outlets to publish relevant ownership information on an accessible website displayed or linked in the organisation's publications, transmissions or website. Alternatively, or in addition, an accessible, easy-to-navigate and searchable online database on transparency of media ownership can be developed by an independent body. In both cases, to be effective and functional, databases should be regularly updated. Also, to make possible comparisons across countries, a systematic approach to collect, record and share information should be set up, connections and interoperability among national databases should be pursued and shared standards for exchanging data on transparency of media ownership should be developed.\n\nTransparency of media ownership is deeply interrelated with the concepts of media pluralism and media concentration and is an essential component of government obligations to guarantee a diverse and plural media environment.\n\nSpecifically, media ownership transparency is crucial for promoting media pluralism, a principle set forth in the European Convention on Human Rights (ECHR) which entails a positive obligation for the state to \"put in place an appropriate legislative and administrative framework to guarantee effective pluralism\". One of the way for guaranteeing media pluralism is to ensure a wide diversity of media ownership, which is a necessary but not sufficient condition for pluralism. Media ownership is also important in terms of pluralism as it might affects media outputs and contents while transparency empowers readers to detect and appraise owners influences on the media and its contents. The European Commission's study on Indicators for Media Pluralism (2009) recognises transparency of media ownership and/or control as a key indicators of media pluralism. Also, media ownership transparency is essential for preventing concentration of media power which can unduly influence public opinion and the political debate. Precisely, transparency of media ownership is a precondition for assessing levels of concentration or other dimensions of diversity in a given media system. Indeed, if readers don't know who the real owners of media companies are, it is difficult to envisage measures to address media concentrations as well as conflict of interests.\n\nThe need to collect and make available to the public crucial information on media ownership, in particular beneficial ownership which in this context refers on shares of a media company held on behalf of another person, is frequently debated in Europe, but there are no agreed standards or binding commitments. In June 2013, governments of the G8 Group adopted the \"Lough Erne Declaration\" which included a commitment to make transparent the beneficial ownership of companies recognising the need to make this information available to relevant authorities to prevent misuse of companies. The declaration was followed by a November 2014 statement by G20 leaders setting the principles on media ownership transparency. In April 2016, following the lack of records held by the Panama-based legal firm Mossack Fonseca (the \"Panama Papers\"), the UK, Germany, France, Italy and Spain reached an agreement for easing the automatic exchange of information of beneficial ownership of companies and trusts. The five countries concerned also urged the remaining G20 countries calling for progress towards a global system for exchanging such information, to be developed, for instance, by the OECD. Even if these commitments are not specifically related to the media sector, they are important steps towards the disclosure of beneficial owners of companies, including the media ones. At the European Union level, the European Commission is working to improve the beneficial ownership provisions included in the 4th Anti-Money Laundering Directive, adopted in 2015 and currently in the process of being transposed by EU Member States into national law.\n\nThere is a group of three constitutional provisions that are relevant when it comes to transparency of media ownership:\nConstitutional provisions recognising freedom of speech and access to information are widely included in national constitutions across Europe, and, even if they are general in nature and scope, they potentially lay the ground for media ownership transparency legislation. For instance, this is the case of Norway that shaped the Norwegian Media Ownership Act on the basis of the obligations enshrined in the constitution. In addition, constitutional provisions, which vary from country to country, do not ensure transparency of media ownership as this depends on how broadly they are construed and then implemented. This is particular relevant when the constitution does not impose a positive obligation upon the state, but simply provides the option of disclosing media ownership transparency data. Constitutions, in some cases, are more focused on disclosure of information to the government or other public body than disclosure directly to the citizens. In this case, the right to access information becomes highly relevant as it is the ground for accessing media ownership data.\n\nThere is a noticeable variation across Europe concerning the extent and the type of the media sectors involved (i.e. the broadcasting sector; print and online sectors) in the provisions regulating media ownership disclosure to public bodies, which in many cases is a dedicated media authority. A crucial issue for media ownership transparency is whether and how the information provided to public authorities is comprehensive, meaningful, updated and easily accessible to the wider public.\n\nGiven the variability of such provisions in Europe, and given the fact that in many countries the required data disclosure is not conceived for directly addressing media transparency, the information provided are in many cases inadequate and does not serve the objective of effectively assessing whether domestic ownership limits or prohibitions are being respected. More specifically, there are at least five reasons explaining why effective media ownership transparency is limited despite the existence of specific legislation.\n\nFirst, European countries legislation is not homogeneous in requiring disclosure from all three media sectors (i.e. broadcasting; print and online). This, also, creates a patchwork of databases containing different type of information, making data comparison complicated.\n\nSecond, in Europe disclosure is often made to public media authorities, but in some cases disclosure is required to a specific ministry (such as the Ministry of Culture in Bulgaria, or the Ministry of Justice in Azerbaijan). This can be problematic because public bodies can have discretion in authorising media services, so any links between media authorities and executive branches should be carefully reviewed to ensure their independence from political power.\n\nThird, disclosure legislation varies extensively across Europe also in terms of the type of information required to be released (e.g. details of shareholders and size of their holdings; interests of affiliated individuals; indirect interests; interests in other media companies; sources of revenues; etc.), including different thresholds and application to different media sectors.\n\nForth, even if media ownership transparency information released to public authorities can in principle be accessed also by the public through freedom of information legislation, in practice, however, in many cases freedom of information is not fully implemented or reliance on it may be perceived by citizens to be excessively complex and even confrontational.\n\nChecks on the data provided and on its regular updating and accuracy, as well as sanctions for failure in reporting or updating it, can help improve the quality of recorded data, which are crucial for assessing media ownership transparency. There is great variability on these sanctions across Europe, but what is common is that sanctions are rarely implemented for a series of reasons: lack of sufficient resources; lack of expertise in the authorities that should check; an unwillingness to check organisations that might have powerful political or commercial influences, etc.\n\nAlso in terms of public accessibility there are considerable variations across Europe: for instance, countries like Norway and Germany developed good practices in terms of online, updated searchable databases. In particular, in Germany the competent media authorities release annual lists with data on national media outlets, including the participating interests, and publish such information on the website of the KEK, the independent Commission on Concentration of the Media. The KEK also publishes reports that are distributed to media, politicians, universities, libraries, etc. In turn, the public use of available databases depends not only on their effective accessibility, but also on factors such as public awareness and confidence in starting and handling requests.\n\nDisclosure of media ownership transparency information directly to the public can be implemented through public registers or by posting data on a media organisation's website. In Europe, disclosure directly to the citizens is often determined not for the sake of controlling or avoiding media concentration, but rather for consumer protection purposes, resulting in the disclosure of information that are badly suited for revealing the true state of media ownership. In addition, as in the case of disclosure to public authorities, some problems impede the full implementation of the existing rules, in particular, lack of enforcement, inadequate oversight and minimal requirements.\n\nOverall, the different national regimes in place in Europe, do not properly perform the function of making clear to the citizens relevant data for meeting citizens' interests in media ownership transparency.\n\nNon media-related specific transparency rules can be found in other legislative acts, such as domestic and EU competition rules, that can indirectly strengthen media ownership transparency, or company laws that require the disclosure of shareholdings interests in private companies. However, while these rules can provide useful insights into company ownership, usually they do not provide real information on who actually owns and controls a media company, in particular beneficial ownership). This is because the primary objective of rules that are not media-specific is not media ownership transparency.\n\nGenerally, these kind of provisions require to disclose data on the name and nationality of the owner's; address; shareholdings; founding capital, etc., but the exact rules, percentages and thresholds vary from country to country. Failure to provide the requested information generally leads to fines and sanctions, and invalidation of the company registration.\n\nDisclosure rules vary remarkably from country to country, and within each country for different types of companies. Consequently, the available data is both fragmented and incoherent, often technical in nature, thus making difficult for the public to understand and for experts to compare data across countries.\n\nSeveral organisations provide valuable information on media ownership to the public. For example, in Italy, the Communications Regulatory Authority (AGCOM) publishes annual reports, which are presented to the parliament, explaining market shares and the main stakeholders in the media market. In the Netherlands, the Commissariat for the Media (CvdM) publishes online an annual report with information on trends and developments in the media market, including data on ownership, market shares, media pluralism.\n\nAt the European Union level, the MAVISE database powered by the European Audiovisual Observatory provides information on television companies operating in Europe with the aim of enhancing transparency in the television sector.\n\nIn many European countries, academics, NGOs and civil society carry out research and mapping of media ownership, and publish \"ad hoc\" publications on the topic. For instance, in Spain the platform \"Portal de la Comunicación\" run by the University of Barcelona effectively monitors the media providing data and statistics to the public. Similarly, in Romania the Mediaindex, managed by the Centre for Independent Journalism, provides useful information on media ownership.\n\nThere are also cases of media company voluntarily providing information on their financial sources and ownership structure directly to the public through their websites. This is the case, for instance, of Il Fatto Quotidiano newspaper in Italy, the Guardian in the UK, and DV in Iceland.\n\nFinally, professional and trade organisations, such as the Norwegian Press Organisations or the Swiss Press Council, establish self-regulation provisions, codes of ethics and guidelines calling for ownership transparency. However, they usually do not provide sufficient stimulus to reveal information that can be politically and commercially sensitive.\n\nOverall, the information provided through these kind of sources and organisations, is not enough systematic or detailed for providing an adequate account of media ownership transparency.\n\nAt the EU level, the legislative competence concerning media ownership transparency is controversial. However, the European Commission has promoted a number of initiatives to improve citizens' awareness of media pluralism, such as the Media Pluralism Monitor, a monitoring tool for assessing risks and threats for media pluralism in the EU member states on the basis of a set of legal, economic and socio-cultural indicators. According to the Media Pluralism Monitor the lack of media ownership transparency is identified as a risk for media plurality. The European Commission's High Level Group on media freedom and pluralism identified “the lack of media ownership transparency” as a key recommendation in its 2013 report. Then a 2014 European Council meeting stated \"transparency of media ownership and of funding sources (be) essential with a view to guaranteeing media freedom and pluralism\" in guidelines issued in a 2014 Foreign Affairs Council meeting. Under the section on actions, the guidelines state that “d) Support actions by third countries to improve transparency of media ownership, the adoption of measures against media concentration and fair and transparent licencing allocation as the associated risks have grown more acute in the digital age”.\n\n\n\n"}
{"id": "41815078", "url": "https://en.wikipedia.org/wiki?curid=41815078", "title": "Transparency report", "text": "Transparency report\n\nA transparency report is a statement issued on a regular basis by a company, disclosing a variety of statistics related to requests for user data, records, or content. Transparency reports generally disclose how frequently and under what authority governments have requested or demanded data or records over a certain period of time. This form of corporate transparency allows the public to discern what private information governments have gained access to through search warrants and court subpoenas, among other methods. Some transparency reports describe how often, as a result of government action or under copyright provisions, content was removed. Disclosing a transparency report also helps people to know about the appropriate scope and authority of content regulation for online discussions.\nGoogle first launched a transparency report in 2010, with Twitter following in 2012. Additional companies began releasing transparency reports as during the aftermath of the global surveillance disclosures beginning in 2013, and the number of companies issuing them has increased rapidly ever since. Transparency reports are issued today by a variety of technology and communications companies, including Google, Microsoft, Verizon, AT&T, Twitter, Apple, Dropbox, Facebook, Yahoo and CloudFlare. Several companies and advocacy groups have lobbied the U.S. government to allow the number of secret data requests (requests which include a gag orders - including National Security Letters) to be described within ranges in the report. \n\nGoogle's latest \"(10th)\" transparency report indicates that the government demands for data are increasing in recent years.This report shows demands from government in the first six months of 2014, and the firm said that it includes demands made under the US Foreign Intelligence, Surveillance Act (FISA) and through National Security Letters (NSLs).\n\"FISA and NSL demands have increased by 15 percent during the six months, according to the firm, and by 150 percent over the 10 reports and the five year reporting period. That's globally. In the US the figures for the same period are 19 percent and 250 percent.\"\nGoogle legal director \"Richard Salgado\" accepted that the government has to fight crime and deal with threats, but the opposition of data demands need to be considered as well.\n\"This increase in government demands comes against a backdrop of ongoing revelations about government surveillance programs. Despite these revelations, we have seen some countries expand their surveillance authorities in an attempt to reach service providers outside their borders,\" he said.\n\"Governments have a legitimate and important role in fighting crime and investigating national security threats. To maintain public confidence in both government and technology, we need legislative reform that ensures surveillance powers are transparent, reasonably scoped by law, and subject to independent oversight.\"\nThe report shows that the US makes the most demands for Google users' data, and Google said that it made 12,539 requests that affected some 22,000 accounts. It added that it provided data in 84 percent of cases.\n\nIn the UK it said there were 1,535 requests covering 1,991 users or accounts, and Google provided data for 72 percent of the requests.\n\nThe latest Yahoo transparency report was released on 25 September 2014. The report states that 30,511 users were affected by 18,594 government data requests.,whereas 57,324 accounts were affected by 29,470 government requests. However, both of these figures do not include those secret requests sent by the FISA court. During the last six month from \"July 1, 2013, to December 31, 2013\", it received between 0 and 1998 FISA requests for user data, affecting up to 54,997 users (including national security letters). Comparing to the first sixth month from \"January 1, 2013 to June 30, 2013\", 32,997 accounts was affected. As we can see from the figures, although the total number of data request drop, the number of data request approved from the FISA court have increased significantly.\nOverall, 41 percent of accounts affected by government data requests came from requests made by the U.S. government.\n\nTransparency reports may be published for a variety of purposes. One purpose could be to clarify how much information governments ask for, how such requests are evaluated, and how the receiving entity chose to respond. This information may lead consumers to the conclusion that the report's publisher is more trustworthy.\n\nHowever, there is some debate about what transparency reports really reveal. Some critics argue that mere quantities of requests may mislead consumers, since most entities have little control over the number of requests they receive, the breadth of the requests they receive, or even the number of requests they ultimately comply with.\n\nCompanies such as Google, Microsoft, Yahoo, Facebook, and Twitter all release transparency reports, all of which list the type and number of government data requests each company receives. these reports include exact numbers and shed a bright light on government activity. The U.S. government will not, however, permit companies to report exact numbers for national security requests or the number of requests that came under the Foreign Intelligence Surveillance (FISA) Section 702, Patriot Act Section 215, or national security letters.\nInstead, they have to aggregate the numbers or provide a range. And that’s even if the government permits a company to publish that data. Google may publish national security letter information, but not FISA information. Facebook may publish FISA information, but it must lump such data in with NSL information. As a result, consumers cannot see the true figure for total government data requests.\nCritics of this policy, such as the Electronic Frontier Foundation, argue that there is no clear national security justification for blocking entities from releasing this information.\n\nIn June 2013, Google asked the Department of Justice for permission to disclose details about the number of FISA requests it receives. As a result, Microsoft, Yahoo, and Facebook followed suit immediately. However, the Department of Justice refused those requests, and they only provide the companies with a heavily redacted version of their arguments.\nHere's what Google legal director Richard Salgado had to say about FISA requests:\n\"We want to go even further. We believe it’s your right to know what kinds of requests and how many each government is making of us and other companies. However, the U.S. Department of Justice contends that U.S. law does not allow us to share information about some national security requests that we might receive. Specifically, the U.S. government argues that we cannot share information about the requests we receive (if any) under the Foreign Intelligence Surveillance Act. But you deserve to know.\"\n\n\"“Our ability to speak has been restricted by laws that prohibit and even criminalize a service provider like us from disclosing the exact number of national security letters ('NSLs') and Foreign Intelligence Surveillance Act ('FISA') court orders received - even if that number is zero.”\"avian network's veep for legal Ben Lee has blogged.\n\nOn 7 October 2014, Twitter announce that there will be a lawsuit against the United States government for violating its First Amendment right to freedom of speech. The Transparency Report which would reveal how many national security letters (NSLs) and Foreign Intelligence Surveillance Act (FISA) orders Twitter receives. They provided a draft of the transparency report to the Department of Justice and discussed it for months. Twitter was still unable to get the permission for allowing them to publish even a redacted version of the report from the government.\nThe response form FBI for its stance is that the information Twitter wants to publish \"is classified and cannot be publicly released\", they also said according to the framework provided on 27 January 2014, Twitter is only permitted to qualify its description of the total number of accounts affected by all national security legal process it has received but it cannot quantify that description with specific detail that goes well beyond what is allowed under the 27th Jan 2014 framework and that discloses properly classified information.\"\n\nThe United States government announced on 30 August 2013 that a transparency report which is in its own form will be released. Director of National Intelligence James Clapper announced the change on his office's Tumblr blog. He said that the decision will come naturally after President Barack Obama ordered the declassification of as much intelligence information as possible. Total numbers for national security letters, Foreign Intelligence Surveillance Act (FISA) business records requests, FISA one register/trap and trace requests will be stated in the transparency report. Beside that, the report will also include the number of targets being investigated in each of these requests. The number will reflect the 12 months prior to the date published.\nThe inspiration of the report comes from the recent surveillance program leaks from former NSA-contractor Edward Snowden, according to an anonymous source speaking with the \"Washington Post\".\nGoogle, Twitter,and Facebook all release their own forms of transparency report, however they are not allowed to release this sort of information in their report.\n\n\n"}
{"id": "286347", "url": "https://en.wikipedia.org/wiki?curid=286347", "title": "Turkology", "text": "Turkology\n\nTurkology (or Turcology) is a complex of humanities sciences studying languages, history, literature, folklore, culture, and ethnology of people speaking Turkic languages and Turkic peoples in chronological and comparative context. This includes ethnic groups from the Sakha in East Siberia to the Balkan Turks and Gagauz in Moldova.\n\nEthnological information on Turkic tribes for the first time was systemized by the 11th-century Turkic philologist Mahmud al-Kashgari in the \"Dīwān ul-Lughat it-Turk\" (Dictionary of Turkic language). Multi-lingual dictionaries were compiled from the late 13th century for the practical application of participants in international trade and political life: Kipchak (Cuman)-Persian-Latin-German \"Codex Cumanicus\", \"Armenian-Kipchak\", and \"Russian-Kipchak\" dictionaries. By the Middle Ages the Turkology was centred around Byzantine/Greek historians, ambassadors and travelers, and geographers. In the 15th-17th centuries the main subject of Turkology was the study of the Ottoman Empire and the Turkish language, and the Turkic languages of Eastern Europe and Western Asia. In 1533 a first hand-written primer appeared, and by 1612 a printed grammar by Jerome Megizer was published, followed by F. Mesgnien-Meninski's 4-volume \"Thesaurus Linguarum Orientalium\" published in 1680.\n\nP. S. Pallas initiated a more scientific approach to Turkology with his \"Comparative dictionaries of all languages and dialects\" (1787) which included lexical materials from Tatar, Mishar, Nogai, Bashkir, and other Türkic languages. In the 19th century, Turkology was further developed by M. A. Kazembek's \"Grammar of the Turkish-Tatar language\" (1839), O. N. Betlingk \"Grammar of the Yakut language\" (1851). A major achievement was the deciphering at the end of the 19th century of the Early Middle Age Orkhon inscriptions by V. Thomsen and W. W. Radloff (1895). By the end of the 19th century, Turkology developed into a complex discipline that included linguistics, history, ethnology, archeology, arts and literature. In the 20th century the Turkology complex included physical anthropology, numismatics, genetics, ancient Turkic alphabetic scripts, typology, genesis, and etymology, onomastics and toponymy. The appearance of \"Türkische Bibliothek\" (1905–27) inaugurated specialised periodicals, followed by \"Mitteilungen zur Osmanischen Geschichte\" (1921–26). Scientific developments allowed calibrated dating, dendrochronology, metallurgy, chemistry, textile, and other specialized disciplines which contributed to the development of the Turkological studies. Deeper study of the ancient sources allowed better understanding of economical, social, mythological and cultural forces of the sedentary and nomadic societies. Linguistic studies uncovered pre-literate symbioses and mutual influences between different peoples.\n\nOn 9 August 1944 the Central Committee VKP(b), the ruling party of the USSR, published an edict prohibiting \"ancientization\" of Turkic history. The edict was followed by a consecutive wave of mass arrests, imprisoning and killing of the intelligentsia, massive creation of replacement \"scientists\", and re-writing of history pages on an industrial scale. Combined with the concurrent wholesale deportation of indigenous populations to remote areas in Middle Asia and Siberia, the wipe-out of the science was nearly complete, and the impact of the action subsided only partially in the newly independent countries after the collapse of the USSR. In the two decades after the Bolshevik's assuming power, the tradition of Turkological studies in Russia and dependent countries was practically wiped out.\n\nOn the other hand, this edict brought unintended benefits to Turkology. One was the nearly immediate linguistic development of an alternate lexicon which replaced the nouns and adjectives containing the word \"Türk\" by a wealth of euphemisms: \"nomads, Siberians, Paleosiberians, Middle Asians, Scythians, Altaians, Tuvians\", etc. that filled scientific publications. The other was \"writing into a drawer\", when results of the years of fruitful work were written down for future publication. When the bonds relaxed, the publications exploded. Another was a flight of scientists from European Russia into remote areas, which brought first class scientists to many intellectually starved outlying areas of Middle Asia. Another one was connected with the statewide efforts to re-invent the history, when a wealth of Turkological facts were found in the process of search for \"correct\" history. And another one was a built-up of the public interest for the forbidden subjects, that resulted that no print size could satisfy the demand. L.N.Gumilev and O.Suleimenov inflamed a surge in the new generation of Turkology scholars.\n\nWith the physical culling of the scholars from the society, concurrently was also organized a total extermination of all their published and unpublished works, their books were removed from the libraries and destroyed from private collections by intimidated population, articles and publications were culled, published photographs were retouched, private photographs were destroyed, published scientific references were erased, or publications with undesired references were destroyed. Very few of the early 20th century expedition diaries, ethnographical notes, reports and drafts for publications were ever recovered.\n\n\n\nA selection of English-language periodicals studying Turkology\n\n\n"}
{"id": "9715522", "url": "https://en.wikipedia.org/wiki?curid=9715522", "title": "Turn construction unit", "text": "Turn construction unit\n\nA turn construction unit (TCU) is the fundamental segment of speech in a conversation, as analyzed in conversation analysis.\n\nThe idea was introduced in (Sacks, Schegloff, & Jefferson 1974) and is meant to describe pieces of conversation which may comprise an entire turn. The end of a TCU, called a \"transition relevance place\" (TRP), marks a point where the turn may go to another speaker, or the present speaker may continue with another TCU.\n\nA Turn Construction Unit (TCU) is a building component of a turn in a conversation. It is a unit of conversation that completes a communicative act.\n\nThere are four types of TCU categorized by the roles they play in the utterance:\n\n1. Lexical TCU: e.g. \"Yes\", \"There\"\n2. Phrasal TCU: e.g. \"In the basket\", \"out of here\"\n3. Clausal TCU: e.g. \"When I am free\", \"If I got the job\"\n4. Sentential TCU: e.g. \"I am working on my thesis\", \"He has got my car\"\n\nA general rule to identify a TCU would be to look for a possible completion in an ongoing utterance. There are three criteria to determine what constitutes a TCU:\n1. Intonationally Complete: This means the utterance is at a possible point of completion with the hint of a falling tone, signaling the possible ending of the utterance.\n2. Grammatically Complete: This means the utterance is at a possible point of completion with a hint of its syntactic completeness, i.e. it signals the end of a sentence in terms of its grammatical structure.\n3. Pragmatically Complete: This means the utterance is seen to have possibly accomplished its purpose in response to the situation during a conversation. For example, the utterance \"She is really\" can be seen as pragmatically complete in response to the exclamation, \"That girl is really pretty!\", in the sense that it functions as an agreement to the previous comment.\n\nScholars in the field of conversation analysis have debated over the relative significance of the above three criteria as signifiers of the end of an utterance. There are, however, no conclusive answer to the discussion, and one can classify a TCU as such when observing either one (or more) of the above features.\n\nTransition Relevance Place (or TRP) is a point of possible completion (or potential end) of an utterance (hence a TCU) where speaker change is a possible next action.\n\nSacks H, Schegloff E A, Jefferson G. \"A simplest systematics for the organization of turn-taking for conversation.\" \"Language\" 50 (1974) pp. 696–735\n\n"}
{"id": "4444344", "url": "https://en.wikipedia.org/wiki?curid=4444344", "title": "Vignette (literature)", "text": "Vignette (literature)\n\nIn a novel, theatrical script, screenplay, sketch stories, and poetry, a vignette (, ) is a short impressionistic scene that focuses on one moment or character and gives a trenchant impression about that character, an idea, setting, and/or object. It is a short, descriptive passage, more about evoking meaning through imagery than about plot.\n\nA blog or web series can also provide a form of vignette or be presented as a series of vignettes. An example of this is the critically acclaimed web series \"High Maintenance\", which presents a different set of characters in each episode, focusing intensely on their specific traits, ideas, and worlds.\n\nVignettes are more commonly used and have been particularly influential in the development of the contemporary notions of a scene as shown in postmodern theater, film and television, where less emphasis is placed on adhering to the conventions of traditional structure and story development. It is also a part of something bigger than itself: for example, a vignette about a house belonging to a collection of vignettes or a whole story, such as \"The House On Mango Street\", by Sandra Cisneros.\n\nThe word \"vignette\" means \"little vine\" in French, and the name of the literary form comes from the drawings of little vines that nineteenth-century printers used to decorate the title pages and beginnings of chapters.\n\n"}
{"id": "37469226", "url": "https://en.wikipedia.org/wiki?curid=37469226", "title": "Waddell's chronology", "text": "Waddell's chronology\n\nWaddell's chronology or Waddell's king list is an Ancient Near Eastern chronology developed by the British Laurence Waddell in his book, \"\", published in 1930.\n\nWaddell's correllations have not been generally accepted or well regarded, in part due to his use of the word Aryan. Conventional lists separate Sargon from Menes by around five hundred years. Commenting on this and other works, the \"Dictionary of National Biography\" says \"These works, containing much painstaking research and impressive to many, did not win the approval of experts.\"\n\nWaddell's primary chronology was compiled from various Sumerian king lists, Egyptian list of pharaohs, the Bhagavata Purana, Mahabharata, Rigveda and numerous Indus Valley Civilization seals and other monuments and relics and sources, some of which he had deciphered himself. It was entitled \"Dated Chronological List of Sumerian or Early Aryan Kings from the Rise of Civilization to the Kassi Dynasty\" and documented an alleged list of world emperors as follows:\n"}
{"id": "4145437", "url": "https://en.wikipedia.org/wiki?curid=4145437", "title": "Year zero", "text": "Year zero\n\nYear zero does not exist in the anno Domini system usually used to number years in the Gregorian calendar and in its predecessor, the Julian calendar. In this system, the year is followed by . However, there is a year zero in astronomical year numbering (where it coincides with the Julian year ) and in ISO 8601:2004 (where it coincides with the Gregorian year ) as well as in all Buddhist and Hindu calendars.\n\nThe \"Anno Domini\" era was introduced in 525 by Scythian monk Dionysius Exiguus (c. 470–c. 544), who used it to identify the years on his Easter table. He introduced the new era to avoid using the \"Diocletian era\", based on the accession of Roman Emperor Diocletian, as he did not wish to continue the memory of a persecutor of Christians. In the preface to his Easter table, Dionysius stated that the \"present year\" was \"the consulship of Probus Junior [Flavius Anicius Probus Iunior]\" which was also 525 years \"since the incarnation of our Lord Jesus Christ\". How he arrived at that number is unknown.\n\nDionysius did not use AD years to date any historical event. This began with the English cleric Bede (c. 672–735), who used AD years in his \"Historia ecclesiastica gentis Anglorum\" (731), popularizing the era. Bede also used a term similar to the English before Christ once, but that practice did not catch on until very much later. Bede did not sequentially number days of the month, weeks of the year, or months of the year. However, he did number many of the days of the week using a counting origin of one in Ecclesiastical Latin. Previous Christian histories used \"anno mundi\" (\"in the year of the world\") beginning on the first day of creation, or \"anno Adami\" (\"in the year of Adam\") beginning at the creation of Adam five days later (the sixth day of creation according to the Genesis creation narrative), used by Africanus, or \"anno Abrahami\" (\"in the year of Abraham\") beginning 3,412 years after Creation according to the Septuagint, used by Eusebius of Caesarea, all of which assigned \"one\" to the year beginning at Creation, or the creation of Adam, or the birth of Abraham, respectively. Bede continued this earlier tradition relative to the AD era.\n\nIn chapter II of book I of \"Ecclesiastical history\", Bede stated that Julius Caesar invaded Britain \"in the year 693 after the building of Rome, but the sixtieth year before the incarnation of our Lord\", while stating in chapter III, \"in the year of Rome 798, Claudius\" also invaded Britain and \"within a very few days … concluded the war in … the fortysixth [year] from the incarnation of our Lord\". Although both dates are wrong, they are sufficient to conclude that Bede did not include a year zero between BC and AD: 798 − 693 + 1 (because the years are inclusive) = 106, but 60 + 46 = 106, which leaves no room for a year zero. The modern English term \"before Christ\" (BC) is only a rough equivalent, \"not\" a direct translation, of Bede's Latin phrase \"ante incarnationis dominicae tempus\" (\"before the time of the lord's incarnation\"), which was itself never abbreviated. Bede's singular use of 'BC' continued to be used sporadically throughout the Middle Ages.\n\nNeither the concept nor a symbol for zero existed in the system of Roman numerals. The Babylonian system of the BC era had used the idea of \"nothingness\" without considering it a number, and the Romans enumerated in much the same way. Wherever a modern zero would have been used, Bede and Dionysius Exiguus did use Latin number words, or the word \"nulla\" (meaning \"nothing\") alongside Roman numerals. Zero was invented in India in the sixth century, and was either transferred or reinvented by the Arabs by about the eighth century. The Arabic numeral for zero (0) did not enter Europe until the thirteenth century. Even then, it was known only to very few, and only entered widespread use in Europe by the seventeenth century.\n\nThe \"anno Domini\" nomenclature was not widely used in Western Europe until the 9th century, and the to historical year was not uniform throughout Western Europe until 1752. The first extensive use (hundreds of times) of 'BC' occurred in \"Fasciculus Temporum\" by Werner Rolevinck in 1474, alongside years of the world (\"anno mundi\"). The terms \"anno Domini\", \"Dionysian era\", \"Christian era\", \"vulgar era\", and \"common era\" were used interchangeably between the Renaissance and the 19th century, at least in Latin. But \"vulgar era\" was suppressed in English at the beginning of the 20th century after \"vulgar\" acquired the meaning of \"offensively coarse\", replacing its original meaning of \"common\" or \"ordinary\". Consequently, historians regard all these eras as equal.\n\nHistorians have never included a year zero. This means that between, for example, and , there are 999 years: 500 years BC, and 499 years AD preceding 500. In common usage \"anno Domini\" 1 is preceded by the year 1 BC, without an intervening year zero. Neither the choice of calendar system (whether Julian or Gregorian) nor the era (\"Anno Domini\" or Common Era) determines whether a year zero will be used. If writers do not use the convention of their group (historians or astronomers), they must explicitly state whether they include a year 0 in their count of years, otherwise their historical dates will be misunderstood.\n\nIn astronomy, for the year AD 1 and later it is common to assign the same numbers as the Anno Domini notation, which in turn is numerically equivalent to the Common Era notation. But the discontinuity between 1 AD and 1 BC makes it cumbersome to compare ancient and modern dates. So the year before 1 AD is designated 0, the year before 0 is −1, and so on.\n\nThe letters \"AD\", \"BC\", \"CE, or \"BCE\" are omitted. So 1 BC in historical notation is equivalent to 0 in astronomical notation, 2 BC is equivalent to −1, etc. Sometimes positive years are preceded by the + sign. This year numbering notation was introduced by the astronomer Jacques Cassini in 1740.\n\nIn 1627, the German astronomer Johannes Kepler first used an astronomical year which was to become year zero in his \"Rudolphine Tables\". He labeled the year \"Christi\" and inserted it between years labeled \"Ante Christum\" (BC) and \"Post Christum\" (AD) on the mean motion pages of the Sun, Moon, and planets. Then in 1702 the French astronomer Philippe de la Hire used a year he labeled at the end of years labeled \"ante Christum\" (BC), immediately before years labeled \"post Christum\" (AD) on the mean motion pages in his \"Tabulæ Astronomicæ\", thus adding the designation \"0\" to Kepler's \"Christi\". Finally, in 1740 the French astronomer Jacques Cassini , who is traditionally credited with the invention of year zero, completed the transition in his \"Tables astronomiques\", simply labeling this year \"0\", which he placed at the end of years labeled \"avant Jesus-Christ\" (BC), immediately before years labeled \"après Jesus-Christ\" (AD).\n\nISO 8601:2004 (and previously ISO 8601:2000, but not ISO 8601:1988) explicitly uses astronomical year numbering in its date reference systems. Because it also specifies the use of the proleptic Gregorian calendar for all years before 1582, some readers incorrectly assume that a year zero is also included in that proleptic calendar, but it is not used with the BC/AD era. The \"basic\" format for year 0 is the four-digit form 0000, which equals the historical year 1 BC. Several \"expanded\" formats are possible: −0000 and +0000, as well as five- and six-digit versions. Earlier years are also negative four-, five- or six-digit years, which have an absolute value one less than the equivalent BC year, hence -0001 = 2 BC. Because only ISO 646 (7-bit ASCII) characters are allowed by ISO 8601, the minus sign is represented by a hyphen-minus.\n\nAll eras used with Hindu and Buddhist calendars, such as the Saka era or the Kali Yuga, begin with the year 0. All these calendars use elapsed, expired, or complete years, in contrast with most other calendars which use current years. A complete year had not yet elapsed for any date in the initial year of the epoch, thus the number 1 cannot be used. Instead, during the first year the indication of 0 years (elapsed) is given in order to show that the epoch is less than 1 year old. This is similar to the Western method of stating a person's age – people do not reach age one until one year has elapsed since birth (but their age during the year beginning at birth is specified in months or fractional years, not as age zero). However, if ages were specified in years and months, such a person would be said to be, for example, 0 years and 6 months or 0.5 years old. This is analogous to the way time is shown on a 24-hour clock: during the first hour of a day, the time elapsed is 0 hours, \"n\" minutes.\n\n"}
