{"id": "36459831", "url": "https://en.wikipedia.org/wiki?curid=36459831", "title": "Aberrant decoding", "text": "Aberrant decoding\n\nAberrant decoding or aberrant reading is a concept used in fields such as communication and media studies, semiotics, and journalism about how messages can be interpreted differently from what was intended by their sender. The concept was proposed by Umberto Eco in an article published first in 1965 in Italian and in 1972 in English.\n\nEvery communication act requires that the messages must be encoded into a set of signs by the sender. These signs must then be transmitted and decoded by the receiver to understand the contained messages. The code system must be shared by both the sender and the receiver in order for the communication to succeed. For example, thoughts must be encoded into words, transmitted through air, and then be decoded back to thoughts. Often the sender has a certain meaning to convey with his message, hoping the receiver will interpret it correctly. This right interpretation can be called the \"preferred decoding\" or \"preferred reading\". When the interpretation of the message is different from what was intended, this can be called \"aberrant decoding\". Aberrant decodings can occur in a more widespread range of situations, as wrong interpretation of a media product or text whose incoming message is not the one intended by the creator of the product or text.\n\nAccording to Eco, aberrant decodings were rare in pre-industrial societies, when most communication occurred between people who shared the same culture. He lists four classes of exceptions where aberrant decodings could have happened:\n\nEco continues that in contemporary media, instead of being exceptions, aberrant decodings have become the norm. For example, TV broadcasters know beforehand that their messages will be interpreted in various ways. He speculated that because of this freedom of interpretation, the power of media over individuals might be much less influential than is thought.\n\nThis idea of examining the messages contained in the media and how the audience interprets them has since become one of the core concepts of academic media research. Eco's article influenced, among others, Stuart Hall's encoding/decoding theory.\n\nJohn Fiske has argued that aberrant decoding occurs mainly with iconic codes, referring to visual messages. As an example, he explains how prehistoric cave paintings of animals are often seen as graceful and moving. However, in 1960 Margaret Abercrombie claimed that the paintings are, in fact, depictions of dead animals. Thus if we accept Abercrombie's claim, we can argue that our modern culture, where we value living animals and only rarely encounter dead ones, has led us to aberrant decoding of the paintings.\n\n"}
{"id": "4412043", "url": "https://en.wikipedia.org/wiki?curid=4412043", "title": "Aniconism in Buddhism", "text": "Aniconism in Buddhism\n\nSince the beginning of the serious study of the history of Buddhist art in the 1890s, the earliest phase, lasting until the 1st century CE, has been described as aniconic; the Buddha was only represented through symbols such as an empty throne, Bodhi tree, a riderless horse with a parasol floating above an empty space (at Sanchi), Buddha's footprints, and the dharma wheel.\n\nAlthough there is still some debate, the first anthropomorphic representations of the Buddha himself are often considered a result of the Greco-Buddhist interaction, in particular in Gandhara, a theory first fully expounded by Alfred A. Foucher, but criticised from the start by Ananda Coomaraswamy. Foucher also accounted for the origins of the aniconic symbols themselves in small souvenirs carried away from the main pilgrimage sites and so becoming recognised and popularized as symbolic of the events associated with the site. Other explanations were that it was inappropriate to represent one who had attained nirvana.\n\nHowever, in 1990, the notion of aniconism in Buddhism was challenged by Susan Huntington, initiating a vigorous debate among specialists that still continues. She sees many early scenes claimed to be aniconic as in fact not depicting scenes from the life of the Buddha, but worship of cetiya (relics) or re-enactments by devotees at the places where these scenes occurred. Thus the image of the empty throne shows an actual relic-throne at Bodh Gaya or elsewhere. She points out that there is only one indirect reference for a specific aniconic doctrine in Buddhism to be found, and that pertaining to only one sect.\n\nAs for the archeological evidence, it shows some anthropomorphic sculptures of the Buddha actually existing during the supposedly aniconic period, which ended during the 1st century CE. Huntington also rejects the association of \"aniconic\" and \"iconic\" art with an emerging division between Theravada and Mahayana Buddhism. Huntington's views have been challenged by Vidya Dehejia and others. Although some earlier examples have been found in recent years, it is common ground that the large free-standing iconic images of the Buddha so prominent in later Buddhist art are not found in the earliest period; discussion is focused on smaller figures in relief panels, conventionally considered to represent scenes from the life of the Buddha, and now re-interpreted by Huntington and her supporters.\n\nIn later periods both the major schools of Buddhism have made great use of representational art, though Theravada temples and other sites typically concentrate on a single large sculpture of the Buddha, whereas Mahayana temples have larger numbers of images of a greater variety of figures with varying degrees of spiritual significance. However some schools, such as Zen Buddhism in Japan, have also shown a general tendency towards aniconism, though without specific prohibition of figurative images.\n\n\n"}
{"id": "696946", "url": "https://en.wikipedia.org/wiki?curid=696946", "title": "Audience", "text": "Audience\n\nAn audience is a group of people who participate in a show or encounter a work of art, literature (in which they are called \"readers\"), theatre, music (in which they are called \"listeners\"), video games (in which they are called \"players\"), or academics in any medium. Audience members participate in different ways in different kinds of art; some events invite overt audience participation and others allowing only modest clapping and criticism and reception.\n\nMedia audience studies have become a recognized part of the curriculum. Audience theory offers scholarly insight into audiences in general. These insights shape our knowledge of just how audiences affect and are affected by different forms of art. The biggest art form is the mass media. Films, video games, radio shows, software (and hardware), and other formats are affected by the audience and its reviews and recommendations.\n\nIn the age of easy internet participation and citizen journalism, professional creators share space, and sometimes attention with the public. American journalist Jeff Jarvis said, \"Give the people control of media, they will use it. The corollary: Don't give the people control of media, and you will lose. Whenever citizens can exercise control, they will.\" Tom Curley, President of the Associated Press, similarly said, \"The users are deciding what the point of their engagement will be — what application, what device, what time, what place.\"\n\nIn rhetoric, some audiences depend on circumstance and situation, and are characterized by the individuals that make up the audience. Sometimes these audiences are subject to persuasion and engage with the ideas of the speaker. Ranging in size and composition, this audience may come together and form a \"composite\" of multiple groups.\n\nAn immediate audience is a type of audience that is composed of individuals who are face-to-face subjects with a speaker and a speaker's rhetorical text or speech. This audience directly listens to, engages with, and consumes the rhetorical text in an unmediated fashion. In measuring immediate audience reception and feedback, (audience measurement), one can depend on personal interviews, applause, and verbal comments made during and after a rhetorical speech.\n\nIn contrast to immediate audiences, mediated audiences are composed of individuals who consume rhetorical texts in a manner that is different from the time or place in which a speaker presents text. Audiences who consume texts or speeches through television, radio and internet are considered mediated audiences because those mediums separate the rhetor and the audience. Such audiences are physically away from the audience and the message is controlled. Understanding the size and composition of mediated audiences can be difficult because mediums such as television, radio, and Internet can displace the audience from the time and circumstance of a rhetorical text or speech. In measuring mediated audience reception and feedback (a practice called audience measurement), one can depend on opinion polls and ratings, as well as comments and forums that may be featured on a website. This applies to may fields such as movies, songs and much more. There are companies that specialise in audience measurement. \n\nTheoretical audiences are imagined for the purpose of helping a speaker compose, practice, or a critic to understand, a rhetorical text or speech.\n\nWhen a rhetor deeply considers, questions, and deliberates over the content of the ideas they are conveying, it can be said that these individuals are addressing the audience of self, or self-deliberating. Scholars Chaim Perelman and L. Olbrechts-Tyteca, in their book \"The New Rhetoric: A Treatise on Argumentation\", argue that the rhetor \"is in a better position than anyone else to test the value of his own arguments.\" The audience of self, while not serving as the ends to all rhetorical purpose or circumstance, nevertheless acts as a type of audience that not only operates as a function of self-help, but as instrument used to discover the available means of persuasion.\n\nThe universal audience is an imagined audience that serves as an ethical and argumentative test for the rhetor. This also requires the speaker to imagine a composite audience that contains individuals from diverse backgrounds and to discern whether or not the content of the rhetorical text or speech would appeal to individuals within that audience. Scholars Perelman and Olbrechts-Tyteca ascertain that the content addressed to a universal audience \"must convince the reader that the reasons adduced are of a compelling character, that they are self-evident, and possess an absolute and timeless validity\". The concept of the universal audience has received criticism for being idealistic because it can be considered as an impediment in achieving persuasive effect with particular audiences. Yet, it still may be useful as an ethical guide for a speaker and a critical tool for a reader or audience.\n\nAn ideal audience is a rhetor's imagined, intended audience. In creating a rhetorical text, a rhetor imagines is the target audience, a group of individuals that will be addressed, persuaded, or affected by the speech or rhetorical text. This type of audience is not necessarily imagined as the most receptive audience, but as the future particular audience that the rhetor will engage with. Imagining such an audience allows a rhetor to formulate appeals that will grant success in engaging with the future particular audience. In considering an ideal audience, a rhetor can imagine future conditions of mediation, size, demographics, and shared beliefs among the audience to be persuaded.\n\nAn implied audience is an imaginary audience determined by an auditor or reader as the text's constructed audience. The implied audience is not the actual audience, but the one that can be inferred by reading or analyzing the text. Communications scholar Edwin Black, in his essay, The Second Persona, presents the theoretical concept of the implied audience using the idea of two personae. The first persona is the implied rhetoric (the idea of the speaker formed by the audience) and the second persona is the implied audience (the idea of the audience formed by and utilized for persuasion in the speech situation). A critic could also determine what the text wants that audience to become or do after the rhetorical situation.\n\nThrough the Internet, every person is given the opportunity to participate in different ways. The Internet gives people a platform to write and reach the people who are interested in what they are writing about. When writers write online, they are able to form communities with the people they share common interests with. The audiences that people are trying to reach can be general or specific, all depending on what the writer is discussing in their online posts. Audiences have to go and check into what the writers are writing to stay on top of the latest information. Writers have to find their niche and try hard to work their way into an already formed community. The audience the writer is reaching is able to respond to the writers posts and can give feedback. The Internet allows these connections to be formed and fostered. In the \"Here Comes Everybody\" book by Clay Shirky, there are various examples of how audience is not only receiving content but actually creating it. Internet creates a chance of being part of an audience and a creator at the same time.\n\nAudience participation is commonly found in performances which break the fourth wall. Examples include the traditional British pantomimes, stand-up comedy, and creative stage shows such as Blue Man Group.\n\nAudience participation can be uncomfortable for certain people, but is growing and evolving as a new tool of brand activation and brand engagement. In a bid to create and reinforce a special bond between brands and their consumers, companies are increasingly looking towards events that involve active audience participation. Often, organizations provide branded objects to event attendees that will involve the audience in the show as well as act as souvenirs of the event, creating a lasting link with the brand. For example, during Super Bowl XLVIII, the audience was incorporated in the Super Bowl XLVIII Halftime Show as part of the lighting effects. Pepsi involved the spectators by giving them \"video ski hats\" that produced visual effects across the crowd.\nBy appealing more directly to people and emotions, brands can obtain feedback from their consumers. Companies that provide or seek such experiences refer to the term \"crowd activation\". For example, Tangible Interaction named one of its branches Crowd Activation and PixMob refers to itself as a crowd activation company on its website.\n\nOne of the most well-known examples of popular audience participation accompanies the motion picture and music \"The Rocky Horror Picture Show\" and its earlier stage incarnation \"The Rocky Horror Show\". The audience participation elements are often seen as the most important part of the picture, to the extent that the audio options on the DVD version include the option.\n\nIn the audience participation for the Rocky Horror Picture Show, the audience will make \"call backs\", and yell at the screen at certain parts of the movie. Also, a number of props are thrown and used by the audience during certain parts of the film. \n\nIn British pantomime performances, the audience is a crucial aspect of the show and is expected to perform certain tasks such as:\n\n\"The Complete Works of William Shakespeare (Abridged)\" divides the audience into groups assigned to call out the concerns of three components of a character's psyche. \n\nIn \"The Mystery of Edwin Drood\", a Broadway theatre musical based on Charles Dickens's last, unfinished work, the audience must vote for whom they think the murderer is, as well as the real identity of the detective and the couple who end up together.\n\nThe 1984 Summer Olympics included card stunts at the Olympic Stadium. \n\nTony and Tina's Wedding engages the entire audience at once, staging a narrative set during a wedding in which the audience performs the role of \"guests\".\n\nThe British panel game \"QI\" often allows the audience to try to answer questions. Currently, the audience have won one show, and have come last in another.\n\nMagic shows often rely on some audience participation. Psychological illusionist Derren Brown relies heavily on audience participation in his live shows.\n\nDuring performances of the Radetzky March, it is traditional for the audience to clap along with the beat of the second (louder) repetitions of the chorus. This is particularly notable at the Neujahrskonzert.\n\nBloggers often allow their readers moderated or unmoderated comments sections.\n\nSome musical groups often heavily incorporate audience participation into their live shows. The superhero-themed comedy rock band The Aquabats typically do so within their theatrical stage shows through such antics as \"pool floatie races\", where members of the band race across the venue on inflatable rafts via crowd surfing, or providing the audience with projectiles (such as plastic balls or beach balls) to throw at costumed \"bad guys\" who come out on stage. Koo Koo Kanga Roo, a comedy dance-pop duo, write their music solely for audience participation, utilizing call and response style sing-along songs which are usually accompanied by a simple dance move that the band encourage the audience to follow along with.\n\nThe television series \"Mystery Science Theater 3000\" featured a man and his robots who were held as imprisoned audience members and tortured by being forced to view \"bad\" movies; to retain their sanity, they talked throughout and heckled each one.\n\nIn a similar vein, the online site Television Without Pity has a stable of reviewers and recappers who speak the lingo of audience members rather than of scholars, and who sometimes act as though they, too, are being tortured. \n\n"}
{"id": "1058381", "url": "https://en.wikipedia.org/wiki?curid=1058381", "title": "Callaïs", "text": "Callaïs\n\nCallaïs is the name of a green stone used for making beads by western European cultures of the later Neolithic and Early Bronze Age. It was described by Pliny the Elder (NH XXXVII.lvi.151) as being paler than lapis lazuli.\n\nIts source was probably Brittany, near Locmariaquer where numerous turquoise items have been found, although this has not been confirmed.\n"}
{"id": "1219664", "url": "https://en.wikipedia.org/wiki?curid=1219664", "title": "Cantometrics", "text": "Cantometrics\n\nCantometrics (\"song measurements\") is a method developed by Alan Lomax and a team of researchers for relating elements of the world's traditional vocal music (or folk songs) to features of social organization as defined via George Murdock's Human Relations Area Files, resulting in a taxonomy of expressive human communications style. Lomax defined Cantometrics as the study of singing as normative expressive behavior and maintained that Cantometrics reveals folk performance style to be a \"systems-maintaining framework\" which models key patterns of co-action in everyday life. His work on Cantometrics gave rise to further comparative studies of aspects of human communication in relation to culture, including: Choreometrics, Parlametrics, Phonotactics (an analysis of vowel frequency in speech), and Minutage (a study of breath management). \n\nInstead of the traditional Western musicological descriptive criteria of pitch, rhythm, and harmony, Cantometrics employs 37 style factors developed by Lomax and his team in consultation with specialists in linguistics, otolaryngology and voice therapy. The vocal style factors were designed to be easily rated by observers on a five-point scale according to their presence or absence. They include, for example: group cohesion in singing; orchestral organization; tense or relaxed vocal quality; breathiness; short or long phrases; rasp (vocal grating, such as associated, for example with the singing of Louis Armstrong); presence and percentage of vocables versus meaningful words); and melisma (ornamentation), to name a few. \n\nIn the early stages of his work on the Cantometrics coding system, Lomax wrote of the relationship of musical style to culture:\"Its fundamental diagnostic traits appear to be vocal quality (color, timbre, normal pitch, attack, type of melodic ornamentation, etc.) and the degree in which song is normally monodic or polyphonic. The determinative socio-psychological factors seem to be . . . the type of social organization, the pattern of erotic life, and the treatment of children... I myself believe that the voice quality is the root [diagnostic] element. From this socio-psychological complex there seem to arise a complex of habitual musical practices which we call musical style\" \n\nLomax first publicly proposed the Cantometrics project in 1959 and launched a group project in conjunction with the Anthropology Department at Columbia University to implement his vision. Early collaborators included musicologist Victor Grauer, who was the first co-creator with Lomax of the Cantometrics computer coding system. Subsequent project members included distinguished Columbia University anthropologist Conrad M. Arensberg, a founder of applied anthropology; anthropologists Edwin Erickson and Barbara Ayres; and statistician Norman Berkowitz. Laban shape notation specialist Irmgard Bartenieff and dancer and movement therapist Forrestine Paulay co-created the Choreometrics movement coding system, for analyzing dance, mapping the movement of the torso, hands, feet, and use of performance space. In 1968 Lomax's research team published a book, \"Folk Song Style and Culture\", in which they stated that, \"for the first time, predictable and universal relationships have been established between the expressive and communication processes, on the one hand, and social structure and culture pattern, on the other\". \n\nGideon D'Arcangelo, a member of the Cantometrics team, described their work this way:Using 37 criteria of observation, the Cantometrics team analyzed over 4,000 songs – around 10 representative songs from over 400 cultures. Each song profile they made was recorded on a computer punch-card and loaded onto the Columbia mainframe. A companion study of dance, Choreometrics, produced analyses of over 1,500 dance performances. Only a computer was capable of handling this enormous data set and looking for the patterns hidden within. The team, led by programmer Norman Berkowitz, developed a powerful set of statistically driven software tools to sort, separate, and group the performance data. Their analyses resulted in the first ever taxonomy of human performance style and in a series of maps showing the dis-semination of culture across the planet. These were presented to the American Association of Science (1966) and later published in the collaborative volume, \"Folk Song Style and Culture\" (1968).\n\nThe Cantometric study of song revealed strong statistical relations between song style and social norms. Alan Lomax stated that the Cantometrics analysis amply justified his original hypothesis that sexually restrictive and highly punitive societies correlated with degree of vocal tension. The tendency to sing together in groups, tonal cohesiveness, and the likelihood of polyphonic singing were all associated with fewer restrictions on women. Multipart singing occurs in societies where the sexes have a complementary relationship. \n\nOther results included strong correlations between length of phrase and precision of articulation, and degree of ornamentation with social stratification. It was found that explicitness or the information load of song varies with the level of economic productivity of the subsistence system.\n\nMurdock's taxonomy encoded the economic, social, and political features of more than 1,100 societies that ethnologists had studied up until that time. In many cases, these codes formed scales – for example, the one concerning the number of levels of political authority outside the local community, from 0 among hunters, to 4 for irrigation empires. Lomax and Arensberg arranged the codes into scales in order to measure the kinds of behaviors of features of culture, such as levels of production or permanence of settlement. When they added factors of expressive communication to the Murdock measures of social relations it produced a geographical taxonomy of human culture.\n\nThree chapters of \"Folk Song Style and Culture\" are devoted to Choreometrics. In chapter ten, \"Dance, Style, and Culture,\" Lomax, Bartenieff, and Paulay describe the origin and meaning of the term: \"In order to distinguish the level of this comparative study of movement from the levels where previous investigators have worked, we have given the method a freshly-coined designation, Choreometrics, meaning the measure of dance, or dance as a measure of culture.\". They wrote that:\nChoreometrics tests the proposition that dance is the most repetitious, redundant, and formally organized system of body communication present in a culture... The dance is composed of those gestures, postures, movements, and movement qualities most characteristic and most essential to the activity of everyday, and thus crucial to cultural continuity. By treating these elements redundantly and formally, dance becomes an effective organizer of joint motor activity. Dance supplies the metronome to meter and regulates, or orders the energy and attention of groups of people, and thereby acquires the weight of general community approval. Thus dance functions to establish and renew consensus at moments when a society, without further discussion or explanation, is ready to act in concert.\n\nBartenieff believed that dance (particularly traditional dance) was uniquely suited to Lomax's type of analysis, since movement is \"not only a medium of expression but also the essence of communication. Although all dancers feel intuitively that movement communicates across culture barriers, she wrote, there have hitherto been no means for describing dance patterns so that they could be consistently compared cross-culturally: \n\n\"The task on which we collaborated with Mr. Lomax was to adapt the Laban system to the problem of comparison of movement styles cross-culturally so that the main style families would emerge from the study of this visually perceived behavior on film, as in Cantometrics they had been found by study of aurally perceived behavior.\" \n\nA series of short documentary films demonstrated some of the results of the team's statistical analysis in dramatic visual terms. These were: \"Dance & Human History\" (1974) (40 min.), which examined two important parameters in the Choreometric study, the dominant trace form of the movement and single/multiple articulation of the torso and relates them to geography and type of society; \"Palm Play\" (1977) (27 min.), which examines the use of the palm in dance cross culturally; \"Step Style\" (1977) (30 min.), which examines the use of the foot in dance cross culturally; and \"The Longest Trail\" (1984) (59 min.), which uses Choreometric data as evidence that the Americas were populated by Siberian hunters. In 2009 all four films were included on the DVD \"Rhythms of Earth: The Choreometrics Films of Alan Lomax and Forrestine Paulay\" produced by John Melville Bishop (Media-Generation, 1974–2008), which included old and new interviews with the original participants of the study. Improvisational jazz musician and composer Roswell Rudd later collaborated with Lomax and Paulay on an unpublished study called the Urban Strain that used Cantometric and Choreometric analysis to study commercially produced twentieth-century American popular music and dance.\n\nThe reaction of musicologists to Cantometrics was complex, as some critics questioned whether one could ever have enough statistics to prove anything about music and culture. One, Richard Middleton, called it an example of sociological homology.\n\nThe musical examples for Cantometrics had not been chosen randomly, however, but for their representativeness, following the scholarly guidance of specialists who had studied the regions and /or supplied the audio or film clip samples. This was done because it was found that style tends to be very repetitive, and in most instances relatively few examples captured the stable performance norms, so that in most cases, coding many examples per culture yielded little new information. Lomax and Grauer settled on about ten examples per culture for Cantometrics, which had the largest dataset. Ten examples per culture usually sufficed, although for some cultures one or more sub-styles needed to be sampled as well. \n\nAlan Lomax himself stressed repeatedly that completeness of sampling was not the point:\nThe adequacy of any of these samples is . . . subject to this test: Will another sample of a similar kind taken in the same culture produce a similar performance profile? From this point of view, I believe that the majority of our samples will hold up. Even \"secret\" songs generally tend to be stylistically close to the more familiar music of a culture. The truth is that, with any one culture or subculture, singing is a rather standardized kind of behavior. It must be so since a main function of song is to . . . permit groups of performers to vocalize together and their listeners to share in a common experience. Cantometrics is a study of these standardized models, which describe singing rather than songs. Therefore, it is not primarily concerned with \"complete\" collections and descriptions, as are most scholarly endeavors, but with locating verifiable regularities and patterns. (Lomax [1968] 2000).\n\nVictor Grauer noted that: “Cantometrics is a statistical method. Its patterns and correlations are based on multiple instances, not just one. There will always be exceptions, which is why statistical methods are generally preferable for comparative studies than the close examination of individual examples.”\n\nThe Cantometrics team also created a set of teaching tapes that make it easy to develop an understanding of world music and to create new song profiles. “Cantometrics helps you to break music down into its parts,” Roswell Rudd told Gideon D’Arcangelo. “You want to know how it’s put together and then you want to know where the parts came from. The Cantometrics teaching tapes are the best thing anybody can use who wants to understand world music, classical music, pop music, whatever. That teaching kit teaches you about the qualities of music – any kind of music from any culture.” \nAlan Lomax foresaw that computers would be an ideal way to make Cantometrics analysis available not just to scholars but to people of all ages and educational backgrounds, particularly school children. With that end in view, during the 1990s he developed The Global Jukebox, an interactive multi-media computer program designed for classrooms, museums, and libraries to visually and aurally map the world's song and dance cultures, incidentally helping people understand their own roots and those of others, while teaching geography, anthropology, and tolerance through song and dance. Since Alan Lomax's death in 2002, The Association for Cultural Equity, which Lomax founded, has been working to update the program, and make it widely available. In fulfillment of this project, as of March 2012 all the recordings of his Archive will be streamed online.\n\n"}
{"id": "92379", "url": "https://en.wikipedia.org/wiki?curid=92379", "title": "Catachresis", "text": "Catachresis\n\nCatachresis (from Greek , \"abuse\"), originally meaning a semantic misuse or error—e.g., using \"militate\" for \"mitigate\", \"chronic\" for \"severe\", \"anachronism\" for \"anomaly\", \"alibi\" for \"excuse\", etc.—is also the name given to many different types of figures of speech in which a word or phrase is being applied in a way that significantly departs from conventional (or traditional) usage.\n\nThere are various subdefinitions of catachresis.\n\nDead people in a graveyard being referred to as inhabitants is an example of catachresis.\n\nCatachresis is often used to convey extreme emotion or alienation. It is prominent in baroque literature and, more recently, in dadaist and surrealist literature.\n\nExample from Alexander Pope's \"Peri Bathous, Or the Art of Sinking in Poetry\":\nMasters of this [Catachresis] will say,\n\nIn Jacques Derrida's ideas of deconstruction, catachresis refers to the original incompleteness that is a part of all systems of meaning. He proposes that metaphor and catachresis are tropes that ground philosophical discourse. Postcolonial theorist Gayatri Spivak applies this word to \"master words\" that claim to represent a group, \"e.g.\", women or the proletariat, when there are no \"true\" examples of \"woman\" or \"proletarian\". In a similar way, words that are imposed upon people and are deemed improper thus denote a catachresis, a word with an arbitrary connection to its meaning.\n\n\n"}
{"id": "32656130", "url": "https://en.wikipedia.org/wiki?curid=32656130", "title": "Center for research on Children, Adolescents, and the Media", "text": "Center for research on Children, Adolescents, and the Media\n\nThe Center for research on Children, Adolescents and the Media (CCAM) at the University of Amsterdam, the Netherlands, was founded in 2005 by Patti Valkenburg. Since then, it has grown into one of the largest research centers in its kind worldwide. CCAM hosts 25 international researchers from 9 academic disciplines. It is part of the Amsterdam School of Communication Research ASCoR. Since 2009, CCAM researchers have organized an international master program on Youth and Media.\n\nChildren and adolescents have become the defining users of media and technologies. Despite a booming media industry aimed at young people, little is known about the uses and effects of these media and technologies. CCAM strives to better understand the role of media in children's and adolescents' lives. What are the intended and unintended effects of advertising? Which children are particularly susceptible to potential negative effects of advertising, pornography, and media violence? When do social media have positive and negative influences on young people? Researchers in CCAM have published dozens of articles and chapters that provide answers on questions like these.\n\nCCAM has an open access policy. All publications can be downloaded from the publication section. In addition, all instruments that CCAM researchers have created to investigate their theories and models are freely accessible via the website of CCAM.\n\nResearch within CCAM is targeted at an academic audience as well as the public at large. Every three months, the center publishes a news bulletin to inform the broader audience of the latest research insights.\n\n"}
{"id": "4459843", "url": "https://en.wikipedia.org/wiki?curid=4459843", "title": "Chironomia", "text": "Chironomia\n\nChironomia is the art of using gesticulations or hand gestures to good effect in traditional rhetoric or oratory. Effective use of the hands, with or without the use of the voice, is a practice of great antiquity, which was developed and systematized by the Greeks and the Romans. Various gestures had conventionalized meanings which were commonly understood, either within certain class or professional groups, or broadly among dramatic and oratorical audiences.\n\nGilbert Austin was a well-known author on chironomia. The article about him contains a summary of theories in chironomia.\n\n"}
{"id": "34569610", "url": "https://en.wikipedia.org/wiki?curid=34569610", "title": "Chonga", "text": "Chonga\n\nChonga is a Spanish-derived term used especially in South Florida, often to indicate a working-class, sexualized, aggressive, and emotionally expressive young woman.\n\nChongas are also a distinct subculture, believed to have developed in Miami in the late 20th century. Members are typically young, working-class Latina women. In South Florida the term is usually considered a pejorative, though some young women are proud to identify themselves as such. While feminist scholarship on chongas is limited, early work by gender studies scholar Jillian Hernandez has suggested that the chonga identity is an \"emerging icon\", and that it can be empowering for working-class women.\n\nThe intended meaning of the term \"chonga\" varies depending on the context in which it is used. The most specific meaning of the term denotes a member of the chonga subculture—young, usually working class and Latina women—who dress and often act in a sexualized, brash, sometimes aggressive manner. The term also has three looser meanings: as a synonym for prostitute; to refer to a woman who acts \"gangsta\" or in a thug like manner; and among female friends, as a jovial way to greet each other, as an alternative to \"girlfriend!\"\n\nUsage of the term to refer to young women is believed to have arisen in Miami, and only became prominent in the early 21st century. The same word has long been used in Latin American countries such as Peru and Ecuador to refer to a brothel; the modern US usage of the word may be related to this, or might have arisen independently among Floridian Cuban-Americans. \n\n\"Chonga\" has lexical similarities with several other Spanish terms, some of which have been in use for centuries. These include: \n\nAccording to the journalist Tamara Lush, Chonga subculture may have first appeared in Miami during the 1980s. Early chongas were usually Cuban teenagers whose parents had recently immigrated to the US. In the 1990s, chongas often wore white shorts with a colored thong underneath, basketball jerseys, and fake gold jewelry. Over the years the style evolved, with for instance tight jeans becoming more popular than shorts.\n\n21st-century chongas will often exhibit at least some of the following characteristics: \n\nNot all chongas live up to these stereotypes; for example, sometimes women whose conduct is the most overtly sexualized will in fact be among the least interested in actual heterosexual encounters—in some cases chonga behavior is perhaps best understood as a kind of bonding between female friends.\n\nUntil 2007, chongas have rarely appeared in the media, despite their high visibility in real life. One of the rare exceptions was the \"Cheerleaders\" (2000) set of art photographs by Luis Gispert. In popular culture, the few exceptions include Bratz dolls which have a chonga-like appearance; the chonga-like characters Lydia and Melina in the television comedy MADtv; and the chonga-like character Tina in the movie \"Do the Right Thing\". Chongas became considerably more common in popular culture after the 2007 release of Chongalicious, a YouTube viral video. Hernandez noted that the only depiction she's aware of that accurately showed chongas in their social context was the 2007 \"Bratz girls\" exhibition by the \"GisMo Collective\" (Jessica Gispert and Crystal Molinary).\n\nAccording to a 2009 article by gender studies scholar Jillian Hernandez, feminist literature covering chongas remains sparse, even after their profile was raised by the \"Chongalicious\" video. Hernandez contrasts this with the extensive body of work on Chicana feminism, which explores the \"chola\" and \"chusma\" phenomena. Hernandez argues the chonga image has become iconic in Miami, and states that the aesthetic appeal of the chonga can be considerable, which in her opinion partly explains why the \"cheerleaders\" set of photographs was successful in launching Gispert's international career.\n\nThe portrayal of chongas in the media can, however, be problematic, sometimes even repressive, as powerful negative images contribute to Latinas internalizing pressure to conform which originates from the dominant Anglo-American culture. Stereotypical representations of chongas can play a role in the United States' wider culture wars, adding to concerns about the sexuality of some Latina women being \"out of control\" with their perceived high rate of reproduction. Citing earlier work by Isabel Molina Guzmán, Hernandez relates this to the Elián González affair, where the media portrayal of Marisleysis González as having the chonga-like characteristic of emotional excess contributed to the degradation of the privileged, \"model minority status\" that Cuban Americans had previously enjoyed.\n\nIn her own research, Hernandez found that most people she questioned considered \"chonga\" a pejorative term. One respondent even went as far as to say the term sums up all the negative Latina stereotypes. A few asserted that while they know several chongas, they don't know any who self-identify as such. Sometimes Latina women will admit they went through a brief \"chonga\" phase in their early teens, but later came to view the style as uncool. Yet some chongas chose to retain the identity into their twenties. Hernandez also found that some young woman are proud to call themselves chongas. Several expressed pride in their sexual attractiveness. The creators of \"Chongalicious\", who are themselves middle class, found they had considerably more male attention while pretending to be chongas, one of them saying back in 2007 that \"I think we would have boyfriends if we were real chongas.\" Hernandez suggests that the chonga sub culture is in several ways a positive thing, representing women who are not shamed into invisibility by their low-class status or ethnic identity. She anticipates a broadening and deepening of feminist scholarship on chongas, to uncover the ways in which the chonga identity can be helpful to young women exploring their \"bodies and pleasures\".\n\n\n\n\n"}
{"id": "14921027", "url": "https://en.wikipedia.org/wiki?curid=14921027", "title": "Christian comedy", "text": "Christian comedy\n\nChristian comedy is a subgenre of comedy where the material presented is aimed towards a Christian audience. The performances are typically held on church grounds or at off-site, church-sponsored venues.\n\nThe material often contains Christian references, although this is not a requirement. Recently, notable performers like Victoria Jackson, Tim Conway, Sinbad and Patricia Heaton have appeared on a DVD series for the Christian market entitled, \"Thou Shalt Laugh\"\n\nChristian comedy is increasingly being used as an outreach, with the idea that a comedy show is a great way to bring people into church who may have never thought about coming.\n\nChristian comedy is also used as a method to renew and refresh the spirit of church members, based on the Bible passage that says laughter does a heart good, like medicine.\n\n\n"}
{"id": "6353282", "url": "https://en.wikipedia.org/wiki?curid=6353282", "title": "Circumscription theory", "text": "Circumscription theory\n\nThe circumscription theory is a theory of the role of warfare in state formation in political anthropology, created by anthropologist Robert Carneiro. The theory has been summarized in one sentence by Schacht: “In areas of circumscribed agricultural land, population pressure led to warfare that resulted in the evolution of the state”. The more circumscribed is an agricultural area, Carneiro argues, the sooner it politically unifies.\n\nThe theory begins with some assumptions. Warfare usually disperses people rather than uniting them. Environmental circumscription occurs when an area of productive agricultural land is surrounded by a less productive area such as the mountains, desert, or sea. Application of extensive agriculture would bring severely diminishing returns.\n\nIf there is no environmental circumscription, then losers in a war can migrate out from the region and settle somewhere else. If there is environmental circumscription, then losers in warfare are forced to submit to their conquerors, because migration is not an option and the populations of the conquered and conqueror are united. The new state organization strives to alleviate the population pressure by increasing the productive capacity of agricultural land through, for instance, more intensive cultivation using irrigation.\n\n\"Primary state development\" occurred in the six original states of the Nile Valley, Peru, Mesoamerican, Yellow River Valley China, Indus River Valley, and Mesopotamia. \"Secondary state development\" occurred in states that developed from contact with already existing states. Primary state development occurred in areas with environmental circumscription.\n\nThe presumption, under the Carneiro Hypothesis, is that agricultural intensification, and the social coordination and coercion necessary to achieve this end was a result of warfare in which vanquished populations could not disperse; the coercive coordination necessary for increased production of surplus is, under Carneiro's hypothesis, a causal factor in the origins of the State. For example, the mountainous river valleys of Peru which descend to the Pacific coast were severely environmentally circumscribed. Amazonian populations could always disperse and maintain sparse contact with other, potentially hostile, neighbors, whereas Andean coastal populations could not.\n\nCarneiro's theory has been criticized by the Dutch \"early state school\" emerging in the 1970s around cultural anthropologist Henri J.M. Claessen, on the ground that considerable contrary evidence can be found to Carneiro's theory. There are also cases of circumscribed environments and violent cultures which have failed to develop states, for example in the narrow highland valleys of interior Papua New Guinea, or the north west Pacific coastlines of North America. Also for example, the formation of some early states in East Africa, Sri Lanka, and Polynesia do not easily fit with Carneiro's model. Hence Claessen's school developed a \"complex interaction model\" to explain early state formation, in which factors such as ecology, social and demographic structures, economic conditions, conflicts, and ideology become aligned in ways which favour state organisation.\n\nThe theory has since been applied to many other contexts, with some arguing it can be applied globally. Carneiro has since also revised his theory in various ways. He has argued that population \"concentration\" can act as a lower level impetus for tribal conflict than geographic circumscription. He has also argued that, in addition to the necessities of conquest, a more important reason for creation of chiefdoms was the rise of war chiefs who use their military loyalists to take over a group of villages and become paramount chiefs.\n\n\n"}
{"id": "51147036", "url": "https://en.wikipedia.org/wiki?curid=51147036", "title": "Constraint-based grammar", "text": "Constraint-based grammar\n\nConstraint-based grammars can perhaps be best understood in contrast to generative grammars. A generative grammar lists all the transformations, merges, movements, and deletions that can result in all well-formed sentences, while constraint-based grammars, take the opposite approach, allowing anything that is not otherwise constrained. \"The grammar is nothing but a set of constraints that structures are required to satisfy in order to be considered well-formed.\" \"A constraint-based grammar is more like a data base or a knowledge representation system than it is like a collection of algorithms.\"\n\nExamples of such grammars include\n"}
{"id": "26914791", "url": "https://en.wikipedia.org/wiki?curid=26914791", "title": "De Prospectiva Pingendi", "text": "De Prospectiva Pingendi\n\nDe Prospectiva pingendi (On the Perspective of painting) is the earliest and only pre–1500 Renaissance treatise solely devoted to the subject of perspective. It was written by the Italian master Piero della Francesca late in his career but possibly by c. 1474. Despite its Latin title, the opus is written in Italian.\n\nThe subjects covered by Piero della Francesca in these writings include arithmetic, algebra, geometry and innovative work in both solid geometry and perspective.\n\nThe script consists of three parts:\n\n\n\"De Prospectiva Pingendi\" was probably created in the years between 1474 until 1482.\n\nThe writings were inspired by the book \"De pictura\" by Leon Battista Alberti written in 1435 but probably also by works by Euclid. The manuscript later came into the possession of the Biblioteca Palatina in Parma before it was transferred to the Biblioteca Ambrosiana.\n\nMuch of Piero’s work was later absorbed into the writing of others, notably Luca Pacioli. Piero’s work on solid geometry appears in Pacioli’s \"De divina proportione\", a work illustrated by Leonardo da Vinci.\n\nIn 1899 the writings were first published in bookform.\n\n"}
{"id": "969975", "url": "https://en.wikipedia.org/wiki?curid=969975", "title": "Drapery", "text": "Drapery\n\nDrapery is a general word referring to cloths or textiles (Old French \"draperie\", from Late Latin \"drappus\"). It may refer to cloth used for decorative purposes – such as around windows – or to the trade of retailing cloth, originally mostly for clothing, formerly conducted by drapers. \n\nIn art history, drapery refers to any cloth or textile depicted, which is usually clothing. The schematic depiction of the folds and woven patterns of loose-hanging clothing on the human form, with ancient prototypes, was reimagined as an adjunct to the female form by Greek vase-painters and sculptors of the earliest fifth century and has remained a major source of stylistic formulas in sculpture and painting, even after the Renaissance adoption of tighter-fitting clothing styles. After the Renaissance, large cloths with no very obvious purpose are often used decoratively, especially in portraits in the grand manner; these are also known as draperies.\n\nFor the Greeks, as Sir Kenneth Clark noted, clinging drapery followed the planes and contours of the bodily form, emphasizing its twist and stretch: \"floating drapery makes visible the line of movement through which it has just passed... Drapery, by suggesting lines of force, indicates for each action a past and a possible future.\" Clark contrasted the formalized draperies in the frieze at Olympia with the sculptural frieze figures of the Parthenon, where \"it has attained a freedom and an expressive power that have never been equalled except by Leonardo da Vinci\". Undraped male figures, Clark observed, \"were kept in motion by their flying cloaks.\"\n\n"}
{"id": "11169494", "url": "https://en.wikipedia.org/wiki?curid=11169494", "title": "Dream world (plot device)", "text": "Dream world (plot device)\n\nDream world (also called dream realm or illusory realm) is a commonly used plot device in fictional works, most notably in science fiction and fantasy fiction. The use of a dream world creates a situation whereby a character (or group of characters) is placed in a marvellous and unpredictable environment and must overcome several personal problems to leave it. The dream world also commonly serves to teach some moral or religious lessons to the character experiencing it – a lesson that the other characters will be unaware of, but one that will influence decisions made regarding them. When the character is reintroduced into the real world (usually when they wake up), the question arises as to what exactly constitutes reality due to the vivid recollection and experiences of the dream world.\n\nAccording to J.R.R. Tolkien, dream worlds contrast with fantasy worlds, in which the world has existence independent of the characters in it. However, other authors have used the dreaming process as a way of accessing a world which, within the context of the fiction, holds as much consistency and continuity as physical reality. The use of \"dream frames\" to contain a fantasy world, and so explain away its marvels, has been criticized and has become much less prevalent.\n\nA similar motif, Locus amoenus, is popular in medieval literature (esp. allegory and romance). A dream world is sometimes invoked in dream visions such as \"The Book of the Duchess\" and \"Piers Plowman\".\nOne of the best-known dream worlds is Wonderland from Lewis Carroll's \"Alice's Adventures in Wonderland\", as well as Looking-Glass Land from its sequel, \"Through the Looking-Glass\". Unlike many dream worlds, Carroll's logic is like that of actual dreams, with transitions and causality flexible. James Branch Cabell's \"Smirt\" and its two sequels taken together form an extended dream and most of their action takes place in a dream world.\n\nThe action of \"The Bridge\" by Iain M. Banks and \"The Chronicles of Thomas Covenant, the Unbeliever\" by Stephen R. Donaldson take place in dream worlds. Other fictional dream worlds include the Dreamlands of H. P. Lovecraft's \"Dream Cycle\" and \"The Neverending Story\"s world of Fantasia, which includes places like the Desert of Lost Dreams, the Sea of Possibilities and the Swamps of Sadness. Dreamworlds, shared hallucinations and other alternate realities feature in a number of works by Philip K. Dick, such as \"The Three Stigmata of Palmer Eldritch\" and \"Ubik\". Similar themes were explored by Jorge Luis Borges, for instance in \"The Circular Ruins\".\n\nIn \"The Wheel of Time\" book series, Tel'aran'rhiod is a dream world that exists in close proximity to the real world. Objects and physical locations that do not frequently change in the real world have parallels in Tel'aran'rhiod. Ordinary people can occasionally slip into Tel'aran'rhiod, and events that occur within this dream world have physical consequences. A person that dies in Tel'aran'rhiod will never wake up again, and in several cases it is shown that physical injuries gained there persist to the waking world. Tel'aran'rhiod can be controlled similar to a lucid dream, and several characters in the series can enter and manipulate Tel'aran'rhiod at will.\n\n\"Paprika\" (1993) by Yasutaka Tsutsui is a science fiction novel that involves entering dream worlds using technology. In the book, dream monitoring and intervention as a means of treating mental disorders is a developing new form of psychotherapy in the near future. Unrest ensues when a new psychotherapy dream-analysis device is stolen, allowing the assailant to enter and manipulate people's dreams.\n\nIn the feminist science fiction novel \"The Kin of Ata Are Waiting for You\", the Kin of Ata maintain the real world through their dreaming, making the real world a form of dream.\n\nIn the 1939 movie, Oz from \"The Wonderful Wizard of Oz\" was altered from a fantasy world (in the novel) to a dream world of Dorothy's; characters who were independent inhabitants of Oz were transformed into dream parallels of introduced Kansas characters.\n\nIn \"The Matrix\", Neo and the rest of the humans live inside a dream world. Their brains are hooked up to a computer network that creates this dream world. However, some may argue that this is not a dream world, as it seems completely normal and indistinguishable from reality (aside from time differences). In the 1980s, the \"Nightmare on Elm Street\" series of horror films introduced a dark dream realm inhabited by the supernatural serial killer Freddy Krueger.\n\nIn the movie \"Sharkboy and Lavagirl\" the main characters enter a world dreamt up by a small boy in order to save the real world.\nDown Town is the land of nightmares where all people who are in comas go in the movie \"Monkeybone\". Dreamworlds also appear in \"Total Recall\" and \"Vanilla Sky\".\n\n\"Paprika\" (2006) is an anime film adaptation of the 1993 novel of the same name, which involves entering and manipulating dream worlds using dream-analysis devices.\n\nThe film \"Waking Life\" takes place almost entirely in a dream realm. In the 2010 film \"Inception\", main characters create artificial, vivid dream worlds and bring others into the dream worlds and perform various things with their brains, without them knowing. This may involve 'Extraction' (stealing memories and secrets), 'Inception' (planting an idea into the mind) and others.\n\nOne of the earliest newspaper comic strips, recounting Little Nemo's adventures in , had a dream world theme.\n\nWriter Neil Gaiman was tasked with re-imagining a Golden Age character, \"The Sandman\". In his version, the Sandman becomes Dream, the Lord of Dreams (also known, to various characters throughout the series, as Morpheus, Oneiros, the Shaper, the Shaper of Form, Lord of the Dreaming, the Dream King, Dream-Sneak, Dream Cat, Murphy, Kai'ckul, and Lord L'Zoril), who is essentially the anthropomorphic personification of dreams. At the start of the series, Morpheus is captured by an occult ritual and held prisoner for 70 years. Morpheus escapes in the modern day and, after avenging himself upon his captors, sets about rebuilding his kingdom, which has fallen into disrepair in his absence.\n\nDream worlds also appear in \"Rozen Maiden\", in the Outback(s) of \"The Maxx\"; in Dream Land, the main setting of many \"Kirby\" games, in the webcomic \"The Dreamland Chronicles\", and the movie \"Sailor Moon Super S the Movie: Black Dream Hole\" also have dream realms in their universes.\n\nThe \"American Dragon Jake Long\" episode \"Dreamscape\" takes place mainly in a dream realm. Similarly, the \"Xiaolin Showdown\" episode of the same title also uses the dream world in its plotline.\n\nIn \"Clamp\" manga series such as \"X/1999\", \"\" and \"xxxHolic\", the dream world is very important to the events that occur within each story. It is later revealed in \"xxxHolic\" that the dream world itself is its own world, as part of the Clamp multiverse. Similarly, in the \"Bone\" graphic novel series by Jeff Smith, the primary plot device is a dream world called \"The Dreaming.\" It exists independently from the real world, and it is described similarly to a river, being said to \"flow\" through people in \"currents.\"\n\nIn \"JoJo's Bizarre Adventure\" part 3 \"Stardust Crusaders,\" Jotaro and his friends and grandpa are put in a dream world which takes the form of an amusement park by Mannish Boy and his Death 13 stand.\n\nIn the \"Jay Jay the Jet Plane\" cartoon series, adventures where air-breathing jet planes cannot go (underwater and in space) happen as dreams.\n\nThe \"\" episode \"Waking Moments\" uses several dream realms and false awakenings. In the \"UFO\" episode \"Ordeal,\" Foster's abduction and rescue is explained away as a dream. The whole of season 8 of \"Dallas\" was retroactively explained, at the start of Season 9, as a dream had by Bobby Ewing. In the episode, \"Dreamworker\", Morpheus, god of dreams, abducts Gabrielle to take as his bride. But Xena follows them into his realm, the DreamScape, where she battles to stop the impending forced marriage. The \"Doctor Who\" episode, \"Amy's Choice\" also depicts multiple dream worlds, which were found out to have been induced by a parasitic seed. Dreamworlds are revisited in the \"Doctor Who\" Christmas special, \"Last Christmas,\" which depicts dreams within dreams caused by mind-leeching aliens.\n\nThe video games \"Link's Awakening\" and \"Super Mario Bros. 2\" take place in a dream of the Wind Fish's (whom Link must wake up) and Mario's respectively.\n\n\"Alundra\" revolves around a dreamwalker who can enter people's dreams. It takes place on an island, where a village has locals suffering from recurring nightmares that sometimes cause death. With his dreamwalking ability, the titular protagonist Alundra attempts to help the locals by entering their dreams.\n\nIn the first two games of the \"EarthBound\" series, the protagonist (Ninten in \"EarthBound Zero\" and Ness in \"EarthBound\") must travel to a dream world named Magicant. However, the two Magicants are different from each other. Ninten visits his Magicant, which is light pink and has seashell spires and clouds, multiple times during the story, until it is revealed to not be his own Magicant but instead just a collection of the memories of his great-grandmother, Maria. Ness's Magicant is a surreal, spacelike land in a purple sea that Ness only gains access to once he records the eight melodies into his Sound Stone, which he then must travel to the center of in order to overcome his weaknesses, characterized by a boss battle against his 'Nightmare' (with an appearance similar to the 'Mani-Mani Statue', a mysterious object encountered in another dreamworld called Moonside), and absorb the power of the Earth into his heart.\n\nAbout a half of \"\" takes place in the Dream World, home to the Staff of Dreams, which was later split by Pins and Needles, where Tak has a half of the staff and Pins and Needles have the Staff of Nightmares half. By the end of the game, Tak restored the staff.\n\nIn \"\", the game is split between two worlds initially known as the Real World and the Phantom World, named such because any being from the Real World is rendered unseen by the inhabitants of the Phantom World, like a phantom, and are only capable of becoming visible after drinking a special elixir. After a time, it is revealed that the Phantom World is in fact the true Real World, while the former Real World is called the Dream World, created from the dreams of the people of the Real World, in which each inhabitant has a Dream World counterpart. In addition, the main antagonist of the game, Deathtamoor, plots to try to merge both the Real World and Dream World with his own \"Dark World\" in an attempt for world domination.\n\nIn \"\" and \"Dreamfall Chapters\" the protagonist Zoë Castillo can travel to Marcuria by dreaming. There's a third world called 'Storytime' inspired by the Australian \"Dreamtime\" myths which is the place of the creation and where every story begins and ends. Also, the protagonist must stop a corporation called WATI-Corp which want to steal dreams and memories from people through their new entertainment device: the Dreamachine which allows people to make lucid dreams.\n\nIn \"Final Fantasy VIII\", the main group of protagonists sometimes experience the lives of three soldiers, Laguna, Kiros, and Ward in what they call \"the dream world\" (which is actually the past) through a mysterious and gifted woman who is acquainted with both parties. The whole of Zanarkand in \"Final Fantasy X\" and its HD remake was a dream, along with the main character, Tidus.\n\nIn the video game \"\", there is a short quest which takes place in a dream world. In the video game, \"Fallout 3\", a main storyline quest involves the main character going into a virtual reality simulator, referred to as \"Tranquility Lane,\" a dream world simulation of a 1950s suburban neighborhood. \n\nOther dreamworlds are the Maginaryworld from \"Sonic Shuffle\", Dream Depot from \"Mario Party 5\", and in Nightopia and Nightmare (collectively known in a place called the \"Night Dimension\") from \"Nights into Dreams...\" and its sequel for the Wii, \"\".\n\nIn the video game \"\", main character John Tanner suffers a car accident that leaves him in a coma. The game take places in his dream, but the character himself doesn't realize he's dreaming. Instead, he thinks he had a lucky escape and with this, thinks that he got an ability to possess other people. During the game, many billboards will turn black and show \"wake up\" messages.\n\nIn \"Pokémon Black\" and \"White\" and its following sequel, players can tuck in one of their Pokémon via a system known as Game Sync. As the tucked in Pokémon falls asleep, it will then be sent to special website, where the player can play with his/her Pokémon in an alternate world called the \"Dream World\".\n\nIn \"\", the seventh installment in the game series \"Kingdom Hearts\", the two main protagonists are sent to worlds that are in slumber and that are dreaming in order to pass the Mark of mastery exam.\n\nThe Dream World is the main focus of \"\" where Mario and Luigi travel through a world full of Luigi's dreams.\n\n\"\" takes place in Lunatea, a dream world.\n\n"}
{"id": "2263875", "url": "https://en.wikipedia.org/wiki?curid=2263875", "title": "Ecphonesis", "text": "Ecphonesis\n\nEcphonesis () is an emotional, exclamatory phrase (exclamation) used in poetry, drama, or song. It is a rhetorical device that originated in ancient literature.\n\nA Latin example is \"O tempora! O mores!\" (\"Oh, the times! Oh, the morals!\"). A modern example is \"Young man!\" from the song YMCA by the Village People.\n\nEdgar Allan Poe used ecphonesis in “The Tell-Tale Heart:” \"Almighty God!--no, no! They heard!--they suspected!--they knew!--they were making a mockery of my horror!--this I thought, and this I think. But anything was better than this agony! Anything was more tolerable than this derision! I could bear those hypocritical smiles no longer! I felt that I must scream or die! and now--again!--hark! louder! louder! louder! louder! \"'Villains!' I shrieked, 'dissemble no more! I admit the deed!--tear up the planks! here, here!--It is the beating of his hideous heart!'\"Other examples of ecphonesis include when Homer Simpson said \"No! No-no-no-no-no-no! Well, yes.\" during \"The Simpsons\" episode \"Homer The Heretic,\" and when the Scarecrow said \"Oh joy! Rapture! I got a brain!\" in \"The Wizard of Oz.\"\n\nDonald Trump has used the expressions \"Sad!\" and \"Wrong!\" without elaboration throughout his 2016 presidential campaign.\n\nIn the Eastern Orthodox Church many prayers are recited silently by the priest who \"speaks to God face-to-face\" according to St. Symeon of Thessaloniki. However, the closing words of such prayers are usually chanted aloud, especially at the closing of an ectenia (litany), and those closing words are called an ecphonesis.\n\n\"Examples:\"\n\n"}
{"id": "19806765", "url": "https://en.wikipedia.org/wiki?curid=19806765", "title": "Effets de soir", "text": "Effets de soir\n\nEffets de soir (also called effets desoir or effets de soir et de matin) are the effects of light caused by the sunset, twilight, or darkness of the early evening or matins. They appear frequently in works by such painters as Vincent van Gogh, Bernard Fries, Armand Guillaumin, and Camille Corot. Literally, it means \"effects of evening\" in French.\n\nThis was part of a group of techniques used by Impressionists such as impasto, \"en plein air\", color theory, and thick strokes of oil paint on canvas.\n\nIn 2008, the Museum of Modern Art curated a major exhibit of van Gogh's work of \"effets de soir\".\nThe exhibit included such iconic paintings as \"The Potato Eaters\", \"The Sower (Van Gogh)\", \"Starry Night Over the Rhone\"\"The Starry Night\", and \"The Night Cafe\".\n\n\nAll of the following are by Vincent van Gogh, unless otherwise noted:\n"}
{"id": "4202524", "url": "https://en.wikipedia.org/wiki?curid=4202524", "title": "Epideictic", "text": "Epideictic\n\nThe epideictic oratory, also called ceremonial oratory, or praise-and-blame rhetoric, is one of the three branches, or \"species\" (eidē), of rhetoric as outlined in Aristotle's \"Rhetoric\", to be used to praise or blame during ceremonies.\n\nThe term's root has to do with display or show (\"deixis\"). It is a literary or rhetorical term from the Greek (ἐπιδεικτικός). It is generally pronounced or . Another English form, now less common, is \"epidictic\" .\n\nThis is rhetoric of ceremony, commemoration, declamation, demonstration, on the one hand, and of play, entertainment, display, including self-display. It is also the rhetoric used at festivals, the Olympic games, state visits and other formal events like openings, closings, anniversaries as well as at births, deaths, or marriages. Its major subject is praise and blame, according to Aristotle in the limited space he provides for it in the \"Art of Rhetoric\" (Freese translation). \n\nThis rhetoric deals with goodness, excellence, nobility, shame, honor, dishonor, beauty, and matters of virtue and vice. The virtues or the \"components\" of virtue according to Aristotle, were \"justice, courage, self-control, magnificence, magnanimity, liberality, gentleness, practical and speculative wisdom\" or \"reason\". Vice was the \"contrary\" of virtue. \n\nIn his book \"Rhetoric and Poetics in Antiquity\", Jeffrey Walker claims that epideictic rhetoric predates the rhetoric of courts and politics, the study of which began in the 5th or 4th century BC with the Sophists. The other two kinds of public speech were deliberative or political speech, and forensic, judicial, or legal speech. Epideictic rhetoric or style is according to Aristotle most appropriate for material that is written or read. In the \"Art of Rhetoric\", Aristotle stated that \"The epideictic style is especially suited to written compositions; for its function is reading.\" (423)\n\nAristotle instructs that in creating a speech of praise or blame, the author should consider the attitude of his audience: Will they be moved to see his object of praise (be it a person or a thing) in a new light, or will he be wasting everyone's time by \"preaching to the choir\"? What values and behavior does this particular audience find praiseworthy? Whether the audience is sympathetic, hostile, or indifferent to his object of praise or blame determines how difficult the task is that lies before him. As Aristotle reminds the reader, \"[F]or as Socrates used to say, it is not difficult to praise Athenians in Athens\" (\"Rhetoric\",1367b). \n\nAccording to Aristotle’s conception of epideixis, “the present is the most important; for all speakers praise or blame in regard to existing qualities, but they often make use of other things, both reminding [the audience] of the past and projecting the course of the future” (\"Rhet.\" 1358b). Epideixis is Aristotle’s least favored and clearly defined topic. Now considered to be the stuff of ceremonies with its exhortations, panegyrics, encomia, funeral orations and displays of oratorical prowess, epideictic rhetoric appears to most to be discourse less about depth and more attuned to style without substance. Still, the \"Art of Rhetoric\" is cited as an example of epideictic work (Lockwood, 1996).\n\nEpideixis may not deserve the charge of lacking depth. The charge that this branch of rhetoric lacks depth can be countered by the recognition that it systematizes the successful attribution of value (to things, people, or concepts). Attributing value (whether in terms of \"the good\" and \"the bad\" or of \"virtue\" and \"vice\") to 1) perception, 2) emotions, 3) thought, 4) action, and 5) goals is the fundamental basis of relativistic conceptions of 1) aesthetics, 2) human character, 3) intelligence, 4) ethics, and 5) wisdom. For instance, applying epideixis to 'human perceptions' yields aesthetics, and its application to 'human action' yields fundamental relativistic ethics. Nevertheless, epideixis can always be reduced to simply the study of how best to preach the positive or negative characteristics of creatures, contraptions, concepts (etc.) to an audience. Epideictic rhetoric appeals to - and serves to sway - personal and cultural values, whereas pure deliberative and judicial rhetoric appeal to reason alone.\n\nAnd, Lockwood, also in \"Reader's Figure\", describes how readers are figured by their readings, and how readers figure their readings, and that readers can accept the readers' account, and forget their own account of their present and past, and that the rhetor's account is produced by language.\n\nFor centuries, epideictic oratory was a contested term, for it is clearly present in both forensic and deliberative forms, but it is difficult to clarify when it appears as a dominant discursive form. According to Chaïm Perelman and Lucy Olbrechts-Tyteca, “The speaker engaged in epidictic discourse is very close to being an educator. Since what he is going to say does not arouse controversy, since no immediate practical interest is ever involved, and there is no question of attacking or defending, but simply of promoting values that are shared in the community . . .” (52). \nSome of the defining terms for epideictic discourse include declamation, demonstration, praise or blame of the personal, and pleasing or inspiring to an audience. \n\nLawrence W. Rosenfield contends that epideictic practice surpasses mere praise and blame, and it is more than a showy display of rhetorical skill: “Epideictic’s understanding calls upon us to join with our community in giving thought to what we witness, and such thoughtful beholding in commemoration constitutes memorializing” (133). Epideictic rhetoric also calls for witnessing events, acknowledging temporality and contingency (140). However, as Rosenfield suspects, it is an uncommon form of discourse because of the rarity of “its necessary constituents — openness of mind, felt reverence for reality, enthusiasm for life, the ability to congeal significant experiences in memorable language . . .” (150).\n\nThe philologist Ernst Curtius provides an account of its history, and many examples, in \"European Literature and the Latin Middle Ages\". Praise and blame were \"reduced\" to praise by Aristotle, he wrote; and recently another author called it a \"blameless genre\". He and Lockwood seem to say that what was in the past called rhetoric was later called literature. Curtius believed that misinterpretations of medieval literature occur because so much of it is epideictic, and the epideictic is so alien to us today. During the Middle Ages it became a \"school subject\" as the sites for political activity diminished in the West, and as the centuries went on the word \"praise\" came to mean that which was written. During this period literature (more specifically histories, biographies, autobiographies, geographies) were called praise(s).\n\nBen Witherington III, writing from a biblical perspective on sacred exhortation, noted that \"in general, epideictic rhetoric is highly emotional and meant to inspire the audience to appreciate something or someone, or at the other end of the spectrum, despise something or someone. Epideictic rhetoric seeks to charm or, to cast odium.\" - I & II Thessalonians: A Socio-Rhetorical Commentary \n\nEpideictic writing in poetry is often associated with the \"fu\" rhapsody that developed in the early Han Dynasty. This highly ornamented style was used for almost any subject imaginable, and often incorporated obscure language with extensive cataloguing of rare items, all in verse of varying rhyme and line length.\n\nCommendatory verse is a genre of epideictic writing. In the Renaissance and Early Modern European tradition, it was taken to glorify both its author and the person to whom it was addressed. Prefatory verses of this kind—i.e. those printed as preface to a book—became a recognised type of advertising in the book trade.\n"}
{"id": "1698091", "url": "https://en.wikipedia.org/wiki?curid=1698091", "title": "European studies", "text": "European studies\n\nEuropean studies is a field of study offered by many academic colleges and universities that focuses on current developments in European integration.\n\nSome programmes offer a social science or public administration curriculum focusing on developments in the European Union. These programmes usually include a combination of political science, EU public policy, European history, European law, economics and sociology. Other universities approach the subject in a broader manner, including topics like European culture, European literature and European languages. While all programmes focus on the study of the European Union, they often cover national topics (in a comparative perspective) as well.\n\nThe subject combines humanities and social sciences. Disciplines that are involved in European studies include:\n\nWhile European studies departments are obviously more common in Europe than elsewhere, there are departments dedicated to its study further afield, including in North America, Asia and Australasia.\n\n\n"}
{"id": "175717", "url": "https://en.wikipedia.org/wiki?curid=175717", "title": "Fantasy world", "text": "Fantasy world\n\nA fantasy world is a human conceived world created in fictional media, such as literature, film or games. Typical fantasy worlds involve magic or magical abilities, nonexistent technology and sometimes, either a historical or futuristic theme. Some worlds may be a parallel world connected to Earth via magical portals or items (like Narnia); a fictional Earth set in the remote past or future (like Middle-earth); or an entirely independent world set in another part of the universe (like the Star Wars Galaxy).\n\nMany fantasy worlds draw heavily on real world history, geography, sociology, mythology, and folklore.\n\nThe setting of a fantasy work is often of great importance to the plot and characters of the story. The setting itself can be imperiled by the evil of the story, suffer a calamity, and be restored by the transformation the story brings about. Stories that use the setting as merely a backdrop for the story have been criticized for their failure to use it fully.\n\nEven when the land itself is not in danger, it is often used symbolically, for thematic purposes, and to underscore moods.\n\nEarly fantasy worlds appeared as fantasy \"lands\", part of the same planet but separated by geographical barriers. For example, Oz, though a fantasy world in every way, is described as part of this world.\n\nAlthough medieval peasants who seldom if ever traveled far from their villages could not conclusively say that it was impossible that, for example, an ogre could live a day's travel away, distant continents were necessary from the Renaissance onwards for such fantastic speculation to be plausible, until finally, further exploration rendered all such terrestrial fantasy lands implausible.\n\nEven within the span of mere decades, Oz, which had been situated in a desert in the United States when first written about in 1900, was relocated to a spot in the Pacific Ocean.\n\nAn early example of the fantasy land/world concept can be seen in the \"One Thousand and One Nights\" (\"Arabian Nights\"), where places of which little was known, but where the occurrence of marvels was thus more credible, had to be set \"long ago\" or \"far away\". This is a process that continues, and finally culminates in the fantasy world having little connection, if any, to actual times and places. A more recent example of a fantasy land with definite connections to the actual world is Austin Tappan Wright's Islandia. Islandia's remoteness and aura of mystery, as well as its preservation of an arcadian society, are explained by means of a law which allows only limited contact with foreigners.\n\nDream frames were also once common for encasing the fantasy world with an explanation of its marvels. Such a dream frame was added to the story of \"The Wonderful Wizard of Oz\" for the movie version; in the book, Oz is clearly defined as an actual place. H.P. Lovecraft made active use of the dream frame, creating elaborate geographies accessible to humans only when they were asleep and dreaming. These dream-settings have been criticized, and are far less frequent today.\n\nThis change is part of a general trend toward more self-consistent and substantive fantasy worlds. This has also altered the nature of the plots; earlier works often feature a solitary individual whose adventures in the fantasy world are of personal significance, and where the world clearly exists to give scope to these adventures, and later works more often feature characters in a social web, where their actions are to save the world and those in it from peril.\n\nThe most common fantasy world is one based on medieval Europe, and has been since William Morris used it in his early fantasy works, such as \"The Well at the World's End\". and particularly since the 1954 publication of J.R.R. Tolkien's \"The Lord of the Rings\". Such a world is often called \"pseudo-medieval\"—particularly when the writer has snatched up random elements from the era, which covered a thousand years and a continent, and thrown them together without consideration for their compatibility, or even introduced ideas not so much based on the medieval era as on romanticized views of it. When these worlds are copied not so much from history as from other fantasy works, there is a heavy tendency to uniformity and lack of realism. The full width and breadth of the medieval era is seldom drawn upon. Governments, for instance, tend to be uncompromisingly feudal-based, or evil empires or oligarchies, usually corrupt, while there was far more variety of rule in the actual Middle Ages. Fantasy worlds also tend to be medieval in economy, and disproportionately pastoral.\n\nCareful world-building plus meticulous attention to detail is often cited as the reason why certain fantasy works are deeply convincing and contain a magical sense of place.\nHeavy and faithful use of real world setting for inspiration, as in Barry Hughart's \"Bridge of Birds\", clearly derived from China, or Lloyd Alexander's use of real world cultures such as Welsh for \"The Chronicles of Prydain\" or Indian for \"The Iron Ring\", make the line between fantasy worlds and alternate histories fuzzy. The use of cultural elements, and still more history and geography, from actual settings pushes a work toward alternative history.\n\nConversely, the creation by an author of an imaginary country—such as Ruritania or Graustark—does not automatically transform that imaginary country into a fantasy world, even if the location would be impossible in reality owing to a lack of land to contain it; but such Ruritanian romances may be pushed toward the category of fantasy worlds by the introduction of, say, witches and wise women, where it is not clear if their magic is effectual.\n\nAccording to Lin Carter in \"Imaginary Worlds: the Art of Fantasy\", fantasy worlds, by their nature, contain some element of magic (paranormal). This element may be the creatures in it (dragons, unicorns, genies and so on) or the magical abilities of the people inhabiting the world. These are often drawn from mythology and folklore, frequently that of the historical country also used for inspiration.\n\nFantasy worlds created through a process called world building are known as a constructed world. Constructed worlds elaborate and make self-consistent the setting of a fantasy work. World building often relies on materials and concepts taken from the real world.\n\nDespite the use of magic or other fantastic elements such as dragons, the world is normally presented as one that would function normally, one in which people could actually live, making economic, historical, and ecological sense. It is considered a flaw to have, for example, pirates living in lands far from trade routes, or to assign prices for a night's stay in an inn that would equate to several years’ income.\n\nFurthermore, the fantastic elements should ideally operate according to self-consistent rules of their own; for example, if wizards' spells sap their strength, a wizard who does not appear to suffer this must either be putting up a facade, or have an alternative explanation. This distinguishes fantasy worlds from surrealism and even from such dream worlds as are found in \"Alice's Adventures in Wonderland\" and \"Through the Looking-Glass\".\n\n\nFairytale fantasy may ignore the normal world-building in order to present a world operating by the same logic as the fairytales from which they are derived, though other works in this subgenre develop their worlds fully. Comic fantasy may ignore all possible logic in search of humor, particularly if it is parodying other fantasies' faulty world-building, as in Diana Wynne Jones's \"Dark Lord of Derkholm\", or the illogic of the setting is integral to the comedy, as in L. Sprague de Camp's \"Solomon's Stone\", where the fantasy world is populated by the heroic and glamorous figures that people daydream about being, resulting in a severe shortage of workers in the more mundane, day-to-day industries. Most other subgenres of fantasy suffer if the world-building is neglected.\n\nRather than creating their own fantasy world, many authors choose to set their novels in Earth's past. In order to explain the absence of miraculous elements, authors may introduce \"a retreat of magic\" (sometimes called \"thinning\") that explains why the magic and other fantastic elements no longer appear: For example, in \"The Lord of the Rings\", the destruction of the One Ring defeated Sauron, but also destroyed the power of the Three Rings of the elves, resulting in them sailing to the West at the end of the story. A contemporary fantasy necessarily takes place in what purports to be the real world, and not a fantasy world. It may, however, include references to such a retreat. J. K. Rowling's \"Fantastic Beasts and Where to Find Them\" explains that wizards eventually decided to conceal all magic creatures and artifacts from non-magic users.\n\n\"Dungeons & Dragons\", the first major role-playing game, has created several detailed and commercially successful fantasy worlds (called \"campaign settings\"), with established characters, locations, histories, and sociologies. The Forgotten Realms is perhaps the most extensively developed of these worlds. These elements of detail can be a large part of what attracts people to RPGs.\n\nMany established fantasy writers have also derided \"Dungeons and Dragons\" and the fantasy fiction it has inspired due to its influencing new writers toward reading the \"Dungeons & Dragons Monster Manual\" instead of studying the original literature and mythology from which modern fantasy literature has sprung.\n\nDue to the fuzzy boundary between fantasy and science fiction, it is similarly difficult to make a hard-and-fast distinction between \"fantasy worlds\" and planets in science fiction. For example, the worlds of Barsoom, Darkover, Gor, and the Witch World combine elements of both genres.\n\n\n"}
{"id": "912426", "url": "https://en.wikipedia.org/wiki?curid=912426", "title": "Folk etymology", "text": "Folk etymology\n\nFolk etymology or reanalysis – sometimes called pseudo-etymology, popular etymology, or analogical reformation – is a change in a word or phrase resulting from the replacement of an unfamiliar form by a more familiar one. The form or the meaning of an archaic, foreign, or otherwise unfamiliar word is reanalyzed as resembling more familiar words or morphemes. Rebracketing is a form of folk etymology in which a word is broken down or \"bracketed\" into a new set of supposed elements. Back-formation, creating a new word by removing or changing parts of an existing word, is often based on folk etymology.\n\nThe term \"folk etymology\" is a loan translation from German Volksetymologie, coined by Ernst Förstemann in 1852. Folk etymology is a productive process in historical linguistics, language change, and social interaction. Reanalysis of a word's history or original form can affect its spelling, pronunciation, or meaning. This is frequently seen in relation to loanwords or words that have become archaic or obsolete.\n\nExamples of words created or changed through folk etymology include the English dialectal form \"sparrowgrass\", originally from Greek (\"asparagus\") remade by analogy to the more familiar words \"sparrow\" and \"grass\", or the word \"burger\", originally from \"Hamburg\" + \"-er\" (\"thing connected with\"), but understood as \"ham\" + \"burger\".\n\nThe technical term \"folk etymology\" refers to a change in the form of a word caused by erroneous popular beliefs about its etymology. The English word is a translation of the German term \"Volksetymologie\", coined by Ernst Förstemann. Förstemann noted that in addition to scientific etymology based on careful study in philology, there exist scholarly but often unsystematic accounts, as well as popular accounts for the history of linguistic forms. Until academic linguists developed comparative philology and described the laws underlying sound changes, the derivation of words was a matter mostly of guess-work. Speculation about the original form of words in turn feeds back into the development of the word and thus becomes a part of a new etymology.\n\nBelieving a word to have a certain origin, people begin to pronounce, spell, or otherwise use the word in a manner appropriate to that perceived origin. This popular etymologizing has had a powerful influence on the forms which words take. Examples in English include \"crayfish\" or \"crawfish\", which are not historically related to \"fish\" but come from Middle English \"crevis\", cognate with French \"écrevisse\". Likewise \"chaise lounge\", from the original French \"chaise longue\" (\"long chair\"), has come to be associated with the word \"lounge\".\n\nRebracketing is a process of language change in which parts of a word that appear to be meaningful (such as *\"ham\" in \"hamburger\") are mistaken as elements of the word's etymology (in this case, the word \"ham\"). Rebracketing functions by reanalyzing the constituent parts of a word. For example, the Old French word \"orenge\" (\"orange tree\") comes from Arabic \"an nāranj\" (\"the orange tree\"), with the initial \"n\" of \"nāranj\" understood as part of the article.\n\nIn back-formation a new word is created, often by removing elements thought to be affixes. For example, Italian \"pronuncia\" (\"pronunciation; accent\") is derived from the verb \"pronunciare\" (\"to pronounce; to utter\") and English \"edit\" derives from \"editor\". Some cases of back-formation are based on folk etymology.\n\nIn linguistic change caused by folk etymology, the form of a word changes so that it better matches its popular rationalisation. Typically this happens either to unanalyzable foreign words or to compounds where the word underlying one part of the compound becomes obsolete.\n\nThere are many examples of words borrowed from foreign languages, and subsequently changed by folk etymology.\n\nThe spelling of many borrowed words reflects folk etymology. For example, \"\" borrowed from Old French was variously spelled \"aundyre\" or \"aundiren\" in Middle English, but was altered by association with \"iron\". Other Old French loans altered in a similar manner include \"belfry\" (from \"berfrei\") by association with \"bell\", \"female\" (from \"femelle\") by \"male\", and \"penthouse\" (from \"apentis\") by \"house\". The variant spelling of \"licorice\" as \"liquorice\" comes from the supposition that it has something to do with liquid. Anglo-Norman \"licoris\" (influenced by \"licor\" \"liquor\") and Late Latin \"liquirītia\" were respelled for similar reasons, though the ultimate origin of all three is Greek \"\" (glycyrrhiza) \"sweet root\".\n\nReanalysis of loan words can affect their spelling, pronunciation, or meaning. The word \"cockroach\", for example, was borrowed from Spanish \"cucaracha\" but was assimilated to the existing English words \"cock\" and \"roach\". \"Jerusalem artichoke\", from Italian \"girasole\", is a kind of sunflower; it is not related to artichokes and does not come from Jerusalem. The phrase \"forlorn hope\" originally meant \"storming party, body of skirmishers\" from Dutch \"verloren hoop\" \"lost troop\". But confusion with English \"hope\" has given the term an additional meaning of \"hopeless venture\".\n\nSometimes imaginative stories are created to account for the link between a borrowed word and its popularly assumed sources. The names of the \"serviceberry\", \"service tree\", and related plants, for instance, come from the Latin name \"sorbus\". The plants were called \"syrfe\" in Old English, which eventually became \"service\". Fanciful stories suggest that the name comes from the fact that the trees bloom in spring, a time when circuit-riding preachers resume church services or when funeral services are carried out for people who died during the winter.\n\nA seemingly plausible but no less speculative etymology accounts for the form of \"Welsh rarebit\", a dish made of cheese and toasted bread. The earliest known reference to the dish in 1725 called it \"Welsh rabbit\". The origin of that name is unknown, but presumably humorous, since the dish contains no rabbit. In 1785 Francis Grose suggested in \"A Classical Dictionary of the Vulgar Tongue\" that the dish is \"a Welch rare bit\", though the word \"rarebit\" was not common prior to Grose's dictionary. Both versions of the name are in current use; individuals sometimes express strong opinions concerning which version is correct.\n\nWhen a word or other form becomes obsolete, words or phrases containing the obsolete portion may be reanalyzed and changed.\n\nSome compound words from Old English were reanalyzed in Middle or Modern English when one of the constituent words fell out of use. Examples include \"bridegroom\" from Old English \"brydguma\" \"bride-man\". The word \"gome\" \"man\" from Old English \"guma\" fell out of use during the sixteenth century and the compound was eventually reanalyzed with the Modern English word \"groom\" \"male servant\". A similar reanalysis caused \"sandblind\", from Old English \"sāmblind\" \"half-blind\" with a once-common prefix \"sām-\" \"semi-\", to be respelled as though it is related to \"sand\". The word \"island\" derives from Old English \"igland\". The modern spelling with the letter \"s\" is the result of comparison with the synonym \"isle\" from Old French and ultimately Latin \"insula\", though the Old French and Old English words are not historically related. In a similar way, the spelling of \"wormwood\" was likely affected by comparison with \"wood\".\n\nThe phrase \"curry favour\", meaning to flatter, comes from Middle English \"curry favel\", \"groom a chestnut horse\". This was an allusion to a fourteenth century French morality poem, \"Roman de Fauvel\", about a chestnut-colored horse who corrupts men through duplicity. The phrase was reanalyzed in early Modern English by comparison to \"favour\" as early as 1510.\n\nWords need not completely disappear before their compounds are reanalyzed. The word \"shamefaced\" was originally \"shamefast\". The original meaning of \"fast\" \"fixed in place\" still exists but mainly in frozen expressions such as \"stuck fast\", \"hold fast\", and \"play fast and loose\". The songbird \"wheatear\" or \"white-ear\" is a back-formation from Middle English \"whit-ers\" \"white arse\", referring to the prominent white rump found in most species. Although both \"white\" and \"arse\" are common in Modern English, the folk etymology may be euphemism.\n\nReanalysis of archaic or obsolete forms can lead to changes in meaning as well. The original meaning of \"hangnail\" referred to a corn on the foot. The word comes from Old English \"ang-\" + \"nægel\" (\"anguished nail\" or \"compressed spike\"), but the spelling and pronunciation were affected by folk etymology in the seventeenth century or earlier. Thereafter, the word came to be used for a tag of skin or torn cuticle near a fingernail or toenail.\n\nSeveral words in Medieval Latin were subject to folk etymology. For example, the word \"widerdonum\" meaning \"reward\" was borrowed from Old High German \"widarlōn\" \"repayment of a loan\". The \"l→d\" alteration is due to confusion with Latin \"donum\" \"gift\". Similarly, the word \"baceler\" or \"bacheler\" (related to modern English \"bachelor\") referred to a junior knight. It is attested from the eleventh century, though its ultimate origin is uncertain. By the late Middle Ages its meaning was extended to the holder of a university degree inferior to master or doctor. This was later re-spelled \"baccalaureus\", probably reflecting a false derivation from \"bacca laurea\" \"laurel berry\", alluding to the possible laurel crown of a poet or conqueror.\n\nIn the fourteenth or fifteenth century French scholars began to spell the verb \"savoir\" (\"to know\") as \"sçavoir\" on the false belief it was derived from Latin \"scire\" \"to know\". In fact it comes from \"sapere\" \"to be wise\".\n\nThe Italian word \"liocorno\" \"unicorn\" derives from 13th century \"lunicorno\" (\"lo\" \"the\" + \"unicorno\" \"unicorn\"). Folk etymology based on \"lione\" \"lion\" altered the spelling and pronunciation. Dialectal \"liofante\" \"elephant\" was likewise altered from \"elefante\" by association with \"lione\".\n\nThe Dutch word for \"hammock\" is \"hangmat\". It was borrowed from Spanish \"hamaca\" (ultimately from Arawak \"amàca\") and altered by comparison with \"hangen\" and \"mat\", \"hanging mat\". German \"Hängematte\" shares this folk etymology.\n\nThe Finnish compound word for \"jealous\" \"mustasukkainen\" literally means \"black-socked\" (\"musta\" \"black\" and \"sukka\" \"sock\"). However, the word is a case of a misunderstood loan translation from Swedish \"svartsjuk\" \"black-sick\". The Finnish word \"sukka\" fit with a close phonological equivalent to the Swedish \"sjuk\"\n\"Islambol\", a folk etymology meaning \"full of Islam\", is one of the names of Istanbul used after the Ottoman conquest of 1453.\n\nAn example from Persian is the word shatranj (chess), which is derived from the Sanskrit chaturanga (2nd century BCE), and after losing the \"u\" to syncope, becomes \"chatrang\" in Middle Persian (6th century CE). Today it is sometimes factorized as \"shat\" (hundred) + \"ranj\" (worry / mood), or \"a hundred worries\".\n\n"}
{"id": "45229950", "url": "https://en.wikipedia.org/wiki?curid=45229950", "title": "Found in collection", "text": "Found in collection\n\n\"Found in collection\" or FIC is a term used by a museum to refer to \"undocumented objects that remain without status after all attempts to reconcile them to existing records of permanent collection and loan objets are completed\". Despite the best efforts of museum staff, museums often have FIC items. This term was developed so that collections with incomplete provenance would be handled ethically and with transparency. Depending on the paperwork and information accompanying the material, the museum has several choices in how to proceed.\n\nMuseums today are meticulous about the documentation they keep when accessioning new items into their collections. However, this was not always the case. As the museum field professionalized so did the standard of paperwork required to accession a collection. Items can become FIC artifacts if records were not kept initially or if the documentation regarding the property transfer was lost in a disaster such as a fire or flood. Additionally, if the museum is old, it has decades of accessioning paperwork that may require its own preservation plan.\n\nFIC collections can also be the result of long-term or permanent loans where contact has lapsed between the two parties. It is for this reason that most museums now renew their loans on an annual basis.\n\n\nMuseums require three pieces of information to accession a collection. \n\nThe most common way this is achieved is through a Deed of Gift, which states these three criteria in one document\n\nPlease seek professional legal advice when dealing with FIC materials. Regardless of whether or not the museum wishes to retain ownership of the item, if possible the collections staff should contact the previous owner to either obtain a deed of gift or return the collection.\n\nIn order to keep track of the FIC collection, a temporary number should be assigned that is completely different in format from the museum's accession number to avoid further confusion. Whether the item is to be accessioned or deaccessioned, it requires establishing a chain of custody, which can be started with the application of a temporary number and assemblage of any associated documentation.\n\nIt should try to obtain ownership by following its state's unclaimed property laws or applicable international conventions. If during the found property process a claimant wishes to challenge the museum's tie to the collection, the claimant must support their case with evidential paperwork. \nIf the museum does not want to keep the artifacts due to them being irrelevant to its mission or outside of its collecting scope, it has several options. If the museum can contact the previous owner or heirs it should do so and return the collection. If the collection has no associated paperwork, the museum should follow the appropriate laws and conventions. Once it establishes ownership through that process the museum can legally and ethically follow its deaccession procedures. This may involve transfer the collection to another cultural institution, selling the collection at public auction, or if all other methods fail, destruction of the collection.\n\nThe 1970 UNESCO Convention was created to provide a platform and environment in which countries could discuss situations in which cultural property may have been illegally transported. Throughout history cultural property has been taken as the spoils of war or trafficked by desperate individuals in order to make a profit. For this reason museums may have to consider the 1970 UNESCO convention on the Means of Prohibiting and Preventing the Illicit Import, Export, and Transfer of Ownership of Cultural Property when sifting through FIC collections. It is important to pay particularly close attention to documentation of items that may have been acquired from conflict zones as sometimes customs forms and bills of sale are faked.\n\nThe Antiquities Act of 1906, signed by Theodore Roosevelt, was the first federal law enacted in response to a growing concern regarding the protection of cultural property. The law stated that antiquities could not be removed or damaged on federal property without the express permission of the government. While not completely enforced in its day, it did set a precedent for caring for national cultural property.\n\nThe Archaeological Resources Protection Act (ARPA) was a much needed upgrade to the 1906 Antiquities Act. It updated definitions to close loopholes and increased fines and penalties for violators. If museums have FIC collections that may have been obtained in violation of the 1906 and 1979 legislation, they should seek legal advice and follow the provisions in the Acts.\n\nThe Native American Graves Protection Act (NAGPRA) was signed into law in 1990 to specifically to \"affirm the rights of lineal descendants, Indian tribes, and Native Hawaiian organizations to custody of Native American human remains, funerary objects, sacred objects, and objects of cultural patrimony that are in the control of federal agencies and museums\". Unfortunately throughout the history of the United States, Native American cultural property and even human remains were not acquired with the consent, let alone documentation. Because of this, Native American and Native Hawaiian artifacts are often FIC. In trying to resolve these culturally sensitive FIC items, NAGPRA legislation should be followed.\n\nWhile most unclaimed property laws refer to unclaimed finances, the procedures regarding artifacts are similar. \n\n"}
{"id": "58902810", "url": "https://en.wikipedia.org/wiki?curid=58902810", "title": "Harry Underwood", "text": "Harry Underwood\n\nHarry Underwood (1969) is a painter known for his use of stenciled images and literary elements atop wood panels. His pictures are painted with house paints and written upon with ordinary No. 2 pencils. His subjects are an eclectic mix of realism, surrealism, pop art and invention.\n\nHarry has been labelled an outsider artist, a pop artist, and a folk artist. However, unlike most folk artists, his paintings are carefully planned often taking months prior to their execution. One critic said of the detailed planning that goes into Harry's work that \"what results is more a cocktail of realism, surrealism, and pop, of Edward Hopper meets Salvador Dali meets Andy Warhol.\" \n\nHe is popularly known by his first name \"Harry\", and distinctively signs his paintings with this moniker.\n\nHarry Underwood was born in 1969 in Miami, FL. His father was a carpenter and his mother worked in a supermarket. His family was deeply religious and he attended the Church of God pentecostal church with them until 1982.\n\nAs a teenager, Harry cleaned pools at motels and bussed tables at the Capri Italian Restaurant in Florida City, FL. He was uprooted by Hurricane Andrew in 1992 and spent time in Austin, TX and New Orleans, LA before settling in Nashville, TN where he found work in the construction industry. He began painting in the early 2000s while working as a flooring installer.\n\nHarry's work is infused with romanticism and an undercurrent of nostalgia for a life not necessarily experienced, but wished for. Repeated images flesh out his work; bathing beauties, motel pools, vintage cars, commercial signs, palm trees, old bicycles, and dancing couples. There is a sense of mid-twentieth century Americana in his works which evokes nostalgia or longing for the vacation one never got to take, or the life one might have lived in the past, with touches of irony and commercialization that relate to the present.\n\nHarry first started painting in the early 2000s while working as a flooring installer and house painter in Nashville, TN. He discovered his color palette while going through half-used paint cans in the garage of a house at which he was working.\n\nHis first major solo show was titled \"A Pictorial History of Wishful Thinking\" and hosted by the Estel Gallery in Nashville, TN in 2007. Since then, his work has been exhibited at numerous leading galleries and institutions across the United States, United Kingdom, and France.\n\nThough labeled an outsider artist, Harry avoids the term. When asked about it once by a University of North Carolina (Wilmington) researcher, he answered \"I don’t think of that label as having anything to do with my vision or how I approach work each day. I don’t consider myself part of a movement. I wasn’t aware of artists like Darger or Edward Hopper until I was meeting people at my shows and they began telling me I reminded them of all that. Persistence is what making art is about. The world is designed to wreck your imagination. I don’t expect I’ll be tied to folk art forever. It wouldn’t be bad if I was. A friend recently called it “Americana,” and I kind of like that.\" \n\n\n"}
{"id": "27884838", "url": "https://en.wikipedia.org/wiki?curid=27884838", "title": "High comedy", "text": "High comedy\n\nHigh comedy or pure comedy is a type of comedy characterized by witty dialogue, satire, biting humor, or criticism of life.\n\nToday, high comedy can be seen among sitcoms and talk shows targeted at cultured and articulate audiences. Examples of high comedy include Arrested Development (TV series), The Simpsons, The Marx Brothers, Woody Allen, Seinfeld, The Larry Sanders Show and The Office (UK TV series).\n\n"}
{"id": "1676362", "url": "https://en.wikipedia.org/wiki?curid=1676362", "title": "History of anthropology", "text": "History of anthropology\n\nHistory of anthropology'scientific word during the Renaissance, has always meant \"the study (or science) of man\". The topics to be included and the terminology have varied historically. At present they are more elaborate than they were during the development of anthropology. For a presentation of modern social and cultural anthropology as they have developed in Britain, France, and North America since approximately 1900, see the relevant sections under Anthropology.\n\nThe term \"anthropology\" ostensibly is a produced compound of Greek \"anthrōpos\", \"human being\" (understood to mean \"humankind\" or \"humanity\"), and a supposed -λογία \"-logia\", \"study\". The compound, however, is unknown in ancient Greek or Latin, whether classical or mediaeval. It first appears sporadically in the scholarly Latin \"anthropologia\" of Renaissance France, where it spawns the French word \"anthropologie\", transferred into English as anthropology. It does belong to a class of words produced with the -logy suffix, such as archeo-logy, bio-logy, etc., \"the study (or science) of\".\n\nThe mixed character of Greek \"anthropos\" and Latin \"-logia\" marks it as New Latin. There is no independent noun, logia, however, of that meaning in classical Greek. The word λόγος (logos) has that meaning. James Hunt attempted to rescue the etymology in his first address to the Anthropological Society of London as president and founder, 1863. He did find an \"anthropologos\" from Aristotle in the standard ancient Greek Lexicon, which he says defines the word as \"speaking or treating of man\". This view is entirely wishful thinking, as Liddell and Scott go on to explain the meaning: \"i.e. fond of personal conversation\". If Aristotle, the very philosopher of the logos, could produce such a word without serious intent, there probably was at that time no anthropology identifiable under that name.\n\nThe lack of any ancient denotation of anthropology, however, is not an etymological problem. Liddell and Scott list 170 Greek compounds ending in \"–logia\", enough to justify its later use as a productive suffix. The ancient Greeks often used suffixes in forming compounds that had no independent variant. The etymological dictionaries are united in attributing \"–logia\" to \"logos\", from \"legein\", \"to collect\". The thing collected is primarily ideas, especially in speech. The American Heritage Dictionary says: \"(It is one of) derivatives independently built to logos.\" Its morphological type is that of an abstract noun: log-os > log-ia (a \"qualitative abstract\")\n\nThe Renaissance origin of the name of anthropology does not exclude the possibility that ancient authors presented anthropogical material under another name (see below). Such an identification is speculative, depending on the theorist's view of anthropology; nevertheless, speculations have been formulated by credible anthropologists, especially those that consider themselves functionalists and others in history so classified now.\n\nMarvin Harris, a historian of anthropology, begins \"The Rise of Anthropological Theory\" with the statement that anthropology is \"the science of history\". He is not suggesting that history be renamed to anthropology, or that there is no distinction between history and prehistory, or that anthropology excludes current social practices, as the general meaning of history, which it has in \"history of anthropology\", would seem to imply. He is using \"history\" in a special sense, as the founders of cultural anthropology used it: \"the natural history of society\", in the words of Herbert Spencer, or the \"universal history of mankind\", the 18th-century Age of Enlightenment objective. Just as natural history comprises the characteristics of organisms past and present, so cultural or social history comprises the characteristics of society past and present. It includes both documented history and prehistory, but its slant is toward institutional development rather than particular non-repeatable historical events.\n\nAccording to Harris, the 19th-century anthropologists were theorizing under the presumption that the development of society followed some sort of laws. He decries the loss of that view in the 20th century by the denial that any laws are discernable or that current institutions have any bearing on ancient. He coins the term ideographic for them. The 19th-century views, on the other hand, are nomothetic; that is, they provide laws. He intends \"to reassert the methodological priority of the search for the laws of history in the science of man\". He is looking for \"a general theory of history\". His perception of the laws: \"I believe that the analogue of the Darwinian strategy in the realm of sociocultural phenomena is the principle of techno-environmental and techno-economic determinism\", he calls cultural materialism, which he also details in \"Cultural Materialism: The Struggle for a Science of Culture.\"\n\nElsewhere he refers to \"my theories of historical determinism\", defining the latter: \"By a deterministic relationship among cultural phenomena, I mean merely that similar variables under similar conditions tend to give rise to similar consequences.\" The use of \"tends to\" implies some degree of freedom to happen or not happen, but in strict determinism, given certain causes, the result and only that result must occur. Different philosophers, however, use determinism in different senses. The deterministic element that Harris sees is lack of human social engineering: \"free will and moral choice have had virtually no significant effect upon the direction taken thus far by evolving systems of social life.\"\n\nHarris agrees with the 19th-century view that laws are abstractions from empirical evidence: \"...sociocultural entities are constructed from the direct or indirect observation of the behavior and thought of specific individuals ...\" Institutions are not a physical reality; only people are. When they act in society, they do so according to the laws of history, of which they are not aware; hence, there is no historical element of free will. Like the 20th-century anthropologists in general, Harris places a high value on the empiricism, or collection of data. This function must be performed by trained observers.\n\nHe borrows terms from linguistics: just as a phon-etic system is a description of sounds developed without regard to the meaning and structure of the language, while a phon-emic system describes the meaningful sounds actually used within the language, so anthropological data can be emic and etic. Only trained observers can avoid eticism, or description without regard to the meaning in the culture: \"... etics are in part observers' emics incorrectly applied to a foreign system...\" He makes a further distinction between synchronic and diachronic. Synchronic (\"same time\") with reference to anthropological data is contemporaneous and cross-cultural. Diachronic (\"through time\") data shows the development of lines through time. Cultural materialism, being a \"processually holistic and globally comparative scientific research strategy\" must depend for accuracy on all four types of data. Cultural materialism differs from the others by the insertion of culture as the effect. Different material factors produce different cultures.\n\nHarris, like many other anthropologists, in looking for anthropological method and data before the use of the term anthropology, had little difficulty finding them among the ancient authors. The ancients tended to see players on the stage of history as ethnic groups characterized by the same or similar languages and customs: the Persians, the Germans, the Scythians, etc. Thus the term history meant to a large degree the \"story\" of the fortunes of these players through time. The ancient authors never formulated laws. Apart from a rudimentary three-age system, the stages of history, such as are found in Lubbock, Tylor, Morgan, Marx and others, are yet unformulated.\n\nEriksen and Nielsen use the term proto-anthropology to refer to near-anthropological writings, which contain some of the criteria for being anthropology, but not all. They classify proto-anthropology as being \"travel writing or social philosophy\", going on to assert \"It is only when these aspects ... are fused, that is, when data and theory are brought together, that anthropology appears.\" This process began to occur in the 18th century of the Age of Enlightenment.\n\nMany anthropological writers find anthropological-quality theorizing in the works of Classical Greece and Classical Rome; for example, John Myres in \"Herodotus and Anthropology\" (1908); E. E. Sikes in \"The Anthropology of the Greeks\" (1914); Clyde Kluckhohn in \"Anthropology and the Classics\" (1961), and many others. An equally long list may be found in French and German as well as other languages.\n\nHerodotus was a 5th-century BC Greek historian who set about to chronicle and explain the Greco-Persian Wars that transpired early in that century. He did so in a surviving work conventionally termed \"the History\" or \"the Histories\". His first line begins: \"These are the researches of Herodotus of Halicarnassus ...\"\n\nThe Achaemenid Empire, deciding to bring Greece into its domain, conducted a massive invasion across the Bosphorus using multi-cultural troops raised from many different locations. They were decisively defeated by the Greek city-states. Herodotus was far from interested in only the non-repeatable events. He provides ethnic details and histories of the peoples within the empire and to the north of it, in most cases being the first to do so. His methods were reading accounts, interviewing witnesses, and in some cases taking notes for himself.\n\nThese \"researches\" have been considered anthropological since at least as early as the late 19th century. The title, \"Father of History\" (\"pater historiae\"), had been conferred on him probably by Cicero. Pointing out that John Myres in 1908 had believed that Herodotus was an anthropologist on a par with those of his own day, James M. Redfield asserts: \"Herodotus, as we know, was both Father of History and Father of Anthropology.\" Herodotus calls his method of travelling around taking notes \"theorizing\". Redfield translates it as \"tourism\" with a scientific intent. He identifies three terms of Herodotus as overlapping on culture: \"diaitia\", material goods such as houses and consumables; \"ethea\", the mores or customs; and \"nomoi\", the authoritative precedents or laws.\n\nThe Roman historian, Tacitus, wrote many of our only surviving contemporary accounts of several ancient Celtic and Germanic peoples.\n\nAnother candidate for one of the first scholars to carry out comparative ethnographic-type studies in person was the medieval Persian scholar Abū Rayhān Bīrūnī in the eleventh century, who wrote about the peoples, customs, and religions of the Indian subcontinent. According to Akbar S. Ahmed, like modern anthropologists, he engaged in extensive participant observation with a given group of people, learnt their language and studied their primary texts, and presented his findings with objectivity and neutrality using cross-cultural comparisons. Others argue, however, that he hardly can be considered an anthropologist in the conventional sense. He wrote detailed comparative studies on the religions and cultures in the Middle East, Mediterranean, and especially South Asia. Biruni's tradition of comparative cross-cultural study continued in the Muslim world through to Ibn Khaldun's work in the fourteenth century.\n\nMedieval scholars may be considered forerunners of modern anthropology as well, insofar as they conducted or wrote detailed studies of the customs of peoples considered \"different\" from themselves in terms of geography. John of Plano Carpini reported of his stay among the Mongols. His report was unusual in its detailed depiction of a non-European culture.\n\nMarco Polo's systematic observations of nature, anthropology, and geography are another example of studying human variation across space. Polo's travels took him across such a diverse human landscape and his accounts of the peoples he met as he journeyed were so detailed that they earned for Polo the name \"the father of modern anthropology\".\n\nThe first use of the term \"anthropology\" in English to refer to a natural science of humanity was apparently in Richard Harvey's 1593 \"Philadelphus, a defense of the legend of Brutus in British history\", which, includes the passage: \"Genealogy or issue which they had, Artes which they studied, Actes which they did. This part of History is named Anthropology.\"\n\nMany scholars consider modern anthropology as an outgrowth of the Age of Enlightenment (1715–89), a period when Europeans attempted to study human behavior systematically, the known varieties of which had been increasing since the fifteenth century as a result of the first European colonization wave. The traditions of jurisprudence, history, philology, and sociology then evolved into something more closely resembling the modern views of these disciplines and informed the development of the social sciences, of which anthropology was a part.\n\nIt took Immanuel Kant (1724-1804) 25 years to write one of the first major treatises on anthropology, \"Anthropology from a Pragmatic Point of View\" (1798), which treats it as a branch of philosophy. Kant is not generally considered to be a modern anthropologist, as he never left his region of Germany, nor did he study any cultures besides his own. He did, however, begin teaching an annual course in anthropology in 1772.\nDevelopments in the systematic study of ancient civilizations through the disciplines of Classics and Egyptology informed both archaeology and eventually social anthropology, as did the study of East and South Asian languages and cultures. At the same time, the Romantic reaction to the Enlightenment produced thinkers, such as Johann Gottfried Herder and later Wilhelm Dilthey, whose work formed the basis for the \"culture concept\", which is central to the discipline.\n\nInstitutionally, anthropology emerged from the development of natural history (expounded by authors such as Buffon) that occurred during the European colonization of the seventeenth, eighteenth, nineteenth and twentieth centuries. Programs of ethnographic study originated in this era as the study of the \"human primitives\" overseen by colonial administrations.\n\nThere was a tendency in late eighteenth century Enlightenment thought to understand human society as natural phenomena that behaved according to certain principles and that could be observed empirically. In some ways, studying the language, culture, physiology, and artifacts of European colonies was not unlike studying the flora and fauna of those places.\n\nEarly anthropology was divided between proponents of unilinealism, who argued that all societies passed through a single evolutionary process, from the most primitive to the most advanced, and various forms of non-lineal theorists, who tended to subscribe to ideas such as diffusionism. Most nineteenth-century social theorists, including anthropologists, viewed non-European societies as windows onto the pre-industrial human past.\n\nMarxist anthropologist Eric Wolf once characterized anthropology as \"the most scientific of the humanities, and the most humanistic of the social sciences\". Understanding how anthropology developed contributes to understanding how it fits into other academic disciplines.\nScholarly traditions of jurisprudence, history, philology and sociology developed during this time and informed the development of the social sciences of which anthropology was a part. At the same time, the Romantic reaction to the Enlightenment produced thinkers such as Herder and later Wilhelm Dilthey whose work formed the basis for the culture concept which is central to the discipline.\n\nThese intellectual movements in part grappled with one of the greatest paradoxes of modernity: as the world is becoming smaller and more integrated, people's experience of the world is increasingly atomized and dispersed. As Karl Marx and Friedrich Engels observed in the 1840s:\n\nIronically, this universal interdependence, rather than leading to greater human solidarity, has coincided with increasing racial, ethnic, religious, and class divisions, and new—and to some confusing or disturbing—cultural expressions. These are the conditions of life with which people today must contend, but they have their origins in processes that began in the 16th century and accelerated in the 19th century.\n\nInstitutionally anthropology emerged from natural history (expounded by authors such as Buffon). This was the study of human beings—typically people living in European colonies. Thus studying the language, culture, physiology, and artifacts of European colonies was more or less equivalent to studying the flora and fauna of those places. It was for this reason, for instance, that Lewis Henry Morgan could write monographs on both \"The League of the Iroquois\" and \"The American Beaver and His Works\". This is also why the material culture of 'civilized' nations such as China have historically been displayed in fine arts museums alongside European art while artifacts from Africa or Native North American cultures were displayed in natural history museums with dinosaur bones and nature dioramas. Curatorial practice has changed dramatically in recent years, and it would be wrong to see anthropology as merely an extension of colonial rule and European chauvinism, since its relationship to imperialism was and is complex.\n\nDrawing on the methods of the natural sciences as well as developing new techniques involving not only structured interviews but unstructured \"participant-observation\"—and drawing on the new theory of evolution through natural selection, they proposed the scientific study of a new object: \"humankind\", conceived of as a whole. Crucial to this study is the concept \"culture\", which anthropologists defined both as a universal capacity and propensity for social learning, thinking, and acting (which they see as a product of human evolution and something that distinguishes Homo sapiens—and perhaps all species of genus \"Homo\"—from other species), and as a particular adaptation to local conditions that takes the form of highly variable beliefs and practices. Thus, \"culture\" not only transcends the opposition between nature and nurture; it transcends and absorbs the peculiarly European distinction between politics, religion, kinship, and the economy as autonomous domains. Anthropology thus transcends the divisions between the natural sciences, social sciences, and humanities to explore the biological, linguistic, material, and symbolic dimensions of humankind in all forms.\n\nAs academic disciplines began to differentiate over the course of the nineteenth century, anthropology grew increasingly distinct from the biological approach of natural history, on the one hand, and from purely historical or literary fields such as Classics, on the other. A common criticism was that many social sciences (such as economists, sociologists, and psychologists) in Western countries focused disproportionately on Western subjects, while anthropology focuseed disproportionately on the \"other\".\n\nMuseums such as the British Museum weren't the only site of anthropological studies: with the New Imperialism period, starting in the 1870s, zoos became unattended \"laboratories\", especially the so-called \"ethnological exhibitions\" or \"Negro villages\". Thus, \"savages\" from the colonies were displayed, often nudes, in cages, in what has been called \"human zoos\". For example, in 1906, Congolese pygmy Ota Benga was put by anthropologist Madison Grant in a cage in the Bronx Zoo, labelled \"the missing link\" between an orangutan and the \"white race\"—Grant, a renowned eugenicist, was also the author of \"The Passing of the Great Race\" (1916). Such exhibitions were attempts to illustrate and prove in the same movement the validity of scientific racism, which first formulation may be found in Arthur de Gobineau's \"An Essay on the Inequality of Human Races\" (1853–55). In 1931, the Colonial Exhibition in Paris still displayed Kanaks from New Caledonia in the \"indigenous village\"; it received 24 million visitors in six months, thus demonstrating the popularity of such \"human zoos\".\n\nAnthropology grew increasingly distinct from natural history and by the end of the nineteenth century the discipline began to crystallize into its modern form—by 1935, for example, it was possible for T.K. Penniman to write a history of the discipline entitled \"A Hundred Years of Anthropology\". At the time, the field was dominated by 'the comparative method'. It was assumed that all societies passed through a single evolutionary process from the most primitive to most advanced. Non-European societies were thus seen as evolutionary 'living fossils' that could be studied in order to understand the European past. Scholars wrote histories of prehistoric migrations which were sometimes valuable but often also fanciful. It was during this time that Europeans first accurately traced Polynesian migrations across the Pacific Ocean for instance—although some of them believed it originated in Egypt. Finally, the concept of race was actively discussed as a way to classify—and rank—human beings based on difference.\n\nEdward Burnett Tylor (2 October 1832 – 2 January 1917) and James George Frazer (1 January 1854 – 7 May 1941) are generally considered the antecedents to modern social anthropology in Britain. Although Tylor undertook a field trip to Mexico, both he and Frazer derived most of the material for their comparative studies through extensive reading, not fieldwork, mainly the Classics (literature and history of Greece and Rome), the work of the early European folklorists, and reports from missionaries, travelers, and contemporaneous ethnologists.\n\nTylor advocated strongly for unilinealism and a form of \"uniformity of mankind\". Tylor in particular laid the groundwork for theories of cultural diffusionism, stating that there are three ways that different groups can have similar cultural forms or technologies: \"independent invention, inheritance from ancestors in a distant region, transmission from one race to another\".\n\nTylor formulated one of the early and influential anthropological conceptions of culture as \"that complex whole, which includes knowledge, belief, art, morals, law, custom, and any other capabilities and habits acquired by [humans] as [members] of society\". However, as Stocking notes, Tylor mainly concerned himself with describing and mapping the distribution of particular elements of culture, rather than with the larger function, and he generally seemed to assume a Victorian idea of progress rather than the idea of non-directional, multilineal cultural development proposed by later anthropologists.\n\nTylor also theorized about the origins of religious beliefs in human beings, proposing a theory of animism as the earliest stage, and noting that \"religion\" has many components, of which he believed the most important to be belief in supernatural beings (as opposed to moral systems, cosmology, etc.). Frazer, a Scottish scholar with a broad knowledge of Classics, also concerned himself with religion, myth, and magic. His comparative studies, most influentially in the numerous editions of \"The Golden Bough\", analyzed similarities in religious belief and symbolism globally. Neither Tylor nor Frazer, however, was particularly interested in fieldwork, nor were they interested in examining how the cultural elements and institutions fit together. The Golden Bough was abridged drastically in subsequent editions after his first.\n\nToward the turn of the twentieth century, a number of anthropologists became dissatisfied with this categorization of cultural elements; historical reconstructions also came to seem increasingly speculative to them. Under the influence of several younger scholars, a new approach came to predominate among British anthropologists, concerned with analyzing how societies held together in the present (synchronic analysis, rather than diachronic or historical analysis), and emphasizing long-term (one to several years) immersion fieldwork. Cambridge University financed a multidisciplinary expedition to the Torres Strait Islands in 1898, organized by Alfred Cort Haddon and including a physician-anthropologist, William Rivers, as well as a linguist, a botanist, and other specialists. The findings of the expedition set new standards for ethnographic description.\n\nA decade and a half later, Polish anthropology student Bronisław Malinowski (1884–1942) was beginning what he expected to be a brief period of fieldwork in the old model, collecting lists of cultural items, when the outbreak of the First World War stranded him in New Guinea. As a subject of the Austro-Hungarian Empire resident on a British colonial possession, he was effectively confined to New Guinea for several years.\n\nHe made use of the time by undertaking far more intensive fieldwork than had been done by \"British\" anthropologists, and his classic ethnography, \"Argonauts of the Western Pacific\" (1922) advocated an approach to fieldwork that became standard in the field: getting \"the native's point of view\" through participant observation. Theoretically, he advocated a functionalist interpretation, which examined how social institutions functioned to satisfy individual needs.\n\nBritish social anthropology had an expansive moment in the Interwar period, with key contributions coming from the Polish-British Bronisław Malinowski and Meyer Fortes\n\nA. R. Radcliffe-Brown also published a seminal work in 1922. He had carried out his initial fieldwork in the Andaman Islands in the old style of historical reconstruction. However, after reading the work of French sociologists Émile Durkheim and Marcel Mauss, Radcliffe-Brown published an account of his research (entitled simply \"The Andaman Islanders\") that paid close attention to the meaning and purpose of rituals and myths. Over time, he developed an approach known as structural functionalism, which focused on how institutions in societies worked to balance out or create an equilibrium in the social system to keep it functioning harmoniously. (This contrasted with Malinowski's functionalism, and was quite different from the later French structuralism, which examined the conceptual structures in language and symbolism.)\n\nMalinowski and Radcliffe-Brown's influence stemmed from the fact that they, like Boas, actively trained students and aggressively built up institutions that furthered their programmatic ambitions. This was particularly the case with Radcliffe-Brown, who spread his agenda for \"Social Anthropology\" by teaching at universities across the British Commonwealth. From the late 1930s until the postwar period appeared a string of monographs and edited volumes that cemented the paradigm of British Social Anthropology (BSA). Famous ethnographies include \"The Nuer,\" by Edward Evan Evans-Pritchard, and \"The Dynamics of Clanship Among the Tallensi,\" by Meyer Fortes; well-known edited volumes include \"African Systems of Kinship and Marriage\" and \"African Political Systems.\"\n\nMax Gluckman, together with many of his colleagues at the Rhodes-Livingstone Institute and students at Manchester University, collectively known as the Manchester School, took BSA in new directions through their introduction of explicitly Marxist-informed theory, their emphasis on conflicts and conflict resolution, and their attention to the ways in which individuals negotiate and make use of the social structural possibilities.\n\nIn Britain, anthropology had a great intellectual impact, it \"contributed to the erosion of Christianity, the growth of cultural relativism, an awareness of the survival of the primitive in modern life, and the replacement of diachronic modes of analysis with synchronic, all of which are central to modern culture.\"\n\nLater in the 1960s and 1970s, Edmund Leach and his students Mary Douglas and Nur Yalman, among others, introduced French structuralism in the style of Lévi-Strauss; while British anthropology has continued to emphasize social organization and economics over purely symbolic or literary topics, differences among British, French, and American sociocultural anthropologies have diminished with increasing dialogue and borrowing of both theory and methods. Today, social anthropology in Britain engages internationally with many other social theories and has branched in many directions.\n\nIn countries of the British Commonwealth, social anthropology has often been institutionally separate from physical anthropology and primatology, which may be connected with departments of biology or zoology; and from archaeology, which may be connected with departments of Classics, Egyptology, and the like. In other countries (and in some, particularly smaller, British and North American universities), anthropologists have also found themselves institutionally linked with scholars of folklore, museum studies, human geography, sociology, social relations, ethnic studies, cultural studies, and social work.\n\nAnthropology has been used in Britain to provide an alternative explanation for the Financial crisis of 2007–2010 to the technical explanations rooted in economic and political theory. Dr. Gillian Tett, a Cambridge University trained anthropologist who went on to become a senior editor at the Financial Times is one of the leaders in this use of anthropology.\n\nCanadian anthropology began, as in other parts of the Colonial world, as ethnological data in the records of travellers and missionaries. In Canada, Jesuit missionaries such as Fathers LeClercq, Le Jeune and Sagard, in the 17th century, provide the oldest ethnographic records of native tribes in what was then the Dominion of Canada. The academic discipline has drawn strongly on both the British Social Anthropology and the American Cultural Anthropology traditions, producing a hybrid \"Socio-cultural\" anthropology.\n\nTrue anthropology began with a Government department: the Geological Survey of Canada, and George Mercer Dawson (director in 1895). Dawson's support for anthropology created impetus for the profession in Canada. This was expanded upon by Prime Minister Wilfrid Laurier, who established a Division of Anthropology within the Geological Survey in 1910.\n\nAnthropologists were recruited from England and the USA, setting the foundation for the unique Canadian style of anthropology. Scholars include the linguist and Boasian Edward Sapir.\n\nAnthropology in France has a less clear genealogy than the British and American traditions, in part because many French writers influential in anthropology have been trained or held faculty positions in sociology, philosophy, or other fields rather than in anthropology.\n\nMost commentators consider Marcel Mauss (1872–1950), nephew of the influential sociologist Émile Durkheim, to be the founder of the French anthropological tradition. Mauss belonged to Durkheim's \"Année Sociologique\" group. While Durkheim and others examined the state of modern societies, Mauss and his collaborators (such as Henri Hubert and Robert Hertz) drew on ethnography and philology to analyze societies that were not as 'differentiated' as European nation states.\n\nTwo works by Mauss in particular proved to have enduring relevance: \"Essay on the Gift,\" a seminal analysis of exchange and reciprocity, and his Huxley lecture on the notion of the person, the first comparative study of notions of person and selfhood cross-culturally.\n\nThroughout the interwar years, French interest in anthropology often dovetailed with wider cultural movements such as surrealism and primitivism, which drew on ethnography for inspiration. Marcel Griaule and Michel Leiris are examples of people who combined anthropology with the French avant-garde. During this time most of what is known as \"ethnologie\" was restricted to museums, such as the Musée de l'Homme founded by Paul Rivet, and anthropology had a close relationship with studies of folklore.\n\nAbove all, Claude Lévi-Strauss helped institutionalize anthropology in France. Along with the enormous influence that his theory of structuralism exerted across multiple disciplines, Lévi-Strauss established ties with American and British anthropologists. At the same time, he established centers and laboratories within France to provide an institutional context within anthropology, while training influential students such as Maurice Godelier and Françoise Héritier. They proved influential in the world of French anthropology. Much of the distinct character of France's anthropology today is a result of the fact that most anthropology is carried out in nationally funded research laboratories (CNRS) rather than academic departments in universities\n\nOther influential writers in the 1970s include Pierre Clastres, who explains in his books on the Guayaki tribe in Paraguay that \"primitive societies\" actively oppose the institution of the state. These stateless societies are not less evolved than societies with states, but chose to conjure the institution of authority as a separate function from society. The leader is only a spokesperson for the group when it has to deal with other groups (\"international relations\") but has no inside authority, and may be violently removed if he attempts to abuse this position.\n\nThe most important French social theorist since Foucault and Lévi-Strauss is Pierre Bourdieu, who trained formally in philosophy and sociology and eventually held the Chair of Sociology at the Collège de France. Like Mauss and others before him, he worked on topics both in sociology and anthropology. His fieldwork among the Kabyle of Algeria places him solidly in anthropology, while his analysis of the function and reproduction of fashion and cultural capital in European societies places him as solidly in sociology.\nFrom its beginnings in the early 19th century through the early 20th century, anthropology in the United States was influenced by the presence of Native American societies. \nCultural anthropology in the United States was influenced greatly by the ready availability of Native American societies as ethnographic subjects. The field was pioneered by staff of the Bureau of Indian Affairs and the Smithsonian Institution's Bureau of American Ethnology, men such as John Wesley Powell and Frank Hamilton Cushing.\n\nLate-eighteenth-century ethnology established the scientific foundation for the field, which began to mature in the United States during the presidency of Andrew Jackson (1829–1837). Jackson was responsible for implementing the Indian Removal Act, the coerced and forced removal of an estimated 100,000 American Indians during the 1830s to Indian Territory in present-day Oklahoma; for insuring that the franchise was extended to all white men, irrespective of financial means while denying virtually all black men the right to vote; and, for suppressing abolitionists' efforts to end slavery while vigorously defending that institution. Finally, he was responsible for appointing Chief Justice Roger B. Taney who would decide, in Scott v. Sandford (1857), that Negroes were \"beings of an inferior order, and altogether unfit to associate with the white race ... and so far inferior that they had no rights which the white man was bound to respect\". As a result of this decision, black people, whether free or enslaved, could never become citizens of the United States.\n\nIt was in this context that the so-called American School of Anthropology thrived as the champion of polygenism or the doctrine of multiple origins—sparking a debate between those influenced by the Bible who believed in the unity of humanity and those who argued from a scientific standpoint for the plurality of origins and the antiquity of distinct types. Like the monogenists, these theories were not monolithic and often used words like races, species, hybrid, and mongrel interchangeably. A scientific consensus began to emerge during this period \"that there exists a Genus Homo, embracing many primordial types of 'species'\". Charles Caldwell, Samuel George Morton, Samuel A. Cartwright, George Gliddon, Josiah C. Nott, and Louis Agassiz, and even South Carolina Governor James Henry Hammond were all influential proponents of this school. While some were disinterested scientists, others were passionate advocates who used science to promote slavery in a period of increasing sectional strife. All were complicit in establishing the putative science that justified slavery, informed the Dred Scott decision, underpinned miscegenation laws, and eventually fueled Jim Crow. Samuel G. Morton, for example, claimed to be just a scientist but he did not hesitate to provide evidence of Negro inferiority to John C. Calhoun, the prominent pro-slavery Secretary of State to help him negotiate the annexation of Texas as a slave state.\n\nThe high-water mark of polygenic theories was Josiah Nott and Gliddon's voluminous eight-hundred page tome titled \"Types of Mankind\", published in 1854. Reproducing the work of Louis Agassiz and Samuel Morton, the authors spread the virulent and explicitly racist views to a wider, more popular audience. The first printing sold out quickly and by the end of the century it had undergone nine editions. Although many Southerners felt that all the justification for slavery they needed was found in the Bible, others used the new science to defend slavery and the repression of American Indians. Abolitionists, however, felt they had to take this science on its own terms. And for the first time, African American intellectuals waded into the contentious debate. In the immediate wake of Types of Mankind and during the pitched political battles that led to Civil War, Frederick Douglass (1818–1895), the statesman and persuasive abolitionist, directly attacked the leading theorists of the American School of Anthropology. In an 1854 address, entitled \"The Claims of the Negro Ethnologically Considered\", Douglass argued that \"by making the enslaved a character fit only for slavery, [slaveowners] excuse themselves for refusing to make the slave a freeman... For let it be once granted that the human race are of multitudinous origin, naturally different in their moral, physical, and intellectual capacities ... a chance is left for slavery, as a necessary institution... There is no doubt that Messrs. Nott, Glidden, Morton, Smith and Agassiz were duly consulted by our slavery propagating statesmen\" (p. 287).\n\nLewis Henry Morgan (1818–1881), a lawyer from Rochester, New York, became an advocate for and ethnological scholar of the Iroquois. His comparative analyses of religion, government, material culture, and especially kinship patterns proved to be influential contributions to the field of anthropology. Like other scholars of his day (such as Edward Tylor), Morgan argued that human societies could be classified into categories of cultural evolution on a scale of progression that ranged from \"savagery\", to \"barbarism\", to \"civilization\". He focused on understanding how cultures integrated and systematized, and how the various features of one culture indicate an evolutionary status in comparison with other cultures. Generally, Morgan used technology (such as bowmaking or pottery) as an indicator of position on this scale.\n\nFranz Boas established academic anthropology in the United States in opposition to this sort of evolutionary perspective. His approach was empirical, skeptical of overgeneralizations, and eschewed attempts to establish universal laws. For example, Boas studied immigrant children to demonstrate that biological race was not immutable, and that human conduct and behavior resulted from nurture, rather than nature.\n\nInfluenced by the German tradition, Boas argued that the world was full of distinct \"cultures,\" rather than societies whose evolution could be measured by how much or how little \"civilization\" they had. He believed that each culture has to be studied in its particularity, and argued that cross-cultural generalizations, like those made in the natural sciences, were not possible.\n\nIn doing so, he fought discrimination against immigrants, blacks, and indigenous peoples of the Americas. Many American anthropologists adopted his agenda for social reform, and theories of race continue to be popular subjects for anthropologists today. The so-called \"Four Field Approach\" has its origins in Boasian Anthropology, dividing the discipline in the four crucial and interrelated fields of sociocultural, biological, linguistic, and archaic anthropology (e.g. archaeology). Anthropology in the United States continues to be deeply influenced by the Boasian tradition, especially its emphasis on culture.\nBoas used his positions at Columbia University and the American Museum of Natural History to train and develop multiple generations of students. His first generation of students included Alfred Kroeber, Robert Lowie, Edward Sapir and Ruth Benedict, who each produced richly detailed studies of indigenous North American cultures. They provided a wealth of details used to attack the theory of a single evolutionary process. Kroeber and Sapir's focus on Native American languages helped establish linguistics as a truly general science and free it from its historical focus on Indo-European languages.\n\nThe publication of Alfred Kroeber's textbook, \"Anthropology,\" marked a turning point in American anthropology. After three decades of amassing material, Boasians felt a growing urge to generalize. This was most obvious in the 'Culture and Personality' studies carried out by younger Boasians such as Margaret Mead and Ruth Benedict. Influenced by psychoanalytic psychologists including Sigmund Freud and Carl Jung, these authors sought to understand the way that individual personalities were shaped by the wider cultural and social forces in which they grew up.\n\nThough such works as \"Coming of Age in Samoa\" and \"The Chrysanthemum and the Sword\" remain popular with the American public, Mead and Benedict never had the impact on the discipline of anthropology that some expected. Boas had planned for Ruth Benedict to succeed him as chair of Columbia's anthropology department, but she was sidelined by Ralph Linton, and Mead was limited to her offices at the AMNH.\n\nAnthropology as it emerged amongst the Western colonial powers (mentioned above) has generally taken a different path than that in the countries of southern and central Europe (Italy, Greece, and the successors to the Austro-Hungarian and Ottoman empires). In the former, the encounter with multiple, distinct cultures, often very different in organization and language from those of Europe, has led to a continuing emphasis on cross-cultural comparison and a receptiveness to certain kinds of cultural relativism.\n\nIn the successor states of continental Europe, on the other hand, anthropologists often joined with folklorists and linguists in building cultural perspectives on nationalism. Ethnologists in these countries tended to focus on differentiating among local ethnolinguistic groups, documenting local folk culture, and representing the prehistory of what has become a nation through various forms of public education (e.g., museums of several kinds).\n\nIn this scheme, Russia occupied a middle position. On the one hand, it had a large region (largely east of the Urals) of highly distinct, pre-industrial, often non-literate peoples, similar to the situation in the Americas. On the other hand, Russia also participated to some degree in the nationalist (cultural and political) movements of Central and Eastern Europe. After the Revolution of 1917, views expressed by anthropologists in the USSR, and later the Soviet Bloc countries, were highly shaped by the requirement to conform to Marxist theories of social evolution.\n\nIn Greece, there was since the 19th century a science of the folklore called \"laographia\" (laography), in the form of \"a science of the interior\", although theoretically weak; but the connotation of the field deeply changed after World War II, when a wave of Anglo-American anthropologists introduced a science \"of the outside\". \n\nIn Italy, the development of ethnology and related studies did not receive as much attention as other branches of learning, but nonetheless included important researchers and thinkers like Ernesto De Martino.\n\nGermany and Norway are the countries that showed the most division and conflict between scholars focusing on domestic socio-cultural issues and scholars focusing on \"other\" societies.. Some German and Austrian scholars have increased cultural anthropology as both legal anthropology regarding \"other\" societies and anthropology of Western civilization.\n\nThe development of world anthropologies has followed different trajectories.\n\nIn the mid-20th century, American anthropology began to study its own history more systematically. In 1967 Marvin Harris published his \"The Rise of Anthropological Theory\", presenting argumentative examinations of anthropology's historical developments, and George W. Stocking, Jr., established the historicist school, examining the historical contexts of anthropological movements.\n\n\n"}
{"id": "9715234", "url": "https://en.wikipedia.org/wiki?curid=9715234", "title": "History of media studies", "text": "History of media studies\n\nThis article outlines the history of media studies.\n\nThough not yet named as such, media studies' roots are in the Chicago School and thinkers such as John Dewey, Charles Cooley and George Mead. These authors saw American society on the cusp of positive social change toward pure democracy. Mead argued that for an ideal society to exist, a form of communication must be developed to allow the unique individual to appreciate the attitudes, viewpoints and positions of others unlike himself, and allow him to be understood by others as well. Mead believed that this \"new media\" would allow humans to empathize with others, and therefore moves toward an \"ideal of human society.\" Where Mead sees an ideal society, Dewey names it the \"Great Community,\" and further asserts the assumption that humans are intelligent enough for self-government, and that that knowledge is \"a function of association and communication.\" Similarly, Cooley asserts that political communication makes public opinion possible, which in turn promotes democracy. Each of these authors represent the Chicago School’s attention to electronic communication as a facilitator of democracy, its faith in the informed electorate, and its focus on the individual as opposed to the mass.\n\nThe social impact of mass communication has been studied at The New School University in New York since its founding in 1919. The first college course to investigate the motion picture was offered here in 1926. Marshall McLuhan's colleague, John Culkin, brought his Center for Understanding Media to The New School in 1975 and The New School began offering the Master of Arts degree in Media Studies, one of the first graduate programs of its kind. Today, among other programs, MA in Media Studies is still being offered by School of Media Studies, The New School, which will celebrate 40th anniversary of Media Studies at The New School during the academic year 2015-2016\n\nBetween the First and Second World Wars, the Institute for Propaganda Analysis briefly rose to importance. Their definition of propaganda was \"expression of opinion or action by individuals or groups deliberately designed to influence opinion or actions of other individuals or groups with reference to predetermined ends.\" \n\nHarold Lasswell, who worked in the paradigm of the Chicago School of sociology wrote Propaganda Technique in the World War, which included this definition of propaganda:\n\"Propaganda in the broadest sense is the technique of influencing human action by the manipulation of representations. These representations may take spoken, written, pictorial or musical form.\"\n\nThese definitions of propaganda clearly show that this was a school of thought that focused on media effects, as it highlighted the influence that media could have over its audiences attitudes and actions.\n\nEpitomizing this early school of media effects studies are experiments done by The Experimental Section of the Research Branch of the U.S. War Department's Information and Education Division. In the experiments, the effects of various U.S. wartime propaganda films on soldiers were observed.\n\nCurrent Propaganda studies are applied into many fields besides politics. Herman described a propaganda model as \"a model of media behavior and performance, not of media effects.\" (Herman, 2000, p. 63) He argued: \"They are profit-seeking business, owned by very wealthy people (or other companies); and they are funded largely by advertisers who are also profit-seeking entities, and who want their advertisements to appear in a supportive selling environment.\" He also presented \"five factors: owner ship, advertising, sourcing, flak and anti-communist ideology-work as filters through which information must pass, and that individually and often in cumulative fashion they greatly influence media choices.\" Until now, there is no conclusion of propaganda, debate still continues.\n\nTypified by the philosophical and theoretical orientations of Max Horkheimer, Theodor Adorno, Walter Benjamin, Leo Lowenthal, and Herbert Marcuse, the Frankfurt school contributed greatly to the development and application of critical theory in media studies. Their Marxist critique of market-driven media was critical of its atomizing and leveling effects.\n\nThe Frankfurt school also lamented the effects of the \"culture industry\" on the production and appreciation of art. For example, in \"A Social Critique of Radio Music\", Adorno asserts: \"…music has ceased to be a human force and is consumed like other consumers’ goods. This produces ‘commodity listening’…The listener suspends all intellectual activity.\"\n\nAs the Frankfurt school lamented on the effects of the \"culture industry\" they also began to identify mass culture and high culture as two distinct entities. Scholars like Benjamin (1936) and Adorno (1945) can be credited with what would eventually become known as popular culture and high culture. Their finite distinction of equating original production with ritualistic behavior as compared with mass culture that finds its identifying symbols in reproductions. These reproductions are souless and lacking in definition and originality.\n\nThe less paradigm in media studies since the Second World War has been associated with the ideas, methods and findings of Paul F. Lazarsfeld and his school: media effect studies. Their studies focused on measurable, short-term behavioral ‘effects’ of media and concluded that the media played a limited role in influencing public opinion. The \"Limited-Effects\" Model developed by Lazarsfeld and his colleagues from Columbia was highly influential in the development of media studies. The model claims the mass media has \"limited-effects\" on voting patterns. Voters are influenced, rather, through the ‘two-step flow’ model, the idea that media messages are disseminated through personal interaction with ‘opinion leaders’.\n\nThe model of limited- effects was so influential that the question of media \"effects\" on politics was left largely unaddressed until the late 1960s. Eventually Mass Communication scholars began to study political behavior again and the limited-effects model was called into question.\n\nAs a response to the previous emphasis upon media effects, from the 1970s researchers became interested in how audiences make sense of media texts. The \"uses and gratifications\" model, associated with Jay Blumler and Elihu Katz, reflected this growing interest in the 'active audience'. One such example of this type of research was conducted by Hodge and Tripp, and separately Palmer, about how school-children make sense of the Australian soap opera \"Prisoner\". They found that pupils could identify with the prisoners: they were \"shut in\", separated from their friends and wouldn't be there had they not been made to be, etc. Also, the children could compare the wardens to their teachers: \"the hard-bitten old [one], the soft new one, the one you could take advantage of...\"John Fiske summarises:\n\nThe children inserted meanings of the program into their social experience of school in a way that informed both -- the meanings of school and the meanings of \"Prisoner\" were each influenced by the other, and the fit between them validated the other.\n"}
{"id": "53132", "url": "https://en.wikipedia.org/wiki?curid=53132", "title": "Humanities", "text": "Humanities\n\nHumanities are academic disciplines that study aspects of human society and culture. In the Renaissance, the term contrasted with divinity and referred to what is now called classics, the main area of secular study in universities at the time. Today, the humanities are more frequently contrasted with natural, and sometimes social, sciences as well as professional training.\n\nThe humanities use methods that are primarily critical, or speculative, and have a significant historical element—as distinguished from the mainly empirical approaches of the natural sciences, yet, unlike the sciences, it has no central discipline.\nThe humanities include ancient and modern languages, literature, philosophy, history, human geography, law, politics, religion, and art.\n\nScholars in the humanities are \"humanity scholars\" or \"humanists\". The term \"humanist\" also describes the philosophical position of humanism, which some \"antihumanist\" scholars in the humanities refuse. The Renaissance scholars and artists were also called humanists. Some secondary schools offer humanities classes usually consisting of literature, global studies and art.\n\nHuman disciplines like history and cultural anthropology study subject matters that the manipulative experimental method does not apply to—and instead mainly use the comparative method and comparative research.\n\nAnthropology is the holistic \"science of humans\", a science of the totality of human existence. The discipline deals with the integration of different aspects of the social sciences, humanities and human biology. In the twentieth century, academic disciplines have often been institutionally divided into three broad domains. The natural \"sciences\" seek to derive general laws through reproducible and verifiable experiments. The \"humanities\" generally study local traditions, through their history, literature, music, and arts, with an emphasis on understanding particular individuals, events, or eras. The \"social sciences\" have generally attempted to develop scientific methods to understand social phenomena in a generalizable way, though usually with methods distinct from those of the natural sciences.\n\nThe anthropological social sciences often develop nuanced descriptions rather than the general laws derived in physics or chemistry, or they may explain individual cases through more general principles, as in many fields of psychology. Anthropology (like some fields of history) does not easily fit into one of these categories, and different branches of anthropology draw on one or more of these domains. Within the United States, anthropology is divided into four sub-fields: archaeology, physical or biological anthropology, anthropological linguistics, and cultural anthropology. It is an area that is offered at most undergraduate institutions. The word \"anthropos\" (άνθρωπος) is from the Greek for \"human being\" or \"person\". Eric Wolf described sociocultural anthropology as \"the most scientific of the humanities, and the most humanistic of the sciences\".\n\nThe goal of anthropology is to provide a holistic account of humans and human nature. This means that, though anthropologists generally specialize in only one sub-field, they always keep in mind the biological, linguistic, historic and cultural aspects of any problem. Since anthropology arose as a science in Western societies that were complex and industrial, a major trend within anthropology has been a methodological drive to study peoples in societies with more simple social organization, sometimes called \"primitive\" in anthropological literature, but without any connotation of \"inferior\". Today, anthropologists use terms such as \"less complex\" societies, or refer to specific modes of subsistence or production, such as \"pastoralist\" or \"forager\" or \"horticulturalist\", to discuss humans living in non-industrial, non-Western cultures, such people or folk (\"ethnos\") remaining of great interest within anthropology.\n\nThe quest for holism leads most anthropologists to study a people in detail, using biogenetic, archaeological, and linguistic data alongside direct observation of contemporary customs. In the 1990s and 2000s, calls for clarification of what constitutes a culture, of how an observer knows where his or her own culture ends and another begins, and other crucial topics in writing anthropology were heard. It is possible to view all human cultures as part of one large, evolving global culture. These dynamic relationships, between what can be observed on the ground, as opposed to what can be observed by compiling many local observations remain fundamental in any kind of anthropology, whether cultural, biological, linguistic or archaeological.\n\nArchaeology is the study of human activity through the recovery and analysis of material culture. The archaeological record consists of artifacts, architecture, biofacts or ecofacts, and cultural landscapes. Archaeology can be considered both a social science and a branch of the humanities. It has various goals, which range from understanding culture history to reconstructing past lifeways to documenting and explaining changes in human societies through time.\n\nArchaeology is thought of as a branch of anthropology in the United States, while in Europe, it is viewed as a discipline in its own right, or grouped under other related disciplines such as history.\n\nClassics, in the Western academic tradition, refers to the studies of the cultures of classical antiquity, namely Ancient Greek and Latin and the Ancient Greek and Roman cultures. Classical studies is considered one of the cornerstones of the humanities; however, its popularity declined during the 20th century. Nevertheless, the influence of classical ideas on many humanities disciplines, such as philosophy and literature, remains strong.\n\nHistory is systematically collected information about the past. When used as the name of a field of study, \"history\" refers to the study and interpretation of the record of humans, societies, institutions, and any topic that has changed over time.\n\nTraditionally, the study of history has been considered a part of the humanities. In modern academia, history is occasionally classified as a social science.\n\nWhile the scientific study of language is known as linguistics and is generally considered a social science, a natural science or a cognitive science, the study of languages is still central to the humanities. A good deal of twentieth-century and twenty-first-century philosophy has been devoted to the analysis of language and to the question of whether, as Wittgenstein claimed, many of our philosophical confusions derive from the vocabulary we use; literary theory has explored the rhetorical, associative, and ordering features of language; and historical linguists have studied the development of languages across time. Literature, covering a variety of uses of language including prose forms (such as the novel), poetry and drama, also lies at the heart of the modern humanities curriculum. College-level programs in a foreign language usually include study of important works of the literature in that language, as well as the language itself.\n\n In common parlance, law means a rule that (unlike a rule of ethics) is enforceable through institutions. The study of law crosses the boundaries between the social sciences and humanities, depending on one's view of research into its objectives and effects. Law is not always enforceable, especially in the international relations context. It has been defined as a \"system of rules\", as an \"interpretive concept\" to achieve justice, as an \"authority\" to mediate people's interests, and even as \"the command of a sovereign, backed by the threat of a sanction\". However one likes to think of law, it is a completely central social institution. Legal policy incorporates the practical manifestation of thinking from almost every social science and discipline of the humanities. Laws are politics, because politicians create them. Law is philosophy, because moral and ethical persuasions shape their ideas. Law tells many of history's stories, because statutes, case law and codifications build up over time. And law is economics, because any rule about contract, tort, property law, labour law, company law and many more can have long-lasting effects on how productivity is organised and the distribution of wealth. The noun \"law\" derives from the late Old English \"lagu\", meaning something laid down or fixed, and the adjective \"legal\" comes from the Latin word \"LEX\".\n\n Literature is a term that does not have a universally accepted definition, but which has variably included all written work; writing that possesses literary merit; and language that foregrounds literariness, as opposed to ordinary language. Etymologically the term derives from Latin \"literatura/litteratura\" \"writing formed with letters\", although some definitions include spoken or sung texts. Literature can be classified according to whether it is fiction or non-fiction, and whether it is poetry or prose; it can be further distinguished according to major forms such as the novel, short story or drama; and works are often categorised according to historical periods, or according to their adherence to certain aesthetic features or expectations (genre).\n\nPhilosophy—etymologically, the \"love of wisdom\"—is generally the study of problems concerning matters such as existence, knowledge, justification, truth, justice, right and wrong, beauty, validity, mind, and language. Philosophy is distinguished from other ways of addressing these issues by its critical, generally systematic approach and its reliance on reasoned argument, rather than experiments (experimental philosophy being an exception).\n\nPhilosophy used to be a very comprehensive term, including what have subsequently become separate disciplines, such as physics. (As Immanuel Kant noted, \"Ancient Greek philosophy was divided into three sciences: physics, ethics, and logic.\") Today, the main fields of philosophy are logic, ethics, metaphysics, and epistemology. Still, it continues to overlap with other disciplines. The field of semantics, for example, brings philosophy into contact with linguistics.\n\nSince the early twentieth century, philosophy in English-speaking universities has moved away from the humanities and closer to the formal sciences, becoming much more \"analytic.\" Analytic philosophy is marked by emphasis on the use of logic and formal methods of reasoning, conceptual analysis, and the use of symbolic and/or mathematical logic, as contrasted with the Continental style of philosophy. This method of inquiry is largely indebted to the work of philosophers such as Gottlob Frege, Bertrand Russell, G.E. Moore, and Ludwig Wittgenstein.\n\nNew philosophies and religions arose in both east and west, particularly around the 6th century BC. Over time, a great variety of religions developed around the world, with Hinduism, Sikhism, Jainism, and Buddhism in India, Zoroastrianism in Persia being some of the earliest major faiths. In the east, three schools of thought were to dominate Chinese thinking until the modern day. These were Taoism, Legalism, and Confucianism. The Confucian tradition, which would attain predominance, looked not to the force of law, but to the power and example of tradition for political morality. In the west, the Greek philosophical tradition, represented by the works of Plato and Aristotle, was diffused throughout Europe and the Middle East by the conquests of Alexander of Macedon in the 4th century BC.\n\nAbrahamic religions are those religions deriving from a common ancient tradition and traced by their adherents to Abraham (circa 1900 BCE), a patriarch whose life is narrated in the Hebrew Bible/Old Testament, where he is described as a prophet (Genesis 20:7), and in the Quran, where he also appears as a prophet. This forms a large group of related largely monotheistic religions, generally held to include Judaism, Christianity, and Islam, and comprises over half of the world's religious adherents.\n\nThe performing arts differ from the visual arts in so far as the former uses the artist's own body, face, and presence as a medium, and the latter uses materials such as clay, metal, or paint, which can be molded or transformed to create some art object. Performing arts include acrobatics, busking, comedy, dance, film, magic, music, opera, juggling, marching arts, such as brass bands, and theatre.\n\nArtists who participate in these arts in front of an audience are called performers, including actors, comedians, dancers, musicians, and singers. Performing arts are also supported by workers in related fields, such as songwriting and stagecraft. Performers often adapt their appearance, such as with costumes and stage makeup, etc. There is also a specialized form of fine art in which the artists \"perform\" their work live to an audience. This is called Performance art. Most performance art also involves some form of plastic art, perhaps in the creation of props. Dance was often referred to as a \"plastic art\" during the Modern dance era.\n\nMusicology as an academic discipline can take a number of different paths, including historical musicology, ethnomusicology and music theory. Undergraduate music majors generally take courses in all of these areas, while graduate students focus on a particular path. In the liberal arts tradition, musicology is also used to broaden skills of non-musicians by teaching skills such as concentration and listening.\n\nTheatre (or theater) (Greek \"theatron\", \"θέατρον\") is the branch of the performing arts concerned with acting out stories in front of an audience using combinations of speech, gesture, music, dance, sound and spectacle — indeed any one or more elements of the other performing arts. In addition to the standard narrative dialogue style, theatre takes such forms as opera, ballet, mime, kabuki, classical Indian dance, Chinese opera, mummers' plays, and pantomime.\n\nDance (from Old French \"dancier\", perhaps from Frankish) generally refers to human movement either used as a form of expression or presented in a social, spiritual or performance setting. Dance is also used to describe methods of non-verbal communication (see body language) between humans or animals (bee dance, mating dance), and motion in inanimate objects (\"the leaves danced in the wind\"). Choreography is the art of creating dances, and the person who does this is called a choreographer.\n\nDefinitions of what constitutes dance are dependent on social, cultural, aesthetic, artistic, and moral constraints and range from functional movement (such as Folk dance) to codified, virtuoso techniques such as ballet.\n\nThe great traditions in art have a foundation in the art of one of the ancient civilizations, such as Ancient Japan, Greece and Rome, China, India, Greater Nepal, Mesopotamia and Mesoamerica.\n\nAncient Greek art saw a veneration of the human physical form and the development of equivalent skills to show musculature, poise, beauty and anatomically correct proportions. Ancient Roman art depicted gods as idealized humans, shown with characteristic distinguishing features (e.g., Zeus' thunderbolt).\n\nIn Byzantine and Gothic art of the Middle Ages, the dominance of the church insisted on the expression of biblical and not material truths. The Renaissance saw the return to valuation of the material world, and this shift is reflected in art forms, which show the corporeality of the human body, and the three-dimensional reality of landscape.\n\nEastern art has generally worked in a style akin to Western medieval art, namely a concentration on surface patterning and local colour (meaning the plain colour of an object, such as basic red for a red robe, rather than the modulations of that colour brought about by light, shade and reflection). A characteristic of this style is that the local colour is often defined by an outline (a contemporary equivalent is the cartoon). This is evident in, for example, the art of India, Tibet and Japan.\n\nReligious Islamic art forbids iconography, and expresses religious ideas through geometry instead. The physical and rational certainties depicted by the 19th-century Enlightenment were shattered not only by new discoveries of relativity by Einstein and of unseen psychology by Freud, but also by unprecedented technological development. Increasing global interaction during this time saw an equivalent influence of other cultures into Western art.\n\nDrawing is a means of making a picture, using any of a wide variety of tools and techniques. It generally involves making marks on a surface by applying pressure from a tool, or moving a tool across a surface. Common tools are graphite pencils, pen and ink, inked brushes, wax color pencils, crayons, charcoals, pastels, and markers. Digital tools that simulate the effects of these are also used. The main techniques used in drawing are: line drawing, hatching, crosshatching, random hatching, scribbling, stippling, and blending. A computer aided designer who excels in technical drawing is referred to as a \"draftsman\" or \"draughtsman\".\n\nPainting taken literally is the practice of applying pigment suspended in a carrier (or medium) and a binding agent (a glue) to a surface (support) such as paper, canvas or a wall. However, when used in an artistic sense it means the use of this activity in combination with drawing, composition and other aesthetic considerations in order to manifest the expressive and conceptual intention of the practitioner. Painting is also used to express spiritual motifs and ideas; sites of this kind of painting range from artwork depicting mythological figures on pottery to The Sistine Chapel to the human body itself.\n\nColour is highly subjective, but has observable psychological effects, although these can differ from one culture to the next. Black is associated with mourning in the West, but elsewhere white may be. Some painters, theoreticians, writers and scientists, including Goethe, Kandinsky, Isaac Newton, have written their own colour theories. Moreover, the use of language is only a generalization for a colour equivalent. The word \"red\", for example, can cover a wide range of variations on the pure red of the spectrum. There is not a formalized register of different colours in the way that there is agreement on different notes in music, such as C or C# in music, although the Pantone system is widely used in the printing and design industry for this purpose.\n\nModern artists have extended the practice of painting considerably to include, for example, collage. This began with cubism and is not painting in strict sense. Some modern painters incorporate different materials such as sand, cement, straw or wood for their texture. Examples of this are the works of Jean Dubuffet or Anselm Kiefer. Modern and contemporary art has moved away from the historic value of craft in favour of concept; this has led some to say that painting, as a serious art form, is dead, although this has not deterred the majority of artists from continuing to practise it either as whole or part of their work.\n\nThe word \"humanities\" is derived from the Renaissance Latin expression \"studia humanitatis\", or \"study of \"humanitas\"\" (a classical Latin word meaning—in addition to \"humanity\"—\"culture, refinement, education\" and, specifically, an \"education befitting a cultivated man\"). In its usage in the early 15th century, the \"studia humanitatis\" was a course of studies that consisted of grammar, poetry, rhetoric, history, and moral philosophy, primarily derived from the study of Latin and Greek classics. The word \"humanitas\" also gave rise to the Renaissance Italian neologism \"umanisti\", whence \"humanist\", \"Renaissance humanism\".\n\nIn the West, the study of the humanities can be traced to ancient Greece, as the basis of a broad education for citizens. During Roman times, the concept of the seven liberal arts evolved, involving grammar, rhetoric and logic (the trivium), along with arithmetic, geometry, astronomy and music (the quadrivium). These subjects formed the bulk of medieval education, with the emphasis being on the humanities as skills or \"ways of doing\".\n\nA major shift occurred with the Renaissance humanism of the fifteenth century, when the humanities began to be regarded as subjects to study rather than practice, with a corresponding shift away from traditional fields into areas such as literature and history. In the 20th century, this view was in turn challenged by the postmodernist movement, which sought to redefine the humanities in more egalitarian terms suitable for a democratic society since the Greek and Roman societies in which the humanities originated were not at all democratic. This was in keeping with the postmodernists' nuanced view of themselves as the culmination of history.\n\nFor many decades, there has been a growing public perception that a humanities education inadequately prepares graduates for employment. The common belief is that graduates from such programs face underemployment and incomes too low for a humanities education to be worth the investment.\n\nIn fact, humanities graduates find employment in a wide variety of management and professional occupations. In Britain, for example, over 11,000 humanities majors found employment in the following occupations:\nMany humanities graduates finish university with no career goals in mind. Consequently, many spend the first few years after graduation deciding what to do next, resulting in lower incomes at the start of their career; meanwhile, graduates from career-oriented programs experience more rapid entry into the labour market. However, usually within five years of graduation, humanities graduates find an occupation or career path that appeals to them.\n\nThere is empirical evidence that graduates from humanities programs earn less than graduates from other university programs. However, the empirical evidence also shows that humanities graduates still earn notably higher incomes than workers with no postsecondary education, and have job satisfaction levels comparable to their peers from other fields. Humanities graduates also earn more as their careers progress; ten years after graduation, the income difference between humanities graduates and graduates from other university programs is no longer statistically significant. Humanities graduates can earn even higher incomes if they obtain advanced or professional degrees.\n\nThe Humanities Indicators, unveiled in 2009 by the American Academy of Arts and Sciences, are the first comprehensive compilation of data about the humanities in the United States, providing scholars, policymakers and the public with detailed information on humanities education from primary to higher education, the humanities workforce, humanities funding and research, and public humanities activities. Modeled after the National Science Board's Science and Engineering Indicators, the Humanities Indicators are a source of reliable benchmarks to guide analysis of the state of the humanities in the United States.\n\nIf \"The STEM Crisis Is a Myth\", statements about a \"crisis\" in the humanities are also misleading and ignore data of the sort collected by the Humanities Indicators.\n\nThe 1980 United States Rockefeller Commission on the Humanities described the humanities in its report, \"The Humanities in American Life\":\nThrough the humanities we reflect on the fundamental question: What does it mean to be human? The humanities offer clues but never a complete answer. They reveal how people have tried to make moral, spiritual, and intellectual sense of a world where irrationality, despair, loneliness, and death are as conspicuous as birth, friendship, hope, and reason.\n\nIn 1950, a little over 1 percent of 22-year-olds in the United States had earned a humanities degrees (defined as a degree in English, language, history, philosophy); in 2010, this had doubled to about 2 and a half percent. In part, this is because there was an overall rise in the number of Americans who have any kind of college degree. (In 1940, 4.6 percent had a four-year degree; in 2016, 33.4 percent had one.) As a percentage of the type of degrees awarded, however, the humanities seem to be declining. Harvard University provides one example. In 1954, 36 percent of Harvard undergraduates majored in the humanities, but in 2012, only 20 percent took that course of study. Professor Benjamin Schmidt of Northeastern University has documented that between 1990 to 2008, degrees in English, history, foreign languages, and philosophy have decreased from 8 percent to just under 5 percent of all U.S. college degrees.\n\nThe Commission on the Humanities and Social Sciences 2013 report \"The Heart of the Matter\" supports the notion of a broad \"liberal arts education\", which includes study in disciplines from the natural sciences to the arts as well as the humanities.\n\nMany colleges provide such an education; some require it. The University of Chicago and Columbia University were among the first schools to require an extensive core curriculum in philosophy, literature, and the arts for all students. Other colleges with nationally recognized, mandatory programs in the liberal arts are Fordham University, St. John's College, Saint Anselm College and Providence College. Prominent proponents of liberal arts in the United States have included Mortimer J. Adler and E. D. Hirsch, Jr..\n\nResearchers in the humanities have developed numerous large- and small-scale digital corpora, such as digitized collections of historical texts, along with the digital tools and methods to analyze them. Their aim is both to uncover new knowledge about corpora and to visualize research data in new and revealing ways. Much of this activity occurs in a field called the digital humanities.\n\nPoliticians in the United States currently espouse a need for increased funding of the STEM fields, science, technology, engineering, mathematics. Federal funding represents a much smaller fraction of funding for humanities than other fields such as STEM or medicine. The result was a decline of quality in both college and pre-college education in the humanities field.\n\nFormer four-term Louisiana Governor, Edwin Edwards (D), has recently acknowledged the importance of the humanities. In a video address to the academic conference, \"Revolutions in Eighteenth-Century Sociability\", Edwards said\n\nThe contemporary debate in the field of critical university studies centers around the declining value of the humanities. As in America, there is a perceived decline in interest within higher education policy in research that is qualitative and does not produce marketable products. This threat can be seen in a variety of forms across Europe, but much critical attention has been given to the field of research assessment in particular. For example, the UK [Research Excellence Framework] has been subject to criticism due to its assessment criteria from across the humanities, and indeed, the social sciences. In particular, the notion of \"impact\" has generated significant debate.\n\nSince the late 19th century, a central justification for the humanities has been that it aids and encourages self-reflection—a self-reflection that, in turn, helps develop personal consciousness or an active sense of civic duty.\n\nWilhelm Dilthey and Hans-Georg Gadamer centered the humanities' attempt to distinguish itself from the natural sciences in humankind's urge to understand its own experiences. This understanding, they claimed, ties like-minded people from similar cultural backgrounds together and provides a sense of cultural continuity with the philosophical past.\n\nScholars in the late 20th and early 21st centuries extended that \"narrative imagination\" to the ability to understand the records of lived experiences outside of one's own individual social and cultural context. Through that narrative imagination, it is claimed, humanities scholars and students develop a conscience more suited to the multicultural world we live in. That conscience might take the form of a passive one that allows more effective self-reflection or extend into active empathy that facilitates the dispensation of civic duties a responsible world citizen must engage in. There is disagreement, however, on the level of influence humanities study can have on an individual and whether or not the understanding produced in humanistic enterprise can guarantee an \"identifiable positive effect on people.\"\n\nThere are three major branches of knowledge: natural sciences, social sciences, and the humanities. Technology is the practical extension of the natural sciences, as politics is the extension of the social sciences. Similarly, the humanities have their own practical extension, sometimes called \"transformative humanities\" (transhumanities) or \"culturonics\" (Mikhail Epstein's term):\nTechnology, politics and culturonics are designed to transform what their respective disciplines study: nature, society, and culture. The field of transformative humanities includes various practicies and technologies, for example, language planning, the construction of new languages, like Esperanto, and invention of new artistic and literary genres and movements in the genre of manifesto, like Romanticism, Symbolism, or Surrealism. Humanistic invention in the sphere of culture, as a practice complementary to scholarship, is an important aspect of the humanities.\n\nThe divide between humanistic study and natural sciences informs arguments of meaning in humanities as well. What distinguishes the humanities from the natural sciences is not a certain subject matter, but rather the mode of approach to any question. Humanities focuses on understanding meaning, purpose, and goals and furthers the appreciation of singular historical and social phenomena—an interpretive method of finding \"truth\"—rather than explaining the causality of events or uncovering the truth of the natural world. Apart from its societal application, narrative imagination is an important tool in the (re)production of understood meaning in history, culture and literature.\n\nImagination, as part of the tool kit of artists or scholars, helps create meaning that invokes a response from an audience. Since a humanities scholar is always within the nexus of lived experiences, no \"absolute\" knowledge is theoretically possible; knowledge is instead a ceaseless procedure of inventing and reinventing the context a text is read in. Poststructuralism has problematized an approach to the humanistic study based on questions of meaning, intentionality, and authorship. In the wake of the death of the author proclaimed by Roland Barthes, various theoretical currents such as deconstruction and discourse analysis seek to expose the ideologies and rhetoric operative in producing both the purportedly meaningful objects and the hermeneutic subjects of humanistic study. This exposure has opened up the interpretive structures of the humanities to criticism humanities scholarship is \"unscientific\" and therefore unfit for inclusion in modern university curricula because of the very nature of its changing contextual meaning.\n\nSome, like Stanley Fish, have claimed that the humanities can defend themselves best by refusing to make any claims of utility. (Fish may well be thinking primarily of literary study, rather than history and philosophy.) Any attempt to justify the humanities in terms of outside benefits such as social usefulness (say increased productivity) or in terms of ennobling effects on the individual (such as greater wisdom or diminished prejudice) is ungrounded, according to Fish, and simply places impossible demands on the relevant academic departments. Furthermore, critical thinking, while arguably a result of humanistic training, can be acquired in other contexts. And the humanities do not even provide any more the kind of social cachet (what sociologists sometimes call \"cultural capital\") that was helpful to succeed in Western society before the age of mass education following World War II.\n\nInstead, scholars like Fish suggest that the humanities offer a unique kind of pleasure, a pleasure based on the common pursuit of knowledge (even if it is only disciplinary knowledge). Such pleasure contrasts with the increasing privatization of leisure and instant gratification characteristic of Western culture; it thus meets Jürgen Habermas' requirements for the disregard of social status and rational problematization of previously unquestioned areas necessary for an endeavor which takes place in the bourgeois public sphere. In this argument, then, only the academic pursuit of pleasure can provide a link between the private and the public realm in modern Western consumer society and strengthen that public sphere that, according to many theorists, is the foundation for modern democracy.\n\nOthers, like Mark Bauerlein, argue that professors in the humanities have increasingly abandoned proven methods of epistemology (\"I care only about the quality of your arguments, not your conclusions.\") in favor of indoctrination (\"I care only about your conclusions, not the quality of your arguments.\"). The result is that professors and their students adhere rigidly to a limited set of viewpoints, and have little interest in, or understanding of, opposing viewpoints. Once they obtain this intellectual self-satisfaction, persistent lapses in learning, research, and evaluation are common.\n\nImplicit in many of these arguments supporting the humanities are the makings of arguments against public support of the humanities. Joseph Carroll asserts that we live in a changing world, a world where \"cultural capital\" is replaced with \"scientific literacy\", and in which the romantic notion of a Renaissance humanities scholar is obsolete. Such arguments appeal to judgments and anxieties about the essential uselessness of the humanities, especially in an age when it is seemingly vitally important for scholars of literature, history and the arts to engage in \"collaborative work with experimental scientists or even simply to make \"intelligent use of the findings from empirical science.\"\n\n\n"}
{"id": "33485814", "url": "https://en.wikipedia.org/wiki?curid=33485814", "title": "Institut für Dokumentologie und Editorik", "text": "Institut für Dokumentologie und Editorik\n\nThe Institut für Dokumentologie und Editorik (IDE - Institute for Documentology and Scholarly Editing) is a German association (with the legal status of \"Eingetragener Verein\") of researchers working on the application of digital methods to historical documents. Fields of interest include digitization, transcription, text encoding, textual criticism, critical scholarly editing, digital palaeography, and digital codicology. It was established in 2006 and has contributed in several ways to the field of digital humanities and has organized Summer Schools on a regular basis at various universities in Germany and Austria (Berlin, Chemnitz, Cologne, Rostock, Vienna). Most notably, the IDE publishes the series \"Schriften des Instituts für Dokumentologie und Editorik\" distributed in print and freely online. The IDE supports open access. The series is discussed and reviewed in German and international journals.\n\nSince July 2014 the IDE also publishes the open access journal \"RIDE: A Review Journal for Digital Editions and Resources\".\n\n"}
{"id": "1949935", "url": "https://en.wikipedia.org/wiki?curid=1949935", "title": "Instituto de Investigaciones Estéticas", "text": "Instituto de Investigaciones Estéticas\n\nThe Institute of Aesthetic Research (Instituto de Investigaciones Estéticas) of the National Autonomous University of Mexico, since its foundation in 1936, research has been carried out in its installations into the different forms of artistic expression in Mexico; the diversity of studies undertaken by the body of researchers in the fields of criticism, theory and history of art across a horizon that reaches other latitudes. It has thus become a space in which the plastic arts converge with dance, literature, photography, cinema and music.\n\nEvery year, through its International Colloquium on Art History, the Institute opens its doors to academic reflection on the history of art. Since 1975, this space has been a meeting point for the voices of both Mexican and foreign researchers.\n\nTo perform its tasks of study and dissemination, both of Mexican art and that of other countries, the Institute harbors a number of different areas, each of which has its particular sphere of interest:\n\nThe distribution of the Institute’s publications is not limited to the UNAM’s system of libraries, but extends to other sales outlets. The electronic shop, still under construction, is also oriented towards the same /will also make a contribution to this effort, bringing the Institute’s work to a broader public.\n\nThe journal Imágenes is an electronic publication which offers various articles publicizing the Institute’s academic activities and other news items to do with the history of art. Its contents and characteristics have made it the most visited section of the Institute’s electronic portal.\n\nIn August, 2007, work started at the new branch headquarters of the Instituto de Investigaciones Estéticas in the City of Oaxaca, which are lodged in an old domestic building in the Alameda de León, which dates from the eighteenth century and was received by the UNAM in commodatum in 2005.\n\nThis branch is home to a library—comprising over six thousand volumes—which belonged to Dr. Beatriz de la Fuente, among which are some facsimiles of pre-Hispanic codices. The library is endowed with the necessary features for operating as a videoconference room. The equipment installed is similar to that in the Francisco de la Maza room in the Institute’s headquarters on the University campus in Mexico City, thus facilitating constant communication between both. It is to be hoped that this study center will become a point of reference for the south of the country and for the whole of Central America.\n\n"}
{"id": "11241203", "url": "https://en.wikipedia.org/wiki?curid=11241203", "title": "International Museum Day", "text": "International Museum Day\n\nInternational Museum Day (IMD) is an international day a celebration that held every year on or around 18 May, coordinated by the International Council of Museums (ICOM). The event highlights a specific theme that changes every year and that is at the heart of the international museum community’s preoccupations.\n\nThe IMD provides the opportunity for museum professionals to meet the public and alert them as to the challenges that museums face. Indeed, following the definition of museums provided by ICOM, a museum is \"a non-profit, permanent institution in the service of society and its development, open to the public, which acquires, conserves, researches, communicates and exhibits the tangible and intangible heritage of humanity and its environment for the purposes of education, study and enjoyment\". International Museum Day therefore serves as a platform to raise public awareness on the role museums play in the development of society today, on an international level.\n\nEach year, all museums in the world are invited to participate in IMD to promote the role of museums around in the world, creating unique, enjoyable and free activities around a theme discussed within the ICOM community for this special day. \nSince its creation in 1977, International Museum Day has gained increasing attention. In 2009, International Museum Day attracted the participation of 20,000 museums hosting events in more than 90 countries. In 2010, 98 countries participated in the celebration, with 100 in 2011, and 30,000 museums in 129 countries in 2012. In 2011, the official IMD poster was translated into 37 languages. Since 2012, this number jumped by one to 38.\n\n\nThe International Council of Museum (ICOM) is the main organisation of museums and museum professionals with a global scope, committed to the promotion and protection of natural and cultural heritage, present and future, tangible and intangible. ICOM’s commitment to culture and knowledge promotion is reinforced by its 31 International Committees dedicated to a wide range of museum specialities, who conduct advanced research in their respective fields for the benefit of the museum community. The organisation is also involved in fighting illicit trafficking, assisting museums in emergency situations, and more.\nICOM created International Museum Day in 1977. The organisation chooses the theme and coordinates the event every year.\n\nMuseums in approximately 70 countries participated in the event. For this edition, the message that was conveyed was \"We are all responsible for universal heritage\".\n\nIn Angola, a debate on \"The Contribution of the National Museum of Anthropology on Asserting Cultural Identity\" was organised.\nIn Algeria, two days were devoted to the theme of heritage and museology in Algeria, the objective being to submit a project to set up a centre for training museum professionals.\nThe Colombo National Museum in Sri Lanka organised visits and workshops for certain schools aimed at teaching pupils to identify with their heritage.\nAt the Acadian Museum of the University of Moncton (Canada), a conference was held to discuss the issues involved in preserving Acadian oral heritage in a museum as a centre of conservation and dissemination.\nIn Israel, the Historic Museum of Bethlehem partially opened on the occasion of IMD.\nIn Botswana, the site museum of Tsodilo celebrated the event by organising performances of plays, music and traditional dances.\nIn Peru, the inhabitants of Lima were invited to the Fifth Feria of “Museums within your reach” with the participation of 30 museums from Europe and Central Asia.\n\nIn 2009, ICOM partnered WFFM (the World Federation of Friends of Museums) in order to promote the event.\n\nIn 2010, museums from 96 countries participated in the event, organised around the theme \"Museums for social harmony\".\n\nIn Mongolia, the theatre museum invited kindergarten children to attend a play in the museum.\n\nThe Samarkand State Museum of Cultural History in Uzbekistan organised an impressive performance with the award-winning children’s dance ensemble Jonona. It was followed by a musical slide show displaying the Samarkand region’s historical heritage.\n\nIn Sri Lanka, the Department of National Museums provided an educational programme with mobile exhibitions for students in the northern region of the country as a means to encourage peace and social harmony among the ethnic groups who are living in the north and the south of the country.\n\nThe Calouste Gulbenkian Museum (Museu Calouste Gulbenkian) in Portugal arranged a special reception for visitors in a bid to highlight its initiative of creating a club for 23 local teenagers with anti-social behaviour.\n\nAbout 30 000 museums in 110 countries participated in the celebration of International Museum Day 2011.\n\nThe theme for 2011 was “Museum and memory. Objects tell our story”. \nFive topics were developed during International Museum Day 2011:\n\nIn Australia, the National Sports Museum in Melbourne organised a programme called \"Remembering the Moments that Made Us\" where visitors of the museum had the opportunity to meet and talk with sporting legends (\"Memory Makers\") who contributed to great sporting moments and memories.\n\nIn Malaysia, seminar with international speakers, exhibitions, sport carnivals, workshops and educational programmes were organised in various museum around the country.\n\nIn Sudan, the Natural History Museum in Khartoum created an educational programme for families and school children who were able to participate in a photography competition on the theme “Documenting Our Natural History”.\n\nIn Argentina, the Museo Argentino de Ciencias Naturales \"Bernardino Ridavia\" in Caba suggested a programme entitled Musecuentos especially established for this occasion. Storytellers shared stories that were highlighted by the museum’s objects.\n\nIn Belgium, the Musée Royal de Mariemont offered guided tours on the theme \"Objects’ CV\".\n\nThe conservation and transmission of collective memory is a preoccupation for other heritage players, beyond the museum community. For this reason, for the first time ever, the International Council of Museums initiated institutional partnerships with other organisations that feel concerned by these questions and share ICOM’s preoccupation for the preservation of memory: \n\nThe International Museum Day 2012 was celebrated around the theme \"Museum in a changing world. New challenges, new inspirations\".\n\nTo celebrate the 35th anniversary of the International Museum Day, the ICOM Fund sponsored a photo contest entitled \"Me in my museum\". The participants had to take photos of themselves, alone or with their friends, in or outside their favourite museums with the official logo created for the event. The winners of the “Me in my museum” contest were Yonit and Efrat, from Israel, whose picture was taken in front of the Tel Aviv Museum of Art.\n\nIn many countries, International Museum Day is the occasion to celebrate museums and their activities. For instance, each year, the month of May is Museums Month in Guatemala, organised with the Ministry of Culture of Guatemala. This year, the theme was \"New challenges and new inspirations\".\n\nIn Brazil, the week of 14–20 May is the opportunity to organise museum activities over several days, and the 18th is celebrated as a national holiday. For the 10th edition of National Museums week, activities such as exhibitions, conferences, guided tours and workshop were organised in Brazilian cities. Museums as well as heritage institutions provided dance performances, music, theatre, poetry contests and more. \n\nIn Peru and Bolivia, International Museum Day is followed by the \"Long Night of Museums\". Visitors have both day and night to visit museums and the event is celebrated in both countries every year. \n\nIn Lithuania, the year 2012 was declared as the Year of Museums, in honour of the bicentenary opening of the first public museums in the country.\n\nThe Museu do Falso (Viseu, Portugal) opened on 18 May 2012, for International Museum Day. Visitors were able to discover the unique Museum of History, made from contributions by contemporary artists, working under the premise of \"Simulacrum: What if a given event occurred differently from how it did?\". This aimed to serve as a hub for cultural actors and citizens.\n\nIn Côte d’Ivoire, IMD 2012 was celebrated in the structure of the Palais Royal of Abenguru. Local institutions and ICOM Côte d’Ivoire organised various events including discussions, game contests for students and guided tours. About 1,500 people joined in the celebrations with important political and cultural actors from the country. \n\nHans-Martin Hinz, President of ICOM, launched the event from Bahrain, with the visit to the National Museum’s exhibition \"Tylos: Journey Beyond Life\" that recounted burial rites and customs in the ancient history of Bahrain. He then experienced the mobile museum \"Enkiru\", an extension of the exhibition specifically geared for children aged 7 to 11. Finally, he participated in a workshop devoted to emerging museum professionals organised by the National Committee of Bahrain, in partnership with ICOM Arab. Meanwhile, the ICOM President personally thanked Chinese and Argentine museums by sending them a video, broadcast during the launch ceremonies for International Museum Day in China and Argentina. \n\nTo celebrate the event, Julien Anfruns, Director General of ICOM, delivered the keynote address on the 17 May at the conference \"Science Museums and New Technologies” organized by the ICOM International Committee for Education and Cultural Action (CECA) in Rome, Italy. He was also a panellist and keynote speaker at the International Bar Association’s conference about new legal challenges in the arts which took place at the MAXXI – National Museum of the 21st Century Arts, Rome).\n\n\nThe museum community decided to celebrate IMD 2013 around the theme: \"Museums (Memory + Creativity) = Social Change\".\n\nIn Peru, the Pachacamac Site Museum scheduled an outdoor interactive project called Paint and Identify in the Pintado Temple to remember the paintings that once decorated this monument. \n\nIn Pakistan, the Museum of Natural History in Islamabad organised a Nature Poster Drawing Competition on the theme of Water and biodiversity, in which students from different schools participated by portraying the beauty of nature. \n\nThe National Museum of History of Moldovain Chişinău, Moldova organised a workshop for the public\non experimental archaeology, paper folding techniques, history and the art of writing. \n\nThe suggested theme for 2014 is Museum collections make connections. \n\nSharjah Museums in the United Arab Emirates carried out an Instagram project called #heartifact, inviting the public to photograph objects that are meaningful to them and post them along with a short description. The museum then created a collage of the images and shared it with the public on International Museum Day. \n\nIn Itu, Brazil, the Museu da Energia organised an event called Arte no Beco (Art in the Alleyway), bringing the museum to the street to raise awareness on the significance of museums and heritage preservation. \n\nIn 2015, the event will celebrate the theme: Museums for a sustainable society.\n\nThe Uganda Museum in Kampala, in Uganda, encouraged visitors to take a plant home or plant a tree at the museum to do their part in creating a sustainable environment. The National Forestry Authority donated trees to the cause. \n\nThe \"Sc'Arti in Mostra\" exhibition organised and promoted by the province of Avellino, in Italy, was the product of an art contest inspired by the themes of reusing and recycling waste through art. The exhibition, open to the public, supported a culture of recycling. \n\nAbout 35,000 museums in 145 countries on all continents participated in IMD 2016.\n\nThe theme of the 2016 event is Museums and Cultural Landscapes. \n\nThe National Gallery of Victoria in Australia organised a conference to discuss how public and private institutions gather their collections and how such collecting can create or preserve a cultural landscape.\n\nThe Chimczuk Museum in the City of Windsor, Canada used International Museum Day as an opportunity to open the \"Fighting in Flanders\" exhibition in the presence of the Belgian ambassador to Canada.\n\n"}
{"id": "34111459", "url": "https://en.wikipedia.org/wiki?curid=34111459", "title": "Jaap van Ginneken", "text": "Jaap van Ginneken\n\nJaap van Ginneken (born September 8, 1943 in Hilversum) is a Dutch psychologist and communication scholar.\n\nVan Ginneken completed a bachelor's degree at the Radboud University Nijmegen, a master’s at the University of Amsterdam, followed by a brief stint at the École pratique des Hautes études en sciences sociales in Paris, and finally a Ph. D. with distinction on mass psychology and crowd psychology. He taught at various universities, ultimately as a long-time associate professor at the International School and Communication Science Department of the University of Amsterdam.\n\nFor most of the 1970s, he worked as a Paris-based newspaper correspondent and roving reporter on third world affairs for Dutch media, with isolated contributions to foreign newspapers such as the French \"Le Monde\" and the British \"The Guardian\". In line with the spirit of May 1968 in France and widespread opposition to the U.S. involvement in the Vietnam war, he adhered to the unequal exchange and dependency theory, and came to sympathize with liberation movements and third world revolutions. Two of his early books then focused on the new conflicts arising from them. \"The rise and fall of Lin Piao\" (and the so-called ‘Gang of Four’) dealt with ultraleftism during the Chinese cultural revolution. \"The third Indochina war\" dealt with the subsequent confrontation between China, Vietnam and Cambodia.\nIn the course of the early 1980s, however, Van Ginneken recognized that he had become too much of a fellow traveler, and returned to academic work in his original fields.\n\nThis covered three themes: first the history of science, second social, political and mass psychology, third media images of other cultures. On the first theme, he published a series of studies on the history of political psychology, crowd psychology, mass psychology and social psychology. He just completed a biography of Kurt Baschwitz: a Jewish- German- Dutch pioneer of communication studies and social psychology. The second theme concerned new approaches to mass psychology and collective behavior sociology, in line with complex adaptive systems and chaos theory \"in Collective behavior and public opinion – Rapid shifts\", with a further Dutch title on self-organization and swarming. Some of his further Dutch books dealt with mass psychology subjects such as behavioral economics and finance, hidden persuaders, and emotional contagion in large groups. Most recently, he has published two books on strange correlates of leadership. The third theme concerned a series of studies on media psychology, and stereotypes about cultural identity. In the international news media: with \"Understanding global news\". In movies: with \"Screening difference – How Hollywood blockbusters imagine race, ethnicity and culture\". As well as on the clash of civilizations, with further Dutch titles on classical comic strips, interpersonal communication and the immigration debate.\n\nNext to his academic work, Van Ginneken always remained involved in a wide range of non-academic projects, for instance in science communication: for national events, major museums and prime-time television. Today, he is an independent speaker and writer, based near Nice in France.\n\n\n"}
{"id": "57147375", "url": "https://en.wikipedia.org/wiki?curid=57147375", "title": "Material religion", "text": "Material religion\n\nMaterial religion is a framework used by scholars of religion examining the interaction between religion and material culture. Its specific focus is on the place of objects, images, spaces, and buildings in religious communities.\n\nSome scholars within the study of religion have criticised the material religion approach for often seeking to reintroduce the phenomenology of religion into the discipline.\n\nThe scholar of religion S. Brent Plate was of the view that \"religion must be understood as deriving from rudimentary human experiences, from lived, embodied practices\". He stated that \"to learn about religion we have to come to our senses. Literally. We have to begin to discover... that we cannot know the worlds of any other culture, let alone our own, unless we get inside the sensational operations of human bodies.\"\n\nThe material religion framework has been promoted by the scholars such as Birgit Meyer, Sally Promey, S. Brent Plate, David Morgan, etc.\n\nIn 2005, the peer-reviewed journal \"Material Religion: The Journal of Objects, Art and Belief\" was launched. In their editorial statement, the editors described it as \"a new project in the study of religious images, objects, spaces, and material practices.\"\n\nThe anthropologist Simon Coleman suggested that the term \"material religion\" was tautological, in that \"religion is inherently material in its very constitution.\"\n\nThe scholars of religion Christopher R. Cotter and David G. Robertson suggested that the material religion framework could be an alternative means to explore religion, in contrast to the dominant world religions paradigm which they regarded as problematic. They nevertheless thought that material religion represented \"phenomenology by stealth\".\n\n"}
{"id": "52856461", "url": "https://en.wikipedia.org/wiki?curid=52856461", "title": "Michael Newton (academic)", "text": "Michael Newton (academic)\n\nMichael Newton is a minority language activist and Scottish Gaelic scholar. He was born in 1965 and raised in a bilingual (Spanish and English speaking) community in Southern California. He embarked on a career in computer game design as a teenager, becoming one of the creators of the pioneering game Dungeon Master at FTL Games. After graduating magna cum laude from the University of San Diego in 1990 with a degree in computer science, he switched his focus to Scottish Gaelic studies and in 1998 was awarded a PhD in Celtic Studies from the University of Edinburgh.\n\nNewton has produced a number of scholarly projects regarding Scottish Gaelic, including books, articles, edited volumes, blog posts, a video documentary, and digital humanities multimedia projects exploring Celtic language poets in North America, for which he has received numerous awards, including the Coralys Award in 2002 and 2003 and the inaugural 2014 Saltire Award from St. Andrews University Scottish Heritage Center. He is a co-founder and board member of Urras Gàidhlig nan Stàitean Aonaichte (Scottish Gaelic Society of the United States).\n\nMuch of his work challenges the negative stereotypes that have been projected onto Gaelic society by anglophone authorities and anglocentric sources, drawing on the methods of post-colonial studies. He is one of the only scholars currently studying the legacy of the Scottish Gaelic immigrant communities of the Americas, especially by locating and analyzing the remains of Scottish Gaelic literature.\n\nHe is currently employed in digital humanities at the University of North Carolina.\n\nThe author Diana Gabaldon, who wrote the Outlander series, wrote a preface to \"Seanchaidh na Coille\". The book was shortlisted for the 2016 Atlantic Book Award for Scholarly Writing and was selected as one of the Best Scottish Books of 2015 by the Association of Scottish Literary Studies.\n\n\n"}
{"id": "1198231", "url": "https://en.wikipedia.org/wiki?curid=1198231", "title": "Middle chronology", "text": "Middle chronology\n\nThe middle chronology is one chronology of the Near Eastern Bronze and Early Iron Age, which fixes the reign of Hammurabi to 1792–1750 BCE and the sack of Babylon to 1595 BCE.\n\nThe chronology is based on a 56/64-year astronomical calculation determined by evidence from the Venus tablet of Ammisaduqa and\nthe Enuma anu enlil tablet 63. Conventional textbooks tend to use the middle chronology, but early dendrochronological and astronomical evidence presented various problems for it. This led to increased adoption of the short chronologies by some. However, more recent studies have shown that the Middle Chronology is most likely.\n\nThe problem raised by using short chronologies is that a century or more needs to be added to some period of the second millennium BCE to accommodate it, but no one so far has been able to make a suggestion as to which period to add it to. That has left second millennium BCE dates appearing artificially short and has resulted in distortion and loss of accuracy for older dates, as a sacrifice to provide greater accuracy for earlier ones.\n\nVarious scholars have favoured different chronologies in recent years. Peter J. Huber has favoured the long chronology, relying on astronomical data available from Enuma anu enlil tablets 20 and 21 linking lunar eclipses to historical events in the Ur III period, along with the Venus tablet of Ammisaduqa, Old Babylonian month lengths.\n\nNumerous elements of Huber's theories have been criticized by a consortium of scholars led by Hermann Gasche and Vahe Gurzadyan, who have suggested an ultra-low chronology based on archaeological evidence and especially on more complete use of astronomical evidence. Gasche and Gurzadyan argue that only the eight-year cycle from the Venus tablet is entirely reliable and of practical use (see update in). The latest studies largely rely on more evidences. A study from 2001 published high-resolution radiocarbon dates from Turkey supporting dates for the 2nd millennium BC that are very close to those proposed by the middle chronology. Further support for the Middle Chronology (or a \"Low-Middle\" eight years lower) was provided by a 2016 study combining dendrochronology and radiocarbon.\n\nA table of historical events, by their different chronologies, is shown below.\n\n"}
{"id": "21514238", "url": "https://en.wikipedia.org/wiki?curid=21514238", "title": "Multiliteracy", "text": "Multiliteracy\n\nMultiliteracies is a term coined in the mid-1990s by the New London Group and is an approach to literacy theory and pedagogy. This approach highlights two key aspects of literacy: linguistic diversity, and multimodal forms of linguistic expression and representation. The term was coined in response to two significant changes in globalized environments: the proliferation of diverse modes of communication through new communications technologies such as the internet, multimedia, and digital media, and the existence of growing linguistic and cultural diversity due to increased transnational migration. Because the way people communicate is changing due to new technologies, and shifts in the usage of the English language within different cultures, a new \"literacy\" must also be used and developed.\nThere are two major topics that demonstrate the way multiliteracies can be used. The first is due to the world becoming smaller, communication between other cultures/languages is necessary to anyone. The usage of the English language is also being changed. While it seems that English is the common, global language, there are different dialects and subcultures that all speak different Englishes. The way English is spoken in Australia, South Africa, India or any other country is different from how it is spoken in the original English speaking countries in the UK.\nThe second way to incorporate the term multiliteracies is the way technology and multimedia is changing how we communicate. These days, text and speech are not the only and main ways to communicate. The definition of media is being extended to include text combined with sounds, and images which are being incorporated into movies, billboards, almost any site on the internet, and television. All these ways of communication require the ability to understand a multimedia world.\n\nThe formulation of \"A Pedagogy of Multiliteracies\" by the New London Group expanded the focus of literacy from reading and writing to an understanding of multiple discourses and forms of representation in public and professional domains. The new literacy pedagogy was developed to meet the learning needs of students to allow them to navigate within these altered technological, cultural, and linguistically diverse communities. The concept of multiliteracies has been applied within various contexts and includes oral vernacular genres, visual literacies, information literacy, emotional literacy, and scientific multiliteracies and numeracy.\n\nDue to changes in the world, especially globalization and an increase in immigration, a debate has arisen about the way students are instructed and learning in school. English, and all subjects, should evolve to incorporate multimodal ways of communication. The New London Group (1996) proposes the teaching of all representations of meaning including, linguistic, visual, audio, spatial, and gestural, which are subsumed under the category of multimodal. A pedagogy of multiliteracies includes a balanced classroom design of Situated Practice, Overt Instruction, Critical Framing and Transformed Practice. Students need to draw on their own experiences and semiotic literacy practices to represent and communicate meaning.\n\nThe changes that transpire through the field of education affect learning processes, while the application of learning processes affects the use of multiliteracies (Selber, 2004). These include the functional, critical, and rhetorical skills that are applied in diverse fields and disciplines.\n\nEducational pedagogies, including Purpose Driven Education, integrate the use of multi-literacy by encouraging student learning through exploration of their passions using their senses, technology, vernaculars, as well as alternative forms of communication. \n\nThe New London Group is a group of ten academics who met at New London, New Hampshire, in the United States in September 1994, to develop a new literacy pedagogy that would serve concerns facing educators as the existing literacy pedagogy did not meet the learning needs of students. Their focus was on replacing the existing monolingual, monocultural, and standardized literacy pedagogy that prioritized reading and writing, with a pedagogy that used multiple modes of meaning making. They emphasised the use of multiple modes of communication, languages, and multiple Englishes to reflect the impact of new technologies and linguistic and cultural diversity, instead of developing competence in a single national language and standardized form of English. The ten academics brought to the discussion their expertise and personal experience from different national and professional contexts. Courtney Cazden from the United States has worked in the areas of classroom discourse and multilingual teaching and learning; Bill Cope from Australia, on literacy pedagogy and linguistic diversity, and new technologies of representation and communication; Mary Kalantzis from Australia, on experimental social education and citizenship education; Norman Fairclough from the United Kingdom, on critical discourse analysis, social practices and discourse, and the relationship between discursive change and social and cultural change; Gunther Kress from the United Kingdom, on social semiotics, visual literacy, discourse analysis, and multimodal literacy; James Gee from the United States, on psycholinguistics, sociolinguistics, and language and literacy; Allan Luke from Australia on critical literacy and applied linguistics; Carmen Luke from Australia, on feminism and critical pedagogy; Sarah Michaels from the United States, on classroom discourse; and Martin Nataka on indigenous education and higher education curriculum. The article \"A Pedagogy of Multiliteracies: Designing Social Futures\" published in 1996, documents the New London Group's \"manifesto\" of literacy pedagogy that is recommended for use in educational institutions, in the community, and within organizations.\n\nThe multiliteracies pedagogical approach involves four key aspects: Situated Practice, Critical Framing, Overt Instruction, and Transformed Practice. Situated Practice involves learning that is grounded in students' own life experiences. Critical Framing supports students in questioning common sense assumptions found within discourses. Overt Instruction is the direct teaching of \"metalanguages\" in order to help learners understand the components of expressive forms or grammars. Transformed Practice is where learners engage in situated practices based in new understandings of literacy practices.\n\nSituated Practice, originally formulated by the New London Group (1996) as one of the related components of Multiliteracies Pedagogy, is constituted by immersion in meaningful practices within a community of learners who are culturally and linguistically diversified. It involves situating meaning making in real-world contexts and taking account of the affective and sociocultural needs of learners. This aspect of the curriculum needs to draw on the lifeworld experiences of students, as well as their out-of-school communities and discourses, as an integral part of the learning experience. In order to apply Situated Practice to curriculum realities, Cope & Kalantzis (2009) reframed it as “experiencing” (p. 184)\".\" They believe human cognition is situated and contextual, and meanings are grounded in the real world of patterns of experience, action and subjective interest. Experiencing takes two forms.\n\nSituated Practice/experiencing connects with a tradition called 'authentic pedagogy'. Authentic pedagogy was first formulated as a direct counterpoint to didactic pedagogy in the twentieth century, initially through the work of John Dewey in the United States and Maria Montessori in Italy. It focuses on the learner's own meanings, the texts that are relevant to them in their everyday lives. When it comes to reading and writing, authentic literacy pedagogy promotes a process of natural language growth that begins when a child learns to speak, with a focus on internalized understanding rather than the formalities of rules. It is learner-centered and aims to provide space for self-expression.\n\nHowever, the New London Group (1996) points out limitations to Situated Practice. First, while situated learning can lead to mastery in practice, learners immersed in rich and complex practices can vary significantly from each other and Situated Practice does not necessarily lead to conscious control and awareness of what one knows and does. Second, Situated Practice does not necessarily create learners who can critique what they are learning in terms of historical, cultural, political, ideological, or value-centered relations. Third, there is the question of putting knowledge into action. Learners might be incapable of reflexively enacting their knowledge in practice. Therefore, they clarify that Situated Practice must be supplemented by other components and powerful learning arises from weaving between Situated Practice, Overt Instruction, Critical Framing and Transformed Practice in a purposeful way.\n\nCritical Framing in multiliteracies requires an investigation of the socio-cultural contexts and purposes of learning and designs of meaning. Cope and Kalantzis (2001) discuss this in the context of our increasingly diverse and globally interconnected lives where the forces of migration, multiculturalism, and global economic integration intensify the processes of change. The act of meaning-making is also diversifying as digital interfaces level the playing field.\n\nMills (2009) discusses how multiliteracies can help us go beyond heritage print texts that reproduce and sustain dominant cultural values by creating affordances for thinking about textual practices that construct and produce culture. Another dimension of this critical framing may be extended to the diverse types and purposes of literacy in contemporary society. The traditional curricula operates on various rules of inclusion and exclusion in the hierarchical ordering of textual practices, often dismissing text types such as picture books or popular fiction. Similarly, items like blogs, emails, websites, visual literacies, and oral discourses may often be overlooked as \"inferior literacies\". In excluding them from mainstream literacy practices, we become prone to disenfranchise groups and may lose out on opportunities to sensitize learners to consider underlying issues of power, privilege, and prejudice, both in terms of identifying these in societal practices, as well as in questioning dominant discourses that normalize these. Mills also states how some scholars such as Unsworth (2006a, 2006b) and Mackey (1998) suggest an increased blurring of 'popular culture' and 'quality literature' facilitated by classical literature made available in electronic formats and supported by online communities and forums.\n\nIn addition to acknowledging increased socio-cultural contextualization and diversification of text-types, multiliteracies pedagogies also enable us to critically frame and reconceptualize traditional notions of writing, calling into question issues of authority, authorship, power, and knowledge. Domingo, Jewitt, & Kress (2014) address these concepts through a study of template designs on websites and blogs that empowers the readers through non-linear readings paths, with the modular layout allowing them to choose their own reading paths. They also discuss the varying affordances of different modes and how writing become just one part of the multimodal ensemble.\n\nMultiliteracies transcend conventional print literacies and the centrality of cultures that have historically extolled it, offering much scope for arts-based approaches in decolonizing initiatives (Flicker et. al., 2014) or reflexive visual methodologies in situated contexts (Mitchell, DeLange, Moletsane, Stuart, & Buthelezi, 2005). However, in so far as access to digital tools and infrastructures is concerned, we still need to take into account issues of agency, capital, socioeconomic status, and digital epistemologies (Prinsloo & Rowsell, 2012).\n\nIn the original formulation of the New London Group, Overt Instruction was one of the major dimensions of literacy pedagogy that was identified. The original view of overt instruction includes the teachers and other experts' supporting students through scaffolding and focusing the students on the important features of their experiences and activities within the community of learners (Cope & Kalantzis, 2000, p. 33). Cope and Kalantiz argue teachers and other experts allow the learner to gain explicit information at times by building on and using what the learner already knows and has achieved. Overt Instruction is not, as it is often misrepresented, direct transmission, drills, and rote learning. It includes the kinds of collaborative efforts between teacher and student in which the student can do a task that is much more complex than the task s/he can do it individually. According to Cope and Kalantzis, \"Overt Instruction introduces an often overlooked element-the connection of the element of the importance of contextualization of learning experiences to conscious understanding of elements of language meaning and design\" (p. 116) Use of metalanguages, Cope and Kalantzis argue, is one of the key features of Overt Instruction. Metalanguages refer to \"languages of reflective generalization that describe the form, content, and function of the discourses of practice\" (p. 34).\n\nAfter applying Overt Instruction orientation to curriculum practices for around a decade, this dimension of literacy pedagogy was reframed and translated in the Learning by Design project into the 'Knowledge Process' of conceptualizing (Cope & Kalantzis, 2009, 2015). \nConceptualizing involves \"the development of abstract, generalizing concepts and theoretical synthesis of these concepts\" (Cope & Kalantzis, 2015, p. 19). Using these Knowledge Processes, learners can categorize terms, and collect these into the mental models. Conceptualizing, according to Cope and Kalantzis (p. 19) occurs in two ways:\nConceptualizing by Naming-categorization is a Knowledge Process by means of which the learner learns to use abstract, generalizing terms. A concept not only names the particular; it also abstracts something general from that particular.\n\nActivity type: define terms, make a glossary, label a diagram, sort or categorize like or unlike things\nConceptualizing with theory-schematization is a Knowledge Process by means of which learners make generalizations and put the key terms together into interpretative framework. They build mental models, abstract frameworks and transferable disciplinary schemas (Cope & Kalantzis, 2009, p. 185). \nActivity type: draw a diagram, make a concept map, or write a summary, theory or formula which puts the concepts together\n\nTransformed Practice, originally framed by the New London Group (1996) as part of the four components of Multiliteracies pedagogy, is embedded in authentic learning, where activities are re-created according to the lifeworld of learners. Transformed Practice is transfer in meaning-making practice, which involves applied learning, real-world meanings, communication in practice, and applying understanding gained from Situated Practice, Overt Instruction, and Critical Framing to a new context. Once learners are aware of how context affects their learning, the \"theory becomes reflective practice\" (The New London Group, 1996, p. 87). In other words, learners can reflect on what they have learned while they engage in reflective practice based on their personal goals and values in new contexts. For instance, learners design a personalized research project on a specific topic.\n\nTransformed Practice subsequently underwent reformation and was renamed \"Applying\" as part of \"Knowledge Processes\" (Cope & Kalantzis, 2009, p. 184), formerly known as Multiliteracy pedagogy. Applying is considered as the typical focus of the tradition of applied or competency-based learning (Cope & Kalantzis, 2015). While learners actively learn by applying experiential, conceptual or critical knowledge in the real world, learners act on the basis of knowing something of the world, and learning something new from the experience of acting. That is, applying occurs more or less unconsciously or incidentally everyday in the lifeworld, since learners are usually doing things and learning by doing them. Applying can occur in two ways:\n\n\n"}
{"id": "16371643", "url": "https://en.wikipedia.org/wiki?curid=16371643", "title": "Noddy (TV interview technique)", "text": "Noddy (TV interview technique)\n\nNoddy headshots or noddies are a type of camera shot used in recorded news or current affairs interviews. The noddies consist of nods and other similar \"listening gestures\" made by the interviewer. If only one camera is available at the interview site, then these shots are recorded after the actual interview takes place. The shots are spliced into the interview during the editing process to mask any cuts that have been made. This editing technique is universally \"read\" by audiences as expressing realism and therefore creates the illusion of a seamless dialogue in the interview.\n\nThe earliest use of the term recorded by the \"Oxford English Dictionary\" dates from 1982. It was explained more fully by John Fiske in 1987: \"the camera is then turned onto the interviewer who asks some of the questions again and gives a series of \"noddies,\" that is, reaction shots, nods, smiles, or expressions of sympathetic listening. These are then used to disguise later edits in the interviewee's speech... Without the \"noddy\", the visuals would show an obvious \"jump\" that would reveal the edit.\"\n\nIn the United Kingdom, the term came to public prominence in 2007 when it was revealed that a BBC programme inserted noddies featuring the senior broadcaster Alan Yentob into interviews that he did not conduct, creating the impression that he had been present. This controversy, which was covered in many newspapers as \"Noddygate\", came at a time when the BBC was already under scrutiny for falsifying certain aspects of entertainment shows for editorial reasons.\n\n\n"}
{"id": "41976334", "url": "https://en.wikipedia.org/wiki?curid=41976334", "title": "On Cinema", "text": "On Cinema\n\nOn Cinema (also called On Cinema at the Cinema for the video series) is an American comedic film review podcast and web series starring Tim Heidecker and Gregg Turkington. The duo appear as a pair of hapless movie reviewers (using their own names). The show started as an independently released podcast from 2011 to 2013, before being picked up as a professionally produced web video series by Thing X in 2012–13 for its first two seasons, and then moving to Adult Swim.com in 2013. It has aired 10 seasons, plus one special\nseason titled \"The Trial\". In addition, \"On Cinema\" spawned a spinoff web series in its fifth season, \"Decker,\" a simultaneous spoof of political-thrillers and homebrew video intended for the web. It later became a TV series, and as of 2018, it has aired 6 seasons of episodes total on Adultswim.com and Adult Swim.\n\nHeidecker and Turkington began making the podcast as a prank and a mockery of the \"self-indulgence\" of the podcasting community. Both Heidecker and Turkington have created an immersive universe through \"On Cinema\" and \"Decker.\" A live Oscar special is also done every year, streamed via YouTube, with interactive elements for fans, such as polling. Several seasons of \"On Cinema\" have discernible multi-episode plot arcs as Heidecker and Turkington explore the dynamic and characters they have created both in the series' episodes and, simultaneously, on social media, through Twitter, Facebook, and YouTube.\n\nThe show has a dedicated cult following of fans who play along with the storylines via social media, often taking sides as \"GreggHeads\" or \"TimHeads\". Heidecker and Turkington also started \"Decker-Con\", where they appear in character and interact with fans.\n\nFor the Summer of 2018, Heidecker and Turkington initiated a nationwide \"On Cinema Live!\" tour with special guests from the On Cinema/Decker universe and special content.\n\nEarly audio episodes of \"On Cinema\" were quite short, frequently no more than one or two minutes long. Heidecker and Turkington would \"review\" films on these podcasts without actually providing any meaningful information or critical insight. Nearly every film that has been discussed or mentioned on \"On Cinema\" since the podcast's inception has received a \"5 bags of popcorn\" rating on a scale of five from the two reviewers, regardless of its reception elsewhere in the press or with the viewing public.\n\nWith the series' growth into an online video series, episodes grew to an average length of eight to twelve minutes. Although reviewing films remains a central conceit, the focus of the series quickly shifted from a mockery of amateur podcasting to an extended character study of the two podcasters. Heidecker, in character on \"On Cinema\", frequently uses his time on camera to discuss anything on his character's mind except film, especially his bizarre ailments, personal crises, and right-wing political views, or to simply berate and belittle Turkington. Turkington's character fancies himself a \"film expert,\" his primary qualification being an enormous collection of forgotten and arguably forgettable mainstream films from the 1980s and 1990s on VHS. The series continues to provide reviews that purposely offer no real critical insight. Recent seasons as of 2018 have seen Tim lose interest in reviewing and start a band first named \"Dekkar\" then \"DKR\" .\n\nGuest appearances have included Jordan Hoffman, Jimmy McNichol, Joe Estevez, Lawrence Turman, Sally Kellerman, Candy Clark, Mark Proksch, John Aprea, Peyton Reed, and Nicholas Meyer, some of whom also appear in the \"Decker\" series.\n\nThe \"On Cinema\" podcast was produced independently by Tim and Gregg. The podcast consists of Tim, along with Gregg as a \"special guest\" for every episode, covering movies poorly and with little insight, and often engaging in arguments. Gregg later developed a more pretentious \"film buff\" persona, and Tim took a turn to being obnoxiously political, sometimes devoting entire episodes to conspiracy theories, much to the chagrin of Gregg.\n\nAnother running joke that was carried over to the video series is Gregg's refusal to believe that \"\" is really \"Star Trek II,\" instead often believing stubbornly that \"\" is the real Star Trek II.\n\nStarting this season, the show is now in video format via Thing X.com, as well as having its name changed to \"On Cinema at the Cinema\". The series is similar to the podcast, but this time episodes always take place on a set meant to look like a movie theatre. Gregg is still never acknowledged as more than a guest each episode, and starts his weekly segments \"Popcorn Classics\" and \"On Cinema On Location\" where he brings in obscure, forgotten VHS movies to showcase and travels to filming locations of obscure movies, respectively. Tim begins using \"60 second soap box\" to talk about current political issues with a conservative narrative, much to the continued annoyance of Gregg. With the start of the web series, Tim uses a rating scale of \"bags of popcorn\" ranging from 0–5, and while Gregg uses five as a max, Tim often goes overboard giving scores of \"6 bags\" or even more, creating tension and confusion throughout the season. Most of the films reviewed get a score of at least \"5 bags\" from both reviewers.\n\nTim reveals he has blood clotting in his brain but does not want to get surgery because of \"side effects, the whole medical industry, and Obamacare\" while Gregg pushes for him to get surgery. In episode 208, Tim introduces the first special guest, Ayaka, a foreign exchange student from Japan staying with Tim's family.\n\nThe first Live On Cinema Oscar Special airs, where Tim and Gregg live stream during the Oscars and drink alcohol. Tim gets very drunk and throws up on some of Gregg's VHS tapes which causes Gregg to walk off the set.\n\nSeason 3 moved the series from Thing X to Adultswim.com. The season begins with Tim in a head bandage and clearly in physical pain as he went through with surgery for his blood clots. As a result of him going through the surgery, Tim's wife divorces him and this is the last time his family is referred to throughout the series. Gregg begins his goal of making the \"Guinness Book of World Records\" by becoming the first person in history to watch 500 movies in 500 days. Tim kicks Gregg off the show after Gregg drives all the way from Hollywood to San Francisco to make a video alleging the location of a \"Star Trek\" filming location, after he and Tim had disagreed on it before. John Aprea and Ayaka are guests on the next episode, where Tim reveals he is dating Ayaka and says he loves her for the first time. In the season finale, Gregg returns to the show as Ayaka was deported back to Japan.\n\nTim begins season four with many health problems and introduces his personal doctor, Dr. San (played by Zac Holtzman), an alternative medical doctor treating Tim with acupuncture, transcutaneous electrical nerve stimulation and other \"natural\" medicines. Dr. San begins coming onto the set with Tim, despite Gregg's objections. However, Tim's face becomes infected from the acupuncture and he denounces Dr. San.\n\nAyaka sends a letter to Tim on the show saying she is pregnant with Tim's child.\n\nThe second Live Oscar Special, Tim and Gregg drink (with Tim getting much drunker than Gregg). We are introduced to Mark Proksch who does impersonations of W.C. Fields and Charlie Chaplin.\n\nTim moves to Jackson Hole, Wyoming and buys a motorcycle to commute back and forth between there and Hollywood for the On Cinema taping.\n\nTim announces that Ayaka has had an abortion, despite remaining pro-life on the topic, saying \"when you are in that situation, choices have to be on the table.\" However, Gregg brings Ayaka onto On Cinema via Skype from Japan, revealing she did go through with the pregnancy and naming the boy Tom Cruise Heidecker Junior, after the actor Tom Cruise. Ayaka moves back to America with Tom Cruise Junior and into Gregg's apartment. This upsets Tim and he moves permanently to Jackson Hole. He makes Gregg host of the show and hands off all responsibilities to him in the season finale.\n\nGregg begins his first season as host, but after he is unable to find a guest, he records himself having conversations with himself and plays VHS video of his conversation during the episode.\n\nTim returns as host in episode 602 after he realized his new friends in Jackson Hole were white supremacists. He rekindles his relationship with Ayaka and moves into Gregg's apartment with her and Tom Cruise Junior. In the season finale, Tim proposes to Ayaka and she accepts.\n\nThe third Live Oscar Special airs, while Tim and Gregg get drunk and Tim, once again, gets much drunker than Gregg and becomes belligerent. Peyton Reed comes on the Special to promote his new film \"Ant-Man\" and announces that Gregg has been cast as a minor character in the movie, which upsets Tim. In the finale segment, Gregg introduces James Dean, the former actor who was believed to be dead since 1955. After reading on a message board about how Dean faked his own death and wrote a memoir called \"I'm Alive: How I Faked my own Death\" he brings Dean on set as his return to the public. Tim does not believe this is the real James Dean, leading to him verbally and physically threatening Dean before trashing the set.\n\nGregg moves to Victorville, California and opens the Victorville Film Archives in a storage locker, where he also lives.\n\nTim gives \"Ant-Man\" a rare one-bag of popcorn which upsets Gregg, leading to him accusing Tim of paying $15,000 to have a minor role in the new \"Fantastic Four\" movie, which Tim denies.\n\nAfter meeting a man at Guitar Center named Axiom, Tim starts a rock band named \"Dekkar\" with him. Their debut single Empty Bottle is released on the show, which upsets Gregg as it is not movie related and was played instead of his Popcorn Classic segment.\n\nGregg tells Tim that Dr. San, who Tim has been looking for since he infected Tim's face with dirty needles in acupuncture in season four, is Ayaka's boss at her job. Tim walks off the set angry that he had not realized this. However, the next episode is \"The Doctor San Forgiveness Special\" where both Tim and Dr. San forgive each other. Dr. San takes over as Tom Cruise Junior's new pediatric doctor.\n\nBy the season seven finale, Tim announces that Tom Cruise Junior has died. He plays a musical tribute to his son with Axiom and Dr. San.\n\nThe fourth Live Oscar Special is the biggest one yet, with periodic musical performances by Dekkar (much to the annoyance of Gregg), the \"Oscar Olympics\" featuring three games, officiated by Joe Estevez, and a DNA test by Dr. San of James Dean, which proves that he is in fact, James Dean. Tim hides the fact he has been drinking alcohol during the Special while no one else is, and he becomes angered by the DNA results. He proceeds to kick Dr. San off the set. An animated rendering of Tom Cruise Junior as a young adult comes on stage, in which Tim and the animated Tom Cruise Junior come out against vaccination.\n\nSeason eight moves the show to Victorville, where Tim has now moved into the storage unit with Gregg. They both buy an abandoned movie theater and open it as the \"Victorville Film Center\" where instead of playing new releases, a nightly showing from Gregg's VHS collection of Popcorn Classics is played. Attendance is minimal because of the obscurity of the films. Mark Proksch is hired as a concessions cashier.\n\nDr. San prescribes Tim a \"nutritional vape system\" in which Tim replaces all meals and food with an electronic cigarette full of supposed nutrients. However, Tim's physical condition worsens as the season progresses, as he comes to the set sweating, bruised, hallucinating, and unfocused. Despite this, he continues to use his nutritional vape system. After he cannot take the physical pain and symptoms of the vape system, Tim goes to an actual doctor who informs him the vape and his blood is full of Lsd, cocaine, and multiple other drugs – both legal and illegal. Tim quits the vape system and swears off Dr. San once again. Tim announces that Ayaka is pregnant with their second child. After Tim tries to get Ayaka to get an abortion, she leaves him and moves back to Japan. Tim begins a romantic relationship with Axiom's sister, Juliana.\n\nA fire is started in the storage unit after Tim's vape pen overheats one night, burning the entire facility down including the Victorville Film Archive. Tim suffers third degree burns on all of his body, including his face and hands. After insurance will not cover the cost of the fire, he returns to the show in bandages so he can keep working to pay for the damages and lawsuits, which exceed $1,000,000 according to Gregg.\n\nHowever, in Tim's return to On Cinema, he is surprised by an intervention by Gregg, Joe Estevez, John Aprea, Mark Proksch, Ayaka, Ayaka's father, and Axiom. They encourage Tim to live a healthier life, which upsets Tim. He yells and kicks everyone but Axiom out, and announces plans to start an electronic music version of Dekkar, now called \"DKR\".\n\nThe season finale ends with a remixed, electronic version of Empty Bottle and Tim announcing that Juliana is now pregnant with his child while Ayaka will go through with her pregnancy too.\n\nSeason nine begins with Gregg informing the audience that the Victorville Film Center has burnt down while he speculates Tim may have done it to collect insurance money.\n\nAfter Gregg and Tim move back to Hollywood, Tim opens up \"Six Bag Cinemas\", a new movie theater concept with recliner chairs and a waiter (who is Mark) that brings food to customers during the movie. Gregg constantly criticizes the theater and food.\n\nAfter Tim stops using the facial cream for the burns on his face, his skin dies and he needs a skin transplant. After a selection process in which Tim volunteers most of the potential donors himself, Manuel from DKR is chosen and donates skin off of his lower back and buttocks to Tim.\n\nTim and Dr. San are arrested and jailed on murder and manslaughter charges. At Tim's \"Electric Sun Desert Music Festival\" in Apple Valley, California, Dr. San allegedly gave out free samples of his nutritional vape system, the same one Tim uses, resulting in 20 deaths. Gregg takes over as host with Mark as his co-host, and the two spend an entire episode blaming Tim instead of reviewing movies.\n\nTim returns on bail, and finishes the last three episodes of the season with Turkington. Together with his lawyer, Doug Lyman, Tim has decided to pin the 20 deaths on Dr. San and the Apple Valley authorities who did not respond in time. In the season finale, it is revealed that Dr. San has committed suicide in jail, and that the relatives of the 20 who died are now primarily blaming Tim for the deaths. At the end of the final episode, Tim reveals to Gregg that he will never forget what Gregg said about him on the show, no matter what happens to him.\n\nA special event, titled \"The Trial\", began on November 15, 2017, streaming on Adult Swim's website with the trial of Tim Heidecker for the death of the \"Electric Sun 20\". Tim was found not guilty of the death of one of the 20, as that victim died of a heroin overdose. A mistrial was called for the remaining 19, due to a hung jury with 11 guilty and 1 not guilty verdicts. Gregg accused Tim of bribing the juror who voted not guilty.\n\nDirector and writer Nicholas Meyer appears as one of the testifiers in an ongoing joke alluding to a long-standing disagreement between Tim and Gregg as to whether or not San Francisco is the setting for the film \"Star Trek II.\" \n\nDuring the Fifth Oscar Special, Mark got locked tight into a standard diving dress while doing an impression of Richard Dreyfuss character in the Jaws movie and had to be hospitalized for asphyxiation.\n\nTim returns from the trial free from prison but facing a civil suit from one of the families of the Electric Sun 19. His assets, including On Cinema and Decker, are being seized and he claims he might soon be facing bankruptcy. After threatening to commit suicide and with help from his attorney (Mark Dwyer), Tim manages to convince the Delgado family to let him try to earn money for them with his various assets. The Delgado's and Tim's Attorney like the show after Episode 7, and hire Gregg as the managing editor of the newly incorporated Delgado Media Holding company, effectively giving him creative control on On Cinema.\n\nThe intro and production set have been upgraded, and the show now has a sponsor by name of Rio Jenesis, a protein shake company that creates a \"germ shield\", of which Tim is now consuming. Gregg begins writing letters to Tim Burton, questioning why he didn't work with Johnny Depp in \"Sherlock Gnomes\". He also announces that he has resurrected his film archives, which appears to be several bins full of VHS tapes (later revealed to be stocked in Mark Proksch hospital room) and is now collecting and wearing movie promotional hats to Tim's vocal displeasure. Episodes 4 through 6 were filmed in 360-degree video.\n\nAs of Episode 7, the show has returned to form with a stronger focus on movies than it had previously had in the last several seasons. However, this is in the context of Tim needing to turn the show around, with him openly discussing the possibility of suicide if it doesn't become more successful. The next three episodes, 8–10, saw Gregg's role on the show increasingly become that of the host, while Tim's role was diminished, allowing for more of Gregg's segments, including Popcorn Classics, to become larger segments in each episode. These changes coincided with Gregg's new role as the managing editor in On Cinema's parent company. In episode 10, the season finale, Tim threw a fit of rage and insulted the Delgados while announcing his wish to campaign for the post of district attorney of the San Bernardino County.\n\nHeidecker has stated that On Cinema was started out of a desire to mock the podcasting community. The first episode was recorded on set of \"The Comedy\", where Heidecker and Turkington were working together, after Heidecker proposed the idea between takes.\nIn April 2017, On Cinema initiated a Patreon page for funding, most of it going to the Oscar specials, with some of the higher options including receiving producer credits, walk-on roles for the Oscar specials, or live custom Skype reviews from Gregg Turkington.\n\nThe show has a dedicated cult following of fans who interact with the storylines via social media, often taking sides as \"GreggHeads\" or \"TimHeads\" in the frequent personal conflicts between the hosts which are often only tangentially, if at all, related to films or cinema. During the annual live Oscar special, Tim and Gregg both frequently provide interactive elements via online polls for fans to vote on. This cult following is especially found on YouTube, Facebook and Twitter, the latter through Gregg and Tim's respective profiles, of which Gregg has completely devoted to the persona of his alter-ego. Heidecker and Turkington have also appeared in character on the podcasts \"Kreative Kontrol\" and \"Best Show\" in 2015 and 2017.\n\nHeidecker and Turkington also started \"Decker-Con\", where new episodes of \"Decker\" are shown to fans and the cast appears as their \"On Cinema\" characters to field questions.\n\nIn 2013 the \"On Cinema Film Guide\" app was released, featuring the voices of Turkington and Heidecker reviewing over 17,000 films.\n\nFor \"The Trial\", Heidecker and Turkington upended the traditional review aspect of the series, and staged an elaborate mock event where Tim's character was \"on trial for murder\" that lasted over a week. It received acclaim from observers, some of whom called it \"brilliant\" and \"ambitious.\"\n\nIn 2018, Heidecker and Turkington initiated a nationwide \"On Cinema Live!\" tour with special guests from the On Cinema/Decker universe such as Joe Estevez, the band \"Dekkar\" and special content created only for the tour, such as a live reviewing of all mid-2018 major release films: \"Superfly\", \"\", \"\", \"\", \"Ant Man & The Wasp\".\n\n"}
{"id": "19027841", "url": "https://en.wikipedia.org/wiki?curid=19027841", "title": "Open Humanities Press", "text": "Open Humanities Press\n\nOpen Humanities Press is an international open access publishing initiative in the humanities, specializing in critical and cultural theory. OHP's editorial board includes leading scholars such as Alain Badiou, Jonathan Culler, Stephen Greenblatt, Jean-Claude Guédon, J. Hillis Miller, Antonio Negri, Peter Suber and Gayatri Spivak among others.\n\nThe Open Humanities Press (OHP) is a scholar-led publishing initiative founded by Paul Ashton (Australia), Gary Hall (UK), Sigi Jöttkandt (Australia) and David Ottina (US). Its aim is to raise awareness of open access publishing in the humanities and to provide promotional and technical support to open access journals that have been invited by OHP's editorial oversight group to join the collective.\n\nOHP launched in May 2008 with seven open access journals and was named a \"beacon of hope\" by the Public Library of Science. In August, 2009 OHP announced it will begin publishing open access book series edited by senior members of OHP's board. \n\nThe monograph series are:\n\nJournals\n\nOpen Humanities Press also host several open access journals, including the following:\n\n\n"}
{"id": "36266017", "url": "https://en.wikipedia.org/wiki?curid=36266017", "title": "Paradox of fiction", "text": "Paradox of fiction\n\nThe paradox of fiction is a philosophical problem about how people can experience strong emotions from purely fictional things, such as art, literature, and imagination. The paradox draws attention to an everyday issue of how people are moved by things which, in some ways, do not exist. Although the ontology of fictional things in general has been discussed in philosophy since Plato, the paradox was first suggested by Colin Radford and Michael Weston in 1975. After Radford and Weston's original paper, they and others have continued the discussion by giving the problem slightly differing formulations and solutions.\n\nThe basic paradox is as follows:\n\n\nThe paradox is that all three premises seem to be true, but can not logically be true at the same time. If any two points (e.g. 1 and 3) are taken to be true, then the third (e.g. 2) must either be false or else produce a contradiction.\n\nThe various proposed solutions to the paradox can be divided into three basic groups:\n\n\n"}
{"id": "16618624", "url": "https://en.wikipedia.org/wiki?curid=16618624", "title": "Planning and zoning commission", "text": "Planning and zoning commission\n\nA Planning and Zoning Commission is a local elected or appointed government board charged with recommending to the local town or city council the boundaries of the various original zoning district and appropriate regulations to be enforced therein and any proposed amendments thereto and shall collect data and keep itself informed as to the best practices generally in effect in the matter city planning and zoning to the end that it may be qualified to act on measures affecting the present and future movement of traffic, the segregation of residential and business districts and the convenience and safety of persons and property in any way dependent on city planning and zoning. Some jurisdictions may refer to them also planning commissions, planning boards, zoning commissions, and zoning boards.\n\nThe chairman of the Planning and Zoning Commission (or a staff member) is responsible for publishing public hearing in the newspaper about certain matters that come before the commission. Most municipal or county Planning and Zoning Commissions consist of five to seven members. This number does not include alternates. In some states, planning and zoning commissions are regional or county.\n\nSome communities elect planning and zoning commission members. In other jurisdictions, the Planning and Zoning Commissioners are appointed by the Mayor or First Selectman of the city or town and approved by the city's legislative body, i.e. city council, board of aldermen, etc. (some planning commissioners are appointed by the City Commission as a whole). \n\nPlease note that planning and zoning commissions may also be approving agencies for development permits, variances to the zoning code. Other jurisdictions may have separate zoning board of adjustments or appeals appointed by the governing body that perform the function instead of the planning and zoning commission doing it. Some jurisdictions have featured court appointed zoning boards/boards of adjustment and appeals due to the quasi-judicial functions.\n"}
{"id": "4214394", "url": "https://en.wikipedia.org/wiki?curid=4214394", "title": "Practical joke", "text": "Practical joke\n\nA practical joke, or prank, is a mischievous trick played on someone, generally causing the victim to experience embarrassment, perplexity, confusion, or discomfort. A person who performs a practical joke is called a \"practical joker\". Other terms for practical jokes include gag, jape, or shenanigan.\n\nPractical jokes differ from confidence tricks or hoaxes in that the victim finds out, or is let in on the joke, rather than being talked into handing over money or other valuables. Practical jokes are generally lighthearted and without lasting impact; they aim to make the victim feel humbled or foolish, but not victimized or humiliated. Thus most practical jokes are affectionate gestures of humour and designed to encourage laughter. However, practical jokes performed with cruelty can constitute bullying, whose intent is to harass or exclude rather than reinforce social bonds through ritual humbling.\n\nSome countries in Western culture traditionally emphasize the carrying out of practical jokes on April Fools' Day.\n\nA practical joke is \"practical\" because it consists of someone doing something physical, in contrast to a verbal or written joke. For example, the joker who is setting up and conducting the practical joke might hang a bucket of water above a doorway and rig the bucket using pulleys so when the door opens the bucket dumps the water. The joker would then wait for the victim to walk through the doorway and be drenched by the bucket of water. Objects can also be used in practical jokes, like fake vomit, chewing gum bugs, exploding cigars, stink bombs, costumes and whoopee cushions.\n\nPractical jokes often occur inside offices, usually to surprise co-workers. Covering the computer accessories with Jell-O, wrapping the desk with Christmas paper or aluminium foil or filling it with balloons are just some examples of office pranks. Practical jokes are also common occurrences during sleepovers, whereby teens will play pranks on their friends as they come into the home, enter a room or even as they sleep.\n\nAmerican humorist H. Allen Smith wrote a 320-page book in 1953 called \"The Compleat Practical Joker\" () that contains numerous examples of practical jokes. The book became a best seller not only in the United States but also in Japan. Moira Marsh has written an entire volume about practical jokes. One of her findings is that in the USA they are more often done by males than females.\n\nA practical joke recalled as his favorite by the playwright Charles MacArthur, concerns the American painter and bohemian character Waldo Peirce. While living in Paris in the 1920s, Peirce \"made a gift of a very big turtle to the woman who was the concierge of his building\". The woman doted on the turtle and lavished care on it. A few days later Peirce substituted a somewhat larger turtle for the original one. This continued for some time, with larger and larger turtles being surreptitiously introduced into the woman's apartment. The concierge was beside herself with happiness and displayed her miraculous turtle to the entire neighborhood. Peirce then began to sneak in and replace the turtle with smaller and smaller ones, to her bewildered distress. This was the storyline behind \"Esio Trot\", by Roald Dahl.\n\nModern and successful pranks often take advantage of the modernization of tools and techniques. In Canada, engineering students have a reputation for annual pranks; at the University of British Columbia these usually involve leaving a Volkswagen Beetle in an unexpected location (such as suspended from the Golden Gate Bridge and the Lions Gate Bridge). A similar prank was undertaken by engineering students at Cambridge University, England, where an Austin 7 car was put on top of the Senate House building. Pranks can also adapt to the political context of the era. Students at the Massachusetts Institute of Technology (MIT) are particularly known for their \"hacks\".\n\nNot unlike the Stone Louse of Germany, in the American West the jackalope has become an institutionalized practical joke perennially perpetrated by ruralites (as a class) on tourists, most of whom have never heard of the decades-old myth.\n\nThe 2003 TV movie \"Windy City Heat\", consists of an elaborate practical joke on the film's star, Perry Caravallo, who is led to believe that he is starring in a faux action film, \"Windy City Heat\", where the filming which is ostensibly for the film's DVD extras actually documents the long chain of pranks and jokes performed at Caravallo's expense.\n"}
{"id": "416518", "url": "https://en.wikipedia.org/wiki?curid=416518", "title": "Puppet ruler", "text": "Puppet ruler\n\nA puppet ruler is a person who has a title indicating possession of political power, but who, in reality, is controlled by outside individuals or forces. Such outside power can be exercised by a foreign government, in which case the puppet ruler's domain is called a puppet state. But the puppet ruler may also be controlled by internal forces, such as non-elected officials.\n\nGoverning through puppet presidents has long been a political tactic in Latin America. Many dictators and strongmen have formally handed over power to other officials for several reasons, often in order to follow constitutional provisions for elections and term limits, to provide a civilian façade for military rule, or to be able to go into semi-retirement away from the capital city. Strongmen who sometimes governed through figureheads included Diego Portales of Chile, Rafael Núñez of Colombia, Tomás Guardia Gutiérrez of Costa Rica, Fulgencio Batista of Cuba, Ulises Heureaux and Rafael Trujillo of the Dominican Republic, Gabriel García Moreno of Ecuador, Raoul Cédras of Haiti, Porfirio Díaz and Plutarco Elías Calles of Mexico, the Somoza family of Nicaragua, José Antonio Remón Cantera, Omar Torrijos and Manuel Noriega of Panama, Dési Bouterse of Suriname, and Antonio Guzmán Blanco and Juan Vicente Gómez of Venezuela. While figureheads who decided to act autonomously were often dismissed, on rare occasions the \"puppets\" later became significant political figures in their own right. For example, Lázaro Cárdenas turned against and exiled Calles to the United States and Joaquín Balaguer was elected to the Dominican presidency six times after the assassination of Trujillo.\n\nA puppet does not have to be a national ruler. For example, Oscar K. Allen was widely recognized to be Huey Long's puppet while serving as governor of Louisiana.\n\nIn the years before and during World War II, Puyi, the deposed Emperor of China, is usually considered to have been the puppet ruler of Manchukuo, a client state of the Empire of Japan on the Chinese mainland. \n\nWin Myint, the current president of Myanmar, is widely viewed by political commentators as a puppet president for Aung San Suu Kyi, who is constitutionally barred from holding the office of president.\n"}
{"id": "54602557", "url": "https://en.wikipedia.org/wiki?curid=54602557", "title": "R-Principle", "text": "R-Principle\n\nIn the Neo-Gricean approach to semantics and pragmatics advanced by Yale linguist Laurence Horn, the R-Principle (\"R\" for \"Relation\") is a reformulation of Paul Grice's Maxim of Relation (\"see\" Gricean maxims) combining with the second sub-maxim of Quantity and the third and fourth sub-maxims of Manner. The R-Principle states: \"Say no more than you must (given Q).\" As such it interacts with the Q-principle, which states: \"Say as much as you can (given R).\" \n\nAccording to the R-Principle, there is no reason to make a stronger statement (say more) if the extra information can be contributed by implicature. For instance, the inference from \"He broke a finger\" to \"He broke a finger of his own\" is an R-based inference, i.e. deriving from the R-Principle, since the economy of expression implies that a more informative statement was not needed. \n"}
{"id": "999666", "url": "https://en.wikipedia.org/wiki?curid=999666", "title": "Satiric misspelling", "text": "Satiric misspelling\n\nA satiric misspelling is an intentional misspelling of a word, phrase or name for a rhetorical purpose. This is often done by replacing a letter with another letter (for example, \"k\" replacing \"c\"), or symbol (for example, \"$\" replacing \"s\", \"@\" replacing \"a\", or \"¢\" replacing \"c\"). Satiric misspelling is found particularly in informal writing on the Internet, but can also be found in some serious political writing that opposes the status quo.\nReplacing the letter \"c\" with \"k\" in the first letter of a word came into use by the Ku Klux Klan during its early years in the mid-to-late 19th century. The concept is continued today within the group.\nIn the 1960s and early 1970s in the United States, leftists, particularly the Yippies, sometimes used \"Amerika\" rather than \"America\" in referring to the United States. It is still used as a political statement today. It is likely that this was originally an allusion to the German spelling of the word, and intended to be suggestive of Nazism, a hypothesis that the \"Oxford English Dictionary\" supports.\n\nIn broader usage, the replacement of the letter \"c\" with \"k\" denotes general political skepticism about the topic at hand and is intended to discredit or debase the term in which the replacement occurs.\n\nA similar usage in Italian, Spanish, Catalan and Portuguese is to write \"okupa\" rather than \"ocupa\" (often on a building or area occupied by squatters, referring to the name adopted by \"okupación\" activist groups), which is particularly remarkable because the letter \"k\" is not part of the Spanish, Portuguese or Italian alphabets. It stems from a combination of English borrow words with k in them to those languages, and Spanish anarchist and punk movements which used \"k\" to signal rebellion.\n\nReplacing \"c\" with \"k\" was at the centre of a Monty Python joke from the Travel Agent sketch. Eric Idle has an affliction that makes him pronounce the letter C as a B, as in \"bolour\" instead of \"colour.\" Michael Palin asks him if he can say the letter K? Idle replies that he can, and Palin suggests that he spell words with a K instead of C. Idle replies, \"what, spell bolour with a K? Kolour. Oh! I never thought of that before! What a silly bunt!\"\n\nThe video game franchise Mortal Kombat is another example of this trend.\n\nA common satiric usage of the letters \"KKK\" is the spelling of \"America\" as \"Amerikkka\", alluding to the Ku Klux Klan, drawing to a perceived notion of an underlying or inherent racism in American society. The earliest known usage of \"Amerikkka\" recorded in the \"Oxford English Dictionary\" is in 1970, in a journal called \"Black World\". Presumably, this was an extrapolation from the then already widespread \"Amerika\".\n\nThe spelling \"Amerikkka\" came into greater use after the 1990 release of the gangsta rap album \"AmeriKKKa's Most Wanted\" by Ice Cube, also used by rapper Spice 1 for his album \"AmeriKKKa's Nightmare\" and by shock rock band Undercover Slut for their album \"Amerikkka Macht Frei\".\n\nThe letters \"KKK\" have been inserted into several other words and names, to indicate similar perceived racism, oppression or corruption. Examples include:\n\nThe dollar sign ($) can be inserted in the place of the letter \"S\", the euro sign (€) in place of \"e\", the yen (¥) sign in place of \"Y\", the won (₩) sign in place of \"W\", or the pound (£) sign in place of \"L,\" or the rupee sign (₹) in place of \"R\" to indicate plutocracy, greed, corruption, or the perceived immoral, unethical, or pathological accumulation of money. For example:\n\nSince at least 1980, people have used the \"at sign\" (\"@\") as a representation of the circled letter A. This has been extended to substituting it for the letter \"A\" as in the Crass fanzine \"Toxic Gr@fity\".\n\nIn Spanish, it became informally common (but not accepted by the RAE, due to @ being a symbol and not a letter) to use @ in place of \"o/a\" to denote both genders. For example, \"señorit@\" can be used to mean \"señorita and/or señorito\" instead of using \"señorita/o.\"\n\nOccasionally a word written in its orthodox spelling is altered with internal capital letters, hyphens, italics, or other devices so as to highlight a fortuitous pun. Some examples:\n\nAlong the same lines, intentional misspellings can be used to promote a specific negative attribute, real or perceived, of a product or service. This is especially effective if the misspelling is done by replacing part of the word with another that has identical phonetic qualities.\n\nSome place names are also spelled differently in order to emphasize some political view. For instance, \"Brasil\" (the Portuguese spelling of \"Brazil\"), is sometimes misconstrued as a typo for \"Brazil\" in English texts. Alternatively, the English spelling \"Brazil\" is used in Portuguese pieces of text as a way to denote anti-Americanism or anti-globalization sentiment.\n\nJournalists may make a politicized editorial decision by choosing to differentially retain (or even create) misspellings, mispronunciations, ungrammaticisms, dialect variants, or interjections.\n\nPlays on acronyms and initialisms are also common, when the full name is spelled out but one of the component words is replaced by another. For example, Richard Stallman and other Free Software Foundation executives often refer to digital rights management as \"digital restrictions management\", a reference to the tendency for DRM to stifle the end user's ability to reshare music or write CDs more than a certain number of times. Likewise, the National Security Agency is often referred to as the \"National Surveillance Agency\" and sometimes \"National Socialist Agency\" by opponents of its PRISM program, who view it as dystopian encroachment on personal privacy.\n\n\n"}
{"id": "603325", "url": "https://en.wikipedia.org/wiki?curid=603325", "title": "Topic and comment", "text": "Topic and comment\n\nIn linguistics, the topic, or theme, of a sentence is what is being talked about, and the comment (rheme or focus) is what is being said about the topic. This opposition of the given/new information is called information structure. That the information structure of a clause is divided in this way is generally agreed on, but the boundary between topic/theme and comment/rheme/focus depends on grammatical theory. \n\nThe difference between \"topic\" and grammatical subject is that topic is used to describe the information structure, or pragmatic structure of a clause and how it coheres with other clauses, whereas the subject is a purely grammatical category. \"Topic\" and \"subject\" must also be distinguished from \"actor\" (or \"agent\"), the \"doer\". In English clauses with a verb in the passive voice, for instance, the topic is typically the subject, while the agent may be omitted or may follow the preposition \"by\". In some languages, word order and other syntactic phenomena are determined largely by the topic–comment (theme–rheme) structure. These languages are sometimes referred to as topic-prominent languages. Korean and Japanese are often given as examples of this.\n\nThe distinction was probably first suggested by Henri Weil in 1844. He established the\nconnection between information structure and word order. Georg von der Gabelentz distinguished psychological subject (roughly topic) and psychological object (roughly focus). In the Prague school, the dichotomy, termed topic–focus articulation, has been studied mainly by Vilém Mathesius, Jan Firbas, František Daneš, Petr Sgall and Eva Hajičová. They have been concerned mainly by its relation to intonation and word-order. Mathesius also pointed that the topic does not provide new information but connects the sentence to the context. The work of Michael Halliday in the 1960s is responsible for developing linguistic science through his systemic functional linguistics model for English.\n\nThe sentence- or clause-level \"topic\", or \"theme\", can be defined in a number of different ways. Among the most common are\n\nIn an ordinary English clause, the subject is normally the same as the topic/theme (example 1), even in the passive voice (where the subject is a patient, not an agent: example 2):\n\nThese clauses have different topics: the first is about \"the dog\", and the second about \"the little girl\".\n\nIn English it is also possible to use other sentence structures to show the topic of the sentence, as in the following:\n\nThe case of expletives is sometimes rather complex. Consider sentences with expletives (meaningless subjects), like:\n\n\nIn these examples the syntactic subject position (to the left of the verb) is manned by the meaningless expletive (\"it\" or \"there\"), whose sole purpose is satisfying the extended projection principle, and is nevertheless necessary. In these sentences the topic is never the subject, but is determined pragmatically. In all these cases, the whole sentence refers to the comment part.\n\nThe relation between topic/theme and comment/rheme/focus should not be confused with the topic-comment relation in Rhetorical structure theory Discourse Treebank (RST-DT corpus) where it is defined as \"a general statement or topic of discussion is introduced, after which a specific remark is made on the statement or topic\" (ex. \"[As far as the pound goes,] [some traders say a slide toward support at 1.5500 may be a favorable development for the dollar this week.]\") \n\nDifferent languages mark topics in different ways. Distinct intonation and word-order are the most common means. The tendency to place topicalized constituents sentence-initially (\"topic fronting\") is widespread. Topic fronting refers to placing the topic at the beginning\nof a clause regardless whether it is marked or not. Again, linguists disagree on many details. \n\nLanguages often show different kinds of grammar for sentences that introduce new topics and those that continue discussing previously established topics. \n\nWhen a sentence continues discussing a previously established topic, it is likely to use pronouns to refer to the topic. Such topics tend to be subjects. In many languages, pronouns referring to previously established topics will show pro-drop.\n\nThe topic/theme comes first in the clause, and is typically marked out by intonation as well.\n\n\nThe main application of the topic-comment structure is in the domain of speech technology, especially the design of embodied conversational agents (intonational focus assignment, relation between information structure and posture and gesture). There were some attempts to apply the theory of topic/comment for the information retrieval and the automatic summarization .\n\n\n\n"}
{"id": "54532163", "url": "https://en.wikipedia.org/wiki?curid=54532163", "title": "Vincenzo Mirabella", "text": "Vincenzo Mirabella\n\nVincenzo Mirabella Alagona (Syracuse, Sicily 1570 - Modica, 1624) was an Italian historian, archaeologist and architect, best known for his work \"Plans of Ancient Syracuse\".\n\nVincenzo Mirabella, son of Michele Mirabella and Giovanna Alagona, was born into a patrician family of French origin which had moved to Sicily in the early fourteenth century. As a young man he dedicated himself to the study of Greek, Latin and Italian literature as well as mathematics, music, history and poetry. He played an active part in civic life, holding office as \"magister nundinarum\" (Master of the Assizes) in 1593, Treasurer of the University in 1613-14 and Jurat, the highest office in the city, in 1616-17. He married Lucrezia Platamone, daughter of Antonio and Giovanna Zumbo, who brought him a substantial dowry and further connections to the leading families of Syracuse. He does not appear to have had any children with her. He lived in a house in Syracuse in front of the Church of St. Thomas in the Pantheon, in a street which bears his name today.\n\nOn a number of occasions he contributed to the development of Syracuse: in 1608 he was involved in the expansion of the cathedral square as representative of the church attorneys; he planned the Theatine Church of San Andrea built in 1610; in 1620 he provided technical advice to the Senate of Syracuse about the construction of a stone bridge over the Anapo to connect the city with Modica. From the early 1620s he moved to Modica to direct the building works for Santa Maria delle Grazie. Of his work on this building, only the western doorway remains, decorated with a fragmentary tympanum supported by two columns mounted on high pedestals and crowned with a decorated arch with an intricate design.\n\nHe published his first book, a collection of madrigals, in 1604. In recognition of his earlier works he was enrolled in the Accademia degli Oziosi in Naples and in 1614 he became the first Sicilian to become a member of the Accademia dei Lincei, (his membership was proposed by Giambattista della Porta) where he met Galileo Galilei, with whom he corresponded. Passionate about the country's history and archaeology, he wrote a \"History of Syracuse\", but did not manage to have it published, and the manuscript was eventually lost.\nFrom October to December 1608 he accompanied the painter Caravaggio on visits to the archaeological remains of Syracuse. On a trip with him to a disused quarry, Caravaggio coined the name 'Ear of Dionysius' for it and later used it as a setting for his famous work the 'Burial of St.Lucy'.\nVincenzo Mirabella assembled the objects he excavated into a diverse archaeological collection, which he exhibited in the rooms of his palace in Ortygia, at the current Via Mirabella nº23, which he steadily transformed into his own museum. At his death, his heirs donated parts of this collection to the Museu Patrio of Syracuse, which later became the Museo archeologico regionale Paolo Orsi.\n\nHis most important work, and the only one still extant today, was published in Naples in 1613 in Naples - \" 'La dichiarazione della pianta delle antiche Siracuse e di alcune scelte medaglie di esse e dei principi che quelle possedettero' \" \"('Description of the plan of ancient Syracuse and of selected medals of that place and of the characteristics they possessed')\". The work was dedicated to Philip III of Spain, who ruled Sicily at the time. The text was accompanied by a topographic plan of Syracuse, divided into nine panels, which bore a detailed hypothetical description of the city from Ortygia to the Euryalus fortress, and from the source of the river Ciane to the house of Archimedes, with a gazetteer of places of historical and archaeological interest. It was supplemented with biographies of Archimedes, Theocritus, Epicharmus of Kos and Tisias. This work was the fruit of his studies of classical authors - Thucydides, Plutarch, Diodorus Siculus, Cicero, Livy, Strabo and Pomponius Mela, as well as of the archaeological endeavours he undertook at his own expense. He was also the first to excavate the catacombs of Syracuse, which he illustrated in a panel of his book.\n\nThe first (1613) edition of \"Pianta delle antiche Siracuse\" was quickly sold out. It was reprinted in Palermo in 1717 with the title \"Descrizione delle quattro città dell'Antica Siracusa\", edited by Giovan Battista Aiccardo. Another edition of the map, recently rediscovered, is in the \"Thesaurus Antiquitatum et Historiarum Siciliae\" of Giovanni Giorgio Graevio, edited by Vander Aa in 1725 in \"Lugduni Batavorum\" (Leiden). There is also a 1989 edition, \"Pianta delle Antiche Siracuse\", edited by Cesare Samà and published by Arnoldo Lombardi.\n\nVincenzo Mirabella died of the plague in Modica in 1624. He was buried in the church of the Madonna delle Grazie, with this epitaph on his tomb:\n"}
{"id": "5218457", "url": "https://en.wikipedia.org/wiki?curid=5218457", "title": "Writing style", "text": "Writing style\n\nIn literature, writing style is the manner of expressing thought in language characteristic of an individual, period, school, or nation. Thus, style is a term that may refer, at one and the same time, to both conventions that go beyond the individual writer and to singular aspects of individual writing. Beyond the essential elements of spelling, grammar, and punctuation, writing style is the choice of words, sentence structure, and paragraph structure, used to convey the meaning effectively. The former are referred to as \"rules\", \"elements\", \"essentials\", \"mechanics\", or \"handbook\"; the latter are referred to as \"style\", or \"rhetoric\". The rules are about \"what\" a writer does; style is about \"how\" the writer does it. While following the rules drawn from established English usage, a writer has great flexibility in how to express a concept. The point of good writing style is to\nnot to\nalthough these are usually evident and are what experts consider the writer’s individual style.\n\nDiction, or the choice of \"words\", is obviously a central element in every writer’s style. Although good diction is partly a matter of trial and error, of tinkering with sentences until they sound right, it is also a matter of following certain general preferences that careful readers and writers tend to share.\n\nSome methods for using diction effectively in writing:\n\nSooner or later, a writer will have the essential elements of formal \"sentence\" correctness under control and will want to find the best ways of making sentences convey meaning effectively: how to phrase statements definitely, place coordinate thoughts in coordinate structures, subordinate to sharpen the relation between main assertions and modifying elements, eliminate unnecessary words, vary sentence structure, maintain consistency of tone, and smooth the general flow of words. Seemingly minor improvements—the moving of a clause from one position to another, a shift from the passive to the active voice, even a slight change in rhythm—can make the difference between drab sentences and pointed ones.\n\nSome methods for writing effective sentences:\n\nThe most important unit of meaning in every literary work is the \"paragraph\". Although each sentence conveys a thought, a literary work is not just a sequence of, say, eighty thoughts; it is rather a development of one central thesis through certain steps. Those steps are paragraphs. Within an effective paragraph the sentences support and extend one another in various ways, making a single, usually complex, unfolding idea.\n\nApart from outright incoherence, choppiness, or long-windedness, perhaps the most common flaw in paragraph construction is rigidity of presentation. Having something to say, the writer merely says it—and goes on to do just the same in the following paragraph. As a result, the reader feels, not like a participant in the writer’s thought, but like someone receiving instructions or being shown a rapid succession of images.\n\nSome methods for writing effective paragraphs:\n\nNote how rewriting the familiar sentence, \"These are the times that try men’s souls.\" by Thomas Paine, changes the overall impact of the message.\n\nCompare the following passages, and note how the authors convey their messages in different manners, as a result of their choices.\n\n\"Hamlet\", Act II, Scene 2 (1599–1602) by William Shakespeare:\n\n\"A Tale of Two Cities\" (1859) by Charles Dickens:\n\n\"Memories of Christmas\" (1945) by Dylan Thomas:\n\n\"The Strawberry Window\" (1955) by Ray Bradbury:\n\n\"Letter from Birmingham Jail\" (1963) by Martin Luther King, Jr.:\n\nThe writer's voice is a rather vague metaphorical term by which some critics refer to distinctive features of a written work in terms of spoken utterance. The voice of a literary work is then the specific group of characteristics displayed by the narrator or poetic \"speaker\" (or, in some uses, the actual author behind them), assessed in terms of \"tone\", \"style\", or \"personality\". Distinctions between various kinds of narrative voice tend to be distinctions between kinds of \"narrator\" in terms of how they address the reader (rather than in terms of their perception of events, as in the distinct concept of \"point of view\"). Likewise in non-narrative poems, distinctions can be made between the personal voice of a private lyric and the assumed voice (the persona) of a dramatic monologue.\n\nAn author uses sentence patterns not only to make a point or tell a story, but to do it in a certain manner that amounts to a personal signature, a characteristic way of presenting reality. It is perfectly understandable that an aspiring writer could fall in love with the work of a brilliant literary figure (for example, William Faulkner or William S. Burroughs) and then try to emulate that literary voice, but when an amateur aims deliberately for the sort of mature voice found in seasoned professionals, the result is likely to be literarily pretentious and largely unreadable. In fact, this sort of literary pretentiousness is a clear mark of an amateur. A strong, distinctive, authoritative writing voice is something most fiction writers want and is something any writer can bring out in himself or herself, but oddly enough, it can’t be produced by concentrating on it, nor can it be imparted by an editor or teacher. Such an effect is achieved simply by writing often and carefully. Spending creative energy in the service of the way sentences read as prose is likely to be at the expense of the characters or story. Writers should concentrate on characters and story and let their voice take care of itself.\n\nWriting coaches, teachers, and authors of creative writing books often speak of the writer's voice as distinguished from other literary elements. However, as voice is often described vaguely, their distinction may be only superficial. In some instances, voice is defined nearly the same as style; in others, as genre, literary mode, point of view, mood, or tone.\n\n"}
