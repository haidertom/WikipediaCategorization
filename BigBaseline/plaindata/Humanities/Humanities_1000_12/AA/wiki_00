{"id": "26754165", "url": "https://en.wikipedia.org/wiki?curid=26754165", "title": "Ambivalent sexism", "text": "Ambivalent sexism\n\nAmbivalent sexism is a theoretical framework which posits that sexism has two sub-components: \"hostile sexism\" and \"benevolent sexism\". Hostile sexism reflects overtly negative evaluations and stereotypes about a gender (e.g., the ideas that women are incompetent and inferior to men). Benevolent sexism represents evaluations of gender that may appear subjectively positive (subjective to the person who is evaluating), but are actually damaging to people and gender equality more broadly (e.g., the ideas that women need to be protected by men). For the most part, psychologists have studied hostile forms of sexism. However, theorists using the theoretical framework of ambivalent sexism have found extensive empirical evidence for both varieties. The theory has largely been developed by social psychologists Peter Glick and Susan Fiske.\n\nSexism, like other forms of prejudice, is a type of bias about a group of people. Sexism is founded in conceptualizations of one gender as being superior or having higher status than another gender in a particular domain, which can lead to discrimination. Research has indicated that stereotypes about socially appropriate gender roles for women and men are a driving factor in the endorsement of sexism. Patriarchy, defined as men's power and \"structural control over political, legal, economic, and religious institutions\", is a feature of sexism and is related to hostile attitudes toward women. Anthropological research suggests that patriarchy is pervasive among the majority of human societies, such that women have been systematically discriminated against, oppressed, and marginalized by men throughout history. Sexism maintains patriarchal social structures and reinforces prescribed gender roles.\n\nTypically, sexism is thought of as hostility toward women, perpetrated by men. However, both women and men can (and often do) endorse sexist beliefs about each other and themselves. In other words, men can express sexist attitudes about women or men, and women can express sexist attitudes about men or women. While sexism has historically disadvantaged women, there are negative consequences of sexism for both men and women. Rigid gender roles can be damaging to women and men alike, restricting opportunities and promoting gender-based prejudice. For the purposes of this article, sexism toward women will be the focus, as it is most relevant to the definition and study of ambivalent sexism.\n\nAmbivalent sexism offers a multidimensional reconceptualization of the traditional view of sexism to include both subjectively benevolent and hostile attitudes toward women. The word \"ambivalent\" is used to describe the construal of sexism because this type of bias includes both negative and positive evaluations of women. The addition of a benevolent feature to definitions of gender-based prejudice was a major contribution to the study of sexism and field of psychology. Traditional conceptualizations of sexism focused almost entirely on overt hostility toward women. While historians, anthropologists, feminist scholars, and psychologists had previously suggested that sexism involves positive and negative evaluations of women, the majority of empirical research at the time evaluated only hostile expressions of sexism. The introduction of the Ambivalent Sexism Inventory (ASI)—a scale which was developed by Glick and Fiske in 1996, and which assesses ambivalently sexist attitudes—marks a shift in how sexism is construed and scientifically measured. Glick and Fiske created the ASI to address a proposed deficiency in the measurement of sexism at the time. They argue that previous scales assessing sexism do not adequately capture the ambivalent nature of gender-based prejudice toward women.\n\nGlick and Fiske assert that hostile and benevolent sexism complement each other in reinforcing traditional gender roles and preserving patriarchal social structures of women as subordinate to men. Both forms of sexism share the assumption that women are inferior and restrict women to a lower social status. Hostile sexism reflects misogyny (i.e., the hatred of women by men) and is expressed through blatant negative evaluations of women. Examples of hostile sexism include beliefs about women as incompetent, unintelligent, overly emotional, and sexually manipulative. Benevolent sexism reflects evaluations of women that are seemingly positive. Examples of benevolently sexist attitudes include the reverence of women in wife, mother, and child caretaker roles, the romanticizing of women as objects of heterosexual affection, and the belief that men have a duty to protect women. While benevolent sexism may not appear to be harmful to women on the surface, these beliefs are extremely caustic to gender equity and restrict women's personal, professional, political, and social opportunities. This is because these seemingly positive evaluations imply that (a) women are weak and need to be protected, (b) women should not deviate from traditional gender roles as mothers and caretakers, and (c) women should be idolized by men for their sexual purity and availability.\n\nBecause benevolently sexist attitudes appear positive, people often do not identify these beliefs as a form of gender-based prejudice. Furthermore, benevolent sexism may be seen by both men and women as reinforcing of the status quo, which some individuals may find comforting. Social and cultural norms may encourage benevolently sexist beliefs among women and men. A classic illustration of this is the endorsement of modern-day chivalry in interactions between women and men. It can be considered traditional and polite for a man to insist that he holds a door open or carries a heavy object for a woman. However, this tradition is founded in historical representations of women as weaker than men. In these types of circumstances, people may find it difficult to distinguish between kindness, tradition, and benevolent sexism. Men and women often disagree on whether or not a specific incident should be considered sexist. In general, women and men tend to show more agreement in classifying extreme and overt expressions of sexism. Hostile sexism is typically easier for people to identify as an expression of prejudice.\n\nOverall, women are rarely perceived by others in an entirely hostile or benevolent manner. In fact, people frequently report high levels of both benevolent and hostile sexism. There are individual differences in people's levels of benevolent and hostile sexism, such that a person can be rated highly on both, one, or neither dimension of the Ambivalent Sexism Inventory. In addition, women are not immune from endorsing sexist beliefs about women. Extensive research supports the idea that it is common for women and men to support ambivalently sexist attitudes about women. Despite this, people find it difficult to believe that others can endorse both benevolent and hostile sexism. Research suggests that, when individuals are shown profiles of a benevolently sexist man and a man who endorses hostile sexism, they feel that it is very unlikely that one person can embody both forms of bias.\n\nSocial psychologists have suggested that sexism may be inherently different from other forms of ambivalent prejudice, in that there is interdependency between women and men in social structures. A central argument to the theory of ambivalent sexism is the idea that there is a complicated balance of power between men and women, such that men have structural power and women have dyadic power (stemming from dependence between two people). Dyadic power reflects the notion that men depend on women to fulfill certain goals, such as heterosexual intimacy and childbearing. Glick and Fiske assert that men's dependence on women is what fuels benevolently sexist attitudes, leading to idolization and the placing of women on a pedestal. In other words, power relationships between men and women foster an ambivalent form of bias towards women.\n\nTheoretically, each form of sexism is composed of three subcomponents: paternalism, gender differentiation, and heterosexuality. Paternalism reflects views of women as underdeveloped adults, providing justification for men to be authoritative and monitor, protect, and make decisions on women's behalf. Gender differentiation promotes the assumption that biological differences between males and females justify the strict adherence to socially prescribed gender roles. Heterosexuality—described as the most prominent cause of men's ambivalence toward women—reflects a tension between genuine desires for closeness and intimacy and a fear of women attaining power over men through sexual attraction.\n\nWithin hostile sexism (HS) and benevolent sexism (BS), the three subcomponents serve distinct functions. Dominative paternalism (HS) suggests that men should control women, while protective paternalism (BS) implies that men should protect and care for women. Competitive gender differentiation (HS) bolsters men's self-confidence (e.g., men are superior to women). Complementary gender differentiation (BS) places importance on traditional gender roles for women (e.g., mother & wife) and assumes that men depend on women to fulfill these roles. Lastly, heterosexual hostility (HS) views women as sexual objects for men's pleasure and promotes the fear of women's capacity to manipulate men by engaging in or withholding sexual activity. Intimate heterosexuality (BS) romanticizes women as having sexual purity and views romantic intimacy as necessary to complete a man.\n\nResearchers typically measure ambivalent sexism at the individual level. The primary method used to measure an individual's endorsement of ambivalent sexism is the Ambivalent Sexism Inventory (ASI), created by Glick and Fiske in 1996. The ASI is a 22-item self-report measure of sexism on which respondents indicate their level of agreement with various statements, which are placed on a 6-point Likert scale. It is composed of two sub-scales that may be independently calculated for sub-scale scores or may be averaged for an overall composite sexism score. The first sub-scale is the hostile sexism scale, which is composed of 11 items designed to assess an individual's position on the dimensions of dominative paternalism, competitive gender differentiation, and heterosexual hostility, as previously defined. A sample item from the hostile sexism sub-scale is \"Women are too easily offended.\" The second sub-scale is the benevolent sexism scale, which is composed of 11 items that aim to assess an individual's position on the dimensions of protective paternalism, complementary gender differentiation, and heterosexual intimacy, as previously defined. A sample item from the benevolent sexism sub-scale is \"Women should be cherished and protected by men.\"\n\nOver fifteen years of additional research and replications support that this inventory possesses psychometric characteristics indicating that the measure is both empirically reliable and valid. Standard criteria in psychological research can be utilized to evaluate a scale. Using statistics, a Cronbach's alpha coefficient can be calculated to indicate whether items on a scale seem to be measuring the same psychological construct or dimension (demonstrating the retestability of a scale). Generally, researchers agree that a Cronbach's alpha coefficient above 0.80 suggests strong reliability in a scale. The ASI has consistently demonstrated this empirical reliability over time. In addition, empirical evaluations of the ASI provide support for the validity of the scale, such that the inventory seems to effectively measure what it proposes to assess: a polarized attitude towards women, where both dimensions can be activated simultaneously.\n\nThe utility of the ASI is not limited to English speakers. There is extensive support for the cross-cultural validity of the ASI. A cross-cultural study examining the theory of ambivalent sexism in 19 countries found that hostile and benevolent components of sexism are not culturally specific. Furthermore, research suggests that ambivalently sexist attitudes towards men exist, such that hostile and benevolent attitudes toward men are found cross-culturally. These studies provide additional empirical evidence that support the framework of ambivalent sexism.\n\nWhile the ASI is widely used and accepted among researchers, one limitation of the ASI is that it is a self-reported measure. Social desirability is a common limitation of self-report measures in survey research; when participants in a research study complete a written self-report questionnaire, respondents are vulnerable to answering the items in a socially desirable manner. For this reason, some researchers employ variations of the ASI in their study designs that do not require self-reports. For example, Dardeene, Dumont, and Bollier (2007) transformed some items from the ASI into scenarios, presenting them to participants to induce conditions of both hostile and benevolent sexism. Hebl, King, Glick, Singletary, and Kazama (2007) designed a field study in which they observed the sexist behaviors of others; they used the theory of ambivalent sexism and the ASI to generate items for their own measure to assess these observed behaviors.\n\nAnother criticism of the ASI is that the labels of the two sub-constructs, \"benevolent\" and \"hostile\", are too abstract, do not generalize to certain languages, and may not be relevant to some cultures.\n\nLastly, findings from the Conn, Hanges, Sipe, and Salvaggio (1999) study suggest that other sexism scales may measure ambivalent attitudes towards women. Glick and Fiske originally proposed the theoretical framework of ambivalent sexism as filling a gap in the psychological literature and providing a novel tool for assessing a new dimension of sexism: benevolent sexism. However, Conn and colleagues (1999), using confirmatory factor analysis, showed that the Modern Sexism Scale (Swim, Aikin, Hall, and Hunter, 1995) captures ambivalent sentiments toward women, such that it identifies individuals that appear nonsexist but actually endorse sexist attitudes. Results from this study suggest that, while both the Modern Sexism Scale and the ASI assess ambivalence toward women, the ASI is unique in its capabilities for separately measuring both hostile and benevolent attitudes. In addition, the ASI captures heterosexual intimacy and benevolent paternalism, whereas the Modern Sexism Scale does not.\n\nWhile many individuals endorse both benevolent and hostile sexism simultaneously, research suggests that people rated significantly higher in one of the two sub-components have distinct constellations of beliefs and patterns of behavior. In other words, someone who is high in benevolent sexism tends to show a different profile of attitudes than someone who is high in hostile sexism. The independence of these types of sexism in predicting human behavior indicates that the two are, in fact, discrete forms of bias on separate but related axes. Examples of research findings identifying disparate outcomes between benevolent sexism and hostile sexism are described below. In addition, the relationships between ambivalent sexism and a range of other related attitudes and behaviors are discussed.\n\nMen who are ambivalently sexist (i.e., high in both benevolent and hostile sexism simultaneously) and men who are high in hostile sexism are more likely to tolerate the sexual harassment of women than men who are benevolently sexist. Overall, hostile sexism is associated with acceptance of sexual harassment. In addition, the endorsement of hostile sexism is related to attitudes about intimate partner violence perpetrated by men towards women, such that people that are high in hostile sexism are more tolerant of intimate partner violence. Benevolently sexist attitudes were not found to be a significant predictor of the tolerance of intimate partner violence. However, the endorsement of benevolent sexism was not a protective factor either. Lastly, men high in hostile sexism are more likely to rape women, whereas men that are high in benevolent sexism are more likely to blame a victim of rape for the attack.\n\nResearch has shown that sexist attitudes relate to preferences for certain characteristics in romantic partners. Evidence suggests that women with higher levels of benevolent sexism have more stereotypical preferences in men as romantic partners, such as financial security and resources. Men with higher levels of hostile sexism are more likely to value physical attractiveness in women as romantic partners. In addition, benevolent sexism tends to predict mate selection, whereas hostile sexism tend to predict subsequent marriage norms after pairing. Women find men high in benevolent sexism attractive, and rate men high in ambivalent sexism as less attractive. Furthermore, in a recent research study on a particular aspect of benevolent sexism, protective paternalistic beliefs, women endorsed more protective paternalistic beliefs for men (toward women) in romantic versus work contexts. The endorsement of these beliefs in romantic contexts is thought to serve to reinforce and maintain such benevolent sexist behaviors. Overall, benevolent sexism and hostile sexism are associated with beliefs that premarital sex is unacceptable for women.\n\nWhile the consequences of hostile sexism in the workplace are more widely known and accepted, research has shown that benevolent sexism may have a more severe impact on a women's cognitive performance. Dardenne, et al.(2006) suggested that hostile sexism can elicit anger or frustration in the target, which may increase her motivation to succeed or perform. Benevolent sexism, because of its seemingly positive evaluations and implicit attributions, is likely to hinder a woman's confidence and performance. The researchers showed that, in a typical team working environment, hostile sexism as well as benevolent sexism had consequences for the participant's performance. Masser and Abrams (2004) highlighted the fact that previous research has shown that benevolent sexism can have detrimental effects on a woman's performance evaluation if that woman violates social norms associated with certain sexist attitudes. Their study showed that hostile sexism, but not benevolent sexism, hurt women's evaluations and recommendations for promotion.\n\nAdditionally, studies have shown that benevolent sexist attitudes lead to lower professional evaluations from men and women. Using an experimental design, Masser and Abrams (2004) found that individuals with hostile sexist attitudes rated women lower when applying for a male-dominant position. Additionally, high hostile sexist individuals recommend men to fill the available position more often than women. The authors argue that this is one of the main contributors to the glass ceiling effect.\n\nIn a recent experimental study on the effects of benevolent sexism on help-seeking behaviors, researchers found that, when stereotypes of women as dependent were made salient, female college students were less willing to seek help. In addition, the more that help was sought, the worse women felt. Therefore, benevolent sexism appears to hold consequences towards women's help-seeking when certain benevolent sexist stereotypes are made salient.\n\nDuring the 2016 US Presidential Election, researchers connected ambivalent sexism to voting intentions. In a non-representative sample of US voters, predominantly male, ambivalent sexism was found to be the sole predictor of intending to vote for someone other than Hillary Clinton in the election. For every step up on the Ambivalent Sexism Inventory, participants were 3.3 times more likely to be voting for someone other than Hillary Clinton. Of those not voting for Clinton, they were not necessarily being pulled over to the Trump campaign, but rather, many were intending to vote Third Party or were still undecided. While higher Islamophobia predicted a vote for Trump, lower Islamophobia and \"higher\" ambivalent sexism predicted being undecided or voting for a Third Party.\n\nBoth benevolent and hostile sexism are considered legitimizing ideologies, in that these attitudes provide the justification for social inequalities between men and women. Social dominance orientation (SDO; Sidanius & Pratto, 1999) asserts that group-based inequalities are systematically reinforced by the disadvantaged group's adoption of the dominant group's ideology and social stratification. Empirical research has consistently supported the validity of Social Dominance Theory, and the SDO model of structural oppression may be particularly apt to describe how patriarchy is perpetuated.\n\nResearchers have explored reasons for why women might internalize ambivalently sexist attitudes towards women. Fischer (2006) found that women may develop benevolently sexist attitudes as a response to experiencing sexism themselves. Cross-cultural research suggests that women's endorsement of benevolent sexism often reflects a culture of extreme hostile sexism among men in a given community. Some researchers argue that, in cultures that are particularly hostile, women may internalize benevolent sexism as a protective mechanism.\n\n"}
{"id": "37040095", "url": "https://en.wikipedia.org/wiki?curid=37040095", "title": "Anthropopoiesis", "text": "Anthropopoiesis\n\nIn anthropology, anthropopoiesis is the self-building process of social man and of a whole culture, particularly referred to what concerns modifications of socialized body. The concept found applications mainly in French and Italian contemporary literatures.\n\nIn accordance with theoretic background which supports the idea, man is an unfinished being or better his behaviour is not strongly prefixed by genetic heritage. Human beings become fully finished only by means of culture acquisition.\n\nAnthropopoiesis is both anthropogenesis (man “reborn” as social creature) and manufacturing of ”mankind patterns and fictions”. Therefore social and cultural practices build up the man by means of ritual and institutional constraints.\n\nAn example could be circumcision, a practice widely existing in many rites of passage amongst Islamic and Jewish believers and also amongst traditional cultures and communities. Besides, Christians ascribe a clear meaning to the sacred garment and to the tonsure; they are convinced that some sacramental rites mark indelible dispositions. All that affects the body and through this one the perception of one’s own identity and social status.\n\n"}
{"id": "246903", "url": "https://en.wikipedia.org/wiki?curid=246903", "title": "Apologetics", "text": "Apologetics\n\nApologetics (from Greek , \"speaking in defense\") is the religious discipline of defending religious doctrines through systematic argumentation and discourse. Early Christian writers (c. 120–220) who defended their beliefs against critics and recommended their faith to outsiders were called Christian apologists. In 21st-century usage, \"apologetics\" is often identified with debates over religion and theology.\n\nThe term \"apologetics\" derives from the Ancient Greek word \"apologia\". In the Classical Greek legal system, two key technical terms were employed: the prosecution delivered the \"kategoria\" (κατηγορία), and the defendant replied with an \"apologia\". To deliver an \"apologia\" meant making a formal speech or giving an explanation to reply and rebut the charges, as in the case of Socrates' Apologia defense, as chronicled in Plato's \"Apology\" (the defense speech of Socrates at his trial). This term appears in the Koine Greek of the New Testament. The Apostle Paul employs the term \"apologia\" in his trial speech to Festus and Agrippa when he says \"I make my defense\" in Acts 26:2. A cognate form appears in Paul's Letter to the Philippians as he is \"defending the gospel\" in Philippians 1:7, and in \"giving an answer\" in 1 Peter 3:15.\n\nAlthough the term \"apologetics\" has Western, primarily Christian origins and is most frequently associated with the defense of Christianity, the term is sometimes used referring to the defense of any religion in formal debate involving religion.\n\nMany apologetic books have been written in defence of the history or teachings of the Bahá'í Faith. The religion's founders wrote several books presenting proofs of their religion, among them are the Báb's \"Seven Proofs\" and Bahá'u'lláh's \"Kitáb-i-Íqán\". Later Bahá'í authors wrote prominent apologetic texts, such as Mírzá Abu'l-Fadl's \"The Brilliant Proof\" and Udo Schaefer et al.'s \"Making the Crooked Straight\";.\n\nOne of the earliest Buddhist apologetic texts is \"The Questions of King Milinda\", which deals with the Buddhist metaphysics such as the \"no-self\" nature of the individual and characteristics such as of wisdom, perception, volition, feeling, consciousness and the soul. In the mid-19th century, encounters between Buddhists and Christians in Japan prompted the formation of a Buddhist Propagation Society . In recent times, A. L. De Silva, an Australian convert to Buddhism, has written a book, \"Beyond Belief\", providing Buddhist apologetic responses and a critique of Christian Fundamentalist doctrine. Gunapala Dharmasiri wrote an apologetic critique of the Christian concept of God from a Theravadan Buddhist perspective.\n\nChristian apologetics combines Christian theology, natural theology, and philosophy to present a rational basis for the Christian faith, to defend the faith against objections and misrepresentation.\n\nChristian apologetics has taken many forms over the centuries. In the Roman Empire, Christians were severely persecuted, and many charges were brought against them. J. David Cassel gives several examples: Tacitus wrote that Nero fabricated charges that Christians started the burning of Rome. Other charges included cannibalism (due to a literal interpretation of the Eucharist) and incest (due to early Christians' practice of addressing each other as \"brother\" and \"sister\"). Saul of Tarsus, Justin Martyr, Irenaeus and others often defended Christianity against charges that were brought to justify persecution.\n\nLater apologists have focused on providing reasons to accept various aspects of Christian belief. Christian apologists of many traditions, in common with Jews, Muslims, and some others, argue for the existence of a unique and personal God. Theodicy is one important aspect of such arguments, and Alvin Plantinga's arguments have been highly influential in this area. Many prominent Christian apologists are scholarly philosophers or theologians, frequently with additional doctoral work in physics, cosmology, comparative religions, or other fields. Others take a more popular or pastoral approach. Some prominent modern apologists are Douglas Groothuis, Frederick Copleston, John Lennox, Walter R. Martin, Dinesh D'Souza, Douglas Wilson, Cornelius Van Til, Gordon Clark, Francis Schaeffer, Greg Bahnsen, Edward John Carnell, James White, R.C. Sproul, Hank Hanegraaff, Ravi Zacharias, Alister McGrath, Lee Strobel, Josh McDowell, Peter Kreeft, G. K. Chesterton, C. S. Lewis, William Lane Craig, J. P. Moreland, Hugh Ross, David Bentley Hart, Gary Habermas, Norman Geisler and Scott Hahn.\n\nNotable apologists within the Catholic Church include Bishop Robert Barron, G. K. Chesterton, Dr. Scott Hahn, Patrick Madrid, Kenneth Hensley, Karl Keating, Ronald Knox, Peter Kreeft, and Gus Loyd.\n\nJohn Henry Newman (February 21, 1801 – August 11, 1890) was an English convert to Roman Catholicism, later made a cardinal, and beatified in 2010. In early life he was a major figure in the Oxford Movement to bring the Church of England back to its Catholic roots. Eventually his studies in history persuaded him to become a Roman Catholic. When John Henry Newman entitled his spiritual autobiography \"Apologia Pro Vita Sua\" in 1864, he was playing upon both this connotation, and the more commonly understood meaning of an expression of contrition or regret.\n\nChristian apologists employ a variety of philosophical and formal approaches, including ontological, cosmological, and teleological arguments. The Christian presuppositionalist approach to apologetics utilizes the transcendental argument for the existence of God.\n\nTertullian was a notable early Christian apologist. He was born, lived and died in Carthage. He is sometimes known as the \"Father of the Latin Church\". He introduced the term \"Trinity\" (Latin \"trinitas\") to the Christian vocabulary and also probably the formula \"three Persons, one Substance\" as the Latin \"tres Personae, una Substantia\" (itself from the Koine Greek \"treis Hypostaseis, Homoousios\"), and also the terms \"Vetus Testamentum\" (Old Testament) and \"Novum Testamentum\" (New Testament).\n\nThere are notable Latter-day Saint apologists who focus on the defense of Mormonism, including early church leaders such as Parley P. Pratt, John Taylor, B. H. Roberts, James E. Talmage and more modern figures such as Hugh Nibley, Orson Scott Card, and Jeff Lindsay.\n\nSeveral well-known Mormon apologetic organizations, such as the Foundation for Ancient Research and Mormon Studies (a group of scholars at Brigham Young University) and FairMormon (an independent, Mormon-run, not-for-profit group), have been formed to defend the doctrines and history of the Latter Day Saint movement in general and The Church of Jesus Christ of Latter-day Saints in particular.\n\nDeism is a form of theism in which God created the universe and established rationally comprehensible moral and natural laws but no longer intervenes in human affairs. Deism is a natural religion where belief in God is based on application of reason and evidence observed in the designs and laws found in nature. The World Order of Deists maintains a web site presenting deist apologetics that demonstrate the existence of God based on evidence and reason, absent divine revelation.\n\nHindu apologetics began developing during the British colonial period. A number of Indian intellectuals had become critical of the British tendency to devalue the Hindu religious tradition. As a result, these Indian intellectuals, as well as a handful of British Indologists, were galvanized to examine the roots of the religion as well as to study its vast arcana and corpus in an analytical fashion. This endeavor drove the deciphering and preservation of Sanskrit. Many translations of Hindu texts were produced which made them accessible to a broader reading audience.\n\nA range of Indian philosophers, including Swami Vivekananda and Aurobindo Ghose, have written rational explanations regarding the values of the Hindu religious tradition. More modern proponents such as the Maharishi Mahesh Yogi have also tried to correlate recent developments from quantum physics and consciousness research with Hindu concepts. The late Reverend Pandurang Shastri Athavale has given a plethora of discourses regarding the symbolism and rational basis for many principles in the Vedic tradition. In his book \"The Cradle of Civilization\", David Frawley, an American who has embraced the Vedic tradition, has characterized the ancient texts of the Hindu heritage as being like \"pyramids of the spirit\". A. C. Bhaktivedanta Swami Prabhupada translated over sixty volumes of classic Vedic scriptures including the biography and conclusions of the famous 16th century bhakti scholar Sri Chaitanya Mahaprabhu; many of these translations and commentaries have been further translated into as many as eighty languages, producing over half a billion books distributed throughout the world. Such individuals have tried to construct an intellectual defense of Hinduism during a phase when the fundamentalistic elements of other faiths have sought to denigrate the ancient religion in an effort to gain converts.\n\n\"Ilm al-Kalām\", literally \"science of discourse\", usually foreshortened to \"kalam\" and sometimes called \"Islamic scholastic theology\", is an Islamic undertaking born out of the need to establish and defend the tenets of Islamic faith against doubters and detractors. A scholar of \"kalam\" is referred to as a \"mutakallim\" (plural \"mutakallimūn\") as distinguished from philosophers, jurists, and scientists.\n\nJewish apologetic literature can be traced back as far as Aristobulus of Paneas, though some discern it in the works of Demetrius the chronographer (3rd century BCE) traces of the style of \"questions\" and \"solutions\" typical of the genre. Aristobulus was a Jewish philosopher of Alexandria and the author of an apologetic work addressed to Ptolemy VI Philometor. Josephus's Contra Apion is a wide-ranging defense of Judaism against many charges laid against Judaism at that time, as too are some of the works of Philo of Alexandria.\n\nIn response to modern Christian missionaries, and congregations that \"are designed to appear Jewish, but are actually fundamentalist Christian churches, which use traditional Jewish symbols to lure the most vulnerable of our Jewish people into their ranks\", Jews for Judaism is the largest counter-missionary organization in existence, today. Kiruv Organisation, founded by Rabbi Yosef Mizrachi, and Outreach Judaism, founded by Rabbi Tovia Singer, are other prominent international organizations that respond \"directly to the issues raised by missionaries and cults, by exploring Judaism in contradistinction to fundamentalist Christianity.\"\n\nSome pantheists have formed organizations such as the World Pantheist Movement and the Universal Pantheist Society to promote and defend the belief in pantheism.\n\nIn a famous speech called \"Red Jacket on Religion for the White Man and the Red\" in 1805, Seneca chief Red Jacket gave an apologetic for Native American religion.\n\nPlato's \"Apology\" may be read as both a religious and literary apology; however, more specifically literary examples may be found in the prefaces and dedications, which proceed many Early Modern plays, novels, and poems. Eighteenth century authors such as Colley Cibber, Frances Burney, and William Congreve, to name but a few, prefaced the majority of their poetic work with such apologies. In addition to the desire to defend their work, the apologetic preface often suggests the author's attempt to humble his- or herself before the audience.\n\n"}
{"id": "15938971", "url": "https://en.wikipedia.org/wiki?curid=15938971", "title": "Argumentative dialogue", "text": "Argumentative dialogue\n\nWhereas formal arguments are static, such as one might find in a textbook or research article, argumentative dialogue is dynamic. It serves as a published record of justification for an assertion. Arguments can also be interactive, in which the proposer and the interlocutor have a more symmetrical relationship. The premises are discussed, as well the validity of the intermediate inferences. For example, consider the following exchange, illustrated by the No true Scotsman fallacy:\n\nIn this dialogue, the proposer first offers a premise, the premise is challenged by the interlocutor, and finally the proposer offers a modification of the premise. This exchange could be part of a larger discussion, for example a murder trial, in which the defendant is a Scotsman, and it had been established earlier that the murderer was eating sugared porridge when he or she committed the murder. \n\nIn argumentative dialogue, the rules of interaction may be negotiated by the parties to the dialogue, although in many cases the rules are already determined by social mores. In the most symmetrical case, argumentative dialogue can be regarded as a process of discovery more than one of justification of a conclusion. Ideally, the goal of argumentative dialogue is for participants to arrive jointly at a conclusion by mutually accepted inferences. In some cases however, the validity of the conclusion is secondary. For example; emotional outlet, scoring points with an audience, wearing down an opponent or lowering the sale price of an item may instead be the actual goals of the dialogue. Walton distinguishes several types of argumentative dialogue which illustrate these various goals:\n\nVan Eemeren and Grootendorst identify various stages of argumentative dialogue. These stages can be regarded as an argument protocol. In a somewhat loose interpretation, the stages are as follows:\n\n\nVan Eemeren and Grootendorst provide a detailed list of rules that must be applied at each stage of the protocol. Moreover, in the account of argumentation given by these authors, there are specified roles of protagonist and antagonist in the protocol which are determined by the conditions which set up the need for argument.\n\nMany cases of argument are highly unsymmetrical, although in some sense they are dialogues. A particularly important case of this is political argument.\n\nMuch of the recent work on argument theory has considered argumentation as an integral part of language and perhaps the most important function of language (Grice, Searle, Austin, Popper). This tendency has moved argumentation theory away from the realm of pure formal logic.\n\nOne of the original contributors to this trend is the philosopher Chaim Perelman, who together with Lucie Olbrechts-Tyteca introduced the French term \"La nouvelle rhetorique\" in 1958 to describe an approach to argument which is not reduced to application of formal rules of inference. Perelman's view of argumentation is much closer to a juridical one, in which rules for presenting evidence and rebuttals play an important role. Though this would apparently invalidate semantic concepts of truth, this approach seems useful in situations in which the possibility of reasoning within some commonly accepted model does not exist or this possibility has broken down because of ideological conflict. Retaining the notion enunciated in the introduction to this article that \"logic\" usually refers to the structure of argument, we can regard the logic of rhetoric as a set of protocols for argumentation.\n"}
{"id": "4071454", "url": "https://en.wikipedia.org/wiki?curid=4071454", "title": "Assembly rooms", "text": "Assembly rooms\n\nIn Great Britain and Ireland, especially in the 18th and 19th centuries, assembly rooms were gathering places for members of the higher social classes open to members of both sexes. At that time most entertaining was done at home and there were few public places of entertainment open to both sexes besides theatres (and there were few of those outside London). Upper class men had more options, including coffee houses and later gentlemen's clubs. \n\nMajor sets of assembly rooms in London, in spa towns such as Bath, and in important provincial cities such as York, were able to accommodate hundreds, or in some cases over a thousand people for events such as masquerade balls (masked balls), conventional balls, public concerts and assemblies (simply gatherings for conversation, perhaps with incidental music and entertainments) or Salons. By later standards these were formal events: the attendees were usually screened to make sure no one of insufficient rank gained admittance; admission might be subscription only; and unmarried women were chaperoned. Nonetheless, assemblies played an important part in the marriage market of the day. \n\nA major set of assembly rooms consisted of a main room and several smaller subsidiary rooms such as card rooms, tea rooms and supper rooms. On the other hand, in smaller towns a single large room attached to the best inn might serve for the occasional assembly for the local landed gentry. \n\nFormal assemblies and the associated assembly rooms faded away in the late 19th and early 20th centuries, as the range of places of public entertainment increased (for example public dance halls and nightclubs) and attitudes became more accepting of women from the higher social classes attending them. Also to some extent they were supplanted by the ballrooms of major hotels as British hotels became larger from the railway age onwards.\n\n\nLondon also had a number of outdoor \"public gardens\" where similar entertainments took place. They were more commercial establishments and tended to have less exclusive rules on admission. Each had at least one major indoor space for balls and the like. See: Marylebone Gardens, Vauxhall Gardens, Ranelagh Gardens and Cremorne Gardens.\n\n"}
{"id": "10855498", "url": "https://en.wikipedia.org/wiki?curid=10855498", "title": "Biocultural anthropology", "text": "Biocultural anthropology\n\nBiocultural anthropology can be defined in numerous ways. It is the scientific exploration of the relationships between human biology and culture. \"Instead of looking for the biology underlying biological roots of human behavior, biocultural anthropology attempts to understand how culture affects our biological capacities and limitations.\"\n\nPhysical anthropologists throughout the first half of the 20th century viewed this relationship from a racial perspective; that is, from the assumption that typological human biological differences lead to cultural differences. After World War II the emphasis began to shift toward an effort to explore the role culture plays in shaping human biology. The shift towards understanding the role of culture to human biology led to the development of Dual inheritance theory in the 1960s. In relation to, and following the development of Dual-inheritance theory, biocultural evolution was introduced and first used in the 1970s.\n\n\nBiocultural methods focus on the interactions between humans and their environment to understand human biological adaptation and variation. Contemporary biocultural anthropologists view culture as having several key roles in human biological variation:\n\nWhile biocultural anthropologists are found in many academic anthropology departments, usually as a minority of the faculty, certain departments have placed considerable emphasis on the \"biocultural synthesis\". Historically, this has included Emory University, the University of Alabama, UMass Amherst (especially in biocultural bioarchaeology) , and the University of Washington , each of which built Ph.D. programs around biocultural anthropology; Binghamton University, which has a M.S. program in biomedical anthropology; Oregon State University, University of Kentucky and others. Paul Baker, an anthropologist at Penn State whose work focused upon human adaptation to environmental variations, is credited with having popularized the concept of \"biocultural\" anthropology as a distinct subcategory of anthropology in general. Khongsdier argues that biocultural anthropology is the future of anthropology because it serves as a guiding force towards greater integration of the subdisciplines.\n\nOther anthropologists, both biological and cultural, have criticized the biocultural synthesis, generally as part of a broader critique of \"four-field holism\" in U.S. anthropology (see anthropology main article). Typically such criticisms rest on the belief that biocultural anthropology imposes holism upon the biological and cultural subfields without adding value, or even destructively. For instance, contributors in the edited volume \"Unwrapping the Sacred Bundle: Reflections on the Disciplining of Anthropology\" argued that the biocultural synthesis, and anthropological holism more generally, are artifacts from 19th century social evolutionary thought that inappropriately impose scientific positivism upon cultural anthropology.\n\nSome departments of anthropology have fully split, usually dividing scientific from humanistic anthropologists, such as Stanford's highly publicized 1998 division into departments of \"Cultural and Social Anthropology\" and \"Anthropological Sciences\". Underscoring the continuing controversy, this split is now being reversed over the objections of some faculty. Other departments, such as at Harvard, have distinct biological and sociocultural anthropology \"wings\" not designed to foster cross subdisciplinary interchange.\n\nBiocultural approaches were derived from biology and science yet social theorists are feeling encroached upon. The Biocultural approach has also not been a central concern to anthropologists which is a contributor to the splitting of the approach into sociocultural anthropology and biosocial anthropology. Biocultural research has shown to contain a few challenges to the researcher. \"In general we are much more experienced in measuring the biological than the cultural. It is also difficult to precisely define what is meant by constructs such as socioeconomic status, poverty, rural, and urban. Operationalizing key variables so that they can be measured in ways that are enthnographically valid as well as replicable. Defining and measuring multiple causal pathways.\"\n\n\n"}
{"id": "38753450", "url": "https://en.wikipedia.org/wiki?curid=38753450", "title": "COCOA (digital humanities)", "text": "COCOA (digital humanities)\n\nCOCOA was an early text file utility and associated file format for digital humanities, then known as humanities computing. It was approximately 4000 punched cards of FORTRAN and created in the late 1960s and early 1970s at University College London and the Atlas Computer Laboratory in Harwell, Oxfordshire. Functionality included word-counting and concordance building.\n\nThe Oxford Concordance Program (OCP) format was a direct descendent of COCOA developed at Oxford University. The Oxford Text Archive holds items in this format.\n\nThe COCOA file format bears at least a passing similarity to the later markup languages such as SGML and XML. A noticeable difference with its successors is that COCOA tags are flat and not tree structured. In that format, every information type and value encoded by a tag should be considered true until the same tag changes its value. Members of the Text Encoding Initiative community maintain legacy support for COCOA, although most in-demand texts and corpora have already been migrated to more widely understand formats such as TEI XML\n"}
{"id": "22370628", "url": "https://en.wikipedia.org/wiki?curid=22370628", "title": "Castle Agrazant", "text": "Castle Agrazant\n\nCastle Agrazant is an opera composed by Ralph Lyford. It premiered on 29 April 1926 with Forrest Lamont performing, in Cincinnati. \"Castle Agrazant\" won a Bispham Memorial Medal Award in 1926.\n\nThe opera is set in Northern France in the aftermath of the Ninth Crusade - specified as 1290 in the program for the opera. Characters include Richard of Agrazant (Riego of Agrazant), a young crusader and religious zealot; and his wife Isabeau. In the story, the husband and crusader, Richard, returns to avenge his persecuted wife, Isabeau.\n\nIn the 1926 premier, Olga Forrai performed as Isabeau, Forrest Lamont performed as Richard, and Howard Preston as Geoffrey.\nThe Opera's performances included a chorus of 65 members and 60 members of the Cincinnati Symphony. The cost to stage the production in 1926 was $15,000 USD (approximately $183,000 in 2010 USD).\n\nThe Opera was also broadcast by radio station WLW in Cincinnati, Ohio on May 3, 1926.\n\nIsabeau is mourning the death of her newborn daughter, alone. Count Lisiac, a former suitor of Isabeau, seizes the opportunity of her husband's absence and her grief to approach Isabeau. When his attempts fail he turns to violence, assaulting the Castle Agrazant and kidnapping Isabeau. Isabeau conceals a note giving details of her abduction before she is taken.\n\nElsewhere, Richard of Agrazant is returning from Jerusalem. He passes Lisiac Hall ignorant that his wife is imprisoned there. He arrives at Castle Agrazant and sees evidence of the assault. He finds his daughter dead in the cradle and the note from Isabeau. He pledges \nrevenge.\n\nIsabeau is feted at Lisiac Hall, but takes no part in the celebrations. Geoffrey becomes inebriated and is more forward with Isabeau. As events spin out of control, Geoffrey's men debate protecting Isabeau from Geoffrey. A herald then announces the arrival of traveling\nmusicians - a monk, a minstrel, and a boy. Geoffrey commands them to perform but asks Isabeau to select a happy song. She requests a song of Nazareth, and Richard (disguised as the monk) thereby confirms she has no desire to stay with Geoffrey.\n\nThe Boy then sings of the recent assault of Castle Agrazant, to the astonishment of Geoffrey and his men. Filled with superstitious dread, Lisiac orders the musicians cast out. The Monk interjects, offering to sing a different song - and his voice is recognized by Isabeau as her Richard's. Richard sings of his love for Isabeau and remorse at going to Jerusalem and leaving 'far from home and wife and child'.\n\nRemoving his disguise, Richard challenges Geoffrey and a melee ensues. In the melee, Isabeau is stabbed by Geoffrey; Geoffrey is run through by Richard's sword. Richard seizes Isabeau and escapes, followed by the boy and musician.\n\nRichard enters, assisting Isabeau. She asks to rest and Richard encourages her to continue on. She weakens further, they do rest, apparently sleeping for the night. In the morning, Richard uses his helmet to fetch water and tells of his visit to Jerusalem. His assessment is that his crusade was in error, he sacrificed all that was worthy in its pursuit. He breaks his blade. Placing the fragments on a rock, he returns to Isabeau. Isabeau bemoans their sad fate and begins to hallucinate that she is comforting her daughter; she hears the horns of Lisiac approaching. She and Richard sing a duet extolling the possibility of living in a brighter realm in the future, forever.\n"}
{"id": "51328035", "url": "https://en.wikipedia.org/wiki?curid=51328035", "title": "Chronological dating", "text": "Chronological dating\n\nChronological dating, or simply dating, is the process of attributing to an object or event a date in the past, allowing such object or event to be located in a previously established chronology. This usually requires what is commonly known as a \"dating method\". Several dating methods exist, depending on different criteria and techniques, and some very well known examples of disciplines using such techniques are, for example, history, archaeology, geology, paleontology, astronomy and even forensic science, since in the latter it is sometimes necessary to investigate the moment in the past in which the death of a cadaver occurred.\n\nDating methods are most commonly classified following two criteria: relative dating and absolute dating.\n\nRelative dating methods are unable to determine the absolute age of an object or event, but can determine the impossibility of a particular event happening before or after another event of which the absolute date is well known. In this relative dating method, Latin terms \"ante quem\" and \"post quem\" are usually used to indicate both the oldest and the most recent possible moments when an event occurred or an artifact was left in a stratum. But this method is also useful in many other disciplines. Historians, for example, know that Shakespeare's play \"Henry V\" was not written before 1587 because Shakespeare's primary source for writing his play was the second edition of Raphael Holinshed's \"Chronicles\", not published until 1587. Thus, 1587 is the \"post quem\" dating of Shakespeare's play \"Henry V\". That means that the play was without fail written after (in Latin, \"post\") 1587.\n\nThe same inductive mechanism is applied in archaeology, geology and paleontology, by many ways. For example, in a stratum presenting difficulties or ambiguities to absolute dating, paleopalynology can be used as a relative referent by means of the study of the pollens found in the stratum. This is admitted because of the simple reason that some botanical species, whether extinct or not, are well known as belonging to a determined position in the scale of time.\n\nFor a non-exhaustive list of relative dating methods and relative dating applications used in geology, paleontology or archaeology, see the following:\n\n\nAbsolute dating methods, by using absolute referent criteria, mainly include the radiometric dating methods. Some examples of both radiometric and non-radiometric absolute dating methods are the following:\n\n\nSame as geologists or paleontologists, archaeologists are also brought to determine the age of ancient materials, but in their case, the areas of their studies are restricted to the history of both ancient and recent humans. Thus, to be considered as archaeological, the remains, objects or artifacts to be dated must be related to human activity. It is commonly assumed that if the remains or elements to be dated are older than the human species, the disciplines which study them are sciences such geology or paleontology, among some others.\n\nNevertheless, the range of time within archaeological dating can be enormous compared to the average lifespan of a singular human being. As an example Pinnacle Point's caves, in the southern coast of South Africa, provided evidence that marine resources (shellfish) have been regularly exploited by humans as of 170,000 years ago. On the other hand, remains as recent as a hundred years old can also be the target of archaeological dating methods. It was the case of an 18th-century sloop whose excavation was led in South Carolina (United States) in 1992. Thus, from the oldest to the youngest, all archaeological sites are likely to be dated by an appropriate method.\n\nDating material drawn from the archaeological record can be made by a direct study of an artifact, or may be deduced by association with materials found in the context the item is drawn from or inferred by its point of discovery in the sequence relative to datable contexts. Dating is carried out mainly post excavation, but to support good practice, some preliminary dating work called \"spot dating\" is usually run in tandem with excavation. Dating is very important in archaeology for constructing models of the past, as it relies on the integrity of dateable objects and samples. Many disciplines of archaeological science are concerned with dating evidence, but in practice several different dating techniques must be applied in some circumstances, thus dating evidence for much of an archaeological sequence recorded during excavation requires matching information from known absolute or some associated steps, with a careful study of stratigraphic relationships.\n\nIn addition, because of its particular relation with past human presence or past human activity, archaeology uses almost all the dating methods that it shares with the other sciences, but with some particular variations, like the following:\n\n\nSeriation is a relative dating method (see, above, the list of relative dating methods). An example of a practical application of seriation, is the comparison of the known style of artifacts such as stone tools or pottery.\n\n\nThe stratigraphy of an archaeological site can be used to date, or refine the date, of particular activities (\"contexts\") on that site. For example, if a context is sealed between two other contexts of known date, it can be inferred that the middle context must date to between those dates.\n\n"}
{"id": "1326648", "url": "https://en.wikipedia.org/wiki?curid=1326648", "title": "Cognitive archaeology", "text": "Cognitive archaeology\n\nCognitive archaeology is a theoretical perspective in archaeology which focuses on the ways that ancient societies thought and the symbolic structures that can be perceived in past material culture.\n\nCognitive archaeologists often study the role that ideology and differing organizational approaches would have had on ancient peoples. The way that these abstract ideas are manifested through the remains that these peoples have left can be investigated and debated often by drawing inferences and using approaches developed in fields such as semiotics, psychology and the wider sciences.\nHumans do not behave under the influence of their senses alone but also through their past experiences such as their upbringing. These experiences contribute to each individual's unique view of the world, a kind of cognitive map that guides them. Groups of people living together tend to develop a shared view of the world and similar cognitive maps which in turn influence their group material culture.\n\nArchaeologists have always tried to imagine what motivated people but early efforts to understand how they thought were unstructured and speculative. Since the rise of processualism these approaches have become more scientific, paying close attention to the Archaeological context of archaeological finds and all possible interpretations. For example, a prehistoric bâton de commandement served an unknown purpose but using cognitive archaeology to interpret it would involve evaluating all its possible functions using clearly defined procedures and comparisons. By applying logic and experimental evidence, the most likely functions can be isolated.\n\nThe multiple interpretations of an artifact, archaeological site or symbol are affected by the archaeologist's own experiences and ideas as well as those of the distant cultural tradition that created it. Cave art for example may not have been art in the modern sense at all but perhaps the product of ritual. Similarly, it would likely have described activities that were perfectly obvious to the people who created it but the symbology employed will be different from that used today or at any other time.\n\nSome archaeologists such as Lewis Binford have critiqued cognitive archaeology, stating that it is only people's actions rather than their thoughts that are preserved in the archaeological record. However it can be argued that even this evidence of actions is still the product of human thought and would have been governed by a multitude of experiences and perspectives. Thus one can see Cognitive Archaeology as a development of Processual Archaeology in that the combination of material culture and actions can be further developed into a study of the ideas which drove action and used objects. This method attempts to avoid the pitfalls of Post-Processual Archaeology by retaining the 'scientific' aspects of Processual Archaeology while reaching for the higher social levels of ideas.\n\nArchaeologist Thomas Huffman defines cognitive archaeology as the study of prehistoric ideology: the ideals, values, and beliefs that constitute a society's worldview. Cognitive archaeologists use the principles of sociocultural anthropology to investigate such diverse things as material symbols, the use of space, political power, and religion. For example, Huffman uses oral history sources from Zimbabwe and Portuguese documents to attempt to explain symbols discovered in the ruins of Great Zimbabwe, specifically connecting the Shona people's historical association of the right with men and the left with women to the placement of entrances to stone structures. This cognitive archaeological approach may be problematic in its logical leaps and incomplete use of archaeological sources, as historian David Beach has pointed out, demonstrating the care that must be used when attempting to explain deep-time intentionality using archaeological evidence. \n\n\n"}
{"id": "50416177", "url": "https://en.wikipedia.org/wiki?curid=50416177", "title": "Cognitive ecology of religion", "text": "Cognitive ecology of religion\n\nCognitive ecology of religion is an integrative approach to studying how religious beliefs covary with social and natural dynamics of the environment. This is done by incorporating a cognitive ecological perspective to cross-cultural god concepts. Religious beliefs are thought to be a byproduct of domain-specific cognitive modules that give rise to religious cognition. The cognitive biases leading to religious belief are constraints on perceptions of the environment, which is part and parcel of a cognitive ecological approach. This means that they not only shape religious beliefs, but they are determinants of how successfully cultural beliefs are transmitted.\n\nFurthermore, cognition and behavior are inextricably linked, so the consequences of cultural concepts are associated with behavioral outcomes (i.e., continued interactions with the environment). For religion, behaviors often take the form of rituals and are similarly executed as a consequence of beliefs. Because the religious beliefs distributed in a population are relevant to their behavioral strategies and fine-tuned by natural selection, cross-cultural representations of gods and their characteristics are hypothesized to address ecologically relevant challenges. In other words, religious beliefs are thought to frequently involve solutions, insofar as evolved cognitive equipment can build them, to social and natural environmental problems faced by a given population.\n\nResearch in evolutionary psychology suggests that the brain is a coordinated network of domain-specific modules corresponding to various adaptations that emerged in our evolutionary history. Most claim that a capacity for religious thoughts is not a modular adaptation itself, but an evolutionary byproduct of multiple integrated mechanisms that arose independently and are designed for different functions. These modules are co-opted to give rise to religious thinking patterns, and they include theory of mind, essential psychology and the hyperactive agency detection device. Moreover, the cultural transmission of these ideas is contingent upon them being minimally counterintuitive.\n\nTheory of mind (ToM) is a capacity to attribute mental states, complete with thoughts, emotions and motivations, to other social agents. This adaptation is ubiquitous in primitive forms among various social species, but the complexity of human social life for long stretches of evolutionary history has facilitated a rich understanding of others' mental experiences to match. Cases of autism have been cited in support for the proposition that ToM is a distinct modular adaptation because of its distinctly narrow impact on ToM capacity. ToM is thought to lend itself to an intuitive sense of mind-body dualism, where the material body is animated by a non-material self (i.e., a \"soul\").\n\nFolk psychology among humans is characterized by essential thinking, or a tendency to interpret objects in terms of \"essences.\" This means that attributions of objects' underlying realities are intuitively inferred from a fuzzy set of the object's ontological features. Cognitive interpretations of essence give rise to concepts of purity, simplified good and evil concepts, and intuitive senses of meaning applied to teleology.\n\nThe capacity for agent detection has been an important modular adaptation for predator avoidance in humans. Some have called this mechanism a hyperactive agency detection device because of its fairly high rate of erroneous agency applications. In a potential predator situation, humans are forced to interpret an object's ontological features, infer agency or non-agency, and execute a behavioral response. Evolutionary theorists have cited the relatively low costs of incorrect agency inferences and the severe fitness costs of detection failure as a reason to suspect that a tendency to interpret naturalistic processes as agent behaviors is an adaptation. This creates a cognitive bias that leads humans to reason about objects and processes in agentive terms. This is particularly foundational to beliefs in a god or gods.\n\nThe integration of ToM, hyperactive applications of agency and essential psychology ultimately renders a cognitive tendency for humans to interact with the naturalistic processes of the world with the intentional stance. This is a perspective from which humans reason that objects and processes may be enacting behaviors intentionally, with meaningful, rational mental states of their own.\n\nReligious beliefs are successfully transmitted if they are compatible with the cognitive tools that reconstruct them upon reception. This means that they must be minimally counterintuitive, or that they violate few enough ontological features of an object or process, to make general sense while remaining memorable violations nonetheless. For example, the concept of a ghost exploits existing intuitions about mind-body dualism and only violates the usual coupling of mind and body. This creates a memorable concept of a non-material person that can move through walls and have motives of its own. On the other hand, a highly counterintuitive idea about an object that violates several of its ontological features, like a jealous Frisbee, is less likely to be culturally transmitted. This is because it is cognitively demanding, not easily reconstructed by the brain and thus, not easily reasoned about and remembered.\n\nReligious behaviors associated with culturally transmitted god concepts can be conceptualized as phenotypic strategies associated with the informational makeup of that cultural concept. Successfully transmitted religious concepts typically involve minimally counterintuitive violations of the intentional stance, which serves a cognitive constraint of cultural evolution. However, ecological factors also play a role in determining which religious behaviors (and their god concepts) are more likely to be replicated. This means that religious rituals associated with salient representational models of gods' minds and concerns are more likely to survive when they are adaptive strategies.\n\nCross-culturally, representational models of gods' minds take an array of diverse forms, such as anthropomorphic or zoomorphic figures, abstract forces, or some combination of these. Models of gods' minds typically fall within a spectrum between two extremes: on one end there are Big Gods, and on the other there are Local Gods. Big Gods are usually moralistic, punitive and omniscient, whereas Local Gods are often concerned about ritual behaviors, amoral and limited in knowledge. The subject matter that gods are believed to care across cultures fall into three categories, but may involve an admixture of more than one. These categories are (1) behaviors toward other people, (2) behaviors toward the gods themselves and (3) behaviors toward nature and/or the environment. While people impute these concerns to gods' minds, they often correspond to ecological challenges. This correspondence establishes why religious ideas often covary with ecological problems in the social and natural world: because these ideas enact behavioral strategies that solve them.\n\nCases of large-scale cooperation in complex societies are a widely studied example of a socioecological problem that religious beliefs address. Existing models of human cooperation have included kin selection, reciprocal altruism, indirect reciprocity and competitive helping. These models are robust across certain conditions likely relevant to the Pleistocene, but cooperation is easily eroded in large-scale, complex societies with frequently anonymous interactions between strangers. This is because profitable defections dominate cooperative strategies due to a lack of significant threats of punishment to defectors. For large-scale cooperation to succeed, a cultural coordination solution stabilized by sanction threats must exist.\n\nReligious rules addressing moral behavior are cultural coordination devices that can expand the scale of cooperative behavior by motivating prosociality. The most important stipulation here is that these devices must be enforced by punishment threats for people who do not behave prosocially. Frequent instances of anonymity in large-scale societies and the costs associated with punishment undermine sanction threats, but widespread beliefs in morally punitive and omniscient gods effectively outsource the punishment costs to a pervasive social monitor. This can effectively motivate widespread prosocial behavior in large-scale, complex societies.\n\nThis has been empirically supported from a few different angles. For instance, the cross-cultural prevalence of omniscient, moralistic gods (i.e., Big Gods) is positively correlated with society size and complexity. Examples of sharing behaviors in experimental economic games played by large-scale societies also reveal more generous behaviors when individuals are primed with Big God concepts before the game. These shifts toward prosociality are not replicated when similar experiments are applied to small-scale societies. Another recent cross-cultural study compiled experimental economic game data from multiple large- and small-scale societies around the world, where people with various religious beliefs played with local or distant people who were often of the same religion. When distant strangers of the same religion were paired in a game, their sharing behaviors were significantly more generous if their common beliefs involved Big God concepts. The researchers of this study argue that this supports the hypothesis stating that widespread beliefs in omniscient, morally punitive Big Gods may have contributed to the expansion of prosocial behavior.\n\nConcerns attributed to gods about how people behave toward the gods themselves are widespread and not easily disentangled from specific ecological conditions. The reason is intuitive; rational agents who do not care about their treatment are counterintuitive. Researchers investigating the socioecological functions of ritual behaviors in deference to gods claim that functionally, these rituals serve as costly signals of commitment to the group. Costly ritual displays are particularly public and ubiquitous in small-scale societies, functioning as social devices that promote intragroup cohesion. Reputations related to trustworthiness can be significantly based on adherence to ritual behavior expectations, and fulfillment of these expectations are often a joint function of other behavioral strategies relevant to separate domains of gods' concerns. More broadly, religious costly signals are an implicit expression of honest commitment to the rest of the group, indicating that the signaler is a dedicated part of other aspect of the group's coordinated solution strategies. In small- and large-scale societies alike, these rituals often coexist with other categories of gods' concerns.\n\nResource management and the prevention of material insecurity are more commonly associated with gods' concerns among small-scale societies. While other aspects of religious belief often address social interactions, problems of resource acquisition and security extend from attributed gods' concerns about peoples' interactions with their natural environment. An example of this effect has been alluded to by anthropologist Marvin Harris, who wrote about the economic reasons that Hindu beliefs, holding cows as sacred and forbidden from slaughter, were adaptive. According to Harris, the long-standing and stable benefits derived from many Hindu peoples' use of cows for labor and sources of fuel and fertilizer seemed to outweigh the costs of not eating them. Another ethnographic example of an adaptive use of animal resources was described by Roy Rappaport in 1984, who considered the reasons for ritual pig sacrifice in Papua New Guinea during times of intergroup conflict. These pigs were consuming local peoples' resources and creating resource insecurities that put a strain on the local groups, escalating the intergroup competition for resources and fueling their conflict. Thus, the ritualistic sacrifices alleviated the strain on local resources and mitigated the hostilities between groups. Furthermore, human behavioral ecology researchers have more recently studied burning practices among the Australian Martu people and the consequential increases in local biodiversity. These authors, in an ethnographic discussion of the Martu people, note that these burning practices stem from religious beliefs that their practices allow the world to continue existing as they know it.\n\nAnother ethnographic example of religious beliefs facilitating resource management comes from the Tyva people, a pastoralist population in southern Siberia. They associate ritual structures called cairns with local spirit masters (\"cher eezi\"). These structures demarcate local territories in which spirit masters reside, and the expectation to stop and give prayer offerings out of respect to \"cher eezi\" is embedded in peoples' beliefs about them. The \"cher eezi\" are believed to be amoral and care mostly about activity within their sacred territories, such as hunting and overexploiting resources that belong to them. More recently, Tyva people have begun facing new challenges associated with urbanization (e.g., pollution, alcohol abuse), and the \"cher eezi\" have been more frequently believed to be concerned about these same problems.\n"}
{"id": "16300571", "url": "https://en.wikipedia.org/wiki?curid=16300571", "title": "Computational creativity", "text": "Computational creativity\n\nComputational creativity (also known as artificial creativity, mechanical creativity, creative computing or creative computation) is a multidisciplinary endeavour that is located at the intersection of the fields of artificial intelligence, cognitive psychology, philosophy, and the arts.\n\nThe goal of computational creativity is to model, simulate or replicate creativity using a computer, to achieve one of several ends:\n\n\nThe field of computational creativity concerns itself with theoretical and practical issues in the study of creativity. Theoretical work on the nature and proper definition of creativity is performed in parallel with practical work on the implementation of systems that exhibit creativity, with one strand of work informing the other.\n\nAs measured by the amount of activity in the field (e.g., publications, conferences and workshops), computational creativity is a growing area of research. But the field is still hampered by a number of fundamental problems. Creativity is very difficult, perhaps even impossible, to define in objective terms. Is it a state of mind, a talent or ability, or a process? Creativity takes many forms in human activity, some \"eminent\" (sometimes referred to as \"Creativity\" with a capital C) and some \"mundane\".\n\nThese are problems that complicate the study of creativity in general, but certain problems attach themselves specifically to \"computational\" creativity:\n\n\nIndeed, not all computer theorists would agree with the premise that computers can only do what they are programmed to do—a key point in favor of computational creativity.\n\nBecause no single perspective or definition seems to offer a complete picture of creativity, the AI researchers Newell, Shaw and Simon developed the combination of novelty and usefulness into the cornerstone of a multi-pronged view of creativity, one that uses the following four criteria to categorize a given answer or solution as creative:\n\n\nWhereas the above reflects a \"top-down\" approach to computational creativity, an alternative thread has developed among \"bottom-up\" computational psychologists involved in artificial neural network research. During the late 1980s and early 1990s, for example, such generative neural systems were driven by genetic algorithms. Experiments involving recurrent nets were successful in hybridizing simple musical melodies and predicting listener expectations.\n\nConcurrent with such research, a number of computational psychologists took the perspective, popularized by Stephen Wolfram, that system behaviors perceived as complex, including the mind's creative output, could arise from what would be considered simple algorithms. As neuro-philosophical thinking matured, it also became evident that language actually presented an obstacle to producing a scientific model of cognition, creative or not, since it carried with it so many unscientific aggrandizements that were more uplifting than accurate. Thus questions naturally arose as to how \"rich,\" \"complex,\" and \"wonderful\" creative cognition actually was.\n\nBefore 1989, artificial neural networks have been used to model certain aspects of creativity. Peter Todd (1989) first trained a neural network to reproduce musical melodies from a training set of musical pieces. Then he used a change algorithm to modify the network's input parameters. The network was able to randomly generate new music in a highly uncontrolled manner. In 1992, Todd\nextended this work, using the so-called distal teacher approach that had been developed by\nPaul Munro, Paul Werbos, D. Nguyen and Bernard Widrow, Michael I. Jordan and David Rumelhart. In the new approach there are two neural networks, one of which is supplying training patterns to another. \nIn later efforts by Todd, a composer would select a set of melodies that define the melody space, position them on a 2-d plane with a mouse-based graphic interface, and train a connectionist network to produce those melodies, and listen to the new \"interpolated\" melodies that the network generates corresponding to intermediate points in the 2-d plane.\n\nMore recently a neurodynamical model of semantic networks has been developed to study how the connectivity structure of these networks relates to the richness of the semantic constructs, or ideas, they can generate. It was demonstrated that semantic neural networks that have richer semantic dynamics than those with other connectivity structures may provide insight into the important issue of how the physical structure of the brain determines one of the most profound features of the human mind – its capacity for creative thought.\n\nSome high-level and philosophical themes recur throughout the field of computational creativity.\n\nMargaret Boden refers to creativity that is novel \"merely to the agent that produces it\" as \"P-creativity\" (or \"psychological creativity\"), and refers to creativity that is recognized as novel \"by society at large\" as \"H-creativity\" (or \"historical creativity\"). Stephen Thaler has suggested a new category he calls \"V-\" or \"Visceral creativity\" wherein significance is invented to raw sensory inputs to a Creativity Machine architecture, with the \"gateway\" nets perturbed to produce alternative interpretations, and downstream nets shifting such interpretations to fit the overarching context. An important variety of such V-creativity is consciousness itself, wherein meaning is reflexively invented to activation turnover within the brain.\n\nBoden also distinguishes between the creativity that arises from an exploration within an established conceptual space, and the creativity that arises from a deliberate transformation or transcendence of this space. She labels the former as \"exploratory creativity\" and the latter as \"transformational creativity\", seeing the latter as a form of creativity far more radical, challenging, and rarer than the former. Following the criteria from Newell and Simon elaborated above, we can see that both forms of creativity should produce results that are appreciably novel and useful (criterion 1), but exploratory creativity is more likely to arise from a thorough and persistent search of a well-understood space (criterion 3) -- while transformational creativity should involve the rejection of some of the constraints that define this space (criterion 2) or some of the assumptions that define the problem itself (criterion 4). Boden's insights have guided work in computational creativity at a very general level, providing more an inspirational touchstone for development work than a technical framework of algorithmic substance. However, Boden's insights are more recently also the subject of formalization, most notably in the work by Geraint Wiggins.\n\nThe criterion that creative products should be novel and useful means that creative computational systems are typically structured into two phases, generation and evaluation. In the first phase, novel (to the system itself, thus P-Creative) constructs are generated; unoriginal constructs that are already known to the system are filtered at this stage. This body of potentially creative constructs are then evaluated, to determine which are meaningful and useful and which are not. This two-phase structure conforms to the Geneplore model of Finke, Ward and Smith, which is a psychological model of creative generation based on empirical observation of human creativity.\n\nA great deal, perhaps all, of human creativity can be understood as a novel combination of pre-existing ideas or objects . Common strategies for combinatorial creativity include:\nThe combinatorial perspective allows us to model creativity as a search process through the space of possible combinations. The combinations can arise from composition or concatenation of different representations, or through a rule-based or stochastic transformation of initial and intermediate representations. Genetic algorithms and neural networks can be used to generate blended or crossover representations that capture a combination of different inputs.\n\nMark Turner and Gilles Fauconnier propose a model called Conceptual Integration Networks that elaborates upon Arthur Koestler's ideas about creativity as well as more recent work by Lakoff and Johnson, by synthesizing ideas from Cognitive Linguistic research into mental spaces and conceptual metaphors. Their basic model defines an integration network as four connected spaces:\n\n\nFauconnier and Turner describe a collection of optimality principles that are claimed to guide the construction of a well-formed integration network. In essence, they see blending as a compression mechanism in which two or more input structures are compressed into a single blend structure. This compression operates on the level of conceptual relations. For example, a series of similarity relations between the input spaces can be compressed into a single identity relationship in the blend.\n\nSome computational success has been achieved with the blending model by extending pre-existing computational models of analogical mapping that are compatible by virtue of their emphasis on connected semantic structures. More recently, Francisco Câmara Pereira presented an implementation of blending theory that employs ideas both from GOFAI and genetic algorithms to realize some aspects of blending theory in a practical form; his example domains range from the linguistic to the visual, and the latter most notably includes the creation of mythical monsters by combining 3-D graphical models.\n\nLanguage provides continuous opportunity for creativity, evident in the generation of novel sentences, phrasings, puns, neologisms, rhymes, allusions, sarcasm, irony, similes, metaphors, analogies, witticisms, and jokes. Native speakers of morphologically rich languages frequently create new word-forms that are easily understood, although they will never find their way to the dictionary. The area of natural language generation has been well studied, but these creative aspects of everyday language have yet to be incorporated with any robustness or scale.\n\nSubstantial work has been conducted in this area of linguistic creation since the 1970s, with the development of James Meehan's TALE-SPIN\n\nThe company Narrative Science makes computer generated news and reports commercially available, including summarizing team sporting events based on statistical data from the game. It also creates financial reports and real estate analyses.\n\nExample of a metaphor: \"She was an ape.\"\n\nExample of a simile: \"Felt like a tiger-fur blanket.\"\nThe computational study of these phenomena has mainly focused on interpretation as a knowledge-based process. Computationalists such as Yorick Wilks, James Martin, Dan Fass, John Barnden, and Mark Lee have developed knowledge-based approaches to the processing of metaphors, either at a linguistic level or a logical level. Tony Veale and Yanfen Hao have developed a system, called Sardonicus, that acquires a comprehensive database of explicit similes from the web; these similes are then tagged as bona-fide (e.g., \"as hard as steel\") or ironic (e.g., \"as hairy as a bowling ball\", \"as pleasant as a root canal\"); similes of either type can be retrieved on demand for any given adjective. They use these similes as the basis of an on-line metaphor generation system called Aristotle that can suggest lexical metaphors for a given descriptive goal (e.g., to describe a supermodel as skinny, the source terms \"pencil\", \"whip\", \"whippet\", \"rope\", \"stick-insect\" and \"snake\" are suggested).\n\nThe process of analogical reasoning has been studied from both a mapping and a retrieval perspective, the latter being key to the generation of novel analogies. The dominant school of research, as advanced by Dedre Gentner, views analogy as a structure-preserving process; this view has been implemented in the structure mapping engine or SME, the MAC/FAC retrieval engine (Many Are Called, Few Are Chosen), ACME (Analogical Constraint Mapping Engine) and ARCS (Analogical Retrieval Constraint System). Other mapping-based approaches include Sapper, which situates the mapping process in a semantic-network model of memory. Analogy is a very active sub-area of creative computation and creative cognition; active figures in this sub-area include Douglas Hofstadter, Paul Thagard, and Keith Holyoak. Also worthy of note here is Peter Turney and Michael Littman's machine learning approach to the solving of SAT-style analogy problems; their approach achieves a score that compares well with average scores achieved by humans on these tests.\n\nHumour is an especially knowledge-hungry process, and the most successful joke-generation systems to date have focussed on pun-generation, as exemplified by the work of Kim Binsted and Graeme Ritchie. This work includes the JAPE system, which can generate a wide range of puns that are consistently evaluated as novel and humorous by young children. An improved version of JAPE has been developed in the guise of the STANDUP system, which has been experimentally deployed as a means of enhancing linguistic interaction with children with communication disabilities. Some limited progress has been made in generating humour that involves other aspects of natural language, such as the deliberate misunderstanding of pronominal reference (in the work of Hans Wim Tinholt and Anton Nijholt), as well as in the generation of humorous acronyms in the HAHAcronym system of Oliviero Stock and Carlo Strapparava.\n\nThe blending of multiple word forms is a dominant force for new word creation in language; these new words are commonly called \"blends\" or \"portmanteau words\" (after Lewis Carroll). Tony Veale has developed a system called ZeitGeist that harvests neological headwords from Wikipedia and interprets them relative to their local context in Wikipedia and relative to specific word senses in WordNet. ZeitGeist has been extended to generate neologisms of its own; the approach combines elements from an inventory of word parts that are harvested from WordNet, and simultaneously determines likely glosses for these new words (e.g., \"food traveller\" for \"gastronaut\" and \"time traveller\" for \"chrononaut\"). It then uses Web search to determine which glosses are meaningful and which neologisms have not been used before; this search identifies the subset of generated words that are both novel (\"H-creative\") and useful. Neurolinguistic inspirations have been used to analyze the process of novel word creation in the brain, understand neurocognitive processes responsible for intuition, insight, imagination and creativity and to create a server that invents novel names for products, based on their description. Further, the system Nehovah blends two source words into a neologism that blends the meanings of the two source words. Nehovah searches WordNet for synonyms and TheTopTens.com for pop culture hyponyms. The synonyms and hyponyms are blended together to create a set of candidate neologisms. The neologisms are then scored based on their word structure, how unique the word is, how apparent the concepts are conveyed, and if the neologism has a pop culture reference. Nehovah loosely follows conceptual blending.\n\nLike jokes, poems involve a complex interaction of different constraints, and no general-purpose poem generator adequately combines the meaning, phrasing, structure and rhyme aspects of poetry. Nonetheless, Pablo Gervás has developed a noteworthy system called ASPERA that employs a case-based reasoning (CBR) approach to generating poetic formulations of a given input text via a composition of poetic fragments that are retrieved from a case-base of existing poems. Each poem fragment in the ASPERA case-base is annotated with a prose string that expresses the meaning of the fragment, and this prose string is used as the retrieval key for each fragment. Metrical rules are then used to combine these fragments into a well-formed poetic structure. Racter is an example of such a software project.\n\nComputational creativity in the music domain has focused both on the generation of musical scores for use by human musicians, and on the generation of music for performance by computers. The domain of generation has included classical music (with software that generates music in the style of Mozart and Bach) and jazz. Most notably, David Cope has written a software system called \"Experiments in Musical Intelligence\" (or \"EMI\") that is capable of analyzing and generalizing from existing music by a human composer to generate novel musical compositions in the same style. EMI's output is convincing enough to persuade human listeners that its music is human-generated to a high level of competence.\n\nIn the field of contemporary classical music, Iamus is the first computer that composes from scratch, and produces final scores that professional interpreters can play. The London Symphony Orchestra played a piece for full orchestra, included in Iamus' debut CD, which \"New Scientist\" described as \"The first major work composed by a computer and performed by a full orchestra\". Melomics, the technology behind Iamus, is able to generate pieces in different styles of music with a similar level of quality.\n\nCreativity research in jazz has focused on the process of improvisation and the cognitive demands that this places on a musical agent: reasoning about time, remembering and conceptualizing what has already been played, and planning ahead for what might be played next. The robot Shimon, developed by Gil Weinberg of Georgia Tech, has demonstrated jazz improvisation. Virtual improvisation software based on machine learning models of musical style include OMax, SoMax and PyOracle, are used to create improvisations in real-time by re-injecting variable length sequences learned on the fly from live performer.\n\nIn 1994, a Creativity Machine architecture (see above) was able to generate 11,000 musical hooks by training a synaptically perturbed neural net on 100 melodies that had appeared on the top ten list over the last 30 years. In 1996, a self-bootstrapping Creativity Machine observed audience facial expressions through an advanced machine vision system and perfected its musical talents to generate an album entitled \"Song of the Neurons\"\n\nIn the field of musical composition, the patented works by René-Louis Baron allowed to make a robot that can create and play a multitude of orchestrated melodies so-called \"coherent\" in any musical style. All outdoor physical parameter associated with one or more specific musical parameters, can influence and develop each of these songs (in real time while listening to the song). The patented invention \"Medal-Composer\" raises problems of copyright.\n\nComputational creativity in the generation of visual art has had some notable successes in the creation of both abstract art and representational art. The most famous program in this domain is Harold Cohen's AARON, which has been continuously developed and augmented since 1973. Though formulaic, Aaron exhibits a range of outputs, generating black-and-white drawings or colour paintings that incorporate human figures (such as dancers), potted plants, rocks, and other elements of background imagery. These images are of a sufficiently high quality to be displayed in reputable galleries.\n\nOther software artists of note include the NEvAr system (for \"Neuro-Evolutionary Art\") of Penousal Machado. NEvAr uses a genetic algorithm to derive a mathematical function that is then used to generate a coloured three-dimensional surface. A human user is allowed to select the best pictures after each phase of the genetic algorithm, and these preferences are used to guide successive phases, thereby pushing NEvAr's search into pockets of the search space that are considered most appealing to the user.\n\nThe Painting Fool, developed by Simon Colton originated as a system for overpainting digital images of a given scene in a choice of different painting styles, colour palettes and brush types. Given its dependence on an input source image to work with, the earliest iterations of the Painting Fool raised questions about the extent of, or lack of, creativity in a computational art system. Nonetheless, in more recent work, The Painting Fool has been extended to create novel images, much as AARON does, from its own limited imagination. Images in this vein include cityscapes and forests, which are generated by a process of constraint satisfaction from some basic scenarios provided by the user (e.g., these scenarios allow the system to infer that objects closer to the viewing plane should be larger and more color-saturated, while those further away should be less saturated and appear smaller). Artistically, the images now created by the Painting Fool appear on a par with those created by Aaron, though the extensible mechanisms employed by the former (constraint satisfaction, etc.) may well allow it to develop into a more elaborate and sophisticated painter.\n\nThe artist Krasimira Dimtchevska and the software developer Svillen Ranev have created a computational system combining a rule-based generator of English sentences and a visual composition builder that converts sentences generated by the system into abstract art. The software generates automatically indefinite number of different images using different color, shape and size palettes. The software also allows the user to select the subject of the generated sentences or/and the one or more of the palettes used by the visual composition builder.\n\nAn emerging area of computational creativity is that of video games. ANGELINA is a system for creatively developing video games in Java by Michael Cook. One important aspect is Mechanic Miner, a system which can generate short segments of code which act as simple game mechanics. ANGELINA can evaluate these mechanics for usefulness by playing simple unsolvable game levels and testing to see if the new mechanic makes the level solvable. Sometimes Mechanic Miner discovers bugs in the code and exploits these to make new mechanics for the player to solve problems with.\n\nIn July 2015 Google released \"DeepDream\" – an open source computer vision program, created to detect faces and other patterns in images with the aim of automatically classifying images, which uses a convolutional neural network to find and enhance patterns in images via algorithmic pareidolia, thus creating a dreamlike psychedelic appearance in the deliberately over-processed images.\n\nIn August 2015 researchers from Tübingen, Germany created a convolutional neural network that uses neural representations to separate and recombine content and style of arbitrary images which is able to turn images into stylistic imitations of works of art by artists such as a Picasso or Van Gogh in about an hour. Their algorithm is put into use in the website DeepArt that allows users to create unique artistic images by their algorithm.\n\nIn early 2016, a global team of researchers explained how a new computational creativity approach known as the Digital Synaptic Neural Substrate (DSNS) could be used to generate original chess puzzles that were not derived from endgame databases. The DSNS is able to combine features of different objects (e.g. chess problems, paintings, music) using stochastic methods in order to derive new feature specifications which can be used to generate objects in any of the original domains. The generated chess puzzles have also been featured on YouTube.\n\nCreativity is also useful in allowing for unusual solutions in problem solving. In psychology and cognitive science, this research area is called creative problem solving. The Explicit-Implicit Interaction (EII) theory of creativity has recently been implemented using a CLARION-based computational model that allows for the simulation of incubation and insight in problem solving. The emphasis of this computational creativity project is not on performance per se (as in artificial intelligence projects) but rather on the explanation of the psychological processes leading to human creativity and the reproduction of data collected in psychology experiments. So far, this project has been successful in providing an explanation for incubation effects in simple memory experiments, insight in problem solving, and reproducing the overshadowing effect in problem solving.\n\nSome researchers feel that creativity is a complex phenomenon whose study is further complicated by the plasticity of the language we use to describe it. We can describe not just the agent of creativity as \"creative\" but also the product and the method. Consequently, it could be claimed that it is unrealistic to speak of a \"general theory of creativity\". Nonetheless, some generative principles are more general than others, leading some advocates to claim that certain computational approaches are \"general theories\". Stephen Thaler, for instance, proposes that certain modalities of neural networks are generative enough, and general enough, to manifest a high degree of creative capabilities. Likewise, the Formal Theory of Creativity is based on a simple computational principle published by Jürgen Schmidhuber in 1991. The theory postulates that creativity and curiosity and selective attention in general are by-products of a simple algorithmic principle for measuring and optimizing learning progress.\n\nTraditional computers, as mainly used in the computational creativity application, do not support creativity, as they fundamentally transform a set of discrete, limited domain of input parameters into a set of discrete, limited domain of output parameters using a limited set of computational functions . As such, a computer cannot be creative, as everything in the output must have been already present in the input data or the algorithms . For some related discussions and references to related work are captured in some recent work on philosophical foundations of simulation.\n\nMathematically, the same set of arguments against creativity has been made by Chaitin. Similar observations come from a Model Theory perspective. All this criticism emphasizes that computational creativity is useful and may look like creativity, but it is not real creativity, as nothing new is created, just transformed in well defined algorithms.\n\nThe International Conference on Computational Creativity (ICCC) occurs annually, organized by The Association for Computational Creativity. Events in the series include:\n\nPreviously, the community of computational creativity has held a dedicated workshop, the International Joint Workshop on Computational Creativity, every year since 1999. Previous events in this series include:\n\n\nThe 1st Conference on Computer Simulation of Musical Creativity will be held\n\nDesign Computing and Cognition is one conference that addresses computational creativity. The ACM Creativity and Cognition conference is another forum for issues related to computational creativity. Journées d'Informatique Musicale 2016 keynote by Shlomo Dubnov was on Information Theoretic Creativity.\n\nA number of recent books provide either a good introduction or a good overview of the field of Computational Creativity. These include:\n\n\nIn addition to the proceedings of conferences and workshops, the computational creativity community has thus far produced these special journal issues dedicated to the topic:\n\n\nIn addition to these, a new journal has started which focuses on computational creativity within the field of music.\n\n\n\n\n\n"}
{"id": "35694818", "url": "https://en.wikipedia.org/wiki?curid=35694818", "title": "Convenience technologies", "text": "Convenience technologies\n\nConvenience Technologies enable viewers and users of television, Internet, mobile devices, Digital Video Recorders (DVR), Video on Demand (VOD) and Digital Versatile Disc (DVD) to more easily seek out specific content and view it in individualized patterns. These technologies increase viewers’ ability to choose when they want to watch a program with the use of DVR, VOD and DVD, and where to watch a program with the use of DVD, iPOD, TiVo ToGo and mobile phones. These technological enhancers provide the most comprehensive and varied adjustments in the technological potential of the medium (Amanda D. Lotz, 2007, p. 59).\n\nConvenience Technologies encourage active selection instead of generally watching what “comes on next” or “is on”. Because of this, consequently, viewers focused more on programs they wanted to watch than on the networks that supplied them (Lotz, 2007, p. 59)\n\nThe main problem for networks is that the DVR using audience appears, by basically every measure that’s vital to advertisers, more wanted than the non-DVR crowds. According to a Horizon Media Study, early adopters of technology are usually above the national average in income, in a “well-off” set. They are typically college graduates and white-collar workers (Lowry, 2010).\n"}
{"id": "29466332", "url": "https://en.wikipedia.org/wiki?curid=29466332", "title": "Conversion narrative", "text": "Conversion narrative\n\nBroadly speaking, a conversion narrative is a narrative that relates the operation of conversion, usually religious. As a specific aspect of American literary and religious history, the conversion narrative was an important facet of Puritan sacred and secular society in New England during a period stretching roughly from 1630 to the end of the First Great Awakening.\n\nAs defined by Patricia Caldwell, the conversion narrative was \"a testimony of personal religious experience…spoken or read aloud to the entire congregation of a gathered church before admission as evidence of the applicant's visible sainthood\" Edmund S. Morgan describes the typical \"morphology of conversion\" related in the conversion narrative as involving the stages of \"knowledge, conviction, faith, combat, and true, imperfect assurance.\"\n\nThe conversion narrative was one of the distinguishing features of the Massachusetts Puritan churches; the relation of a conversion narrative emphasized their belief in \"faith as the essence of the church: and they were to ensure the presence of faith in their members by a screening process that included narratives of religious experiences.\" In adopting this requirement for membership, Bremer argues that the New England churches were extending the beliefs of their English brethren that \"admission to the communion table should be limited to those with saving faith.\" As Morgan goes on to point out, the adaptation of the conversion narrative as a requirement for church membership \"was as important politically as religiously, for it altered not only the character of church membership but the character of freemanship.\" Freemanship was restricted to church members and with the adaptation of this requirement for church membership, given the force of law with an act by the General Court in 1636, \"the new system of church membership may be said to have reached full definition, legal establishment, and coordination with the civil government in Massachusetts\"\n\nA key figure in the development and adaptation of the conversion narrative to the New England Puritan churches was John Cotton.\n\n"}
{"id": "847462", "url": "https://en.wikipedia.org/wiki?curid=847462", "title": "Critical applied linguistics", "text": "Critical applied linguistics\n\nCritical applied linguistics (CALx) is an interdisciplinary critical approach to English applied linguistics. One of the central concerns in this approach is exposing the political dimensions and power relations involved in mainstream applied linguistics, in areas like language teaching, language policy and planning, language testing, language rights, and so on. \n"}
{"id": "2363629", "url": "https://en.wikipedia.org/wiki?curid=2363629", "title": "Critical medical anthropology", "text": "Critical medical anthropology\n\nCritical medical anthropology (CMA) is a branch of medical anthropology that blends critical theory and ground-level ethnographic approaches in the consideration of the political economy of health, and the effect of social inequality on people's health. It puts emphasis on the structure of social relationships, rather than purely biomedical factors in analyzing health and accounting for its determinants.\n\nCMA starts with the idea that human health is a biosocial and political ecological product. Consequently, CMA is critical of the tendency to naturalize the process of health and illness in the health and social sciences. CMA dates to the 1980s, but has deeper roots in critical theory concerning the social determinants of health. CMA adds an anthropological dimension to traditional critical approaches, thereby avoiding a top-down perspective. In other words, CMA recognizes that there is interaction between the macro-level of social structure, the meso-level of social organization and agentive action, and the micro-level of individual experience and health.\n\nDuring the early years of medical anthropology’s formation, explanations within the discipline tended to be narrowly focused on explaining health-related beliefs and behaviors at the local level in terms of specific ecological conditions, cultural configurations, or psychological factors. While providing needed insight about the nature and function of traditional and folk medical models, the initial perspectives in medical anthropology tended to ignore the wider causes and determinants of human decision making and behavior. Explanations that are limited to accounting for health-related issues in terms of the influence of human personalities, culturally constituted motivations and understandings, or even local ecological relationships, emergent critical medical anthropologists began to argue, are inadequate because they tend not to include examination of the structures of social relationship that unite (commonly in an unequal fashion) and influence far-flung individuals, communities, and even whole nations. A critical understanding, by contrast, involves paying close attention to what has been called the “vertical links” that connect the social group of interest to the larger regional, national, and global human society and to the configuration of social relationships that contribute to the patterning of human behavior, belief, attitude, and emotion.\n\nConsequently, what came to be called critical medical anthropology focused attention on understanding the origins of dominant cultural constructions in health, including which social class, gender, or ethnic group’s interests particular health concepts express and under what set of historic conditions they arise. Further, CMA emphasizes structures of power and inequality in health care systems and the contributions of health ideas and practices in reinforcing inequalities in the wider society. Moreover, CMA addresses the social origins of illness, such as the way in which poverty, discrimination, industrial pollution of the environment, social violence, and fear of violence contribute to poor health. Critical medical anthropologists argue that experience and “agency,” that is, individual and group decision making and action, are constructed and reconstructed in the action arena between socially constituted categories of meaning and the political-economic forces that shape the context [and texture] of daily life. In other words, people develop their own individual and collective understandings and responses to illness and to other threats to their well-being, but they do so in a world that is not of their own making, a world in which inequality of access to health care, the media, productive resources (e.g., land, potable water, clean air), and valued social statuses play a significant role in their daily options. \n\nAdditionally, while recognizing the fundamental importance of physical (including biological) reality in health, such as the nature of particular pathogens or the release of toxins into the environment, CMA emphasizes the fact that it is not merely the idea of “nature”—the way external reality is conceived and related to by humans—but also the very physical shape of nature, including human biology, that has been deeply influenced by an evolutionary history of social inequality, overt and covert social conflict, and the operation of both physical power and the power to shape dominant ideas and conceptions in society and internationally through processes of globalization, control of production and reproduction, and control of labor. \n\n"}
{"id": "394976", "url": "https://en.wikipedia.org/wiki?curid=394976", "title": "Culture shock", "text": "Culture shock\n\nCulture shock is an experience a person may have when one moves to a cultural environment which is different from one's own; it is also the personal disorientation a person may feel when experiencing an unfamiliar way of life due to immigration or a visit to a new country, a move between social environments, or simply transition to another type of life. One of the most common causes of culture shock involves individuals in a foreign environment. Culture shock can be described as consisting of at least one of four distinct phases: honeymoon, negotiation, adjustment, and adaptation. \n\nCommon problems include: information overload, language barrier, generation gap, technology gap, skill interdependence, formulation dependency, homesickness (cultural), boredom (job dependency), response ability (cultural skill set). There is no true way to entirely prevent culture shock, as individuals in any society are personally affected by cultural contrasts differently.\n\nDuring this period, the differences between the old and new culture are seen in a romantic light. For example, in moving to a new country, an individual might love the new food, the pace of life, and the locals' habits. During the first few weeks, most people are fascinated by the new culture. They associate with nationals who speak their language, and who are polite to the foreigners. Like most honeymoon periods, this stage eventually ends.\n\nAfter some time (usually around three months, depending on the individual), differences between the old and new culture become apparent and may create anxiety. Excitement may eventually give way to unpleasant feelings of frustration and anger as one continues to experience unfavorable events that may be perceived as strange and offensive to one's cultural attitude. Language barriers, stark differences in public hygiene, traffic safety, food accessibility and quality may heighten the sense of disconnection from the surroundings.\n\nWhile being transferred into a different environment puts special pressure on communication skills, there are practical difficulties to overcome, such as circadian rhythm disruption that often leads to insomnia and daylight drowsiness; adaptation of gut flora to different bacteria levels and concentrations in food and water; difficulty in seeking treatment for illness, as medicines may have different names from the native country's and the same active ingredients might be hard to recognize.\n\nStill, the most important change in the period is communication: People adjusting to a new culture often feel lonely and homesick because they are not yet used to the new environment and meet people with whom they are not familiar every day. The language barrier may become a major obstacle in creating new relationships: special attention must be paid to one's and others' culture-specific body language signs, linguistic faux pas, conversation tone, linguistic nuances and customs, and false friends. \n\nIn the case of students studying abroad, some develop additional symptoms of loneliness that ultimately affect their lifestyles as a whole. Due to the strain of living in a different country without parental support, international students often feel anxious and feel more pressure while adjusting to new cultures—even more so when the cultural distances are wide, as patterns of logic and speech are different and a special emphasis is put on rhetoric.\n\nAgain, after some time (usually 6 to 12 months), one grows accustomed to the new culture and develops routines. One knows what to expect in most situations and the host country no longer feels all that new. One becomes concerned with basic living again, and things become more \"normal\". One starts to develop problem-solving skills for dealing with the culture and begins to accept the culture's ways with a positive attitude. The culture begins to make sense, and negative reactions and responses to the culture are reduced.\n\nIn the mastery stage individuals are able to participate fully and comfortably in the host culture. Mastery does not mean total conversion; people often keep many traits from their earlier culture, such as accents and languages. It is often referred to as the bicultural stage.\n\nReverse culture shock (also known as \"re-entry shock\" or \"own culture shock\") may take place—returning to one's home culture after growing accustomed to a new one can produce the same effects as described above. These are results from the psychosomatic and psychological consequences of the readjustment process to the primary culture. The affected person often finds this more surprising and difficult to deal with than the original culture shock. This phenomenon, the reactions that members of the re-entered culture exhibit toward the re-entrant, and the inevitability of the two are encapsulated in the following saying, which is also the title of a book by Thomas Wolfe, \"You Can't Go Home Again\".\n\nReverse culture shock is generally made up of two parts: idealization and expectations. When an extended period of time is spent abroad we focus on the good from our past, cut out the bad, and create an idealized version of the past. Secondly, once removed from our familiar setting and placed in a foreign one we incorrectly assume that our previous world has not changed. We expect things to remain exactly the same as when we left them. The realization that life back home is now different, that the world has continued without us, and the process of readjusting to these new conditions as well as actualizing our new perceptions about the world with our old way of living causes discomfort and psychological anguish. \n\nThere are three basic outcomes of the Adjustment Phase:\n\nCulture shock has many different effects, time spans, and degrees of severity. Many people are handicapped by its presence and do not recognize what is bothering them.\n\nCulture shock is a subcategory of a more universal construct called transition shock. Transition shock is a state of loss and disorientation predicated by a change in one's familiar environment that requires adjustment. There are many symptoms of transition shock, including:\n\n"}
{"id": "52813", "url": "https://en.wikipedia.org/wiki?curid=52813", "title": "Dialectic", "text": "Dialectic\n\nDialectic or dialectics (, \"dialektikḗ\"; related to dialogue), also known as the dialectical method, is at base a discourse between two or more people holding different points of view about a subject but wishing to establish the truth through reasoned arguments. Dialectic resembles debate, but the concept excludes subjective elements such as emotional appeal and the modern pejorative sense of rhetoric. Dialectic may be contrasted with the didactic method, wherein one side of the conversation teaches the other. Dialectic is alternatively known as minor logic, as opposed to major logic or critique.\n\nWithin Hegelianism, the word \"dialectic\" has the specialised meaning of a contradiction between ideas that serves as the determining factor in their relationship. Dialectic comprises three stages of development: first, a thesis or statement of an idea, which gives rise to a second step, a reaction or antithesis that contradicts or negates the thesis, and third, the synthesis, a statement through which the differences between the two points is resolved. Dialectical materialism, a theory or set of theories produced mainly by Karl Marx and Friedrich Engels, adapted the Hegelian dialectic into arguments regarding traditional materialism.\n\nDialectic tends to imply a \"process\" of evolution and so does not naturally fit within formal logic (see logic and dialectic). This process is particularly marked in Hegelian dialectic and even more so in Marxist dialectic which may rely on the evolution of ideas over longer time periods in the real world; dialectical logic attempts to address this.\n\nIn classical philosophy, dialectic () is a form of reasoning based upon dialogue of arguments and counter-arguments, advocating \"propositions\" (theses) and \"counter-propositions\" (antitheses). The outcome of such a dialectic might be the refutation of a relevant proposition, or of a synthesis, or a combination of the opposing assertions, or a qualitative improvement of the dialogue.\n\nMoreover, the term \"dialectic\" owes much of its prestige to its role in the philosophies of Socrates and Plato, in the Greek Classical period (5th to 4th centuries BCE). Aristotle said that it was the pre-Socratic philosopher Zeno of Elea who invented dialectic, of which the dialogues of Plato are the examples of the Socratic dialectical method.\n\nAccording to Kant, however, the ancient Greeks used the word \"dialectic\" to signify the logic of false appearance or semblance. To the Ancients, \"it was nothing but the logic of illusion. It was a sophistic art of giving to one's ignorance, indeed even to one's intentional tricks, the outward appearance of truth, by imitating the thorough, accurate method which logic always requires, and by using its topic as a cloak for every empty assertion.\"\n\nThe Socratic dialogues are a particular form of dialectic known as the method of elenchus (literally, \"refutation, scrutiny\") whereby a series of questions clarifies a more precise statement of a vague belief, logical consequences of that statement are explored, and a contradiction is discovered. The method is largely destructive, in that false belief is exposed and only constructive in that this exposure may lead to further search for truth. The detection of error does not amount to a proof of the antithesis; for example, a contradiction in the consequences of a definition of \"piety\" does not provide a correct definition. The principal aim of Socratic activity may be to improve the soul of the interlocutors, by freeing them from unrecognized errors; or indeed, by teaching them the spirit of inquiry.\n\nIn common cases, Socrates used enthymemes as the foundation of his argument.\n\nFor example, in the \"Euthyphro\", Socrates asks Euthyphro to provide a definition of piety. Euthyphro replies that the pious is that which is loved by the gods. But, Socrates also has Euthyphro agreeing that the gods are quarrelsome and their quarrels, like human quarrels, concern objects of love or hatred. Therefore, Socrates reasons, at least one thing exists that certain gods love but other gods hate. Again, Euthyphro agrees. Socrates concludes that if Euthyphro's definition of piety is acceptable, then there must exist at least one thing that is both pious and impious (as it is both loved and hated by the gods)—which Euthyphro admits is absurd. Thus, Euthyphro is brought to a realization by this dialectical method that his definition of piety is not sufficiently meaningful.\n\nFor example, in Plato's Gorgias, dialectic occurs between Socrates, the Sophist Gorgias, and two men, Polus and Callicles. Because Socrates' ultimate goal was to reach true knowledge, he was even willing to change his own views in order to arrive at the truth. The fundamental goal of dialectic, in this instance, was to establish a precise definition of the subject (in this case, rhetoric) and with the use of argumentation and questioning, make the subject even more precise. In the Gorgias, Socrates reaches the truth by asking a series of questions and in return, receiving short, clear answers.\nThere is another interpretation of the dialectic, as a method of intuition suggested in The Republic. Simon Blackburn writes that the dialectic in this sense is used to understand \"the total process of enlightenment, whereby the philosopher is educated so as to achieve knowledge of the supreme good, the Form of the Good\".\n\nAristotle stresses that rhetoric is closely related to dialectic. He offers several formulas to describe this affinity between the two disciplines: first of all, rhetoric is said to be a “counterpart” (antistrophos) to dialectic (Rhet. I.1, 1354a1); (ii) it is also called an “outgrowth” (paraphues ti) of dialectic and the study of character (Rhet. I.2, 1356a25f.); finally, Aristotle says that rhetoric is part of dialectic and resembles it (Rhet. I.2, 1356a30f.). In saying that rhetoric is a counterpart to dialectic, Aristotle obviously alludes to Plato's Gorgias (464bff.), where rhetoric is ironically defined as a counterpart to cookery in the soul. Since, in this passage, Plato uses the word ‘antistrophos’ to designate an analogy, it is likely that Aristotle wants to express a kind of analogy too: what dialectic is for the (private or academic) practice of attacking and maintaining an argument, rhetoric is for the (public) practice of defending oneself or accusing an opponent. The analogy to dialectic has important implications for the status of rhetoric. Plato argued in his Gorgias that rhetoric cannot be an art (technê), since it is not related to a definite subject, while real arts are defined by their specific subjects, as e.g. medicine or shoemaking are defined by their products, i.e., health and shoes.\n\nLogic, which could be considered to include dialectic, was one of the three liberal arts taught in medieval universities as part of the trivium; the other elements were rhetoric and grammar.\n\nBased mainly on Aristotle, the first medieval philosopher to work on dialectics was Boethius (480–524). After him, many scholastic philosophers also made use of dialectics in their works, such as Abelard, William of Sherwood, Garlandus Compotista, Walter Burley, Roger Swyneshed, William of Ockham, and Thomas Aquinas.\n\nThis dialectic (a \"quaestio disputata\") was formed as follows:\n\nThe concept of dialectics was given new life by Georg Wilhelm Friedrich Hegel (following Johann Gottlieb Fichte), whose dialectically synthetic model of nature and of history made it, as it were, a fundamental aspect of the nature of reality (instead of regarding the contradictions into which dialectics leads as a sign of the sterility of the dialectical method, as Immanuel Kant tended to do in his \"Critique of Pure Reason\"). In the mid-19th century, the concept of \"dialectic\" was appropriated by Karl Marx (see, for example, \"Das Kapital\", published in 1867) and Friedrich Engels and retooled in a dynamic, nonidealistic manner. It would also become a crucial part of later representations of Marxism as a philosophy of dialectical materialism. These representations often contrasted dramatically and led to vigorous debate among different Marxist groupings, leading some prominent Marxists to give up on the idea of dialectics completely.\n\nHegelian dialectic, usually presented in a threefold manner, was stated by Heinrich Moritz Chalybäus as comprising three dialectical stages of development: a thesis, giving rise to its reaction; an antithesis, which contradicts or negates the thesis; and the tension between the two being resolved by means of a synthesis. In more simplistic terms, one can consider it thus: problem → reaction → solution. Although this model is often named after Hegel, he himself never used that specific formulation. Hegel ascribed that terminology to Kant. Carrying on Kant's work, Fichte greatly elaborated on the synthesis model and popularized it.\n\nOn the other hand, Hegel did use a three-valued logical model that is very similar to the antithesis model, but Hegel's most usual terms were: Abstract-Negative-Concrete. Hegel used this writing model as a backbone to accompany his points in many of his works.\n\nThe formula, thesis-antithesis-synthesis, does not explain why the thesis requires an antithesis. However, the formula, abstract-negative-concrete, suggests a flaw, or perhaps an incompleteness, in any initial thesis—it is too abstract and lacks the negative of trial, error, and experience. For Hegel, the concrete, the synthesis, the absolute, must always pass through the phase of the negative, in the journey to completion, that is, mediation. This is the essence of what is popularly called Hegelian dialectics.\n\nAccording to the German philosopher Walter Kaufmann: Fichte introduced into German philosophy the three-step of thesis, antithesis, and synthesis, using these three terms. Schelling took up this terminology. \"Hegel did not.\" He never once used these three terms together to designate three stages in an argument or account in any of his books. And they do not help us understand his \"Phenomenology\", his \"Logic\", or his philosophy of history; they impede any open-minded comprehension of what he does by forcing it into a scheme which was available to him and which he deliberately spurned [...] The mechanical formalism [...] Hegel derides expressly and at some length in the preface to the \"Phenomenology\".\n\nKaufmann also cites Hegel's criticism of the triad model commonly misattributed to him, adding that \"the only place where Hegel uses the three terms together occurs in his lectures on the history of philosophy, on the last page but one of the section on Kant—where Hegel roundly reproaches Kant for having 'everywhere posited thesis, antithesis, synthesis'\".\n\nTo describe the activity of overcoming the negative, Hegel also often used the term \"Aufhebung\", variously translated into English as \"sublation\" or \"overcoming,\" to conceive of the working of the dialectic. Roughly, the term indicates preserving the useful portion of an idea, thing, society, etc., while moving beyond its limitations. (Jacques Derrida's preferred French translation of the term was \"relever\".)\n\nIn the \"Logic\", for instance, Hegel describes a dialectic of existence: first, existence must be posited as pure Being (\"Sein\"); but pure Being, upon examination, is found to be indistinguishable from Nothing (\"Nichts\"). When it is realized that what is coming into being is, at the same time, also returning to nothing (in life, for example, one's living is also a dying), both Being and Nothing are united as Becoming.\n\nAs in the Socratic dialectic, Hegel claimed to proceed by making implicit contradictions explicit: each stage of the process is the product of contradictions inherent or implicit in the preceding stage. For Hegel, the whole of history is one tremendous dialectic, major stages of which chart a progression from self-alienation as slavery to self-unification and realization as the rational constitutional state of free and equal citizens. The Hegelian dialectic cannot be mechanically applied for any chosen thesis. Critics argue that the selection of any antithesis, other than the logical negation of the thesis, is subjective. Then, if the logical negation is used as the antithesis, there is no rigorous way to derive a synthesis. In practice, when an antithesis is selected to suit the user's subjective purpose, the resulting \"contradictions\" are rhetorical, not logical, and the resulting synthesis is not rigorously defensible against a multitude of other possible syntheses. The problem with the Fichtean \"thesis–antithesis–synthesis\" model is that it implies that contradictions or negations come from outside of things. Hegel's point is that they are inherent in and internal to things. This conception of dialectics derives ultimately from Heraclitus.\n\nHegel stated that the purpose of dialectics is \"to study things in their own being and movement and thus to demonstrate the finitude of the partial categories of understanding.\"\n\nOne important dialectical principle for Hegel is the transition from quantity to quality, which he terms the Measure. The measure is the qualitative quantum, the quantum is the existence of quantity. \n\nAs an example, Hegel mentions the states of aggregation of water: \"Thus the temperature of water is, in the first place, a point of no consequence in respect of its liquidity: still with the increase or diminution of the temperature of the liquid water, there comes a point where this state of cohesion suffers a qualitative change, and the water is converted into steam or ice\". As other examples Hegel mentions the reaching of a point where a single additional grain makes a heap of wheat; or where the bald tail is produced, if we continue plucking out single hairs.\n\nAnother important principle for Hegel is the negation of the negation, which he also terms \"Aufhebung\" (sublation): Something is only what it is in its relation to another, but by the negation of the negation this something incorporates the other into itself. The dialectical movement involves two moments that negate each other, something and its other. As a result of the negation of the negation, \"something becomes its other; this other is itself something; therefore it likewise becomes an other, and so on ad infinitum\". Something in its passage into other only joins with itself, it is self-related. In becoming there are two moments: coming-to-be and ceasing-to-be: by sublation, i.e., negation of the negation, being passes over into nothing, it ceases to be, but something new shows up, is coming to be. What is sublated (\"aufgehoben\") on the one hand ceases to be and is put to an end, but on the other hand it is preserved and maintained. In dialectics, a totality transforms itself; it is self-related, then self-forgetful, relieving the original tension.\n\nMarxist dialectic is a form of Hegelian dialectic which applies to the study of historical materialism. It purports to be a reflection of the real world created by man. Dialectic would thus be a robust method under which one could examine personal, social, and economic behaviors. Marxist dialectic is the core foundation of the philosophy of dialectical materialism, which forms the basis of the ideas behind historical materialism.\n\nKarl Marx and Friedrich Engels proposed that Hegel's dialectic is too abstract: \n\nIn contradiction to Hegelian idealism, Marx presented his own dialectic method, which he claims to be \"direct opposite\" of Hegel's method: \n\nIn Marxism, the dialectical method of historical study became intertwined with historical materialism, the school of thought exemplified by the works of Marx, Engels, and Vladimir Lenin. In the USSR, under Joseph Stalin, Marxist dialectics became \"diamat\" (short for dialectical materialism), a theory emphasizing the primacy of the material way of life; social \"praxis\" over all forms of social consciousness; and the secondary, dependent character of the \"ideal\". The term \"dialectical materialism\" was coined by the 19th-century social theorist Joseph Dietzgen who used the theory to explain the nature of socialism and social development. The original populariser of Marxism in Russia, Georgi Plekhanov used the terms \"dialectical materialism\" and \"historical materialism\" interchangeably. For Lenin, the primary feature of Marx's \"dialectical materialism\" (Lenin's term) was its application of materialist philosophy to history and social sciences. Lenin's main input in the philosophy of dialectical materialism was his theory of reflection, which presented human consciousness as a dynamic reflection of the objective material world that fully shapes its contents and structure. Later, Stalin's works on the subject established a rigid and formalistic division of Marxist–Leninist theory in the dialectical materialism and historical materialism parts. While the first was supposed to be the key method and theory of the philosophy of nature, the second was the Soviet version of the philosophy of history.\n\nA dialectical method was fundamental to Marxist politics, e.g., the works of Karl Korsch, Georg Lukács and certain members of the Frankfurt School. Soviet academics, notably Evald Ilyenkov and Zaid Orudzhev, continued pursuing unorthodox philosophic study of Marxist dialectics; likewise in the West, notably the philosopher Bertell Ollman at New York University.\n\nFriedrich Engels proposed that Nature is dialectical, thus, in Anti-Dühring he said that the negation of negation is: \n\nIn \"Dialectics of Nature\", Engels said: \n\nMarxist dialectics is exemplified in \"Das Kapital\" (Capital), which outlines two central theories: (i) surplus value and (ii) the materialist conception of history; Marx explains dialectical materialism: \n\nClass struggle is the primary contradiction to be resolved by Marxist dialectics, because of its central role in the social and political lives of a society. Nonetheless, Marx and Marxists developed the concept of class struggle to comprehend the dialectical contradictions between mental and manual labor, and between town and country. Hence, philosophic contradiction is central to the development of dialectics the progress from quantity to quality, the acceleration of gradual social change; the negation of the initial development of the \"status quo\"; the negation of that negation; and the high-level recurrence of features of the original \"status quo\". In the USSR, Progress Publishers issued anthologies of dialectical materialism by Lenin, wherein he also quotes Marx and Engels: \n\nLenin describes his dialectical understanding of the concept of \"development\": \n\nDialectical naturalism is a term coined by American philosopher Murray Bookchin to describe the philosophical underpinnings of the political program of social ecology. Dialectical naturalism explores the complex interrelationship between social problems, and the direct consequences they have on the ecological impact of human society. Bookchin offered dialectical naturalism as a contrast to what he saw as the \"empyrean, basically antinaturalistic dialectical idealism\" of Hegel, and \"the wooden, often scientistic dialectical materialism of orthodox Marxists\".\n\nNeo-orthodoxy, in Europe also known as theology of crisis and dialectical theology, is an approach to theology in Protestantism that was developed in the aftermath of the First World War (1914–1918). It is characterized as a reaction against doctrines of 19th-century liberal theology and a more positive reevaluation of the teachings of the Reformation, much of which had been in decline (especially in western Europe) since the late 18th century. It is primarily associated with two Swiss professors and pastors, Karl Barth (1886–1968) and Emil Brunner (1899–1966), even though Barth himself expressed his unease in the use of the term.\n\nIn dialectical theology the difference and opposition between God and human beings is stressed in such a way that all human attempts at overcoming this opposition through moral, religious or philosophical idealism must be characterized as 'sin'. In the death of Christ humanity is negated and overcome, but this judgment also points forwards to the resurrection in which humanity is reestablished in Christ. For Barth this meant that only through God's 'no' to everything human can his 'yes' be perceived. Applied to traditional themes of Protestant theology, such as double predestination, this means that election and reprobation cannot be viewed as a quantitative limitation of God's action. Rather it must be seen as its \"qualitative definition\". As Christ bore the rejection as well as the election of God for all humanity, every person is subject to both aspects of God's double predestination.\n\nDialectics has become central to continental philosophy, but it plays no part in Anglo-American philosophy. In other words, on the continent of Europe, dialectics has entered intellectual culture as what might be called a legitimate part of thought and philosophy, whereas in America and Britain, the dialectic plays no discernible part in the intellectual culture, which instead tends toward positivism. A prime example of the European tradition is Jean-Paul Sartre's \"Critique of Dialectical Reason\", which is very different from the works of Popper, whose philosophy was for a time highly influential in the UK where he resided (see below). Sartre states:\n\nKarl Popper has attacked the dialectic repeatedly. In 1937, he wrote and delivered a paper entitled \"What Is Dialectic?\" in which he attacked the dialectical method for its willingness \"to put up with contradictions\". Popper concluded the essay with these words: \"The whole development of dialectic should be a warning against the dangers inherent in philosophical system-building. It should remind us that philosophy should not be made a basis for any sort of scientific system and that philosophers should be much more modest in their claims. One task which they can fulfill quite usefully is the study of the critical methods of science\" (Ibid., p. 335).\n\nIn chapter 12 of volume 2 of \"The Open Society and Its Enemies\" (1944; 5th rev. ed., 1966), Popper unleashed a famous attack on Hegelian dialectics in which he held that Hegel's thought (unjustly in the view of some philosophers, such as Walter Kaufmann) was to some degree responsible for facilitating the rise of fascism in Europe by encouraging and justifying irrationalism. In section 17 of his 1961 \"addenda\" to \"The Open Society\", entitled \"Facts, Standards and Truth: A Further Criticism of Relativism\", Popper refused to moderate his criticism of the Hegelian dialectic, arguing that it \"played a major role in the downfall of the liberal movement in Germany [...] by contributing to historicism and to an identification of might and right, encouraged totalitarian modes of thought. [...] [And] undermined and eventually lowered the traditional standards of intellectual responsibility and honesty\".\n\nThe philosopher of science and physicist Mario Bunge repeatedly criticized Hegelian and Marxian dialectics, calling them \"fuzzy and remote from science\" and a \"disastrous legacy\". He concluded: \"The so-called laws of dialectics, such as formulated by Engels (1940, 1954) and Lenin (1947, 1981), are false insofar as they are intelligible.\"\n\nIn the past few decades, European and American logicians have attempted to provide mathematical foundations for dialectical logic or argument. There had been pre-formal and partially-formal treatises on argument and dialectic, from authors such as Stephen Toulmin (\"The Uses of Argument\"), Nicholas Rescher (\"Dialectics\"), and van Eemeren and Grootendorst (pragma-dialectics). One can include the communities of informal logic and paraconsistent logic. However, building on theories of defeasible reasoning (see John L. Pollock), systems have been built that define well-formedness of arguments, rules governing the process of introducing arguments based on fixed assumptions, and rules for shifting burden. Many of these logics appear in the special area of artificial intelligence and law, though the computer scientists' interest in formalizing dialectic originates in a desire to build decision support and computer-supported collaborative work systems.\n\n\n\n"}
{"id": "8603776", "url": "https://en.wikipedia.org/wiki?curid=8603776", "title": "Digital Classicist", "text": "Digital Classicist\n\nThe Digital Classicist is a community of those interested in the application of Digital Humanities to the field of Classics and to ancient world studies more generally. The project claims the twin aims of bringing together scholars and students with an interest in computing and the ancient world, and disseminating advice and experience to the Classics discipline at large. The Digital Classicist was founded in 2005 as a collaborative project based at King's College London and the University of Kentucky, with editors and advisors from the Classics discipline at large.\n\nMany notable Classicists and Digital Humanists are on the advisory board of the Digital Classicist, including Richard Beacham (of the King's Visualisation Lab), Alan Bowman (Professor of Ancient History at University of Oxford), Gregory Crane (of the Perseus Project), Bernard Frischer (of the Virtual World Heritage Laboratory), Michael Fulford (Professor of Archaeology and Pro-Vice-Chancellor at University of Reading), Willard McCarty (winner of the Lyman Award and Professor of Humanities Computing at Department of Digital Humanities), James O'Donnell (Provost of Georgetown University), Silvio Panciera (of University of Rome La Sapienza) and Boris Rankov (Professor of Ancient History at Royal Holloway, University of London). A former member was the late Ross Scaife (Stoa Consortium and University of Kentucky).\n\nThe Digital Classicist community have taken an active role in posting news to the long-standing blog of the Stoa Consortium, which concerns itself with both Classical and Digital Humanities topics. A particular focus seems to be the Open Source and Creative Commons movements, and various communities of scholars with digital interests.\n\nThe Digital Classicist discussion list is hosted by JISCmail in the UK. Most list traffic consists of announcements and calls, with occasional flurries of more involved discussion.\n\nThe main website of the Digital Classicist is a gateway containing links to the Digital Classicist Wiki and other resources, including listings for seminars and conference panels. The seminar programmes include: abstract, slides (in pdf), audio (in mp3) and, from 2013, video recordings.\n\nThe project Wiki contains lists of digital Classics projects, software tools that have been made available for classicists, and a FAQ that solicits collaborative community advice on a range of topics from simple questions about, e.g., Greek fonts and Unicode, word-processing and printing issues, to more advanced Humanities Computing questions and project management advice. The Wiki is hosted on the servers of the Centre for Computing in the Humanities at King's College London\n\nThe members of the Digital Classicist community also report quite heavily on any conference and seminar activity that they take to reflect well on the project as a whole. Among the events cited are a series of summer seminars which have run each year since 2006 at the Institute of Classical Studies in London, and panels at the Classical Association Annual Conference in Birmingham 2007 Glasgow 2009, and Durham 2011 and the Digital Resources in the Humanities and Arts conference in September 2008. The Project was also among the sponsors of the Open Source Critical Editions workshop in 2006. In 2008 the Digital Medievalist published a collaborative issue of Digital Classicist articles in memory of Ross Scaife. A collection of papers from the 2007 seminar series and conference panels have been published by Ashgate: \"Digital Research in the Study of Classical Antiquity\" (Bodard and Mahony (eds) 2010). More recent papers have been collected together in a \"Bulletin of the Institute of Classical Studies\": Mahony and Dunn (eds) 2013\"The Digital Classicist 2013\" (2013) London BICS Supplement-122 Institute of Classical Studies.\n\n\n"}
{"id": "31260737", "url": "https://en.wikipedia.org/wiki?curid=31260737", "title": "Digital Humanities Quarterly", "text": "Digital Humanities Quarterly\n\nDigital Humanities Quarterly is a peer-reviewed open-access academic journal covering all aspects of digital media in the humanities. The journal is also a community experiment in journal publication.\n\nThe journal is funded and published by the Alliance of Digital Humanities Organizations and its editor-in-chief is Julia Flanders.\n\n\"Digital Humanities Quarterly\" has been noted among the \"few interesting attempts to peer review born-digital scholarship.\" Having emerged from a desire to disseminate digital humanities practices to the wider arts and humanities community and beyond, the journal is committed to open access and open standards to deliver journal content, publishing under a Creative Commons license. It develops translation services and multilingual reviews in keeping with the international character of the Alliance of Digital Humanities Organizations.\n\nThe journal aims to heighten the visibility and acceptance of digital humanities with reviews that are modeled on traditional book reviews but focus on digital projects, providing assessments of \"software tools, sites, other kinds of innovations that need the same kind of critical scrutiny and benefit from the same kind of contextualizing review that a traditional book review offers.\"\n"}
{"id": "2943406", "url": "https://en.wikipedia.org/wiki?curid=2943406", "title": "Ecocriticism", "text": "Ecocriticism\n\nEcocriticism is the study of literature and the environment from an interdisciplinary point of view, where literature scholars analyze texts that illustrate environmental concerns and examine the various ways literature treats the subject of nature. Some ecocritics brainstorm possible solutions for the correction of the contemporary environmental situation, though not all ecocritics agree on the purpose, methodology, or scope of ecocriticism. \nIn the United States, ecocriticism is often associated with the Association for the Study of Literature and Environment (ASLE), which hosts biennial meetings for scholars who deal with environmental matters in literature. ASLE publishes a journal—\"Interdisciplinary Studies in Literature and Environment\" (\"ISLE\")—in which current international scholarship can be found.\n\nEcocriticism is an intentionally broad approach that is known by a number of other designations, including \"green (cultural) studies\", \"ecopoetics\", and \"environmental literary criticism\" and is often informed by other fields such as ecology, sustainable design, biopolitics, environmental history, environmentalism, and social ecology, among others.\n\nIn comparison with other 'political' forms of criticism, there has been relatively little dispute about the moral and philosophical aims of ecocriticism, although its scope has broadened rapidly from nature writing, romantic poetry, and canonical literature to take in film, television, theatre, animal stories, architectures, scientific narratives and an extraordinary range of literary texts. At the same time, ecocriticism has borrowed methodologies and theoretically informed approaches liberally from other fields of literary, social and scientific study.\n\nCheryll Glotfelty's working definition in \"The Ecocriticism Reader\" is that \"ecocriticism is the study of the relationship between literature and the physical environment\", and one of the implicit goals of the approach is to recoup professional dignity for what Glotfelty calls the \"undervalued genre of nature writing\". Lawrence Buell defines \"'ecocriticism' ... as [a] study of the relationship between literature and the environment conducted in a spirit of commitment to environmentalist praxis\".\n\nSimon Estok noted in 2001 that \"ecocriticism has distinguished itself, debates notwithstanding, firstly by the ethical stand it takes, its commitment to the natural world as an important thing rather than simply as an object of thematic study, and, secondly, by its commitment to making connections\".\n\nMore recently, in an article that extends ecocriticism to Shakespearean studies, Estok argues that ecocriticism is more than \"simply the study of Nature or natural things in literature; rather, it is any theory that is committed to effecting change by analyzing the function–thematic, artistic, social, historical, ideological, theoretical, or otherwise–of the natural environment, or aspects of it, represented in documents (literary or other) that contribute to material practices in material worlds\". This echoes the functional approach of the cultural ecology branch of ecocriticism, which analyzes the analogies between ecosystems and imaginative texts and posits that such texts potentially have an ecological (regenerative, revitalizing) function in the cultural system.\n\nAs Michael P. Cohen has observed, \"if you want to be an ecocritic, be prepared to explain what you do and be criticized, if not satirized.\" Certainly, Cohen adds his voice to such critique, noting that one of the problems of ecocriticism has been what he calls its \"praise-song school\" of criticism. All ecocritics share an environmentalist motivation of some sort, but whereas the majority are 'nature endorsing', some are 'nature sceptical'. In part this entails a shared sense of the ways in which 'nature' has been used to legitimise gender, sexual and racial norms (so homosexuality has been seen as 'unnatural', for example), but it also involves scepticism about the uses to which 'ecological' language is put in ecocriticism; it can also involve a critique of the ways cultural norms of nature and the environment contribute to environmental degradation. Greg Garrard has dubbed 'pastoral ecology' the notion that nature undisturbed is balanced and harmonious, while Dana Phillips has criticised the literary quality and scientific accuracy of nature writing in \"The Truth of Ecology\". Similarly, there has been a call to recognize the place of the Environmental Justice movement in redefining ecocritical discourse.\n\nIn response to the question of what ecocriticism is or should be, Camilo Gomides has offered an operational definition that is both broad and discriminating: \"The field of enquiry that analyzes and promotes works of art which raise moral questions about human interactions with nature, while also motivating audiences to live within a limit that will be binding over generations\" (16). He tests it for a film (mal)adaptation about Amazonian deforestation. Implementing the Gomides definition, Joseph Henry Vogel makes the case that ecocriticism constitutes an \"economic school of thought\" as it engages audiences to debate issues of resource allocation that have no technical solution. Ashton Nichols has recently argued that the historical dangers of a romantic version of nature now need to be replaced by \"urbanatural roosting\", a view that sees urban life and the natural world as closely linked and argues for humans to live more lightly on the planet, the way virtually all other species do.\n\nEcocritics investigate such things as the underlying ecological values, what, precisely, is meant by the word nature, and whether the examination of \"place\" should be a distinctive category, much like class, gender or race. Ecocritics examine human perception of wilderness, and how it has changed throughout history and whether or not current environmental issues are accurately represented or even mentioned in popular culture and modern literature. Scholars in ecocriticism engage in questions regarding anthropocentrism, and the \"mainstream assumption that the natural world be seen primarily as a resource for human beings\" as well as critical approaches to changing ideas in \"the material and cultural bases of modern society\". Other disciplines, such as history, economics, philosophy, ethics, and psychology, are also considered by ecocritics to be possible contributors to ecocriticism.\n\nWhile William Rueckert may have been the first person to use the term \"ecocriticism\" (Barry 240) in his 1978 essay entitled \"Literature and Ecology: An Experiment in Ecocriticism,\" ecocriticism as a movement owes much to Rachel Carson's 1962 environmental exposé \"Silent Spring\". Drawing from this critical moment, Rueckert's intent was to focus on \"the application of ecology and ecological concepts to the study of literature\".\n\nEcologically minded individuals and scholars have been publishing progressive works of ecotheory and criticism since the explosion of environmentalism in the late 1960s and 1970s. However, because there was no organized movement to study the ecological/environmental side of literature, these important works were scattered and categorized under a litany of different subject headings: pastoralism, human ecology, regionalism, American Studies etc. British marxist critic Raymond Williams, for example, wrote a seminal critique of pastoral literature in 1973, \"The Country and the City\".\n\nAnother early ecocritical text, Joseph Meeker's \"The Comedy of Survival\" (1974), proposed a version of an argument that was later to dominate ecocriticism and environmental philosophy; that environmental crisis is caused primarily by a cultural tradition in the West of separation of culture from nature, and elevation of the former to moral predominance. Such anthropocentrism is identified in the tragic conception of a hero whose moral struggles are more important than mere biological survival, whereas the science of animal ethology, Meeker asserts, shows that a \"comic mode\" of muddling through and \"making love not war\" has superior ecological value. In the later, \"second wave\" ecocriticism, Meeker's adoption of an ecophilosophical position with apparent scientific sanction as a measure of literary value tended to prevail over Williams's ideological and historical critique of the shifts in a literary genre's representation of nature.\n\nAs Glotfelty noted in \"The Ecocriticism Reader\", \"One indication of the disunity of the early efforts is that these critics rarely cited one another's work; they didn't know that it existed...Each was a single voice howling in the wilderness.\" Nevertheless, ecocriticism—unlike feminist and Marxist criticisms—failed to crystallize into a coherent movement in the late 1970s, and indeed only did so in the USA in the 1990s.\n\nIn the mid-1980s, scholars began to work collectively to establish ecocritism as a genre, primarily through the work of the Western Literature Association in which the revaluation of nature writing as a non-fictional literary genre could function. In 1990, at the University of Nevada, Reno, Glotfelty became the first person to hold an academic position as a professor of Literature and the Environment, and UNR has retained the position it established at that time as the intellectual home of ecocriticism even as ASLE has burgeoned into an organization with thousands of members in the US alone. From the late 1990s, new branches of ASLE and affiliated organizations were started in the UK, Japan, Korea, Australia and New Zealand (ASLEC-ANZ), India (OSLE-India), Taiwan, Canada and Europe.\n\n\n\n"}
{"id": "53693222", "url": "https://en.wikipedia.org/wiki?curid=53693222", "title": "Eloquentia Perfecta", "text": "Eloquentia Perfecta\n\nEloquentia Perfecta, a tradition of the Society of Jesus, is a value of Jesuit rhetoric that revolves around cultivating a person as a whole, as one learns to speak and write for the common good.\n\nSteven Mallioux, a Professor of Rhetoric at LMU, concluded that \"an optimal orator would combine written and oral language concepts such as morality or ethics and intelligence.\" This concept has expanded from education in Jesuit colleges and preaching this tradition and guiding Spiritual Exercises to courses in American Colleges such as Loyola Marymount University, University of San Francisco, and Fordham University.\n\nLMU's core curriculum provides a few aspects that construct Eloquentia Perfecta, the first being that \"It incorporates the traditional mode of rhetoric through writing, reading, speaking, and listening.\" The second aspect is, \"The remediation of this form of rhetoric in terms of adapting to the information age and its digital elements.\" \n\nIn ancient Athens, they had a goal of \"perfect eloquence\" in their education system, which was long before the Jesuits existed. They believed that speech had great power and could achieve many things with \"perfect eloquence\" way of speaking. Isocrates taught the \"art of word\" in his school that he opened and continued with words are needed to express one's thoughts.\n\nJesuit education is believed by many Jesuits that the late sixteenth century's Ratio Studiorum was the founding document of Jesuit education. Under Ratio Studiorum, \"perfect eloquence\" was renamed Eloquentia Perfecta. Ratio was developed from an idea from Ignatius of Loyola vision of education which had a baseline of classical humanities with a Renaissance focus. In addition, there was some math and history. As students go up to higher education, there is an integration of the study of science, logic, philosophy, and theology. With each progressive year of education, the Jesuit values of Eloquentia Perfecta is integrated into the curriculum. The goals were not explicit but Eloquentia Perfecta are the ides of \"developing an eloquent and mature. For example, when students gave speeches, they had to adapt to different audiences and be able to speak in a variety of styles to persuade the audience.\n\nAs education of the eighteenth century arose, Jesuit education in France was revised with the addition of sciences, plays, speeches, and the discussion of philosophical ideas. Along with the revision, however, Jesuit education maintained the practices of lectures, critical thinking, public speaking, as well as challenging students with quizzes and exams. The differences between traditional thinking and modern thinking provided a divide during changing times in the Enlightenment. The goal of education remained as the education aimed to strengthen the students communication skills with leadership skills, emotions, and eloquence. Students who attended Universities in the eighteenth century had the option of only getting a master's degree, however towards the end of the century, universities had incorporate BAs (Bachelor of Arts) and BSs (Bachelor of Science) degrees that students could get. If the student wanted to continue their education then they could get their master's as well.\n\nAmerican Jesuit liberal-arts-colleges in the mid-twentieth-century had a new major discipline incorporated into their educational system. In college, students would have to take two thirds of their college requirement credits on liberal education and the other third on their major. Before the twentieth century, students had to learn about classical core education, however, it has changed to a professional field which includes nursing, business, and education. Furthermore, there are still studies in rhetoric and logic that students are required to take involving speech and debate. In the education system, some teachers still use earlier Jesuit colleges methods where they provide lectures and exams while others use more recent methods like discussion and question-answer from students. Graduates from college during this time period say that the most crucial benefit they got out of their educational experience was that they \"learned to think\", which means integrating concepts from the old and new ideas in society in involving a person's mind and character.\n\nIn 1599, the Society of Jesus was presented with \"Ratio Studiorum,\" which included Jesuit educational framework and rules for the professors of rhetoric. Within this framework was the values of Eloquentia Perfecta which was, and continues to be, taught in Jesuit schools worldwide. These schools aim to promote Eloquentia Perfecta by educating their students into ideal orators by incorporating critical thinking, civic responsibility, and ethics into a Jesuit rhetoric curriculum.\n\nGert Beista, the author of \"The Beautiful Risk of Education\", explains that there are three objectives to Jesuit rhetoric that focuses on, \"reconnecting with the question of purpose in education.\" The first is that Jesuit rhetoric provides students with the knowledge, skills, and judgment that enables them to ‘‘do something’’ within their current society such as training for real-world issues with eloquence. The second of the three objectives is \"socialization\" where Beista states that, \"Through education, we become members of and part of particular social, cultural and political orders.\" The last objective is what Beista likes to call, \"subjectification.\" This term is characterized to be the opposite of socialization, in which its emphasis is on individualization and independence in one's thinking and actions.\n\nAlthough Jesuit rhetoric promotes the study of Eloquentia Perfecta, by midcentury in the United States, Jesuit rhetorical studies differed little in comparison to rhetorical studies in non-Jesuit Schools. This is due to the similarity of the fundamental study of Aristotle, Cicero, and Quintilian. After the American Civil War, however, non-Jesuit colleges began to differ in the curriculum. This divergence was due to the molding of non-Jesuit schools by the elective system, while Jesuit colleges conserved classical courses involving Greek and Latin literature.\n\nWith the advancements of Jesuit rhetoric, Jesuit colleges introduced three important rhetorics written by Jesuits. These three rhetorics included \"Ars Dicendi\" by German Jesuit Joseph Kleutgen, \"A Practical Introduction to English Rhetoric\", and \"The Art of Oratorical Composition\" both written by a Belgian-born Jesuit, Charles Coppens. Coppens taught at multiple American Jesuit colleges including the Jesuit seminary St. Stanislaus in Missouri. He defines the three terms rhetoric, oratory, and eloquence. Coppens states that rhetoric is, “the art of inventing, arranging, and expressing thought in a manner adapted to influence or control the minds and wills of others.” He defines oratory as, “the branch of rhetoric which expresses through orally.” Lastly, he defines eloquence as, “the expression or utterance of strong emotion in a manner adapted to excite correspondent emotions in others.” \n\nThe Ignatius of Loyola created a document of the \"Spiritual Exercises,\" a sequence of meditations that have been utilized in universities. These spiritual practices have been around since the sixteenth century and have been more accessible to people around the world as it was published over 4,500 times. Jesuit Spiritual Exercises have been the groundwork of Ignation pedagogy, also known as the Ignation pedagogical paradigm. Ignition pedagogy, which started in 1980's, is the discipline that cultivates a person's understanding, behavior, and contemplation.\n\nMany scholars might have the assumption that the original traditions of Eloquentia Perfecta have been erased in the later century, both through religious and academic teachings. However, though the term has been altered to fit modern society communication, the traditional teachings of the topic are very much alive. Through both digital technology and verbal communication, Eloquentia Perfecta continues to carry on the original goal of rhetorical eloquence to spread justice to all. Many of the Jesuit scholars have had to really adapt to new medians of expression and constantly have to recreate lesson plans for students to adapt to current societal standards. As stated by Morgan T. Reitmeyer and Susan A. Sci in their article, How To Talk Ethically: Cultivating the Digital Citizen through Eloquentia Perfecta, \"News is no longer something to simply consume; rather it is something to which we are compelled to respond within a wide array of media.\" As social justice has become a social phenomenon for current day societies, mainly because news is so easily accessible through digital devices, people are feeling more compelled to speak with Eloquentia Perfecta to portray their message.\n\nAs many Jesuit-affiliated universities have created a required course for all incoming first year students to take on Eloquentia Perfecta, the goal of Eloquentia Perfecta teachings remain, which is to spread the oral and written justice to people all over. Our society's culture today is a place for people to share their voices publicly using all different types of technology. Many of the digital platforms (i.e. Snapchat, Twitter, and Instagram) allow people to integrate their personal insight and moral judgments to their followers. There are many famous people whom use their public voice on these platforms in society to relay eloquent, and justice messages to the public. Many of these messages relate to real-life issues within different cultures around the world.\n\nOne prime example of Eloquentia Perfecta, being Jeannie Gaffigan, a writer, actress, and Catholic comedian, was awarded the Inaugural Eloquentia Perfecta Award from Fordham’s Graduate School of Religion and Religious Education (GRE) and the Paulist Press in October 2016. The award was given to Gaffigan because of her constant dedication to capturing the core significance of humanity. As a public figure, and social activist, she shines light on the idea that humanity is full of flaws that must be addressed. She bases her career on bringing people from all over the world together through skepticism, errors and uncertainty. As she receives much of her inspiration through Catholic religion, one of her most inspirational quotes to live by is by St. Ignatius of Loyola, founder of Society of Jesus, which reads, “Love ought to manifest itself in deeds rather than in words,” and spreads this faith through her many social platforms.\n\n\"Eloquentia Perfecta.\"\n\nEloquentia Perfecta is the most fundamental goal of all of these four practices listed below. The perfect eloquence is achieved through literature of many different cultures, where one must first understand other cultural and rhetorical languages to master this practice. These practices were all created in the early ages of Jesuit teachings, yet all still are related to modern day times. Eloquentia Perfecta is ultimately the only quality in which one must have to fulfill any sort of leadership role. Many believe that it is more important to have perfect eloquence in language and communication than it is to have any sore of technology-based skills in higher up positions in society.\n\n“The fly in the bottle.”\n\nThis metaphor first came alive by Ludwig Wittgenstein in 1914. It originally was used to help students get out of their comfort ones and expand their critical thinking skills by becoming exposed to different languages and cultures. It have been adopted into modern day education where educators can push students to think about the questions of life that don't necessarily apply to their particular areas of skill.\n\n“Heritage and Perspective.”\n\n\"Heritage and Perspective\" became a popular value in school, as it teaches past-recognition. It is based on the idea that modern day citizens are formed by the past and must grasp the concept that the past is still relevant to today's world. Without the knowledge of the past it is hard to understand some of the current situations in which an individual in society might get caught up in.\n\n“We are not born for ourselves alone.”\n\nFather Pedro Arrupe made the assertion that all students must become people of the world who help people to truly reach the fundamental goal of academic Jesuit teachings. He meant this in a rhetorical and philosophical way and not only referred to pure Jesuit practice. Women and men should be serving others to truly reach the Jesuit-practice goals.\n\n“The spirit of finesse.”\n\nThis phrase became well known by Henri Marrou, as he dubbed it as the opposite of “geometric spirit.” This phrase is made to push its followers into a humane mentality. It is meant to “weave webs with words that reflect the webs we weave with our lives, which are not neat geometric patterns but broken in places and filled with knots and tangles.” \n\n"}
{"id": "49387044", "url": "https://en.wikipedia.org/wiki?curid=49387044", "title": "Gloria Wekker", "text": "Gloria Wekker\n\nGloria Daisy Wekker (born June 13, 1950) is an Afro-Surinamese Dutch educator and writer who has focused on gender studies and sexuality in the Afro-Caribbean region and diaspora. She was the winner of the Ruth Benedict Prize from the American Anthropological Association in 2007.\n\nGloria Wekker was born in 1950 in Paramaribo, Suriname. She moved to Amsterdam in the 1970s and became active in the Afro-European Women’s Movement. Wekker earned a master's degree in cultural anthropology from the University of Amsterdam in 1981 and began her career working in various governmental agencies in Amsterdam, such as the Ministry of Health, Welfare and Culture on Ethnic Minorities' Affairs and the Ministry of Social Affairs and Employment. In 1984, she became a founding member of \"Sister Outsider\", an Amsterdam-based, literary circle for lesbian black women named after the work by Audre Lorde. In 1987, she served as a Policy Associate in the Office for the Coordination of Ethnic Minorities' Affairs.\n\nIn 1992, Wekker earned her doctorate at the University of California, Los Angeles with a thesis on the sexuality and subjectivity of Afro-Surinamese women. In 2001, she was appointed to the Aletta-chair of the Department of Women's Studies at the Utrecht University. Her work focuses on the intersections of colonialism, racism, white privilege, feminist theory, lesbian theory and women in the Caribbean. Her work has earned her the title of \"Holland’s Angela Davis\" as she has forced the Dutch to examine their alleged ingrained stereotypes and attitudes towards racism and patriarchy. She has led debate which questioned the racist nature of such iconic images in Dutch tradition as Sinterklaas (Santa Clause)'s helpers as blackface golliwogs known as \"Zwarte Piet\" (Black Pete), as well as the imagery of what constitutes beauty.\n\nWekker was nominated in 2004 for the Dutch Scientific Research Council's \"Triomfprijs\" (Triumph prize). In 2006, her book \"The Politics of Passion: Women's Sexual Culture in the Afro-Surinamese Diaspora\" won critical praise and was awarded with the 2007 Ruth Benedict Prize from the American Anthropological Association. In 2011, she began a sabbatical to work at the Netherlands Institute for Advanced Studies on a research project, which resulted in the publication in 2016 of \"White Innocence: Paradoxes of Colonialism and Race\". Because of her work with both sociology and policy, Wekker has been named as part of an international committee which was appointed at the University of Amsterdam in 2015 to increase diversity at the university.\n\n\n"}
{"id": "581819", "url": "https://en.wikipedia.org/wiki?curid=581819", "title": "Ink brush", "text": "Ink brush\n\nInk brushes (; ; ) are used in Chinese calligraphy as well as Japanese calligraphy and Korean calligraphy which have a root of Chinese calligraphy. They are also used in Chinese painting and other brush painting styles. The brush was invented in China around 300 B.C. Together with the inkstone, inkstick and Xuan paper, these four writing implements form the Four Treasures of the Study.\n\nBrushes differ greatly in terms of size, texture, material, and cost. The brush hair chosen depends on one's needs at the moment; certain kinds of brushes are more suited to certain script styles and individuals than others. \n\nSynthetic hair is not traditionally used. Prices vary greatly depending on the quality of the brush; cheap brushes cost less than one US dollar while expensive brushes can cost more than a thousand dollars. Currently, the finest brushes are made in the town of Shanlian, in the Nanxun District, prefecture-level city of Huzhou, of Zhejiang province.\n\nThe earliest intact ink brush was found in 1954 in the tomb of a Chu citizen from the Warring States period (475-221 BCE) located in an archaeological dig site \"Zuo Gong Shan 15\" near Changsha (長沙). The primitive version of an ink brush found had a wooden stalk and a bamboo tube securing the bundle of hair to the stalk. Legend wrongly credits the invention of the ink brush to the later Qin general Meng Tian.\n\nTraces of the writing brush, however, were discovered on the Shang jades, and were suggested to be the grounds of the oracle bone inscriptions.\n\nThe Fudepen, also known as a \"Brush Pen\", is a modern Japanese invention analogous to a Fountain pen. Today, Japanese companies such as Pentel and Sakura Color Products Corporation manufacture pens with tips resembling those of a small ink brush. These brush pens work almost identically to small ink brushes and can be used for most of the same purposes.\n\n"}
{"id": "8320742", "url": "https://en.wikipedia.org/wiki?curid=8320742", "title": "Line of beauty", "text": "Line of beauty\n\nLine of beauty is a term and a theory in art or aesthetics used to describe an S-shaped curved line (a serpentine line) appearing within an object, as the boundary line of an object, or as a virtual boundary line formed by the composition of several objects. This theory originated with William Hogarth (18th-century English painter, satirist, and writer), and is an essential part of Hogarth's theory of aesthetics as described in his \"Analysis of Beauty\" (1753). According to this theory, S-shaped curved lines signify liveliness and activity and excite the attention of the viewer as contrasted with straight lines, parallel lines, or right-angled intersecting lines, which signify stasis, death, or inanimate objects.\n\nIn contrast to grand compositional lines, which are regularly found in Baroque or Rococo art, the serpentine line is not primarily dictating the whole composition of a canvas. Instead, the line should be understood as being found in parts; a composition is created by employing various kinds of lines in various relations to each other without destroying its simplicity.\n\n\n"}
{"id": "21105447", "url": "https://en.wikipedia.org/wiki?curid=21105447", "title": "List of anonymous masters", "text": "List of anonymous masters\n\nIn art history, an anonymous master is an Old Master whose work is known, but whose name is lost.\n\nOnly in the Renaissance did individual artists in Western Europe acquire personalities known by their peers (some listed by Vasari in his \"Lives of the Artists\"), such as those known by :\n\nThe idea of a named and recognised painter originated among art historians early in the 20th century, who were attributing works they recognised to known painters. They later went back on some of these attributions, renaming as anonymous the painters they had formerly named. One example is the case of Pier Francesco Fiorentino, to whom Bernard Berenson attributed a number of works which were later re-attributed to Pseudo Pier Francesco Fiorentino, a Florence copyist. Some painters have even been described as anonymous (even many times like Barthélemy Eyck) before later being recognised. They thus held several names historically (those who are noted on the page devoted to them), although doubts continue surrounding some, such as Giovanni Gaddi (after 1333 – 1383) maybe the \"Master of the Misericordia dell’Accademia\".\n\nMaster of the Plump-Cheeked Madonnas==Artists==\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn recent years the names of a variety of artists who were formerly listed as \"anonymous\" have become known; accordingly scholarly writings and museum labels have been changed to reflect their new identities. Much the most famous of these is the Master of Flémalle (c 1378–1445), painter of the comté de Hainaut, who was established as Robert Campin. Other examples include:\n\n\n"}
{"id": "2961961", "url": "https://en.wikipedia.org/wiki?curid=2961961", "title": "List of buzzwords", "text": "List of buzzwords\n\nThis is a list of common buzzwords which form part of the jargon of corporate, academic, government, and everyday work and social environments, as well as by writers and public speakers.\n\n\n\n"}
{"id": "16351550", "url": "https://en.wikipedia.org/wiki?curid=16351550", "title": "Marilyn Deegan", "text": "Marilyn Deegan\n\nProfessor Marilyn Deegan is the former Director of Research Development at the former Centre for Computing in the Humanities, now the Department of Digital Humanities), King's College London.\n\nOriginally a scientist, she now has over forty years experience in Digital Humanities and digital libraries, with a particular interest in the issues surrounding digital preservation. Until 2011 Prof. Deegan was Editor of the Literary and Linguistic Computing journal, Oxford University Press.\n\n"}
{"id": "40862609", "url": "https://en.wikipedia.org/wiki?curid=40862609", "title": "Medical Heritage Library", "text": "Medical Heritage Library\n\nThe Medical Heritage Library (MHL) is a digital curation collaborative among several medical libraries which promotes free and open access to quality historical resources in medicine. The MHL is currently digitizing books and journals and is working to expand to the digitization of archival materials and still images. In 2010, the MHL began digitizing titles, mainly monographs, in a variety of medical history and related fields including chemistry, nursing, dentistry, audiology, physiology, psychology, psychiatry, biological science, hydrotherapy, weather, veterinary medicine, gardening, physical culture, and alternative medicine chosen for their scholarly, educational, and research value. Since the inception of the project, materials in audio and video formats have been added to the collection.\n\nThe MHL works to:\n\nThe MHL maintains a blog, Twitter account, and Facebook page to interact with researchers, librarians, archivists, students, and the interested general public about the MHL collections, the history of medicine, digital humanities, and related topics.\n\nThe MHL began digitization of monographs in 2010 with an initial grant from the Sloan Foundation. Work on the MHL project has continued with funding support from collaborating institutions, the National Endowment for the Humanities (announcement), and the Mellon Foundation via a program administered by the Council on Library and Information Resources (announcement). All digitized works are located at the Internet Archive.\n\nThe collection includes books, pamphlets, journals, and video and audio recordings in the history of medicine and related fields. A working list of subject headings is available here. Titles have been chosen for their scholarly, educational, and research value. The MHL consults with a volunteer group of scholars in the history of medicine and related fields and surveys its users regularly. As of August 2014, the collection consists of nearly 60,000 items including monographs, journals, audio and video on topics including surgery, public health, infectious diseases, gynecology, psychology, anatomy, neuroscience, tobacco, and homeopathy.\n\nThe MHL has created a full-text search tool for use by researchers. The tool allows users to search the full-text of one or more items simultaneously. The tool is in an extended beta release and comments or questions are welcome!\n\nThe UK Medical Heritage Library started in 2014 with nine digitisation partners in England and Scotland, including [UCL] (University College London), the [University of Leeds], the [University of Glasgow], the [London School of Hygiene & Tropical Medicine], [King's College London], and the [University of Bristol] - along with the libraries of the [Royal College of Physicians of London], the [Royal College of Physicians of Edinburgh], and the [Royal College of Surgeons of England]. The original partnership is between the [Wellcome Library] and [Jisc]. Material digitized by the UK MHL project is also available through the MHL portal at the Internet Archive and searchable through the full-text search tool described above.\n\nOriginal members of the collaborative formed in 2010 are:\n\nContent contributors have joined the project regularly since 2011; the MHL continues to seek additional content contributors.\n\n\n\n"}
{"id": "26742938", "url": "https://en.wikipedia.org/wiki?curid=26742938", "title": "Museum Anthropology Review", "text": "Museum Anthropology Review\n\nMuseum Anthropology Review is a peer-reviewed gold open access academic journal focusing on research in material culture studies, museum-based scholarship, and the study of museums in society. In addition to anthropology, it covers the fields of folklore, art history, and museum studies. It was established in 2007 and is published for the Mathers Museum of World Cultures by the Indiana University Bloomington Libraries as part of its IUScholarWorks program using Open Journal Systems. The journal is edited by Jason Baird Jackson.\n"}
{"id": "1771987", "url": "https://en.wikipedia.org/wiki?curid=1771987", "title": "News satire", "text": "News satire\n\nNews satire is a type of parody presented in a format typical of mainstream journalism, and called a satire because of its content. News satire has been around almost as long as journalism itself, but it is particularly popular on the web, with websites like The Onion, where it is relatively easy to mimic a legitimate news source. News satire relies heavily on irony and deadpan humor.\n\nTwo slightly different types of news satire exist. One form uses satirical commentary and sketch comedy to comment on real-world news events, while the other presents wholly fictionalized news stories.\n\nAuthor Samuel Clemens (Mark Twain) was employed as a newspaper reporter before becoming famous as a novelist, and in this position he published many satirical articles. He left two separate journalism positions, Nevada (1864) fleeing a challenge to duel and San Francisco fleeing outraged police officials because his satire and fiction were often taken for the truthful accounts they were presented as. Ironically, the accuracy of many newspaper and autobiographical accounts used to follow the early life of Samuel Clemens are in doubt.\n\nNewspapers still print occasional news satire features, in particular on April Fools' Day. This news is specifically identified somewhere in the paper or in the next day as a joke.\n\nIn 1934, Metro-Goldwyn-Mayer released a series of ten one-reel theatrical shorts called \"Goofy Movies\", which included \"Wotaphony Newsreel,\" a newsreel parody that paired actual footage with a mocking, deadpan narration.\n\nAlso in 1934, halfway through a Kraft Music Hall radio show, Dean Taylor (\"Others collect the news, Dean makes it!\") narrated a fake newsreel which began with a report on the New York Giants and Philadelphia Phillies being cancelled due to bad weather, and baseball season being rescheduled to when farmers need rain.\n\nNews satire has been prevalent on television since the 1960s, when it enjoyed a renaissance in the UK with the \"Satire Boom\", led by such luminaries as Peter Cook, Alan Bennett, Jonathan Miller, David Frost, Eleanor Bron, and Dudley Moore, and the television program \"That Was The Week That Was\". In the United States, the NBC network adapted this program and also produced its own content, from the \"news\" segment of \"Rowan and Martin's Laugh-In\", to the still-running \"Saturday Night Live\" mock newscast segment \"Weekend Update\". Cable television got into the cable news act with Home Box Office's \"Not Necessarily the News\" in the mid-1980s.\n\nIn the 2000s, Comedy Central's \"The Daily Show\" became an icon of the American political satire genre, as Jon Stewart delved into opinionated political criticism. Its spinoff, Stephen Colbert's \"The Colbert Report\", also enjoyed a high level of popularity during its 9-year run.\n\nThe 2004 National Annenberg Election Survey found that \"Daily Show\" viewers were better informed than those who relied solely on conventional network news, and Steven Young of \"Los Angeles Daily News\" compares the trust and influence that long-time host Jon Stewart enjoyed to that of CBS anchor Walter Cronkite in the 1970s. However, a study published in the \"Journal of Communication\" suggests that news entertainment shows such as \"The Daily Show\" or \"The Colbert Report\" may not be as influential in teaching voters about political issues and candidates as was previously thought. Researchers from Ohio State University have found reasons to discount how effective these shows are in informing the general public. People watching television news learned more about a candidate's position on issues and about political procedures compared to those watching the news entertainment shows, while news entertainment shows primarily taught viewers about a candidate’s personal background.\n\nAfter the success of \"The Daily Show\", Fox News launched its own news satire program in February 2007 with the title of \"The 1/2 Hour News Hour\". Its creator describes it as \"The Daily Show for conservatives\", but it was canceled within a few months. Fox News then launched the more successful series \"Red Eye\" which ran from February 6, 2007 to April 7, 2017. As of 2017, news satire in the United States remains popular, especially in late night television; late-night talk shows often incorporate elements of news satire. Current American programs known primarily for their news satire include those hosted by former correspondents for \"The Daily Show\" (John Oliver's \"Last Week Tonight\", Samantha Bee's \"Full Frontal\", and \"The Daily Show\" itself under Trevor Noah's tenure), as well as Bill Maher's \"Real Time\".\n\nIn Britain, several news satires have been created, most famously the works of Chris Morris. Shows such as the radio series \"On the Hour\" and its television version \"The Day Today\" parodied news programs very accurately, so they were almost believable and could have been confused with actual news programs, if it was not for the fake stories reported. Morris went on to continue this and several other themes in \"Brass Eye\", one of the most controversial series on British television, especially after one episode broadcast mocked the way the news covered stories about pedophilia. Previous news satire shows in Britain include: \"The Late Edition\" with Marcus Brigstocke, on digital station BBC Four, which was heavily influenced by \"The Daily Show\"; \"News Knight with Sir Trevor McDonald\", which parodied news differently by using an actual newsreader as the host; and \"Broken News\", which featured several sketches of different news channels blending into each other.\n\nAs of 2018, current British news-related programs that have been described as satire include: \"Have I Got News for You\" and \"Mock the Week\" on the BBC; Channel 4's \"The Last Leg\"; ITV's \"Newzoids\"; and Dave's \"Unspun with Matt Forde\".\n\nRecent news satire television series in Australia include Working Dog Productions' \"Frontline\", Shaun Micallef's \"Newstopia\", and the many programs created by The Chaser since 2001. As of 2017, current programs of the Australian Broadcasting Corporation include \"Shaun Micallef's Mad as Hell\" and \"The Weekly with Charlie Pickering\".\n\nIn Canada, \"This Hour Has 22 Minutes\" is an ensemble news satire show with four anchors on CBC. The \"Rick Mercer Report\" is a spinoff of \"22 Minutes\" with former anchor Rick Mercer, and is also shown on CBC. CBC Radio One features \"This Is That\", an improvised news satire program which mimics the style of actual CBC Radio public affairs programs. The 1960s series \"This Hour Has Seven Days\", although primarily a real newsmagazine, included some satirical features in its format, such as political humor songs by actress and singer Dinah Christie. On French-language television networks in Quebec, noted news satire shows have included \"La Fin du monde est à 7 heures\", \"Et Dieu créa... Laflaque\" and \"Infoman\". On the Internet, noted satire sites include \"The Lapine\" and \"The Beaverton\".\n\nIn Germany, heute-show (ZDF), and formerly Wochenshow (on SAT.1) and Freitag Nacht News (on RTL) are popular news satires on TV.\n\nThe Egyptian show \"El Bernameg\", hosted by Bassem Youssef (on Capital Broadcast Center 2011-13 and MBC MASR from 2014 on), is modeled on \"The Daily Show\". Launched in the wake of the Egyptian Revolution of 2011, it has been quite popular, but also a source of tremendous controversy, as Youssef has repeatedly been under investigation by the authorities for his willingness to poke fun at powerful people.\n\nNews satire has been posted on the web almost since its inception, with \"The Onion\" foremost among recognized news satire sites due to its enduring and profitable business model. The content of the website, which started in 1996, is syndicated through mainstream media sites such as CNN and CNET. Today there are hundreds of news satire sites online. Sites such as Hollywood Leek specialize in satirical articles about celebrities and Hollywood entertainment news. Sometimes fake news reporters influence real world politics, like Citizen Kate whose 90 episodes covered the 2008 presidential campaign trail, she commissioned a butter bust of Obama presented to him by the Butter Cow Lady of Iowa, making international headlines. El Koshary Today is an Egyptian website that carries fake international news stories. Other satire sites attempt to emulate a genuine news source of some sort; however, these sites now take a variety of forms.\n\nBecause interesting stories are often emailed and can quickly become separated from their point of origin, it is not uncommon for news satire stories to be picked up as real by the media, as happened with a \"Faking News\" story about a lawsuit against Axe by an Indian man after having failed to attract a girl. Additionally, a parody post on Al Sharpton's parody News Groper blog was quoted as if real by MSNBC. Another satire publication, \"The Giant Napkin\", published an article about a man literally fighting his house fire with more fire, a story taken seriously by several social networking sites. That Google News accepts news satire sources helps contribute to this phenomenon; while Google News does mark such stories with a \"satire\" tag, not all readers notice the tag; moreover, sometimes satirical sources may not carry the tag. At least one site, \"thespoof.com\", relies on user-generated content in a Web 2.0 manner.\n\nSome websites like \"Literally Unbelievable post\" the genuine and shocked reactions of individuals who believe the satirical articles are real. The reactions are taken from social media websites, such as Facebook, in which users can directly comment on links to the article's source.\n\nMulti-author Indian website News That Matters Not, launched in November 2009, won a Manthan South Asia Award for socially responsible e-content (Digital Inclusion for Development), organized by Digital Empowerment Foundation. In India, several community-based news satire websites have crept up in recent times. Their popularity on Facebook defines that they are popular amongst the masses. Very new websites such as The Scoop Times, Fakekhabar.com, Sunkey.co.in and The UnReal Times also claim to be run by students, and were covered in \"The Times of India\" in July 2011.\n\nA plethora of news satire sites participate in a hosted community site, which additionally runs its own satire news feed on HumorFeed. HumorFeed is notable for its relatively high standards of admission and active community involvement. At present, over 60 sites are contributing members, at least eight of which have published books and two of which publish regular hard-copy periodicals. Several HumorFeed members also run \"Check Please!\", an online journal devoted to the serious examination of online satire, ranging from its role in relation to actual journalism to practical considerations of producing an online satire site.\n\nIn July 2009, a satire piece about Kanye West published on the website ScrapeTV was picked up by numerous media outlets and reported as factual, despite disclaimers on the site.\n\nSatirical Twitter accounts of news sources are popular, and they are often mistaken as legitimate sources. Online publications have made quizzes challenging users to distinguish between the tweets of the real \"Vice\" and the tweets of their parodies. The @Salondotcom parody account confused so many Twitter users that the real Salon.com reported them for impersonation.\n\nIn Pakistan, Khabaristan Times (KT) is a renowned satire and parody website with its commentary on Pakistani politics and the military. In 2015, a satirical piece by the website went viral and international media outlets including New York Times reported the story as if it were true. In 2017, KT was reportedly blocked in Pakistan, however, it appeared to be available to users outside Pakistan.\n\nIn the Middle East, \"The Pan-Arabia Enquirer\" is the most widely read satirical news website. It gained notoriety in 2013 when an article about Emirates launching shisha lounges on its fleet of A380s was picked up as fact by news websites around the world. \"AlHudood\", another middle eastern satire news publisher, has gained publicity in the region when they published an article about the Jordanian police arresting Santa Claus and confiscating all of his gifts for not paying the customs before entering Jordan.\n\nIn Turkey, Zaytung has become a source of mass reading since the socio-political Gezi Park 2013 protests in Turkey.\n\nIn the Caribbean, Trinidad and Tobago-based website Wired868 has two satirical columnists under the pseudonyms Mr Live Wire and Filbert Street, who comment satirically on relevant political and news stories such as the fall from power of ex-FIFA vice-president Jack Warner, media issues, general news and the challenges faced by Prime Minister Kamla Persad-Bissessar and her People's Partnership coalition Government.\n\nIn Australia, there are numerous satirical news websites including \"The Shovel, The Betoota Advocate\", \"The (Un)Australian\", \"The Fault Report\", \"The Sauce\" and \"The Tunnel Presents\". \"The Shovel\" mainly satirizes the Australian political and social culture and \"The Betoota Advocate\" satirizes the political right and Australian journalism. In February 2015, \"The Betoota Advocate\" shot to fame after the publication's editor's sneaked in to the media scrum outside Parliament House in Canberra during a leadership spill motion and managed to interview some of Australia's most high-profile media personalities and politicians, posing as legitimate journalists. The fallout from \"The Betoota Advocate\" stunt has led to a security increase surrounding parliamentary media and screening of all crew. \"The Fault Report\" was established in 2014 and also has a political editorial focus. British-born Australian author John Birmingham once described \"The Fault Report\" as, \"Like \"The Onion\". But with Vegemite\", on his blog Cheeseburger Gothic. \"The Tunnel Presents\", which has been online since June 2011, is by Brisbane-based satire writing team The Tunnel and has political and social satire stories with a Queensland focus.\n\nIn Italy, the most famous website specialized in mock-journalism is . Born as a parody of the popular press, but in addition to the tabloid press, its goals are also the domestic and foreign politics. The website was created in the 2012 and the editorial staff is composed of authors who have contributed to La Palestra, a column wanted on his blog by the comedian and satirical author Daniele Luttazzi. In few years Lercio saw the publication of a book with a collection of 2014 best articles. From the same year Lercio it is present on the national radio with a daily strip. Thanks to the many fans the articles are shared on the social network with a good success and, mostly in the beginning of his history, some articles were taken as true by the national press.\n\nIn Hungary, HírCsárda is the number one news satire medium. The site, started in 2010, has drawn public attention after the Hungarian government demanded that an article should be emended that dealt with the then state secretary of education Rózsa Hoffmann. The page has since been threatened by various celebrities, but has remained active regardless. Also present in Hungary is Központi Újság (Central News), a news satire website of the joke party Hungarian Two-tailed Dog Party.\n\nTreefort Music Fest, a grassroots music festival in Boise, Idaho, has satirically used the television news format to announce its line-up of bands.\n\nIn 2015, John J Edmunds IV launched season 1 of New Jersey based satire news show, \"My Minute Minute.\" The program is an internet based show streamed live in high definition to Facebook LIVE, YouTube, Periscope & YouNow streaming services on a weekly basis. The show producer, John Edmunds tells stories of Political corruption, medical corruption, Drug-related crimes, sneaky business owners and operations and stories of satirical nature. They publish weekly at www.SatireNews.tv\n\n"}
{"id": "43297766", "url": "https://en.wikipedia.org/wiki?curid=43297766", "title": "Northampton Sekhemka statue", "text": "Northampton Sekhemka statue\n\nThe Northampton Sekhemka statue is an Ancient Egyptian artefact, given by the Marquess of Northampton to Northampton Museum, in or about 1870. The statue dates from the 5th dynasty (c. 2494–2345 BC, making it slightly older than Stonehenge) and depicts Sekhemka the scribe with his wife, Sitmerit. It was the subject of a controversial sale in July 2014, that raised questions of the museum's ownership and the ethics of selling artefacts. The statue was sold to an unidentified buyer for £15.76m, which broke the world record for Ancient Egyptian art at auction. On 1 August 2014, Northampton Museums had their accreditation removed by Arts Council England, which ruled that the sale did not meet the accredited standards for museums in managing their collections.\n\nThe statue depicts Sekhemka sitting in a traditional scribal pose and holding on his knees a partly unrolled papyrus which lists various offerings. He is named in an inscription on the plinth of his statue as \"Inspector of Scribes in the House of Largesse, one revered before the Great God\". His wife Sit-Merit is shown sitting at his feet. The limestone statue is tall with the base from front to rear being . Archaeologist Mike Pitts, editor of \"British Archaeology\", took many detailed colour photographs of the statue whilst it was on display in Christie's prior to auction and has published them on his own blog.\n\nThe statue's provenance is unclear. \"Al-Ahram Weekly\" reports that one account describes the statue as being acquired by Northampton Museum in 1849 from the Ottoman sultan, while another version holds that it was acquired by the 2nd Marquess of Northampton during a trip to Egypt, after which his son offered it to Northampton Museum in the 19th century. T. G. H. James noted in 1961 that Northampton Museum held no precise information regarding the acquisition of the statue, but that it was presented to the museum around 1870 by the 3rd Marquess of Northampton and, based on a record from 1899, it is likely to have been acquired by the 2nd Marquess during a trip to Egypt in 1850.\n\nNorthampton Borough Council claimed that they learned the full value of the Sekhemka statue in 2012 during an insurance assessment, and according to \"The Daily Telegraph\" it \"immediately began making plans to cash it in and use the money for other heritage projects in the region.\" The then leader of Northampton Borough Council, David Mackintosh, told the BBC that the statue had \"been in our ownership for over 100 years and it's never really been the centrepiece of our collection\", and that \"We want to expand our museum and to do that we need to raise the money\". The council proposed to use the amount realized through a sale for funding “the restoration of Delapre Abbey, improvements to the museum service and/or other cultural or heritage projects” but the Museum Association asked that proposed sale be halted pending consultation which \"was needed to establish the financially motivated disposal was 'last resort'\"\n\nThe council stated that when the statue was valued in 2010 it was taken off display because of security concerns, and that it would have required 24-hour guarding. However, Axa Art Insurance Ltd subsequently reported that the cabinet display previously used in Northampton Museum was \"adequate\". The council were also asked \"why, when the Friends of Northampton Museum and Art Gallery offered £8,000 to buy a new cabinet, was the offer not taken up?\" but did not reply to this specific question.\n\nIn October 2012, the council published the results of a petition that was signed by 199 (average of all petitions 193 as of July 2014):\n\nNorthampton Borough Council claimed in January 2013 to have sought the views of the public regarding the proposed sale of the statue, but the form this took was criticised by the Museum Associations ethics committee:\n\nNevertheless, the BBC repeated the council's claim that the consultation indicated that of the 173 replies 51% were in favour and 49% were against the sale. No question in the consultation document asked whether the statue should be sold or not; however, those who participated in the consultation could leave optional narrative comments, and the council used these to claim a small majority in favour of selling the statue. The Save Sekhemka Action Group objected to the methods used in the consultation document:\n\nThe Save Sekhemka Action Group reported that their own survey showed \"overwhelming support for protecting the museum's accredited status and keeping the statue\".\n\nThe \"Northampton Chronicle and Echo\" carried out a Facebook poll in June 2014, and found that the majority wanted to keep the statue.\n\nThe present Lord Northampton originally protested at the decision of Northampton Borough Council to sell the statue. However, the BBC reported that, following negotiations lasting a year, he struck a private deal with the council which resulted in him receiving £6 million from the sale. Northampton Borough Council has refused to release details of the legal arrangement. The Marquess had previously been involved with the controversial attempted sale of the Sevso Treasure.\n\nIn June 2014, the council was asked by a local newspaper: \"Are you prepared to show the documents and agreements made with the Marquess of Northampton to any member of the public who asks to see them? If not, why not?\" and replied \"The details of the agreement are confidential between Lord Northampton and the borough council, but we can confirm that 55% of the sale will go to the council and 45% will go to Lord Northampton.\" The council also stated \"The council’s ownership of Sekhemka has been confirmed following advice from lawyers, who are satisfied we have legal right to proceed with the sale. We do not have any deed specifically relating to Sekhemka.\" After the sale of the statue The Save Sekhemka Action Group questioned why the Marquess of Northampton would be receiving over £5 million from the proceeds since, according to Northampton Borough Council, the council owned the statue.\n\nThe Egyptian Ministry of Antiquities asked the Egyptian Embassy in London to take all legal procedures to stop the sale of the statue. Minister Mamdouh Al-Damati condemned the sale as being incompatible with the values and role of museums worldwide which should spread culture rather than seeking to earn money. He also called on the International Council of Museums (ICOM) to stop the sale on ethical grounds. The Museum Association for the United Kingdom warned the council that it would review Northampton’s membership if it went ahead with the sale. The Arts Council of England said the sale could jeopardise the accreditation status of Northampton Museums and that could in future limit the museum's ability to obtain grant funding. Archaeologist Andy Brockman, who took part in the Save Sekhemka campaign said the sale would \"bring Northampton Council into disrepute\" and that the sale was \"opposed by museum and archaeological professionals who wish to make sure no part of Egypt's cultural history is sold off.\"\n\nICOM CIPEG also expressed concern that the sale might encourage illegal excavation and plundering of Ancient Egyptian antiquities.\n\nIn July 2013, a local politician who opposed the sale of the statue commented: \"I've read there is a curse attached to Sekhemka and if it should fall on anyone, it should fall on this administration for not having the courage to change their minds.\" The day before the sale was scheduled to take place the estate office of the Marquess of Northampton's Castle Ashby caught fire leading to stories about the \"Curse Of Sekhemka\". Fire crews from three counties fought the blaze.\n\nChristie's sold the Sekhemka statue for £15.76 m at an auction on 10 July 2014 to an anonymous buyer. The auction was briefly halted by a protester who called out that “no-one should bid or buy it...stolen property,” while a small, vocal group of Egyptian protesters demonstrated outside. The final auction price was almost £10 m more than Christie's guide price. The price obtained broke the existing world record for an Ancient Egyptian artwork sold at auction.\n\nThe Save Sekhemka Action group described the sale as a \"day of shame for Northampton\", and said that selling the statue had been \"the decision of one man [council leader David Mackintosh], taken against all professional advice locally, nationally and internationally\" The sale was described by the Egyptian Embassy as a \"shameful and unethical act\". Scott Furlong, of Arts Council England, said: \"It is very disappointing that the local authority committed to the sale and entered into an agreement with an auction house before our discussions with them were concluded.\" Northampton council leader David Mackintosh said the council's share of the proceeds would be used to develop the existing museum. The writer Alan Moore also condemned the council's decision to sell the statue.\nThe Art Fund commented the day after the sale:\nThe Arts Council announced that Northampton Museums' accreditation would be reviewed on 24 July 2014:\n\nOn 1 August 2014, Northampton Museums had their accreditation removed by the Arts Council England, who ruled that the sale broke the required standards for museums managing their collections, rendering the museums ineligible for funding from a range of arts grants and funding bodies. The museums are excluded from future participation until at least August 2019. Scott Furlong of the Arts Council commented: \"It is always hugely regrettable when we have to exclude a museum from the Accreditation Scheme. However, it is equally important that we are robust in upholding the standards and principles which underpin the scheme and are shared by the vast majority of museums.\" The leader of Northampton borough council, David Mackintosh said the Arts Council decision was \"disappointing\" and \"puzzling\", and stated \"We are possibly one of the only local authorities in the country with plans for a multimillion pound investment in their museum service.\"\n\nThe Save Sekhemka Action Group commented \"This is indeed a black and shameful day for Northampton's Culture and Heritage\" and that \"it will mean the certain decline of both the Central and Abington Museum since the loss of this statue stops the Museum Service being eligible for outside grants from the Lottery, Arts Council England and other art/cultural grant giving bodies.\" They said that the monetary loss through loss of accreditation is likely to be in excess of the £8m gross the council received from the sale of the statue.\n\nIn November 2014, the Borough Council's bid for a Heritage Lottery Fund grant of £240,400 was rejected. The funding was being sought for an exhibition of designer shoes dating from the 19th century to the present. The council said it was \"disappointed\". The Museums Association decided to ban the council from membership for five years.\n\nIn September 2014, the Friends of Northampton Museums and Art Gallery decided to wind itself up after 55 years' financial and practical service to the town. The sale of the statue was partly to blame for this; the group was against the sale, though some felt it did not fall within the group's functions.\n\nOn 30 March 2015, British culture minister Ed Vaizey placed a four-month temporary export ban on the statue, which had been sold to an unidentified overseas buyer. The Arts Council said there was a chance the statue could be sold to a UK buyer if \"a serious intention to raise funds to purchase the statue is made at the recommended price of £15,732,600 plus VAT.\"\n\nEgyptian Ambassador Ahsraf Elkholy condemned the sale as \"an abuse to the Egyptian archaeology and the cultural property,\" saying that the statue should have been given back to Egypt if the council no longer wanted it.\n\nOn 2 October 2015, Vaizey extended the export ban until 29 March 2016, after hearing of a serious bid to raise funds to save the statue for the UK. Since no-one made a counter-offer during this extension, in April 2016 the ban was lifted.\n\nOn 21 April 2015 the Save Sekhemka Action Group said that they think that a condition of the original Deed of Gift was that the statue should never be sold, making the auction illegal. The group said that they had no intention of trying to buy the statue back but suggest that it is put on display at a major museum. It is also challenging the £6m donation from the sale proceeds to the Marquess of Northampton's family. It will also examine borough council records to determine \"the legal and financial arrangements reached with the Marquis of Northampton\".\n\nThe BBC reported in October 2016 that the statue now is thought to have been exported to the United States. BBC news revealed how the council, which made £8m from the sale, had been warned by lawyers not to sell it for \"financial motives\".\nThe council said it sold the figurine to help fund a £14m extension to its museum and art gallery.\n\n\n"}
{"id": "65821", "url": "https://en.wikipedia.org/wiki?curid=65821", "title": "Pastiche", "text": "Pastiche\n\nA pastiche is a work of visual art, literature, theatre, or music that imitates the style or character of the work of one or more other artists. Unlike parody, pastiche celebrates, rather than mocks, the work it imitates.\n\nThe word \"pastiche\" is a French cognate of the Italian noun \"pasticcio\", which is a pâté or pie-filling mixed from diverse ingredients. Metaphorically, \"pastiche\" and \"pasticcio\" describe works that are either composed by several authors, or that incorporate stylistic elements of other artists' work. Pastiche is an example of eclecticism in art.\n\nAllusion is not pastiche. A literary allusion may refer to another work, but it does not reiterate it. Moreover, allusion requires the audience to share in the author's cultural knowledge. Both allusion and pastiche are mechanisms of intertextuality.\n\nIn literature usage, the term denotes a literary technique employing a generally light-hearted tongue-in-cheek imitation of another's style; although jocular, it is usually respectful.\n\nFor example, many stories featuring Sherlock Holmes, originally penned by Arthur Conan Doyle, have been written as pastiches since the author's time. Ellery Queen and Nero Wolfe are other popular subjects of mystery parodies and pastiches.\n\nA similar example of pastiche is the posthumous continuations of the Robert E. Howard stories, written by other writers without Howard's authorization. This includes the Conan the Barbarian stories of L. Sprague de Camp and Lin Carter.\nDavid Lodge's novel \"The British Museum Is Falling Down\" (1965) is a pastiche of works by Joyce, Kafka, and Virginia Woolf. In 1991 Alexandra Ripley wrote the novel \"Scarlett\", a pastiche of \"Gone with the Wind\", in an unsuccessful attempt to have it recognized as a canonical sequel. \n\nIn 2017, John Banville published Mrs. Osmond, a sequel to Henry James's The Portrait of a Lady, written in a style similar to that of James.\n\nCharles Rosen has characterized Mozart's various works in imitation of Baroque style as pastiche, and Edvard Grieg's \"Holberg Suite\" was written as a conscious homage to the music of an earlier age. Some of Pyotr Ilyich Tchaikovsky's works, such as his \"Variations on a Rococo Theme\" and \"Serenade for Strings\", employ a poised \"classical\" form reminiscent of 18th-century composers such as Mozart (the composer whose work was his favorite). Perhaps one of the best examples of pastiche in modern music is that of George Rochberg, who used the technique in his String Quartet No. 3 of 1972 and Music for the Magic Theater. Rochberg turned to pastiche from serialism after the death of his son in 1963.\n\n\"Bohemian Rhapsody\" by Queen is unusual as it is a pastiche in both senses of the word, as there are many distinct styles imitated in the song, all \"hodge-podged\" together to create one piece of music. A similar earlier example is \"Happiness is a Warm Gun\" by The Beatles. One can find musical \"pastiches\" throughout the work of the American composer Frank Zappa.\n\nA \"pastiche Mass\" is a musical Mass where the constituent movements come from different Mass settings. Most often this convention has been chosen for concert performances, particularly by early-music ensembles. Masses are composed of movements: Kyrie, Gloria, Credo, Sanctus, Agnus Dei; for example, the \"Missa Solemnis\" by Beethoven and the \"Messe de Nostre Dame\" by Guillaume de Machaut. In a pastiche Mass, the performers may choose a Kyrie from one composer, and a Gloria from another; or choose a Kyrie from one setting of an individual composer, and a Gloria from another.\n\nIn musical theatre pastiche is often an indispensable tool for evoking the sounds of a particular era for which a show is set. For the 1971 musical \"Follies\", a show about a reunion of performers from a musical revue set between the World Wars, Stephen Sondheim wrote over a dozen songs in the style of Broadway songwriters of the 1920s and 1930s. Sondheim imitates not only the music of composers such as Cole Porter, Irving Berlin, Jerome Kern, and George Gershwin but also the lyrics of writers such as Ira Gershwin, Dorothy Fields, Otto Harbach, and Oscar Hammerstein II. For example, Sondheim notes that the torch song \"Losing My Mind\" sung in the show contains \"near-stenciled rhythms and harmonies\" from the Gershwins' \"The Man I Love\" and lyrics written in the style of Dorothy Fields. Examples of musical pastiche also appear in other Sondheim shows including \"Gypsy\", \"Saturday Night\", and \"Anyone Can Whistle\".\n\nPastiche can also be a cinematic device whereby filmmakers pay homage to another filmmaker's style and use of cinematography, including camera angles, lighting, and mise en scène. A film's writer may also offer a pastiche based on the works of other writers (this is especially evident in historical films and documentaries but can be found in non-fiction drama, comedy and horror films as well). Italian director Sergio Leone`s Once Upon a Time in the West is a pastiche of earlier American Westerns. Another major filmmaker, Quentin Tarantino, often uses various plots, characteristics and themes from many lesser-known films to create his films, among them from the films of Sergio Leone, in effect creating a pastiche of a pastiche. Tarantino has openly stated that \"I steal from every single movie ever made.\" Director Todd Haynes' 2002 film Far From Heaven was a conscious attempt to replicate a typical Douglas Sirk melodrama - in particular All That Heaven Allows. The film works as a mostly reverential and unironic tribute to Sirk's filmmaking, lovingly re-creating the stylized mise-en-scene, colors, costumes, cinematography and lighting of Sirkian melodrama.\n\nIn cinema, the influence of George Lucas' \"Star Wars\" films (spawning their own pastiches, such as the 1983 3D film \"\") can be regarded as a function of postmodernity.\n\nIn discussions of urban planning, the term \"pastiche\" may describe developments as imitations of the building styles created by major architects: with the implication that the derivative work is unoriginal and of little merit, and the term is generally attributed without reference to its urban context. Many post-war European developments can in this way be described as pastiches of the work of architects and planners such as Le Corbusier or Ebenezer Howard. The term itself is not pejorative, however Alain de Botton describes pastiche as \"an unconvincing reproduction of the styles of the past\".\n\n"}
{"id": "288400", "url": "https://en.wikipedia.org/wiki?curid=288400", "title": "Provenance", "text": "Provenance\n\nProvenance (from the French \"provenir\", 'to come from/forth') is the chronology of the ownership, custody or location of a historical object. The term was originally mostly used in relation to works of art but is now used in similar senses in a wide range of fields, including archaeology, paleontology, archives, manuscripts, printed books and science and computing. The primary purpose of tracing the provenance of an object or entity is normally to provide contextual and circumstantial evidence for its original production or discovery, by establishing, as far as practicable, its later history, especially the sequences of its formal ownership, custody and places of storage. The practice has a particular value in helping authenticate objects. Comparative techniques, expert opinions and the results of scientific tests may also be used to these ends, but establishing provenance is essentially a matter of documentation. The term dates to the 1780s in English. Provenance is conceptually comparable to the legal term \"chain of custody\".\n\nIn archaeology and paleontology, the derived term provenience is used with a related but very particular meaning, to refer to the location (in modern research, recorded precisely in three dimensions) where an artifact or other ancient item was found. \"Provenance\" covers an object's complete documented history. An artifact may thus have both a provenience and a provenance.\n\nThe provenance of works of fine art, antiques and antiquities is of great importance, especially to their owner. There are a number of reasons why painting provenance is important, which mostly also apply to other types of fine art. A good provenance increases the value of a painting, and establishing provenance may help confirm the date, artist and, especially for portraits, the subject of a painting. It may confirm whether a painting is genuinely of the period it seems to date from. The provenance of paintings can help resolve ownership disputes. For example, provenance between 1933 and 1945 can determine whether a painting was looted by the Nazis. Many galleries are putting a great deal of effort into researching the provenance of paintings in their collections for which there is no firm provenance during that period. Documented evidence of provenance for an object can help to establish that it has not been altered and is not a forgery, a reproduction, stolen or looted art. Provenance helps assign the work to a known artist, and a documented history can be of use in helping to prove ownership. An example of a detailed provenance is given in the Arnolfini portrait.\n\nThe quality of provenance of an important work of art can make a considerable difference to its selling price in the market; this is affected by the degree of certainty of the provenance, the status of past owners as collectors, and in many cases by the strength of evidence that an object has not been illegally excavated or exported from another country. The provenance of a work of art may vary greatly in length, depending on context or the amount that is known, from a single name to an entry in a scholarly catalogue some thousands of words long.\n\nAn expert certification can mean the difference between an object having no value and being worth a fortune. Certifications themselves may be open to question. Jacques van Meegeren forged the work of his father Han van Meegeren (who in his turn had forged the work of Vermeer). Jacques sometimes produced a certificate with his forgeries stating that a work was created by his father.\n\nJohn Drewe was able to pass off as genuine paintings, a large number of forgeries that would have easily been recognised as such by scientific examination. He established an impressive (but false) provenance and because of this galleries and dealers accepted the paintings as genuine. He created this false provenance by forging letters and other documents, including false entries in earlier exhibition catalogues.\n\nSometimes provenance can be as simple as a photograph of the item with its original owner. Simple yet definitive documentation such as that can increase its value by an order of magnitude, but only if the owner was of high renown. Many items that were sold at auction have gone far past their estimates because of a photograph showing that item with a famous person. Some examples include antiques owned by politicians, musicians, artists, actors, etc.\n\nThe objective of provenance research is to produce a complete list of owners (together, where possible, with the supporting documentary proof) from when the painting was commissioned or in the artist's studio through to the present time. In practice, there are likely to be gaps in the list and documents that are missing or lost. The documented provenance should also list when the painting has been part of an exhibition and a bibliography of when it has been discussed (or illustrated) in print.\n\nWhere the research is proceeding backwards, to discover the previous provenance of a painting whose current ownership and location is known, it is important to record the physical details of the painting – style, subject, signature, materials, dimensions, frame, etc. The titles of paintings and the attribution to a particular artist may change over time. The size of the work and its description can be used to identify earlier references to the painting. The back of a painting can contain significant provenance information. There may be exhibition marks, dealer stamps, gallery labels and other indications of previous ownership. There may also be shipping labels. In the BBC TV programme \"Fake or Fortune?\" the provenance of the painting \"Bords de la Seine à Argenteuil\" was investigated using a gallery sticker and shipping label on the back. Early provenance can sometimes be indicated by a \"cartellino\" (a representation of an inscribed label) added to the front of a painting. However, these can be forged, or can fade or be painted over.\n\nAuction records are an important resource to assist in researching the provenance of paintings. \n\nIf a painting has been in private hands for an extended period and on display in a stately home, it may be recorded in an inventory – for example, the Lumley inventory. The painting may also have been noticed by a visitor who subsequently wrote about it. It may have been mentioned in a will or a diary. Where the painting has been bought from a dealer, or changed hands in a private transaction, there may be a bill of sale or sales receipt that provides evidence of provenance. Where the artist is known, there may be a catalogue raisonné listing all the artist's known works and their location at the time of writing. A database of catalogues raisonnés is available at the International Foundation for Art Research. Historic photos of the painting may be discussed and illustrated in a more general work on the artist, period or genre. Similarly, a photograph of a painting may show inscriptions (or a signature) that subsequently became lost as a result of overzealous restoration. Conversely, a photograph may show that an inscription was not visible at an earlier date. One of the disputed aspects of the \"Rice\" portrait of Jane Austen concerns apparent inscriptions identifying artist and sitter.\n\nProvenance – also known as \"custodial history\" – is a core concept of archival science and archival processing. The term refers to the individuals, groups, or organizations that originally created or received the items in an accumulation of records, and to the items' subsequent chain of custody. The principle of provenance (sometimes also termed the principle of \"archival integrity\" or \"respect des fonds\") stipulates that records originating from a common source (or fonds) should be kept together – where practicable, physically; but in all cases intellectually, in the way in which they are catalogued and arranged in finding aids. Conversely, records of different provenance should be preserved and documented separately. In archival practice, proof of provenance is provided by the operation of control systems that document the history of records kept in archives, including details of amendments made to them. The authority of an archival document or set of documents of which the provenance is uncertain (because of gaps in the recorded chain of custody) will be considered to be severely compromised.\n\nThe principles of archival provenance were developed in the 19th century by both French and Prussian archivists, and gained widespread acceptance on the basis of their formulation in the \"Manual for the Arrangement and Description of Archives\" by Dutch state archivists Samuel Muller, J. A. Feith, and R. Fruin, published in the Netherlands in 1898 (often referred to as the \"Dutch Manual\").\n\nSeamus Ross has argued a case for adapting established principles and theories of archival provenance to the field of modern digital preservation and curation.\n\n\"Provenance\" is also the title of the journal published by the Society of Georgia Archivists.\n\nIn the case of books, the study of provenance refers to the study of the ownership of individual copies of books. It is usually extended to include study of the circumstances in which individual copies of books have changed ownership, and of evidence left in books that shows how readers interacted with them.\n\nProvenance studies may shed light on the books themselves, providing evidence of the role particular titles have played in social, intellectual and literary history. Such studies may also add to our knowledge of particular owners of books. For instance, looking at the books owned by a writer may help to show which works influenced him or her.\n\nMany provenance studies are historically focused, and concentrated on books owned by writers, politicians and public figures. The recent ownership of books is studied, however, as is evidence of how ordinary or anonymous readers have interacted with books.\n\nProvenance can be studied both by examining the books themselves (for instance looking at inscriptions, marginalia, bookplates, book rhymes, and bindings) and by reference to external sources of information such as auction catalogues.\n\nIn transactions of old wine with the potential of improving with age, the issue of provenance has a large bearing on the assessment of the contents of a bottle, both in terms of quality and the risk of wine fraud. A documented history of wine cellar conditions is valuable in estimating the quality of an older vintage due to the fragile nature of wine.\n\nRecent technology developments have aided collectors in assessing the temperature and humidity history or the wine which are two key components in establishing perfect provenance. For example, there are devices available that rest inside the wood case and can be read through the wood by waving a smartphone equipped with a simple app. These devices track the conditions the case has been exposed to for the duration of the battery life, which can be as long as 15 years, and sends a graph and high/low readings to the smartphone user. This takes the trust issue out of the hands of the owner and gives it to a third party for verification.\n\nArchaeology and anthropology researchers use \"provenience\" to refer to the exact location or find spot of an artifact, a bone or other remains, a soil sample, or a feature within an ancient site, whereas \"provenance\" covers an object's complete documented history. Ideally, in modern excavations, the provenience is recorded in three dimensions on a site grid with great precision, and may also be recorded on video to provide additional proof and context. In older work, often undertaken by amateurs, only the general site or approximate area may be known, especially when an artifact was found outside a professional excavation and its specific position not recorded. The term \"provenience\" appeared in the 1880s, about a century after \"provenance\". Outside of academic contexts, it has been used as a synonymous variant spelling of \"provenance\", especially in American English.\n\nAny given antiquity may have both a provenience (where it was found) and a provenance (where it has been since it was found). A summary of the distinction is that \"provenience is a fixed point, while provenance can be considered an itinerary that an object follows as it moves from hand to hand.\" Another metaphor is that provenience is an artifact's \"birthplace\", while provenance is its \"résumé\", though this is imprecise (many artifacts originated as trade goods created in one region but were used and finally deposited in another).\n\nAside from scientific precision, a need for the distinction in these fields has been described thus:\nIn this context, the \"provenance\" can occasionally be the detailed history of where an object has been since its creation, as in art history contexts – not just since its modern finding. In some cases, such as where there is an inscription on the object, or an account of it in written materials from the same era, an object of study in archaeology or cultural anthropology may have an early provenance – a known history that predates modern research – then a provenience from its modern finding, and finally a continued provenance relating to its handling and storage or display after the modern acquisition.\n\nEvidence of provenance in the more general sense can be of importance in archaeology. Fakes are not unknown, and finds are sometimes removed from the context in which they were found without documentation, reducing their value to science. Even when apparently discovered \"in situ\", archaeological finds are treated with caution. The provenience of a find may not be properly represented by the context in which it was found (e.g. due to stratigraphic layers being disturbed by erosion, earthquakes, or ancient reconstruction or other disturbance at a site. Artifacts can also be moved through looting as well as trade, far from their place of origin and long before modern rediscovery. Further research is often required to establish the true provenance of a find, and what the relationship is between the exact provenience and the overall provenance.\n\nIn paleontology and paleoanthropology, it is recognized that fossils can also move from their primary context and are sometimes found, apparently \"in-situ\", in deposits to which they do not belong because they have been moved, for example, by the erosion of nearby but different outcrops. It is unclear how strictly paleontology maintains the \"provenience\" and \"provenance\" distinction. For example, a short glossary at a website (primarily aimed at young students) of the American Museum of Natural History treats the terms as synonymous, while scholarly paleontology works make frequent use of \"provenience\" in the same precise sense as used in archaeology and paleoanthropology.\n\nWhile exacting details of a find's provenience are primarily of use to scientific researchers, most natural history and archaeology museums also make strenuous efforts to record how the items in their collections were acquired. These records are often of use in helping to establish a chain of provenance.\n\nScientific research is generally held to be of good provenance when it is documented in detail sufficient to allow reproducibility. Scientific workflow systems assist scientists and programmers with tracking their data through all transformations, analyses, and interpretations. Data sets are reliable when the process used to create them are reproducible and analyzable for defects. Current initiatives to effectively manage, share, and reuse ecological data are indicative of the increasing importance of data provenance. Examples of these initiatives are National Science Foundation Datanet projects, DataONE and Data Conservancy, as well as the U.S. Global Change Research Program. Some international academic consortia, such as the Research Data Alliance, have specific group to tackle issues of provenance. In that case it is the Research Data Provenance Interest Group.\n\nWithin computer science, informatics uses the term 'provenance' to mean the lineage of data, as per data provenance, with research in the last decade extending the conceptual model of causality and relation to include processes that act on data and agents that are responsible for those processes. See, for example, the proceedings of the International Provenance Annotation Workshop (IPAW) and Theory and Practice of Provenance (TaPP). Semantic web standards bodies, including the World Wide Web Consortium in 2014, have ratified a standard data model for provenance representation known as PROV which draws from many of the better-known provenance representation systems that preceded it, such as the Proof Markup Language and the Open Provenance Model.\n\nInteroperability is a design goal of most recent computer science provenance theories and models, for example the Open Provence Model (OPM) 2008 generation workshop aimed at \"establishing inter-operability of systems\" through information exchange agreements. Data models and serialisation formats for delivering provenance information typically reuse existing metadata models where possible to enable this. Both the OPM Vocabulary and the PROV Ontology make extensive use of metadata models such as Dublin Core and Semantic Web technologies such as the Web Ontology Language (OWL). Current practice is to rely on the W3C PROV data model, OPM's successor.\n\nThere are several maintained and open-source provenance capture implementation at the operating system level such as CamFlow, Progger for Linux and MS Windows, and SPADE for Linux, MS Windows, and MacOS. Other implementations exist for specific programming and scripting languages, such as RDataTracker for R, and NoWorkflow for Python.\n\n\nIn the geologic use of the term, provenance instead refers to the origin or source area of particles within a rock, most commonly in sedimentary rocks. It does not refer to the circumstances of the collection of the rock. The provenance of sandstone, in particular, can be evaluated by determining the proportion of quartz, feldspar, and lithic fragments (see diagram).\n\nSeed provenance refers to the specified area in which plants that produced seed are located or were derived. Local provenancing is a position maintained by ecologists that suggests that only seeds of local provenance should be planted in a particular area. However, this view depends on the adaptationist program – a view that populations are universally locally adapted. It is maintained that local seed is best adapted to local conditions, and that outbreeding depression will be avoided. Evolutionary biologists suggest that strict adherence to provenance collecting is not a wise decision because:\n\nProvenance trials, where material of different provenances are planted in a single place or at different locations spanning a range of environmental conditions, is a way to reveal genetic variation among provenances. It also contributes to an understanding of how different provenances respond to various climatic and environmental conditions and can as such contribute with knowledge on how to strategically select provenances for climate change adaptation.\n\nThe term \"provenance\" is used when ascertaining the source of goods such as computer hardware to assess if they are genuine or counterfeit. Chain of custody is an equivalent term used in law, especially for evidence in criminal or commercial cases.\n\nSoftware provenance encompasses the origin of software and its licensing terms. For example, when incorporating a free, open source or proprietary software component in an application, one may wish to understand its provenance to ensure that licensing requirements are fulfilled and that other software characteristics can be understood.\n\nData provenance covers the provenance of computerized data. There are two main aspects of data provenance: ownership of the data and data usage. Ownership will tell the user who is responsible for the source of the data, ideally including information on the originator of the data. Data usage gives details regarding how the data has been used and modified and often includes information on how to cite the data source or sources. Data provenance is of particular concern with electronic data, as data sets are often modified and copied without proper citation or acknowledgement of the originating data set. Databases make it easy to select specific information from data sets and merge this data with other data sources without any documentation of how the data was obtained or how it was modified from the original data set or sets.\nThe automated analysis of data provenance graphs has been described as a mean to verify compliance with regulations regarding data usage such as introduced by the EU GDPR.\n\nSecure Provenance refers to providing integrity and confidentiality guarantees to provenance information. In other words, secure provenance means to ensure that history cannot be rewritten, and users can specify who else can look into their actions on the object.\n\nA simple method of ensuring data provenance in computing is to mark a file as read only. This allows the user to view the contents of the file, but not edit or otherwise modify it. Read only can also in some cases prevent the user from accidentally or intentionally deleting the file.\n\n\nProvenance in book studies\n\n"}
{"id": "2786731", "url": "https://en.wikipedia.org/wiki?curid=2786731", "title": "Pseudoword", "text": "Pseudoword\n\nA pseudoword or non-word is a unit of speech or text that appears to be an actual word in a certain language, while in fact it has no meaning in the lexicon. It is a kind of non-lexical vocable.\n\nSuch words without a meaning in a certain language or no occurrence in any text corpus or dictionary can be the result of (the interpretation of) a truly random signal, there will usually be an underlying deterministic source as is the case for:\n\n\nWhen nonsensical words are strung together, gibberish may arise. Word salad in contrast may contain legible and intelligible words but without semantic or syntactic correlation or coherence.\n\nWithin linguistics, a pseudoword is defined specifically as respecting the phonotactic restrictions of a language. That is, it does not include sounds or series of sounds that do not exist in that language: it is easily pronounceable for speakers of the language. Also, when written down, a pseudoword does not include strings of characters that are not permissible in the spelling of the target language. \"Vonk\" is a pseudoword in English, while \"dfhnxd\" is not. The latter is an example of a nonword. Nonwords are contrasted with pseudowords in that they are not pronounceable and by that their spelling could not be the spelling of a real word.\n\nPseudowords are also sometimes called wug words in the context of linguistic experiments. This is because \"wug\" [wʌg] was one such pseudoword used by Jean Berko Gleason in her wug test 1958 experiments. Words like \"wug\", which could have been a perfectly acceptable word in English but isn't due to an accidental gap, were presented to children. The experimenter would then prompt the children to create a plural for \"wug\", which was almost invariably \"wugs\" [wʌgz]. The experiments were designed to see if English morphophonemics would be applied by children to novel words. They revealed that even at a very young age, children have already internalized many of the complex features of their language.\n\nA logatome is a short pseudoword or just a syllable which is used in acoustic experiments to examine speech recognition.\n\nA logatome or nonsense syllable is a short pseudoword consisting most of the time of just one syllable which has no meaning of its own. Examples of English logatomes are the nonsense words \"snarp\" or \"bluck\".\n\nLike other pseudowords, logatomes obey all the phonotactic rules of a specific language.\n\nLogatomes are used in particular in acoustic experiments. They are also used in experiments in the psychology of learning as a way to examine speech recognition. and in experimental psychology, especially the psychology of learning and memory.\n\nNonsense syllables were first introduced by Hermann Ebbinghaus in his experiments on the learning of lists. His intention was that they would form a standard stimulus so that experiments would be reproducible. However, with increasing use it became apparent that different nonsense syllables were learned at very different rates, even when they had the same superficial structure. Glaze introduced the concept of association value to describe these differences, which turned out to be reliable between people and situations. Since Glaze's time, experiments using nonsense syllables typically control association value in order to reduce variability in results between stimuli.\n\nNonsense syllables can vary in structure. The most used are the so-called CVC syllables, composed of a consonant, a vowel, and a consonant. These have the advantage that nearly all are pronounceable, that is, they fit the phonotactics of any language that uses closed syllables, such as English and German. They are often described as \"CVC trigrams\", reflecting their three-letter structure. Obviously many other structures are possible, and can be described on the same principles, e.g. VC, VCV, CVCV. But the CVC trigrams have been studied most intensively; for example, Glaze determined association values for 2019 of them.\n\nThe term nonsense syllable is widely used to describe non-lexical vocables used in music, most notably in scat singing but also in many other forms of vocal music. Although such usages do not invoke the technical issues about structure and associability that are of concern in psychology, the essential meaning of the term is the same.\n\n"}
{"id": "52898110", "url": "https://en.wikipedia.org/wiki?curid=52898110", "title": "Queer of color critique", "text": "Queer of color critique\n\nQueer of color critique is a methodology that recognizes the intersections of race, gender, class, sexuality, capital, and nation, and disidentifies with the universality of social categories present in canonical sociology and historical materialism. Roderick Ferguson is credited with coining this term in his 2004 book \"Aberrations in Black, \"and draws from woman of color feminism, postcolonial studies, queer theory and African American studies. In his critique of canonical sociology, Ferguson argues that racialized heteronormativity and heteropatriarchy has played a conspicuous role in shaping sociology and social policy, and recognizes its intersection with revolutionary nationalism. Queer of color critique operates as a method for building unlikely coalitions across different identity categories. In framing queer of color critique, Ferguson draws from Barbara Smith and the Combahee River Collective's use of coalitional politics to address gender, race, and sexuality in context with capitalist expansion.\n\nQueer of color critique has been taken up by multiple scholars as an attempt at a more intersectional framework on which to build and extend their work in various, sometimes intersecting academic subjects.\n\nThough most references at the intersection of queerness and indigeneity fall on Two-Spirit identity and ideas surrounding it, queer of color critique extends the discussion to settler colonialism, future potentialities of Native identity and life, and general discourse about how Native Studies as an academic study can benefit from a sort of \"queering\". According to scholar Andrea Smith, looking at indigeneity from this perspective questions the limitations of a \"subjectless\" or \"postidentity\" analysis in regards to the shedding of a particular ethnic identity, which in itself has roots in colonialist and nationalist ideology. On the other hand, even this sort of critique does not fully acknowledge the extent of the absence of indigeneity in the context of direct and indirect investment in settler colonialism by those of color doing the critiquing.\n\nThe unraveling of colonialist ideology,—the belief in a normative society—according to scholar Emma Perez, is necessary to fully understand national histories and identities, specifically of queer individuals.\n\nQueer diasporic critique can be considered an extension of and complement to queer of color critique in that it considers ethnic and cultural identity as an underlying context when analyzing and critiquing arguments based on Eurocentric, white centered queer theories, as well as critiquing the heteronormativity of area studies. Oftentimes, these ideas are connected to ideas of nationhood and national identity. In the words of scholar Gayatri Gopinath, \"While both queer of color and queer diasporic analysis are part of a collective endeavor to reshape queer studies through a thorough engagement with questions of race, nationalism, and transnationalism, it may also be useful to explore some of the points at which the interventions and emphases of each project both intersect and diverge.\" In this respect, critique emphasizing diaspora tends to focus more on a \"global restructuring of capital and its attendant gender and sexual hierarchies\" and the creation of \"home\" in regards to diaspora and transnationalism.\n\nAn example of queer of color critique in practice can be seen in the analysis of queer Muslims in Europe done by scholar Fatima El-Tayeb, which touches on the larger themes explored in queer theory. Among these is the idea of \"coming-out\" as a person of diaspora, which challenges the currently held notion of its role in the creation of a \"normative, healthy and desirable LGBT identity\". Another describes how the idea of Islamophobia permeates into the intersectional oppressions faced by queer Muslims in the west. The ideas of migration and \"home\" are also critiqued in that the ethnic migrant laborer lives amongst an \"increasingly segregated, criminalized and policed multi-ethnic population of color\". These queer diasporic and queer of color critiques therefore act as a lens through which to view homonormativity and the various facets through which is functions.\n\nAs a type of community manifestation of this type of critique, the queer of color activist group takes an intersectional, colored approach to queer activism. This helps undermine binaries such as the \"Muslim/European dichotomy to the normative coming out narrative\", which, according to El-Tayeb, perpetuate homonormativity and racism.\n\nSome notable scholars who have incorporated queer of color critique into their work are Roderick Ferguson, Jesus Values-Morales, Andrea Smith, Gayatri Gopinath, Fatima El-Tayeb, Martin Manalansan IV, Juana María Rodríguez, José Esteban Muñoz, Emma Perez, Edward Brockenbrough, Salvador Vidal-Ortiz, Amy Villarejo, Jasbir Puar, Scott Lauria Morgensen, Kevin K. Kumashiro, Lawrence La Fountain-Stokes, Chandan Reddy, Jennifer C. Nash, and others.\n\n"}
{"id": "9235009", "url": "https://en.wikipedia.org/wiki?curid=9235009", "title": "Records of Early English Drama", "text": "Records of Early English Drama\n\nThe Records of Early English Drama (REED) is a performance history research project, based at the University of Toronto, Ontario, Canada. It was founded in 1976 by a group of international scholars interested in understanding “the native tradition of English playmaking that apparently flourished in late medieval provincial towns” and formed the context for the development of the English Renaissance theatre, including the work of Shakespeare and his contemporaries. REED’s primary focus is to locate, transcribe, edit, and publish historical documents from England, Wales, and Scotland containing evidence of drama, secular music, and other communal entertainment and mimetic ceremony from the late Middle Ages until 1642, when the Puritans closed the London public theatres. \n\nFrom its inception in 1976 to 2016, REED published twenty-seven print collections of records edited by over thirty international scholars. REED is also engaged in creating a collection of free digital resources for research and education including \"Patrons and Performances\" (2003) and \"Early Modern London Theatres\" (2011). In March 2017, REED moved to digital publication of records with the launch of \"REED Online\", a publication site where records will be freely available. \n\nDuring a 1970-71 research trip in York, England, to study manuscripts related to the York cycle of biblical plays (also known as the York Mystery Plays), Alexandra F. Johnston, an early drama scholar from the University of Toronto, came across a manuscript transcription of a 1433 indenture agreement between the leaders of the medieval Mercers' Guild and their pageant masters. The document contained details of a medieval pageant wagon and sophisticated staging unknown to researchers of the time. Johnston also met Margaret Dorrell, an Australian graduate student at the University of Leeds, who was working on a similar project related to the York records; the two women decided to collaborate.\n\nWithin the next two years, Johnston and Dorrell met other scholars of medieval and Renaissance drama working independently on manuscripts from other English cities (David Galloway of the University of New Brunswick on Norwich, Reginald Ingram of the University of British Columbia on Coventry, and Lawrence Clopper of Indiana University Bloomington on Chester). The idea of a scholarly publishing project to find, transcribe, and edit documentary evidence of performance arose from these meetings and was met with interest by the individual researchers and their academic communities. \n\nIn January 1974, Johnston circulated a position paper on the project. Discussions and planning followed and, in February 1975, the inaugural REED meeting was held at Victoria University in the University of Toronto. In 1975-76, Johnston received a Canada Council personal grant for the publication of the York records as a pilot project, and in late 1976, REED was officially launched with a Canada Council ten-year Major Editorial Grant for the proposed series of collections, establishing REED as a long-term research and publishing project. Because three of the four initial collections were edited by Canadian researchers, Toronto, Canada, became the home of the project. \n\nIn 1979, REED published its first two collections of records: York, edited by Alexandra F. Johnston and Margaret Rogerson (née Dorrell), and Chester, edited by Lawrence D. Clopper. Since then the project has expanded its scope from major cities and towns to all the counties of England, Wales, and Scotland, based on historic pre-1642 county borders.\n\nAfter its inception in 1976, REED produced the bi-annual \"REED Newsletter\" which, in 1997, became the refereed scholarly journal \"Early Theatre\". \n\nREED has had close ties to the English Department, the Centre for Medieval Studies (CMS), the Centre for Reformation and Renaissance Studies (CRRS), and the Graduate Centre for Study of Drama. From 1976 to 2009 the project was based at Victoria University in the University of Toronto. In 2009 the offices of the project moved to the English Department. REED retains active relationships with the English Department, the CMS, and the University of Toronto Libraries. REED’s internal governance is provided by an Executive Board of senior scholars in early drama and related fields, with digital advisors and collections editors drawn from Canada, the United States, Australia, New Zealand, and the United Kingdom. \n\nREED has collaborated with the Poculi Ludique Societas (PLS) to mount four productions of full cycles of medieval biblical dramas: the \"York Plays\" (also called the York Mystery Plays) in 1977 and 1998, and the \"Chester Plays\" (also called the Chester Mystery Plays) in 1983 and 2010, with participation from international amateur theatre groups.\n\nIn November 2002, REED, in partnership with the Art Gallery of Ontario, hosted the Picturing Shakespeare symposium, an exhibition of and an accompanying public symposium regarding the Sanders portrait, an Elizabethan painting reputed to be the only one of Shakespeare made during his lifetime.\n\nIn addition to revealing evidence of vernacular entertainment activities, the research work for the collections produces a body of knowledge regarding professional travelling entertainers, their patronage, and their performance venues. This cumulative information was first launched for public use through the Patrons and Performances website in 2003. \n\nIn 2011, REED collaborated with the Department of Digital Humanities, King's College London, and the Department of English at the University of Southampton to create \"Early Modern London Theatres\" (\"EMLoT\"), a research database and educational resource, with learning modules. \"EMLoT\" gathers documents related to professional theatres north and south of the Thames up to 1642 and bibliographic information about their subsequent transcriptions, documenting how scholars “got [their] information about the early theatres, from whom and when.”\n\nIn 2016, to mark the 400th anniversary of Shakespeare’s death, REED collaborated with the BBC and The British Library to produce an ongoing public website titled Shakespeare on Tour. Many REED editors contributed stories and images from their research in the Elizabethan period to help raise “the curtain on performances of The Bard’s plays countrywide from the 16th Century to the present day.” \n\nThroughout its existence, REED maintained its primary focus and published about six collections each decade. In 2015, REED published its last print collection (\"Civic London to 1558\", edited by Anne Lancashire), and in March 2017, the first digital collection (\"Staffordshire\", edited by Alan B. Somerset) was made freely available on its publication website, \"REED Online\". All subsequent collections will be added to this database and website.\n\nREED has received substantial funding from private individuals and foundations (including the Jackman Foundation), the Canada Council, and the Social Sciences and Humanities Research Council in Canada; the National Endowment for the Humanities and the Andrew W. Mellon Foundation in the U.S.; as well as the Arts and Humanities Research Council and The British Academy in the U.K.\n\n\n"}
{"id": "47687243", "url": "https://en.wikipedia.org/wiki?curid=47687243", "title": "Reyhan (script)", "text": "Reyhan (script)\n\nReyhan () is one of the six canonical scripts of Perso-Arabic calligraphy. The word Reyhan means basil in Arabic and Persian. Reyhan is a variant of the Muhaqqaq script, but it is finer than Muhaqqaq, likened to flowers and leaves of basil. It was developed during the Abbasid era by Ibn al-Bawwab. \n"}
{"id": "11107956", "url": "https://en.wikipedia.org/wiki?curid=11107956", "title": "Script typeface", "text": "Script typeface\n\nScript typefaces are based upon the varied and often fluid stroke created by handwriting. They are generally used for display or trade printing, rather than for extended body text in the Latin alphabet. Some Greek alphabet typefaces, especially historically, have been a closer simulation of handwriting.\n\nScript typefaces are organized into highly regular formal types similar to cursive writing and looser, more casual scripts.\nA majority of formal scripts are based upon the letterforms of seventeenth and eighteenth century writing-masters like George Bickham, George Shelley and George Snell. The letters in their original form are generated by a quill or metal nib of a pen. Both are able to create fine and thick strokes. Typefaces based upon their style of writing appear late in the eighteenth century and early nineteenth century. Contemporary revivals of formal script faces can be seen in Kuenstler Script and Matthew Carter's typeface Snell Roundhand. These typefaces are frequently used for invitations and diplomas to effect an elevated and elegant feeling. They may use typographic ligatures to have letters connect. \nCasual scripts show a less formal, more active hand. The strokes may vary in width but often appear to have been created by wet brush rather than a pen nib. They appear in the early twentieth century and with the advent of photocomposition in the early-1950s their number rapidly increased. They were popularly used in advertising in Europe and North America into the 1970s. Examples of casual script types include Brush Script, Kaufmann and Mistral. Some may be non-connecting. \n\nScript typefaces place particular demands on printing technology if the letters are intended to join up and vary like handwriting. A typeface intended to mimic handwriting, such as Claude Garamond's grecs du roi typeface, will require many alternate characters. In digital type these (once drawn) can be substituted seamlessly through contextual ligature insertion in applications like InDesign, but this was complicated in metal. Another complexity in metal type was that sorts had to have delicate overhanging parts to interlock. This required careful design and casting for the sorts to fit together without gaps or the sorts breaking, or leaving gaps to be filled in by the natural spread of ink on paper.\n\nScript typefaces have evolved rapidly in the second half of the 20th century due to developments in technology and the end of widespread use of metal type. Historically, most signwriting on logos, displays and shop frontages did not use fonts but was rather custom-designed lettering created by signpainters and engravers. As phototypesetting and then computers have made printing text at a range of sizes far easier than in the metal type period, it has become increasingly common for businesses to use type for logos and signs rather than hand-drawn lettering. In addition, phototypesetting made overlap of characters relatively simple, something very complicated to achieve in metal type. Matthew Carter has cited his 1966 Snell Roundhand typeface as deliberately designed to replicate a style of calligraphy hard to simulate in metal. An additional development enabling more sophisticated script fonts has been the release of the OpenType format, which most fonts are now released in. This allows fonts to have a large character set, increasing the sophistication of design possible, and contextual insertion, in which characters that match one another are inserted into a document automatically, so fonts can convincingly mimic handwriting without the user having to choose the correct substitute characters manually. Many modern script typefaces emulate the styles of hand-drawn lettering from different historical periods.\n\nIn Unicode there is a script Latin alphabet for mathematical use, with both capital and small letters. Few fonts provide support for all 52 characters, and their presentations vary in style from roundhand to chancery hand and others. \n\nThese characters are listed here: \n\n\n\n"}
{"id": "33692006", "url": "https://en.wikipedia.org/wiki?curid=33692006", "title": "Shared historical authority", "text": "Shared historical authority\n\nShared historical authority is a current trend in museums and historical institutions which aims to open the interpretation of history to the public.\n\nThe concept of shared historical authority is defined by the premise that traditional institutions of historical authority, such as museums and historical societies, are increasingly inviting non-professionals (the general public) to share their historical viewpoints and experiences with the public. It is argued that this trend toward sharing authority is changing the nature of public historical experience in significant ways. Shared authority removes the hierarchy commonly practiced within cultural institutions. Moving away from a top down approach, shared authority is geared towards collaboration that includes dialogue, and participatory engagement. \n\nTypical examples of shared historical authority include:\n\nIn each case the institution serves as a catalyst for non-traditional participants to contribute to a body of information presented to the public. The institution uses its resources - e.g. staff expertise, collections, public space - to help non-traditional participants share their contributions in publicly accessible and engaging ways. At its most basic, shared authority turns people who would otherwise be historical consumers (visitors and audiences) into participants and co-generators of historical content for public display. Museums who coordinate programs that share historical authority often wish to imbue a sense of democratization to the historical narrative, in contrast to the top-down historical narratives that sometimes emerge in museums. In addition, shared authority projects frequently try to involve communities who have traditionally been disenfranchised or underrepresented in historical narratives and institutions, providing a platform for alternative voices to engage in a public historical dialogue. The role of shared historical authority continues to be debated in the field of public history.\n\nThe need for museums and other historical institutions to \"share authority\" with their audiences and surrounding communities is rooted in the ideologies of New Social History and social constructivism. Both paradigms reject the concept of a \"master narrative\" for describing historical events, finding it an inadequate method for representing the multiple experiences and perspectives of individuals involved. Arising from the work of folklorists such as John Lomax and Alan Lomax, New Deal-era Works Progress Administration (WPA) programs such as the Federal Writers' Project and the work of Studs Terkel, the social history movement of the 1960s placed new academic emphasis on the experiences of people not represented in traditional or \"official\" historical narratives, and gave further impetus to projects focused on collecting and sharing those experiences.\n\nMichael Frisch, a professor at the University at Buffalo, The State University of New York, popularized the term \"shared authority\" in his 1990 book \"A Shared Authority: Essays on the Craft and Meaning of Oral and Public History.\" In recent years, Frisch has distinguished between \"sharing authority\" and \"\"a\" shared authority.\" The former suggests that historians possess authority and have a responsibility to share it, reinforcing a traditional, top-down view of history. \"A shared authority\", by contrast, recognizes that traditional historical authorities and the public share in the interpretive and meaning-making process \"\"by definition\".\"\n\nBeginning in the early 2000s, the proliferation of Web 2.0 technologies that allow users to easily create and share content on digital platforms offered historical institutions a variety of new tools to facilitate public participation.\n\nOther examples of shared historical authority include StoryCorps, City of Memory, and Philaplace, an internet based neighborhood history project produced by the Historical Society of Philadelphia that combines scholarly essays with stories from anyone who cares to submit one. Staff members then curate the submitted stories. Dennis Severs House is a historic townhouse in London (18 Folgate St.) that was restored by Dennis Severs. The house is filled with historic objects alongside modern touches, sound clips of carriages and crying babies, and plates of real food set out each day by the staff. Visitors are encouraged to roam the house on their own, sit down on the furniture, interact with other visitors and draw their own conclusions. The experience is meant to blur the lines between art and history.\n\nThe Lower East Side Tenement Museum is the first museum to focus on the lives of urban, immigrant tenement dwellers. It shares authority by inviting the families of former residents to contribute objects, photographs, documents, interviews and oral histories to the museum tours. Part of the museum's mission is to address today's immigrant issues. This provides another avenue for sharing authority through public programs that connect speakers with varied backgrounds to public audiences. The museum invites sharing on one of its tours, \"Sweatshop Workers\", with the words:\n\nOpen House: If These Walls Could Talk is an exhibition that was produced by the Minnesota Historical Society in 2006. The exhibition traced the stories of families in a single house in St. Paul, Minnesota between 1888 and 2006. The curators did not want to show patterns or people as part of aggregate groups. Instead, they chose to emphasize singularity and individuality. To accomplish this, the Minnesota Historical Society built a house for visitors to walk through. Instead of reading large panels of wall texts, visitors had to interact with objects to hear, read, or see information. Unlike projects in which the content is produced in conjunction with a group of community members, here authority was shared at the level of narrative creation. Curators controlled the objects in the house, recordings of former residents, and the setup of the space. Without an overarching structure, visitors could wander through at random, co-creating their own narratives. There was no clear beginning and end beyond entering and exiting the house.\n\nThe Black Bottom Performance Project is a partnership between the University of Pennsylvania and residents of Black Bottom, an historically black neighborhood destroyed by urban renewal policies and the University of Pennsylvania's expansion in the 1960s. Billy Yalowitz, a theater professor working at the university, invited Penn students as well as student and teacher partners from University City High School—a school built in the former Black Bottom neighborhood—and former residents of the neighborhood to work together on the telling of the neighborhood's history, ultimately creating \"Black Bottom Sketches\" in 1998.\n\nThe Wing Luke Museum is an example of a museum in which shared authority is a core component of its programming policies.\n\nDespite the interest and affirmation that sharing authority is currently receiving in museum and public humanities circles, there are scholars and practitioners who criticise the practice. Generally, these criticisms are aimed at one of two levels. First, some scholars suggest that the phrase itself is wrong. \"Sharing authority\" implies that the process is something museums/archives do rather than something that just \"is.\" In his essay for \"Letting Go?\", Michael Frisch suggests that a more appropriate formulation of the concept is \"a shared authority.\"\n\nScholars and artists also worry that sharing authority devalues the hard-won expertise of professionals. The artist Fred Wilson, whose 1992-1993 exhibit \"Mining the Museum\" at the Maryland Historical Society is considered a landmark moment in museums' assessments of their role as historical arbiters, has expressed, \"I don't think people should share authority to the degree that you devalue your own scholarship, your own knowledge. That's not sharing anything. You're not giving what you have. That is highly problematic. You have to be realistic about your years of experience, what you can give, and what others can give.\"\n\n\n"}
{"id": "38686487", "url": "https://en.wikipedia.org/wiki?curid=38686487", "title": "Silver Gavel Award", "text": "Silver Gavel Award\n\nThe Silver Gavel Award (also known as the ABA Silver Gavel Awards for Media and The Arts) is an annual award the American Bar Association gives to honor outstanding work by those who help improve comprehension of jurisprudence in the United States.\n\nThe award is the American Bar Association's highest form of recognition. The American Bar Association gives out the award during its annual meeting, bestowing one award in each of several categories. Decisions on award recipients are announced by the chairman of the American Bar Association's standing committee on gavel awards. In a comment in the \"ABA Journal\", American Bar Association Division for Public Education representative Howard Kaplan noted, \"From the very beginning, the Association has recognized that legal drama has an unmatched capacity to humanize legal actors and, well, dramatize legal issues for public audiences.\"\n\nThe Bar Association gave the first award in 1958. The film directed by Sidney Lumet, \"12 Angry Men\", received the award in 1958. Stanley Kramer's movie \"Judgment at Nuremberg\" received the award in 1962, and \"To Kill a Mockingbird\" directed by Robert Mulligan was recognized with the award in 1963. In 1985, 391 candidates were entered in consideration to receive a Silver Gavel. In addition to 15 honorees recognized with Silver Gavel Awards in 1987, the American Bar Association also handed out 20 Certificates of Merit. In 1988, 298 organizations submitted 500 candidates for consideration for the Silver Gavel. A total of 12 awards were given out in 1996, in categories including literary works, pieces written in periodicals, journalism, plays, and writing for the screen. The 51st Silver Gavel Awards were announced by American Bar Association president William H. Neukom in Washington, D.C. at the National Press Club and included honorees \"The Denver Post\", \"The Dallas Morning News\", and Jeffrey Toobin for his book \"\". In 2011 Judge Jean Hudson Boyd was the first woman to receive the award.\n\n\"The News & Observer\" noted, \"The ... Silver Gavel Awards are considered the premier honors for law-related publications and productions.\" The \"Pittsburgh Post-Gazette\" characterized the honor as the \"top media award\" of the American Bar Association.\n\n"}
{"id": "36315801", "url": "https://en.wikipedia.org/wiki?curid=36315801", "title": "Social artistry", "text": "Social artistry\n\nSocial artistry is the attempt to address or recognize a particular social issue using art and creativity. Social artists are people who use creative skills to work with people or organizations in their community to affect change. While a traditional artist uses their creative skills to express their take on the world, a social artist puts their skills to use to help promote and improve communities. Thus, the main aim of a social artist is to improve society as a whole and to help other people find their own means of creative expression.\n\nSocial artists may address issues such as youth alienation or the breakdown of communities. Most commonly, social artists will address these problems by helping people express themselves and find their voice, or by bringing people together and using art to help them to foster an understanding of each other.\n\nSocial artistry can incorporate several different art forms including theatre, poetry, music and visual art. \n\nFindings from 2013 confirm the shift from individual expression to community engagement, or \"from autonomous to socially engaged.\" Lingo and Tepper cite several examples:\n\n"}
{"id": "40833540", "url": "https://en.wikipedia.org/wiki?curid=40833540", "title": "Social network (sociolinguistics)", "text": "Social network (sociolinguistics)\n\nIn the field of sociolinguistics, social network describes the structure of a particular speech community. Social networks are composed of a \"web of ties\" (Lesley Milroy) between individuals, and the structure of a network will vary depending on the types of connections it is composed of. Social network theory (as used by sociolinguists) posits that social networks, and the interactions between members within the networks, are a driving force behind language change.\n\nThe key participant in a social network is the \"anchor\", or center individual. From this anchor, ties of varying strengths radiate outwards to other people with whom the anchor is directly linked. These people are represented by \"points\". Participants in a network, regardless of their position, can also be referred to as \"actors \"or \"members\".\n\nThere are multiple ways to describe the structure of a social network. Among them are \"density, member closeness centrality, multiplexity, \"and\" orders\". These metrics measure the different ways of connecting within of a network, and when used together they provide a complete picture of the structure of a particular network.\n\nA social network is defined as either \"loose\" or \"tight\" depending on how connected its members are with each other, as measured by factors like density and multiplexity. This measure of tightness is essential to the study of socially motivated language change because the tightness of a social network correlates with lack of innovation in the population's speech habits. Conversely, a loose network is more likely to innovate linguistically.\n\nThe density of a given social network is found by dividing the number of all existing links between the actors by the number of potential links within the same set of actors. The higher the resulting number, the more dense a network is. Dense networks are most likely to be found in small, stable communities with few external contacts and a high degree of social cohesion. Loose social networks, by contrast, are more liable to develop in larger, unstable communities that have many external contacts and exhibit a relative lack of social cohesion.\n\nMember closeness centrality is the measurement of how close an individual actor is to all the other actors in the community. An actor with high closeness centrality is a central member, and thus has frequent interaction with other members of the network. A central member of a network tends to be under pressure to maintain the norms of that network, while a peripheral member of the network (one with a low closeness centrality score) does not face such pressure. Therefore, central members of a given network are typically not the first members to adopt a linguistic innovation because they are socially motivated to speak according to pre-existing norms within the network.\n\nMultiplexity is the number of separate social connections between any two actors. It has been defined as the \"interaction of exchanges within and across relationships\". A single tie between individuals, such as a shared workplace, is a uniplex relationship. A tie between individuals is multiplex\" \"when those individuals interact in multiple social contexts. For instance, A is B's boss, and they have no relationship outside of work, so their relationship is uniplex. However, C is both B's coworker and neighbor, so the relationship between B and C is multiplex, since they interact with each other in a variety of social roles.\n\nOrders are a way of defining the place of a speaker within a social network. Actors are classified into three different zones\nA \"first order zone\" is composed of all individuals that are directly linked to any given individual. The first order zone can also be referred to as the \"interpersonal environment\" or \"neighborhood\". A first order member of a network is an actor who has a large number of direct connections to the center of the network.\nA \"second order zone\" is a grouping of any individuals who are connected to at least one actor within the first order zone. However, actors in the second order zone are not directly connected to the central member of the network. A second order member has a loose or indirect connection to the network, and may only be connected to a certain network member.\nA \"third order zone\" is made up of newly observed individuals not directly connected to the first order zone. Third order members may be connected to actors in the second order zone, but not the first. They are peripheral members of the network, and are often the actors with the lowest member closeness centrality, since they may not have frequent contact with other members of the network.\n\nSocial networks are used in sociolinguistics to explain linguistic variation in terms of community norms, rather than broad categories like gender or race. Instead of focusing on the social characteristics of speakers, social network analysis concentrates on the relationships between speakers, then considers linguistic change in the light of those relationships. In an effort to depart from variationist sociolinguistics, the concept of the social network has been used to examine the links between the strength of network ties and the use of a linguistic variant. This allows researchers to create an accurate picture of a community's language use without resorting to stereotypical classification.\n\nThe concept of social networks is applicable at both the macro and micro levels. Social networks are at work in communities as large as nation-states or as small as an online dating service. They can also be applied to intimate social groups such as a friendship, family unit, or neighborhood. Because even the smallest of networks contains an enormous number of potential connections between actors, sociolinguists usually only study small networks so that the fieldwork is manageable. In fact, even when studying small networks, sociolinguists rely on the metrics outlined in the previous section, rather than mapping the network out, one connection at a time. One way of mapping the general structure of a network is to assign a \"strength scale\" to each speaker. For example, in Lesley Milroy's study of social networks in Belfast, Northern Ireland, the researchers measured five social variables, which together generated a strength scale for each member of the network: \nThe allocation of a network strength score allows the network patterns of individuals to be measured and possible links with linguistic patterns to be tested.\n\nIn recent years, computer simulation and modeling have been used to study social networks from a broader perspective. Because previous social network studies were focused on individual connections, the size of the networks were limited so that the researcher could work personally with subjects. With the rise of advanced computer modeling techniques, sociolinguists have been able to study the linguistic behavior of large networks of individuals over long periods of time without the inconvenience of individually working with thousands of subjects.\n\nAdvances in computer simulation and modeling technology have been used to study social networks on a larger scale, both with more participants and over a greater span of time. Previous social network studies had to examine individual connections in great detail, and so had to limit the size of the networks involved. Linguists working in the field were also unable to accurately pinpoint the causes of linguistic change because it tends to occur slowly over a long period of time, on a scale beyond the scope of a single research project. With the rise of computer modeling, sociolinguists have been able to study the linguistic behavior of large networks without the huge expenditure of time required to individually work with thousands of subjects long-term. The pioneering study in this field was Fagyal et al. in 2011.\n\nBecause social networks investigate the forces that impact individual behavior, rather than simply attributing linguistic difference to social class, a theory of language change based on social networks is able to explain linguistic behavior more deeply than variationist sociolinguistics. The two major findings of social network theory are that dense (highly interconnected) networks are resistant to change, and that most linguistic change is initiated by weak links—people who are not centrally connected to the network in question. Though most sociolinguistics working on social networks agree on these findings, there has been extended debate about which actors in the network are the primary drivers of linguistic change. The results of this debate are two theories, the strong-tie theory, and the weak-tie theory.\n\nThis study demonstrated that actors chose to imitate other (more prestigious) actors who embodied desirable social attributes, especially \"toughness\" as exemplified by urban students. This imitation of desirable qualities indicates that strongly connected agents lead change by spreading norms through network members. In Eckert's study of speech norms in Detroit high schools, she notes that suburban youth adopted the speech traits of urban youth (including a diphthongized and lowered [i]).\n\nLabov's 1986 study of Philadelphia speech communities (a term used before \"social networks\" became widespread) demonstrated that the agents of linguistic change were the leaders of the speech communities. Actors with high levels of prestige in the linguistic led the use of these forms, and enforced them as norms within the community. Members of this network then used the forms normalized within the network outside of the network, and continuous usage led to wide adoption of these speech norms.\n\nTakeshi Sibata's 1960 study of elementary school children provides strong support for the view that insiders, or leaders, in a social network facilitate language change. He interviewed several elementary school children, and taught them some invented words he created for the purpose of this study. After teaching the students these words, and telling them to teach the other students these words, he came back a week later to observe the results. A few children, those who were popular, friendly, cheerful, active in class activities, were the main people who spread those words. As the centers of their respective networks, these children functioned as strong-tie leaders of linguistic change.\n\nLabov's 1966 study of African American Vernacular English in South Harlem, revealed that second-order actors in African American social networks were the initiators of linguistic change in their communities. Though these second-order actors, or \"lames\" were not held in high regard by the leaders of the speech network, they had connections to other networks, and were sources of new linguistic variables. This study served as the basis of the \"Weak Tie Theory\" proposed by Milroy and Milroy.\n\nThis Milroy and Milroy study examined vernacular English as it was spoken in inner-city Belfast in the 1970s, in three working class communities in Belfast: those in the Ballymacarrett area, the Hammer area, and the Clonard area. Milroy took part in the life of each community as an acquaintance, or 'friend of a friend', investigating the correlation between the integration of individuals in the community and the way those individuals speak.\n\nEach individual studied was given a network strength score based on the person's knowledge of other people in the community, the workplace and at leisure activities to give a score of 1 to 5, with 5 being the highest network 'strength score'. Out of the five variables, one measured density, while the other four measured multiplexity.\n\nEach person's use of phonological variables, (ai), (a), (l), (th), (ʌ), (e), which were clearly indexical of the Belfast urban speech community, were then measured. The independent variables for this study were age, sex and location. These linguistic variables made up the dependent variable of the study, and were analyzed in relation to the network structure and background of each individual speaker. Deviation from the regional standard was determined by density and multiplicity of the social networks into which speakers are integrated.\n\nThe researchers found that a high network strength score was correlated with the use of vernacular forms, and therefore that the use of vernacular variants was strongly influenced by the level of integration into a network. The conclusion of the study was that close-knit networks are important for dialect maintenance.\n\nThis 1987 study, also conducted by Milroy, examined the variable [u], and its relationship to working class identity. The researchers found that actors with the weakest tie to this community identity were most likely to use the variable [u], possibly as a way to strengthen their ties to the network.\n\nIn Ballymacarrett, one of the villages the researchers surveyed, unrounded [u] was most often used by young males and females, who had weak ties to the working class networks, but use the variables frequently to project an image of working-class toughness. These young people often interacted with members of other social networks, and thus spread the [u] realization through their own social networks, which resulted in the adoption of unrounded [u] in most of Belfast. These results provide support for the weak tie theory of language change, because it was the actors on the peripheries of social networks who were responsible for spreading linguistic change. \n\nOne key study that employed computer simulations was Fagyal, Swarup, Escobar, Gasser, and Lakkarajud's work on the roles of group insiders (leaders) and outsiders (loners) in language change. The researchers found that both first-order and second-order network members (also known as \"leaders\" and \"loners\") were both needed in order for changes to spread predictably within the network.\n\nIn this study, the researchers simulated a social network of 900 participants, called nodes, which were connected into a network using a matrix algorithm. They then randomly assigned a linguistic variant to each node. On each cycle of the algorithm, every node interacted with another node, and the variant assigned to each node changed randomly depending on which variant the other node had. This cycle was repeated 40,000 times, and at the end of each cycle, the variant connected to each node was recorded.\n\nThe results of the Fagyal et al. study indicated that \"in a large, socially heterogenous population\", one linguistic variant eventually became the community norm, though other variants were not entirely eliminated. However, when the researchers manipulated the network to remove either loners or leaders, the results changed: without loners, one variant rapidly caused the loss of all other variants; and without leaders, no single variant became the norm for a majority of speakers.\n\nThese findings allowed the researchers to address the major debate in social network theory: whether it is leaders (or centers) or loners who are responsible for language change. In their findings, the presence of both leaders and loners was essential, though the two types of agents played different roles in the process of change.\n\nRather than introducing entirely new forms, leaders accelerate the adoption of forms that already exist within the network. Conversely, the researchers describe the loners' role this way: \"when loners are a part of a population structure that allows their influence to reach centrally-connected hubs, they can have a decisive impact on the linguistic system over time.\"\n\nPreviously, researchers had posited that loners preserved old forms that had been neglected by the larger community. Fagyal et al. complicate this claim by suggesting that the role of loners in a network is to safeguard old features, then reintroduce them to the community.\n\nThe researchers in Berg's 2006 study of digital social networks as linguistic social networks note the value of social networks as both linguistic corpuses and linguistic networks.\n\nIn Carmen Perez-Sabater's 2012 study of Facebook users, she discusses the use of English by native and non-native speakers on university Facebook pages. The researchers categorize these posts as a model of \"computer-mediated communication\", a new communication style that combines features of writing and speech. Facebook posts generally have a degree of informality, whether the users are native or nonnative English speakers, but native English speakers often have a higher degree of informality. For example, non-native speakers cited in the study use separated letter-style greetings and salutations, indicating linguistic insecurity. The conclusions of the study were that \"computer-mediated communication\" do not always tend toward informality, and that online social networks pattern similarly to non-virtual social networks.\n\n\n"}
{"id": "27763", "url": "https://en.wikipedia.org/wiki?curid=27763", "title": "Structuralism", "text": "Structuralism\n\nIn sociology, anthropology, and linguistics, structuralism is the methodology that implies elements of human culture must be understood by way of their relationship to a broader, overarching system or structure. It works to uncover the structures that underlie all the things that humans do, think, perceive, and feel. Alternatively, as summarized by philosopher Simon Blackburn, structuralism is \"the belief of alien life that is not intelligible except through their interrelations. These relations constitute a structure, and behind local variations in the surface phenomena there are constant laws of abstract culture\".\n\nStructuralism in Europe developed in the early 1900s, in the structural linguistics of Ferdinand de Saussure and the subsequent Prague, Moscow and Copenhagen schools of linguistics. In the late 1950s and early 1960s, when structural linguistics was facing serious challenges from the likes of Noam Chomsky and thus fading in importance, an array of scholars in the humanities borrowed Saussure's concepts for use in their respective fields of study. French anthropologist Claude Lévi-Strauss was arguably the first such scholar, sparking a widespread interest in structuralism.\n\nThe structuralist mode of reasoning has been applied in a diverse range of fields, including anthropology, sociology, psychology, literary criticism, economics and architecture. The most prominent thinkers associated with structuralism include Claude Lévi-Strauss, linguist Roman Jakobson, and psychoanalyst Jacques Lacan. As an intellectual movement, structuralism was initially presumed to be the heir apparent to existentialism. However, by the late 1960s, many of structuralism's basic tenets came under attack from a new wave of predominantly French intellectuals such as the philosopher and historian Michel Foucault, the philosopher Jacques Derrida, the Marxist philosopher Louis Althusser, and the literary critic Roland Barthes. Though elements of their work necessarily relate to structuralism and are informed by it, these theorists have generally been referred to as post-structuralists. In the 1970s, structuralism was criticized for its rigidity and ahistoricism. Despite this, many of structuralism's proponents, such as Lacan, continue to assert an influence on continental philosophy and many of the fundamental assumptions of some of structuralism's post-structuralist critics are a continuation of structuralism.\n\nThe term \"structuralism\" is a related term that describes a particular philosophical/literary movement or moment. The term appeared in the works of French anthropologist Claude Lévi-Strauss and gave rise in France to the \"structuralist movement,\" which influenced the thinking of other writers such as Louis Althusser, the psychoanalyst Jacques Lacan, as well as the structural Marxism of Nicos Poulantzas, most of whom disavowed themselves as being a part of this movement.\nThe origins of structuralism connect with the work of Ferdinand de Saussure on linguistics, along with the linguistics of the Prague and Moscow schools. In brief, Saussure's structural linguistics propounded three related concepts.\n\nProponents of structuralism would argue that a specific domain of culture may be understood by means of a structure—modelled on language—that is distinct both from the organizations of reality and those of ideas or the imagination—the \"third order\". In Lacan's psychoanalytic theory, for example, the structural order of \"the Symbolic\" is distinguished both from \"the Real\" and \"the Imaginary\"; similarly, in Althusser's Marxist theory, the structural order of the capitalist mode of production is distinct both from the actual, real agents involved in its relations and from the ideological forms in which those relations are understood.\n\nBlending Freud and Saussure, the French (post)structuralist Jacques Lacan applied structuralism to psychoanalysis and, in a different way, Jean Piaget applied structuralism to the study of psychology. But Jean Piaget, who would better define himself as constructivist, considers structuralism as \"a method and not a doctrine\" because for him \"there exists no structure without a construction, abstract or genetic\".\n\nAlthough the French theorist Louis Althusser is often associated with a brand of structural social analysis which helped give rise to \"structural Marxism\", such association was contested by Althusser himself in the Italian foreword to the second edition of \"Reading Capital\". In this foreword Althusser states the following: \n\nDespite the precautions we took to distinguish ourselves from the 'structuralist' ideology ..., despite the decisive intervention of categories foreign to 'structuralism' ..., the terminology we employed was too close in many respects to the 'structuralist' terminology not to give rise to an ambiguity. With a very few exceptions ... our interpretation of Marx has generally been recognized and judged, in homage to the current fashion, as 'structuralist'... We believe that despite the terminological ambiguity, the profound tendency of our texts was not attached to the 'structuralist' ideology.\nIn a later development, feminist theorist Alison Assiter enumerated four ideas that she says are common to the various forms of structuralism. First, that a structure determines the position of each element of a whole. Second, that every system has a structure. Third, structural laws deal with co-existence rather than change. Fourth, structures are the \"real things\" that lie beneath the surface or the appearance of meaning.\n\nIn \"Course in General Linguistics\" the analysis focuses not on the \"use\" of language (called \"\"parole\", or speech), but rather on the underlying system of language (called \"langue\"\"). This approach examines how the elements of language relate to each other in the present, synchronically rather than diachronically. Saussure argued that linguistic signs were composed of two parts:\n\n\nThis was quite different from previous approaches that focused on the relationship between words and the things in the world that they designate. Other key notions in structural linguistics include paradigm, syntagm, and value (though these notions were not fully developed in Saussure's thought). A structural \"idealism\" is a class of linguistic units (lexemes, morphemes or even constructions) that are possible in a certain position in a given linguistic environment (such as a given sentence), which is called the \"syntagm\". The different functional role of each of these members of the paradigm is called \"value\" (\"\" in French).\n\nSaussure's \"Course\" influenced many linguists between World War I and World War II. In the United States, for instance, Leonard Bloomfield developed his own version of structural linguistics, as did Louis Hjelmslev in Denmark and Alf Sommerfelt in Norway. In France Antoine Meillet and Émile Benveniste continued Saussure's project, and members of the Prague school of linguistics such as Roman Jakobson and Nikolai Trubetzkoy conducted research that would be greatly influential. However, by the 1950s Saussure's linguistic concepts were under heavy criticism and were soon largely abandoned by practicing linguists: \n\nSaussure's views are not held, so far as I know, by modern linguists, only by literary critics and the occasional philosopher. [Strict adherence to Saussure] has elicited wrong film and literary theory on a grand scale. One can find dozens of books of literary theory bogged down in signifiers and signifieds, but only a handful that refer to Chomsky.\nThe clearest and most important example of Prague school structuralism lies in phonemics. Rather than simply compiling a list of which sounds occur in a language, the Prague school sought to examine how they were related. They determined that the inventory of sounds in a language could be analysed in terms of a series of contrasts. Thus in English the sounds /p/ and /b/ represent distinct phonemes because there are cases (minimal pairs) where the contrast between the two is the only difference between two distinct words (e.g. 'pat' and 'bat'). Analyzing sounds in terms of contrastive features also opens up comparative scope—it makes clear, for instance, that the difficulty Japanese speakers have differentiating /r/ and /l/ in English is because these sounds are not contrastive in Japanese. Phonology would become the paradigmatic basis for structuralism in a number of different fields.\n\nAccording to structural theory in anthropology and social anthropology, meaning is produced and reproduced within a culture through various practices, phenomena and activities that serve as systems of signification. A structuralist approach may study activities as diverse as food-preparation and serving rituals, religious rites, games, literary and non-literary texts, and other forms of entertainment to discover the deep structures by which meaning is produced and reproduced within the culture. For example, Lévi-Strauss analysed in the 1950s cultural phenomena including mythology, kinship (the alliance theory and the incest taboo), and food preparation. In addition to these studies, he produced more linguistically focused writings in which he applied Saussure's distinction between \"langue\" and \"parole\" in his search for the fundamental structures of the human mind, arguing that the structures that form the \"deep grammar\" of society originate in the mind and operate in people unconsciously. Lévi-Strauss took inspiration from mathematics.\n\nAnother concept used in structural anthropology came from the Prague school of linguistics, where Roman Jakobson and others analysed sounds based on the presence or absence of certain features (such as voiceless vs. voiced). Lévi-Strauss included this in his conceptualization of the universal structures of the mind, which he held to operate based on pairs of binary oppositions such as hot-cold, male-female, culture-nature, cooked-raw, or marriageable vs. tabooed women.\n\nA third influence came from Marcel Mauss (1872–1950), who had written on gift-exchange systems. Based on Mauss, for instance, Lévi-Strauss argued that kinship systems are based on the exchange of women between groups (a position known as 'alliance theory') as opposed to the 'descent'-based theory described by Edward Evans-Pritchard and Meyer Fortes. While replacing Marcel Mauss at his \"Ecole Pratique des Hautes Etudes\" chair, Lévi-Strauss' writing became widely popular in the 1960s and 1970s and gave rise to the term \"structuralism\" itself.\n\nIn Britain, authors such as Rodney Needham and Edmund Leach were highly influenced by structuralism. Authors such as Maurice Godelier and Emmanuel Terray combined Marxism with structural anthropology in France. In the United States, authors such as Marshall Sahlins and James Boon built on structuralism to provide their own analysis of human society. Structural anthropology fell out of favour in the early 1980s for a number of reasons. D'Andrade suggests that this was because it made unverifiable assumptions about the universal structures of the human mind. Authors such as Eric Wolf argued that political economy and colonialism should be at the forefront of anthropology. More generally, criticisms of structuralism by Pierre Bourdieu led to a concern with how cultural and social structures were changed by human agency and practice, a trend which Sherry Ortner has referred to as 'practice theory'.\n\nSome anthropological theorists, however, while finding considerable fault with Lévi-Strauss's version of structuralism, did not turn away from a fundamental structural basis for human culture. The Biogenetic Structuralism group for instance argued that some kind of structural foundation for culture must exist because all humans inherit the same system of brain structures. They proposed a kind of neuroanthropology which would lay the foundations for a more complete scientific account of cultural similarity and variation by requiring an integration of cultural anthropology and neuroscience—a program that theorists such as Victor Turner also embraced.\n\nIn literary theory, structuralist criticism relates literary texts to a larger structure, which may be a particular genre, a range of intertextual connections, a model of a universal narrative structure, or a system of recurrent patterns or motifs.Structuralism argues that there must be a structure in every text, which explains why it is easier for experienced readers than for non-experienced readers to interpret a text. Hence, everything that is written seems to be governed by specific rules, or a \"grammar of literature\", that one learns in educational institutions and that are to be unmasked.\n\nA potential problem of structuralist interpretation is that it can be highly reductive, as scholar Catherine Belsey puts it: \"the structuralist danger of collapsing all difference.\" An example of such a reading might be if a student concludes the authors of \"West Side Story\" did not write anything \"really\" new, because their work has the same structure as Shakespeare's \"Romeo and Juliet\". In both texts a girl and a boy fall in love (a \"formula\" with a symbolic operator between them would be \"Boy + Girl\") despite the fact that they belong to two groups that hate each other (\"Boy's Group - Girl's Group\" or \"Opposing forces\") and conflict is resolved by their death. Structuralist readings focus on how the structures of the single text resolve inherent narrative tensions. If a structuralist reading focuses on multiple texts, there must be some way in which those texts unify themselves into a coherent system. The versatility of structuralism is such that a literary critic could make the same claim about a story of two \"friendly\" families (\"Boy's Family + Girl's Family\") that arrange a marriage between their children despite the fact that the children hate each other (\"Boy - Girl\") and then the children commit suicide to escape the arranged marriage; the justification is that the second story's structure is an 'inversion' of the first story's structure: the relationship between the values of love and the two pairs of parties involved have been reversed.\n\nStructuralistic literary criticism argues that the \"literary banter of a text\" can lie only in new structure, rather than in the specifics of character development and voice in which that structure is expressed. Literary structuralism often follows the lead of Vladimir Propp, Algirdas Julien Greimas, and Claude Lévi-Strauss in seeking out basic deep elements in stories, myths, and more recently, anecdotes, which are combined in various ways to produce the many versions of the ur-story or ur-myth.\n\nThere is considerable similarity between structural literary theory and Northrop Frye's archetypal criticism, which is also indebted to the anthropological study of myths. Some critics have also tried to apply the theory to individual works, but the effort to find unique structures in individual literary works runs counter to the structuralist program and has an affinity with New Criticism.\n\nThroughout the 1940s and 1950s, existentialism, such as that propounded by Jean-Paul Sartre, was the dominant European intellectual movement. Structuralism rose to prominence in France in the wake of existentialism, particularly in the 1960s. The initial popularity of structuralism in France led to its spread across the globe.\n\nStructuralism rejected the concept of human freedom and choice and focused instead on the way that human experience and thus, behaviour, is determined by various structures. The most important initial work on this score was Claude Lévi-Strauss's 1949 volume \"The Elementary Structures of Kinship\". Lévi-Strauss had known Jakobson during their time together at the New School in New York during WWII and was influenced by both Jakobson's structuralism as well as the American anthropological tradition. In \"Elementary Structures\" he examined kinship systems from a structural point of view and demonstrated how apparently different social organizations were in fact different permutations of a few basic kinship structures. In the late 1950s he published \"Structural Anthropology\", a collection of essays outlining his program for structuralism.\n\nBy the early 1960s structuralism as a movement was coming into its own and some believed that it offered a single unified approach to human life that would embrace all disciplines. Roland Barthes and Jacques Derrida focused on how structuralism could be applied to literature.\n\nThe so-called \"Gang of Four\" of structuralism was Lévi-Strauss, Lacan, Barthes, and Foucault.\n\nStructuralism is less popular today than other approaches, such as post-structuralism and deconstruction. Structuralism has often been criticized for being ahistorical and for favouring deterministic structural forces over the ability of people to act. As the political turbulence of the 1960s and 1970s (and particularly the student uprisings of May 1968) began affecting academia, issues of power and political struggle moved to the center of people's attention.\n\nIn the 1980s, deconstruction—and its emphasis on the fundamental ambiguity of language rather than its crystalline logical structure—became popular. By the end of the century structuralism was seen as an historically important school of thought, but the movements that it spawned, rather than structuralism itself, commanded attention.\n\nSeveral social thinkers and academics have strongly criticized structuralism or even dismissed it \"in toto\". The French hermeneutic philosopher Paul Ricœur (1969) criticized Lévi-Strauss for constantly overstepping the limits of validity of the structuralist approach, ending up in what Ricœur described as \"a Kantianism without a transcendental subject\". Anthropologist Adam Kuper (1973) argued that \"'Structuralism' came to have something of the momentum of a millennial movement and some of its adherents felt that they formed a secret society of the seeing in a world of the blind. Conversion was not just a matter of accepting a new paradigm. It was, almost, a question of salvation.\" Philip Noel Pettit (1975) called for an abandoning of \"the positivist dream which Lévi-Strauss dreamed for semiology\" arguing that semiology is not to be placed among the natural sciences. Cornelius Castoriadis (1975) criticized structuralism as failing to explain symbolic mediation in the social world; he viewed structuralism as a variation on the \"logicist\" theme, and he argued that, contrary to what structuralists advocate, language—and symbolic systems in general—cannot be reduced to logical organizations on the basis of the binary logic of oppositions. Critical theorist Jürgen Habermas (1985) accused structuralists, such as Foucault, of being positivists; he remarked that while Foucault is not an ordinary positivist, he nevertheless paradoxically uses the tools of science to criticize science (see \"Performative contradiction\" and \"Foucault–Habermas debate\"). Sociologist Anthony Giddens (1993) is another notable critic; while Giddens draws on a range of structuralist themes in his theorizing, he dismisses the structuralist view that the reproduction of social systems is merely \"a mechanical outcome\".\n\n\n\n"}
{"id": "45526803", "url": "https://en.wikipedia.org/wiki?curid=45526803", "title": "The Bro Code: How Contemporary Culture Creates Sexist Men", "text": "The Bro Code: How Contemporary Culture Creates Sexist Men\n\nThe Bro Code: How Contemporary Culture Creates Sexist Men is a documentary created by Thomas Keith in 2011.\n\nThe film has been described as a treatise on misogyny.\n\nThomas Keith is a professor at California Polytechnic University and Claremont Graduate University where he teaches philosophy and gender studies. His specific areas of study include: American philosophy, race, class, and gender.\n\n"}
{"id": "28278995", "url": "https://en.wikipedia.org/wiki?curid=28278995", "title": "The Society for the Preservation of Wild Culture", "text": "The Society for the Preservation of Wild Culture\n\nThe Society for the Preservation of Wild Culture (SPWC) was a Toronto arts organization in existence from 1986 to 1991 that explored environmental and ecological issues from an artistic perspective in a \"quirky and innovative\" way. The SPWC was best known for three programs: a literary magazine, The Journal of Wild Culture; artist-guided walks, \"landscape readings\"; and a series of cabarets, The Café of Wild Culture.\n\nThe organization was a unique hybrid. The oxymoron \"wild culture\" tweaked the interest of contrasting types: artists, scientists and activists, and the efforts made by the organization to develop creative projects and discourse around the term were well received. It was concurrently accepted as an arts organization by artists and an environmental organization by environmentalists.\n\nThe organisation was resurrected in 2011 and is now producing an online magazine based in London and Toronto.\n\nThe style of the organization was determined by how participating artists expressed themselves around the undefined idea of \"wild culture\" (also see \"wildculture\"). While calling for new articulations of wild culture through its projects, at its height the society filled the cultural vacuum in Toronto with an eclectic kind of \"thinking man's\" fun and provided a forum for experimentation amongst performance artists. The broader public was encouraged by the SPWC to engage with questions about nature and art, while frequently congregating in the outdoors. This audience was also attracted to the organization's ability to 'soft pedal doom and gloom while partying for the planet\".\n\nDuring a landscape reading on the aboriginal history of downtown Toronto, poet M. T. Kelly offered a view of how the SPWC sought to affect its audience: \"There is a bridge between history and landscape. To get people to change their view of the environment, you can't just argue in economic terms. It's an emotional thing. People act politically when they get emotionally involved\".\n\nThe notion of \"wild culture\" grew out of multidisciplinary artist Whitney Smith's experience of \"a spiritual updraft in the art spheres\" while foraging wild foods in the Ontario forest that he sold to local chefs. From 1982 to 1985 a series of three performances, \"Fern Policy\", explored the possibilities of artistic growth in the nature-culture ecotone. In May 1985 Smith made the first public announcement on the formation of the society at a Toronto art event, \"L'Affaire 'Pataphysique\", that presented examples of 'pataphysics by local artists parodying theory and methods of modern science. Following this event Smith began recruiting artists to help develop \"The Journal of Wild Culture\".\n\nThough there were attempts by the organization to define \"wild culture\", there was never an accepted definition. Smith preferred his colleagues and audiences to find wild culture's meaning through the titles of the projects in which it appeared, where the social context was at play; that is, that there existed a serious-sounding and possibly genuine academic journal published by a preserving society with a long name, all devoted to a subject no one knew anything about. Negotiating the serious and the non-serious in a way that made sense and entertained became part of the artists' work.\n\nBefore there was Smith's recent definition of wild culture (\"the articulated ecotone between what humans do and what they can't control in nature\"), no single explanation existed around which the S.P.W.C artists\" work was done. Some said that it was the vagueness of the idea, the inability to pin it down, that made it so attractive. In the absence of concrete description, Smith offered a metaphor, which he has recently modified: On the surface of a transparent painting is the human geographic reality that is part of our everyday life, and in the background are elements of nature, seen and unseen, that are very much alive but that people aren\"t always aware of, whether out of convenience, ignorance, apathy, or any state of unconsciousness or self-centeredness that contributes to the disconnection from our primal history and our present psychic hold on the home terrain. Wild culture is the two planes, foreground and background, seen together.\n\nThe literary organ of the SPWC, its subtitle, ecology, and imagination, spoke to the notion of \"The Journal of Wild Culture\" being a platform for artists to express themselves through the lens, or mirror, of the natural world. Smith said that \"one of the things wild culture \"is\", is a tolerance for ambiguity and an acceptance that things cannot be defined\". The \"quirky and innovative\" magazine carried on its discourse in a way that influenced the way more serious themes could be delivered with a sense of play and timeliness.\n\nBorn out of the wild foods foraging of founder Whitney Smith, the magazine was conceived in 1986-1987 by an editorial team that included Smith and architect Peter Ferguson, public relations consultant Kim Obrist and filmmaker and publisher Christopher Lowry. Smith attributed his inspiration for the formation of the society to the National Geographic Society (which published its own journal) and \"FILE\" magazine, produced by the conceptual and media-based art collective, General Idea, and to the \"Utne Reader\"'s use of other published materials. The SPWC was in production in Toronto from 1986 to 1991. Graphic designer Bernard Stockl became the art director and quickly established the look of the magazine, including the characteristic contents page. Smith and Lowry assembled a photocopied \"Journal of Wild Culture\" Preview Issue that was circulated in the arts community, and a donation of $5000 \"from an anonymous angel\" followed, just enough to pay for the printing of the first issue.\n\nThe premier issue was launched on July 27, 1987 at the Wild Culture Hoedown on Toronto Island. It was described by Smith at the time as \"a cross between a literary journal and an arty comic book with ecology as its theme\". Future Wild Culture events followed the format and spirit of the Hoedown by offering down-home high-end cuisine using wild foods and made on site by Chris Klugman, a well-known local chef, and featuring artists whose personae related to nature themes: the Marquis de Sod and Mr. Potatohead were the guests of honour at the launch. Poet Christopher Dewdney, an early contributor to the magazine, said that \"half of the experience at \"The Journal of Wild Culture\" is the parties.) Volume I, Number 1 was sold for $3.95 and 3000 copies were widely distributed in Canada by Disticor, and the issue sold out; later distribution of increased numbers went into the U.S. It developed a small but devoted fan base, particularly in British Columbia. In 1990 its southwestern U.S. distributor reported that the magazine had \"a cult following in Texas\".\n\nSmith said that Stockl, who died of AIDS-related causes in 1992, was a significant contributor to JWC. \"Bernie's deep sense of graphic taste and design intelligence struck the right tone with the first issue: serious like an academic journal but also accessible and visually engaging. In order for the quirkiness to work we needed the credible and elegant look that his gave us\". Stockl said he modeled the JWC design after \"Harper's\" and \"Arts and Architecture\": \"The trick was to create certain effects with what was available to us. Trying to cheat our way through it without it looking like that\". The Bernard Franklin Stockl Memorial Scholarship is offered annually at the Alberta College of Design for \"creative and innovative exploration in the use of typography for the purpose of communication\".\n\nIn the late 1980s, when advertisers were slow to embrace the few existing green magazines, and particularly one which the \"Utne Reader\" editor, Eric Utne, called \"indescribable\", low ad sales made it difficult to pay the bills and meet that quarterly schedule; only seven issues were published. Two Wild Culture auctions and funding from the federal and provincials arts councils helped take up the slack, but with a low subscription base and advertising revenue, a sudden drop in grant revenue, fund-raising and marketing fatigue, Smith's reluctance to step into the role of \"a career publisher\", the magazine decided to take a sabbatical. More recently Smith commented on his own burn-out keeping the magazine and the SPWC going, the dilemma of the artist-publisher, and the difficulty of keeping cultural magazines afloat in factors relating to demise of JWC. In early 1991, on CBC radio's \"Arts Report\", it was announced that the magazine was suspending publication. The plan was to pursue a more economically feasible course by following the format of \"Granta\" magazine, offering it as a trade paperback available in bookstores. A pilot issue of selections from past JWC issues was put out by Somerville House in 1992, \"Wild Culture\", edited by Smith and Lowry, but sales were not encouraging; one explanation for this was that the book did not offer new material.\n\nAn attempt by Smith and some new colleagues in 2002 to resurrect the \"Journal of Wild Culture\" online never got off the ground. Smith said that wild culture was \"a notion with a mind of its own\" and that \"the ingredients for a re-launch in 2002 just weren't there\".\n\nLandscape Readings were public walking tours led by artists of outdoor environments that held an intellectual or personal interest for the artist. Landscape Readings were a hybrid that combined the attraction of authors reading their own works with a bracing picnic outing in a setting which combines the context for a lecture on ecology, geology, history or biography.\n\nThe readings were a project initially conceived by Smith to provide a venue for writer and poet Christopher Dewdney to share his extensive knowledge of palaeozoic geology, among other things, and his sense of humour. In July 1987 he gave the first landscape reading of Toronto's High Park Carolinian forest, which was documented in the forthcoming issue of \"The Journal of Wild Culture\".\n\nOther artist guides included Gordon Rayner, Hank Hedges, M. T. Kelly, June Callwood, Larry Zolf, Joyce Weiland, and architect Donald Schmitt. The Readings were created to \"give [SPWC participating] artists a new venue\".\n\nThe Café of Wild Culture was conceived in collaboration with bookseller and film programmer Marc Glassman, who recognized that the sense of humour that was so much a part of the 60s and 70s was missing in the 80s. The Café was performed first in Toronto at The Rivoli, and later in New York at the Village Gate and at Goddard College in Vermont. Its legitimate non-theatre style played off the vaudeville and variety revue made up of several short unrelated acts (in the Café's case, no longer than 7 minutes) that caught the wild culture spirit of thoughtful irreverence. Acts ranged from tendentious 'pataphysical lectures, authentic scientific explanations, obtuse dance works, gentlemen's shirt-ironing contests, and wild food cooking demonstrations, in which small servings were provided for the audience, and a game called StorySlide where artists improvised a performed text based on a random photographic slide show.\n\nSmith met his match when he began a project called the Great Festival of the Lakes, which was to encourage the presentation of community arts festivals in Great Lakes cities. \"I was very concerned about water quality issues at the time, and thought that the SPWC needed an activist project to sponsor. I was wrong. Organizing anything around the Great Lakes is like trying to organize Europe. I learned a lot about underestimating scale on that one, and spreading myself too thin\". The project was abandoned after a couple of years.\n\nIn 1990, the SPWC worked with an organization started by Michael Stadtlander and Jamie Kennedy, Knives and Forks, on Spring Feast, which became a precursor of future events promoting local chefs and wild and organic foods.\n\nFrom September 2011 Smith's work on the SPWC focused on the online publishing platform, The Journal of Wild Culture. The project was beta-launched in December 2012 in London as www.wildculture.com by an editorial and design team including Smith, Joe Hedges of Branding by Garden, Tom Jeffreys, Sarah Lester, Rosie Jackson and Liam Desroy, continued with Smith, Jeffreys and designer Hedges from February to October 2013, at which time Smith took over sole editorial responsibilities, in collaboration, until 2016, with board members Lisa Wilson and Richard Stursberg; Stursberg continues to participate in an advisory role. The publication has no advertising, sends out a weekly newsletter, is supported by donations and the work of a growing community of international contributors. Current editors and contributing editors under publisher/editor Smith include Chellis Glendinning, Herbert Wright, Chris Lowry, Henry Giroux and illustrator Brad Harley.\n\n"}
{"id": "1264097", "url": "https://en.wikipedia.org/wiki?curid=1264097", "title": "Theodorus of Gadara", "text": "Theodorus of Gadara\n\nTheodorus of Gadara () was a Greek rhetorician of the 1st century BC who founded a rhetorical school in Gadara (present-day Um Qais, Jordan), where he taught future Roman emperor Tiberius the art of rhetoric. It was written of Tiberius that:\n\nHis other well-known pupil was Greek rhetorician Hermagoras of Temnos, who later taught oratory in Rome.\n\nTheodorus was one of the two most famous rhetoric teachers of the time, the other being Apollodorus of Pergamon. Students of Apollodorus were commonly referred to as \"Apollodoreans\", while students of Theodorus were known as \"Theodoreans\".\n\nAccording to the Suda, Theodorus wrote the following books, among others: \n"}
{"id": "14795435", "url": "https://en.wikipedia.org/wiki?curid=14795435", "title": "Tibetan calligraphy", "text": "Tibetan calligraphy\n\nTibetan calligraphy refers to the calligraphic traditions used to write the Tibetan language. As in other parts of East Asia, nobles, high lamas, and persons of high rank were expected to have high abilities in calligraphy. However, unlike calligraphy in China, Japan, and Korea, calligraphy was done using a reed pen as opposed to a brush. Nevertheless, East Asian influence is apparent visually, as Tibetan calligraphy is at times more free-flowing than calligraphy involving the descendants of other Brahmi scripts. Given the overriding religious nature of Tibetan culture, many of the traditions in calligraphy come from religious texts, and most Tibetan scribes have a monastic background.\n\nA variety of different styles of calligraphy existed in Tibet:\n\n\nThe vertical Phags-pa script is known as \"horyig\" ( \"hor-yig\", \"Mongolian letters\"). A more ornamental version of the \"horyig\" style was used in the past to make personal seals. It is often found written vertically as opposed to horizontally.\n\nThese styles are not fixed, and are not limited to those listed above. By mixing features of various styles, and adding various ornaments to the text, the number of styles becomes quite large. While \"ujain\" may be used to write entire Sutras or Buddhist texts, the rest of the styles are more frequently used to write a single phrase or saying.\n\nThe world record for the longest calligraphy scroll is held by Jamyang Dorjee Chakrishar, who penned a 163.2 meter scroll containing 65,000 Tibetan characters. The scroll contains prayers for the 14th Dalai Lama composed by 32 different monks.\n\n\n"}
{"id": "40313", "url": "https://en.wikipedia.org/wiki?curid=40313", "title": "Universal grammar", "text": "Universal grammar\n\nUniversal grammar (UG) in linguistics, is the theory of the genetic component of the language faculty, usually credited to Noam Chomsky. The basic postulate of UG is that a certain set of structural rules are innate to humans, independent of sensory experience. With more linguistic stimuli received in the course of psychological development, children then adopt specific syntactic rules that conform to UG. It is sometimes known as \"mental grammar\", and stands contrasted with other \"grammars\", e.g. prescriptive, descriptive and pedagogical. The advocates of this theory emphasize and partially rely on the poverty of the stimulus (POS) argument and the existence of some universal properties of natural human languages. However, the latter has not been firmly established, as some linguists have argued languages are so diverse that such universality is rare. It is a matter of empirical investigation to determine precisely what properties are universal and what linguistic capacities are innate.\n\nThe theory of universal grammar proposes that if human beings are brought up under normal conditions (not those of extreme sensory deprivation), then they will always develop language with certain properties (e.g., distinguishing nouns from verbs, or distinguishing function words from content words). The theory proposes that there is an innate, genetically determined language faculty that knows these rules, making it easier and faster for children to learn to speak than it otherwise would be. This faculty does not know the vocabulary of any particular language (so words and their meanings must be learned), and there remain several parameters which can vary freely among languages (such as whether adjectives come before or after nouns) which must also be learned.\n\nAs Chomsky puts it, \"Evidently, development of language in the individual must involve three factors: (1) genetic endowment, which sets limits on the attainable languages, thereby making language acquisition possible; (2) external data, converted to the experience that selects one or another language within a narrow range; (3) principles not specific to the Faculty of Language.\"\n\nOccasionally, aspects of universal grammar seem describable in terms of general details regarding cognition. For example, if a predisposition to categorize events and objects as different classes of things is part of human cognition, and directly results in nouns and verbs showing up in all languages, then it could be assumed that rather than this aspect of universal grammar being specific to language, it is more generally a part of human cognition. To distinguish properties of languages that can be traced to other facts regarding cognition from properties of languages that cannot, the abbreviation UG* can be used. UG is the term often used by Chomsky for those aspects of the human brain which cause language to be the way that it is (i.e. are universal grammar in the sense used here) but here for discussion, it is used for those aspects which are furthermore specific to language (thus UG, as Chomsky uses it, is just an abbreviation for universal grammar, but UG* as used here is a subset of universal grammar).\n\nIn the same article, Chomsky casts the theme of a larger research program in terms of the following question: \"How little can be attributed to UG while still accounting for the variety of 'I-languages' attained, relying on third factor principles?\" (I-languages meaning internal languages, the brain states that correspond to knowing how to speak and understand a particular language, and third factor principles meaning (3) in the previous quote).\n\nChomsky has speculated that UG might be extremely simple and abstract, for example only a mechanism for combining symbols in a particular way, which he calls \"merge\". The following quote shows that Chomsky does not use the term \"UG\" in the narrow sense UG* suggested above:\n\n\"The conclusion that merge falls within UG holds whether such recursive generation is unique to FL (faculty of language) or is\nappropriated from other systems.\"\n\nIn other words, merge is seen as part of UG because it causes language to be the way it is, universal, and is not part of the environment or general properties independent of genetics and environment. Merge is part of universal grammar whether it is specific to language, or whether, as Chomsky suggests, it is also used for an example in mathematical thinking.\n\nThe distinction is important because there is a long history of argument about UG*, whereas most people working on language agree that there is universal grammar. Many people assume that Chomsky means UG* when he writes UG (and in some cases he might actually mean UG* [though not in the passage quoted above]).\n\nSome students of universal grammar study a variety of grammars to extract generalizations called linguistic universals, often in the form of \"If X holds true, then Y occurs.\" These have been extended to a variety of traits, such as the phonemes found in languages, the word orders which languages choose, and the reasons why children exhibit certain linguistic behaviors.\n\nLater linguists who have influenced this theory include Chomsky and Richard Montague, developing their version of this theory as they considered issues of the argument from poverty of the stimulus to arise from the constructivist approach to linguistic theory. The application of the idea of universal grammar to the study of second language acquisition (SLA) is represented mainly in the work of McGill linguist Lydia White.\n\nSyntacticians generally hold that there are parametric points of variation between languages, although heated debate occurs over whether UG constraints are essentially universal due to being \"hard-wired\" (Chomsky's principles and parameters approach), a logical consequence of a specific syntactic architecture (the generalized phrase structure approach) or the result of functional constraints on communication (the functionalist approach).\n\nIn an article titled, \"The Faculty of Language: What Is It, Who Has It, and How Did It Evolve?\" Hauser, Chomsky, and Fitch present the three leading hypotheses for how language evolved and brought humans to the point where they have a universal grammar.\n\nThe first hypothesis states that the faculty of language in the broad sense (FLb) is strictly homologous to animal communication.\nThis means that homologous aspects of the faculty of language exist in non-human animals.\n\nThe second hypothesis states that the FLb is a derived, uniquely human, adaptation for language. This hypothesis holds that individual traits were subject to natural selection and came to be specialized for humans.\n\nThe third hypothesis states that only the faculty of language in the narrow sense (FLn) is unique to humans. It holds that while mechanisms of the FLb are present in both human and non-human animals, the computational mechanism of recursion is recently evolved solely in humans. This is the hypothesis which most closely aligns to the typical theory of universal grammar championed by Chomsky.\n\nThe idea of a universal grammar can be traced back to Roger Bacon's observations in his \"Overview of Grammar\" and \"Greek Grammar\" that all languages are built upon a common grammar, even though it may undergo incidental variations; and the 13th century speculative grammarians who, following Bacon, postulated universal rules underlying all grammars. The concept of a universal grammar or language was at the core of the 17th century projects for philosophical languages. There is a Scottish school of universal grammarians from the 18th century, as distinguished from the philosophical language project, which included authors such as James Beattie, Hugh Blair, James Burnett, James Harris, and Adam Smith. The article on grammar in the first edition of the \"Encyclopædia Britannica\" (1771) contains an extensive section titled \"Of Universal Grammar\".\n\nThe idea rose to prominence and influence, in modern linguistics with theories from Chomsky and Montague in the 1950s–1970s, as part of the \"linguistics wars\".\n\nDuring the early 20th century, in contrast, language was usually understood from a behaviourist perspective, suggesting that language acquisition, like any other kind of learning, could be explained by a succession of trials, errors, and rewards for success. In other words, children learned their mother tongue by simple imitation, through listening and repeating what adults said. For example, when a child says \"milk\" and the mother will smile and give her some as a result, the child will find this outcome rewarding, thus enhancing the child's language development.\n\nChomsky argued that the human brain contains a limited set of constraints for organizing language. This implies in turn that all languages have a common structural basis: the set of rules known as \"universal grammar\".\n\nSpeakers proficient in a language know which expressions are acceptable in their language and which are unacceptable. The key puzzle is how speakers come to know these restrictions of their language, since expressions that violate those restrictions are not present in the input, indicated as such. Chomsky argued that this poverty of stimulus means that Skinner's behaviourist perspective cannot explain language acquisition. The absence of negative evidence—evidence that an expression is part of a class of ungrammatical sentences in a given language—is the core of his argument. For example, in English, an interrogative pronoun like \"what\" cannot be related to a predicate within a relative clause:\n\nSuch expressions are not available to language learners: they are, by hypothesis, ungrammatical. Speakers of the local language do not use them, or note them as unacceptable to language learners. Universal grammar offers an explanation for the presence of the poverty of the stimulus, by making certain restrictions into universal characteristics of human languages. Language learners are consequently never tempted to generalize in an illicit fashion.\n\nThe presence of creole languages is sometimes cited as further support for this theory, especially by Bickerton's controversial language bioprogram theory. Creoles are languages that develop and form when disparate societies come together and are forced to devise a new system of communication. The system used by the original speakers is typically an inconsistent mix of vocabulary items, known as a pidgin. As these speakers' children begin to acquire their first language, they use the pidgin input to effectively create their own original language, known as a creole. Unlike pidgins, creoles have native speakers (those with acquisition from early childhood) and make use of a full, systematic grammar.\n\nAccording to Bickerton, the idea of universal grammar is supported by creole languages because certain features are shared by virtually all in the category. For example, their default point of reference in time (expressed by bare verb stems) is not the present moment, but the past. Using pre-verbal auxiliaries, they uniformly express tense, aspect, and mood. Negative concord occurs, but it affects the verbal subject (as opposed to the object, as it does in languages like Spanish). Another similarity among creoles can be seen in the fact that questions are created simply by changing the intonation of a declarative sentence, not its word order or content.\n\nHowever, extensive work by Carla Hudson-Kam and Elissa Newport suggests that creole languages may not support a universal grammar at all. In a series of experiments, Hudson-Kam and Newport looked at how children and adults learn artificial grammars. They found that children tend to ignore minor variations in the input when those variations are infrequent, and reproduce only the most frequent forms. In doing so, they tend to standardize the language that they hear around them. Hudson-Kam and Newport hypothesize that in a pidgin-development situation (and in the real-life situation of a deaf child whose parents are or were disfluent signers), children systematize the language they hear, based on the probability and frequency of forms, and not that which has been suggested on the basis of a universal grammar. Further, it seems to follow that creoles would share features with the languages from which they are derived, and thus look similar in terms of grammar.\n\nMany researchers of universal grammar argue against a concept of relexification, which says that a language replaces its lexicon almost entirely with that of another. This goes against universalist ideas of a universal grammar, which has an innate grammar.\n\nGeoffrey Sampson maintains that universal grammar theories are not falsifiable and are therefore pseudoscientific. He argues that the grammatical \"rules\" linguists posit are simply post-hoc observations about existing languages, rather than predictions about what is possible in a language. Similarly, Jeffrey Elman argues that the unlearnability of languages assumed by universal grammar is based on a too-strict, \"worst-case\" model of grammar, that is not in keeping with any actual grammar. In keeping with these points, James Hurford argues that the postulate of a language acquisition device (LAD) essentially amounts to the trivial claim that languages are learnt by humans, and thus, that the LAD is less a theory than an explanandum looking for theories.\n\nMorten H. Christiansen and Nick Chater have argued that the relatively fast-changing nature of language would prevent the slower-changing genetic structures from ever catching up, undermining the possibility of a genetically hard-wired universal grammar. Instead of an innate universal grammar, they claim, \"apparently arbitrary aspects of linguistic structure may result from general learning and processing biases deriving from the structure of thought processes, perceptuo-motor factors, cognitive limitations, and pragmatics\".\n\nHinzen summarizes the most common criticisms of universal grammar:\n\nIn addition, it has been suggested that people learn about probabilistic patterns of word distributions in their language, rather than hard and fast rules (see Distributional hypothesis). For example, children overgeneralize the past tense marker \"ed\" and conjugate irregular verbs incorrectly, producing forms like \"goed\" and \"eated\" and correct these errors over time. It has also been proposed that the poverty of the stimulus problem can be largely avoided, if it is assumed that children employ \"similarity-based generalization\" strategies in language learning, generalizing about the usage of new words from similar words that they already know how to use.\n\nLanguage acquisition researcher Michael Ramscar has suggested that when children erroneously expect an ungrammatical form that then never occurs, the repeated failure of expectation serves as a form of implicit negative feedback that allows them to correct their errors over time such as how children correct grammar generalizations like \"goed\" to \"went\" through repetitive failure. This implies that word learning is a probabilistic, error-driven process, rather than a process of fast mapping, as many nativists assume.\n\nIn the domain of field research, the Pirahã language is claimed to be a counterexample to the basic tenets of universal grammar. This research has been led by Daniel Everett. Among other things, this language is alleged to lack all evidence for recursion, including embedded clauses, as well as quantifiers and colour terms. According to the writings of Everett, the Pirahã showed these linguistic shortcomings not because they were simple-minded, but because their culture—which emphasized concrete matters in the present and also lacked creation myths and traditions of art making—did not necessitate it. Some other linguists have argued, however, that some of these properties have been misanalyzed, and that others are actually expected under current theories of universal grammar. Other linguists have attempted to reassess Pirahã to see if it did indeed use recursion. In a corpus analysis of the Pirahã language, linguists failed to disprove Everett's arguments against universal grammar and the lack of recursion in Pirahã. However, they also stated that there was \"no strong evidence for the lack of recursion either\" and they provided \"suggestive evidence that Pirahã may have sentences with recursive\nstructures\".\n\nDaniel Everett has gone as far as claiming that universal grammar does not exist. In his words, \"universal grammar doesn't seem to work, there doesn't seem to be much evidence for [it]. And what can we put in its place? A complex interplay of factors, of which culture, the values human beings share, plays a major role in structuring the way that we talk and the things that we talk about.\" Michael Tomasello, a developmental psychologist, also supports this claim, arguing that \"although many aspects of human linguistic competence have indeed evolved biologically, specific grammatical principles and constructions have not. And universals in the grammatical structure of different languages have come from more general processes and constraints of human cognition, communication, and vocal-auditory processing, operating during the conventionalization and transmission of the particular grammatical constructions of particular linguistic communities.\"\n\n"}
{"id": "2067260", "url": "https://en.wikipedia.org/wiki?curid=2067260", "title": "Value (semiotics)", "text": "Value (semiotics)\n\nIn semiotics, the value of a sign depends on its position and relations in the system of signification and upon the particular codes being used.\n\nValue is the sign as it is determined by the other signs in a semiotic system. For linguist Ferdinand de Saussure, for example, the content of a sign in linguistics is ultimately determined and delimited not by its internal content, but by what surrounds it: the synonyms \"redouter\" (\"to dread\"), \"craindre\" (\"to fear\"), and \"avoir peur\" (\"to be afraid\") have their particular values because they exist in opposition to one another. If two of the terms disappeared, then the remaining sign would take on their roles, become vaguer, less articulate, and lose its \"extra something\" because it would have nothing to distinguish itself from.\n\nFor de Saussure, this suggests that thought is a chaotic nebula until linguistic structure dissects it and holds its divisions in equilibriums. This is akin to the philosophy of \nSir William Hamilton, who indirectly influenced Saussure and believed that the mind could only grasp an idea through distinguishing it from something that it is not. He reasoned that the two objects would otherwise collapse together for the mind and become indistinguishable from one another.\n\nValue determines the sign as a whole, not just meaning. Sound is also an indeterminate nebulous. The arbitrary nature of the sign and the flexibility of sound means that an agreed upon contrast is required. For example, \"zena\" is useful because it stands in contrast to \"zenb\" within an agreed upon system. Without the distinction, \"zena\" could be used for absolutely anything, or indeed nothing, making communication an impossibility.\n\nIt must also be noted that it is only the sign as a whole that has value. Linguistic structure simultaneously unites sound with thought and decomposes \"thought-sound\" into linguistic units, or signs, consisting of a signifier and a signified (sound-pattern and concept, respectively). When analysed in isolation, the sound-pattern or concept are pure differences, emerging from series of sound-patterns or concepts that they themselves are dependent upon. But in isolation, they are mere abstractions, because neither can exist without the connection between the two. It is the sign as a whole, then, that is the concrete entity of structural linguistics, which is not a pure difference, a negative term, but a pure value, a positive term that is merely in opposition or resistance to all the other signs in the system.\n\nDrawing from the original definition proposed by Saussure (1857–1913), a sign has two parts:\n\nThis emphasises that the sign is merely a symbol for the class of object referred to. Hence, the lexical word or noun \"box\" evokes a range of possibility from cheap card to gold-encrusted container. The reader or audience may not be able to see the particular box referred to but will be aware of its likely form from the other signs accompanying the use of the particular word.\n\nHowever, there is no necessary connection between the signifier and the signified. There is nothing inherently \"boxy\" about the component sounds or letters that comprise the noun \"box\"—the scope of onomatopoeia is limited when forming a language. All that is necessary is that the relevant group of people should decide to use that word to denote the object. Evidence that this is the correct view comes from the fact that each language can encode signifiers with whichever signified they wish to communicate. Hence, for example, the letters comprising \"air\" signify what humans breathe in English, and what fish breathe in Malay, i.e. water.\n\nThis makes a system of signs a very flexible mechanism for communicating meaning, but one which is conditioned by history and culture, i.e. once a sign acquires a commonly accepted meaning in each language, it cannot arbitrarily be changed by any one person, but it is able to change diachronically.\n\nFurther, Roman Jakobson (1896–1982) proposes that when a group of signs is used, there is an emotive function that reflects the speaker's attitude to the topic of his or her discourse. Language and the other coding systems are the means whereby one self-aware individual communicates with another. By selecting particular signs and placing them in a context, the addresser is making a cognitive use of the sign system to refer to his or her own social, moral, ethical, political or other values.\n\nBecause signs may have multiple meanings, a sign can only be interpreted in its context. Saussure believed that any one sign takes its value from its position and relations with other signs within the linguistic system. Modern semiotics draws its inspiration from the work of, \"inter alios\", Roland Barthes (1915–1980), who argued that semiotics should expand its scope and concern: \"...any system of signs, whatever their substance and limits; images, gestures, musical sounds, objects, and the complex associations of all of these, which form the content of ritual, convention or public entertainment: these constitute, if not languages, at least systems of signification\" (1967, 9). \n\nIn the system to be interrogated, the relations will be both weak and strong, positive and negative, qualitative and quantitative, etc. In this, a sign cannot be attributed a value outside its context (although what is signified may have connotative meaning(s) that resonate outside the context), and what is \"not\" present can be just as significant as what is present.\n\nIn a slightly different context of critique through the \"archaeological\" and \"genealogical\" methods for the study of knowledge, Michel Foucault (1926–1984) used the idea of discontinuity as a means to \"revalorise\" elements of knowledge. In this, he considered the silences and lacunae within a text to be as significant as express statements. In both systems, the specific processes of analysis examine these gaps to reveal whose interests are served by the omissions. Such analysis is particularly useful to identify which questions are left unasked.\n\nThe commutation test can be used to identify which signifiers are significant. The test depends on substitution: a particular signifier is chosen, then the effect of substituting alternatives is considered to determine the extent to which the value of the sign is changed. This both illuminates the meaning of the original choice and identifies the paradigms and code to which the signifiers used belong.\n\nParadigmatic analysis compiles a list of the signifiers present in the text. This set comprises the paradigm. The analyst then compares and contrasts the set with absent signifiers, i.e. with other signifiers that might have been chosen. This reveals the significance of the choices made which might have been required because of technical production constraints or the limitations of the individual’s own technique, or because of the tropes, generic conventions, style and rhetorical purpose of the work. The analysis of paradigmatic relations helps to define the ‘value’ of specific items in a system.\n\n"}
