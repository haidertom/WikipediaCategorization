{"id": "40836275", "url": "https://en.wikipedia.org/wiki?curid=40836275", "title": "Cosmic age problem", "text": "Cosmic age problem\n\nThe cosmic age problem is a historical problem in astronomy concerning the age of the universe. The problem was that at various times in the 20th century, some objects in the universe were estimated to be older than the time elapsed since the Big Bang, as estimated from measurements of the expansion rate of the universe known as the Hubble constant, denoted H. (This is more correctly called the Hubble parameter, since it generally varies with time).\nIf so, this would represent a contradiction, since objects such as galaxies, stars and planets could not have existed in the extreme temperatures and densities shortly after the Big Bang.\n\nSince around 1997–2003, the problem is believed to be solved by most cosmologists: modern cosmological measurements lead to a precise estimate of the age of the universe (i.e. time since the Big Bang) of 13.8 billion years, and recent age estimates for the oldest objects are either younger than this, or consistent allowing for measurement uncertainties.\n\nFollowing theoretical developments of the Friedmann equations by Alexander Friedmann and Georges Lemaître in the 1920s, and the discovery of the expanding universe by Edwin Hubble in 1929, it was immediately clear that tracing this expansion backwards in time predicts that the universe had almost zero size at a finite time in the past. This concept, initially known as the \"Primeval Atom\" by Lemaitre, was later elaborated into the modern Big Bang theory. If the universe had expanded at a constant rate in the past, the age of the universe now (i.e. the time since the Big Bang) is simply the inverse of the Hubble constant, often known as the \"Hubble time\". For Big Bang models with zero cosmological constant and positive matter density, the actual age must be somewhat younger than this Hubble time; typically the age would be between 66% and 90% of the Hubble time, depending on the density of matter.\n\nHubble's early estimate of his constant was 550 (km/s)/Mpc, and the inverse of that is 1.8 billion years. It was believed by many geologists such as Arthur Holmes in the 1920s that the Earth was probably over 2 billion years old, but with large uncertainty. The possible discrepancy between the ages of the Earth and the universe was probably one motivation for the development of the Steady State theory in 1948 as an alternative to the Big Bang; in the (now obsolete) steady state theory, the universe is infinitely old and on average unchanging with time. The steady state theory postulated spontaneous creation of matter to keep the average density constant as the universe expands, and therefore most galaxies still have an age less than 1/H. However, if H had been 550 (km/s)/Mpc, our Milky Way galaxy would be exceptionally large compared to most other galaxies, so it could well be much older than an average galaxy, therefore eliminating the age problem.\n\nIn the 1950s, two substantial errors were discovered in Hubble's extragalactic distance scale: first in 1952, Walter Baade discovered there were two classes of Cepheid variable star. Hubble's sample comprised different classes nearby and in other galaxies, and correcting this error made all other galaxies twice as distant as Hubble's values, thus doubling the Hubble time. A second error was discovered by Allan Sandage and coworkers: for galaxies beyond the Local Group, Cepheids were too faint to observe with Hubble's instruments, so Hubble used the brightest stars as distance indicators. Many of Hubble's \"brightest stars\" were actually HII regions or clusters containing many stars, which caused another underestimation of distances for these more distant galaxies. Thus, in 1958 Sandage published the first reasonably accurate measurement of the Hubble constant, at 75 (km/s)/Mpc, which is close to modern estimates of 68–74 (km/s)/Mpc.\n\nThe age of the Earth (actually the Solar System) was first accurately measured around 1955 by Clair Patterson at 4.55 billion years, essentially identical to the modern value. For H ~ 75 (km/s)/Mpc, the inverse of H is 13.0 billion years; so after 1958 the Big Bang model age was comfortably older than the Earth.\n\nHowever, in the 1960s and onwards, new developments in the theory of stellar evolution enabled age estimates for large star clusters called globular clusters: these generally gave age estimates of around 15 billion years, with substantial scatter. Further revisions of the Hubble constant by Sandage and Gustav Tammann in the 1970s gave values around 50–60 (km/s)/Mpc, and an inverse of 16-20 billion years, consistent with globular cluster ages.\n\nHowever, in the late 1970s to early 1990s, the age problem re-appeared: new estimates of the Hubble constant gave higher values, with Gerard de Vaucouleurs estimating values 90–100 (km/s)/Mpc, while Marc Aaronson and co-workers gave values around 80-90  (km/s)/Mpc. Sandage and Tammann continued to argue for values 50-60, leading to a period of controversy sometimes called the \"Hubble wars\". The higher values for H appeared to predict a universe younger than the globular cluster ages, and gave rise to some speculations during the 1980s that the Big Bang model was seriously incorrect.\n\nThe age problem was eventually thought to be resolved by several developments between 1995-2003: firstly, a large program with the Hubble space telescope measured the Hubble constant at 72 (km/s)/Mpc with 10 percent uncertainty. Secondly, measurements of parallax by the Hipparcos spacecraft in 1995 revised globular cluster distances upwards by 5-10 percent; this made their stars brighter than previously estimated and therefore younger, shifting their age estimates down to around 12-13 billion years. Finally, from 1998-2003 a number of new cosmological observations including supernovae, cosmic microwave background observations and large galaxy redshift surveys led to the acceptance of dark energy and the establishment of the Lambda-CDM model as the standard model of cosmology. The presence of dark energy implies that the universe was expanding more slowly at around half its present age than today, which makes the universe older for a given value of the Hubble constant. The combination of the three results above essentially removed the discrepancy between estimated globular cluster ages and the age of the universe.\n\nMore recent measurements from WMAP and the Planck spacecraft lead to an estimate of the age of the universe of 13.80 billion years with only 0.3 percent uncertainty (based on the standard Lambda-CDM model), and modern age measurements for globular clusters and other objects are currently smaller than this value (within the measurement uncertainties). A substantial majority of cosmologists therefore believe the age problem is now resolved.\n\n"}
{"id": "1610231", "url": "https://en.wikipedia.org/wiki?curid=1610231", "title": "Energy density", "text": "Energy density\n\nEnergy density is the amount of energy stored in a given system or region of space per unit volume. Colloquially it may also be used for energy per unit mass, though the accurate term for this is specific energy. Often only the \"useful\" or extractable energy is measured, which is to say that inaccessible energy (such as rest mass energy) is ignored. In cosmological and other general relativistic contexts, however, the energy densities considered are those that correspond to the elements of the stress–energy tensor and therefore do include mass energy as well as energy densities associated with the pressures described in the next paragraph.\n\nEnergy per unit volume has the same physical units as pressure, and in many circumstances is a synonym: for example, the energy density of a magnetic field may be expressed as (and behaves as) a physical pressure, and the energy required to compress a compressed gas a little more may be determined by multiplying the difference between the gas pressure and the external pressure by the change in volume. In short, pressure is a measure of the enthalpy per unit volume of a system. A pressure gradient has the potential to perform work on the surroundings by converting enthalpy to work until equilibrium is reached.\n\nThere are many different types of energy stored in materials, and it takes a particular type of reaction to release each type of energy. In order of the typical magnitude of the energy released, these types of reactions are: nuclear, chemical, electrochemical, and electrical.\n\nNuclear reactions are used by stars and nuclear power plants, both of which derive energy from the binding energy of nuclei. Chemical reactions are used by animals to derive energy from food, and by automobiles to derive energy from gasoline. Liquid hydrocarbons (fuels such as gasoline, diesel and kerozene) are today the most dense way known to economically store and transport chemical energy at a very large scale (1 kg of diesel fuel burns with the oxygen contained in ~15 kg of air). Electrochemical reactions are used by most mobile devices such as laptop computers and mobile phones to release the energy from batteries.\n\nThe following is a list of the thermal energy densities (that is to say: the amount of heat energy that can be extracted) of commonly used or well-known energy storage materials; it doesn't include uncommon or experimental materials. Note that this list does not consider the mass of reactants commonly available such as the oxygen required for combustion or the energy efficiency in use. An extended version of this table is found at Energy density#Extended Reference Table. Major reference = .\n\nThe following unit conversions may be helpful when considering the data in the table: 3.6 MJ = 1 kWh ≈ 1.34 HPh.\n\nIn energy storage applications the energy density relates the mass of an energy store to the volume of the storage facility, e.g. the fuel tank. The higher the energy density of the fuel, the more energy may be stored or transported for the same amount of volume. The energy density of a fuel per unit mass is called the specific energy of that fuel. In general an engine using that fuel will generate less kinetic energy due to inefficiencies and thermodynamic considerations—hence the specific fuel consumption of an engine will always be greater than its rate of production of the kinetic energy of motion.\n\nThe greatest energy source by far is mass itself. This energy, \"E = mc\", where \"m = ρV\", \"ρ\" is the mass per unit volume, \"V\" is the volume of the mass itself and \"c\" is the speed of light. This energy, however, can be released only by the processes of nuclear fission (0.1%), nuclear fusion (1%), or the annihilation of some or all of the matter in the volume \"V\" by matter-antimatter collisions (100%). Nuclear reactions cannot be realized by chemical reactions such as combustion. Although greater matter densities can be achieved, the density of a neutron star would approximate the most dense system capable of matter-antimatter annihilation possible. A black hole, although denser than a neutron star, does not have an equivalent anti-particle form, but would offer the same 100% conversion rate of mass to energy in the form of Hawking radiation. In the case of relatively small black holes (smaller than astronomical objects) the power output would be tremendous.\n\nThe highest density sources of energy aside from antimatter are fusion and fission. Fusion includes energy from the sun which will be available for billions of years (in the form of sunlight) but so far (2018), sustained fusion power production continues to be elusive. \n\nPower from fission of uranium and thorium in nuclear power plants will be available for many decades or even centuries because of the plentiful supply of the elements on earth, though the full potential of this source can only be realised through breeder reactors, which are, apart from the BN-600 reactor, not yet used commercially. Coal, gas, and petroleum are the current primary energy sources in the U.S. but have a much lower energy density. Burning local biomass fuels supplies household energy needs (cooking fires, oil lamps, etc.) worldwide. \n\nThe density of thermal energy contained in the core of a light water reactor (PWR or BWR) of typically 1 GWe (1 000 MW electrical corresponding to ~3 000 MW thermal) is in the range of 10 to 100 MW of thermal energy per cubic meter of cooling water depending on the location considered in the system (the core itself (~30 m), the reactor pressure vessel (~50 m), or the whole primary circuit (~300 m)). This represents a considerable density of energy which requires under all circumstances a continuous water flow at high velocity in order to be able to remove the heat from the core, even after an emergency shutdown of the reactor. The incapacity to cool the cores of three boiling water reactors (BWR) at Fukushima in 2011 after the tsunami and the resulting loss of the external electrical power and of the cold source was the cause of the meltdown of the three cores in only a few hours. Meanwhile, the three reactors were correctly shut down just after the Tōhoku earthquake. This extremely high power density distinguishes nuclear power plants (NPP's) from any thermal power plants (burning coal, fuel or gas) or any chemical plants and explains the large redundancy required to permanently control the neutron reactivity and to remove the residual heat from the core of NPP's.\n\nEnergy density differs from energy conversion efficiency (net output per input) or embodied energy (the energy output costs to provide, as harvesting, refining, distributing, and dealing with pollution all use energy). Large scale, intensive energy use impacts and is impacted by climate, waste storage, and environmental consequences.\n\nNo single energy storage method boasts the best in specific power, specific energy, and energy density. Peukert's Law describes how the amount of useful energy that can be obtained (for a lead-acid cell) depends on how quickly we pull it out. To maximize both specific energy and energy density, one can compute the specific energy density of a substance by multiplying the two values together, where the higher the number, the better the substance is at storing energy efficiently.\n\nAlternative options are discussed for energy storage to increase energy density and decrease charging time.\n\nGravimetric and volumetric energy density of some fuels and storage technologies (modified from the Gasoline article):\n\nThis table lists energy densities of systems that require external components, such as oxidisers or a heat sink or source. These figures do not take into account the mass and volume of the required components as they are assumed to be freely available and present in the atmosphere. Such systems cannot be compared with self-contained systems. These values may not be computed at the same reference conditions.\n\nDivide joule/m by 10 to get MJ/L. Divide MJ/L by 3.6 to get kWh/L.\n\nElectric and magnetic fields store energy. In a vacuum, the (volumetric) energy density is given by\n\nwhere E is the electric field and B is the magnetic field. The solution will be (in SI units) in Joules per cubic metre. In the context of magnetohydrodynamics, the physics of conductive fluids, the magnetic energy density behaves like an additional pressure that adds to the gas pressure of a plasma.\n\nIn normal (linear and nondispersive) substances, the energy density (in SI units) is\n\nwhere D is the electric displacement field and H is the magnetizing field.\n\nIn the case of absence of magnetic fields, by exploting Fröhlich's relationships it is also possible to extend these equations to anisotropy and nonlinearity dielectrics, as well as to calculate the correlated Helmholtz free energy and entropy densities.\n\n\n\n"}
{"id": "26356935", "url": "https://en.wikipedia.org/wiki?curid=26356935", "title": "Energy operator", "text": "Energy operator\n\nIn quantum mechanics, energy is defined in terms of the energy operator, acting on the wave function of the system as a consequence of time translation symmetry.\n\nIt is given by:\n\nIt acts on the wave function (the probability amplitude for different configurations of the system)\n\nThe energy operator corresponds to the full energy of a system. The Schrödinger equation describes the space- and time-dependence of the slow changing (non-relativistic) wave function of a quantum system. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta.\n\nUsing the energy operator to the Schrödinger equation:\n\ncan be obtained:\n\nwhere \"i\" is the imaginary unit, \"ħ\" is the reduced Planck constant, and formula_5 is the Hamiltonian operator.\n\nIn a stationary state additionally occurs the time-independent Schrödinger equation:\nwhere \"E\" is an eigenvalue of energy.\n\nThe relativistic mass-energy relation:\n\nwhere again \"E\" = total energy, \"p\" = total 3-momentum of the particle, \"m\" = invariant mass, and \"c\" = speed of light, can similarly yield the Klein–Gordon equation:\n\nthat is:\n\nThe energy operator is easily derived from using the free particle wave function (plane wave solution to Schrödinger's equation). Starting in one dimension the wave function is\n\nThe time derivative of \"Ψ\" is\n\nBy the De Broglie relation:\n\nwe have\n\nRe-arranging the equation leads to\n\nwhere the energy factor \"E\" is a scalar value, the energy the particle has and the value that is measured. The partial derivative is a linear operator so this expression \"is\" the operator for energy:\n\nIt can be concluded that the scalar \"E\" is the eigenvalue of the operator, while formula_16 is the operator. Summarizing these results:\n\nFor a 3-d plane wave\n\nthe derivation is exactly identical, as no change is made to the term including time and therefore the time derivative. Since the operator is linear, they are valid for any linear combination of plane waves, and so they can act on any wave function without affecting the properties of the wave function or operators. Hence this must be true for any wave function. It turns out to work even in relativistic quantum mechanics, such as the Klein–Gordon equation above.\n\n"}
{"id": "41627505", "url": "https://en.wikipedia.org/wiki?curid=41627505", "title": "Imago Universi", "text": "Imago Universi\n\nAndreas Cellarius, German mathematician and cartographer (1596–1665), conceived an Atlas of the Universe, published in 1660, under the title of \"Harmonia Macrocosmica\". Numerous illustrations of the solar system appear in this atlas by different authors known at that time. Referring to Ptolemy, Cellarius called the representation of this Ptolemaic conception of heaven as \"Imago universi secundum Ptolaeum\"\n\n\"Imago\" is a word in Latin which means\" 'image\"' or even \"representation\". Therefore, the title expresses the \"Picture of the Universe according to Ptolemy.\" The Latin expression was used in the Middle Ages to express the representation and size of the known world at that time.\n\n\"Imago Universi\" is also the title, in Latin, of a cosmographic treatise, written in 2013 by the Spanish scientist Gabriel Barceló.\n\nAfter analyzing the history of cosmology, the treatise delves into the prevailing scientific lack of explanation of the rotation of the heavenly bodies in the laws of dynamic behaviour of the sidereal system. The author proposes the application of the Theory of Dynamic Interactions (TID) to astrophysics, in particular, the dynamics of stellar systems and galaxies. This theory allows new comprehension of the dynamics of nature and understands the dynamic equilibrium of the universe, always subjected to rotational accelerations, but repetitive and persistent. The author also highlights that the orbiting always coincides with the intrinsic rotation of celestial bodies. Paradox incorporating the book, noting that this had not been found to date.\n\n\n1. Einstein, Albert: The Origins of the General Theory of Relativity, lecture given at the George A. Foundation Gibson, University of Glasgow, 20 June 1933. Published by Jackson, Wylie and co, Glasgow, 1933.\n\n"}
{"id": "52634071", "url": "https://en.wikipedia.org/wiki?curid=52634071", "title": "Nature-based solutions", "text": "Nature-based solutions\n\nNature-based solutions (NBS or NbS) refers to the sustainable management and use of nature for tackling socio-environmental challenges. The challenges include issues such as climate change, water security, water pollution, food security, human health, and disaster risk management. \n\nA definition by the European Union states that these solutions are \"inspired and supported by nature, which are cost-effective, simultaneously provide environmental, social and economic benefits and help build resilience. The Nature-based Solutions Initiative meanwhile defines them as \"actions that work with and enhance nature so as to help people adapt to change and disasters\". Such solutions bring more, and more diverse, nature and natural features and processes into cities, landscapes and seascapes, through locally adapted, resource-efficient and systemic interventions\". With NBS, healthy, resilient and diverse ecosystems (whether natural, managed or newly created) can provide solutions for the benefit of societies and overall biodiversity.\n\nFor instance, the restoration or protection of mangroves along coastlines utilizes a nature-based solution to accomplish several things. Mangroves moderate the impact of waves and wind on coastal settlements or cities and sequester CO . They also provide safe nurseries for marine life that can be the basis for sustaining populations of fish that local populations may depend on. Additionally, the mangrove forests can help control coastal erosion resulting from sea level rise. Similarly, in cities green roofs or walls are nature-based solutions that can be used to moderate the impact of high temperatures, capture storm water, abate pollution, and act as carbon sinks, while enhancing biodiversity.\n\nConservation approaches and environment management initiatives have been carried out for decades. What is new is that the benefits of such nature-based solutions to human well-being have been articulated well more recently. Even if the term itself is still being framed, examples of nature-based solutions can be found all over the world, and imitated. Nature-based solutions are on their way to being mainstreamed in national and international policies and programmes (e.g. climate change policy, law, infrastructure investment and financing mechanisms). For example, the theme for World Water Day 2018 was \"Nature for water\" and by UN-Water's accompanying UN World Water Development Report had the title \"Nature-based Solutions for Water\".\n\nSocieties increasingly face challenges such as climate change, urbanization, jeopardized food security and water resource provision, and disaster risk. One approach to answer these challenges is to singularly rely on technological strategies. An alternative approach is to manage the (socio-)ecological systems in a comprehensive way in order to sustain and potentially increase the delivery of ecosystem services to humans. In this context, nature-based solutions (NBS) have recently been put forward by practitioners and quickly thereafter by policymakers. These solutions stress the sustainable use of nature in solving coupled environmental-social-economic challenges. \n\nWhile ecosystem services are often valued in terms of immediate benefits to human well-being and economy, NBS focus on the benefits to people and the environment itself, to allow for sustainable solutions that are able to respond to environmental change and hazards in the long-term. NBS go beyond the traditional biodiversity conservation and management principles by \"re-focusing\" the debate on humans and specifically integrating societal factors such as human well-being and poverty reduction, socio-economic development, and governance principles. \n\nWith respect to water issues, NBS can achieve the following, according to the World Water Development Report 2018 by UN-Water: \n\nIn this sense, NBS are strongly connected to ideas such as natural systems agriculture, natural solutions, ecosystem-based approaches, adaptation services, natural infrastructure, green infrastructure and ecological engineering. For instance, ecosystem-based approaches are increasingly promoted for climate change adaptation and mitigation by organisations like United Nations Environment Programme and non-governmental organisations such as The Nature Conservancy. These organisations refer to \"policies and measures that take into account the role of ecosystem services in reducing the vulnerability of society to climate change, in a multi-sectoral and multi-scale approach\".\n\nLikewise, natural infrastructure is defined as a \"strategically planned and managed network of natural lands, such as forests and wetlands, working landscapes, and other open spaces that conserves or enhances ecosystem values and functions and provides associated benefits to human populations\"; and green infrastructure refers to an \"interconnected network of green spaces that conserves natural systems and provides assorted benefits to human populations\".\n\nSimilarly, the concept of ecological engineering generally refers to \"protecting, restoring (i.e. ecosystem restoration) or modifying ecological systems to increase the quantity, quality and sustainability of particular services they provide, or to build new ecological systems that provide services that would otherwise be provided through more conventional engineering, based on non-renewable resources\".\n\nThe International Union for the Conservation of Nature (IUCN) defines NBS as actions to protect, sustainably manage, and restore natural or modified ecosystems, that address societal challenges effectively and adaptively, simultaneously providing human well-being and biodiversity benefits, with climate change, food security, disaster risks, water security, social and economic development as well as human health being the common societal challenges.\n\nIUCN proposes to consider NBS as an umbrella concept. Categories and examples of NBS approaches according to IUCN include:\n\nThe general objective of NBS is clear, namely the sustainable management and use of nature for tackling societal challenges. However, different stakeholders view NBS from other perspectives. For instance, IUCN defines NBS as \"actions to protect, sustainably manage and restore natural or modified ecosystems, which address societal challenges effectively and adaptively, while simultaneously providing human well-being and biodiversity benefits\". This framing puts the need for well-managed and restored ecosystems at the heart of NBS, with the overarching goal of \"Supporting the achievement of society's development goals and safeguard human well-being in ways that reflect cultural and societal values and enhance the resilience of ecosystems, their capacity for renewal and the provision of services\". \n\nIn the context of the ongoing political debate on jobs and growth (main drivers of the current EU policy agenda), the European Commission underlines that NBS can transform environmental and societal challenges into innovation opportunities, by turning natural capital into a source for green growth and sustainable development. In their view, NBS to societal challenges are \"solutions that are inspired and supported by nature, which are cost-effective, simultaneously provide environmental, social and economic benefits and help build resilience. Such solutions bring more, and more diverse, nature and natural features and processes into cities, landscapes and seascapes, through locally adapted, resource-efficient and systemic interventions.\" \n\nThis framing is somewhat broader, and puts economy and social assets at the heart of NBS as importantly as sustaining environmental conditions. It shares similarities with the definition proposed by Maes and Jacobs (2015) defining NBS as \"any transition to a use of ES with decreased input of non-renewable natural capital and increased investment in renewable natural processes\". In their view, development and evaluation of NBS spans three basic requirements: (1) decrease of fossil fuel input per produced unit; (2) lowering of systemic trade-offs and increasing synergies between ES; and (3) increasing labor input and jobs. Here, nature is seen as a tool to inspire more systemic solutions to societal problems.\n\nWhatever definition used, promoting sustainability and the increased role of natural, self-sustained processes relying on biodiversity, are inherent to NBS. They constitute actions easily seen as positive for a wide range of stakeholders, as they bring about benefits at environmental, economic and social levels. As a consequence, the concept of NBS is gaining acceptance outside the conservation community (e.g. urban planning) and is now on its way to be mainstreamed into policies and programmes (climate change policy, law, infrastructure investment and financing mechanisms).\n\nIn 2015, the European network BiodivERsA mobilized a range of scientists, research donors and stakeholders and proposed a typology characterizing NBS along two gradients. 1. \"how much engineering of biodiversity and ecosystems is involved in NBS\", and 2. \"how many ecosystem services and stakeholder groups are targeted by a given NBS\". The typology highlights that NBS can involve very different actions on ecosystems (from protection to management and even creation of new ecosystems) and is based on the assumption that the higher the number of services and stakeholder groups targeted, the lower the capacity to maximize the delivery of each service and simultaneously fulfil the specific needs of all stakeholder groups. As such, three types of NBS are distinguished (Figure 2):\n\nType 1 NBS consists of no or minimal intervention in ecosystems, with the objectives of maintaining or improving the delivery of a range of ES both inside and outside of these conserved ecosystems. Examples include the protection of mangroves in coastal areas to limit risks associated to extreme weather conditions and provide benefits and opportunities to local populations; and the establishment of marine protected areas to conserve biodiversity within these areas while exporting biomass into fishing grounds. This type of NBS is connected to, for example, the concept of biosphere reserves which incorporates core protected areas for nature conservation and buffer zones and transition areas where people live and work in a sustainable way.\n\nType 2 NBS corresponds to management approaches that develop sustainable and multifunctional ecosystems and landscapes (extensively or intensively managed). These types improve the delivery of selected ES compared to what would be obtained with a more conventional intervention. Examples include innovative planning of agricultural landscapes to increase their multi-functionality; and approaches for enhancing tree species and genetic diversity to increase forest resilience to extreme events. This type of NBS is strongly connected to concepts like natural systems agriculture, agro-ecology, and evolutionary-orientated forestry.\n\nType 3 NBS consists of managing ecosystems in very extensive ways or even creating new ecosystems (e.g., artificial ecosystems with new assemblages of organisms for green roofs and walls to mitigate city warming and clean polluted air). Type 3 is linked to concepts like green and blue infrastructures and objectives like restoration of heavily degraded or polluted areas and greening cities.\n\nType 1 and 2 would typically fall within the IUCN NBS framework, whereas Type 2 and moreover Type 3 are often exemplified by EC for turning natural capital into a source for green growth and sustainable development.\n\nHybrid solutions exist along this gradient both in space and time. For instance, at landscape scale, mixing protected and managed areas could be needed to fulfil multi-functionality and sustainability goals. Similarly, a constructed wetland can be developed as a type 3 but, when well established, may subsequently be preserved and surveyed as a type 1.\n\nDemonstrating the benefits of nature and healthy ecosystems and showcasing the return on investment they can offer is necessary in order to increase awareness, but also to provide support and guidance on how to implement NBS. A large number of initiatives around the world already highlight the effectiveness of NBS approaches to address a wide range of societal challenges.\n\nThe following table shows examples from around the world:\n\nIn 2018, The Hindu reported that the East Kolkata wetlands, the world's largest organic sewage treatment facility had been used to clean the sewage of Kolkata in an organic manner by using algae for several decades. In use since the 1930s, the natural system was discovered by Dhrubajyoti Ghosh, an ecologist and a municipal engineer in the 1970s while working in the region. Ghosh worked for decades to protect the wetlands. It had been a practice in Kolkata, one of the five largest cities in India, for the municipal authorities to pump sewage into shallow ponds (\"bheris\"). Under the heat of the tropical sun, algae proliferated in them, converting the sewage into clean water, which in turn was used by villagers to grow paddy and vegetables. This system has been in use in the region since the 1930s and treats 750 million litres of wastewater per day, giving livelihood to 100,000 people in the vicinity. For his work, Ghosh was included in the UN Global 500 Roll of Honour in 1990 and received the Luc Hoffmann award in 2016.\n\nThere is currently no accepted basis on which a government agency, municipality or private company can systematically assess the efficiency, effectiveness and sustainability of a particular nature-based solution. However, a series of principles are proposed to guide effective and appropriate implementation, and thus to upscale NBS in practice. For example, NBS embrace and are not meant to replace nature conservation norms. Also, NBS are determined by site-specific natural and cultural contexts that include traditional, local and scientific knowledge. NBS are an integral part of the overall design of policies, and measure or actions, to address a specific challenges. Finally, NBS can be implemented alone or in an integrated manner with other solutions to societal challenges (e.g. technological and engineering solutions) and they are applied at the landscape scale.\n\nImplementing NBS requires political, economic, and scientific challenges to be tackled. First and foremost, private sector investment is needed, not to replace but to supplement traditional sources of capital such as public funding or philanthropy. The challenge is therefore to provide a robust evidence base for the contribution of nature to economic growth and jobs, and to demonstrate the economic viability of these solutions – compared to technological ones – on a timescale compatible with that of global change. Furthermore, it requires measures like adaptation of economic subsidy schemes, and the creation of opportunities for conservation finance, to name a few. Indeed, such measures will be needed to scale up NBS interventions, and strengthen their impact in mitigating the world's most pressing challenges.\n\nSince 2016, the EU is supporting a multi-stakeholder dialogue platform (called ThinkNature) to promote the co-design, testing and deployment of improved and innovative NBS in an integrated way. Creation of such science-policy-business-society interfaces could promote the market uptake of NBS. The project is part of the EU’s Horizon 2020 – Research and Innovation programme, and will last for 3 years. There are a total of 17 international partners involved, including the Technical University of Crete (Project Leader), the University of Helsinki and BiodivERsA.\n\nIn 2017, as part of the Presidency of the Estonian Republic of the Council of the European Union, a conference called “Nature-based Solutions: From Innovation to Common-use” was organized by the Ministry of the Environment of Estonia and the University of Tallinn. This conference aimed to strengthen synergies among various recent initiatives and programs related to NBS launched by the European Commission and by the EU Member States, focusing on policy and governance of NBS, and on research and innovation.\n\nIn recognition of the importance of natural ecosystems for mitigation and adaptation, the Paris Agreement calls on all Parties to acknowledge “the importance of the conservation and enhancement, as appropriate, of sinks and reservoirs of the greenhouse gases” and to “note the importance of ensuring the integrity of all ecosystems, including oceans, and the protection of biodiversity, recognized by some cultures as Mother Earth”. It then includes in its Articles several references to nature-based solutions. For example, Article 5.2 encourages Parties to adopt “…policy approaches and positive incentives for activities relating to reducing emissions from deforestation and forest degradation, and the role of conservation and sustainable management of forests and enhancement of forest carbon stocks in developing countries; and alternative policy approaches, such as joint mitigation and adaptation approaches for the integral and sustainable management of forests, while reaffirming the importance of incentivizing, as appropriate, non-carbon benefits associated with such approaches”. Article 7.1 further encourages Parties to build the resilience of socioeconomic and ecological systems, including through economic diversification and sustainable management of natural resources. In total, the Agreement refers to nature (ecosystems, natural resources, forests) in 13 distinct places. An in-depth analysis of all Nationally Determined Contributions submitted to UNFCCC, revealed that around 130 NDCs or 65% of signatories commit to nature-based solutions in their climate pledges, suggesting broad consensus for the role of nature in helping meet climate change goals. However, high-level commitments rarely translate into robust, measurable actions on-the-ground.\n\nThe term NBS was put forward by practitioners in the late 2000s (in particular the International Union for the Conservation of Nature and the World Bank) and thereafter by policymakers in Europe (most notably the European Commission). \n\nThe term \"nature-based solutions\" was first used in the late 2000s. It was used in the context of finding new solutions to mitigate and adapt to climate change effects, whilst simultaneously protecting biodiversity and improving sustainable livelihoods. \n\nThe IUCN referred to NBS in a position paper for the United Nations Framework Convention on Climate Change. The term was also adopted by European policymakers, in particular by the European Commission in a report stressing that NBS can offer innovative means to create jobs and growth as part of a green economy. The term started to make appearances in the mainstream media around the time of the Global Climate Action Summit in California in September 2018 \n\n\n"}
{"id": "52660479", "url": "https://en.wikipedia.org/wiki?curid=52660479", "title": "Open energy system databases", "text": "Open energy system databases\n\nOpen energy system database projects employ open data methods to collect, clean, and republish energy-related datasets for open use. The resulting information is then available, given a suitable open license, for statistical analysis and for building numerical energy system models, including open energy system models. Permissive licenses like Creative Commons CC0 and are preferred, but some projects will house data made public under market transparency regulations and carrying unqualified copyright.\n\nThe databases themselves may furnish information on national power plant fleets, renewable generation assets, transmission networks, time series for electricity loads, dispatch, spot prices, and cross-border trades, weather information, and similar. They may also offer other energy statistics including fossil fuel imports and exports, gas, oil, and coal prices, emissions certificate prices, and information on energy efficiency costs and benefits.\n\nMuch of the data is sourced from official or semi-official agencies, including national statistics offices, transmission system operators, and electricity market operators. Data is also crowdsourced using public wikis and public upload facilities. Projects usually also maintain a strict record of the provenance and version histories of the datasets they hold. Some projects, as part of their mandate, also try to persuade primary data providers to release their data under more liberal licensing conditions.\n\nTwo drivers favor the establishment of such databases. The first is a wish to reduce the duplication of effort that accompanies each new analytical project as it assembles and processes the data that it needs from primary sources. And the second is an increasing desire to make public policy energy models more transparent to improve their acceptance by policymakers and the public. Better transparency dictates the use of open information, able to be accessed and scrutinized by third-parties, in addition to releasing the source code for the models in question.\n\nIn the mid-1990s, energy models used structured text files for data interchange but efforts were being made to migrate to relational database management systems for data processing. These early efforts however remained local to a project and did not involve online publishing or open data principles.\n\nThe first energy information portal to go live was OpenEI in late 2009, followed by reegle in 2011.\n\nA 2012 paper marks the first scientific publication to advocate the crowdsourcing of energy data. The 2012 PhD thesis by Chris Davis also discusses the crowdsourcing of energy data in some depth. A 2016 thesis surveyed the spatial (GIS) information requirements for energy planning and finds that most types of data, with the exception of energy expenditure data, are available but nonetheless remain scattered and poorly coordinated.\n\nIn terms of open data, a 2017 paper concludes that energy research has lagged behind other fields, most notably physics, biotechnology, and medicine. The paper also lists the benefits of open data and open models and discusses the reasons that many projects nonetheless remain closed. A one-page opinion piece from 2017 advances the case for using open energy data and modeling to build public trust in policy analysis. The article also argues that scientific journals have a responsibility to require that data and code be submitted alongside text for peer review.\n\nData models are central to the design and organization of databases. Open energy database projects generally try to develop and adhere to well resolved data models, using defacto and published standards where applicable. Some projects attempt to coordinate their data models in order to harmonize their data and improve its utility. Defining and maintaining suitable metadata is also a key issue. The life-cycle management of data includes, but is not limited to, the use of version control to track the provenance of incoming and cleansed data. Some sites allow users to comment on and rate individual datasets.\n\nIssues surrounding copyright remain at the forefront with regard to open energy data. As noted, most energy datasets are collated and published by official or semi-official sources. But many of the publicly available energy datasets carry no license, limiting their reuse in numerical and statistical models, open or otherwise. Copyright protected material cannot lawfully be circulated, nor can it be modified and republished.\n\nMeasures to enforce market transparency have not helped much because the associated information is again not licensed to enable modification and republication. Transparency measures include the 2013 European energy market transparency regulation 543/2013. Indeed, 543/2013 \"is only an obligation to publish, not an obligation to license\". Notwithstanding, 543/2013 does enable downloaded data to be computer processed with legal certainty.\n\nEnergy databases with hardware located with the European Union are protected under a general database law, irrespective of the legal status of the information they hold.\nDatabase rights not waived by public sector providers significantly restrict the amount of data a user can lawfully access.\n\nA December 2017 submission by energy researchers in Germany and elsewhere highlighted a number of concerns over the re-use of public sector information within the Europe Union.\nThe submission drew heavily on a recent legal opinion covering electricity data.\n\nNational and international energy statistics are published regularly by governments and international agencies, such as the IEA. In 2016 the United Nations issued guidelines for energy statistics. While the definitions and sectoral breakdowns are useful when defining models, the information provided is rarely in sufficient detail to enable its use in high-resolution energy system models.\n\nThere are few published standards covering the collection and structuring of high-resolution energy system data. The IEC Common Information Model (CIM) defines data exchange protocols for low and high voltage electricity networks.\n\nEnergy system models are data intensive and normally require detailed information from a number of sources. Dedicated projects to collect, collate, document, and republish energy system datasets have arisen to service this need. Most database projects prefer open data, issued under free licenses, but some will accept datasets with proprietary licenses in the absence of other options.\n\nThe OpenStreetMap project, which uses the Open Database License (ODbL), contains geographic information about energy system components, including transmission lines. Wikipedia itself has a growing set of information related to national energy systems, including descriptions of individual power stations.\n\nThe following table summarizes projects that specifically publish open energy system data. Some are general repositories while others (for instance, oedb) are designed to interact with open energy system models in real-time.\n\nThe Energy Research Data Portal for South Africa is being developed by the Energy Research Centre, University of Cape Town, Cape Town, South Africa. Coverage includes South Africa and certain other African countries where the Centre undertakes projects. The website uses the CKAN open source data portal software. A number of data formats are supported, including CSV and XLSX. The site also offers an API for automated downloads. , the portal contained 65datasets.\n\nThe energydata.info project from the World Bank Group, Washington, DC, USA is an energy database portal designed to support national development by improving public access to energy information. As well as sharing data, the platform also offers tools to visualize and analyze energy data. Although the World Bank Group has made available a number of dataset and apps, external users and organizations are encouraged to contribute. The concepts of open data and open source development are central to the project. energydata.info uses its own fork of the CKAN open source data portal as its web-based platform. The Creative Commons CC BY 4.0 license is preferred for data but other open licenses can be deployed. Users are also bound by the terms of use for the site.\n\n, the database held 131datasets, the great majority related to developing countries. The datasets are tagged and can be easily filtered. A number of download formats, including GIS files, are supported: CSV, XLS, XLSX, ArcGIS, Esri, GeoJSON, KML, and SHP. Some datasets are also offered as HTML. Again, , four apps are available. Some are web-based and run from a browser.\n\nThe semantic wiki-site and database Enipedia lists energy systems data worldwide. Enipedia is maintained by the Energy and Industry Group, Faculty of Technology, Policy and Management, Delft University of Technology, Delft, the Netherlands. A key tenet of Enipedia is that data displayed on the wiki is not trapped within the wiki, but can be extracted via SPARQL queries and used to populate new tools. Any programming environment that can download content from a URL can be used to obtain data. Enipedia went live in March 2011, judging by traffic figures quoted by Davis.\n\nA 2010 study describes how community driven data collection, processing, curation, and sharing is revolutionizing the data needs of industrial ecology and energy system analysis. A 2012 chapter introduces a system of systems engineering (SoSE) perspective and outlines how agent-based models and crowdsourced data can contribute to the solving of global issues.\n\nThe OpenEnergy Platform (OEP) is a collaborative versioned dataset repository for storing open energy system model datasets. A dataset is presumed to be in the form of a database table, together with metadata. Registered users can upload and download datasets manually using a web-interface or programmatically via an API using HTTP POST calls. Uploaded datasets are screened for integrity using deterministic rules and then subject to confirmation by a moderator. The use of versioning means that any prior state of the database can be accessed (as recommended in this 2012 paper). Hence, the repository is specifically designed to interoperate with energy system models. The backend is a PostgreSQL object-relational database under subversion version control. Open source licenses are specific to each dataset. Unlike other database projects, users can download the current version (the public tables) of the entire PostgreSQL database or any previous version. Initial development is being lead by the Reiner Lemoine Institute, Berlin, Germany.\n\nThe Open Data Energy Networks ( or ) portal is run by eight partners, led by the French national transmission system operator (TSO) Réseau de Transport d'Électricité (RTE). The portal was previously known as Open Data RTE. The site offers electricity system datasets under a Creative Commons compatible license, with metadata, an RSS feed for notifying updates, and an interface for submitting questions. of information obtained from the site can also register third-party URLs (be they publications or webpages) against specific datasets.\n\nThe portal uses the French Government Licence Ouverte license and this is explicitly compatible with the United Kingdom Open Government Licence (OGL), the Creative Commons license (and thereby later versions), and the Open Data Commons license.\n\nThe site hosts electricity, gas, and weather information related to France.\n\nThe Open Power System Data (OPSD) project seeks to characterize the German and western European power plant fleets, their associated transmission network, and related information and to make that data available to energy modelers and analysts. The platform was originally implemented by the University of Flensburg, DIW Berlin, the Technical University of Berlin, and the energy economics consultancy Neon Neue Energieökonomik, all from Germany. The first phase of the project, from August 2015 to July 2017, was funded by the Federal Ministry for Economic Affairs and Energy (BMWi) for . The project later received funding for a second phase, from January 2018 to December 2020, with ETH Zurich replacing Flensburg University as a partner.\n\nDevelopers collate and harmonize data from a range of government, regulatory, and industry sources throughout Europe. The website and the metadata utilize English, whereas the original material can be in any one of 24languages. Datasets follow the emerging frictionless data package standard being developed by Open Knowledge International (OKI). The website was launched on 28October 2016. , the project offers the following primary packages, for Germany and other European countries:\n\n\nIn addition, the project hosts selected contributed packages:\n\n\nTo facilitate analysis, the data is aggregated into large structured files (in CSV format) and loaded into data packages with standardized machine-readable metadata (in JSON format). The same data is usually also provided as XLSX (Excel) and SQLite files. The datasets can be accessed in real-time using stable URLs. The Python scripts deployed for data processing are available on GitHub and carry an MIT license. The licensing conditions for the data itself depends on the source and varies in terms of openness. Previous versions of the datasets and scripts can be recovered in order to track changes or replicate earlier studies. The project also engages with energy data providers, such as transmission system operators (TSO) and ENTSO-E, to encourage them to make their data available under open licenses (for instance, Creative Commons and ODbL licenses).\n\nA number of published electricity market modeling analyses are based on OPSD data.\n\nIn 2017, the Open Power System Data project won the Schleswig-Holstein Open Science Award and the Germany Land of Ideas award.\n\nOpen Energy Information (OpenEI) is a collaborative website, run by the US government, providing open energy data to software developers, analysts, users, consumers, and policymakers. The platform is sponsored by the United States Department of Energy (DOE) and is being developed by the National Renewable Energy Laboratory (NREL). OpenEI launched on 9December 2009. While much of its data is from US government sources, the platform is intended to be open and global in scope.\n\nOpenEI provides two mechanisms for contributing structured information: a semantic wiki (using MediaWiki and the Semantic MediaWiki extension) for collaboratively-managed resources and a dataset upload facility for contributor-controlled resources. US government data is distributed under a CC0 public domain dedication, whereas other contributors are free to select an open data license of their choice. Users can rate data using a five-star system, based on accessibility, adaptability, usefulness, and general quality. Individual datasets can be manually downloaded in an appropriate format, often as CSV files. Scripts for processing data can also be shared through the site. In order to build a community around the platform, a number of forums are offered covering energy system data and related topics.\n\nMost of the data on OpenEI is exposed as linked open data (LOD) (described elsewhere on this page). OpenEI also uses LOD methods to populate its definitions throughout the wiki with real-time connections to DBPedia, reegle, and Wikipedia.\n\nOpenEI has been used to classify geothermal resources in the United States. And to publicize municipal utility rates, again within the US.\n\nOpenGridMap employs crowdsourcing techniques to gather detailed data on electricity network components and then infer a realistic network structure using methods from statistics and graph theory. The scope of the project is worldwide and both distribution and transmission networks can be reverse engineered. The project is managed by the Chair of Business Information Systems, TUM Department of Informatics, Technical University of Munich, Munich, Germany. The project maintains a website and a Facebook page and provides an Android mobile app to help the public document electrical devices, such as transformers and substations. The bulk of the data is being made available under a Creative Commons license. The processing software is written primarily in Python and MATLAB and is hosted on GitHub.\n\nOpenGridMap provides a tailored GIS web application, layered on OpenStreetMap, which contributors can use to upload and edit information directly. The same database automatically stores field recordings submitted by the mobile app. Subsequent classification by experts allows normal citizens to document and photograph electrical components and have them correctly identified. The project is experimenting with the use of hobby drones to obtain better information on associated facilities, such as photovoltaic installations. Transmission line data is also sourced from and shared with OpenStreetMap. Each component record is verified by a moderator.\n\nOnce sufficient data is available, the transnet software is run to produce a likely network, using statistical correlation, Voronoi partitioning, and minimum spanning tree (MST) algorithms. The resulting network can be exported in CSV (separate files for nodes and lines), XML, and CIM formats. CIM models are well suited for translation into software-specific data formats for further analysis, including power grid simulation. Transnet also displays descriptive statistics about the resulting network for visual confirmation.\n\nThe project is motivated by the need to provide datasets for high-resolution energy system models, so that energy system transitions (like the German \"Energiewende\") can be better managed, both technically and policy-wise. The rapid expansion of renewable generation and the anticipated uptake of electric vehicles means that electricity system models must increasingly represent distribution and transmission networks in some detail.\n\n, OpenGridMap techniques have been used to estimate the low voltage network in the German city of Garching and to estimate the high voltage grids in several other countries.\n\nreegle is a clean energy information portal covering renewable energy, energy efficiency, and climate compatible development topics. reegle was launched in 2006 by REEEP and REN21 with funding from the Dutch (VROM), German (BMU), and UK (Defra) environment ministries. Originally released as a specialized internet search engine, reegle was relaunched in 2011 as an information portal.\n\nreegle offers and utilizes linked open data (LOD) (described elsewhere on this page). Sources of data include UN and World Bank databases, as well as dedicated partners around the world. reegle maintains a comprehensive structured glossary (driven by an LOD-compliant thesaurus) of energy and climate compatible development terms to assist with the tagging of datasets. The glossary also facilitates intelligent web searches.\n\nreegle offers country profiles which collate and display energy data on a per-country basis for most of the world. These profiles are kept current automatically using LOD techniques.\n\nRenewables.ninja is a website that can calculate the hourly power output from solar photovoltaic installations and wind farms located anywhere in the world. The website is a joint project between the Department of Environmental Systems Science, ETH Zurich, Zürich, Switzerland and the Centre for Environmental Policy, Imperial College London, London, United Kingdom. The website went live during September 2016. The resulting time series are provided under a Creative Commons license and the underlying power plant models are published using a BSD-new license. , only the solar model, written in Python, has been released.\n\nThe project relies on weather data derived from meteorological reanalysis models and weather satellite images. More specifically, it uses the 2016 MERRA-2 reanalysis dataset from NASA and satellite images from CM-SAF SARAH. For locations in Europe, this weather data is further \"corrected\" by country so that it better fits with the output from known PV installations and windfarms. Two 2016 papers describe the methods used in detail in relation to Europe. The first covers the calculation of PV power. And the second covers the calculation of wind power.\n\nThe website displays an interactive world map to aid the selection of a site. Users can then choose a plant type and enter some technical characteristics. , only year 2014 data can be served, due to technical restrictions. The results are automatically plotted and are available for download in hourly CSV format with or without the associated weather information. The site offers an API for programmatic dataset recovery using token-based authorization. Examples deploying cURL and Python are provided.\n\nA number of studies have been undertaking using the power production datasets underpinning the website (these studies predate the launch of the website), with the bulk focusing on energy options for Great Britain.\n\nThe SMARD site (pronounced \"smart\") serves electricity market data from Germany, Austria, and Luxembourg and also provides visual information. The electricity market plots and their underlying time series are released under a permissive CC BY 4.0 license. The site itself was launched on 3July 2017 in German and an English translation followed shortly. The data portal is mandated under the German Energy Industry Act (\"\" or \"EnWG\") section §111d, introduced as an amendment on 13October 2016. Four table formats are offered: CSV, XLS, XML, and PDF. The maximum sampling resolution is . Market data visuals or plots can be downloaded in PDF, SVG, PNG, and JPG formats. Representative output is shown in the thumbnail (on the left), in this case mid-winter dispatch over two days for the whole of Germany. The horizontal ordering by generation type is first split into renewable and conventional generation and then based on merit.\n\n\n\n"}
{"id": "1841288", "url": "https://en.wikipedia.org/wiki?curid=1841288", "title": "Outline of energy", "text": "Outline of energy\n\nThe following outline is provided as an overview of and topical guide to energy:\n\nEnergy – in physics, this is an indirectly observed quantity often understood as the ability of a physical system to do work on other physical systems. Since work is defined as a force acting through a distance (a length of space), energy is always equivalent to the ability to exert force (a pull or a push) against an object that is moving along a definite path of certain length.\n\n\nUnits of energy\n\n\nEnergy industry\n\nSee especially and for a large number of conventional energy related topics.\n\n\nHistory of energy\n\n\n\n\n\n\nEnergy economics\n\n\n\n\n\n\n"}
{"id": "35659147", "url": "https://en.wikipedia.org/wiki?curid=35659147", "title": "Patterns in nature", "text": "Patterns in nature\n\nPatterns in nature are visible regularities of form found in the natural world. These patterns recur in different contexts and can sometimes be modelled mathematically. Natural patterns include symmetries, trees, spirals, meanders, waves, foams, tessellations, cracks and stripes. Early Greek philosophers studied pattern, with Plato, Pythagoras and Empedocles attempting to explain order in nature. The modern understanding of visible patterns developed gradually over time.\n\nIn the 19th century, Belgian physicist Joseph Plateau examined soap films, leading him to formulate the concept of a minimal surface. German biologist and artist Ernst Haeckel painted hundreds of marine organisms to emphasise their symmetry. Scottish biologist D'Arcy Thompson pioneered the study of growth patterns in both plants and animals, showing that simple equations could explain spiral growth. In the 20th century, British mathematician Alan Turing predicted mechanisms of morphogenesis which give rise to patterns of spots and stripes. Hungarian biologist Aristid Lindenmayer and French American mathematician Benoît Mandelbrot showed how the mathematics of fractals could create plant growth patterns.\n\nMathematics, physics and chemistry can explain patterns in nature at different levels. Patterns in living things are explained by the biological processes of natural selection and sexual selection. Studies of pattern formation make use of computer models to simulate a wide range of patterns.\n\nEarly Greek philosophers attempted to explain order in nature, anticipating modern concepts. Plato (c. 427 – c. 347 BC) — looking only at his work on natural patterns — argued for the existence of universals. He considered these to consist of ideal forms ( \"eidos\": \"form\") of which physical objects are never more than imperfect copies. Thus, a flower may be roughly circular, but it is never a perfect mathematical circle. Pythagoras explained patterns in nature like the harmonies of music as arising from number, which he took to be the basic constituent of existence. Empedocles to an extent anticipated Darwin's evolutionary explanation for the structures of organisms.\n\nIn 1202, Leonardo Fibonacci (c. 1170 – c. 1250) introduced the Fibonacci number sequence to the western world with his book \"Liber Abaci\". Fibonacci gave an (unrealistic) biological example, on the growth in numbers of a theoretical rabbit population.\n\nIn 1658, the English physician and philosopher Sir Thomas Browne discussed \"how Nature Geometrizeth\" in \"The Garden of Cyrus\", citing Pythagorean numerology involving the number 5, and the Platonic form of the quincunx pattern. The discourse's central chapter features examples and observations of the quincunx in botany.\n\nIn 1917, D'Arcy Wentworth Thompson (1860–1948) published his book \"On Growth and Form\". His description of phyllotaxis and the Fibonacci sequence, the mathematical relationships in the spiral growth patterns of plants, is classic. He showed that simple equations could describe all the apparently complex spiral growth patterns of animal horns and mollusc shells.\n\nThe Belgian physicist Joseph Plateau (1801–1883) formulated the mathematical problem of the existence of a minimal surface with a given boundary, which is now named after him. He studied soap films intensively, formulating Plateau's laws which describe the structures formed by films in foams.\n\nThe German psychologist Adolf Zeising (1810–1876) claimed that the golden ratio was expressed in the arrangement of plant parts, in the skeletons of animals and the branching patterns of their veins and nerves, as well as in the geometry of crystals.\n\nErnst Haeckel (1834–1919) painted beautiful illustrations of marine organisms, in particular Radiolaria, emphasising their symmetry to support his faux-Darwinian theories of evolution.\n\nThe American photographer Wilson Bentley (1865–1931) took the first micrograph of a snowflake in 1885.\nIn 1952, Alan Turing (1912–1954), better known for his work on computing and codebreaking, wrote \"The Chemical Basis of Morphogenesis\", an analysis of the mechanisms that would be needed to create patterns in living organisms, in the process called morphogenesis. He predicted oscillating chemical reactions, in particular the Belousov–Zhabotinsky reaction. These activator-inhibitor mechanisms can, Turing suggested, generate patterns (dubbed \"Turing patterns\") of stripes and spots in animals, and contribute to the spiral patterns seen in plant phyllotaxis.\n\nIn 1968, the Hungarian theoretical biologist Aristid Lindenmayer (1925–1989) developed the L-system, a formal grammar which can be used to model plant growth patterns in the style of fractals. L-systems have an alphabet of symbols that can be combined using production rules to build larger strings of symbols, and a mechanism for translating the generated strings into geometric structures. In 1975, after centuries of slow development of the mathematics of patterns by Gottfried Leibniz, Georg Cantor, Helge von Koch, Wacław Sierpiński and others, Benoît Mandelbrot wrote a famous paper, \"How Long Is the Coast of Britain? Statistical Self-Similarity and Fractional Dimension\", crystallising mathematical thought into the concept of the fractal.\n\nLiving things like orchids, hummingbirds, and the peacock's tail have abstract designs with a beauty of form, pattern and colour that artists struggle to match. The beauty that people perceive in nature has causes at different levels, notably in the mathematics that governs what patterns can physically form, and among living things in the effects of natural selection, that govern how patterns evolve.\n\nMathematics seeks to discover and explain abstract patterns or regularities of all kinds.\nVisual patterns in nature find explanations in chaos theory, fractals, logarithmic spirals, topology and other mathematical patterns. For example, L-systems form convincing models of different patterns of tree growth.\nThe laws of physics apply the abstractions of mathematics to the real world, often as if it were perfect. For example, a crystal is perfect when it has no structural defects such as dislocations and is fully symmetric. Exact mathematical perfection can only approximate real objects. Visible patterns in nature are governed by physical laws; for example, meanders can be explained using fluid dynamics.\n\nIn biology, natural selection can cause the development of patterns in living things for several reasons, including camouflage, sexual selection, and different kinds of signalling, including mimicry and cleaning symbiosis. In plants, the shapes, colours, and patterns of insect-pollinated flowers like the lily have evolved to attract insects such as bees. Radial patterns of colours and stripes, some visible only in ultraviolet light serve as nectar guides that can be seen at a distance.\n\nSymmetry is pervasive in living things. Animals mainly have bilateral or mirror symmetry, as do the leaves of plants and some flowers such as orchids. Plants often have radial or rotational symmetry, as do many flowers and some groups of animals such as sea anemones. Fivefold symmetry is found in the echinoderms, the group that includes starfish, sea urchins, and sea lilies.\n\nAmong non-living things, snowflakes have striking sixfold symmetry; each flake's structure forms a record of the varying conditions during its crystallization, with nearly the same pattern of growth on each of its six arms. Crystals in general have a variety of symmetries and crystal habits; they can be cubic or octahedral, but true crystals cannot have fivefold symmetry (unlike quasicrystals). Rotational symmetry is found at different scales among non-living things, including the crown-shaped splash pattern formed when a drop falls into a pond, and both the spheroidal shape and rings of a planet like Saturn.\n\nSymmetry has a variety of causes. Radial symmetry suits organisms like sea anemones whose adults do not move: food and threats may arrive from any direction. But animals that move in one direction necessarily have upper and lower sides, head and tail ends, and therefore a left and a right. The head becomes specialised with a mouth and sense organs (cephalisation), and the body becomes bilaterally symmetric (though internal organs need not be). More puzzling is the reason for the fivefold (pentaradiate) symmetry of the echinoderms. Early echinoderms were bilaterally symmetrical, as their larvae still are. Sumrall and Wray argue that the loss of the old symmetry had both developmental and ecological causes.\n\nFractals are infinitely self-similar, iterated mathematical constructs having fractal dimension. Infinite iteration is not possible in nature so all 'fractal' patterns are only approximate. For example, the leaves of ferns and umbellifers (Apiaceae) are only self-similar (pinnate) to 2, 3 or 4 levels. Fern-like growth patterns occur in plants and in animals including bryozoa, corals, hydrozoa like the air fern, \"Sertularia argentea\", and in non-living things, notably electrical discharges. Lindenmayer system fractals can model different patterns of tree growth by varying a small number of parameters including branching angle, distance between nodes or branch points (internode length), and number of branches per branch point.\n\nFractal-like patterns occur widely in nature, in phenomena as diverse as clouds, river networks, geologic fault lines, mountains, coastlines, animal coloration, snow flakes, crystals, blood vessel branching, actin cytoskeleton, and ocean waves.\n\nSpirals are common in plants and in some animals, notably molluscs. For example, in the nautilus, a cephalopod mollusc, each chamber of its shell is an approximate copy of the next one, scaled by a constant factor and arranged in a logarithmic spiral. Given a modern understanding of fractals, a growth spiral can be seen as a special case of self-similarity.\n\nPlant spirals can be seen in phyllotaxis, the arrangement of leaves on a stem, and in the arrangement (parastichy) of other parts as in composite flower heads and seed heads like the sunflower or fruit structures like the pineapple and snake fruit, as well as in the pattern of scales in pine cones, where multiple spirals run both clockwise and anticlockwise. These arrangements have explanations at different levels – mathematics, physics, chemistry, biology – each individually correct, but all necessary together. Phyllotaxis spirals can be generated mathematically from Fibonacci ratios: the Fibonacci sequence runs 1, 1, 2, 3, 5, 8, 13... (each subsequent number being the sum of the two preceding ones). For example, when leaves alternate up a stem, one rotation of the spiral touches two leaves, so the pattern or ratio is 1/2. In hazel the ratio is 1/3; in apricot it is 2/5; in pear it is 3/8; in almond it is 5/13. In disc phyllotaxis as in the sunflower and daisy, the florets are arranged in Fermat's spiral with Fibonacci numbering, at least when the flowerhead is mature so all the elements are the same size. Fibonacci ratios approximate the golden angle, 137.508°, which governs the curvature of Fermat's spiral.\n\nFrom the point of view of physics, spirals are lowest-energy configurations which emerge spontaneously through self-organizing processes in dynamic systems. From the point of view of chemistry, a spiral can be generated by a reaction-diffusion process, involving both activation and inhibition. Phyllotaxis is controlled by proteins that manipulate the concentration of the plant hormone auxin, which activates meristem growth, alongside other mechanisms to control the relative angle of buds around the stem. From a biological perspective, arranging leaves as far apart as possible in any given space is favoured by natural selection as it maximises access to resources, especially sunlight for photosynthesis.\n\nIn mathematics, a dynamical system is chaotic if it is (highly) sensitive to initial conditions (the so-called \"butterfly effect\"), which requires the mathematical properties of topological mixing and dense periodic orbits.\n\nAlongside fractals, chaos theory ranks as an essentially universal influence on patterns in nature. There is a relationship between chaos and fractals—the \"strange attractors\" in chaotic systems have a fractal dimension. Some cellular automata, simple sets of mathematical rules that generate patterns, have chaotic behaviour, notably Stephen Wolfram's Rule 30.\n\nVortex streets are zigzagging patterns of whirling vortices created by the unsteady separation of flow of a fluid, most often air or water, over obstructing objects. Smooth (laminar) flow starts to break up when the size of the obstruction or the velocity of the flow become large enough compared to the viscosity of the fluid.\n\nMeanders are sinuous bends in rivers or other channels, which form as a fluid, most often water, flows around bends. As soon as the path is slightly curved, the size and curvature of each loop increases as helical flow drags material like sand and gravel across the river to the inside of the bend. The outside of the loop is left clean and unprotected, so erosion accelerates, further increasing the meandering in a powerful positive feedback loop.\n\nWaves are disturbances that carry energy as they move. Mechanical waves propagate through a medium – air or water, making it oscillate as they pass by. Wind waves are sea surface waves that create the characteristic chaotic pattern of any large body of water, though their statistical behaviour can be predicted with wind wave models. As waves in water or wind pass over sand, they create patterns of ripples. When winds blow over large bodies of sand, they create dunes, sometimes in extensive dune fields as in the Taklamakan desert. Dunes may form a range of patterns including crescents, very long straight lines, stars, domes, parabolas, and longitudinal or seif ('sword') shapes.\n\nBarchans or crescent dunes are produced by wind acting on desert sand; the two horns of the crescent and the slip face point downwind. Sand blows over the upwind face, which stands at about 15 degrees from the horizontal, and falls onto the slip face, where it accumulates up to the angle of repose of the sand, which is about 35 degrees. When the slip face exceeds the angle of repose, the sand avalanches, which is a nonlinear behaviour: the addition of many small amounts of sand causes nothing much to happen, but then the addition of a further small amount suddenly causes a large amount to avalanche. Apart from this nonlinearity, barchans behave rather like solitary waves.\n\nA soap bubble forms a sphere, a surface with minimal area — the smallest possible surface area for the volume enclosed. Two bubbles together form a more complex shape: the outer surfaces of both bubbles are spherical; these surfaces are joined by a third spherical surface as the smaller bubble bulges slightly into the larger one.\n\nA foam is a mass of bubbles; foams of different materials occur in nature. Foams composed of soap films obey Plateau's laws, which require three soap films to meet at each edge at 120° and four soap edges to meet at each vertex at the tetrahedral angle of about 109.5°. Plateau's laws further require films to be smooth and continuous, and to have a constant average curvature at every point. For example, a film may remain nearly flat on average by being curved up in one direction (say, left to right) while being curved downwards in another direction (say, front to back). Structures with minimal surfaces can be used as tents. Lord Kelvin identified the problem of the most efficient way to pack cells of equal volume as a foam in 1887; his solution uses just one solid, the bitruncated cubic honeycomb with very slightly curved faces to meet Plateau's laws. No better solution was found until 1993 when Denis Weaire and Robert Phelan proposed the Weaire–Phelan structure; the Beijing National Aquatics Center adapted the structure for their outer wall in the 2008 Summer Olympics.\n\nAt the scale of living cells, foam patterns are common; radiolarians, sponge spicules, silicoflagellate exoskeletons and the calcite skeleton of a sea urchin, \"Cidaris rugosa\", all resemble mineral casts of Plateau foam boundaries. The skeleton of the Radiolarian, \"Aulonia hexagona\", a beautiful marine form drawn by Ernst Haeckel, looks as if it is a sphere composed wholly of hexagons, but this is mathematically impossible. The Euler characteristic states that for any convex polyhedron, the number of faces plus the number of vertices (corners) equals the number of edges plus two. A result of this formula is that any closed polyhedron of hexagons has to include exactly 12 pentagons, like a soccer ball, Buckminster Fuller geodesic dome, or fullerene molecule. This can be visualised by noting that a mesh of hexagons is flat like a sheet of chicken wire, but each pentagon that is added forces the mesh to bend (there are fewer corners, so the mesh is pulled in).\n\nTessellations are patterns formed by repeating tiles all over a flat surface. There are 17 wallpaper groups of tilings. While common in art and design, exactly repeating tilings are less easy to find in living things. The cells in the paper nests of social wasps, and the wax cells in honeycomb built by honey bees are well-known examples. Among animals, bony fish, reptiles or the pangolin, or fruits like the salak are protected by overlapping scales or osteoderms, these form more-or-less exactly repeating units, though often the scales in fact vary continuously in size. Among flowers, the snake's head fritillary, \"Fritillaria meleagris\", have a tessellated chequerboard pattern on their petals. The structures of minerals provide good examples of regularly repeating three-dimensional arrays. Despite the hundreds of thousands of known minerals, there are rather few possible types of arrangement of atoms in a crystal, defined by crystal structure, crystal system, and point group; for example, there are exactly 14 Bravais lattices for the 7 lattice systems in three-dimensional space.\n\nCracks are linear openings that form in materials to relieve stress. When an elastic material stretches or shrinks uniformly, it eventually reaches its breaking strength and then fails suddenly in all directions, creating cracks with 120 degree joints, so three cracks meet at a node. Conversely, when an inelastic material fails, straight cracks form to relieve the stress. Further stress in the same direction would then simply open the existing cracks; stress at right angles can create new cracks, at 90 degrees to the old ones. Thus the pattern of cracks indicates whether the material is elastic or not. In a tough fibrous material like oak tree bark, cracks form to relieve stress as usual, but they do not grow long as their growth is interrupted by bundles of strong elastic fibres. Since each species of tree has its own structure at the levels of cell and of molecules, each has its own pattern of splitting in its bark.\n\nLeopards and ladybirds are spotted; angelfish and zebras are striped. These patterns have an evolutionary explanation: they have functions which increase the chances that the offspring of the patterned animal will survive to reproduce. One function of animal patterns is camouflage; for instance, a leopard that is harder to see catches more prey. Another function is signalling — for instance, a ladybird is less likely to be attacked by predatory birds that hunt by sight, if it has bold warning colours, and is also distastefully bitter or poisonous, or mimics other distasteful insects. A young bird may see a warning patterned insect like a ladybird and try to eat it, but it will only do this once; very soon it will spit out the bitter insect; the other ladybirds in the area will remain undisturbed. The young leopards and ladybirds, inheriting genes that somehow create spottedness, survive. But while these evolutionary and functional arguments explain why these animals need their patterns, they do not explain how the patterns are formed.\n\nAlan Turing, and later the mathematical biologist James Murray, described a mechanism that spontaneously creates spotted or striped patterns: a reaction-diffusion system. The cells of a young organism have genes that can be switched on by a chemical signal, a morphogen, resulting in the growth of a certain type of structure, say a darkly pigmented patch of skin. If the morphogen is present everywhere, the result is an even pigmentation, as in a black leopard. But if it is unevenly distributed, spots or stripes can result. Turing suggested that there could be feedback control of the production of the morphogen itself. This could cause continuous fluctuations in the amount of morphogen as it diffused around the body. A second mechanism is needed to create standing wave patterns (to result in spots or stripes): an inhibitor chemical that switches off production of the morphogen, and that itself diffuses through the body more quickly than the morphogen, resulting in an activator-inhibitor scheme. The Belousov–Zhabotinsky reaction is a non-biological example of this kind of scheme, a chemical oscillator.\n\nLater research has managed to create convincing models of patterns as diverse as zebra stripes, giraffe blotches, jaguar spots (medium-dark patches surrounded by dark broken rings) and ladybird shell patterns (different geometrical layouts of spots and stripes, see illustrations). Richard Prum's activation-inhibition models, developed from Turing's work, use six variables to account for the observed range of nine basic within-feather pigmentation patterns, from the simplest, a central pigment patch, via concentric patches, bars, chevrons, eye spot, pair of central spots, rows of paired spots and an array of dots. More elaborate models simulate complex feather patterns in the guineafowl \"Numida meleagris\" in which the individual feathers feature transitions from bars at the base to an array of dots at the far (distal) end. These require an oscillation created by two inhibiting signals, with interactions in both space and time.\n\nPatterns can form for other reasons in the vegetated landscape of tiger bush and fir waves. Tiger bush stripes occur on arid slopes where plant growth is limited by rainfall. Each roughly horizontal stripe of vegetation effectively collects the rainwater from the bare zone immediately above it. Fir waves occur in forests on mountain slopes after wind disturbance, during regeneration. When trees fall, the trees that they had sheltered become exposed and are in turn more likely to be damaged, so gaps tend to expand downwind. Meanwhile, on the windward side, young trees grow, protected by the wind shadow of the remaining tall trees. Natural patterns are sometimes formed by animals, as in the Mima mounds of the Northwestern United States and some other areas, which appear to be created over many years by the burrowing activities of pocket gophers, while the so-called fairy circles of Namibia appear to be created by the interaction of competing groups of sand termites, along with competition for water among the desert plants.\n\nIn permafrost soils with an active upper layer subject to annual freeze and thaw, patterned ground can form, creating circles, nets, ice wedge polygons, steps, and stripes. Thermal contraction causes shrinkage cracks to form; in a thaw, water fills the cracks, expanding to form ice when next frozen, and widening the cracks into wedges. These cracks may join up to form polygons and other shapes.\n\nThe fissured pattern that develops on vertebrate brains are caused by a physical process of constrained expansion dependent on two geometric parameters: relative tangential cortical expansion and relative thickness of the cortex. Similar patterns of gyri (peaks) and sulci (troughs) have been demonstrated in models of the brain starting from smooth, layered gels, with the patterns caused by compressive mechanical forces resulting from the expansion of the outer layer (representing the cortex) after the addition of a solvent. Numerical models in computer simulations support natural and experimental observations that the surface folding patterns increase in larger brains.\n\n\n\n\n\n"}
