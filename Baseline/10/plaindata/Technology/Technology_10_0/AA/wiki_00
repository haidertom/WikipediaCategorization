{"id": "36235294", "url": "https://en.wikipedia.org/wiki?curid=36235294", "title": "3G adoption", "text": "3G adoption\n\n3G mobile telephony was relatively slow to be adopted 3Gglobally. In some instances, 3G networks do not use the same radio frequencies as 2G so mobile operators must build entirely new networks and license entirely new frequencies, especially so to achieve high data transmission rates. Other delays were due to the expenses of upgrading transmission hardware, especially for UMTS, whose deployment required the replacement of most broadcast towers. Due to these issues and difficulties with deployment, many carriers were not able to or delayed acquisition of these updated capabilities.\n\nIn December 2007, 190 3G networks were operating in 40 countries and 154 HSDPA networks were operating in 71 countries, according to the Global Mobile Suppliers Association (GSA). In Asia, Europe, Canada and the USA, telecommunication companies use W-CDMA technology with the support of around 100 terminal designs to operate 3G mobile networks.\n\nRoll-out of 3G networks was delayed in some countries by the enormous costs of additional spectrum licensing fees. (See Telecoms crash.) The license fees in some European countries were particularly high, bolstered by government auctions of a limited number of licenses and sealed bid auctions, and initial excitement over 3G's potential.\n\nThe 3G standard is perhaps well known because of a massive expansion of the mobile communications market post-2G and advances of the consumer mophone. An especially notable development during this time is the smartphone (for example, the iPhone, and the Android family), combining the abilities of a PDA with a mobile phone, leading to widespread demand for mobile internet connectivity. 3G has also introduced the term \"mobile broadband\" because its speed and capability make it a viable alternative for internet browsing, and USB Modems connecting to 3G networks are becoming increasingly common.\n\nThe first African use of 3G technology was a 3G video call made in Johannesburg on the Vodacom network in November 2004. The first commercial launch was by Emtel-ltd in Mauritius in 2004. In late March 2006, a 3G service was provided by the new company Wana in Morocco. In May 2007, Safaricom launched 3G services in Kenya while later that year Vodacom Tanzania also started providing services. In February 2012 Bharti Airtel Launched a 3.75G Network in selected cities in Kenya with a countrywide rollout planned for later in the year. In Egypt, Mobinil launched the service in 2008 and in Somaliland, Telesom started first 3G services on 3 July 2011, to both prepaid and postpaid subscription customers.\nTelecommunication networks in Nigeria like Globacom, Etisalat, Airtel and MTN provide 3G services to their numerous customers.\n\nAsia is also using 3G services very well. A lot of companies like Dialog Axiata PLC Sri Lanka (First to serve 3G Service in South Asia in 2006), BSNL, WorldCall, PTCL, Mobilink, Zong, Ufone, Telenor PK, Maxis, Vodafone, Airtel, Idea Cellular, Aircel, Tata DoCoMo and Reliance have released their 3G services.\n\nSri Lanka's All Mobile Networks(Dialog, Mobitel, Etisalat, Hutch, Airtel,) And CDMA Network Providers (Lankabell, Dialog,Suntel,SLT) Launched 3G Services.\n\nDialog, Mobitel launched 4G LTE Services In Sri Lanka.\nNot Only (Dialog CDMA, Lankabell CDMA Have 4G LTE Services.\nSri Lanka Telecom Have 4G LTE , FTTX Services..\n\nOn March 19, 2012, Etisalat Afghanistan, the fastest growing telecommunications company in the country and part of Etisalat Group, announced the launch of 3G services in Afghanistan. between 2013-2014 all telecommunications company ( Afghan Wireless, Etisalat, Roshan, MTN and Salaam Network) provided 3G, 3.5G and 3.75G services and they are planning for 4G services in 2016-2017.\n\nNepal was one of the first countries in southern Asia to launch 3G services. Nepal's first 3G company was NTC(Nepal Telecom Corporation) and the second was Ncell. Ncell also covered Mount Everest with 3G. NTC provides high speed video calling with other 3G services, as well as post-paid and pre-paid 3G SIM cards.\n\n3G and 4G was simultaneously launched in Pakistan on April 23, 2014 through a SMRA Auction. Three out of Five Companies got a 3G licence i.e. Ufone, Mobilink and Telenor while China Mobile's Zong got 3G as well as a 4G licence. Whereas fifth company, Warid Pakistan did not participate in the auction procedure, But they launched 4G LTE services on their existing 2G 1800 MHz spectrum due to Technology neutral terms and became world's first Telecom Company to transform directly from 2G to 4G. With that Pakistan joined the 3G and 4G world.\nIn the non-mobile sector, Pakistan's biggest telecommunication company PTCL launched its 3G network, EVO, in mid-2008 and has since then established itself in this sector. It provides 3G services in 105 cities across Pakistan. Omantel's WorldCall also provides 3G services in 50 cities Pakistan-wide. They provide mobile broadband service via dongles and modems. On 14 August 2010, Pakistan became the first country in the world to experience EVDO's RevB 3G technology that offers maximum speeds of 9.3 Mbit/s. At present the services of EVO Nitro (brand name) are available in Islamabad, Rawalpindi, Lahore and Karachi. The RevA network, with speeds if up to 3.1 Mbit/s is available in over 100 cities of the country.\n\nState-run mobile operator Teletalk Bangladesh limited and other GSM operators GrameenPhone, Banglalink, Robi and Airtel already started hi-speed 3G+ and 3.5G services using UMTS with HSDPA facilities. Grameenphone has a plan to launch 4G LTE services first time in Bangladesh using TD-LTE technology. Currently Grameenphone owned 10 MHz spectrum at 3G auction by BTRC.Robi and Airtel recently merged, newly merged company has a plan to introduce 4G operation soon. Two other data operators, Qubee and Banglalion, currently offer 4G Wimax services in Bangladesh. CityCell now switched off their operation by government order. 4G LTE services have already begun in Bangladesh through all mobile operators except Teletalk, the state run mobile operator. Bangladesh has a plan to introduce super speed 5G service soon. A test run will be conducted in the country in mid July 2018.\n\nChina announced in May 2008, that the telecoms sector was re-organized and three 3G networks would be allocated so that the largest mobile operator, China Mobile, would retain its GSM customer base. China Unicom would retain its GSM customer base but relinquish its CDMA2000 customer base, and launch 3G on the globally leading W-CDMA (UMTS) standard. The CDMA2000 customers of China Unicom would go to China Telecom, which would then launch 3G on the CDMA2000 1x EV-DO standard. This meant that China would have all three main cellular technology 3G standards in commercial use. Finally in January 2009, Ministry of industry and Information Technology of China awarded licenses of all three standards: TD-SCDMA to China Mobile, W-CDMA to China Unicom and CDMA2000 to China Telecom. The launch of 3G occurred on 1 October 2009, to coincide with the 60th Anniversary of the Founding of the People's Republic of China. By August 2011, China Telecom's 3G subscriber has exceeded 23 million\n\n11 December 2008, India entered the 3G arena with the launch of 3G enabled Mobile and Data services by Government owned Mahanagar Telephone Nigam Ltd MTNL in Delhi and later in Mumbai. MTNL becomes the first 3G Mobile service provider in India. After MTNL, another state operator Bharat Sanchar Nigam Ltd. (BSNL) launched 3G services on 22 Feb 2009 in Chennai and Kolkata and later launched 3G as Nationwide. The auction of 3G wireless spectrum was announced in April 2010 and 3G Spectrum allocated to all private operators on 1 September 2010.\n\nNorth Korea has had a 3G network since 2008, which is called Koryolink, a joint venture between Egyptian company Orascom Telecom Holding and the state-owned Korea Post and Telecommunications Corporation (KPTC) is North Korea's only 3G Mobile operator, and one of only two mobile companies in the country. According to Orascom quoted in BusinessWeek, the company had 125,661 subscribers in May 2010. The Egyptian company owns 75 percent of Koryolink, and is known to invest in infrastructure for mobile technology in developing nations. It covers Pyongyang, and five additional cities and eight highways and railways. Its only competitor, SunNet, uses GSM technology and suffers from poor call quality and disconnections. Phone numbers on the network are prefixed with +850 (0)192.\n\n3G services were made available in the Philippines on December 2008.\n\n3G services were made available in Singapore on October 2007. Widespread adoption of 3G began in January 2009, with the upgrading of phones to iPhone 3G and Android.\n\nIn Europe, mass market commercial 3G services were introduced starting in March 2003 by O2 in the UK and Italy. The European Union Council suggested that the 3G operators should cover 80% of the European national populations by the end of 2005.\n\nIn Canada, Bell Mobility, SaskTel and Telus launched a 3G EVDO network in 2005. Rogers Wireless was the first to implement UMTS technology, with HSDPA services in eastern Canada in late 2006. Realizing they would miss out on roaming revenue from the 2010 Winter Olympics, Bell and Telus formed a joint venture and rolled out a shared HSDPA network using Nokia Siemens technology. After the AWS spectrum in 2008, new entrants to the Canadian wireless markets including but not limited to Mobilicity, Wind Mobile and Vidéotron have deployed their own UMTS networks in Canada using the AWS spectrum.\n\nIn Iran Rightel won the bid for the third Operator license. Rightel is the first 3G operator in Iran. Rightel has commercially launched in the last months of 2011.\n\nIn Jordan, Orange is the first mobile 3G operator.\n\nMobitel Iraq is the first mobile 3G operator in Iraq. It was launched commercially on February 2007.\n\nMTN Syria is the first mobile 3G operator in Syria. It was launched commercially on May 2010.\n\nIn Lebanon Ministry of Telecoms launched a test period on September 20, 2011, where 4,000 smart-phone users were selected to enjoy 3G for one month and provide feedback. Currently, the test period is over, MTC Touch and Alfa began rolling out the new 3G services.\n\nSaudi Arabia has got 4G as well as 3G/HSPA With Zain KSA, Saudi Telecom, and Mobily KSA.\n\nTurkcell, Avea and Vodafone launched their 3G networks commercially on 30 July 2009 at the same time. Turkcell and Vodafone launched their 3G service on all provincial centres. Avea launched it on 16 provincial centres. It was after Turkey's monopoly mobile operator Turkcell accepted number portability, mobile operators attended frequency band auction and frequencies for 3G usage distributed around mobile operators. Turkcell got A band, Vodafone B and Avea C. Currently Turkcell and Vodafone have 3G networks on most of crowded cities and towns. Turkey has 3.9G networks now.\n\nIn late 2005, Vodafone NZ launched their 3G network, followed by Spark NZ's XT network in 2008, and newcomer 2degrees using a combination of Vodafone's 3G towers and their own in 2009. 2degrees has since built more towers, and is now self-sufficient in the major cities (Auckland, Hamilton, Wellington, Christchurch and Dunedin) but relies on a roaming agreement with Vodafone to cover the rest of the country. This gives it essentially the same footprint as Vodafone.\n"}
{"id": "55216958", "url": "https://en.wikipedia.org/wiki?curid=55216958", "title": "Apple Watch Series 3", "text": "Apple Watch Series 3\n\nThe Apple Watch Series 3 is the third-generation model of the Apple Watch. It was released on September 22, 2017. \n\nThe main feature is the new built-in LTE cellular connectivity, offering voice and data communication and Apple Music streaming. The watch comes with an electronic SIM card and shares the same mobile number as the user's iPhone. Add-on plans start at $10/month from the four major US carriers.\n\nApple Watch Series 3 has a dual-core Apple S3 processor that is 70% faster than the Apple S2 and enables Siri voice responses. The cellular-capable watch has a red digital crown while the non-LTE version has a plain digital crown. It has a built-in NFC chip which can be used for Apple Pay. Apple claims 18 hours of battery life.\n\nThe Apple Watch Series 3 ships with watchOS 4, which has an updated Heart Rate app (including resting and recovery period monitoring), Workout app (with High Intensity Interval Training), as well as two-way data synchronization with GymKit-integrated cardio fitness equipment from companies such as Life Fitness, Technogym, Cybex, Schwinn, MS Artrix, Stair Master and Star Trac.\n\nThe Apple Watch Series 3 (GPS) requires an iPhone 5s or later with iOS 11 or later. The Apple Watch Series 3 (GPS + Cellular) requires an iPhone 6 or later with iOS 11 or later.\n\n"}
{"id": "195113", "url": "https://en.wikipedia.org/wiki?curid=195113", "title": "Digital divide", "text": "Digital divide\n\nA digital divide is an economic and social inequality with regard to access to, use of, or impact of information and communication technologies (ICT). The divide within countries (such as the digital divide in the United States) may refer to inequalities between individuals, households, businesses, or geographic areas, usually at different socioeconomic levels or other demographic categories. The divide between differing countries or regions of the world is referred to as the global digital divide, examining this technological gap between developing and developed countries on an international scale.\n\nThe term \"digital divide\" describes a gap in terms of access to and usage of information and communication technology. It was traditionally considered to be a question of having or not having access, but with a global mobile phone penetration of over 95%, it is becoming a relative inequality between those who have more and less bandwidth and more or fewer skills. Conceptualizations of the digital divide have been described as \"who, with which characteristics, connects how to what\":\nDifferent authors focus on different aspects, which leads to a large variety of definitions of the digital divide. \"For example, counting with only 3 different choices of subjects (individuals, organizations, or countries), each with 4 characteristics (age, wealth, geography, sector), distinguishing between 3 levels of digital adoption (access, actual usage and effective adoption), and 6 types of technologies (fixed phone, mobile... Internet...), already results in 3x4x3x6 = 216 different ways to define the digital divide. Each one of them seems equally reasonable and depends on the objective pursued by the analyst\".\nThe \"digital divide\" is also referred to by a variety of other terms which have similar meanings, though may have a slightly different emphasis: digital inclusion, digital participation, basic digital skills, media literacy and digital accessibility.\n\nThe National Digital Inclusion Alliance, a US-based nonprofit organization, has found the term \"digital divide\" to be problematic, since there are a multiplicity of divides. Instead, they chosen to use the term \"digital inclusion\", providing a definition:\nDigital Inclusion refers to the activities necessary to ensure that all individuals and communities, including the most disadvantaged, have access to and use of Information and Communication Technologies (ICTs). This includes 5 elements: 1) affordable, robust broadband internet service; 2) internet-enabled devices that meet the needs of the user; 3) access to digital literacy training; 4) quality technical support; and 5) applications and online content designed to enable and encourage self-sufficiency, participation and collaboration.\n\nThe infrastructure by which individuals, households, businesses, and communities connect to the Internet address the physical mediums that people use to connect to the Internet such as desktop computers, laptops, basic mobile phones or smartphones, iPods or other MP3 players, gaming consoles such as Xbox or PlayStation, electronic book readers, and tablets such as iPads.\n\nTraditionally the nature of the divide has been measured in terms of the existing numbers of subscriptions and digital devices. Given the increasing number of such devices, some have concluded that the digital divide among individuals has increasingly been closing as the result of a natural and almost automatic process. Others point to persistent lower levels of connectivity among women, racial and ethnic minorities, people with lower incomes, rural residents, and less educated people as evidence that addressing inequalities in access to and use of the medium will require much more than the passing of time. Recent studies have measured the digital divide not in terms of technological devices, but in terms of the existing bandwidth per individual (in kbit/s per capita). \n\nAs shown in the Figure on the side, the digital divide in kbit/s is not monotonically decreasing, but re-opens up with each new innovation. For example, \"the massive diffusion of narrow-band Internet and mobile phones during the late 1990s\" increased digital inequality, as well as \"the initial introduction of broadband DSL and cable modems during 2003–2004 increased levels of inequality\". This is because a new kind of connectivity is never introduced instantaneously and uniformly to society as a whole at once, but diffuses slowly through social networks. As shown by the Figure, during the mid-2000s, communication capacity was more unequally distributed than during the late 1980s, when only fixed-line phones existed. The most recent increase in digital equality stems from the massive diffusion of the latest digital innovations (i.e. fixed and mobile broadband infrastructures, e.g. 3G and fiber optics FTTH).\nMeasurement methodologies of the digital divide, and more specifically an Integrated Iterative Approach General Framework (Integrated Contextual Iterative Approach – ICI) and the digital divide modeling theory under measurement model DDG (Digital Divide Gap) are used to analyze the gap existing between developed and developing countries, and the gap among the 27 members-states of the European Union.\n\nInstead of tracking various kinds of digital divides among fixed and mobile phones, narrow- and broadband Internet, digital TV, etc., it has recently been suggested to simply measure the amount of kbit/s per actor. This approach has shown that the digital divide in kbit/s per capita is actually widening in relative terms: \"While the average inhabitant of the developed world counted with some 40 kbit/s more than the average member of the information society in developing countries in 2001, this gap grew to over 3 Mbit/s per capita in 2010.\" \n\nThe upper graph of the Figure on the side shows that the divide between developed and developing countries has been diminishing when measured in terms of subscriptions per capita. In 2001, fixed-line telecommunication penetration reached 70% of society in developed OECD countries and 10% of the developing world. This resulted in a ratio of 7 to 1 (divide in relative terms) or a difference of 60% (divide in measured in absolute terms). During the next decade, fixed-line penetration stayed almost constant in OECD countries (at 70%), while the rest of the world started a catch-up, closing the divide to a ratio of 3.5 to 1. The lower graph shows the divide not in terms of ICT devices, but in terms of kbit/s per inhabitant. While the average member of developed countries counted with 29 kbit/s more than a person in developing countries in 2001, this difference got multiplied by a factor of one thousand (to a difference of 2900 kbit/s). In relative terms, the fixed-line capacity divide was even worse during the introduction of broadband Internet at the middle of the first decade of the 2000s, when the OECD counted with 20 times more capacity per capita than the rest of the world. This shows the importance of measuring the divide in terms of kbit/s, and not merely to count devices. The International Telecommunications Union concludes that \"the bit becomes a unifying variable enabling comparisons and aggregations across different kinds of communication technologies\".\n\nHowever, research shows that the digital divide is more than just an access issue and cannot be alleviated merely by providing the necessary equipment. There are at least three factors at play: information accessibility, information utilization and information receptiveness. More than just accessibility, individuals need to know how to make use of the information and communication tools once they exist within a community. Information professionals have the ability to help bridge the gap by providing reference and information services to help individuals learn and utilize the technologies to which they do have access, regardless of the economic status of the individual seeking help.\n\nInternet connectivity can be utilized at a variety of locations such as homes, offices, schools, libraries, public spaces, Internet cafe and others. There are also varying levels of connectivity in rural, suburban, and urban areas.\n\nCommon Sense Media, a nonprofit group based in San Francisco, surveyed almost 1,400 parents and reported in 2011 that 47 percent of families with incomes more than $75,000 had downloaded apps for their children, while only 14 percent of families earning less than $30,000 had done so.\n\nThe gap in a digital divide may exist for a number of reasons. Obtaining access to ICTs and using them actively has been linked to a number of demographic and socio-economic characteristics: among them income, education, race, gender, geographic location (urban-rural), age, skills, awareness, political, cultural and psychological attitudes. Multiple regression analysis across countries has shown that income levels and educational attainment are identified as providing the most powerful explanatory variables for ICT access and usage. Evidence was found that Caucasians are much more likely than non-Caucasians to own a computer as well as have access to the Internet in their homes. As for geographic location, people living in urban centers have more access and show more usage of computer services than those in rural areas. Gender was previously thought to provide an explanation for the digital divide, many thinking ICT were male gendered, but controlled statistical analysis has shown that income, education and employment act as confounding variables and that women with the same level of income, education and employment actually embrace ICT more than men (see Women and ICT4D). However, each nation has its own set of causes or the digital divide. For example, the digital divide in Germany is unique because it is not largely due to difference in quality of infrastructure.\n\nOne telling fact is that \"as income rises so does Internet use ...\", strongly suggesting that the digital divide persists at least in part due to income disparities. Most commonly, a digital divide stems from poverty and the economic barriers that limit resources and prevent people from obtaining or otherwise using newer technologies.\n\nIn research, while each explanation is examined, others must be controlled in order to eliminate interaction effects or mediating variables, but these explanations are meant to stand as general trends, not direct causes. Each component can be looked at from different angles, which leads to a myriad of ways to look at (or define) the digital divide. For example, measurements for the intensity of usage, such as incidence and frequency, vary by study. Some report usage as access to Internet and ICTs while others report usage as having previously connected to the Internet. Some studies focus on specific technologies, others on a combination (such as Infostate, proposed by Orbicom-UNESCO, the Digital Opportunity Index, or ITU's ICT Development Index). Based on different answers to the questions of who, with which kinds of characteristics, connects how and why, to what there are hundreds of alternatives ways to define the digital divide. \"The new consensus recognizes that the key question is not how to connect people to a specific network through a specific device, but how to extend the expected gains from new ICTs\". In short, the desired impact and \"the end justifies the definition\" of the digital divide.\n\nDuring the mid-1990s the US Department of Commerce, National Telecommunications & Information Administration (NTIA) began publishing reports about the Internet and access to and usage of the resource. The first of three reports is entitled \"Falling Through the Net: A Survey of the ‘Have Nots’ in Rural and Urban America\" (1995), the second is \"Falling Through the Net II: New Data on the Digital Divide\" (1998), and the final report \"Falling Through the Net: Defining the Digital Divide\" (1999). The NTIA’s final report attempted to clearly define the term digital divide; \"the digital divide—the divide between those with access to new technologies and those without—is now one of America's leading economic and civil rights issues. This report will help clarify which Americans are falling further behind, so that we can take concrete steps to redress this gap.\" Since the introduction of the NTIA reports, much of the early, relevant literature began to reference the NTIA’s digital divide definition. The digital divide is commonly defined as being between the \"haves\" and \"have-nots.\"\n\nThe Facebook Divide, a concept derived from the \"digital divide\", is the phenomenon with regard to access to, use of, or impact of Facebook on individual society and among societies. It is suggested at the International Conference on Management Practices for the New Economy (ICMAPRANE-17) on February 10–11, 2017. Additional concepts of Facebook Native and Facebook Immigrants are suggested at the conference. The Facebook Divide, Facebook native, Facebook immigrants, and Facebook left-behind are concepts for social and business management research. Facebook Immigrants are utilizing Facebook for their accumulation of both bonding and bridging social capital. These Facebook Native, Facebook Immigrants, and Facebook left-behind induced the situation of Facebook inequality. In February 2018, the Facebook Divide Index was introduced at the ICMAPRANE conference in Noida, India, to illustrate the Facebook Divide phenomenon.\n\nOvercoming the divide \n\nAn individual must be able to connect in order to achieve enhancement of social and cultural capital as well as achieve mass economic gains in productivity. Therefore, access is a necessary (but not sufficient) condition for overcoming the digital divide. Access to ICT meets significant challenges that stem from income restrictions. The borderline between ICT as a necessity good and ICT as a luxury good is roughly around the \"magical number\" of US$10 per person per month, or US$120 per year, which means that people consider ICT expenditure of US$120 per year as a basic necessity. Since more than 40% of the world population lives on less than US$2 per day, and around 20% live on less than US$1 per day (or less than US$365 per year), these income segments would have to spend one third of their income on ICT (120/365 = 33%). The global average of ICT spending is at a mere 3% of income. Potential solutions include driving down the costs of ICT, which includes low cost technologies and shared access through Telecentres.\n\nFurthermore, even though individuals might be capable of accessing the Internet, many are thwarted by barriers to entry such as a lack of means to infrastructure or the inability to comprehend the information that the Internet provides. Lack of adequate infrastructure and lack of knowledge are two major obstacles that impede mass connectivity. These barriers limit individuals' capabilities in what they can do and what they can achieve in accessing technology. Some individuals have the ability to connect, but they do not have the knowledge to use what information ICTs and Internet technologies provide them. This leads to a focus on capabilities and skills, as well as awareness to move from mere access to effective usage of ICT.\n\nThe United Nations is aiming to raise awareness of the divide by way of the World Information Society Day which has taken place yearly since May 17, 2006. It also set up the Information and Communications Technology (ICT) Task Force in November 2001. Later UN initiatives in this area are the World Summit on the Information Society, which was set up in 2003, and the Internet Governance Forum, set up in 2006.\n\nIn the year 2000, the United Nations Volunteers (UNV) programme launched its Online Volunteering service, which uses ICT as a vehicle for and in support of volunteering. It constitutes an example of a volunteering initiative that effectively contributes to bridge the digital divide. ICT-enabled volunteering has a clear added value for development. If more people collaborate online with more development institutions and initiatives, this will imply an increase in person-hours dedicated to development cooperation at essentially no additional cost. This is the most visible effect of online volunteering for human development.\n\nSocial media websites serve as both manifestations of and means by which to combat the digital divide. The former describes phenomena such as the divided users demographics that make up sites such as Facebook and Myspace or Word Press and Tumblr. Each of these sites host thriving communities that engage with otherwise marginalized populations. An example of this is the large online community devoted to Afrofuturism, a discourse that critiques dominant structures of power by merging themes of science fiction and blackness. Social media brings together minds that may not otherwise meet, allowing for the free exchange of ideas and empowerment of marginalized discourses.\n\nAttempts to bridge the digital divide include a program developed in Durban, South Africa, where very low access to technology and a lack of documented cultural heritage has motivated the creation of an \"online indigenous digital library as part of public library services.\" This project has the potential to narrow the digital divide by not only giving the people of the Durban area access to this digital resource, but also by incorporating the community members into the process of creating it.\n\nTo address the divide The Gates Foundation began the Gates Library Initiative. The Gates Foundation focused on providing more than just access, they placed computers and provided training in libraries. In this manner if users began to struggle while using a computer, the user was in a setting where assistance and guidance was available. Further, the Gates Library Initiative was \"modeled on the old-fashioned life preserver: The support needs to be around you to keep you afloat.\"\n\nIn nations where poverty compounds effects of the digital divide, programs are emerging to counter those trends. Prior conditions in Kenya—lack of funding, language and technology illiteracy contributed to an overall lack of computer skills and educational advancement for those citizens. This slowly began to change when foreign investment began. In the early 2000s, The Carnegie Foundation funded a revitalization project through the Kenya National Library Service (KNLS). Those resources enabled public libraries to provide information and communication technologies (ICT) to their patrons. In 2012, public libraries in the Busia and Kiberia communities introduced technology resources to supplement curriculum for primary schools. By 2013, the program expanded into ten schools.\n\nCommunity Informatics (CI) provides a somewhat different approach to addressing the digital divide by focusing on issues of \"use\" rather than simply \"access\". CI is concerned with ensuring the opportunity not only for ICT access at the community level but also, according to Michael Gurstein, that the means for the \"effective use\" of ICTs for community betterment and empowerment are available. Gurstein has also extended the discussion of the digital divide to include issues around access to and the use of \"open data\" and coined the term \"data divide\" to refer to this issue area.\n\nOnce an individual is connected, Internet connectivity and ICTs can enhance his or her future social and cultural capital. Social capital is acquired through repeated interactions with other individuals or groups of individuals. Connecting to the Internet creates another set of means by which to achieve repeated interactions. ICTs and Internet connectivity enable repeated interactions through access to social networks, chat rooms, and gaming sites. Once an individual has access to connectivity, obtains infrastructure by which to connect, and can understand and use the information that ICTs and connectivity provide, that individual is capable of becoming a \"digital citizen\".\n\nIn the United States, research provided by Sungard Availability Services notes a direct correlation between a company's access to technological advancements and its overall success in bolstering the economy. The study, which includes over 2,000 IT executives and staff officers, indicates that 69 percent of employees feel they do not have access to sufficient technology in order to make their jobs easier, while 63 percent of them believe the lack of technological mechanisms hinders their ability to develop new work skills. Additional analysis provides more evidence to show how the digital divide also affects the economy in places all over the world. A BCG Report suggests that in countries like Sweden, Switzerland, and the U.K., the digital connection among communities is made easier, allowing for their populations to obtain a much larger share of the economies via digital business. In fact, in these places, populations hold shares approximately 2.5 percentage points higher. During a meeting with the United Nations a Bangladesh representative expressed his concern that poor and undeveloped countries would be left behind due to a lack of funds to bridge the digital gap.\n\nThe digital divide also impacts children's ability to learn and grow in low-income school districts. Without Internet access, students are unable to cultivate necessary tech skills in order to understand today's dynamic economy. Federal Communication Commission's Broadband Task Force created a report showing that about 70% of teachers give students homework that demand access to broadband. Even more, approximately 65% of young scholars use the Internet at home to complete assignments as well as connect with teachers and other students via discussion boards and shared files. A recent study indicates that practically 50% of students say that they are unable to finish their homework due to an inability to either connect to the Internet, or in some cases, find a computer. This has led to a new revelation: 42% of students say they received a lower grade because of this disadvantage. Finally, according to research conducted by the Center for American Progress, \"if the United States were able to close the educational achievement gaps between native-born white children and black and Hispanic children, the U.S. economy would be 5.8 percent—or nearly $2.3 trillion—larger in 2050\".\n\nFurthermore, according to the 2012 Pew Report \"Digital Differences\", a mere 62% of households who make less than $30,000 a year use the Internet, while 90% of those making between $50,000 and $75,000 had access. Studies also show that only 51% of Hispanics and 49% of African Americans have high-speed Internet at home. This is compared to the 66% of Caucasians that too have high-speed Internet in their households. Overall, 10% of all Americans don't have access to high-speed Internet, an equivalent of almost 34 million people. Supplemented reports from the Guardian demonstrate the global effects of limiting technological developments in poorer nations, rather than simply the effects in the United States. Their study shows that the rapid digital expansion excludes those who find themselves in the lower class. 60% of the world's population, almost 4 billion people, have no access to the Internet and are thus left worse off.\n\nSince gender, age, racial, income, and educational gaps in the digital divide have lessened compared to past levels, some researchers suggest that the digital divide is shifting from a gap in access and connectivity to ICTs to a knowledge divide. A knowledge divide concerning technology presents the possibility that the gap has moved beyond access and having the resources to connect to ICTs to interpreting and understanding information presented once connected.\n\nThe second-level digital divide, also referred to as the production gap, describes the gap that separates the consumers of content on the Internet from the producers of content. As the technological digital divide is decreasing between those with access to the Internet and those without, the meaning of the term digital divide is evolving. Previously, digital divide research has focused on accessibility to the Internet and Internet consumption. However, with more and more of the population with access to the Internet, researchers are examining how people use the Internet to create content and what impact socioeconomics are having on user behavior.\nNew applications have made it possible for anyone with a computer and an Internet connection to be a creator of content, yet the majority of user generated content available widely on the Internet, like public blogs, is created by a small portion of the Internet using population. Web 2.0 technologies like Facebook, YouTube, Twitter, and Blogs enable users to participate online and create content without having to understand how the technology actually works, leading to an ever-increasing digital divide between those who have the skills and understanding to interact more fully with the technology and those who are passive consumers of it. Many are only nominal content creators through the use of Web 2.0, posting photos and status updates on Facebook, but not truly interacting with the technology.\n\nSome of the reasons for this production gap include material factors like the type of Internet connection one has and the frequency of access to the Internet. The more frequently a person has access to the Internet and the faster the connection, the more opportunities they have to gain the technology skills and the more time they have to be creative.\n\nOther reasons include cultural factors often associated with class and socioeconomic status. Users of lower socioeconomic status are less likely to participate in content creation due to disadvantages in education and lack of the necessary free time for the work involved in blog or web site creation and maintenance. Additionally, there is evidence to support the existence of the second-level digital divide at the K-12 level based on how educators' use technology for instruction. Schools' economic factors have been found to explain variation in how teachers use technology to promote higher-order thinking skills.\n\nThe global digital divide describes global disparities, primarily between developed and developing countries, in regards to access to computing and information resources such as the Internet and the opportunities derived from such access. As with a smaller unit of analysis, this gap describes an inequality that exists, referencing a global scale.\n\nThe Internet is expanding very quickly, and not all countries—especially developing countries—are able to keep up with the constant changes. The term \"digital divide\" doesn't necessarily mean that someone doesn’t have technology; it could mean that there is simply a difference in technology. These differences can refer to, for example, high-quality computers, fast Internet, technical assistance, or telephone services. The difference between all of these is also considered a gap.\n\nIn fact, there is a large inequality worldwide in terms of the distribution of installed telecommunication bandwidth. In 2014 only 3 countries (China, US, Japan) host 50% of the globally installed bandwidth potential (see pie-chart Figure on the right). This concentration is not new, as historically only 10 countries have hosted 70–75% of the global telecommunication capacity (see Figure). The U.S. lost its global leadership in terms of installed bandwidth in 2011, being replaced by China, which hosts more than twice as much national bandwidth potential in 2014 (29% versus 13% of the global total).\n\nThe global digital divide is a special case of the digital divide, the focus is set on the fact that \"Internet has developed unevenly throughout the world\" causing some countries to fall behind in technology, education, labor, democracy, and tourism. The concept of the digital divide was originally popularized in regard to the disparity in Internet access between rural and urban areas of the United States of America; the \"global\" digital divide mirrors this disparity on an international scale.\n\nThe global digital divide also contributes to the inequality of access to goods and services available through technology. Computers and the Internet provide users with improved education, which can lead to higher wages; the people living in nations with limited access are therefore disadvantaged. This global divide is often characterized as falling along what is sometimes called the north-south divide of \"northern\" wealthier nations and \"southern\" poorer ones.\n\nSome people argue that basic necessities need to be considered before achieving digital inclusion, such as an ample food supply and quality health care. Minimizing the global digital divide requires considering and addressing the following types of access:\nInvolves \"the distribution of ICT devices per capita…and land lines per thousands\". Individuals need to obtain access to computers, landlines, and networks in order to access the Internet. This access barrier is also addressed in Article 21 of the Convention on the Rights of Persons with Disabilities by the United Nations. \nThe cost of ICT devices, traffic, applications, technician and educator training, software, maintenance and infrastructures require ongoing financial means.\nFinancial access and \"the levels of household income play a significant role in widening the gap\" \nEmpirical tests have identified that several socio-demographic characteristics foster or limit ICT access and usage. Among different countries, educational levels and income are the most powerful explanatory variables, with age being a third one. \n\nWhile a Global Gender Gap in access and usage of ICT's exist, empirical evidence show that this due to unfavorable conditions with respect to employment, education and income and not to technophobia or lower ability. On the contrary, in the contexts under study, women with the prerequsites for access and usage turn out to be more active users of digital tools than men.\nIn order to use computer technology, a certain level of information literacy is needed. Further challenges include information overload and the ability to find and use reliable information. \nComputers need to be accessible to individuals with different learning and physical abilities including complying with Section 508 of the Rehabilitation Act as amended by the Workforce Investment Act of 1998 in the United States. \nIn illustrating institutional access, Wilson states \"the numbers of users are greatly affected by whether access is offered only through individual homes or whether it is offered through schools, community centers, religious institutions, cybercafés, or post offices, especially in poor countries where computer access at work or home is highly limited\". \nGuillen & Suarez argue that \"democratic political regimes enable a faster growth of the Internet than authoritarian or totalitarian regimes\". The Internet is considered a form of e-democracy and attempting to control what citizens can or cannot view is in contradiction to this. Recently situations in Iran and China have denied people the ability to access certain websites and disseminate information. Iran has prohibited the use of high-speed Internet in the country and has removed many satellite dishes in order to prevent the influence of Western culture, such as music and television.\nMany experts claim that bridging the digital divide is not sufficient and that the images and language needed to be conveyed in a language and images that can be read across different cultural lines. A 2013 study conducted by Pew Research Center noted how participants taking the survey in Spanish were nearly twice as likely to not use the internet.\n\nIn the early 21st century, residents of developed countries enjoy many Internet services which are not yet widely available in developing countries, including:\n\n\nThere are four specific arguments why it is important to \"bridge the gap\":\n\n\nWhile these four arguments are meant to lead to a solution to the digital divide, there are a couple other components that need to be considered. The first one is rural living versus suburban living. Rural areas used to have very minimal access to the Internet, for example. However, nowadays, power lines and satellites are used to increase the availability in these areas. Another component to keep in mind is disabilities. Some people may have the highest quality technologies, but a disability they have may keep them from using these technologies to their fullest extent.\n\nUsing previous studies (Gamos, 2003; Nsengiyuma & Stork, 2005; Harwit, 2004 as cited in James), James asserts that in developing countries, \"internet use has taken place overwhelmingly among the upper-income, educated, and urban segments\" largely due to the high literacy rates of this sector of the population. As such, James suggests that part of the solution requires that developing countries first build up the literacy/language skills, computer literacy, and technical competence that low-income and rural populations need in order to make use of ICT.\n\nIt has also been suggested that there is a correlation between democrat regimes and the growth of the Internet. One hypothesis by Gullen is, \"The more democratic the polity, the greater the Internet use...Government can try to control the Internet by monopolizing control\" and Norris \"et al.\" also contends, \"If there is less government control of it, the Internet flourishes, and it is associated with greater democracy and civil liberties.\n\nFrom an economic perspective, Pick and Azari state that \"in developing nations…foreign direct investment (FDI), primary education, educational investment, access to education, and government prioritization of ICT as all important\". Specific solutions proposed by the study include: \"invest in stimulating, attracting, and growing creative technical and scientific workforce; increase the access to education and digital literacy; reduce the gender divide and empower women to participate in the ICT workforce; emphasize investing in intensive Research and Development for selected metropolitan areas and regions within nations\".\n\nThere are projects worldwide that have implemented, to various degrees, the solutions outlined above. Many such projects have taken the form of Information Communications Technology Centers (ICT centers). Rahnman explains that \"the main role of ICT intermediaries is defined as an organization providing effective support to local communities in the use and adaptation of technology. Most commonly an ICT intermediary will be a specialized organization from outside the community, such as a non-governmental organization, local government, or international donor. On the other hand, a social intermediary is defined as a local institution from within the community, such as a community-based organization.\n\nOther proposed solutions that the Internet promises for developing countries are the provision of efficient communications within and among developing countries, so that citizens worldwide can effectively help each other to solve their own problems. Grameen Banks and Kiva loans are two microcredit systems designed to help citizens worldwide to contribute online towards entrepreneurship in developing communities. Economic opportunities range from entrepreneurs who can afford the hardware and broadband access required to maintain Internet cafés to agribusinesses having control over the seeds they plant.\n\nAt the Massachusetts Institute of Technology, the IMARA organization (from Swahili word for \"power\") sponsors a variety of outreach programs which bridge the Global Digital Divide. Its aim is to find and implement long-term, sustainable solutions which will increase the availability of educational technology and resources to domestic and international communities. These projects are run under the aegis of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) and staffed by MIT volunteers who give training, install and donate computer setups in greater Boston, Massachusetts, Kenya, Indian reservations the American Southwest such as the Navajo Nation, the Middle East, and Fiji Islands. The CommuniTech project strives to empower underserved communities through sustainable technology and education. According to Dominik Hartmann of the MIT's Media Lab, interdisciplinary approaches are needed to bridge the global digital divide.\n\nBuilding on the premise that any effective solution must be decentralized, allowing the local communities in developing nations to generate their own content, one scholar has posited that social media—like Facebook, YouTube, and Twitter—may be useful tools in closing the divide. As Amir Hatem Ali suggests, \"the popularity and generative nature of social media empower individuals to combat some of the main obstacles to bridging the digital divide\". Facebook’s statistics reinforce this claim. According to Facebook, more than seventy-five percent of its users reside outside of the US. Moreover, more than seventy languages are presented on its website. The reasons for the high number of international users are due to many the qualities of Facebook and other social media. Amongst them, are its ability to offer a means of interacting with others, user-friendly features, and the fact that most sites are available at no cost. The problem with social media, however, is that it can be accessible, provided that there is physical access. Nevertheless, with its ability to encourage digital inclusion, social media can be used as a tool to bridge the global digital divide.\n\nSome cities in the world have started programs to bridge the digital divide for their residents, school children, students, parents and the elderly. One such program, founded in 1996, was sponsored by the city of Boston and called the Boston Digital Bridge Foundation. It especially concentrates on school children and their parents, helping to make both equally and similarly knowledgeable about computers, using application programs, and navigating the Internet.\n\nFree Basics is a partnership between social networking services company Facebook and six companies (Samsung, Ericsson, MediaTek, Opera Software, Nokia and Qualcomm) that plans to bring affordable access to selected Internet services to less developed countries by increasing efficiency, and facilitating the development of new business models around the provision of Internet access. In the whitepaper realised by Facebook's founder and CEO Mark Zuckerberg, connectivity is asserted as a \"human right\", and Internet.org is created to improve Internet access for people around the world.\n\n\"Free Basics provides people with access to useful services on their mobile phones in markets where internet access may be less affordable. The websites are available for free without data charges, and include content about news, employment, health, education and local information etc. By introducing people to the benefits of the internet through these websites, we hope to bring more people online and help improve their lives.\"\n\nHowever, Free Basics is also accused of violating net neutrality for limiting access to handpicked services. Despite a wide deployment in numerous countries, it has been met with heavy resistance notably in India where the Telecom Regulatory Authority of India eventually banned it in 2016.\n\nSeveral projects to bring internet to the entire world with a satellite constellation have been devised in the last decade, one of these being Starlink by Elon Musk's company SpaceX. Unlike Free Basics, it would provide people with a full internet access and would not be limited to a few selected services. In the same week Starlink was announced, serial-entrepreneur Richard Branson announced his own project OneWeb, a similar constellation with approximately 700 satellites that has already procured communication frequency licenses for their broadcast spectrum and could possibly be operational as early as in 2019.\n\nThe biggest hurdle of these projects is the astronomical financial and logistical costs of launching so many satellites. After the failure of previous satellite-to-consumer space ventures, satellite industry consultant Roger Rusch said \"It's highly unlikely that you can make a successful business out of this.\" Musk has publicly acknowledged this business reality, and indicated in mid-2015 that while endeavoring to develop this technically-complicated space-based communication system he wants to avoid overextending the company and stated that they are being measured in the pace of development.\n\nOne Laptop Per Child (OLPC) is another attempt to narrow the digital divide. This organization, founded in 2005, provides inexpensively produced \"XO\" laptops (dubbed the \"$100 laptop\", though actual production costs vary) to children residing in poor and isolated regions within developing countries. Each laptop belongs to an individual child and provides a gateway to digital learning and Internet access. The XO laptops are designed to withstand more abuse than higher-end machines, and they contain features in context to the unique conditions that remote villages present. Each laptop is constructed to use as little power as possible, have a sunlight-readable screen, and is capable of automatically networking with other XO laptops in order to access the Internet—as many as 500 machines can share a single point of access.\n\nSeveral of the 67 principles adopted at the World Summit on the Information Society convened by the United Nations in Geneva in 2003 directly address the digital divide:\n\n\n\n\n"}
{"id": "7695885", "url": "https://en.wikipedia.org/wiki?curid=7695885", "title": "Global spread of the printing press", "text": "Global spread of the printing press\n\nThe global spread of the printing press began with the invention of the printing press with movable type by Johannes Gutenberg in Mainz, Germany . Western printing technology was adopted in all world regions by the end of the 19th century, displacing the manuscript and block printing.\n\nIn the Western world, the operation of a press became synonymous with the enterprise of publishing and lent its name to a new branch of media, the \"press\" (see List of the oldest newspapers).\n\nGutenberg's first major print work was the 42-line Bible in Latin, printed probably between 1452 and 1454 in the German city of Mainz. After Gutenberg lost a lawsuit against his investor Johann Fust, Fust put Gutenberg's employee Peter Schöffer in charge of the print shop. Thereupon Gutenberg established a new one with the financial backing of another money lender. With Gutenberg's monopoly revoked, and the technology no longer secret, printing spread throughout Germany and beyond, diffused first by emigrating German printers, but soon also by foreign apprentices.\n\nIn rapid succession, printing presses were set up in Central and Western Europe. Major towns, in particular, functioned as centers of diffusion (Cologne 1466, Rome 1467, Venice 1469, Paris 1470, Kraków 1473, London 1477). In 1481, barely 30 years after the publication of the 42-line Bible, the small Netherlands already featured printing shops in 21 cities and towns, while Italy and Germany each had shops in about 40 towns at that time. According to one estimate, \"by 1500, 1000 printing presses were in operation throughout Western Europe and had produced 8 million books\" and during the 1550s there were \"three hundred or more\" printers and booksellers in Geneva alone. The output was in the order of twenty million volumes and rose in the sixteenth century tenfold to between 150 and 200 million copies. Germany and Italy were considered the two main centres of printing in terms of quantity and quality.\n\nThe near-simultaneous discovery of sea routes to the West (Christopher Columbus, 1492) and East (Vasco da Gama, 1498) and the subsequent establishment of trade links greatly facilitated the global spread of Gutenberg-style printing. Traders, colonists, but perhaps most importantly, missionaries exported printing presses to the new European oversea domains, setting up new print shops and distributing printing material. In the Americas, the first extra-European print shop was founded in Mexico City in 1544 (1539?), and soon after Jesuits started operating the first printing press in Asia (Goa, 1556).\n\nFor a long time however, movable type printing remained mainly the business of Europeans working from within the confines of their colonies. According to Suraiya Faroqhi, lack of interest and religious reasons were among the reasons for the slow adoption of the printing press outside Europe: Thus, the printing of Arabic, after encountering strong opposition by Muslim legal scholars and the manuscript scribes, remained prohibited in the Ottoman empire between 1483 and 1729, initially even on penalty of death, while some movable Arabic type printing was done by Pope Julius II (1503−1512) for distribution among Middle Eastern Christians, and the oldest Qur’an printed with movable type was produced in Venice in 1537/1538 for the Ottoman market.\n\nIn India, reports are that Jesuits \"presented a polyglot Bible to the Emperor Akbar in 1580 but did not succeed in arousing much curiosity.\" But also practical reasons seem to have played a role. The English East India Company, for example, brought a printer to Surat in 1675, but was not able to cast type in Indian scripts, so the venture failed.\n\nNorth America saw the adoption by the Cherokee Indian Elias Boudinot who published the tribe's first newspaper \"Cherokee Phoenix\" from 1828, partly in his native language, using the Cherokee alphabet recently invented by his compatriot Sequoyah.\n\nIn the 19th century, the arrival of the Gutenberg-style press to the shores of Tahiti (1818), Hawaii (1821) and other Pacific islands, marked the end of a global diffusion process which had begun almost 400 years earlier. At the same time, the \"old style\" press (as the Gutenberg model came to be termed in the 19th century), was already in the process of being displaced by industrial machines like the steam powered press (1812) and the rotary press (1833), which radically departed from Gutenberg's design, but were still of the same development line.\n\nThe following represents a selection:\n\nIn the 15th century, printing presses were established in 77 Italian cities and towns. At the end of the following century, 151 locations in Italy had seen at one time printing activities, of which 130 (86%) were north of Rome. During these two centuries a total of 2894 printers were active in Italy, with only 216 of them located in southern Italy. Ca. 60% of the Italian printing shops were situated in six cities (Venice, Rome, Milan, Naples, Bologna and Florence), with the concentration of printers in Venice being particularly high (ca. 30%).\n\nApart from the cities above, a small number of lesser towns also set up printing presses.\n\nIn 1481, printing was already being done in 21 towns and cities.\n\nIn the 16th century, a total of 20 print shops were active in 30 different places in Hungary, as some of them were moving several times due to political instability.\n\nIn the 15th and 16th centuries printing presses were also established in Poznań, Lwów, Brześć Litewski and Vilnius.\n\nBy 1500, the cut-off point for incunabula, 236 towns in Europe had presses, and it is estimated that twenty million books had been printed for a European population of perhaps seventy million.\n\nUntil the reign of Peter the Great printing in Russia remained confined to the print office established by Fedorov in Moscow. In the 18th century, annual printing output gradually rose from 147 titles in 1724 to 435 (1787), but remained constrained by state censorship and widespread illiteracy.\n\nThe first book which had Armenian letters was published in Mainz (Germany) in 1486. The first Armenian book to be published by the printing press was \"Urbatagirq\"—Book of Friday prayers—which was published by Hakob Meghapart in Venice in 1512.\n\nDue to religious qualms, Sultan Bayezid II and successors prohibited printing in Arabic script in the Ottoman empire from 1483 on penalty of death, but printing in other scripts was done by Jews as well as the Greek and Armenian communities (1515 Saloniki, 1554 Bursa (Adrianople), 1552 Belgrade, 1658 Smyrna). In 1727, Sultan Achmed III gave his permission for the establishment of the first legal print house for printing secular works in Arabic script (religious publications still remained forbidden), but printing activities did not really take off until the 19th century.\n\n\n\n\nOn the effects of Gutenberg's printing\n\n"}
{"id": "37482023", "url": "https://en.wikipedia.org/wiki?curid=37482023", "title": "HusITa", "text": "HusITa\n\nhusITa (Human Services Information Technology Applications) is an international virtual associationand a registered US non-profit organizationestablished with the mission of promoting the ethical and effective use of information technology in the human services. The main focus of husITa, and the claim to expertise of its associates, is situated at the intersection of three core domains: information technology, human services, and social development. husITa pursues its mission through international conferences, publications and research dissemination directed at technology applications and innovations that promote social well-being.\n\nFor much of its early history husITa operated as an informal international network of human service academics and practitioners. One of the outcomes of its first international conferencehusITa1 held in 1987 in Birmingham, Englandwas the establishment of a working group to determine the feasibility of an international body 'to highlight the importance of human service computing, to guide developments, and to foster international co-operation'.\n\nThe working group was composed of Hein de Graaf (Netherlands), Walter LaMendola (USA), Dick Schoech (USA), and Stuart Toole (UK). Initial projects identified by the working group included the development of research agendas, position papers, repositories of information, and promoting a second husITa conference in 1989. Bryan Glastonbury was later added to the group as secretary. The working group met in Colorado, Denver for three days in May 1988 and published a report on the issues that a husITa international organization would need to address.\n\nAlthough the 1988 Denver meeting agreed its objectives, husITa wasn't formally established as an organization for another twelve years. The structure of the formal organization was later agreed to at Denver in 2000. The founding members at the Denver 2000 meeting were: Hein de Graaf, Walter LaMendola, Rob MacFadden, Jo Ann Regan, Jackie Rafferty, Jan Steyaert, Dick Schoech, Stuart Toole, and Victor Savtschenko.\n\nhusITa's objectives (agreed by the 1988 Denver working group) are to:\n\nThe \"Journal of Technology in Human Services\" is the official journal of husITa. Formerly known as \"Computers in Human Services\" it was launched in 1985 as a Haworth Press publication. Dick Schoech, a professor of social work at the University of Texas at Arlington, was its founding editor. The \"Journal of Technology in Human Services\" is a peer-reviewed, refereed journal now published by Taylor & Francis. Its scope includes the potential of information and communication technologies in mental health, developmental disability, welfare, addictions, education, and other human services. The current Editor-in-Chief is Dr. Lauri Goldkind (Associate Professor, Fordham University, USA), with Dr. Chitat Chan (Assistant Professor, Hong Kong Polytechnic University, Hong Kong) serves as the Associate Editor-in-Chief.\n\nhusITa1: husITa's first international conference was held between in September 1987 in Birmingham, England.\n\nhusITa2: \"Computer Technology and Human Services in the 90’s: Advancing Theory and Practice\", June 1991 in New Brunswick, New Jersey.\n\nhusITa3: \"Information Technology and the Quality of Life and Services\", June 1993 in Maastricht, the Netherlands. The same year saw the formation of a husITa Foundation in the Netherlands which continued until its disestablishment in 2003.\n\nhusITa4: \"Information Technology in the Human Services: Dreams and Realities\", June 1996 in Lapland, Finland.\n\nhusITa5: \"Social Services in the Information Society: Closing the GAP\", August–September 1999 in Budapest, Hungary.\n\nhusITa6: \"Technology and Human Services in a Multicultural Society\", September 2001, in Charleston, South Carolina. However, the conference was cut short as a result of the terrorist attacks in the USA on 11 September 2001. A brief husITa board meeting was held, the by-laws were approved, and officers were elected.\n\nhusITa7: \"Digital Inclusion-Building a Digital Inclusive Society\", August 2004 in Hong Kong, China. It had been delayed from its planned date of 2003 due to an outbreak of SARS.\n\nhusITa8: \"Information Technology and Diversity in Human Services: Promoting Strength Through Difference\", August 2007 in Toronto, Canada.\n\nhusITa9: \"ICT as a Context for Human Services\", June 2010 in Hong Kong, China. This event was held in conjunction with the 2010 Joint World Conference on Social Work and Social Development.\n\nhusITa14: \"Sustainable & Ethical use of Technology\". July 9–12, Melbourne, Australia. Held in conjunction with the 2014 Joint World Conference on Social Work, Education, and Social Development.\n\nhusITa was built on the activity of an international network of human service organizations, academics and practitioners in the USA, the UK and the Netherlands. The section below highlights some of the key organizations, people and events.\n\nIn 1978, Gunther R. Geiss, aprofessor of social work at Adelphi University, New York, conducted a survey of US schools of social work. The survey sought to identify faculty members who had used computers in their administrative, teaching or research activities, or who had consulted or participated in the design and development of computer-based information systems. There were over 80 positive responses indicating a wide range of activities and levels of involvement. The survey initiated the development of a system to track and communicate with individuals with expertise in computers and human services.\n\nWalter LaMendola, professor of social work at the University of Denver in Colorado, described an incident during a social work conference in 1979 suggesting early indications of the resistance of some social work professionals to computer use in the human services. This is a theme which has continued throughout the history of technology use in the human services and continues to the present day. Some aspects of this resistance can be considered as a well-founded concern about the ethical issues surrounding human service technology applications. However, other aspects of technology resistance seem to be a less rational form of Neo-Luddism.\n\nGrowing interest in the use of technology in the human services led a group of US human service technology specialists, meeting at a Council of Social Work Education conference in Louisville Kentucky in 1981, to form the Computer Use In Social Services Network (CUSSN). By the end of 1981 the network had over 350 members. The CUSSN newsletter continued in print until 1992 when it was merged with the first academic journal on human service technology \"Computers in Human Services\".\n\nIn 1984 Gunther Geiss was sponsored by the Silberman Fund to organize the Wye Plantation Conference on Human Services Technology. Conference members developed pre-conference position papers via EYES: a centralized email system.\n\nIn 1985, CUSSN developed CUSSNet CUSSNet, a PC and FidoNet based networking system that automatically exchanged emails between members each night during off-peak telephone hours. FidoNet was a PC distributed email, bulletin board, and file sharing system that preceded the Internet. CUSSNet quickly developed nodes in major cities in the US, the UK, and the Netherlands.\n\nThe name husITa (Human Service Information Technology Applications) was coined in 1983 by Walter LaMendola and Brian Klepinger at the University of Denver.\n\nThe Human Service Microcomputer Conference was held in Seattle.\n\nIn 1984 Stuart Toole formed Computer Applications in Social Work (CASW) in the UK to set up and run national conferences and to publish the CASW journal.\n\nBased on the success of the first UK technology conferences, Stuart Toole, Walter LaMendola, and Brian Klepinger agreed to pursue an international conference in 1987: this conference was to become HUSITA's first international conference HUSITA1.\n\nThe CASW journal was later renamed New Technology in the Human Services in [when] and continued in publication under this title until it was closed in 2003.\n\nIn 1986 the second UK conference held on social welfare computing was held.\n\nIn 1985 Bryan Glastonbury, from the University of Southampton published \"Computers in Social Work\", the first major academic text on technology and human services. In the same year the University of Southampton began publishing the journal New Technology in the Human Services under the editorship of Bryan Glastonbury. In the same year the University of Southampton established the Centre for Human Service Technology (CHST) with Jackie Rafferty as Director. In 2007, Jan Steyaert joined as adjunct research professor and together they edited a special issue of the British Journal of Social Work on \"social work in the digital age\".\nThe Centre for Human Service Technology is based at the University of Southampton in England. CHST is an international, multi-disciplinary research center focused on influencing the appropriate use of technology in social work practice and education and researching its implementation and impact.\n\nIn July 1997 the CTI Centre for Human Services held a conference on \"Social Services and Learning Technology\" hosted by the Institute for Health and Community Services at the University of Bournemouth.\n\nIn 2003 the journal New Technology in Human Services ceased publication.\n\nIn 1986 Hein de Graaf, Director of the CREON foundation in the Netherlands, organised the first of a series of three-day gatherings. The CREON foundation was a Dutch foundation for computer research, expertise and support in field of the human services. The gatherings, called WELCOM, were designed to increase the knowledge and understanding of information technology in the Dutch human services. WELCOM1 was held in 1986 in Bussum with Walter LaMendola as the main international speaker. WELCOM2, a smaller Dutch-only conference, took place in 1987, again in Bussum. The next WELCOM event, WELCOM3: a combined conference and fair, was held jointly with HUSITA3 in Maastricht in 1993.\n\nFollowing the success of HUSITA's first international conference held in Birmingham in 1987 the Dutch Ministry of Social Welfare, Health and Cultural Affairs organized an informal meeting of European experts in the field of Information Technology and Human Services. The meeting was one of the outcomes of a feasibility study carried out by the CREON foundation, concerning international cooperation in this field. A main conclusion of this feasibility study was that an international (European) network should be established for the exchange of products, ideas, expertise, experiences and skills with respect to the introduction and use of IT in the human services. As a first step in this approach the informal meeting of experts was organized. The European network of organizations was called ENITH (European Network Information Technology and Human services).\n\nIn 1992 an ENITH3 Expert Meeting on “IT Applications and the Quality of Life and Services” was held in The Netherlands.\n\nIn 1994, from September 21 to September 23 an ENITH4 conference was held in Berlin, Germany. Bernd kolleck chaired this conference.\n\nIn September 1995 a CAUSA5/ENITH5 conference on “The Impact of Information Technology on Social Policy,” was held in Eindhoven, The Netherlands. Jan Steyaert chaired this conference.\n"}
{"id": "34955132", "url": "https://en.wikipedia.org/wiki?curid=34955132", "title": "Infopoverty", "text": "Infopoverty\n\nInfopoverty is the name given to the Programme and the World Conference started in 2001, in the ambit of the United Nations, aimed to fight poverty towards the application of ICT, Information and Communication Technologies.\nThe term has been coined in 1998 by Arch. Pierpaolo Saporito, Founder and President of OCCAM - Observatory on Digital Communication and Gerardo Zepeda-Bermudez, Vice-President and Member of the Board.\n\nThe Infopoverty World Conference is the annual international conference, under the auspices of the United Nations, at the United Nations headquarters, New York, organized by OCCAM, together with the European Parliament, UNESCO, and other scientific and university institutions (Infopoverty Institute at Oklahoma University). At its 13th edition, the Infopoverty World Conference saw the participation of more than 100 international organizations,hundreds of from Governments, international and regional organizations, public and private institutions and the civil society and 63 countries.\n\nThe Infopoverty Programme transfers into concrete actions the orientations emerged from the Conference, realizing the ICT Villages, aimed to help the most disadvantaged communities.The first pilot projects were realized at San Ramon and San Pedro, Honduras, in cooperation with the local Ministry of Science and Technologies, following the devastation from Hurricane Mitch.\nThese experiences were instrumental for the definition, thanks to the collaboration with the most important international institutions, of the ICT Village model, validated by the World Summit on the Information Society in Tunis, 2005, with the creation of the Borj Touil Village.\nSubsequently, the model was developed in Sambaina (Madagascar) which was proclaimed Millennium Village Project by the United Nations, and are in progress in Leshoto, in Peru and Ethiopia.\n\n"}
{"id": "300543", "url": "https://en.wikipedia.org/wiki?curid=300543", "title": "Knowledge gap hypothesis", "text": "Knowledge gap hypothesis\n\nThe knowledge gap hypothesis explains that knowledge, like other forms of wealth, is often differentially distributed throughout a social system. Specifically, the hypothesis predicts that \"as the infusion of mass media information into a social system increases, segments of the population with higher socioeconomic status tend to acquire this information at a faster rate than the lower status segments, so that the gap in knowledge between these segments tends to increase rather than decrease\". Phillip J. Tichenor, then Associate Professor of Journalism and Mass Communication, George A. Donohue, Professor of Sociology, and Clarice N. Olien, Instructor in Sociology – three University of Minnesota researchers – first proposed the knowledge gap hypothesis in 1970.\n\nAlthough first formally articulated in 1970, Tichenor, Donohue, and Olien note that the knowledge gap hypothesis has been implicit throughout the mass communication literature.\n\nIndeed, research published as early as the 1920s had already begun to examine the influence of individual characteristics on people's media content preferences. For example, Gray and Munroe identified education – still used today as an operationalization of socioeconomic status in knowledge gap research (see, e.g., Hwang and Jeong, 2009) – as a significant and positive correlate of a person's tendency to prefer \"serious\" (rather than non-serious) print content.\n\nPopular belief, however, held that such differences in preferences might be diminished by the advent of radio, which required neither the special skill nor the exertion of reading (Lazarsfeld, 1940). Guglielmo Marconi, inventor of the wireless telegraph, even believed that the radio would \"make war impossible, because it will make war ridiculous\" (Narodny, 1912, p. 145). Interested in whether radio had attenuated these individual differences in content preferences, Paul Lazarsfeld, head of the Office of Radio Research at Columbia University, set out to examine whether (1) the total amount of time that people listened to the radio and (2) the type of content they listened to correlated with their socioeconomic status. Not only did Lazarsfeld's data indicate people of lower socioeconomic status tended to listen to more radio programming, but also they were simultaneously less likely to listen to \"serious\" radio content. Contrary to popular belief at the time, then, the widespread adoption of the radio seems to have had little, if any, effect on a person's tendency to prefer specific types of content.\n\nFurther evidence supporting the knowledge gap hypothesis came from Star and Hughes (1950) analysis of efforts to inform Cincinnati adults about the United Nations. Like Gray and Munroe (1929) and Lazarsfeld (1940) before them, Star and Hughes found that while the campaign was successful in reaching better-educated people, those with less education virtually ignored the campaign. Additionally, after realizing that the highly educated people reached by the campaign also tended to be more interested in the topic, Star and Hughes suggested that knowledge, education, and interest may be interdependent.\n\nBased on observations implicit in mass communication research, Tichenor, Donohue, and Olien (1970) define the knowledge gap hypothesis as follows:\n\nAdditionally, Tichenor, Donohue, and Olien suggest 5 reasons why the knowledge gap should exist: \nailor their conte\n\nGiven the preceding information, the knowledge gap hypothesis can be expressed using the following set of related propositions:\n\nThe knowledge gap hypothesis can be operationalized both for cross-sectional and time-series appropriate research. For cross-sectional research, the knowledge gap hypothesis expects that \"\"at any given time\", there should be a higher correlation between acquisition of knowledge and education for topics highly publicized in the media than for topics less highly publicized. Tichenor, Donohue, and Olien (1970) tested this hypothesis using an experiment in which participants were asked to read and discuss two news stories of varying publicity. The results of the experiment support the hypothesis because correlations between education and understanding were significant for high publicity stories but not significant for low publicity stories.\n\nFor time-series research, the knowledge gap hypothesis expects that \"\"over time\", acquisition of knowledge of a heavily publicized topic will proceed at a faster rate among better educated persons than among those with less education.\" Tichenor, Donohue, and Olien (1970) tested this hypothesis using public opinion surveys gathered between 1949 and 1965 measuring whether participants believed humans would reach the Moon in the foreseeable future. During the 15-year span, belief among grade-school educated people increased only about 25 percentage points while belief among college educated people increased more than 60 percentage points, a trend consistent with the hypothesis.\n\nAlthough by the mid-1970s extensive data supported the existence of a knowledge gap among low and high socioeconomic status individuals, Donohue, Tichenor, and Olien (1975) sought to refine the hypothesis to determine under what conditions the knowledge gap might be attenuated or even eliminated. To this end, they examined survey data on national and local issues from probability samples of 16 Minnesota communities gathered between 1969 and 1975. Donohue and colleagues identified three variables that weakened the knowledge gap:\n\nAt least two narrative reviews and one meta-analysis of knowledge gap hypothesis research exist. Gaziano conducted two narrative reviews, one of 58 articles with relevant data in 1983 and the other of 39 additional studies in 1997. Gaziano writes, \"the most consistent result is the presence of knowledge differentials, regardless of topic, methodological, or theoretical variations, study excellence, or other variables and conditions\" (1997, p. 240). Evidence from several decades, Gaziano concludes, underscores the enduring character of knowledge gaps and indicates that they transcend topics and research settings.\n\nBecause narrative reviews examine significance tests rather than effect sizes, Hwang and Jeong (2009) conducted a meta-analysis of 46 knowledge gap studies. Consistent with Gaziano's results, however, Hwang and Jeong found constant knowledge gaps across time.\n\nIn 2010 Elizabeth Corley and Dietram Scheufele conducted a study to investigate the widening knowledge gap with the example of nanotechnology. On the whole, public opinion research has shown that respondents with higher socioeconomic status (SES) acquire new information at a higher rate than low SES respondents. Their previous analyses of two large national surveys conducted in 2004 and 2007 found that respondents with at least a college degree displayed an increase in knowledge levels between 2004 and 2007 while respondents with education levels of less than a high school diploma had a significant decrease in nanotechnology knowledge levels. These results stress that the group that is most in need of help, low SES bracket, have not been helped through communication efforts and their nanotechnology knowledge levels have decreased over time.\n\nCorley and Scheufele investigated a wide range of factors that may help to close knowledge gaps, including mass media. The researchers found that the number of days a week that respondents spent online was significantly correlated to knowledge levels about nanotechnology. Therefore, internet use helped those with less formal education to catch up to their counterparts.\n\nThe emergence of the Internet, and more specifically Web 2.0, may be playing a role in closing the knowledge gap. In fact, Corley and Scheufele explain that \"the internet may finally live up to the hype … as a tool for creating a more informed citizenry by serving as a \"leveler\" of knowledge gaps.\" (2010, p. 2) This is widely due to the fact that information on Web 2.0 is written in layman's terms. The content is created by those individuals who have an understanding of the information, but who are also able to tailor the articles towards a more general audience.\n\nStill, the knowledge gap may still exist even with the emergence of Web 2.0. The disenfranchised group, in this situation, the group with lower SES, must still be motivated to get the information to close the gap. Also, information about a given subject must be given. Without the content being provided, Web 2.0 will not be much of a help. However, if the content is provided, Web 2.0 has allowed the readers to be more interactive and talk with others online, through discussion boards, forums and blogs. The results of the research conducted by Corley and Scheufele are a clear call to action for researchers to investigate non-traditional ways of connecting with lay audiences about emerging technologies.\n\nOverall, studies show the introduction of Web 2.0 may help in closing the knowledge gap because the content that traditionally those with lower SES could not reach, can now be understood because it is written in layman's terms. Web 2.0 has helped because:\n\n\nThere are now three existing competing hypotheses: 1) Media Malaise hypothesis (that predicts a general negative effect), 2) the Virtuous Circle hypothesis (that predicts a general positive effect), and 3) the Differential Effect hypothesis (that predicts a positive effect from newspapers, and a null or negative effect from television)\" (Fraile, 2011). Three types of media outlets have been used to examine the media effects on knowledge gap: 1) Television – knowledge gap between lower and higher education groups are greater among light television users compared to heavy television users (Eveland, 2000), 2) Newspaper – the exposure to newspaper can potentially reinforce the knowledge gap in politics for different SES groups since reading newspaper requires literacy ability to effectively understand the information (Jerit \"et al.\", 2006), while other studies suggest that exposure to newspaper actually slightly decreases the knowledge gap rather than increasing it (Eveland, 2000), and 3) Internet - internet exposure increases public's general knowledge in health issues (Shim, 2008).\n\n"}
{"id": "13706125", "url": "https://en.wikipedia.org/wiki?curid=13706125", "title": "List of emerging technologies", "text": "List of emerging technologies\n\nEmerging technologies are those technical innovations which represent progressive developments within a field for competitive advantage.\n\n\n"}
{"id": "51410157", "url": "https://en.wikipedia.org/wiki?curid=51410157", "title": "Modern Muse", "text": "Modern Muse\n\nThe Modern Muse Charity is an online platform designed to encourage the next generation of female business leaders and entrepreneurs.\n\nThe platform, www.modernmuse.org, is aimed at girls aged 8 and above; it features the professional pathways of women from all walks of life, working across business and society, with a focus on encouraging girls into STEM (science, technology, engineering and maths) and digital careers.\n\nMuses are women of all professional levels, across all sectors. They offer information and insights about their career paths. Via an online forum, questions can be asked of the Muses.\n\nModern Muse seek to improve social mobility through engagement with education and by providing insight to the variety of career options, work experience, job placements, internships and apprenticeships available. Modern Muse was developed in partnership with BP and Deloitte’s Super Pioneers programme. Keytree and FDM are also founding partners.\n\nThe Modern Muse platform offers young women access to female role models. The Modern Muse platform also allows teachers and parents to register and use the platform. A Muse may be any woman in the workplace who is passionate about their career.\n\nFounding Modern Muse Patrons include: \n\nVia the Modern Muse platform:\nBy reaching out to young women, Modern Muse aims to increase the number of women running businesses by 100,000 in the next ten years and to help them achieve their full potential.\n\nKaren Gill and Maxine Benson co-founded and own Everywoman, as well as Modern Muse. Both Gill and Benson were awarded an MBE in 2009 in recognition of her service to women’s enterprise.\n\n"}
{"id": "2496273", "url": "https://en.wikipedia.org/wiki?curid=2496273", "title": "Soft handover", "text": "Soft handover\n\nSoft handover or soft handoff refers to a feature used by the CDMA and W-CDMA standards, where a cell phone is simultaneously connected to two or more cells (or cell sectors) during a call. If the sectors are from the same physical cell site (a sectorised site), it is referred to as softer handoff. This technique is a form of mobile-assisted handover, for IS-95/CDMA2000 CDMA cell phones continuously make power measurements of a list of neighboring cell sites, and determine whether or not to request or end soft handover with the cell sectors on the list.\n\nDue to the properties of the CDMA signaling scheme, it is possible for a CDMA phone to simultaneously receive signals from two or more radio base stations that are transmitting the same bit stream (using different transmission codes) on the different physical channels in the same frequency bandwidth. If the signal power from two or more radio base stations is nearly the same, the phone receiver can combine the received signals in such a way that the bit stream is decoded much more reliably than if only one base station were transmitting to the subscriber station. If any one of these signals fades significantly, there will be a relatively high probability of having adequate signal strength from one of the other radio base stations.\n\nOn the uplink (phone-to-cell-site), all the cell site sectors that are actively supporting a call in soft handover send the bit stream that they receive back to the Radio Network Controller (RNC), along with information about the quality of the received bits. The RNC examines the quality of all these bit streams and dynamically chooses the bit stream with the highest quality. Again, if the signal degrades rapidly, the chance is still good that a strong signal will be available at one of the other cell sectors that is supporting the call in soft handover.\n\nSoft handover results in a diversity gain called soft handover gain.\n\n\n"}
