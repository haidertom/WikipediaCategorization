{"id": "644223", "url": "https://en.wikipedia.org/wiki?curid=644223", "title": "Computer-assisted translation", "text": "Computer-assisted translation\n\nComputer-assisted translation,computer-aided translation or CAT is a form of language translation in which a human translator uses computer hardware to support and facilitate the translation process.\n\nComputer-assisted translation is sometimes called machine-assisted, or machine-aided, translation (not to be confused with machine translation).\n\nThe automatic machine translation systems available today are not able to produce high-quality translations unaided: their output must be edited by a human to correct errors and improve the quality of translation. Computer-assisted translation (CAT) incorporates that manual editing stage into the software, making translation an interactive process between human and computer.\n\nSome advanced computer-assisted translation solutions include controlled machine translation (MT). Higher priced MT modules generally provide a more complex set of tools available to the translator, which may include terminology management features and various other linguistic tools and utilities. Carefully customized user dictionaries based on correct terminology significantly improve the accuracy of MT, and as a result, aim at increasing the efficiency of the entire translation process.\n\nComputer-assisted translation is a broad and imprecise term covering a range of tools, from the fairly simple to the complicated. These can include:\n\nTranslation memory programs store previously translated source texts and their equivalent target texts in a database and retrieve related segments during the translation of new texts.\n\nSuch programs split the source text into manageable units known as \"segments\". A source-text sentence or sentence-like unit (headings, titles or elements in a list) may be considered a segment. Texts may also be segmented into larger units such as paragraphs or small ones, such as clauses. As the translator works through a document, the software displays each source segment in turn, and provides a previous translation for re-use if it finds a matching source segment in its database. If it does not, the program allows the translator to enter a translation for the new segment. After the translation for a segment is completed, the program stores the new translation and moves on to the next segment. In the dominant paradigm, the translation memory is, in principle, a simple database of fields containing the source language segment, the translation of the segment, and other information such as segment creation date, last access, translator name, and so on. Another translation memory approach does not involve the creation of a database, relying on aligned reference documents instead.\n\nSome translation memory programs function as standalone environments, while others function as an add-on or macro for commercially available word-processing or other business software programs. Add-on programs allow source documents from other formats, such as desktop publishing files, spreadsheets, or HTML code, to be handled using the TM program.\n\nTranslation memory technology is particularly useful to organizations translating text that contains specialized vocabulary related to a particular industry, such as automotive manufacturing.\n\nNew to the translation industry, Language search-engine software is typically an Internet-based system that works similarly to Internet search engines. Rather than searching the Internet, however, a language search engine searches a large repository of Translation Memories to find previously translated sentence fragments, phrases, whole sentences, even complete paragraphs that match source document segments.\n\nLanguage search engines are designed to leverage modern search technology to conduct searches based on the source words in context to ensure that the search results match the meaning of the source segments. Like traditional TM tools, the value of a language search engine rests heavily on the Translation Memory repository it searches against.\n\nTerminology management software provides the translator a means of automatically searching a given terminology database for terms appearing in a document, either by automatically displaying terms in the translation memory software interface window or through the use of hot keys to view the entry in the terminology database. Some programs have other hotkey combinations allowing the translator to add new terminology pairs to the terminology database on the fly during translation. Some of the more advanced systems enable translators to check, either interactively or in batch mode, if the correct source/target term combination has been used within and across the translation memory segments in a given project. Independent terminology management systems also exist that can provide workflow functionality, visual taxonomy, work as a type of term checker (similar to spell checker, terms that have not been used correctly are flagged) and can support other types of multilingual term facet classifications such as pictures, videos, or sound.\n\nAlignment programs take completed translations, divide both source and target texts into segments, and attempt to determine which segments belong together in order to build a translation memory or other reference resource with the content. Many alignment programs allow translators to manually realign mismatched segments. The resulting bitext (also known as parallel text) alignment can then be imported into a translation memory program for future translations or used as a reference document.\n\nInteractive machine translation is a paradigm in which the automatic system attempts to predict the translation the human translator is going to produce by suggesting translation hypotheses. These hypotheses may either be the complete sentence, or the part of the sentence that is yet to be translated.\n\nAugmented translation is a form of human translation carried out within an integrated technology environment that provides translators access to subsegment adaptive machine translation (MT) and translation memory (TM), terminology lookup (CAT), and automatic content enrichment (ACE) to aid their work, and that automates project management, file handling, and other ancillary tasks.\n\nBased on the concept of augmented reality, augmented translation seeks to make translators more productive by providing them with relevant information on an as-needed basis. This information adapts to the habits and style of individual translators in order to accelerate their work and increase productivity. It differs from classical postediting of MT, which has linguists revise entire texts translated by machines, in that it provides machine translation and information as suggestions that can be adopted in their entirety, edited, or ignored, as appropriate.\n\nAugmented translation extends principles first developed in the 1980s that made their way into CAT tools. However, it integrates several functions that have previously been discrete into one environment. For example, translators historically have had to leave their translation environments to do terminology research, but in an augmented environment, an ACE component would automatically provide links to information about terms and concepts found in the text directly within the environment.\n\nAs of May 2017, no full implementations of an augmented translation environment exist, although individual developers have created partial systems.\n\n\n"}
{"id": "2334223", "url": "https://en.wikipedia.org/wiki?curid=2334223", "title": "Do You Speak American?", "text": "Do You Speak American?\n\nDo You Speak American? is a documentary film and accompanying book about journalist Robert MacNeil's investigation into how different people throughout the United States of America speak. The book and documentary look at the evolution of America's way of speaking from the English language to various ways of speaking in regions throughout the country. Divisions of ethnicity, geography and social status and how they affect how Americans communicate are addressed. As part of the project, MacNeil traveled across the country conducting interviews with ordinary people as well as experts such as William Labov.\n\nIn the United States, the documentary was broadcast in several parts on PBS. The companion book () was co-authored by MacNeil and William Cran.\n\n"}
{"id": "59114506", "url": "https://en.wikipedia.org/wiki?curid=59114506", "title": "Influence of French on English", "text": "Influence of French on English\n\nThere has been a long-standing influence of French on English, in terms of syntax, grammar, lexicon, spelling and pronunciation.\n\nMost French vocabulary that entered English occurred after the Norman conquest of England in 1066 and the establishment of a French-speaking administration. French became the language of the court, the administration and the elites for several centuries, until after the Hundred Years War. English has been constantly influenced by French from that time till present day.\nAccording to Laura K. Lawless, more than a third of the current English vocabulary is of French origin. According to linguist Henriette Walter, words of French origin represent more than two thirds of the English vocabulary. It is estimated by linguist Anthony Lacoudre that over 40 000 English words are directly French and may be understood without orthographical change by French speakers.\n\nAt the beginning of XIth century, the English language did not have a well-defined status. Indeed, the inhabitants of what would become Great Britain did not have a language that allowed them to communicate with each other. There were many different dialectal forms. Great Britain, in which various Celtic idioms had coexisted since the IVth century, had experienced partial Roman occupation since the 1st century A.D., and this for four centuries.\n\nFrom 450 onwards, the Saxons, the Angles and the Jutes, who came from the continent, settled in the south and east. Germanic dialects would prevail in these regions, supplanting Celtic dialects, which would remain in the west and north of the island (Wales, Cornwall, Scotland) and Ireland. In the VIIIth century, Vikings from Scandinavia settled on the island. Their languages, also Germanic, in turn influence the languages already present on the island. Thus, at the dawn of XIth century, the country was made up of a series of peoples with significantly different speeches, most of them Germanic, with multiple influences.\n\nIt is therefore a linguistically disunited people that the Normans will get massively in contact with, from 1066. William II of Normandy, supported by his King, Philip I of France, and his blood legitimacy to the throne of England, landed at Hastings, in Sussex, on 29 September 1066. His men are deployed around the city waiting for the king Harold II's troops. On October 14, exhausted by the long journey to Hastings, Harold II's troops lost the battle after a day. Following the defeat of the English, Duke William II of Normandy became King of England on December 25, 1066, crowned under the name of William I of England, also known as William the Conqueror. This date marks the beginning of a long period of ties between the peoples and languages.\n\nIn fact, these links already existed before the Battle of Hastings. Indeed, the geographical location of Normandy, facing the English Channel, favoured commercial contacts with England. These ties will be further strengthened at the beginning of the XIth century when the daughter of the Duke Richard II of Normandy, Emma, marries King Æthelred II of England. But it is really from the 1066 conquest that proto-English becomes massively impregnated with Old French, then modern French. It should be noted, however, that only French will influence English in the centuries following the conquest. The reverse contribution of English to French will only be real from the XVIIIth century.\n\nThe arrival of William the Conqueror and his barons significantly changed the linguistic situation in England. Norman is essentially imposed in the upper layers of society. The Anglo-Saxon dialects were supplanted by Norman in the circles of the court and aristocracy, justice and the Church. The influential circles, who came from Normandy and settled in England, kept their Norman mother tongue, while the more modest rural and urban strata continued to speak English.\n\nNorman is a particular variety of the Gallo-Roman language, spoken in Normandy. It is one of the Oil languages alongside, among others, the Picard and the Walloon. The Norman language is modified in contact with the Anglo-Saxon language. It then integrates words and phrases from English and will give birth to a dialect, Anglo-Norman, still spoken on the Anglo-Norman isles. Anglo-Norman can be described as a vernacular language, on English soil in the XIth century, in the field of literature, culture, court and among the clergy. French was therefore, at first, spoken in England under the form of this Anglo-Norman dialect.\n\nDuring the XIIth century, continental French has a greater influence on Old English. It acquires great prestige in England, especially within the aristocracy and the clergy. It becomes the language of law and justice nationwide. Rich and noble families, most of them of Norman origin, teach their children French or send them to study in France. The expansion of the French language in England was also encouraged by royal marriages. From Henry II Plantagenet and Eleanor of Aquitaine at the beginning of the century, to Henri VI and Marguerite in the XVth century, all kings of England married French princesses. These marriages made French the language of the English court for several centuries and were decisive in strengthening the use of French in England. This period (XIIth-XVth centuries) is characterized by a massive influx of French words into Old English vocabulary.\n\nIn 1204, Philippe Auguste Normandy is officially annexed to the kingdom of France, politically isolating England from the continent. Normans who choose to stay in England move further away from France and, therefore, from the French language. Keeping its status as the language of justice and the language of power, England saw the first teaching manuals for teaching French to the English. These manuals were intended for English nobles who wish to perfect their knowledge of French and teach it to their children. Two types of French spoken in the higher spheres of English society can be distinguished during the XIIIth century : the Anglo-Norman dialect, which was the aristocrats' mother tongue, and a more prestigious type of French as a second language. Knowing \"parisian\" French was a mark of social distinction. As a language of culture, French supplanted Latin from the XIIth century onward as the language of diplomacy and worldly relations throughout Europe. The mass and influence of French literature reinforced its reputation and appeal.\n\nThe XVIth century, that of the Renaissance, is a decisive century for French since king François I of France, through the Ordonnance de Villers-Cotterêts (1539), makes French the official language of administration in the whole kingdom.\nAlthough troubled by the European wars of religion, the Italian Wars, the language is marked by intellectual, technical and scientific effervescence. It ushered in an era of prosperity that would also spread to England through French.\n\nThe XVIIth century announces the apogee of the Kingdom of France. This period was characterized by the political, literary and artistic prestige of France and the French language. Peace restored and unity ensured in the country, economy grew considerably. Personalities such as the King Henri IV, the Cardinal of Richelieu or the Sun King contribute to fixing and enhancing the French language in Europe, the Americas, India and Oceania.\n\nThe creation of the Académie française by Richelieu in 1635, under Louis XIII, was a step that led to the standardization of French in continental Europe and abroad, including England. French is then the second language of all the elites in Europe, from Turkey to Ireland and from Moscow to Lisbon. The greatest scholars and intellectuals, writers and scientists, express themselves and correspond in this new standardised French. French is considered a perfect language, whose beauty and elegance are determined by the development of scientific logic, aided by dictionaries and grammars.\n\nThe geographical use of French has continuously and greatly diversified in the last five hundred years, with countries and states like New-Brunswick, Quebec, Ivory Coast, Benin, Togo, Guinea, Cameroon, Congo, Democratic Republic of the Congo, Madagascar, Mauritius, Tchad, Djibouti, Senegal, Morocco, Algeria, Tunisia, Lebanon, France, Belgium, Switzerland, Luxembourg, Monaco, Aosta Valley, French Polynesia, New Caledonia, and Vanuatu adopting it as their official language. This geographical diversity has led to many different contacts with vernacular dialects, regional and international languages, from which French has often been enriched locally.\nIn a number of countries and regions where French shares co-officiality with English (Cameroon, Canada, Jersey, Mauritius, Rwanda, Vanuatu), particular lexical regionalisms are observed where French and English terms are used interchangeably.\n\nSeveral elements must be observed.\n\n\nThe following French glossary in English is in no way exhaustive. These words come as examples to illustrate the countless French words that are part of the English language.\n\nIn this section, examples of French-to-English lexical contributions are classified by field and in chronological order. The periods during which these words were used in the English language are specified as much as possible. It is not always possible to state with certainty the precise period from which a word was borrowed or integrated.\n\nThe English word is on the left, with its current French equivalent in brackets, then comes its Old French origin in bold and the century of its introduction on the right.\n\n\n\n\n\n\n\n\n\n"}
{"id": "17524", "url": "https://en.wikipedia.org/wiki?curid=17524", "title": "Language", "text": "Language\n\nLanguage is a system that consists of the development, acquisition, maintenance and use of complex systems of communication, particularly the human ability to do so; and a language is any specific example of such a system.\n\nThe scientific study of language is called linguistics. Questions concerning the philosophy of language, such as whether words can represent experience, have been debated at least since Gorgias and Plato in ancient Greece. Thinkers such as Rousseau have argued that language originated from emotions while others like Kant have held that it originated from rational and logical thought. 20th-century philosophers such as Wittgenstein argued that philosophy is really the study of language. Major figures in linguistics include Ferdinand de Saussure and Noam Chomsky.\n\nEstimates of the number of human languages in the world vary between 5,000 and 7,000. However, any precise estimate depends on a partly arbitrary distinction between languages and dialects. Natural languages are spoken or signed, but any language can be encoded into secondary media using auditory, visual, or tactile stimuli – for example, in whistling, signed, or braille. This is because human language is modality-independent. Depending on philosophical perspectives regarding the definition of language and meaning, when used as a general concept, \"language\" may refer to the cognitive ability to learn and use systems of complex communication, or to describe the set of rules that makes up these systems, or the set of utterances that can be produced from those rules. All languages rely on the process of semiosis to relate signs to particular meanings. Oral, manual and tactile languages contain a phonological system that governs how symbols are used to form sequences known as words or morphemes, and a syntactic system that governs how words and morphemes are combined to form phrases and utterances.\n\nHuman language has the properties of productivity and displacement, and relies entirely on social convention and learning. Its complex structure affords a much wider range of expressions than any known system of animal communication. Language is thought to have originated when early hominins started gradually changing their primate communication systems, acquiring the ability to form a theory of other minds and a shared intentionality. This development is sometimes thought to have coincided with an increase in brain volume, and many linguists see the structures of language as having evolved to serve specific communicative and social functions. Language is processed in many different locations in the human brain, but especially in Broca's and Wernicke's areas. Humans acquire language through social interaction in early childhood, and children generally speak fluently by approximately three years old. The use of language is deeply entrenched in human culture. Therefore, in addition to its strictly communicative uses, language also has many social and cultural uses, such as signifying group identity, social stratification, as well as social grooming and entertainment.\n\nLanguages evolve and diversify over time, and the history of their evolution can be reconstructed by comparing modern languages to determine which traits their ancestral languages must have had in order for the later developmental stages to occur. A group of languages that descend from a common ancestor is known as a language family. The Indo-European family is the most widely spoken and includes languages as diverse as English, Russian and Hindi; the Sino-Tibetan family includes Mandarin, Bodo and the other Chinese languages, and Tibetan; the Afro-Asiatic family includes Arabic, Somali, and Hebrew; the Bantu languages include Swahili, and Zulu, and hundreds of other languages spoken throughout Africa; and the Malayo-Polynesian languages include Indonesian, Malay, Tagalog, and hundreds of other languages spoken throughout the Pacific. The languages of the Dravidian family, spoken mostly in Southern India, include Tamil Telugu and Kannada. Academic consensus holds that between 50% and 90% of languages spoken at the beginning of the 21st century will probably have become extinct by the year 2100.\n\nThe English word \"language\" derives ultimately from Proto-Indo-European \"\" \"tongue, speech, language\" through Latin \"lingua\", \"language; tongue\", and Old French \"language\". The word is sometimes used to refer to codes, ciphers, and other kinds of artificially constructed communication systems such as formally defined computer languages used for computer programming. Unlike conventional human languages, a formal language in this sense is a system of signs for encoding and decoding information. This article specifically concerns the properties of natural human language as it is studied in the discipline of linguistics.\n\nAs an object of linguistic study, \"language\" has two primary meanings: an abstract concept, and a specific linguistic system, e.g. \"French\". The Swiss linguist Ferdinand de Saussure, who defined the modern discipline of linguistics, first explicitly formulated the distinction using the French word \"langage\" for language as a concept, \"langue\" as a specific instance of a language system, and \"parole\" for the concrete usage of speech in a particular language.\n\nWhen speaking of language as a general concept, definitions can be used which stress different aspects of the phenomenon. These definitions also entail different approaches and understandings of language, and they also inform different and often incompatible schools of linguistic theory. Debates about the nature and origin of language go back to the ancient world. Greek philosophers such as Gorgias and Plato debated the relation between words, concepts and reality. Gorgias argued that language could represent neither the objective experience nor human experience, and that communication and truth were therefore impossible. Plato maintained that communication is possible because language represents ideas and concepts that exist independently of, and prior to, language.\n\nDuring the Enlightenment and its debates about human origins, it became fashionable to speculate about the origin of language. Thinkers such as Rousseau and Herder argued that language had originated in the instinctive expression of emotions, and that it was originally closer to music and poetry than to the logical expression of rational thought. Rationalist philosophers such as Kant and Descartes held the opposite view. Around the turn of the 20th century, thinkers began to wonder about the role of language in shaping our experiences of the world – asking whether language simply reflects the objective structure of the world, or whether it creates concepts that it in turn imposes on our experience of the objective world. This led to the question of whether philosophical problems are really firstly linguistic problems. The resurgence of the view that language plays a significant role in the creation and circulation of concepts, and that the study of philosophy is essentially the study of language, is associated with what has been called the linguistic turn and philosophers such as Wittgenstein in 20th-century philosophy. These debates about language in relation to meaning and reference, cognition and consciousness remain active today.\n\nOne definition sees language primarily as the mental faculty that allows humans to undertake linguistic behaviour: to learn languages and to produce and understand utterances. This definition stresses the universality of language to all humans, and it emphasizes the biological basis for the human capacity for language as a unique development of the human brain. Proponents of the view that the drive to language acquisition is innate in humans argue that this is supported by the fact that all cognitively normal children raised in an environment where language is accessible will acquire language without formal instruction. Languages may even develop spontaneously in environments where people live or grow up together without a common language; for example, creole languages and spontaneously developed sign languages such as Nicaraguan Sign Language. This view, which can be traced back to the philosophers Kant and Descartes, understands language to be largely innate, for example, in Chomsky's theory of Universal Grammar, or American philosopher Jerry Fodor's extreme innatist theory. These kinds of definitions are often applied in studies of language within a cognitive science framework and in neurolinguistics.\n\nAnother definition sees language as a formal system of signs governed by grammatical rules of combination to communicate meaning. This definition stresses that human languages can be described as closed structural systems consisting of rules that relate particular signs to particular meanings. This structuralist view of language was first introduced by Ferdinand de Saussure, and his structuralism remains foundational for many approaches to language.\n\nSome proponents of Saussure's view of language have advocated a formal approach which studies language structure by identifying its basic elements and then by presenting a formal account of the rules according to which the elements combine in order to form words and sentences. The main proponent of such a theory is Noam Chomsky, the originator of the generative theory of grammar, who has defined language as the construction of sentences that can be generated using transformational grammars. Chomsky considers these rules to be an innate feature of the human mind and to constitute the rudiments of what language is. By way of contrast, such transformational grammars are also commonly used to provide formal definitions of language are commonly used in formal logic, in formal theories of grammar, and in applied computational linguistics. In the philosophy of language, the view of linguistic meaning as residing in the logical relations between propositions and reality was developed by philosophers such as Alfred Tarski, Bertrand Russell, and other formal logicians.\n\nYet another definition sees language as a system of communication that enables humans to exchange verbal or symbolic utterances. This definition stresses the social functions of language and the fact that humans use it to express themselves and to manipulate objects in their environment. Functional theories of grammar explain grammatical structures by their communicative functions, and understand the grammatical structures of language to be the result of an adaptive process by which grammar was \"tailored\" to serve the communicative needs of its users.\n\nThis view of language is associated with the study of language in pragmatic, cognitive, and interactive frameworks, as well as in sociolinguistics and linguistic anthropology. Functionalist theories tend to study grammar as dynamic phenomena, as structures that are always in the process of changing as they are employed by their speakers. This view places importance on the study of linguistic typology, or the classification of languages according to structural features, as it can be shown that processes of grammaticalization tend to follow trajectories that are partly dependent on typology. In the philosophy of language, the view of pragmatics as being central to language and meaning is often associated with Wittgenstein's later works and with ordinary language philosophers such as J.L. Austin, Paul Grice, John Searle, and W.O. Quine.\n\nA number of features, many of which were described by Charles Hockett and called design features set human language apart from other known systems of communication, such as those used by non-human animals.\n\nCommunication systems used by other animals such as bees or apes are closed systems that consist of a finite, usually very limited, number of possible ideas that can be expressed. In contrast, human language is open-ended and productive, meaning that it allows humans to produce a vast range of utterances from a finite set of elements, and to create new words and sentences. This is possible because human language is based on a dual code, in which a finite number of elements which are meaningless in themselves (e.g. sounds, letters or gestures) can be combined to form an infinite number of larger units of meaning (words and sentences). However, one study has demonstrated that an Australian bird, the chestnut-crowned babbler, is capable of using the same acoustic elements in different arrangements to create two functionally distinct vocalizations. Additionally, pied babblers have demonstrated the ability to generate two functionally distinct vocalisations composed of the same sound type, which can only be distinguished by the number of repeated elements.\n\nSeveral species of animals have proved to be able to acquire forms of communication through social learning: for instance a bonobo named Kanzi learned to express itself using a set of symbolic lexigrams. Similarly, many species of birds and whales learn their songs by imitating other members of their species. However, while some animals may acquire large numbers of words and symbols, none have been able to learn as many different signs as are generally known by an average 4 year old human, nor have any acquired anything resembling the complex grammar of human language.\n\nHuman languages also differ from animal communication systems in that they employ grammatical and semantic categories, such as noun and verb, present and past, which may be used to express exceedingly complex meanings. Human language is also unique in having the property of recursivity: for example, a noun phrase can contain another noun phrase (as in \"<nowiki>the chimpanzee]'s lips]</nowiki>\") or a clause can contain another clause (as in \"<nowiki>[I see [the dog is running</nowiki>\"). Human language is also the only known natural communication system whose adaptability may be referred to as \"modality independent\". This means that it can be used not only for communication through one channel or medium, but through several. For example, spoken language uses the auditive modality, whereas sign languages and writing use the visual modality, and braille writing uses the tactile modality.\n\nHuman language is also unique in being able to refer to abstract concepts and to imagined or hypothetical events as well as events that took place in the past or may happen in the future. This ability to refer to events that are not at the same time or place as the speech event is called \"displacement\", and while some animal communication systems can use displacement (such as the communication of bees that can communicate the location of sources of nectar that are out of sight), the degree to which it is used in human language is also considered unique.\n\nTheories about the origin of language differ in regard to their basic assumptions about what language is. Some theories are based on the idea that language is so complex that one cannot imagine it simply appearing from nothing in its final form, but that it must have evolved from earlier pre-linguistic systems among our pre-human ancestors. These theories can be called continuity-based theories. The opposite viewpoint is that language is such a unique human trait that it cannot be compared to anything found among non-humans and that it must therefore have appeared suddenly in the transition from pre-hominids to early man. These theories can be defined as discontinuity-based. Similarly, theories based on the generative view of language pioneered by Noam Chomsky see language mostly as an innate faculty that is largely genetically encoded, whereas functionalist theories see it as a system that is largely cultural, learned through social interaction.\n\nChomsky is one prominent proponent of a discontinuity-based theory of human language origins. He suggests that for scholars interested in the nature of language, \"talk about the evolution of the language capacity is beside the point.\" Chomsky proposes that perhaps \"some random mutation took place [...] and it reorganized the brain, implanting a language organ in an otherwise primate brain.\" Though cautioning against taking this story literally, Chomsky insists that \"it may be closer to reality than many other fairy tales that are told about evolutionary processes, including language.\"\n\nContinuity-based theories are held by a majority of scholars, but they vary in how they envision this development. Those who see language as being mostly innate, for example psychologist Steven Pinker, hold the precedents to be animal cognition, whereas those who see language as a socially learned tool of communication, such as psychologist Michael Tomasello, see it as having developed from animal communication in primates: either gestural or vocal communication to assist in cooperation. Other continuity-based models see language as having developed from music, a view already espoused by Rousseau, Herder, Humboldt, and Charles Darwin. A prominent proponent of this view is archaeologist Steven Mithen. Stephen Anderson states that the age of spoken languages is estimated at 60,000 to 100,000 years and that: Researchers on the evolutionary origin of language generally find it plausible to suggest that language was invented only once, and that all modern spoken languages are thus in some way related, even if that relation can no longer be recovered ... because of limitations on the methods available for reconstruction.\n\nBecause language emerged in the early prehistory of man, before the existence of any written records, its early development has left no historical traces, and it is believed that no comparable processes can be observed today. Theories that stress continuity often look at animals to see if, for example, primates display any traits that can be seen as analogous to what pre-human language must have been like. And early human fossils can be inspected for traces of physical adaptation to language use or pre-linguistic forms of symbolic behaviour. Among the signs in human fossils that may suggest linguistic abilities are: the size of the brain relative to body mass, the presence of a larynx capable of advanced sound production and the nature of tools and other manufactured artifacts.\n\nIt was mostly undisputed that pre-human australopithecines did not have communication systems significantly different from those found in great apes in general. However, a 2017 study on Ardipithecus ramidus challenges this belief. Scholarly opinions vary as to the developments since the appearance of the genus \"Homo\" some 2.5 million years ago. Some scholars assume the development of primitive language-like systems (proto-language) as early as \"Homo habilis\" (2.3 million years ago) while others place the development of primitive symbolic communication only with \"Homo erectus\" (1.8 million years ago) or \"Homo heidelbergensis\" (0.6 million years ago), and the development of language proper with Anatomically Modern \"Homo sapiens\" with the Upper Paleolithic revolution less than 100,000 years ago.\n\nThe study of language, linguistics, has been developing into a science since the first grammatical descriptions of particular languages in India more than 2000 years ago, after the development of the Brahmi script. Modern linguistics is a science that concerns itself with all aspects of language, examining it from all of the theoretical viewpoints described above.\n\nThe academic study of language is conducted within many different disciplinary areas and from different theoretical angles, all of which inform modern approaches to linguistics. For example, descriptive linguistics examines the grammar of single languages, theoretical linguistics develops theories on how best to conceptualize and define the nature of language based on data from the various extant human languages, sociolinguistics studies how languages are used for social purposes informing in turn the study of the social functions of language and grammatical description, neurolinguistics studies how language is processed in the human brain and allows the experimental testing of theories, computational linguistics builds on theoretical and descriptive linguistics to construct computational models of language often aimed at processing natural language or at testing linguistic hypotheses, and historical linguistics relies on grammatical and lexical descriptions of languages to trace their individual histories and reconstruct trees of language families by using the comparative method.\n\nThe formal study of language is often considered to have started in India with Pāṇini, the 5th century BC grammarian who formulated 3,959 rules of Sanskrit morphology. However, Sumerian scribes already studied the differences between Sumerian and Akkadian grammar around 1900 BC. Subsequent grammatical traditions developed in all of the ancient cultures that adopted writing.\n\nIn the 17th century AD, the French Port-Royal Grammarians developed the idea that the grammars of all languages were a reflection of the universal basics of thought, and therefore that grammar was universal. In the 18th century, the first use of the comparative method by British philologist and expert on ancient India William Jones sparked the rise of comparative linguistics. The scientific study of language was broadened from Indo-European to language in general by Wilhelm von Humboldt. Early in the 20th century, Ferdinand de Saussure introduced the idea of language as a static system of interconnected units, defined through the oppositions between them.\n\nBy introducing a distinction between diachronic and synchronic analyses of language, he laid the foundation of the modern discipline of linguistics. Saussure also introduced several basic dimensions of linguistic analysis that are still fundamental in many contemporary linguistic theories, such as the distinctions between syntagm and paradigm, and the Langue-parole distinction, distinguishing language as an abstract system (\"langue\"), from language as a concrete manifestation of this system (\"parole\").\n\nIn the 1960s, Noam Chomsky formulated the generative theory of language. According to this theory, the most basic form of language is a set of syntactic rules that is universal for all humans and which underlies the grammars of all human languages. This set of rules is called Universal Grammar; for Chomsky, describing it is the primary objective of the discipline of linguistics. Thus, he considered that the grammars of individual languages are only of importance to linguistics insofar as they allow us to deduce the universal underlying rules from which the observable linguistic variability is generated.\n\nIn opposition to the formal theories of the generative school, functional theories of language propose that since language is fundamentally a tool, its structures are best analyzed and understood by reference to their functions. Formal theories of grammar seek to define the different elements of language and describe the way they relate to each other as systems of formal rules or operations, while functional theories seek to define the functions performed by language and then relate them to the linguistic elements that carry them out. The framework of cognitive linguistics interprets language in terms of the concepts (which are sometimes universal, and sometimes specific to a particular language) which underlie its forms. Cognitive linguistics is primarily concerned with how the mind creates meaning through language.\n\nSpeaking is the default modality for language in all cultures. The production of spoken language depends on sophisticated capacities for controlling the lips, tongue and other components of the vocal apparatus, the ability to acoustically decode speech sounds, and the neurological apparatus required for acquiring and producing language. The study of the genetic bases for human language is at an early stage: the only gene that has definitely been implicated in language production is FOXP2, which may cause a kind of congenital language disorder if affected by mutations.\n\n The brain is the coordinating center of all linguistic activity; it controls both the production of linguistic cognition and of meaning and the mechanics of speech production. Nonetheless, our knowledge of the neurological bases for language is quite limited, though it has advanced considerably with the use of modern imaging techniques. The discipline of linguistics dedicated to studying the neurological aspects of language is called neurolinguistics.\n\nEarly work in neurolinguistics involved the study of language in people with brain lesions, to see how lesions in specific areas affect language and speech. In this way, neuroscientists in the 19th century discovered that two areas in the brain are crucially implicated in language processing. The first area is Wernicke's area, which is in the posterior section of the superior temporal gyrus in the dominant cerebral hemisphere. People with a lesion in this area of the brain develop receptive aphasia, a condition in which there is a major impairment of language comprehension, while speech retains a natural-sounding rhythm and a relatively normal sentence structure. The second area is Broca's area, in the posterior inferior frontal gyrus of the dominant hemisphere. People with a lesion to this area develop expressive aphasia, meaning that they know what they want to say, they just cannot get it out. They are typically able to understand what is being said to them, but unable to speak fluently. Other symptoms that may be present in expressive aphasia include problems with fluency, articulation, word-finding, word repetition, and producing and comprehending complex grammatical sentences, both orally and in writing. Those with this aphasia also exhibit ungrammatical speech and show inability to use syntactic information to determine the meaning of sentences. Both expressive and receptive aphasia also affect the use of sign language, in analogous ways to how they affect speech, with expressive aphasia causing signers to sign slowly and with incorrect grammar, whereas a signer with receptive aphasia will sign fluently, but make little sense to others and have difficulties comprehending others' signs. This shows that the impairment is specific to the ability to use language, not to the physiology used for speech production.\n\nWith technological advances in the late 20th century, neurolinguists have also incorporated non-invasive techniques such as functional magnetic resonance imaging (fMRI) and electrophysiology to study language processing in individuals without impairments.\n\nSpoken language relies on human physical ability to produce sound, which is a longitudinal wave propagated through the air at a frequency capable of vibrating the ear drum. This ability depends on the physiology of the human speech organs. These organs consist of the lungs, the voice box (larynx), and the upper vocal tract – the throat, the mouth, and the nose. By controlling the different parts of the speech apparatus, the airstream can be manipulated to produce different speech sounds.\n\nThe sound of speech can be analyzed into a combination of segmental and suprasegmental elements. The segmental elements are those that follow each other in sequences, which are usually represented by distinct letters in alphabetic scripts, such as the Roman script. In free flowing speech, there are no clear boundaries between one segment and the next, nor usually are there any audible pauses between words. Segments therefore are distinguished by their distinct sounds which are a result of their different articulations, and they can be either vowels or consonants. Suprasegmental phenomena encompass such elements as stress, phonation type, voice timbre, and prosody or intonation, all of which may have effects across multiple segments.\n\nConsonants and vowel segments combine to form syllables, which in turn combine to form utterances; these can be distinguished phonetically as the space between two inhalations. Acoustically, these different segments are characterized by different formant structures, that are visible in a spectrogram of the recorded sound wave (See illustration of Spectrogram of the formant structures of three English vowels). Formants are the amplitude peaks in the frequency spectrum of a specific sound.\n\nVowels are those sounds that have no audible friction caused by the narrowing or obstruction of some part of the upper vocal tract. They vary in quality according to the degree of lip aperture and the placement of the tongue within the oral cavity. Vowels are called \"close\" when the lips are relatively closed, as in the pronunciation of the vowel (English \"ee\"), or \"open\" when the lips are relatively open, as in the vowel (English \"ah\"). If the tongue is located towards the back of the mouth, the quality changes, creating vowels such as (English \"oo\"). The quality also changes depending on whether the lips are rounded as opposed to unrounded, creating distinctions such as that between (unrounded front vowel such as English \"ee\") and (rounded front vowel such as German \"ü\").\n\nConsonants are those sounds that have audible friction or closure at some point within the upper vocal tract. Consonant sounds vary by place of articulation, i.e. the place in the vocal tract where the airflow is obstructed, commonly at the lips, teeth, alveolar ridge, palate, velum, uvula, or glottis. Each place of articulation produces a different set of consonant sounds, which are further distinguished by manner of articulation, or the kind of friction, whether full closure, in which case the consonant is called \"occlusive\" or \"stop\", or different degrees of aperture creating \"fricatives\" and \"approximants\". Consonants can also be either \"voiced or unvoiced\", depending on whether the vocal cords are set in vibration by airflow during the production of the sound. Voicing is what separates English in \"bus\" (unvoiced sibilant) from in \"buzz\" (voiced sibilant).\n\nSome speech sounds, both vowels and consonants, involve release of air flow through the nasal cavity, and these are called \"nasals\" or \"nasalized\" sounds. Other sounds are defined by the way the tongue moves within the mouth: such as the l-sounds (called \"laterals\", because the air flows along both sides of the tongue), and the r-sounds (called \"rhotics\") that are characterized by how the tongue is positioned relative to the air stream.\n\nBy using these speech organs, humans can produce hundreds of distinct sounds: some appear very often in the world's languages, whereas others are much more common in certain language families, language areas, or even specific to a single language.\n\nWhen described as a system of symbolic communication, language is traditionally seen as consisting of three parts: signs, meanings, and a code connecting signs with their meanings. The study of the process of semiosis, how signs and meanings are combined, used, and interpreted is called semiotics. Signs can be composed of sounds, gestures, letters, or symbols, depending on whether the language is spoken, signed, or written, and they can be combined into complex signs, such as words and phrases. When used in communication, a sign is encoded and transmitted by a sender through a channel to a receiver who decodes it.\nSome of the properties that define human language as opposed to other communication systems are: the arbitrariness of the linguistic sign, meaning that there is no predictable connection between a linguistic sign and its meaning; the duality of the linguistic system, meaning that linguistic structures are built by combining elements into larger structures that can be seen as layered, e.g. how sounds build words and words build phrases; the discreteness of the elements of language, meaning that the elements out of which linguistic signs are constructed are discrete units, e.g. sounds and words, that can be distinguished from each other and rearranged in different patterns; and the productivity of the linguistic system, meaning that the finite number of linguistic elements can be combined into a theoretically infinite number of combinations.\n\nThe rules by which signs can be combined to form words and phrases are called syntax or grammar. The meaning that is connected to individual signs, morphemes, words, phrases, and texts is called semantics. The division of language into separate but connected systems of sign and meaning goes back to the first linguistic studies of de Saussure and is now used in almost all branches of linguistics.\n\nLanguages express meaning by relating a sign form to a meaning, or its content. Sign forms must be something that can be perceived, for example, in sounds, images, or gestures, and then related to a specific meaning by social convention. Because the basic relation of meaning for most linguistic signs is based on social convention, linguistic signs can be considered arbitrary, in the sense that the convention is established socially and historically, rather than by means of a natural relation between a specific sign form and its meaning.\n\nThus, languages must have a vocabulary of signs related to specific meaning. The English sign \"dog\" denotes, for example, a member of the species \"Canis familiaris\". In a language, the array of arbitrary signs connected to specific meanings is called the lexicon, and a single sign connected to a meaning is called a lexeme. Not all meanings in a language are represented by single words. Often, semantic concepts are embedded in the morphology or syntax of the language in the form of grammatical categories.\n\nAll languages contain the semantic structure of predication: a structure that predicates a property, state, or action. Traditionally, semantics has been understood to be the study of how speakers and interpreters assign truth values to statements, so that meaning is understood to be the process by which a predicate can be said to be true or false about an entity, e.g. \"<nowiki>[x [is y]]\" or \"[x [does y]]</nowiki>\". Recently, this model of semantics has been complemented with more dynamic models of meaning that incorporate shared knowledge about the context in which a sign is interpreted into the production of meaning. Such models of meaning are explored in the field of pragmatics.\n\nDepending on modality, language structure can be based on systems of sounds (speech), gestures (sign languages), or graphic or tactile symbols (writing). The ways in which languages use sounds or signs to construct meaning are studied in phonology. The study of how humans produce and perceive vocal sounds is called phonetics. In spoken language, meaning is produced when sounds become part of a system in which some sounds can contribute to expressing meaning and others do not. In any given language, only a limited number of the many distinct sounds that can be created by the human vocal apparatus contribute to constructing meaning.\n\nSounds as part of a linguistic system are called phonemes. Phonemes are abstract units of sound, defined as the smallest units in a language that can serve to distinguish between the meaning of a pair of minimally different words, a so-called minimal pair. In English, for example, the words \"bat\" and \"pat\" form a minimal pair, in which the distinction between and differentiates the two words, which have different meanings. However, each language contrasts sounds in different ways. For example, in a language that does not distinguish between voiced and unvoiced consonants, the sounds and (if they both occur) could be considered a single phoneme, and consequently, the two pronunciations would have the same meaning. Similarly, the English language does not distinguish phonemically between aspirated and non-aspirated pronunciations of consonants, as many other languages like Korean and Hindi do: the unaspirated in \"spin\" and the aspirated in \"pin\" are considered to be merely different ways of pronouncing the same phoneme (such variants of a single phoneme are called allophones), whereas in Mandarin Chinese, the same difference in pronunciation distinguishes between the words 'crouch' and 'eight' (the accent above the á means that the vowel is pronounced with a high tone).\n\nAll spoken languages have phonemes of at least two different categories, vowels and consonants, that can be combined to form syllables. As well as segments such as consonants and vowels, some languages also use sound in other ways to convey meaning. Many languages, for example, use stress, pitch, duration, and tone to distinguish meaning. Because these phenomena operate outside of the level of single segments, they are called suprasegmental. Some languages have only a few phonemes, for example, Rotokas and Pirahã language with 11 and 10 phonemes respectively, whereas languages like Taa may have as many as 141 phonemes. In sign languages, the equivalent to phonemes (formerly called cheremes) are defined by the basic elements of gestures, such as hand shape, orientation, location, and motion, which correspond to manners of articulation in spoken language.\n\nWriting systems represent language using visual symbols, which may or may not correspond to the sounds of spoken language. The Latin alphabet (and those on which it is based or that have been derived from it) was originally based on the representation of single sounds, so that words were constructed from letters that generally denote a single consonant or vowel in the structure of the word. In syllabic scripts, such as the Inuktitut syllabary, each sign represents a whole syllable. In logographic scripts, each sign represents an entire word, and will generally bear no relation to the sound of that word in spoken language.\n\nBecause all languages have a very large number of words, no purely logographic scripts are known to exist. Written language represents the way spoken sounds and words follow one after another by arranging symbols according to a pattern that follows a certain direction. The direction used in a writing system is entirely arbitrary and established by convention. Some writing systems use the horizontal axis (left to right as the Latin script or right to left as the Arabic script), while others such as traditional Chinese writing use the vertical dimension (from top to bottom). A few writing systems use opposite directions for alternating lines, and others, such as the ancient Maya script, can be written in either direction and rely on graphic cues to show the reader the direction of reading.\n\nIn order to represent the sounds of the world's languages in writing, linguists have developed the International Phonetic Alphabet, designed to represent all of the discrete sounds that are known to contribute to meaning in human languages.\n\nGrammar is the study of how meaningful elements called \"morphemes\" within a language can be combined into utterances. Morphemes can either be \"free\" or \"bound\". If they are free to be moved around within an utterance, they are usually called \"words\", and if they are bound to other words or morphemes, they are called affixes. The way in which meaningful elements can be combined within a language is governed by rules. The rules for the internal structure of words are called morphology. The rules of the internal structure of phrases and sentences are called \"syntax\".\n\nGrammar can be described as a system of categories and a set of rules that determine how categories combine to form different aspects of meaning. Languages differ widely in whether they are encoded through the use of categories or lexical units. However, several categories are so common as to be nearly universal. Such universal categories include the encoding of the grammatical relations of participants and predicates by grammatically distinguishing between their relations to a predicate, the encoding of temporal and spatial relations on predicates, and a system of grammatical person governing reference to and distinction between speakers and addressees and those about whom they are speaking.\n\nLanguages organize their parts of speech into classes according to their functions and positions relative to other parts. All languages, for instance, make a basic distinction between a group of words that prototypically denotes things and concepts and a group of words that prototypically denotes actions and events. The first group, which includes English words such as \"dog\" and \"song\", are usually called nouns. The second, which includes \"run\" and \"sing\", are called verbs. Another common category is the adjective: words that describe properties or qualities of nouns, such as \"red\" or \"big\". Word classes can be \"open\" if new words can continuously be added to the class, or relatively \"closed\" if there is a fixed number of words in a class. In English, the class of pronouns is closed, whereas the class of adjectives is open, since an infinite number of adjectives can be constructed from verbs (e.g. \"saddened\") or nouns (e.g. with the -like suffix, as in \"noun-like\"). In other languages such as Korean, the situation is the opposite, and new pronouns can be constructed, whereas the number of adjectives is fixed.\n\nWord classes also carry out differing functions in grammar. Prototypically, verbs are used to construct predicates, while nouns are used as arguments of predicates. In a sentence such as \"Sally runs\", the predicate is \"runs\", because it is the word that predicates a specific state about its argument \"Sally\". Some verbs such as \"curse\" can take two arguments, e.g. \"Sally cursed John\". A predicate that can only take a single argument is called \"intransitive\", while a predicate that can take two arguments is called \"transitive\".\n\nMany other word classes exist in different languages, such as conjunctions like \"and\" that serve to join two sentences, articles that introduce a noun, interjections such as \"wow!\", or ideophones like \"splash\" that mimic the sound of some event. Some languages have positionals that describe the spatial position of an event or entity. Many languages have classifiers that identify countable nouns as belonging to a particular type or having a particular shape. For instance, in Japanese, the general noun classifier for humans is \"nin\" (人), and it is used for counting humans, whatever they are called:\n\nFor trees, it would be:\n\nIn linguistics, the study of the internal structure of complex words and the processes by which words are formed is called morphology. In most languages, it is possible to construct complex words that are built of several morphemes. For instance, the English word \"unexpected\" can be analyzed as being composed of the three morphemes \"un-\", \"expect\" and \"-ed\".\n\nMorphemes can be classified according to whether they are independent morphemes, so-called roots, or whether they can only co-occur attached to other morphemes. These bound morphemes or affixes can be classified according to their position in relation to the root: \"prefixes\" precede the root, suffixes follow the root, and infixes are inserted in the middle of a root. Affixes serve to modify or elaborate the meaning of the root. Some languages change the meaning of words by changing the phonological structure of a word, for example, the English word \"run\", which in the past tense is \"ran\". This process is called \"ablaut\". Furthermore, morphology distinguishes between the process of inflection, which modifies or elaborates on a word, and the process of derivation, which creates a new word from an existing one. In English, the verb \"sing\" has the inflectional forms \"singing\" and \"sung\", which are both verbs, and the derivational form \"singer\", which is a noun derived from the verb with the agentive suffix \"-er\".\n\nLanguages differ widely in how much they rely on morphological processes of word formation. In some languages, for example, Chinese, there are no morphological processes, and all grammatical information is encoded syntactically by forming strings of single words. This type of morpho-syntax is often called isolating, or analytic, because there is almost a full correspondence between a single word and a single aspect of meaning. Most languages have words consisting of several morphemes, but they vary in the degree to which morphemes are discrete units. In many languages, notably in most Indo-European languages, single morphemes may have several distinct meanings that cannot be analyzed into smaller segments. For example, in Latin, the word \"bonus\", or \"good\", consists of the root \"bon-\", meaning \"good\", and the suffix -\"us\", which indicates masculine gender, singular number, and nominative case. These languages are called \"fusional languages\", because several meanings may be fused into a single morpheme. The opposite of fusional languages are agglutinative languages which construct words by stringing morphemes together in chains, but with each morpheme as a discrete semantic unit. An example of such a language is Turkish, where for example, the word \"evlerinizden\", or \"from your houses\", consists of the morphemes, \"ev-ler-iniz-den\" with the meanings \"house-plural-your-from\". The languages that rely on morphology to the greatest extent are traditionally called polysynthetic languages. They may express the equivalent of an entire English sentence in a single word. For example, in Persian the single word \"nafahmidamesh\" means \"I didn't understand it\" consisting of morphemes \"na-fahm-id-am-esh\" with the meanings, \"negation.understand.past.I.it\". As another example with more complexity, in the Yupik word \"tuntussuqatarniksatengqiggtuq\", which means \"He had not yet said again that he was going to hunt reindeer\", the word consists of the morphemes \"tuntu-ssur-qatar-ni-ksaite-ngqiggte-uq\" with the meanings, \"reindeer-hunt-future-say-negation-again-third.person.singular.indicative\", and except for the morpheme \"tuntu\" (\"reindeer\") none of the other morphemes can appear in isolation.\n\nMany languages use morphology to cross-reference words within a sentence. This is sometimes called \"agreement\". For example, in many Indo-European languages, adjectives must cross-reference the noun they modify in terms of number, case, and gender, so that the Latin adjective \"bonus\", or \"good\", is inflected to agree with a noun that is masculine gender, singular number, and nominative case. In many polysynthetic languages, verbs cross-reference their subjects and objects. In these types of languages, a single verb may include information that would require an entire sentence in English. For example, in the Basque phrase \"ikusi nauzu\", or \"you saw me\", the past tense auxiliary verb \"n-au-zu\" (similar to English \"do\") agrees with both the subject (you) expressed by the \"n\"- prefix, and with the object (me) expressed by the – \"zu\" suffix. The sentence could be directly transliterated as \"see you-did-me\"\n\nAnother way in which languages convey meaning is through the order of words within a sentence. The grammatical rules for how to produce new sentences from words that are already known is called syntax. The syntactical rules of a language determine why a sentence in English such as \"I love you\" is meaningful, but \"*love you I\" is not. Syntactical rules determine how word order and sentence structure is constrained, and how those constraints contribute to meaning. For example, in English, the two sentences \"the slaves were cursing the master\" and \"the master was cursing the slaves\" mean different things, because the role of the grammatical subject is encoded by the noun being in front of the verb, and the role of object is encoded by the noun appearing after the verb. Conversely, in Latin, both \"Dominus servos vituperabat\" and \"Servos vituperabat dominus\" mean \"the master was reprimanding the slaves\", because \"servos\", or \"slaves\", is in the accusative case, showing that they are the grammatical object of the sentence, and \"dominus\", or \"master\", is in the nominative case, showing that he is the subject.\n\nLatin uses morphology to express the distinction between subject and object, whereas English uses word order. Another example of how syntactic rules contribute to meaning is the rule of inverse word order in questions, which exists in many languages. This rule explains why when in English, the phrase \"John is talking to Lucy\" is turned into a question, it becomes \"Who is John talking to?\", and not \"John is talking to who?\". The latter example may be used as a way of placing special emphasis on \"who\", thereby slightly altering the meaning of the question. Syntax also includes the rules for how complex sentences are structured by grouping words together in units, called phrases, that can occupy different places in a larger syntactic structure. Sentences can be described as consisting of phrases connected in a tree structure, connecting the phrases to each other at different levels. To the right is a graphic representation of the syntactic analysis of the English sentence \"the cat sat on the mat\". The sentence is analyzed as being constituted by a noun phrase, a verb, and a prepositional phrase; the prepositional phrase is further divided into a preposition and a noun phrase, and the noun phrases consist of an article and a noun.\n\nThe reason sentences can be seen as being composed of phrases is because each phrase would be moved around as a single element if syntactic operations were carried out. For example, \"the cat\" is one phrase, and \"on the mat\" is another, because they would be treated as single units if a decision was made to emphasize the location by moving forward the prepositional phrase: \"[And] on the mat, the cat sat\". There are many different formalist and functionalist frameworks that propose theories for describing syntactic structures, based on different assumptions about what language is and how it should be described. Each of them would analyze a sentence such as this in a different manner.\n\nLanguages can be classified in relation to their grammatical types. Languages that belong to different families nonetheless often have features in common, and these shared features tend to correlate. For example, languages can be classified on the basis of their basic word order, the relative order of the verb, and its constituents in a normal indicative sentence. In English, the basic order is SVO: \"The snake(S) bit(V) the man(O)\", whereas for example, the corresponding sentence in the Australian language Gamilaraay would be \"d̪uyugu n̪ama d̪ayn yiːy\" (snake man bit), SOV. Word order type is relevant as a typological parameter, because basic word order type corresponds with other syntactic parameters, such as the relative order of nouns and adjectives, or of the use of prepositions or postpositions. Such correlations are called implicational universals. For example, most (but not all) languages that are of the SOV type have postpositions rather than prepositions, and have adjectives before nouns.\n\nAll languages structure sentences into Subject, Verb, and Object, but languages differ in the way they classify the relations between actors and actions. English uses the nominative-accusative word typology: in English transitive clauses, the subjects of both intransitive sentences (\"I run\") and transitive sentences (\"I love you\") are treated in the same way, shown here by the nominative pronoun \"I\". Some languages, called ergative, Gamilaraay among them, distinguish instead between Agents and Patients. In ergative languages, the single participant in an intransitive sentence, such as \"I run\", is treated the same as the patient in a transitive sentence, giving the equivalent of \"me run\". Only in transitive sentences would the equivalent of the pronoun \"I\" be used. In this way the semantic roles can map onto the grammatical relations in different ways, grouping an intransitive subject either with Agents (accusative type) or Patients (ergative type) or even making each of the three roles differently, which is called the tripartite type.\n\nThe shared features of languages which belong to the same typological class type may have arisen completely independently. Their co-occurrence might be due to universal laws governing the structure of natural languages, \"language universals\", or they might be the result of languages evolving convergent solutions to the recurring communicative problems that humans use language to solve.\n\nWhile humans have the ability to learn any language, they only do so if they grow up in an environment in which language exists and is used by others. Language is therefore dependent on communities of speakers in which children learn language from their elders and peers and themselves transmit language to their own children. Languages are used by those who speak them to communicate and to solve a plethora of social tasks. Many aspects of language use can be seen to be adapted specifically to these purposes. Due to the way in which language is transmitted between generations and within communities, language perpetually changes, diversifying into new languages or converging due to language contact. The process is similar to the process of evolution, where the process of descent with modification leads to the formation of a phylogenetic tree.\n\nHowever, languages differ from biological organisms in that they readily incorporate elements from other languages through the process of diffusion, as speakers of different languages come into contact. Humans also frequently speak more than one language, acquiring their first language or languages as children, or learning new languages as they grow up. Because of the increased language contact in the globalizing world, many small languages are becoming endangered as their speakers shift to other languages that afford the possibility to participate in larger and more influential speech communities.\n\nThe semantic study of meaning assumes that meaning is in a relation between signs and meanings that are firmly established through social convention. However, semantics does not study the way in which social conventions are made and affect language. Rather, when studying the way in which words and signs are used, it is often the case that words have different meanings, depending on the social context of use. An important example of this is the process called deixis, which describes the way in which certain words refer to entities through their relation between a specific point in time and space when the word is uttered. Such words are, for example, the word, \"I\" (which designates the person speaking), \"now\" (which designates the moment of speaking), and \"here\" (which designates the position of speaking). Signs also change their meanings over time, as the conventions governing their usage gradually change. The study of how the meaning of linguistic expressions changes depending on context is called pragmatics. Deixis is an important part of the way that we use language to point out entities in the world. Pragmatics is concerned with the ways in which language use is patterned and how these patterns contribute to meaning. For example, in all languages, linguistic expressions can be used not just to transmit information, but to perform actions. Certain actions are made only through language, but nonetheless have tangible effects, e.g. the act of \"naming\", which creates a new name for some entity, or the act of \"pronouncing someone man and wife\", which creates a social contract of marriage. These types of acts are called speech acts, although they can also be carried out through writing or hand signing.\n\nThe form of linguistic expression often does not correspond to the meaning that it actually has in a social context. For example, if at a dinner table a person asks, \"Can you reach the salt?\", that is, in fact, not a question about the length of the arms of the one being addressed, but a request to pass the salt across the table. This meaning is implied by the context in which it is spoken; these kinds of effects of meaning are called conversational implicatures. These social rules for which ways of using language are considered appropriate in certain situations and how utterances are to be understood in relation to their context vary between communities, and learning them is a large part of acquiring communicative competence in a language.\n\nAll healthy, normally developing human beings learn to use language. Children acquire the language or languages used around them: whichever languages they receive sufficient exposure to during childhood. The development is essentially the same for children acquiring sign or oral languages. This learning process is referred to as first-language acquisition, since unlike many other kinds of learning, it requires no direct teaching or specialized study. In \"The Descent of Man\", naturalist Charles Darwin called this process \"an instinctive tendency to acquire an art\".\n\nFirst language acquisition proceeds in a fairly regular sequence, though there is a wide degree of variation in the timing of particular stages among normally developing infants. From birth, newborns respond more readily to human speech than to other sounds. Around one month of age, babies appear to be able to distinguish between different speech sounds. Around six months of age, a child will begin babbling, producing the speech sounds or handshapes of the languages used around them. Words appear around the age of 12 to 18 months; the average vocabulary of an eighteen-month-old child is around 50 words. A child's first utterances are holophrases (literally \"whole-sentences\"), utterances that use just one word to communicate some idea. Several months after a child begins producing words, he or she will produce two-word utterances, and within a few more months will begin to produce telegraphic speech, or short sentences that are less grammatically complex than adult speech, but that do show regular syntactic structure. From roughly the age of three to five years, a child's ability to speak or sign is refined to the point that it resembles adult language. Studies published in 2013 have indicated that unborn fetuses are capable of language acquisition to some degree.\n\nAcquisition of second and additional languages can come at any age, through exposure in daily life or courses. Children learning a second language are more likely to achieve native-like fluency than adults, but in general, it is very rare for someone speaking a second language to pass completely for a native speaker. An important difference between first language acquisition and additional language acquisition is that the process of additional language acquisition is influenced by languages that the learner already knows.\n\nLanguages, understood as the particular set of speech norms of a particular community, are also a part of the larger culture of the community that speaks them. Languages differ not only in pronunciation, vocabulary, and grammar, but also through having different \"cultures of speaking.\" Humans use language as a way of signalling identity with one cultural group as well as difference from others. Even among speakers of one language, several different ways of using the language exist, and each is used to signal affiliation with particular subgroups within a larger culture. Linguists and anthropologists, particularly sociolinguists, ethnolinguists, and linguistic anthropologists have specialized in studying how ways of speaking vary between speech communities.\n\nLinguists use the term \"varieties\" to refer to the different ways of speaking a language. This term includes geographically or socioculturally defined dialects as well as the jargons or styles of subcultures. Linguistic anthropologists and sociologists of language define communicative style as the ways that language is used and understood within a particular culture.\n\nBecause norms for language use are shared by members of a specific group, communicative style also becomes a way of displaying and constructing group identity. Linguistic differences may become salient markers of divisions between social groups, for example, speaking a language with a particular accent may imply membership of an ethnic minority or social class, one's area of origin, or status as a second language speaker. These kinds of differences are not part of the linguistic system, but are an important part of how people use language as a social tool for constructing groups.\n\nHowever, many languages also have grammatical conventions that signal the social position of the speaker in relation to others through the use of registers that are related to social hierarchies or divisions. In many languages, there are stylistic or even grammatical differences between the ways men and women speak, between age groups, or between social classes, just as some languages employ different words depending on who is listening. For example, in the Australian language Dyirbal, a married man must use a special set of words to refer to everyday items when speaking in the presence of his mother-in-law. Some cultures, for example, have elaborate systems of \"social deixis\", or systems of signalling social distance through linguistic means. In English, social deixis is shown mostly through distinguishing between addressing some people by first name and others by surname, and in titles such as \"Mrs.\", \"boy\", \"Doctor\", or \"Your Honor\", but in other languages, such systems may be highly complex and codified in the entire grammar and vocabulary of the language. For instance, in languages of east Asia such as Thai, Burmese, and Javanese, different words are used according to whether a speaker is addressing someone of higher or lower rank than oneself in a ranking system with animals and children ranking the lowest and gods and members of royalty as the highest.\n\nThroughout history a number of different ways of representing language in graphic media have been invented. These are called writing systems.\n\nThe use of writing has made language even more useful to humans. It makes it possible to store large amounts of information outside of the human body and retrieve it again, and it allows communication across distances that would otherwise be impossible. Many languages conventionally employ different genres, styles, and registers in written and spoken language, and in some communities, writing traditionally takes place in an entirely different language than the one spoken. There is some evidence that the use of writing also has effects on the cognitive development of humans, perhaps because acquiring literacy generally requires explicit and formal education.\n\nThe invention of the first writing systems is roughly contemporary with the beginning of the Bronze Age in the late 4th millennium BC. The Sumerian archaic cuneiform script and the Egyptian hieroglyphs are generally considered to be the earliest writing systems, both emerging out of their ancestral proto-literate symbol systems from 3400–3200 BC with the earliest coherent texts from about 2600 BC. It is generally agreed that Sumerian writing was an independent invention; however, it is debated whether Egyptian writing was developed completely independently of Sumerian, or was a case of cultural diffusion. A similar debate exists for the Chinese script, which developed around 1200 BC. The pre-Columbian Mesoamerican writing systems (including among others Olmec and Maya scripts) are generally believed to have had independent origins.\n\nAll languages change as speakers adopt or invent new ways of speaking and pass them on to other members of their speech community. Language change happens at all levels from the phonological level to the levels of vocabulary, morphology, syntax, and discourse. Even though language change is often initially evaluated negatively by speakers of the language who often consider changes to be \"decay\" or a sign of slipping norms of language usage, it is natural and inevitable.\n\nChanges may affect specific sounds or the entire phonological system. Sound change can consist of the replacement of one speech sound or phonetic feature by another, the complete loss of the affected sound, or even the introduction of a new sound in a place where there had been none. Sound changes can be \"conditioned\" in which case a sound is changed only if it occurs in the vicinity of certain other sounds. Sound change is usually assumed to be \"regular\", which means that it is expected to apply mechanically whenever its structural conditions are met, irrespective of any non-phonological factors. On the other hand, sound changes can sometimes be \"sporadic\", affecting only one particular word or a few words, without any seeming regularity. Sometimes a simple change triggers a chain shift in which the entire phonological system is affected. This happened in the Germanic languages when the sound change known as Grimm's law affected all the stop consonants in the system. The original consonant * became /b/ in the Germanic languages, the previous * in turn became /p/, and the previous * became /f/. The same process applied to all stop consonants and explains why Italic languages such as Latin have \"p\" in words like pater\" and pisces\", whereas Germanic languages, like English, have father\" and fish\".\n\nAnother example is the Great Vowel Shift in English, which is the reason that the spelling of English vowels do not correspond well to their current pronunciation. This is because the vowel shift brought the already established orthography out of synchronization with pronunciation. Another source of sound change is the erosion of words as pronunciation gradually becomes increasingly indistinct and shortens words, leaving out syllables or sounds. This kind of change caused Latin \"mea domina\" to eventually become the French \"madame\" and American English \"ma'am\".\n\nChange also happens in the grammar of languages as discourse patterns such as idioms or particular constructions become grammaticalized. This frequently happens when words or morphemes erode and the grammatical system is unconsciously rearranged to compensate for the lost element. For example, in some varieties of Caribbean Spanish the final /s/ has eroded away. Since Standard Spanish uses final /s/ in the morpheme marking the second person subject \"you\" in verbs, the Caribbean varieties now have to express the second person using the pronoun \"tú\". This means that the sentence \"what's your name\" is \"¿como te llamas?\" in Standard Spanish, but in Caribbean Spanish. The simple sound change has affected both morphology and syntax. Another common cause of grammatical change is the gradual petrification of idioms into new grammatical forms, for example, the way the English \"going to\" construction lost its aspect of movement and in some varieties of English has almost become a full-fledged future tense (e.g. \"I'm gonna\").\n\nLanguage change may be motivated by \"language internal\" factors, such as changes in pronunciation motivated by certain sounds being difficult to distinguish aurally or to produce, or through patterns of change that cause some rare types of constructions to drift towards more common types. Other causes of language change are social, such as when certain pronunciations become emblematic of membership in certain groups, such as social classes, or with ideologies, and therefore are adopted by those who wish to identify with those groups or ideas. In this way, issues of identity and politics can have profound effects on language structure.\n\nOne important source of language change is contact and resulting diffusion of linguistic traits between languages. Language contact occurs when speakers of two or more languages or varieties interact on a regular basis. Multilingualism is likely to have been the norm throughout human history and most people in the modern world are multilingual. Before the rise of the concept of the ethno-national state, monolingualism was characteristic mainly of populations inhabiting small islands. But with the ideology that made one people, one state, and one language the most desirable political arrangement, monolingualism started to spread throughout the world. Nonetheless, there are only 250 countries in the world corresponding to some 6000 languages, which means that most countries are multilingual and most languages therefore exist in close contact with other languages.\n\nWhen speakers of different languages interact closely, it is typical for their languages to influence each other. Through sustained language contact over long periods, linguistic traits diffuse between languages, and languages belonging to different families may converge to become more similar. In areas where many languages are in close contact, this may lead to the formation of language areas in which unrelated languages share a number of linguistic features. A number of such language areas have been documented, among them, the Balkan language area, the Mesoamerican language area, and the Ethiopian language area. Also, larger areas such as South Asia, Europe, and Southeast Asia have sometimes been considered language areas, because of widespread diffusion of specific areal features.\n\nLanguage contact may also lead to a variety of other linguistic phenomena, including language convergence, borrowing, and relexification (replacement of much of the native vocabulary with that of another language). In situations of extreme and sustained language contact, it may lead to the formation of new mixed languages that cannot be considered to belong to a single language family. One type of mixed language called pidgins occurs when adult speakers of two different languages interact on a regular basis, but in a situation where neither group learns to speak the language of the other group fluently. In such a case, they will often construct a communication form that has traits of both languages, but which has a simplified grammatical and phonological structure. The language comes to contain mostly the grammatical and phonological categories that exist in both languages. Pidgin languages are defined by not having any native speakers, but only being spoken by people who have another language as their first language. But if a Pidgin language becomes the main language of a speech community, then eventually children will grow up learning the pidgin as their first language. As the generation of child learners grow up, the pidgin will often be seen to change its structure and acquire a greater degree of complexity. This type of language is generally called a creole language. An example of such mixed languages is Tok Pisin, the official language of Papua New-Guinea, which originally arose as a Pidgin based on English and Austronesian languages; others are Kreyòl ayisyen, the French-based creole language spoken in Haiti, and Michif, a mixed language of Canada, based on the Native American language Cree and French.\n\n\"SIL Ethnologue\" defines a \"living language\" as \"one that has at least one speaker for whom it is their first language\". The exact number of known living languages varies from 6,000 to 7,000, depending on the precision of one's definition of \"language\", and in particular, on how one defines the distinction between languages and dialects. As of 2016, \"Ethnologue\" cataloged 7,097 living human languages. The \"Ethnologue\" establishes linguistic groups based on studies of mutual intelligibility, and therefore often includes more categories than more conservative classifications. For example, the Danish language that most scholars consider a single language with several dialects is classified as two distinct languages (Danish and Jutish) by the \"Ethnologue\".\n\nAccording to the \"Ethnologue\", 389 languages (nearly 6%) have more than a million speakers. These languages together account for 94% of the world's population, whereas 94% of the world's languages account for the remaining 6% of the global population. To the right is a table of the world's 10 most spoken languages with population estimates from the \"Ethnologue\" (2009 figures).\n\nThere is no clear distinction between a language and a dialect, notwithstanding a famous aphorism attributed to linguist Max Weinreich that \"a language is a dialect with an army and navy\". For example, national boundaries frequently override linguistic difference in determining whether two linguistic varieties are languages or dialects. Hakka, Cantonese and Mandarin are, for example, often classified as \"dialects\" of Chinese, even though they are more different from each other than Swedish is from Norwegian. Before the Yugoslav civil war, Serbo-Croatian was considered a single language with two dialects, but now Croatian and Serbian are considered different languages and employ different writing systems. In other words, the distinction may hinge on political considerations as much as on cultural differences, distinctive writing systems, or degree of mutual intelligibility.\n\nThe world's languages can be grouped into language families consisting of languages that can be shown to have common ancestry. Linguists recognize many hundreds of language families, although some of them can possibly be grouped into larger units as more evidence becomes available and in-depth studies are carried out. At present, there are also dozens of language isolates: languages that cannot be shown to be related to any other languages in the world. Among them are Basque, spoken in Europe, Zuni of New Mexico, Purépecha of Mexico, Ainu of Japan, Burushaski of Pakistan, and many others.\n\nThe language family of the world that has the most speakers is the Indo-European languages, spoken by 46% of the world's population. This family includes major world languages like English, Spanish, Russian, and Hindustani (Hindi/Urdu). The Indo-European family achieved prevalence first during the Eurasian Migration Period (c. 400–800 AD), and subsequently through the European colonial expansion, which brought the Indo-European languages to a politically and often numerically dominant position in the Americas and much of Africa. The Sino-Tibetan languages are spoken by 20% of the world's population and include many of the languages of East Asia, including Hakka, Mandarin Chinese, Cantonese, and hundreds of smaller languages.\n\nAfrica is home to a large number of language families, the largest of which is the Niger-Congo language family, which includes such languages as Swahili, Shona, and Yoruba. Speakers of the Niger-Congo languages account for 6.9% of the world's population. A similar number of people speak the Afroasiatic languages, which include the populous Semitic languages such as Arabic, Hebrew language, and the languages of the Sahara region, such as the Berber languages and Hausa.\n\nThe Austronesian languages are spoken by 5.5% of the world's population and stretch from Madagascar to maritime Southeast Asia all the way to Oceania. It includes such languages as Malagasy, Māori, Samoan, and many of the indigenous languages of Indonesia and Taiwan. The Austronesian languages are considered to have originated in Taiwan around 3000 BC and spread through the Oceanic region through island-hopping, based on an advanced nautical technology. Other populous language families are the Dravidian languages of South Asia (among them Kannada Tamil and Telugu), the Turkic languages of Central Asia (such as Turkish), the Austroasiatic (among them Khmer), and Tai–Kadai languages of Southeast Asia (including Thai).\n\nThe areas of the world in which there is the greatest linguistic diversity, such as the Americas, Papua New Guinea, West Africa, and South-Asia, contain hundreds of small language families. These areas together account for the majority of the world's languages, though not the majority of speakers. In the Americas, some of the largest language families include the Quechumaran, Arawak, and Tupi-Guarani families of South America, the Uto-Aztecan, Oto-Manguean, and Mayan of Mesoamerica, and the Na-Dene, Iroquoian, and Algonquian language families of North America. In Australia, most indigenous languages belong to the Pama-Nyungan family, whereas New Guinea is home to a large number of small families and isolates, as well as a number of Austronesian languages.\n\nLanguage endangerment occurs when a language is at risk of falling out of use as its speakers die out or shift to speaking another language. Language loss occurs when the language has no more native speakers, and becomes a \"dead language\". If eventually no one speaks the language at all, it becomes an \"extinct language\". While languages have always gone extinct throughout human history, they have been disappearing at an accelerated rate in the 20th and 21st centuries due to the processes of globalization and neo-colonialism, where the economically powerful languages dominate other languages.\n\nThe more commonly spoken languages dominate the less commonly spoken languages, so the less commonly spoken languages eventually disappear from populations. The total number of languages in the world is not known. Estimates vary depending on many factors. The consensus is that there are between 6,000 and 7,000 languages spoken as of 2010, and that between 50–90% of those will have become extinct by the year 2100. The top 20 languages, those spoken by more than 50 million speakers each, are spoken by 50% of the world's population, whereas many of the other languages are spoken by small communities, most of them with less than 10,000 speakers.\n\nThe United Nations Educational, Scientific and Cultural Organization (UNESCO) operates with five levels of language endangerment: \"safe\", \"vulnerable\" (not spoken by children outside the home), \"definitely endangered\" (not spoken by children), \"severely endangered\" (only spoken by the oldest generations), and \"critically endangered\" (spoken by few members of the oldest generation, often semi-speakers). Notwithstanding claims that the world would be better off if most adopted a single common \"lingua franca\", such as English or Esperanto, there is a consensus that the loss of languages harms the cultural diversity of the world. It is a common belief, going back to the biblical narrative of the tower of Babel in the Old Testament, that linguistic diversity causes political conflict, but this is contradicted by the fact that many of the world's major episodes of violence have taken place in situations with low linguistic diversity, such as the Yugoslav and American Civil War, or the genocide of Rwanda, whereas many of the most stable political units have been highly multilingual.\n\nMany projects aim to prevent or slow this loss by revitalizing endangered languages and promoting education and literacy in minority languages. Across the world, many countries have enacted specific legislation to protect and stabilize the language of indigenous speech communities. A minority of linguists have argued that language loss is a natural process that should not be counteracted, and that documenting endangered languages for posterity is sufficient.\n\n"}
{"id": "2707199", "url": "https://en.wikipedia.org/wiki?curid=2707199", "title": "Languages of Chad", "text": "Languages of Chad\n\nChad has two official languages, French and Modern Standard Arabic, and over 120 indigenous languages. A vernacular version of Arabic, Chadian Arabic, is the lingua franca. Of the two official languages, French has the most speakers in Chad (though Chadian Arabic has more speakers in Chad than both French and Standard Arabic) . Chad submitted an application to join the Arab League as a member state on 25 March 2014, which is still pending.\n\nChadian Sign Language is actually Nigerian Sign Language, a dialect of American Sign Language; Andrew Foster introduced ASL in the 1960s, and Chadian teachers for the deaf train in Nigeria.\n\n\n\n(\"Ethnologue\" lists 54 Chadic languages in Chad altogether, many of them small.)\n\n\n\n"}
{"id": "4240949", "url": "https://en.wikipedia.org/wiki?curid=4240949", "title": "Manu propria", "text": "Manu propria\n\nIt is also found in several ancient documents in front of or after the writer's signature at the end of the document.\n\nRichly decorated \"manu propria\" signs were frequently used by medieval dignitaries and literates to verify the authenticity of handwritten documents.\n\n\"mppria\" was commonly used in the 18th century. However, it was not only used for Latin documents.\n\n\nLater, official documents were routinely accompanied with this abbreviation, for example declaration of war on Serbia by Emperor Franz Joseph from 1914 ends with \"m.p.\".\n\nOrdinary personal cheques frequently include the abbreviation at the end of the signature line.\n\nSome of the countries that still regularly use \"manu propria\" include:\n\n"}
{"id": "15402122", "url": "https://en.wikipedia.org/wiki?curid=15402122", "title": "Monzombo language", "text": "Monzombo language\n\nMonzombo is a minor Ubangian language of the Congos.\n\nThere are three varieties, Monzombo (Mondjembo), Kpala (Kwala), and Yango, which \"Ethnologue\" lists separately. It is not clear how distinct they are.\n"}
{"id": "51495200", "url": "https://en.wikipedia.org/wiki?curid=51495200", "title": "Prosodic bootstrapping", "text": "Prosodic bootstrapping\n\nProsodic bootstrapping (also known as phonological bootstrapping) in linguistics refers to the hypothesis that learners of a primary language (L1) use prosodic features such as pitch, tempo, rhythm, amplitude, and other auditory aspects from the speech signal as a cue to identify other properties of grammar, such as syntactic structure. Acoustically signaled prosodic units in the stream of speech may provide critical perceptual cues by which infants initially discover syntactic phrases in their language. Although these features by themselves are not enough to help infants learn the entire syntax of their native language, they provide various cues about different grammatical properties of the language, such as identifying the ordering of heads and complements in the language using stress prominence, indicating the location of phrase boundaries, and word boundaries. It is argued that prosody of a language plays an initial role in the acquisition of the first language helping children to uncover the syntax of the language, mainly due to the fact that children are sensitive to prosodic cues at a very young age.\n\nThe argument for prosodic bootstrapping was first introduced by Gleitman and Wanner (1982), who observed that infants might use prosodic cues (particularly acoustic cues) to discover underlying grammatical information about their native language. These cues (e.g intonation contour in a question phrase, lengthening a final segment) could aid infants in dividing the speech input into different lexical units, and furthermore aid in placing these units into syntactic phrases appropriate to the language.\n\nProsodic bootstrapping may also provide an explanation to the problem as to how infants segment continuous input. Just like adult speakers, children are exposed to continuous speech. Hearing continuous speech poses a problem for children learning their native language because pauses in speech do not align with word boundaries. As a result, children have to construct word representations from the speech that they hear.\n\nA study conducted by Christophe et al (1994) showed that infants, aging three-days old, are sensitive to acoustic properties of a language. It was shown that three-day olds are able to discriminate bisyllabic stimuli with the same segments based on whether they were extracted from within a word or across a word boundary. The duration of the word initial consonant and the word final vowel are the cues for the existence of a word boundary, which infants may use to learn about syntactic structure.\n\nAnother main support for the prosodic bootstrapping hypothesis is that the use of prosodic elements to segment parts of speech can occur at a very early age, as early as 3 days, where infants have shown the ability to differentiate languages based on phonological characteristics alone, and the fact that the use of prosodic cues occurs before the use of lexical or syntactic data. This has led to hypothesis of \"bootstrapping from the signal\"/\"prosodic bootstrapping\", which has three main elements: \n\nA phonological phrase boundary indicates how the continuous speech stream is broken up into smaller units, which infants use to pick out and more closely identify individual parts of the sentence. A phonological phrase can contain between four to seven syllables, and can be detected by infants, due to the fact that the edges of the phrases are either strengthened or lengthened. Various studies have been done to test if prosody helps with acquisition of syntax, morphology, and phonology.\n\nAnother acoustic cue that indicates a prosodic boundary is the duration of a pause. These pauses will usually be longer in duration at the edge of a word boundary, when referring to clause boundaries. For example, the two sentences below, while seemingly similar on the surface representation, have different prosodic structure, which correlates to the different syntactic structure (\"...\" = longer duration of pause in speech): \nUsing different durations of pause, the underlying syntactic structure can be better distinguished by the listener.\n\nFor infants who are learning their native language, it is difficult to extract words from speech waves because pronounced words are not separated by silence. There are several proposals for lexical acquisition. The first is that children hear words in isolation: if a new piece goes between two words that are known, the new piece must be a new word. The second proposal is that there are some cues in the speech that give signal to the presence of a word boundary: duration, pitch, energy.\n\nThe fact that speech is presented in a continuous stream without pause only makes the task of acquiring a language more difficult for infants. It has been proposed that prosodic features such as the strength of certain sounds, relative to their location in the word, can be used to break apart and identify fragments within the speech stream, in order to differentiate between potentially ambiguous sentences. In English for example, the final [d] in the word \"bold\" tends to be \"weak\", in that it is not fully released. On the other hand, an initial [d] in a word such as \"dime\" is more clearly released, opposed to its word-final counterpart. This difference in strong v. weak sounds may help to better identify where the sound occurs in the word, whether at the beginning or the end.\n\nStudies have shown that phonological boundaries can be interpreted as word boundaries, which further aids the child in the task of developing a lexicon. For example, Millotte et al (2010) tested 16-month olds, observing how children use phonological phrase boundaries to constrain lexical access. When infants heard a prosodic boundary, they were able to detect the existence of a word boundary. In the experiments authors used the conditioned head-turn procedure which showed that when infants were trained to turn their heads for a bisyllabic word, they responded to sentences that contained this word more often than to those that contained both syllables of this word, but separated by a phonological phrase boundary.\n\nBecause prosodic boundaries will never occur inside of a word, thus infants will not be constrained in how they identify words in the speech signal. For example, children can differentiate between words such as \"dice\" and \"red ice\", even though both are phonologically similar. This is because a prosodic boundary will not appear in the middle of the word *(d][ice) but around the word instead ([dice]).\n\nChildren use phonological phrase boundaries to constrain lexical access. They infer the existence of a word boundary given a prosodic boundary. If two sequences differ in prosody while being made up of identical segments (pay per vs. paper), children treat them as different sequences. Studies that measured cues from prosody to phonological phrases have been done in a variety of languages that differ from each other, providing support that phonological phrases could possibly aid in acquiring lexicon universally.\n\nIn addition to helping to identify lexical items, a key element of prosodic bootstrapping involves using prosodic cues to identify syntactic knowledge about the language. Because prosodic phrase boundaries are correlated to syntactic boundaries, listeners can determine the syntactic category of a word, using only prosodic boundary information. Christophe et al. (2008) demonstrated that adults could use prosodic phrases to determine the syntactic category of ambiguous words. Listeners were provided two sentences with an ambiguous word [mɔʀ], which could either belong to a verb category (\"mord\", translated as \"it bites\") or a noun category (\"mort\", translated as the adjective \"dead\").\nThe table above depicts the two sentences heard by French-speaking adults in Christophe et al. (2008), where the emboldened word is the phonetically ambiguous word, and the brackets represent phonological phrase boundaries. Using the position of the prosodic boundaries, adults were able to determine which category the ambiguous word [mɔʀ] belonged to, since the word is assigned to a different phonological phrase, depending on its syntactic category and semantic meaning in the sentence.\n\nAn important tool for acquiring syntax is the use of function words (e.g. articles, verb morphemes, prepositions) to point out syntactic constituent boundaries. These function words frequently occur in language, and generally appear at the borders of prosodic units. Because of their high frequency in the input, and the fact that they tend to have only one to two syllables, infants are able to pick out these function words when they occur at the edges of a prosodic unit. In turn, the function words can help learners determine the syntactic category of the neighboring words (e.g., learning that the word \"the\" [ðə] introduces a noun phrase, and that suffixes such as \"-ed\" require a verb to precede it). For example, in the sentence \"The turtle is eating a pigeon\", through the use of function words such as \"the\" and the auxiliary verb \"is\", children can get better sense as to where prosodic boundaries fall, resulting in a division such as [The turtle][is eating][a pigeon], where brackets indicate a boundary. As a result, infants tend to look out for these words to better identify the beginnings and ends of the prosodic units. Noun articles like \"the\" or \"a\", in English for example, can only be followed by noun, since they are the only words that can fit this category; one would never hear a sentence such as \"The *destroy was widespread\". Likewise, the use of verb morphemes (e.g past tense \"-ed\" [d]/[t], continuous \"-ing\" [iŋ], auxiliary \"is\" [ɪz]) indicate that a verb must precede it, and indicate that no other word can fill the category besides a verb (e.g. *\"I saw that he *happyed yesterday\").\n\nIn a study by Carvalho et al (2016), experimenters tested preschool children, where they showed that by the age of 4 prosody is used in real time to determine what kind of syntactic structure sentences could have. The children in the experiments were able to determine the target word as a noun when it was in a sentence with a prosodic structure typical for a noun and as a verb when it was in a sentence with a prosodic structure typical for a verb. Children by the age of 4 use phrasal prosody to determine the syntactic structure of different sentences.\n\nRhythm is an important aspect of prosody in terms of syllable timing and emphasis, and varies from language to language. Languages are grouped into different categories based on their rhythm, primarily in stress based, rhythm (syllable) based, and mora based categories. Infants around 6 months of age have shown to be able to differentiate between different languages solely on the basis of these particular stress differences. More specifically, infants by 2 months of age can from vague categories of different rhythmic structures, those that are native classes, and those that are nonnative. Before reaching 2 months, infants can distinguish between languages of any class, but by the age of 2 months can only put languages in the native or nonnative class. For example, English speaking infants will have a hard time differentiating between English and Dutch (since both are stress based languages), but will be able to distinguish Russian (a stress based language) and Japanese (a mora based language). By 2 months however, an English speaking baby will group syllable-timed and mora-timed languages into one \"nonnative\" group, and thus will have a hard time differentiating languages such as French (syllable-timed) and Japanese (mora-timed). This stress variance is also a useful tool for bilingual infants, and acts as a strong indicator when differentiating between different languages being learned.\n\nThe question of whether the head direction parameter can be detected using prosodic cues has been tested with French babies listening to Turkish sentences, in order to determine whether or not 6 to 12 weeks old babies are sensitive to prosodic prominence in speech. Setting the head direction parameter allows infants to acquire a hierarchal branching structure for a particular language, which determines whether the language is left-headed (right-branching) or right-headed (left-branching). This particular experiment (Christophe et al. 2003) had 6- to 12-week-old babies listening to modified \"nonsense\" (the modified French and modified Turkish sentences in the table below) sentences that were neither French nor Turkish, but only differed in the fact that the Turkish based sentences were head final and French based sentenced were head initial. The reasoning behind this is that infants might be able detect prominence within these phonological phrases, as prominence has been shown to follow a systematic pattern with languages; head-initial languages have prominence on the right (French), while head-final languages have prominence on the left (Turkish).\n\nThese nonsense sentences were created in order to eliminate any non-prosodic interference (e.g phonological differences, different number of syllables, etc.) thus babies would only be able to differentiate between the two languages based on the prominence of prosodic cues in the sentences. \nThe table above depicts the sentences heard by the French babies (translated as \"The large orangoutang was nervous\"), where the bolded and enlarged letter indicates word stress and prominence (Christophe et al. 2003). As predicted, French babies tended to prefer the modified nonsense French phrases, based solely on prosodic prominence, given by the location of the head direction parameter.\n\nJusczyk et al (1992) tested 9 month-olds, where they showed that infants are sensitive to acoustic correlates of main phrasal units that are present in the prosody of English sentences. The prosodic markers in the input are longer durations of the syllable that precedes a main phrasal boundary and declinations in fundamental frequency.\n\nSeveral language models have been used to show that in a computational simulation, prosody can help children acquire syntax.\n\nIn one study, Gutman et al (2015) build a computational model that used prosodic structure and function words to jointly determine the syntactic categories of words. The model assigned syntactic labels to prosodic phrases with success, using phrasal prosody to determine the boundaries of phrases, and function words at the edges for classification. The study presented the model of how early syntax acquisition is possible with the help of prosody: children access phrasal prosody and pay attention to words placed at the edges of prosodic boundaries. The idea behind the computational implementation is that prosodic boundaries signal syntactic boundaries and function words that are used to label the prosodic phrases. As an example, a sentence \"She's eating a cherry\" has a prosodic structure such as [She's eating] [a cherry] where the skeleton of a syntactic structure is [VN NP] (VN is for verbal nucleus where a phrase contains a verb and adjacent words such as auxiliaries and subject pronouns). Here, children may utilize their knowledge of function words and prosodic boundaries in order to create an approximation of syntactic structure.\n\nIn a study by Pate et al (2011), where a computational language model was presented, it was shown that acoustic cues can be helpful for determining syntactic structure when they are used with lexical information. Combining acoustic cues with lexical cues may usefully provide children with initial information about the place of syntactic phrases which supports the prosodic bootstrapping hypothesis.\n\nA key criticism of the bootstrapping theory in general is that these mechanisms (whether they be syntactic, semantic, or prosodic) serve mainly as a starting point for learning the language. That is, the bootstrapping mechanisms are only useful up to a certain point in linguistic development for infants, and thus there might be some other mechanism that might be used later on, since the bootstrapping mechanisms primarily use information that is not controlled for \"cross-linguistic variation\" (information that varies from language to language).\n\nRegarding prosodic bootstrapping in particular, there is speculation on how accurately prosodic phrases map to syntactic structure. That is, phrases with identical syntactic structure can have different possible prosodic structures. In the sentence \"The cat chased the rat that ate the cheese.\", the prosodic structure would resemble:\n\n[The cat] [chased the rat] [that ate the cheese]\n\nHowever, the prosodic unit [chased the rat] in this case is not a syntactic constituent, demonstrating that not every prosodic unit is a syntactic unit. Rather, one can observe that a language may not always provide one-to-one mapping from prosodic information to linguistic units. Prosody does not give children direct and systematic information from prosodic structure to linguistic structure.\n\nJusczyk (1997) argued that most people who accept this theory assume that children are drawing on \"a range of information available in the speech signal that extends beyond prosody\", further explaining that relying on prosodic information alone is not enough to learn the structure of the language.\n\n"}
{"id": "17729828", "url": "https://en.wikipedia.org/wiki?curid=17729828", "title": "Terminology (disambiguation)", "text": "Terminology (disambiguation)\n\nTerminology is the study of terms and their use.\n\nTerminology may also refer to:\n\n\n"}
{"id": "1422131", "url": "https://en.wikipedia.org/wiki?curid=1422131", "title": "Šatrovački", "text": "Šatrovački\n\nŠatrovački (; Serbian Cyrillic: шатровачки) or šatra (; Serbian Cyrillic: шатра) is an argot in the Serbo-Croatian language. Šatrovački was initially developed by various subcultures in Yugoslavia and used a form of secret communication within various ingroups. Today, it is primarily used among youth as a form of pig latin. It is more widespread in urban areas, such as capitals Belgrade (Serbia), Zagreb (Croatia) and Sarajevo (Bosnia and Herzegovina).\n\nWords are formed by replacing the syllable order. For example: pivo\" (beer), becomes \"vopi. The new word has the same meaning as the stem. Since the spelling is nearly phonetic it does not change. However, sometimes one of the vowels is changed to make the new word easier to pronounce, avoid ambiguity, or if the stem word is not in nominative. For example, \"trava\" (\"grass\", marijuana) would become \"vutra\" instead of \"vatra\" (\"fire\").\n\nSome words are more commonly spoken in Šatrovački than others, but there is no specific rule. Examples of transformed sentences (although, most of the words in a single sentence are rarely transformed) are:\n\n\n\nUtrovački (Утровачки) is a more complex form of \"šatrovački\". Words are formed using: U + last part + ZA + first part + NJE. E.g. vikipedija (Wikipedia) becomes ukipedijazavinje. Today, utrovački is not widely used.\n\nAlternative Utrovački is same as above, but without \"ZA\", e.g. pivo (beer) becomes uvopinje, or cigare (tobacco) becomes ugarecinje.\n\nA more simplified version of šatrovački is using only parts of the word, while excluding the first syllable, and is most commonly used among young people in Serbia. For example, koncert (concert) would be shorthened to cert. The rules of creating a new word that can be used in nominative while the stem is not apply similarly to standard šatrovački. An example of a full sentence would be:\n\nThis is particularly characteristic of Novi Sad youth subculture, and is very rarely spoken outside of Vojvodina.\n\n\nA very rare but present form of expression found in the Belgrade projects (blokovi). Words are reconstructed by adding various suffixes so that the original word remains relatively intact. Usually, the basis is šatrovački. The resulting words have a generally diminutive meaning.\n\n\nThese diminutives can later be combined using the Šatrovački method, resulting in words like \"kajblo\", or \"kićblo\". However, this is a rare usage, confined to the area of Zemun and New Belgrade.\n\nAlso there is another type of šatrovački, where the words are reconstructed by addition of letter P after each syllable:\n\n\n\n"}
