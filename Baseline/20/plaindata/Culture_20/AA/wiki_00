{"id": "2511603", "url": "https://en.wikipedia.org/wiki?curid=2511603", "title": "American-Born Confused Desi", "text": "American-Born Confused Desi\n\n\"American-Born Confused Desi\" (\"ABCD\") is a term used to refer to Indian Americans born or raised in the United States, in contrast to those who were born overseas and later settled in the USA.\n\n\"ABCD\" or \"American-Born Confused Desi\" has become a polarizing factor in the Indian and other South Asian diaspora in the US, with first-generation immigrant parents and young South Asians of second or later generations. Though the term was originally coined in reference to Indian-Americans, it has been adopted by the South Asian community at large. The term \"desi\" comes from the word \"des\" (homeland) in Hindi. The word has its origin in Sanskrit \"desh\". It's pronounced as \"desh\" in Bengali language (Bangla) too. \"Desi\" means \"of the homeland\" and denotes anything or anyone from South Asia. The term has been commonly known since at least the 1980s. The term \"confused\" is used to describe the psychological state of many second-generation South Asian Americans who struggle to balance values and traditions taught at home with attitudes and practices that are more conducive to the majority white culture.\n\nThe longer and lesser known form \"American Born Confused Desi, Emigrated From Gujarat, House In Jersey\" is also occasionally seen; playing on the alphabet theme, it has been expanded for K-Z variously as \"Kids Learning Medicine, Now Owning Property, Quite Reasonable Salary, Two Uncles Visiting, White Xenophobia, Yet Zestful\" or \"Keeping Lotsa Motels, Named Omkarnath Patel, Quickly Reaching Success Through Underhanded Vicious Ways, Xenophobic Yet Zestful\". The former version of the A—Z expansion was proposed by South Asian immigrants as a reaction to the latter version that derogated them.\n\n\"Confused Americanized Desi (CAD)\" is a related term, which refers to people of South Asian origin who are both born and living in the subcontinent but tend to follow western lifestyle and values.\nCoconuts is also a term used which basically refers to people who are \"white from the inside and brown from the outside\".\n\nAmong South Asian Americans, the term may be considered divisive, as first generation South Asian Americans use it to criticize the Americanization and lack of belonging to either Indian Asian or American culture they perceive in their second-generation peers or children. Writer Vijay Prashad describes the term as \"ponderous and overused\" and notes it as one of the mechanisms by which new immigrants attempt to make second-generation youth feel \"culturally inadequate and unfinished.\".\n\nThe term American-Born Confused Desi first appeared in the movie \"American Desi\" (2001).\"\" is a 2013 Malayalam language movie released in India.The film narrates the journey of two young American Malayalees to their motherland, Kerala, with the title based on the term \"American-Born Confused Desi\".\n\n\n"}
{"id": "752", "url": "https://en.wikipedia.org/wiki?curid=752", "title": "Art", "text": "Art\n\nArt is a diverse range of human activities in creating visual, auditory or performing artifacts (artworks), expressing the author's imaginative, conceptual idea, or technical skill, intended to be appreciated for their beauty or emotional power. In their most general form these activities include the production of works of art, the criticism of art, the study of the history of art, and the aesthetic dissemination of art. \n\nThe three classical branches of art are painting, sculpture and architecture. Music, theatre, film, dance, and other performing arts, as well as literature and other media such as interactive media, are included in a broader definition of the arts. Until the 17th century, \"art\" referred to any skill or mastery and was not differentiated from crafts or sciences. In modern usage after the 17th century, where aesthetic considerations are paramount, the fine arts are separated and distinguished from acquired skills in general, such as the decorative or applied arts.\n\nThough the definition of what constitutes art is disputed and has changed over time, general descriptions mention an idea of imaginative or technical skill stemming from human agency and creation. The nature of art and related concepts, such as creativity and interpretation, are explored in a branch of philosophy known as aesthetics.\n\nIn the perspective of the history of art, artistic works have existed for almost as long as humankind: from early pre-historic art to contemporary art; however, some theories restrict the concept of \"artistic works\" to modern Western societies. One early sense of the definition of \"art\" is closely related to the older Latin meaning, which roughly translates to \"skill\" or \"craft,\" as associated with words such as \"artisan.\" English words derived from this meaning include \"artifact\", \"artificial\", \"artifice\", \"medical arts\", and \"military arts\". However, there are many other colloquial uses of the word, all with some relation to its etymology.\nOver time, philosophers like Plato, Aristotle, Socrates and Kant, among others, questioned the meaning of art. Several dialogues in Plato tackle questions about art: Socrates says that poetry is inspired by the muses, and is not rational. He speaks approvingly of this, and other forms of divine madness (drunkenness, eroticism, and dreaming) in the \"Phaedrus \"(265a–c), and yet in the \"\"Republic\"\" wants to outlaw Homer's great poetic art, and laughter as well. In \"Ion\", Socrates gives no hint of the disapproval of Homer that he expresses in the \"Republic\". The dialogue \"Ion\" suggests that Homer's \"Iliad\" functioned in the ancient Greek world as the Bible does today in the modern Christian world: as divinely inspired literary art that can provide moral guidance, if only it can be properly interpreted.\n\nWith regards to the literary art and the musical arts, Aristotle considered epic poetry, tragedy, comedy, dithyrambic poetry and music to be mimetic or imitative art, each varying in imitation by medium, object, and manner. For example, music imitates with the media of rhythm and harmony, whereas dance imitates with rhythm alone, and poetry with language. The forms also differ in their object of imitation. Comedy, for instance, is a dramatic imitation of men worse than average; whereas tragedy imitates men slightly better than average. Lastly, the forms differ in their manner of imitation—through narrative or character, through change or no change, and through drama or no drama. Aristotle believed that imitation is natural to mankind and constitutes one of mankind's advantages over animals.\n\nThe second, and more recent, sense of the word \"art\" as an abbreviation for \"creative art\" or \"fine art\" emerged in the early 17th century. Fine art refers to a skill used to express the artist's creativity, or to engage the audience's aesthetic sensibilities, or to draw the audience towards consideration of more refined or \"finer\" work of art.\n\nWithin this latter sense, the word \"art\" may refer to several things: (i) a study of a creative skill, (ii) a process of using the creative skill, (iii) a product of the creative skill, or (iv) the audience's experience with the creative skill. The creative arts (\"art\" as discipline) are a collection of disciplines which produce \"artworks\" (\"art\" as objects) that are compelled by a personal drive (art as activity) and convey a message, mood, or symbolism for the perceiver to interpret (art as experience). Art is something that stimulates an individual's thoughts, emotions, beliefs, or ideas through the senses. Works of art can be explicitly made for this purpose or interpreted on the basis of images or objects. For some scholars, such as Kant, the sciences and the arts could be distinguished by taking science as representing the domain of knowledge and the arts as representing the domain of the freedom of artistic expression.\n\nOften, if the skill is being used in a common or practical way, people will consider it a craft instead of art. Likewise, if the skill is being used in a commercial or industrial way, it may be considered commercial art instead of fine art. On the other hand, crafts and design are sometimes considered applied art. Some art followers have argued that the difference between fine art and applied art has more to do with value judgments made about the art than any clear definitional difference. However, even fine art often has goals beyond pure creativity and self-expression. The purpose of works of art may be to communicate ideas, such as in politically, spiritually, or philosophically motivated art; to create a sense of beauty (see aesthetics); to explore the nature of perception; for pleasure; or to generate strong emotions. The purpose may also be seemingly nonexistent.\n\nThe nature of art has been described by philosopher Richard Wollheim as \"one of the most elusive of the traditional problems of human culture\". Art has been defined as a vehicle for the expression or communication of emotions and ideas, a means for exploring and appreciating formal elements for their own sake, and as \"mimesis\" or representation. Art as mimesis has deep roots in the philosophy of Aristotle. Leo Tolstoy identified art as a use of indirect means to communicate from one person to another. Benedetto Croce and R.G. Collingwood advanced the idealist view that art expresses emotions, and that the work of art therefore essentially exists in the mind of the creator. The theory of art as form has its roots in the philosophy of Kant, and was developed in the early twentieth century by Roger Fry and Clive Bell. More recently, thinkers influenced by Martin Heidegger have interpreted art as the means by which a community develops for itself a medium for self-expression and interpretation. George Dickie has offered an institutional theory of art that defines a work of art as any artifact upon which a qualified person or persons acting on behalf of the social institution commonly referred to as \"the art world\" has conferred \"the status of candidate for appreciation\". Larry Shiner has described fine art as \"not an essence or a fate but something we have made. Art as we have generally understood it is a European invention barely two hundred years old.\"\n\nArt may be characterized in terms of mimesis (its representation of reality), narrative (storytelling), expression, communication of emotion, or other qualities. During the Romantic period, art came to be seen as \"a special faculty of the human mind to be classified with religion and science\".\n\nThe oldest documented forms of art are visual arts, which include creation of images or objects in fields including today painting, sculpture, printmaking, photography, and other visual media. Sculptures, cave paintings, rock paintings and petroglyphs from the Upper Paleolithic dating to roughly 40,000 years ago have been found, but the precise meaning of such art is often disputed because so little is known about the cultures that produced them. The oldest art objects in the world—a series of tiny, drilled snail shells about 75,000 years old—were discovered in a South African cave. Containers that may have been used to hold paints have been found dating as far back as 100,000 years. Etched shells by \"Homo erectus\" from 430,000 and 540,000 years ago were discovered in 2014.\n\nMany great traditions in art have a foundation in the art of one of the great ancient civilizations: Ancient Egypt, Mesopotamia, Persia, India, China, Ancient Greece, Rome, as well as Inca, Maya, and Olmec. Each of these centers of early civilization developed a unique and characteristic style in its art. Because of the size and duration of these civilizations, more of their art works have survived and more of their influence has been transmitted to other cultures and later times. Some also have provided the first records of how artists worked. For example, this period of Greek art saw a veneration of the human physical form and the development of equivalent skills to show musculature, poise, beauty, and anatomically correct proportions.\n\nIn Byzantine and Medieval art of the Western Middle Ages, much art focused on the expression of subjects about Biblical and religious culture, and used styles that showed the higher glory of a heavenly world, such as the use of gold in the background of paintings, or glass in mosaics or windows, which also presented figures in idealized, patterned (flat) forms. Nevertheless, a classical realist tradition persisted in small Byzantine works, and realism steadily grew in the art of Catholic Europe.\n\nRenaissance art had a greatly increased emphasis on the realistic depiction of the material world, and the place of humans in it, reflected in the corporeality of the human body, and development of a systematic method of graphical perspective to depict recession in a three-dimensional picture space.\n\nIn the east, Islamic art's rejection of iconography led to emphasis on geometric patterns, calligraphy, and architecture. Further east, religion dominated artistic styles and forms too. India and Tibet saw emphasis on painted sculptures and dance, while religious painting borrowed many conventions from sculpture and tended to bright contrasting colors with emphasis on outlines. China saw the flourishing of many art forms: jade carving, bronzework, pottery (including the stunning terracotta army of Emperor Qin), poetry, calligraphy, music, painting, drama, fiction, etc. Chinese styles vary greatly from era to era and each one is traditionally named after the ruling dynasty. So, for example, Tang dynasty paintings are monochromatic and sparse, emphasizing idealized landscapes, but Ming dynasty paintings are busy and colorful, and focus on telling stories via setting and composition. Japan names its styles after imperial dynasties too, and also saw much interplay between the styles of calligraphy and painting. Woodblock printing became important in Japan after the 17th century.\n\nThe western Age of Enlightenment in the 18th century saw artistic depictions of physical and rational certainties of the clockwork universe, as well as politically revolutionary visions of a post-monarchist world, such as Blake's portrayal of Newton as a divine geometer, or David's propagandistic paintings. This led to Romantic rejections of this in favor of pictures of the emotional side and individuality of humans, exemplified in the novels of Goethe. The late 19th century then saw a host of artistic movements, such as academic art, Symbolism, impressionism and fauvism among others.\n\nThe history of twentieth-century art is a narrative of endless possibilities and the search for new standards, each being torn down in succession by the next. Thus the parameters of impressionism, Expressionism, Fauvism, Cubism, Dadaism, Surrealism, etc. cannot be maintained very much beyond the time of their invention. Increasing global interaction during this time saw an equivalent influence of other cultures into Western art. Thus, Japanese woodblock prints (themselves influenced by Western Renaissance draftsmanship) had an immense influence on impressionism and subsequent development. Later, African sculptures were taken up by Picasso and to some extent by Matisse. Similarly, in the 19th and 20th centuries the West has had huge impacts on Eastern art with originally western ideas like Communism and Post-Modernism exerting a powerful influence.\n\nModernism, the idealistic search for truth, gave way in the latter half of the 20th century to a realization of its unattainability. Theodor W. Adorno said in 1970, \"It is now taken for granted that nothing which concerns art can be taken for granted any more: neither art itself, nor art in relationship to the whole, nor even the right of art to exist.\" Relativism was accepted as an unavoidable truth, which led to the period of contemporary art and postmodern criticism, where cultures of the world and of history are seen as changing forms, which can be appreciated and drawn from only with skepticism and irony. Furthermore, the separation of cultures is increasingly blurred and some argue it is now more appropriate to think in terms of a global culture, rather than of regional ones.\n\nIn \"The Origin of the Work of Art\", Martin Heidegger, a German philosopher and a seminal thinker, describes the essence of art in terms of the concepts of being and truth. He argues that art is not only a way of expressing the element of truth in a culture, but the means of creating it and providing a springboard from which \"that which is\" can be revealed. Works of art are not merely representations of the way things are, but actually produce a community's shared understanding. Each time a new artwork is added to any culture, the meaning of what it is to exist is inherently changed.\n\nThe creative arts are often divided into more specific categories, typically along perceptually distinguishable categories such as media, genre, styles, and form. Art form refers to the elements of art that are independent of its interpretation or significance. It covers the methods adopted by the artist and the physical composition of the artwork, primarily non-semantic aspects of the work (i.e., figurae), such as color, contour, dimension, medium, melody, space, texture, and value. Form may also include visual design principles, such as arrangement, balance, contrast, emphasis, harmony, proportion, proximity, and rhythm.\n\nIn general there are three schools of philosophy regarding art, focusing respectively on form, content, and context. Extreme Formalism is the view that all aesthetic properties of art are formal (that is, part of the art form). Philosophers almost universally reject this view and hold that the properties and aesthetics of art extend beyond materials, techniques, and form. Unfortunately, there is little consensus on terminology for these informal properties. Some authors refer to subject matter and content – i.e., denotations and connotations – while others prefer terms like meaning and significance.\n\nExtreme Intentionalism holds that authorial intent plays a decisive role in the meaning of a work of art, conveying the content or essential main idea, while all other interpretations can be discarded. It defines the subject as the persons or idea represented, and the content as the artist's experience of that subject. For example, the composition of Napoleon I on his Imperial Throne is partly borrowed from the Statue of Zeus at Olympia. As evidenced by the title, the subject is Napoleon, and the content is Ingres's representation of Napoleon as \"Emperor-God beyond time and space\". Similarly to extreme formalism, philosophers typically reject extreme intentionalism, because art may have multiple ambiguous meanings and authorial intent may be unknowable and thus irrelevant. Its restrictive interpretation is \"socially unhealthy, philosophically unreal, and politically unwise\".\n\nFinally, the developing theory of post-structuralism studies art's significance in a cultural context, such as the ideas, emotions, and reactions prompted by a work. The cultural context often reduces to the artist's techniques and intentions, in which case analysis proceeds along lines similar to formalism and intentionalism. However, in other cases historical and material conditions may predominate, such as religious and philosophical convictions, sociopolitical and economic structures, or even climate and geography. Art criticism continues to grow and develop alongside art.\n\nArt can connote a sense of trained ability or mastery of a medium. Art can also simply refer to the developed and efficient use of a language to convey meaning with immediacy and or depth. Art can be defined as an act of expressing feelings, thoughts, and observations.\n\nThere is an understanding that is reached with the material as a result of handling it, which facilitates one's thought processes.\nA common view is that the \"art\", particular in its elevated sense, requires a certain level of creative expertise by the artist, whether this be a demonstration of technical ability, an originality in stylistic approach, or a combination of these two. Traditionally skill of execution was viewed as a quality inseparable from art and thus necessary for its success; for Leonardo da Vinci, art, neither more nor less than his other endeavors, was a manifestation of skill. Rembrandt's work, now praised for its ephemeral virtues, was most admired by his contemporaries for its virtuosity. At the turn of the 20th century, the adroit performances of John Singer Sargent were alternately admired and viewed with skepticism for their manual fluency, yet at nearly the same time the artist who would become the era's most recognized and peripatetic iconoclast, Pablo Picasso, was completing a traditional academic training at which he excelled.\nA common contemporary criticism of some modern art occurs along the lines of objecting to the apparent lack of skill or ability required in the production of the artistic object. In conceptual art, Marcel Duchamp's \"Fountain\" is among the first examples of pieces wherein the artist used found objects (\"ready-made\") and exercised no traditionally recognised set of skills. Tracey Emin's \"My Bed\", or Damien Hirst's \"The Physical Impossibility of Death in the Mind of Someone Living\" follow this example and also manipulate the mass media. Emin slept (and engaged in other activities) in her bed before placing the result in a gallery as work of art. Hirst came up with the conceptual design for the artwork but has left most of the eventual creation of many works to employed artisans. Hirst's celebrity is founded entirely on his ability to produce shocking concepts. The actual production in many conceptual and contemporary works of art is a matter of assembly of found objects. However, there are many modernist and contemporary artists who continue to excel in the skills of drawing and painting and in creating \"hands-on\" works of art.\n\nArt has had a great number of different functions throughout its history, making its purpose difficult to abstract or quantify to any single concept. This does not imply that the purpose of Art is \"vague\", but that it has had many unique, different reasons for being created. Some of these functions of Art are provided in the following outline. The different purposes of art may be grouped according to those that are non-motivated, and those that are motivated (Lévi-Strauss).\n\nThe non-motivated purposes of art are those that are integral to being human, transcend the individual, or do not fulfill a specific external purpose. In this sense, Art, as creativity, is something humans must do by their very nature (i.e., no other species creates art), and is therefore beyond utility.\nMotivated purposes of art refer to intentional, conscious actions on the part of the artists or creator. These may be to bring about political change, to comment on an aspect of society, to convey a specific emotion or mood, to address personal psychology, to illustrate another discipline, to (with commercial arts) sell a product, or simply as a form of communication.\n\nThe functions of art described above are not mutually exclusive, as many of them may overlap. For example, art for the purpose of entertainment may also seek to sell a product, i.e. the movie or video game.\n\nSince ancient times, much of the finest art has represented a deliberate display of wealth or power, often achieved by using massive scale and expensive materials. Much art has been commissioned by political rulers or religious establishments, with more modest versions only available to the most wealthy in society.\n\nNevertheless, there have been many periods where art of very high quality was available, in terms of ownership, across large parts of society, above all in cheap media such as pottery, which persists in the ground, and perishable media such as textiles and wood. In many different cultures, the ceramics of indigenous peoples of the Americas are found in such a wide range of graves that they were clearly not restricted to a social elite, though other forms of art may have been. Reproductive methods such as moulds made mass-production easier, and were used to bring high-quality Ancient Roman pottery and Greek Tanagra figurines to a very wide market. Cylinder seals were both artistic and practical, and very widely used by what can be loosely called the middle class in the Ancient Near East. Once coins were widely used, these also became an art form that reached the widest range of society.\n\nAnother important innovation came in the 15th century in Europe, when printmaking began with small woodcuts, mostly religious, that were often very small and hand-colored, and affordable even by peasants who glued them to the walls of their homes. Printed books were initially very expensive, but fell steadily in price until by the 19th century even the poorest could afford some with printed illustrations. Popular prints of many different sorts have decorated homes and other places for centuries.\n\nPublic buildings and monuments, secular and religious, by their nature normally address the whole of society, and visitors as viewers, and display to the general public has long been an important factor in their design. Egyptian temples are typical in that the most largest and most lavish decoration was placed on the parts that could be seen by the general public, rather than the areas seen only by the priests. Many areas of royal palaces, castles and the houses of the social elite were often generally accessible, and large parts of the art collections of such people could often be seen, either by anybody, or by those able to pay a small price, or those wearing the correct clothes, regardless of who they were, as at the Palace of Versailles, where the appropriate extra accessories (silver shoe buckles and a sword) could be hired from shops outside.\n\nSpecial arrangements were made to allow the public to see many royal or private collections placed in galleries, as with the Orleans Collection mostly housed in a wing of the Palais Royal in Paris, which could be visited for most of the 18th century. In Italy the art tourism of the Grand Tour became a major industry from the Renaissance onwards, and governments and cities made efforts to make their key works accessible. The British Royal Collection remains distinct, but large donations such as the Old Royal Library were made from it to the British Museum, established in 1753. The Uffizi in Florence opened entirely as a gallery in 1765, though this function had been gradually taking the building over from the original civil servants' offices for a long time before. The building now occupied by the Prado in Madrid was built before the French Revolution for the public display of parts of the royal art collection, and similar royal galleries open to the public existed in Vienna, Munich and other capitals. The opening of the Musée du Louvre during the French Revolution (in 1793) as a public museum for much of the former French royal collection certainly marked an important stage in the development of public access to art, transferring ownership to a republican state, but was a continuation of trends already well established.\n\nMost modern public museums and art education programs for children in schools can be traced back to this impulse to have art available to everyone. Museums in the United States tend to be gifts from the very rich to the masses. (The Metropolitan Museum of Art in New York City, for example, was created by John Taylor Johnston, a railroad executive whose personal art collection seeded the museum.) But despite all this, at least one of the important functions of art in the 21st century remains as a marker of wealth and social status.\n\nThere have been attempts by artists to create art that can not be bought by the wealthy as a status object. One of the prime original motivators of much of the art of the late 1960s and 1970s was to create art that could not be bought and sold. It is \"necessary to present something more than mere objects\" said the major post war German artist Joseph Beuys. This time period saw the rise of such things as performance art, video art, and conceptual art. The idea was that if the artwork was a performance that would leave nothing behind, or was simply an idea, it could not be bought and sold. \"Democratic precepts revolving around the idea that a work of art is a commodity impelled the aesthetic innovation which germinated in the mid-1960s and was reaped throughout the 1970s. Artists broadly identified under the heading of Conceptual art ... substituting performance and publishing activities for engagement with both the material and materialistic concerns of painted or sculptural form ... [have] endeavored to undermine the art object qua object.\"\n\nIn the decades since, these ideas have been somewhat lost as the art market has learned to sell limited edition DVDs of video works, invitations to exclusive performance art pieces, and the objects left over from conceptual pieces. Many of these performances create works that are only understood by the elite who have been educated as to why an idea or video or piece of apparent garbage may be considered art. The marker of status becomes understanding the work instead of necessarily owning it, and the artwork remains an upper-class activity. \"With the widespread use of DVD recording technology in the early 2000s, artists, and the gallery system that derives its profits from the sale of artworks, gained an important means of controlling the sale of video and computer artworks in limited editions to collectors.\"\n\nArt has long been controversial, that is to say disliked by some viewers, for a wide variety of reasons, though most pre-modern controversies are dimly recorded, or completely lost to a modern view. Iconoclasm is the destruction of art that is disliked for a variety of reasons, including religious ones. Aniconism is a general dislike of either all figurative images, or often just religious ones, and has been a thread in many major religions. It has been a crucial factor in the history of Islamic art, where depictions of Muhammad remain especially controversial. Much art has been disliked purely because it depicted or otherwise stood for unpopular rulers, parties or other groups. Artistic conventions have often been conservative and taken very seriously by art critics, though often much less so by a wider public. The iconographic content of art could cause controversy, as with late medieval depictions of the new motif of the Swoon of the Virgin in scenes of the Crucifixion of Jesus. The \"Last Judgment\" by Michelangelo was controversial for various reasons, including breaches of decorum through nudity and the Apollo-like pose of Christ.\n\nThe content of much formal art through history was dictated by the patron or commissioner rather than just the artist, but with the advent of Romanticism, and economic changes in the production of art, the artists' vision became the usual determinant of the content of his art, increasing the incidence of controversies, though often reducing their significance. Strong incentives for perceived originality and publicity also encouraged artists to court controversy. Théodore Géricault's \"Raft of the Medusa\" (c. 1820), was in part a political commentary on a recent event. Édouard Manet's \"Le Déjeuner sur l'Herbe\" (1863), was considered scandalous not because of the nude woman, but because she is seated next to men fully dressed in the clothing of the time, rather than in robes of the antique world. John Singer Sargent's \"Madame Pierre Gautreau (Madam X)\" (1884), caused a controversy over the reddish pink used to color the woman's ear lobe, considered far too suggestive and supposedly ruining the high-society model's reputation.\nThe gradual abandonment of naturalism and the depiction of realistic representations of the visual appearance of subjects in the 19th and 20th centuries led to a rolling controversy lasting for over a century. In the twentieth century, Pablo Picasso's \"Guernica\" (1937) used arresting cubist techniques and stark monochromatic oils, to depict the harrowing consequences of a contemporary bombing of a small, ancient Basque town. Leon Golub's \"Interrogation III\" (1981), depicts a female nude, hooded detainee strapped to a chair, her legs open to reveal her sexual organs, surrounded by two tormentors dressed in everyday clothing. Andres Serrano's \"Piss Christ\" (1989) is a photograph of a crucifix, sacred to the Christian religion and representing Christ's sacrifice and final suffering, submerged in a glass of the artist's own urine. The resulting uproar led to comments in the United States Senate about public funding of the arts.\n\nBefore Modernism, aesthetics in Western art was greatly concerned with achieving the appropriate balance between different aspects of realism or truth to nature and the ideal; ideas as to what the appropriate balance is have shifted to and fro over the centuries. This concern is largely absent in other traditions of art. The aesthetic theorist John Ruskin, who championed what he saw as the naturalism of J. M. W. Turner, saw art's role as the communication by artifice of an essential truth that could only be found in nature.\n\nThe definition and evaluation of art has become especially problematic since the 20th century. Richard Wollheim distinguishes three approaches to assessing the aesthetic value of art: the Realist, whereby aesthetic quality is an absolute value independent of any human view; the Objectivist, whereby it is also an absolute value, but is dependent on general human experience; and the Relativist position, whereby it is not an absolute value, but depends on, and varies with, the human experience of different humans.\n\nThe arrival of Modernism in the late nineteenth century lead to a radical break in the conception of the function of art, and then again in the late twentieth century with the advent of postmodernism. Clement Greenberg's 1960 article \"Modernist Painting\" defines modern art as \"the use of characteristic methods of a discipline to criticize the discipline itself\". Greenberg originally applied this idea to the Abstract Expressionist movement and used it as a way to understand and justify flat (non-illusionistic) abstract painting:\n\nPop artists like Andy Warhol became both noteworthy and influential through work including and possibly critiquing popular culture, as well as the art world. Artists of the 1980s, 1990s, and 2000s expanded this technique of self-criticism beyond \"high art\" to all cultural image-making, including fashion images, comics, billboards and pornography.\n\nDuchamp once proposed that art is any activity of any kind- everything. However, the way that only certain activities are classified today as art is a social construction. There is evidence that there may be an element of truth to this. \"\" is an art history book which examines the construction of the modern system of the arts i.e. Fine Art. Shiner finds evidence that the older system of the arts before our modern system (fine art) held art to be any skilled human activity i.e. Ancient Greek society did not possess the term art but techne. Techne can be understood neither as art or craft, the reason being that the distinctions of art and craft are historical products that came later on in human history. Techne included painting, sculpting and music but also; cooking, medicine, horsemanship, geometry, carpentry, prophecy, and farming etc.\n\nFollowing Duchamp during the first half of the twentieth century, a significant shift to general aesthetic theory took place which attempted to apply aesthetic theory between various forms of art, including the literary arts and the visual arts, to each other. This resulted in the rise of the New Criticism school and debate concerning \"the intentional fallacy\". At issue was the question of whether the aesthetic intentions of the artist in creating the work of art, whatever its specific form, should be associated with the criticism and evaluation of the final product of the work of art, or, if the work of art should be evaluated on its own merits independent of the intentions of the artist.\n\nIn 1946, William K. Wimsatt and Monroe Beardsley published a classic and controversial New Critical essay entitled \"The Intentional Fallacy\", in which they argued strongly against the relevance of an author's intention, or \"intended meaning\" in the analysis of a literary work. For Wimsatt and Beardsley, the words on the page were all that mattered; importation of meanings from outside the text was considered irrelevant, and potentially distracting.\n\nIn another essay, \"The Affective Fallacy,\" which served as a kind of sister essay to \"The Intentional Fallacy\" Wimsatt and Beardsley also discounted the reader's personal/emotional reaction to a literary work as a valid means of analyzing a text. This fallacy would later be repudiated by theorists from the reader-response school of literary theory. Ironically, one of the leading theorists from this school, Stanley Fish, was himself trained by New Critics. Fish criticizes Wimsatt and Beardsley in his essay \"Literature in the Reader\" (1970).\n\nAs summarized by Gaut and Livingston in their essay \"The Creation of Art\": \"Structuralist and post-structuralists theorists and critics were sharply critical of many aspects of New Criticism, beginning with the emphasis on aesthetic appreciation and the so-called autonomy of art, but they reiterated the attack on biographical criticisms's assumption that the artist's activities and experience were a privileged critical topic.\" These authors contend that: \"Anti-intentionalists, such as formalists, hold that the intentions involved in the making of art are irrelevant or peripheral to correctly interpreting art. So details of the act of creating a work, though possibly of interest in themselves, have no bearing on the correct interpretation of the work.\"\n\nGaut and Livingston define the intentionalists as distinct from formalists stating that: \"Intentionalists, unlike formalists, hold that reference to intentions is essential in fixing the correct interpretation of works.\" They quote Richard Wollheim as stating that, \"The task of criticism is the reconstruction of the creative process, where the creative process must in turn be thought of as something not stopping short of, but terminating on, the work of art itself.\"\n\nThe end of the 20th century fostered an extensive debate known as the linguistic turn controversy, or the \"innocent eye debate\", and generally referred to as the structuralism-poststructuralism debate in the philosophy of art. This debate discussed the encounter of the work of art as being determined by the relative extent to which the conceptual encounter with the work of art dominates over the perceptual encounter with the work of art.\n\nDecisive for the linguistic turn debate in art history and the humanities were the works of yet another tradition, namely the structuralism of Ferdinand de Saussure and the ensuing movement of poststructuralism. In 1981, the artist Mark Tansey created a work of art titled \"The Innocent Eye\" as a criticism of the prevailing climate of disagreement in the philosophy of art during the closing decades of the 20th century. Influential theorists include Judith Butler, Luce Irigaray, Julia Kristeva, Michel Foucault and Jacques Derrida. The power of language, more specifically of certain rhetorical tropes, in art history and historical discourse was explored by Hayden White. The fact that language is \"not\" a transparent medium of thought had been stressed by a very different form of philosophy of language which originated in the works of Johann Georg Hamann and Wilhelm von Humboldt. Ernst Gombrich and Nelson Goodman in his book \"Languages of Art: An Approach to a Theory of Symbols\" came to hold that the conceptual encounter with the work of art predominated exclusively over the perceptual and visual encounter with the work of art during the 1960s and 1970s. He was challenged on the basis of research done by the Nobel prize winning psychologist Roger Sperry who maintained that the human visual encounter was not limited to concepts represented in language alone (the linguistic turn) and that other forms of psychological representations of the work of art were equally defensible and demonstrable. Sperry's view eventually prevailed by the end of the 20th century with aesthetic philosophers such as Nick Zangwill strongly defending a return to moderate aesthetic formalism among other alternatives.\n\n Disputes as to whether or not to classify something as a work of art are referred to as classificatory disputes about art. Classificatory disputes in the 20th century have included cubist and impressionist paintings, Duchamp's \"Fountain\", the movies, superlative imitations of banknotes, conceptual art, and video games. Philosopher David Novitz has argued that disagreement about the definition of art are rarely the heart of the problem. Rather, \"the passionate concerns and interests that humans vest in their social life\" are \"so much a part of all classificatory disputes about art\" (Novitz, 1996). According to Novitz, classificatory disputes are more often disputes about societal values and where society is trying to go than they are about theory proper. For example, when the \"Daily Mail\" criticized Hirst's and Emin's work by arguing \"For 1,000 years art has been one of our great civilising forces. Today, pickled sheep and soiled beds threaten to make barbarians of us all\" they are not advancing a definition or theory about art, but questioning the value of Hirst's and Emin's work. In 1998, Arthur Danto, suggested a thought experiment showing that \"the status of an artifact as work of art results from the ideas a culture applies to it, rather than its inherent physical or perceptible qualities. Cultural interpretation (an art theory of some kind) is therefore constitutive of an object's arthood.\"\n\nAnti-art is a label for art that intentionally challenges the established parameters and values of art; it is term associated with Dadaism and attributed to Marcel Duchamp just before World War I, when he was making art from found objects. One of these, \"Fountain\" (1917), an ordinary urinal, has achieved considerable prominence and influence on art. Anti-art is a feature of work by Situationist International, the lo-fi Mail art movement, and the Young British Artists, though it is a form still rejected by the Stuckists, who describe themselves as anti-anti-art.\n\nArchitecture is often included as one of the visual arts; however, like the decorative arts, or advertising, it involves the creation of objects where the practical considerations of use are essential in a way that they usually are not in a painting, for example.\n\nSomewhat in relation to the above, the word \"art\" is also used to apply judgments of value, as in such expressions as \"that meal was a work of art\" (the cook is an artist), or \"the art of deception\", (the highly attained level of skill of the deceiver is praised). It is this use of the word as a measure of high quality and high value that gives the term its flavor of subjectivity. Making judgments of value requires a basis for criticism. At the simplest level, a way to determine whether the impact of the object on the senses meets the criteria to be considered \"art\" is whether it is perceived to be attractive or repulsive. Though perception is always colored by experience, and is necessarily subjective, it is commonly understood that what is not somehow aesthetically satisfying cannot be art. However, \"good\" art is not always or even regularly aesthetically appealing to a majority of viewers. In other words, an artist's prime motivation need not be the pursuit of the aesthetic. Also, art often depicts terrible images made for social, moral, or thought-provoking reasons. For example, Francisco Goya's painting depicting the Spanish shootings of 3rd of May 1808 is a graphic depiction of a firing squad executing several pleading civilians. Yet at the same time, the horrific imagery demonstrates Goya's keen artistic ability in composition and execution and produces fitting social and political outrage. Thus, the debate continues as to what mode of aesthetic satisfaction, if any, is required to define 'art'.\n\nThe assumption of new values or the rebellion against accepted notions of what is aesthetically superior need not occur concurrently with a complete abandonment of the pursuit of what is aesthetically appealing. Indeed, the reverse is often true, that the revision of what is popularly conceived of as being aesthetically appealing allows for a re-invigoration of aesthetic sensibility, and a new appreciation for the standards of art itself. Countless schools have proposed their own ways to define quality, yet they all seem to agree in at least one point: once their aesthetic choices are accepted, the value of the work of art is determined by its capacity to transcend the limits of its chosen medium to strike some universal chord by the rarity of the skill of the artist or in its accurate reflection in what is termed the \"zeitgeist\". Art is often intended to appeal to and connect with human emotion. It can arouse aesthetic or moral feelings, and can be understood as a way of communicating these feelings. Artists express something so that their audience is aroused to some extent, but they do not have to do so consciously. Art may be considered an exploration of the human condition; that is, what it is to be human.\n\n\n\n\n"}
{"id": "27741962", "url": "https://en.wikipedia.org/wiki?curid=27741962", "title": "Cultural property law", "text": "Cultural property law\n\nCultural property law is the body of law that protects and regulates the disposition of culturally significant material, including historic real property, ancient and historic artifacts, artwork, and intangible cultural property. Cultural property can be any property, tangible or intangible, having special significance to a defined group of people, whether or not the group is vested with a traditional property interest. Cultural property laws may be international (such as international conventions or bilateral agreements) or domestic (such as federal laws or state laws).\n\nTwo major treaties have dealt with the issue of cultural heritage protection during armed conflict:\n\nRepatriation issues may also apply domestically, for instance, in the United States, the 1990 Native American Graves Protection and Repatriation Act (NAGPRA)\n\n\n"}
{"id": "48811073", "url": "https://en.wikipedia.org/wiki?curid=48811073", "title": "Cybernetic Culture Research Unit", "text": "Cybernetic Culture Research Unit\n\nThe Cybernetic Culture Research Unit (Ccru) was a student-run interdisciplinary collective founded in 1995 out of the University of Warwick's philosophy department. It was associated with the work of Sadie Plant and Nick Land.\n\nThe collective's research was closely tied to the work of philosophers Sadie Plant (around whom it was founded), Nick Land, and their colleagues throughout the 1990s, and in particular the emerging cyberfeminist thinking that would lead to the \"Virtual Futures\" conferences at Warwick in the middle of the decade. Ultimately, Plant would abandon her academic post and affiliation with the Ccru in 1997, during which time it came under the direction of Land. Under his leadership, the collective became increasingly experimental and unorthodox in its work, with its output (which included writing, performance events, and collaborative art) crossing post-structuralism, cybernetics, science-fiction, rave culture, and occult studies. In 2015, a collection of Ccru pieces entitled \"Ccru: Writings 1997-2003\" was published.\n\nAlthough it only existed in an official capacity for little over two years—following the departure of Plant, the University of Warwick would deny any relationship to the renegade collective—the Ccru's cultural impact has been significant. Those who were affiliated with the Ccru during and after its time as part of the University of Warwick Philosophy department include philosophers Iain Hamilton Grant, Ray Brassier and Reza Negarestani; cultural theorists Mark Fisher and Kodwo Eshun; publisher and philosopher Robin Mackay; digital media theorists Luciana Parisi and Matthew Fuller; electronic music artist and Hyperdub label head Steve Goodman, aka Kode9; writer and theorist Anna Greenspan; novelist Hari Kunzru; and artists Jake and Dinos Chapman, among others. Land and the Ccru collaborated frequently with the experimental art collective 0[rphan<nowiki>]</nowiki>d[rift><nowiki>]</nowiki> (Maggie Roberts and Ranu Mukherjee), notably on \"Syzygy\", a month-long multidisciplinary residency at Beaconsfield Contemporary Art gallery in South London, 1999, and on 0[rphan]d[rift>]'s \"Cyberpositive\" (London: Cabinet, 1995), a schizoid work of cut-and-paste cyberphilosophy.\n\nThe role played by Land, Plant, and the Ccru in the development of what has come to be known as accelerationism is profound, and its legacy is apparent in contemporary debates concerning the viability of the theory in its various guises. It is important to note that accelerationism as it was deployed by the Ccru should be distinguished from the term more frequently associated with Nick Srnicek and Alex Williams’ ‘Manifesto for an Accelerationist Politics’. Land himself makes this distinction clear in his commentary on the manifesto.\n\n"}
{"id": "722906", "url": "https://en.wikipedia.org/wiki?curid=722906", "title": "Inclusio", "text": "Inclusio\n\nIn biblical studies, inclusio is a literary device based on a concentric principle, also known as bracketing or an envelope structure, which consists of creating a frame by placing similar material at the beginning and end of a section, although whether this material should consist of a word or a phrase, or whether greater amounts of text also qualify, and of what length the frames section should be, are matters of some debate. Inclusio is found in various sources, both antique and new. The purpose of an inclusio may be structural - to alert the reader to a particularly important theme - or it may serve to show how the material within the inclusio relates to the inclusio itself. An important case of this occurs in the Gospel of Mark's treatment of the \"Cursing of the Fig Tree\" and the \"Cleansing of the Temple\" (Chapter 11). By giving the first half of the story before the Cleansing of the Temple, and the conclusion after, Mark creates a \"frame\" that effectively highlights that he wants the Cleansing of the Temple to be seen in light of the Cursing of the Fig Tree - i.e. Jesus' actions in the Temple are not just a reform measure, but a judgment against it.\n\nWhile this may not be evident to many of the Bible's modern day readers, the Hebrew Bible is full of literary devices, some of which, having fallen out of favor over the years, are lost on most modern readers. \"Inclusio\", of which many instances can be found in the Bible, is one of these, although many instances of its usage are not apparent to those reading translations of the Bible rather than the Hebrew source.\n\nParticularly noteworthy are the many instances of \"inclusio\" in the Book of Jeremiah. A rather far-flung example of \"inclusio\" in the Book of Jeremiah can be found in its first section, chapters 1–24, which are enveloped both by a similar question in the first and last episode (1:11, 24:3), and by similar imagery—that of almond rods and baskets of figs. \"Inclusio\" may also be found between chapters 36 and 45, both of which mention Baruch ben Nerya, to whom Jeremiah's prophecies were entrusted. \"Bracketing\" can also be seen in The Lord's sayings in 1:10 and 24:6. Indeed, the whole book save for its last (52nd) chapter—which some claim was appended to it—can be thought of as inside the \"inclusio\" formed by 1:1 and 51:64, both of which mention the preaching of Jeremiah (דברי ירמיה), thus implying the lateness of chapter 52; although analyzing whether so trivial a measure has any meaning but that which appeases the eye is best left to the astute reader. None of this is to say that the shorter forms of inclusio—those in which the section enframed is quite shorter—are not found in the Book of Jeremiah. An example is found in Jeremiah 4:22, which reads:\n\nThe phrase \"לא ידעו\" (\"did not know\") is found at the beginning and the end of The Lord's analysis of his people. English translations do not preserve this structure.\n\nInclusio also abounds in other books of the Bible. An obvious example of inclusio is found in the first and last (29th) verses of Psalm 118 \"הודו לה' כי-טוב כי לעולם חסדו.\". Another, more disputed, example may be found in the Book of Ruth, where one finds a certain resemblance, if somewhat chiastic, between 1:1 and 1:22—in the former Elimelekh leaves Bethlehem in favor of Moab, and in the latter Ruth and Naomi leave Moab in favor of Bethlehem. Finally, it has been suggested that Genesis 2 contains inclusio, for the male is created at the start of the passage and the female at the end, providing textual evidence for the parallels between the two.\n\nThe rabbis of the Talmud were aware of occurrences of inclusio in the Bible, as shown by R. Yohanan's comment in the Babylonian Talmud, Berakhot 10a that \"Any psalm dear to David he opened with \"אשרי\" ('happy is he') and closed with \"אשרי\" ('happy is he'). Redactors of rabbinic document frequently made use of inclusio to mark off the endpoints of literary units of different sizes and possibly to suggest conceptual connections between seemingly disparate statements. At the end of the Mishnah tractate Kelim, R. Yose explicitly notes the phenomenon: \"Happy are you, Kelim, in that you opened with [statements regarding] impurity and departed with [statements regarding] purity.\" Tractate Berakhot, which opens with a discussion of the laws of reciting the שמע (Hear O Israel) passage from Deuteronomy 6:4-9, concludes with a homiletic interpretation of the second verse from this passage (v. 5), showing how the ritual recitation of the tractate's opening may serve as a source of spiritual instruction at the tractate's end. Tractate Nazir is framed by allusions to two famous biblical Nazirites - Samson (M. Nazir 1:2) and Samuel (M. Nazir 9:5), representing respectively negative and positive exemplars of this institution.\n\nMany chapters of Mishnah are also framed by inclusio. In the opening mishnah of Taanit Chapter 1, R. Joshua notes that rain on the festival of Sukkot is \"not a sign of blessing\", and the closing mishnah of the chapter notes that rainfall after the month of Nisan is \"a sign of curse\". This characterization of rainfall as God's way of communicating His blessings and curses is a central theme of the chapter. Sometimes the inclusio is based on a wordplay. Ohalot Chapter 7 opens with a discussion of corpse impurity in a \"נפש אטומה\" ('solid monument')and closes with the statement that a baby whose head has emerged from the womb may not be killed to save the mother because \"אין דוחין נפש מפני נפש\" ('one soul may not be set aside in favor of another'). The use of the word נפש (nefesh) at the beginning and the end of the chapter in opposite meanings, symbolizing respectively death and life, emphasize the interconnection between the mysteries of birth and of death.\n\nExamples of inclusio may be found in later rabbinic literature as well. Tosefta Makkot Chapter 3 opens and closes with statements regarding the designation of three cities of refuge. Homilies regarding Isaiah 32:20 appear at the beginning and end of BT Bava Kamma Chapter 1. The opening homily of Leviticus Rabba 29 asserts that the fate of Adam on the day of his creation is a sign for his children annually on the same date, and the closing homily of this section asserts that when Israel observes the commandments of this day God will regard them as having been created anew. Rabbinic redactors, following in the footsteps of their biblical predecessors, continued to employ inclusio as a literary marker and tool.\n\nThe New Testament also uses inclusio. The main teaching part in the Sermon on the Mount starts and ends with the expression “the Law and the Prophets” (Matthew 5:17 + 7:12). Matthew’s account of the first part of Jesus’ public ministry is framed by an account on his teaching and his miracles (Matthew 4:23 +9:35).\nAlso, Matthew’s Gospel begins with the prophecy that Jesus' name would be “Emmanuel, that is, ‘God with us,’” (1:23, in which the author has linked Isaiah 7:14 and 8:8, 10 together) and it ends with the promise, \"I am with you always, to the end of the age\". This forms an inclusio about Jesus in his relationship to his people that suggests his deity. \nThe letter to the Hebrews uses Jeremiah’s prophecy as an inclusio in 8:8-12 and 10:16-18.\nThere are many more examples of this literary device in the New Testament.\n"}
{"id": "18069727", "url": "https://en.wikipedia.org/wiki?curid=18069727", "title": "Lifeway", "text": "Lifeway\n\nThe expression lifeway is a fairly new technical term that is not yet in most general dictionaries and for which most textbooks instead still use \"way of life\". The \"American Heritage Dictionary\" defines a lifeway as: \"1. A customary manner of living; a way of life. 2. A custom, practice, or art: \"the traditional lifeways of a tribal society.\"\"\n\nIn several disciplines, \"lifeway\" is used in the sense of the ecological position of human beings within a larger ecosystem - such as a food web. It is studied by cultural ecology, anthropological linguistics, and cultural anthropology. The most basic distinction usually made between lifeways is that between the hunter-gatherer (including fishers) and that of the farmer (including the shepherd, goatherd or rancher) who domesticates wildlife to raise for food and clothing.\n\nUrban lifeways (trading on relationships or information, manufacturing which requires infrastructural capital at hand, etc.) are studied by urban economics but are also technically lifeways in the same sense as that of the hunter-gatherer and farmer.\n\n"}
{"id": "5477429", "url": "https://en.wikipedia.org/wiki?curid=5477429", "title": "Little Emperor Syndrome", "text": "Little Emperor Syndrome\n\nThe Little Emperor Syndrome (or Little Emperor Effect) was an aspect/view of Mainland China's one-child policy where children of modern upper class and wealthier Chinese families gain seemingly excessive amounts of attention from their parents and grandparents. Combined with increased spending power due to China's growing economic strength within the family unit and parents' general desire for their child to experience the benefits they themselves were denied, the phenomenon is generally considered to be problematic. The British journalist Andrew Marshall even argues that it is shaping modern Chinese society in unexpected ways that may culminate into a future \"behavioral time-bomb\".\n\nLittle Emperors were primarily an urban phenomenon. The one-child policy generally only applied to urban communities and, given the value of labor, one child families are not prevalent within rural communities. Economic development has not had as large an impact outside of urban centers.\n\nModern China's economic growth has tremendously elevated the annual per capita income of urban areas as women have become increasingly represented in the workforce, frequently resulting in families with two sources of income. This greatly improved purchasing power coupled with excessive pampering of only children is the cause of increased spending on children. From toys to clothes, parents shower their child in material goods and give in to every demand; it is common for children to be the \"best-dressed members of their families.\"\n\nRecently, it has become common for most of a family's income to be spent on the child. This effect has become considerable enough to be noticed on a global scale: marketing groups attribute a near doubling of platinum Jewellery sales in China to \"China's 'spoiled brat' generation.\"\n\nLittle Emperors also bear the burden of heavy expectations. Parents who feel they lost their chance in the Cultural Revolution (\"compensation syndrome\") put immense pressure on these children to succeed and compete academically. From an early age parents push their only child to educational extremes as they cater to their whims; \"though many of these precocious kids can recite the English alphabet or read newspapers in traditional Chinese characters by the time they're 10, their parents often still perform basic tasks for them: fixing their hair, tying their shoes, wiping their bottoms.\" Boarding school, private English lessons, music lessons and an additional range of extracurricular activities are the normal fare.\n\nOne factor frequently associated with the Little Emperor effect is the \"four-two-one\" family structure, which refers to the collapse of the traditionally large Chinese family into four grandparents and two parents doting on one child. Beyond the obvious further funneling of resources towards the whims and potential of the only child, this four-two-one reconfiguration of the familial structure has distinct ramifications for Chinese society. The Little Emperors of the one-child policy have warped the traditional family beyond recognition; \"in the past, the power in a household devolved from the father,\" who ruled over a multitude of offspring.\n\nNow the household structures itself entirely around the one child. This shift from earlier structures that supported the culture of filial piety has caused much concern; \"traditionally, a great number of children, particularly sons, was seen as proof of the family's standing and it guaranteed the continuity of ancestor-worshipping customs.\" The most salient issue stems from the worry about who will look after the elderly. Aside from a potentially radical shift in cultural norms concerning the treatment of the elderly, this new family structure poses a purely demographic problem: \"the composition of the dependent population is shifting away from children toward elderly population.\"\n\nMany Chinese families use traditional Confucian values to teach their only child. Confucianism considers Ren (love and social responsibility) the core emotion that inspires other moral concepts in personal motivation. The child often receives too much love and has been highly mentally and physically restricted to devote themselves to a heavy load of schoolwork, considering that the economic future of the family depends on their success. Such a situation can directly lead to the overindulgence of the child thus reversing traditional Confucian values of Ren (仁) and filial piety (xiao 孝). There is also evidence that many young Chinese feel heavily burdened and a huge sense of responsibility toward their parents, understanding that their success can have crucial consequences for their family.\n\nDepending on specific family conditions and a child's outlook, this burden can lead to a diligent lifestyle by youngsters or to a more rebellious attitude to traditional codes or to not being able to cope with such pressure nor to develop self-discipline.\n\nThe combination of immense pressure to excel and extreme pampering is reported to have resulted in a stunting of social and emotional growth. The perceived maladjustment of the Little Emperors is an exaggerated subject within the media; \"the government has [tried] to cope with the Little Emperor problem through frequent cautionary stories in the press.\" These stories depict children hanging themselves after being denied sweets and cases of matricide in retribution for a scolding or late dinner. The discussion of Little Emperors has saturated public discussion concerning the one-child policy in Chinese and international media.\n\nPsychological studies do not support this view or, at best, offered mixed results. Results from earlier studies are inconsistent with some more recent studies that suggest there are no reliable differences between only children and those with siblings. However, a survey published in 2013 on 431 Beijing adults finds that those who had grown up after the introduction of the one-child policy were lacking \"entrepreneurial drive and the willingness to take risks. This even had a significant impact on career choices.\n\n"}
{"id": "20754313", "url": "https://en.wikipedia.org/wiki?curid=20754313", "title": "Maqbara", "text": "Maqbara\n\nThe Arabic word Maqbara (مقبرة \"mausoleum\"; \"plural\": مقابر Maqâbir) is derived from the word Qabr, which means grave. Though maqbara refers to the graves of all Muslims, it refers especially to the graves (Raula or Rauza) of religious figures or Waliyullahs considered to have dedicated their life to Islam, striving to be true Muslims and training others to follow Islam as preached by the Islamic prophet Muhammad.\nIn Asian countries, maqbara also refers to the Dargah of Waliyullahs, Sufis, Sheikhs, Imams, Qutbs and Ghouses. There are a large number of Dargahs of Waliyullahs all over India, and their maqbaras are found therein.\nIn Madurai, South Tamil Nadu, the term Maqbara usually refers to the Dargahs of three saints: Meer Ahmad Ibrahim Waliyullah Al Kabir, Meer Amjad Ibrahim Waliyullah As Saghir, and Syed Abdus Salaam Ibrahim Saalim Waliyullah. The graves of all three sheikhs are in the Kazimar big mosque (Periya Pallivasal) in the heart of Madurai city, the cultural capital of Tamil Nadu in South India.\n\n"}
{"id": "24698694", "url": "https://en.wikipedia.org/wiki?curid=24698694", "title": "Myth", "text": "Myth\n\nMyth is a folklore genre consisting of narratives that play a fundamental role in society, such as foundational tales. The main characters in myths are usually gods, demigods or supernatural humans. Myths are often endorsed by rulers and priests and are closely linked to religion or spirituality. In fact, many societies group their myths, legends and history together, considering myths to be true accounts of their remote past. Creation myths particularly, take place in a primordial age when the world had not achieved its later form. Other myths explain how a society's customs, institutions and taboos were established and sanctified. There is a complex relationship between recital of myths and enactment of rituals.\n\nThe study of myth began in ancient history. Rival classes of the Greek myths by Euhemerus, Plato and Sallustius were developed by the Neoplatonists and later revived by Renaissance mythographers. Today, the study of myth continues in a wide variety of academic fields, including folklore studies, philology, and psychology. The term mythology may either refer to the study of myths in general, or a body of myths regarding a particular subject. The academic comparisons of bodies of myth is known as comparative mythology.\n\nDefinitions of \"myth\" to some extent vary by scholar. Finnish folklorist Lauri Honko offers a widely cited definition:\nScholars in other fields use the term \"myth\" in varied ways. In a broad sense, the word can refer to any traditional story, popular misconception or imaginary entity.\n\nHowever, while myth and other folklore genres may overlap, myth is often thought to differ from genres such as legend and folktale in that neither are considered to be sacred narratives. Some kinds of folktales, such as fairy stories, are not considered true by anyone, and may be seen as distinct from myths for this reason. Main characters in myths are usually gods, demigods or supernatural humans, while legends generally feature humans as their main characters. However, many exceptions or combinations exist, as in the \"Iliad\", \"Odyssey\" and \"Aeneid\". Moreover, as stories spread between cultures or as faiths change, myths can come to be considered folktales, their divine characters recast as either as humans or demihumans such as giants, elves and faeries. Conversely, historical and literary material may acquire mythological qualities over time. For example, the Matter of Britain (the legendary history of Great Britain, especially those focused on King Arthur and the knights of the Round Table) and the Matter of France, seem distantly to originate in historical events of the fifth and eighth-centuries respectively, and became mythologised over the following centuries.\n\nIn colloquial use, the word \"myth\" can also be used of a collectively held belief that has no basis in fact, or any false story. This usage, which is often pejorative, arose from labeling the religious myths and beliefs of other cultures as incorrect, but it has spread to cover non-religious beliefs as well. However, as commonly used by folklorists and academics in other relevant fields, such as anthropology, the term \"myth\" has no implication whether the narrative may be understood as true or otherwise.\n\nSince the term \"myth\" is widely used to imply that a story is not objectively true, the identification of a narrative as a myth can be highly political: many adherents of religions view their religion's stories as true and therefore object to the stories being characterised as myths. Nevertheless, scholars now routinely speak of Christian mythology, Jewish mythology, Islamic mythology, Hindu mythology, and so forth. Traditionally, Western scholarship, with its Judaeo-Christian heritage, has viewed narratives in the Abrahamic religions as being the province of theology rather than mythology; meanwhile, identifying religious stories of colonised cultures, such as stories in Hinduism, as myths enabled Western scholars to imply that they were of lower truth-value than the stories of Christianity. Labelling all religious narratives as \"myths\" can be thought of as treating different traditions with parity.\n\nIn present use, \"mythology\" usually refers to the collected myths of a group of people, but may also mean the study of such myths. For example, Greek mythology, Roman mythology and Hittite mythology all describe the body of myths retold among those cultures. Folklorist Alan Dundes defines myth as a sacred narrative that explains how the world and humanity evolved into their present form. Dundes classified a sacred narrative as \"a story that serves to define the fundamental worldview of a culture by explaining aspects of the natural world and delineating the psychological and social practices and ideals of a society\". Anthropologist Bruce Lincoln defines \"myth\" as \"ideology in narrative form.\"\n\nThe compilation or description of myths is sometimes known as \"mythography\", a term which can also be used of a scholarly anthology of myths (or, confusingly, of the study of myths generally). Key mythographers in the Classical tradition include Ovid (43 BCE–17/18 CE), whose tellings of myths have been profoundingly influential; Fabius Planciades Fulgentius, a Latin writer of the late fifth to early sixth centuries, whose \"Mythologies\" (Latin: \"Mitologiarum libri III\") gathered and gave moralistic interpretations of a wide range of myths; the anonymous medieval Vatican Mythographers, who developed anthologies of Classical myths that remained influential to the end of the Middle Ages; and the Renaissance scholar Natalis Comes, whose ten-book \"Mythologiae\" became a standard source for classical mythology in later Renaissance Europe. Other prominent mythographies include the thirteenth-century \"Prose Edda\" attributed to the Icelander Snorri Sturluson, which is the main surviving survey of Norse Mythology from the Middle Ages.\n\nBecause \"myth\" is sometimes used in a pejorative sense, some scholars have opted to use the term \"mythos\" instead. However, \"mythos\" now more commonly refers to its Aristotelian sense as a \"plot point\" or to 'a body of interconnected myths or stories, esp[ecially] those belonging to a particular religious or cultural tradition'. It is sometimes used specifically for modern, fictional mythologies, such as the world building of H.P. Lovecraft.\n\n\"Conscious generation\" of mythology was termed \"mythopoeia\" by, amongst others, J.R.R. Tolkien. It was notoriously also suggested, separately, by Nazi ideologist Alfred Rosenberg.\n\nThe word \"myth\" comes from Ancient Greek \"μῦθος\" [\"mȳthos\"], meaning 'speech, narrative, fiction, myth, plot'. In Anglicised form, this Greek word began to be used in English (and was likewise adapted into other European languages) in the early nineteenth century, in a much narrower sense, as a scholarly term for 'a traditional story, typically involving supernatural beings or forces, which embodies and provides an explanation, aetiology, or justification for something such as the early history of a society, a religious belief or ritual, or a natural phenomenon'.\n\nIn turn, Ancient Greek [\"mythología\"] (\"story,\" \"lore,\" \"legends,\" \"the telling of stories\") combines the word \"mȳthos\" with the suffix -\"λογία\" [\"-logia\"] (\"study\"), and meant 'romance, fiction, story-telling'. Accordingly, Plato used \"mythología\" as a general term for \"fiction\" or \"story-telling\" of any kind.\n\nThe Greek term \"mythología\" was then borrowed into Latin. Late Latin \"mythologia\", which occurs in the title of Latin author Fulgentius' fifth-century \"Mythologiæ\", denoted the explication of Greek and Roman stories about their gods, which we now call classical mythology. Fulgentius's \"Mythologiæ\" explicitly treated its subject matter as allegories requiring interpretation and not as true events.\n\nThe Latin term was then adopted in Middle French as \"mythologie\". Whether from French or Latin usage, English adopted the word \"mythology\" in the fifteenth century, at first in the sense 'the exposition of a myth or myths; the interpretation of fables; a book of such expositions'. The word is first attested in John Lydgate's \"Troy Book\" of c. 1425.\n\nFrom Lydgate until the seventeenth or eighteenth-century, \"mythology\" was used to mean a moral, fable, allegory or a parable, or collection of traditional stories, understood to be false. It came eventually to be applied to similar bodies of traditional stories among other polytheistic cultures around the world.\n\nThus the word \"mythology\" entered the English language before the word \"myth\"; Johnson's \"Dictionary\", for example, has an entry for \"mythology\", but not for \"myth\". Indeed, the Greek loanword \"mythos\" (pl. \"mythoi\") and Latinate \"mythus\" (pl. \"mythi\") both appeared in English before the first example of \"myth\" in 1830.\n\nThe term μῦθος (\"mythos\") appears in the works of Homer and other poets of Homer's era. In these works, the term had several meanings: conversation, narrative, speech, story, tale, and word.\n\nLike the related term λόγος (\"logos\"), \"mythos\" expresses whatever can be delivered in the form of words; these can be contrasted with ἔργον (\"ergon\"), a Greek term for action, deed, and work. The term \"mythos\" lacks an explicit distinction between true or false narratives.\n\nIn the context of the theatre of ancient Greece, the term \"mythos\" referred to the myth, the narrative, the plot, and the story of a play. According to David Wiles, the Greek term \"mythos\" in this era covered an entire spectrum of different meanings, from undeniable falsehoods to stories with religious and symbolic significance.\n\nAccording to philosopher Aristotle (384–322 BCE), the spirit of a theatrical play was its \"mythos\". The term \"mythos\" was also used for the source material of Greek tragedy. The tragedians of the era could draw inspiration from Greek mythology, a body of \"traditional storylines\" which concerned gods and heroes. David Wiles observes that modern conceptions about Greek tragedy can be misleading. It is commonly thought that the ancient audience members were already familiar with the \"mythos\" behind a play, and could predict the outcome of the play. However, the Greek dramatists were not expected to faithfully reproduce traditional myths when adapting them for the stage. They were instead recreating the myths and producing new versions. Storytellers like Euripides (c. 480–406 BCE) relied on suspense to excite their audiences. In one of his works, Merope attempts to kill her son's murderer with an axe, unaware that the man in question is actually her son. According to an ancient description of audience reactions to this work, the audience members were genuinely unsure of whether she would commit filicide or she will be stopped in time. They rose to their feet in terror and caused an uproar.\n\nDavid Wiles points that the traditional \"mythos\" of Ancient Greece, was primarily a part of its oral tradition. The Greeks of this era were a literate culture, but produced no sacred texts. There were no definitive or authoritative versions of myths recorded in texts and preserved forever in an unchanging form. Instead multiple variants of myths were in circulation. These variants were adapted into songs, dances, poetry, and visual art. Performers of myths could freely reshape their source material for a new work, adapting it to the needs of a new audience or in response to a new situation.\n\nChildren in Ancient Greece were familiar with traditional myths from an early age. According to the philosopher Plato (c. 428–347 BCE), mothers and nursemaids narrated myths and stories to the children in their charge: David Wiles describes them as a repository of mythological lore.\n\nBruce Lincoln has called attention to the apparent meaning of the terms \"mythos\" and \"logos\" in the works of Hesiod. In \"Theogony\", Hesiod attributes to the Muses the ability to both proclaim truths and narrate plausible falsehoods (falsehoods which seem like real things). The verb used for narrating the falsehoods in the text is \"legein\", which is etymologically associated with \"logos\". There are two variants in the manuscript tradition for the verb used to proclaim truths. One variant uses \"gerusasthai\", the other \"mythesasthai\". The latter is a form of the verb \"mytheomai\" (to speak, to tell), which is etymologically associated with \"mythos\". In the \"Works and Days\", Hesiod describes his dispute with his brother Perses. He also announces to his readers his intention to tell true things to his brother. The verb he uses for telling the truth is \"mythesaimen\", another form of \"mytheomai\".\n\nLincoln draws the conclusion that Hesiod associated the \"speech of \"mythos\"\" (as Lincoln calls it) with telling the truth. While he associated the \"speech of \"logos\"\" with telling lies, and hiding one's true thoughts (dissimulation). This conclusion is strengthened by the use of the plural term \"logoi\" (the plural form of \"logos\") elsewhere in Hesiod's works. Three times the term is associated with the term \"seductive\" and three times with the term \"falsehoods\". In his genealogy of the gods, Hesiod lists \"logoi\" among the children of Eris, the goddess personifying strife. Eris' children are ominous figures, which personify various physical and verbal forms of conflict.\n\nComparative mythology is the systematic comparison of myths from different cultures. It seeks to discover underlying themes that are common to the myths of multiple cultures. In some cases, comparative mythologists use the similarities between separate mythologies to argue that those mythologies have a common source. This source may inspire myths or provide a common \"protomythology\" that diverged into the mythologies of each culture.\n\nA number of commentators have argued that myths function to form and shape society and social behaviour. Eliade argued that one of the foremost functions of myth is to establish models for behavior and that myths may provide a religious experience. By telling or reenacting myths, members of traditional societies detach themselves from the present, returning to the mythical age, thereby coming closer to the divine.\n\nHonko asserted that, in some cases, a society reenacts a myth in an attempt to reproduce the conditions of the mythical age. For example, it might reenact the healing performed by a god at the beginning of time in order to heal someone in the present. Similarly, Barthes argued that modern culture explores religious experience. Since it is not the job of science to define human morality, a religious experience is an attempt to connect with a perceived moral past, which is in contrast with the technological present.\n\nPattanaik defines mythology as \"a subjective truth of people that is communicated through stories, symbols and rituals\". He adds, \"unlike fantasy that is nobody’s truth, and history that seeks to be everybody’s truth, mythology is somebody’s truth.\"\n\nOne theory claims that myths are distorted accounts of historical events. According to this theory, storytellers repeatedly elaborate upon historical accounts until the figures in those accounts gain the status of gods. For example, the myth of the wind-god Aeolus may have evolved from a historical account of a king who taught his people to use sails and interpret the winds. Herodotus (fifth-century BCE) and Prodicus made claims of this kind. This theory is named \"euhemerism\" after mythologist Euhemerus (c. 320 BCE), who suggested that Greek gods developed from legends about human beings.\n\nSome theories propose that myths began as allegories for natural phenomena: Apollo represents the sun, Poseidon represents water, and so on. According to another theory, myths began as allegories for philosophical or spiritual concepts: Athena represents wise judgment, Aphrodite desire, and so on. Müller supported an allegorical theory of myth. He believed myths began as allegorical descriptions of nature and gradually came to be interpreted literally. For example, a poetic description of the sea as \"raging\" was eventually taken literally and the sea was then thought of as a raging god.\n\nSome thinkers claimed that myths result from the personification of objects and forces. According to these thinkers, the ancients worshiped natural phenomena, such as fire and air, gradually deifying them. For example, according to this theory, ancients tended to view things as gods, not as mere objects. Thus, they described natural events as acts of personal gods, giving rise to myths.\n\nAccording to the myth-ritual theory, myth is tied to ritual. In its most extreme form, this theory claims myths arose to explain rituals. This claim was first put forward by Smith, who argued that people begin performing rituals for reasons not related to myth. Forgetting the original reason for a ritual, they account for it by inventing a myth and claiming the ritual commemorates the events described in that myth. Frazer claimed that humans started out with a belief in magical rituals; later, they began to lose faith in magic and invented myths about gods, reinterpreting their rituals as religious rituals intended to appease the gods.\n\nHistorically, important approaches to the study of mythology have included those of Vico, Schelling, Schiller, Jung, Freud, Lévy-Bruhl, Lévi-Strauss, Frye, the Soviet school, and the Myth and Ritual School.\n\nThe critical interpretation of myth began with the Presocratics. Euhemerus was one of the most important pre-modern mythologists. He interpreted myths as accounts of actual historical events – distorted over many retellings. Sallustius divided myths into five categories – theological, physical (or concerning natural laws), animistic (or concerning soul), material, and mixed. Mixed concerns myths that show the interaction between two or more of the previous categories and are particularly used in initiations.\n\nPlato famously condemned poetic myth when discussing education in the \"Republic.\" His critique was primarily on the grounds that the uneducated might take the stories of gods and heroes literally. Nevertheless, he constantly referred to myths throughout his writings. As Platonism developed in the phases commonly called Middle Platonism and neoplatonism, writers such as Plutarch, Porphyry, Proclus, Olympiodorus, and Damascius wrote explicitly about the symbolic interpretation of traditional and Orphic myths.\n\nMythological themes were consciously employed in literature, beginning with Homer. The resulting work may expressly refer to a mythological background without itself becoming part of a body of myths (Cupid and Psyche). Medieval romance in particular plays with this process of turning myth into literature. \"Euhemerism\", as stated earlier, refers to the rationalization of myths, putting themes formerly imbued with mythological qualities into pragmatic contexts. An example of this would be following a cultural or religious paradigm shift (notably the re-interpretation of pagan mythology following Christianization).\n\nInterest in polytheistic mythology revived during the Renaissance, with early works of mythography appearing in the sixteenth century, among them the \"Theologia Mythologica\" (1532).\n\nThe first modern, Western scholarly theories of myth appeared during the second half of the nineteenth century — at the same time as the word \"myth\" was adopted as a scholarly term in European languages. They were driven partly by a new interest in Europe's ancient past and vernacular culture, associated with Romantic Nationalism and epitomised by the research of Jacob Grimm (1785–1863). This movement drew European scholars' attention not only to Classical myths, but also material now associated with Norse mythology, Finnish mythology, and so forth. Western theories were also partly driven by Europeans' efforts to comprehend and control the cultures, stories and religions they were encountering through colonialism. These encounters included both extremely old texts such as the Sanskrit \"Rigveda\" and the Sumerian \"Epic of Gilgamesh\", and current oral narratives such as mythologies of the indigenous peoples of the Americas or stories told in traditional African religions.\n\nThe intellectual context for nineteenth-century scholars was profoundly shaped by emerging ideas about evolution. These ideas included the recognition that many Eurasian languages—and therefore, conceivably, stories—were all descended from a lost common ancestor (the Indo-European language) which could rationally be reconstructed through the comparison of its descendant languages. They also included the idea that cultures might evolve in ways comparable to species. In general, nineteenth-century theories framed myth as a failed or obsolete mode of thought, often by interpreting myth as the primitive counterpart of modern science within a unilineal framework that imagined that human cultures are travelling, at different speeds, along a linear path of cultural development.\n\nOne of the dominant mythological theories of the later nineteenth century was \"nature mythology\", whose foremost exponents included Max Müller and Edward Burnett Tylor. This theory posited that \"primitive man\" was primarily concerned with the natural world. It tended to interpret myths that seemed distasteful European Victorians—for example tales about sex, incest, or cannibalism—as being metaphors for natural phenomena like agricultural fertility. Unable to conceive impersonal natural laws, early humans tried to explain natural phenomena by attributing souls to inanimate objects, giving rise to animism. According to Tylor, human thought evolved through stages, starting with mythological ideas and gradually progressing to scientific ideas. Müller also saw myth arising from language, even calling myth a \"disease of language\". He speculated that myths arose due to the lack of abstract nouns and neuter gender in ancient languages. Anthropomorphic figures of speech, necessary in such languages, were eventually taken literally, leading to the idea that natural phenomena were in actuality conscious beings or gods. Not all scholars, not even all nineteenth-century scholars, accepted this view. Lucien Lévy-Bruhl claimed \"the primitive mentality is a condition of the human mind, and not a stage in its historical development.\" Recent scholarship, noting the fundamental lack of evidence for \"nature mythology\" interpretations among people who actually circulated myths, has likewise abandoned the key ideas of \"nature mythology\".\n\nJames George Frazer saw myths as a misinterpretation of magical rituals, which were themselves based on a mistaken idea of natural law: this idea was central to the \"myth and ritual\" school of thought. According to Frazer, humans begin with an unfounded belief in impersonal magical laws. When they realize applications of these laws do not work, they give up their belief in natural law in favor of a belief in personal gods controlling nature, thus giving rise to religious myths. Meanwhile, humans continue practicing formerly magical rituals through force of habit, reinterpreting them as reenactments of mythical events. Finally humans come to realize nature follows natural laws, and they discover their true nature through science. Here again, science makes myth obsolete as humans progress \"from magic through religion to science.\"\n\nSegal asserted that by pitting mythical thought against modern scientific thought, such theories imply modern humans must abandon myth.\n\nThe earlier twentieth century saw major work developing psychoanalytical approaches to interpreting myth, led by Sigmund Freud, who, drawing inspiration from Classical myth, began developing the concept of the Oedipus complex in his 1899 \"The Interpretation of Dreams\". Jung likwise tried to understand the psychology behind world myths. Jung asserted that all humans share certain innate unconscious psychological forces, which he called \"archetypes\". He believed similarities between the myths of different cultures reveals the existence of these universal archetypes.\n\nThe mid-twentieth century saw the influential development of a structuralist theory of mythology, led by Lévi-Strauss. Strauss argued that myths reflect patterns in the mind and interpreted those patterns more as fixed mental structures, specifically pairs of opposites (good/evil, compassionate/callous), rather than unconscious feelings or urges. Meanwhile, Bronislaw Malinowski developed analyses of myths focusing on their social functions in the real world. He is associated with the idea that myths such as origin stories might provide a \"mythic charter\"—a legitimisation—for cultural norms and social institutions. Thus, following the Structuralist Era (roughly the 1960s to 1980s), the predominant anthropological and sociological approaches to myth increasingly treated myth as a form of narrative that can be studied, interpreted and analyzed like ideology, history and culture. In other words, myth is a form of understanding and telling stories that is connected to power, political structures, and political and economic interests. These approaches contrast with approaches such as those of Campbell and Eliade that hold that myth has some type of essential connection to ultimate sacred meanings that transcend cultural specifics. In particular, myth was studied in relation to history from diverse social sciences. Most of these studies share the assumption that history and myth are not distinct in the sense that history is factual, real, accurate, and truth, while myth is the opposite.\n\nIn the 1950s, Barthes published a series of essays examining modern myths and the process of their creation in his book \"Mythologies\", which stood as an early work in the emerging post-structuralist approach to mythology, which recognised myths' existence in the modern world and in popular culture.\n\nThe twentieth century saw rapid secularisation in Western culture. This made Western scholars more willing to analyse narratives in the Abrahamic religions as myths; theologians such as Rudolf Bultmann argued that a modern Christianity needed to demythologize; and other religious scholars embraced the idea that the mythical status of Abrahamic narratives was a legitimate feature of their importance. This, in his appendix to \"Myths, Dreams and Mysteries\", and in \"The Myth of the Eternal Return\", Eliade attributed modern humans’ anxieties to their rejection of myths and the sense of the sacred. The Christian theologian Conrad Hyers wrote that\nBoth in nineteenth-century research that tended to see existing records of stories and folklore as imperfect fragments of partially lost myths, and in twentieth-century structuralist work that sought to identify underlying patterns and structures in often diverse versions of a given myth, there had been a tendency to synthesise sources to attempt to reconstruct what scholars supposed to be more perfect or underlying forms of myths. From the late twentieth century, however, researchers influenced by postmodernism tended instead to argue that each account of a given myth has its own cultural significance and meaning, and argued that rather than representing degradation from a once more perfect form, myths are inherently plastic and variable. There is, consequently, no such thing as the 'original version' or 'original form' of a myth. One prominent example of this movement was A.K. Ramanujan's essay \"Three Hundred Ramayanas\".\n\nCorrespondingly, scholars challenged the precedence that had once been given to texts as a medium for mythology, arguing that other media, such as the visual arts or even landscape and place-naming, could be as or more important.\n\nIn modern society, myth is often regarded as a collection of stories. Scholars in the field of cultural studies research how myth has worked itself into modern discourses. Mythological discourse can reach greater audiences than ever before via digital media. Various mythic elements appear in television, cinema and video games.\n\nAlthough myth was traditionally transmitted through the oral tradition on a small scale, the film industry has enabled filmmakers to transmit myths to large audiences via film. In Jungian psychology myths are the expression of a culture or society’s goals, fears, ambitions and dreams.\n\nThe basis of modern visual storytelling is rooted in the mythological tradition. Many contemporary films rely on ancient myths to construct narratives. Disney Corporation is well-known among cultural study scholars for \"reinventing\" traditional childhood myths. While many films are not as obvious as Disney fairy tales, the plots of many films are based on the rough structure of myths. Mythological archetypes, such as the cautionary tale regarding the abuse of technology, battles between gods and creation stories, are often the subject of major film productions. These films are often created under the guise of cyberpunk action films, fantasy, dramas and apocalyptic tales.\n\n21st-century films such as \"Clash of the Titans\", \"Immortals\" and \"Thor\" continue the trend of mining traditional mythology to frame modern plots. Authors use mythology as a basis for their books, such as Rick Riordan, whose Percy Jackson and the Olympians series is situated in a modern-day world where the Greek deities are manifest.\n\n\n\n"}
{"id": "13097936", "url": "https://en.wikipedia.org/wiki?curid=13097936", "title": "Narreme", "text": "Narreme\n\nNarreme is the basic unit of narrative structure. According to Helmut Bonheim (2000), the concept of \"narreme\" was developed three decades earlier by Eugene Dorfman and expanded by Henri Wittmann, The narreme is to narratology what the sememe is to semantics, the morpheme is to morphology and the phoneme to phonology. The narreme, however, has yet to be persuasively defined in practice. In interpretative narratology constrained in a framework of Principles and parameters, narration is the projection of a narreme N, the abstract head of a narrative macrostructure where N dominates immediately N (Wittmann 1995).\n\n\n"}
{"id": "1743079", "url": "https://en.wikipedia.org/wiki?curid=1743079", "title": "Nine Saints", "text": "Nine Saints\n\nThe Nine Saints were a group of missionaries who were important in the initial growth of Christianity in what is now Ethiopia during the late 5th century. Their names were Abba Aftse, Abba Alef, Abba Aragawi, Abba Garima (Isaac, or Yeshaq), Abba Guba, Abba Liqanos, Abba Pantelewon, Abba Sehma, and Abba Yem’ata. Although frequently described as coming from Syria, only two or three actually came from that province; according to Paul B. Henze, others have been traced to Constantinople, Anatolia, and even Rome.\n\nThe Ethiopian historian Tadesse Tamrat speculates that they may have been connected with the anti-Monophysite and anti-Miaphysite persecutions that followed the Council of Chalcedon, which adopted Dyophysitism. Tradition states that upon arrival they were welcomed by the Axumite king Ella Amida. Their activities spread Christianity beyond \"a narrow corridor between Adulis and Aksum along the caravan routes.\" Besides converting the local inhabitants to Christianity, they also founded a number of monastic houses that followed the rule of Saint Pachomius: Abba Aftse founded the monastery at Yeha; Abba Alef the northernmost establishment at Bi'isa on the south bank of the Mareb River; the foundation of the important monastery of Debre Damo is attributed to Abba Aragawi; Abbas Liqanos and Pantelewon are credited with establishing Pentalewon Monastery in Axum; Abba Garima founded Abba Garima Monastery north of Adwa; Abba Guba the one at Madara; Abba Sehma one at Sedenya; and Abba Yem’ata founded the southernmost one of the group in the Gar'alta, noted for its Abuna Yemata Guh church named after him.\nRecent radiocarbon dating supports the tradition of Saint Abba Garima's arrival at the Abba Garima Monastery in 494. The Garima Gospels, which Garima is said to have written, is now regarded as \"the world's earliest illustrated Christian manuscript\" and the oldest surviving Ethiopian manuscript of any kind.\n\nA painting belonging to the Cyprus Presidential Palace with the same title (but quite unrelated to the above) was on exhibition in the Λεβέντειος Πινακοθήκη in Nicosia in 2014. Information about the painting is found in the August 25th issue of the Greek-Cypriot Sunday newspaper Καθημερινή, .\nThe nine saints are also found in the Sinaxaristis (Συναξαριστής in Greek), \n\n\n"}
{"id": "81724", "url": "https://en.wikipedia.org/wiki?curid=81724", "title": "Oral tradition", "text": "Oral tradition\n\nOral tradition, or oral lore, is a form of human communication wherein knowledge, art, ideas and cultural material is received, preserved and transmitted orally from one generation to another. The transmission is through speech or song and may include folktales, ballads, chants, prose or verses. In this way, it is possible for a society to transmit oral history, oral literature, oral law and other knowledge across generations without a writing system, or in parallel to a writing system. Religions such as Buddhism, Hinduism and Jainism, for example, have used an oral tradition, in parallel to a writing system, to transmit their canonical scriptures, secular knowledge such as Sushruta Samhita, hymns and mythologies from one generation to the next.\n\nOral tradition is information, memories and knowledge held in common by a group of people, over many generations, and it is not same as testimony or oral history. In a general sense, \"oral tradition\" refers to the recall and transmission of a specific, preserved textual and cultural knowledge through vocal utterance. As an academic discipline, it refers both to a set of objects of study and a method by which they are studied.\n\nThe study of oral tradition is distinct from the academic discipline of oral history, which is the recording of personal memories and histories of those who experienced historical eras or events. Oral tradition is also distinct from the study of orality defined as thought and its verbal expression in societies where the technologies of literacy (especially writing and print) are unfamiliar to most of the population. A folklore is a type of oral tradition, but knowledge other than folklore has been orally transmitted and thus preserved in human history.\n\nAccording to John Foley, oral tradition has been an ancient human tradition found in \"all corners of the world\". Modern archaeology has been unveiling evidence of the human efforts to preserve and transmit arts and knowledge that depended completely or partially on an oral tradition, across various cultures:\n\nIn Asia, the transmission of folklore, mythologies as well as scriptures in ancient India, in different Indian religions, was by oral tradition, preserved with precision with the help of elaborate mnemonic techniques. Some scholars such as Jack Goody state that the Vedas are not the product strictly of an oral tradition, basing this view by comparing inconsistencies in the transmitted versions of literature from various oral societies such as the Greek, Serbia and other cultures, then noting that the Vedic literature is too consistent and vast to have been composed and transmitted orally across generations, without being written down. According to Goody, the Vedic texts likely involved both a written and oral tradition, calling it a \"parallel products of a literate society\".\n\nIn ancient Greece, the oral tradition was a dominant tradition. Homer's epic poetry, states Michael Gagarin, was largely composed, performed and transmitted orally. As folklores and legends were performed in front of distant audiences, the singers would substitute the names in the stories with local characters or rulers to give the stories a local flavor and thus connect with the audience, but making the historicity embedded in the oral tradition as unreliable. The lack of surviving texts about the Greek and Roman religious traditions have led scholars to presume that these were ritualistic and transmitted as oral traditions, but some scholars disagree that the complex rituals in the ancient Greek and Roman civilizations were an exclusive product of an oral tradition. The Torah and other ancient Jewish literature, the Judeo-Christian Bible and texts of early centuries of Christianity are rooted in an oral tradition, and the term \"People of the Book\" is a medieval construct. This is evidenced, for example, by the multiple scriptural statements by Paul admitting \"previously remembered tradition which he received\" orally.\n\nOral traditions face the challenge of accurate transmission and verifiability of the accurate version, particularly when the culture lacks written language or has limited access to writing tools. Oral cultures have employed various strategies that achieve this without writing. For example, a heavily rhythmic speech filled with mnemonic devices enhances memory and recall. A few useful mnemonic devices include alliteration, repetition, assonance, and proverbial sayings. In addition, the verse is often metrically composed with an exact number of syllables or morae - such as with Greek and Latin prosody and in Chandas found in Hindu and Buddhist texts. The verses of the epic or text are typically designed wherein the long and short syllables are repeated by certain rules, so that if an error or inadvertent change is made, an internal examination of the verse reveals the problem. Such strategies help facilitate transmission of information from individual to individual without a written intermediate, and they can also be applied to oral governance.\n\nRudyard Kipling's The Jungle Book provides an excellent demonstration of oral governance in the Law of the Jungle. Not only does grounding rules in oral proverbs allow for simple transmission and understanding, but it also legitimizes new rulings by allowing extrapolation. These stories, traditions, and proverbs are not static, but are often altered upon each transmission barring the overall meaning remains intact. In this way, the rules that govern the people are modified by the whole and not authored by a single entity.\n\nAncient texts of Hinduism, Buddhism and Jainism were preserved and transmitted by an oral tradition. For example, the śrutis of Hinduism called the Vedas, the oldest of which trace back to the second millennium BCE. Michael Witzel explains this oral tradition as follows:\n\nAncient Indians developed techniques for listening, memorization and recitation of their knowledge, in schools called Gurukul, while maintaining exceptional accuracy of their knowledge across the generations. Many forms of recitation or \"paths\" were designed to aid accuracy in recitation and the transmission of the \"Vedas\" and other knowledge texts from one generation to the next. All hymns in each Veda were recited in this way; for example, all 1,028 hymns with 10,600 verses of the Rigveda was preserved in this way; as were all other Vedas including the Principal Upanishads, as well as the Vedangas. Each text was recited in a number of ways, to ensure that the different methods of recitation acted as a cross check on the other. Pierre-Sylvain Filliozat summarizes this as follows:\n\nThese extraordinary retention techniques guaranteed an accurate Śruti, fixed across the generations, not just in terms of unaltered word order but also in terms of sound. That these methods have been effective, is testified to by the preservation of the most ancient Indian religious text, the \"\" (ca. 1500 BCE).\n\nThe following overview draws upon \"Oral-Formulaic Theory and Research: An Introduction and Annotated Bibliography\", (NY: Garland Publishing, 1985, 1986, 1989); additional material is summarized from the overlapping prefaces to the following volumes: \"The Theory of Oral Composition: History and Methodology\", (Indiana University Press, 1988, 1992); \"Immanent Art: From Structure to Meaning in Traditional Oral Epic\" (Bloomington: Indiana University Press, 1991); \"The Singer of Tales in Performance\" (Bloomington: Indiana University Press, 1995) and \"Comparative Research on Oral Traditions: A Memorial for Milman Parry\" (Columbus, Ohio: Slavica Publishers, 1987). in the work of the Serb scholar Vuk Stefanović Karadžić (1787–1864), a contemporary and friend of the Brothers Grimm. Vuk pursued similar projects of \"salvage folklore\" (similar to rescue archaeology) in the cognate traditions of the Southern Slavic regions which would later be gathered into Yugoslavia, and with the same admixture of romantic and nationalistic interests (he considered all those speaking the Eastern Herzegovinian dialect as Serbs). Somewhat later, but as part of the same scholarly enterprise of nationalist studies in folklore, the turcologist Vasily Radlov (1837–1918) would study the songs of the Kara-Kirghiz in what would later become the Soviet Union; Karadzic and Radloff would provide models for the work of Parry.\n\nIn a separate development, the media theorist Marshall McLuhan (1911–1980) would begin to focus attention on the ways that communicative media shape the nature of the content conveyed. He would serve as mentor to the Jesuit, Walter Ong (1912–2003), whose interests in cultural history, psychology and rhetoric would result in \"Orality and Literacy\" (Methuen, 1980) and the important but less-known \"Fighting for Life: Contest, Sexuality and Consciousness\" (Cornell, 1981) These two works articulated the contrasts between cultures defined by primary orality, writing, print, and the secondary orality of the electronic age.\n\nOng's works also made possible an integrated theory of oral tradition which accounted for both production of content (the chief concern of Parry-Lord theory) and its reception. This approach, like McLuhan's, kept the field open not just to the study of aesthetic culture but to the way physical and behavioral artifacts of oral societies are used to store, manage and transmit knowledge, so that oral tradition provides methods for investigation of cultural differences, other than the purely verbal, between oral and literate societies.\n\nThe most-often studied section of \"Orality and Literacy\" concerns the \"psychodynamics of orality\" This chapter seeks to define the fundamental characteristics of 'primary' orality and summarizes a series of descriptors (including but not limited to verbal aspects of culture) which might be used to index the relative orality or literacy of a given text or society.\n\nIn advance of Ong's synthesis, John Miles Foley began a series of papers based on his own fieldwork on South Slavic oral genres, emphasizing the dynamics of performers and audiences. Foley effectively consolidated oral tradition as an academic field when he compiled \"Oral-Formulaic Theory and Research\" in 1985. The bibliography gives a summary of the progress scholars made in evaluating the oral tradition up to that point, and includes a list of all relevant scholarly articles relating to the theory of Oral-Formulaic Composition. He also both established both the journal \"Oral Tradition\" and founded the \"Center for Studies in Oral Tradition\" (1986) at the University of Missouri. Foley developed Oral Theory beyond the somewhat mechanistic notions presented in earlier versions of Oral-Formulaic Theory, by extending Ong's interest in cultural features of oral societies beyond the verbal, by drawing attention to the agency of the bard and by describing how oral traditions bear meaning.\n\nThe bibliography would establish a clear underlying methodology which accounted for the findings of scholars working in the separate Linguistics fields (primarily Ancient Greek, Anglo-Saxon and Serbo-Croatian). Perhaps more importantly, it would stimulate conversation among these specialties, so that a network of independent but allied investigations and investigators could be established.\n\nFoley's key works include \"The Theory of Oral Composition\" (1988); \"Immanent Art\" (1991); \"Traditional Oral Epic: The Odyssey, Beowulf and the Serbo-Croatian Return-Song\" (1993); \"The Singer of Tales in Performance\" (1995); \"Teaching Oral Traditions\" (1998); \"How to Read an Oral Poem\" (2002). His Pathways Project (2005-2012) draws parallels between the media dynamics of oral traditions and the Internet.\n\nThe theory of oral tradition would undergo elaboration and development as it grew in acceptance. While the number of formulas documented for various traditions proliferated, the concept of the formula remained lexically-bound. However, numerous innovations appeared, such as the \"formulaic system\" with structural \"substitution slots\" for syntactic, morphological and narrative necessity (as well as for artistic invention). Sophisticated models such as Foley's \"word-type placement rules\" followed. Higher levels of formulaic composition were defined over the years, such as \"ring composition\", \"responsion\" and the \"type-scene\" (also called a \"theme\" or \"typical scene\"). Examples include the \"Beasts of Battle\" and the \"Cliffs of Death\". Some of these characteristic patterns of narrative details, (like \"the arming sequence;\" \"the hero on the beach\"; \"the traveler recognizes his goal\") would show evidence of global distribution.\n\nAt the same time, the fairly rigid division between oral and literate was replaced by recognition of transitional and compartmentalized texts and societies, including models of diglossia (Brian Stock Franz Bäuml, and Eric Havelock). Perhaps most importantly, the terms and concepts of \"orality\" and \"literacy\" came to be replaced with the more useful and apt \"traditionality\" and \"textuality\". Very large units would be defined (The Indo-European Return Song) and areas outside of military epic would come under investigation: women's song, riddles and other genres.\n\nThe methodology of oral tradition now conditions a large variety of studies, not only in folklore, literature and literacy, but in philosophy, communication theory, Semiotics, and including a very broad and continually expanding variety of languages and ethnic groups, and perhaps most conspicuously in biblical studies, in which Werner Kelber has been especially prominent. The annual bibliography is indexed by 100 areas, most of which are ethnolinguistic divisions.\n\nPresent developments explore the implications of the theory for rhetoric and composition, interpersonal communication, cross-cultural communication, postcolonial studies, rural community development, popular culture and film studies, and many other areas. The most significant areas of theoretical development at present may be the construction of systematic hermeneutics and aesthetics specific to oral traditions.\n\nThe theory of oral tradition encountered early resistance from scholars who perceived it as potentially supporting either one side or another in the controversy between what were known as \"unitarians\" and \"analysts\" – that is, scholars who believed Homer to have been a single, historical figure, and those who saw him as a conceptual \"author function,\" a convenient name to assign to what was essentially a repertoire of traditional narrative. A much more general dismissal of the theory and its implications simply described it as \"unprovable\" Some scholars, mainly outside the field of oral tradition, represent (either dismissively or with approval) this body of theoretical work as reducing the great epics to children's party games like \"telephone\" or \"Chinese whispers\". While games provide amusement by showing how messages distort content via uncontextualized transmission, Parry's supporters argue that the theory of oral tradition reveals how oral methods optimized the signal-to-noise ratio and thus improved the quality, stability and integrity of content transmission.\n\nThere were disputes concerning particular findings of the theory. For example, those trying to support or refute Crowne's hypothesis found the \"Hero on the Beach\" formula in numerous Old English poems. Similarly, it was also discovered in other works of Germanic origin, Middle English poetry, and even an Icelandic prose saga. J.A. Dane, in an article characterized as \"polemics without rigor\" claimed that the appearance of the theme in Ancient Greek poetry, a tradition without known connection to the Germanic, invalidated the notion of \"an autonomous theme in the baggage of an oral poet.\"\n\nWithin Homeric studies specifically, Lord's \"The Singer of Tales\", which focused on problems and questions that arise in conjunction with applying oral-formulaic theory to problematic texts such as the \"Iliad\", \"Odyssey\", and even \"Beowulf\", influenced nearly all of the articles written on Homer and oral-formulaic composition thereafter. However, in response to Lord, Geoffrey Kirk published \"The Songs of Homer\", questioning Lord's extension of the oral-formulaic nature of Serbian and Croatian literature (the area from which the theory was first developed) to Homeric epic. Kirk argues that Homeric poems differ from those traditions in their \"metrical strictness\", \"formular system[s]\", and creativity. In other words, Kirk argued that Homeric poems were recited under a system that gave the reciter much more freedom to choose words and passages to get to the same end than the Serbo-Croatian poet, who was merely \"reproductive\". Shortly thereafter, Eric Havelock's \"Preface to Plato\" revolutionized how scholars looked at Homeric epic by arguing not only that it was the product of an oral tradition, but also that the oral-formulas contained therein served as a way for ancient Greeks to preserve cultural knowledge across many different generations. Adam Parry, in his 1966 work \"Have we Homer's \"Iliad\"?\", theorized the existence of the most fully developed oral poet to his time, a person who could (at his discretion) creatively and intellectually create nuanced characters in the context of the accepted, traditional story. In fact, he discounted the Serbo-Croatian tradition to an \"unfortunate\" extent, choosing to elevate the Greek model of oral-tradition above all others. Lord reacted to Kirk's and Parry's essays with \"Homer as Oral Poet\", published in 1968, which reaffirmed Lord's belief in the relevance of Yugoslav poetry and its similarities to Homer and downplayed the intellectual and literary role of the reciters of Homeric epic.\n\nMany of the criticisms of the theory have been absorbed into the evolving field as useful refinements and modifications. For example, in what Foley called a \"pivotal\" contribution, Larry Benson introduced the concept of \"written-formulaic\" to describe the status of some Anglo-Saxon poetry which, while demonstrably written, contains evidence of oral influences, including heavy reliance on formulas and themes A number of individual scholars in many areas continue to have misgivings about the applicability of the theory or the aptness of the South Slavic comparison, and particularly what they regard as its implications for the creativity which may legitimately be attributed to the individual artist. However, at present, there seems to be little systematic or theoretically coordinated challenge to the fundamental tenets of the theory; as Foley put it, \"\"there have been numerous suggestions for revisions or modifications of the theory, but the majority of controversies have generated further understanding.\n\n\n"}
{"id": "33524705", "url": "https://en.wikipedia.org/wiki?curid=33524705", "title": "Origins of society", "text": "Origins of society\n\nThe origins of society — the evolutionary emergence of distinctively human social organization — is an important topic within evolutionary biology, anthropology, prehistory and palaeolithic archaeology. While little is known for certain, debates since Hobbes and Rousseau have returned again and again to the philosophical, moral and evolutionary questions posed.\n\nArguably the most influential theory of human social origins is that of Thomas Hobbes, who in his \"Leviathan\" argued that without strong government, society would collapse into \"Bellum omnium contra omnes\" — \"the war of all against all\":\n\nIf Hobbes' idea is accepted, it follows that society could not have emerged prior to the state. This school of thought has remained influential to this day. Prominent in this respect is British archaeologist Colin Renfrew (Baron Renfrew of Kaimsthorn), who points out that the state did not emerge until long after the evolution of \"Homo sapiens\". The earliest representatives of our species, according to Renfrew, may well have been \"anatomically\" modern, but they were not yet \"cognitively\" or \"behaviourally\" modern. For example, they lacked political leadership, large-scale cooperation, food production, organised religion, law or symbolic artefacts. Humans were simply hunter-gatherers, who — much like extant apes — ate whatever food they could find in the vicinity. Renfrew controversially suggests that hunter-gatherers to this day think and socialise along lines not radically different from those of their nonhuman primate counterparts. In particular, he says that they do not \"ascribe symbolic meaning to material objects\" and for that reason \"lack fully developed 'mind.'\"\n\nHowever, hunter-gatherer ethnographers emphasise that extant foraging peoples certainly do have social institutions — notably institutionalised rights and duties codified in formal systems of kinship. Elaborate rituals such as initiation ceremonies serve to cement contracts and commitments, quite independently of the state. Other scholars would add that insofar as we can speak of \"human revolutions\" — \"major transitions\" in human evolution — the first was not the Neolithic Revolution but the rise of symbolic culture that occurred toward the end of the Middle Stone Age.\n\nArguing the exact opposite of Hobbes's position, anarchist anthropologist Pierre Clastres views the state and society as mutually incompatible: genuine society is always struggling to survive \"against\" the state.\n\nLike Hobbes, Jean-Jacques Rousseau argued that society was born in a social contract. In Rousseau's case, however, sovereignty is vested in the entire populace, who enter into the contract directly with one another. \"The problem\", he explained, \"is to find a form of association which will defend and protect with the whole common force the person and goods of each associate, and in which each, while uniting himself with all, may still obey himself alone, and remain as free as before.\" This is the fundamental problem of which the Social Contract provides the solution. The contract's clauses, Rousseau continued, may be reduced to one — \"the total alienation of each associate, together with all his rights, to the whole community. Each man, in giving himself to all, gives himself to nobody; and as there is no associate over whom he does not acquire the same right as he yields others over himself, he gains an equivalent for everything he loses, and an increase of force for the preservation of what he has\". In other words: \"Each of us puts his person and all his power in common under the supreme direction of the general will, and, in our corporate capacity, we receive each member as an indivisible part of the whole.\" At once, in place of the individual personality of each contracting party, this act of association creates a moral and collective body, composed of as many members as the assembly contains votes, and receiving from this act its unity, its common identity, its life and its will. By this means, each member of the community acquires not only the capacities of the whole but also, for the first time, rational mentality:\n\nIn his influential book, \"Ancient Law\" (1861), Maine argued that in early times, the basic unit of human social organisation was the patriarchal family:\n\nHostile to French revolutionary and other radical social ideas, Maine's motives were partly political. He sought to undermine the legacy of Rousseau and other advocates of man’s natural rights by asserting that originally, no one had any rights at all – ‘every man, living during the greater part of his life under the patriarchal despotism, was practically controlled in all his actions by a regimen not of law but of caprice’. Not only were the patriarch’s children subject to what Maine calls his ‘despotism’: his wife and his slaves were equally affected. The very notion of kinship, according to Maine, was simply a way of categorizing those who were forcibly subjected to the despot’s arbitrary rule. Maine later added a Darwinian strand to this argument. In his \"The Descent of Man,\" Darwin had cited reports that a wild-living male gorilla would monopolise for itself as large a harem of females as it could violently defend. Maine endorsed Darwin’s speculation that ‘primeval man’ probably 'lived in small communities, each with as many wives as he could support and obtain, whom he would have jealously guarded against all other men’. Under pressure to spell out exactly what he meant by the term 'patriarchy', Maine clarified that ‘sexual jealousy, indulged through power, might serve as a definition of the Patriarchal Family’.\n\nIn his influential book, \"Ancient Society\" (1877), its title echoing Maine's \"Ancient Law,\" Lewis Henry Morgan proposed a very different theory. Morgan insisted that throughout the earlier periods of human history, neither the state nor the family existed.\n\nFrederick Engels built on Morgan's ideas in his 1884 essay, \"The Origin of the Family, Private Property and the State in the light of the researches of Lewis Henry Morgan.\" His primary interest was the position of women in early society, and — in particular — Morgan's insistence that the matrilineal clan preceded the family as society's fundamental unit. 'The mother-right gens', wrote Engels in his survey of contemporary historical materialist scholarship, 'has become the pivot around which the entire science turns...' Engels argued that the matrilineal clan represented a principle of self-organization so vibrant and effective that it allowed no room for patriarchal dominance or the territorial state.\n\nEmile Durkheim considered that in order to exist, any human social system must counteract the natural tendency for the sexes to promiscuously conjoin. He argued that social order presupposes sexual morality, which is expressed in prohibitions against sex with certain people or during certain periods — in traditional societies particularly during menstruation.\n\nThe incest taboo, wrote Durkheim in 1898, is no more than a particular example of something more basic and universal - the ritualistic setting apart of 'the sacred' from 'the profane'. This begins as the segregation of the sexes, each of which - at least on important occasions - is 'sacred' or 'set apart' from the other. 'The two sexes', as Durkheim explains, 'must avoid each other with the same care as the profane flees from the sacred and the sacred from the profane.' Women as sisters act out the role of 'sacred' beings invested 'with an isolating power of some sort, a power which holds the masculine population at a distance.' Their menstrual blood in particular sets them in a category apart, exercising a 'type of repulsing action which keeps the other sex far from them'. In this way, the earliest ritual structure emerges — establishing morally regulated 'society' for the first time.\n\nCharles Darwin pictured early human society as resembling that of apes, with one or more dominant males jealously guarding a harem of females. In his myth of the 'Primal Horde', Sigmund Freud later took all this as his starting point but then postulated an insurrection mounted by the tyrant's own sons: Following this, the band of brothers were about to take sexual possession of their mothers and sisters when suddenly they were overcome with remorse. In their contradictory emotional state, their dead father now became stronger than the living one had been. In memory of him, the brothers revoked their deed by forbidding the killing and eating of the 'totem' (as their father had now become) and renouncing their claim to the women who had just been set free. In this way, the two fundamental taboos of primitive society – not to eat the totem and not to marry one's sisters – were established for the first time.\n\nA related but less dramatic version of Freud's 'sexual revolution' idea was proposed in 1960 by American social anthropologist Marshall Sahlins. Somehow, he writes, the world of primate brute competition and sexual dominance was turned upside-down: \n\nIf we accept Rousseau's line of reasoning, no single dominant individual is needed to embody society, to guarantee security or to enforce social contracts. The people themselves can do these things, combining to enforce the general will. A modern origins theory along these lines is that of evolutionary anthropologist Christopher Boehm. Boehm argues that ape social organisation tends to be despotic, typically with one or more dominant males monopolising access to the locally available females. But wherever there is dominance, we can also expect resistance. In the human case, resistance to being personally dominated intensified as humans used their social intelligence to form coalitions. Eventually, a point was reached when the costs of attempting to impose dominance became so high that the strategy was no longer evolutionarily stable, whereupon social life tipped over into 'reverse dominance' — defined as a situation in which only the entire community, on guard against primate-style individual dominance, is permitted to use force to suppress deviant behaviour.\n\nHuman beings, writes social anthropologist Ernest Gellner, are not genetically programmed to be members of this or that social order. You can take a human infant and place it into any kind of social order and it will function acceptably. What makes human society so distinctive is the fabulous range of quite different forms it takes across the world. Yet in any given society, the range of permitted behaviours is quite narrowly constrained. This is not owing to the existence of any externally imposed system of rewards and punishments. The constraints come from within — from certain compulsive moral concepts which members of the social order have internalised. The society installs these concepts in each individual's psyche in the manner first identified by Emile Durkheim, namely, by means of collective rituals such as initiation rites. Therefore, the problem of the origins of society boils down to the problem of the origins of collective ritual.\n\nFeminist scholars — among them palaeoanthropologists Leslie Aiello and Camilla Power — take similar arguments a step further, arguing that any reform or revolution which overthrew male dominance must surely have been led by women. Evolving human females, Power and Aiello suggest, actively separated themselves from males on a periodic basis, using their own blood (and/or pigments such as red ochre) to mark themselves as fertile and defiant: In similar vein, anthropologist Chris Knight argues that Boehm's idea of a 'coalition of everyone' is hard to envisage, unless — along the lines of a modern industrial picket line — it was formed to co-ordinate 'sex-strike' action against badly behaving males: In virtually all hunter-gatherer ethnographies, according to Knight, a persistent theme is that 'women like meat', and that they determinedly use their collective bargaining power to motivate men to hunt for them and bring home their kills — on pain of exclusion from sex. Arguments about women's crucial role in domesticating males — motivating them to cooperate — have also been advanced by anthropologists Kristen Hawkes, Sarah Hrdy and Bruce Knauft among others. Meanwhile, other evolutionary scientists continue to envisage uninterrupted male dominance, continuity with primate social systems and the emergence of society on a gradualist basis without revolutionary leaps.\n\nIn his 1985 book, \"Social Evolution\", Robert Trivers outlines the theoretical framework used today by most evolutionary biologists to understand how and why societies are established. Trivers sets out from the fundamental fact that genes survive beyond the death of the bodies they inhabit, because copies of the same gene may be replicated in multiple different bodies. From this, it follows that a creature should behave altruistically to the extent that those benefiting carry the same genes — 'inclusive fitness', as this source of cooperation in nature is termed. Where animals are unrelated, cooperation should be limited to 'reciprocal altruism' or 'tit-for-tat'.\nWhere previously, biologists took parent-offspring cooperation for granted, Trivers predicted on theoretical grounds both cooperation and conflict — as when a mother needs to wean an existing baby (even against its will) in order to make way for another. Previously, biologists had interpreted male infanticidal behaviour as aberrant and inexplicable or, alternatively, as a necessary strategy for culling excess population. Trivers was able to show that such behaviour was a logical strategy by males to enhance their own reproductive success at the expense of conspecifics including rival males. Ape or monkey females whose babies are threatened have directly opposed interests, often forming coalitions to defend themselves and their offspring against infanticidal males.\nHuman society, according to Trivers, is unusual in that it involves the male of the species investing parental care in his own offspring — a rare pattern for a primate. Where such cooperation occurs, it's not enough to take it for granted: in Trivers' view we need to \"explain\" it using an overarching theoretical framework applicable to humans and nonhumans alike.\n\nRobin Dunbar originally studied gelada baboons in the wild in Ethiopia, and has done much to synthesise modern primatological knowledge with Darwinian theory into a comprehensive overall picture. The components of primate social systems 'are essentially alliances of a political nature aimed at enabling the animals concerned to achieve more effective solutions to particular problems of survival and reproduction'. Primate societies are in essence 'multi-layered sets of coalitions'. Although physical fights are ultimately decisive, the social mobilisation of allies usually decides matters and requires skills that go beyond mere fighting ability. The manipulation and use of coalitions demands sophisticated social — more precisely \"political\" — intelligence.\nUsually but not always, males exercise dominance over females. Even where male despotism prevails, females typically gang up with one another to pursue agendas of their own. When a male gelada baboon attacks a previously dominant rival so as to take over his harem, the females concerned may insist on their own say in the outcome. At various stages during the fighting, the females may 'vote' among themselves on whether to accept the provisional outcome. Rejection is signalled by refusing to groom the challenger; acceptance is signalled by going up to him and grooming him. According to Dunbar, the ultimate outcome of an inter-male 'sexual fight' always depends on the female 'vote'.\nDunbar points out that in a primate social system, lower-ranking females will typically suffer the most intense harassment. Consequently, they will be the first to form coalitions in self-defence. But maintaining commitment from coalition allies involves much time-consuming manual grooming, putting pressure on time-budgets. In the case of evolving humans, who were living in increasingly large groups, the costs would soon have outweighed the benefits — unless some more efficient way of maintaining relationships could be found. Dunbar argues that 'vocal grooming' — using the voice to signal commitment — was the time-saving solution adopted, and that this led eventually to speech. Dunbar goes on to suggest (citing evolutionary anthropologist Chris Knight) that \"distinctively human\" society may have been evolved under pressure from female ritual and 'gossiping' coalitions established to dissuade males from fighting one another and instead cooperate in hunting for the benefit of the whole camp: Dunbar stresses that this is currently a minority theory among specialists in human origins — most still support the 'bison-down-at-the-lake' theory attributing early language and cooperation to the imperatives of men's activities such as hunting. Despite this, he argues that 'female bonding may have been a more powerful force in human evolution than is sometimes supposed'. Although still controversial, the idea that female coalitions may have played a decisive role has subsequently received strong support from a number of anthropologists including Sarah Hrdy, Camilla Power, Ian Watts. and Jerome Lewis. It is also consistent with recent studies by population geneticists (see Verdu et al. 2013 for Central African Pygmies; Schlebusch 2010 for Khoisan) showing a deep-time tendency to matrilocality among African hunter-gatherers.\n\n\n"}
{"id": "47077127", "url": "https://en.wikipedia.org/wiki?curid=47077127", "title": "Project 1975", "text": "Project 1975\n\nProject 1975 started in 2010 as a two-year project based in the Netherlands with the intent to explore the relationships between contemporary art and postcolonialism. With this project Stedelijk Museum Bureau Amsterdam (SMBA) explored the role of art and visual culture in the context of colonial practices.\nThe project consisted of multiple exhibitions, seminars, reading groups, articles, and a blog. \n\"1975\" in the title refers to the year that Suriname gained independence (the independent Republic of Surinam was founded in 1975) and the Netherlands thus became to some extent \"postcolonial\"..\n\nThe project broadened SMBA’s focus, traditionally on artists based in Amsterdam, to include artists and people who were new to the city but wanted to contribute to the artistic and cultural environment. Consequently, themes that had not previously been addressed in art institutions in Amsterdam found a place to be discussed at SMBA. Many questions were raised in this project. Artists and critics responded to questions such as \"Do colonial mindsets persist in art and in its institutions?\".\n\nExhibitions that took place in the context of Project 1975 were: \"See Reason\", \"Identity Bluffs\", \"The Marx Lounge\", \"Mounira Al Solh & Bassam Ramlawi\", \"Informality, Art, Economy & Precarity\", \" Vincent Vulsma - A Sign of Autumn \", \"The Jinn - Tala Madani\", \"Any other Business – Nicoline van Harskamp\", \"Bart Groenendaal, Stefan Ruitenbeek, Quinsy Gario\", \"The Memories are Present\", \"Time, Trade & Travel\" and finally \"Hollandaise - a Journey into an Iconic Fabric\".\n\nThe project was finalized with a publication: \"Project 1975. Contemporary Art and the Postcolonial Unconscious \" which includes (visual) documentation of the project, interviews between the curators and artists and essays.\n\nThe Memories are Present and the video programme \"Really Exotic\" ran from 16 June to 12 August 2012 and was curated by Kerstin Winking (SMBA). The participating artists in the exhibition were Artun Alaska Arasli, and Christoph Westermeier. The focus in this exhibition was on the museum as a bearer and communicator of knowledge and interrogated institutional divisions. Central attention was paid to the ways in which different institutions collect, categorise and display objects. The exhibition challenged the binary oppositions still prevalent in many institutions between “art objects” and “ethnographic objects”. \nThe video programme \"Really Exotic\" focused on the notion of the exotic experience. Presented were works that could convey or tell the viewer more about this type of experience. The videoprogram was organised by Joram\nKraaijeveld and Kerstin Winking (SMBA) in collaboration with Marthe Singelenberg\n(Filmtheater Kriterion).\n\nThe exhibition Time, Trade & Travel took place from 25 August to 21 October 2012 and was organized in collaboration with the Nubuke Foundation, Accra, Ghana. Participating artists were: Bernard Akoi-Jackson, Dorothy Akpene Amenuke, Serge Clottey, Zachary Formwalt, Iris Kensmil, Aukje Koks, Navid Nuur, Jeremiah Quarshie, kąrî’kạchä seidóu, Katarina Zdjelar. It was the result of an active exchange of knowledge between artists and curators from SMBA and Nubiuke Foundation, Accra. The curators from both institutions as well as the participating artists visited each other in their work and cultural environment. The title of this exhibition refers to the complicated aspects of international trade and traffic with their capitalist forces and influence on life and art. The participating artists in this exhibition set out to discover historical encounters between Africans and Europeans, the subsequent trade and cultual relationships that evolved from these contacts and the extent to which these cultural and economic relationships are still of influence today.\nThe exhibition travelled on to the Nubuke Foundation in Accra, Ghana.\n\nThe exhibition was curated by: Jelle Bouwhuis and Kerstin Winking (Stedelijk Museum Bureau Amsterdam), Kofi Setordji and Odile Tevie (Nubuke Foundation). Time, Trade & Travel was made possible in part by contributions from the Mondrian Fund, the Amsterdam Fund for the Arts, HIVOS and SNS REAAL Fund.\n\nThe exhibition Hollandaise: a journey into an iconic fabric took place at SMBA from 30 November 2012 to 6 January 2013. The exhibition travelled on to Raw Material Company, Dakar (Senegal), where it was on view from 10 April – 1 June 2013.\n\nThe curator for this exhibition was Koyo Kouoh. Participating artists in this exhibition were Godfried Donkor, Abdoulaye Konaté, Wendelien van Oldenborgh, Willem de Rooij, Billie Zangewa.\n\nFor this exhibition Kouoh commissioned five artists, all working in the medium of textile, in Europe and Africa to make new works on the subject of “Hollandaise” or “Dutch wax”, the colourful wax print fabrics that are most often regarded as typically African. In the context of this exhibition a catalogue, edited by Kouoh, and an SMBA Newsletter were published.\n\n"}
{"id": "1523896", "url": "https://en.wikipedia.org/wiki?curid=1523896", "title": "Prologue", "text": "Prologue\n\nA prologue or prolog from Greek πρόλογος \"prologos\", from πρό \"pro\", \"before\" and λόγος \"logos\", \"word\" is an opening to a story that establishes the context and gives background details, often some earlier story that ties into the main one, and other miscellaneous information. The Ancient Greek \"prólogos\" included the modern meaning of \"prologue\", but was of wider significance, more like the meaning of preface. The importance, therefore, of the prologue in Greek drama was very great; it sometimes almost took the place of a romance, to which, or to an episode in which, the play itself succeeded.\n\nIt is believed that the prologue in this form was practically the invention of Euripides, and with him, as has been said, it takes the place of an explanatory first act. This may help to modify the objection which criticism has often brought against the Greek prologue, as an impertinence, a useless growth prefixed to the play, and standing as a barrier between us and our enjoyment of it. The point precisely is that, to an Athenian audience, it was useful and pertinent, as supplying just what they needed to make the succeeding scenes intelligible. But it is difficult to accept the view that Euripides invented the plan of producing a god out of a machine to justify the action of deity upon man, because it is plain that he himself disliked this interference of the supernatural and did not believe in it. He seems, in such a typical prologue as that to the \"Hippolytus\", to be accepting a conventional formula, and employing it, almost perversely, as a medium for his ironic rationalism.\n\nMany of the existing Greek prologues may be later in date than the plays they illustrate, or may contain large interpolations. On the Latin stage the prologue was often more elaborate than it was in Athens, and in the careful composition of the poems which Plautus prefixes to his plays we see what importance he gave to this portion of the entertainment; sometimes, as in the preface to the \"Rudens\", Plautus rises to the height of his genius in his adroit and romantic prologues, usually placed in the mouths of persons who make no appearance in the play itself.\n\nMolière revived the Plautian prologue in the introduction to his \"Amphitryon\". Racine introduced Piety as the speaker of a prologue which opened his choral tragedy of Esther.\n\nThe tradition of the ancients vividly affected our own early dramatists. Not only were the mystery plays and miracles of the Middle Ages begun by a homily, but when the drama in its modern sense was inaugurated in the reign of Elizabeth, the prologue came with it, directly adapted from the practice of Euripides and Terence. Sackville, Lord Buckhurst, prepared a sort of prologue in dumb show for his \"Gorboduc\" of 1562; and he also wrote a famous Induction, which is, practically, a prologue, to a miscellany of short romantic epics by diverse hands.\n\nPrologues of Renaissance drama often served a specific function of transition and clarification for the audience. A direct address made by one actor, the prologue acted as an appeal to the audience's attention and sympathy, providing historical context, a guide to themes of the play, and occasionally, a disclaimer . In this mode, a prologue, like any scripted performance, would exist as the text, the actor who speaks that text, and the presentation of the language as it is spoken. In ushering the audience from the reality into the world of the play, the prologue straddles boundaries between audience, actors, characters, playwrights--basically, it creates a distinction between the imaginary space within the play and the outside world. Ben Jonson has often been noted as using the prologue to remind the audience of the complexities between themselves and all aspects of the performance.\n\nThe actor reciting the prologue would appear dressed in black, a stark contrast to the elaborate costumes used during the play. The prologue removed his hat and wore no makeup. He may have carried a book, scroll, or a placard displaying the title of the play. He was introduced by three short trumpet calls, on the third of which he entered and took a position downstage. He made three bows in the current fashion of the court, and then addressed the audience.\nThe Elizabethan prologue was unique in incorporating aspects of both classical and medieval traditions. In the classical tradition, the prologue conformed to one of four subgenres: the \"sustatikos\", which recommends either the play or the poet; the \"epitimetikos\", in which a curse is given against a rival, or thanks given to the audience; \"dramatikos\", in which the plot of the play is explained; and mixtos, which contains all of these things. In the medieval tradition, expressions of morality and modesty are seen, as well as a meta-theatrical self-consciousness, and an unabashed awareness of the financial contract engaged upon by paid actors and playwrights, and a paying audience.\n\nPrologues have long been used in non-dramatic fiction, since at least the time of Geoffrey Chaucer's \"Canterbury Tales\", although Chaucer had prologues to many of the tales, rather than one at the front of the book.\n\n\n"}
{"id": "25234", "url": "https://en.wikipedia.org/wiki?curid=25234", "title": "Quadrivium", "text": "Quadrivium\n\nThe quadrivium (plural: quadrivia) is the four subjects, or arts, taught after teaching the trivium. The word is Latin, meaning \"four ways\", and its use for the four subjects has been attributed to Boethius or Cassiodorus in the 6th century. Together, the trivium and the quadrivium comprised the seven liberal arts (based on thinking skills), as distinguished from the practical arts (such as medicine and architecture).\n\nThe quadrivium consisted of arithmetic, geometry, music, and astronomy. These followed the preparatory work of the trivium, consisting of grammar, logic, and rhetoric. In turn, the quadrivium was considered preparatory work for the study of philosophy (sometimes called the \"liberal art \"par excellence\"\") and theology.\n\nThese four studies compose the secondary part of the curriculum outlined by Plato in \"The Republic\" and are described in the seventh book of that work (in the order Arithmetic, Geometry, Astronomy, Music). \nThe quadrivium is implicit in early Pythagorean writings and in the \"De nuptiis\" of Martianus Capella, although the term \"quadrivium\" was not used until Boethius, early in the sixth century. As Proclus wrote:\nThe Pythagoreans considered all mathematical science to be divided into four parts: one half they marked off as concerned with quantity, the other half with magnitude; and each of these they posited as twofold. A quantity can be considered in regard to its character by itself or in its relation to another quantity, magnitudes as either stationary or in motion. Arithmetic, then, studies quantities as such, music the relations between quantities, geometry magnitude at rest, spherics [astronomy] magnitude inherently moving.\nAt many medieval universities, this would have been the course leading to the degree of Master of Arts (after the BA). After the MA, the student could enter for bachelor's degrees of the higher faculties (Theology, Medicine or Law). To this day, some of the postgraduate degree courses lead to the degree of Bachelor (the B.Phil and B.Litt. degrees are examples in the field of philosophy).\n\nThe study was eclectic, approaching the philosophical objectives sought by considering it from each aspect of the quadrivium within the general structure demonstrated by Proclus (AD 412–485), namely arithmetic and music on the one hand and geometry and cosmology on the other.\n\nThe subject of music within the quadrivium was originally the classical subject of harmonics, in particular the study of the proportions between the musical intervals created by the division of a monochord. A relationship to music as actually practised was not part of this study, but the framework of classical harmonics would substantially influence the content and structure of music theory as practised in both European and Islamic cultures.\n\nIn modern applications of the liberal arts as curriculum in colleges or universities, the quadrivium may be considered to be the study of number and its relationship to space or time: arithmetic was pure number, geometry was number in space, music was number in time, and astronomy was number in space and time. Morris Kline classified the four elements of the quadrivium as pure (arithmetic), stationary (geometry), moving (astronomy), and applied (music) number.\n\nThis schema is sometimes referred to as \"classical education\", but it is more accurately a development of the 12th- and 13th-century Renaissance with recovered classical elements, rather than an organic growth from the educational systems of antiquity. The term continues to be used by the Classical education movement and at the independent Oundle School, in the United Kingdom.\n\n"}
{"id": "25535894", "url": "https://en.wikipedia.org/wiki?curid=25535894", "title": "Repatriation and reburial of human remains", "text": "Repatriation and reburial of human remains\n\nThe repatriation and reburial of human remains is a current debate in archaeology. Various indigenous peoples around the world, such as Native Americans and Indigenous Australians have requested that human remains from their respective communities be repatriated for reburial. A famous case is that of the Kennewick Man in the United States. Similarly, contemporary Druids have requested the reburial of ancient human remains in the British Isles.\n\nRepatriation in general seems to be concerned with objects, in the broadest sense of the word, ranging from human remains to art repatriation. But it actually is about people in the present and their perception of the past in the present. Repatriation claims are linked to politics, ethnic identity, and other debates or problems in contemporary society that have or claim to have a historical link to the object.\n\nThe controversy comes from the fact that some believe that it is disrespectful to the dead and to their contemporary descendants for their remains to be displayed in a museum or stored in other ways.\n\nThe first and foremost undercurrent of repatriation is the ill treatment of people in the past, the repatriation of human remains is to a degree part of a healing process bandaging the traumas of history. In essence it is important that this ill treatment is addressed but with the repatriation and reburial of remains they are essentially lost to the world as a reminder of that part of the object's history or biography. Repatriation also presents an opportunity for people to lay claim to their own past and actively decide what is and what is not a part of their cultural heritage. The basis beneath the open wounds of history is the difference in treatment of remains that were seen as sufficiently other and could therefore be studied without any ethical considerations.\n\nThe contesting of ownership of human remains in museums and other institutions, and demands of return to cultural groups is largely fuelled by the difference in the handling of ‘white’ and indigenous remains. Where the former were reburied the latter were subjects of study and eventually ending up in museums. In a sense one cultural group assumed the right to carry out scientific research upon another cultural group. This disrespectful unequal treatment stems from a time when race and cultural differences had huge social implications. These are changing but the aftermath of centuries of inequality cannot be corrected so easily. This frustration is what partly fuels the repatriation and ownership claims that seem to have increased in the last 30 years. The “traumas of history” can be addressed by reconciliation, repatriation and formal governmental apologies disapproving of conducts in the past by the institutions they now represent. A good example of a repatriation case is described by Thorton where a large group of massacred Indians is returned to their tribe, showing the healing power of the repatriation gesture.\n\nThe Neo-druidic movement is a modern religion, with some groups originating in the 18th century and others in the 20th century. They are generally inspired by either Victorian-era ideas of the druids of the Iron Age, or later neopagan movements. Some practice ancestor veneration, and because of this may believe that they have a responsibility to care for the ancient dead where they now live. In 2006 Paul Davies requested that the Alexander Keiller Museum in Avebury, Wiltshire rebury their Neolithic human remains, and that storing and displaying them was \"immoral and disrespectful\". The National Trust refused to allow reburial, but did allow for Neo-druids to perform a healing ritual in the museum.\n\nThe archaeological community has voiced criticism of the Neo-druids, making statements such as \"no single modern ethnic group or cult should be allowed to appropriate our ancestors for their own agendas. It is for the international scientific community to curate such remains.\" An argument proposed by archaeologists is that, \n\"Druids are not the only people who have feelings about human remains... We don't know much about the religious beliefs of these [Prehistoric] people, but know that they wanted to be remembered, their stories, mounds and monuments show this. Their families have long gone, taking all memory with them, and we archaeologists, by bringing them back into the world, are perhaps the nearest they have to kin. We care about them, spending our lives trying to turn their bones back into people... The more we know the better we can remember them. Reburying human remains destroys people and casts them into oblivion: this is at best, misguided, and at worse cruel.\"\n\n"}
{"id": "914436", "url": "https://en.wikipedia.org/wiki?curid=914436", "title": "Shield-maiden", "text": "Shield-maiden\n\nA shield-maiden (), in Scandinavian folklore and mythology was a female warrior. They are often mentioned in sagas such as \"Hervarar saga ok Heiðreks\" and in \"Gesta Danorum\". Shield-maidens also appear in stories of other Germanic peoples: Goths, Cimbri, and Marcomanni. The mythical valkyries may have been based on the shield-maidens.\n\nThe historical existence of shield-maidens is heavily debated, but scholars including Neil Price, argue that they existed while others, like scholar Judith Jesch disagree, citing a lack of hard evidence for trained or regular women warriors.\n\nThere are few historic attestations that Viking Age women took part in warfare, but the Byzantine historian John Skylitzes records that women fought in battle when Sviatoslav I of Kiev attacked the Byzantines in Bulgaria in 971. When the Varangians (not to be confused with the Byzantine Varangian Guard) had suffered a devastating defeat in the Siege of Dorostolon, the victors were stunned at discovering armed women among the fallen warriors.\n\nWhen Leif Erikson's pregnant half-sister Freydís Eiríksdóttir was in Vinland, she is reported to have taken up a sword, and, bare-breasted, scared away the attacking Skrælings. The fight is recounted in the \"Greenland saga\", though Freydís is not explicitly referred to as a shield-maiden in the text.\n\nSaxo Grammaticus reported that shield-maidens fought on the side of the Danes at the Battle of Brávellir in the year 750:\nExamples of shield-maidens mentioned by name in the Norse sagas include Brynhildr in the \"Vǫlsunga saga\", Hervor in \"Hervarar saga ok Heiðreks\", the Brynhildr of the \"Bósa saga ok Herrauðs\", the Swedish princess Thornbjǫrg in \"Hrólfs saga Gautrekssonar\" and Princess Hed, Visna and Veborg in \"Gesta Danorum\".\n\nTwo shield-maidens appear in certain translations of the \"Hervarar saga\". The first of these Hervors was known to have taken up typically masculine roles early in her childhood and often raided travelers in the woods dressed as a man. Later in her life, she claimed the cursed sword Tyrfing from her father's burial site and became a seafaring raider. She eventually settled and married. Her granddaughter was also named Hervor and commanded forces against attacking Huns. Although the saga remarks on her bravery she is mortally wounded by enemy forces and dies on the battlefield. Scholars Judith Jesch and Jenny Jochens theorize that shield-maidens' often grim fates or their sudden return to typically female roles is a testament to their role as figures of both male and female fantasy as well as emblematic of the danger of abandoning gender roles.\n\nBrynhildr of the \"Vǫlsunga saga\", along with her rival in love, Guðrún Gjúkadóttir, provides an example of how a shield-maiden compares to more conventional aristocratic womanhood in the sagas. Brynhildr is chiefly concerned with honor, much like a male warrior. When she ends up married to Gudrun's brother Gunnarr instead of Sigurðr, the man she intended to marry, Brynhildr speaks a verse comparing the courage of the two men:\nBrynhildr is married to Gunnarr and not Sigurðr because of deceit and trickery, including a potion of forgetfulness given to Sigurðr so he forgets his previous relationship with her. Brynhildr is upset not only for the loss of Sigurðr but also for the dishonesty involved. Similar to her male counterparts, the shield-maiden prefers to do things straightforwardly, without the deception considered stereotypically feminine in much of medieval literature. She enacts her vengeance directly, resulting in the deaths of herself, Sigurðr, and Sigurð's son by Guðrún. By killing the child, she demonstrates an understanding of feud and filial responsibility; if he lived, the boy would grow up to take vengeance on Brynhildr's family.\n\nGuðrún has a similar concern with family ties, but at first does not usually act directly. She is more inclined to incite her male relatives to action than take up arms herself. Guðrún is no shield-maiden, and Brynhildr mocks her for this, saying, \"Only ask what is best for you to know. That is suitable for noble women. And it is easy to be satisfied while everything happens according to your desires.\" In her later marriages, however, she is willing to kill her children, burn down a hall, and send her other sons to avenge the murder of her daughter, Svanhildr. In the world of the sagas, women can be both honorable and remorseless, much like the male heroes. While a shield-maiden does not fill a woman's typical role, her strength of character is found in even the more domestic women in these stories.\n\nGraves of female settlers containing weapons have been uncovered, but scholars do not agree how these should be interpreted. Norse immigrant graves in England and chemical analysis of the remains suggested a somewhat equal distribution of men and women, suggesting husbands and wives, while some of the women were buried with weapons. In a tie-in special to the TV series \"Vikings\" Neil Price showed that a 10th Century Birka-burial excavated in the 1970s containing a large number of weapons and the bones of two horses turned out to be the grave of a woman upon bone analysis by Anna Kjellström. In 2017, DNA analysis confirmed that the person was female; the so called Birka female Viking warrior, but others including respected scholar of the Vikings, Judith Jesch says that conclusion is premature. \n\nWhile women warriors are a staple of fantasy, they are not often referred to as shield-maidens. Some who are include Éowyn in J. R. R. Tolkien's \"The Lord of the Rings\" and Thorgil in Nancy Farmer's \"The Sea of Trolls\" trilogy.\n\nIn the 2013 TV series \"Vikings\", the legendary Viking shield-maiden Lagertha, played by Katheryn Winnick, is a principal character.\n\n"}
{"id": "28937240", "url": "https://en.wikipedia.org/wiki?curid=28937240", "title": "Strauss–Howe generational theory", "text": "Strauss–Howe generational theory\n\nThe Strauss–Howe generational theory, also known as the Fourth Turning theory or simply the Fourth Turning, which was created by authors William Strauss and Neil Howe, describes a theorized recurring generation cycle in American history. \n\nAccording to the theory, historical events are associated with recurring generational personas (Archetype). These generational personas unleash a new era (called a turning) in which a new social, political, and economic climate exists. These successive eras (turnings) tend to last around 20–22 years. \n\nThese eras are then part of a larger cyclical \"saeculum\" (a long human life, which usually spans between 80–90 years, although some \"saecula\" have lasted longer).\n\nThe theory states that after every Saeculum, a crisis recurs in American history, which is followed by a recovery (high).\n\nDuring this recovery, institutions and communitarian values are strong. Ultimately, succeeding generational archetypes attack and weaken institutions in the name of autonomy and individualism, which ultimately creates a tumultuous political environment that ripens conditions for another crisis. \n\nStrauss and Howe laid the groundwork for their theory in their 1991 book \"Generations\", which discusses the history of the United States as a series of generational biographies going back to 1584. In their 1997 book \"The Fourth Turning\", the authors expanded the theory to focus on a fourfold cycle of generational types and recurring mood eras in American history. They have since expanded on the concept in a variety of publications.\n\nThe theory was developed to describe the history of the United States, including the Thirteen Colonies and their British antecedents, and this is where the most detailed research has been done. However, the authors have also examined generational trends elsewhere in the world and described similar cycles in several developed countries.\n\nIn a 2009 article published in \"The Chronicle of Higher Education\", Eric Hoover called the authors pioneers in a burgeoning industry of consultants, speakers and researchers focused on generations. Academic response to the theory has been mixed—some applauding Strauss and Howe for their \"bold and imaginative thesis\" and others criticizing the theory. Criticism has focused on the lack of rigorous empirical evidence for their claims, and a perception that aspects of the argument gloss over real differences within the population.\n\nWilliam Strauss and Neil Howe's partnership began in the late 1980s when they began writing their first book \"Generations\", which discusses the history of the United States as a succession of generational biographies. Each had written on generational topics: Strauss on Baby Boomers and the Vietnam War draft, and Howe on the G.I. Generation and federal entitlement programs. Strauss co-wrote two books with Lawrence Baskir about how the Vietnam War affected the Baby Boomers (\"Chance and Circumstance: The Draft the War and The Vietnam Generation\" (1978) and \"Reconciliation after Vietnam\" (1977)). Neil Howe studied what he believed to be the US's entitlement attitude of the 1980s and co-authored \"On Borrowed Time: How America's entitlement ego puts America's future at risk of Bankruptcy\" in 1988 with Peter George Peterson. The authors' interest in generations as a broader topic emerged after they met in Washington, D.C., and began discussing the connections between each of their previous works.\n\nThey wondered why Boomers and G.I.s had developed such different ways of looking at the world, and what it was about these generations’ experiences growing up that prompted their different outlooks. They also wondered whether any previous generations had acted along similar lines, and their research discussed historical analogues to the current generations. The two ultimately described a recurring pattern in Anglo-American history of four generational types, each with a distinct collective persona, and a corresponding cycle of four different types of era, each with a distinct mood. The groundwork for this theory was laid out in \"Generations\" in 1991. Strauss and Howe expanded on their theory and updated the terminology in \"The Fourth Turning\" in 1997. \"Generations\" helped popularize the idea that people in a particular age group tend to share a distinct set of beliefs, attitudes, values and behaviors because they all grow up and come of age during a particular period in history.\n\nIn their books \"Generations\" (1991) and \"The Fourth Turning\" (1997), Strauss and Howe discussed the generation gap between Baby Boomers and their parents and predicted there would be no such generation gap between Millennials and their elders. In 2000, they published \"Millennials Rising\". A 2000 \"New York Times\" book review for this book titled: \"What's the Matter With Kids Today? Not a Thing\", described the message of \"Millennials Rising\" as “we boomers are raising a cohort of kids who are smarter, more industrious and better behaved than any generation before”, saying the book complimented the Baby Boomer cohort by complimenting their parenting skills.\n\nIn the mid-1990s, the authors began receiving inquiries about how their generational research could be applied to strategic problems in organizations. Strauss and Howe were quickly established as pioneers in a growing field, and started speaking frequently about their work at events and conferences. In 1999, Strauss and Howe founded LifeCourse Associates, a publishing, speaking and consulting company built on their generational theory. As LifeCourse partners, they have offered keynote speeches, consulting services, and customized communications to corporate, nonprofit, government, and education clients. They have also written six books in which they assert that the Millennial Generation is transforming various sectors, including schools, colleges, entertainment, and the workplace. \n\nOn December 18, 2007, William Strauss died at the age of 60 from pancreatic cancer. Neil Howe continues to expand LifeCourse Associates and to write books and articles on a variety of generational topics. Each year Mr. Howe gives about 60 speeches, often followed by customized workshops, at colleges, elementary schools, and corporations. Neil Howe is a public policy adviser to the Blackstone Group, senior adviser to the Concord Coalition, and senior associate to the Center for Strategic and International Studies.\n\nSteve Bannon, former Chief Strategist and Senior Counselor to President Trump is a prominent proponent of the theory. As a documentary filmmaker Bannon discussed the details of Strauss–Howe generational theory in \"Generation Zero\". According to historian David Kaiser, who was consulted for the film, \"Generation Zero\" “focused on the key aspect of their theory, the idea that every 80 years American history has been marked by a crisis, or 'fourth turning', that destroyed an old order and created a new one”. Kaiser said Bannon is \"very familiar with Strauss and Howe’s theory of crisis, and has been thinking about how to use it to achieve particular goals for quite a while.\" A February 2017 article from \"Business Insider\" titled: \"Steve Bannon's obsession with a dark theory of history should be worrisome\", commented: \"Bannon seems to be trying to bring about the 'Fourth Turning'.\"\n\nStrauss and Howe's work combines history with prophecy. They provided historical information regarding living and past generations and made various predictions. Many of their predictions were regarding the Millennial Generation, who were young children when they began their work, thus lacking significant historical data. In their first book \"Generations\" (1991), Strauss and Howe describe the history of the US as a succession of Anglo-American generational biographies from 1584 to the present, and they describe a theorized recurring generational cycle in American history. The authors posit a pattern of four repeating phases, generational types and a recurring cycle of spiritual awakenings and secular crises, from the founding colonials of America through the present day.\n\nStrauss and Howe followed in 1993 with their second book \"13th Gen: Abort, Retry, Ignore, Fail?\", which was published while Gen Xers were young adults. The book examines the generation born between 1961 and 1981, \"Gen-Xers\" (which they called \"13ers\", describing them as the thirteenth generation since the US became a nation). The book asserts that 13ers' location in history as under protected children during the Consciousness Revolution explains their pragmatic attitude. They describe Gen Xers as growing up during a time when society was less focused on children and more focused on adults and their self-actualization.\n\nIn 1997, the authors published \"The Fourth Turning: An American Prophecy,\" which expanded on the ideas presented in \"Generations\" and extended their cycles back into the early 15th century. The authors began the use of more colorful names for generational archetypes - e.g. \"Civics\" became \"Heroes\" (which they applied to the Millennial Generation), \"Adaptives\" became \"Artists\" - and of the terms \"Turning\" and \"Saeculum\" for the generational cycles. The title is a reference to what their first book called a Crisis period, which they expected to recur soon after the turn of the millennium.\n\nIn 2000, the two authors published \"Millennials Rising: The Next Great Generation\". This work discussed the personality of the Millennial Generation, whose oldest members were described as the high school graduating class of the year 2000. In this 2000 book, Strauss and Howe asserted that Millennial teens and young adults were recasting the image of youth from \"downbeat and alienated to upbeat and engaged\". They credited increased parental attention and protection for these positive changes. They asserted Millennials are held to higher standards than adults apply to themselves and that they're a lot less vulgar and violent than the teen culture older people produce for them. They described them as less sexually charged and as ushering in a new sexual modesty, with increasing belief that sex should be saved for marriage and a return to conservative family values. They predicted that over the following decade, Millennials would transform what it means to be young. According to the authors, Millennials could emerge as the next \"Great Generation\". The book was described as an optimistic, feel-good book for the parents of the Millennial Generation, predominantly the Baby Boomers.\n\nStrauss and Howe define a social generation as the aggregate of all people born over a span of roughly twenty years or about the length of one phase of life: childhood, young adulthood, midlife, and old age. Generations are identified (from first birthyear to last) by looking for cohort groups of this length that share three criteria. First, members of a generation share what the authors call an \"age location in history\": they encounter key historical events and social trends while occupying the same phase of life. In this view, members of a generation are shaped in lasting ways by the eras they encounter as children and young adults and they share certain common \"beliefs and behaviors\". Aware of the experiences and traits that they share with their peers, members of a generation would also share a sense of common \"perceived membership\" in that generation.\n\nStrauss and Howe say they based their definition of a generation on the work of various writers and social thinkers, from ancient writers such as Polybius and Ibn Khaldun to modern social theorists such as José Ortega y Gasset, Karl Mannheim, John Stuart Mill, Émile Littré, Auguste Comte, and François Mentré.\n\nWhile writing \"Generations\", Strauss and Howe described a theorized pattern in the historical generations they examined, which they say revolved around generational events which they call turnings. In \"Generations\", and in greater detail in \"The Fourth Turning\", they describe a four-stage cycle of social or mood eras which they call \"turnings\". The turnings include: \"The High\", \"The Awakening\", \"The Unraveling\" and \"The Crisis\".\n\nAccording to Strauss and Howe, the First Turning is a High, which occurs after a Crisis. During \"The High\" institutions are strong and individualism is weak. Society is confident about where it wants to go collectively, though those outside the majoritarian center often feel stifled by the conformity.\n\nAccording to the authors, the most recent First Turning in the US was the post–World War II American High, beginning in 1946 and ending with the assassination of John F. Kennedy on November 22, 1963.\n\nAccording to the theory, the Second Turning is an Awakening. This is an era when institutions are attacked in the name of personal and spiritual autonomy. Just when society is reaching its high tide of public progress, people suddenly tire of social discipline and want to recapture a sense of \"self-awareness\", \"spirituality\" and \"personal authenticity\". Young activists look back at the previous High as an era of cultural and spiritual poverty.\n\nStrauss & Howe say the US's most recent Awakening was the “Consciousness Revolution,” which spanned from the campus and inner-city revolts of the mid-1960s to the tax revolts of the early 1980s.\n\nAccording to Strauss and Howe, the Third Turning is an Unraveling. The mood of this era they say is in many ways the opposite of a High: Institutions are weak and distrusted, while individualism is strong and flourishing. The authors say Highs come after Crises, when society wants to coalesce and build and avoid the death and destruction of the previous crisis. Unravelings come after Awakenings, when society wants to atomize and enjoy. They say the most recent Unraveling in the US began in the 1980s and includes the Long Boom and Culture War.\n\nAccording to the authors, the Fourth Turning is a Crisis. This is an era of destruction, often involving war or revolution, in which institutional life is destroyed and rebuilt in response to a perceived threat to the nation's survival. After the crisis, civic authority revives, cultural expression redirects towards community purpose, and people begin to locate themselves as members of a larger group.\n\nThe authors say the previous Fourth Turning in the US began with the Wall Street Crash of 1929 and climaxed with the end of World War II. The G.I. Generation (which they call a Hero archetype, born 1901 to 1924) came of age during this era. They say their confidence, optimism, and collective outlook epitomized the mood of that era. The authors assert the Millennial Generation (which they also describe as a Hero archetype, born 1982 to 2004) show many similar traits to those of the G.I. youth, which they describe as including: rising civic engagement, improving behavior, and collective confidence.\n\nThe authors describe each turning as lasting about 20–22 years. Four turnings make up a full cycle of about 80 to 90 years, which the authors term a \"saeculum\", after the Latin word meaning both \"a long human life\" and \"a natural century\".\n\nGenerational change drives the cycle of turnings and determines its periodicity. As each generation ages into the next life phase (and a new social role) society’s mood and behavior fundamentally changes, giving rise to a new turning. Therefore, a symbiotic relationship exists between historical events and generational personas. Historical events shape generations in childhood and young adulthood; then, as parents and leaders in midlife and old age, generations in turn shape history.\n\nEach of the four turnings has a distinct mood that recurs every saeculum. Strauss and Howe describe these turnings as the \"seasons of history\". At one extreme is the Awakening, which is analogous to summer, and at the other extreme is the Crisis, which is analogous to winter. The turnings in between are transitional seasons, similar to autumn and spring. Strauss and Howe have discussed 26 theorized turnings over 7 saecula in Anglo-American history, from the year 1435 through today.\n\nAt the heart of Strauss & Howe's ideas is a basic alternation between two different types of eras, Crises and Awakenings. Both of these are defining eras in which people observe that historic events are radically altering their social environment. Crises are periods marked by major secular upheaval, when society focuses on reorganizing the outer world of institutions and public behavior (they say the last American Crisis was the period spanning the Great Depression and World War II). Awakenings are periods marked by cultural or religious renewal, when society focuses on changing the inner world of values and private behavior (the last American Awakening was the \"Consciousness Revolution\" of the 1960s and 1970s).\n\nDuring Crises, great peril provokes a societal consensus, an ethic of personal sacrifice, and strong institutional order. During Awakenings, an ethic of individualism emerges, and the institutional order is attacked by new social ideals and spiritual agendas. According to the authors, about every eighty to ninety years—the length of a long human life—a national Crisis occurs in American society. Roughly halfway to the next Crisis, a cultural Awakening occurs (historically, these have often been called Great Awakenings).\n\nIn describing this cycle of Crises and Awakenings, Strauss and Howe draw from the work of other historians and social scientists who have also discussed long cycles in American and European history. The Strauss–Howe cycle of Crises corresponds with long cycles of war identified by such scholars as Arnold J. Toynbee, Quincy Wright, and L. L. Ferrar Jr., and with geopolitical cycles identified by William R. Thompson and George Modelski. Strauss and Howe say their cycle of Awakenings corresponds with Anthony Wallace's work on revitalization movements; they also say recurring Crises and Awakenings correspond with two-stroke cycles in politics (Walter Dean Burnham, Arthur Schlesinger Sr. and Jr.), foreign affairs (Frank L. Klingberg), and the economy (Nikolai Kondratieff) as well as with long-term oscillations in crime and substance abuse.\n\nThe authors say two different types of eras and two formative age locations associated with them (childhood and young adulthood) produce four generational \"archetypes\" that repeat sequentially, in rhythm with the cycle of Crises and Awakenings. In \"Generations\", Strauss and Howe refer to these four archetypes as \"Idealist, Reactive, Civic,\" and \"Adaptive\". In \"The Fourth Turning\" (1997) they change this terminology to \"Prophet, Nomad, Hero,\" and \"Artist\". They say the generations in each archetype not only share a similar age-location in history, they also share some basic attitudes towards family, risk, culture and values, and civic engagement. In essence, generations shaped by similar early-life experiences develop similar collective personas and follow similar life-trajectories. To date, Strauss and Howe have described 25 generations in Anglo-American history, each with a corresponding archetype. The authors describe the archetypes as follows:\n\nProphet (Idealist) generations enter childhood \"during a High\", a time of rejuvenated community life and consensus around a new societal order. Prophets grow up as the increasingly indulged children of this post-Crisis era, come of age as self-absorbed young crusaders of an Awakening, focus on morals and principles in midlife, and emerge as elders guiding another Crisis. Examples: Transcendental Generation, Missionary Generation, Baby Boomers.\n\nFamous prophets: Abraham Lincoln and Franklin Delano Roosevelt\n\nNomad (Reactive) generations enter childhood \"during an Awakening\", a time of social ideals and spiritual agendas, when young adults are passionately attacking the established institutional order. Nomads grow up as under-protected children during this Awakening, come of age as alienated, post-Awakening adults, become pragmatic midlife leaders during a Crisis, and age into resilient post-Crisis elders. Examples: Gilded Generation, Lost Generation, Generation X\n\nFamous Nomads: John D Rockefeller and Jeff Bezos\n\nHero (Civic) generations enter childhood \"after an Awakening\", \"during an Unraveling\", a time of individual pragmatism, self-reliance, and laissez-faire. Heroes grow up as increasingly protected post-Awakening children, come of age as team-oriented young optimists during a Crisis, emerge as energetic, overly-confident midlifers, and age into politically powerful elders attacked by another Awakening. Examples: G.I. Generation, Millennials\n\nFamous Heroes: Thomas Jefferson and John F Kennedy\n\nArtist (Adaptive) generations enter childhood \"after an Unraveling,\" \"during a Crisis\", a time when great dangers cut down social and political complexity in favor of public consensus, aggressive institutions, and an ethic of personal sacrifice. Artists grow up overprotected by adults preoccupied with the Crisis, come of age as the socialized and conformist young adults of a post-Crisis world, break out as process-oriented midlife leaders during an Awakening, and age into thoughtful post-Awakening elders. Examples: Silent Generation, Homelanders\n\nFamous Artists: Martin Luther King Jr and Theodore Roosevelt\n\n\nNote (0): Strauss and Howe base the turning start and end dates not on the generational birth year span, but when the prior generation is entering adulthood. A generation \"coming of age\" is signaled by a \"triggering event\" that marks the turning point and the ending of one turning and the beginning of the new. For example, the \"triggering event\" that marked the coming of age for the Baby Boom Generation was the Assassination of John F. Kennedy. This marked the end of a first turning and the beginning of a second turning. This is why turning start and end dates don't match up exactly with the generational birth years, but they tend to start and end a few years after the generational year spans. This also explains why a generation is described to have \"entered childhood\" during a particular turning, rather than \"born during\" a particular turning.\n\nNote (1): According to Strauss and Howe their generational types have appeared in Anglo-American history in a fixed order for more than 500 years with one hitch, occurring in the Civil War Saeculum. They say the reason for this is because according to the chart, the Civil War came about ten years too early; the adult generations allowed the worst aspects of their generational personalities to come through; and the Progressives grew up scarred rather than ennobled.\n\nNote (2): Strauss and Howe initially used the name \"13th Generation\" in their book \"Generations\", which was published mere weeks before Douglas Coupland's \"\" was, but later adopted \"Generation X\" when it became the more widely accepted term for the cohort. The generation is so numbered because it is the thirteenth generation alive since American Independence (counting back until Benjamin Franklin's).\n\nNote (3): Although there is as yet no universally accepted name for this generation, \"Millennials\" (a name Strauss and Howe coined) has become the most widely accepted. Other names used in reference to it include Generation Y (as it is the generation following Generation X) and \"The Net Generation\".\n\nNote (4): New Silent Generation was a proposed holding name used by Howe and Strauss in their demographic history of America, \"Generations\", to describe the generation whose birth years began somewhere in the mid-2000s and the ending point will be around the mid-2020s. Howe now refers to this generation (most likely currently being born) as the Homeland Generation.\n\nNote (5): There is no consistent agreement among participants on the Fourth Turning message board that 9/11 and the War on Terror lie fully within a Crisis era. The absence of any attempt to constrict consumer spending through taxes or rationing and the tax cuts of the time suggest that any Crisis Era may have begun, if at all, later, as after Hurricane Katrina or the Financial Meltdown of 2008.\n\nThe basic length of both generations and turnings—about twenty years—derives from longstanding socially and biologically determined phases of life. This is the reason it has remained relatively constant over centuries. Some have argued that rapid increases in technology in recent decades are shortening the length of a generation. According to Strauss and Howe, however, this is not the case. As long as the transition to adulthood occurs around age 20, the transition to midlife around age 40, and the transition to old age around age 60, they say the basic length of both generations and turnings will remain the same.\n\nIn their book, The Fourth Turning, however, Strauss and Howe say that the precise boundaries of generations and turnings are erratic. The generational rhythm is not like certain simple, inorganic cycles in physics or astronomy, where time and periodicity can be predicted to the second. Instead, it resembles the complex, organic cycles of biology, where basic intervals endure but precise timing is difficult to predict. Strauss and Howe compare the saecular rhythm to the four seasons, which they say similarly occur in the same order, but with slightly varying timing. Just as winter may come sooner or later, and be more or less severe in any given year, the same is true of a Fourth Turning in any given saeculum.\n\nAccording to Strauss and Howe, there are many potential threats that could feed a growing sense of public urgency as the Fourth Turning progresses, including a terrorist attack, a financial collapse, a major war, a crisis of nuclear proliferation, an environmental crisis, an energy shortage, or new civil wars. The generational cycle cannot explain the role or timing of these individual threats. Nor can it account for the great events of history, like the bombing of Pearl Harbor, President Kennedy’s assassination, or 9/11. What the generational cycle can do, according to Strauss and Howe, is explain how society is likely to respond to these events in different eras. It is the response, not the initial event, which defines an era according to the theory. According to Strauss and Howe, the crisis period lasts for approximately 20 years.\n\nThe Strauss and Howe retelling of history through a generational lens has received mixed reviews. Many reviewers have praised the authors' books and theory for their ambition, erudition and accessibility. Former U.S Vice President Al Gore (who graduated from Harvard University with Mr. Strauss) called \"Generations: The History of America's Future, 1584 to 2069\" the most stimulating book on American history he'd ever read. He even sent a copy to each member of Congress. The theory has been influential in the fields of generational studies, marketing, and business management literature. However, it has also been criticized by several historians and some political scientists and journalists, as being overly-deterministic, non-falsifiable, and unsupported by rigorous evidence.\n\nAfter the publication of their first book \"Generations\", Martin Keller, professor of history at Brandeis University, said that the authors \"had done their homework\". He said that their theory could be seen as pop-sociology and that it would \"come in for a lot more criticism as history. But it's almost always true that the broader you cast your net, the more holes it's going to have. And I admire [the authors'] boldness.\" Harvard sociologist David Riesman said the book showed an \"impressive grasp of a great many theoretical and historical bits and pieces\". \"The Times Literary Supplement\" called it \"fascinating,\" but also, \"about as vague and plausible as astrological predictions.\" \"Publishers Weekly\", though, called \"Generations\" \"as woolly as a newspaper horoscope\".\n\nIn his review for the \"Boston Globe\", historian David Kaiser called \"The Fourth Turning\" \"a provocative and immensely entertaining outline of American history\". \"Strauss and Howe have taken a gamble\", argued Kaiser. \"If the United States calmly makes it to 2015, their work will end up in the ashcan of history, but if they are right, they will take their place among the great American prophets.\" Kaiser has since argued that Strauss and Howe's predictions of coming crisis seems to have occurred, citing events such as 9/11, the 2008 financial crisis, and the recent political gridlock.\n\nKaiser has incorporated Strauss and Howe's theory in two historical works of his own, \"American Tragedy: Kennedy, Johnson, and the Origins of the Vietnam War\" (2000), and \"No End Save Victory: How FDR Led the Nation into War\" (2014). \"New York Times\" book reviewer Michael Lind wrote that \"The Fourth Turning\" (1997) was vague and verged into the realm of pseudoscience. Lind said that the theory is essentially \"non-falsifiable\" and \"mystifying,\" although he believed the authors did have some insights into modern American history.\n\nIn 1993, Andrew Leonard reviewed the book \"13th Gen: Abort, Retry, Ignore, Fail?\". He wrote “as the authors (Strauss and Howe) relentlessly attack the iniquitous 'child-abusive culture' of the 1960s and '70s and exult in heaping insult after insult on their own generation -- they caricature Baby Boomers as countercultural, long-haired, sex-obsessed hedonists -- their real agenda begins to surface. That agenda becomes clear in part of their wish list for how the 13th generation may influence the future: \"13ers will reverse the frenzied and centrifugal cultural directions of their younger years. They will clean up entertainment, de-diversify the culture, reinvent core symbols of national unity, reaffirm rituals of family and neighborhood bonding, and re-erect barriers to cushion communities from unwanted upheaval.\"\n\nAgain in 1993, writing for \"The Globe and Mail\", Jim Cormier reviewed the same book: \"self-described boomers Howe and Strauss add no profound layer of analysis to previous pop press observations. But in cobbling together a more extensive overview of the problems and concerns of the group they call the 13ers, they've created a valuable primer for other fogeys who are feeling seriously out of touch.\" Cormier believed that the authors \"raised as many new questions as answers about the generation that doesn't want to be a generation. But at least they've made an honest, empathetic and good-humoured effort to bridge the bitter gap between the twentysomethings and fortysomethings.\"\n\nIn 1993, Charles Laurence at the \"London Daily Telegraph\" wrote that, in \"13th Gen,\" Strauss and Howe offered this youth generation \"a relatively neutral definition as the 13th American generation from the Founding Fathers,\". According to Alexander Ferron's review in \"Eye Magazine,\" \"\"13th Gen\" is best read as the work of two top-level historians. While its agenda is the 13th generation, it can also be seen as an incredibly well-written and exhaustive history of America from 1960 to 1981--examining the era through everything except the traditional historical subjects (war, politics, famine, etc).\"\n\nIn 2011, Jon D. Miller, at the Longitudinal Study of American Youth (funded by the National Science Foundation) wrote that Strauss and Howe's 1961 to 1981 birth year definition of \"Generation X\" (13th Gen) has been widely used in popular and academic literature.\n\nDavid Brooks reviewed the follow-up book about the next generation titled \"Millennials Rising\" (2000). \"Millennials\" is a term coined by Strauss and Howe. Brooks wrote: “This is not a good book, if by good you mean the kind of book in which the authors have rigorously sifted the evidence and carefully supported their assertions with data. But it is a very good bad book. It's stuffed with interesting nuggets. It's brightly written. And if you get away from the generational mumbo jumbo, it illuminates changes that really do seem to be taking place.” Further, Brooks wrote that the generations aren't treated equally: \"Basically, it sounds as if America has two greatest generations at either end of the age scale and two crummiest in the middle\".\n\nIn 2001, reviewer Dina Gomez wrote in \"NEA Today\" that Strauss and Howe make their case “convincingly,” with “intriguing analysis of popular culture.” While conceding that the book \"over-generalizes\", Gomez also argues that it is “hard to resist the book’s hopeful vision for our children and future.\"\n\n\"Millennials Rising\" ascribes seven \"core traits\" to the Millennial cohort, which are: special, sheltered, confident, team-oriented, conventional, pressured, and achieving. A 2009, \"Chronicle of Higher Education\" report commented Howe and Strauss based these core traits on a \"hodgepodge of anecdotes, statistics, and pop-culture references\" and on surveys of approximately 600 high-school seniors from Fairfax County, Virginia, an affluent county with median household income approximately twice the national average. The report described \"Millennials Rising\" as a \"good-news revolution\" making \"sweeping predictions\" and as describing Millennials as \"rule followers who were engaged, optimistic, and downright pleasant\", commenting the book gave educators and \"tens of millions of parents, a warm feeling. Who wouldn't want to hear that their kids are special?\"\n\nIn 1991, Jonathan Alter wrote in \"Newsweek\" that the book \"Generations\" was a \"provocative, erudite and engaging analysis of the rhythms of American life\". However, he believed it was also \"an elaborate historical horoscope that will never withstand scholarly scrutiny.\" He continued, \"these sequential 'peer personalities' are often silly, but the book provides reams of fresh evidence that American history is indeed cyclical, as Arthur Schlesinger Jr. and others have long argued.\" But he complained, \"The generational boundaries are plainly arbitrary. The authors lump together everyone born from 1943 through the end of 1960 (Baby Boomers), a group whose two extremes have little in common. And the predictions are facile and reckless.\" He concluded: \"However fun and informative, the truth about generational generalizations is that they're generally unsatisfactory.\" Arthur E. Levine, a former president of the Teachers College of Columbia University said \"Generational images are stereotypes. There are some differences that stand out, but there are more similarities between students of the past and the present. But if you wrote a book saying that, how interesting would it be?\"\n\nIn response to criticism that they stereotype or generalize all members of a generation the authors have said, \"We've never tried to say that any individual generation is going to be monochromatic. It'll obviously include all kinds of people. But as you look at generations as social units, we consider it to be at least as powerful and, in our view, far more powerful than other social groupings such as economic class, race, sex, religion and political parties.\"\n\nGerald Pershall wrote in 1991: \"\"Generations\" is guaranteed to attract pop history and pop social science buffs. Among professional historians, it faces a tougher sell. Period specialists will resist the idea that their period is akin to several others. Sweeping theories of history are long out of fashion in the halls of ivy, and the authors' lack of academic standing won't help their cause. Their generational quartet is \"just too wooden\" and \"just too neat,\" says one Yale historian. \"Prediction is for prophets,\" scoffed William McLoughlin (a former history professor at Brown), who said it is wrong to think that \"if you put enough data together and have enough charts and graphs, you've made history into a science.\" He also said the book might get a friendlier reception in sociology and political science departments than the science department.\n\nSociologist David Riesman and political scientist Richard Neustadt offered strong, if qualified, praise. Riesman found in the work an \"impressive grasp of a great many theoretical and historical bits and pieces\" and Neustadt said Strauss and Howe \"are asking damned important questions, and I honor them.\"\n\nIn 1991, professor and \"New York Times\" writer Jay Dolan critiqued \"Generations\" for not talking more about class, race and sex, to which Neil Howe replied that they \"are probably generalizations not even as effective as a generation to say something about how people think and behave. One of the things to understand is that most historians never look at history in terms of generations. They prefer to tell history as a seamless row of 55-year-old leaders who always tend to think and behave the same way -- but they don't and they never have. If you look at the way America's 55-year-old leaders were acting in the 1960s -- you know, the ebullient and confidence of the JFKs and LBJs and Hubert Humphreys -- and compare them with today's leaders in Congress -- the indecision, the lack of sure-footedness -- I think you would have to agree that 55-year-olds do not always act the same way and you're dealing with powerful generational forces at work that explain why one generation of war veterans, war heroes, and another generation which came of age in very different circumstances tend to have very different instincts about acting in the world.”\n\nResponding to criticisms in 1991, Bill Strauss accepted that some historians might not like their theory, which they presented as a new paradigm for looking at American history, that filled a need for a unifying vision of American history:\n\nIn 2006, Frank Giancola wrote an article in \"Human Resource Planning\" that stated \"the emphasis on generational differences is not generally borne out by empirical research, despite its popularity\".\n\nIn 2016 an article was published that explains the differences in generations, observed with the employer's position, through the development of working conditions, initiated by the employer. This development is due to the competition of firms on the job market for receiving more highly skilled workers. New working conditions as a product on the market have a classic product life-cycle and when they become widespread standard expectations of employees change accordingly.\n\nOne criticism of Strauss and Howe's theory, and the field of \"generational studies\" in general, is that conclusions are overly broad and do not reflect the reality of every person in each generation regardless of their race, color, national origin, religion, sex, age, disability, or genetic information For example, Hoover cited the case of Millennials by writing that \"commentators have tended to slap the Millennial label on white, affluent teenagers who accomplish great things as they grow up in the suburbs, who confront anxiety when applying to super-selective colleges, and who multitask with ease as their helicopter parents hover reassuringly above them. The label tends not to appear in renderings of teenagers who happen to be minorities, or poor, or who have never won a spelling bee. Nor does the term often refer to students from big cities and small towns that are nothing like Fairfax County, Va. Or who lack technological know-how. Or who struggle to complete high school. Or who never even consider college. Or who commit crimes. Or who suffer from too little parental support. Or who drop out of college. Aren't they Millennials, too?\"\n\nIn their 2000 book \"Millennials Rising\" Strauss and Howe brought attention to the Millennial children of immigrants in the United States, \"who face daunting challenges.\" They wrote \"one-third have no health insurance, live below the poverty line and live in overcrowded housing\".\n\nIn a 2017 article from \"Quartz\" two journalists commented on Strauss–Howe generational theory saying: \"the theory is too vague to be proven wrong, and has not been taken seriously by most professional historians. But it is superficially compelling, and plots out to some degree how America’s history has unfolded since its founding\".\n\n\n\n"}
{"id": "29192344", "url": "https://en.wikipedia.org/wiki?curid=29192344", "title": "Tragedy (event)", "text": "Tragedy (event)\n\nA tragedy is an event of great loss, usually of human life. Such an event is said to be \"tragic\". Traditionally the event would require \"some element of moral failure, some flaw in character, or some extraordinary combination of elements\" to be tragic.\n\nNot all death is considered a tragedy. Rather it is a precise set of symptoms surrounding the loss that define it as such. There are a variety of factors that define a death as \"tragic\".\n\nAn event in which a massive number of deaths occur may be seen as a tragedy. This can be re-enforced by media attention or other public outcry.\n\nA tragedy does not necessarily involve massive death. The death of a single person, e.g., a public figure or a child, may be seen as a tragedy. The person need not necessarily have been famous before death.\n\nGenerally, the label of \"tragedy\" is given to an event based on public perception. There are a number of factors that can make a death be considered a tragedy.\n\nThe scope of an event can affect the public view, and make it appear tragic. This can be the case whether the death toll is high, or if a single, unexpected death occurs in a well-beloved person.\n\nThe degree of attachment in the public eye may also impact whether or not the event is publicly labeled as a tragedy. For example, the unexpected death of a preparatory school student that receives heavy media attention may be seen as more tragic than that of a recidivist prisoner who is beaten to death by fellow inmates.\n\nA death may be viewed as a tragedy when it is premature in nature. An old person dying of old age is an expectation, but the death of a child or of a young, healthy adult that is not expected by others can be viewed as tragic.\n\nPublicity is a factor in making the public view an event as a tragedy. With publicity of a large number of deaths or even a single death, this plays on the emotions of the general public, and thereby impacts perception.\n\nThe range of coverage affects the number of people in whose eyes the event is viewed as tragic. While local coverage may garner sympathy from those in the hometown of the deceased, international coverage may lead the whole world to mourn.\n\nThe resulting consequences from one or more deaths can be seen as a tragedy. For example, if a large number of persons are killed in a terrorist attack, not only is life lost, but others may lose their sense of security, and this impacts the lives of others in other ways.\n\nThe long-term effects of an event can render it as tragic. Tragedies often have effects that shape those affected, and are remembered even long after, as they clearly impact the future for those involved. They may also be commemorated on anniversaries or whenever they otherwise come to mind. A public tragedy often leads to measures being taken to prevent similar tragic events in the future.\n\nThere are various ways tragedy can affect people.\n\nThe typical reaction to tragedy is heavy grief, followed by a slow recovery. Common feelings following a tragedy include sadness, depression, crying, blame, and guilt. Some people wonder what they did to deserve such suffering.\n\nFor some, their faith may be a source of comfort in the wake of tragedy.\n\n"}
