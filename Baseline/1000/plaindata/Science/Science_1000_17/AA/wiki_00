{"id": "7876216", "url": "https://en.wikipedia.org/wiki?curid=7876216", "title": "All About Radiation", "text": "All About Radiation\n\nAll About Radiation is one of the books by L. Ron Hubbard that form the canonical texts of Scientology, although it is no longer promoted by the Church of Scientology nor included in their \"Basics\" book canon. Its first printing was from HASI (Hubbard Association of Scientologists International) by way of the Speedwell Printing Company, Kent, England, 1957. Later editions were published by the Church of Scientology's in-house publisher Bridge Publications. It is controversial for its claims, amongst other things, that radiation poisoning and even cancer can be cured by courses of vitamins. There is no known cure for radiation poisoning and current medical practice is to provide palliative care until the symptoms subside or the patient dies.\n\nEarly printings of the book were credited on the cover as simply \"By a nuclear physicist and a medical doctor\", while subsequent ones credited L. Ron Hubbard as being the nuclear physicist and \"Medicus\" as being the doctor.\n\nBy the 1979 edition, the \"medical doctor\" was credited as being Richard Farley.\n\nIn the book's most recent edition, the book's authorship is attributed to Hubbard and Gene Denk and Farley R. Spink.\n\nThe book has gone through a number of printings since its initial run, and has undergone a few modifications over the years, mostly to remove controversial assertions made in the original lectures. As it is a fundamental Scientology tenet that Hubbard's works are considered immutable Standard Tech, not to be altered in any way, except by Hubbard himself, these changes are considered evidence to Freezone practitioners that the current Church alters the text. It is to be noted that the first part of the book is not by Hubbard and that the second part was not written by Hubbard but edited from four of his lectures given in April 1957 in London. These lectures are available since March 2005 with a transcription which makes it possible to see how the book text was edited from the lectures. The book was not reissued in June 2007 as part of the Golden Age of Knowledge program. Among the text removed from the book in later editions:\n\n\nDespite calling himself a nuclear physicist (some editions of the book even call him \"one of America's first nuclear physicists\" on the dustjacket), Hubbard was not a qualified physicist. His degree was from the unaccredited Sequoia University, a diploma mill. The one course in nuclear physics Hubbard took was in 1931 at George Washington University, whose records indicate that he scored an F in the course. Hubbard dropped out of school shortly thereafter, with a 2.28 grade point average.\n\nHubbard referred to himself as a nuclear physicist on many occasions in the 1950s, such as in the tape-recorded 1956 lecture \"A Postulate Out of a Golden Age\", where he not only claimed to be a nuclear physicist, but that he was offered (and turned down) a U.S. Government post as one. This comment has been edited out of the CD version of the lecture currently offered by the L. Ron Hubbard Classic Lectures series.\n\nIn February 1966, Hubbard defended his mail-order degree: \"I was a Ph.D., Sequoia's [sic] University and therefore a perfectly valid doctor under the laws of the State of California\". But only a month later, he announced: \"having reviewed the damage being done in our society with nuclear physics and psychiatry by persons calling themselves \"Doctor\" [I] do hereby resign in protest my university degree as a Doctor of philosophy (Ph. D.)\" \n\nThe final results of the Anderson Report in 1965 declared:\n\n\"The Board heard evidence from a highly qualified radiologist who has made a special study of radiation and its effects. He said that Hubbard's knowledge of radiation, as displayed by his writings in \"All About Radiation\", was the 'sort of knowledge that perhaps a boy who has read Intermediate Physics might, with a lot of misapprehensions and lack of understanding, demonstrate'... From this witness's evidence it is apparent that Hubbard is completely incompetent to deal with the subject of radiation and that his knowledge of nuclear physics is distorted, inaccurate, mistaken and negligible. No evidence was called which disputed in any way these conclusions.\" \n\n\n"}
{"id": "6600576", "url": "https://en.wikipedia.org/wiki?curid=6600576", "title": "Alternative cancer treatments", "text": "Alternative cancer treatments\n\nAlternative cancer treatments are alternative or complementary treatments for cancer that have not been approved by the government agencies responsible for the regulation of therapeutic goods. They include diet and exercise, chemicals, herbs, devices, and manual procedures. The treatments are not supported by evidence, either because no proper testing has been conducted, or because testing did not demonstrate statistically significant efficacy. Concerns have been raised about the safety of some of them. Some treatments that have been proposed in the past have been found in clinical trials to be useless or unsafe. Some of these obsolete or disproven treatments continue to be promoted, sold, and used. Promoting or marketing such treatments is illegal in most of the developed world including the United States and European Union.\n\nA distinction is typically made between complementary treatments which do not disrupt conventional medical treatment, and alternative treatments which may replace conventional treatment. \nAlternative cancer treatments are typically contrasted with experimental cancer treatments – which are treatments for which experimental testing is underway – and with complementary treatments, which are non-invasive practices used alongside other treatment. All approved chemotherapeutic cancer treatments were considered experimental cancer treatments before their safety and efficacy testing was completed.\n\nSince the 1940s, medical science has developed chemotherapy, radiation therapy, adjuvant therapy and the newer targeted therapies, as well as refined surgical techniques for removing cancer. Before the development of these modern, evidence-based treatments, 90% of cancer patients died within five years. With modern mainstream treatments, only 34% of cancer patients die within five years. However, while mainstream forms of cancer treatment generally prolong life or permanently cure cancer, most treatments also have side effects ranging from unpleasant to fatal, such as pain, blood clots, fatigue, and infection. These side effects and the lack of a guarantee that treatment will be successful create appeal for alternative treatments for cancer, which purport to cause fewer side effects or to increase survival rates despite evidence to suggest a 2–5 fold increase in death with alternative medicines.\n\nAlternative cancer treatments have typically not undergone properly conducted, well-designed clinical trials, or the results have not been published due to publication bias (a refusal to publish results of a treatment outside that journal's focus area, guidelines or approach). Among those that have been published, the methodology is often poor. A 2006 systematic review of 214 articles covering 198 clinical trials of alternative cancer treatments concluded that almost none conducted dose-ranging studies, which are necessary to ensure that the patients are being given a useful amount of the treatment. These kinds of treatments appear and vanish frequently, and have throughout history.\n\nComplementary and alternative cancer treatments are often grouped together, in part because of the adoption of the phrase \"complementary and alternative medicine\" by the United States Congress. However, according to Barrie R. Cassileth, in cancer treatment the distinction between complementary and alternative therapies is \"crucial\".\n\nComplementary treatments are used in conjunction with proven mainstream treatments. They tend to be pleasant for the patient, not involve substances with any pharmacological effects, inexpensive, and intended to treat side effects rather than to kill cancer cells. Medical massage and self-hypnosis to treat pain are examples of complementary treatments.\n\nAbout half the practitioners who dispense complementary treatments are physicians, although they tend to be generalists rather than oncologists. As many as 60% of American physicians have referred their patients to a complementary practitioner for some purpose.\n\nAlternative treatments, by contrast, are used in place of mainstream treatments. The most popular alternative cancer therapies include restrictive diets, mind-body interventions, bioelectromagnetics, nutritional supplements, and herbs. The popularity and prevalence of different treatments varies widely by region. While conventional physicians should always be kept aware of any complementary treatments used by a patient, many physicians in the United Kingdom are at least tolerant of their use, and some might recommend them.\n\nSurvey data about how many cancer patients use alternative or complementary therapies vary from nation to nation as well as from region to region. A 2000 study published by the \"European Journal of Cancer\" evaluated a sample of 1023 women from a British cancer registry suffering from breast cancer and found that 22.4% had consulted with a practitioner of complementary therapies in the previous twelve months. The study concluded that the patients had spent many thousands of pounds on such measures and that use \"of practitioners of complementary therapies following diagnosis is a significant and possibly growing phenomenon\".\n\nIn Australia, one study reported that 46% of children suffering from cancer have been treated with at least one non-traditional therapy. Further 40% of those of any age receiving palliative care had tried at least one such therapy. Some of the most popular alternative cancer treatments were found to be dietary therapies, antioxidants, high dose vitamins, and herbal therapies.\n\nUse of unconventional cancer treatments in the United States has been influenced by the U.S. federal government's National Center for Complementary and Alternative Medicine (NCCAM), initially known as the Office of Alternative Medicine (OAM), which was established in 1992 as a National Institutes of Health (NIH) adjunct by the U.S. Congress. Over thirty American medical schools have offered general courses in alternative medicine, including the Georgetown, Columbia, and Harvard university systems, among others.\n\nPeople who choose alternative treatments tend to believe that evidence-based medicine is extremely invasive or ineffective, while still believing that their own health could be improved. They are loyal to their alternative healthcare providers and believe that \"treatment should concentrate on the whole person\".\n\nCancer patients who choose alternative treatments instead of conventional treatments believe themselves less likely to die than patients who choose only conventional treatments. They feel a greater sense of control over their destinies, and report less anxiety and depression. They are more likely to engage in benefit finding, which is the psychological process of adapting to a traumatic situation and deciding that the trauma was valuable, usually because of perceived personal and spiritual growth during the crisis.\n\nHowever, patients who use alternative treatments have a poorer survival time, even after controlling for type and stage of disease. In 2017, researchers at Yale School of Medicine published a paper which suggested that people who choose alternative medicine over conventional cancer treatments were more than twice as likely to die within five years of diagnosis. And specifically, in those with breast cancer, people choosing alternative medicine were 5.68 times more likely to die within five years. \n\nThe reason that patients using alternative treatments die sooner may be because patients who accurately perceive that they are likely to survive do not attempt unproven remedies, and patients who accurately perceive that they are unlikely to survive are attracted to unproven remedies. Among patients who believe their condition to be untreatable by evidence-based medicine, \"desperation drives them into the hands of anyone with a promise and a smile.\" Con artists have long exploited patients' perceived lack of options to extract payments for ineffectual and even harmful treatments.\n\nIn a survey of American cancer patients, Baby Boomers were more likely to support complementary and alternative treatments than people from an older generation. White, female, college-educated patients who had been diagnosed more than a year ago were more likely than others to report a favorable impression of at least some complementary and alternative benefits.\n\nMany therapies have been (and continue to be) promoted to treat or prevent cancer in humans but lack good scientific and medical evidence of effectiveness. In many cases, there is good scientific evidence that the alleged treatments do not work. Unlike accepted cancer treatments, unproven and disproven treatments are generally ignored or avoided by the medical community, and are often pseudoscientific.\n\nDespite this, many of these therapies have continued to be promoted as effective, particularly by promoters of alternative medicine. Scientists consider this practice quackery, and some of those engaged in it have been investigated and prosecuted by public health regulators such as the US Federal Trade Commission, the Mexican Secretariat of Health and the Canadian Competition Bureau. In the United Kingdom, the Cancer Act makes the unauthorized promotion of cancer treatments a criminal offense.\n\n\nMost studies of complementary and alternative medicine in the treatment of cancer pain are of low quality in terms of scientific evidence. Studies of massage therapy have produced mixed results, but overall show some temporary benefit for reducing pain, anxiety, and depression and a very low risk of harm, unless the patient is at risk for bleeding disorders. There is weak evidence for a modest benefit from hypnosis, supportive psychotherapy and cognitive therapy. Results about Reiki and touch therapy were inconclusive. The most studied such treatment, acupuncture, has demonstrated no benefit as an adjunct analgesic in cancer pain. The evidence for music therapy is equivocal, and some herbal interventions such as PC-SPES, mistletoe, and saw palmetto are known to be toxic to some cancer patients. The most promising evidence, though still weak, is for mind–body interventions such as biofeedback and relaxation techniques.\n\nAs stated in the scientific literature, the measures listed below are defined as 'complementary' because they are applied in conjunction with mainstream anti-cancer measures such as chemotherapy, in contrast to the ineffective therapies viewed as 'alternative' since they are offered as substitutes for mainstream measures.\n\nSome alternative cancer treatments are based on unproven or disproven theories of how cancer begins or is sustained in the body. Some common concepts are:\n\nGovernment agencies around the world routinely investigate purported alternative cancer treatments in an effort to protect their citizens from fraud and abuse.\n\nIn 2008, the United States Federal Trade Commission acted against companies that made unsupported claims that their products, some of which included highly toxic chemicals, could cure cancer. Targets included Omega Supply, Native Essence Herb Company, Daniel Chapter One, Gemtronics, Inc., Herbs for Cancer, Nu-Gen Nutrition, Inc., Westberry Enterprises, Inc., Jim Clark's All Natural Cancer Therapy, Bioque Technologies, Inc., Cleansing Time Pro, and Premium-essiac-tea-4less.\n\n\n"}
{"id": "34892999", "url": "https://en.wikipedia.org/wiki?curid=34892999", "title": "Astronaut training", "text": "Astronaut training\n\nAstronaut training describes the complex process of preparing astronauts for their space missions before, during and after the flight, which includes medical tests, physical training, extra-vehicular activity (EVA) training, procedure training, rehabilitation process, as well as training on experiments they will accomplish during their stay in space.\n\nThe training is geared to the special conditions and environments astronauts will be confronted with during launch, in space, and during landing. All phases of the flight must be considered during training to ensure safety to, and functionality of the astronauts, as well as to ensure a successful completion of the mission. The Apollo astronauts that walked on the Moon also received training for geology fieldwork on the Lunar surface.\n\nThe effects of launching and landing has various effects on astronauts, with the most significant effects that occur being space motion sickness, orthostatic intolerance, and cardiovascular events.\n\nSpace motion sickness is an event that can occur within minutes of being in changing gravity environments (i.e. from 1g on Earth prior to launch to more than 1g during launch, and then from microgravity in space to hypergravity during re-entry and again to 1g after landing). The symptoms range from drowsiness and headaches, to nausea and vomiting. There are three general categories of space motion sickness:\n\n\nAbout three-fourths of astronauts experience \nspace motion sickness, with effects rarely exceeding two days. There is a risk for post-flight motion sickness, however this is only significant following long-duration space missions.\n\nPost-flight, following exposure to microgravity, the vestibular system, located in the inner ear is disrupted because of the microgravity-induced unresponsiveness of the otoliths which are small calcareous concretions that sense body postures and are responsible for ensuring proper balance. In most cases, this leads to some postflight postural illusions.\n\nCardiovascular events represent important factors during the three phases of a space mission. They can be divided in:\n\nAstronauts are trained in preparation for the conditions of launch as well as the harsh environment of space. This training aims to prepare the crew for events falling under two broad categories: events relating to operation of the spacecraft (internal events), and events relating to the space environment (external events).\n\nDuring training, astronauts are familiarized with the engineering systems of the spacecraft including spacecraft propulsion, spacecraft thermal control, and life support systems. In addition to this, astronauts receive training in orbital mechanics, scientific experimentation, earth observation, and astronomy. This training is particularly important for missions when an astronaut will encounter multiple systems (for example on the International Space Station (ISS)). Training is performed in order to prepare astronauts for events that may pose a hazard to their health, the health of the crew, or the successful completion of the mission. These types of events may be: failure of a critical life support system, capsule depressurization, fire, and other life-threatening events. In addition to the need to train for hazardous events, astronauts will also need to train to ensure the successful completion of their mission. This could be in the form of training for EVA, scientific experimentation, or spacecraft piloting.\n\nExternal events refers more broadly to the ability to live and work in the extreme environment of space. This includes adaptation to microgravity (or weightlessness), isolation, confinement, and radiation. The difficulty associated with living and working in microgravity include spatial disorientation, motion sickness, and vertigo. During long-duration missions, astronauts will often experience isolation and confinement. This has been known to limit performance of astronaut crews and hence training aims to prepare astronauts for such challenges. The long-term effects of radiation on crews is still largely unknown. However, it is theorized that astronauts on a trip to Mars will likely receive more than 1000x the radiation dosage of a typical person on earth. As such, present and future training must incorporate systems and processes for protecting astronauts against radiation.\n\nScientific experimentation has historically been an important element of human spaceflight, and is the primary focus of the International Space Station. Training on how to successfully carry out these experiments is an important part of astronaut training, as it maximizes the scientific return of the mission. Once on-orbit, communication between astronauts and scientists on the ground can be limited, and time is strictly apportioned between different mission activities. It is vital that astronauts are familiar with their assigned experiments in order to complete them in a timely manner, with as little intervention from the ground as possible.\n\nFor missions to the ISS, each astronaut is required to become proficient at one hundred or more experiments. During training, the scientists responsible for the experiments do not have direct contact with the astronauts who will be carrying them out. Instead, scientists instruct trainers who in turn prepare the astronauts for carrying out the experiment. Much of this training is done at the European Astronaut Center.\n\nFor human experiments, the scientists describe their experiments to the astronauts who then choose whether to participate on board the ISS. For these experiments, the astronauts will be tested before, during, and after the mission to establish a baseline and determine when the astronaut returned to the baseline.\n\nAt NASA, following the selection phase, the so-called \"AsCans\" (Astronaut candidates) have to undergo up to two years of training/indoctrination period to become fully qualified astronauts. \nInitially, all AsCans must go through basic training to learn both technical and soft skills. There are 16 different technical courses in:\n\n\nAsCans initially go through Basic Training, where they are trained on Soyuz, and ISS systems, flight safety and operations, as well as land or water survival. Pilot AsCans will receive training on NASA's T-38 Trainer Jet. Furthermore, because modern space exploration is done by a consortium of different countries and is a very publicly visible area, astronauts received professional and cultural training, as well as language courses (specifically in Russian).\n\nFollowing completion of Basic Training candidates proceed to NASA's Advanced Training. AsCans are trained on life-sized models to get a feel of what they will be doing in space. This was done both through the use of the Shuttle Training Aircraft while it was still operational and is done through simulation mock-ups. The shuttle training aircraft was exclusively used by the commander and pilot astronauts for landing practices until the retirement of the Shuttle, while advanced simulation system facilities are used by all the candidates to learn how to work and successfully fulfill their tasks in the space environment. Simulators and EVA training facilities help candidates to best prepare their different mission operations. In particular, vacuum chambers, parabolic flights, and neutral buoyancy facilities (NBF) allow candidates to get acclimated to the micro gravity environment, particularly for EVA. Virtual reality is also becoming increasingly used as a tool to immerse AsCans into the space environment.\nThe final phase is the Intensive Training. It starts at about three months prior to launch and serves to prepare the candidates specifically for the mission they have been assigned to. Flight-specific integrated simulations are designed to provide a dynamic testing ground for mission rules and flight procedures. The final Intensive Training joint crew/flight controller training is carried out in parallel with \"mission planning.\" This phase is where candidates will undergo mission specific operational training, as well as experience with their assigned experiments. Crew medical officer training is also included to effectively intervene with proactive and reactive actions in case of medical issues.\n\nAstronaut training in Europe is carried out by the European Astronaut Centre (EAC), headquartered in Cologne, Germany. European training has three phases: Basic training, Advanced training, and Increment Specific Training.\n\nFor all ESA selected astronauts, Basic Training begins at the EAC headquarters. This section of the training cycle has four separate training blocks that last 16 months. Astronauts will receive an orientation on the major spacefaring nations, their space agencies, and all major manned and unmanned space programs. Training in this phase also looks into applicable laws and policies of the space sector. Technical (including engineering, astrodynamics, propulsion, orbital mechanics, etc.) and scientific (including human physiology, biology, earth observation, and astronomy) basics are introduced, to ensure that all new astronauts have the required base level of knowledge. Training is done on ISS operations and facilities, including an introduction to all major operating systems on board the ISS that are required for its functionality as a manned space research laboratory. This phase also covers in-depth systems operations for all spacecraft that service the ISS (e.g. Soyuz, Progress, Automatic Transfer Vehicle (ATV), and the H-II Transfer Vehicle (HTV)), as well as ground control and launch facility training. This training phase also focuses on skills such as robotic operations, rendezvous and docking, Russian language courses, human behavior and performance, and finally a PADI open water scuba diving course. This scuba course provides basic EVA training at ESA's NBF before moving onto the larger NASA training facility at the Lyndon B. Johnson Space Center.\n\nAdvanced Training includes a much more in-depth look into the ISS, including learning how to service and operate all systems. Enhanced science training is also implemented at this time to ensure all astronauts can perform science experiments on board the ISS. This phase takes around one year to complete and training is completed across the ISS partner network, no longer only at the EAC. It is only upon completion of this phase that astronauts are assignment to a spaceflight.\n\nIncrement-Specific Training starts only after an astronaut has been assigned to a flight. This phase lasts 18 months and prepares them for their role on their assigned mission. During this phase crew members as well as backup crews will train together. The crew tasks on the ISS are individually tailored, with consideration to the astronaut's particular experience and professional background. There are three different user levels for all on-board equipment (i.e. user level, operator level, and specialist level). A crew member can be a specialist on systems while also only being an operator or user on others, hence why the training program is individually tailored. Increment Specific Training also includes training to deal with off-nominal situations. Astronauts will also learn how to run the experiments that are specifically scheduled for their assigned missions.\n\nTraining for cosmonauts falls into three phases: General Space Training, Group Training, and Crew Training. General Space Training lasts about two years and consists of classes, survival training, and a final exam which determines whether a cosmonaut will be a test or research cosmonaut. The next year is devoted to Group Training where cosmonauts specialize in the Soyuz or ISS as well as professional skills. The final phases, the Crew Training phase, lasts a year and a half and is dedicated to detailed vehicle operations procedures, ISS training, and English language.\n\nTraining primarily takes place at the Yuri Gagarin Cosmonaut Training Center. The center facilities have full size mockups of all major Soviet and Russian spacecraft including the ISS. As with the ISS astronauts, cosmonauts train in the USA, Germany, Japan, and Canada for specific training in the various ISS modules.\n\nThe Japanese human spaceflight program has historically focused on training astronauts for Space Shuttle missions. As such, training previously took place at NASA’s Lyndon B. Johnson Space Center, and followed that of NASA astronauts and other international participants in the Space Shuttle program.\n\nSince the development of domestic training facilities at the Tsukuba Space Center, training has increasingly taken place in Japan. With Japan’s participation in the ISS, the training of Japanese astronauts follows a similar structure to that of other ISS partners. Astronauts carry out 1.5 years of Basic Training mainly at Tsukuba, followed by 1.5–2 years of Advanced Training at Tsukuba and ISS partner sites. Training for any international ISS astronauts involving the Kibo module will also be carried out at Tsukuba Space Center.\n\nAdvanced Training is followed by Increment-Specific Training, which, along with any Kibo training, will be carried out at Tsukuba. EVA training for Kibo takes place in the Weightless Environment Test System (WETS). WETS is a Neutral Buoyancy Facility featuring a full-scale mock-up of the Kibo module on the ISS. The Tsukuba Space Center also includes medical facilities for assessing suitability of candidates, an isolation chamber for simulating some of the mental and emotional stressors of long duration spaceflight, and a hypobaric chamber for training in hull breach or Life Support System failure scenarios resulting in a reduction or loss of air pressure.\n\nAlthough official detail of the selection process for the Shenzhou program is not available, what is known is that candidates are chosen by the Chinese National Space Administration from the Chinese air force and must be between 25 and 30 years of age, with a minimum of 800 hours flying time, and a degree-level education. Candidates must be between 160 cm and 172 cm in height, and between 50 kg and 70 kg in weight.\n\nFor China's Shenzhou astronauts, training begins with a year-long program of education in the basics of spaceflight. During this period, candidates are also introduced to human physiology and psychology. The second phase of training, lasting nearly 3 years involves extensive training in piloting the Shenzhou vehicle in nominal and emergency modes. The third and final stage of training is mission specific training, and lasts approximately 10 months. During this phase of training, astronauts are trained in the high fidelity Shenzhou trainer, as well as the Neutral Buoyancy Facility located at the Astronaut Center of China (ACC), in Beijing. As well as time spent in the Neutral Buoyancy Facility (NBF), training for EVA takes place in a high vacuum, low temperature chamber that simulates the environmental conditions of space. At all stages of training, astronauts undergo physical conditioning, including time in a human centrifuge located at the ACC, and a program of micro gravity flights, carried out in Russia.\n\nThe Indian human space flight program still awaits a formal go ahead. Once cleared the mission is expected to take two Indians in a Soyuz-type orbital vehicle into low earth orbit. The training for these astronauts should be based on the lessons learned from training India’s only Cosmonaut Wing Commander Rakesh Sharma (\"See Salyut-7 1984\") and through India’s international co-operation with NASA and Roscosmos. This would allow India to gain insights from their rich experiences in human spaceflight. There also lies a possibility that India may go proceed through its human spaceflight program individually, necessitating the Indian Space Research Organisation (ISRO) to develop its own training program. For astronaut training, India is deciding a place which is at a distance of 8 to 10 km from Kempegowda international airport. This land is under the ownership of ISRO. Astronaut training and biomedical engineering centers will be built on it. Though India’s first man mission training will take place in USA or in Russia, this place can be used for future training. Moreover, center will have chambers for radiation regulation, thermal cycling and centrifugal for the acceleration training. .\n\nWhile it is likely that the first generation of non-government spaceflight astronauts will perform suborbital trajectories, currently some companies like Virgin Galactic and Xcor Aerospace are developing their own proprietary suborbital astronaut training programs, however the first official Suborbital Astronaut Training program of the 21st century was a joint effort between the two government agencies, the Ecuadorian Air Force and the Gagarin Cosmonaut Training Center<ref name=\"FAE-ESAA ASA/T astronaut training:2005\">Ecuadorian Air Force Official document on ASA/T program. <http://www.exa.ec/bp8/FAE-ESAA.pdf></ref> developed the ASA/T (Advanced Suborbital Astronaut Training) program with a duration up to 16 months, it started in 2005 and completed in 2007 focusing in command and research duties during short duration missions with suborbital trajectories up to 180 kilometers. This program had one Ecuadorian citizen graduate in 2007,<ref name=\"FAE-ESAA ASA/T astronaut training:2007\">Ecuadorian Air Force presented with ASA/T program completion brief. <http://www.exa.ec/bp8/></ref><ref name=\"FAE-ESAA ASA/T astronaut training:2008\">Ecuadorian Air Force presented with space program brief. <http://www.exa.ec/bp9/></ref> recently the Ecuadorian Space Agency has made a call for a new class of ASA/T training candidates, accordingly to the EXA, they will focus on renting commercial suborbital vehicles in order to perform manned space research\n\nLooking ahead, the emergence of commercial space tourism will necessitate new standards for flight participants that currently do not exist. These standards will be to ensure that medical screenings are done properly in order to ensure safe and successful flights. This type of medical screening will differ from space agency astronaut selection and training because the goal is not to fly the highest performing individual, but merely to ensure a safe flight for the passengers under the rigors of space travel. The main considerations for this type of travel will be:\n\n\nMedical regulations for commercial space flight might mitigate commercial space company risk by selecting only those capable of passing standard medical criteria, as opposed to allowing anyone who can purchase a ticket to fly. The first generation of commercial space flight will likely be suborbital trajectories which invoke significant acceleration changes, causing cardiovascular and pulmonary issues. Because of this any future medical criteria for commercial spaceflight participants needs to focus specifically on the detrimental effects of rapidly changing gravitational levels, and which individuals will be capable of tolerating this.\n\nBioastronautics and upper-atmospheric research have been conducted by Project PoSSUM scientist-astronaut candidates since 2015. As of October 2018, the program has attracted members from 37 different countries and published research on mesospheric dynamics and human performance in space suits, microgravity, and post-landing environments. \n\nCurrent research on fitness training and strategies for commercial astronauts conducted by Astrowright Spaceflight Consulting, the first commercial firm to offer dedicated fitness training for space tourists, suggests that conventional fitness training is inadequate to support safe movement in microgravity, and that training utilizing reduced points of stability should be emphasized.\n\nAstronauts for long term missions such as those to the Moon, an asteroid, or even to Mars need to carry out multiple tasks and duties, because on such missions the astronauts will need to function largely autonomously, and will need to be proficient in many different areas. For these types of missions, the training to prepare astronauts will likely include training as doctors, scientists, engineers, technicians, pilots, and geologists. In addition there will be a focus on the psychological aspects of long-duration missions where crew is largely isolated.\n\nCurrently a six-month mission to the ISS requires up to five years of astronaut training. This level of training is to be expected and likely to be expanded upon for future space exploration missions. It may also include in-flight training aspects. It may be possible that the ISS will be used as a long-duration astronaut training facility in the future.\n\nA powerful tool for astronaut training will be the continuing use of analog environments, including NASA Extreme Environment Mission Operations (NOAA NEEMO), NASA's Desert Research and Technology Studies (Desert RATS), Envihab (planned), Flight Analog Research Unit, Haughton-Mars Project (HMP), or even the ISS (in-flight). In fact, at NEEMO a total of 15 mission astronauts (known as aquanauts) have been trained for future missions to asteroids. The use of virtual reality will also continue to be used as a means of training astronauts in a cost effective manner, particularly for operations such as extra-vehicular activity (EVA).\n\nThese missions are not completely independent without the presence of robots. This opens up a new avenue towards Human-Robot Interaction which has to be thoroughly understood and practised to develop a harmonious relationship between astronauts and robots. These robots would aid the astronauts from being their personal assistants to next generation of extreme environment explorers. Currently there is a robot on the ISS aiding the astronauts in their mammoth tasks with a human touch. Intercultural and human robot interaction training is the need of the hour for long duration missions.\n\nTraining also has to be evolved for moon landing to Manned mission to Mars. Factors like crew dynamics, crew size, and crew activities play a crucial role as these missions would last from 1 year to Moon to 3 years on Mars. The training required for such missions has to be versatile and easy to learn, adapt, and improvise.\n\n\n\n"}
{"id": "36684546", "url": "https://en.wikipedia.org/wiki?curid=36684546", "title": "Bad Pharma", "text": "Bad Pharma\n\nBad Pharma: How Drug Companies Mislead Doctors and Harm Patients is a book by the British physician and academic Ben Goldacre about the pharmaceutical industry, its relationship with the medical profession, and the extent to which it controls academic research into its own products. It was published in the UK in September 2012 by the Fourth Estate imprint of HarperCollins, and in the United States in February 2013 by Faber and Faber.\n\nGoldacre argues in the book that \"the whole edifice of medicine is broken\", because the evidence on which it is based is systematically distorted by the pharmaceutical industry. He writes that the industry finances most of the clinical trials into its own products and much of doctors' continuing education, that clinical trials are often conducted on small groups of unrepresentative subjects and negative data is routinely withheld, and that apparently independent academic papers may be planned and even ghostwritten by pharmaceutical companies or their contractors, without disclosure. Describing the situation as a \"murderous disaster\", he makes suggestions for action by patients' groups, physicians, academics and the industry itself.\n\nResponding to the book's publication, the Association of the British Pharmaceutical Industry issued a statement in 2012 arguing that the examples the book offers were historical, that the concerns had been addressed, that the industry is among the most regulated in the world, and that it discloses all data in accordance with international standards.\n\nIn January 2013 Goldacre joined the Cochrane Collaboration, \"British Medical Journal\" and others in setting up AllTrials, a campaign calling for the results of all past and current clinical trials to be reported. The British House of Commons Public Accounts Committee expressed concern in January 2014 that drug companies were still only publishing around 50 percent of clinical-trial results.\n\nAfter graduating in 1995 with a first-class honours degree in medicine from Magdalen College, Oxford, Goldacre obtained an MA in philosophy from King's College London, then undertook clinical training at UCL Medical School, qualifying as a medical doctor in 2000 and as a psychiatrist in 2005. As of 2014 he was Wellcome Research Fellow in Epidemiology at the London School of Hygiene and Tropical Medicine.\n\nGoldacre is known for his \"Bad Science\" column in the \"Guardian\", which he has written since 2003, and for his first book, \"Bad Science\" (2008). This unpicked the claims of several forms of alternative medicine, and criticized certain physicians and the media for a lack of critical thinking. It also looked at the MMR vaccine controversy, AIDS denialism, the placebo effect and the misuse of statistics. Goldacre was recognized in June 2013 by \"Health Service Journal\" as having done \"more than any other single individual to shine a light on how science and research gets distorted by the media, politicians, quacks, PR and the pharmaceutical industry.\"\n\nGoldacre writes in the introduction of \"Bad Pharma\" that he aims to defend the following:\nDrugs are tested by the people who manufacture them, in poorly designed trials, on hopelessly small numbers of weird, unrepresentative patients, and analysed using techniques which are flawed by design, in such a way that they exaggerate the benefits of treatments. Unsurprisingly, these trials tend to produce results that favour the manufacturer. When trials throw up results that companies don't like, they are perfectly entitled to hide them from doctors and patients, so we only ever see a distorted picture of any drug's true effects. Regulators see most of the trial data, but only from early on in a drug's life, and even then they don't give this data to doctors or patients, or even to other parts of government. This distorted evidence is then communicated and applied in a distorted fashion.\n\nIn their forty years of practice after leaving medical school, doctors hear about what works through ad hoc oral traditions, from sales reps, colleagues or journals. But those colleagues can be in the pay of drug companies – often undisclosed – and the journals are too. And so are the patient groups. And finally, academic papers, which everyone thinks of as objective, are often covertly planned and written by people who work directly for the companies, without disclosure. Sometimes whole academic journals are even owned outright by one drug company. Aside from all this, for several of the most important and enduring problems in medicine, we have no idea what the best treatment is, because it's not in anyone's financial interest to conduct any trials at all.\nIn \"Missing Data,\" Goldacre argues that the clinical trials undertaken by drug companies routinely reach conclusions favourable to the company. For example, in a 2007 journal article published in PLOS Medicine, researchers studied every published trial on statins, drugs prescribed to reduce cholesterol levels. In the 192 trials they looked at, industry-funded trials were 20 times more likely to produce results that favoured the drug.\n\nHe writes that these positive results are achieved in a number of ways. Sometimes the industry-sponsored studies are flawed by design (for example by comparing the new drug to an existing drug at an inadequate dose), and sometimes patients are selected to make a positive result more likely. In addition, the data is analysed as the trial progresses. If the trial seems to be producing negative data it is stopped prematurely and the results are not published, or if it is producing positive data it may be stopped early so that longer-term effects are not examined. He writes that this publication bias, where negative results remain unpublished, is endemic within medicine and academia. As a consequence, he argues, doctors may have no idea what the effects are of the drugs they prescribe.\n\nAn example he gives of the difficulty of obtaining missing data from drug companies is that of oseltamivir (Tamiflu), manufactured by Roche to reduce the complications of bird flu. Governments spent billions of pounds stockpiling this, based in large part on a meta-analysis that was funded by the industry. \"Bad Pharma\" charts the efforts of independent researchers, particularly Tom Jefferson of the Cochrane Collaboration Respiratory Group, to gain access to information about the drug.\n\nIn the second chapter, the book describes the process as new drugs move from animal testing through phase 1 (first-in-man study), phase 2, and phase 3 clinical trials. Phase 1 participants are referred to as volunteers, but in the US are paid $200–$400 per day, and because studies can last several weeks and subjects may volunteer several times a year, earning potential becomes the main reason for participation. Participants are usually taken from the poorest groups in society, and outsourcing increasingly means that trials may be conducted in countries with highly competitive wages by contract research organizations (CROs). The rate of growth for clinical trials in India is 20 percent a year, in Argentina 27 percent, and in China 47 percent, while trials in the UK have fallen by 10 percent a year and in the US by six percent.\n\nThe shift to outsourcing raises issues about data integrity, regulatory oversight, language difficulties, the meaning of informed consent among a much poorer population, the standards of clinical care, the extent to which corruption may be regarded as routine in certain countries, and the ethical problem of raising a population's expectations for drugs that most of that population cannot afford. It also raises the question of whether the results of clinical trials using one population can invariably be applied elsewhere. There are both social and physical differences: Goldacre asks whether patients diagnosed with depression in China are really the same as patients diagnosed with depression in California, and notes that people of Asian descent metabolize drugs differently from Westerners.\n\nThere have also been cases of available treatment being withheld during clinical trials. In 1996 in Kano, Nigeria, the drug company Pfizer compared a new antibiotic during a meningitis outbreak to a competing antibiotic that was known to be effective at a higher dose than was used during the trial. Goldacre writes that 11 children died, divided almost equally between the two groups. The families taking part in the trial were apparently not told that the competing antibiotic at the effective dose was available from Médecins Sans Frontières in the next-door building.\n\nChapter three describes the concept of \"regulatory capture,\" whereby a regulator – such as the Medicines and Healthcare products Regulatory Agency (MHRA) in the UK, or the Food and Drug Administration (FDA) in the United States – ends up advancing the interests of the drug companies rather than the interests of the public. Goldacre writes that this happens for a number of reasons, including the revolving door of employees between the regulator and the companies, and the fact that friendships develop between regulator and company employees simply because they have knowledge and interests in common. The chapter also discusses surrogate outcomes and accelerated approval, and the difficulty of having ineffective drugs removed from the market once they have been approved. He argues that regulators do not require that new drugs offer an improvement over what is already available, or even that they be particularly effective.\n\n\"Bad Trials\" examines the ways in which clinical trials can be flawed. Goldacre writes that this happens by design and by analysis, and that it has the effect of maximizing a drug's benefits and minimizing harm.\nThere have been instances of fraud, though he says these are rare. More common are what he calls the \"wily tricks, close calls, and elegant mischief at the margins of acceptability.\"\n\nThese include testing drugs on unrepresentative, \"freakishly ideal\" patients; comparing new drugs to something known to be ineffective, or effective at a different dose or if used differently; conducting trials that are too short or too small; and stopping trials early or late. It also includes measuring uninformative outcomes; packaging the data so that it is misleading; ignoring patients who drop out (i.e. using per-protocol analysis, where only patients who complete the trial are counted in the final results, rather than intention-to-treat analysis, where everyone who starts the trial is counted); changing the main outcome of the trial once it has finished; producing subgroup analyses that show apparently positive outcomes for certain tightly defined groups (such as Chinese men between the ages of 56 and 71), thereby hiding an overall negative outcome; and conducting \"seeding trials,\" where the objective is to persuade physicians to use the drug.\n\nAnother criticism is that outcomes are presented in terms of relative risk reduction to exaggerate the apparent benefits of the treatment. For example, he writes, if four people out of 1,000 will have a heart attack within the year, but on statins only two will, that is a 50 percent reduction if expressed as relative risk reduction. But if expressed as absolute risk reduction, it is a reduction of just 0.2 percent.\n\nIn chapter five Goldacre suggests using the General Practice Research Database in the UK, which contains the anonymized records of several million patients, to conduct randomized trials to determine the most effective of competing treatments. For example, to compare two statins, atorvastatin and simvastatin, doctors would randomly assign patients to one or the other. The patients would be followed up by having data about their cholesterol levels, heart attacks, strokes and deaths taken from their computerized medical records. The trials would not be blind – patients would know which statin they had been prescribed – but Goldacre writes that they would be unlikely to hold such firm beliefs about which one is preferable to the extent that it could affect their health.\n\nIn the final chapter, Goldacre looks at how doctors are persuaded to prescribe \"me-too drugs,\" brand-name drugs that are no more effective than significantly cheaper off-patent ones. He cites as examples the statins atorvastatin (Lipitor, made by Pfizer) and simvastatin (Zocor), which he writes seem to be equally effective, or at least there is no evidence to suggest otherwise. Simvastatin came off patent several years ago, yet there are still three million prescriptions a year in the UK for atorvastatin, costing the National Health Service (NHS) an annual £165 million extra.\n\nHe addresses the issue of medicalization of certain conditions (or, as he argues, of personhood), whereby pharmaceutical companies \"widen the boundaries of diagnosis\" before offering solutions. Female sexual dysfunction was highlighted in 1999 by a study published in the \"Journal of the American Medical Association\", which alleged that 43 percent of women were suffering from it. After the article appeared, the \"New York Times\" wrote that two of its three authors had worked as consultants for Pfizer, which at the time was preparing to launch UK-414,495, known as female Viagra. The journal's editor said that the failure to disclose the relationship with Pfizer was the journal's mistake.\n\nThe chapter also examines celebrity endorsement of certain drugs, the extent to which claims in advertisements aimed at doctors are appropriately sourced, and whether direct-to-consumer advertising (currently permitted in the US and New Zealand) ought to be allowed. It discusses how PR firms promote stories from patients who complain in the media that certain drugs are not made available by the funder, which in the UK is the NHS and the National Institute for Health and Clinical Excellence (NICE). Two breast-cancer patients who campaigned in the UK in 2006 for trastuzumab (Herceptin) to be available on the NHS were being handled by a law firm working for Roche, the drug's manufacturer. The historian Lisa Jardine, who was suffering from breast cancer, told the \"Guardian\" that she had been approached by a PR firm working for the company.\n\nThe chapter also covers the influence of drug reps, how ghostwriters are employed by the drug companies to write papers for academics to publish, how independent the academic journals really are, how the drug companies finance doctors' continuing education, and how patients' groups are often funded by industry.\n\nIn the afterword and throughout the book, Goldacre makes suggestions for action by doctors, medical students, patients, patient groups and the industry. He advises doctors, nurses and managers to stop seeing drug reps, to ban them from clinics, hospitals and medical schools, to declare online and in waiting rooms all gifts and hospitality received from the industry, and to remove all drug company promotional material from offices and waiting rooms. (He praises the website of the American Medical Student Association – www.amsascorecard.org – which ranks institutions according to their conflict-of-interest policies, writing that it makes him \"feel weepy.\") He also suggests that regulations be introduced to prevent pharmacists from sharing doctors' prescribing records with drug reps.\n\nHe asks academics to lobby their universities and academic societies to forbid academics from being involved in ghostwriting, and to lobby for \"film credit\" contributions at the end of every academic paper, listing everyone involved, including who initiated the idea of publishing the paper. He also asks for full disclosure of all past clinical trial results, and a list of academic papers that were, as he puts it, \"rigged\" by industry, so that they can be retracted or annotated. He asks drug company employees to become whistleblowers, either by writing an anonymous blog, or by contacting him.\n\nHe advises patients to ask their doctors whether they accept drug-company hospitality or sponsorship, and if so to post details in their waiting rooms, and to make clear whether it is acceptable to the patient for the doctor to discuss his or her medical history with drug reps. Patients who are invited to take part in a trial are advised to ask, among other things, for a written guarantee that the trial has been publicly registered, and that the main outcome of the trial will be published within a year of its completion. He advises patient groups to write to drug companies with the following: \"We are living with this disease; is there anything at all that you're withholding? If so, tell us today.\"\n\nThe book was generally well received. The \"Economist\" described it as \"slightly technical, eminently readable, consistently shocking, occasionally hectoring and unapologetically polemical\". Helen Lewis in the \"New Statesman\" called it an important book, while Luisa Dillner, writing in the \"Guardian\", described it as a \"thorough piece of investigative medical journalism\".\n\nAndrew Jack wrote in the \"Financial Times\" that Goldacre is \"at his best in methodically dissecting poor clinical trials. ... He is less strong in explaining the complex background reality, such as the general constraints and individual slips of regulators and pharma companies' employees.\" Jack also argued that the book failed to reflect how many lives have been improved by the current system, for example with new treatments for HIV, rheumatoid arthritis and cancer.\n\nMax Pemberton, a psychiatrist, wrote in the \"Daily Telegraph\" that \"this is a book to make you enraged ... because it's about how big business puts profits over patient welfare, allows people to die because they don't want to disclose damning research evidence, and the tricks they play to make sure doctors do not have all the evidence when it comes to appraising whether a drug really works or not.\"\n\nThe Association of the British Pharmaceutical Industry (ABPI) replied in the \"New Statesman\" that Goldacre was \"stuck in a bygone era where pharmaceutical companies wine and dine doctors in exchange for signing on the dotted line\". The ABPI issued a press release, writing that the pharmaceutical industry is responsible for the discovery of 90 percent of all medicines, and that it takes an average of 10–12 years and £1.1bn to introduce a medicine to the market, with just one in 5,000 new compounds receiving regulatory approval. This makes research and development an expensive and risky business. They wrote that the industry is one of the most heavily regulated in the world, and is committed to ensuring full transparency in the research and development of new medicines. They also maintained that the examples Goldacre offered were \"long documented and historical, and the companies concerned have long addressed these issues\". Goldacre argues in the book that \"the most dangerous tactic of all is the industry's enduring claim that these problems are all in the past\".\n\nHumphrey Rang of the British Pharmacological Society wrote that Goldacre had chosen his target well and had produced some shocking examples of secrecy and dishonesty, particularly the nondisclosure of data on the antidepressant reboxetine (chapter one), in which only one trial out of seven was published (the published study showed positive results, while the unpublished trials suggested otherwise). He argued that Goldacre had gone \"over the top\" in devoting a whole chapter (chapter five) to recommending large clinical trials using electronic patient data from general practitioners, without fully pointing out how problematic these can be; such trials raise issues, for example, about informed consent and regulatory oversight. Rang also criticized Goldacre's style, describing the book as too long, repetitive, hyperbolic, and in places too conversational. He particularly objected to the line, \"medicine is broken\", calling it a \"foolish remark\".\n\nFollowing the book's publication, Goldacre co-founded AllTrials with David Tovey, editor-in-chief of the Cochrane Library, together with the \"British Medical Journal\", the Centre for Evidence-based Medicine, and others in the UK, and Dartmouth College's Geisel School of Medicine and the Dartmouth Institute for Health Policy and Clinical Practice in the US. Set up in January 2013, the group campaigns for all past and current clinical trials to be registered and reported, for all treatments in use.\n\nThe British House of Commons Public Accounts Committee produced a report in January 2014, after hearing evidence from Goldacre, Fiona Godlee, editor-in-chief of the \"British Medical Journal\", and others, about the stockpiling of Tamiflu and the withholding of data about the drug by its manufacturer, Roche. The committee said it was \"surprised and concerned\" to learn that information from clinical trials is routinely withheld from doctors, and recommended that the Department of Health take steps to ensure that all clinical-trial data be made available for currently prescribed treatments.\n\n\n\n\n\n"}
{"id": "6738308", "url": "https://en.wikipedia.org/wiki?curid=6738308", "title": "Borderless selling", "text": "Borderless selling\n\nBorderless selling is the process of selling services to clients outside the country of origin of services through modern methods which eliminate the actions specifically designed to hinder international trade. International trade through \"borderless selling\" is a new phenomenon born in the current \"globalization\" era.\n\nBorderless selling is defined as the process of performing sales transaction between two or more parties from different countries (an exporter and an importer) which is free from actions specifically designed to hinder international trade, such as tariff barriers, currency restrictions, and import quotas.\n\nInternational trade which is the exchange of goods and services across international borders has been present throughout much of history of economics, society and politics. \n\nIt is assumed that offshore outsourcing gave birth to \"borderless selling\". The selling of services by offshore outsourcing service providers to foreign clients is free from actions specifically designed to hinder international trade, such as tariff barriers, currency restrictions, and import quotas. This is largely because most of the services are sold or delivered electronically from the offshore service provider to the foreign client. This phenomenon gave birth to borderless selling.\n\nThere is a high correlation between outsourcing and exporting activity. However, borderless selling is different from free international trade or selling. Under the belief in Mercantilism, most nations had high tariffs and many restrictions on international trade for centuries. In the 19th century, a belief in free trade became paramount in west, especially in Britain and this outlook has since then dominated the thinking of western nations. Traditionally international trade was possible between only those countries which regulated international trade through bilateral treaties. Borderless selling is possible between any two countries of the world because services can be exported using modern telecommunication networks without the need to regulate trade.\n\nThe \"borderless selling\" term was originated as part of the research carried out by team led by Paramjeev Singh Sethi.\n\n\n\nMany services can be sold through borderless selling, popularly including:\n\nDifferent means used for borderless selling:\n\n"}
{"id": "57896735", "url": "https://en.wikipedia.org/wiki?curid=57896735", "title": "CEASE therapy", "text": "CEASE therapy\n\nCEASE (Complete Elimination of Autistic Spectrum Expression) therapy is used by naturopaths (particularly homeopaths) who claim, without evidence, that it can treat or even cure people with autism. It involves a mixture of supplements, high-dose vitamin C, 'orthomolecular support', dietary restrictions and homeopathy and was developed by the late Tinus Smits - a Dutch doctor. Smits claimed to have used it to treat over 300 children with autism. The therapy became more notable in 2017/2018 because of regulatory action taken by professional bodies in The Netherlands, UK and Canada following a series of complaints about unfounded claims. \n\nSmits in the book \"Autism Beyond Despair - CEASE Therapy\" stated that autistic children should never be vaccinated. \n\nIn October 2017 the Dutch Advertising Code Foundation (Stichting Reclame Code) found that the official website for CEASE therapy was in breach of advertising regulations.\n\nIn the United Kingdom, the Professional Standards Authority (PSA) placed some requirements on the Society of Homeopaths (SoH) when they reaccredited their members' register under their Accredited Register scheme, due to concerns about the way in which members marketed CEASE therapy. The PSA asked the SoH to confirm \"what action it will take to ensure children are safe as a condition of its re-accreditation\". In June 2018 the Society of Homeopaths published a position statement advising their members not to imply any cure of autism when marketing CEASE therapy. It has been estimated that more than 120 homeopaths are offering CEASE in the UK though not all are SoH members. In July 2015 the UK's Advertising Standards Authority (ASA) found Teddington Homeopathy's marketing of CEASE therapy in breach of the Advertising Standards Code. The following month the ASA added the company to its list of non-compliant online advertisers for \"making unproven efficacy claims for CEASE therapy\". In July 2018 the ASA upheld an adjudication against Bubbling Life's website, determining that the claims relating to CEASE, vaccination, autism and ASD could discourage customers from seeking appropriate advice or treatment. \n\nIn British Columbia, Canada, the Board of the College of Naturopathic Physicians investigated three CEASE practitioners following complaints from the public and subsequently \"determined that naturopathic doctors in British Columbia must not advertise or offer CEASE therapy\". As well as this prohibition the College's updated position statements also clarify that naturopathic doctors in BC must not offer anti-vaccination materials or advice (including on social media) and must not imply that vaccination causes autism.\n\n"}
{"id": "41608446", "url": "https://en.wikipedia.org/wiki?curid=41608446", "title": "Chemical Society Located in Taipei", "text": "Chemical Society Located in Taipei\n\nChemical Society Located in Taipei (CSLT; ; literally 'Chinese Chemical Society') is a Taiwanese scholarly organization dedicated to chemistry. The organization traces its roots to the establishment of Chinese Chemical Society in Nanjing in 1932 and was reestablished in Taiwan in 1950. For political reasons, the organization's English name was changed to \"Chemical Society Located in Taipei\" although it still retains the name \"Chinese Chemical Society\" (中國化學會) in Chinese.\n\nCSLT and Wiley publish a monthly periodical - Journal of the Chinese Chemical Society.\n\n"}
{"id": "2155752", "url": "https://en.wikipedia.org/wiki?curid=2155752", "title": "Citizen science", "text": "Citizen science\n\nCitizen science (CS; also known as community science, crowd science, crowd-sourced science, civic science, volunteer monitoring, or networked science) is scientific research conducted, in whole or in part, by amateur (or nonprofessional) scientists. Citizen science is sometimes described as \"public participation in scientific research,\" participatory monitoring, and participatory action research.\n\nThe term CS has multiple origins, as well as differing concepts. It was first defined independently in the mid-1990s by Rick Bonney in the United States and Alan Irwin in the United Kingdom. Alan Irwin, a British sociologist, defines CS as \"developing concepts of scientific citizenship which foregrounds the necessity of opening up science and science policy processes to the public\". Irwin sought to reclaim two dimensions of the relationship between citizens and science: 1) that science should be responsive to citizens' concerns and needs; and 2) that citizens themselves could produce reliable scientific knowledge. The American ornithologist Rick Bonney, unaware of Irwin's work, defined CS as projects in which nonscientists, such as amateur birdwatchers, voluntarily contributed scientific data. This describes a more limited role for citizens in scientific research than Irwin's conception of the term.\n\nThe terms \"citizen science\" and \"citizen scientists\" entered the Oxford English Dictionary (\"OED\") in June 2014. \"Citizen science\" is defined as \"scientific work undertaken by members of the general public, often in collaboration with or under the direction of professional scientists and scientific institutions\". \"Citizen scientist\" is defined as: (a) \"a scientist whose work is characterized by a sense of responsibility to serve the best interests of the wider community (now rare)\"; or (b) \"a member of the general public who engages in scientific work, often in collaboration with or under the direction of professional scientists and scientific institutions; an amateur scientist\". The first use of the term \"citizen scientist\" can be found in the magazine \"New Scientist\" in an article about ufology from October 1979.\n\nMuki Haklay cites, from a policy report for the Wilson Center entitled \"Citizen Science and Policy: A European Perspective\", an alternate first use of the term \"citizen science\" by R. Kerson in the magazine \"MIT Technology Review\" from January 1989. Quoting from the Wilson Center report: \"The new form of engagement in science received the name 'citizen science'. The first recorded example of the use of the term is from 1989, describing how 225 volunteers across the US collected rain samples to assist the Audubon Society in an acid-rain awareness raising campaign.\"\n\nA \"Green Paper on Citizen Science\" was published in 2013 by the European Commission's Digital Science Unit and Socientize.eu, which included a definition for CS, referring to \"the general public engagement in scientific research activities when citizens actively contribute to science either with their intellectual effort or surrounding knowledge or with their tools and resources. Participants provide experimental data and facilities for researchers, raise new questions and co-create a new scientific culture.\"\n\nCitizen science may be performed by individuals, teams, or networks of volunteers. Citizen scientists often partner with professional scientists to achieve common goals. Large volunteer networks often allow scientists to accomplish tasks that would be too expensive or time consuming to accomplish through other means.\n\nMany citizen-science projects serve education and outreach goals. These projects may be designed for a formal classroom environment or an informal education environment such as museums.\n\nCitizen science has evolved over the past four decades. Recent projects place more emphasis on scientifically sound practices and measurable goals for public education. Modern citizen science differs from its historical forms primarily in the access for, and subsequent scale of, public participation; technology is credited as one of the main drivers of the recent explosion of citizen science activity.\n\nIn March 2015, the Office of Science and Technology Policy published a factsheet entitled \"Empowering Students and Others through Citizen Science and Crowdsourcing\". Quoting: \"Citizen science and crowdsourcing projects are powerful tools for providing students with skills needed to excel in science, technology, engineering, and math (STEM). Volunteers in citizen science, for example, gain hands-on experience doing real science, and in many cases take that learning outside of the traditional classroom setting\".\nIn May 2016, a new open-access journal was started by the Citizen Science Association along with Ubiquity Press called \"Citizen Science: Theory and Practice\" (CS:T&P). Quoting from the editorial article titled \"The Theory and Practice of Citizen Science: Launching a New Journal\", \"CS:T&P provides the space to enhance the quality and impact of citizen science efforts by deeply exploring the citizen science concept in all its forms and across disciplines. By examining, critiquing, and sharing findings across a variety of citizen science endeavors, we can dig into the underpinnings and assumptions of citizen science and critically analyze its practice and outcomes.\"\n\nOther definitions for citizen science have also been proposed. For example, Bruce Lewenstein of Cornell University's Communication and S&TS departments describes 3 possible definitions:\n\nScientists and scholars who have used other definitions include Frank N. von Hippel, Stephen Schneider, Neal Lane and Jon Beckwith. Other alternative terminologies proposed are \"civic science\" and \"civic scientist\".\n\nFurther, Muki Haklay offers an overview of the typologies of the level of citizen participation in citizen science, which range from \"crowdsourcing\" (level 1), where the citizen acts as a sensor, to \"distributed intelligence\" (level 2), where the citizen acts as a basic interpreter, to \"participatory science\", where citizens contribute to problem definition and data collection (level 3), to \"extreme citizen science\", which involves collaboration between the citizen and scientists in problem definition, collection and data analysis.\n\nA 2014 Mashable article defines a citizen scientist as: \"Anybody who voluntarily contributes his or her time and resources toward scientific research in partnership with professional scientists.\"\n\nIn 2016 the Australian Citizen Science Association released their definition which states \"Citizen science involves public participation and collaboration in scientific research with the aim to increase scientific knowledge.\"\n\nIn 2016, the book \"Analyzing the Role of Citizen Science in Modern Research\" defined citizen science as \"work undertaken by civic educators together with citizen communities to advance science, foster a broad scientific mentality, and/or encourage democratic engagement, which allows society to deal rationally with complex modern problems\".\n\nIn a Smart City era, Citizen Science relays on various web-based tools (eg.WebGIS) and becomes Cyber Citizen Science. Some projects, such as SETI@home, use the Internet to take advantage of distributed computing. These projects are generally passive. Computation tasks are performed by volunteers' computers and require little involvement beyond initial setup. There is disagreement as to whether these projects should be classified as citizen science.\n\nThe astrophysicist and Galaxy Zoo co-founder Kevin Schawinski stated: \"We prefer to call this [Galaxy Zoo] citizen science because it's a better description of what you're doing; you're a regular citizen but you're doing science. Crowd sourcing sounds a bit like, well, you're just a member of the crowd and you're not; you're our collaborator. You're pro-actively involved in the process of science by participating.\"\n\nCompared to SETI@home, \"Galaxy Zoo volunteers do real work. They're not just passively running something on their computer and hoping that they'll be the first person to find aliens. They have a stake in science that comes out of it, which means that they are now interested in what we do with it, and what we find.\"\n\nCitizen policy may be another result of citizen science initiatives. Bethany Brookshire (pen name SciCurious) writes: \"If citizens are going to live with the benefits or potential consequences of science (as the vast majority of them will), it's incredibly important to make sure that they are not only well informed about changes and advances in science and technology, but that they also ... are able to ... influence the science policy decisions that could impact their lives.\"\n\nIn a research report published by the National Park Service in 2008, Brett Amy Thelen and Rachel K. Thiet mention the following concerns, previously reported in the literature, about the validity of volunteer-generated data:\n\nThe question of data accuracy, in particular, remains open. John Losey, who created the Lost Ladybug citizen science project, has argued that the cost-effectiveness of citizen science data can outweigh data quality issues, if properly managed.\n\nIn December 2016, authors M. Kosmala, A. Wiggins, A. Swanson and B. Simmons published a study in the journal Frontiers in Ecology and the Environment called \"Assessing Data Quality in Citizen Science\". The abstract describes how ecological and environmental CS projects have enormous potential to advance science. Also, CS projects can influence policy and guide resource management by producing datasets that are otherwise infeasible to generate. In the section \"In a Nutshell\" (pg3), four condensed conclusions are stated. They are:\n\nThey conclude that as CS continues to grow and mature, a key metric of project success they expect to see will be a growing awareness of data quality. They also conclude that CS will emerge as a general tool helping \"to collect otherwise unobtainable high-quality data in support of policy and resource management, conservation monitoring, and basic science.\"\n\nA study of Canadian lepidoptera datasets published in 2018 compared the use of a professionally curated dataset of butterfly specimen records with four years of data from a CS program, eButterfly. The eButterfly dataset was used as it was determined to be of high quality because of the expert vetting process used on the site, and there existed a historic dataset covering the same geographic area consisting of specimen data, much of it institutional. The authors note that, in this case, CS data provides both novel and complementary information to the specimen data. Five new species were reported from the CS data, and geographic distribution information was improved for over 80% of species in the combined dataset when CS data was included. \n\nIn March 2015, the state of Wyoming passed new laws (Senate Files 12 and 80) clarifying that trespassing laws applied even if the trespasser's intention was to gather data to further a U.S. government science program. This hampered some CS researchers who were collecting data while on other people's land.\n\nVarious studies have been published that explore the ethics of CS, including issues such as intellectual property and project design.(e.g.) The Citizen Science Association (CSA), based at the Cornell Lab of Ornithology, and the European Citizen Science Association (ECSA), based in the Museum für Naturkunde in Berlin, have working groups on ethics and principles.\n\nIn September 2015, the European Citizen Science Association (ECSA) published its \"Ten Principles of Citizen Science\", which have been developed by the \"Sharing best practice and building capacity\" working group of the ECSA, led by the Natural History Museum, London with input from many members of the association.\nThe medical ethics of internet crowdsourcing has been questioned by Graber & Graber in the Journal of Medical Ethics. In particular, they analyse the effect of games and the crowdsourcing project Foldit. They conclude: \"games can have possible adverse effects, and that they manipulate the user into participation\".\n\nIn the research paper \"Can citizen science enhance public understanding of science?\" by Bonney et al. 2016, statistics which analyse the economic worth of citizen science are used, drawn from two papers: i)Sauermann and Franzoni 2015, and\nii)Theobald et al. 2015. In \"Crowd science user contribution patterns and their implications\" by Sauermann and Franzoni (2015), seven projects from the Zooniverse web portal are used to estimate the monetary value of the CS that had taken place. The 7 projects are: Solar Stormwatch, Galaxy Zoo Supernovae, Galaxy Zoo Hubble, Moon Zoo, Old Weather, The Milky Way Project and Planet Hunters. Using data from 180 days in 2010, they find a total of 100,386 users participated, contributing 129,540 hours of unpaid work. Estimating at a rate of $12 an hour (an undergraduate research assistant's basic wage), the total contributions amount to $1,554,474, an average of $222,068 per project. It should be noted that the range over the 7 projects was from $22,717 to $654,130.\n\nIn \"Global change and local solutions: Tapping the unrealized potential of citizen science for biodiversity research\" by Theobald et al. 2015, the authors surveyed 388 unique biodiversity-based projects. Quoting: \"We estimate that between 1.36 million and 2.28 million people volunteer annually in the 388 projects we surveyed, though variation is great\" and that \"the range of in-kind contribution of the volunteerism in our 388 citizen science projects as between $667 million to $2.5 billion annually.\" \n\nWorldwide participation in citizen science continues to grow. A list of the top five citizen science communities compiled by Marc Kuchner and Kristen Erickson in July 2018 shows a total of 3.75 million participants, although there is likely substantial overlap between the communities. \n\nThere have been studies published which examine the place of CS within education.(e.g.) Teaching aids can include books and activity or lesson plans.(e.g.). Some examples of studies are:\n\nFrom the Second International Handbook of Science Education, a chapter entitled: \"Citizen Science, Ecojustice, and Science Education: Rethinking an Education from Nowhere\" by Mueller and Tippins (2011), acknowledges in the abstract that: \"There is an emerging emphasis in science education on engaging youth in citizen science.\" The authors also ask: \"whether citizen science goes further with respect to citizen development.\" The abstract ends by stating that the \"chapter takes account of the ways educators will collaborate with members of the community to effectively guide decisions, which offers promise for sharing a responsibility for democratizing science with others.\"\n\nFrom the journal Democracy and Education, an article entitled: \"Lessons Learned from Citizen Science in the Classroom\" by authors Gray, Nicosia and Jordan (GNJ) (2012) give a response to a study by Mueller, Tippins and Bryan (MTB) called \"The Future of Citizen Science\". GNJ begins by stating in the abstract that the study The Future Of Citizen Science: \"provides an important theoretical perspective about the future of \ndemocratized science and K12 education.\" But GRB state: \"However, the authors (MTB) fail to adequately address the existing \nbarriers and constraints to moving community-based science into the classroom.\" They end the abstract by arguing: \"that the resource constraints of scientists, teachers, and students likely pose problems to moving true democratized science into the classroom.\"\n\nIn 2014, a study was published called \"Citizen Science and Lifelong Learning\" by R. Edwards in the journal Studies in the Education of Adults. Edwards begins by writing in the abstract that CS projects have expanded over recent years and engaged CSs and professionals in diverse ways. He continues: \"Yet there has been little educational exploration of such projects to date.\" He describes that \"there has been limited exploration of the educational backgrounds of adult contributors to citizen science\". Edwards explains that CS contributers are referred to as volunteers, citizens or as amateurs. He ends the abstract: \"The article will explore the nature and significance of these different characterisations and also suggest possibilities for further research.\"\n\nIn the journal Microbiology and Biology Education a study was published by Shah and Martinez (2015) called \"Current Approaches in Implementing Citizen Science in the Classroom\". They begin by writing in the abstract that CS is a partnership between inexperienced amateurs and trained scientists. The authors continue: \"With recent studies showing a weakening in scientific competency of American students, incorporating citizen science initiatives in the curriculum provides a means to address deficiencies\". They argue that combining traditional and innovative methods can help provide a practical experience of science. The abstract ends: \"Citizen science can be used to emphasize the recognition and use of systematic approaches to solve problems affecting the community.\"\n\nIn November 2017, authors Mitchell, Triska and Liberatore published a study in Public Library of Science titled \"Benefits and Challenges of Incorporating Citizen Science into University Education\". The authors begin by stating in the abstract that CSs contribute data with the expectation that it will be used. It reports that CS has been used for first year university students as a means to experience research. They continue: \"Surveys of more than 1500 students showed that their environmental engagement increased significantly after participating in data collection and data analysis.\" However, only a third of students agreed that data collected by CSs was reliable. A positive outcome of this was that the students were more careful of their own research. The abstract ends: \"If true for citizen scientists in general, enabling participants as well as scientists to analyse data could enhance data quality, and so address a key constraint of broad-scale citizen science programs.\"\n\n\"Citizen science\" is a fairly new term but an old practice. Prior to the 20th century, science was often the pursuit of gentleman scientists, amateur or self-funded researchers such as Sir Isaac Newton, Benjamin Franklin, and Charles Darwin. By the mid-20th century, however, science was dominated by researchers employed by universities and government research laboratories. By the 1970s, this transformation was being called into question. Philosopher Paul Feyerabend called for a \"democratization of science\". Biochemist Erwin Chargaff advocated a return to science by nature-loving amateurs in the tradition of Descartes, Newton, Leibniz, Buffon, and Darwin—science dominated by \"amateurship instead of money-biased technical bureaucrats\".\n\nA study from 2016 indicates that the largest impact of citizen science is in research on biology, conservation and ecology, and is utilized mainly as a methodology of collecting and classifying data.\n\nAstronomy has long been a field where amateurs have contributed throughout time, all the way up to the present day.\n\nCollectively, amateur astronomers observe a variety of celestial objects and phenomena sometimes with equipment that they build themselves. Common targets of amateur astronomers include the Moon, planets, stars, comets, meteor showers, and a variety of deep-sky objects such as star clusters, galaxies, and nebulae. Observations of comets and stars are also used to measure the local level of artificial skyglow. One branch of amateur astronomy, amateur astrophotography, involves the taking of photos of the night sky. Many amateurs like to specialize in the observation of particular objects, types of objects, or types of events that interest them.\n\nThe American Association of Variable Star Observers has gathered data on variable stars for educational and professional analysis since 1911 and promotes participation beyond its membership on its Citizen Sky website.\n\nButterfly counts have a long tradition of involving individuals in the study of butterflies' range and their relative abundance. Two long-running programs are the UK Butterfly Monitoring Scheme (started in 1976) and the North American Butterfly Association's Butterfly Count Program (started in 1975). There are various protocols for monitoring butterflies and different organizations support one or more of transects, counts and/or opportunistic sightings. eButterfly is an example of a program designed to capture any of the three types of counts for observers in North America. Species-specific programs also exist, with monarchs the prominent example. Two examples of this involve the counting of monarch butterflies during the fall migration to overwintering sites in Mexico: (1) Monarch Watch is a continent-wide project, while (2) the Cape May Monarch Monitoring Project is an example of a local project. The Austrian project Viel-Falter investigated if and how trained and supervised pupils are able to systematically collect data about the occurrence of diurnal butterflies, and how this data could contribute to a permanent butterfly monitoring system. Despite substantial identification uncertainties for some species or species groups, the data collected by pupils was successfully used to predict the general habitat quality for butterflies.\n\nCitizen science projects have become increasingly focused on providing benefits to scientific research. The North American Bird Phenology Program (historically called the Bird Migration and Distribution records) may have been the earliest collective effort of citizens collecting ornithological information in the U.S. The program, dating back to 1883, was started by Wells Woodbridge Cooke. Cooke established a network of observers around North America to collect bird migration records. The Audubon Society's Christmas Bird Count, which began in 1900, is another example of a long-standing tradition of citizen science which has persisted to the present day. Citizen scientists help gather data that will be analyzed by professional researchers, and can be used to produce bird population and biodiversity indicators.\n\nRaptor migration research relies on the data collected by the hawkwatching community. This mostly volunteer group counts migrating accipiters, buteos, falcons, harriers, kites, eagles, osprey, vultures and other raptors at hawk sites throughout North America during the spring and fall seasons. The daily data is uploaded to hawkcount.org where it can be viewed by professional scientists and the public.\n\nSuch indices can be useful tools to inform management, resource allocation, policy and planning. For example, European breeding bird survey data provide input for the Farmland Bird Index, adopted by the European Union as a structural indicator of sustainable development. This provides a cost-effective alternative to government monitoring.\n\nSimilarly, data collected by citizen scientists as part of BirdLife Australia's has been analysed to produce the first-ever Australian Terrestrial Bird Indices.\n\nThe concept of citizen science has been extended to the ocean environment for characterizing ocean dynamics and tracking marine debris. For example, the mobile app Marine Debris Tracker is a joint partnership of National Oceanic and Atmospheric Administration and the University of Georgia. Long term sampling efforts such as the continuous plankton recorder has been fitted on ships of opportunity since 1931. Plankton collection by sailors and subsequent genetic analysis was pioneered in 2013 by Indigo V Expeditions as a way to better understand marine microbial structure and function.\n\nCitizen science has recently developed in Coral reef studies. \n\nUnderwater photography has become more and more popular since the early 2000s, resulting on millions of pictures posted every year on various websites and social media. This mass of documentation is endowed with an enormous scientific potential, as millions of tourists possess a much superior coverage power than professional scientists, who can not allow themselves to spend so much time in the field. \nAs a consequence, several participative sciences programs have been developped, supported by geo-localization and identification web sites (such as iNaturalist.org). Another example, the \"Monitoring through many eyes\" project collates thousands of underwater images of the Great Barrier Reef and provides an interface for elicitation of reef health indicators.\n\nAdditionally, the National Oceanic and Atmospheric Administration offers opportunities for volunteer participation. By taking measurements in The United States' National Marine Sanctuaries, citizens are able to contribute data to a variety of marine biology projects. By enabling these citizens, NOAA benefited from 137,000 hours of research during 2016.\n\nThere also exist protocols for auto-organization and self-teaching aimed at biodiversity-interested snorkelers, in order for them to turn their observations into sound scientific data, available for research. This kind of approach has been successfully used in Réunion island, allowing for tens of new records and even new species.\n\nCitizen science has a long tradition in Natural science. But nowadays, citizen science projects can also be found in various fields of science like Art history. For example, the Zooniverse project AnnoTate is a transcription tool developed to enable volunteers to read and transcribe the personal papers of British-born and émigré artists. The papers are drawn from the Tate Archive. Another example of citizen science in art history is ARTigo. ARTigo collects semantic data on artworks from the footprints left by players of games featuring artwork images. From these footprints, ARTigo automatically builds a semantic search engine for artworks.\n\nNewer technologies have increased the options for citizen science. Citizen scientists can build and operate their own instruments to gather data for their own experiments or as part of a larger project. Examples include amateur radio, amateur astronomy, Six Sigma Projects, and Maker activities. Most recently scientist Joshua Pearce has advocated for the creation of open-source hardware based scientific equipment that both citizen scientists and professional scientists, which can be replicated by digital manufacturing techniques such as 3D printing. Multiple studies have shown this approach radically reduces scientific equipment costs. Examples of this approach include water testing, nitrate and other environmental testing, basic biology and optics. Groups such as Public Labs, which is a community where citizen scientists can learn how to investigate environmental concerns using inexpensive DIY techniques, embody this approach.\n\nVideo technology has enabled expanded citizen science. The Citizen Science Center in the Nature Research Center wing of the North Carolina Museum of Natural Sciences has exhibits on how to get involved in scientific research and become a citizen scientist. For example, visitors can observe birdfeeders at the Prairie Ridge Ecostation satellite facility via live video feed and record which species they see.\n\nSince 2005, the Genographic Project has used the latest genetic technology to expand our knowledge of the human story, and its pioneering use of DNA testing to engage and involve the public in the research effort has helped to create a new breed of \"citizen scientist\". Geno 2.0 expands the scope for citizen science, harnessing the power of the crowd to discover new details of human population history. This includes supporting, organization and dissemination of personal DNA (genetic) testing. Like Amateur astronomy, citizen scientists encouraged by volunteer organizations like the International Society of Genetic Genealogy have provided valuable information and research to the professional scientific community.\n\nWith unmanned aerial vehicles, further citizen science is enabled. One example is the ESA's AstroDrone smartphone app for gathering robotic data with the Parrot AR.Drone.\n\nCitizens in Space (CIS), a project of the United States Rocket Academy, seeks to combine citizen science with citizen space exploration. CIS is training citizen astronauts to fly as payload operators on suborbital reusable spacecraft that are now in development. CIS will also be developing, and encouraging others to develop, citizen-science payloads to fly on suborbital vehicles. CIS has already acquired a contract for 10 flights on the Lynx suborbital vehicle, being developed by XCOR Aerospace, and plans to acquire additional flights on XCOR Lynx and other suborbital vehicles in the future.\n\nCIS believes that \"The development of low-cost reusable suborbital spacecraft will be the next great enabler, allowing citizens to participate in space exploration and space science.\"\n\nThe Internet has been a boon to citizen science, particularly through gamification. One of the first Internet-based citizen science experiments was NASA's Clickworkers, which enabled the general public to assist in the classification of images, greatly reducing the time to analyze large data sets. Another was the Citizen Science Toolbox, launched in 2003, of the Australian Coastal Collaborative Research Centre. Mozak is a game in which players create 3D reconstructions from images of actual human and mouse neurons, helping to advance understanding of the brain. One of the largest citizen science games is Eyewire, a brain-mapping puzzle game developed at the Massachusetts Institute of Technology that now has over 200,000 players. Another example is Quantum Moves, a game developed by the Center for Driven Community Research at Aarhus University, which uses online community efforts to solve quantum physics problems. The solutions found by players can then be used in the lab to feed computational algorithms used in building a scalable quantum computer.\n\nMore generally, Amazon's Mechanical Turk is frequently used in the creation, collection, and processing of data by paid citizens. There is controversy as to whether or not the data collected through such services is reliable, as it is subject to participants' desire for compensation. However, use of Mechanical Turk tends to quickly produce more diverse participant backgrounds, as well as comparably accurate data when compared to traditional collection methods.\n\nThe internet has also enabled citizen scientists to gather data to be analyzed by professional researchers. Citizen science networks are often involved in the observation of cyclic events of nature (phenology), such as effects of global warming on plant and animal life in different geographic areas, and in monitoring programs for natural-resource management. On BugGuide.Net, an online community of naturalists who share observations of arthropod, amateurs and professional researchers contribute to the analysis. By October 2014, BugGuide has over 808,718 images submitted by more than 27,846 contributors.\n\nThe Zooniverse is home to the internet's largest, most popular and most successful citizen science projects. The Zooniverse and the suite of projects it contains is produced, maintained and developed by the Citizen Science Alliance (CSA). The member institutions of the CSA work with many academic and other partners around the world to produce projects that use the efforts and ability of volunteers to help scientists and researchers deal with the flood of data that confronts them. On June 29, 2015, the Zooniverse released a new software version with a project-building tool allowing any registered user to create a project. Project owners may optionally complete an approval process to have their projects listed on the Zooniverse site and promoted to the Zooniverse community. A NASA/JPL picture to the right gives an example from one of Zooniverse's projects The Milky Way Project.\n\nThe website CosmoQuest has as its goal \"To create a community of people bent on together advancing our understanding of the universe; a community of people who are participating in doing science, who can explain why what they do matters, and what questions they are helping to answer.\n\nCrowdCrafting enables its participants to create and run projects where volunteers help with image classification, transcription, geocoding and more. The platform is powered by PyBossa software, a free and open-source framework for crowdsourcing.\n\nProject Soothe is a citizen science research project based at the University of Edinburgh. The aim of this research is to create a bank of soothing images, submitted by members of the public, which can be used to help others through psychotherapy and research in the future. Since 2015, Project Soothe has received over 600 soothing photographs from people in 23 countries. Anyone aged 12 years or over are eligible to participate in this research in two ways: (1) By submitting soothing photos that they have taken with a description of why the images make them feel soothed (2) By rating the photos that have been submitted by people worldwide for their soothability.\n\nThe bandwidth and ubiquity afforded by smartphone technology has vastly expanded the opportunities for citizen science. Examples include iNaturalist, the San Francisco project, the WildLab, Project Noah, and Aurorasurus. Due to their ubiquity, for example, Twitter, Facebook, and smartphones have been useful for citizen scientists, having enabled them to discover and propagate a new type of aurora dubbed \"STEVE\" in 2016.\n\nThere are also smartphone apps for monitoring birds, marine wildlife and other organisms, and the \"Loss of the Night\". \n\nAn Android app Sapelli is a mobile data-collection and -sharing platform designed with a particular focus on non-literate and illiterate users with little or no prior ICT experience. A smartphone focussed platform for Citizen Science applications is SPOTTERON, which creates synergy effects for projects by sharing a common feature set.\n\n\"The Crowd and the Cloud\" is a four-part series broadcast during April 2017, which examines citizen science. It shows how smartphones, computers and mobile technology enable regular citizens to become part of a 21st-century way of doing science. The programs also demonstrate how CSs help professional scientists to advance knowledge, which helps speed up new discoveries and innovations. The Crowd & The Cloud is based upon work supported by the National Science Foundation.\n\nSince 1975, in order to improve earthquake detection and collect useful information, the European-Mediterranean Seismological Centre monitors the visits of earthquake eyewitnesses to its website and relies on Facebook and Twitter.\n\nCitizen science has been used to provide valuable data in hydrology (catchment science), notably flood risk, water quality and water resource management. A growth in internet use and smartphone ownership has allowed users to collect and share real-time flood-risk information using, for example, social media and web-based forms. Although traditional data collection methods are well-established, citizen science is being used to fill the data gaps on a local level, and is therefore meaningful to individual communities. It has been demonstrated that citizen science is particularly advantageous during a flash flood because the public are more likely to witness these rarer hydrological events than scientists.\n\nThere are many CS projects in Africa and South America. Some examples in Africa are:\n\n\n\nCS projects in South America include:\n\n\n\nThe first Conference on Public Participation in Scientific Research was held in Portland, Oregon in August 2012. Citizen science is now often a theme at large conferences, such as the annual meeting of the American Geophysical Union.\n\nIn 2010, 2012 and 2014 there were three Citizen Cybersience summits, organised by the Citizen Cyberscience Centre in Geneva. The 2014 summit was hosted in London and attracted over 300 participants.\n\nIn January 2015, the ETH Zürich and University of Zürich hosted an international meeting on the \"Challenges and Opportunities in Citizen Science\".\n\nThe first citizen science conference hosted by the Citizen Science Association was in San Jose, California, in February 2015 in partnership with the AAAS conference. The Citizen Science Association conference, CitSci 2017, was held in Saint Paul, Minnesota, United States, between May 17 and 20, 2017. The conference had more than 600 attendees. The next CitSci is in March 2019 in Raleigh, USA.\n\nThe platform \"Österreich forscht\" hosts the annual Austrian citizen science conference since 2015.\n\n\n"}
{"id": "14386680", "url": "https://en.wikipedia.org/wiki?curid=14386680", "title": "Committee on the Public Understanding of Science", "text": "Committee on the Public Understanding of Science\n\nThe Committee on the Public Understanding of Science or Copus was founded in 1985 by the British Association for the Advancement of Science (BAAS), the Royal Institution and the Royal Society. Its aim was to interpret scientific advances and make them more accessible to non-scientists.\n\nIt played a part in developing the public understanding of science it establishing standards for communicating science and technology\n\nThe Copus Grant Schemes was set up in 1987 and the last round of grants was for 2003/4. The scheme was funded by the Office of Science and Technology and the Royal Society. 25 grants worth a total of over £750,000 were awarded in 2003/2004.\n\nIn 2000 The new Copus Council was formed to be a more inclusive partnership for science communication in the UK. In 2002 following a report commissioned by the Office of Science and Technology the Copus Council was discontinued.\n"}
{"id": "1773453", "url": "https://en.wikipedia.org/wiki?curid=1773453", "title": "Drapetomania", "text": "Drapetomania\n\nDrapetomania was a conjectural mental illness that, in 1851, American physician Samuel A. Cartwright hypothesized as the cause of enslaved Africans fleeing captivity. It has since been debunked as pseudoscience and part of the edifice of scientific racism.\n\nThe term derives from the Greek δραπέτης (\"drapetes\", \"a runaway [slave]\") and μανία (\"mania\", \"madness, frenzy\").\n\nIn \"Diseases and Peculiarities of the Negro Race\", Cartwright points out that the Bible calls for a slave to be submissive to his master, and by doing so, the slave will have no desire to run away.\n\nCartwright described the disorder – which, he said, was \"unknown to our medical authorities, although its diagnostic symptom, the absconding from service, is well known to our planters and overseers\" – in a paper delivered before the Medical Association of Louisiana that was widely reprinted.\n\nHe stated that the malady was a consequence of masters who \"made themselves too familiar with [slaves], treating them as equals\".\n\nIn addition to identifying drapetomania, Cartwright prescribed a remedy. His feeling was that with \"proper medical advice, strictly followed, this troublesome practice that many Negroes have of running away can be almost entirely prevented\".\n\nIn the case of slaves \"sulky and dissatisfied without cause\" – a warning sign of imminent flight – Cartwright prescribed \"whipping the devil out of them\" as a \"preventative measure\". As a remedy for this \"disease\", doctors also made running a physical impossibility by prescribing the removal of both big toes.\n\nWhile Cartwright's article was reprinted in the South, in the northern United States it was widely mocked. A satirical analysis of the article appeared in a \"Buffalo Medical Journal\" editorial in 1855. Renowned landscape architect Frederick Law Olmsted, in \"A Journey in the Seaboard Slave States\" (1856), observed that white indentured servants had often been known to flee as well, so he satirically hypothesized that the supposed disease was actually of white European origin, and had been introduced to Africa by traders.\n\nAs late as 1914, the third edition of Thomas Lathrop Stedman's \"Practical Medical Dictionary\" included an entry for \"drapetomania\", defined as \"Vagabondage, dromomania; an uncontrollable or insane impulsion to wander.\"\n\n\n\n"}
{"id": "24365881", "url": "https://en.wikipedia.org/wiki?curid=24365881", "title": "Energo-Chromo-Kinese", "text": "Energo-Chromo-Kinese\n\nEnergo-Chromo-Kinese, also named ECK, is a pseudo-scientific and esoteric-oriented new religious movement founded in October 1987 in Villefranche-sur-Mer by Patrick Véret, a former acupuncturist and homeopath, and his wife Danielle Drouant, now Danielle Didier.\n\nECK uses many associations and societies (including Connaissance ontologique universelle et recherche biologique énergétique (COURBE), Energo 8 international, Energo conseils, Jéricho 3000, Association pour la recherche en médecine énergétique and SOS Spasmophilie) and is particularly active in the therapeutic and medical fields. Centers and schools were subsequently established to teach the beliefs of the group, which won over business executives and major corporations, but especially doctors, dentists and kinesiotherapists. Customers who attend these four-degree courses become \"kinergists\". The doctrine is a \"gnostic pantheism\" and is explained in two books written by Patrick Véret: \"La Médecine énergétique\" and \"La spasmophilie enfin vaincue\", respectively written in 1981 and 1985. According to French cult consultant Jean-Marie Abgrall, ECK doctrines \"represent an amalgam (or a synthesis, according to its proponents) of various theories referring to human \"energy\" — mainly Chinese medicine and Vedic medicine. According to ECK, the human body has seven energy centers that vibrate on the same frequencies as certain colors or certain sounds.\"\n\nOn 22 February 1993, the French branch of the organization was dissolved by a court decision of the Tribunal de commerce of Paris and the founders split off. Véret founded the Nutrition énergétique des organes et des méridiens (NEOM), and his former wife Danielle Drouant led the Ordre du temple de la Jérusalem céleste (OTJC).\n\nThe movement is currently active in France, Switzerland, Spain, Italy, Canada, the United States, Portugal, Australia... In France, the group seems to be in the decline.\n\nECK was listed as a cult in the 1999 parliamentary report established by the Parliamentary Commission on Cults in France and also appeared in the 1997 Belgian parliamentary report. It was considered as dangerous because of its pseudo-medical speech which could be harmful to members' health, exaggerated requests for money, and indoctrination of the members who became dependent to the group. It was also criticized by anti-cult groups and former members.\n\nIn 2007, an academic thesis about the dangers of cults for health contained a large analysis of ECK beliefs and practices.\n"}
{"id": "45254767", "url": "https://en.wikipedia.org/wiki?curid=45254767", "title": "Expression Atlas", "text": "Expression Atlas\n\nThe Expression Atlas is a database that provides information on gene expression patterns. The Expression Atlas allows searches by gene, splice variant and protein attribute. Individual genes or gene sets can be searched for. There are two components to the Expression Atlas, the Baseline Atlas and the Differential Atlas:\n\nThe Baseline Atlas provides information about which gene products are present (and at what abundance) under \"normal\" conditions. This component of the Expression Atlas consists of highly curated and quality-checked RNA-seq experiments from ArrayExpress. It aims to answer questions such as:\n\n\nThe Differential Atlas allows users to identify genes that are up- or down-regulated in different experimental conditions.\n\n\n\n"}
{"id": "43397800", "url": "https://en.wikipedia.org/wiki?curid=43397800", "title": "Fields of Science and Technology", "text": "Fields of Science and Technology\n\nFields of Science and Technology (FOS) is a compulsory classification for statistics of branches of scholarly and technical fields, published by the OECD in 2002. It was created out of the need to interchange data of research facilities, research results etc. It was revised in 2007 under the name \"Revised Fields of Science and Technology\". \n\n\n"}
{"id": "43040461", "url": "https://en.wikipedia.org/wiki?curid=43040461", "title": "GikII", "text": "GikII\n\nGikII is a series of European workshops on the intersections between law, technology and popular culture. It is hosted at a different institution every year. The first conference was in 2006 and was held in Edinburgh, and was organised by Lilian Edwards and Andres Guadamuz.\n\nThe conference has been held in several European universities and institutions, including UCL, Oxford, Edinburgh, Amsterdam, Humboldt Institute in Berlin, and Sussex.\n\nThe conference deals with what the organisers describe as \"geek law\", studying the intersection of law, regulation, popular culture and technology. The covered topics include artificial intelligence, cryptocurrencies, virtual worlds, games, tattoos, 3D printing, fan fiction, digital privacy, avatar rights, augmented reality, and robots.\n\nThe Call for Papers of the first workshop gave the following explanation:\n\nGeeks are the people who contribute to this knowledge: fellow travellers on the digital omnibus, who delight in finding, publishing, inventing and sharing nuggets of joyful knowledge and innovation from the worlds of technology, science, popular culture, and technotrivia. LIIs are Legal Information Institutes: invaluable on-line temples of legal knowledge. The patriarch of the field is AustLII, but the concept has spread through the world bringing us BAILII, PacLII, CommonLII, and no doubt, many more bad puns to come.\n\nGikII proposes to be the place where these worlds, institutions and players will come together for the first time at a major law and technology conference.\n"}
{"id": "20923452", "url": "https://en.wikipedia.org/wiki?curid=20923452", "title": "Government scientist", "text": "Government scientist\n\nA government scientist is a scientist employed by a country's government, either in a research-driven job (for example J. Robert Oppenheimer on the Manhattan Project), or for another role that requires scientific training and methods. In some countries other terms such Technical officers is also used for scientists.\n\nIn Australia, most government scientists are employed by the Commonwealth Scientific and Industrial Research Organisation. A Chief Scientist is appointed to advise the government through the Office of the Chief Scientist.\n\nIn Singapore, government scientists are classified according to the Departmental Titles (Alteration) (Amendment) Act 1996, which amended the Departmental Titles (Alteration) Ordinance of 1950.\nIn the United Kingdom, government scientists are part of the Scientific Civil Service. However, that was not always the case. Before the Second World War, government scientists were recruited and employed by the Civil Service on an ad hoc basis, with grades, job titles, and organizations that varied between departments. In 1930, the Carpenter Committee was appointed to investigate the organization of civil service scientific and technical staff, and its report proposed a reorganization that covered the entire Service. This report was endorsed by the Tomlin Commission, however it was impossible to reach agreement with the relevant staff associations, who wanted other professional groups within the civil service to be similarly reorganized, and nothing ended up happening.\n\nWorld War Two changed this by causing a far greater number of scientific and technical staff to be employed by the government. The Barlow Committee on Scientific Staff in Government Departments reviewed the positions of government scientists during wartime, issuing a report on 1943-04-23. This report spurred the creation of a government white paper, entitled \"The Scientific Civil Service\", which resulted in a reorganization of government scientisgts across the entire Service. This reorganization classified governmenvnt scientists across the entire Service into three major classes similar to those civil servants for the Treasury had already been classified in:\n\nIn the United States, the employment of scientists by state and federal governments was, like in the U.K., affected by the Second World War. President Roosevelt first created the National Defense Research Committee under Vannevar Bush. This was then expanded to the Office of Scientific Research and Development, also led by Bush. The OSRD employed scientists on a contract basis, with the OSRD as client and individual scientists as contractors. Scientists were contracted to research (through study and experiment) a specified subject, without constraints as to method, and to issue reports to the OSRD.\n\nAfter the war, scientific research was continued by agencies such as the Office of Naval Research established in 1947, which again employed scientists as contractors. Scientific research was published in the normal way. The Atomic Energy Commission, established in 1946, and the National Institutes of Health, established in 1930, also paid scientists for scientific research, and were major sources of government research funding.\n\nThe National Science Foundation was eventually established in 1950. Defence research was explicitly excluded from its charter, even though Dr Bush had originally envisioned the NSF as including that as well. The armed forces established their own research departments, such as the Office of Ordnance Research for the Department of the Army, established on the campus of Duke University in June 1951.\n\nU.S. local, state, and federal governments also employ scientists directly. The federal government employs them in departments such as the Department of Agriculture, Department of the Interior, and the Public Health Service. States and cities employ scientists in similar roles, including at fish and game commissions, parks, aquariums, arboretums, and museums; and at agencies such as environmental inspection agencies, crime laboratories, and public health monitoring agencies.\n"}
{"id": "177793", "url": "https://en.wikipedia.org/wiki?curid=177793", "title": "Great chain of being", "text": "Great chain of being\n\nThe Great Chain of Being is a strict hierarchical structure of all matter and life, thought in medieval Christianity to have been decreed by God. The chain starts with God and progresses downward to angels, demons (fallen/renegade angels), stars, moon, kings, princes, nobles, commoners, wild animals, domesticated animals, trees, other plants, precious stones, precious metals and other minerals.\n\nThe Great Chain of Being (, \"Ladder of Being\") is a concept derived from Plato, Aristotle (in his \"Historia Animalium\"), Plotinus and Proclus. Further developed during the Middle Ages, it reached full expression in early modern Neoplatonism.\n\nThe Chain of Being is composed of a great number of hierarchical links, from the most basic and foundational elements up through the very highest perfection: God.\n\nGod sits at the top of the chain, and beneath him sit the angels, both existing wholly in \"spirit\" form. Earthly flesh is fallible and ever-changing, mutable. Spirit, however, is unchanging and permanent. This sense of permanence is crucial to understanding this conception of reality. It is generally impossible to change the position of an object in the hierarchy. (One exception might be in the realm of alchemy, where alchemists attempted to transmute base elements, such as lead, into higher elements, either silver or, more often, gold—the highest \"element\".)\n\nIn the natural order, earth (rock) is at the bottom of the chain; this element possesses only the attribute of existence. Each link succeeding upward contains the positive attributes of the previous link and adds at least one other. Rocks possess only existence; the next link up is plants which possess life \"and\" existence. Animals add motion and appetite as well.\n\nMan is both mortal flesh, as those below him, and also spirit, as those above. In this dichotomy, the struggle between flesh and spirit becomes a moral one. The way of the spirit is higher, more noble; it brings one closer to God. The desires of the flesh move one away from God. The Christian fall of Lucifer is thought of as especially terrible, as angels are wholly spirit, yet Lucifer defied God (who is the ultimate perfection).\n\nEach link in the chain might be divided further into its component parts. In medieval secular society, for example, the king is at the top, succeeded by the aristocratic lords and the clergy, and then the peasants below them. Solidifying the king's position at the top of humanity's social order is the doctrine of the Divine Right of Kings. The implied permanent state of inequality became a source of popular grievance, and led eventually to political change as in the French Revolution. In the family, the father is head of the household; below him, his wife; below her, their children.\n\nMilton's \"Paradise Lost\" ranked the angels (c.f. Pseudo-Dionysius the Areopagite's ranking of angels), and Christian culture conceives of angels in orders of archangels, seraphim, and cherubim, among others.\n\nSubdivisions are equally apparent among animals. At the top of the animals are wild beasts (such as lions), which were seen as superior as they defied training and domestication. Below them are domestic animals, further sub-divided so that useful animals (such as dogs and horses) are higher than docile creatures (such as sheep). Birds are also sub-divided, with eagles above pigeons, for example. Fish come below birds and are subdivided between actual fish and other sea creatures. Below them come insects, with useful insects such as spiders and bees and attractive creatures such as ladybirds and dragonflies at the top, and unpleasant insects such as flies and beetles at the bottom. At the very bottom of the animal sector are snakes, which are relegated to this position as punishment for the serpent's actions in the Garden of Eden.\n\nBelow animals comes the division for plants, which is further subdivided. Trees are at the top, with useful trees such as oaks at the top, and the traditionally demonic yew tree at the bottom. Food-producing plants such as cereals and vegetables are further subdivided.\n\nAt the very bottom of the chain are minerals. At the top of this section are metals (further sub-divided, with gold at the top and lead at the bottom), followed by rocks (with granite and marble at the top), soil (subdivided between nutrient-rich soil and low-quality types), sand, grit, dust, and dirt at the very bottom of the entire great chain.\n\nThe central concept of the Chain of Being is that everything imaginable fits in somewhere, giving order and meaning to the universe.\n\nGod is at the top of the chain and is also external to creation. God is believed to exist outside the physical limitations of time and space. He possessed the spiritual attributes of reason, love, and imagination, like all spiritual beings, but he alone possessed the divine attributes of omnipotence, omniscience, and omnipresence. God serves as the model of authority for the strongest, most virtuous, most excellent type of being within any category.\n\nAngels were beings of pure spirit who had no physical bodies of their own. In order to affect the physical world, angels were thought to build temporary bodies for themselves out of particles of earthly elements. Medieval and Renaissance theologians believed angels to possess reason, love, imagination, and, like God, to stand outside the physical limitations of time. They possessed sensory awareness unbound by physical organs, and they possessed language. They lacked, however, the divine attributes of omnipotence, omniscience, and omnipresence of God, and they simultaneously lacked the physical passions experienced by humans and animals. Depending upon the author, the class of angels was further subdivided into three, seven, nine, or ten ranks, variously known as triads, orders, or choirs. Each rank had greater power and responsibility than the entities below them. The most common classification is that of St. Thomas Aquinas. \n\n\nFor Medieval and Renaissance thinkers, humans occupied a unique position on the Chain of Being, straddling the world of spiritual beings and the world of physical creation. Humans were thought to possess divine powers such as reason, love, and imagination. Like angels, humans were spiritual beings, but unlike angels, human souls were \"knotted\" to a physical body. As such, they were subject to passions and physical sensations—pain, hunger, thirst, sexual desire—just like other animals lower on the Chain of Being. They also possessed the powers of reproduction unlike the minerals and rocks lowest on the Chain of Being. Humans had a particularly difficult position, balancing the divine and the animalistic parts of their nature. For instance, an angel is only capable of intellectual sin such as pride (as evidenced by Lucifer's fall from heaven in Christian belief). Humans, however, were capable of both intellectual sin and physical sins such as lust and gluttony if they let their animal appetites overrule their divine reason. Humans also possessed sensory attributes: sight, touch, taste, hearing, and smell. Unlike angels, however, their sensory attributes were limited by physical organs (they could only know things discerned through the five senses). The highest-ranking human being was the king.\n\nAnimals, like humans higher on the chain, were animated (capable of independent motion). They possessed physical appetites and sensory attributes, the number depending upon their position within the Chain of Being. They had limited intelligence and awareness of their surroundings. Unlike humans, they were thought to lack spiritual and mental attributes such as immortal souls and the ability to use logic and language. The primate of all animals (the \"king of beasts\") was variously thought to be either the lion or the elephant. However, each subgroup of animals also had its own primate, an avatar superior in qualities of its type.\n\n\nNote that avian creatures, linked to the element of air, were considered superior to aquatic creatures linked to the element of water. Air naturally tended to rise and soar above the surface of water, and analogously, aerial creatures were placed higher in the chain.\n\n\nThe chart would continue to descend through various reptiles, amphibians, and insects. The higher up the chart one went, the more noble, mobile, strong, and intelligent the creature in Renaissance belief. At the very bottom of the animal section, we find sessile creatures like the oysters, clams, and barnacles. Like the plants below them, these creatures lacked mobility, and were thought to lack various sensory organs such as sight and hearing. However, they were still considered superior to plants because they had tactile and gustatory senses (touch and taste).\n\nPlants, like other living creatures, possessed the ability to grow in size and reproduce. However, they lacked mental attributes and possessed no sensory organs. Instead, their gifts included the ability to eat soil, air, and \"heat.\" Plants did have greater tolerances for heat and cold, and immunity to the pain that afflicts most animals. At the very bottom of the botanical hierarchy, fungi and mosses, lacking leaf and blossom, were so limited in form that Renaissance thinkers thought them scarcely above the level of minerals. However, each plant was also thought to be gifted with various edible or medicinal virtues unique to its own type.\n\n\nCreations of the earth, the lowest of elements, all minerals lacked the plant's basic ability to grow and reproduce. They also lacked mental attributes and sensory organs found in beings higher on the chain. Their unique gifts, however, were typically their unusual solidity and strength. Many minerals, in fact, were thought to possess magical powers, particularly gems. The mineral primate is the diamond.\n\n\nThe basic idea of a ranking of the world's organisms goes back to Aristotle's biology. In his \"History of Animals\", where he ranked animals over plants based on their ability to move and sense, and graded the animals by their reproductive mode and possession of blood (he ranked all invertebrates as \"bloodless\").\n\nAristotle's non-religious concept of higher and lower organisms was taken up by natural philosophers during the Scholastic period to form the basis of the \"Scala Naturae\". The \"scala\" allowed for an ordering of beings, thus forming a basis for classification where each kind of mineral, plant and animal could be slotted into place. In medieval times, the great chain was seen as a God-given ordering: God at the top, dirt at the bottom, every grade of creature in its place. Just as rock never turns to flowers and worms never turn to lions, humans never turn to angels. This was not our lot in life. In the Northern Renaissance, the scientific focus shifted to biology. The threefold division of the chain below humans formed the basis for Linnaeus's \"Systema Naturæ\" from 1737, where he divided the physical components of the world into the three familiar kingdoms of minerals, plants and animals.\n\nThe set nature of species, and thus the absoluteness of creatures' places in the great chain, came into question during the 18th century. The dual nature of the chain, divided yet united, had always allowed for seeing creation as essentially one continuous whole, with the potential for overlap between the links. Radical thinkers like Jean-Baptiste Lamarck saw a progression of life forms from the simplest creatures striving towards complexity and perfection, a schema accepted by zoologists like Henri de Blainville. The very idea of an ordering of organisms, even if supposedly fixed, laid the basis for the idea of transmutation of species, for example Charles Darwin's theory of evolution.\n\nThe Chain of Being continued to be part of metaphysics in 19th century education, and the concept was well known. The geologist Charles Lyell used it as a metaphor in his 1851 \"Elements of Geology\" description of the geological column, where he used the term \"missing links\" in relation to missing parts of the continuum. The term \"missing link\" later came to signify transitional fossils, particularly those bridging the gulf between man and beasts.\n\nThe idea of the great chain as well as the derived \"missing link\" was abandoned in early 20th century science, as the notion of modern animals representing ancestors of other modern animals was abandoned in biology. The idea of a certain sequence from \"lower\" to \"higher\" however lingers on, as does the idea of progress in biology.\n\nAllenby and Garreau propose the Catholic Church's narrative of the Great Chain of Being kept the peace for centuries in Europe. The very concept of rebellion simply lay outside the reality within which most people lived for to defy the King was to defy God. King James I himself wrote, \"The state of monarchy is the most supreme thing upon earth: for kings are not only God's Lieutenants upon earth, and sit upon God's throne, but even by God himself they are called Gods.\"\n\nThe Enlightenment broke this supposed divine plan and fought the last vestiges of feudal hierarchy by creating secular governmental structures that vested power into the hands of ordinary citizens rather than divinely ordained monarchs.\n\nHowever, scholars such as Brian Tierney and Michael Novak have noted the medieval contribution to democracy and human rights.\n\nThe American spiritual writer and philosopher Ken Wilber uses a concept called the \"Great Nest of Being\" which is similar to the Great Chain of Being, and which he claims to belong to a culture-independent \"perennial philosophy\" traceable across 3000 years of mystical and esoteric writings. Wilber's system corresponds with other concepts of transpersonal psychology.\n\nIn the 1977 book \"A Guide for the Perplexed\", British philosopher and economist E. F. Schumacher wrote that fundamental gaps exist between the existence of minerals, plants, animals and humans, where each of the four classes of existence is marked by a level of existence not shared by that below. Clearly influenced by the great chain of being, but lacking the angels and God, he called his hierarchy the \"levels of being\". In the book, he claims that science has generally avoided seriously discussing these discontinuities, because they present such difficulties for strictly materialistic science, and they largely remain mysteries.\n\n"}
{"id": "19128312", "url": "https://en.wikipedia.org/wiki?curid=19128312", "title": "Hungarian Turanism", "text": "Hungarian Turanism\n\nHungarian Turanism () is a diverse phenomenon that revolves around an identification or association of Hungarian history and people with the histories and peoples of Central Asia, Inner Asia or the Ural region. It includes many different conceptions and served as a guiding principle for many political movements. It was most lively in the second half of the 19th century and in the first half of the 20th century. It is related to the concept of Turanism.\n\nHungarian nobiliary historical tradition considered the Turkish peoples the closest relatives of Hungarians. This tradition was preserved in medieval chronicles (such as Gesta Hungarorum and Gesta Hunnorum et Hungarorum, the Chronicon Pictum, and Chronica Hungarorum by Johannes de Thurocz) as early as the 13th century. According to Chronica Hungarorum, the Hungarians are descendants of the Huns, and came from the Asian parts of Scythia, and Turks share this Scythian origin with them. This tradition served as starting point for the scientific research of the ethnogenesis of Hungarian people, which began in the 18th century, in Hungary and abroad. Sándor Kőrösi Csoma (the writer of the first Tibetan-English dictionary) traveled to Asia in the strong belief that he could find the kindred of Magyars in Turkestan, amongst the Uyghurs.\n\nBefore the Hungarian conquest of the Carpathian Basin, the Hungarians were semi-nomadic and their culture was similar to other steppe peoples. Most scientists presume a Uralic homeland for the ancient Hungarian conquerors (mainly on genealogical linguistic grounds, and on the basis of genetic research carried out on a limited number of ancient skeletons found in graves from the age of the conquest). The proto-Hungarian tribes lived in the Eurasian forest steppe zone, and so these ancient ancestors of Hungarians and their relationship with other equestrian nomadic peoples has been and still is a topic for research.\n\nAs a scientific movement, Turanism was concerned with research into Asian cultures in the context of Hungarian history and culture. It was embodied and represented by many scholars who had shared premises (i.e. the Asian origin of the Hungarians, and their kinship with Asian peoples), and who arrived at the same or very similar conclusions. Turanism was a driving force in the development of Hungarian social sciences, especially linguistics, archaeology and Orientalism.\n\nPolitical Turanism was born in the 19th century, in response to the growing influence of Pan-Germanism and Pan-Slavism, seen by Hungarians as very dangerous to the nation, and the state of Hungary, because the country had large ethnic German and Slavic populations. This political ideology originated in the work of the Finnish nationalist and linguist Matthias Alexander Castrén, who championed the ideology of Pan-Turanism — the belief in the racial unity and future greatness of the Ural-Altaic peoples. He concluded that the Finns originated in Central Asia and far from being a small, isolated people, they were part of a larger community that included such peoples as the Magyars, the Turks, and the Mongols etc. Political Turanism was a romantic nationalist movement, which stressed the importance of common ancestry and cultural affinity between Hungarians and the peoples of the Caucasus and Inner and Central Asia, such as the Turks, Mongols, Parsi etc. It called for closer collaboration and political alliance between them and Hungary, as a means of securing and furthering shared interests and to counter the threats posed by the policies of the great powers of Europe. The idea for a \"Turanian brotherhood and collaboration\" was borrowed from the Pan-Slavic concept of \"Slavic brotherhood and collaboration\".\n\nAfter the First World War, political Turanism played a role in the formation of Hungarian far-right ideologies because of its ethnic nationalist nature. It began to carry anti-Jewish sentiments and tried to show the \"existence and superiority of a unified Hungarian race\". Nonetheless, Andrew C. Janos asserts that Turanism's role in the interwar development of far-right ideologies was negligible.\n\nIn the communist era after the Second World War, Turanism was portrayed and vilified as an exclusively fascist ideology. Since the fall of communism in 1989 there has been a renewal of interest in Turanism.\n\nFriedrich Max Müller, the German Orientalist and philologist, published and proposed a new grouping of the non-Aryan and non-Semitic Asian languages in 1855. In his work \"The languages of the seat of war in the East. With a survey of the three families of language, Semitic, Arian, and Turanian.\" he called these languages \"Turanian\". Müller divided this group into two subgroups, the Southern Division, and the Northern Division. Hungarian language was classed by him as a member of this Northern Division, in the Finnic Class, in the Ugric Branch, with the Voguls and Ugro-Ostiakes as closest relatives. (In the long run, his evolutionist theory about languages' structural development, tying growing grammatical refinement to socio-economic development, and grouping languages into 'antediluvian', 'familial', 'nomadic', and 'political' developmental stages proved unsound, but his Northern Division was renamed and re-classed as the Ural-Altaic languages.) His theory was well known and widely discussed in international scientific circles, and was known to Hungarian scientists as well. He was invited to Budapest, the Hungarian capital, by Ármin Vámbéry, the Orientalist and Turkologist, in 1874, and become an associate member of the Hungarian Aceademy of Sciences. His public lectures received wide attention, and his terms (originally borrowed by him from Persian texts like the Shahnameh which used the term \"Turan\" to denote the territories of Turkestan, north of Amu Darya river, inhabited by nomadic warriors) \"Turan\" and \"Turanian\" become denizens in Hungarian language as \"Turán\" and \"turáni\". The meaning of these terms was never defined officially. Vámbéry himself used \"Turan\" to denote the areas of Eastern Balkan, Central and Inner Asia inhabited by Turkic peoples, and used \"Turanian\" to denote those Turkic peoples and languages (and he meant the Finno-Ugric peoples and languages as the members of this group), which lived in or originated from this \"Turan\" area. Hungarian scientists shared his definition. But in common parlance these terms were used in many (and often different) meanings and senses.\n\nHungarians have had a thousand year old, and still living tradition about the Asian origins of Magyars. This tradition was preserved in medieval chronicles (such as Gesta Hungarorum and Gesta Hunnorum et Hungarorum) as early as the 13th century. This tradition served as starting point for the scientific research of the ethnogenesis of Hungarian people, which began in the 18th century, in Hungary and abroad. Sándor Kőrösi Csoma (the writer of the first Tibetan-English dictionary) traveled to Asia in the strong belief that he could find the kindred of Magyars in Turkestan, amongst the Uyghurs.\n\n\"...when Kőrösi set off for the search of the ancient homeland of Magyars and the 'left behind Magyars', he considered that he might find those somewhere in Central Asia, respectively amongst the Uighurs...\"\n\nVámbéry Ármin had the same motivation for his travels to Asia and the Ottoman Empire.\n\n\"...from this came my hope, that with the help of comparative linguistics I could find a ray of light in Central Asia, which dispels the gloom over the dark corners of Hungarian prehistory...\"\n\n\"...\"következett tehát ebből az a reménységem, hogy Középázsiában az összehasonlító nyelvtudomány segítségével világosságot vető sugarat lelhetek, mely eloszlatja a homályt a magyar őstörténelem sötét tájairól\"...\" in: Vámbéry Ármin: Küzdelmeim. Ch.IV. p. 62.\n\nThe linguistic theories of the Dutch philosopher Marcus Zuerius van Boxhorn and the German thinker Gottfried Wilhelm Leibniz gave the real basis of the modern scientific research of the origin of the Hungarian language and people. Boxhorn conjectured that the European and Indo-Iranian languages were all derived from a shared ancestor language, and he named this ancestor language \"Scythian\", after the equestrian, nomadic warriors of the Asian steppes. But linguists theorizing about ancestor languages had to deal with the common belief of the era, that, according to the Bible, Hebrew was the original language of all humans. Leibniz published material countering the Biblical theory, and supported Boxhorn's notion of a Scythian ancestor language.\n\n\"Information about hither-to unknown peoples and languages of Asia and the Americas came into the hands of scholars such as Gottfried Leibniz, who recognized that there was no better method “for specifying the relationship and origin of the various peoples of the earth, than the comparison of their languages”. In order to classify as many languages as possible in genealogical groupings, Leibniz proposed that similar materials be collected from each newly described language. To this end he asked that explorers either obtain translations of well-known Christian prayers such as the Pater Noster, or, better yet, “words for common things” (vocabula rerum vulgarium), a sample list of which he appended to a letter to the Turkologist D. Podesta (Leibniz 1768/1989b).The word list included numerals, kinship terms, body parts, necessitates (food, drink, weapons,domestic animals), naturalia (God, celestial and weather phenomena, topographic features, wild animals) and a dozen verbs (eat, drink, speak, see …). Leibniz took a particular interest in the expansion of the Russian Empire southward and eastward, and lists based on his model were taken on expeditions sent by the tsars to study the territories recently brought under their control, as well as the peoples living on these and on nearby lands.\" Kevin Tuite: \"The rise and fall and revival of the Ibero-Caucasian hypothesis.\" 2008. in: Historiographia Linguistica, 35 #1; p. 23-82.\n\nLeibniz recognized that the Semitic languages such as Hebrew and Arabic, and some European languages like Sami, Finnish, and Hungarian did not belong to the same language family as most of the languages of Europe. He recognized the connection between the Finnish languages and Hungarian. He placed the original homeland of the Hungarians to the Volga-Caspian Sea region.\n\nThese theories had a great impact on the research of the origins of the Hungarian language and the ethnogenesis of Hungarian nation. Both of the two main views/theories about the origin of the Hungarian people and language, the one about the Turkic origin, and the other about the Finno-Ugric origin had their scientific roots in them.\n\nIn fact, the Turkic theory matched the tradition (the Gestas) and historical sources (like the works of Constantine VII and Leo VI the Wise) better, but the accounts and works of travelers like Swedish Philip Johan von Strahlenberg (published in his work:\" An historico-geographical description of the north and east parts of Europe and Asia \") turned the attention to the \"Finnish-Hungarian connection\".\n\nJohann Eberhard Fischer (1697-1771) was a German historian and language researcher, who participated in the Great Northern Expedition of 1733-1743. In his work “Qvaestiones Petropolitanae, De origine Ungrorum”, published in 1770, he put Hungarian into a group of kindred peoples and languages which he called 'Scythian'. He considered the Ugric peoples (he called them ‘Jugors’, these are the Khanty and Mansi) the closest relatives of Hungarians, actually as ‘Magyars left behind’, and originated them from the Uyghurs, who live on the western frontiers of China.\n\nThe followers of the \"Turkist\" and \"Ugrist\" theories lived together peacefully, and the theories were refined as science developed. (In fact the two theories converged, as linguists, like Rasmus Christian Rask, Wilhelm Schott (1802-1889) and Matthias Castrén recognized the similarities and connection between Finn-Ugric and Altaic languages. The German linguist and Orientalist Schott was a proponent of Finn-Turk-Hungarian kinship, and considered the Hungarians a mixture of Turks and Hyperboreans / i.e. Saami, Samoyed etc. /.) The discourse remained fully scientific up until the Hungarian Revolution of 1848 and the 1848-49 War of Independence but after the bitter experiences of the war and the defeat everything got political overtones.\n\n\"... the Sun went down into a sea of blood. The night of immeasurable grief fell on Hungary; her noblest powers were broken. Even the gates of scientific institutions became closed...\"\n\n\"...\"a Nap vértengerbe áldozott le. Magyarországra a mérhetetlen gyásznak éjszakája borult; legnemesebb erői törve voltak. Még a tudományos intézetek kapui is bezárultak\"...\" in: Herman Ottó: Petényi J. S. a magyar tudományos madártan megalapítója. p. 39.\n\nHungary's constitution and her territorial integrity were abolished, and her territory was partitioned into crown lands. This signalled the start of a long era of absolutist rule. The Habsburgs introduced dictatorial rule, and every aspect of Hungarian life was put under close scrutiny and governmental control. Press and theatrical/public performances were censored.\n\nGerman became the official language of public administration. The edict issued on 1849.X.9. (Grundsätze für die provisorische Organisation des Unterrichtswesens in dem Kronlande Ungarn), placed education under state control, the curriculum was prescribed and controlled by the state, the education of national history was confined, and history was educated from a Habsburg viewpoint. Even the bastion of Hungarian culture, the Academy was kept under control: the institution was staffed with foreigners, mostly Germans and ethnic Germans, and the institution was practically defunct until the end of 1858. Hungarians responded with passive resistance. Questions of nation, language, national origin became politically sensitive matters. Anti-Habsburg and anti-German sentiments were strong. A large number of freedom fighters took refuge in the Ottoman Empire. This resulted in renewed cultural exchange, and mutual sympathy. Turks were seen by many as good allies of the Hungarian cause. Such was the atmosphere, when Vámbéry traveled to Constantinople in 1857 for the first time.\n\n\"It should happen and it will happen - I encouraged myself with this, and did not hurt me other problems, just this one: how could I get a passport from the strict and suspicious Austrian authorities, and exactly to Turkey, where the Hungarian emigration resided, and, as was believed in Vienna, made rebellious plans tirelessly.\"\n\n\"Mennie kell és menni fog, - ezzel biztattam magam és nem bántott más gond, csak az az egy: hogy mi úton-módon kaphatok útlevelet a szigorú és gyanakvó osztrák hatóságtól; hozzá még épen Törökországba, hol akkor a magyar emigráczió tartotta székét és, mint Bécsben hitték, pártütő terveket sző fáradhatatlanúl.\" in: Vámbéry Ármin: Küzdelmeim. Ch. IV. p. 42.\n\nAnd this atmosphere granted public interest for the then new theory of Max Müller. The Habsburg government saw this \"Turkism\" as dangerous to the empire, but had no means to suppress it. (The Habsburg Empire lost large territories in the early 19th century /Flanders and Luxembourg/, and lost most of its Italian holdings a little later, so many members of the Austrian political elite (Franz Joseph I of Austria himself, Archduke Albrecht, Duke of Teschen, major general Ferdinand Franz Xaver Johann Freiherr Mayerhofer von Grünbühel for example)) dreamed about Eastern land grabs.)\n\nAs a consequence of the Franco-Austrian War and the Austro-Prussian War, the Habsburg Empire was on the verge of collapse in 1866, because these misfortunate military endeavours resulted in increased state spending, speeding inflation, towering state debts and financial crisis.\n\nThe Habsburgs were forced to reconcile with Hungary, to save their empire and dynasty. The Habsburgs and part of the Hungarian political elite arranged the Austro-Hungarian Compromise of 1867. The Compromise was arranged and legitimated by a very small part of the Hungarian society (suffrage was very limited: less than 8 percent of the population had voting rights), and was seen by a very large part of the population as betrayal of the Hungarian cause and the heritage of the 1848-49 War of Independence. This caused deep and lasting cracks in Hungarian society. Academic science remained under state scrutiny and pressure, and press remained under (albeit more permissive) censorship. Matters of nation, language, national origin remained politically sensitive themes, and Turkism remained popular.\n\n\"However, to get the Compromise accepted within the society posed serious difficulties. Many counties (for example Heves, Pest, Szatmár) rejected the Compromise and stood up for Kossuth, the opposition organized a network of Democratic circles, on the Great Hungarian Plain anti-government and anti-Compromise demonstrations of several thousand men took place, etc. The government, suspending its liberal principles, decided to take firm counter moves: imprisoned László Böszörményi who published the Kossuth letters, banned the Democratic circles, sent a royal commissioner to the most resistant Heves County. The stabilization of the system and the admittance of new political institutions, however, still dragged on for years.\"\n\n\"Viszont a kiegyezés elfogadtatása a társadalommal, komoly nehézségekbe ütközött. Több megye (például Heves, Pest, Szatmár) elutasította a kiegyezést és kiállt Kossuth mellett, az ellenzék megszervezte a demokrata körök hálózatát, az Alföldön többezres kormány- és kiegyezés-ellenes népgyűlésekre került sor stb. A kormány, felfüggesztve liberális elveit, határozott ellenlépésekre szánta el magát: bebörtönözte a Kossuth leveleit közlő Böszörményi Lászlót, betiltotta a demokrata köröket, a leginkább ellenálló Heves megyébe pedig királyi biztost küldött. A rendszer stabilizálása és az új politikai intézmények elfogadása azonban még így is évekig elhúzódott.\" in: Cieger András: Kormány a mérlegen - a múlt században.\n\nVámbéry started his second journey into Asia in July 1861 with the approval and monetary help of the Akadémia and its president, Emil Dessewffy. After a long and perilous journey he arrived at Pest in May 1864. He went to London to arrange the English language publication of his book about the travels. \"Travels in Central Asia\" and its Hungarian counterpart \"Közép-ázsiai utazás\" were published in 1865. Thanks to his travels Vámbéry became an internationally renowned writer and celebrity. He became acquainted with members of British social elite. The Ambassador of Austria in London gave him a letter of recommendation to the Emperor, who received him in an audience and rewarded Vámbéry's international success by granting him professorship in the Royal University of Pest.\n\nVámbéry published his \"Vámbéry Ármin vázlatai Közép-Ázsiából. Ujabb adalékok az oxusmelléki országok népismereti, társadalmi és politikai viszonyaihoz.\" in 1868. Perhaps this was the first instance of the use of the word \"turáni\" in a Hungarian language scientific text.\n\nAt the beginning of Hungarian Turanism, some of its notable promoters and researchers, like Ármin Vámbéry, Vilmos Hevesy, (Also known as Wilhelm von Hevesy(1877-1945) He was the older brother of György Hevesy, and an electrical engineer by profession, although he was kind of a Finno-Ugrist publishing books and other writings about the Finno-Ugric-Munda kinship, like \"Munda-Magyar-Maori, an Indian link between the antipodes new tracks of Hungarian origins\" and \"Finnisch-Ugrisches aus Indien\" in the 1920s and 30's.) and Ignác Goldziher were Jewish or of Jewish descent (Vámbéry was neither proud nor ashamed of his Jewish ancestry, he became a member of the Reformed Church, and considered himself Hungarian).\n\nVámbéry was a key figure in the development of Turanism, and in the development of the \"scientific consciousness\" of the general public. He was a talented writer: he presented serious scientific matters in an interesting, readable manner. His enjoyable books and other writings, presenting customs, traditions and culture of far-flung peoples and faraway places were key in raising wide public interest in ethnography, ethnology and history. In fact, the power of his books, coupled with the widespread disillusionment about the political elite turned public attention to the lower classes and peasantry, as better heirs and keepers of real Hungarian legacy.(The neologists of the first half of the 19th century had turned towards folklore, myths, ballads and tales in their search of a new national literary style, but had not had interest in other aspects of rural peasant life.)\n\nVámbéry's later work, entitled \"Magyar és török-tatár szóegyezések.\" and published in 1869-70, was the casus belli of the \"Ugor-török háború\" (\"Ugric-Turk War\"), which started as a scientific dispute, but quickly turned into a long-lasting (it raged for two decades) bitter feud. In this work Vámbéry tried to prove with the help of word comparisons, that as a result of intermingling of the early Hungarians with Turkic peoples, the Hungarian language got a distinct dual (Ugric AND Turkic) character, albeit it is basically Ugric in origin, so he presented a variant of linguistic contact theory.\n\n\"...the Hungarian language is Ugric in its origin, but because the nations later contact and historical transformation it is equally Ugric and Turkic in character...\"\n\n\"...\"a magyar nyelv eredetében ugor, de a nemzet későbbi érintkezése és történeti átalakulásánál fogva egyformán ugor és török jellemű\"...\" in: Vámbéry Ármin: Magyar és török-tatár szóegyezések. p. 120.\n\n\"The fight, which my fanatical opponents, regrettably, brought over also to the field of personal remarks, lasted quite a long time, but the old Latin proverb was proven once again: Philologi certant, tamen sub judice lis.\"\n\n\"A küzdelem, melyet fanatikus ellenfeleim, sajnos, átvittek a személyeskedés terére is, eltartott jó sokáig, de ezúttal is bevált a régi diák közmondás: Philologi certant, tamen sub judice lis.\" in: Vámbéry Ármin: Küzdelmeim. Ch. IX. p. 130.\n\nVámbéry's work was criticized by Finno-Ugrist József Budenz in \"Jelentés Vámbéry Ármin magyar-török szóegyezéséről.\", published in 1871. Budenz criticised Vámbéry and his work in an aggressive, derogatory style, and questioned Vámbéry's (scientific) honesty and credibility. (Budenz's work was investigated and analysed by a group of modern linguists, and they found it neither as scientific nor as conclusive in the question of the affiliation of Hungarian language, as the author stated.)\n\nThe historian Henrik Marczali, linguist Károly Pozder, linguist József Thúry, anthropologist Aurél Török, and others supported Vámbéry.\n\nThe Finn-Ugrist Pál Hunfalvy widened the front of the \"Ugric-Turk War\" with his book \"Magyarország ethnographiája.\", published in 1876. In this book he stresses the very strong connection between language and nation (p. 48.), tries to prove that the Huns were Finn-Ugric (p. 122.), questions the credibility and origin of the Gestas (p. 295.), concludes that the Huns, Bulgars and Avars were Ugric (p. 393.), mentions, that the Jews are more prolific than other peoples, so the quickly growing number of them presents a real menace for the nation (p. 420.), and stresses what an important and eminent role the Germans played in the development of Hungarian culture and economy (p. 424.).\n\nIn his work titled \"Vámbéry Ármin: A magyarok eredete. Ethnologiai tanulmány.\", and published in 1882, Vámbéry went a step further, and presented a newer version of his theory, in which he claimed that Hungarian nation and language are basically Turkic in origin, and the Finn-Ugric element in them is a result of later contact and intermingling.\n\n\"...I see a compound people in Hungarians, in which not the Finn-Ugric, but the Turkic-Tatar component gives the true core...\"\n\n\"...\"a magyarban vegyülék népet látok, a melyben nem finn-ugor, hanem török-tatár elem képezi a tulajdonképeni magvat\"...\" in: Vámbéry Ármin: A magyarok eredete. Ethnologiai tanulmány. Preface. p. VI.\n\nVámbéry's work was criticized heavily by his Finno-Ugrist opponents. This critique gave rise to the ever-circling myth of the \"fish-smelling kinship\" and its variants. It should be noted, that no one of the authors has ever given the written source/base of this accusation against the Turanist scientists. In fact, Turanist scientists did not write such things about the Finn-Ugric peoples, and Vámbéry and his followers mentioned these kin of Hungarians with due respect. In reality it was coined by the Finno-Ugrist Ferdinánd Barna, in his work \"Vámbéry Ármin A magyarok eredete czímű műve néhány főbb állításának bírálata.\" (“Critique of some main statements of Ármin Vámbéry’s work, titled ‘The origin of Hungarians’.”) published in 1884. In this work Barna called the Finno-Ugric peoples \"a petty, fish fat eating people spending their woeful lives with fish- and easel-catching\", and tried to give this colorful description of his into Vámbéry’s mouth.\n\nVámbéry held to his scientific theory about the mixed origin of Hungarian language and people till his death. He considered Hungarian a contact language, more precisely a mixed language, having not just one but two (Finno-Ugric AND Turkic) genetic ancestors. His strongest evidences were the large corpus of ancient Turkish words in Hungarian word-stock (300-400 for a minimum, and even more with good alternative Turkic etymologies), and the strong typological similarity of Hungarian and Turkic languages. His Finno-Ugrist opponents strongly rejected not only the fact of such mixing and dual ancestry, but even the theoretical possibility of it. But, in the context of linguistics the use of a strictly binary family tree model proved unfruitful and problematic over the years. We have seen the Uralic tree disintegrate and flatten into a “comb”, and the place of Samoyedic languages and Yukaghir languages within/in relation to the other members is still very problematic. Some scientists questioned seriously even the existence of Uralic as valid language family, and attention turned towards the complex areal relations and interactions of Eurasian languages (Uralic and Altaic languages included). In the light of these developments linguists have started to pay due credit to Vámbéry and his work.\n\nIn connection with Vámbéry's work and the ensuing Ugric-Turkic War it is worth recalling the thoughts of linguist Maarten Mous:\n„Mixed languages pose a challenge to historical linguistics because these languages defy classification. One attitude towards mixed languages has been that they simply do not exist, and that the claims for mixed languages are instances of a naive use of the term. The inhibition to accept the existence of mixed languages is linked to the fact that it was inconceivable how they could emerge, and moreover their mere existence posited a threat to the validity of the comparative method and to genetic linguistics.” \n\nThe \"Ugric-Turkic War\" was never closed properly. This forced scientists to try to harmonize and synthesize the differing theories somehow. This resulted in the development of a complex national mythology. This combined the Asian roots and origins of Magyars with their European present. Turanism got a new meaning: it became the given name of a variant of Orientalism, which researched Asia and its culture in context of Hungarian history and culture.\n\nTuranism was a driving force in the development of Hungarian social sciences, especially linguistics, ethnography, history, archaeology, and Orientalism, and in the development of Hungarian arts, from architecture to applied and decorative arts. Turanist scientists greatly contributed to the development of Hungarian and international science and arts.\n\nThis is a short list of Turkist/Turanist scientists and artists, who have left a lasting legacy in Hungarian culture:\n\nThe idea of a Hungarian Oriental Institute originated from Jenő Zichy. Unfortunately, this idea did not come true. Instead, a kind of lyceum was formed in 1910, called \"Turáni Társaság\" (The Hungarian Turan Society (also called The Hungarian Asiatic Society)). The Turan society concentrated on Turan as geographic location where the ancestors of Hungarians might have lived.\n\n\"The goal of Turanian Society is the cultural and economic progress, confederation, flourishment of all Turanians, i.e. the Hungarian nation and all kindred European and Asian nations, furthermore the geographical, ethnographical, economical etc. research of the Asian continent, past and present. Political and religious issues are excluded. It wishes to accomplish its objectives in agreement with non-Turanian nations.\"\n\n\"Turáni Társaság célja az egész turánság, vagyis a magyar nemzet és a velünk rokon többi európai és ázsiai népek kulturális és gazdasági előrehaladása, tömörülése, erősödése, úgymint az ázsiai kontinens földrajzi, néprajzi, gazdasági stb. kutatása múltban és jelenben. Politikai és felekezeti kérdések kizártak. Céljait a nem turáni népekkel egyetértve óhajtja elérni.\"\n\nThe scholars of the Turan society interpreted the ethnic and linguistic kinship and relations between Hungarians and the so-called Turanian peoples on the basis of the then prevailing Ural-Altaic linguistic theory. The Society arranged Turkish, Finnish and Japanese language courses. The Turan Society arranged and funded five expeditions into Asia till 1914.(The Mészáros-Milleker expedition, the Timkó expedition, the Milleker expedition, the Kovács-Holzwarth expedition, and the Sebők-Schutz expedition.) The Society held public lectures regularly. Lecturers included `Abdu'l-Bahá and Shuho Chiba. After the outbreak of First World War politics ensnarled the work of the Society. In 1916, the Turan Society was redressed into the \"Magyar Keleti Kultúrközpont\" (Hungarian Eastern Cultural Centre), and direct governmental influence over its operation grew. The defeat in the First World War, and the following revolutionary movements and Entente occupation of the country disrupted the operation of the Eastern Cultural Centre, so real work began only in 1920. But the organisation was split into three that year, because of pronounced internal ideological stresses. Those who wanted a more scincelike approach formed the \"Kőrösi Csoma-Társaság\" (Kőrösi Csoma Society). The more radical political turanists left the Turan Society, and formed the \"Magyarországi Turán Szövetség\" (Turan Federation of Hungary).\nIn 1920, Archduke Joseph Francis of Austria (Archduke Joseph Francis Habsburg) became the first patron of the Hungarian Turan Society\n\nHungarians and their ancestors lived amongst or in direct contact with Turanian/Turkic peoples from time immemorial to 1908. (A common Hungarian-Turkish border ceased to exist after 1908, in the wake of the annexation of Bosnia and Herzegovina and the evacuation of the Sanjak of Novibazar.) These peoples played an eminent role in the birth and formation of Hungarian people, language, culture, state and nation. During the ethnogenesis of Hungarian people Kabar, Jász (Alan), Avar, Bulgar, Besenyő (Pecheneg), Kun (Cuman) tribes and population fragments merged and amalgamated into the Hungarian population.\n\nHungary warred with the Ottoman Empire for centuries. As a result of a discord of succession Hungary broke up into three parts in the 16th century: one was under Habsburg rule, one became part of the Ottoman Empire (1541.VIII.29.), and the third formed the “keleti Magyar Királyság” (Eastern Hungarian Kingdom)/ “Erdélyi Fejedelemség” (Principality of Transylvania). Erdély became an ally of the Ottomans (1528.II. 29.). The intensive everyday contacts in the one and a half centuries that followed resulted in pronounced Ottoman Turkish influence on Hungarian art and culture from music to jewellery and clothing, from agriculture to warfare. In the last third of the 17th century strife intensified between the Ottomans and the Habsburgs. The main scene of these power struggles was the territory of Hungary. The Ottoman attempts at further territorial expansion failed in the end and the Habsburgs reconquered the Hungarian territories. But there was a conflict in the circles of Hungarian political elite: many members of it were unwilling to swap the Ottoman alliance for direct Habsburg rule. A large group aspired for full independence, but felt Turkish dependence more amenable than Habsburg reign. Thököly's liberation movement and Rákóczi's War of Independence meant the climax of this Turkism. So, as one can see, Turkish orientation had a long tradition in Hungary.\n\nTurkism was reborn in the wake of the 1848-49 War of Independence. During the war Hungary was attacked by the Habsburgs, and many of her ethnic minorities turned against the country. Serious clashes occurred between the Hungarians and the Vlachs of Eastern Hungary and the Serbs of the South. There were serious atrocities against ethnic Hungarians; these events are remembered as \"oláhjárások\" and \"rácjárások\" (\"Vlach rampages\" and \"Rascian rampages\"). Hungary was defeated with the help of Russian military intervention.\n\nThese painful events and experiences changed Hungarians' attitudes profoundly: They began to feel themselves insecure and endangered in their own home. From this time on, Pan-Slavism and Pan-Germanism were seen as serious threats to the existence of Hungary and Hungarians. Hungarians looked for allies and friends to secure their position. They turned towards the rivals of the Habsburgs - to Turkey, to the Italians, even to the Prussians - for support and help. Hungarians were interested in a stable, strong and friendly Turkey, capable of preventing Russian and/or Habsburg expansion in the Balkans.\n\nHungarian political movements and attempts to regain independence proved unfruitful. At the same time, the Habsburgs were unable to acquire the leading position of the German union, and Germany became united under Prussian rule. The Habsburgs took their empire to the verge of collapse with a series of miscalculated political and military moves. This led to the Austro-Hungarian Compromise of 1867. The Hungarian supporters of the Compromise have argued that the already weakened Austria is no longer a threat to the Hungarians, but can help prevent Slavic expansion.\n\nDespite the Compromise, the Hungarians were ambivalent towards these old-new Austrian allies.\n\n\"If the balance of opinion in Hungary were always determined by sober political calculation, this brave and independent people, isolated in the broad ocean of Slav populations, and comparatively insignificant in numbers, would remain constant to the conviction that its position can only be secured by the support of the German element in Austria and Germany. But the Kossuth episode, and the suppression in Hungary itself of the German elements that remained loyal to the Empire, with other symptoms showed that among Hungarian hussars and lawyers self confidence is apt in critical moments to get the better of political calculation and self-control. Even in quiet times many a Magyar will get the gypsies to play to him the song, 'Der Deutsche ist ein Hundsfott' ('The German is a blackguard').\" Bismarck, Otto von: \"Bismarck, the man and the statesman: being the reflections and reminiscences of Otto, Prince von Bismarck.\" 1898. Vol. II. p. 255-256.\n\nIn the half-century prior to the First World War, some Hungarians encouraged Turanism as a means of uniting Turks and Hungarians against the perils posed by the Slavs and Pan-Slavism. However Pan-Turanism was never more than an outrider to the more prevalent Pan-Turkist movement. Turanism helped in the creation of the important Turkish-Austro-Hungarian and Bulgarian-Austro-Hungarian military and strategic alliances.\n\nThe movement received impetus after Hungary's defeat in World War I. Under the terms of the Treaty of Trianon (1920.VI.4.), the new Hungarian state constituted only 32,7 percent of the territory of historic, pre-treaty Hungary, and lost 58,4 percent of its total population. More than 3,2 million ethnic Hungarians, one-third of all Hungarians resided outside the new boundaries of Hungary, in the successor states, under oppressive conditions. Old Hungarian cities of great cultural importance like Pozsony, Kassa, Kolozsvár were lost. Under these circumstances no Hungarian government could survive without seeking justice for Magyars and Hungary. Reuniting the Magyars became a crucial point in public life and on the political agenda. Public sentiment became strongly anti-Western, anti-French, and anti-British. Outrage led many to reject Europe and turn towards the East in search of new friends and allies in a bid to revise the terms of the treaty and restore Hungarian power.\n\n\"Disappointment towards Europe caused by 'the betrayal of the West in Trianon', and the pessimistic feeling of loneliness, led different strata in society towards Turanism. They tried to look for friends, kindred peoples and allies in the East so that Hungary could break out of its isolation and regain its well deserved position among the nations. A more radical group of conservative, rightist people, sometimes even with an anti-Semitic hint propagated sharply anti-Western views and the superiority of Eastern culture, the necessity of a pro-Eastern policy, and development of the awareness of Turanic racialism among Hungarian people.” in: Uhalley, Stephen and Wu, Xiaoxin eds.: \"China and Christianity. Burdened Past, Hopeful Future.\" 2001. p. 219.\n\nTuranism never became official, because it was out of accord with the ideological background of the regime. But it was used by the government as an informal tool to break the country’s international isolation, and build alliances. Hungary signed treaties of friendship and collaboration with the Republic of Turkey in 1923, with the Republic of Estonia in 1937, with the Republic of Finland in 1937, with Japan in 1938, with Bulgaria in 1941.\n\nIn Transylvania, \"Turanist ethnographers and folklorists privileged the peasants' cultural 'uniqueness', locating a cultural essence of Magyarness in everything from fishing hooks and methods of animal husbandry to ritual folk songs, archaic, 'individualistic' dances, spicy dishes and superstitions.\" According to the historian Krisztián Ungváry \"With the awakening of Hungarian nationalism at the beginning of the 20th century, the question became topical again. The elite wanted to see itself as a military nation.The claims of certain linguistic researchers regarding the Finno-Ugric relationship were therefore strongly rejected, because many found the idea that their nation was related to a peaceful farming people (the Finns) as insulting...The extremist Turanians insisted on “ties of ancestry” with the Turkish peoples, Tibet, Japan and even the Sumerians, and held the view that Jesus was not a Jew but a Hungarian or a “noble of Parthia”.\"\n\nAccording to Andrew C. János, while some Hungarian Turanists went as far as to argue they were racially healthier than and superior to other Europeans (including Germans, who were already corrupted by Judaism), others felt more modestly, that as Turanians living in Europe, they might provide an important bridge between East and West and thus play a role in world politics out of proportion of their numbers or the size of their country. This geopolitical argument was taken to absurd extremes by Ferenc Szálasi, head of the Arrow Cross-Hungarist movement, who believed that, owing to their unique historical and geographical position, Hungarians might play a role equal to, or even more important than, Germany in building the new European order, while Szálasi's own charisma might eventually help him supersede Hitler as leader of the international movement.\n\nFerenc Szálasi, the leader of the Hungarian Arrow Cross Party believed in the existence of a genuine Turanian-Hungarian race (to the extent that his followers went about making anthropological surveys, collecting skull measurements) that was crucial for his ideology of \"Hungarism\". Szálasi was himself a practicing Catholic and wavered between a religious and a racial basis for Hungarism. The unique vocation of “Turanian” (Turkic) Hungary was its capacity for mediating and uniting both east and west, Europe and Asia, the Christian Balkans and the Muslim Middle East, and from this stemmed its ultimate vocation to lead the world order through culture and example, a task that neither Italy nor Germany was prepared to accomplish. \n\nAfter the Second World War the Soviet Red Army occupied Hungary. The Hungarian government was placed under the direct control of the administration of the occupying forces. All Turanist organisations were disbanded by the government, and the majority of Turanist publications was banned and confiscated. In 1948 Hungary was converted into a communist one-party state. Turanism was portrayed and vilified as an exclusively fascist ideology, although Turanism's role in the interwar development of far-right ideologies was negligible. The official prohibition lasted until the collapse of the socialist regime in 1989.\n\nA Hungarian non-commissioned officer Ferenc Jós Badiny wrote his book ( Jézus Király, a pártus herceg) \"King Jesus, the Parthian prince\", where he invented the theory of Jesus the Parthian warrior prince.\nMany Christian Hungarian Turanists held the view that Jesus Christ was not a Jew but a proto-Hungarian or a “noble of Parthia”. The theory of “Jesus, the Parthian prince” are such, or the revivification of real or supposed elements of priest-magicians of ancient “magic” Middle-Eastern world, shamanism, and pagan ancient Hungarian religion. Also some Muslim Turkish Turanists held the view that Muhammad was not an Arab but a Sumerian, and Sumerians are Turanid according to Turanist theses. It is an opportunity for the Christian Turanists to link Jesus to the ancient Middle-Eastern mystery and the ancient pagan Hungarian beliefs. Both Catholic and Protestant religious leaders of Hungary acted against this theory and beliefs.\n\nThe far-right Jobbik party and its president Gábor Vona are uncompromising supporters of Turanism (the ideology of Jobbik considers Hungarians as a Turanian nation).\n\nThe Habsburg conspiracy theory is very popular amongst political Turanists, which was invented only in the 1970s. According to the myth, the Habsburgs envied the glorius Turanian past and \"ancestry\" of the Hungarian nation, therefore Habsburgs created a plan to hide it from the Hungarian and European public opinion. In the reality, it was Emperor Francis Joseph who used his political prestige to give a university cathedra (as professor) for Ármin Vámbéry, the leaders of Hungarian turanists.\n\nThe Kurultáj is a tribal assembly based on the common heritage of the peoples of Central Asian nomadic origin. (Azerbaijani, Bashkirs, Bulgarians, Buryats, Chuvash, Gagauz, Hungarians, Karachays, Karakalpaks, Kazakhs, Kyrgyz, Nogai, Tatars, Turks, Turkmen, Uighurs, Üzbeks, Yakuts etc.) It is also a popular tourist attraction in Hungary (from late 2000s) and Central Asia. The first Kurultáj was in Kazakhstan in 2007 and the last one was organized in 2014 at Bugac, Hungary.\n\nIn the 1990s a well developed souvenir and merchandise business has grown around Turanism, traditionalist and historical reenactment groups, which is quite similar to other well known international examples of business of this kind.\nAccording to the opinion of Hungarian researcher Igaz Levente this merchandise industry grown around modern Hungarian Turanism became a kind of business, which he called \"Szittya biznisz\" (Scythian business), and it has not got much to do with ancient Hungarian traditions.\n\n\n"}
{"id": "51754640", "url": "https://en.wikipedia.org/wiki?curid=51754640", "title": "Hybrid Shipping Container", "text": "Hybrid Shipping Container\n\nA hybrid shipping container is a shipping system that uses the energy of phase-change material (PCM) in combination with the ability to recharge without removing the media. This ability is known as \"cold-energy battery\".\n\nCurrently, this technology is only being used in a limited number of shipping containers.\n\n1. SkyCell 770C\n2. SkyCell 1500C\n3. SkyCell 770CRT\n4. SkyCell 1500CRT\n\nA Cold-energy battery works by storing energy to a given temperature and using its thermal mass to maintain this temperature. It can be recharged by being placed in a temperature range applicable to its phase change window.\n"}
{"id": "15627", "url": "https://en.wikipedia.org/wiki?curid=15627", "title": "Junk science", "text": "Junk science\n\nThe expression junk science is used to describe scientific data, research, or analysis considered by the person using the phrase to be spurious or fraudulent. The concept is often invoked in political and legal contexts where facts and scientific results have a great amount of weight in making a determination. It usually conveys a pejorative connotation that the research has been untowardly driven by political, ideological, financial, or otherwise unscientific motives.\n\nThe concept was popularized in the 1990s in relation to expert testimony in civil litigation. More recently, invoking the concept has been a tactic to criticize research on the harmful environmental or public health effects of corporate activities, and occasionally in response to such criticism. The term has been used by proponents of both sides of such political debates. Author Dan Agin in his book \"Junk Science\" harshly criticized those who deny the basic premise of global warming, while former Fox News commentator Steven Milloy has extensively denounced research linking the fossil fuel industry to climate change, on his website \"junkscience.com\".\n\nIn some contexts, junk science is counterposed to the \"sound science\" or \"solid science\" that favors one's own point of view. This dichotomy has been particularly promoted by Steven Milloy and the Advancement of Sound Science Center, and is somewhat different from pseudoscience and fringe science.\n\nThe phrase \"junk science\" appears to have been in use prior to 1985. A 1985 United States Department of Justice report by the Tort Policy Working Group noted:\nThe use of such invalid scientific evidence (commonly referred to as 'junk science') has resulted in findings of causation which simply cannot be justified or understood from the standpoint of the current state of credible scientific or medical knowledge.\n\nIn 1989, the climate scientist Jerry Mahlman (Director of the Geophysical Fluid Dynamics Laboratory) characterized the theory that global warming was due to solar variation (presented in \"Scientific Perspectives on the Greenhouse Problem\" by Frederick Seitz et al.) as \"noisy junk science.\"\n\nPeter W. Huber popularized the term with respect to litigation in his 1991 book \"Galileo's Revenge: Junk Science in the Courtroom.\" The book has been cited in over 100 legal textbooks and references; as a consequence, some sources cite Huber as the first to coin the term. By 1997, the term had entered the legal lexicon as seen in an opinion by Supreme Court of the United States Justice John Paul Stevens: \nAn example of 'junk science' that should be excluded under the Daubert standard as too unreliable would be the testimony of a phrenologist who would purport to prove a defendant's future dangerousness based on the contours of the defendant's skull. Lower courts have subsequently set guidelines for identifying junk science, such as the 2005 opinion of United States Court of Appeals for the Seventh Circuit Judge Easterbrook:\nPositive reports about magnetic water treatment are not replicable; this plus the lack of a physical explanation for any effects are hallmarks of junk science.\n\nAs the subtitle of Huber's book, \"Junk Science in the Courtroom\", suggests, his emphasis was on the use or misuse of expert testimony in civil litigation. One prominent example cited in the book was litigation over casual contact in the spread of AIDS. A California school district sought to prevent a young boy with AIDS, Ryan Thomas, from attending kindergarten. The school district produced an expert witness, Steven Armentrout, who testified that a possibility existed that AIDS could be transmitted to schoolmates through yet undiscovered \"vectors.\" However, five experts testified on behalf of Thomas that AIDS is not transmitted through casual contact, and the court affirmed the \"solid science\" (as Mr. Huber called it) and rejected Armentrout's argument.\n\nIn 1999, Paul Ehrlich and others advocated public policies to improve the dissemination of valid environmental scientific knowledge and discourage junk science: \nThe Intergovernmental Panel on Climate Change reports offer an antidote to junk science by articulating the current consensus on the prospects for climate change, by outlining the extent of the uncertainties, and by describing the potential benefits and costs of policies to address climate change.\n\nIn a 2003 study about changes in environmental activism regarding the Crown of the Continent Ecosystem, Pedynowski noted that junk science can undermine the credibility of science over a much broader scale because misrepresentation by special interests casts doubt on more defensible claims and undermines the credibility of all research.\n\nIn his 2006 book \"Junk Science\", Dan Agin emphasized two main causes of junk science: fraud, and ignorance. In the first case, Agin discussed falsified results in the development of organic transistors: \nAs far as understanding junk science is concerned, the important aspect is that both Bell Laboratories and the international physics community were fooled until someone noticed that noise records published by Jan Hendrik Schön in several papers were identical—which means physically impossible.\n\nIn the second case, he cites an example that demonstrates ignorance of statistical principles in the lay press: \nSince no such proof is possible [that genetically modified food is harmless], the article in The New York Times was what is called a \"bad rap\" against the U.S. Department of Agriculture—a bad rap based on a junk-science belief that it's possible to prove a null hypothesis.\n\nAgin asks the reader to step back from the rhetoric, as \"how things are labeled does not make a science junk science.\" In its place, he offers that junk science is ultimately motivated by the desire to hide undesirable truths from the public.\n\nJohn Stauber and Sheldon Rampton of \"PR Watch\" say the concept of junk science has come to be invoked in attempts to dismiss scientific findings that stand in the way of short-term corporate profits. In their book \"Trust Us, We're Experts\" (2001), they write that industries have launched multimillion-dollar campaigns to position certain theories as junk science in the popular mind, often failing to employ the scientific method themselves. For example, the tobacco industry has described research demonstrating the harmful effects of smoking and second-hand smoke as junk science, through the vehicle of various astroturf groups.\n\nTheories more favorable to corporate activities are portrayed in words as \"sound science.\" Past examples where \"sound science\" was used include the research into the toxicity of Alar, which was heavily criticized by antiregulatory advocates, and Herbert Needleman's research into low dose lead poisoning. Needleman was accused of fraud and personally attacked.\n\nFox News commentator Steven Milloy often invokes the concept of junk science to attack the results of credible scientific research on topics like global warming, ozone depletion, and passive smoking. The credibility of Milloy's website junkscience.com was questioned by Paul D. Thacker, a writer for \"The New Republic\", in the wake of evidence that Milloy had received funding from Philip Morris, RJR Tobacco, and Exxon Mobil. Thacker also noted that Milloy was receiving almost $100,000 a year in consulting fees from Philip Morris while he criticized the evidence regarding the hazards of second-hand smoke as junk science. Following the publication of this article, the Cato Institute, which had hosted the junkscience.com site, ceased its association with the site and removed Milloy from its list of adjunct scholars.\n\nTobacco industry documents reveal that Philip Morris executives conceived of the \"Whitecoat Project\" in the 1980s as a response to emerging scientific data on the harmfulness of second-hand smoke. The goal of the Whitecoat Project, as conceived by Philip Morris and other tobacco companies, was to use ostensibly independent \"scientific consultants\" to spread doubt in the public mind about scientific data through invoking concepts like junk science. According to epidemiologist David Michaels, Assistant Secretary of Energy for Environment, Safety, and Health in the Clinton Administration, the tobacco industry invented the \"sound science\" movement in the 1980s as part of their campaign against the regulation of second-hand smoke.\n\nDavid Michaels has argued that, since the U.S. Supreme Court ruling in \"Daubert v. Merrell Dow Pharmaceuticals, Inc.\", lay judges have become \"gatekeepers\" of scientific testimony and, as a result, respected scientists have sometimes been unable to provide testimony so that corporate defendants are \"increasingly emboldened\" to accuse adversaries of practicing junk science.\n\nIn 1995, the Union of Concerned Scientists launched the Sound Science Initiative, a national network of scientists committed to debunking junk science through media outreach, lobbying, and developing joint strategies to participate in town meetings or public hearings. In its newsletter on Science and Technology in Congress, the American Association for the Advancement of Science also recognized the need for increased understanding between scientists and lawmakers: \"Although most individuals would agree that sound science is preferable to junk science, fewer recognize what makes a scientific study 'good' or 'bad'.\" The American Dietetic Association, criticizing marketing claims made for food products, has created a list of \"Ten Red Flags of Junk Science.\"\n\nIndividual scientists have also invoked the concept.\n\n\n\n"}
{"id": "24421659", "url": "https://en.wikipedia.org/wiki?curid=24421659", "title": "Laboratory Safety Institute", "text": "Laboratory Safety Institute\n\nThe Laboratory Safety Institute (LSI) is a 501(c)3 non-profit organization based in the United States that supports safety in science education. \nFounded in 1978 by Dr. James Kaufman to provide safety training for secondary school science teachers, LSI has grown to become \"An International Center for Health, Safety and Environmental Affairs.\"\n\nLSI members are science educators and administrators as well as corporate hygiene officers, directors of environmental affairs, chemical handling and storage and waste management personnel.\n\nLSI publishes articles and newsletters regarding best practices in laboratory safety as well as safety manuals and teaching tools for teachers and laboratory managers.\n\n"}
{"id": "56023027", "url": "https://en.wikipedia.org/wiki?curid=56023027", "title": "List of scientific misconduct incidents", "text": "List of scientific misconduct incidents\n\nScientific misconduct is the violation of the standard codes of scholarly conduct and ethical behavior in the publication of professional scientific research. A \"Lancet\" review on \"Handling of Scientific Misconduct in Scandinavian countries\" gave examples of policy definitions. In Denmark, scientific misconduct is defined as \"intention[al] or gross negligence leading to fabrication of the scientific message or a false credit or emphasis given to a scientist\", and in Sweden as \"intention[al] distortion of the research process by fabrication of data, text, hypothesis, or methods from another researcher's manuscript form or publication; or distortion of the research process in other ways.\"\n\nA 2009 systematic review and meta-analysis of survey data found that about 2% of scientists admitted to falsifying, fabricating, or modifying data at least once.\n\n\n\n\n\n\n"}
{"id": "25512296", "url": "https://en.wikipedia.org/wiki?curid=25512296", "title": "List of scientists whose names are used as SI units", "text": "List of scientists whose names are used as SI units\n\nList of scientists whose names are used as SI units is the list of those scientists whose names are assigned as the names of the international units by the International Committee for Weights and Measures. The International System of Units (abbreviated SI from ) is the most widely used system of units of measurement. There are seven base units and 22 derived units (excluding compound units). These units are used both in science and in commerce. Two of the base units and 17 of the derived units are named after scientists. By this convention, their names are immortalised. Below is the list of the scientists whose names are used as SI units.\n\nNapier and decibel are two dimensionless units used to define relative amplitudes in logarithmic scales. They are not SI units, but their usage together with SI units is permitted.\n\n\n"}
{"id": "41885308", "url": "https://en.wikipedia.org/wiki?curid=41885308", "title": "Living educational theory", "text": "Living educational theory\n\nLiving educational theory (LET) is a research method in educational research.\n\nThe idea of action research as a living practice entered the mainstream of action research from the book, \"Action Research as a Living Practice\" by Terrance Carson and Dennis Sumara in 1997. Carson and Sumara transformed the concept of traditional action research with the idea that, ...\" participation in action research practices are particular ways of living and understanding that require more of the researcher than the \"application\" of research methods. Rather, action research is a lived practice that requires that the researcher not only investigate the subject at hand but, as well, provide some account of the way in which the investigation both shapes and is shaped by the investigator . This requires what Martin Buber called an \"I-Thou\" approach toward other and this approach applied to action research as well. To make Buber's language more modern and accessible, LET translated Buber's \"I-Thou\" approach toward another human being to an \"I/you/we\" approach to action research. This differs greatly from an approach to living theory action research imagined by Jack Whitehead (2002) where he imagines living theory action research as forming an \"I-theory\" of knowledge. Director of the Philosophy for Children Project at Notre Dame de Namur University William Barry proposes LET focuses on the connections between the researcher and the other person or subject where the lives of action researchers are inextricable linked in a profound manner with the individuals and communities involved in the subject of study. LET from a Barryian perspective is a critical theory and emancipatory action research approach which seeks the dialectic, not debate and battles of [discourse].\n\nA major difference of William Barry's version of living educational theory, which was the focus of his successful completion of a Ph.D. thesis at Nottingham Trent University, UK, is the essential question behind the living educational theory approach to action research (2012b). The question is not \"How can I generate a living legacy for myself through an I-It theory approach toward knowledge and other forms of life?\" Rather the essential question is, \"How does one conduct a life that includes the practice of educational action research?\" The theory/practice problem disappears when honesty about one's biases regarding spiritual, existential, and emotional intelligence are made clear in the action research process.\n\nThe phraseology \"educational theory\" originated with the work of Jack Whitehead, a former lecturer at the University of Bath, and it was further developed and greatly improved methodologically by Jean McNiff in 2009 because of her willingness to be transparent about her values and intentions. Whitehead's main emphasis for conducting research is to promote the individual under the guise of collaboration and research outcomes must be captured on video for authentic validation. Whitehead's view of action research promotes that living educational theory (he uses living theory and living educational theory interchangeably so it is difficult for a reader to know what he is writing about) should be aimed at the bringing of energy-flowing values as explanatory principles and standards of judgments into the Academy for the legitimation of living educational theories (Whitehead 2008). In the eyes of Whitehead radical constructivism is at the core of living educational theory research. In 2013, Whitehead and McNiff separated as collaborators as McNiff saw spiritual, emotional intelligence as key to action research while Whitehead disagreed and believed that media accounts (primarily video tapping people) of action research could provide clues to virtues which held the future of humanity though energy flowing examples of collaboration. McNiff stated in a May 2013 conference she San Francisco, California (ARNA Conference) that she would never appear or work with Whitehead again. She repeated this message again months later at a UK conference in York. American William Barry believed the concept of LET was too important and found a dialectic between McNiff and Whitehead and he created a new understanding of LET which was presented at a three-day international conference in 2013 at Liverpool Hope University titled, \"Researching Our Own Practice\" .\n\nLiving educational theory was first clearly defined and developed by California Professor of Philosophy William Barry (2012b) in Liz Atkins and Susan Wallace's book , \"Qualitative Research in Education\", co-published by Sage and the British Educational Research Association (BERA). This book was one of four in a series sponsored by the BERA regarding best practice progressive research methods in educational research. The originality and uniqueness of Barry's development of living educational theory (LET) action research is the importance of gaining \"ontological weight\" through the action research process. Ontological weight empowers the researcher's ability, and the ability of other people involved in the action research project, to have the research experience and focus of the research be transformational and add, or at least reinforce, a sense of meaning in learning and life. Barry was influenced to use the concept \"ontological weight\" by the existentialist Catholic philosopher Gabriel Marcel (1963).\n\nThe idea of action research as a living practice entered the mainstream of action research from the book, \"Action Research as a Living Practice\" by Terrance Carson and Dennis Sumara in 1997. The term \"educational theory\" originated with the work of Jack Whitehead, a former lecturer at the University of Bath, and it was further developed and greatly improved methodologically by Jean McNiff in 2009. Whitehead's main emphasis for conducting research is to promote the individual under the guise of collaboration and research outcomes must be captured on video for authentic validation. Whitehead's view of action research promotes that living educational theory (he uses living theory and living educational theory interchangeably so it is difficult for a reader to know what he is writing about) should be aimed at the bringing of energy-flowing values as explanatory principles and standards of judgments into the Academy for the legitimation of living educational theories (Whitehead 2008). In the eyes of Whitehead, radical constructivism is at the core of living educational theory research.\n\nBarry was asked by the BERA sponsored authors to reflect on the nature of living educational theory (LET) because there existed no clear definition of LET in the literature. Barry was asked because he had successfully used LET in an innovative fashion, and was the first to clearly define LET as based in critical theory which embraced transpersonal psychology through his earned 2012 PhD thesis at Nottingham Trent University Nottingham, UK. He proposed LET as a way of challenging the oppressive use of power using critical theory in a need fulfilling way (Glasser 1998). Barry proposed the following definition and approach to action research he calls living educational theory and his approach has been used as an action research method in undergraduate and graduate courses and research at Notre Dame de Namur University in Silicon Valley, California as well as by other researchers around the world.\n\nBarry explained that living educational theory \"[is] a critical and transformational approach to action research. It confronts the researcher to challenge the status quo of their educational practice and to answer the question, 'How can I improve that I'm doing?' Researchers who use this approach must be willing to recognize and assume responsibility for being a 'living contradiction' in their professional practice – thinking one way and acting in another. The mission of the LET action researcher is to overcome workplace norms and self – behavior which contradict the researcher's values and beliefs. The vision of the LET researcher is to make an original contribution to knowledge through generating an educational theory proven to improve the learning of people within a social learning space. The standard of judgment for theory validity is evidence of workplace reform, transformational growth of the researcher, and improved learning by the people researcher claimed to have influenced...\" .\n\nBarry's LET approach to action research was heavily influenced by action researchers focused on emancipatory social change, collaboration, and liberation theology (2012a). Prominent developers of LET, without whose work LET would most likely never had been developed by Barry, are notable action researchers, educators, and philosophers such as Martin Buber's (1970) conception of 'I and Thou' and Krishnamurti's (1953) liberation pedagogy emphasizing education as significant to leading a quality filled life; Paulo Freire (1998 and 1970) and his concept of participatory action research and the need to be politically aware; the work of Carr and Kremmis (1986) and Habermas (1992) and their concept and building critical educational knowledge; Professor Manheimer of UNC (1999) and his challenge to his readers to enfold the past into the living present in order to become historical to oneself and then strive to linking life times with each other; Apple (1982) and Michel Foucault (1990) and the role of power and politics in education and Joe Kincheloe (2008), Henry Giroux (1997), and Peter McLaren (1989) and their promotion of critical pedagogy.\n\nProf. Barry was the first Ph.D. researcher to successfully use living educational theory in conjunction with neuro-linguistic programming (NLP), spiral dynamics and autoethnography (based on a multiple intelligences model which includes spiritual and emotional intelligence and embraces transpersonal knowing) as valid methods of research working under the methodological umbrella of phenomenology and hermeneutics. His LET approach to Ph.D.level action research led to the unique use of fictional storytelling as a vehicle by which to replace the traditional literature review chapter in Ph.D. research but in a more rigorous and creative fashion. The process of storytelling allows the researcher to exercise their emotional intelligence in a superior manner than the traditional research literature review allows.\n\nLiving educational theory as defined and created by Barry is part of the curriculum of multiple courses at Notre Dame de Namur University located in Silicon Valley, California in their credentialing program for teacher education. Barry's Living Educational Theory Action Research Method is based on a six step process based on research questions that normally start from the format, \" How can I influence the transformation of...?\" or \"How can I contribute to the improvement of...?\" The research is dialectical in nature:\n\n\n\n\n"}
{"id": "6321284", "url": "https://en.wikipedia.org/wiki?curid=6321284", "title": "Molecularium Project", "text": "Molecularium Project\n\nThe Molecularium Project is an informal science education project of Rensselaer Polytechnic Institute. The Molecularium Project introduces young audiences to the world of atoms and molecules using character driven stories, immersive animation, interactive games and activities, and state of the art molecular visualizations. Rensselaer's three principal Scientist / Educators behind the project are Dr. Linda S. Schadler, Dr. Richard W. Siegel, and Dr. Shekhar Garde. The Molecularium Project began as an outreach project of Rensselaer's Nanoscale Science and Engineering Center. To realize the productions, the scientists employed the creative team Nanotoon Entertainment, led by writer/director V. Owen Bush, and writer/producer Kurt Przybilla. The Molecularium Project is funded by Rensselaer, the National Science Foundation, and New York State.\n\nIn 2002, Dr. Schadler and Dr. Garde produced a seven-minute pilot show for the local planetarium called “Molecularium” for the Digistar II Planetarium system. It introduces children to the concepts of atoms and molecules from small molecules like H2O to larger molecules like polymers.\n\nIn early 2004, Schadler, Garde, and Siegel were awarded a U.S. National Science Foundation grant to make a new Molecularium show exclusively for the fulldome medum. They recruited the filmmaker and experience designer V. Owen Bush to bring the idea to life. Bush founded the production company Nanotoon Entertainment with writer/producer Kurt Przybilla to realize the new project. Bush and Przybilla proposed an adventure story of personified atoms flying a ship called the Molecularium through nanoscale materials including a snowflake, a penny, a stick of gum and the human body.\n\nIn February 2005, the team debuted \"Molecularium - Riding Snowflakes\" a 23-minute digital planetarium show at the Children's Museum of Science and Technology. In 2005, \"Molecularium - Riding Snowflakes\" won the Domie at Domefest in Albuquerque New Mexico. \"Molecularium - Riding Snowflakes\" has shown at Chabot Space and Science Center in Oakland Ca., the Newark Museum Planetarium in Newark, NJ, Dubai Children’s City, UAE, and Thinktank, Birmingham, UK, among many other digital planetariums. It has been translated and versioned in Arabic, Korean and Turkish. It is Distributed by E&S, Spitz, Sky-Skan, and e-Planetarium.\n\nIn 2010, the American Library Association (ALA) selected the Molecularium Kid's Site for inclusion to its Great Websites for Kids.\n\nMolecules to the MAX! is a 41-minute fully animated 3D IMAX film for the Giant Screen. The film re-imagines the characters and story developed for \"Molecularium- Riding Snowflakes\" for an older audience and a different medium. The film's simulations and rendering were partially computed at the Computational Center for Nanotechnology Innovations. The film was produced by Nanotoon Entertainment and Developed at Rensselaer, with a gift from Curtis R. Priem, co-founder of Nvidia corporation.\n\nThe digital version of the film premiered at EMPAC, in Troy, NY on Feb. 27, 2009. The IMAX version premiered at the Giant Screen Cinema Association International Conference and Trade Show in Indianapolis, Indiana, on September 22, 2009. The IMAX 3D Premiere was at the GSCA Film Expo in Los Angeles on Feb. 24, 2010. It is available in 2D & 3D for 15/70 and 8/70 large format film and in digital 3D. The film has been composed with Omnimax / IMAX Domes in mind. Molecules to the MAX! was nominated for Best Film Produced for the Giant Screen, Best Film for Lifelong Learning and Best Sound Design at the 2010 GSCA’s Achievement Awards. Molecules to the MAX! has shown at the National Museum of Natural Science (Taichung, Taiwan) Maloka Interactive Museum (Bogata, Columbia), The Scientific Center (Salmiya, Kuwait), McWane Science Center (Birmingham, Alabama) Proctor's Theatre (Schenectady, New York) among others. It has been translated and versioned in Spanish, Chinese, Japanese and Arabic. It is distributed to Giant Screen theaters by SK Films.\n\nIn the spring of 2012, the Molecularium Project launched NanoSpace, an online molecular theme park. Visitors to NanoSpace learn scientific concepts with games, activities and movies. Areas within Nanospace include the Hall of Atoms and Molecules, H2O park (the water cycle), Sizes in the Universe (scale and scientific notation), Material Boulevard (Materials Science), and DNA Land (Molecular Biology).\n"}
{"id": "31341328", "url": "https://en.wikipedia.org/wiki?curid=31341328", "title": "Olavo de Carvalho", "text": "Olavo de Carvalho\n\nOlavo Luiz Pimentel de Carvalho (born 29 April 1947) is a Brazilian journalist, essayist and former astrologer. His interests include historical philosophy, the history of revolutionary movements, the traditionalist school and comparative religion. He is known for his conservative and right-wing political stance, and for being a critic of the political Left. He believes on conspiracy theory of Cultural Marxism.\n\nOlavo started his career as a journalist in several newspapers. He also acted as an astrologer in the 1980s. He moved to Richmond, Virginia in 2005, and works as an international correspondent. He writes a weekly column for the Brazilian newspaper \"Diário do Comércio\" and teaches philosophy in an online course to over 2,000 students. Carvalho has previously written for several other magazines and newspapers, such as \"Bravo!\", \"Primeira Leitura\", \"Claudia\", \"O Globo\", \"Folha de S.Paulo\" (where he starts to write in February 1977, with an article debut about The Magic Flute in the \"Folhetim\" literary supplement), \"Época\" and \"Zero Hora\", and taught philosophy to a smaller circle of students while still living in Brazil. He introduced to Portuguese-speaking readers works of important philosophers of the 20th century, such as Eric Voegelin, Xavier Zubiri, Bernard Lonergan, René Guénon, and Frithjof Schuon.\n\nHe founded the website \"Maskless Media\" (\"Mídia Sem Máscara\") in 2002. It presents itself as an observatory of the news media.\n\nHe was the host of the show \"True Outspeak\" on BlogTalkRadio, which aired from 2006 to 2013.\n\nThe book \"O Mínimo Que Você Precisa Saber para Não Ser um Idiota\" (\"The Least You Need to Know in Order to Not Be an Idiot,\" 2013) is a collection of his many articles for magazines published between 1997 and 2013. The book sold 350,000 copies in Brazil.\n\nCarvalho founded the Inter-American Institute for Philosophy, Government, and Social Thought in 2009, and serves as its president. He collaborates with Ted Baehr, Paul Gottfried, Judith Reisman, Alejandro Peña Esclusa, and Stephen Baskerville through the Inter-American Institute. Vladimir Tismaneanu of \"FrontPage Magazine\" praised Carvalho's ideas in an article on the Brazilian left.\n\nAmong his famous students is the Catholic priest, TV host, writer and professor Father Paulo Ricardo.\n\nAccording to her daughter Olavo had a troubled early life with maltreatment of his children. All content was wrapped in a letter that was later shared on Facebook social network. According to the letter, Olavo had even pointed a gun to the head of one of his children. Olavo also accused Pepsi of using cells from aborted fetuses to sweeten soft drinks. \n\nOlavo strongly criticizes several figures who occupy a prominent place in the history of the sciences, such as Isaac Newton and Giordano Bruno, who according to him \"did not make any discoveries... He did not even study modern sciences, physics, astronomy, biology or mathematics, he was not condemned for defending scientific theories, but for practicing witchcraft, which at the time was a crime\". , The criticism extends to Galileo, of whom he writes:\nA background of charlatanism appears to have already been introduced into physics by Galileo, when he proclaimed that he had overturned the notions of ancient science, according to which an object not propelled by an external force stands still - an illusion of the senses, he said. In fact, he pontificated, an object in such conditions remains stationary or in uniform and rectilinear motion. But, after having thus overthrown the old physics, he discreetly clarified that rectilinear and uniform movement does not really exist, but is a fiction conceived by the mind to facilitate measurements. Now if the object not moved from without stands still or has a fictitious movement, it means, strictly speaking, that it stands still in every case, just as ancient physics said, and that Galileo, by means of a new system of measurements, could only explain why it stands still. That is to say, Galileo did not dispute ancient physics, he merely invented a better way of proving that it was correct, and that the testimony of the senses, being true enough, does not have in itself proof of its veracity, which was well known since the time of Aristotle. It was this episode that inaugurated the craze of modern scientists to take simple changes of methods as if they were \"proofs\" of a new constitution of reality.\n\nHe is also critical of Georg Cantor's work on transfinite numbers, accusing him of confusing \"numbers with their mere signs,\" seeing his work as a \"play on words\" and a \"false logic\", and has stated that the special theory of relativity was invented by Einstein merely to obfuscate the fact that Copernicus was wrong and that the earth does not in fact revolve about the sun. \n\nHe does not believe in global warming, basing his arguments on the Climategate episode in which hackers, on the eve of the Copenhagen Conference, disseminated thousands of e-mails from University of East Anglia climatologists in order to undermine the credibility of conference. In addition, Olavo claims Climategate to be the work of a conspiracy led by the Rockefeller family, the Council of Foreign Relations and the Bilderberg Club, indicating them also as leaders of the \"global abortion [...] campaigns of the new global religion, and of the Obama administration's proposal for universal control of the movement of capital. \"\n\nFor Olavo, AIDS does not pose a risk to the heterosexual population, basing his arguments on journalist Michael Fumento's book The Myth of Heterosexual Aids, and he does not agree that AIDS has been an imminent danger to all humanity, claiming that this idea has been disseminated by the pharmaceutical industry and other groups to raise government funding.\n\nOlavo maintains that his ideas do not fall into an ideological category, and points out that the evaluation of a position as politically left or right wing is subjective and varies by place and historical context. Broadly speaking however, he does see himself as aligned with the American right.\n\nIn November 2018, after the Brazilian presidential election, he declared that (if invited) he would accept to be the Brazilian ambassador to the United States. He stated that, if nominated by President-elect Jair Bolsonaro, this would be the only position he would accept. According to him:\n\"What Brazil needs most is money, and as an ambassador to the United States, I would be able to make money. I have some practice from this international trade business from the time I lived in Romania. I am not totally ignorant in international trade. [...] The ambassador to a foreign other country has full authority over his countrymen there. He can kick out whoever he likes, he can have anyone arrested. He's a king.\"\n\n"}
{"id": "19607864", "url": "https://en.wikipedia.org/wiki?curid=19607864", "title": "Open-notebook science", "text": "Open-notebook science\n\nOpen-notebook science is the practice of making the entire primary record of a research project publicly available online as it is recorded. This involves placing the personal, or laboratory, notebook of the researcher online along with all raw and processed data, and any associated material, as this material is generated. The approach may be summed up by the slogan 'no insider information'. It is the logical extreme of transparent approaches to research and explicitly includes the making available of failed, less significant, and otherwise unpublished experiments; so called 'dark data'. The practice of open notebook science, although not the norm in the academic community, has gained significant recent attention in the research and general media as part of a general trend towards more open approaches in research practice and publishing. Open notebook science can therefore be described as part of a wider open science movement that includes the advocacy and adoption of open access publication, open data, crowdsourcing data, and citizen science. It is inspired in part by the success of open-source software and draws on many of its ideas.\n\nThe term \"open-notebook science\" was first used in 2006 in a blog post by Jean-Claude Bradley, an Associate Professor of Chemistry at Drexel University at the time. Bradley described open-notebook science as follows:\n\n\"A team of groundbreaking scientists at SGC are now sharing their lab notebooks online\".\n\n\n\n\n\nThese are initiatives more open than traditional laboratory notebooks but lacking a key component for full Open Notebook Science. Usually either the notebook is only partially shared or shared with significant delay.\n\nA public laboratory notebook makes it convenient to cite the exact instances of experiments used to support arguments in articles. For example, in a paper on the optimization of a Ugi reaction, three different batches of product are used in the characterization and each spectrum references the specific experiment where each batch was used: EXP099, EXP203 and EXP206. This work was subsequently published in the Journal of Visualized Experiments, demonstrating that the integrity data provenance can be maintained from lab notebook to final publication in a peer-reviewed journal.\n\nWithout further qualifications, Open Notebook Science implies that the research is being reported on an ongoing basis without unreasonable delay or filter. This enables others to understand exactly how research actually happens within a field or a specific research group. Such information could be of value to collaborators, prospective students or future employers. Providing access to selective notebook pages or inserting an embargo period would be inconsistent with the meaning of the term \"Open\" in this context. Unless error corrections, failed experiments and ambiguous results are reported, it will not be possible for an outside observer to understand exactly how science is being done. Terms such as Pseudo or Partial have been used as qualifiers for the sharing of laboratory notebook information in a selective way or with a significant delay.\n\nThe arguments against adopting Open Notebook Science fall mainly into three categories which have differing importance in different fields of science. The primary concern, expressed particularly by biological and medical scientists is that of 'data theft' or 'being scooped'. While the degree to which research groups steal or adapt the results of others remains a subject of debate it is certainly the case that the fear of not being first to publish drives much behaviour, particularly in some fields. This is related to the focus in these fields on the published peer reviewed paper as being the main metric of career success.\n\nThe second argument advanced against Open Notebook Science is that it constitutes prior publication, thus making it impossible to patent and difficult to publish the results in the traditional peer reviewed literature. With respect to patents, publication on the web is clearly classified as disclosure. Therefore, while there may be arguments over the value of patents, and approaches that get around this problem, it is clear that Open Notebook Science is not appropriate for research for which patent protection is an expected and desired outcome. With respect to publication in the peer reviewed literature the case is less clear cut. Most publishers of scientific journals accept material that has previously been presented at a conference or in the form of a preprint. Those publishers that accept material that has been previously published in these forms have generally indicated informally that web publication of data, including Open Notebook Science, falls into this category. Open notebook projects have been successfully published in high impact factor peer reviewed journals but this has not been tested with a wide range of publishers. It is to be expected that those publishers that explicitly exclude these forms of pre-publication will not accept material previously disclosed in an open notebook.\n\nThe final argument relates to the problem of the 'data deluge'. If the current volume of the peer reviewed literature is too large for any one person to manage, then how can anyone be expected to cope with the huge quantity of non peer reviewed material that could potentially be available, especially when some, perhaps most, would be of poor quality? A related argument is that 'my notebook is too specific' for it to be of interest to anyone else. The question of how to discover high quality and relevant material is a related issue. The issue of curation and validating data and methodological quality is a serious issue and one that arguably has relevance beyond Open Notebook Science but is a particular challenge here.\n\nThe Open Notebook Science Challenge, now directed towards reporting solubility measurements in non-aqueous solvent, has received sponsorship from Submeta, Nature and Sigma-Aldrich. The first of ten winners of the contest for December 2008 was Jenny Hale.\n\nLogos can be used on notebooks to indicate the conditions of sharing. Fully open notebooks are marked as \"All Content\" and \"Immediate\" access. Partially open notebooks can be marked as either \"Selected Content\" and/or \"Delayed\".\n\n"}
{"id": "18700697", "url": "https://en.wikipedia.org/wiki?curid=18700697", "title": "Open peer review", "text": "Open peer review\n\nOpen peer review is a process in which names of peer reviewers of papers submitted to academic journals are disclosed to the authors of the papers in question. In some cases, as with the \"BMJ\" and BioMed Central, the process also involves posting the entire pre-publication history of the article online, including not only signed reviews of the article, but also its previous versions and author responses to the reviewers.\n\nThere is no single definition of open peer review, as it is implemented differently by different academic journals, but it has been broadly defined as \"any scholarly review mechanism providing disclosure of author and referee identities to one another at any point during the peer review or publication process\".\n\nPossible advantages to an open peer-review system include reviewers being \"more tactful and constructive\" than they would be if they could remain anonymous. It has also been argued that open review leads to more honest reviewing and prevents reviewers from following their individual agendas, as well as leading to the detection of reviewers' conflicts of interests. Some studies have also found that open peer review is associated with an increase in quality of reviews, although other studies have not found such an association. A study of BioMed Central medical journals, all of which use open peer review, found that reviewers usually did not notice problems or request changes in reporting of the results of randomized trials. The same study found most, but not all, of the requested changes had a positive effect on reporting.\n\nA 1999 study found that open peer review did not affect the quality of reviews or the recommendation regarding whether the paper being reviewed should be published, but that it \"significantly increased the likelihood of reviewers declining to review\". Open review of abstracts tended to lead to bias favoring authors from English-speaking countries and prestigious academic institutions. It has also been argued that open peer review could lead to authors accumulating enemies who try to keep their papers from being published or their grant applications from being successful.\n"}
{"id": "1217056", "url": "https://en.wikipedia.org/wiki?curid=1217056", "title": "Organicism", "text": "Organicism\n\nOrganicism is the philosophical perspective which views the universe and its parts as organic wholes and – either by analogy or literally – as living organisms. It can be synonymous with holism. Organicism is an important tradition within the history of natural philosophy where it has remained as a vital current alongside reductionism and mechanism, the approaches that have dominated science since the seventeenth century. Plato is among the earliest philosophers to have regarded the universe as an intelligent living being (see \"Timaeus\"). Organicism flourished for a period during the era of German romanticism during which time the new science of biology was first defined by Jean-Baptiste Lamarck. Within modern-day biological sciences organicism is the approach that stresses the organization (particularly the self-organizing properties), rather than the composition, of organisms. John Scott Haldane was the first biologist to use the term to describe his philosophical views in 1917, after which it was followed by certain other biologists in the 20th century.\n\nOrganicism as a doctrine rejects mechanism and reductionism (doctrines that claim that the smallest parts by themselves explain the behavior of larger organized systems of which they are a part). However, organicism also rejects vitalism, the doctrine that there is a vital force different from physical forces that accounts for living things. As Capra puts it, both schools, organicism and vitalism, were born from the quest for getting rid of the Cartesian picture of reality, a view that has been claimed to be the most destructive paradigm nowadays, from science to politics.\nA number of biologists in the early to mid-twentieth century embraced organicism. They wished to reject earlier vitalisms but to stress that whole organism biology was not fully explainable by atomic mechanism. The larger organization of an organic system has features that must be taken into account to explain its behavior.\n\nGilbert and Sarkar distinguish organicism from holism to avoid what they see as the vitalistic or spiritualistic connotations of holism. Dusek notes that holism contains a continuum of degrees of the top-down control of organization, ranging from monism (the doctrine that the only complete object is the whole universe, or that there is only one entity, the universe) to organicism, which allows relatively more independence of the parts from the whole, despite the whole being more than the sum of the parts, and/or the whole exerting some control on the behavior of the parts.\n\nStill more independence is present in relational holism. This doctrine does not assert top-down control of the whole over its parts, but does claim that the relations of the parts are essential to explanation of behavior of the system. Aristotle and early modern philosophers and scientists tended to describe reality as made of substances and their qualities, and to neglect relations. Gottfried Wilhelm Leibniz showed the bizarre conclusions to which a doctrine of the non-existence of relations led. Twentieth century philosophy has been characterized by the introduction of and emphasis on the importance of relations, whether in symbolic logic, in phenomenology, or in metaphysics.\n\nWilliam Wimsatt has suggested that the number of terms in the relations considered distinguishes reductionism from holism. Reductionistic explanations claim that two or at most three term relations are sufficient to account for the system's behavior. At the other extreme the system could be considered as a single ten to the twenty-sixth term relation, for instance.\n\nOrganicism has some intellectually and politically controversial or suspect associations. \"Holism,\" the doctrine that the whole is more than the sum of its parts, often used synonymously with organicism, or as a broader category under which organicism falls, has been co-opted in recent decades by \"holistic medicine\" and by New Age Thought. German Nazism appealed to organicist and holistic doctrines, discrediting for many in retrospect, the original organicist doctrines. (See Anne Harrington). Soviet Dialectical Materialism also made appeals to an holistic and organicist approach stemming from Hegel via Karl Marx's co-worker Friedrich Engels, again giving a controversial political association to organicism.\n\nOrganicism' has also been used to characterize notions put forth by various late 19th-century social scientists who considered human society to be analogous to an organism, and individual humans to be analogous to the cells of an organism. This sort of organicist sociology was articulated by Alfred Espinas, Paul von Lilienfeld, Jacques Novicow, Albert Schäffle, Herbert Spencer, and René Worms, among others.\n\nThomas Hobbes arguably put forward a form of organicism. In the \"Leviathan\", he argued that the state is like a secular God whose constituents (individual people) make up a larger organism.\n\nIn breathing entities, cells – i.e., the smallest unit of life – were first observed in the 17th century, when the multifaceted equipment microscope was conceived. Before that period, the individual organisms were studied as a whole in a field known as organismic biology; that area of research remains an important component of the biological sciences. Further, as Capra puts it, during the early 1900s, the quantum researchers struggled with the same paradigm shift from \"the parts to the whole\" that culminated into the scholars of organismic biology.\n\nIn biology organicism considers that the observable structures of life, its overall form and the properties and characteristics of its component parts are a result of the reciprocal play of all the components on each other.\nExamples of 20th century biologists who were organicists are Ross Harrison, Paul Weiss, and Joseph Needham. Donna Haraway discusses them in her first book \"Crystals, Fabrics, and Fields\". John Scott Haldane (father of J. B. S. Haldane), William Emerson Ritter, Edward Stuart Russell, Joseph Henry Woodger, Ludwig von Bertalanffy, and Ralph Stayner Lillie are other early twentieth century organicists. Robert Rosen, founder of \"Relational Biology\" provided a comprehensive mathematical and category-theoretic treatment of irreducible causal relations he believed to be responsible for life.\n\nIn the early 1930s Joseph Henry Woodger and Joseph Needham, together with Conrad Hal Waddington, John Desmond Bernal, Dorothy Needham, and Dorothy Wrinch, formed the Theoretical Biology Club, to promote the organicist approach to biology. The club was in opposition to mechanism, reductionism and the gene-centric view of evolution. Most of the members were influenced by the philosophy of Alfred North Whitehead. The club disbanded as the Rockefeller Foundation refused to fund their investigations.\n\n\nNotes\nCitations\n\n\n"}
{"id": "242710", "url": "https://en.wikipedia.org/wiki?curid=242710", "title": "Outline of academic disciplines", "text": "Outline of academic disciplines\n\nAn academic discipline or field of study is a branch of knowledge, taught and researched as part of higher education. A scholar's discipline is commonly defined by the university faculties and learned societies to which he or she belongs and the academic journals in which he or she publishes research.\n\nDisciplines vary between well-established ones that exist in almost all universities and have well-defined rosters of journals and conferences and nascent ones supported by only a few universities and publications. A discipline may have branches, and these are often called sub-disciplines.\n\nThere is no consensus on how some academic disciplines should be classified, for example whether anthropology and linguistics are disciplines of the social sciences or of the humanities.\n\nThe following outline is provided as an overview of and topical guide to academic disciplines.\n\n\n\n\n\n\n\n\"Also a branch of electrical engineering\"\n\nPure mathematics\n\nApplied mathematics\n\n\nChemical Engineering\n\nCivil Engineering\n\nEducational Technology\n\nElectrical Engineering\n\nMaterials Science and Engineering\n\nMechanical Engineering\n\nSystems science\n\n\n\n"}
{"id": "56821883", "url": "https://en.wikipedia.org/wiki?curid=56821883", "title": "Paperity", "text": "Paperity\n\nPaperity is a multidisciplinary aggregator of open access journals and papers. It was launched in October 2014 with 160,000 articles. As of March 2018, Paperity includes 1.5 million articles from 4,200 journals, covering all academic disciplines: mathematical sciences, life sciences, medicine, social sciences, humanities, arts. Paperity provides full-text search, RSS feeds and a mobile application to access the literature. All articles are available in full text without fees.\n\nPaperity shares the aggregated metadata with other academic services: EBSCO, Altmetric, WorldCat, OCLC, Plagiat.pl, StrikePlagiarism.com. \n\n"}
{"id": "25994113", "url": "https://en.wikipedia.org/wiki?curid=25994113", "title": "Patras Science Park", "text": "Patras Science Park\n\nThe Patras Science Park is a science park located in Patras, Greece near the University of Patras and the University Hospital of Rio. The site is the home for many high technology companies in Western Greece.\nThe following companies and institutes are current or former residents of the Science Park:\n\n"}
{"id": "4917580", "url": "https://en.wikipedia.org/wiki?curid=4917580", "title": "Peter Murray-Rust", "text": "Peter Murray-Rust\n\nPeter Murray-Rust (born 1941) is a chemist currently working at the University of Cambridge. As well as his work in chemistry, Murray-Rust is also known for his support of open access and open data.\n\nHe was educated at Bootham School and Balliol College, Oxford. After obtaining a Doctor of Philosophy with a thesis entitled \"A structural investigation of some compounds showing charge-transfer properties,\" he became lecturer in chemistry at the (new) University of Stirling and was first warden of Andrew Stewart Hall of Residence. In 1982, he moved to Glaxo Group Research at Greenford to head Molecular Graphics, Computational Chemistry and later protein structure determination. He was Professor of Pharmacy in the University of Nottingham from 1996–2000, setting up the Virtual School of Molecular Sciences. He is now Reader Emeritus in Molecular Informatics at the University of Cambridge and Senior Research Fellow Emeritus of Churchill College, Cambridge.\n\nHis research interests have involved the automated analysis of data in scientific publications, creation of virtual communities, e.g. The Virtual School of Natural Sciences in the Globewide Network Academy, and the Semantic Web. With Henry Rzepa, he has extended this to chemistry through the development of markup languages, especially Chemical Markup Language. He campaigns for open data, particularly in science, and is on the advisory board of the Open Knowledge International and a co-author of the Panton Principles for Open scientific data. Together with a few other chemists, he was a founder member of the Blue Obelisk movement in 2005.\n\nIn 2002, Peter Murray-Rust and his colleagues proposed an electronic repository for unpublished chemical data called the World Wide Molecular Matrix (WWMM). In January 2011, a symposium around his career and visions was organized, called \"Visions of a Semantic Molecular Future\". In 2011, he and Henry Rzepa were joint recipients of the Herman Skolnik Award of the American Chemical Society. In 2014, he was awarded a Fellowship by the Shuttleworth Foundation to develop the automated mining of science from the literature.\n\nIn 2009 Murray-Rust coined the term \"\"Doctor Who\" model\" for the phenomenon exhibited by the Blue Obelisk project and other Open Science projects, where when a project leader does not have the resources to continue to lead a project (e.g. because he or she has moved to another university with other tasks), someone else will stand up to become the new leader and continue the project. This is a reference to the long-running British science fiction television series \"Doctor Who\", in which the main character periodically regenerates into a different form, which is played by a different actor.\n\nAs of 2014, Murray-Rust was granted a Fellowship by Shuttleworth Foundation in relation to the ContentMine project which uses machines to liberate 100,000,000 facts from the scientific literature.\n\nMurray-Rust is also known for his work on making scientific knowledge from literature freely available, and in such taking a stance against publishers that are not fully compliant with the Berlin Declaration on Open Access. In 2014, he actively raised awareness of glitches in the publishing system of Elsevier, where restrictions were imposed by Elsevier on the reuse of papers after the authors had paid Elsevier to make the paper freely available. He has also made statements about predatory journals; he has come under criticism by Jeffrey Beall for his involvement with publisher MDPI and for his account of this involvement.\n\n"}
{"id": "246066", "url": "https://en.wikipedia.org/wiki?curid=246066", "title": "Prediction", "text": "Prediction\n\nA prediction (Latin \"præ-\", \"before,\" and \"dicere\", \"to say\"), or forecast, is a statement about a future event. A prediction is often, but not always, based upon experience or knowledge. There is no universal agreement about the exact difference between the two terms; different authors and disciplines ascribe different connotations. (Contrast with estimation.)\n\nAlthough future events are necessarily uncertain, so guaranteed accurate information about the future is in many cases impossible, prediction can be useful to assist in making plans about possible developments; Howard H. Stevenson writes that prediction in business \"... is at least two things: Important and hard.\"\n\nIn a non-statistical sense, the term \"prediction\" is often used to refer to an informed guess or opinion.\n\nA prediction of this kind might be informed by a predicting person's abductive reasoning, inductive reasoning, deductive reasoning, and experience; and may be of useful — if the predicting person is a knowledgeable person in the field.\n\nThe Delphi method is a technique for eliciting such expert-judgement-based predictions in a controlled way. This type of prediction might be perceived as consistent with statistical techniques in the sense that, at minimum, the \"data\" being used is the predicting expert's cognitive experiences forming an intuitive \"probability curve.\"\n\nIn statistics, prediction is a part of statistical inference. One particular approach to such inference is known as predictive inference, but the prediction can be undertaken within any of the several approaches to statistical inference. Indeed, one possible description of statistics is that it provides a means of transferring knowledge about a sample of a population to the whole population, and to other related populations, which is not necessarily the same as prediction over time. When information is transferred across time, often to specific points in time, the process is known as forecasting. Forecasting usually requires time series methods, while prediction is often performed on cross-sectional data.\n\nStatistical techniques used for prediction include regression analysis and its various sub-categories such as linear regression, generalized linear models (logistic regression, Poisson regression, Probit regression), etc. In case of forecasting, autoregressive moving average models and vector autoregression models can be utilized. When these and/or related, generalized set of regression or machine learning methods are deployed in commercial usage, the field is known as predictive analytics.\n\nIn many applications, such as time series analysis, it is possible to estimate the models that generate the observations. If models can be expressed as transfer functions or in terms of state-space parameters then smoothed, filtered and predicted data estimates can be calculated. If the underlying generating models are linear then a minimum-variance Kalman filter and a minimum-variance smoother may be used to recover data of interest from noisy measurements. These techniques rely on one-step-ahead predictors (which minimise the variance of the prediction error). When the generating models are nonlinear then stepwise linearizations may be applied within Extended Kalman Filter and smoother recursions. However, in nonlinear cases, optimum minimum-variance performance guarantees no longer apply.\n\nTo use regression analysis for prediction, data are collected on the variable that is to be predicted, called the dependent variable or response variable, and on one or more variables whose values are hypothesized to influence it, called independent variables or explanatory variables. A functional form, often linear, is hypothesized for the postulated causal relationship, and the parameters of the function are estimated from the data—that is, are chosen so as to optimize is some way the fit of the function, thus parameterized, to the data. That is the estimation step. For the prediction step, explanatory variable values that are deemed relevant to future (or current but not yet observed) values of the dependent variable are input to the parameterized function to generate predictions for the dependent variable.\n\nIn science, a prediction is a rigorous, often quantitative, statement, forecasting what would happen under specific conditions; for example, if an apple fell from a tree it would be attracted towards the center of the earth by gravity with a specified and constant acceleration. The scientific method is built on testing statements that are logical consequences of scientific theories. This is done through repeatable experiments or observational studies.\n\nA scientific theory which is contradicted by observations and evidence will be rejected. New theories that generate many new predictions can more easily be supported or falsified (see predictive power). Notions that make no \"testable\" predictions are usually considered not to be part of science (protoscience or nescience) until testable predictions can be made.\n\nMathematical equations and models, and computer models, are frequently used to describe the past and future behaviour of a process within the boundaries of that model. In some cases the probability of an outcome, rather than a specific outcome, can be predicted, for example in much of quantum physics.\n\nIn microprocessors, branch prediction permits avoidance of pipeline emptying at branch instructions. In engineering, possible failure modes are predicted and avoided by correcting the mechanism causing the failure.\n\nAccurate prediction and forecasting are very difficult in some areas, such as natural disasters, pandemics, demography, population dynamics and meteorology. For example, it is possible to predict the occurrence of solar cycles, but their exact timing and magnitude is much more difficult (see picture to right).\n\nEstablished science makes useful predictions which are often extremely reliable and accurate; for example, eclipses are routinely predicted.\n\nNew theories make predictions which allow them to be disproved by reality. For example, predicting the structure of crystals at the atomic level is a current research challenge. In the early 20th century the scientific consensus was that there existed an absolute frame of reference, which was given the name \"luminiferous ether\". The existence of this absolute frame was deemed necessary for consistency with the established idea that the speed of light is constant. The famous Michelson-Morley experiment demonstrated that predictions deduced from this concept were not borne out in reality, thus disproving the theory of an absolute frame of reference. The special theory of relativity was proposed by Einstein as an explanation for the seeming inconsistency between the constancy of the speed of light and the non-existence of a special, preferred or absolute frame of reference.\n\nAlbert Einstein's theory of general relativity could not easily be tested as it did not produce any effects observable on a terrestrial scale. However, the theory predicted that large masses such as stars would bend light, in contradiction to accepted theory; this was observed in a 1919 eclipse.\n\nMathematical models of stock market behaviour (and economic behaviour in general) are also unreliable in predicting future behaviour. Among other reasons, this is because economic events may span several years, and the world is changing over a similar time frame, thus invalidating the relevance of past observations to the present. Thus there are an extremely small number (of the order of 1) of relevant past data points from which to project the future. In addition, it is generally believed that stock market prices already take into account all the information available to predict the future, and subsequent movements must therefore be the result of unforeseen events. Consequently, it is extremely difficult for a stock investor to anticipate or predict a stock market boom, or a stock market crash. In contrast to predicting the actual stock return, forecasting of broad economic trends tends to have better accuracy. Such analysis is provided by both non-profit groups as well as by for-profit private institutions, including brokerage housesand consulting companies.\n\nSome correlation has been seen between actual stock market movements and prediction data from large groups in surveys and prediction games.\n\nAn actuary uses actuarial science to assess and predict future business risk, such that the risk(s) can be mitigated. For example, in insurance an actuary would use a life table (which incorporates the historical experience of mortality rates and sometimes an estimate of future trends) to project life expectancy.\n\nPredicting the outcome of sporting events is a business which has grown in popularity in recent years. Handicappers predict the outcome of games using a variety of mathematical formulas, simulation models or qualitative analysis. Early, well known sports bettors, such as Jimmy the Greek, were believed to have access to information that gave them an edge. Information ranged from personal issues, such as gambling or drinking to undisclosed injuries; anything that may affect the performance of a player on the field.\n\nRecent times have changed the way sports are predicted. Predictions now typically consist of two distinct approaches: Situational plays and statistical based models. Situational plays are much more difficult to measure because they usually involve the motivation of a team. Dan Gordon, noted handicapper, wrote “Without an emotional edge in a game in addition to value in a line, I won’t put my money on it”. These types of plays consist of: Betting on the home underdog, betting against Monday Night winners if they are a favorite next week, betting the underdog in “look ahead” games etc. As situational plays become more widely known they become less useful because they will impact the way the line is set.\n\nThe widespread use of technology has brought with it more modern sports betting systems. These systems are typically algorithms and simulation models based on regression analysis. Jeff Sagarin, a sports statistician, has brought attention to sports by having the results of his models published in USA Today. He is currently paid as a consultant by the Dallas Mavericks for his advice on lineups and the use of his Winval system, which evaluates free agents. Brian Burke, a former Navy fighter pilot turned sports statistician, has published his results of using regression analysis to predict the outcome of NFL games. Ken Pomeroy is widely accepted as a leading authority on college basketball statistics. His website includes his College Basketball Ratings, a tempo based statistics system. Some statisticians have become very famous for having successful prediction systems. Dare wrote “the effective odds for sports betting and horse racing are a direct result of human decisions and can therefore potentially exhibit consistent error”. Unlike other games offered in a casino, prediction in sporting events can be both logical and consistent.\n\nIn politics it is common to attempt to predict the outcome of elections via political forecasting techniques (or assess the popularity of politicians) through the use of opinion polls. Prediction games have been used by many corporations and governments to learn about the most likely outcome of future events.\n\nPredictions have often been made, from antiquity until the present, by using paranormal or supernatural means such as prophecy or by observing omens. Methods including water divining, astrology, numerology, fortune telling, interpretation of dreams, and many other forms of divination, have been used for millennia to attempt to predict the future. These means of prediction have not been proven by scientific experiments.\n\nIn literature, vision and prophecy are literary devices used to present a possible timeline of future events. They can be distinguished by vision referring to what an individual sees happen. The New Testament book of Revelation (Bible) thus uses vision as a literary device in this regard. It is also prophecy or prophetic literature when it is related by an individual in a sermon or other public forum.\n\nDivination is the attempt to gain insight into a question or situation by way of an occultic standardized process or ritual. It is an integral part of witchcraft and has been used in various forms for thousands of years. Diviners ascertain their interpretations of how a querent should proceed by reading signs, events, or omens, or through alleged contact with a supernatural agency, most often describe as an angel or a god though viewed by Christians and Jews as a fallen angel or demon.\n\nFiction (especially fantasy, forecasting and science fiction) often features instances of prediction achieved by unconventional means.\n\n"}
{"id": "36843243", "url": "https://en.wikipedia.org/wiki?curid=36843243", "title": "Preference test", "text": "Preference test\n\nA preference test is an experiment in which animals are allowed free access to multiple environments which differ in one or more ways. Various aspects of the animal's behaviour can be measured with respect to the alternative environments, such as latency and frequency of entry, duration of time spent, range of activities observed, or relative consumption of a goal object in the environment. These measures can be recorded either by the experimenter or by motion detecting software. Strength of preference can be inferred by the magnitude of the difference in the response, but see \"Advantages and disadvantages\" below. Statistical testing is used to determine whether observed differences in such measures support the conclusion that preference or aversion has occurred. Prior to testing, the animals are usually given the opportunity to explore the environments to habituate and reduce the effects of novelty.\n\nPreference tests can be used to test for preferences of only one characteristic of an environment, e.g. cage colour, or multiple characteristics e.g. a choice between hamster wheel, Habitrail tunnels or additional empty space for extended locomotion.\n\nThe simplest of preference tests offers a choice between two alternatives. This can be done by putting different goal boxes at the ends of the arms of a 'T' shaped maze, or having a chamber divided in into differing halves. A famous example of this simple method is an investigation of the preferences of chickens for different types of wire floor in battery cages. Two types of metal mesh flooring were being used in the 1950s; one type was a large, open mesh using thick wire, the other was a smaller mesh size but the wire was considerably thinner. A prestigious committee, the Brambell Committee, conducting an investigation into farm animal welfare concluded the thicker mesh should be used as this was likely to be more comfortable for the chickens. However, preference tests showed that chickens preferred the thinner wire. Photographs taken from under the cages showed that the thinner mesh offered more points of contact for the feet than the thick mesh, thereby spreading the load on the hens' feet and presumably feeling more comfortable to the birds.\n\nThe number of choices that can be offered is theoretically limitless for some preference tests, e.g., light intensity, cage size, food types; however, the number is often limited by experimental practicalities, current practice (e.g., animal caging systems) or costs. Furthermore, animals usually investigate all areas of the apparatus in a behaviour called \"information gathering\", even those with minor preference, so the more choices that are available may dilute the data on the dominant preference(s).\n\nMost preference tests involve no 'cost' for making a choice, so they do not indicate the strength of an animals motivation or need to obtain the outcome of the choice. For example, if a laboratory mouse is offered three sizes of cage space it may prefer one of them, but this choice does not indicate whether the mouse 'needs' that particular space, or whether it has a relatively slight preference for it. To measure an animals motivation toward a choice one may perform a \"consumer demand test.\" In this sort of test, the choice involves some \"cost\" to the animal, such as physical effort (e.g., lever pressing, weighted door).\n\nPreference tests have been used widely in the study of animal behaviour and motivation, e.g.:\n\n\n\n\n\n\n\n\n\n"}
{"id": "55779967", "url": "https://en.wikipedia.org/wiki?curid=55779967", "title": "Priority certificate", "text": "Priority certificate\n\nA priority certificate is a document attesting that the entities named in such a certificate are the first to discover a phenomenon from nature, the first proponent of a theory, abstract idea, solution to a problem, proof of a theorem etc. A person who makes a new and useful discovery is entitled to receive such a priority certificate for that specific discovery. \n\nPrivate or public companies and organizations, such as universities, R&D institutions, trade shows and exhibitions are known to grant priority certificates to confer formal recognition upon the claimant(s).\n\n"}
{"id": "1593617", "url": "https://en.wikipedia.org/wiki?curid=1593617", "title": "Retrodiction", "text": "Retrodiction\n\nRetrodiction (also known as postdiction—although this should not be confused with the use of the term in criticisms of parapsychological research) is the act of making a \"prediction\" about the past.\n\nThe activity of retrodiction (or postdiction) involves moving backwards in time, step-by-step, in as many stages as are considered necessary, from the present into the speculated past to establish the ultimate cause of a specific event (for instance, in the case of reverse engineering, forensics, etc.).\n\nGiven that retrodiction is a process in which \"past observations, events and data are used as evidence to infer the process(es) that produced them\" and that diagnosis \"involve[s] going from visible effects such as symptoms, signs and the like to their prior causes\" the essential balance between prediction and retrodiction could be characterized as:\nregardless of whether the prognosis is of the course of the disease in the absence of treatment, or of the application of a specific treatment regimen to a specific disorder in a particular patient:\n\nIn scientific method, the terms \"retrodiction\" or \"postdiction\" are used in several senses.\n\nOne use refers to the act of evaluating a scientific theory by predicting known rather than new events. For example, a theory in physics that claims to extend or replace the standard model but that fails to predict the existence of known particles has not met the test of \"postdiction\".\n\nMichael Clive Price has written: \n\nA retrodiction occurs when already gathered data is accounted for by a later theoretical advance in a more convincing fashion. The advantage of a retrodiction over a prediction is that the already gathered data is more likely to be free of experimenter bias. An example of a retrodiction is the perihelion shift of Mercury which Newtonian mechanics plus gravity was unable, totally, to account for whilst Einstein's general relativity made short work of it.\n\nAnother use refers to a process by which one attempts to test a theory whose predictions are too long-term to be tested by waiting for a future event to occur. Instead, one speculates about uncertain events in the more distant past, and applies the theory to consider how it would have predicted a known event in the less distant past. This is useful in, for example, the fields of archaeology, climatology, evolutionary biology, financial analysis, forensic science, and cosmology.\n\nIn the field of neuroscience, the term \"postdiction\" was introduced by David Eagleman to describe a perceptual process in which the brain collects information after an event before it retrospectively decides what happened at the time of the event (Eagleman and Sejnowski, 2000). Some perceptual illusions in which the brain mistakenly perceives the location of moving stimuli may involve postdiction. Such illusions include the flash lag illusion and the cutaneous rabbit illusion.\n\n\n"}
{"id": "47542146", "url": "https://en.wikipedia.org/wiki?curid=47542146", "title": "Scale of chords", "text": "Scale of chords\n\nA scale of chords may be used to set or read an angle in the absence of a protractor. To draw an angle, compasses describe an arc from origin with a radius taken from the 60 mark. The required angle is copied from the scale by the compasses, and an arc of this radius drawn from the sixty mark so it intersects the first arc. The line drawn from this point to the origin will be at the target angle.\n\nA chord is a line drawn between two points on the circumference of a circle. Look at the centre point of this line. For a circle of radius , each half will be formula_1 so the chord will be formula_2. The line of chords scale represents each of these values linearly on a scale running from 0 to 60.\n\nIt appears on Gunter's scale and the Foster Serle dialing scales. The commercial company Stanley marketed a metal version (Stanley 60R Line of Chords Rule) in 2015.\n\n\n\n"}
{"id": "19086436", "url": "https://en.wikipedia.org/wiki?curid=19086436", "title": "Science.ie", "text": "Science.ie\n\nThe Science.ie portal provides all sorts of information about careers in science, technology, engineering and mathematics (STEM).\n\nScience.ie is an initiative of the Irish Government’s Discover Science & Engineering (DSE) awareness programme in Ireland. DSE is managed by Forfás on behalf of the Office of Science and Technology at the Department of Jobs, Enterprise and Innovation.\n\nThe careers-related information on Science.ie has been moved to a new DSE website - My Science Career - which was launched in early October 2009. On MyScienceCareer.ie is:\n\n\nA redeveloped Science.ie was also launched in October 2009. The site has been redesigned and includes social media bookmarking and RSS feeds.\n\nScience.ie provides more general information on science in Ireland. This includes listings of science links, news and events. Its \"Resources\" section gives information on activities and visitor centres where you can learn about science.\n\nThe site also provides a free newsletter relating to Irish science, technology and innovation news, events, research and facts which is issued monthly by email.\n\nIn November 2009 Science.ie launched a Twitter channel. Follow Science.ie on Twitter.\n\nDSE runs numerous other initiatives, including My Science Career, Project Blogger, Science Week Ireland and Discover Primary Science.\n\n"}
{"id": "55547169", "url": "https://en.wikipedia.org/wiki?curid=55547169", "title": "Science information on Wikipedia", "text": "Science information on Wikipedia\n\nScience information on Wikipedia includes the information which Wikipedia presents about science. It critiques and discusses the impact and quality of that information, and the culture of Wikipedia editors, scientists, and layman engagement with this information.\n\nA 2017 study found evidence that Wikipedia's popularity as the most popular general information source has influenced how everyone talks and writes about science.\n\nA 2016 study found evidence that Wikipedia increases the distribution and impact of open access science publications.\n\nUNESCO reports that Wikipedia is a popular source of science information because Wikipedia has high ranking in search engines.\n\nA 2018 study examined the way that Wikipedia integrates new scientific information.\n\nIn 2016 the Wiki Education Foundation and the Simons Foundation presented an outreach program called the \"Year of Science\". In this program, Wikipedia educators visited academic conferences and invited scientists to contribute information from their field of expertise to Wikipedia.\n\nSome universities have programs to encourage students to edit Wikipedia's science articles as part of the learning experience.\n\nThe Wikipedia community invites academics to edit Wikipedia articles.\n\nVarious academic societies have encouraged their membership to edit Wikipedia.\n\nA 2005 study published in the journal \"Nature\" compared 40 Wikipedia articles on science topics to their \"Encyclopædia Britannica\" counterpart. Subject experts found four \"serious errors\" in each encyclopedia. They also found 162 less serious problems in Wikipedia, and 123 in \"Britannica\".\n\nA popular science writer for \"Vice\" complained in 2017 that Wikipedia's science articles were too technical.\n\nVarious scientists and media organizations have questioned and critiqued the extent to which Wikipedia articles on science influence political decisions relating to science. \n\n"}
{"id": "7621278", "url": "https://en.wikipedia.org/wiki?curid=7621278", "title": "Scientific Memoirs", "text": "Scientific Memoirs\n\n\"Scientific Memoirs, Selected from the Transactions of Foreign Academies of science and Learned Societies and from Foreign Journals\" was a series of books edited and published by Richard Taylor (1781–1858) in London between 1837 and 1852.\n\nAfter 1852 the publication continued in two series:\n\nThe September 1843 edition contained Ada Lovelace's notes appended to her translation of Luigi Federico Menabrea's article, originally published in 1842 in French in the Swiss Journal Bibliothèque universelle de Genève, based on Charles Babbage's lectures on his Analytical Engine, given in Turin, Italy, in 1840.\n\nSome volumes have been reprinted by Johnson Reprint Corp. New York in 1966.\n\n"}
{"id": "875785", "url": "https://en.wikipedia.org/wiki?curid=875785", "title": "Social effects of evolutionary theory", "text": "Social effects of evolutionary theory\n\nThe social effects of evolutionary thought have been considerable. As the scientific explanation of life's diversity has developed, it has often displaced alternative, sometimes very widely held, explanations. Because the theory of evolution includes an explanation of humanity's origins, it has had a profound impact on human societies. Some have vigorously denied acceptance of the scientific explanation due to its perceived religious implications (e.g. its implied rejection of the special creation of humans presumably described in the Bible). This has led to a vigorous conflict between creation and evolution in public education, primarily in the United States.\n\nThe theory of evolution by natural selection has also been adopted as a foundation for various ethical and social systems, such as social Darwinism, an idea that preceded the publication of The Origin of Species, popular in the 19th century, which holds that \"the survival of the fittest\" (a phrase coined in 1851 by Herbert Spencer, 6 years before Darwin published his theory of evolution) explains and justifies differences in wealth and success among societies and people. A similar interpretation was one created by Darwin's cousin, Francis Galton, known as eugenics, which claimed that human civilization was subverting natural selection by allowing the less bright and less healthy to survive and out-breed the more smart and more healthy.\n\nLater advocates of this theory suggested radical and often coercive social measures in an attempt to \"correct\" this imbalance. Thomas Huxley spent much time demonstrating through a series of thought experiments that it would not only be immoral, but impossible, Stephen Jay Gould and others have argued that social Darwinism is based on misconceptions of evolutionary theory, and many ethicists regard it as a case of the is-ought problem. After the atrocities of the Holocaust became linked with eugenics, it greatly fell out of favor with public and scientific opinion, though it was never universally accepted by either, and at no point in Nazi literature is Charles Darwin or the scientific theory of evolution mentioned.\n\nIn his book \"The End of Faith\", Sam Harris argues that Nazism was largely a continuation of Christian anti-Semitism. Jim Walker compiled a list of 129 quotes from Mein Kampf in which Hitler described himself as a Christian, or mentioned God, Jesus or a biblical passage. Some argue that six million of the people killed during the Holocaust were killed because of their religion (Judaism) not their race, \"strength,\" or any reason with an obvious link to the mechanism of Darwinian evolution. Hitler often used Christian beliefs like, \"Jews killed Jesus,\" to justify his anti-Semitism.\n\nThe notion that humans share ancestors with other animals has also affected how some people view the relationship between humans and other species. Many proponents of animal rights hold that if animals and humans are of the same nature, then rights cannot be distinct to humans.\n\nCharles Darwin, in fact, considered \"sympathy\" to be one of the most important moral virtues — and that it was, indeed, a product of natural selection and a trait beneficial to social animals (including humans). Darwin further argued that the most \"sympathetic\" societies would consequently be the most \"successful.\" He also stated that our sympathy should be extended to \"all sentient beings\":\n\nThomas Huxley, \"Darwin's Bulldog\", spent much of his book Evolution and Ethics debunking Social Darwinism, piece by piece. The following is a summary of his arguments in the \"Prolegomena\", the most detailed and comprehensive of the two sections devoted to it. It should be noted that Huxley is here attempting to disprove the science behind Social Darwinism; as such, the moral arguments only come in later in the essay.\n\nConsider a garden. Without constant upkeep, it would return to the \"state of nature\", even the very walls surrounding it crumbling in sufficient time, but by constant diligence of the gardener, may be maintained in a \"state of art\". This \"state of art\" is not permanent: It is instead the replacement of natural selection by artificial selection through the human energy expended in maintaining it.\n\nThis artificial selection is, however, part of natural selection: It is the action upon a set of species by the human species by way of the human species expending energy through evolved intelligence on its choice of selection. It is thus no less natural than, for example, a predator expending energy through evolved instinct on preferentially hunting a certain prey species. The presence of humans may change the dynamic, but in a perfectly natural way. Hence, it is part of the \"cosmic process\", that is natural laws, even though the \"histological process\" may remove many aspects of the \"struggle for existence\" that is a key part of the natural laws that apply to biology, from its preferred plant species by substituting human work for work done by the species itself.\nNot only is the state of nature hostile to the state of art of the garden; but the principle of the horticultural process, by which the latter is created and maintained, is antithetic to that of the cosmic process. The characteristic feature of the latter is the intense and unceasing competition of the struggle for existence. The characteristic of the former is the elimination of that struggle, by the removal of the conditions which give rise to it. The tendency of the cosmic process is to bring about the adjustment of the forms of plant life to the current conditions; the tendency of the horticultural process is the adjustment of the conditions to the needs of the forms of plant life which the gardener desires to raise.\nNature uses unrestricted breeding to let hundreds compete for the natural resources that would only support one, and uses frost and drought to kill off the weak and unlucky, requiring not just strength, but \"flexibility and good fortune.\" However, a gardener restricts multiplication, gives each plant sufficient space and nourishment, protects from frost and drought—and, in every other way, attempts to modify the conditions to benefit the forms that most nearly approach the result he desires. However, though the gardener's actions may have circumvented natural selection, he can still improve the species, should he find them wanting, through selective breeding. The struggle for existence is not actually required for improvement: only heritability, variation, and some form of selective pressure.\n\nCan we then apply this to humans? Let's see how far we can take the analogy with respect to colonization:\nSuppose a shipload of English colonists sent to form a settlement, in such a country as Tasmania was in the middle of the last century. On landing, they find themselves in the midst of a state of nature, widely different from that left behind them in everything but the most general physical conditions. The common plants, the common birds and quadrupeds, are as totally distinct as the men from anything to be seen on the side of the globe from which they come. The colonists proceed to put an end to this state of things over as large an area as they desire to occupy. They clear away the native vegetation, extirpate or drive out the animal population, so far as may be necessary, and take measures to defend themselves from the re-immigration of either. In their place, they introduce English grain and fruit trees; English dogs, sheep, cattle, horses; and English men; in fact, they set up a new Flora and Fauna and a new variety of mankind, within the old state of nature. Their farms and pastures represent a garden on a great scale, and themselves the gardeners who have to keep it up, in watchful antagonism to the old regime. Considered as a whole, the colony is a composite unit introduced into the old state of nature; and, thenceforward, a competitor in the struggle for existence, to conquer or be vanquished.\n\nUnder the conditions supposed, there is no doubt of the result, if the work of the colonists be carried out energetically and with intelligent combination of all their forces. On the other hand, if they are slothful, stupid, and careless; or if they waste their energies in contests with one another, the chances are that the old state of nature will have the best of it. The native savage will destroy the immigrant civilized man; of the English animals and plants some will be extirpated by their indigenous rivals, others will pass into the feral state and themselves become components of the state of nature. In a few decades, all other traces of the settlement will have vanished.\nHowever, as yet we lack an organized gardener. Let us imagine an idealized one: an administrative authority of intelligence and foresight as much greater than men as men are to their livestock. The unwanted native species - men, animals, or plants - are all weeded out and destroyed. Those to replace them are chosen with a view to his ideal of the colony, just as a gardener tries to create through his selection his ideal garden. And, finally, to ensure that no struggle for existence between the colonists interferes with the struggle against nature, he provides them with sufficient food, housing, and so on. \"With every step of this progress in civilization, the colonists would become more and more independent of the state of nature; more and more, their lives would be conditioned by a state of art. In order to attain his ends, the administrator would have to avail himself of the courage, industry, and co-operative intelligence of the settlers; and it is plain that the interest of the community would be best served by increasing the proportion of persons who possess such qualities, and diminishing that of persons devoid of them. In other words, by selection directed towards an ideal.\"\n\nHowever, though this might create a paradise where every aspect of nature works to support its colonists, problems arise: \"as soon as the colonists began to multiply, the administrator would have to face the tendency to the reintroduction of the cosmic struggle into his artificial fabric, in consequence of the competition, not merely for the commodities, but for the means of existence. When the colony reached the limit of possible expansion, the surplus population must be disposed of somehow; or the fierce struggle for existence must recommence and destroy that peace, which is the fundamental condition of the maintenance of the state of art against the state of nature.\n\nIf the administrator is guided purely by scientific considerations, he would work to restrict the population by removing \"the hopelessly diseased, the infirm aged, the weak or deformed in body or in mind, and the excess of infants born,\" just as a \"gardener pulls up defective and superfluous plants, or the breeder\ndestroys undesirable cattle. Only the strong and the healthy, carefully matched, with a view to the progeny best adapted to the purposes of the administrator, would be permitted to perpetuate their kind.\"\n\nAnd so we have reached Social Darwinism. However, we do not have an idealized administrator:\n\nOf the more thoroughgoing of the multitudinous attempts to apply the principles of cosmic evolution, or what are supposed to be such, to social and political problems, which have appeared of late years, a considerable proportion appear to me to be based upon the notion that human society is competent to furnish, from its own resources, an administrator of the kind I have imagined. The pigeons, in short, are to be their own Sir John Sebright. A despotic government, whether individual or collective, is to be endowed with the preternatural intelligence, and with what, I am afraid, many will consider the preternatural ruthlessness, required for the purpose of carrying out the principle of improvement by selection, with the somewhat drastic thoroughness upon which the success of the method depends. Experience certainly does not justify us in limiting the ruthlessness of individual \"saviors of society\"; and, on the well-known grounds of the aphorism which denies both body and soul to corporations, it seems probable (indeed the belief is not without support in history) that a collective despotism, a mob got to believe in its own divine right by demagogic missionaries, would be capable of more thorough work in this direction than any single tyrant, puffed up with the same illusion, has ever achieved. But intelligence is another affair. The fact that \"saviors of society\" take to that trade is evidence enough that they have none to spare. And such as they possess is generally sold to the capitalists of physical force on whose resources they depend. However, I doubt whether even the keenest judge of character, if he had before him a hundred boys and girls under fourteen, could pick out, with the least chance of success, those who should be kept, as certain to be serviceable members of the polity, and those who should be chloroformed, as equally sure to be stupid, idle, or vicious. The \"points\" of a good or of a bad citizen are really far harder to discern than those of a puppy or a short-horn calf; many do not show themselves before the practical difficulties of life stimulate manhood to full exertion. And by that time the mischief is done. The evil stock, if it be one, has had time to multiply, and selection is nullified.\nHowever, humans are not cattle, nor flowers: the organization of human society is kept together by\n\n...bonds of such a singular character, that the attempt to perfect society after his fashion would run serious risk of loosening them. They do not even correspond to social insects such as bees: With bees, \"The members of the society are each organically predestined to the performance of one particular class of functions only. If they were endowed with desires, each could desire to perform none but those offices for which its organization specially fits it; and which, in view of the good of the whole, it is proper it should do. Among mankind, on the contrary, there is no such predestination to a sharply defined place in the social organism. However much men may differ in the quality of their intellects, the intensity of their passions, and the delicacy of their sensations, it cannot be said that one is fitted by his organization to be an agricultural laborer and nothing else, and another to be a landowner and nothing else. Moreover, with all their enormous differences in natural endowment, men agree in one thing, and that is their innate desire to enjoy the pleasures and to escape the pains of life; and, in short, to do nothing but that which it pleases them to do, without the least reference to the welfare of the society into which they are born, checked only by sympathy, familial and social bonds, and fear of the judgment of ones fellow man. \"Every forward step of social progress brings men into closer relations with their fellows, and increases the importance of the pleasures and pains derived from sympathy.\n\nIn short, he describes a creation of morality.\n\nSince morality is what keeps the desire for selfishness in check, it is necessary to the propagation of society, with one requirement: the punishment of wrongdoers being necessary for the continuation of society, self-restraint must not be taken so far that wrongdoers may act unrestrained: Without the protection of society against them, \"The followers of the \"golden rule\" may indulge in hopes of heaven, but they must reckon with the certainty that other people will be masters of the earth.\"\n\nHuxley sums up this section of his argument against Social Darwinism:\nI have further shown cause for the belief that direct selection, after the fashion of the horticulturist and the breeder, neither has played, nor can play, any important part in the evolution of society; apart from other reasons, because I do not see how such selection could be practiced without a serious weakening, it may be the destruction, of the bonds which hold society together. It strikes me that men who are accustomed to contemplate the active or passive extirpation of the weak, the unfortunate, and the superfluous; who justify that conduct on the ground that it has the sanction of the cosmic process, and is the only way of ensuring the progress of the race; who, if they are consistent, must rank medicine among the black arts and count the physician a mischievous preserver of the unfit; on whose matrimonial undertakings the principles of the stud have the chief influence; whose whole lives, therefore, are an education in the noble art of suppressing natural affection and sympathy, are not likely to have any large stock of these commodities left. But, without them, there is no conscience, nor any restraint on the conduct of men, except the calculation of self-interest, the balancing of certain present gratifications against doubtful future pains; and experience tells us how much that is worth. Every day, we see firm believers in the hell of the theologians commit acts by which, as they believe when cool, they risk eternal punishment; while they hold back from those which are opposed to the sympathies of their associates.\nHuxley finishes with a series of short, further evidences against Social Darwinism, including:\n\n\nBefore Darwin's argument and presentation of the evidence for evolution, Western religions generally discounted or condemned any claims that diversity of life is the result of an evolutionary process, as did most scientists in the English scientific establishment. However, evolution was accepted by some religious groups such as the Unitarian church and the liberal Anglican theologians who went on to publish \"Essays and Reviews\". as well as by many scientists in France and Scotland and some in England, notably Robert Edmund Grant. Literal or authoritative interpretations of Scripture hold that a supreme being directly created humans and other animals as separate \"Created kinds\", which to some means species. This view is commonly referred to as creationism. From the 1920s to the present in the US, there has been a strong religious backlash to the teaching of evolution theory, particularly by conservative evangelicals. They have expressed concerns about the effects of the teaching of evolution on society and their faith (see Creation-evolution controversy).\n\nIn response to the wide scientific acceptance of the theory of evolution, many religions have formally or informally synthesized the scientific and religious viewpoints. Several important 20th century scientists (Fisher, Dobzhansky) whose work confirmed Darwin's theory, were also Christians who saw no incompatibility between their experimental and theoretical confirmations of evolution and their faith. Some religions have adopted a theistic evolution viewpoint, where God provides a divine spark that ignited the process of evolution and (or), where God has guided evolution in one way or another.\n\nThe Roman Catholic Church, beginning in 1950 with Pope Pius XII's encyclical Humani Generis, took up a neutral position with regard to evolution. \"The Church does not forbid that...research and discussions, on the part of men experienced in both fields, take place with regard to the doctrine of evolution, in as far as it inquires into the origin of the human body as coming from pre-existent and living matter.\"\n\nIn an October 22, 1996, address to the Pontifical Academy of Science, Pope John Paul II updated the Church's position, recognizing that Evolution is \"more than a hypothesis\" - \"In his encyclical Humani Generis, my predecessor Pius XII has already affirmed that there is no conflict between evolution and the doctrine of the faith regarding man and his vocation... Today, more than a half-century after the appearance of that encyclical, some new findings lead us toward the recognition of evolution as more than an hypothesis. In fact it is remarkable that this theory has had progressively greater influence on the spirit of researchers, following a series of discoveries in different scholarly disciplines.\"\n\nClassical figures have not discussed the subject as it has only come up in the 19th century. Contemporaries have come up with several distinct stances. One stance is that adaptation, or evolution on a micro scale, is accepted within a species, but cross-species evolution, that is evolution from one species into another species, is not as the human beginning is considered to be miraculous. However, this traditional thought would not conflict with the view that human-like beings could have been created around the same time as human beings, which, in this view, would explain the fossil records that look human but are not. Another stance is that since evolution is the simplest explanation it is the most reasonable to accept under the condition that it is not random but occurs only with the permission of God every step of the way. One particular argument that supports the idea that evolution is possible is the one stating that in that the stages of human development in evolution are akin to the distinct stages of development acknowledged in the Koran. The final stance completely rejects cross-species evolution across all organisms, but approves of adaptation (micro evolution).\n\nMany important political figures on the left have never publicized their views on biology, and so their opinions of evolutionary theory are unknown. To some extent, Marxists are the exception. Karl Marx, Friedrich Engels and Vladimir Lenin supported Darwin's evolutionary theory. Marx even sent Darwin a copy of his book \"Das Kapital\", though Darwin never wrote back to him. Karl Marx's work was based on a material view of the world that showed natural causes and effects for all aspects of human society and economy. He recognized that Darwin's work provided a similar material explanation for all of nature, thus supporting Marx's worldview.\n\nIn 1861 Karl Marx wrote to his friend Ferdinand Lassalle, \"Darwin’s work is most important and suits my purpose in that it provides a basis in natural science for the historical class struggle. ... Despite all shortcomings, it is here that, for the first time, 'teleology' in natural science is not only dealt a mortal blow but its rational meaning is empirically explained.\"\n\nMost later Marxists agreed with this view, but some – particularly those in the early Soviet Union – believed that evolutionary theory conflicted with their economic and social ideals. As a result, they came to support Lamarckism instead – the idea that an organism can pass on characteristics that it acquired during its lifetime to its offspring. This led to the practice of Lysenkoism, which caused agricultural problems.\n\nIn his book, \"\", anarcho-communist Peter Kropotkin argued that co-operation and mutual aid are as important in the evolution of the species as competition and mutual strife, if not more so.\n\nOn the contemporary moderate left, some authors such as Peter Singer (in his book, \"A Darwinian Left\") support Darwinism but reach different political and economic lessons than more conservative observers. Richard Dawkins' book, \"The Selfish Gene\", has a chapter, \"Nice guys finish first,\" that attempts to explain the role of altruism and cooperation in evolution and how social animals not only cannot survive without such traits, but how evolution will create them. Dawkins explains that when an animal sacrifices itself or uses its resources for the survival of other members of the same species, its genes, present on the other animals, survive. For example, if a mother dies to save three of its pups, one and a half copies (on average) of its genes will survive, because there is a 50% chance of a particular gene being present in its offspring. Dawkins also made a documentary of the same name. According to the documentary, Dawkins added that chapter as a way of overcoming modern day misinterpretations of the concept of \"survival of the fittest\".\n\n\"Social Darwinism\" is a derogatory term associated with the 19th century Malthusian theory developed by Whig philosopher Herbert Spencer. It is associated with evolutionary theory but now widely regarded as unwarranted. Social Darwinism was later expanded by others into ideas about \"survival of the fittest\" in commerce and human societies as a whole, and led to claims that social inequality, sexism, racism and imperialism were justified. However, these ideas contradict Darwin's own views, and contemporary scientists and philosophers consider these ideas to be neither mandated by evolutionary theory nor supported by data.\n\nSocial Darwinism is further linked with nationalism and imperialism. During the age of New Imperialism, the concepts of evolution justified the exploitation of \"lesser breeds without the law\" by \"superior races.\" To elitists, strong nations were composed of white people who were successful at expanding their empires, and as such, these strong nations would survive in the struggle for dominance. With this attitude, Europeans, except for Christian missionaries, seldom adopted the customs and languages of local people under their empires. Christian missionaries, on the other hand, were the very first individuals to meet new peoples and develop writing systems for local inhabitants' languages that lacked one. Being critics of Darwinism, they ardently opposed slavery and provided an education and religious instruction to the new peoples they interacted with since they felt that this was their duty as Christians.\n\n"}
{"id": "50665038", "url": "https://en.wikipedia.org/wiki?curid=50665038", "title": "Stop Faking It! (book series)", "text": "Stop Faking It! (book series)\n\nStop Faking It! - \"Finally Understanding Science So You Can Teach It\" is a series of books published by the National Science Teachers Association, written by William C. Robertson, and illustrated by Brian Diskin. The series, consisting of nine books, was written from 2002 to 2010.\n\n"}
{"id": "5976593", "url": "https://en.wikipedia.org/wiki?curid=5976593", "title": "The Day of the Dinosaur", "text": "The Day of the Dinosaur\n\nThe Day of the Dinosaur is a science book by L. Sprague de Camp and Catherine Crook de Camp, illustrated with plates. It was first published in hardcover by Doubleday in 1968, and in paperback by Curtis Books in 1970 or 1971. A second hardcover edition was issued by Bonanza Books in 1985. The first chapter was reprinted as \"One Day in the Cretaceous\" in the de Camps's collection \"Footprints on Sand\" (, 1981).\n\nAs stated on the dust cover of the Doubleday edition, the work is a survey of \"the exciting story of the lost world of the great reptiles and of the fossil hunters who discovered them millions of years later.\" It argues, among other things, that the theory of evolution took hold after Darwin because of interest spurred by recently popularized dinosaur remains, corresponding to legends of dragons.\n\n\n\"Publishers' Weekly\" called the book \"clear, comprehensive, [and] well-researched,\" noting that it \"begins as a vivid and scientifically sound depiction of the age of the giant dinosaurs [and] develops into an impressive tribute to the science of paleontology. Awesome and sometimes spine-chilling as some of the de Camps' descriptions are ... the human story of the first discovery of fossils and the realization of their implications communicates a drama of its own.\" Summing up, he noted that \"[r]eaders who are for the first time being introduced to the wonders of paleontology will be engrossed.\"\n\nMary L. Blackwell, writing in \"Library Journal\" called it \"an accurate and vivid description of the great creatures who roamed the earth more than 100 million years ago and also a fascinating account of the earth itself that makes the reality of its antiquity comprehensible.\" She felt the authors' \"carefully organized, practical approach\" resulted in \"a book that will appeal not only to students of paleontology but to everyone interested in this remote world.\" She rated it \"[r]ecommended for any public or school library.\"\n\nIn \"Natural History\" Isaac Asimov, noting that \"few people ... can speak more charmingly and enlightenedly about scientific subjects than L. Sprague de Camp,\" felt \"[t]he book reads ... like a pleasant and informal lecture, given at their ease, by a pair of enormously rational and urbane individuals\" with which he found it \"virtually impossible to find fault.\" He singled out the way the de Camps \"make the dinosaurs come alive by picturing them in action\" and the \"most remarkable first chapter ... which ... is an evocation (the best I know) of a typical day in the Mesozoic.\" He felt that \"[t]he book deals, satisfactorily, with the paleontologists and their discoveries, too, especially with the Cope-Marsh feud [and] with the effects on contemporary man of the great discoveries of paleontology; the impetus given to the search for giant living creatures--and to romancing about them--and the ferocious object lesson given on the subject of mass extinctions.\" He also notes that the de Camps point out \"[w]e are in the midst of [another] great dying now, ... brought on by man himself.\"\n\n\"The Booklist\" characterized the book as \"[a]n informative, comprehensible, often lively survey of the Age of Reptiles and the careers of some of the scientists who found and studied dinosaur fossils.\" \"Science Books\" rated it \"[a] very comprehensive book about Mesozoic reptiles, [with] [t]the text ... quite free of inaccuracies and... accompanied by many good illustrations,\" and \"[t]he writing style [as] fluctuat[ing] between ... humorous whimsy and scientific exposition, which may limit its popularity.\" It called \"[t]he section [on] the history of the early fossil hunters and development of the great natural history museums ... a real contribution, since this information is collected from many disparate sources.\"\n\nPhilip and Phylis Morrison, writing for \"Scientific American\", found it \"excellent and fresh, ... lively and intelligent,\" \"a savory mixture of biology and history, ... cover[ing] a wide range of lore and logic, from genetics and the problem of extinction to the scaling of beasts.\" \"Skeptical and yet imaginative,\" they wrote, \"the text lives up to the De Camp reputation.\" They found the book's \"final imaginary safari in the Jurassic ... logically planned: for the big flesh-eaters one had best carry a real elephant gun, the Continental .600 or perhaps the Holland & Holland double express .500.\"\n\nBruce Fleury, in a retrospective more than twenty years after the book's initial publication, noted that it \"precede[d] the 'dinosaur renaissance' but remain[ed a] valuable and readable introduction to the subject\" and \"[l]ike De Camp's many other popular works on scientific topics, ... well written and ... highly recommended.\"\n"}
{"id": "2044626", "url": "https://en.wikipedia.org/wiki?curid=2044626", "title": "The Future Is Wild", "text": "The Future Is Wild\n\nThe Future Is Wild is a British 2002 thirteen-part pseudo-documentary television miniseries. Based on research and interviews with several scientists, the miniseries shows how life could evolve in the future if humans were to disappear from the Earth altogether through extinction. The version broadcast on the Discovery Channel modified this premise, supposing instead that the human species had completely abandoned the Earth and had sent back probes to examine the progress of life on the planet as time progressed. The show styled itself after the format of a nature documentary. It is narrated by John de Lancie in the Discovery Channel version.\n\nThe miniseries was released with a companion book written by geologist Dougal Dixon, the author of several speculative evolution books, or \"anthropologies and zoologies of the future\" (such as \"\"), in conjunction with natural history television producer John Adams. For a time in 2005, a theme park based on this program was opened in Japan. In 2008 a special on the Discovery Channel about the development of the video game \"Spore\" was combined with airings of \"The Future Is Wild\".\n\nA documentary film version of the series was originally set to be picked up by Warner Bros., however, the series may be rebooted by production company Vanguard Animation and broadcasting at HBO.\n\nThe 2-part 2005 series \"Extraterrestrial\" (also known as \"Alien Worlds\") takes a similar scientific approach to the creation of speculative ecologies and the depiction of their inhabitants. As the title suggests, however, these are set on extrasolar planets with no connection to terrestrial evolution.\n\nTwelve ecosystems were presented, four in each of the three future periods.\n\nThe early episodes describe a world after an ice age, when giant sea-birds roam the beaches and carnivorous bats rule the skies. Ice sheets extend as far south as Paris in the northern hemisphere and as far north as Buenos Aires in the southern hemisphere. The Amazon rainforest has dried up and become grassland. The North American plains have become cold desert, and Africa has collided with Europe, enclosing the Mediterranean Sea. Without water to replace it in the dry climate, the Mediterranean has dried out into a salt flat dotted with brine lakes, as it has been in the past. Most of Europe is frozen tundra. The part of Africa east of the African Rift Valley has broken away from the rest of the continent. Asia has dried up and is now mountainous. The once warm, tropical area of Central America has been transformed into a dry area. Australia has moved north and collided with eastern Indonesia.\n\n\n\n\nIn the scenario for 100 million years in the future, the world is much hotter than at present. Octopuses and enormous tortoises have come on to the land, much of which is flooded by shallow seas surrounded by brackish swamps. Antarctica has drifted towards the tropics and is covered with dense rainforests, as it was before. Australia has collided with North America and Asia, forcing up an enormous, 12-kilometre-high mountain plateau much taller than the modern Himalayas. Greenland has been reduced to a small, temperate island. There are cold, deep ocean trenches. The Sahara has once again become the rich grassland it was millions of years ago\n\n\n\n\n\nThe hypothetical world of 200 million years from now is recovering from a mass extinction caused by a flood basalt eruption even larger than the one that created the Siberian Traps, wiping out 99% of the species on the planet. Fish have taken to the skies, squid to the forests, and the world's largest-ever desert is filled with strange worms and insects. All the continents have collided with one another and fused into a single supercontinent, a second Pangaea. (A few present-day geographical features can still be discerned, including Hudson Bay, Novaya Zemlya and the Scandinavian Peninsula, as well as the general outline of Africa.) One large global ocean with a single-current system gives rise to deadly hurricanes called hypercanes, which batter the coastlines of the continent all year long. The northwestern side of Pangaea II, drenched with an endless supply of rain, has become a temperate forest. Mountains resting at the end of the coast prevent most of the rain's moisture from reaching a long line of scrubby rainshadow deserts. The very center of the continent receives no rain at all and has become a barren, plantless desert. Only fish, arthropods, worms and mollusks were left to repopulate the Earth.\n\n\n\nEach episode generally focuses on just one food chain within a particular ecosystem.\n\n\"The Future is Wild\" is a £5-million co-production of the British Broadcasting Corporation (BBC), the Franco-German channel Arte, the German ZDF, the Austrian ORF, the Italian Mediaset, and Animal Planet and Discovery Channels Inc of the United States.\n\nThe BBC intended that the miniseries would repeat the success it had with its prehistoric documentary series \"Walking With Dinosaurs\", which attracted 17 million viewers in 1999. The program used computer-generated imagery to show the possible future of life on Earth. The 13-part series was produced in four years by independent producer John Adams, who conceived it in 1997.\n\nScientists involved in the project include the following:\n\n\"The Future is Wild\" doubled the previous ratings record for the Animal Planet channel when it was aired in the United States. The series was shown on BBC2 in late 2004.\n\nZDF Enterprises sold the television rights of the series to 18 markets: Belgium, Canada, Croatia, the Czech Republic, Ecuador, France, Germany, Hong Kong, Hungary, Japan, Korea, Mexico, the Middle East, Poland, Romania, Russia, Slovenia and Venezuela.\n\nThe series was released on three DVDs: episodes 1–5, episodes 6–9 and episodes 10–13. The three DVDs have also been released together as a set. Both the single DVDs and the three-DVD set are available for DVD regions one and two. Although the singles are available for region four, the three-DVD set is not. In addition to the complete edition, there is also an abridged region 2 3-disc version which condenses each of the three time periods into one 52-minute episode.\n\nAn educational CD-ROM entitled \"The Future Is Wild\" was produced by Sherston Software in 2006. It is designed to fit in with international school curricula for science, mathematics, geography and history.\n\nA book version was released in 2003, published by Firefly Books.\n\nIn 2008-2012 Futuroscope theme park in Poitiers, France contained an exhibit dedicated to the movie, its animals and habitats.\n\nSince 2016 Dinosaurier Park Teufelsschlucht in Ernzen has displayed multiple animals from the series. \n\n\n\n"}
{"id": "1077699", "url": "https://en.wikipedia.org/wiki?curid=1077699", "title": "The Mind of God", "text": "The Mind of God\n\nThe Mind of God is a 1992 non-fiction book by Paul Davies. Subtitled \"The Scientific Basis for a Rational World\", it is a whirlwind tour and explanation of theories, both physical and metaphysical, regarding ultimate causes. Its title comes from a quotation from Stephen Hawking: \"If we do discover a theory of everything...it would be the ultimate triumph of human reason—for then we would truly know the mind of God.\"\n\nIn the preface, Davies explains that he has been interested in ultimate causes since childhood, having annoyed his parents with unending \"why's\" about everything, with each answer demanding another \"why,\" and usually ending with the reply, \"Because God made it that way, and \"that's that!\"\" In the book proper, Davies briefly explores: the nature of reason, belief, and metaphysics; theories of the origin of the universe; the laws of nature; the relationship of mathematics to physics; a few arguments for the existence of God; the possibility that the universe shows evidence of a deity; and his opinion of the implications of Gödel's incompleteness theorem, that \"the search for a closed logical scheme that provides a complete and self-consistent explanation is doomed to failure.\"\n\nHe concludes with a statement of his belief that, even though we may never attain a theory of everything, \"the existence of mind in some organism on some planet in the universe is surely a fact of fundamental significance. Through conscious beings the universe has generated self-awareness. This can be no trivial detail, no minor byproduct of mindless, purposeless forces. We are truly meant to be here.\"\n\n\n"}
{"id": "4042480", "url": "https://en.wikipedia.org/wiki?curid=4042480", "title": "Things of Science", "text": "Things of Science\n\nThings of Science was an educational program launched by the nonprofit news syndicate Science Service in November 1940. The program consisted of a series of kits available by subscription and sent by mail monthly. The program continued until 1989. , there is no mention of the program or its archives on the website of the Society for Science & the Public, which succeeded the old Science Service organization.\n\nEach month, thousands of subscribers received a small blue box about the size of a videocasette containing some material such as nylon thread or dinosaur bones. The box contained a yellow booklet explaining the topic for that month, along with the pieces and supplies needed to cover the topic. Some kits would teach about a specific topic, such as coal, static electricity, mechanical linkages, nonwoven fabrics, electroplating, or optical illusions. Other kits would provide parts to build items such as a small spectrograph, telescope, or pinhole camera. In addition to the monthly subscription, some kits were available for individual purchase, such as a \"soilless gardening\" unit which provided seeds, plant food, and instructions in hydroponics. Some kits contained basic materials for simple experiments in psychology.\n\nThe modest annual subscription price ($5 in the 1960s) covered the cost of printing and postage. The instructions were written by Science Service staff, and the kit materials were donated by various companies.\n\nThe Things of Science Club was started by Watson Davis, editor-in-chief of Science Service, because editors served by the service often asked for samples of the things the syndicate wrote about. The initial focus of the program was newspaper editors, but it soon shifted to young people. By 1946 the Science Service estimated that half of its subscribers were school groups and science clubs, and the other half were individuals. Membership in the club was limited to a few thousand because some of the \"things\", such as dinosaur bones, were hard to come by.\n\n"}
{"id": "53256704", "url": "https://en.wikipedia.org/wiki?curid=53256704", "title": "Threatcasting", "text": "Threatcasting\n\nThreatcasting is a conceptual framework used to help multidisciplinary groups envision future scenarios. It is also a process that enables systematic planning against threats ten years in the future. Utilizing the threatcasting process, groups explore possible future threats and how to transform the future they desire into reality while avoiding undesired futures. Threatcasting is a continuous, multiple-step process with inputs from social science, technical research, cultural history, economics, trends, expert interviews, and science fiction storytelling. These inputs inform the exploration of potential visions of the future.\n\nOnce inputs are explored for impact and application, participants create a science fiction story (Science Fiction Prototyping) based ten years in the future to add context around human activity. Science Fiction Prototyping consists of a future story about a person in a place doing a thing. The threatcasting process results in creation of many potential futures scenarios - some futures are desirable while others are not. Identifying both types of futures (desirable and undesirable) will help the participant recognize which future to aim toward, and which to avoid. Utilizing the scenarios, participants plot actions necessary in the present and at various intervals working toward the ten year future scenario. These actions will help participants understand how to empower or disrupt the target future scenario. Flags (warning events) are also determined in order to map societal indicators onto the recommended path toward the targeted future. When identified flags appear in society, threatcasting participants map these back to the original forecast to see whether or not they are on track toward the target future scenario.\n\nThe notion of threatcasting can be traced back to Brian David Johnson, an applied futurist, who first began using threatcasting, also referred to as futurecasting, in 2011 and to George Hemingway of the Stratalis Group, who pioneered notion of futurecasting for corporate strategy and innovation industrial markets, including mining in the same year. Early adopters of threatcasting include the United States Air Force Academy, the Government of California, and the Army Cyber Institute at West Point Military Academy. Official use of the term threatcasting is attributed to Brian David Johnson in a 2014 Gazette article “Drones, smart hydrants considered by experts looking at future of firefighting.”\n\nThreatcasting is fundamentally different from traditional strategic planning and scenario building processes due to the identification of specific actions, indicators and concrete steps that can be taken today to disrupt, mitigate and recover from future threats.\n\nThe Army Cyber Institute at West Point in conjunction with Arizona State University's Global Securities Initiative and the School for the Future of Innovation in Society have established a Threatcasting Lab to host and manage a Cyber Threatcasting Project which looks to envision future cyber threats ten years in the future. The first session of this collaborative group was held at West Point, NY in August 2016.\n\n\n"}
{"id": "58208079", "url": "https://en.wikipedia.org/wiki?curid=58208079", "title": "Timeline of women in science", "text": "Timeline of women in science\n\nThis is a timeline of women in science, spanning from ancient history up to the 21st century. While the timeline primarily focuses on women involved with natural sciences such as astronomy, biology, chemistry and physics, it also includes women from the social sciences (e.g. sociology, psychology) and the formal sciences (e.g. mathematics, computer science), as well as notable science educators and medical scientists. The chronological events listed in the timeline relate to both scientific achievements and gender equality within the sciences.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
