{"id": "1076270", "url": "https://en.wikipedia.org/wiki?curid=1076270", "title": "AMPL", "text": "AMPL\n\nA Mathematical Programming Language (AMPL) is an algebraic modeling language to describe and solve high-complexity problems for large-scale mathematical computing (i.e., large-scale optimization and scheduling-type problems).\nIt was developed by Robert Fourer, David Gay, and Brian Kernighan at Bell Laboratories.\nAMPL supports dozens of solvers, both open source and commercial software, including CBC, CPLEX, FortMP, Gurobi, MINOS, IPOPT, SNOPT, KNITRO, and LGO. Problems are passed to solvers as nl files.\nAMPL is used by more than 100 corporate clients, and by government agencies and academic institutions.\n\nOne advantage of AMPL is the similarity of its syntax to the mathematical notation of optimization problems. This allows for a very concise and readable definition of problems in the domain of optimization. Many modern solvers available on the NEOS Server (formerly hosted at the Argonne National Laboratory, currently hosted at the University of Wisconsin, Madison) accept AMPL input. According to the NEOS statistics AMPL is the most popular format for representing mathematical programming problems.\n\nAMPL features a mix of declarative and imperative programming styles. Formulating optimization models occurs via declarative language elements such as sets, scalar and multidimensional parameters, decision variables, objectives and constraints, which allow for concise description of most problems in the domain of mathematical optimization.\n\nProcedures and control flow statements are available in AMPL for\n\nTo support re-use and simplify construction of large-scale optimization problems, AMPL allows separation of model and data.\n\nAMPL supports a wide range of problem types, among them:\n\nAMPL invokes a solver in a separate process which has these advantages:\nInteraction with the solver is done through a well-defined nl interface.\n\nAMPL is available for many popular 32- and 64-bit operating systems including Linux, Mac OS X, some Unix, and Windows.\nThe translator is proprietary software maintained by AMPL Optimization LLC. However, several online services exist, providing free modeling and solving facilities using AMPL. A free student version with limited functionality and a free full-featured version for academic courses are also available.\n\nAMPL can be used from within Microsoft Excel via the SolverStudio Excel add-in.\n\nThe AMPL Solver Library (ASL), which allows reading nl files and provides the automatic differentiation, is open-source. It is used in many solvers to implement AMPL connection.\n\nThis table present significant steps in AMPL history.\nA transportation problem from George Dantzig is used to provide a sample AMPL model. This problem finds the least cost shipping schedule that meets requirements at markets and supplies at factories.\n\nHere is a partial list of solvers supported by AMPL:\n\n\n"}
{"id": "36175304", "url": "https://en.wikipedia.org/wiki?curid=36175304", "title": "Actuarial Society of South Africa HIV/AIDS models", "text": "Actuarial Society of South Africa HIV/AIDS models\n\nThe Actuarial Society of South Africa HIV/AIDS models, also known as ASSA AIDS models, are a series of mathematical models developed to assist the actuarial profession and the Actuarial Society of South Africa in assessing and addressing the impact of the HIV and AIDS epidemic in South Africa. The models have been developed by the AIDS Committee of the Society and the Center for Actuarial Research (CARe) at the University of Cape Town in Cape Town, South Africa.\n\nIn 1996 the first and earliest version of ASSA AIDS model ASSA500 was developed by the AIDS Committee of the society, While the ASSA2008 model is the most recent version of ASSA AIDS and demographic model which was released in March 2011. The models have assisted insurers and those insured to have fair and balanced insurance policies in a country ravaged by AIDS.\n\nA joint task team of the South African National Department of Health and the Treasury used the ASSA model to estimate the impact of extending the life of AIDS patients.\n\nASSA is one of only two models used in South Africa; both are capable of making projections on the progression of the epidemic through an interaction of many factors. Four population risk groups are included, along with assumptions about sexual behaviour, rates of infection, conception rates, the median duration to mortality of those with HIV/AIDS, and the rates of transmission between mother and child. The impact of drug treatments at birth and while nursing, enhanced STD treatment, and risk avoidance is projected by a lower rate scenario The model makes provisions for migration of the population, separate modeling of racial groups, and separate modeling of provincial populations.\n\nA study by the South African National Department of Health and the Treasury used the ASSA model to project a positive result for the increased implementation of antiretroviral drugs (ARV) in the country, although their cost is a problem.\n\n\n"}
{"id": "351908", "url": "https://en.wikipedia.org/wiki?curid=351908", "title": "Almost surely", "text": "Almost surely\n\nIn probability theory, one says that an event happens almost surely (sometimes abbreviated as a.s.) if it happens with probability one. In other words, the set of possible exceptions may be non-empty, but it has probability zero. The concept is precisely the same as the concept of \"almost everywhere\" in measure theory.\n\nIn probability experiments on a finite sample space, there is often no difference between \"almost surely\" and \"surely\". However, the distinction becomes important when the sample space is an infinite set, because an infinite set can have non-empty subsets of probability zero.\n\nSome examples of the use of this concept include the strong and uniform versions of the law of large numbers, and the continuity of the paths of Brownian motion.\n\nThe terms almost certainly (a.c.) and almost always (a.a.) are also used. Almost never describes the opposite of \"almost surely\": an event that happens with probability zero happens \"almost never\".\n\nLet formula_1 be a probability space. An event formula_2 happens \"almost surely\" if formula_3. Equivalently, formula_4 happens almost surely if the probability of formula_4 not occurring is zero: formula_6. More generally, any event formula_7 (not necessarily in formula_8) happens almost surely if formula_9 is contained in a null set: a subset of some formula_10 such that The notion of almost sureness depends on the probability measure formula_11. If it is necessary to emphasize this dependence, it is customary to say that the event formula_4 occurs \"P\"-almost surely, or almost surely (\"P\").\n\nIn general, an event can happen \"almost surely\" even if the probability space in question includes outcomes which do not belong to the event, as is illustrated in the examples below.\n\nImagine throwing a dart at a unit square (i.e. a square with area 1) so that the dart always hits exactly one point of the square, and so that each point in the square is equally likely to be hit. \n\nNow, notice that since the square has area 1, the probability that the dart will hit any particular subregion of the square equals the area of that subregion. For example, the probability that the dart will hit the right half of the square is 0.5, since the right half has area 0.5.\n\nNext, consider the event that \"the dart hits a diagonal of the unit square exactly\". Since the areas of the diagonals of the square are zero, the probability that the dart lands exactly on a diagonal is zero. So, the dart will almost never land on a diagonal (i.e. it will almost surely \"not\" land on a diagonal). Nonetheless the set of points on the diagonals is not empty and a point on a diagonal is no less possible than any other point: the diagonal does contain valid outcomes of the experiment.\n\nConsider the case where a (possibly biased) coin is tossed, corresponding to the probability space formula_13, where the event formula_14 occurs if heads is flipped, and formula_15 if tails. For this particular coin, assume the probability of flipping heads is formula_16 from which it follows that the complement event, flipping tails, has formula_17.\n\nSuppose we were to conduct an experiment where the coin is tossed repeatedly, with outcomes formula_18, and it is assumed each flip's outcome is independent of all the others. That is, they are \"i.i.d.\". Define the sequence of random variables on the coin toss space, formula_19 where formula_20. \"i.e.\" each formula_21 records the outcome of the formula_22'th flip.\n\nAny infinite sequence of heads and tails is a possible outcome of the experiment. However, any particular infinite sequence of heads and tails has probability zero of being the exact outcome of the (infinite) experiment. To see why, note that the \"i.i.d.\" assumption implies that the probability of flipping all heads over formula_23 flips is simply formula_24. Letting formula_25 yields zero, since formula_26 by assumption. Note that the result is the same no matter how much we bias the coin towards heads, so long as we constrain formula_27 to be greater than 0, and less than 1.\n\nIn particular, the event \"the sequence contains at least one formula_28\" happens almost surely (i.e., with probability 1).\nHowever, if instead of an infinite number of flips we stop flipping after some finite time, say a million flips, then the all-heads sequence has non-zero probability. The all-heads sequence has probability formula_29, while the probability of getting at least one tails is formula_30 and the event is no longer almost sure.\n\nIn asymptotic analysis, one says that a property holds asymptotically almost surely (a.a.s.) if, over a sequence of sets, the probability converges to 1. For instance, a large number is asymptotically almost surely composite, by the prime number theorem; and in random graph theory, the statement \"formula_31 is connected\" (where formula_32 denotes the graphs on formula_23 vertices with edge probability formula_27) is true a.a.s. when, for any formula_35\n\nIn number theory this is referred to as \"almost all\", as in \"almost all numbers are composite\". Similarly, in graph theory, this is sometimes referred to as \"almost surely\".\n\n\n"}
{"id": "4416073", "url": "https://en.wikipedia.org/wiki?curid=4416073", "title": "Approximations of π", "text": "Approximations of π\n\nApproximations for the mathematical constant pi () in the history of mathematics reached an accuracy within 0.04% of the true value before the beginning of the Common Era (Archimedes). In Chinese mathematics, this was improved to approximations correct to what corresponds to about seven decimal digits by the 5th century.\n\nFurther progress was not made until the 15th century (Jamshīd al-Kāshī). Early modern mathematicians reached an accuracy of 35 digits by the beginning of the 17th century (Ludolph van Ceulen), and 126 digits by the 19th century (Jurij Vega), surpassing the accuracy required for any conceivable application outside of pure mathematics.\n\nThe record of manual approximation of is held by William Shanks, who calculated 527 digits correctly in the years preceding 1873. Since the middle of the 20th century, the approximation of has been the task of electronic digital computers; , the record is 22.4trillion digits. (For a comprehensive account, see Chronology of computation of.)\n\nThe best known approximations to dating to before the Common Era were accurate to two decimal places; this was improved upon in Chinese mathematics in particular by the mid-first millennium, to an accuracy of seven decimal places. After this, no further progress was made until the late medieval period.\n\nSome Egyptologists\nhave claimed that the ancient Egyptians used an approximation of as from as early as the Old Kingdom.\nThis claim has met with skepticism.\n\nBabylonian mathematics usually approximated to 3, sufficient for the architectural projects of the time (notably also reflected in the description of Solomon's Temple in the Hebrew Bible).\nThe Babylonians were aware that this was an approximation, and one Old Babylonian mathematical tablet excavated near Susa in 1936 (dated to between the 19th and 17th centuries BCE) gives a better approximation of as , about 0.5 percent below the exact value.\n\nAt about the same time, the Egyptian Rhind Mathematical Papyrus (dated to the Second Intermediate Period, c. 1600 BCE, although stated to be a copy of an older, Middle Kingdom text) implies an approximation of as ≈ 3.16 (accurate to 0.6 percent) by calculating the area of a circle by approximating the circle by an octagon.\n\nAstronomical calculations in the \"Shatapatha Brahmana\" (c. 6th century BCE) use a fractional approximation of .\n\nIn the 3rd century BCE, Archimedes proved the sharp inequalities  <  < , by means of regular 96-gons (accuracies of 2·10 and 4·10, respectively).\n\nIn the 2nd century CE, Ptolemy, used the value , the first known approximation accurate to three decimal places (accuracy 2·10).\n\nThe Chinese mathematician Liu Hui in 263 CE computed to between and by inscribing a 96-gon and 192-gon; the average of these two values is (accuracy 9·10).\nHe also suggested that 3.14 was a good enough approximation for practical purposes. He has also frequently been credited with a later and more accurate result (accuracy 2·10), although some scholars instead believe that this is due to the later (5th-century) Chinese mathematician Zu Chongzhi.\nZu Chongzhi is known to have computed between 3.1415926 and 3.1415927, which was correct to seven decimal places. He gave two other approximations of: and . The latter fraction is the best possible rational approximation of using fewer than five decimal digits in the numerator and denominator. Zu Chongzhi's result surpasses the accuracy reached in Hellenistic mathematics, and would remain without improvement for close to a millennium.\n\nIn Gupta-era India (6th century), mathematician Aryabhata in his astronomical treatise Āryabhaṭīya calculated the value of to five significant figures (). using it to calculate an approximation of the Earth's circumference. Aryabhata stated that his result \"approximately\" (\"\" \"approaching\") gave the circumference of a circle. His 15th-century commentator Nilakantha Somayaji (Kerala school of astronomy and mathematics) has argued that the word means not only that this is an approximation, but that the value is incommensurable (irrational).\n\nBy the 5th century CE, was known to about seven digits in Chinese mathematics, and to about five in Indian mathematics. Further progress was not made for nearly a millennium, until the 14th century, when Indian mathematician and astronomer Madhava of Sangamagrama, founder of the Kerala school of astronomy and mathematics, discovered the infinite series for , now known as the Madhava–Leibniz series, and gave two methods for computing the value of . One of these methods is to obtain a rapidly converging series by transforming the original infinite series of . By doing so, he obtained the infinite series\n\nand used the first 21 terms to compute an approximation of correct to 11 decimal places as .\n\nThe other method he used was to add a remainder term to the original series of . He used the remainder term\n\nin the infinite series expansion of to improve the approximation of to 13 decimal places of accuracy when  = 75.\n\nJamshīd al-Kāshī (Kāshānī), a Persian astronomer and mathematician, correctly computed 2 to 9 sexagesimal digits in 1424. This figure is equivalent to 17 decimal digits as\n\nwhich equates to\n\nHe achieved this level of accuracy by calculating the perimeter of a regular polygon with 3 × 2 sides.\n\nIn the second half of the 16th century, the French mathematician François Viète discovered an infinite product that converged on known as Viète's formula.\n\nThe German-Dutch mathematician Ludolph van Ceulen (\"circa\" 1600) computed the first 35 decimal places of with a 2-gon. He was so proud of this accomplishment that he had them inscribed on his tombstone.\n\nIn \"Cyclometricus\" (1621), Willebrord Snellius demonstrated that the perimeter of the inscribed polygon converges on the circumference twice as fast as does the perimeter of the corresponding circumscribed polygon. This was proved by Christiaan Huygens in 1654. Snellius was able to obtain seven digits of from a 96-sided polygon.\n\nIn 1789, the Slovene mathematician Jurij Vega calculated the first 140 decimal places for , of which the first 126 were correct and held the world record for 52 years until 1841, when William Rutherford calculated 208 decimal places, of which the first 152 were correct. Vega improved John Machin's formula from 1706 and his method is still mentioned today.\n\nThe magnitude of such precision (152 decimal places) can be put into context by the fact that the circumference of the largest known object, the observable universe, can be calculated from its diameter (93billion light-years) to a precision of less than one Planck length (at , the shortest unit of length that has real meaning) using expressed to just 62 decimal places.\n\nThe English amateur mathematician William Shanks, a man of independent means, spent over 20 years calculating to 707 decimal places. This was accomplished in 1873, with the first 527 places correct. He would calculate new digits all morning and would then spend all afternoon checking his morning's work. This was the longest expansion of until the advent of the electronic digital computer three-quarters of a century later.\n\nIn 1910, the Indian mathematician Srinivasa Ramanujan found several rapidly converging infinite series of , including\n\nwhich computes a further eight decimal places of with each term in the series. His series are now the basis for the fastest algorithms currently used to calculate . See also Ramanujan–Sato series.\n\nFrom the mid-20th century onwards, all calculations of have been done with the help of calculators or computers.\n\nIn 1944, D. F. Ferguson, with the aid of a mechanical desk calculator, found that William Shanks had made a mistake in the 528th decimal place, and that all succeeding digits were incorrect.\n\nIn the early years of the computer, an expansion of to decimal places was computed by Maryland mathematician Daniel Shanks (no relation to the above-mentioned William Shanks) and his team at the United States Naval Research Laboratory in Washington, D.C. In 1961, Shanks and his team used two different power series for calculating the digits of . For one, it was known that any error would produce a value slightly high, and for the other, it was known that any error would produce a value slightly low. And hence, as long as the two series produced the same digits, there was a very high confidence that they were correct. The first 100,265 digits of were published in 1962. The authors outlined what would be needed to calculate to 1 million decimal places and concluded that the task was beyond that day's technology, but would be possible in five to seven years.\n\nIn 1989, the Chudnovsky brothers computed to over 1 billion decimal places on the supercomputer IBM 3090 using the following variation of Ramanujan's infinite series of :\n\nIn 1999, Yasumasa Kanada and his team at the University of Tokyo computed to over 200 billion decimal places on the supercomputer HITACHI SR8000/MPP (128 nodes) using another variation of Ramanujan's infinite series of . In October 2005, they claimed to have calculated it to 1.24 trillion places.\n\nRecords since then have all been accomplished on personal computers using the Chudnovsky algorithm. In 2009, Fabrice Bellard computed just under 2.7 trillion digits, and from 2010 onward, all records have been set using Alexander Yee's y-cruncher software. , the record stands at 22,459,157,718,361 ( × 10) digits. The limitation on further expansion is primarily storage space for the computation.\n\nIn November 2002, Yasumasa Kanada and a team of 9 others used the Hitachi SR8000, a 64-node supercomputer with 1 terabyte of main memory, to calculate to roughly 1.24 trillion digits in around 600 hours.\n\nIn August 2009, a Japanese supercomputer called the T2K Open Supercomputer more than doubled the previous record by calculating to roughly 2.6 trillion digits in approximately 73 hours and 36 minutes.\n\nIn December 2009, Fabrice Bellard used a home computer to compute 2.7 trillion decimal digits of . Calculations were performed in base 2 (binary), then the result was converted to base 10 (decimal). The calculation, conversion, and verification steps took a total of 131 days.\n\nIn August 2010, Shigeru Kondo used Alexander Yee's y-cruncher to calculate 5 trillion digits of . This was the world record for any type of calculation, but significantly it was performed on a home computer built by Kondo. The calculation was done between 4 May and 3 August, with the primary and secondary verifications taking 64 and 66 hours respectively.\n\nIn October 2011, Shigeru Kondo broke his own record by computing ten trillion (10) and fifty digits using the same method but with better hardware.\n\nIn December 2013, Kondo broke his own record for a second time when he computed 12.1 trillion digits of .\n\nIn October 2014, Sandon Van Ness, going by the pseudonym \"houkouonchi\" used y-cruncher to calculate 13.3 trillion digits of .\n\nIn November 2016, Peter Trueb and his sponsors computed on y-cruncher and fully verified 22.4 trillion digits of . The computation took (with three interruptions) 105 days to complete.\n\nDepending on the purpose of a calculation, can be approximated by using fractions for ease of calculation. The most notable such approximations are (relative error of about 4·10) and (relative error of about 8·10).\n\nOf some notability are legal or historical texts purportedly \"defining \" to have some rational value, such as the \"Indiana Pi Bill\" of 1897, which stated \"the ratio of the diameter and circumference is as five-fourths to four\" (which would imply \"\") and a passage in the Hebrew Bible that implies that .\n\nThe so-called \"Indiana Pi Bill\" of 1897 has often been characterized as an attempt to \"legislate the value of Pi\". Rather, the bill dealt with a purported solution to the problem of geometrically \"squaring the circle\".\n\nThe bill was nearly passed by the Indiana General Assembly in the U.S., and has been claimed to imply a number of different values for , although the closest it comes to explicitly asserting one is the wording \"the ratio of the diameter and circumference is as five-fourths to four\", which would make , a discrepancy of nearly 2 percent. A mathematics professor who happened to be present the day the bill was brought up for consideration in the Senate, after it had passed in the House, helped to stop the passage of the bill on its second reading, after which the assembly thoroughly ridiculed it before tabling it indefinitely.\n\nIt is sometimes claimed that the Hebrew Bible implies that \" equals three\", based on a passage in and giving measurements for the round basin located in front of the Temple in Jerusalem as having a diameter of 10 cubits and a circumference of 30 cubits.\n\nThe issue is discussed in the Talmud and in Rabbinic literature. Among the many explanations and comments are these:\n\nThere is still some debate on this passage in biblical scholarship. Many reconstructions of the basin show a wider brim (or flared lip) extending outward from the bowl itself by several inches to match the description given in In the succeeding verses, the rim is described as \"a handbreadth thick; and the brim thereof was wrought like the brim of a cup, like the flower of a lily: it received and held three thousand baths\" , which suggests a shape that can be encompassed with a string shorter than the total length of the brim, e.g., a Lilium flower or a Teacup.\n\nArchimedes, in his \"Measurement of a Circle\", created the first algorithm for the calculation of based on the idea that the perimeter of any (convex) polygon inscribed in a circle is less than the circumference of the circle, which, in turn, is less than the perimeter of any circumscribed polygon. He started with inscribed and circumscribed regular hexagons, whose perimeters are readily determined. He then shows how to calculate the perimeters of regular polygons of twice as many sides that are inscribed and circumscribed about the same circle. This is a recursive procedure which would be described today as follows: Let and denote the perimeters of regular polygons of sides that are inscribed and circumscribed about the same circle, respectively. Then,\nArchimedes uses this to successively compute and . Using these last values he obtains\nIt is not known why Archimedes stopped at a 96-sided polygon; it only takes patience to extend the computations. Heron reports in his \"Metrica\" (about 60 CE) that Archimedes continued the computation in a now lost book, but then attributes an incorrect value to him.\n\nArchimedes uses no trigonometry in this computation and the difficulty in applying the method lies in obtaining good approximations for the square roots that are involved. Trigonometry, in the form of a table of chord lengths in a circle, was probably used by Claudius Ptolemy of Alexandria to obtain the value of given in the \"Almagest\" (circa 150 CE).\n\nAdvances in the approximation of (when the methods are known) were made by increasing the number of sides of the polygons used in the computation. A trigonometric improvement by Willebrord Snell (1621) obtains better bounds from a pair of bounds gotten from the polygon method. Thus, more accurate results were obtained from polygons with fewer sides. Viète's formula, published by François Viète in 1593, was derived by Viète using a closely related polygonal method, but with areas rather than perimeters of polygons whose numbers of sides are powers of two.\n\nThe last major attempt to compute by this method was carried out by Grienberger in 1630 who calculated 39 decimal places of using Snell's refinement.\n\nFor fast calculations, one may use formulae such as Machin's:\ntogether with the Taylor series expansion of the function arctan(\"x\"). This formula is most easily verified using polar coordinates of complex numbers, producing:\n\nformula_10\n\nFormulae of this kind are known as \"Machin-like formulae\". Machin's particular formula was used well into the computer era for calculating record numbers of digits of , but more recently other similar formulae have been used as well.\n\nFor instance, Shanks and his team used the following Machin-like formula in 1961 to compute the first 100,000 digits of :\n\nformula_11\n\nand they used another Machin-like formula,\n\nformula_12\n\nas a check.\n\nThe record as of December 2002 by Yasumasa Kanada of Tokyo University stood at 1,241,100,000,000 digits. The following Machin-like formulae were used for this:\nK. Takano (1982).\nF. C. W. Störmer (1896).\n\nOther formulae that have been used to compute estimates of include:\n\nLiu Hui (see also Viète's formula):\n\nMadhava:\n\nEuler:\n\nNewton / Euler Convergence Transformation:\nwhere (2k+1)!! denotes the product of the odd integers up to 2k+1.\n\nRamanujan:\n\nDavid Chudnovsky and Gregory Chudnovsky:\n\nRamanujan's work is the basis for the Chudnovsky algorithm, the fastest algorithms used, as of the turn of the millennium, to calculate .\n\nExtremely long decimal expansions of are typically computed with iterative formulae like the Gauss–Legendre algorithm and Borwein's algorithm. The latter, found in 1985 by Jonathan and Peter Borwein, converges extremely quickly:\n\nFor formula_21 and\nwhere formula_23, the sequence formula_24 converges quartically to , giving about 100 digits in three steps and over a trillion digits after 20 steps. However, it is known that using an algorithm such as the Chudnovsky algorithm (which converges linearly) is faster than these iterative formulae.\n\nThe first one million digits of and are available from Project Gutenberg (see external links below). A former calculation record (December 2002) by Yasumasa Kanada of Tokyo University stood at 1.24 trillion digits, which were computed in September 2002 on a 64-node Hitachi supercomputer with 1 terabyte of main memory, which carries out 2 trillion operations per second, nearly twice as many as the computer used for the previous record (206 billion digits). The following Machin-like formulæ were used for this:\n\nThese approximations have so many digits that they are no longer of any practical use, except for testing new supercomputers. Properties like the potential normality of will always depend on the infinite string of digits on the end, not on any finite computation.\n\nHistorically, base 60 was used for calculations. In this base, can be approximated to eight (decimal) significant figures with the number 3:8:29:44, which is\n\nIn addition, the following expressions can be used to estimate :\n\nPi can be obtained from a circle if its radius and area are known using the relationship:\n\nIf a circle with radius ' is drawn with its center at the point (0, 0), any point whose distance from the origin is less than ' will fall inside the circle. The Pythagorean theorem gives the distance from any point (, ) to the center:\n\nMathematical \"graph paper\" is formed by imagining a 1×1 square centered around each cell (, ), where and are integers between − and . Squares whose center resides inside or exactly on the border of the circle can then be counted by testing whether, for each cell (, ),\n\nThe total number of cells satisfying that condition thus approximates the area of the circle, which then can be used to calculate an approximation of . Closer approximations can be produced by using larger values of .\n\nMathematically, this formula can be written:\n\nIn other words, begin by choosing a value for . Consider all cells (, ) in which both and are integers between − and . Starting at 0, add 1 for each cell whose distance to the origin (0,0) is less than or equal to \"\". When finished, divide the sum, representing the area of a circle of radius , by to find the approximation of .\nFor example, if is 5, then the cells considered are:\n\nThe 12 cells (0, ±5), (±5, 0), (±3, ±4), (±4, ±3) are \"exactly on\" the circle, and 69 cells are \"completely inside\", so the approximate area is 81, and is calculated to be approximately 3.24 because 81 / 5 = 3.24. Results for some values of are shown in the table below:\n\nFor related results see The circle problem: number of points (x,y) in square lattice with x^2 + y^2 <= n.\n\nSimilarly, the more complex approximations of given below involve repeated calculations of some sort, yielding closer and closer approximations with increasing numbers of calculations.\n\nBesides its simple continued fraction representation [3; 7, 15, 1, 292, 1, 1...], which displays no discernible pattern, has many generalized continued fraction representations generated by a simple rule, including these two.\n\nThe Gregory–Leibniz series\nis the power series for arctan(x) specialized to  = 1. It converges too slowly to be of practical interest. However, the power series converges much faster for smaller values of formula_57, which leads to formulae where formula_58 arises as the sum of small angles with rational tangents, known as Machin-like formulae.\n\nKnowing that 4 arctan 1 = , the formula can be simplified to get:\n\nwith a convergence such that each additional 10 terms yields at least three more digits.\n\nObserving an equilateral triangle and noting that\nyields\nwith a convergence such that each additional five terms yields at least three more digits.\n\nThe Gauss–Legendre algorithm or Salamin–Brent algorithm was discovered independently by Richard Brent and Eugene Salamin in 1975. This can compute formula_58 to formula_63 digits in time proportional to formula_64, much faster than the trigonometric formulae.\n\nThe Bailey–Borwein–Plouffe formula (BBP) for calculating was discovered in 1995 by Simon Plouffe. Using math, the formula can compute any particular digit of —returning the hexadecimal value of the digit—without having to compute the intervening digits (digit extraction).\nIn 1996, Simon Plouffe derived an algorithm to extract the th decimal digit of (using base10 math to extract a base10 digit), and which can do so with an improved speed of time. The algorithm requires virtually no memory for the storage of an array or matrix so the one-millionth digit of can be computed using a pocket calculator. However, it would be quite tedious and impractical to do so.\nThe calculation speed of Plouffe's formula was improved to by Fabrice Bellard, who derived an alternative formula (albeit only in base2 math) for computing .\n\nMany other expressions for were developed and published by Indian mathematician Srinivasa Ramanujan. He worked with mathematician Godfrey Harold Hardy in England for a number of years.\n\nExtremely long decimal expansions of are typically computed with the Gauss–Legendre algorithm and Borwein's algorithm; the Salamin–Brent algorithm, which was invented in 1976, has also been used.\n\nIn 1997, David H. Bailey, Peter Borwein and Simon Plouffe published a paper (Bailey, 1997) on a new formula for as an infinite series:\n\nThis formula permits one to fairly readily compute the \"k\"th binary or hexadecimal digit of , without having to compute the preceding \"k\" − 1 digits. Bailey's website contains the derivation as well as implementations in various programming languages. The PiHex project computed 64 bits around the quadrillionth bit of (which turns out to be 0).\n\nFabrice Bellard further improved on BBP with his formula:\n\nOther formulae that have been used to compute estimates of include:\nThis converges extraordinarily rapidly. Ramanujan's work is the basis for the fastest algorithms used, as of the turn of the millennium, to calculate .\n\nPi Hex was a project to compute three specific binary digits of using a distributed network of several hundred computers. In 2000, after two years, the project finished computing the five trillionth (5*10), the forty trillionth, and the quadrillionth (10) bits. All three of them turned out to be 0.\n\nOver the years, several programs have been written for calculating to many digits on personal computers.\n\nMost computer algebra systems can calculate and other common mathematical constants to any desired precision.\n\nFunctions for calculating are also included in many general libraries for arbitrary-precision arithmetic, for instance Class Library for Numbers and MPFR.\n\nPrograms designed for calculating may have better performance than general-purpose mathematical software. They typically implement checkpointing and efficient disk swapping to facilitate extremely long-running and memory-expensive computations.\n\n"}
{"id": "40276", "url": "https://en.wikipedia.org/wiki?curid=40276", "title": "Blackboard bold", "text": "Blackboard bold\n\nBlackboard bold is a typeface style that is often used for certain symbols in mathematical texts, in which certain lines of the symbol (usually vertical or near-vertical lines) are doubled. The symbols usually denote number sets. One way of producing blackboard bold is to double-strike a character with a small offset on a typewriter. Thus they are also referred to as double struck.\n\nIn typography, such a font with characters that are not solid is called an \"inline\", \"shaded\" or \"tooled\" font.\n\nIn some texts these symbols are simply shown in bold type. Blackboard bold in fact originated from the attempt to write bold letters on blackboards in a way that clearly differentiated them from non-bold letters i.e. by using the edge rather than point of the chalk. It then made its way back into print form as a separate style from ordinary bold, possibly starting with the original 1965 edition of Gunning and Rossi's textbook on complex analysis.\n\nSome mathematicians do not recognize blackboard bold as a separate style from bold. Jean-Pierre Serre uses double-struck letters when writing bold on the blackboard, whereas his published works consistently use ordinary bold for the same symbols. Donald Knuth also prefers boldface to blackboard bold, and consequently did not include blackboard bold in the Computer Modern fonts he created for the TeX mathematical typesetting system.\n\nThe \"Chicago Manual of Style\" in 1993 (14th edition) advises: \"blackboard bold should be confined to the classroom\" (13.14) whereas in 2003 (15th edition) it states that \"open-faced (blackboard) symbols are reserved for familiar systems of numbers\" (14.12).\n\nTeX, the standard typesetting system for mathematical texts, does not contain direct support for blackboard bold symbols, but the add-on AMS Fonts package (codice_1) by the American Mathematical Society provides this facility; a blackboard bold R is written as codice_2. The codice_3 package loads codice_1.\n\nIn Unicode, a few of the more common blackboard bold characters (C, H, N, P, Q, R and Z) are encoded in the Basic Multilingual Plane (BMP) in the \"Letterlike Symbols (2100–214F)\" area, named DOUBLE-STRUCK CAPITAL C etc. The rest, however, are encoded outside the BMP, from codice_5 to codice_6 (uppercase, excluding those encoded in the BMP), codice_7 to codice_8 (lowercase) and codice_9 to codice_10 (digits). Being outside the BMP, these are relatively new and not widely supported.\n\nThe following table shows all available Unicode blackboard bold characters.\n\nThe symbols are nearly universal in their interpretation, unlike their normally-typeset counterparts, which are used for many different purposes.\n\nThe first column shows the letter as typically rendered by the ubiquitous LaTeX markup system. The second column shows the Unicode code point. The third column shows the symbol itself (which will only display correctly on browsers that support Unicode and have access to a suitable font). The fourth column describes known typical (but not universal) usage in mathematical texts.\n\nIn addition, a blackboard-bold Greek letter mu (not found in Unicode) is sometimes used by number theorists and algebraic geometers (with a subscript \"n\") to designate the group (or more specifically group scheme) of \"n\"-th roots of unity.\n\n\n"}
{"id": "58559351", "url": "https://en.wikipedia.org/wiki?curid=58559351", "title": "Brown measure", "text": "Brown measure\n\nIn mathematics, the Brown measure of an operator in a finite factor is a probability measure on the complex plane which may be viewed as an analog of the spectral counting measure (based on algebraic multiplicity) of matrices. \n\nLet formula_1 be a finite factor with the canonical normalized trace formula_2. For every operator formula_3, the function\n\nis subharmonic and its Laplacian in the distributional sense is a probability measure on formula_5 which is called the Brown measure of formula_6.\n\n"}
{"id": "23335649", "url": "https://en.wikipedia.org/wiki?curid=23335649", "title": "Canonical map", "text": "Canonical map\n\nIn mathematics, a canonical map, also called a natural map, is a map or morphism between objects that arises naturally from the definition or the construction of the objects being mapped against each other. In general it is the map which preserves the widest amount of structure, and it tends to be unique. In the rare cases where latitude in choice remains, the map is either conventionally agreed upon to be the most useful for further analysis, or sometimes simply the most elegant or beautiful known.\n\nA closely related notion is a structure map or structure morphism; the map that comes with the given structure on the object. They are also sometimes called canonical maps.\n\nA canonical isomorphism is a canonical map that is also an isomorphism (i.e., invertible).\n\nIn some contexts, it is necessary to address an issue of \"choices\" of canonical maps or canonical isomorphisms; see prestack for a typical example.\n\n"}
{"id": "26193465", "url": "https://en.wikipedia.org/wiki?curid=26193465", "title": "Comparison of vector algebra and geometric algebra", "text": "Comparison of vector algebra and geometric algebra\n\nVector algebra and geometric algebra are complementary approaches to providing additional algebraic structures on vector spaces, with geometric interpretations, particularly vector fields in multivariable calculus and applications in mathematical physics.\n\nVector algebra is specific to Euclidean 3-space, while geometric algebra uses multilinear algebra and applies in all dimensions and signatures, notably 3+1 spacetime as well as 2 dimensions. They are mathematically equivalent in 3 dimensions, where this article is focused, though the approaches differ. Vector algebra is more widely used in elementary multivariable calculus, while geometric algebra is used in more advanced treatments, and is proposed for elementary use as well.\n\nGeometric algebra (GA) is an extension or completion of vector algebra (VA). The reader is herein assumed to be familiar with the basic concepts and operations of VA and this article will mainly concern itself with operations in formula_1 the GA of 3D space (nor is this article intended to be mathematically rigorous). In GA, vectors are not normally written boldface as the meaning is usually clear from the context.\n\nThe fundamental difference is that GA provides an additional product of vectors called the \"geometric product\". Elements of GA are graded multivectors, scalars are grade 0, the usual vectors are grade 1, bivectors are grade 2 and the highest grade (3 in the 3D case) is traditionally called the pseudoscalar and designated formula_2.\n\nThe ungeneralized 3D vector form of the geometric product is :\n\nthat is the sum of the usual dot (inner) product and the outer (exterior) product (this last is closely related to the cross product and will be explained below).\n\nIn VA, entities such as pseudovectors and pseudoscalars need to be bolted on, whereas in GA the equivalent bivector and pseudovector respectively exist naturally as subspaces of the algebra.\n\nFor example, applying vector calculus in 2 dimensions, such as to compute torque or curl, requires adding an artificial 3rd dimension and extending the vector field to be constant in that dimension, or alternately considering these to be scalars. The torque or curl is then a normal vector field in this 3rd dimension. By contrast, geometric algebra in 2 dimensions defines these as a pseudoscalar field (a bivector), without requiring a 3rd dimension. Similarly, the scalar triple product is ad hoc, and can instead be expressed uniformly using the exterior product and the geometric product.\n\nHere are some comparisons between standard formula_4 vector relations and their corresponding exterior product and geometric product equivalents. All the exterior and geometric product equivalents here are good for more than three dimensions, and some also for two. In two dimensions the cross product is undefined even if what it describes (like torque) is perfectly well defined in a plane without introducing an arbitrary normal vector outside of the space.\n\nMany of these relationships only require the introduction of the exterior product to generalize, but since that may not be familiar to somebody with only a background in vector algebra and calculus, some examples are given.\n\nformula_5 is perpendicular to the plane containing formula_6 and formula_7.\nformula_8 is an oriented representation of the same plane.\n\nWe have the pseudoscalar formula_9 (right handed orthonormal frame) and so\n\nThis yields a convenient definition for the cross product of traditional vector algebra:\n\n(this is antisymmetric). Relevant is the distinction between axial and polar vectors in vector algebra, which is natural in geometric algebra as the distinction between vectors and bivectors (elements of grade two).\n\nThe formula_14 here is a unit pseudoscalar of Euclidean 3-space, which establishes a duality between the vectors and the bivectors, and is named so because of the expected property\n\nThe equivalence of the formula_16 cross product and the exterior product expression above can be confirmed by direct multiplication of formula_17 with a determinant expansion of the exterior product\n\nSee also Cross product as an exterior product. Essentially, the geometric product of a bivector and the pseudoscalar of Euclidean 3-space provides a method of calculation of the Hodge dual.\n\nOrdinarily:\n\nMaking use of the geometric product and the fact that the exterior product of a vector wedge with itself is zero:\n\nIn three dimensions the product of two vector lengths can be expressed in terms of the dot and cross products\n\nThe corresponding generalization expressed using the geometric product is\n\nThis follows from expanding the geometric product of a pair of vectors with its reverse\n\nLinear algebra texts will often use the determinant for the solution of linear systems by Cramer's rule or for and matrix inversion.\n\nAn alternative treatment is to axiomatically introduce the wedge product, and then demonstrate that this can be used directly to solve linear systems. This is shown below, and does not require sophisticated math skills to understand.\n\nIt is then possible to define determinants as nothing more than the coefficients of the wedge product in terms of \"unit \"k\"-vectors\" (formula_26 terms) expansions as above.\n\nWhen linear system solution is introduced via the wedge product, Cramer's rule follows as a side-effect, and there is no need to lead up to the end results with definitions of minors, matrices, matrix invertibility, adjoints, cofactors, Laplace expansions, theorems on determinant multiplication and row column exchanges, and so forth.\n\nMatrix inversion (Cramer's rule) and determinants can be naturally expressed in terms of the wedge product.\n\nThe use of the wedge product in the solution of linear equations can be quite useful for various geometric product calculations.\n\nTraditionally, instead of using the wedge product, Cramer's rule is usually presented as a generic algorithm that can be used to solve linear equations of the form formula_33 (or equivalently to invert a matrix). Namely\n\nThis is a useful theoretic result. For numerical problems row reduction with pivots and other methods are more stable and efficient.\n\nWhen the wedge product is coupled with the Clifford product and put into a natural geometric context, the fact that the determinants are used in the expression of formula_35 parallelogram area and parallelepiped volumes (and higher-dimensional generalizations thereof) also comes as a nice side-effect.\n\nAs is also shown below, results such as Cramer's rule also follow directly from the wedge product's selection of non-identical elements. The end result is then simple enough that it could be derived easily if required instead of having to remember or look up a rule.\n\nTwo variables example\n\nPre- and post-multiplying by formula_37 and formula_38,\n\nProvided formula_41 the solution is\n\nFor formula_43, this is Cramer's rule since the formula_44 factors of the wedge products\n\ndivide out.\n\nSimilarly, for three, or \"N\" variables, the same ideas hold\n\nAgain, for the three variable three equation case this is Cramer's rule since the formula_48 factors of all the wedge products divide out, leaving the familiar determinants.\n\nA numeric example with three equations and two unknowns:\nIn case there are more equations than variables and the equations have a solution, then each of the k-vector quotients will be scalars.\n\nTo illustrate here is the solution of a simple example with three equations and two unknowns.\n\nThe right wedge product with formula_50 solves for formula_51\n\nand a left wedge product with formula_53 solves for formula_54\n\nObserve that both of these equations have the same factor, so\none can compute this only once (if this was zero it would\nindicate the system of equations has no solution).\n\nCollection of results for\nformula_51 and formula_54 yields a Cramer's rule-like form:\n\nWriting formula_59, we have the end result:\n\nFor the plane of all points formula_61 through the plane passing through three independent points formula_62, formula_63, and formula_64, the normal form of the equation is\n\nThe equivalent wedge product equation is\n\nUsing the Gram–Schmidt process a single vector can be decomposed into two components with respect to a reference vector, namely the projection onto a unit vector in a reference direction, and the difference between the vector and that projection.\n\nWith, formula_67, the projection of formula_68 onto formula_69 is\n\nOrthogonal to that vector is the difference, designated the rejection,\n\nNote the similarity in form to the \"w\", \"u\", \"v\" trivector itself\n\nwhich, if you take the set of formula_73 as a basis for the trivector space, suggests this is the natural way to define the length of a trivector. Loosely speaking the length of a vector is a length, length of a bivector is area, and the length of a trivector is volume.\n\nIf a vector is factored directly into projective and rejective terms using the geometric product formula_74, then it is not necessarily obvious that the rejection term, a product of vector and bivector is even a vector. Expansion of the vector bivector product in terms of the standard basis vectors has the following form\n\nThe trivector term is formula_76. Expansion of formula_77 yields the same trivector term (it is the completely symmetric part), and the vector term is negated. Like the geometric product of two vectors, this geometric product can be grouped into symmetric and antisymmetric parts, one of which is a pure k-vector. In analogy the antisymmetric part of this product can be called a generalized dot product, and is roughly speaking the dot product of a \"plane\" (bivector), and a vector.\n\nThe properties of this generalized dot product remain to be explored, but first here is a summary of the notation\n\nLet formula_82, where formula_83, and formula_84. Expressing formula_85 and the formula_86, products in terms of these components is\n\nWith the conditions and definitions above, and some manipulation, it can be shown that the term formula_88, which then justifies the previous solution of the normal to a plane problem. Since the vector term of the vector bivector product the name dot product is zero\nwhen the vector is perpendicular to the plane (bivector), and this vector, bivector \"dot product\" selects only the components that are in the plane, so in analogy to the vector-vector dot product this name itself is justified by more than the fact this is the non-wedge product term of the geometric vector-bivector product.\n\nIt can be shown that a unit vector derivative can be expressed using the cross product\n\n\\frac{d}{dt}\\left(\\frac{\\mathbf r}{\\Vert \\mathbf r \\Vert}\\right)\n"}
{"id": "46414426", "url": "https://en.wikipedia.org/wiki?curid=46414426", "title": "Continuous q-Legendre polynomials", "text": "Continuous q-Legendre polynomials\n\nIn mathematics, the continuous \"q\"-Legendre polynomials are a family of basic hypergeometric orthogonal polynomials in the basic Askey scheme. give a detailed list of their properties.\n"}
{"id": "13505846", "url": "https://en.wikipedia.org/wiki?curid=13505846", "title": "European Congress of Mathematics", "text": "European Congress of Mathematics\n\nThe European Congress of Mathematics (ECM) is an international congress of the mathematics community, held every four years. Its objectives are \"to present various new aspects of pure and applied mathematics to a wide audience, to be a forum for discussion of the relationship between mathematics and society in Europe, and to enhance cooperation among mathematicians from all European countries.\"\n\nThe Congress is held under the auspices of the European Mathematical Society (EMS), and was one of its earliest initiatives. The EMS Prizes are awarded at the beginning of the Congress.\n\n\nThe 8th European Congress of Mathematics will be held in Slovenia in 2020.\n\n"}
{"id": "46593443", "url": "https://en.wikipedia.org/wiki?curid=46593443", "title": "Field, power, and root-power quantities", "text": "Field, power, and root-power quantities\n\nA power quantity is a power or a quantity directly proportional to power, e.g., energy density, acoustic intensity, and luminous intensity. Energy quantities may also be labelled as power quantities in this context.\n\nA root-power quantity is a quantity such as voltage, current, sound pressure, electric field strength, speed, or charge density, the square of which, in linear systems, is proportional to power. The term \"root-power quantity\" was introduced in the ; it replaces and deprecates the term field quantity.\n\nIt is essential to know which category a measurement belongs to when using decibels (dB) for comparing the levels of such quantities. A change of one bel in the level corresponds to a 10× change in \"power\", so when comparing power quantities \"x\" and \"y\", the difference is defined to be 10×log(\"y\"/\"x\") decibel. With root-power quantities, however the difference is defined as 20×log(\"y\"/\"x\") dB. In linear systems, these definitions allow the distinction between root-power quantities and power quantities to be ignored when specifying changes as levels: an amplifier can be described as having \"3 dB\" of gain without needing to specify whether voltage or power are being compared; for a given linear load (e.g. an speaker), such an increase will result in a 3 dB increase in both the sound pressure level and the sound power level at a given location near the speaker. Conversely, when ratios cannot be identified as either power or root-power quantities, the units neper (Np) and decibel (dB) cannot be sensibly used.\n\nIn the analysis of signals and systems using sinusoids, field quantities and root-power quantities may be complex-valued.\n\nIn justifying the deprecation of the term \"field quantity\" and instead using \"root-power quantity\" in the context of levels, ISO 80000 draws attention to the conflicting use of the former term to mean a quantity that depends on the position, which in physics is called a \"field\". Such a field is often called a \"field quantity\" in the literature, but is called a \"field\" here for clarity. Several types of field (such as the electromagnetic field) meet the definition of a root-power quantity, whereas others (such as the Poynting vector and temperature) do not. Conversely, not every root-power quantity is a field (such as the voltage on a loudspeaker).\n\n"}
{"id": "12751687", "url": "https://en.wikipedia.org/wiki?curid=12751687", "title": "God Created the Integers", "text": "God Created the Integers\n\nGod Created the Integers: The Mathematical Breakthroughs That Changed History is an anthology, edited by Stephen Hawking, of \"excerpts from thirty-one of the most important works in the history of mathematics.\" \n\nThe title of the book is a reference to a quotation attributed to mathematician Leopold Kronecker, who once wrote that \"God made the integers; all else is the work of man.\" \n\nThe works are grouped by author and ordered chronologically. Each section is prefaced by notes on the mathematician's life and work. The anthology includes works by the following mathematicians:\n\nSelections from the works of Euler, Bolyai, Lobachevsky and Galois, which are included in the second edition of the book (published in 2007), were not included in the first edition.\n"}
{"id": "37174589", "url": "https://en.wikipedia.org/wiki?curid=37174589", "title": "History of the Theory of Numbers", "text": "History of the Theory of Numbers\n\nHistory of the Theory of Numbers is a three-volume work by L. E. Dickson summarizing work in number theory up to about 1920. The style is unusual in that Dickson mostly just lists results by various authors, with little further discussion. The central topic of quadratic reciprocity and higher reciprocity laws is barely mentioned; this was apparently going to be the topic of a fourth volume that was never written .\n\n\n\n"}
{"id": "253859", "url": "https://en.wikipedia.org/wiki?curid=253859", "title": "History of topos theory", "text": "History of topos theory\n\nThis page gives some very general background to the mathematical idea of topos. This is an aspect of category theory, and has a reputation for being abstruse. The level of abstraction involved cannot be reduced beyond a certain point; but on the other hand context can be given. This is partly in terms of historical development, but also to some extent an explanation of differing attitudes to category theory. \n\nDuring the latter part of the 1950s, the foundations of algebraic geometry were being rewritten; and it is here that the origins of the topos concept are to be found. At that time the Weil conjectures were an outstanding motivation to research. As we now know, the route towards their proof, and other advances, lay in the construction of étale cohomology.\n\nWith the benefit of hindsight, it can be said that algebraic geometry had been wrestling with two problems for a long time. The first was to do with its points: back in the days of projective geometry it was clear that the absence of 'enough' points on an algebraic variety was a barrier to having a good geometric theory (in which it was somewhat like a compact manifold). There was also the difficulty, that was clear as soon as topology took form in the first half of the twentieth century, that the topology of algebraic varieties had 'too few' open sets. \n\nThe question of points was close to resolution by 1950; Alexander Grothendieck took a sweeping step (invoking the Yoneda lemma) that disposed of it — naturally at a cost, that every variety or more general \"scheme\" should become a functor. It wasn't possible to \"add\" open sets, though. The way forward was otherwise.\n\nThe topos definition first appeared somewhat obliquely, in or about 1960. General problems of so-called 'descent' in algebraic geometry were considered, at the same period when the fundamental group was generalised to the algebraic geometry setting (as a pro-finite group). In the light of later work (c. 1970), 'descent' is part of the theory of comonads; here we can see one way in which the Grothendieck school bifurcates in its approach from the 'pure' category theorists, a theme that is important for the understanding of how the topos concept was later treated.\n\nThere was perhaps a more direct route available: the abelian category concept had been introduced by Grothendieck in his foundational work on homological algebra, to unify categories of sheaves of abelian groups, and of modules. An abelian category is supposed to be closed under certain category-theoretic operations — by using this kind of definition one can focus entirely on structure, saying nothing at all about the nature of the objects involved. This type of definition can be traced back, in one line, to the lattice concept of the 1930s. It was a possible question to ask, around 1957, for a purely category-theoretic characterisation of categories of sheaves of \"sets\", the case of sheaves of abelian groups having been subsumed by Grothendieck's work (the \"Tohoku\" paper).\n\nSuch a definition of a topos was eventually given five years later, around 1962, by Grothendieck and Verdier (see Verdier's Bourbaki seminar \"Analysis Situs\"). The characterisation was by means of categories 'with enough colimits', and applied to what is now called a Grothendieck topos. The theory was rounded out by establishing that a Grothendieck topos was a category of sheaves, where now the word \"sheaf\" had acquired an extended meaning, since it involved a Grothendieck topology.\n\nThe idea of a Grothendieck topology (also known as a \"site\") has been characterised by John Tate as a bold pun on the two senses of Riemann surface. Technically speaking it enabled the construction of the sought-after étale cohomology (as well as other refined theories such as flat cohomology and crystalline cohomology). At this point — about 1964 — the developments powered by algebraic geometry had largely run their course. The 'open set' discussion had effectively been summed up in the conclusion that varieties had a rich enough \"site\" of open sets in unramified covers of their (ordinary) Zariski-open sets.\n\nThe current definition of topos goes back to William Lawvere and Myles Tierney. While the timing follows closely on from that described above, as a matter of history, the attitude is different, and the definition is more inclusive. That is, there are examples of toposes that are not Grothendieck topos. What is more, these may be of interest for a number of logical disciplines.\n\nLawvere and Tierney's definition picks out the central role in topos theory of the sub-object classifier. In the usual category of sets, this is the two-element set of Boolean truth-values, true and false. It is almost tautologous to say that the subsets of a given set \"X\" are \"the same as\" (just as good as) the functions on \"X\" to any such given two-element set: fix the 'first' element and make a subset \"Y\" correspond to the function sending \"Y\" there and its complement in \"X\" to the other element.\n\nNow sub-object classifiers can be found in sheaf theory. Still tautologously, though certainly more abstractly, for a topological space \"X\" there is a direct description of a sheaf on \"X\" that plays the role with respect to all sheaves of sets on \"X\". Its set of sections over an open set \"U\" of \"X\" is just the set of open subsets of \"U\". The space associated with a sheaf, for it, is more difficult to describe.\n\nLawvere and Tierney therefore formulated axioms for a topos that assumed a sub-object classifier, and some limit conditions (to make a cartesian-closed category, at least). For a while this notion of topos was called 'elementary topos'.\n\nOnce the idea of a connection with logic was formulated, there were several developments 'testing' the new theory:\n\n\nThere was some irony that in the pushing through of David Hilbert's long-range programme a natural home for intuitionistic logic's central ideas was found: Hilbert had detested the school of L. E. J. Brouwer. Existence as 'local' existence in the sheaf-theoretic sense, now going by the name of Kripke–Joyal semantics, is a good match. On the other hand Brouwer's long efforts on 'species', as he called the intuitionistic theory of reals, are presumably in some way subsumed and deprived of status beyond the historical. There is a theory of the real numbers in each topos, and so no one master intuitionist theory.\n\nThe later work on étale cohomology has tended to suggest that the full, general topos theory isn't required. On the other hand, other sites are used, and the Grothendieck topos has taken its place within homological algebra.\n\nThe Lawvere programme was to write higher-order logic in terms of category theory. That this can be done cleanly is shown by the book treatment by Joachim Lambek and P. J. Scott. What results is essentially an intuitionistic (i.e. constructive logic) theory, its content being clarified by the existence of a \"free topos\". That is a set theory, in a broad sense, but also something belonging to the realm of pure syntax. The structure on its sub-object classifier is that of a Heyting algebra. To get a more classical set theory one can look at toposes in which it is moreover a Boolean algebra, or specialising even further, at those with just two truth-values. In that book, the talk is about constructive mathematics; but in fact this can be read as foundational computer science (which is not mentioned). If one wants to discuss set-theoretic operations, such as the formation of the image (range) of a function, a topos is guaranteed to be able to express this, entirely constructively.\n\nIt also produced a more accessible spin-off in pointless topology, where the \"locale\" concept isolates some of more accessible insights found by treating \"topos\" as a significant development of \"topological space\". The slogan is 'points come later': this brings discussion full circle on this page. The point of view is written up in Peter Johnstone's \"Stone Spaces\", which has been called by a leader in the field of computer science 'a treatise on extensionality'. The extensional is treated in mathematics as ambient - it is not something about which mathematicians really expect to have a theory. Perhaps this is why topos theory has been treated as an oddity; it goes beyond what the traditionally geometric way of thinking allows. The needs of thoroughly intensional theories such as untyped lambda calculus have been met in denotational semantics. Topos theory has long looked like a possible 'master theory' in this area.\n\nThe \"topos\" concept arose in algebraic geometry, as a consequence of combining the concept of \"sheaf\" and \"closure under categorical operations\". It plays a certain definite role in cohomology theories.\n\nThe subsequent developments associated with logic are more interdisciplinary. They include examples drawing on homotopy theory (classifying toposes). They involve links between category theory and mathematical logic, and also (as a high-level, organisational discussion) between category theory and theoretical computer science based on type theory. Granted the general view of Saunders Mac Lane about \"ubiquity\" of concepts, this gives them a definite status. A 'killer application' is étale cohomology.\n\n"}
{"id": "13595525", "url": "https://en.wikipedia.org/wiki?curid=13595525", "title": "ICTP Ramanujan Prize", "text": "ICTP Ramanujan Prize\n\nThe ICTP Ramanujan Prize for Young Mathematicians from Developing Countries is a mathematics prize awarded annually by the International Centre for Theoretical Physics and named after the mathematician Srinivasa Ramanujan. It was founded in 2004, and was first awarded in 2005.\n\nThe prize is awarded to a researcher from a developing country less than 45 years of age who has conducted outstanding research in a developing country. The prize is supported by the Ministry of Science and Technology (India) and Norwegian Academy of Science and Letters through the Abel Fund, with the cooperation of the International Mathematical Union.\n\nSource: International Mathematical Union\n\n\n\n"}
{"id": "1248704", "url": "https://en.wikipedia.org/wiki?curid=1248704", "title": "Ideal theory", "text": "Ideal theory\n\nIn mathematics, ideal theory is the theory of ideals in commutative rings; and is the precursor name for the contemporary subject of commutative algebra. The name grew out of the central considerations, such as the Lasker–Noether theorem in algebraic geometry, and the ideal class group in algebraic number theory, of the commutative algebra of the first quarter of the twentieth century. It was used in the influential van der Waerden text on abstract algebra from around 1930.\n\nThe ideal theory in question had been based on elimination theory, but in line with David Hilbert's taste moved away from algorithmic methods. Gröbner basis theory has now reversed the trend, for computer algebra.\n\nThe importance of the ideal in general of a module, more general than an \"ideal\", probably led to the perception that \"ideal theory\" was too narrow a description. Valuation theory, too, was an important technical extension, and was used by Helmut Hasse and Oscar Zariski. Bourbaki used \"commutative algebra\"; sometimes \"local algebra\" is applied to the theory of local rings. D. G. Northcott's 1953 Cambridge Tract \"Ideal Theory\" (reissued 2004 under the same title) was one of the final appearances of the name.\n"}
{"id": "37302995", "url": "https://en.wikipedia.org/wiki?curid=37302995", "title": "Lehrbuch der Topologie", "text": "Lehrbuch der Topologie\n\nIn mathematics, Lehrbuch der Topologie (German for \"textbook of topology\") is a book by Herbert Seifert and William Threlfall, first published in 1934 and published in an English translation in 1980. It was one of the earliest textbooks on algebraic topology, and was the standard reference on this topic for many years.\n\nAlbert W. Tucker wrote a review.\n\n"}
{"id": "1595681", "url": "https://en.wikipedia.org/wiki?curid=1595681", "title": "Lie theory", "text": "Lie theory\n\nIn mathematics, the researcher Sophus Lie ( ) initiated lines of study involving integration of differential equations, transformation groups, and contact of spheres that have come to be called Lie theory. For instance, the latter subject is Lie sphere geometry. This article addresses his approach to transformation groups, which is one of the areas of mathematics, and was worked out by Wilhelm Killing and Élie Cartan.\n\nThe foundation of Lie theory is the exponential map relating Lie algebras to Lie groups which is called the Lie group–Lie algebra correspondence. The subject is part of differential geometry since Lie groups are differentiable manifolds. Lie groups evolve out of the identity (1) and the tangent vectors to one-parameter subgroups generate the Lie algebra. The structure of a Lie group is implicit in its algebra, and the structure of the Lie algebra is expressed by root systems and root data.\n\nLie theory has been particularly useful in mathematical physics since it describes important physical groups such as the Galilean group, the Lorentz group and the Poincaré group.\n\nThe one-parameter groups are the first instance of Lie theory. The compact case arises through Euler's formula in the complex plane. Other one-parameter groups occur in the split-complex number plane as the unit hyperbola\nand in the dual number plane as the line formula_2\nIn these cases the Lie algebra parameters have names: angle, hyperbolic angle, and slope. Using the appropriate \"angle\", and a radial vector, any one of these planes can be given a polar decomposition. Any one of these decompositions, or Lie algebra renderings, may be necessary for rendering the Lie subalgebra of a 2 × 2 real matrix.\n\nThere is a classical 3-parameter Lie group and algebra pair: the quaternions of unit length which can be identified with the 3-sphere. Its Lie algebra is the subspace of quaternion vectors. Since the commutator ij − ji = 2k, the Lie bracket in this algebra is twice the cross product of ordinary vector analysis.\n\nAnother elementary 3-parameter example is given by the Heisenberg group and its Lie algebra.\nStandard treatments of Lie theory often begin with the classical groups.\n\nEarly expressions of Lie theory are found in books composed by Sophus Lie with Friedrich Engel and Georg Scheffers from 1888 to 1896.\n\nIn Lie's early work, the idea was to construct a theory of \"continuous groups\", to complement the theory of discrete groups that had developed in the theory of modular forms, in the hands of Felix Klein and Henri Poincaré. The initial application that Lie had in mind was to the theory of differential equations. On the model of Galois theory and polynomial equations, the driving conception was of a theory capable of unifying, by the study of symmetry, the whole area of ordinary differential equations.\n\nAccording to historian Thomas W. Hawkins, it was Élie Cartan that made Lie theory what it is:\n\nLie theory is frequently built upon a study of the classical linear algebraic groups. Special branches include Weyl groups, Coxeter groups, and buildings. The classical subject has been extended to Groups of Lie type.\n\nIn 1900 David Hilbert challenged Lie theorists with his Fifth Problem presented at the International Congress of Mathematicians in Paris.\n\n\n\n"}
{"id": "2230309", "url": "https://en.wikipedia.org/wiki?curid=2230309", "title": "List of computer algebra systems", "text": "List of computer algebra systems\n\nThe following tables provide a comparison of computer algebra systems (CAS). A CAS is a package comprising a set of algorithms for performing symbolic manipulations on algebraic objects, a language to implement them, and an environment in which to use the language. A CAS may include a user interface and graphics capability; and to be effective may require a large library of algorithms, efficient data structures and a fast kernel.\n\nThese computer algebra systems are sometimes combined with \"front end\" programs that provide a better user interface, such as the general-purpose GNU TeXmacs.\n\nBelow is a summary of significantly developed \"symbolic\" functionality in each of the systems.\n\nThose which do not \"edit equations\" may have a GUI, plotting, ASCII graphic formulae and math font printing. The ability to generate plaintext files is also a sought-after feature because it allows a work to be understood by people who do not have a computer algebra system installed.\n\nThe software can run under their respective operating systems natively without emulation. Some systems must be compiled first using an appropriate compiler for the source language and target platform. For some platforms, only older releases of the software may be available.\n\nSome graphing calculators have CAS features.\n\n\n"}
{"id": "12524069", "url": "https://en.wikipedia.org/wiki?curid=12524069", "title": "List of disproved mathematical ideas", "text": "List of disproved mathematical ideas\n\nIn mathematics, ideas are supposedly not accepted as fact until they have been rigorously proved. However, there have been some ideas that were fairly accepted in the past but which were subsequently shown to be false. This article is meant to serve as a repository for compiling a list of such ideas.\n\n\n"}
{"id": "8339650", "url": "https://en.wikipedia.org/wiki?curid=8339650", "title": "List of mathematic operators", "text": "List of mathematic operators\n\nIn mathematics, an operator or transform is a function from one space of functions to another. Operators occur commonly in engineering, physics and mathematics. Many are integral operators and differential operators.\n\nIn the following \"L\" is an operator\n\nwhich takes a function formula_2 to another function formula_3. Here, formula_4 and formula_5 are some unspecified function spaces, such as Hardy space, \"L\" space, Sobolev space, or, more vaguely, the space of holomorphic functions.\n\n"}
{"id": "22609470", "url": "https://en.wikipedia.org/wiki?curid=22609470", "title": "List of mathematical abbreviations", "text": "List of mathematical abbreviations\n\nThis article is a listing of abbreviated names of mathematical functions, function-like operators and other mathematical terminology.\n\n\n"}
{"id": "5971846", "url": "https://en.wikipedia.org/wiki?curid=5971846", "title": "List of mathematicians (Z)", "text": "List of mathematicians (Z)\n\n\n\n\n\n"}
{"id": "193837", "url": "https://en.wikipedia.org/wiki?curid=193837", "title": "List of matrices", "text": "List of matrices\n\nThis page lists some important classes of matrices used in mathematics, science and engineering. A matrix (plural matrices, or less commonly matrixes) is a rectangular array of numbers called \"entries\". Matrices have a long history of both study and application, leading to diverse ways of classifying matrices. A first group is matrices satisfying concrete conditions of the entries, including constant matrices. An important example is the identity matrix given by\n\nFurther ways of classifying matrices are according to their eigenvalues or by imposing conditions on the product of the matrix with other matrices. Finally, many domains, both in mathematics and other sciences including physics and chemistry have particular matrices that are applied chiefly in these areas.\nThe following lists matrices whose entries are subject to certain conditions. Many of them apply to \"square matrices\" only, that is matrices with the same number of columns and rows. The main diagonal of a square matrix is the diagonal joining the upper left corner and the lower right one or equivalently the entries \"a\". The other diagonal is called anti-diagonal (or counter-diagonal).\n\nThe list below comprises matrices whose elements are constant for any given dimension (size) of matrix. The matrix entries will be denoted \"a\". The table below uses the Kronecker delta δ for two integers \"i\" and \"j\" which is 1 if \"i\" = \"j\" and 0 else.\n\nA number of matrix-related notions is about properties of products or inverses of the given matrix. The matrix product of a \"m\"-by-\"n\" matrix \"A\" and a \"n\"-by-\"k\" matrix \"B\" is the \"m\"-by-\"k\" matrix \"C\" given by\nThis matrix product is denoted \"AB\". Unlike the product of numbers, matrix products are not commutative, that is to say \"AB\" need not be equal to \"BA\". A number of notions are concerned with the failure of this commutativity. An inverse of square matrix \"A\" is a matrix \"B\" (necessarily of the same dimension as \"A\") such that \"AB\" = \"I\". Equivalently, \"BA\" = \"I\". An inverse need not exist. If it exists, \"B\" is uniquely determined, and is also called \"the\" inverse of \"A\", denoted \"A\".\n\nThe following matrices find their main application in statistics and probability theory.\n\nThe following matrices find their main application in graph and network theory.\n\n\n"}
{"id": "634754", "url": "https://en.wikipedia.org/wiki?curid=634754", "title": "List of partial differential equation topics", "text": "List of partial differential equation topics\n\nThis is a list of partial differential equation topics.\n\n\n\n\n"}
{"id": "2302006", "url": "https://en.wikipedia.org/wiki?curid=2302006", "title": "List of simple Lie groups", "text": "List of simple Lie groups\n\nIn mathematics, the simple Lie groups were first classified by Wilhelm Killing and later perfected by Élie Cartan. This classification is often referred to as Killing-Cartan classification. \n\nThe list of simple Lie groups can be used to read off the list of simple Lie algebras and Riemannian symmetric spaces. See also the table of Lie groups for a smaller list of groups that commonly occur in theoretical physics, and the Bianchi classification for groups of dimension at most 3. \n\nUnfortunately, there is no universally accepted definition of a simple Lie group. In particular, it is not always defined as a Lie group that is simple as an abstract group. Authors differ on whether a simple Lie group has to be connected, or on whether it is allowed to have a non-trivial center, or on whether R is a simple Lie group. \n\nThe most common definition is that a Lie group is simple if it is connected, non-abelian, and every closed \"connected\" normal subgroup is either the identity or the whole group. In particular, simple groups are allowed to have a non-trivial center, but R is not simple. \n\nIn this article the connected simple Lie groups with trivial center are listed. Once these are known, the ones with non-trivial center are easy to list as follows. Any simple Lie group with trivial center has a universal cover, whose center is the fundamental group of the simple Lie group. The corresponding simple Lie groups with non-trivial center can be obtained as quotients of this universal cover by a subgroup of the center.\n\nThe Lie algebra of a simple Lie group is a simple Lie algebra. This is a one-to-one correspondence between connected simple Lie groups with trivial center and simple Lie algebras of dimension greater than 1. (Authors differ on whether the one-dimensional Lie algebra should be counted as simple.)\n\nOver the complex numbers the semisimple Lie algebras are classified by their Dynkin diagrams, of types \"ABCDEFG\". If \"L\" is a real simple Lie algebra, its complexification is a simple complex Lie algebra, unless \"L\" is already \nthe complexification of a Lie algebra, in which case the complexification of \"L\" is a product of two copies of \"L\". This reduces the problem of classifying the real simple Lie algebras to that of finding all the real forms of each complex simple Lie algebra (i.e., real Lie algebras whose complexification is the given complex Lie algebra). There are always at least 2 such forms: a split form and a compact form, and there are usually a few others. The different real forms correspond to the classes of automorphisms of order at most 2 of the complex Lie algebra.\n\nSymmetric spaces are classified as follows. \n\nFirst, the universal cover of a symmetric space is still symmetric, so we can reduce to the case of simply connected symmetric spaces. (For example, the universal cover of a real projective plane is a sphere.)\n\nSecond, the product of symmetric spaces is symmetric, so we may as well just classify the irreducible simply connected ones (where irreducible means they cannot be written as a product of smaller symmetric spaces). \n\nThe irreducible simply connected symmetric spaces are the real line, and exactly two symmetric spaces corresponding to each \"non-compact\" simple Lie group \"G\",\none compact and one non-compact. The non-compact one is a cover of the quotient of \"G\" by a maximal compact subgroup \"H\", and the compact one is a cover of the quotient of\nthe compact form of \"G\" by the same subgroup \"H\". This duality between compact and non-compact symmetric spaces is a generalization of the well known duality between spherical and hyperbolic geometry.\n\nA symmetric space with a compatible complex structure is called Hermitian. The compact simply connected irreducible Hermitian symmetric spaces fall into 4 infinite families with 2 exceptional ones left over, and each has a non-compact dual. In addition the complex plane is also a Hermitian symmetric space; this gives the complete list of irreducible Hermitian symmetric spaces.\n\nThe four families are the types A III, B I and D I for , D III, and C I, and the two exceptional ones are types E III and E VII of complex dimensions 16 and 27.\n\nformula_1  stand for the real numbers, complex numbers, quaternions, and octonions.\n\nIn the symbols such as \"E\" for the exceptional groups, the exponent −26 is the signature of an invariant symmetric bilinear form that is negative definite on the maximal compact subgroup. It is equal to the dimension of the group minus twice the dimension of a maximal compact subgroup.\n\nThe fundamental group listed in the table below is the fundamental group of the simple group with trivial center. \nOther simple groups with the same Lie algebra correspond to subgroups of this fundamental group (modulo the action of the outer automorphism group).\n\nThe following table lists some Lie groups with simple Lie algebras of small \ndimension. The groups on a given line all have the same Lie algebra. In the dimension 1 case, the groups are abelian and not simple.\n\n"}
{"id": "34032940", "url": "https://en.wikipedia.org/wiki?curid=34032940", "title": "Logan plot", "text": "Logan plot\n\nA Logan plot (or Logan graphical analysis) is a graphical analysis technique based on the compartment model that uses linear regression to analyze pharmacokinetics of tracers involving reversible uptake. It is mainly used for the evaluation of nuclear medicine imaging data after the injection of a labeled ligand that binds reversibly to specific receptor or enzyme.\n\nIn conventional compartmental analysis, an iterative method is used to fit the individual model parameters in the solution of a compartmental model of specific configuration to the measurements with a measured plasma time-activity curve that serves as an forcing (input) function, and the binding of the tracer can then be described. Graphical analysis is a simplified method that transforms the model equations into a linear equation evaluated at multiple time points and provides fewer parameters (i.e., slope and intercept). Although the slope and the intercept can be interpreted in terms of a combination of model parameters if a compartmental model configuration is assumed, the graphical methods are independent of any specific model configuration. In case of irreversible tracers, certain fraction of the radioactivity is trapped in the tissue or the binding site during the course of the experiment, whereas reversible tracers show uptake and loss from all compartments throughout the study. The theoretical foundation of graphical analysis for irreversible tracers (also called Patlak graphical analysis or Patlak plot) was laid by Clifford Patlak and his colleagues at NIH. Based on the original work of Patlak, Jean Logan and her colleagues from Brookhaven National Laboratory extended the method to tracers with reversible kinetics.\n\nThe kinetics of radiolabeled compounds in a compartmental system can be described in terms of a set of first-order, constant-coefficient, ordinary differential equations. The time course of the activity in the multicompartmental system driven by a metabolite-corrected plasma input function formula_1 can be described by:\n\nwhere formula_3 is a column vector of activity concentration for each compartment at time formula_4, formula_5 is the matrix of the transfer constants between compartments, and formula_6 is the vector of plasma-to-tissue transfer constants. Patlak and Blasberg showed that the above equation can be written as:\n\nwhere formula_8 represents a row vector of 1s and formula_9. The total activity in the region of interest, formula_10, is a combination of radioactivities from all compartments plus a plasma volume fraction (formula_11) and thus:\n\nBy dividing both sides by formula_10, one obtains the following linear equation:\n"}
{"id": "27606747", "url": "https://en.wikipedia.org/wiki?curid=27606747", "title": "Mathematical Methods in the Physical Sciences", "text": "Mathematical Methods in the Physical Sciences\n\nMathematical Methods in the Physical Sciences is a 1966 textbook by mathematician Mary L. Boas intended to develop skills in mathematical problem solving needed for junior to senior-graduate courses in engineering, physics, and chemistry. The book provides a comprehensive survey of analytic techniques and provides careful statements of important theorems while omitting most detailed proofs. Each section contains a large number of problems, with selected answers. Numerical computational approaches using computers are outside the scope of the book.\n\nThe book, now in its third edition, was still widely used in university classrooms as of 1999\nand is frequently cited in other textbooks and scientific papers.\n\n\n\n"}
{"id": "168905", "url": "https://en.wikipedia.org/wiki?curid=168905", "title": "Mathematical folklore", "text": "Mathematical folklore\n\nAs the term is understood by mathematicians, folk mathematics or mathematical folklore is the body of theorems, definitions, proofs, or mathematical facts or techniques that circulate among mathematicians by word of mouth but have not appeared in print, either in books or in scholarly journals. Knowledge of folklore is the coin of the realm of academic mathematics.\n\nQuite important at times for researchers are folk theorems, which are results known, at least to experts in a field, and considered to have established status, but not published in complete form. Sometimes these are only alluded to in the public literature. \nAn example is a book of exercises, described on the back cover:\nAnother distinct category is wellknowable mathematics, a term introduced by John Conway. This consists of matters that are known and factual, but not in active circulation in relation with current research. Both of these concepts are attempts to describe the actual context in which research work is done.\n\nSome people, principally non-mathematicians, use the term \"folk mathematics\" to refer to the informal mathematics studied in many ethno-cultural studies of mathematics.\n\nMathematical folklore may also refer to unusual (and possibly apocryphal) stories or jokes involving mathematicians or mathematics that are told verbally in mathematics departments. Compilations include tales collected in G. H. Hardy's \"A Mathematician's Apology\" and ; examples include:\n\n"}
{"id": "22468661", "url": "https://en.wikipedia.org/wiki?curid=22468661", "title": "Mathematics and art", "text": "Mathematics and art\n\nMathematics and art are related in a variety of ways. Mathematics has itself been described as an art motivated by beauty. Mathematics can be discerned in arts such as music, dance, painting, architecture, sculpture, and textiles. This article focuses, however, on mathematics in the visual arts.\n\nMathematics and art have a long historical relationship. Artists have used mathematics since the 4th century BC when the Greek sculptor Polykleitos wrote his \"Canon\", prescribing proportions based on the ratio 1: for the ideal male nude. Persistent popular claims have been made for the use of the golden ratio in ancient art and architecture, without reliable evidence. In the Italian Renaissance, Luca Pacioli wrote the influential treatise \"De Divina Proportione\" (1509), illustrated with woodcuts by Leonardo da Vinci, on the use of the golden ratio in art. Another Italian painter, Piero della Francesca, developed Euclid's ideas on perspective in treatises such as \"De Prospectiva Pingendi\", and in his paintings. The engraver Albrecht Dürer made many references to mathematics in his work \"Melencolia I\". In modern times, the graphic artist M. C. Escher made intensive use of tessellation and hyperbolic geometry, with the help of the mathematician H. S. M. Coxeter, while the De Stijl movement led by Theo van Doesburg and Piet Mondrian explicitly embraced geometrical forms. Mathematics has inspired textile arts such as quilting, knitting, cross-stitch, crochet, embroidery, weaving, Turkish and other carpet-making, as well as kilim. In Islamic art, symmetries are evident in forms as varied as Persian girih and Moroccan zellige tilework, Mughal jali pierced stone screens, and widespread muqarnas vaulting.\n\nMathematics has directly influenced art with conceptual tools such as linear perspective, the analysis of symmetry, and mathematical objects such as polyhedra and the Möbius strip. Magnus Wenninger creates colourful stellated polyhedra, originally as models for teaching. Mathematical concepts such as recursion and logical paradox can be seen in paintings by Rene Magritte and in engravings by M. C. Escher. Computer art often makes use of fractals including the Mandelbrot set, and sometimes explores other mathematical objects such as cellular automata. Controversially, the artist David Hockney has argued that artists from the Renaissance onwards made use of the camera lucida to draw precise representations of scenes; the architect Philip Steadman similarly argued that Vermeer used the camera obscura in his distinctively observed paintings.\n\nOther relationships include the algorithmic analysis of artworks by X-ray fluorescence spectroscopy, the finding that traditional batiks from different regions of Java have distinct fractal dimensions, and stimuli to mathematics research, especially Filippo Brunelleschi's theory of perspective, which eventually led to Girard Desargues's projective geometry. A persistent view, based ultimately on the Pythagorean notion of harmony in music, holds that everything was arranged by Number, that God is the geometer of the world, and that therefore the world's geometry is sacred, as seen in artworks such as William Blake's \"The Ancient of Days\".\n\nPolykleitos the elder (c.450–420 BC) was a Greek sculptor from the school of Argos, and a contemporary of Phidias. His works and statues consisted mainly of bronze and were of athletes. According to the philosopher and mathematician Xenocrates, Polykleitos is ranked as one of the most important sculptors of Classical antiquity for his work on the \"Doryphorus\" and the statue of Hera in the Heraion of Argos. While his sculptures may not be as famous as those of Phidias, they are much admired. In the \"Canon\" of Polykleitos, a treatise he wrote designed to document the \"perfect\" anatomical proportions of the male nude, Polykleitos gives us a mathematical approach towards sculpturing the human body.\n\nPolykleitos uses the distal phalanx of the little finger as the basic module for determining the proportions of the human body. Polykleitos multiplies the length of the distal phalanx by the square root of two () to get the distance of the second phalanges and multiplies the length again by to get the length of the third phalanges. Next, he takes the finger length and multiplies that by to get the length of the palm from the base of the finger to the ulna. This geometric series of measurements progresses until Polykleitos has formed the arm, chest, body, and so on.\n\nThe influence of the \"Canon\" of Polykleitos is immense in Classical Greek, Roman, and Renaissance sculpture, many sculptors following Polykleitos's prescription. While none of Polykleitos's original works survive, Roman copies demonstrate his ideal of physical perfection and mathematical precision. Some scholars argue that Pythagorean thought influenced the \"Canon\" of Polykleitos. The \"Canon\" applies the basic mathematical concepts of Greek geometry, such as the ratio, proportion, and \"symmetria\" (Greek for \"harmonious proportions\") and turns it into a system capable of describing the human form through a series of continuous geometric progressions.\n\nIn classical times, rather than making distant figures smaller with linear perspective, painters sized objects and figures according to their thematic importance. In the Middle Ages, some artists used reverse perspective for special emphasis. The Muslim mathematician Alhazen (Ibn al-Haytham) described a theory of optics in his \"Book of Optics\" in 1021, but never applied it to art. The Renaissance saw a rebirth of Classical Greek and Roman culture and ideas, among them the study of mathematics to understand nature and the arts. Two major motives drove artists in the late Middle Ages and the Renaissance towards mathematics. First, painters needed to figure out how to depict three-dimensional scenes on a two-dimensional canvas. Second, philosophers and artists alike were convinced that mathematics was the true essence of the physical world and that the entire universe, including the arts, could be explained in geometric terms.\n\nThe rudiments of perspective arrived with Giotto (1266/7 – 1337), who attempted to draw in perspective using an algebraic method to determine the placement of distant lines. In 1415, the Italian architect Filippo Brunelleschi and his friend Leon Battista Alberti demonstrated the geometrical method of applying perspective in Florence, using similar triangles as formulated by Euclid, to find the apparent height of distant objects. Brunelleschi's own perspective paintings are lost, but Masaccio's painting of the Holy Trinity shows his principles at work.\nThe Italian painter Paolo Uccello (1397–1475) was fascinated by perspective, as shown in his paintings of \"The Battle of San Romano\" (c. 1435–1460): broken lances lie conveniently along perspective lines.\n\nThe painter Piero della Francesca (c.1415–1492) exemplified this new shift in Italian Renaissance thinking. He was an expert mathematician and geometer, writing books on solid geometry and perspective, including \"De Prospectiva Pingendi (On Perspective for Painting)\", \"Trattato d'Abaco (Abacus Treatise)\", and \"De corporibus regularibus (On Regular Solids)\". The historian Vasari in his \"Lives of the Painters\" calls Piero the \"greatest geometer of his time, or perhaps of any time.\" Piero's interest in perspective can be seen in his paintings including the Polyptych of Perugia, the \"San Agostino altarpiece\" and \"The Flagellation of Christ\". His work on geometry influenced later mathematicians and artists including Luca Pacioli in his \"De Divina Proportione\" and Leonardo da Vinci. Piero studied classical mathematics and the works of Archimedes. He was taught commercial arithmetic in \"abacus schools\"; his writings are formatted like abacus school textbooks, perhaps including Leonardo Pisano (Fibonacci)'s 1202 \"Liber Abaci\". Linear perspective was just being introduced into the artistic world. Alberti explained in his 1435 \"De pictura\": \"light rays travel in straight lines from points in the observed scene to the eye, forming a kind of pyramid with the eye as vertex.\" A painting constructed with linear perspective is a cross-section of that pyramid.\n\nIn \"De Prospectiva Pingendi\", Piero transforms his empirical observations of the way aspects of a figure change with point of view into mathematical proofs. His treatise starts in the vein of Euclid: he defines the point as \"the tiniest thing that is possible for the eye to comprehend\". He uses deductive logic to lead the reader to the perspective representation of a three-dimensional body.\n\nThe artist David Hockney argued in his book \"\" that artists started using a camera lucida from the 1420s, resulting in a sudden change in precision and realism, and that this practice was continued by major artists including Ingres, Van Eyck, and Caravaggio. Critics disagree on whether Hockney was correct. Similarly, the architect Philip Steadman argued controversially that Vermeer had used a different device, the camera obscura, to help him create his distinctively observed paintings.\n\nIn 1509, Luca Pacioli (c. 1447–1517) published \"De divina proportione\" on mathematical and artistic proportion, including in the human face. Leonardo da Vinci (1452–1519) illustrated the text with woodcuts of regular solids while he studied under Pacioli in the 1490s. Leonardo's drawings are probably the first illustrations of skeletonic solids. These, such as the rhombicuboctahedron, were among the first to be drawn to demonstrate perspective by being overlaid on top of each other. The work discusses perspective in the works of Piero della Francesca, Melozzo da Forlì, and Marco Palmezzano. Da Vinci studied Pacioli's \"Summa\", from which he copied tables of proportions. In \"Mona Lisa\" and \"The Last Supper\", Da Vinci's work incorporated linear perspective with a vanishing point to provide apparent depth. \"The Last Supper\" is constructed in a tight ratio of 12:6:4:3, as is Raphael's \"The School of Athens\", which includes Pythagoras with a tablet of ideal ratios, sacred to the Pythagoreans. In \"Vitruvian Man\", Leonardo expressed the ideas of the Roman architect Vitruvius, innovatively showing the male figure twice, and centring him in both a circle and a square.\n\nAs early as the 15th century, curvilinear perspective found its way into paintings by artists interested in image distortions. Jan van Eyck's 1434 \"Arnolfini Portrait\" contains a convex mirror with reflections of the people in the scene, while Parmigianino's \"Self-portrait in a Convex Mirror\", c. 1523–1524, shows the artist's largely undistorted face at the centre, with a strongly curved background and artist's hand around the edge.\n\nThree-dimensional space can be represented convincingly in art, as in technical drawing, by means other than perspective. Oblique projections, including cavalier perspective (used by French military artists to depict fortifications in the 18th century), were used continuously and ubiquitously by Chinese artists from the first or second centuries until the 18th century. The Chinese acquired the technique from India, which acquired it from Ancient Rome. Oblique projection is seen in Japanese art, such as in the Ukiyo-e paintings of Torii Kiyonaga (1752–1815).\n\nThe golden ratio (roughly equal to 1.618) was known to Euclid. The golden ratio has persistently been claimed in modern times to have been used in art and architecture by the ancients in Egypt, Greece and elsewhere, without reliable evidence. The claim may derive from confusion with \"golden mean\", which to the Ancient Greeks meant \"avoidance of excess in either direction\", not a ratio. Pyramidologists since the nineteenth century have argued on dubious mathematical grounds for the golden ratio in pyramid design. The Parthenon, a 5th-century BC temple in Athens, has been claimed to use the golden ratio in its façade and floor plan, but these claims too are disproved by measurement. The Great Mosque of Kairouan in Tunisia has similarly been claimed to use the golden ratio in its design, but the ratio does not appear in the original parts of the mosque. The historian of architecture Frederik Macody Lund argued in 1919 that the Cathedral of Chartres (12th century), Notre-Dame of Laon (1157–1205) and Notre Dame de Paris (1160) are designed according to the golden ratio, drawing regulator lines to make his case. Other scholars argue that until Pacioli's work in 1509, the golden ratio was unknown to artists and architects. For example, the height and width of the front of Notre-Dame of Laon have the ratio 8/5 or 1.6, not 1.618. Such Fibonacci ratios quickly become hard to distinguish from the golden ratio. After Pacioli, the golden ratio is more definitely discernible in artworks including Leonardo's \"Mona Lisa\".\n\nAnother ratio, the only other morphic number, was named the plastic number in 1928 by the Dutch architect Hans van der Laan (originally named \"le nombre radiant\" in French). Its value is the solution of the cubic equation\n\nan irrational number which is approximately 1.325. According to the architect Richard Padovan, this has characteristic ratios and , which govern the limits of human perception in relating one physical size to another. Van der Laan used these ratios when designing the 1967 St. Benedictusberg Abbey church in the Netherlands.\n\nPlanar symmetries have for millennia been exploited in artworks such as carpets, lattices, textiles and tilings.\n\nMany traditional rugs, whether pile carpets or flatweave kilims, are divided into a central field and a framing border; both can have symmetries, though in handwoven carpets these are often slightly broken by small details, variations of pattern and shifts in colour introduced by the weaver. In kilims from Anatolia, the motifs used are themselves usually symmetrical. The general layout, too, is usually present, with arrangements such as stripes, stripes alternating with rows of motifs, and packed arrays of roughly hexagonal motifs. The field is commonly laid out as a wallpaper with a wallpaper group such as pmm, while the border may be laid out as a frieze of frieze group pm11, pmm2 or pma2. Turkish and Central Asian kilims often have three or more borders in different frieze groups. Weavers certainly had the intention of symmetry, without explicit knowledge of its mathematics.\nThe mathematician and architectural theorist Nikos Salingaros suggests that the \"powerful presence\" (aesthetic effect) of a \"great carpet\" such as the best Konya two-medallion carpets of the 17th century is created by mathematical techniques related to the theories of the architect Christopher Alexander. These techniques include making opposites couple; opposing colour values; differentiating areas geometrically, whether by using complementary shapes or balancing the directionality of sharp angles; providing small-scale complexity (from the knot level upwards) and both small- and large-scale symmetry; repeating elements at a hierarchy of different scales (with a ratio of about 2.7 from each level to the next). Salingaros argues that \"all successful carpets satisfy at least nine of the above ten rules\", and suggests that it might be possible to create a metric from these rules.\n\nElaborate lattices are found in Indian Jali work, carved in marble to adorn tombs and palaces. Chinese lattices, always with some symmetry, exist in 14 of the 17 wallpaper groups; they often have mirror, double mirror, or rotational symmetry. Some have a central medallion, and some have a border in a frieze group. Many Chinese lattices have been analysed mathematically by Daniel S. Dye; he identifies Sichuan as the centre of the craft.\n\nSymmetries are prominent in textile arts including quilting, knitting, cross-stitch, crochet, embroidery and weaving, where they may be purely decorative or may be marks of status. Rotational symmetry is found in circular structures such as domes; these are sometimes elaborately decorated with symmetric patterns inside and out, as at the 1619 Sheikh Lotfollah Mosque in Isfahan. Items of embroidery and lace work such as tablecloths and table mats, made using bobbins or by tatting, can have a wide variety of reflectional and rotational symmetries which are being explored mathematically.\n\nIslamic art exploits symmetries in many of its artforms, notably in girih tilings. These are formed using a set of five tile shapes, namely a regular decagon, an elongated hexagon, a bow tie, a rhombus, and a regular pentagon. All the sides of these tiles have the same length; and all their angles are multiples of 36° (π/5 radians), offering fivefold and tenfold symmetries. The tiles are decorated with strapwork lines (girih), generally more visible than the tile boundaries. In 2007, the physicists Peter Lu and Paul Steinhardt argued that girih resembled quasicrystalline Penrose tilings. Elaborate geometric zellige tilework is a distinctive element in Moroccan architecture. Muqarnas vaults are three-dimensional but were designed in two dimensions with drawings of geometrical cells.\n\nThe Platonic solids and other polyhedra are a recurring theme in Western art. They are found, for instance, in a marble mosaic featuring the small stellated dodecahedron, attributed to Paolo Uccello, in the floor of the San Marco Basilica in Venice; in Leonardo da Vinci's diagrams of regular polyhedra drawn as illustrations for Luca Pacioli's 1509 book \"The Divine Proportion\"; as a glass rhombicuboctahedron in Jacopo de Barbari's portrait of Pacioli, painted in 1495; in the truncated polyhedron (and various other mathematical objects) in Albrecht Dürer's engraving Melencolia I; and in Salvador Dalí's painting \"The Last Supper\" in which Christ and his disciples are pictured inside a giant dodecahedron.\n\nAlbrecht Dürer (1471–1528) was a German Renaissance printmaker who made important contributions to polyhedral literature in his 1525 book, \"Underweysung der Messung (Education on Measurement)\", meant to teach the subjects of linear perspective, geometry in architecture, Platonic solids, and regular polygons. Dürer was likely influenced by the works of Luca Pacioli and Piero della Francesca during his trips to Italy. While the examples of perspective in \"Underweysung der Messung\" are underdeveloped and contain inaccuracies, there is a detailed discussion of polyhedra. Dürer is also the first to introduce in text the idea of polyhedral nets, polyhedra unfolded to lie flat for printing. Dürer published another influential book on human proportions called \"Vier Bücher von Menschlicher Proportion (Four Books on Human Proportion)\" in 1528.\n\nDürer's well-known engraving \"Melencolia I\" depicts a frustrated thinker sitting by a truncated triangular trapezohedron and a magic square. These two objects, and the engraving as a whole, have been the subject of more modern interpretation than the contents of almost any other print, including a two-volume book by Peter-Klaus Schuster, and an influential discussion in Erwin Panofsky's monograph of Dürer.\nSalvador Dalí's \"Corpus Hypercubus\" depicts an unfolded three-dimensional net for a hypercube, a four-dimensional regular polyhedron.\n\nTraditional Indonesian wax-resist batik designs on cloth combine representational motifs (such as floral and vegetal elements) with abstract and somewhat chaotic elements, including imprecision in applying the wax resist, and random variation introduced by cracking of the wax. Batik designs have a fractal dimension between 1 and 2, varying in different regional styles. For example, the batik of Cirebon has a fractal dimension of 1.1; the batiks of Yogyakarta and Surakarta (Solo) in Central Java have a fractal dimension of 1.2 to 1.5; and the batiks of Lasem on the north coast of Java and of Tasikmalaya in West Java have a fractal dimension between 1.5 and 1.7.\n\nThe drip painting works of the modern artist Jackson Pollock are similarly distinctive in their fractal dimension. His 1948 \"Number 14\" has a coastline-like dimension of 1.45, while his later paintings had successively higher fractal dimensions and accordingly more elaborate patterns. One of his last works, \"Blue Poles\", took six months to create, and has the fractal dimension of 1.72.\n\nThe astronomer Galileo Galilei in his \"Il Saggiatore\" wrote that \"[The universe] is written in the language of mathematics, and its characters are triangles, circles, and other geometric figures.\" Artists who strive and seek to study nature must first, in Galileo's view, fully understand mathematics. Mathematicians, conversely, have sought to interpret and analyse art through the lens of geometry and rationality. The mathematician Felipe Cucker suggests that mathematics, and especially geometry, is a source of rules for \"rule-driven artistic creation\", though not the only one. Some of the many strands of the resulting complex relationship are described below.\n\nThe mathematician Jerry P. King describes mathematics as an art, stating that \"the keys to mathematics are beauty and elegance and not dullness and technicality\", and that beauty is the motivating force for mathematical research. King cites the mathematician G. H. Hardy's 1940 essay \"A Mathematician's Apology\". In it, Hardy discusses why he finds two theorems of classical times as first rate, namely Euclid's proof there are infinitely many prime numbers, and the proof that the square root of 2 is irrational. King evaluates this last against Hardy's criteria for mathematical elegance: \"\"seriousness, depth, generality, unexpectedness, inevitability\", and \"economy\"\" (King's italics), and describes the proof as \"aesthetically pleasing\". The Hungarian mathematician Paul Erdős agreed that mathematics possessed beauty but considered the reasons beyond explanation: \"Why are numbers beautiful? It's like asking why is Beethoven's Ninth Symphony beautiful. If you don't see why, someone can't tell you. I \"know\" numbers are beautiful.\"\n\nMathematics can be discerned in many of the arts, such as music, dance, painting, architecture, and sculpture. Each of these is richly associated with mathematics. Among the connections to the visual arts, mathematics can provide tools for artists, such as the rules of linear perspective as described by Brook Taylor and Johann Lambert, or the methods of descriptive geometry, now applied in software modelling of solids, dating back to Albrecht Dürer and Gaspard Monge. Artists from Luca Pacioli in the Middle Ages and Leonardo da Vinci and Albrecht Dürer in the Renaissance have made use of and developed mathematical ideas in the pursuit of their artistic work. The use of perspective began, despite some embryonic usages in the architecture of Ancient Greece, with Italian painters such as Giotto in the 13th century; rules such as the vanishing point were first formulated by Brunelleschi in about 1413, his theory influencing Leonardo and Dürer. Isaac Newton's work on the optical spectrum influenced Goethe's \"Theory of Colours\" and in turn artists such as Philipp Otto Runge, J. M. W. Turner, the Pre-Raphaelites and Wassily Kandinsky. Artists may also choose to analyse the symmetry of a scene. Tools may be applied by mathematicians who are exploring art, or artists inspired by mathematics, such as M. C. Escher (inspired by H. S. M. Coxeter) and the architect Frank Gehry, who more tenuously argued that computer aided design enabled him to express himself in a wholly new way.\n\nThe artist Richard Wright argues that mathematical objects that can be constructed can be seen either \"as processes to simulate phenomena\" or as works of \"computer art\". He considers the nature of mathematical thought, observing that fractals were known to mathematicians for a century before they were recognised as such. Wright concludes by stating that it is appropriate to subject mathematical objects to any methods used to \"come to terms with cultural artifacts like art, the tension between objectivity and subjectivity, their metaphorical meanings and the character of representational systems.\" He gives as instances an image from the Mandelbrot set, an image generated by a cellular automaton algorithm, and a computer-rendered image, and discusses, with reference to the Turing test, whether algorithmic products can be art. Sasho Kalajdzievski's \"Math and Art: An Introduction to Visual Mathematics\" takes a similar approach, looking at suitably visual mathematics topics such as tilings, fractals and hyperbolic geometry.\n\nSome of the first works of computer art were created by Desmond Paul Henry's \"Drawing Machine 1\", an analogue machine based on a bombsight computer and exhibited in 1962. The machine was capable of creating complex, abstract, asymmetrical, curvilinear, but repetitive line drawings. More recently, Hamid Naderi Yeganeh has created shapes suggestive of real world objects such as fish and birds, using formulae that are successively varied to draw families of curves or angled lines. Artists such as Mikael Hvidtfeldt Christensen create works of generative or algorithmic art by writing scripts for a software system such as \"Structure Synth\": the artist effectively directs the system to apply a desired combination of mathematical operations to a chosen set of data.\n\nThe mathematician and theoretical physicist Henri Poincaré's \"Science and Hypothesis\" was widely read by the Cubists, including Pablo Picasso and Jean Metzinger. Poincaré viewed Euclidean geometry as just one of many possible geometric configurations, rather than as an absolute objective truth. The possible existence of a fourth dimension inspired artists to question classical : non-Euclidean geometry became a valid alternative. The concept that painting could be expressed mathematically, in colour and form, contributed to Cubism, the art movement that led to abstract art. Metzinger, in 1910, wrote that: \"[Picasso] lays out a free, mobile perspective, from which that ingenious mathematician Maurice Princet has deduced a whole geometry\". Later, Metzinger wrote in his memoirs:\n\nMaurice Princet joined us often ... it was as an artist that he conceptualized mathematics, as an aesthetician that he invoked \"n\"-dimensional continuums. He loved to get the artists interested in the new views on space that had been opened up by Schlegel and some others. He succeeded at that.\n\nThe impulse to make teaching or research models of mathematical forms naturally creates objects that have symmetries and surprising or pleasing shapes. Some of these have inspired artists such as the Dadaists Man Ray, Marcel Duchamp and Max Ernst, and following Man Ray, Hiroshi Sugimoto.\nMan Ray photographed some of the mathematical models in the Institut Henri Poincaré in Paris, including \"Objet mathematique\" (Mathematical object). He noted that this represented Enneper surfaces with constant negative curvature, derived from the pseudo-sphere. This mathematical foundation was important to him, as it allowed him to deny that the object was \"abstract\", instead claiming that it was as real as the urinal that Duchamp made into a work of art. Man Ray admitted that the object's [Enneper surface] formula \"meant nothing to me, but the forms themselves were as varied and authentic as any in nature.\" He used his photographs of the mathematical models as figures in his series he did on Shakespeare's plays, such as his 1934 painting \"Antony and Cleopatra\". The art reporter Jonathan Keats, writing in \"ForbesLife\", argues that Man Ray photographed \"the elliptic paraboloids and conic points in the same sensual light as his pictures of Kiki de Montparnasse\", and \"ingeniously repurposes the cool calculations of mathematics to reveal the topology of desire\". Twentieth century sculptors such as Henry Moore, Barbara Hepworth and Naum Gabo took inspiration from mathematical models. Moore wrote of his 1938 \"Stringed Mother and Child\": \"Undoubtedly the source of my stringed figures was the Science Museum ... I was fascinated by the mathematical models I saw there ... It wasn't the scientific study of these models but the ability to look through the strings as with a bird cage and to see one form within another which excited me.\"\n\nThe artists Theo van Doesburg and Piet Mondrian founded the De Stijl movement, which they wanted to \"establish a visual vocabulary elementary geometrical forms comprehensible by all and adaptable to any discipline\". Many of their artworks visibly consist of ruled squares and triangles, sometimes also with circles. De Stijl artists worked in painting, furniture, interior design and architecture. After the breakup of De Stijl, Van Doesburg founded the Avant-garde Art Concret movement, describing his 1929–1930 \"Arithmetic Composition\", a series of four black squares on the diagonal of a squared background, as \"a structure that can be controlled, a \"definite\" surface without chance elements or individual caprice\", yet \"not lacking in spirit, not lacking the universal and not ... empty as there is \"everything\" which fits the internal rhythm\". The art critic Gladys Fabre observes that two progressions are at work in the painting, namely the growing black squares and the alternating backgrounds.\n\nThe mathematics of tessellation, polyhedra, shaping of space, and self-reference provided the graphic artist M. C. Escher (1898—1972) with a lifetime's worth of materials for his woodcuts. In the \"Alhambra Sketch\", Escher showed that art can be created with polygons or regular shapes such as triangles, squares, and hexagons. Escher used irregular polygons when tiling the plane and often used reflections, glide reflections, and translations to obtain further patterns. Many of his works contain impossible constructions, made using geometrical objects which set up a contradiction between perspective projection and three dimensions, but are pleasant to the human sight. Escher's \"Ascending and Descending\" is based on the \"impossible staircase\" created by the medical scientist Lionel Penrose and his son the mathematician Roger Penrose.\n\nSome of Escher's many tessellation drawings were inspired by conversations with the mathematician H. S. M. Coxeter on hyperbolic geometry. Escher was especially interested in five specific polyhedra, which appear many times in his work. The Platonic solids—tetrahedrons, cubes, octahedrons, dodecahedrons, and icosahedrons—are especially prominent in \"Order and Chaos\" and \"Four Regular Solids\". These stellated figures often reside within another figure which further distorts the viewing angle and conformation of the polyhedrons and provides a multifaceted perspective artwork.\n\nThe visual intricacy of mathematical structures such as tessellations and polyhedra have inspired a variety of mathematical artworks. Stewart Coffin makes polyhedral puzzles in rare and beautiful woods; George W. Hart works on the theory of polyhedra and sculpts objects inspired by them; Magnus Wenninger makes \"especially beautiful\" models of complex stellated polyhedra.\n\nThe distorted perspectives of anamorphosis have been explored in art since the sixteenth century, when Hans Holbein the Younger incorporated a severely distorted skull in his 1533 painting \"The Ambassadors\". Many artists since then, including Escher, have make use of anamorphic tricks.\n\nThe mathematics of topology has inspired several artists in modern times. The sculptor John Robinson (1935–2007) created works such as \"Gordian Knot\" and \"Bands of Friendship\", displaying knot theory in polished bronze. Other works by Robinson explore the topology of toruses. \"Genesis\" is based on Borromean rings – a set of three circles, no two of which link but in which the whole structure cannot be taken apart without breaking. The sculptor Helaman Ferguson creates complex surfaces and other topological objects. His works are visual representations of mathematical objects; \"The Eightfold Way\" is based on the projective special linear group PSL(2,7), a finite group of 168 elements. The sculptor Bathsheba Grossman similarly bases her work on mathematical structures.\n\nA liberal arts inquiry project examines connections between mathematics and art through the Möbius strip, flexagons, origami and panorama photography.\n\nMathematical objects including the Lorenz manifold and the hyperbolic plane have been crafted using fiber arts including crochet. The American weaver Ada Dietz wrote a 1949 monograph \"Algebraic Expressions in Handwoven Textiles\", defining weaving patterns based on the expansion of multivariate polynomials. The mathematician J. C. P. Miller used the Rule 90 cellular automaton to design tapestries depicting both trees and abstract patterns of triangles. The \"mathekniticians\" Pat Ashforth and Steve Plummer use knitted versions of mathematical objects such as hexaflexagons in their teaching, though their Menger sponge proved too troublesome to knit and was made of plastic canvas instead. Their \"mathghans\" (Afghans for Schools) project introduced knitting into the British mathematics and technology curriculum.\n\nModelling is far from the only possible way to illustrate mathematical concepts. Giotto's \"Stefaneschi Triptych\", 1320, illustrates recursion in the form of \"mise en abyme\"; the central panel of the triptych contains, lower left, the kneeling figure of Cardinal Stefaneschi, holding up the triptych as an offering. Giorgio Chirico's metaphysical paintings such as his 1917 \"Great Metaphysical Interior\" explore the question of levels of representation in art by depicting paintings within his paintings.\n\nArt can exemplify logical paradoxes, as in some paintings by the surrealist René Magritte, which can be read as semiotic jokes about confusion between levels. In \"La condition humaine\" (1933), Magritte depicts an easel (on the real canvas), seamlessly supporting a view through a window which is framed by \"real\" curtains in the painting. Similarly, Escher's \"Print Gallery\" (1956) is a print which depicts a distorted city which contains a gallery which recursively contains the picture, and so \"ad infinitum\". Magritte made use of spheres and cuboids to distort reality in a different way, painting them alongside an assortment of houses in his 1931 \"Mental Arithmetic\" as if they were children's building blocks, but house-sized. \"The Guardian\" observed that the \"eerie toytown image\" prophesied Modernism's usurpation of \"cosy traditional forms\", but also plays with the human tendency to seek patterns in nature.\n\nSalvador Dalí's last painting, \"The Swallow's Tail\" (1983), was part of a series inspired by René Thom's catastrophe theory. The Spanish painter and sculptor Pablo Palazuelo (1916–2007) focused on the investigation of form. He developed a style that he described as the geometry of life and the geometry of all nature. Consisting of simple geometric shapes with detailed patterning and coloring, in works such as \"Angular I\" and \"Automnes\", Palazuelo expressed himself in geometric transformations.\n\nThe artist Adrian Gray practises stone balancing, exploiting friction and the centre of gravity to create striking and seemingly impossible compositions.\n\nArtists, however, do not necessarily take geometry literally. As Douglas Hofstadter writes in his 1980 reflection on human thought, \"Gödel, Escher, Bach\", by way of (among other things) the mathematics of art: \"The difference between an Escher drawing and non-Euclidean geometry is that in the latter, comprehensible interpretations can be found for the undefined terms, resulting in a comprehensible total system, whereas for the former, the end result is not reconcilable with one's conception of the world, no matter how long one stares at the pictures.\" Hofstadter discusses the seemingly paradoxical lithograph \"Print Gallery\" by M. C. Escher; it depicts a seaside town containing an art gallery which seems to contain a painting of the seaside town, there being a \"strange loop, or tangled hierarchy\" to the levels of reality in the image. The artist himself, Hofstadter observes, is not seen; his reality and his relation to the lithograph are not paradoxical. The image's central void has also attracted the interest of mathematicians Bart de Smit and Hendrik Lenstra, who propose that it could contain a Droste effect copy of itself, rotated and shrunk; this would be a further illustration of recursion beyond that noted by Hofstadter.\n\nAlgorithmic analysis of images of artworks, for example using X-ray fluorescence spectroscopy, can reveal information about art. Such techniques can uncover images in layers of paint later covered over by an artist; help art historians to visualize an artwork before it cracked or faded; help to tell a copy from an original, or distinguish the brushstroke style of a master from those of his apprentices.\nJackson Pollock's drip painting style has a definite fractal dimension; among the artists who may have influenced Pollock's controlled chaos, Max Ernst painted Lissajous figures directly by swinging a punctured bucket of paint over a canvas.\n\nThe computer scientist Neil Dodgson investigated whether Bridget Riley's stripe paintings could be characterised mathematically, concluding that while separation distance could \"provide some characterisation\" and global entropy worked on some paintings, autocorrelation failed as Riley's patterns were irregular. Local entropy worked best, and correlated well with the description given by the art critic Robert Kudielka.\n\nThe American mathematician George Birkhoff's 1933 \"Aesthetic Measure\" proposes a quantitative metric of the aesthetic quality of an artwork. It does not attempt to measure the connotations of a work, such as what a painting might mean, but is limited to the \"elements of order\" of a polygonal figure. Birkhoff first combines (as a sum) five such elements: whether there is a vertical axis of symmetry; whether there is optical equilibrium; how many rotational symmetries it has; how wallpaper-like the figure is; and whether there are unsatisfactory features such as having two vertices too close together. This metric, \"O\", takes a value between −3 and 7. The second metric, \"C\", counts elements of the figure, which for a polygon is the number of different straight lines containing at least one of its sides. Birkhoff then defines his aesthetic measure of an object's beauty as \"O/C\". This can be interpreted as a balance between the pleasure looking at the object gives, and the amount of effort needed to take it in. Birkhoff's proposal has been criticized in various ways, not least for trying to put beauty in a formula, but he never claimed to have done that.\n\nArt has sometimes stimulated the development of mathematics, as when Brunelleschi's theory of perspective in architecture and painting started a cycle of research that led to the work of Brook Taylor and Johann Heinrich Lambert on the mathematical foundations of perspective drawing, and ultimately to the mathematics of projective geometry of Girard Desargues and Jean-Victor Poncelet.\n\nThe Japanese paper-folding art of origami has been reworked mathematically by Tomoko Fusé using modules, congruent pieces of paper such as squares, and making them into polyhedra or tilings. Paper-folding was used in 1893 by T. Sundara Rao in his \"Geometric Exercises in Paper Folding\" to demonstrate geometrical proofs. The mathematics of paper folding has been explored in Maekawa's theorem, Kawasaki's theorem, and the Huzita–Hatori axioms.\n\nOptical illusions such as the Fraser spiral strikingly demonstrate limitations in human visual perception, creating what the art historian Ernst Gombrich called a \"baffling trick.\" The black and white ropes that appear to form spirals are in fact concentric circles. The mid-twentieth century Op art or optical art style of painting and graphics exploited such effects to create the impression of movement and flashing or vibrating patterns seen in the work of artists such as Bridget Riley, Spyros Horemis, and Victor Vasarely.\n\nA strand of art from Ancient Greece onwards sees God as the geometer of the world, and the world's geometry therefore as sacred. The belief that God created the universe according to a geometric plan has ancient origins. Plutarch attributed the belief to Plato, writing that \"Plato said God geometrizes continually\" (\"Convivialium disputationum\", liber 8,2). This image has influenced Western thought ever since. The Platonic concept derived in its turn from a Pythagorean notion of harmony in music, where the notes were spaced in perfect proportions, corresponding to the lengths of the lyre's strings; indeed, the Pythagoreans held that everything was arranged by Number. In the same way, in Platonic thought, the regular or Platonic solids dictate the proportions found in nature, and in art. A Mediaeval manuscript illustration may refer to a verse in the Old Testament: \"When he established the heavens I was there: when he set a compass upon the face of the deep\" (Proverbs 8:27), showing God drawing out the universe with a pair of compasses. In 1596, the mathematical astronomer Johannes Kepler modelled the universe as a set of nested Platonic solids, determining the relative sizes of the orbits of the planets. William Blake's \"Ancient of Days\" and his painting of the physicist Isaac Newton, naked and drawing with a compass, attempt to depict the contrast between the mathematically perfect spiritual world and the imperfect physical world, as in a different way does Salvador Dalí's 1954 \"Crucifixion (Corpus Hypercubus)\", which depicts the cross as a hypercube, representing the divine perspective with four dimensions rather than the usual three. In Dali's \"The Sacrament of the Last Supper\" (1955) Christ and his disciples are pictured inside a giant dodecahedron.\n\n\n"}
{"id": "5106151", "url": "https://en.wikipedia.org/wiki?curid=5106151", "title": "Metatheorem", "text": "Metatheorem\n\nIn logic, a metatheorem is a statement about a formal system proven in a metalanguage. Unlike theorems proved within a given formal system, a metatheorem is proved within a metatheory, and may reference concepts that are present in the metatheory but not the object theory.\n\nA formal system is determined by a formal language and a deductive system (axioms and rules of inference). The formal system can be used to prove particular sentences of the formal language with that system. Metatheorems, however, are proved externally to the system in question, in its metatheory. Common metatheories used in logic are set theory (especially in model theory) and primitive recursive arithmetic (especially in proof theory). Rather than demonstrating particular sentences to be provable, metatheorems may show that each of a broad class of sentences can be proved, or show that certain sentences cannot be proved.\n\nExamples of metatheorems include:\n\n\n\n"}
{"id": "1661158", "url": "https://en.wikipedia.org/wiki?curid=1661158", "title": "Mughal architecture", "text": "Mughal architecture\n\n\"Mughal Architecture\" is the type of Indo-Islamic architecture developed by the Mughals in the 16th, 17th and 18th centuries throughout the ever-changing extent of their empire in the Indian subcontinent. It developed the styles of earlier Muslim dynasties in India as an amalgam of Islamic, Persian, Turkish and Indian architecture. Mughal buildings have a uniform pattern of structure and character, including large bulbous domes, slender minarets at the corners, massive halls, large vaulted gateways and delicate ornamentation. Examples of the style can be found in India, Afghanistan, Bangladesh and Pakistan.\n\nThe Mughal dynasty was established after the victory of Babur at Panipat in 1526. During his five-year reign, Babur took considerable interest in erecting buildings, though few have survived. His grandson Akbar built widely, and the style developed vigorously during his reign. Among his accomplishments were Agra Fort, the fort-city of Fatehpur Sikri, and the Buland Darwaza. Akbar's son Jahangir commissioned the Shalimar Gardens in Kashmir.\n\nMughal architecture reached its zenith during the reign of Shah Jahan, who constructed the Taj Mahal, the Jama Masjid, the Red Fort, and the Shalimar Gardens in Lahore. The end of his reign corresponded with the decline of Mughal architecture and the Empire itself.\n\nAgra fort is a UNESCO world heritage site in Agra, Uttar Pradesh. The major part of Agra fort was built by Akbar The Great during 1565 to 1574. The architecture of the fort clearly indicates the free adoption of the Rajput planning and construction. Some of the important buildings in the fort are Jahangiri Mahal built for Jahangir and his family, the Moti Masjid, and Mena Bazaars. The Jahangir Mahal is an impressive structure and has a courtyard surrounded by double-storeyed halls and rooms.\n\nHumayun's tomb is the tomb of the Mughal Emperor Humayun in Delhi, India. The tomb was commissioned by Humayun's first wife and chief consort, Empress Bega Begum (also known as Haji Begum), in 1569-70, and designed by Mirak Mirza Ghiyas and his son, Sayyid Muhammad, Persian architects chosen by her. It was the first garden-tomb on the Indian subcontinent. It is often regarded as the first mature example of Mughal architecture.\n\nAkbar’s greatest architectural achievement was the construction of Fatehpur Sikri, his capital city near Agra at a trade and Jain pilgrimage. The construction of the walled city was started in 1569 and completed in 1574.\n\nIt contained some of the most beautiful buildings – both religious and secular which testify to the Emperor’s aim of achieving social, political and religious integration. The main religious buildings were the huge Jama Masjid and small tomb of Salim Chisti. The tomb, built in 1571 in the corner of the mosque compound, is a square marble chamber with a verandah. The cenotaph has an exquisitely designed lattice screen around it. Buland Darwaza, also known as the Gate of Magnificence, was built by Akbar in 1576 to commemorate his victory over Gujarat and the Deccan. It is 40 metres high and 50 metres from the ground. The total height of the structure is about 54 metres from ground level...\n\nThe Haramsara, the royal seraglio in Fatehpur Sikri was an area where the royal women lived. The opening to the Haramsara is from the Khwabgah side separated by a row of cloiters. According to Abul Fazl, in Ain-i-Akbari, the inside of Harem was guarded by senior and active women, outside the enclosure the eunuchs were placed, and at a proper distance there were faithful Rajput guards.\n\nThis is the largest palace in the Fatehpur Sikri seraglio, connected to the minor \"haramsara\" (where the less important harem ladies and maids would have resided) quarters. The main entrance is double storied, projecting out of the facade to create a kind of porch leading into a recessed entrance with a balcony. Inside there is a quadrangle surrounded by rooms. The columns of rooms are ornamented with a variety of Hindu sculptural motifs. \nThe glazed tiles on the roofs from Multan have an eye catching shade of turquoise. The mosque was built in honour of Jodha Bai, mother of Jahangir and wife of Akbar. Her Mughal name was Mariyam Zamani Begum and this being the reason that the mosque was built in her honor in Lahore’s walled city. Jahangir built his mother Mariyam Zamani Begum’s mosque and is just 1 km away from the tomb of Akbar near Agra at a place called Sikandra.\n\nBuland Darwaza dominates the landscape. Historian `Abd al-Qadir Bada'uni writes that it was the highest gateway in Hindustan at that time until today.\n\nA chronogram is inscribed on the central archway composed by Ashraf Khan, one of Akbar's principal secretaries that reads,\nThe Tomb of Sheikh Salim Chishti is famed as one of the finest examples of Mughal architecture in India, built during the years 1580 and 1581, along with the imperial complex at Situated near Zenana Rauza and facing south towards Buland Darwaza, within the quadrangle of the Jama Masjid which measures 350 ft. by 440 ft. It enshrines the burial place of the Sufi saint, Salim Chisti (1478 – 1572), a descendant of Khwaja Moinuddin Chishti of Ajmer, and lived in a cavern on the ridge at Sikri. The mausoleum, constructed by Akbar as a mark of his respect for the Sufi saint, who foretold the birth of his son, who was named Prince Salim after him and later succeeded Akbar to the throne of the Mughal Empire.\n\nThe Wazir Khan Mosque in Lahore was commissioned during the reign of Shah Jahan, and is famous for its rich embellishment which covers almost every interior surface.\nRather than building a huge monuments like his predecessors to demonstrate their power, Shah Jahan built elegant monuments. The force and originality of this previous building style gave way under Shah Jahan to a delicate elegance and refinement of detail, illustrated in the palaces erected during his reign at Agra, Delhi and Lahore. Some examples include the Taj Mahal at Agra, the tomb of his wife Mumtaz Mahal. The Moti Masjid (Pearl Mosque) in the Lahore Fort and the Jama Masjid at Delhi are imposing buildings of his era, and their position and architecture have been carefully considered so as to produce a pleasing effect and feeling of spacious elegance and well-balanced proportion of parts. Shah Jahan also built sections of the Sheesh Mahal, and Naulakha pavilion, which are all enclosed in the fort. He also built a mosque named after himself in Thatta called Shahjahan Mosque. Shah Jahan also built the Red Fort in his new capital at Shah Jahanabad, now Delhi. The red sandstone Red Fort is noted for its special buildings-Diwan-i-Aam and Diwan-i-Khas. Another mosque was built during his tenure in Lahore called Wazir Khan Mosque, by Shaikh Ilm-ud-din Ansari who was the court physician to the emperor.\n\nThe Taj Mahal, a World Heritage Site described as the \"teardrop on the cheek of time\" by Rabindranath Tagore, was built between 1630–49 by the emperor Shah Jahan in memory of his wife Mumtaz Mahal.(Mumtaz died after her 14th delivery). Its construction took 22 years and required 22,000 laborers and 1,000 elephants. Built entirely of white marble at a cost of $1018200000, it is one of the New7Wonders of the World. The building's longest plane of symmetry runs through the entire complex except for the sarcophagus of Shah Jahan, which is placed off centre in the crypt room below the main floor. This symmetry is extended to the building of an entire mirror mosque in red sandstone, to complement the Mecca-facing mosque placed to the west of the main structure. Shah Jahan used \"pietra dura\", a method of decoration on a large scale-inlaid work of jewels.\n\nThe Wazir Khan Masjid was commissioned during the reign of the Mughal Emperor Shah Jahan in 1634, and completed in 1642. Considered to be the most ornately decorated Mughal-era mosque. Wazir Khan Masjid is renowned for its intricate faience tile work known as \"kashi-kari\", as well as its interior surfaces that are almost entirely embellished with elaborate Mughal-era frescoes. The mosque has been under extensive restoration since 2009 under the direction of the Aga Khan Trust for Culture and the Government of Punjab.\n\nThe Shalimar Gardens (1641–1642) built on the orders of Bahadur Shah Zafar in Lahore, Pakistan, is also on the UNESCO world heritage list.\n\nThe Shah Jahan Mosque is the central mosque for the city of Thatta, in the Pakistani province of Sindh. The mosque commissioned by Shah Jahan, who bestowed it to the city as a token of gratitude. Its style is heavily influenced by Central Asian Timurid architecture, which was introduced after Shah Jahan's campaigns near Balkh and Samarkand. The mosque is considered to have the most elaborate display of tile work in South Asia, and is also notable for its geometric brick work - a decorative element that is unusual for Mughal-period mosques.\n\nIn Aurangzeb's reign (1658–1707) squared stone and marble was replaced by brick or rubble with stucco ornament. Srirangapatna and Lucknow have examples of later Indo-Mughal architecture. He made additions to the Lahore Fort and also built one of the thirteen gates which was later named after him (Alamgir).\n\nThe Badshahi Masjid in Lahore, Pakistan was commissioned by the sixth Mughal Emperor Aurangzeb. Constructed between 1671 and 1673, it was the largest mosque in the world upon construction. It is the third largest mosque in Pakistan and the seventh largest mosque in the world. The mosque is adjacent to the Lahore Fort and is the last in the series of congregational mosques in red sandstone. The red sandstone of the walls contrasts with the white marble of the domes and the subtle intarsia decoration. Aurangzeb's mosque's architectural plan is similar to that of his father, Shah Jahan, the Jama Masjid in Delhi; though it is much larger. It also functions as an \"idgah\". The courtyard which spreads over 276,000 square feet, can accommodate one hundred thousand worshippers; ten thousand can be accommodated inside the mosque. The minarets are tall. The Mosque is one of the most famous Mughal structures, but suffered greatly under the reign of Maharaja Ranjit Singh. In 1993, the Government of Pakistan included the Badshahi Mosque in the tentative list for UNESCO World Heritage Site.\n\nAdditional monuments from this period are associated with women from Aurangzeb's imperial family. The construction of the elegant Zinat al-Masjid in Daryaganj was overseen by Aurangzeb's second daughter Zinat-al-Nissa. Aurangzeb's sister Roshan-Ara who died in 1671. The tomb of Roshanara Begum and the garden surrounding it were neglected for a long time and are now in an advanced state of decay. Bibi Ka Maqbara was a mausoleum built by Prince Azam Shah, son of Emperor Aurangzeb, in the late 17th century as a loving tribute to his mother, Dilras Bano Begam in Aurangabad, Maharashtra. The Alamgiri Gate, built in 1673, is the main entrance to the Lahore Fort in present-day Lahore. It was constructed to face west towards the Badshahi Mosque in the days of the Mughal Emperor Aurangzeb.\n\nAnother construction of the Mughal era is Lalbagh Fort (also known as \"Fort Aurangabad\"), a Mughal palace fortress at the Buriganga River in the southwestern part of Dhaka, Bangladesh, whose construction started in 1678 during the reign of Aurangzeb.\n\nMughal gardens are gardens built by the Mughals in the Islamic style of architecture. This style was influenced by Persian gardens and Timurid gardens. Significant use of rectilinear layouts are made within the walled enclosures. Some of the typical features include pools, fountains and canals inside the gardens. The famous gardens are the Char Bagh gardens at Taj Mahal, gardens at Humayun's Tomb Shalimar Gardens of Lahore, Delhi and Kashmir as well as Pinjore Garden in Haryana.\n\nShahi Bridge, Jaunpur was constructed during the reign of the Mughal Emperor Akbar.\n\n"}
{"id": "31187897", "url": "https://en.wikipedia.org/wiki?curid=31187897", "title": "Mumford's compactness theorem", "text": "Mumford's compactness theorem\n\nIn mathematics, Mumford's compactness theorem states that the space of compact Riemann surfaces of fixed genus \"g\" > 1 with no closed geodesics of length less than some fixed \"ε\" > 0 in the Poincaré metric is compact. It was proved by as a consequence of a theorem about the compactness of sets of discrete subgroups of semisimple Lie groups generalizing Mahler's compactness theorem.\n"}
{"id": "6306271", "url": "https://en.wikipedia.org/wiki?curid=6306271", "title": "Outline of logic", "text": "Outline of logic\n\nLogic is the formal science of using reason and is considered a branch of both philosophy and mathematics. Logic investigates and classifies the structure of statements and arguments, both through the study of formal systems of inference and the study of arguments in natural language. The scope of logic can therefore be very large, ranging from core topics such as the study of fallacies and paradoxes, to specialized analyses of reasoning such as probability, correct reasoning, and arguments involving causality. One of the aims of logic is to identify the correct (or valid) and incorrect (or fallacious) inferences. Logicians study the criteria for the evaluation of arguments.\n\nPhilosophy of logic\n\nPhilosophical logic\n\nInformal logic\nCritical thinking\nArgumentation theory\n\n\n\n\n\nLogical connective\n\n\nProposition\n\nRule of inference  (list)\n\n\nObject language\n\nMetalanguage\n\nPropositional logic\n\n\nPredicate logic\n\n\nMathematical relation\n\nMathematical logic\n\nSet theory  (list)\n\nMetalogic – The study of the metatheory of logic.\n\nProof theory – The study of deductive apparatus.\n\nModel theory – The study of interpretation of formal systems.\n\nComputability theory – branch of mathematical logic that originated in the 1930s with the study of computable functions and Turing degrees. The field has grown to include the study of generalized computability and definability. The basic questions addressed by recursion theory are \"What does it mean for a function from the natural numbers to themselves to be computable?\" and \"How can noncomputable functions be classified into a hierarchy based on their level of noncomputability?\". The answers to these questions have led to a rich theory that is still being actively researched.\n\nClassical logic\n\nNon-classical logic\n\n\nModal logic\n\nMathematical logic –\n\nHistory of logic\n\n\n\n\n\n\n"}
{"id": "43844668", "url": "https://en.wikipedia.org/wiki?curid=43844668", "title": "Princeton Lectures in Analysis", "text": "Princeton Lectures in Analysis\n\nThe Princeton Lectures in Analysis is a series of four mathematics textbooks, each covering a different area of mathematical analysis. They were written by Elias M. Stein and Rami Shakarchi and published by Princeton University Press between 2003 and 2011. They are, in order, \"Fourier Analysis: An Introduction\"; \"Complex Analysis\"; \"Real Analysis: Measure Theory, Integration, and Hilbert Spaces\"; and \"Functional Analysis: Introduction to Further Topics in Analysis\".\n\nStein and Shakarchi wrote the books based on a sequence of intensive undergraduate courses Stein began teaching in the spring of 2000 at Princeton University. At the time Stein was a mathematics professor at Princeton and Shakarchi was a graduate student in mathematics. Though Shakarchi graduated in 2002, the collaboration continued until the final volume was published in 2011. The series emphasizes the unity among the branches of analysis and the applicability of analysis to other areas of mathematics.\n\nThe \"Princeton Lectures in Analysis\" has been identified as a well written and influential series of textbooks, suitable for advanced undergraduates and beginning graduate students in mathematics.\n\nThe first author, Elias M. Stein, is a mathematician who has made significant research contributions to the field of mathematical analysis. Before 2000 he had authored or co-authored several influential advanced textbooks on analysis.\n\nBeginning in the spring of 2000, Stein taught a sequence of four intensive undergraduate courses in analysis at Princeton University, where he was a mathematics professor. At the same time he collaborated with Rami Shakarchi, then a graduate student in Princeton's math department studying under Charles Fefferman, to turn each of the courses into a textbook. Stein taught Fourier analysis in that first semester, and by the fall of 2000 the first manuscript was nearly finished. That fall Stein taught the course in complex analysis while he and Shakarchi worked on the corresponding manuscript. Paul Hagelstein, then a postdoctoral scholar in the Princeton math department, was a teaching assistant for this course. In spring 2001, when Stein moved on to the real analysis course, Hagelstein started the sequence anew, beginning with the Fourier analysis course. Hagelstein and his students used Stein and Shakarchi's drafts as texts, and they made suggestions to the authors as they prepared the manuscripts for publication. The project received financial support from Princeton University and from the National Science Foundation.\n\nShakarchi earned his Ph.D. from Princeton in 2002 and moved to London to work in finance. Nonetheless he continued working on the books, even as his employer, Lehman Brothers, collapsed in 2008. The first two volumes were published in 2003. The third followed in 2005, and the fourth in 2011. Princeton University Press published all four.\n\nThe volumes are split into seven to ten chapters each. Each chapter begins with an epigraph providing context for the material and ends with a list of challenges for the reader, split into Exercises, which range in difficulty, and more difficult Problems. Throughout the authors emphasize the unity among the branches of analysis, often referencing one branch within another branch's book. They also provide applications of the theory to other fields of mathematics, particularly partial differential equations and number theory.\n\n\"Fourier Analysis\" covers the discrete, continuous, and finite Fourier transforms and their properties, including inversion. It also presents applications to partial differential equations, Dirichlet's theorem on arithmetic progressions, and other topics. Because Lebesgue integration is not introduced until the third book, the authors use Riemann integration in this volume. They begin with Fourier analysis because of its central role within the historical development and contemporary practice of analysis.\n\n\"Complex Analysis\" treats the standard topics of a course in complex variables as well as several applications to other areas of mathematics. The chapters cover the complex plane, Cauchy's integral theorem, meromorphic functions, connections to Fourier analysis, entire functions, the gamma function, the Riemann zeta function, conformal maps, elliptic functions, and theta functions.\n\n\"Real Analysis\" begins with measure theory, Lebesgue integration, and differentiation in Euclidean space. It then covers Hilbert spaces before returning to measure and integration in the context of abstract measure spaces. It concludes with a chapter on Hausdorff measure and fractals.\n\n\"Functional Analysis\" has chapters on several advanced topics in analysis: L spaces, distributions, the Baire category theorem, probability theory including Brownian motion, several complex variables, and oscillatory integrals.\n\nThe books \"received rave reviews indicating they are all outstanding works written with remarkable clarity and care.\" Reviews praised the exposition, identified the books as accessible and informative for advanced undergraduates or graduate math students, and predicted they would grow in influence as they became standard references for graduate courses. William Ziemer wrote that the third book omitted material he expected to see in an introductory graduate text but nonetheless recommended it as a reference.\n\nPeter Duren compared Stein and Shakarchi's attempt at a unified treatment favorably with Walter Rudin's textbook \"Real and Complex Analysis\", which Duren calls too terse. On the other hand, Duren noted that this sometimes comes at the expense of topics that reside naturally within only one branch. He mentioned in particular geometric aspects of complex analysis covered in Lars Ahlfors's textbook but noted that Stein and Shakarchi also treat some topics Ahlfors skips.\n\n\n"}
{"id": "3909097", "url": "https://en.wikipedia.org/wiki?curid=3909097", "title": "Projection (mathematics)", "text": "Projection (mathematics)\n\nIn mathematics, a projection is a mapping of a set (or other mathematical structure) into a subset (or sub-structure), which is equal to its square for mapping composition (or, in other words, which is idempotent). The restriction to a subspace of a projection is also called a \"projection\", even if the idempotence property is lost.\nAn everyday example of a projection is the casting of shadows onto a plane (paper sheet). The projection of a point is its shadow on the paper sheet. The shadow of a point on the paper sheet is this point itself (idempotence). The shadow of a three-dimensional sphere is a closed disk. Originally, the notion of projection was introduced in Euclidean geometry to denote the projection of the Euclidean space of three dimensions onto a plane in it, like the shadow example. The two main projections of this kind are: \n\nThe concept of projection in mathematics is a very old one, most likely having its roots in the phenomenon of the shadows cast by real world objects on the ground. This rudimentary idea was refined and abstracted, first in a geometric context and later in other branches of mathematics. Over time differing versions of the concept developed, but today, in a sufficiently abstract setting, we can unify these variations.\n\nIn cartography, a map projection is a map of a part of the surface of the Earth onto a plane, which, in some cases, but not always, is the restriction of a projection in the above meaning. The 3D projections are also at the basis of the theory of perspective. \n\nThe need for unifying the two kinds of projections and of defining the image by a central projection of any point different of the center of projection are at the origin of projective geometry. However, a projective transformation is a bijection of a projective space, a property \"not\" shared with the \"projections\" of this article.\n\nIn an abstract setting we can generally say that a \"projection\" is a mapping of a set (or of a mathematical structure) which is idempotent, which means that a projection is equal to its composition with itself. A projection may also refer to a mapping which has a right inverse. Both notions are strongly related, as follows. Let \"p\" be an idempotent map from a set \"A\" into itself (thus \"p\"∘\"p\" = \"p\") and \"B\" = \"p\"(\"A\") be the image of \"p\". If we denote by π the map \"p\" viewed as a map from \"A\" onto \"B\" and by \"i\" the injection of \"B\" into \"A\", then we have π.\"i\"= Id. Conversely, π.\"i\" = Id implies that π∘\"i\" is idempotent.\n\nThe original notion of projection has been extended or generalized to various mathematical situations, frequently, but not always, related to geometry, for example:\n\n\n\n\n\n\n\n\n\n"}
{"id": "38943054", "url": "https://en.wikipedia.org/wiki?curid=38943054", "title": "Restricted root system", "text": "Restricted root system\n\nIn mathematics, restricted root systems, sometimes called relative root systems, are the root systems associated with a symmetric space. The associated finite reflection group is called the restricted Weyl group. The restricted root system of a symmetric space and its dual can be identified. For symmetric spaces of noncompact type arising as homogeneous spaces of a semisimple Lie group, the restricted root system and its Weyl group are related to the Iwasawa decomposition of the Lie group.\n\n\n"}
{"id": "26513", "url": "https://en.wikipedia.org/wiki?curid=26513", "title": "Reverse Polish notation", "text": "Reverse Polish notation\n\nReverse Polish notation (RPN), also known as Polish postfix notation or simply postfix notation, is a mathematical notation in which operators follow their operands, in contrast to Polish notation (PN), in which operators precede their operands. It does not need any parentheses as long as each operator has a fixed number of operands. The description \"Polish\" refers to the nationality of logician Jan Łukasiewicz, who invented this notation in 1924.\n\nThe reverse Polish scheme was proposed in 1954 by Arthur Burks, Don Warren, and Jesse Wright and was independently reinvented by Friedrich L. Bauer and Edsger W. Dijkstra in the early 1960s to reduce computer memory access and utilize the stack to evaluate expressions. The algorithms and notation for this scheme were extended by Australian philosopher and computer scientist Charles L. Hamblin in the mid-1950s.\n\nDuring the 1970s and 1980s, Hewlett-Packard used RPN in all of their desktop and hand-held calculators, and continued to use it in some into the 2010's. In computer science, reverse Polish notation is used in stack-oriented programming languages such as Forth and PostScript.\n\nMost of what follows is about binary operators. An example of a unary operator whose standard notation may be interpreted as reverse Polish notation is the factorial, \"\"n\"!\".\n\nIn reverse Polish notation, the operators follow their operands; for instance, to add 3 and 4, one would write rather than . If there are multiple operations, operators are given immediately after their second operands; so the expression written in conventional notation would be written in reverse Polish notation: 4 is first subtracted from 3, then 5 is added to it. An advantage of reverse Polish notation is that it removes the need for parentheses that are required by infix notation. While can also be written , that means something quite different from . In reverse Polish notation, the former could be written , which unambiguously means which reduces to ; the latter could be written (or , if keeping similar formatting), which unambiguously means .\n\nIn comparison testing of reverse Polish notation with algebraic notation, reverse Polish has been found to lead to faster calculations, for two reasons. Because reverse Polish calculators do not need expressions to be parenthesized, fewer operations need to be entered to perform typical calculations. Additionally, users of reverse Polish calculators made fewer mistakes than for other types of calculator. Later research clarified that the increased speed from reverse Polish notation may be attributed to the smaller number of keystrokes needed to enter this notation, rather than to a smaller cognitive load on its users. However, anecdotal evidence suggests that reverse Polish notation is more difficult for users to learn than algebraic notation.\n\nThe following algorithm evaluates postfix expressions using a stack, with the expression processed from left to right:\n\nThe following algorithm produces the same results of the previous one, but the expression is processed from right to left:\n\nThe infix expression can be written like this in reverse Polish notation:\n\n\n\nThe following table shows the state of the operand stack at each stage of the above left-to-right algorithm:\n\nThe above example could be rewritten by following the \"chain calculation\" method described by HP for their series of reverse Polish notation calculators:\nAs was demonstrated in the Algebraic mode, it is usually easier (fewer keystrokes) in working a problem like this to begin with the arithmetic operations inside the parentheses first.\n\nEdsger Dijkstra invented the shunting-yard algorithm to convert infix expressions to postfix expressions (reverse Polish notation), so named because its operation resembles that of a railroad shunting yard.\n\nThere are other ways of producing postfix expressions from infix expressions. Most operator-precedence parsers can be modified to produce postfix expressions; in particular, once an abstract syntax tree has been constructed, the corresponding postfix expression is given by a simple post-order traversal of that tree.\n\nThe first computers to implement architectures enabling reverse Polish notation were the English Electric Company's KDF9 machine, which was announced in 1960 and delivered (i.e. made available commercially) in 1963, and the American Burroughs B5000, announced in 1961 and also delivered in 1963. One of the designers of the B5000, Robert S. Barton, later wrote that he developed reverse Polish notation independently of Hamblin sometime in 1958 after reading a 1954 textbook on symbolic logic by Irving Copi, where he found a reference to Polish notation, which made him read the works of Jan Łukasiewicz as well, and before he was aware of Hamblin's work. Designed by Robert \"Bob\" Appleby Ragen, Friden introduced reverse Polish notation to the desktop calculator market with the EC-130 supporting a four-level stack in June 1963. The successor EC-132 added a square root function in April 1965. Around 1966, the Monroe Epic calculator supported an unnamed input scheme resembling RPN as well.\n\nHewlett-Packard engineers designed the 9100A Desktop Calculator in 1968 with reverse Polish notation with only three stack levels, a reverse Polish notation variant later referred to as \"three-level RPN\". This calculator popularized reverse Polish notation among the scientific and engineering communities. The HP-35, the world's first handheld scientific calculator, introduced the classical \"four-level RPN\" in 1972. HP used reverse Polish notation on every handheld calculator it sold, whether scientific, financial, or programmable, until it introduced the HP-10 adding machine calculator in 1977. By this time, HP was the leading manufacturer of calculators for professionals, including engineers and accountants.\n\nLater LCD-based calculators in the early 1980s such as the HP-10C, HP-11C, HP-15C, HP-16C, and the financial calculator, the HP-12C also used reverse Polish notation. In 1988, Hewlett-Packard introduced a business calculator, the HP-19B, without reverse Polish notation, but its 1990 successor, the HP-19BII, gave users the option of using algebraic notation or reverse Polish notation.\n\nAround 1987, HP introduced RPL, an object-oriented successor to reverse Polish notation. It deviates from classical reverse Polish notation by utilizing a stack only limited by the amount of available memory (instead of three or four fixed levels) and which can hold all kinds of data objects (including symbols, strings, lists, matrices, graphics, programs, etc.) instead of just numbers. It also changed the behaviour of the stack to no longer duplicate the top register on drops (since in an unlimited stack there is no longer a top register) and the behaviour of the key so that it no longer duplicates values into Y under certain conditions, both part of the specific ruleset of the so-called \"automatic memory stack\" or \"operational (memory) stack\" in classical reverse Polish notation in order to ease some calculations and to save keystrokes, but which had shown to also sometimes cause confusion among users not familiar with these properties. From 1990 to 2003 HP manufactured the HP-48 series of graphing RPL calculators and in 2006 introduced the HP 50g.\n\nAs of 2011, Hewlett-Packard was offering the calculator models 12C, 12C Platinum, 17bII+, 20b, 30b, 33s, 35s, 48gII (RPL) and 50g (RPL) which support reverse Polish notation. While calculators emulating classical models continue to support classical reverse Polish notation, new reverse Polish notation models feature a variant of reverse Polish notation, where the key behaves as in RPL. This latter variant is sometimes known as \"entry RPN\". In 2013, the HP Prime introduced a \"128-level\" form of entry RPN called \"advanced RPN\". By late 2017, only the 12C, 12C Platinum, 17bii+, 35s and Prime remain active HP models supporting reverse Polish notation.\n\nThe community-developed calculators WP 31S and WP 34S, which are based on the HP 20b/HP 30b hardware platform, support Hewlett-Packard-style classical reverse Polish notation with either a four- or an eight-level stack. A seven-level stack had been implemented in the MITS 7400C scientific desktop calculator in 1972 and an eight-level stack was already suggested by John A. Ball in 1978.\n\nIn Britain, Clive Sinclair's Sinclair Scientific and Scientific Programmable models used reverse Polish notation.\n\nIn 1974 Commodore produced the Minuteman *6 (MM6) without key and the Minuteman *6X (MM6X) with key, both implementing a form of \"two-level RPN\". The SR4921 RPN came with a variant of \"four-level RPN\" with stack levels named X, Y, Z, and W (rather than T). In contrast to Hewlett-Packard's reverse Polish notation implementation, W filled with 0 instead of its contents being duplicated on stack drops.\n\nPrinz and Prinztronic were own-brand trade names of the British Dixons photographic and electronic goods stores retail chain, which was later rebranded as Currys Digital stores, and became part of DSG International. A variety of calculator models was sold in the 1970s under the Prinztronic brand, all made for them by other companies.\n\nAmong these was the PROGRAM Programmable Scientific Calculator which featured reverse Polish notation.\n\nThe Aircraft Navigation Computer Heathkit OC-1401/OCW-1401 used \"five-level RPN\" in 1978.\n\nSoviet programmable calculators (MK-52, MK-61, B3-34 and earlier B3-21 models) used reverse Polish notation for both automatic mode and programming. Modern Russian calculators MK-161 and MK-152, designed and manufactured in Novosibirsk since 2007 and offered by Semico, are backward compatible with them. Their extended architecture is also based on reverse Polish notation.\n\nExisting implementations using reverse Polish notation include:\n\n\n\n"}
{"id": "59545", "url": "https://en.wikipedia.org/wiki?curid=59545", "title": "Sagrada Família", "text": "Sagrada Família\n\nThe (; ; ) is a large unfinished Roman Catholic church in Barcelona, designed by Catalan architect Antoni Gaudí (1852–1926). Gaudí's work on the building is part of a UNESCO World Heritage Site, and in November 2010 Pope Benedict XVI consecrated and proclaimed it a minor basilica, as distinct from a cathedral, which must be the seat of a bishop.\n\nIn 1882, construction of Sagrada Família started under architect Francisco de Paula del Villar. In 1883, when Villar resigned, Gaudí took over as chief architect, transforming the project with his architectural and engineering style, combining Gothic and curvilinear Art Nouveau forms. Gaudí devoted the remainder of his life to the project, and he is buried in the crypt. At the time of his death at age 73 in 1926, when he was run down by a streetcar, less than a quarter of the project was complete.\n\nRelying solely on private donations, Sagrada Familia's construction progressed slowly and was interrupted by the Spanish Civil War, only to resume intermittent progress in the 1950s. Since commencing construction in 1882, advancements in technologies such as computer aided design and computerised numerical control (CNC) have enabled faster progress and construction passed the midpoint in 2010. However, some of the project's greatest challenges remain, including the construction of ten more spires, each symbolising an important Biblical figure in the New Testament. It is anticipated that the building can be completed by 2026—the centenary of Gaudí's death. \n\nThe basilica has a long history of dividing the citizens of Barcelona: over the initial possibility it might compete with Barcelona's cathedral, over Gaudí's design itself, over the possibility that work after Gaudí's death disregarded his design, and the 2007 proposal to build an underground tunnel of Spain's high-speed rail link to France which could disturb its stability. Describing Sagrada Família, art critic Rainer Zerbst said \"it is probably impossible to find a church building anything like it in the entire history of art\", and Paul Goldberger describes it as \"the most extraordinary personal interpretation of Gothic architecture since the Middle Ages\".\n\nThe Basilica of the Sagrada Família was the inspiration of a bookseller, Josep Maria Bocabella, founder of Asociación Espiritual de Devotos de San José (Spiritual Association of Devotees of St. Joseph).\n\nAfter a visit to the Vatican in 1872, Bocabella returned from Italy with the intention of building a church inspired by the basilica at Loreto. The apse crypt of the church, funded by donations, was begun 19 March 1882, on the festival of St. Joseph, to the design of the architect Francisco de Paula del Villar, whose plan was for a Gothic revival church of a standard form. The apse crypt was completed before Villar's resignation on 18 March 1883, when Gaudí assumed responsibility for its design, which he changed radically. Antoni Gaudí began work on the church in 1883 but was not appointed Architect Director until 1884.\n\nOn the subject of the extremely long construction period, Gaudí is said to have remarked: \"My client is not in a hurry.\" When Gaudí died in 1926, the basilica was between 15 and 25 percent complete. After Gaudí's death, work continued under the direction of Domènec Sugrañes i Gras until interrupted by the Spanish Civil War in 1936.\n\nParts of the unfinished basilica and Gaudí's models and workshop were destroyed during the war by Catalan anarchists. The present design is based on reconstructed versions of the plans that were burned in a fire as well as on modern adaptations. Since 1940 the architects Francesc Quintana, Isidre Puig Boada, Lluís Bonet i Gari and Francesc Cardoner have carried on the work. The illumination was designed by Carles Buïgas.\nThe current director and son of Lluís Bonet, Jordi Bonet i Armengol, has been introducing computers into the design and construction process since the 1980s. Mark Burry of New Zealand serves as Executive Architect and Researcher. Sculptures by J. Busquets, Etsuro Sotoo and the controversial Josep Maria Subirachs decorate the fantastical façades. Barcelona-born Jordi Fauli took over as chief architect in 2012.\n\nThe central nave vaulting was completed in 2000 and the main tasks since then have been the construction of the transept vaults and apse. , work concentrated on the crossing and supporting structure for the main tower of Jesus Christ as well as the southern enclosure of the central nave, which will become the Glory façade.\n\nThe church shares its site with the Sagrada Família Schools building, a school originally designed by Gaudí in 1909 for the children of the construction workers. Relocated in 2002 from the eastern corner of the site to the southern corner, the building now houses an exhibition.\n\nChief architect Jordi Fauli announced in October 2015 that construction is 70 percent complete and has entered its final phase of raising six immense towers. The towers and most of the church's structure are to be completed by 2026, the centennial of Gaudí's death; decorative elements should be complete by 2030 or 2032. Visitor entrance fees of 15–20 euros finance the annual construction budget of 25million euros .\n\nComputer-aided design technology has been used to accelerate construction of the building. Current technology allows stone to be shaped off-site by a CNC milling machine, whereas in the 20th century the stone was carved by hand.\n\nIn 2008, some renowned Catalan architects advocated halting construction, to respect Gaudí's original designs, which although they were not exhaustive and were partially destroyed, have been partially reconstructed in recent years.\n\nSince 2013, AVE high-speed trains have passed near the Sagrada Família through an underground tunnel that runs beneath the centre of Barcelona.\n\nThe tunnel's construction, which began on 26 March 2010, was controversial. The Ministry of Public Works of Spain (\"Ministerio de Fomento\") claimed the project posed no risk to the church. Sagrada Família engineers and architects disagreed, saying there was no guarantee that the tunnel would not affect the stability of the building. The Board of the Sagrada Família (\"Patronat de la Sagrada Família\") and the neighborhood association \"AVE pel Litoral\" (AVE by the Coast) had led a campaign against this route for the AVE, without success.\n\nIn October 2010, the tunnel boring machine reached the church underground under the location of the building's principal façade. Service through the tunnel was inaugurated on 8 January 2013. Track in the tunnel makes use of a system by Edilon Sedra in which the rails are embedded in an elastic material to dampen vibrations. No damage to the Sagrada Família has been reported to date.\n\nThe main nave was covered and an organ installed in mid-2010, allowing the still-unfinished building to be used for religious services. The church was consecrated by Pope Benedict XVI on 7 November 2010 in front of a congregation of 6,500 people. A further 50,000 people followed the consecration Mass from outside the basilica, where more than 100 bishops and 300 priests were on hand to offer Holy Communion. Starting on 9 July 2017, there is an international mass celebrated at the basilica on every Sunday and holy day of obligation, at 9 a.m, open to the public (until the church is full). Occasionally, Mass is celebrated at other times, where attendance requires an invitation. When masses are scheduled, instructions to obtain an invitation are posted on the basilica's website. In addition, visitors may pray in the chapel of the Blessed Sacrament and Penitence.\n\nOn 19 April 2011, an arsonist started a small fire in the sacristy which forced the evacuation of tourists and construction workers; the sacristy was damaged, and the fire took 45 minutes to contain.\n\nThe style of la Sagrada Família is variously likened to Spanish Late Gothic, Catalan Modernism and to Art Nouveau or Catalan Noucentisme. While the Sagrada Família falls within the Art Nouveau period, Nikolaus Pevsner points out that, along with Charles Rennie Mackintosh in Glasgow, Gaudí carried the Art Nouveau style far beyond its usual application as a surface decoration.\n\nWhile never intended to be a cathedral (seat of a bishop), the Sagrada Família was planned from the outset to be a cathedral-sized building. Its ground-plan has obvious links to earlier Spanish cathedrals such as Burgos Cathedral, León Cathedral and Seville Cathedral. In common with Catalan and many other European Gothic cathedrals, the Sagrada Família is short in comparison to its width, and has a great complexity of parts, which include double aisles, an ambulatory with a chevet of seven apsidal chapels, a multitude of towers and three portals, each widely different in structure as well as ornament. Where it is common for cathedrals in Spain to be surrounded by numerous chapels and ecclesiastical buildings, the plan of this church has an unusual feature: a covered passage or cloister which forms a rectangle enclosing the church and passing through the narthex of each of its three portals. With this peculiarity aside, the plan, influenced by Villar's crypt, barely hints at the complexity of Gaudí's design or its deviations from traditional church architecture. There are no exact right angles to be seen inside or outside the church, and few straight lines in the design.\n\nGaudí's original design calls for a total of eighteen spires, representing in ascending order of height the Twelve Apostles, the Virgin Mary, the four Evangelists and, tallest of all, Jesus Christ. Eight spires have been built , corresponding to four apostles at the Nativity façade and four apostles at the Passion façade.\n\nAccording to the 2005 \"Works Report\" of the project's official website, drawings signed by Gaudí and recently found in the Municipal Archives, indicate that the spire of the Virgin was in fact intended by Gaudí to be shorter than those of the evangelists. The spire height will follow Gaudí's intention, which according to the report will work with the existing foundation. \n\nThe Evangelists' spires will be surmounted by sculptures of their traditional symbols: a winged bull (Saint Luke), a winged man (Saint Matthew), an eagle (Saint John), and a winged lion (Saint Mark). The central spire of Jesus Christ is to be surmounted by a giant cross; its total height () will be one metre less than that of Montjuïc hill in Barcelona as Gaudí believed that his creation should not surpass God's. The lower spires are surmounted by communion hosts with sheaves of wheat and chalices with bunches of grapes, representing the Eucharist. Plans call for tubular bells to be placed within the spires, driven by the force of the wind, and driving sound down into the interior of the church. Gaudí performed acoustic studies to achieve the appropriate acoustic results inside the temple. However, only one bell is currently in place.\n\nThe completion of the spires will make Sagrada Família the tallest church building in the world.\n\nThe Church will have three grand façades: the Nativity façade to the East, the Passion façade to the West, and the Glory façade to the South (yet to be completed). The Nativity Façade was built before work was interrupted in 1935 and bears the most direct Gaudí influence. The Passion façade was built according to the design that Gaudi created in 1917. The construction began in 1954, and the towers, built over the elliptical plan, were finished in 1976. It is especially striking for its spare, gaunt, tormented characters, including emaciated figures of Christ being scourged at the pillar; and Christ on the Cross. These controversial designs are the work of Josep Maria Subirachs. The Glory façade, on which construction began in 2002, will be the largest and most monumental of the three and will represent one's ascension to God. It will also depict various scenes such as Hell, Purgatory, and will include elements such as the Seven deadly sins and the Seven heavenly virtues.\n\nConstructed between 1894 and 1930, the Nativity façade was the first façade to be completed. Dedicated to the birth of Jesus, it is decorated with scenes reminiscent of elements of life. Characteristic of Gaudí's naturalistic style, the sculptures are ornately arranged and decorated with scenes and images from nature, each a symbol in its own manner. For instance, the three porticos are separated by two large columns, and at the base of each lies a turtle or a tortoise (one to represent the land and the other the sea; each are symbols of time as something set in stone and unchangeable). In contrast to the figures of turtles and their symbolism, two chameleons can be found at either side of the façade, and are symbolic of change.\n\nThe façade faces the rising sun to the northeast, a symbol for the birth of Christ. It is divided into three porticos, each of which represents a theological virtue (Hope, Faith and Charity). The Tree of Life rises above the door of Jesus in the portico of Charity. Four towers complete the façade and are each dedicated to a Saint (Matthias, Barnabas, Jude the Apostle, and Simon the Zealot).\n\nOriginally, Gaudí intended for this façade to be polychromed, for each archivolt to be painted with a wide array of colours. He wanted every statue and figure to be painted. In this way the figures of humans would appear as much alive as the figures of plants and animals.\n\nGaudí chose this façade to embody the structure and decoration of the whole church. He was well aware that he would not finish the church and that he would need to set an artistic and architectural example for others to follow. He also chose for this façade to be the first on which to begin construction and for it to be, in his opinion, the most attractive and accessible to the public. He believed that if he had begun construction with the Passion Façade, one that would be hard and bare (as if made of bones), before the Nativity Façade, people would have withdrawn at the sight of it. Some of the statues were destroyed in 1936 during the Spanish Civil War, and subsequently were reconstructed by the Japanese artist Etsuro Sotoo.\n\nIn contrast to the highly decorated Nativity Façade, the Passion Façade is austere, plain and simple, with ample bare stone, and is carved with harsh straight lines to resemble the bones of a skeleton. Dedicated to the Passion of Christ, the suffering of Jesus during his crucifixion, the façade was intended to portray the sins of man. Construction began in 1954, following the drawings and instructions left by Gaudí for future architects and sculptors. The towers were completed in 1976, and in 1987 a team of sculptors, headed by Josep Maria Subirachs, began work sculpting the various scenes and details of the façade. They aimed to give a rigid, angular form to provoke a dramatic effect. Gaudí intended for this façade to strike fear into the onlooker. He wanted to \"break\" arcs and \"cut\" columns, and to use the effect of chiaroscuro (dark angular shadows contrasted by harsh rigid light) to further show the severity and brutality of Christ's sacrifice.\n\nFacing the setting sun, indicative and symbolic of the death of Christ, the Passion Façade is supported by six large and inclined columns, designed to resemble Sequoia trunks. Above there is a pyramidal pediment, made up of eighteen bone-shaped columns, which culminate in a large cross with a crown of thorns. Each of the four towers is dedicated to an apostle (James, Thomas, Philip, and Bartholomew) and, like the Nativity Façade, there are three porticos, each representing the theological virtues, though in a much different light.\n\nThe scenes sculpted into the façade may be divided into three levels, which ascend in an \"S\" form and reproduce the stations of the Cross (Via Crucis of Christ). The lowest level depicts scenes from Jesus' last night before the crucifixion, including the Last Supper, Kiss of Judas, Ecce homo, and the Sanhedrin trial of Jesus. The middle level portrays the Calvary, or Golgotha, of Christ, and includes The Three Marys, Saint Longinus, Saint Veronica, and a hollow-face illusion of Christ on the Veil of Veronica. In the third and final level the Death, Burial and the Resurrection of Christ can be seen. A bronze figure situated on a bridge creating a link between the towers of Saint Bartholomew and Saint Thomas represents the Ascension of Jesus.\n\nThe largest and most striking of the façades will be the Glory Façade, on which construction began in 2002. It will be the principal façade and will offer access to the central nave. Dedicated to the Celestial Glory of Jesus, it represents the road to God: Death, Final Judgment, and Glory, while Hell is left for those who deviate from God's will. Aware that he would not live long enough to see this façade completed, Gaudí made a model which was demolished in 1936, whose original fragments were base for the development of the design for the façade. The completion of this façade may require the partial demolition of the block with buildings across the Carrer de Mallorca.\nTo reach the Glory Portico the large staircase will lead over the underground passage built over Carrer de Mallorca with the decoration representing Hell and vice. On other projects Carrer de Mallorca will have to go underground. It will be decorated with demons, idols, false gods, heresy and schisms, etc. Purgatory and death will also be depicted, the latter using tombs along the ground. The portico will have seven large columns dedicated to gifts of the Holy Spirit. At the base of the columns there will be representations of the Seven Deadly Sins, and at the top, The Seven Virtues.\n\nThis facade will have five doors corresponding to the five naves of the temple, with the central one having a triple entrance, that will give the Glory Façade a total seven doors representing the sacraments:\n\n\nIn September 2008, the doors of the Glory façade, by Josep Maria Subirachs, were installed. Inscribed with the Lord's prayer, these central doors are inscribed with the words \"Give us our daily bread\" in fifty different languages. The handles of the door are the letters \"A\" and \"G\" that form the initials of Antoni Gaudí within the phrase \"lead us not into temptation\".\n\nThe church plan is that of a Latin cross with five aisles. The central nave vaults reach while the side nave vaults reach . The transept has three aisles. The columns are on a 7.5metre (25 ft) grid. However, the columns of the apse, resting on del Villar's foundation, do not adhere to the grid, requiring a section of columns of the ambulatory to transition to the grid thus creating a horseshoe pattern to the layout of those columns. The crossing rests on the four central columns of porphyry supporting a great hyperboloid surrounded by two rings of twelve hyperboloids (currently under construction). The central vault reaches . The apse is capped by a hyperboloid vault reaching . Gaudí intended that a visitor standing at the main entrance be able to see the vaults of the nave, crossing, and apse; thus the graduated increase in vault loft.\n\nThere are gaps in the floor of the apse, providing a view down into the crypt below.\n\nThe columns of the interior are a unique Gaudí design. Besides branching to support their load, their ever-changing surfaces are the result of the intersection of various geometric forms. The simplest example is that of a square base evolving into an octagon as the column rises, then a sixteen-sided form, and eventually to a circle. This effect is the result of a three-dimensional intersection of helicoidal columns (for example a square cross-section column twisting clockwise and a similar one twisting counter-clockwise).\n\nEssentially none of the interior surfaces are flat; the ornamentation is comprehensive and rich, consisting in large part of abstract shapes which combine smooth curves and jagged points. Even detail-level work such as the iron railings for balconies and stairways are full of curvaceous elaboration.\n\nIn 2010 an organ was installed in the chancel by the Blancafort Orgueners de Montserrat organ builders. The instrument has 26 stops (1,492 pipes) on two manuals and a pedalboard.\n\nTo overcome the unique acoustical challenges posed by the church's architecture and vast size, several additional organs will be installed at various points within the building. These instruments will be playable separately (from their own individual consoles) and simultaneously (from a single mobile console), yielding an organ of some 8000 pipes when completed.\n\nThe towers on the Nativity façade are crowned with geometrically shaped tops that are reminiscent of Cubism (they were finished around 1930), and the intricate decoration is contemporary to the style of Art Nouveau, but Gaudí's unique style drew primarily from nature, not other artists or architects, and resists categorization.\n\nGaudí used hyperboloid structures in later designs of the Sagrada Família (more obviously after 1914), however there are a few places on the nativity façade—a design not equated with Gaudí's ruled-surface design—where the hyperboloid crops up. For example, all around the scene with the pelican there are numerous examples (including the basket held by one of the figures). There is a hyperboloid adding structural stability to the cypress tree (by connecting it to the bridge). And finally, the \"bishop's mitre\" spires are capped with hyperboloid structures. In his later designs, ruled surfaces are prominent in the nave's vaults and windows and the surfaces of the Passion façade.\n\nThemes throughout the decoration include words from the liturgy. The towers are decorated with words such as \"Hosanna\", \"Excelsis\", and \"Sanctus\"; the great doors of the Passion façade reproduce excerpts of the Passion of Jesus from the New Testament in various languages, mainly Catalan; and the Glory façade is to be decorated with the words from the Apostles' Creed, while its main door reproduce the entire Lord's Prayer in Catalan, surrounded by multiple variations of \"Give us this day our daily bread\" in other languages. The three entrances symbolize the three virtues: Faith, Hope and Love. Each of them is also dedicated to a part of Christ's life. The Nativity Façade is dedicated to his birth; it also has a cypress tree which symbolizes the tree of life. The Glory façade is dedicated to his glory period. The Passion façade is symbolic of his suffering. The apse tower bears Latin text of Hail Mary. All in all, the Sagrada Família is symbolic of the lifetime of Christ.\n\nAreas of the sanctuary will be designated to represent various concepts, such as saints, virtues and sins, and secular concepts such as regions, presumably with decoration to match.\n\n\nThe art historian Nikolaus Pevsner, writing in the 1960s, referred to Gaudí's buildings as growing \"like sugar loaves and anthills\" and describes the ornamenting of buildings with shards of broken pottery as possibly \"bad taste\" but handled with vitality and \"ruthless audacity\".\n\nThe building's design itself has been polarizing. Assessments by Gaudí's fellow architects were generally\npositive; Louis Sullivan greatly admired it, describing Sagrada Família as the\n\"greatest piece of creative architecture in the last twenty-five years. It is spirit symbolised\nin stone!\"\nWalter Gropius also praised the Sagrada Família, describing the building's walls as \"a marvel of\ntechnical perfection\".\nTime Magazine called it \"sensual, spiritual, whimsical, exuberant\", George Orwell called it \"one of the most hideous buildings in the world\", James A. Michener called it \"one of the strangest-looking serious buildings in the world\" and British historian Gerald Brenan stated about\nthe building \"Not even in the European architecture of the period can one discover anything so vulgar\nor pretentious.\" The building's distinctive silhouette has nevertheless become symbolic of Barcelona itself, drawing an estimated 2.5 million visitors annually.\n\nTogether with six other Gaudí buildings in Barcelona, part of la Sagrada Família is a UNESCO World Heritage Site, as testifying \"to Gaudí's exceptional creative contribution to the development of architecture and building technology\", \"having represented el Modernisme of Catalonia\" and \"anticipated and influenced many of the forms and techniques that were relevant to the development of modern construction in the 20th century\". The inscription only includes the Crypt and the Nativity Façade.\n\nVisitors can access the Nave, Crypt, Museum, Shop, and the Passion and Nativity towers. Entrance to either of the towers requires a reservation and advance purchase of a ticket. Access is possible only by lift (elevator) and a short walk up the remainder of the towers to the bridge between the towers. Descent is via a very narrow spiral staircase of over 300 steps. There is a posted caution for those with medical conditions.\n\nAs of June 2017, on-line ticket purchase has been available. As of August 2010, there had been a service whereby visitors could buy an entry code either at Servicaixa ATM kiosks (part of \"La Caixa\") or online. During the peak season, May to October, reservation delays for entrance of up to a few days are not unusual.\n\nConstruction on Sagrada Família is not supported by any government or official church sources. Private patrons funded the initial stages. Money from tickets purchased by tourists is now used to pay for the work, and private donations are accepted through the Friends of the Sagrada Família.\n\nThe construction budget for 2009 was €18 million.\n\nIn October 2018, Sagrada Família trustees agreed to pay €36 million in payments to the city authorities, to land a building permit after 136 years of construction. Most of the funds would be directed to improve the access between the church and Barcelona's metro system.\n\n\n\n"}
{"id": "220089", "url": "https://en.wikipedia.org/wiki?curid=220089", "title": "Set-builder notation", "text": "Set-builder notation\n\nIn set theory and its applications to logic, mathematics, and computer science, set-builder notation is a mathematical notation for describing a set by enumerating its elements or stating the properties that its members must satisfy.\n\nDefining sets by properties is also known as set comprehension, set abstraction or as defining a set's intension.\n\nSet-builder notation is sometimes simply referred to as \"set notation\", although this phrase may be better reserved for the broader class of means of denoting sets.\n\nA set is an unordered collection of \"elements\". (An \"element\" may also be referred to as a \"member\".) An element may be any mathematical entity.\n\nA set can be described directly by enumerating all of its elements between curly brackets, as in the following two examples:\n\n\nThis is sometimes called the \"roster method\" for specifying a set.\n\nWhen it is desired to denote a set that contains elements from a regular sequence an ellipses notation may be employed, as shown in the next examples:\n\n\nThere is no order among the elements of a set (this explains and validates the equality of the last example), but with the ellipses notation we show an ordered sequence before (or after) the ellipsis as a convenient notational vehicle for explaining to a reader which elements are in a set. The first few elements of the sequence are shown then the ellipses indicate that the simplest interpretation should be applied for continuing the sequence. Should no terminating value appear to the right of the ellipses then the sequence is considered to be unbounded.\n\nIn each preceding example, each set is described by enumerating its elements. Not all sets can be described in this way, or if they can, their enumeration may be too long or too complicated to be useful. Therefore, many sets are defined by a property that characterizes their elements. This characterization may be done informally using general prose, as in the following example.\n\n\nHowever, the prose approach may lack accuracy or be ambiguous. Thus, set builder notation is often used with a predicate characterizing the elements of the set being defined, as described in the following section.\n\nSet builder notation can be used to describe sets that are defined by a predicate, rather than explicitly enumerated. In this form, set builder notation has three parts: a variable, a colon or vertical bar separator, and a logical predicate. Thus there is a variable on the left of the separator, and a rule on the right of it. These three parts are contained in curly brackets:\nor\nThe vertical bar, which can also be written as a colon, is a separator that can be read as \"such that\", \"for which\", or \"with the property that\". The formula is said to be the \"rule\" or the \"predicate\". All values of \"x\" for which the predicate holds (is true) belong to the set being defined. All values of for which the predicate does not hold do not belong to the set. Thus formula_8 is the set of all values of that satisfy the formula . It may be the empty set, if no value of satisfies the formula.\n\nA domain can appear on the left of the vertical bar: \nor by adjoining it to the predicate:\nThe ∈ symbol here denotes set membership, while the formula_13 symbol denotes the logical \"and\" operator, known as logical conjunction. This notation represents the set of all values of that belong to some given set for which the predicate is true. (see \"Set existence axiom\" below)\n\nIn general, it is not a good idea to consider sets without defining a domain, as this would represent the subset of \"all possible things that may exist\" for which the predicate is true. This can easily lead to contradictions and paradoxes. For example, Russell's paradox shows that the expression formula_14 although seemingly well formed as a set builder expression, can not define a set without producing a contradiction.\n\nIn cases where the set \"E\" is clear from context, it may be not explicitly specified. It is common in the literature for an author to state the domain ahead of time, and then not specify it in the set builder notation. For example, an author may say something such as, \"Unless otherwise stated, variables are to be taken to be natural numbers.\"\n\nThe following examples illustrate particular sets defined by set builder notation via predicates. In each case, the domain is specified on the left side of the vertical bar, while the rule is specified on the right side. \n\n\n\n\n\n\nAn extension of set-builder notation replaces the single variable with a term that may include one or more variables, combined with functions acting on them. So instead of formula_30, we may have formula_31 which should be read\n\nFor example:\n\nWhen inverse functions can be explicitly stated, the expression on the left can be eliminated through simple substitution. Consider the example set formula_37. Make the substitution formula_40, which is to say formula_41, then replace \"t\" in the set builder notation to find \n\nTwo sets are equal if and only if they have the same elements. Sets defined by set builder notation are equal if and only if their set builder rules, including the domain specifiers, are equivalent. That is \nif and only if \nTherefore, in order to prove the equality of two sets defined by set builder notation, it suffices to prove the equivalence of their predicates, including the domain qualifiers.\n\nFor example,\nbecause the two rule predicates are logically equivalent:\nThis equivalence holds because, for any real number \"x\", we have formula_47 if and only if \"x\" is a rational number with formula_48. In particular, both sets are equal to the set formula_49.\n\nIn many formal set theories, such as Zermelo–Fraenkel set theory, set builder notation is not part of the formal syntax of the theory. Instead, there is a set existence axiom scheme, which states that if \"E\" is a set and Φ(x) is a formula in the language of set theory, then there is a set \"Y\" whose members are exactly the elements of \"E\" that satisfy Φ:\nThe set \"Y\" obtained from this axiom is exactly the set described in set builder notation as formula_51.\n\nIn Z notation, the set of all \"x\" in a universe of discourse \"A\" that satisfy the condition \"P\"(\"x\") is written\nIn Z, the set membership of an element \"x\" in set \"A\" is written as formula_53 instead of formula_54. Versions of set builder notation are also available in Z which allow for terms more complicated than a single variable, using a bullet to indicate the form of members of the set. For example,\ndenotes the set of all values \"F\"(\"x\"), where \"x\" is in \"A\" and \"P\"(\"x\") holds.\n\nA similar notation available in a number of programming languages (notably Python and Haskell) is the list comprehension, which combines map and filter operations over one or more lists.\n\nIn Python, the set-builder's braces are replaced with square brackets, parentheses, or curly braces, giving list, generator, and set objects, respectively. Python uses an English-based syntax. Haskell replaces the set-builder's braces with square brackets and uses symbols, including the standard set-builder vertical bar.\n\nThe same can be achieved in Scala using Sequence Comprehensions, where the \"for\" keyword returns a list of the yielded variables using the \"yield\" keyword.\n\nConsider these set-builder notation examples in some programming languages:\nThe set builder notation and list comprehension notation are both instances of a more general notation known as \"monad comprehensions\", which permits map/filter-like operations over any monad with a zero element.\n\n"}
{"id": "548156", "url": "https://en.wikipedia.org/wiki?curid=548156", "title": "State-space representation", "text": "State-space representation\n\nIn control engineering, a state-space representation is a mathematical model of a physical system as a set of input, output and state variables related by first-order differential equations or difference equations. State variables are variables whose values evolve through time in a way that depends on the values they have at any given time and also depends on the externally imposed values of input variables. Output variables’ values depend on the values of the state variables.\n\nThe \"state space\" is the Euclidean space in which the variables on the axes are the state variables. The state of the system can be represented as a vector within that space.\n\nTo abstract from the number of inputs, outputs and states, these variables are expressed as vectors. Additionally, if the dynamical system is linear, time-invariant, and finite-dimensional, then the differential and algebraic equations may be written in matrix form.\nThe state-space method is characterized by significant algebraization of general system theory, which makes it possible to use Kronecker vector-matrix structures. The capacity of these structures can be efficiently applied to research systems with modulation or without it. \nThe state-space representation (also known as the \"time-domain approach\") provides a convenient and compact way to model and analyze systems with multiple inputs and outputs. With formula_1 inputs and formula_2 outputs, we would otherwise have to write down formula_3 Laplace transforms to encode all the information about a system. Unlike the frequency domain approach, the use of the state-space representation is not limited to systems with linear components and zero initial conditions. The state-space model is used in many different areas. In econometrics, the state-space model can be used for forecasting stock prices and numerous other variables.\n\nThe internal state variables are the smallest possible subset of system variables that can represent the entire state of the system at any given time. The minimum number of state variables required to represent a given system, formula_4, is usually equal to the order of the system's defining differential equation. If the system is represented in transfer function form, the minimum number of state variables is equal to the order of the transfer function's denominator after it has been reduced to a proper fraction. It is important to understand that converting a state-space realization to a transfer function form may lose some internal information about the system, and may provide a description of a system which is stable, when the state-space realization is unstable at certain points. In electric circuits, the number of state variables is often, though not always, the same as the number of energy storage elements in the circuit such as capacitors and inductors. The state variables defined must be linearly independent, i.e., no state variable can be written as a linear combination of the other state variables or the system will not be able to be solved.\n\nThe most general state-space representation of a linear system with formula_1 inputs, formula_2 outputs and formula_4 state variables is written in the following form:\nwhere:\n\nIn this general formulation, all matrices are allowed to be time-variant (i.e. their elements can depend on time); however, in the common LTI case, matrices will be time invariant. The time variable formula_26 can be continuous (e.g. formula_27) or discrete (e.g. formula_28). In the latter case, the time variable formula_29 is usually used instead of formula_26. Hybrid systems allow for time domains that have both continuous and discrete parts. Depending on the assumptions taken, the state-space model representation can assume the following forms:\n\nStability and natural response characteristics of a continuous-time LTI system (i.e., linear with matrices that are constant with respect to time) can be studied from the eigenvalues of the matrix A. The stability of a time-invariant state-space model can be determined by looking at the system's transfer function in factored form. It will then look something like this:\n\nThe denominator of the transfer function is equal to the characteristic polynomial found by taking the determinant of formula_32,\nThe roots of this polynomial (the eigenvalues) are the system transfer function's poles (i.e., the singularities where the transfer function's magnitude is unbounded). These poles can be used to analyze whether the system is asymptotically stable or marginally stable. An alternative approach to determining stability, which does not involve calculating eigenvalues, is to analyze the system's Lyapunov stability.\n\nThe zeros found in the numerator of formula_34 can similarly be used to determine whether the system is minimum phase.\n\nThe system may still be input–output stable (see BIBO stable) even though it is not internally stable. This may be the case if unstable poles are canceled out by zeros (i.e., if those singularities in the transfer function are removable).\n\nThe state controllability condition implies that it is possible – by admissible inputs – to steer the states from any initial value to any final value within some finite time window. A continuous time-invariant linear state-space model is controllable if and only if\nwhere rank is the number of linearly independent rows in a matrix, and where \"n\" is the number of state variables.\n\nObservability is a measure for how well internal states of a system can be inferred by knowledge of its external outputs. The observability and controllability of a system are mathematical duals (i.e., as controllability provides that an input is available that brings any initial state to any desired final state, observability provides that knowing an output trajectory provides enough information to predict the initial state of the system).\n\nA continuous time-invariant linear state-space model is observable if and only if\n\nThe \"transfer function\" of a continuous time-invariant linear state-space model can be derived in the following way:\n\nFirst, taking the Laplace transform of \nyields\nNext, we simplify for formula_39, giving\nand thus\n\nSubstituting for formula_39 in the output equation\n\nThe transfer function formula_45 is defined as the ratio of the output to the input of a system considering its initial conditions to be zero (formula_46). However, the ratio of a vector to a vector does not exist, so we consider the following condition satisfied by the transfer function\ncomparison with the equation for formula_48 above gives\nClearly formula_45 must have formula_2 by formula_1 dimensionality, and thus has a total of formula_53 elements.\nSo for every input there are formula_2 transfer functions with one for each output.\nThis is why the state-space representation can easily be the preferred choice for multiple-input, multiple-output (MIMO) systems. The Rosenbrock system matrix provides a bridge between the state-space representation and its transfer function.\n\nAny given transfer function which is strictly proper can easily be transferred into state-space by the following approach (this example is for a 4-dimensional, single-input, single-output system):\n\nGiven a transfer function, expand it to reveal all coefficients in both the numerator and denominator. This should result in the following form:\n\nThe coefficients can now be inserted directly into the state-space model by the following approach:\n\nThis state-space realization is called controllable canonical form because the resulting model is guaranteed to be controllable (i.e., because the control enters a chain of integrators, it has the ability to move every state).\nThe transfer function coefficients can also be used to construct another type of canonical form\n\nThis state-space realization is called observable canonical form because the resulting model is guaranteed to be observable (i.e., because the output exits from a chain of integrators, every state has an effect on the output).\n\nTransfer functions which are only proper (and not strictly proper) can also be realised quite easily. The trick here is to separate the transfer function into two parts: a strictly proper part and a constant. \n\nThe strictly proper transfer function can then be transformed into a canonical state-space realization using techniques shown above. The state-space realization of the constant is trivially formula_61. Together we then get a state-space realization with matrices \"A\", \"B\" and \"C\" determined by the strictly proper part, and matrix \"D\" determined by the constant.\n\nHere is an example to clear things up a bit:\nwhich yields the following controllable realization\n\nNotice how the output also depends directly on the input. This is due to the formula_65 constant in the transfer function.\n\nA common method for feedback is to multiply the output by a matrix \"K\" and setting this as the input to the system: formula_66.\nSince the values of \"K\" are unrestricted the values can easily be negated for negative feedback.\nThe presence of a negative sign (the common notation) is merely a notational one and its absence has no impact on the end results.\n\nbecomes\n\nsolving the output equation for formula_71 and substituting in the state equation results in\n\nThe advantage of this is that the eigenvalues of \"A\" can be controlled by setting \"K\" appropriately through eigendecomposition of formula_74.\nThis assumes that the closed-loop system is controllable or that the unstable eigenvalues of \"A\" can be made stable through appropriate choice of \"K\".\n\nFor a strictly proper system \"D\" equals zero. Another fairly common situation is when all states are outputs, i.e. \"y\" = \"x\", which yields \"C\" = \"I\", the Identity matrix. This would then result in the simpler equations\n\nThis reduces the necessary eigendecomposition to just formula_77.\n\nIn addition to feedback, an input, formula_78, can be added such that formula_79.\n\nbecomes\n\nsolving the output equation for formula_71 and substituting in the state equation \nresults in\n\nOne fairly common simplification to this system is removing \"D\", which reduces the equations to\n\nA classical linear system is that of one-dimensional movement of an object.\nNewton's laws of motion for an object moving horizontally on a plane and attached to a wall with a spring\n\nwhere\n\nThe state equation would then become\n\nwhere\n\nThe controllability test is then\n\nwhich has full rank for all formula_94 and formula_96.\n\nThe observability test is then\n\nwhich also has full rank.\nTherefore, this system is both controllable and observable.\n\nThe more general form of a state-space model can be written as two functions.\n\nThe first is the state equation and the latter is the output equation.\nIf the function formula_109 is a linear combination of states and inputs then the equations can be written in matrix notation like above.\nThe formula_93 argument to the functions can be dropped if the system is unforced (i.e., it has no inputs).\n\nA classic nonlinear system is a simple unforced pendulum\n\nwhere\nThe state equations are then\n\nwhere\n\nInstead, the state equation can be written in the general form\n\nThe equilibrium/stationary points of a system are when formula_124 and so the equilibrium points of a pendulum are those that satisfy\n\nfor integers \"n\".\n\n\n"}
{"id": "571280", "url": "https://en.wikipedia.org/wiki?curid=571280", "title": "Stratification (mathematics)", "text": "Stratification (mathematics)\n\nStratification has several usages in mathematics.\n\nIn mathematical logic, stratification is any consistent assignment of numbers to predicate symbols guaranteeing that a unique formal interpretation of a logical theory exists. Specifically, we say that a set of clauses of the form formula_1 is stratified if and only if\nthere is a stratification assignment S that fulfills the following conditions:\n\n\nThe notion of stratified negation leads to a very effective operational semantics for stratified programs in terms of the stratified least fixpoint, that is obtained by iteratively applying the fixpoint operator to each \"stratum\" of the program, from the lowest one up.\nStratification is not only useful for guaranteeing unique interpretation of Horn clause\ntheories. It has also been used by W.V. Quine (1937) to address Russell's paradox, which undermined Frege's central work \"Grundgesetze der Arithmetik\" (1902).\n\nIn New Foundations (NF) and related set theories, a formula formula_4 in the language of first-order logic with equality and membership is said to be\nstratified if and only if there is a function\nformula_5 which sends each variable appearing in formula_4 (considered as an item of syntax) to\na natural number (this works equally well if all integers are used) in such a way that\nany atomic formula formula_7 appearing in formula_4 satisfies formula_9 and any atomic formula formula_10 appearing in formula_4 satisfies formula_12.\n\nIt turns out that it is sufficient to require that these conditions be satisfied only when\nboth variables in an atomic formula are bound in the set abstract formula_13\nunder consideration. A set abstract satisfying this weaker condition is said to be\nweakly stratified.\n\nThe stratification of New Foundations generalizes readily to languages with more\npredicates and with term constructions. Each primitive predicate needs to have specified\nrequired displacements between values of formula_5 at its (bound) arguments\nin a (weakly) stratified formula. In a language with term constructions, terms themselves\nneed to be assigned values under formula_5, with fixed displacements from the\nvalues of each of their (bound) arguments in a (weakly) stratified formula. Defined term\nconstructions are neatly handled by (possibly merely implicitly) using the theory\nof descriptions: a term formula_16 (the x such that formula_4) must\nbe assigned the same value under formula_5 as the variable x.\n\nA formula is stratified if and only if it is possible to assign types to all variables appearing\nin the formula in such a way that it will make sense in a version TST of the theory of\ntypes described in the New Foundations article, and this is probably the best way\nto understand the stratification of New Foundations in practice.\n\nThe notion of stratification can be extended to the lambda calculus; this is found\nin papers of Randall Holmes.\n\nIn singularity theory, there is a different meaning, of a decomposition of a topological space \"X\" into disjoint subsets each of which is a topological manifold (so that in particular a \"stratification\" defines a partition of the topological space). This is not a useful notion when unrestricted; but when the various strata are defined by some recognisable set of conditions (for example being locally closed), and fit together manageably, this idea is often applied in geometry. Hassler Whitney and René Thom first defined formal conditions for stratification. See Whitney stratification and topologically stratified space.\n\nSee stratified sampling.\n"}
{"id": "222947", "url": "https://en.wikipedia.org/wiki?curid=222947", "title": "Table of bases", "text": "Table of bases\n\nThis article is about \"bases\" as that term is used in discussion of certain numeral systems.\n\nThis table of bases gives the values of 0 to 256 in bases 2 to 36. (Using A−Z for 10−35)\n\n"}
{"id": "30977", "url": "https://en.wikipedia.org/wiki?curid=30977", "title": "Theorem", "text": "Theorem\n\nIn mathematics, a theorem is a statement that has been proven on the basis of previously established statements, such as other theorems, and generally accepted statements, such as axioms. A theorem is a logical consequence of the axioms. The proof of a mathematical theorem is a logical argument for the theorem statement given in accord with the rules of a deductive system. The proof of a theorem is often interpreted as justification of the truth of the theorem statement. In light of the requirement that theorems be proved, the concept of a theorem is fundamentally \"deductive\", in contrast to the notion of a scientific law, which is \"experimental\".\n\nMany mathematical theorems are conditional statements. In this case, the proof deduces the conclusion from conditions called hypotheses or premises. In light of the interpretation of proof as justification of truth, the conclusion is often viewed as a necessary consequence of the hypotheses, namely, that the conclusion is true in case the hypotheses are true, without any further assumptions. However, the conditional could be interpreted differently in certain deductive systems, depending on the meanings assigned to the derivation rules and the conditional symbol.\n\nAlthough they can be written in a completely symbolic form, for example, within the propositional calculus, theorems are often expressed in a natural language such as English. The same is true of proofs, which are often expressed as logically organized and clearly worded informal arguments, intended to convince readers of the truth of the statement of the theorem beyond any doubt, and from which a formal symbolic proof can in principle be constructed. Such arguments are typically easier to check than purely symbolic ones—indeed, many mathematicians would express a preference for a proof that not only demonstrates the validity of a theorem, but also explains in some way \"why\" it is obviously true. In some cases, a picture alone may be sufficient to prove a theorem. Because theorems lie at the core of mathematics, they are also central to its aesthetics. Theorems are often described as being \"trivial\", or \"difficult\", or \"deep\", or even \"beautiful\". These subjective judgments vary not only from person to person, but also with time: for example, as a proof is simplified or better understood, a theorem that was once difficult may become trivial. On the other hand, a deep theorem may be stated simply, but its proof may involve surprising and subtle connections between disparate areas of mathematics. Fermat's Last Theorem is a particularly well-known example of such a theorem.\n\nLogically, many theorems are of the form of an indicative conditional: \"if A, then B\". Such a theorem does not assert \"B\", only that \"B\" is a necessary consequence of \"A\". In this case \"A\" is called the hypothesis of the theorem (\"hypothesis\" here is something very different from a conjecture) and \"B\" the conclusion (formally, \"A\" and \"B\" are termed the \"antecedent\" and \"consequent\"). The theorem \"If \"n\" is an even natural number then \"n\"/2 is a natural number\" is a typical example in which the hypothesis is \"\"n\" is an even natural number\" and the conclusion is \"\"n\"/2 is also a natural number\".\n\nTo be proved, a theorem must be expressible as a precise, formal statement. Nevertheless, theorems are usually expressed in natural language rather than in a completely symbolic form, with the intention that the reader can produce a formal statement from the informal one.\n\nIt is common in mathematics to choose a number of hypotheses within a given language and declare that the theory consists of all statements provable from these hypotheses. These hypotheses form the foundational basis of the theory and are called axioms or postulates. The field of mathematics known as proof theory studies formal languages, axioms and the structure of proofs.\nSome theorems are \"trivial\", in the sense that they follow from definitions, axioms, and other theorems in obvious ways and do not contain any surprising insights. Some, on the other hand, may be called \"deep\", because their proofs may be long and difficult, involve areas of mathematics superficially distinct from the statement of the theorem itself, or show surprising connections between disparate areas of mathematics. A theorem might be simple to state and yet be deep. An excellent example is Fermat's Last Theorem, and there are many other examples of simple yet deep theorems in number theory and combinatorics, among other areas.\n\nOther theorems have a known proof that cannot easily be written down. The most prominent examples are the four color theorem and the Kepler conjecture. Both of these theorems are only known to be true by reducing them to a computational search that is then verified by a computer program. Initially, many mathematicians did not accept this form of proof, but it has become more widely accepted. The mathematician Doron Zeilberger has even gone so far as to claim that these are possibly the only nontrivial results that mathematicians have ever proved. Many mathematical theorems can be reduced to more straightforward computation, including polynomial identities, trigonometric identities and hypergeometric identities.\n\nTo establish a mathematical statement as a theorem, a proof is required, that is, a line of reasoning from axioms in the system (and other, already established theorems) to the given statement must be demonstrated. However, the proof is usually considered as separate from the theorem statement. Although more than one proof may be known for a single theorem, only one proof is required to establish the status of a statement as a theorem. The Pythagorean theorem and the law of quadratic reciprocity are contenders for the title of theorem with the greatest number of distinct proofs.\n\nTheorems in mathematics and theories in science are fundamentally different in their epistemology. A scientific theory cannot be proved; its key attribute is that it is falsifiable, that is, it makes predictions about the natural world that are testable by experiments. Any disagreement between prediction and experiment demonstrates the incorrectness of the scientific theory, or at least limits its accuracy or domain of validity. Mathematical theorems, on the other hand, are purely abstract formal statements: the proof of a theorem cannot involve experiments or other empirical evidence in the same way such evidence is used to support scientific theories.\nNonetheless, there is some degree of empiricism and data collection involved in the discovery of mathematical theorems. By establishing a pattern, sometimes with the use of a powerful computer, mathematicians may have an idea of what to prove, and in some cases even a plan for how to set about doing the proof. For example, the Collatz conjecture has been verified for start values up to about 2.88 × 10. The Riemann hypothesis has been verified for the first 10 trillion zeroes of the zeta function. Neither of these statements is considered proved.\n\nSuch evidence does not constitute proof. For example, the Mertens conjecture is a statement about natural numbers that is now known to be false, but no explicit counterexample (i.e., a natural number \"n\" for which the Mertens function \"M\"(\"n\") equals or exceeds the square root of \"n\") is known: all numbers less than 10 have the Mertens property, and the smallest number that does not have this property is only known to be less than the exponential of 1.59 × 10, which is approximately 10 to the power 4.3 × 10. Since the number of particles in the universe is generally considered less than 10 to the power 100 (a googol), there is no hope to find an explicit counterexample by exhaustive search.\n\nThe word \"theory\" also exists in mathematics, to denote a body of mathematical axioms, definitions and theorems, as in, for example, group theory. There are also \"theorems\" in science, particularly physics, and in engineering, but they often have statements and proofs in which physical assumptions and intuition play an important role; the physical axioms on which such \"theorems\" are based are themselves falsifiable.\n\nA number of different terms for mathematical statements exist; these terms indicate the role statements play in a particular subject. The distinction between different terms is sometimes rather arbitrary and the usage of some terms has evolved over time.\n\n\n\nThere are other terms, less commonly used, that are conventionally attached to proved statements, so that certain theorems are referred to by historical or customary names. For example:\n\n\nA few well-known theorems have even more idiosyncratic names. The division algorithm (see Euclidean division) is a theorem expressing the outcome of division in the natural numbers and more general rings. Bézout's identity is a theorem asserting that the greatest common divisor of two numbers may be written as a linear combination of these numbers. The Banach–Tarski paradox is a theorem in measure theory that is paradoxical in the sense that it contradicts common intuitions about volume in three-dimensional space.\n\nA theorem and its proof are typically laid out as follows:\n\nThe end of the proof may be signalled by the letters Q.E.D. (\"quod erat demonstrandum\") or by one of the tombstone marks \"□\" or \"∎\" meaning \"End of Proof\", introduced by Paul Halmos following their usage in magazine articles.\n\nThe exact style depends on the author or publication. Many publications provide instructions or macros for typesetting in the house style.\n\nIt is common for a theorem to be preceded by definitions describing the exact meaning of the terms used in the theorem. It is also common for a theorem to be preceded by a number of propositions or lemmas which are then used in the proof. However, lemmas are sometimes embedded in the proof of a theorem, either with nested proofs, or with their proofs presented after the proof of the theorem.\n\nCorollaries to a theorem are either presented between the theorem and the proof, or directly after the proof. Sometimes, corollaries have proofs of their own that explain why they follow from the theorem.\n\nIt has been estimated that over a quarter of a million theorems are proved every year.\n\nThe well-known aphorism, , is probably due to Alfréd Rényi, although it is often attributed to Rényi's colleague Paul Erdős (and Rényi may have been thinking of Erdős), who was famous for the many theorems he produced, the number of his collaborations, and his coffee drinking.\n\nThe classification of finite simple groups is regarded by some to be the longest proof of a theorem. It comprises tens of thousands of pages in 500 journal articles by some 100 authors. These papers are together believed to give a complete proof, and several ongoing projects hope to shorten and simplify this proof. Another theorem of this type is the four color theorem whose computer generated proof is too long for a human to read. It is certainly the longest known proof of a theorem whose statement can be easily understood by a layman.\n\nLogic, especially in the field of proof theory, considers theorems as statements (called formulas or well formed formulas) of a formal language. The statements of the language are strings of symbols and may be broadly divided into nonsense and well-formed formulas. A set of deduction rules, also called transformation rules or rules of inference, must be provided. These deduction rules tell exactly when a formula can be derived from a set of premises. The set of well-formed formulas may be broadly divided into theorems and non-theorems. However, according to Hofstadter, a formal system often simply defines all its well-formed formula as theorems.\n\nDifferent sets of derivation rules give rise to different interpretations of what it means for an expression to be a theorem. Some derivation rules and formal languages are intended to capture mathematical reasoning; the most common examples use first-order logic. Other deductive systems describe term rewriting, such as the reduction rules for λ calculus.\n\nThe definition of theorems as elements of a formal language allows for results in proof theory that study the structure of formal proofs and the structure of provable formulas. The most famous result is Gödel's incompleteness theorem; by representing theorems about basic number theory as expressions in a formal language, and then representing this language within number theory itself, Gödel constructed examples of statements that are neither provable nor disprovable from axiomatizations of number theory.\n\nA theorem may be expressed in a formal language (or \"formalized\"). A formal theorem is the purely formal analogue of a theorem. In general, a formal theorem is a type of well-formed formula that satisfies certain logical and syntactic conditions. The notation formula_1 is often used to indicate that formula_1 is a theorem.\n\nFormal theorems consist of formulas of a formal language and the transformation rules of a formal system. Specifically, a formal theorem is always the last formula of a derivation in some formal system each formula of which is a logical consequence of the formulas that came before it in the derivation. The initially accepted formulas in the derivation are called its axioms, and are the basis on which the theorem is derived. A set of theorems is called a theory.\n\nWhat makes formal theorems useful and of interest is that they can be interpreted as true propositions and their derivations may be interpreted as a proof of the truth of the resulting expression. A set of formal theorems may be referred to as a formal theory. A theorem whose interpretation is a true statement about a formal system is called a metatheorem.\n\nThe concept of a formal theorem is fundamentally syntactic, in contrast to the notion of a \"true proposition,\" which introduces semantics. Different deductive systems can yield other interpretations, depending on the presumptions of the derivation rules (i.e. belief, justification or other modalities). The soundness of a formal system depends on whether or not all of its theorems are also validities. A validity is a formula that is true under any possible interpretation, e.g. in classical propositional logic validities are tautologies. A formal system is considered semantically complete when all of its tautologies are also theorems.\n\nThe notion of a theorem is very closely connected to its formal proof (also called a \"derivation\"). To illustrate how derivations are done, we will work in a very simplified formal system. Let us call ours formula_3 Its alphabet consists only of two symbols { A, B } and its formation rule for formulas is:\n\nThe single axiom of formula_3 is:\n\nThe only rule of inference (transformation rule) for formula_3 is:\n\nTheorems in formula_3 are defined as those formulae that have a derivation ending with that formula. For example,\n\n\nis a derivation. Therefore, \"ABBBAB\" is a theorem of formula_8 The notion of truth (or falsity) cannot be applied to the formula \"ABBBAB\" until an interpretation is given to its symbols. Thus in this example, the formula does not yet represent a proposition, but is merely an empty abstraction.\n\nTwo metatheorems of formula_3 are:\n\n\n\n"}
{"id": "145018", "url": "https://en.wikipedia.org/wiki?curid=145018", "title": "Ultrafinitism", "text": "Ultrafinitism\n\nIn the philosophy of mathematics, ultrafinitism (also known as ultraintuitionism, strict formalism, strict finitism, actualism, predicativism, and strong finitism) is a form of finitism. There are various philosophies of mathematics that are called ultrafinitism. A major identifying property common among most of these philosophies is their objections to totality of number theoretic functions like exponentiation over natural numbers.\n\nLike other finitists, ultrafinitists deny the existence of the infinite set N of natural numbers.\n\nIn addition, some ultrafinitists are concerned with acceptance of objects in mathematics that no one can construct in practice because of physical restrictions in constructing large finite mathematical objects.\nThus some ultrafinitists will deny or refrain from accepting the existence of large numbers, for example, the floor of the first Skewes's number, which is a huge number defined using the exponential function as exp(exp(exp(79))), or\nThe reason is that nobody has yet calculated what natural number is the floor of this real number, and it may not even be physically possible to do so. Similarly, formula_2 (in Knuth's up-arrow notation) would be considered only a formal expression which does not correspond to a natural number. The brand of ultrafinitism concerned with physical realizability of mathematics is often called actualism.\n\nEdward Nelson criticized the classical conception of natural numbers because of the circularity of its definition. In classical mathematics the natural numbers are defined as 0 and numbers obtained by the iterative applications of the successor function to 0. But the concept of natural number is already assumed for the iteration. In other words, to obtain a number like formula_2 one needs to perform the successor function iteratively, in fact exactly formula_2 times to 0.\n\nSome versions of ultrafinitism are forms of constructivism, but most constructivists view the philosophy as unworkably extreme. The logical foundation of ultrafinitism is unclear; in his comprehensive survey \"Constructivism in Mathematics\" (1988), the constructive logician A. S. Troelstra dismissed it by saying \"no satisfactory development exists at present.\" This was not so much a philosophical objection as it was an admission that, in a rigorous work of mathematical logic, there was simply nothing precise enough to include.\n\nSerious work on ultrafinitism has been led, since 1959, by Alexander Esenin-Volpin, who in 1961 sketched a program for proving the consistency of Zermelo–Fraenkel set theory in ultrafinite mathematics. Other mathematicians who have worked in the topic include Doron Zeilberger, Edward Nelson, Rohit Jivanlal Parikh, and Jean Paul Van Bendegem. The philosophy is also sometimes associated with the beliefs of Ludwig Wittgenstein, Robin Gandy, Petr Vopenka, and J. Hjelmslev.\n\nShaughan Lavine has developed a form of set-theoretical ultra-finitism that is consistent with classical mathematics.\nLavine has shown that the basic principles of arithmetic such as \"there is no largest natural number\" can be upheld, as Lavine allows for the inclusion of \"indefinitely large\" numbers.\n\nOther considerations of the possibility of avoiding unwieldy large numbers can be based on computational complexity theory, as in Andras Kornai's work on explicit finitism (which does not deny the existence of large numbers) and Vladimir Sazonov's notion of feasible number.\n\nThere has also been considerable formal development on versions of ultrafinitism that are based on complexity theory, like Samuel Buss's Bounded Arithmetic theories, which capture mathematics associated with various complexity classes like P and PSPACE. Buss's work can be considered the continuation of Edward Nelson's work on predicative arithmetic as bounded arithmetic theories like S12 are interpretable in Raphael Robinson's theory Q and therefore are predicative in Nelson's sense. The power of these theories for developing mathematics is studied in Bounded reverse mathematics as can be found in the works of Stephen A. Cook and Phuong The Nguyen. However these researches are not philosophies of mathematics but rather the study of restricted forms of reasoning similar to Reverse Mathematics.\n\n\n\n"}
{"id": "26837834", "url": "https://en.wikipedia.org/wiki?curid=26837834", "title": "University of Chicago School Mathematics Project", "text": "University of Chicago School Mathematics Project\n\nThe University of Chicago School Mathematics Project (UCSMP) is a multi-faceted project of the University of Chicago in the United States, intended to improve competency in mathematics in the United States by elevating educational standards for children in elementary and secondary schools.\n\nThe UCSMP supports educators by supplying training materials to them and offering a comprehensive mathematics curriculum at all levels of primary and secondary education. It seeks to bring international strengths into the United States, translating non-English math textbooks for English students and sponsoring international conferences on the subject of math education. Launched in 1983 with the aid of a six-year grant from Amoco, the UCSMP is used throughout the United States.\n\nUCSMP developed \"Everyday Mathematics\", a pre-K and elementary school mathematics curriculum.\n\n\n\n"}
{"id": "45391102", "url": "https://en.wikipedia.org/wiki?curid=45391102", "title": "Viral dynamics", "text": "Viral dynamics\n\nViral dynamics is a field of applied mathematics concerned with describing the progression of viral infections within a host organism. It employs a family of mathematical models that describe changes over time in the populations of cells targeted by the virus and the viral load. These equations may also track competition between different viral strains and the influence of immune responses. The original viral dynamics models were inspired by compartmental epidemic models (e.g. the SI model), with which they continue to share many common mathematical features, such as the concept of the basic reproductive ratio (\"R\"). The major distinction between these fields is in the scale at which the models operate: while epidemiological models track the spread of infection between individuals within a population (i.e. \"between host\"), viral dynamics models track the spread of infection between cells within an individual (i.e. \"within host\"). Analyses employing viral dynamic models have been used extensively to study HIV, hepatitis B virus, and hepatitis C virus, among other infections\n\n"}
{"id": "51347294", "url": "https://en.wikipedia.org/wiki?curid=51347294", "title": "Wilhelm Winkler", "text": "Wilhelm Winkler\n\nWilhelm Winkler (June 29, 1884 – September 3, 1984) had successful careers as both an academic statistician (despite receiving no formal academic training in the field), and a program director in the Austrian government.\n\nWilhelm was the fifth of the eight children of Anne and music teacher Julius Winkler, a family situation that required him to work starting at age 13. He attended law school at Karl Friedrich University (now Charles University) in Prague, practiced law briefly in 1908, did a stint in the Austrian army, then settled into a position at the Statistical Bureau of Bohemia as the sole German-speaking statistician. While working there, he attended many university classes and reached the conclusion that \"the German statistical literature did not offer too many ideas. New life came into statistics from England and Russia where the importance of mathematical tools was recognized.\"\n\nWinkler re-enlisted in the Austrian army at the outbreak of World War I in 1914, and was decorated twice for bravery before being wounded in November 1915. During a lengthy recovery, he worked for the War Economy committee; his talents were recognized and he was appointed Secretary of State for Military Affairs at the end of the war in 1918 and he was a delegate to the Versailles Peace Conference. That year, he also married a Jewish woman named Clara Deutch. He joined the Austrian Central Statistics Office in 1920, and was promoted to director of its department of population statistics in 1925. Concurrently, he became a \"Privat-Dozent\" (assistant professor) at the University of Vienna in 1921 and an \"Ausserordentlicher Professor\" in 1929. He founded an institute for the study of minority populations, which published a constant stream of progressive and influential papers that made him unpopular with colleagues in his government job. Despite his lack of formal education, he was elected a member of the International Statistical Institute in 1926 where he actively promoted applied and precise mathematical formulations in contrast to the wordy generalizations that he had criticized 20 years earlier. As both the husband of a Jew and an outspoken critic of the unfair treatment of European minorities, Winkler was promptly fired from both his government and academic positions following the 1938 Nazi annexation of Austria. Despite severe persecution from the Nazi party, he wrote the textbook \"Basic Course in Demography\" during the occupation.\n\nAt the end of the war, he was rehired by the University of Vienna as the first full professor of statistics since 1883, and became Dean of the School of Law and Statecraft from 1950 to 1955. He was also restored as Austria's lead government statistician from 1945 to 1955. Despite these influential positions and growing international recognition, Winkler spent many years defending the statistical department from opposition within the university. The regressive attitude of Austrian and German academics towards statistics as a truly independent discipline meant that his contributions to international developments became more difficult. He did not retire until age 71, and continued to publish and vigorously promote statistics thereafter. He died just after his 100th birthday, having published 20 textbooks and over 200 papers, founded two statistical societies, edited two statistical journals, been awarded two honorary degrees, and reshaped the development of German-speaking statistics through his progressive education initiatives.\n\n"}
