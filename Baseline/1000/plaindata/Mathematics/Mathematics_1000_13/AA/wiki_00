{"id": "1309", "url": "https://en.wikipedia.org/wiki?curid=1309", "title": "Almost all", "text": "Almost all\n\nIn mathematics, the term \"almost all\" means \"all but a negligible amount\". More precisely, if X is a set, \"almost all elements of X\" means \"all elements of X but those in a negligible subset of X\". The meaning of \"negligible\" depends on the mathematical context; for instance, it can mean finite, countable, or null.\n\nIn contrast, \"almost no\" means \"a negligible amount\"; that is, \"almost no elements of X\" means \"the elements of some negligible subset of X\".\n\nThroughout mathematics, \"almost all\" is sometimes used to mean \"all (elements of an infinite set) but finitely many\". This use occurs in philosophy as well. Similarly, \"almost all\" can mean \"all (elements of an uncountable set) but countably many\".\n\nExamples:\n\nWhen speaking about the reals, sometimes \"almost all\" means \"all reals but a null set\". Similarly, if S is some set of reals, \"almost all numbers in S\" can mean \"all numbers in S but those in a null set\". The real line can be thought of as a one-dimensional Euclidean space. In the more general case of an n-dimensional space (where n is a positive integer), these definitions can be generalised to \"all points but those in a null set\" or \"all points in S but those in a null set\" (this time, S is a set of points in the space). Even more generally, \"almost all\" is sometimes used in the sense of \"almost everywhere\" in measure theory, or in the closely related sense of \"almost surely\" in probability theory.\n\nExamples:\n\nIn number theory, \"almost all positive integers\" can mean \"the positive integers in a set whose natural density is 1\". That is, if A is a set of positive integers, and if the proportion of positive integers below n that are in A (out of all positive integers below n) tends to 1 as n tends to infinity, then almost all positive integers are in A. More generally, let S be an infinite set of positive integers, such as the set of even positive numbers or of primes. If A is a subset of S, and if the proportion of elements of S below n that are in A (out of all elements of S below n) tends to 1 as n tends to infinity, then it can be said that almost all elements of S are in A.\n\nExamples:\n\nIn graph theory, if A is a set of (finite labelled) graphs, it can be said to contain almost all graphs if the proportion of graphs with n vertices that are in A tends to 1 as n tends to infinity. However, it is sometimes easier to work with probabilities, so the definition is reformulated as follows. The proportion of graphs with n vertices that are in A equals the probability that a random graph with n vertices (chosen with the uniform distribution) is in A, and choosing a graph in this way has the same outcome as generating a graph by flipping a coin for each pair of vertices to decide whether to connect them. Therefore, equivalently to the preceding definition, A contains almost all graphs if the probability that a coin flip-generated graph with n vertices is in A tends to 1 as n tends to infinity. Sometimes the latter definition is modified so that the graph is chosen randomly in some other way, where not all graphs with n vertices have the same probability, and those modified definitions are not always equivalent to the main one.\n\nThe use of the term \"almost all\" in graph theory is not standard; the term \"asymptotically almost surely\" is more commonly used for this concept.\n\nExample:\n\nIn topology and especially dynamical systems theory (including applications in economics), \"almost all\" of a topological space's points can mean \"all of the space's points but those in a meagre set\". Some use a more limited definition, where a subset only contains almost all of the space's points if it contains some open dense set.\n\nExample:\n\nIn abstract algebra and mathematical logic, if U is an on a set X, \"almost all elements of X\" sometimes means \"the elements of some \"element\" of U\". For any partition of X into two disjoint sets, one of them necessarily contains almost all elements of X. It is possible to think of the elements of a filter on X as containing almost all elements of X even if it isn't an ultrafilter.\n"}
{"id": "47950379", "url": "https://en.wikipedia.org/wiki?curid=47950379", "title": "Arditi–Ginzburg equations", "text": "Arditi–Ginzburg equations\n\nThe Arditi–Ginzburg equations describe ratio dependent predator–prey dynamics. Where \"N\" is the population of a prey species and \"P\" that of a predator, the population dynamics are described by the following two equations:\n\nHere \"f\"(\"N\") captures any change in the prey population not due to predator activity including inherent birth and death rates. The per capita effect of predators on the prey population (the harvest rate) is modeled by a function \"g\" which is a function of the ratio \"N\"/\"P\" of prey to predators. Predators receive a reproductive payoff, \"e,\" for consuming prey, and die at rate \"u\". Making predation pressure a function of the ratio of prey to predators contrasts with the prey dependent Lotka–Volterra equations, where the effect of predators on the prey population is simply a function of the magnitude of the prey population \"g\"(\"N\"). Because the number of prey harvested by each predator decreases as predators become more dense, ratio dependent predation represents an example of a trophic function. Ratio dependent predation may account for heterogeneity in large-scale natural systems in which predator efficiency decreases when prey is scarce. The merit of ratio dependent versus prey dependent models of predation has been the subject of much controversy, especially between the biologists Lev R. Ginzburg and Peter A. Abrams. Ginzburg purports that ratio dependent models more accurately depict predator-prey interactions while Abrams maintains that these models make unwarranted complicating assumptions.\n\n"}
{"id": "19410107", "url": "https://en.wikipedia.org/wiki?curid=19410107", "title": "Arithmeum", "text": "Arithmeum\n\nThe Arithmeum is a mathematics museum owned by the Forschungsinstitut für Diskrete Mathematik (Research Institute for Discrete Mathematics) at the University of Bonn.\n\nIt was founded by the Director of the Institute, Bernhard Korte, who contributed his private collection of calculating machines.\n\nThe building's steel-glass facade - located at Lennéstrasse 2 - is meant to represent the \"transparency of science\".\n\nThe permanent exhibit \"Calculating in Olden and Modern Times\" () shows the progression of mechanical calculating machines through 1,200 pieces.\n\nIt holds the very large,(4000 pieces), IJzebrand Schuitema (1929-2013) 400 year collection of slide rules.\n\nThere are also exhibits on very-large-scale integrated (VLSI) logic chips, historical arithmetic books dating back to Johannes Gutenberg's times, and the relationship between art and science.\n\n"}
{"id": "31338378", "url": "https://en.wikipedia.org/wiki?curid=31338378", "title": "Boolean-valued", "text": "Boolean-valued\n\nBoolean-valued usually refers to:\n\n"}
{"id": "32809583", "url": "https://en.wikipedia.org/wiki?curid=32809583", "title": "Chihara–Ismail polynomials", "text": "Chihara–Ismail polynomials\n\nIn mathematics, the Chihara–Ismail polynomials are a family of orthogonal polynomials introduced by , generalizing the van Doorn polynomials introduced by and the Karlin–McGregor polynomials. They have a rather unusual measure, which is discrete except for a single limit point at 0 with jump 0, and is non-symmetric, but whose support has an infinite number of both positive and negative points.\n\n"}
{"id": "2870898", "url": "https://en.wikipedia.org/wiki?curid=2870898", "title": "Cocycle", "text": "Cocycle\n\nIn mathematics a cocycle is a closed cochain. Cocycles are used in algebraic topology to express obstructions (for example, to integrating a differential equation on a closed manifold). They are likewise used in group cohomology. In autonomous dynamical systems, cocycles are used to describe particular kinds of map, as in the Oseledec theorem.\n\n"}
{"id": "47790980", "url": "https://en.wikipedia.org/wiki?curid=47790980", "title": "Control variable (programming)", "text": "Control variable (programming)\n\nA control variable in computer programming is a program variable that is used to regulate the flow of control of the program.\n\nIn definite iteration, control variables are variables which are successively assigned (or bound to) values from a predetermined sequence of values.\n\nIn some programming languages control variables are just ordinary variables used for manipulating the program flow. This is the case of C, Fortran, and Pascal, which allow for control variables to have their values changed within the loop body. However, some languages have special rules for control variables. In Ada, for instance, the control variable of the for loop must remain constant within the loop body.\n"}
{"id": "26661047", "url": "https://en.wikipedia.org/wiki?curid=26661047", "title": "Counting rods", "text": "Counting rods\n\nCounting rods () are small bars, typically 3–14 cm long, that were used by mathematicians for calculation in ancient East Asia. They are placed either horizontally or vertically to represent any integer or rational number.\n\nThe written forms based on them are called rod numerals. They are a true positional numeral system with digits for 1–9 and a blank for 0, from the Warring states period (circa 475 BCE) to the 16th century.\n\nChinese arithmeticians used counting rods well over two thousand years ago. In 1954 forty-odd counting rods of the Warring States period (5th century BCE to 221 BCE) were found in Zuǒjiāgōngshān (左家公山) Chu Grave No.15 in Changsha, Hunan.\n\nIn 1973 archeologists unearthed a number of wood scripts from a tomb in Hubei dating from the period of the Han dynasty (206 BCE to 220 CE). On one of the wooden scripts was written: \"当利二月定算\". This is one of the earliest examples of using counting-rod numerals in writing.\n\nIn 1976 a bundle of Western Han-era (202 BCE to 9 CE) counting rods made of bones was unearthed from Qianyang County in Shaanxi. The use of counting rods must predate it; Sunzi ( 544 to 496 BCE), a military strategist at the end of Spring and Autumn period of 771 BCE to 5th century BCE, mentions their use to make calculations to win wars before going into the battle; Laozi (died 531 BCE), writing in the Warring States period, said \"a good calculator doesn't use counting rods\". The \"Book of Han\" (finished 111 CE) recorded: \"they calculate with bamboo, diameter one fen, length six cun, arranged into a hexagonal bundle of two hundred seventy one pieces\".\n\nAt first, calculating rods were round in cross-section, but by the time of the Sui dynasty (581 to 618 CE) mathematicians used triangular rods to represent positive numbers and rectangular rods for negative numbers.\n\nAfter the abacus flourished, counting rods were abandoned except in Japan, where rod numerals developed into a symbolic notation for algebra.\n\nCounting rods represent digits by the number of rods, and the perpendicular rod represents five. To avoid confusion, vertical and horizontal forms are alternately used. Generally, vertical rod numbers are used for the position for the units, hundreds, ten thousands, etc., while horizontal rod numbers are used for the tens, thousands, hundred thousands etc. It is written in \"Sunzi Suanjing\" that \"one is vertical, ten is horizontal\".\n\nRed rods represent positive numbers and black rods represent negative numbers. Ancient Chinese clearly understood negative numbers and zero (leaving a blank space for it), though they had no symbol for the latter. The Nine Chapters on the Mathematical Art, which was mainly composed in the first century CE, stated \"(when using subtraction) subtract same signed numbers, add different signed numbers, subtract a positive number from zero to make a negative number, and subtract a negative number from zero to make a positive number\". Later, a go stone was sometimes used to represent zero.\n\nThis alternation of vertical and horizontal rod numeral form is very important to understanding written transcription of rod numerals on manuscripts correctly. For instance, in Licheng suanjin, 81 was transcribed as , and 108 was transcribed as ; it is clear that the latter clearly had a blank zero on the \"counting board\" (i.e., floor or mat), even though on the written transcription, there was no blank. In the same manuscript, 405 was transcribed as , with a blank space in between for obvious reasons, and could in no way be interpreted as \"45\". In other words, transcribed rod numerals may not be positional, but on the counting board, they are positional. is an exact image of the counting rod number 405 on a table top or floor.\n\nThe value of a number depends on its physical position on the counting board. A 9 at the rightmost position on the board stands for 9. Moving the batch of rods representing 9 to the left one position (i.e., to the tens place) gives 9[] or 90. Shifting left again to the third position (to the hundreds place) gives 9[][] or 900. Each time one shifts a number one position to the left, it is multiplied by 10. Each time one shifts a number one position to the right, it is divided by 10. This applies to single-digit numbers or multiple-digit numbers.\n\nSong dynasty mathematician Jia Xian used hand-written Chinese decimal orders 步十百千萬 as rod numeral place value, as evident from a facsimile from a page of Yongle Encyclopedia. He arranged 七萬一千八百二十四 as\n\nHe treated the Chinese order numbers as place value markers, and 七一八二四 became place value decimal number. He then wrote the rod numerals according to their place value:\n\nIn Japan, mathematicians put counting rods on a counting board, a sheet of cloth with grids, and used only vertical forms relying on the grids. An 18th-century Japanese mathematics book has a checker counting board diagram, with the order of magnitude symbols \"千百十一分厘毛“(thousand, hundred, ten, unit, tenth, hundredth, thousandth).\n\nExamples:\nRod numerals are a positional numeral system made from shapes of counting rods. Positive numbers are written as they are and the negative numbers are written with a slant bar at the last digit. The vertical bar in the horizontal forms 6–9 are drawn shorter to have the same character height.\n\nA circle (〇) is used for 0. Many historians think it was imported from Indian numerals by Gautama Siddha in 718, but some think it was created from the Chinese text space filler \"□\", and others think that the Indians acquired it from China, because it resembles a Confucian philosophical symbol for \"nothing\".\n\nIn the 13th century, Southern Song mathematicians changed digits for 4, 5, and 9 to reduce strokes. The new horizontal forms eventually transformed into Suzhou numerals. Japanese continued to use the traditional forms.\n\nExamples:\nIn Japan, Seki Takakazu developed the rod numerals into symbolic notation for algebra and drastically improved Japanese mathematics. After his period, the positional numeral system using Chinese numeral characters was developed, and the rod numerals were used only for the plus and minus signs. \n\nA fraction was expressed with rod numerals as two rod numerals one on top of another (without any other symbol, like the modern horizontal bar).\n\nThe method for using counting rods for mathematical calculation was called \"rod calculation\" or rod calculus (筹算). Rod calculus can be used for a wide range of calculations, including finding the value of , finding square roots, cube roots, or higher order roots, and solving a system of linear equations.\n\nBefore the introduction of written zero, there was no way to distinguish 10007 and 107 in written forms except by inserting a bigger space between 1 and 7, and so rod numerals were used only for doing calculations with counting rods. Once written zero came into play, the rod numerals had become independent, and their use indeed outlives the counting rods, after its replacement by abacus. One variation of horizontal rod numerals, the Suzhou numerals is still in use for book-keeping and in herbal medicine prescription in Chinatowns in some parts of the world.\n\nUnicode 5.0 includes counting rod numerals in their own block in the Supplementary Multilingual Plane (SMP) from U+1D360 to U+1D37F. The code points for the horizontal digits 1–9 are U+1D360 to U+1D368 and those for the vertical digits 1–9 are U+1D369 to U+1D371. The former are called \"unit digits\" and the latter are called \"tens digits\", which is opposite of the convention described above. Zero should be represented by U+3007 (〇, ideographic number zero) and the negative sign should be represented by U+20E5 (combining reverse solidus overlay). As these were recently added to the character set and since they are included in the SMP, font support may still be limited.\n\n\nFor a look of the ancient counting rods, and further explanation, you can visit the sites\n"}
{"id": "6166234", "url": "https://en.wikipedia.org/wiki?curid=6166234", "title": "Cryptomorphism", "text": "Cryptomorphism\n\nIn mathematics, two objects, especially systems of axioms or semantics for them, are called cryptomorphic if they are equivalent but not obviously equivalent. This word is a play on the many morphisms in mathematics, but \"cryptomorphism\" is only very distantly related to \"isomorphism\", \"homomorphism\", or \"morphisms\". The equivalence may possibly be in some informal sense, or may be formalized in terms of a bijection or equivalence of categories between the mathematical objects defined by the two cryptomorphic axiom systems.\n\nThe word was coined by Garrett Birkhoff before 1967, for use in the third edition of his book \"Lattice Theory\". Birkhoff did not give it a formal definition, though others working in the field have made some attempts since.\n\nIts informal sense was popularized (and greatly expanded in scope) by Gian-Carlo Rota in the context of matroid theory: there are dozens of equivalent axiomatic approaches to matroids, but two different systems of axioms often look very different. \n\nIn his 1997 book \"Indiscrete Thoughts\", Rota describes the situation as follows:\n\nThough there are many cryptomorphic concepts in mathematics outside of matroid theory and universal algebra, the word has not caught on among mathematicians generally. It is, however, in fairly wide use among researchers in matroid theory.\n\n\n"}
{"id": "33439201", "url": "https://en.wikipedia.org/wiki?curid=33439201", "title": "Electoral Calculus", "text": "Electoral Calculus\n\nElectoral Calculus is a political forecasting web site which attempts to predict future United Kingdom general election results. It considers national factors but excludes local issues.\n\nThe site was developed by Martin Baxter, who is a financial analyst specialising in mathematical modelling.\n\nThe site includes maps, predictions and analysis articles. It has a separate section for elections in Scotland.\n\nThe site is based around the employment of scientific techniques on data about Britain's electoral geography, which can be used to calculate the uniform national swing. It takes account of national polls and trends but excludes local issues.\n\nThe calculations were initially based on what is termed the \"Transition Model\", which is derived from the additive uniform national swing model. This uses national swings in a proportional manner to predict local effects. The \"Strong Transition Model\" was introduced in October 2007, and considers the effects of strong and weak supporters. The models are explained in detail on the web site.\n\nIt was listed by \"The Guardian\" in 2004 as one of the \"100 most useful websites\", being \"the best\" for predictions. In 2012 it was described by PhD student Chris Prosser at the University of Oxford as \"probably the leading vote/seat predictor on the internet\". Its detailed predictions for individual seats have been noted by Paul Evans on the localdemocracy.org.uk blog. Academic Nick Anstead noted in his observations from a 2010 \"Personal Democracy Forum\" event, that Mick Fealty of Slugger O'Toole considered Electoral Calculus to be \"massively improved\" in comparison with the swingometer.\n\nWith reference to the 2010 United Kingdom general election, it was cited by journalists Andrew Rawnsley and Michael White in \"The Guardian\". John Rentoul in \"The Independent\" referred to the site after the election.\n\n"}
{"id": "23831652", "url": "https://en.wikipedia.org/wiki?curid=23831652", "title": "Erdős Prize", "text": "Erdős Prize\n\nThe Anna and Lajos Erdős Prize in Mathematics is a prize given by the Israel Mathematical Union to an Israeli mathematician (in any field of mathematics and computer science), \"with preference to candidates up to the age of 40.\" The prize was established by Paul Erdős in 1977 in honor of his parents, and is awarded annually or biannually. The name was changed from \"Erdős Prize\" in 1996, after Erdős's death, to reflect his original wishes.\n\nSource: Israel Mathematical Union\n"}
{"id": "7043631", "url": "https://en.wikipedia.org/wiki?curid=7043631", "title": "Generalized inverse", "text": "Generalized inverse\n\nIn mathematics, and in particular, algebra, a generalized inverse of an element \"x\" is an element \"y\" that has some properties of an inverse element but not necessarily all of them. Generalized inverses can be defined in any mathematical structure that involves associative multiplication, that is, in a semigroup. This article describes generalized inverses of a matrix formula_1.\n\nFormally, given a matrix formula_2 and a matrix formula_3, formula_4 is a generalized inverse of formula_1 if it satisfies the condition formula_6.\n\nThe purpose of constructing a generalized inverse of a matrix is to obtain a matrix that can serve as an inverse in some sense for a wider class of matrices than invertible matrices. A generalized inverse exists for an arbitrary matrix, and when a matrix has a regular inverse, this inverse is its unique generalized inverse.\n\nConsider the linear system\n\nwhere formula_1 is an formula_9 matrix and formula_10, the column space of formula_1. If formula_1 is nonsingular (which implies formula_13) then formula_14 will be the solution of the system. Note that, if formula_1 is nonsingular, then\n\nNow suppose formula_1 is rectangular (formula_18), or square and singular. Then we need a right candidate formula_19 of order formula_20 such that for all formula_10,\n\nThat is, formula_23 is a solution of the linear system formula_7. \nEquivalently, we need a matrix formula_19 of order formula_26 such that\n\nHence we can define the generalized inverse or g-inverse as follows: Given an formula_9 matrix formula_1, an formula_20 matrix formula_19 is said to be a generalized inverse of formula_1 if formula_27 The matrix formula_34 has been termed a regular inverse of formula_1 by some authors.\n\nThe Penrose conditions define different generalized inverses for formula_2 and formula_37\n\n\nwhere formula_42 indicates conjugate transpose. If formula_4 satisfies the first condition, then it is a generalized inverse of formula_1. If it satisfies the first two conditions, then it is a reflexive generalized inverse of formula_1. If it satisfies all four conditions, then it is the pseudoinverse of formula_1. A pseudoinverse is sometimes called the Moore–Penrose inverse, after the pioneering works by E. H. Moore and Roger Penrose. \n\nWhen formula_1 is non-singular, any generalized inverse formula_48 and is unique, but in all other cases, there are an infinite number of matrices that satisfy condition (1). However, the Moore–Penrose inverse is unique.\n\nThere are other kinds of generalized inverse:\n\n\nLet\n\nSince formula_68, formula_69 is singular and has no regular inverse. However, formula_69 and formula_71 satisfy conditions (1) and (2), but not (3) or (4). Hence, formula_71 is a reflexive generalized inverse of formula_69.\n\nLet\n\nSince formula_69 is not square, formula_69 has no regular inverse. However, formula_77 is a right inverse of formula_69. The matrix formula_69 has no left inverse.\n\nThe following characterizations are easy to verify:\n\nAny generalized inverse can be used to determine whether a system of linear equations has any solutions, and if so to give all of them. If any solutions exist for the \"n\" × \"m\" linear system\n\nwith vector formula_81 of unknowns and vector formula_82 of constants, all solutions are given by \n\nparametric on the arbitrary vector formula_84, where formula_4 is any generalized inverse of formula_1. Solutions exist if and only if formula_87 is a solution, that is, if and only if formula_88. If \"A\" has full column rank, the bracketed expression in this equation is the zero matrix and so the solution is unique.\n\nIn practical applications it is necessary to identify the class of matrix transformations that must be preserved by a generalized inverse. For example, the Moore-Penrose inverse, formula_89, satisfies the following definition of consistency with respect to transformations involving unitary matrices \"U\" and \"V\":\n\nThe Drazin inverse, formula_91 satisfies the following definition of consistency with respect to similarity transformations involving a nonsingular matrix \"S\":\n\nThe Unit-Consistent (UC) inverse, formula_93, satisfies the following definition of consistency with respect to transformations involving nonsingular diagonal matrices \"D\" and \"E\":\n\nThe fact that the Moore-Penrose inverse provides consistency with respect to rotations (which are orthonormal transformations) explains its widespread use in physics and other applications in which Euclidean distances must be preserved. The UC inverse, by contrast, is applicable when system behavior is expected to be invariant with respect to the choice of units on different state variables, e.g., miles versus kilometers.\n\n\n"}
{"id": "7392980", "url": "https://en.wikipedia.org/wiki?curid=7392980", "title": "Graduate Texts in Mathematics", "text": "Graduate Texts in Mathematics\n\nGraduate Texts in Mathematics (GTM) (ISSN 0072-5285) is a series of graduate-level textbooks in mathematics published by Springer-Verlag. The books in this series, like the other Springer-Verlag mathematics series, are yellow books of a standard size (with variable numbers of pages). The GTM series is easily identified by a white band at the top of the book.\n\nThe books in this series tend to be written at a more advanced level than the similar Undergraduate Texts in Mathematics series, although there is a fair amount of overlap between the two series in terms of material covered and difficulty level.\n\n\n\n"}
{"id": "945503", "url": "https://en.wikipedia.org/wiki?curid=945503", "title": "Hellenic Mathematical Society", "text": "Hellenic Mathematical Society\n\nThe Hellenic Mathematical Society (HMS) (Greek: Ελληνική Μαθηματική Εταιρεία) is a learned society which promotes the study of mathematics in Greece. It was founded in 1918, and published the \"Bulletin of the Greek Mathematical Society\".\n\nIt is a member of the European Mathematical Society. \n\n\n\n"}
{"id": "43131303", "url": "https://en.wikipedia.org/wiki?curid=43131303", "title": "Historical dynamics", "text": "Historical dynamics\n\nHistorical dynamics broadly includes the scientific modeling of history. This might also be termed computer modeling of history, historical simulation, or simulation of history - allowing for an extensive range of techniques in simulation and estimation. Historical dynamics does not exist as a separate science, but there are individual efforts such as long range planning, population modeling, economic forecasting, demographics, global modeling, country modeling, regional planning, urban planning and many others in the general categories of computer modeling, planning, forecasting, and simulations.\n\nSome examples of \"large\" history where historical dynamics simulations would be helpful include; global history, large structures, , long duration history, philosophy of history, Eurasian history, comparative history, long-range environmental history, world systems theory, non-Western political and economic development, and historical demography.\nWith the rise of technologies like wikis, and internet-wide search engines, some historical and social data can be mined to constrain models of history and society. Data from social media sites, and busy sites, can be mined for human patterns of action. These can provide more and more realistic behavioral models for individuals and groups of any size. Agent-based models and microsimulations of human behavior can be embedded in larger historical simulations. Related subfields are behavioral economics and human behavioral ecology.\n\nIn every sector of human activity, there are extensive databases for transportation data, urban development, health statistics, education data, social data, economic data—along with many projections. See , , , and .\n\nSome examples of database activity include Asian Development Bank statistics, World Bank data, and the International Monetary Fund data.\n\nTime series analysis and econometrics are well established fields for the analysis of trends and forecasting; but, survey data and microdatasets can also be used in forecasts and simulations.\n\nThe United Nations and other organizations routinely project the population of individual countries and regions of the world decades into the future. These demographic models are used by other organizations for projecting demand for services in all sectors of each economy.\n\n\nEach country often has their corresponding modeling groups for each of these major sectors. These can be grouped in separate articles according to sector. Groups include government departments, international aid agencies, as well as nonprofit and non-governmental organizations.\n\nA broad class of models used for economic and social modeling of countries and sectors are the Computable general equilibrium (CGE) model - also called applied general equilibrium models. In the context of time based simulations and policy analysis, see dynamic stochastic general equilibrium models.\n\nPartly because of the controversy over global climate change, there is an extensive network of global climate models, and related social and economic models. These seek to estimate, not only the change in climate and its physical effects, but also the impact on human society and the natural environment. See global economic models, social model, microsimulation, climate model, global climate models, and general circulation model.\n\nThe relationship between the environment and society is examined through environmental social science. human ecology, political ecology, and ecology, in general, can be areas where computer and mathematical modeling over time can be relevant to historical simulation.\n\nWeb-based historical simulations, simulations of history, interactive historical simulations, are increasingly popular for entertainment and educational purposes. The field is expanding rapidly and no central index seems to be available. Another example is \n\nSeveral computer games allow players to interact with the game to model societies over time. The Civilization (series) is one example. Others include Age of Empires, Rise of Nations, Spore, Colonization, Alpha Centauri, Call to Power, and . A longer list of games in historical context, which might include degrees of simulation, are found at .\n\nMilitary simulation is a well-developed field and increasingly accessible on the internet.\n\nComputer models for simulating society fall under artificial society, social simulation, computational sociology, computational social science, and mathematical sociology. There is an interdisciplinary Journal of Artificial Societies and Social Simulation for computer simulation of social processes. The European Social Simulation Association promotes social simulation research in Europe; it is the publisher of JASSS. There is a corresponding Computational Social Science Society of the Americas., and a Pan-Asian Association for Agent-based Approach in Social Systems Sciences. PAAA lists some related Japanese associations.\n\nThe SimSoc (Simulated Society tool) is in its fifth edition.\n\nThere has been extensive research in urban planning, environmental planning and related fields: regional planning, land-use planning, transportation planning, urban studies, and regional science. Journals for these fields are listed at List of planning journals.\n\nSimCity is a game for simulations of artificial cities. It has spawned a range of \"sim\" games. The planning groups try to simulate changes in real cities. The game groups allow experiments with artificial cities. And the two are merging in such efforts as Vizicities\n\nThe profiling of industries is well developed, and most industries make forecasts and plans. See industrial history, history of steel, history of mining, history of construction, history of the petroleum industry, and many other histories of specific industries. See cyclical industrial dynamics for modeling of industries in the sense of \"historical dynamics of industries\". Some related terms are industrial planning, history of industry, industrial evolution, technology change, and technology forecasting. An example of \"history friendly\" industrial models. from the journal, Industrial and Corporate Change.\n\nEconomy-wide models must take into account the interactions between industry and the rest of the economy. See Input–output model, economic planning, and social accounting matrix for some relevant techniques.\n\nMany of the techniques from futures studies are applicable to historical dynamics. Whether projecting forward from a point in the past to the present for validation studies, or projecting backwards from the present into the past - many of the techniques are useful. Likewise, simulations of the past, or alternative pasts, provide a groundwork of techniques for futures studies.\n\n"}
{"id": "8122079", "url": "https://en.wikipedia.org/wiki?curid=8122079", "title": "Introduction to Commutative Algebra", "text": "Introduction to Commutative Algebra\n\nIntroduction to Commutative Algebra is a well-known commutative algebra textbook written by Michael Atiyah and Ian G. Macdonald. It deals with elementary concepts of commutative algebra including localization, primary decomposition, integral dependence, Noetherian and Artinian rings and modules, Dedekind rings, completions and a moderate amount of dimension theory. It is notable for being among the shorter English-language introductory textbooks in the subject, relegating a good deal of material to the exercises. \n"}
{"id": "9087019", "url": "https://en.wikipedia.org/wiki?curid=9087019", "title": "Inverse Symbolic Calculator", "text": "Inverse Symbolic Calculator\n\nThe Inverse Symbolic Calculator is an online number checker established July 18, 1995 by Peter Benjamin Borwein, Jonathan Michael Borwein and Simon Plouffe of the Canadian Centre for Experimental and Constructive Mathematics (Burnaby, Canada). A user will input a number and the Calculator will use an algorithm to search for and calculate closed-form expressions or suitable functions that have roots near this number. Hence, the calculator is of great importance for those working in numerical areas of experimental mathematics.\n\nThe ISC contains 54 million mathematical constants. Plouffe's Inverter (opened in 1998) contains 214 million. A newer version of the tables with 3.702 billion entries (as of June 19, 2010) exists.\n\nIn 2016, Plouffe released a portable version of Plouffe's Inverter containing 3 billion entries.\n\n\n\n"}
{"id": "11851829", "url": "https://en.wikipedia.org/wiki?curid=11851829", "title": "Krieger–Nelson Prize", "text": "Krieger–Nelson Prize\n\nThe Krieger–Nelson Prize is presented by the Canadian Mathematical Society in recognition of an outstanding woman in mathematics. It was first\nawarded in 1995. The award is named after Cecilia Krieger and Evelyn Nelson, both known for their contributions to mathematics in Canada.\n\nWhile the award has largely been awarded to a female mathematician working at a Canadian University, it has also been awarded to Canadian-born or -educated women working outside of the country. For example, Cathleen Morawetz, past president of the American Mathematical Society, and a faculty member at the Courant Institute of Mathematical Sciences (a division of New York University) was awarded the Krieger–Nelson Prize in 1997. (Morawetz was educated at the University of Toronto in Toronto, Canada). According to the call for applications, the award winner should be a \"member of the Canadian mathematical community\".\n\nThe recipient of the Krieger–Nelson Prize delivers a lecture to the Canadian Mathematical Society, typically during its summer meeting.\n"}
{"id": "18634", "url": "https://en.wikipedia.org/wiki?curid=18634", "title": "Lemma (mathematics)", "text": "Lemma (mathematics)\n\nIn mathematics, a \"helping theorem\" or lemma (plural lemmas or lemmata) is a proven proposition which is used as a stepping stone to a larger result rather than as a statement of interest by itself. The word derives from the Ancient Greek λῆμμα (\"anything which is received, such as a gift, profit, or a bribe\"). \n\nThere is no formal distinction between a lemma and a theorem, only one of intention – see Theorem terminology. However, a lemma can be considered a minor result whose sole purpose is to help prove a theorem  – a step in the direction of proof – or a short theorem appearing at an intermediate stage in a proof.\n\nA good stepping stone can lead to many others. Some powerful results in mathematics are known as lemmas, such as Bézout's lemma, Dehn's lemma, Euclid's lemma, Farkas' lemma, Fatou's lemma, Gauss's lemma, Greendlinger's lemma, Itō's lemma, Jordan's lemma, Nakayama's lemma, Poincaré's lemma, Riesz's lemma, Schur's lemma, Schwarz's lemma, Urysohn's lemma, Vitali covering lemma, Yoneda's lemma and Zorn's lemma. While these results originally seemed too simple or too technical to warrant independent interest, they have turned out to be central to the theories in which they occur.\n\n\n"}
{"id": "342038", "url": "https://en.wikipedia.org/wiki?curid=342038", "title": "List of Lie groups topics", "text": "List of Lie groups topics\n\nThis is a list of Lie group topics, by Wikipedia page.\n\n\"See Table of Lie groups for a list\"\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "336815", "url": "https://en.wikipedia.org/wiki?curid=336815", "title": "List of conjectures by Paul Erdős", "text": "List of conjectures by Paul Erdős\n\nThe prolific mathematician Paul Erdős and his various collaborators made many famous mathematical conjectures, over a wide field of subjects, and in many cases Erdős offered monetary rewards for solving them.\n\n\n\n\n"}
{"id": "9212913", "url": "https://en.wikipedia.org/wiki?curid=9212913", "title": "List of impossible puzzles", "text": "List of impossible puzzles\n\nThis is a list of puzzles that cannot be solved.\n\n\n"}
{"id": "39728316", "url": "https://en.wikipedia.org/wiki?curid=39728316", "title": "List of polygons", "text": "List of polygons\n\nIn geometry, a polygon is traditionally a plane figure that is bounded by a finite chain of straight line segments closing in a loop to form a closed chain. These segments are called its \"edges\" or \"sides\", and the points where two edges meet are the polygon's \"vertices\" (singular: vertex) or \"corners\".\n\nThe word polygon comes from Late Latin \"polygōnum\" (a noun), from Greek πολύγωνον (\"polygōnon/polugōnon\"), noun use of neuter of πολύγωνος (\"polygōnos/polugōnos\", the masculine adjective), meaning \"many-angled\". Individual polygons are named (and sometimes classified) according to the number of sides, combining a Greek-derived numerical prefix with the suffix \"-gon\", e.g. \"pentagon\", \"dodecagon\". The triangle, quadrilateral and nonagon are exceptions, although the regular forms \"trigon\", \"tetragon\", and \"enneagon\" are sometimes encountered as well.\n\nPolygons are primarily named by prefixes from Greek numbers.\n\nTo construct the name of a polygon with more than 20 and fewer than 100 edges, combine the prefixes as follows. The \"kai\" connector is not included by some authors.\nExtending the system up to 999 is expressed with these prefixes.\n\n"}
{"id": "24664148", "url": "https://en.wikipedia.org/wiki?curid=24664148", "title": "Logicomix", "text": "Logicomix\n\nLogicomix: An Epic Search for Truth is a graphic novel about the foundational quest in mathematics, written by Apostolos Doxiadis, author of \"Uncle Petros and Goldbach's Conjecture\", and theoretical computer scientist Christos Papadimitriou of the University of California, Berkeley. Character design and artwork are by Alecos Papadatos and color is by Annie Di Donna. The book was originally written in English, and was translated into Greek by author Apostolos Doxiadis for the release in Greece, which preceded the UK and U.S. releases.\n\nSet between the late 19th century and the present day, the graphic novel \"Logicomix\" is based on the story of the so-called \"foundational quest\" in mathematics.\n\n\"Logicomix\" intertwines the philosophical struggles with the characters' own personal turmoil. These are in turn played out just upstage of the momentous historical events of the era and the ideological battles which gave rise to them. The narrator of the story is Bertrand Russell, who stands as an icon of many of these themes: a deeply sensitive and introspective man, Russell was not just a philosopher and pacifist, he was also one of the prominent figures in the foundational quest. Russell's life story, depicted by \"Logicomix\", is itself a journey through the goals and struggles, and triumph and tragedy shared by many great thinkers of the 20th century: Georg Cantor, Ludwig Wittgenstein, G. E. Moore, Alfred North Whitehead, David Hilbert, Gottlob Frege, Henri Poincaré, Kurt Gödel, and Alan Turing.\n\nA parallel tale, set in present-day Athens, records the creators’ disagreement on the meaning of the story, thus setting in relief the foundational quest as a quintessentially modern adventure. It is on the one hand a tragedy of the hubris of rationalism, which descends inextricably on madness, and on the other an origin myth of the computer.\n\nIn chronological order:\n\nJim Holt reviewed the book for the \"New York Times\" and says the story \"is presented with real graphic verve. (Even though I’m a text guy, I couldn’t keep my eyes off the witty drawings.)\" although he does note \"one serious misstep\" involving the overplaying of the impact Russell's paradox had on mathematics. A review at \"The Guardian\" said that the \"authors tell the story with a humour and lightness of touch that pokes fun at the philosophers and mathematicians involved, but never trivialises the philosophy or the mathematics\" concluding that \"Doxiadis has shown that by using fiction to provide an emotional context to mathematical discoveries it can make for a gripping read. Uncle Petros was a bestseller and the much more ambitious Logicomix deserves to be one too.\"\n\nThe book was recommended by the \"New Statesman\" in late September. On October 2 the book made the New York Times, Sunday Book Review, Editor's Choice list and the next week it was #1 on the NYT Graphic Novel Best Seller list. The book sold out on the day it was released in the United States and United Kingdom, and also got into the Top 10 on Amazon.com and Amazon.co.uk, leading the manager of a major Athens bookstore to say \"No Greek book has sold abroad like this in 30 years.\"\n\nAccording to Paolo Mancosu, the authors \"admittedly take liberties with the real course of events\", for example with reference to the alleged meetings Russell would have had with Frege and Cantor. Although \"such departures from reality can be fruitful for narrative purposes\", according to Mancosu, in some cases they are objectionable, as the portrayal of Frege as a \"rabid paranoid antisemite\", and the \"constant refrain of the alleged causal link between logic and madness\". From \"the conceptual point of view, some of the major ideas about the foundation of mathematics are conveyed with reasonable accuracy\", although sometimes errors, mistakes and inaccuracies occur.\n\nHowever, the global judgement by Mancosu is positive:\n\n\n"}
{"id": "29515785", "url": "https://en.wikipedia.org/wiki?curid=29515785", "title": "MAOL table book", "text": "MAOL table book\n\nThe MAOL table book (Finnish: \"MAOL-taulukot\") is a book published by MAOL, the Finnish association for teachers of mathematical subjects and distributed by Otava. It is a book of numeric tables to aid in studying mathematics, chemistry and physics at the gymnasium level. The book includes a list of mathematical notation and symbols, a diverse collection of formulae, and several numeric tables. The Finnish matricular examination board has accepted the book and allowed it to be used in the Finnish abitur examinations.\n\nThe colour of the cover of the book is changed with each edition of the book.\n\n"}
{"id": "18831", "url": "https://en.wikipedia.org/wiki?curid=18831", "title": "Mathematics", "text": "Mathematics\n\nMathematics (from Greek μάθημα \"máthēma\", \"knowledge, study, learning\") includes the study of such topics as quantity, structure, space, and change.\n\nMathematicians seek and use patterns to formulate new conjectures; they resolve the truth or falsity of conjectures by mathematical proof. When mathematical structures are good models of real phenomena, then mathematical reasoning can provide insight or predictions about nature. Through the use of abstraction and logic, mathematics developed from counting, calculation, measurement, and the systematic study of the shapes and motions of physical objects. Practical mathematics has been a human activity from as far back as written records exist. The research required to solve mathematical problems can take years or even centuries of sustained inquiry.\n\nRigorous arguments first appeared in Greek mathematics, most notably in Euclid's \"Elements\". Since the pioneering work of Giuseppe Peano (1858–1932), David Hilbert (1862–1943), and others on axiomatic systems in the late 19th century, it has become customary to view mathematical research as establishing truth by rigorous deduction from appropriately chosen axioms and definitions. Mathematics developed at a relatively slow pace until the Renaissance, when mathematical innovations interacting with new scientific discoveries led to a rapid increase in the rate of mathematical discovery that has continued to the present day.\n\nMathematics is essential in many fields, including natural science, engineering, medicine, finance and the social sciences. Applied mathematics has led to entirely new mathematical disciplines, such as statistics and game theory. Mathematicians engage in pure mathematics, or mathematics for its own sake, without having any application in mind. Practical applications for what began as pure mathematics are often discovered.\n\nThe history of mathematics can be seen as an ever-increasing series of abstractions. The first abstraction, which is shared by many animals, was probably that of numbers: the realization that a collection of two apples and a collection of two oranges (for example) have something in common, namely quantity of their members.\n\nAs evidenced by tallies found on bone, in addition to recognizing how to count physical objects, prehistoric peoples may have also recognized how to count abstract quantities, like time – days, seasons, years.\n\nEvidence for more complex mathematics does not appear until around 3000 BC, when the Babylonians and Egyptians began using arithmetic, algebra and geometry for taxation and other financial calculations, for building and construction, and for astronomy. The most ancient mathematical texts from Mesopotamia and Egypt are from 2000–1800 BC. Many early texts mention Pythagorean triples and so, by inference, the Pythagorean theorem seems to be the most ancient and widespread mathematical development after basic arithmetic and geometry. It is in Babylonian mathematics that elementary arithmetic (addition, subtraction, multiplication and division) first appear in the archaeological record. The Babylonians also possessed a place-value system, and used a sexagesimal numeral system, still in use today for measuring angles and time.\n\nBeginning in the 6th century BC with the Pythagoreans, the Ancient Greeks began a systematic study of mathematics as a subject in its own right with Greek mathematics. Around 300 BC, Euclid introduced the axiomatic method still used in mathematics today, consisting of definition, axiom, theorem, and proof. His textbook \"Elements\" is widely considered the most successful and influential textbook of all time. The greatest mathematician of antiquity is often held to be Archimedes (c. 287–212 BC) of Syracuse. He developed formulas for calculating the surface area and volume of solids of revolution and used the method of exhaustion to calculate the area under the arc of a parabola with the summation of an infinite series, in a manner not too dissimilar from modern calculus. Other notable achievements of Greek mathematics are conic sections (Apollonius of Perga, 3rd century BC), trigonometry (Hipparchus of Nicaea (2nd century BC), and the beginnings of algebra (Diophantus, 3rd century AD).\n\nThe Hindu–Arabic numeral system and the rules for the use of its operations, in use throughout the world today, evolved over the course of the first millennium AD in India and were transmitted to the Western world via Islamic mathematics. Other notable developments of Indian mathematics include the modern definition of sine and cosine, and an early form of infinite series.\nDuring the Golden Age of Islam, especially during the 9th and 10th centuries, mathematics saw many important innovations building on Greek mathematics. The most notable achievement of Islamic mathematics was the development of algebra. Other notable achievements of the Islamic period are advances in spherical trigonometry and the addition of the decimal point to the Arabic numeral system. Many notable mathematicians from this period were Persian, such as Al-Khwarismi, Omar Khayyam and Sharaf al-Dīn al-Ṭūsī. \n\nDuring the early modern period, mathematics began to develop at an accelerating pace in Western Europe. The development of calculus by Newton and Leibniz in the 17th century revolutionized mathematics. Leonhard Euler was the most notable mathematician of the 18th century, contributing numerous theorems and discoveries. Perhaps the foremost mathematician of the 19th century was the German mathematician Carl Friedrich Gauss, who made numerous contributions to fields such as algebra, analysis, differential geometry, matrix theory,number theory, and statistics. In the early 20th century, Kurt Gödel transformed mathematics by publishing his incompleteness theorems, which show that any axiomatic system that is consistent will contain unprovable propositions.\n\nMathematics has since been greatly extended, and there has been a fruitful interaction between mathematics and science, to the benefit of both. Mathematical discoveries continue to be made today. According to Mikhail B. Sevryuk, in the January 2006 issue of the \"Bulletin of the American Mathematical Society\", \"The number of papers and books included in the \"Mathematical Reviews\" database since 1940 (the first year of operation of MR) is now more than 1.9 million, and more than 75 thousand items are added to the database each year. The overwhelming majority of works in this ocean contain new mathematical theorems and their proofs.\"\n\nThe word \"mathematics\" comes from Ancient Greek μάθημα (\"máthēma\"), meaning \"that which is learnt\", \"what one gets to know\", hence also \"study\" and \"science\". The word for \"mathematics\" came to have the narrower and more technical meaning \"mathematical study\" even in Classical times. Its adjective is (\"mathēmatikós\"), meaning \"related to learning\" or \"studious\", which likewise further came to mean \"mathematical\". In particular, (\"mathēmatikḗ tékhnē\"), , meant \"the mathematical art\".\n\nSimilarly, one of the two main schools of thought in Pythagoreanism was known as the \"mathēmatikoi\" (μαθηματικοί)—which at the time meant \"teachers\" rather than \"mathematicians\" in the modern sense.\n\nIn Latin, and in English until around 1700, the term \"mathematics\" more commonly meant \"astrology\" (or sometimes \"astronomy\") rather than \"mathematics\"; the meaning gradually changed to its present one from about 1500 to 1800. This has resulted in several mistranslations. For example, Saint Augustine's warning that Christians should beware of \"mathematici\", meaning astrologers, is sometimes mistranslated as a condemnation of mathematicians.\n\nThe apparent plural form in English, like the French plural form (and the less commonly used singular derivative ), goes back to the Latin neuter plural (Cicero), based on the Greek plural (\"ta mathēmatiká\"), used by Aristotle (384–322 BC), and meaning roughly \"all things mathematical\"; although it is plausible that English borrowed only the adjective \"mathematic(al)\" and formed the noun \"mathematics\" anew, after the pattern of \"physics\" and \"metaphysics\", which were inherited from Greek. In English, the noun \"mathematics\" takes a singular verb. It is often shortened to \"maths\" or, in North America, \"math\".\n\nMathematics has no generally accepted definition. Aristotle defined mathematics as \"the science of quantity\", and this definition prevailed until the 18th century. Galileo Galilei (1564–1642) said, \"The universe cannot be read until we have learned the language and become familiar with the characters in which it is written. It is written in mathematical language, and the letters are triangles, circles and other geometrical figures, without which means it is humanly impossible to comprehend a single word. Without these, one is wandering about in a dark labyrinth.\" Carl Friedrich Gauss (1777–1855) referred to mathematics as \"the Queen of the Sciences\". Benjamin Peirce (1809–1880) called mathematics \"the science that draws necessary conclusions\". David Hilbert said of mathematics: \"We are not speaking here of arbitrariness in any sense. Mathematics is not like a game whose tasks are determined by arbitrarily stipulated rules. Rather, it is a conceptual system possessing internal necessity that can only be so and by no means otherwise.\" Albert Einstein (1879–1955) stated that \"as far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality.\"\n\nStarting in the 19th century, when the study of mathematics increased in rigor and began to address abstract topics such as group theory and projective geometry, which have no clear-cut relation to quantity and measurement, mathematicians and philosophers began to propose a variety of new definitions. Some of these definitions emphasize the deductive character of much of mathematics, some emphasize its abstractness, some emphasize certain topics within mathematics. Today, no consensus on the definition of mathematics prevails, even among professionals. There is not even consensus on whether mathematics is an art or a science. A great many professional mathematicians take no interest in a definition of mathematics, or consider it undefinable. Some just say, \"Mathematics is what mathematicians do.\"\n\nThree leading types of definition of mathematics are called logicist, intuitionist, and formalist, each reflecting a different philosophical school of thought. All have severe problems, none has widespread acceptance, and no reconciliation seems possible.\n\nAn early definition of mathematics in terms of logic was Benjamin Peirce's \"the science that draws necessary conclusions\" (1870). In the \"Principia Mathematica\", Bertrand Russell and Alfred North Whitehead advanced the philosophical program known as logicism, and attempted to prove that all mathematical concepts, statements, and principles can be defined and proved entirely in terms of symbolic logic. A logicist definition of mathematics is Russell's \"All Mathematics is Symbolic Logic\" (1903).\n\nIntuitionist definitions, developing from the philosophy of mathematician L. E. J. Brouwer, identify mathematics with certain mental phenomena. An example of an intuitionist definition is \"Mathematics is the mental activity which consists in carrying out constructs one after the other.\" A peculiarity of intuitionism is that it rejects some mathematical ideas considered valid according to other definitions. In particular, while other philosophies of mathematics allow objects that can be proved to exist even though they cannot be constructed, intuitionism allows only mathematical objects that one can actually construct.\n\nFormalist definitions identify mathematics with its symbols and the rules for operating on them. Haskell Curry defined mathematics simply as \"the science of formal systems\". A formal system is a set of symbols, or \"tokens\", and some \"rules\" telling how the tokens may be combined into \"formulas\". In formal systems, the word \"axiom\" has a special meaning, different from the ordinary meaning of \"a self-evident truth\". In formal systems, an axiom is a combination of tokens that is included in a given formal system without needing to be derived using the rules of the system.\n\nThe German mathematician Carl Friedrich Gauss referred to mathematics as \"the Queen of the Sciences\". More recently, Marcus du Sautoy has called mathematics \"the Queen of Science ... the main driving force behind scientific discovery\". In the original Latin \"Regina Scientiarum\", as well as in German \"Königin der Wissenschaften\", the word corresponding to \"science\" means a \"field of knowledge\", and this was the original meaning of \"science\" in English, also; mathematics is in this sense a field of knowledge. The specialization restricting the meaning of \"science\" to \"natural science\" follows the rise of Baconian science, which contrasted \"natural science\" to scholasticism, the Aristotelean method of inquiring from first principles. The role of empirical experimentation and observation is negligible in mathematics, compared to natural sciences such as biology, chemistry, or physics. Albert Einstein stated that \"as far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality.\"\n\nMany philosophers believe that mathematics is not experimentally falsifiable, and thus not a science according to the definition of Karl Popper. However, in the 1930s Gödel's incompleteness theorems convinced many mathematicians that mathematics cannot be reduced to logic alone, and Karl Popper concluded that \"most mathematical theories are, like those of physics and biology, hypothetico-deductive: pure mathematics therefore turns out to be much closer to the natural sciences whose hypotheses are conjectures, than it seemed even recently.\" Other thinkers, notably Imre Lakatos, have applied a version of falsificationism to mathematics itself.\n\nAn alternative view is that certain scientific fields (such as theoretical physics) are mathematics with axioms that are intended to correspond to reality. Mathematics shares much in common with many fields in the physical sciences, notably the exploration of the logical consequences of assumptions. Intuition and experimentation also play a role in the formulation of conjectures in both mathematics and the (other) sciences. Experimental mathematics continues to grow in importance within mathematics, and computation and simulation are playing an increasing role in both the sciences and mathematics.\n\nThe opinions of mathematicians on this matter are varied. Many mathematicians feel that to call their area a science is to downplay the importance of its aesthetic side, and its history in the traditional seven liberal arts; others feel that to ignore its connection to the sciences is to turn a blind eye to the fact that the interface between mathematics and its applications in science and engineering has driven much development in mathematics. One way this difference of viewpoint plays out is in the philosophical debate as to whether mathematics is \"created\" (as in art) or \"discovered\" (as in science). It is common to see universities divided into sections that include a division of \"Science and Mathematics\", indicating that the fields are seen as being allied but that they do not coincide. In practice, mathematicians are typically grouped with scientists at the gross level but separated at finer levels. This is one of many issues considered in the philosophy of mathematics.\n\nMathematics arises from many different kinds of problems. At first these were found in commerce, land measurement, architecture and later astronomy; today, all sciences suggest problems studied by mathematicians, and many problems arise within mathematics itself. For example, the physicist Richard Feynman invented the path integral formulation of quantum mechanics using a combination of mathematical reasoning and physical insight, and today's string theory, a still-developing scientific theory which attempts to unify the four fundamental forces of nature, continues to inspire new mathematics.\n\nSome mathematics is relevant only in the area that inspired it, and is applied to solve further problems in that area. But often mathematics inspired by one area proves useful in many areas, and joins the general stock of mathematical concepts. A distinction is often made between pure mathematics and applied mathematics. However pure mathematics topics often turn out to have applications, e.g. number theory in cryptography. This remarkable fact, that even the \"purest\" mathematics often turns out to have practical applications, is what Eugene Wigner has called \"the unreasonable effectiveness of mathematics\". As in most areas of study, the explosion of knowledge in the scientific age has led to specialization: there are now hundreds of specialized areas in mathematics and the latest Mathematics Subject Classification runs to 46 pages. Several areas of applied mathematics have merged with related traditions outside of mathematics and become disciplines in their own right, including statistics, operations research, and computer science.\n\nFor those who are mathematically inclined, there is often a definite aesthetic aspect to much of mathematics. Many mathematicians talk about the \"elegance\" of mathematics, its intrinsic aesthetics and inner beauty. Simplicity and generality are valued. There is beauty in a simple and elegant proof, such as Euclid's proof that there are infinitely many prime numbers, and in an elegant numerical method that speeds calculation, such as the fast Fourier transform. G. H. Hardy in \"A Mathematician's Apology\" expressed the belief that these aesthetic considerations are, in themselves, sufficient to justify the study of pure mathematics. He identified criteria such as significance, unexpectedness, inevitability, and economy as factors that contribute to a mathematical aesthetic. Mathematicians often strive to find proofs that are particularly elegant, proofs from \"The Book\" of God according to Paul Erdős. The popularity of recreational mathematics is another sign of the pleasure many find in solving mathematical questions.\n\nMost of the mathematical notation in use today was not invented until the 16th century. Before that, mathematics was written out in words, limiting mathematical discovery. Euler (1707–1783) was responsible for many of the notations in use today. Modern notation makes mathematics much easier for the professional, but beginners often find it daunting. According to Barbara Oakley, this can be attributed to the fact that mathematical ideas are both more \"abstract\" and more \"encrypted\" than those of natural language. Unlike natural language, where people can often equate a word (such as \"cow\") with the physical object it corresponds to, mathematical symbols are abstract, lacking any physical analog. Mathematical symbols are also more highly encrypted than regular words, meaning a single symbol can encode a number of different operations or ideas.\n\nMathematical language can be difficult to understand for beginners because even common terms, such as \"or\" and \"only\", have a more precise meaning than they have in everyday speech, and other terms such as \"open\" and \"field\" refer to specific mathematical ideas, not covered by their laymen's meanings. Mathematical language also includes many technical terms such as \"homeomorphism\" and \"integrable\" that have no meaning outside of mathematics. Additionally, shorthand phrases such as \"iff\" for \"if and only if\" belong to mathematical jargon. There is a reason for special notation and technical vocabulary: mathematics requires more precision than everyday speech. Mathematicians refer to this precision of language and logic as \"rigor\".\n\nMathematical proof is fundamentally a matter of rigor. Mathematicians want their theorems to follow from axioms by means of systematic reasoning. This is to avoid mistaken \"theorems\", based on fallible intuitions, of which many instances have occurred in the history of the subject. The level of rigor expected in mathematics has varied over time: the Greeks expected detailed arguments, but at the time of Isaac Newton the methods employed were less rigorous. Problems inherent in the definitions used by Newton would lead to a resurgence of careful analysis and formal proof in the 19th century. Misunderstanding the rigor is a cause for some of the common misconceptions of mathematics. Today, mathematicians continue to argue among themselves about computer-assisted proofs. Since large computations are hard to verify, such proofs may not be sufficiently rigorous.\n\nAxioms in traditional thought were \"self-evident truths\", but that conception is problematic. At a formal level, an axiom is just a string of symbols, which has an intrinsic meaning only in the context of all derivable formulas of an axiomatic system. It was the goal of Hilbert's program to put all of mathematics on a firm axiomatic basis, but according to Gödel's incompleteness theorem every (sufficiently powerful) axiomatic system has undecidable formulas; and so a final axiomatization of mathematics is impossible. Nonetheless mathematics is often imagined to be (as far as its formal content) nothing but set theory in some axiomatization, in the sense that every mathematical statement or proof could be cast into formulas within set theory.\n\nMathematics can, broadly speaking, be subdivided into the study of quantity, structure, space, and change (i.e. arithmetic, algebra, geometry, and analysis). In addition to these main concerns, there are also subdivisions dedicated to exploring links from the heart of mathematics to other fields: to logic, to set theory (foundations), to the empirical mathematics of the various sciences (applied mathematics), and more recently to the rigorous study of uncertainty. While some areas might seem unrelated, the Langlands program has found connections between areas previously thought unconnected, such as Galois groups, Riemann surfaces and number theory.\n\nIn order to clarify the foundations of mathematics, the fields of mathematical logic and set theory were developed. Mathematical logic includes the mathematical study of logic and the applications of formal logic to other areas of mathematics; set theory is the branch of mathematics that studies sets or collections of objects. Category theory, which deals in an abstract way with mathematical structures and relationships between them, is still in development. The phrase \"crisis of foundations\" describes the search for a rigorous foundation for mathematics that took place from approximately 1900 to 1930. Some disagreement about the foundations of mathematics continues to the present day. The crisis of foundations was stimulated by a number of controversies at the time, including the controversy over Cantor's set theory and the Brouwer–Hilbert controversy.\n\nMathematical logic is concerned with setting mathematics within a rigorous axiomatic framework, and studying the implications of such a framework. As such, it is home to Gödel's incompleteness theorems which (informally) imply that any effective formal system that contains basic arithmetic, if \"sound\" (meaning that all theorems that can be proved are true), is necessarily \"incomplete\" (meaning that there are true theorems which cannot be proved \"in that system\"). Whatever finite collection of number-theoretical axioms is taken as a foundation, Gödel showed how to construct a formal statement that is a true number-theoretical fact, but which does not follow from those axioms. Therefore, no formal system is a complete axiomatization of full number theory. Modern logic is divided into recursion theory, model theory, and proof theory, and is closely linked to theoretical computer science, as well as to category theory. In the context of recursion theory, the impossibility of a full axiomatization of number theory can also be formally demonstrated as a consequence of the MRDP theorem.\n\nTheoretical computer science includes computability theory, computational complexity theory, and information theory. Computability theory examines the limitations of various theoretical models of the computer, including the most well-known model – the Turing machine. Complexity theory is the study of tractability by computer; some problems, although theoretically solvable by computer, are so expensive in terms of time or space that solving them is likely to remain practically unfeasible, even with the rapid advancement of computer hardware. A famous problem is the \"\" problem, one of the Millennium Prize Problems. Finally, information theory is concerned with the amount of data that can be stored on a given medium, and hence deals with concepts such as compression and entropy.\n\nThe study of quantity starts with numbers, first the familiar natural numbers and integers (\"whole numbers\") and arithmetical operations on them, which are characterized in arithmetic. The deeper properties of integers are studied in number theory, from which come such popular results as Fermat's Last Theorem. The twin prime conjecture and Goldbach's conjecture are two unsolved problems in number theory.\n\nAs the number system is further developed, the integers are recognized as a subset of the rational numbers (\"fractions\"). These, in turn, are contained within the real numbers, which are used to represent continuous quantities. Real numbers are generalized to complex numbers. These are the first steps of a hierarchy of numbers that goes on to include quaternions and octonions. Consideration of the natural numbers also leads to the transfinite numbers, which formalize the concept of \"infinity\". According to the fundamental theorem of algebra all solutions of equations in one unknown with complex coefficients are complex numbers, regardless of degree. Another area of study is the size of sets, which is described with the cardinal numbers. These include the aleph numbers, which allow meaningful comparison of the size of infinitely large sets.\n\nMany mathematical objects, such as sets of numbers and functions, exhibit internal structure as a consequence of operations or relations that are defined on the set. Mathematics then studies properties of those sets that can be expressed in terms of that structure; for instance number theory studies properties of the set of integers that can be expressed in terms of arithmetic operations. Moreover, it frequently happens that different such structured sets (or structures) exhibit similar properties, which makes it possible, by a further step of abstraction, to state axioms for a class of structures, and then study at once the whole class of structures satisfying these axioms. Thus one can study groups, rings, fields and other abstract systems; together such studies (for structures defined by algebraic operations) constitute the domain of abstract algebra.\n\nBy its great generality, abstract algebra can often be applied to seemingly unrelated problems; for instance a number of ancient problems concerning compass and straightedge constructions were finally solved using Galois theory, which involves field theory and group theory. Another example of an algebraic theory is linear algebra, which is the general study of vector spaces, whose elements called vectors have both quantity and direction, and can be used to model (relations between) points in space. This is one example of the phenomenon that the originally unrelated areas of geometry and algebra have very strong interactions in modern mathematics. Combinatorics studies ways of enumerating the number of objects that fit a given structure.\n\nThe study of space originates with geometry – in particular, Euclidean geometry, which combines space and numbers, and encompasses the well-known Pythagorean theorem. Trigonometry is the branch of mathematics that deals with relationships between the sides and the angles of triangles and with the trigonometric functions. The modern study of space generalizes these ideas to include higher-dimensional geometry, non-Euclidean geometries (which play a central role in general relativity) and topology. Quantity and space both play a role in analytic geometry, differential geometry, and algebraic geometry. Convex and discrete geometry were developed to solve problems in number theory and functional analysis but now are pursued with an eye on applications in optimization and computer science. Within differential geometry are the concepts of fiber bundles and calculus on manifolds, in particular, vector and tensor calculus. Within algebraic geometry is the description of geometric objects as solution sets of polynomial equations, combining the concepts of quantity and space, and also the study of topological groups, which combine structure and space. Lie groups are used to study space, structure, and change. Topology in all its many ramifications may have been the greatest growth area in 20th-century mathematics; it includes point-set topology, set-theoretic topology, algebraic topology and differential topology. In particular, instances of modern-day topology are metrizability theory, axiomatic set theory, homotopy theory, and Morse theory. Topology also includes the now solved Poincaré conjecture, and the still unsolved areas of the Hodge conjecture. Other results in geometry and topology, including the four color theorem and Kepler conjecture, have been proved only with the help of computers.\n\nUnderstanding and describing change is a common theme in the natural sciences, and calculus was developed as a powerful tool to investigate it. Functions arise here, as a central concept describing a changing quantity. The rigorous study of real numbers and functions of a real variable is known as real analysis, with complex analysis the equivalent field for the complex numbers. Functional analysis focuses attention on (typically infinite-dimensional) spaces of functions. One of many applications of functional analysis is quantum mechanics. Many problems lead naturally to relationships between a quantity and its rate of change, and these are studied as differential equations. Many phenomena in nature can be described by dynamical systems; chaos theory makes precise the ways in which many of these systems exhibit unpredictable yet still deterministic behavior.\n\nApplied mathematics concerns itself with mathematical methods that are typically used in science, engineering, business, and industry. Thus, \"applied mathematics\" is a mathematical science with specialized knowledge. The term \"applied mathematics\" also describes the professional specialty in which mathematicians work on practical problems; as a profession focused on practical problems, \"applied mathematics\" focuses on the \"formulation, study, and use of mathematical models\" in science, engineering, and other areas of mathematical practice.\n\nIn the past, practical applications have motivated the development of mathematical theories, which then became the subject of study in pure mathematics, where mathematics is developed primarily for its own sake. Thus, the activity of applied mathematics is vitally connected with research in pure mathematics.\n\nApplied mathematics has significant overlap with the discipline of statistics, whose theory is formulated mathematically, especially with probability theory. Statisticians (working as part of a research project) \"create data that makes sense\" with random sampling and with randomized experiments; the design of a statistical sample or experiment specifies the analysis of the data (before the data be available). When reconsidering data from experiments and samples or when analyzing data from observational studies, statisticians \"make sense of the data\" using the art of modelling and the theory of inference – with model selection and estimation; the estimated models and consequential predictions should be tested on new data.\n\nStatistical theory studies decision problems such as minimizing the risk (expected loss) of a statistical action, such as using a procedure in, for example, parameter estimation, hypothesis testing, and selecting the best. In these traditional areas of mathematical statistics, a statistical-decision problem is formulated by minimizing an objective function, like expected loss or cost, under specific constraints: For example, designing a survey often involves minimizing the cost of estimating a population mean with a given level of confidence. Because of its use of optimization, the mathematical theory of statistics shares concerns with other decision sciences, such as operations research, control theory, and mathematical economics.\n\nComputational mathematics proposes and studies methods for solving mathematical problems that are typically too large for human numerical capacity. Numerical analysis studies methods for problems in analysis using functional analysis and approximation theory; numerical analysis includes the study of approximation and discretization broadly with special concern for rounding errors. Numerical analysis and, more broadly, scientific computing also study non-analytic topics of mathematical science, especially algorithmic matrix and graph theory. Other areas of computational mathematics include computer algebra and symbolic computation.\n\nArguably the most prestigious award in mathematics is the Fields Medal, established in 1936 and awarded every four years (except around World War II) to as many as four individuals. The Fields Medal is often considered a mathematical equivalent to the Nobel Prize.\n\nThe Wolf Prize in Mathematics, instituted in 1978, recognizes lifetime achievement, and another major international award, the Abel Prize, was instituted in 2003. The Chern Medal was introduced in 2010 to recognize lifetime achievement. These accolades are awarded in recognition of a particular body of work, which may be innovational, or provide a solution to an outstanding problem in an established field.\n\nA famous list of 23 open problems, called \"Hilbert's problems\", was compiled in 1900 by German mathematician David Hilbert. This list achieved great celebrity among mathematicians, and at least nine of the problems have now been solved. A new list of seven important problems, titled the \"Millennium Prize Problems\", was published in 2000. Only one of them, the Riemann hypothesis, duplicates one of Hilbert's problems. A solution to any of these problems carries a $1 million reward.\n\n\n"}
{"id": "9050760", "url": "https://en.wikipedia.org/wiki?curid=9050760", "title": "Multi-compartment model", "text": "Multi-compartment model\n\nA multi-compartment model is a type of mathematical model used for describing the way materials or energies are transmitted among the \"compartments\" of a system. Each compartment is assumed to be a homogeneous entity within which the entities being modelled are equivalent. For instance, in a pharmacokinetic model, the compartments may represent different sections of a body within which the concentration of a drug is assumed to be uniformly equal.\n\nHence a multi-compartment model is a lumped parameters model.\n\nMulti-compartment models are used in many fields including pharmacokinetics, epidemiology, biomedicine, systems theory, complexity theory, engineering, physics, information science and social science. The circuits systems can be viewed as a multi-compartment model as well.\n\nIn systems theory, it involves the description of a network whose components are compartments that represent a population of elements that are equivalent with respect to the manner in which they process input signals to the compartment.\nMost commonly, the mathematics of multi-compartment models is simplified to provide only a single parameter—such as concentration—within a compartment.\n\nPossibly the simplest application of multi-compartment model is in the single-cell concentration monitoring (see the figure above). If the volume of a cell is \"V\", the mass of solute is \"q\", the input is \"u\"(\"t\") and the secretion of the solution is proportional to the density of it within the cell, then the concentration of the solution \"C\" within the cell over time is given by\n\nwhere \"k\" is the proportionality.\n\nAs the number of compartments increases, the model can be very complex and the solutions usually beyond ordinary calculation.\n\nThe formulae for n-cell multi-compartment models become:\n\nWhere \n\nOr in matrix forms:\n\nWhere\n\nIn the special case of a closed system (see below) i.e. where formula_9 then there is a general solution.\n\nWhere formula_11, formula_12, ... and formula_13 are the eigenvalues of formula_14; formula_15, formula_16, ... and formula_17 are the respective eigenvectors of formula_14; and formula_19, formula_20, ... and formula_21 are constants.\n\nHowever it can be shown that given the above requirement to ensure the 'contents' of a closed system are constant, then for every pair of eigenvalue and eigenvector then either formula_22 or formula_23 and also that one eigenvalue is 0, say formula_11\n\nSo\n\nWhere\n\nThis solution can be rearranged:\n\nThis somewhat inelegant equation demonstrates that all solutions of an \"n-cell\" multi-compartment model with constant or no inputs are of the form:\n\nWhere formula_30 is a \"nxn\" matrix and formula_12, formula_32, ... and formula_13 are constants.\nWhere formula_34\n\nGenerally speaking, as the number of compartments increase, it is challenging both to find the algebraic and numerical solutions of the model. However, there are special cases of models, which rarely exist in nature, when the topologies exhibit certain regularities that the solutions become easier to find. The model can be classified according to the interconnection of cells and input/output characteristics:\n\n\n\n"}
{"id": "37658021", "url": "https://en.wikipedia.org/wiki?curid=37658021", "title": "Null model", "text": "Null model\n\nIn mathematics, for example in the study of statistical properties of graphs, a null model is type of random object that matches one specific object in some of its features, or more generally satisfies a collection of constraints, but which is otherwise taken to be an unbiasedly random structure. The null model is used as a term of comparison, to verify whether the object in question displays some non-trivial features (properties that wouldn't be expected on the basis of chance alone or as a consequence of the constraints), such as community structure in graphs. An appropriate null model behaves in accordance with a reasonable null hypothesis for the behavior of the system under investigation.\n\nOne null model of utility in the study of complex networks is that proposed by Newman and Girvan, consisting of a randomized version of an original graph formula_1, produced through edges being rewired at random, under the constraint that the expected degree of each vertex matches the degree of the vertex in the original graph.\n\nThe null model is the basic concept behind the definition of modularity, a function which evaluates the goodness of partitions of a graph into clusters. In particular, given a graph formula_1 and a specific community partition formula_3 (an assignment of a community-index formula_4 (here taken as an integer from formula_5 to formula_6) to each vertex formula_7 in the graph), the modularity measures the difference between the number of links from/to each pair of communities, from that expected in a graph that is completely random in all respects other than the set of degrees of each of the vertices (the degree sequence). In other words, the modularity contrasts the exhibited community structure in formula_1 with that of a null model, which in this case is the configuration model (the maximally random graph subject to a constraint on the degree of each vertex).\n\n"}
{"id": "41847276", "url": "https://en.wikipedia.org/wiki?curid=41847276", "title": "One-shot deviation principle", "text": "One-shot deviation principle\n\nThe one-shot deviation principle (also known as one-deviation property) is the principle of optimality of dynamic programming applied to game theory. It says that a strategy profile of a finite extensive-form game is a subgame perfect equilibrium (SPE) if and only if there exist no profitable one-shot deviations for each subgame and every player. In simpler terms, if no player can increase their payoffs by deviating a single decision, or period, from their original strategy, then the strategy that they have chosen is a SPE. As a result, no player can profit from deviating from the strategy for one period and then reverting to the strategy. \n\nFurthermore, the one-shot deviation principle is very important for infinite horizon games, in which the principle typically does not hold, since it is not plausible to consider an infinite number of strategies and payoffs in order to solve. In an infinite horizon game where the discount factor is less than 1, a strategy profile is a subgame perfect equilibrium if and only if it satisfies the one-shot deviation principle.\n\nThe following is the paraphrased definition from Watson (2013)\n\nTo check whether strategy \"s\" is a subgame perfect Nash equilibrium, we have to ask every player \"i\" and every subgame, if considering \"s\", there is a strategy \"s’\" that yields a strictly higher payoff for player \"i\" than does \"s\" in the subgame. This analysis is equivalent to looking at single deviations from \"s\", meaning \"s’\" differs from s at only one information set. Note that the choices associated with \"s\" and \"s’\" are the same at all nodes that are successors of nodes in the information set where s and \"s’\" prescribe different actions. \n\nConsider a symmetric game with two players in which each player makes binary choice decisions, A or B, in three sequences. There are 8 (2) total number of pure strategies for each player: {AAA, AAB, ABA, ABB, BBB, BBA, BAB, BAA}. In this example, consider that a player chooses strategy (AAA). To check whether this strategy is a SPE, the one-shot deviation principle states that the player needs to check the payoffs of only three other strategies which differ from the original strategy by a single deviation, instead of all seven others. These three strategies are: (BAA), (ABA), and (AAB). If none of these three strategies yields a higher payoff than (AAA), then the player can conclude that (AAA) is a SPE.\n"}
{"id": "22656", "url": "https://en.wikipedia.org/wiki?curid=22656", "title": "Operand", "text": "Operand\n\nIn mathematics an operand is the object of a mathematical operation, i.e. it is the object or quantity that is operated on.\n\nThe following arithmetic expression shows an example of operators and operands:\n\nIn the above example, '+' is the symbol for the operation called addition. \n\nThe operand '3' is one of the inputs (quantities) followed by the addition operator, and the operand '6' is the other input necessary for the operation.\n\nThe result of the operation is 9. (The number '9' is also called the sum of the augend 3 and the addend 6.)\n\nAn operand, then, is also referred to as \"one of the inputs (quantities) for an operation\".\n\nOperands may be complex, and may consist of expressions also made up of operators with operands.\n\nIn the above expression '(3 + 5)' is the first operand for the multiplication operator and '2' the second. The operand '(3 + 5)' is an expression in itself, which contains an addition operator, with the operands '3' and '5'.\n\nRules of precedence affect which values form operands for which operators:\n\nIn the above expression, the multiplication operator has the higher precedence than the addition operator, so the multiplication operator has operands of '5' and '2'. The addition operator has operands of '3' and '5 × 2'.\n\nDepending on the mathematical notation being used the position of an operator in relation to its operand(s) may vary. In everyday usage infix notation is the most common, however other notations also exist, such as the prefix and postfix notations. These alternate notations are most common within computer science.\n\nBelow is a comparison of three different notations — all represent an addition of the numbers '1' and '2'\n\nIn a mathematical expression, the order of operation is carried out from left to right. Start with the left most value and seek the first operation to be carried out in accordance with the order specified above (i.e., start with parentheses and end with the addition/subtraction group). For example, in the expression\n\nthe first operation to be acted upon is any and all expressions found inside a parenthesis. So beginning at the left and moving to the right, find the first (and in this case, the only) parenthesis, that is, (2 + 2). Within the parenthesis itself is found the expression 2. The reader is required to find the value of 2 before going any further. The value of 2 is 4. Having found this value, the remaining expression looks like this:\n\nThe next step is to calculate the value of expression inside the parenthesis itself, that is, (2 + 4) = 6. Our expression now looks like this:\n\nHaving calculated the parenthetical part of the expression, we start over again beginning with the left most value and move right. The next order of operation (according to the rules) is exponents. Start at the left most value, that is, 4, and scan your eyes to the right and search for the first exponent you come across. The first (and only) expression we come across that is expressed with an exponent is 2. We find the value of 2, which is 4. What we have left is the expression\n\nThe next order of operation is multiplication. 4 × 4 is 16. Now our expression looks like this:\n\nThe next order of operation according to the rules is division. However, there is no division operator sign (÷) in the expression, 16 − 6. So we move on to the next order of operation, i.e., addition and subtraction, which have the same precedence and are done left to right.\n\nSo the correct value for our original expression, 4 × 2 − (2 + 2), is 10. \n\nIt is important to carry out the order of operation in accordance with rules set by convention. If the reader evaluates an expression but does not follow the correct order of operation, the reader will come forth with a different value. The different value will be the incorrect value because the order of operation was not followed. The reader will arrive at the correct value for the expression if and only if each operation is carried out in the proper order.\n\nThe number of operands of an operator is called its arity. Based on arity, operators are classified as nullary (no operands), unary (1 operand), binary (2 operands), ternary (3 operands) etc.\n\nIn computer programming languages, the definitions of operator and operand are almost the same as in mathematics.\n\nIn computing, an operand is the part of a computer instruction which specifies what data is to be manipulated or operated on, while at the same time representing the data itself.\nA computer instruction describes an operation such as add or multiply X, while the operand (or operands, as there can be more than one) specify on which X to operate as well as the value of X.\n\nAdditionally, in assembly language, an operand is a value (an argument) on which the instruction, named by mnemonic, operates. The operand may be a processor register, a memory address, a literal constant, or a label. A simple example (in the x86 architecture) is\n\nMOV DS, AX\n\nwhere the value in register operand codice_1 is to be moved (codice_2) into register codice_3. Depending on the instruction, there may be zero, one, two, or more operands.\n\n"}
{"id": "25056", "url": "https://en.wikipedia.org/wiki?curid=25056", "title": "Polish notation", "text": "Polish notation\n\nPolish notation (PN), also known as normal Polish notation (NPN), Łukasiewicz notation, Warsaw notation, Polish prefix notation or simply prefix notation, is a mathematical notation in which operators \"precede\" their operands, in contrast to (the more common) infix notation (in which operators are placed \"between\" operands), as well as to reverse Polish notation (RPN, in which operators \"follow\" their operands). It does not need any parentheses as long as each operator has a fixed number of operands. The description \"Polish\" refers to the nationality of logician Jan Łukasiewicz, who invented Polish notation in 1924.\n\nThe term \"Polish notation\" is sometimes taken (as the opposite of \"infix notation\") to also include reverse Polish notation.\n\nWhen Polish notation is used as a syntax for mathematical expressions by programming language interpreters, it is readily parsed into abstract syntax trees and can, in fact, define a one-to-one representation for the same. Because of this, Lisp (see below) and related programming languages define their entire syntax in terms of prefix notation (and others use postfix notation).\n\nA quotation from a paper by Jan Łukasiewicz, \"Remarks on Nicod's Axiom and on \"Generalizing Deduction\"\", page 180, states how the notation was invented:\nI came upon the idea of a parenthesis-free notation in 1924. I used that notation for the first time in my article Łukasiewicz(1), p. 610, footnote.\n\nThe reference cited by Łukasiewicz is apparently a lithographed report in Polish. The referring paper by Łukasiewicz \"Remarks on Nicod's Axiom and on \"Generalizing Deduction\"\" was reviewed by Henry A. Pogorzelski in the \"Journal of Symbolic Logic\" in 1965. Heinrich Behmann, editor in 1924 of the article of Moses Schönfinkel already had the idea of eliminating parentheses in logic formulas.\n\nAlonzo Church mentions this notation in his classic book on mathematical logic as worthy of remark in notational systems even contrasted to Alfred Whitehead and Bertrand Russell's logical notational exposition and work in Principia Mathematica.\n\nIn Łukasiewicz's 1951 book, \"Aristotle's Syllogistic from the Standpoint of Modern Formal Logic\", he mentions that the principle of his notation was to write the functors before the arguments to avoid brackets and that he had employed his notation in his logical papers since 1929. He then goes on to cite, as an example, a 1930 paper he wrote with Alfred Tarski on the sentential calculus.\n\nWhile no longer used much in logic, Polish notation has since found a place in computer science.\n\nThe expression for adding the numbers 1 and 2 is written in Polish notation as (pre-fix), rather than as (in-fix). In more complex expressions, the operators still precede their operands, but the operands may themselves be expressions including again operators and their operands. For instance, the expression that would be written in conventional infix notation as\ncan be written in Polish notation as\nAssuming a given arity of all involved operators (here the \"−\" denotes the binary operation of subtraction, not the unary function of sign-change), any well formed prefix representation thereof is unambiguous, and brackets within the prefix expression are unnecessary. As such, the above expression can be further simplified to\n\nThe processing of the product is deferred until its two operands are available (i.e., 5 minus 6, and 7). As with \"any\" notation, the innermost expressions are evaluated first, but in Polish notation this \"innermost-ness\" can be conveyed by the sequence of operators and operands rather than by bracketing.\n\nIn the conventional infix notation parentheses are required to override the standard precedence rules, since, referring to the above example, moving them\nor removing them\nchanges the meaning and the result of the expression. This version is written in Polish notation as\n\nWhen dealing with non-commutative operations, like division or subtraction, it is necessary to coordinate the sequential arrangement of the operands with the definition of how the operator takes its arguments, i.e., from left to right. For example, , with 10 left to 5, has the meaning of 10 ÷ 5 (read as \"divide 10 by 5\"), or , with 7 left to 6, has the meaning of 7 - 6 (read as \"subtract from 7 the operand 6\").\n\nPrefix/postfix notation is especially popular for its innate ability to express the intended order of operations without the need for parentheses and other precedence rules, as are usually employed with infix notation. Instead, the notation uniquely indicates which operator to evaluate first. The operators are assumed to have a fixed arity each, and all necessary operands are assumed to be explicitly given. A valid prefix expression always starts with an operator and ends with an operand. Evaluation can either proceed from left to right, or in the opposite direction. Starting at the left, the input string, consisting of tokens denoting operators or operands, is pushed token for token on a stack, until the top entries of the stack contain the number of operands that fits to the top most operator (immediately beneath). This group of tokens at the stacktop (the last stacked operator and the according number of operands) is replaced by the result of executing the operator on these/this operand(s). Then the processing of the input continues in this manner. The rightmost operand in a valid prefix expression thus empties the stack, except for the result of evaluating the whole expression. When starting at the right, the pushing of tokens is performed similarly, just the evaluation is triggered by an operator, finding the appropriate number of operands that fits its arity already at the stacktop. Now the leftmost token of a valid prefix expression must be an operator, fitting to the number of operands in the stack, which again yields the result. As can be seen from the description, a push-down store with no capability of arbitrary stack inspection suffices to implement this parsing.\n\nThe above sketched stack manipulation works –with mirrored input– also for expressions in reverse Polish notation.\n\nThe table below shows the core of Jan Łukasiewicz's notation for sentential logic. Some letters in the Polish notation table stand for particular words in Polish, as shown:\n\nNote that the quantifiers ranged over propositional values in Łukasiewicz's work on many-valued logics.\n\nBocheński introduced a system of Polish notation that names all 16 binary connectives of classical propositional logic. For classical propositional logic, it is a compatible extension of the notation of Łukasiewicz. But the notations are incompatible in the sense that Bocheński uses L and M (for nonimplication and converse nonimplication) in propositional logic and Łukasiewicz uses L and M in modal logic.\n\nPrefix notation has seen wide application in Lisp s-expressions, where the brackets are required since the operators in the language are themselves data (first-class functions). Lisp functions may also be variadic. The Tcl programming language, much like Lisp also uses Polish notation through the mathop library. The Ambi programming language uses Polish notation for arithmetic operations and program construction.\n\nPostfix notation is used in many stack-oriented programming languages like PostScript and Forth. CoffeeScript syntax also allows functions to be called using prefix notation, while still supporting the unary postfix syntax common in other languages.\n\nThe number of return values of an expression equals the difference between the number of operands in an expression and the total arity of the operators minus the total number of return values of the operators.\n\nPolish notation, usually in postfix form, is the chosen notation of certain calculators, notably from Hewlett-Packard. At a lower level, postfix operators are used by some stack machines such as the Burroughs large systems.\n\n\n"}
{"id": "41345437", "url": "https://en.wikipedia.org/wiki?curid=41345437", "title": "Predictive intake modelling", "text": "Predictive intake modelling\n\nPredictive intake modelling uses mathematical modelling strategies to estimate intake of food, personal care products, and their formulations.\n\nPredictive intake modelling seeks to estimate intake of products and/or their constituents which may enter the body through various routes such as ingestion, inhalation and absorption.\n\nPredictive intake modelling can be applied to determine trends in food consumption and product use for the purpose of extrapolation.\n\nA predictive intake modelling approach is used to estimate voluntary food intake (VFI) by animals where their eating habits cannot be exactly measured. For humans, predictive intake modelling is used to make estimations of intake from foods, pesticides, cosmetics and inhalants as well as substances that can be contained in these like nutrients, functional ingredients, chemicals and contaminants.\n\nPredictive intake modelling has applications in public health, risk assessment and exposure assessment, where estimating intake or exposure to different substances can influence the decision making process.\n\nThe regression analysis approach is based on estimations through extrapolation or interpolation where there is a cause-and-effect relationship found by data fitting. These trends tend to be phenomenological.\n\nA mechanistic modelling approach is one where a model is derived from basic theory. Examples of these include compartmental models which can be used to describe the circulation and concentration of airborne particles in a room or household for estimating intake of inhalants.\n\nA population-based approach tracks consumer intake from individual members of a sample population over time. Mathematical models are used to combine these habits and practices databases with separate databases on product or food formulation to estimate intake or exposure for the sample population. Moreover, survey weights may be applied to each subject in the study based on their age, demographic and location allowing the sample of subjects to correctly represent an entire population, and thus estimate intake for that population.\n\nProbabilistic models are based on the Monte Carlo method where distributions of data from various sources are randomly sampled from to calculate percentile statistics. Such probabilistic techniques typically utilise product or consumption survey data from a sample population combined with distributions of substances that may be found within those foods or products. For example, The Food and Drug Administration (FDA) suggest that the estimation of intake of substances in food can be probabilistically conducted through food consumption surveys (NHANES/CSFII) from sample populations combined with distributions of substance concentration data to calculate the Estimated Daily Intake. The European Food Safety Authority (EFSA) funded the Monte Carlo Risk Assessment (MCRA) tool to estimate usual intake exposure distributions based on statistical models which utilise the EFSA Comprehensive Database, which contains detailed food consumption survey data. EFSA also funded Creme Global to develop a model and databases of European food consumption on which statistical models can be run to assess intake and exposure on a pan-European basis.\n\n"}
{"id": "3909097", "url": "https://en.wikipedia.org/wiki?curid=3909097", "title": "Projection (mathematics)", "text": "Projection (mathematics)\n\nIn mathematics, a projection is a mapping of a set (or other mathematical structure) into a subset (or sub-structure), which is equal to its square for mapping composition (or, in other words, which is idempotent). The restriction to a subspace of a projection is also called a \"projection\", even if the idempotence property is lost.\nAn everyday example of a projection is the casting of shadows onto a plane (paper sheet). The projection of a point is its shadow on the paper sheet. The shadow of a point on the paper sheet is this point itself (idempotence). The shadow of a three-dimensional sphere is a closed disk. Originally, the notion of projection was introduced in Euclidean geometry to denote the projection of the Euclidean space of three dimensions onto a plane in it, like the shadow example. The two main projections of this kind are: \n\nThe concept of projection in mathematics is a very old one, most likely having its roots in the phenomenon of the shadows cast by real world objects on the ground. This rudimentary idea was refined and abstracted, first in a geometric context and later in other branches of mathematics. Over time differing versions of the concept developed, but today, in a sufficiently abstract setting, we can unify these variations.\n\nIn cartography, a map projection is a map of a part of the surface of the Earth onto a plane, which, in some cases, but not always, is the restriction of a projection in the above meaning. The 3D projections are also at the basis of the theory of perspective. \n\nThe need for unifying the two kinds of projections and of defining the image by a central projection of any point different of the center of projection are at the origin of projective geometry. However, a projective transformation is a bijection of a projective space, a property \"not\" shared with the \"projections\" of this article.\n\nIn an abstract setting we can generally say that a \"projection\" is a mapping of a set (or of a mathematical structure) which is idempotent, which means that a projection is equal to its composition with itself. A projection may also refer to a mapping which has a right inverse. Both notions are strongly related, as follows. Let \"p\" be an idempotent map from a set \"A\" into itself (thus \"p\"∘\"p\" = \"p\") and \"B\" = \"p\"(\"A\") be the image of \"p\". If we denote by π the map \"p\" viewed as a map from \"A\" onto \"B\" and by \"i\" the injection of \"B\" into \"A\", then we have π.\"i\"= Id. Conversely, π.\"i\" = Id implies that π∘\"i\" is idempotent.\n\nThe original notion of projection has been extended or generalized to various mathematical situations, frequently, but not always, related to geometry, for example:\n\n\n\n\n\n\n\n\n\n"}
{"id": "929709", "url": "https://en.wikipedia.org/wiki?curid=929709", "title": "Pseudomathematics", "text": "Pseudomathematics\n\nPseudomathematics or mathematical crankery is a form of mathematics-like activity that does not work within the framework, definitions, rules, or rigor of formal mathematical practice. Pseudomathematics has equivalents in other scientific fields, such as pseudophysics, and overlaps with these to some extent.\n\nExcessive pursuit of pseudomathematics can result in the practitioner being labelled a crank. The topic of mathematical crankery has been extensively studied by mathematician Underwood Dudley, who has written several popular works about mathematical cranks and their ideas. Because it is based on non-mathematical principles, pseudomathematics is not related to attempts at genuine proofs that contain mistakes. Indeed, such mistakes are common in the careers of amateur mathematicians who go on to produce celebrated results.\n\nOne common type of approach is claiming to have solved classical problems in terms that have been proven mathematically impossible. Common examples include the following constructions in Euclidean geometry using only compass and straightedge:\n\nFor more than 2,000 years, many people had tried and failed to find such constructions; in the 19th century, they were all proven impossible.\n\nAnother common approach is to misapprehend standard mathematical methods, and insisting that the use or knowledge of higher mathematics is somehow cheating or misleading.\n\nThe term \"pseudomath\" was coined by the logician Augustus De Morgan, discoverer of De Morgan's laws, in his \"A Budget of Paradoxes\" (1915). De Morgan wrote,\nDe Morgan gave as example of a pseudomath a certain James Smith who claimed persistently to have proved that formula_1. Of Smith, De Morgan wrote, \"He is beyond a doubt the ablest head at unreasoning, and the greatest hand at writing it, of all who have tried in our day to attach their names to an error.\" The term \"pseudomath\" was adopted later by Tobias Dantzig. Dantzig observed,\n\nMore recently, the term \"pseudomathematics\" has been applied to creationist attempts to refute the theory of evolution by way of spurious arguments purportedly based in probability or complexity theory.\n\n\n"}
{"id": "1618671", "url": "https://en.wikipedia.org/wiki?curid=1618671", "title": "Quadrature (mathematics)", "text": "Quadrature (mathematics)\n\nIn mathematics, quadrature is a historical term which means the process of determining area. This term is still used nowadays in the context of differential equations, where \"solving an equation by quadrature\" means expressing its solution in terms of integrals.\n\nQuadrature problems served as one of the main sources of problems in the development of calculus, and introduce important topics in mathematical analysis.\n\nMathematicians of ancient Greece, according to the Pythagorean doctrine, understood determination of area of a figure as the process of geometrically constructing a square having the same area (\"squaring\"), thus the name \"quadrature\" for this process. The Greek geometers were not always successful (see quadrature of the circle), but they did carry out quadratures of some figures whose sides were not simply line segments, such as the lunes of Hippocrates and the quadrature of the parabola. By Greek tradition, these constructions had to be performed using only a compass and straightedge.\n\nFor a quadrature of a rectangle with the sides \"a\" and \"b\" it is necessary to construct a square with the side formula_1 (the geometric mean of \"a\" and \"b\"). For this purpose it is possible to use the following: if one draws the circle with diameter made from joining line segments of lengths \"a\" and \"b\", then the height (\"BH\" in the diagram) of the line segment drawn perpendicular to the diameter, from the point of their connection to the point where it crosses the circle, equals the geometric mean of \"a\" and \"b\". A similar geometrical construction solves the problems of quadrature of a parallelogram and of a triangle.\nProblems of quadrature for curvilinear figures are much more difficult. The quadrature of the circle with compass and straightedge was proved in the 19th century to be impossible. Nevertheless, for some figures (for example a lune of Hippocrates) a quadrature can be performed. The quadratures of the surface of a sphere and a parabola segment discovered by Archimedes became the highest achievement of analysis in antiquity.\nFor the proof of these results, Archimedes used the method of exhaustion of Eudoxus.\n\nIn medieval Europe, quadrature meant the calculation of area by any method. Most often the method of indivisibles was used; it was less rigorous than the geometric constructions of the Greeks, but it was simpler and more powerful. With its help, Galileo Galilei and Gilles de Roberval found the area of a cycloid arch, Grégoire de Saint-Vincent investigated the area under a hyperbola (\"Opus Geometricum\", 1647), and Alphonse Antonio de Sarasa, de Saint-Vincent's pupil and commentator, noted the relation of this area to logarithms.\n\nJohn Wallis algebrised this method; he wrote in his \"Arithmetica Infinitorum\" (1656) some series which are equivalent to what is now called the definite integral, and he calculated their values. Isaac Barrow and James Gregory made further progress: quadratures for some algebraic curves and spirals. Christiaan Huygens successfully performed a quadrature of the surface area of some solids of revolution.\n\nThe quadrature of the hyperbola by Saint-Vincent and de Sarasa provided a new function, the natural logarithm, of critical importance. With the invention of integral calculus came a universal method for area calculation. In response, the term \"quadrature\" has become traditional, and instead the modern phrase \"finding the area\" is more commonly used for what is technically the \"computation of a univariate definite integral\".\n\n\n"}
{"id": "23855903", "url": "https://en.wikipedia.org/wiki?curid=23855903", "title": "Quantum ergodicity", "text": "Quantum ergodicity\n\nIn quantum chaos, a branch of mathematical physics, quantum ergodicity is a property of the quantization of classical mechanical systems that are chaotic in the sense of exponential sensitivity to initial conditions. Quantum ergodicity states, roughly, that in the high-energy limit, the probability distributions associated to energy eigenstates of a quantized ergodic Hamiltonian tend to a uniform distribution in the classical phase space. This is consistent with the intuition that the flows of ergodic systems are equidistributed in phase space. By contrast, classical completely integrable systems generally have periodic orbits in phase space, and this is exhibited in a variety of ways in the high-energy limit of the eigenstates: typically that some form of concentration or \"scarring\" occurs in the limit.\n\nThe model case of a Hamiltonian is the geodesic Hamiltonian on the cotangent bundle of a compact Riemannian manifold. The quantization of the geodesic flow is given by the fundamental solution of the Schrödinger equation\nwhere formula_2 is the square root of the Laplace-Beltrami operator. The quantum ergodicity theorem of Shnirelman, Yves Colin de Verdière, and Zelditch states that a compact Riemannian manifold whose unit tangent bundle is ergodic under the geodesic flow is also ergodic in the sense that the probability density associated to the \"n\"th eigenfunction of the Laplacian tends weakly to the uniform distribution on the unit cotangent bundle as \"n\" → ∞ in a subset of the natural numbers of natural density equal to one. Quantum ergodicity can be formulated as a non-commutative analogue of the classical ergodicity (T. Sunada).\n\n\n"}
{"id": "19985265", "url": "https://en.wikipedia.org/wiki?curid=19985265", "title": "Red auxiliary number", "text": "Red auxiliary number\n\nIn the study of ancient Egyptian mathematics, red auxiliary numbers are numbers written in red ink in the Rhind Mathematical Papyrus, apparently used as aids for arithmetic computations involving fractions.\n\n"}
{"id": "53561047", "url": "https://en.wikipedia.org/wiki?curid=53561047", "title": "Sphuṭacandrāpti", "text": "Sphuṭacandrāpti\n\nSphuṭacandrāpti (Computation of True Moon) is a treatise in Sanskrit composed by the fourteenth-century CE Kerala astronomer-mathematician Sangamagrama Madhava. The treatise enunciates a method for the computation of the position of the moon at intervals of 40 minutes each throughout the day. This is one of only two works of Madhava that have survived to modern times, the other one being \"Veṇvāroha\". However, both \"Sphuṭacandrāpti\" and \"Veṇvāroha\" have more or less the same contents, that of the latter being apparently a more refined version of that of the former.\n\nK. V. Sarma while working in Vishveshvaranand Institute of Sanskrit and Indological Studies, Hoshiarpur, has brought out in 1973 a critical edition of the treatise with an introduction, translation and notes. The full text of this work, which has only 65 pages, can be accessed from Internet Archive at the following link:\nScanned copies of the pages of the text referred to above are available in Wikimedia Commons at the following link:\n\n"}
{"id": "38624698", "url": "https://en.wikipedia.org/wiki?curid=38624698", "title": "Stochastic quantization", "text": "Stochastic quantization\n\nIn physics, stochastic quantization is a method for modelling quantum mechanics, introduced by Edward Nelson in 1966, and streamlined by Parisi and Wu.\n\nStochastic quantization serves to quantize Euclidean field theories, and is used for numerical applications, such as numerical simulations of gauge theories with fermions. This serves to address the problem of fermion doubling that usually occurs in these numerical calculations.\n\nStochastic quantization takes advantage of the fact that a Euclidean quantum field theory can be modeled as the equilibrium limit of a statistical mechanical system coupled to a heat bath. In particular, in the path integral representation of a Euclidean quantum field theory, the path integral measure is closely related to the Boltzmann distribution of a statistical mechanical system in equilibrium. In this relation, Euclidean Green's functions become correlation functions in the statistical mechanical system. A statistical mechanical system in equilibrium can be modeled, via the ergodic hypothesis, as the stationary distribution of a stochastic process. Then the Euclidean path integral measure can also be thought of as the stationary distribution of a stochastic process; hence the name stochastic quantization.\n"}
{"id": "58904582", "url": "https://en.wikipedia.org/wiki?curid=58904582", "title": "Tetradic number", "text": "Tetradic number\n\nA tetradic number, also known as a four-way number, is a number that remains the same when flipped back to front, flipped front to back, mirrored up-down, or flipped up-down. The only numbers that remain the same which turned up-side-down or mirrored are 0, 1, and 8, so a tetradic number is a palindromic number containing only 0, 1, and 8 as digits. The first few tetradic numbers are 1, 8, 11, 88, 101, 111, 181, 808, 818, ... (OEIS A006072).\n\nTetradic numbers are also known as four-way numbers due to the fact that they have four-way symmetry and can flipped back to front, flipped front to back, mirrored up-down, or flipped up-down and always stay the same. The four-way symmetry explains the name, due to tetra- being the Greek prefix for four. Tetradic numbers are both strobogrammatic and palindromic.\n\nIf you have a tetradic number, a larger one can always be generated by adding another tetradic number to each end, retaining the symmetry.\n\nTetradic primes are a specific type of tetradic number defined as tetradic numbers that are also prime numbers. The first few tetradic primes are 11, 101, 181, 18181, 1008001, 1180811, 1880881, 1881881, ... (OEIS A068188).\n\nThe largest known tetradic prime is \n\nwhere formula_2 is a repunit. The prime has 180,055 decimal digits.\n"}
{"id": "41400343", "url": "https://en.wikipedia.org/wiki?curid=41400343", "title": "Timeline of women in mathematics", "text": "Timeline of women in mathematics\n\nThis is a timeline of women in mathematics.\n\n350–370 until 415: The lifetime of Hypatia, a Greek Alexandrine Neoplatonist philosopher in Egypt who was the first well-documented woman in mathematics.\n\n1748: Italian mathematician Maria Agnesi published the first book discussing both differential and integral calculus, called \"Instituzioni analitiche ad uso della gioventù italiana\".\n\n1759: French mathematician Émilie du Châtelet's translation and commentary on Isaac Newton's work \"Principia Mathematica\" was published posthumously; it is still considered the standard French translation.\n\n1827: French mathematician Sophie Germain saw her theorem, known as Germain's Theorem, published in a footnote of a book by the mathematician Adrien-Marie Legendre. In this theorem Germain proved that if \"x\", \"y\", and \"z\" are integers and if \"x\" + \"y\" = \"z\" then either \"x\", \"y\", or \"z\" must be divisible by 5. Germain's theorem was a major step toward proving Fermat's last theorem for the case where n equals 5.\n\n1829: The first public examination of an American girl in geometry was held.\n\n1874: Russian mathematician Sofia Kovalevskaya became the first woman in modern Europe to gain a doctorate in mathematics, which she earned from the University of Göttingen in Germany. \n\n1880: Charlotte Angas Scott of Britain obtained special permission to take the Cambridge Mathematical Tripos Exam, as women were not normally allowed to sit for the exam. She came eighth on the Tripos of all students taking them, but due to her sex, the title of \"eighth wrangler,\" a high honour, went officially to a male student. At the ceremony, however, after the seventh wrangler had been announced, all the students in the audience shouted her name. Because she could not attend the award ceremony, Scott celebrated her accomplishment at Girton College where there were cheers and clapping at dinner, and a special evening ceremony where the students sang \"See the Conquering Hero Comes\", and she received an ode written by a staff member, and was crowned with laurels. \n\n1886: Winifred Edgerton Merrill became the first American woman to earn a PhD in mathematics, which she earned from Columbia University.\n\n1888: The Kovalevskaya top, one of a brief list of known examples of integrable rigid body motion, was discovered by Sofia Kovalevskaya.\n\n1889: Sofia Kovalevskaya was appointed as the first female professor in Northern Europe, at the University of Stockholm.\n\n1890: British woman Philippa Fawcett became the first woman to obtain the top score in the Cambridge Mathematical Tripos Exam.\n\n1913: American mathematician Mildred Sanderson published her theorem about modular invariants in her thesis. It states: “To any modular invariant i of a system of forms under any group G of linear transformations with coefficients in the GF[pn], there corresponds a formal invariant I under G such that I = i for all sets of values in the field of the coefficients of the system of forms.” She was Leonard Dickson’s first female graduate student, and he later wrote of her thesis, “This paper is a highly important contribution to this field of work; its importance lies partly in the fact that it establishes a correspondence between modular and formal invariants. Her main theorem has already been frequently quoted on account of its fundamental character. Her proof is a remarkable piece of mathematics.” E.T. Bell wrote, “Miss Sanderson’s single contribution (1913) to modular invariants has been rated by competent judges as one of the classics of the subject.”\n\n1918: German mathematician Emmy Noether published Noether's (first) theorem, which states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. \n\n1927: American mathematician Anna Pell-Wheeler became the first woman to present a lecture at the American Mathematical Society Colloquium.\n\n1930: Cecilia Kreiger became the first woman to earn a PhD in mathematics in Canada, at the University of Toronto.\n\n1930s: British mathematician Mary Cartwright proved her theorem, now known as Cartwright's theorem, which gives an estimate for the maximum modulus of an analytic function that takes the same value no more than p times in the unit disc. To prove the theorem she used a new approach, applying a technique introduced by Lars Ahlfors for conformal mappings.\n\n1943: Euphemia Haynes became the first African-American woman to earn a Ph.D. in mathematics, which she earned from Catholic University.\n\n1949: American mathematician Gertrude Mary Cox became the first woman elected into the International Statistical Institute.\n\n1956: American mathematician Gladys West began collecting data from satellites at the Naval Surface Warfare Center Dahlgren Division. Her calculations directly impacted the development of accurate GPS systems.\n\n1962: American mathematician Mina Rees became the first woman to win the Yueh-Gin Gung and Dr. Charles Y. Hu Award for Distinguished Service to Mathematics, which is the most prestigious award made by the Mathematical Association of America.\n\n1964: Mary Cartwright became the first woman to win the Sylvester Medal of the Royal Society of London, which is given every three years since 1901 for the encouragement of mathematical research, without regard to nationality.\n\n1966: American mathematician and physics professor Mary L. Boas published \"Mathematical Methods in the Physical Sciences\", which was still widely used in college classrooms as of 1999.\n\n1968: Mary Cartwright became the first woman to win the De Morgan Medal, the London Mathematical Society's premier award.\n\n1970: American mathematician Mina Rees became the first female president of the American Association for the Advancement of Science.\n\n1971: American mathematician Mary Ellen Rudin constructed the first Dowker space.\n\n1971: The Association for Women in Mathematics (AWM) was founded. It is a professional society whose mission is to encourage women and girls to study and to have active careers in the mathematical sciences, and to promote equal opportunity for and the equal treatment of women and girls in the mathematical sciences. It is incorporated in America in the state of Massachusetts.\n\n1971: The Joint Committee on Women in the Mathematical Sciences (JCW), was founded as a committee of the American Mathematical Society (AMS). It is now a joint committee of seven mathematical and statistical societies which works to identify mechanisms for the enhancement of opportunities for women in the mathematical and statistical sciences, recommend actions to the governing bodies of the member societies in support of these opportunities, and document its recommendations by presenting data.\n\n1973: American mathematician Jean Taylor published her dissertation on “Regularity of the Singular Set of Two-Dimensional Area-Minimizing Flat Chains Modulo 3 in R3” which solved a long-standing problem about length and smoothness of soap-film triple function curves.\n\n1974: American mathematician Joan Birman published the book \"Braids, Links, and Mapping Class Groups\". It has become a standard introduction, with many of today’s researchers having learned the subject through it.\n\n1975–1977: American amateur mathematician Marjorie Rice, who had no formal training in mathematics beyond high school, discovered three new types of tessellating pentagons and more than sixty distinct tessellations by pentagons.\n\n1975: American mathematician Julia Robinson became the first female mathematician elected to the National Academy of Sciences.\n\n1979: Mary Ellen Rudin became the first woman to present the Earle Raymond Hedrick Lectures; these lectures were established by the Mathematical Association of America in 1952 to present to the Association a lecturer of known skill as an expositor of mathematics \"who will present a series of at most three lectures accessible to a large fraction of those who teach college mathematics.\"\n\n1979: American mathematician Dorothy Lewis Bernstein became the first female president of the Mathematical Association of America.\n\n1981: Canadian-American mathematician Cathleen Morawetz became the first female mathematician to give a Josiah Willard Gibbs Lecture; these lectures are of a semi-popular nature and are given by invitation, and are usually devoted to mathematics or its applications.\n\n1981: American mathematician Doris Schattschneider became the first female editor of \"Mathematics Magazine.\"\n\n1983: Julia Robinson became the first female president of the American Mathematical Society.\n\n1983: Julia Robinson became the first female mathematician to be awarded a MacArthur Fellowship.\n\n1988: Doris Schattschneider became the first woman to present the J. Sutherland Frame Lectures, which are presented at the summer meeting of the Mathematical Association of America.\n\n1992: American mathematician Gloria Gilmer became the first woman to deliver a major National Association of Mathematicians lecture (it was the Cox–Talbot address).\n\n1995: American mathematician Margaret Wright became the first female president of the Society for Industrial and Applied Mathematics.\n\n1995: Israeli-Canadian mathematician Leah Edelstein-Keshet became the first female president of the Society for Mathematical Biology.\n\n1996: Joan Birman became the first woman to receive the Chauvenet Prize, which is awarded annually by the Mathematical Association of America to the author of an outstanding expository article on a mathematical topic by a member of the association.\n\n1996: Ioana Dumitriu, a New York University sophomore from Romania, became the first woman to be named a Putnam Fellow. Putnam Fellows are the top five (or six, in case of a tie) scorers on The William Lowell Putnam Mathematical Competition.\n\n1998: Melanie Wood became the first female American to make the U.S. International Math Olympiad Team. She won silver medals in the 1998 and 1999 International Mathematical Olympiads.\n\n2002: Susan Howson became the first woman to win the Adams Prize, given annually by the University of Cambridge to a British mathematician under the age of 40.\n\n2002: Melanie Wood became the first American woman and second woman overall to be named a Putnam Fellow in 2002.\n\n2004: Melanie Wood became the first woman to win the Frank and Brennie Morgan Prize for Outstanding Research in Mathematics by an Undergraduate Student. It is an annual award given to an undergraduate student in the US, Canada, or Mexico who demonstrates superior mathematics research.\n\n2004: American Alison Miller became the first ever female gold medal winner on the U.S. International Math Olympiad Team.\n\n2006: Polish-Canadian mathematician Nicole Tomczak-Jaegermann became the first woman to win the CRM-Fields-PIMS prize, which recognizes exceptional achievement in the mathematical sciences.\n\n2006: Stefanie Petermichl, a German mathematical analyst then at the University of Texas at Austin, became the first woman to win the Salem Prize, an annual award given to young mathematicians considered to have done outstanding work in Raphael Salem's field of interest, primarily Fourier series and related areas in analysis. She shared the prize with Artur Avila.\n\n2012: Latvian mathematician Daina Taimina became the first woman to win the Euler Book Prize, which is awarded annually to an author or authors of an outstanding book about mathematics, for her book \"Crocheting Adventures with Hyperbolic Planes.\"\n\n2012: The Working Committee for Women in Mathematics, Chinese Mathematical Society (WCWM-CMS) was founded; it is a national non-profit academic organization in which female mathematicians who are engaged in research, teaching, and applications of mathematics can share their scientific research through academic exchanges both in China and abroad. It is one of the branches of the Chinese Mathematical Society (CMS).\n\n2014: Maryam Mirzakhani became the first woman as well as the first Iranian to be awarded the Fields Medal, which she was awarded for \"her outstanding contributions to the dynamics and geometry of Riemann surfaces and their moduli spaces.\" She shared the prize with Martin Hairer, Manjul Bhargava, and Artur Avila. It is a prize awarded to two, three, or four mathematicians not over 40 years of age at each International Congress of the International Mathematical Union, and is often viewed as the greatest honor a mathematician can receive.\n\n2016: French mathematician Claire Voisin received the CNRS Gold medal, the highest scientific research award in France.\n\nTimeline of women in mathematics in the United States\n"}
{"id": "132729", "url": "https://en.wikipedia.org/wiki?curid=132729", "title": "Tuple", "text": "Tuple\n\nIn mathematics, a tuple is a finite ordered list (sequence) of elements. An -tuple is a sequence (or ordered list) of elements, where is a non-negative integer. There is only one 0-tuple, an empty sequence, or empty tuple, as it is referred to. An -tuple is defined inductively using the construction of an ordered pair.\n\nMathematicians usually write tuples by listing the elements within parentheses \"formula_1\" and separated by commas; for example, formula_2 denotes a 5-tuple. Sometimes other symbols are used to surround the elements, such as square brackets \"[ ]\" or angle brackets \"< >\". Braces \"{ }\" are only used in defining arrays in some programming languages such as Java and Visual Basic, but not in mathematical expressions, as they are the standard notation for sets. The term \"tuple\" can often occur when discussing other mathematical objects, such as vectors.\n\nIn computer science, tuples come in many forms. In dynamically typed languages, such as Lisp, lists are commonly used as tuples. Most typed functional programming languages implement tuples directly as product types, tightly associated with algebraic data types, pattern matching, and destructuring assignment. Many programming languages offer an alternative to tuples, known as record types, featuring unordered elements accessed by label. A few programming languages combine ordered tuple product types and unordered record types into a single construct, as in C structs and Haskell records. Relational databases may formally identify their rows (records) as \"tuples\".\n\nTuples also occur in relational algebra; when programming the semantic web with the Resource Description Framework (RDF); in linguistics; and in philosophy.\n\nThe term originated as an abstraction of the sequence: single, double, triple, quadruple, quintuple, sextuple, septuple, octuple, ..., ‑tuple, ..., where the prefixes are taken from the Latin names of the numerals. The unique 0‑tuple is called the null tuple. A 1‑tuple is called a singleton, a 2‑tuple is called an ordered pair and a 3‑tuple is a triple or triplet. can be any nonnegative integer. For example, a complex number can be represented as a 2‑tuple, a quaternion can be represented as a 4‑tuple, an octonion can be represented as an 8‑tuple and a sedenion can be represented as a 16‑tuple.\n\nAlthough these uses treat \"‑tuple\" as the suffix, the original suffix was \"‑ple\" as in \"triple\" (three-fold) or \"decuple\" (ten‑fold). This originates from medieval Latin \"plus\" (meaning \"more\") related to Greek ‑πλοῦς, which replaced the classical and late antique \"‑plex\" (meaning \"folded\"), as in \"duplex\".\n\nThe general rule for the identity of two -tuples is\n\nThus a tuple has properties that distinguish it from a set.\n\nThere are several definitions of tuples that give them the properties described in the previous section.\n\nIf we are dealing with sets, an -tuple can be regarded as a function, , whose domain is the tuple's implicit set of element indices, , and whose codomain, , is the tuple's set of elements. Formally:\nwhere:\nIn slightly less formal notation this says:\n\nAnother way of modeling tuples in Set Theory is as nested ordered pairs. This approach assumes that the notion of ordered pair has already been defined; thus a 2-tuple \nThis definition can be applied recursively to the -tuple:\n\nThus, for example:\n\nA variant of this definition starts \"peeling off\" elements from the other end:\nThis definition can be applied recursively:\n\nThus, for example:\n\nUsing Kuratowski's representation for an ordered pair, the second definition above can be reformulated in terms of pure set theory:\n\nIn this formulation:\n\nIn discrete mathematics, especially combinatorics and finite probability theory, -tuples arise in the context of various counting problems and are treated more informally as ordered lists of length . -tuples whose entries come from a set of elements are also called \"arrangements with repetition\", \"permutations of a multiset\" and, in some non-English literature, \"variations with repetition\". The number of -tuples of an -set is . This follows from the combinatorial rule of product. If is a finite set of cardinality , this number is the cardinality of the -fold Cartesian power . Tuples are elements of this product set.\n\nIn type theory, commonly used in programming languages, a tuple has a product type; this fixes not only the length, but also the underlying types of each component. Formally:\nand the projections are term constructors:\n\nThe tuple with labeled elements used in the relational model has a record type. Both of these types can be defined as simple extensions of the simply typed lambda calculus.\n\nThe notion of a tuple in type theory and that in set theory are related in the following way: If we consider the natural model of a type theory, and use the Scott brackets to indicate the semantic interpretation, then the model consists of some sets formula_29 (note: the use of italics here that distinguishes sets from types) such that:\nand the interpretation of the basic terms is:\n\nThe -tuple of type theory has the natural interpretation as an -tuple of set theory:\nThe unit type has as semantic interpretation the 0-tuple.\n\n\n"}
{"id": "3739933", "url": "https://en.wikipedia.org/wiki?curid=3739933", "title": "Turing's proof", "text": "Turing's proof\n\nTuring's proof is a proof by Alan Turing, first published in January 1937 with the title On Computable Numbers, with an Application to the Entscheidungsproblem. It was the second proof of the assertion (Alonzo Church's proof was first) that some decision problems are \"undecidable\": there is no single algorithm that infallibly gives a correct \"yes\" or \"no\" answer to each instance of the problem. In his own words:\n\"...what I shall prove is quite different from the well-known results of Gödel ... I shall now show that there is no general method which tells whether a given formula U is provable in K [\"Principia Mathematica\"]...\" (\"Undecidable\", p. 145).\n\nTuring preceded this proof with two others. The second and third both rely on the first. All rely on his development of type-writer-like \"computing machines\" that obey a simple set of rules and his subsequent development of a \"universal computing machine\".\n\nIn 1905, Jules Richard presented this profound paradox. Alan Turing's first proof constructs this paradox with his so-called computing machine and proves that this machine cannot answer a simple question: will this machine be able to determine if \"any\" computing machine (including itself) will become trapped in an unproductive \"infinite loop\" (i.e. it fails to continue its computation of the diagonal number).\n\nA succinct definition of Richard's paradox is found in Whitehead and Russell's \"Principia Mathematica\":\n\nTuring's proof is complicated by a large number of definitions, and confounded with what Martin Davis called \"petty technical details\" and \"...technical details [that] are incorrect as given\" (Davis's commentary in \"Undecidable\", p. 115). Turing himself published \"A correction\" in 1937: \"The author is indebted to P. Bernays for pointing out these errors\" (\"Undecidable\", p. 152).\n\nSpecifically, in its original form the third proof is badly marred by technical errors. And even after Bernays' suggestions and Turing's corrections, errors remained in the description of the universal machine. And confusingly, since Turing was unable to correct his original paper, some text within the body harks to Turing's flawed first effort.\n\nBernays' corrections may be found in \"Undecidable\", pp. 152–154; the original is to be found as:\n\nThe on-line version of Turing's paper has these corrections in an addendum; however, corrections to the Universal Machine must be found in an analysis provided by Emil Post.\n\nAt first, the only mathematician to pay close attention to the details of the proof was Post (cf. Hodges p. 125) — mainly because he had arrived simultaneously at a similar reduction of \"algorithm\" to primitive machine-like actions, so he took a personal interest in the proof. Strangely (perhaps World War II intervened) it took Post some ten years to dissect it in the \"Appendix\" to his paper \"Recursive Unsolvability of a Problem of Thue\", 1947 (reprinted in \"Undecidable\", p. 293).\n\n\"Before readers tackle \"Proof #3\" they are advised to place those corrections on their copy of the proof.\"\n\nOther problems present themselves: In his \"Appendix\" Post commented indirectly on the paper's difficulty and directly on its \"outline nature\" (Post in \"Undecidable\", p. 299) and \"intuitive form\" of the proofs (\"ibid\".). Post had to infer various points:\n\nAnyone who has ever tried to read the paper will understand Hodges' complaint:\n\nIn his proof that the Entscheidungsproblem can have no solution, Turing proceeded from two proofs that were to lead to his final proof. His first theorem is most relevant to the halting problem, the second is more relevant to Rice's theorem.\n\nFirst proof: that no \"computing machine\" exists that can decide whether or not an arbitrary \"computing machine\" (as represented by an integer 1, 2, 3, . . .) is \"circle-free\" (i.e. goes on printing its number in binary ad infinitum): \"...we have no general process for doing this in a finite number of steps\" (p. 132, \"ibid\".). Turing's proof, although it seems to use the \"diagonal process\", in fact shows that his machine (called H) cannot calculate its own number, let alone the entire diagonal number (Cantor's diagonal argument): \"The fallacy in the argument lies in the assumption that B [the diagonal number] is computable\" (\"Undecidable\", p. 132). The proof does not require much mathematics.\n\nSecond proof: This one is perhaps more familiar to readers as Rice's theorem: \"We can show further that \"there can be no machine E which, when supplied with the S.D [\"program\"] of an arbitrary machine M, will determine whether M ever prints a given symbol (0 say)\"\" (his italics, \"Undecidable\", p. 134).\n\nThird proof: \"Corresponding to each computing machine M we construct a formula Un(M) and we show that, if there is a general method for determining whether Un(M) is provable, then there is a general method for determining whether M ever prints 0\" (\"Undecidable\", p. 145)\n\n[Readers who brave Proof #3 should come equipped with a solid background in (i) logic (ii) the paper of Kurt Gödel \"On Formally Undecidable Propositions of Principia Mathematica and Related Systems\" (reprinted in \"Undecidable\", p. 5). For assistance with Gödel's paper they should consult e.g. Ernest Nagel and James R. Newman, \"Godel's Proof\", New York University Press, 1958.]\n\nThis proof requires the use of formal logic to prove a first lemma, followed by a brief word-proof of the second:\n\nFinally, in only 64 words and symbols Turing proves by \"reductio ad absurdum\" that \"the Hilbert Entscheidungsproblem can have no solution\" (\"Undecidable\", p. 145).\n\nTuring created a thicket of abbreviations; see the glossary at the end of this for help.\n\nSome key clarifications:\n\nTuring begins the proof with the assertion of the existence of a “decision/determination” machine D. When fed any S.D (string of symbols A, C, D, L, R, N, semicolon “;”) it will determine if this S.D (symbol string) represents a \"computing machine\" that is either \"circular\" — and therefore \"un-satisfactory u\" — or \"circle-free\" — and therefore \"satisfactory s\".\n\nTuring makes no comment about how machine D goes about its work. For sake of argument, we suppose that D would first look to see if the string of symbols is \"well-formed\" (i.e. in the form of an algorithm and not just a scramble of symbols), and if not then discard it. Then it would go “circle-hunting”. To do this perhaps it would use “heuristics” (tricks: taught or learned). For purposes of the proof, these details are not important.\n\nTuring then describes (rather loosely) the algorithm (method) to be followed by a machine he calls H. Machine H contains within it the decision-machine D (thus D is a “subroutine” of H). Machine H’s algorithm is expressed in H’s table of instructions, or perhaps in H’s Standard Description on tape and united with the universal machine U; Turing does not specify this.\n\nMachine H is responsible for converting \"any\" number N into an equivalent S.D symbol string for sub-machine D to test. (In programming parlance: H passes an arbitrary \"S.D” to D, and D returns “satisfactory” or “unsatisfactory”.) Machine H is also responsible for keeping a tally R (“Record”?) of successful numbers (we suppose that the number of “successful” S.D's, i.e. R, is much less than the number of S.D's tested, i.e. N). Finally, H prints on a section of its tape a diagonal number “beta-primed” B’. H creates this B’ by “simulating” (in the computer-sense) the “motions” of each “satisfactory” machine/number; eventually this machine/number under test will arrive at its Rth “figure” (1 or 0), and H will print it. H then is responsible for “cleaning up the mess” left by the simulation, incrementing N and proceeding onward with its tests, \"ad infinitum\".\n\nAn example: Suppose machine H has tested 13472 numbers and produced 5 satisfactory numbers, i.e. H has converted the numbers 1 through 13472 into S.D’s (symbol strings) and passed them to D for test. As a consequence H has tallied 5 satisfactory numbers and run the first one to its 1st “figure”, the second to its 2nd figure, the third to its 3rd figure, the fourth to its 4th figure, and the fifth to its 5th figure. The count now stands at N = 13472, R = 5, and B’ = “.10011” (for example). H cleans up the mess on its tape, and proceeds:\n\n\"H\" increments \"N\" = 13473 and converts \"13473\" to symbol string ADRLD. If sub-machine D deems ADLRD unsatisfactory, then H leaves the tally-record R at 5. H will increment the number N to 13474 and proceed onward. On the other hand, if D deems ADRLD satisfactory then H will increment R to 6. H will convert N (again) into ADLRD [this is just an example, ADLRD is probably useless] and “run” it using the universal machine U until this machine-under-test (U \"running\" ADRLD) prints its 6th “figure” i.e. 1 or 0. H will print this 6th number (e.g. “0”) in the “output” region of its tape (e.g. B’ = “.100110”).\n\nH cleans up the mess, and then increments the number \"N\" to 13474.\n\nThe whole process unravels when H arrives at its own number K. We will proceed with our example. Suppose the successful-tally/record R stands at 12. H finally arrives at its own number minus 1, i.e. N = K-1 = 4335...3214, and this number is unsuccessful. Then H increments N to produce K = 4355...3215, i.e. its own number. H converts this to “LDDR...DCAR” and passes it to decision-machine D. Decision-machine D must return “satisfactory” (that is: H must \"by definition\" go on and on testing, \"ad infinitum\", because it is \"circle-free\"). So H now increments tally R from 12 to 13 and then re-converts the number-under-test K into its S.D and uses U to simulate it. But this means that H will be simulating its own motions. What is the first thing the simulation will do? This simulation K-aka-H either creates a new N or “resets” the “old” N to 1. This \"K-aka-H\" either creates a new R or “resets” the “old” R to 0. Old-H “runs” new \"K-aka-H\" until it arrives at its 12th figure.\n\nBut it never makes it to the 13th figure; K-aka-H eventually arrives at 4355...3215, again, and \"K-aka-H\" must repeat the test. \"K-aka-H\" will never reach the 13th figure. The H-machine probably just prints copies of itself \"ad infinitum\" across blank tape. But this contradicts the premise that H is a satisfactory, non-circular computing machine that goes on printing the diagonal numbers's 1's and 0's forever. (We will see the same thing if N is reset to 1 and R is reset to 0.)\n\nIf the reader does not believe this, they can write a \"stub\" for decision-machine D (stub \"D\" will return \"satisfactory\") and then see for themselves what happens at the instant machine H encounters its own number.\n\nLess than one page long, the passage from premises to conclusion is obscure.\n\nTuring proceeds by \"reductio ad absurdum\". He asserts the existence of a machine E, which when given the S.D (Standard Description, i.e. \"program\") of an arbitrary machine M, will determine whether M ever prints a given symbol (0 say). He does not assert that this M is a \"computing machine\".\n\nGiven the existence of machine E, Turing proceeds as follows:\n\nThe difficulty in the proof is step 1. The reader will be helped by realizing that Turing is not explaining his subtle handiwork. (In a nutshell: he is using certain equivalencies between the “existential-“ and “universal-operators” together with their equivalent expressions written with logical operators.)\n\nHere's an example: Suppose we see before us a parking lot full of hundreds of cars. We decide to go around the entire lot looking for: “Cars with flat (bad) tires”. After an hour or so we have found two “cars with bad tires.” We can now say with certainty that “Some cars have bad tires”. Or we could say: “It’s not true that ‘All the cars have good tires’”. Or: “It is true that: ‘not all the cars have good tires”. Let us go to another lot. Here we discover that “All the cars have good tires.” We might say, “There’s not a single instance of a car having a bad tire.” Thus we see that, if we can say something about each car separately then we can say something about ALL of them collectively.\n\nThis is what Turing does:\nFrom \"M\" he creates a collection of machines {\"M\"1, \"M\"2, \"M\"3, \"M\"4, ..., \"Mn\"} and about each he writes a sentence: “\"X\" prints at least one 0” and allows only two “truth values”, True = blank or False = :0:. One by one he determines the truth value of the sentence for each machine and makes a string of blanks or :0:, or some combination of these. We might get something like this: “\"M\"1 prints a 0” = True AND “\"M\"2 prints a 0” = True AND “\"M\"3 prints a 0” = True AND “\"M\"4 prints a 0” = False, ... AND “\"Mn\" prints a 0” = False. He gets the string\nif there are an infinite number of machines \"Mn\". If on the other hand if every machine had produced a \"True\" then the expression on the tape would be\n\nThus Turing has converted statements about each machine considered separately into a single \"statement\" (string) about all of them. Given the machine (he calls it G) that created this expression, he can test it with his machine E and determine if it ever produces a 0. In our first example above we see that indeed it does, so we know that not all the M's in our sequence print 0s. But the second example shows that, since the string is blanks then every Mn in our sequence has produced a 0.\n\nAll that remains for Turing to do is create a process to create the sequence of Mn's from a single M.\n\nSuppose \"M\" prints this pattern:\n\nTuring creates another machine F that takes M and crunches out a sequence of Mn's that successively convert the first n 0's to “0-bar” (0):\nHe claims, without showing details, that this machine F is truly build-able. We can see that one of a couple things could happen. F may run out of machines that have 0's, or it may have to go on \"ad infinitum\" creating machines to “cancel the zeros”.\n\nTuring now combines machines E and F into a composite machine G. G starts with the original M, then uses F to create all the successor-machines M1, M2. . ., Mn. Then G uses E to test each machine starting with M. If E detects that a machine never prints a zero, G prints :0: for that machine. If E detects that a machine does print a 0 (we assume, Turing doesn’t say) then G prints :: or just skips this entry, leaving the squares blank. We can see that a couple things can happen.\n\nNow, what happens when we apply E to G itself?\n\nAs we can apply the same process for determining if M prints 1 infinitely often. When we combine these processes, we can determine that M does, or does not, go on printing 1's and 0's \"ad infinitum\". Thus we have a method for determining if M is circle-free. By Proof 1 this is impossible. So the first assertion that E exists, is wrong: E does not exist.\n\nHere Turing proves \"that the Hilbert Entscheidungsproblem can have no solution\" (\"Undecidable\", p. 145). Here he\n\n\n\nTuring demonstrates the existence of a formula Un(M) which says, in effect, that \"in some complete configuration of M, 0 appears on the tape\" (p. 146). This formula is TRUE, that is, it is \"constructible\", and he shows how to go about this.\n\nThen Turing proves two Lemmas, the first requiring all the hard work. (The second is the converse of the first.) Then he uses \"reductio ad absurdum\" to prove his final result:\n\n\n\n\"If readers intend to study the proof in detail they should correct their copies of the pages of the third proof with the corrections that Turing supplied\".\n\nTo (even attempt to) follow the technical details, the reader will need to understand the definition of \"provable\" and be aware of important \"clues\".\n\n\"Provable\" means, in the sense of Gödel, that (i) the axiom system itself is powerful enough to produce (express) the sentence \"This sentence is provable\", and (ii) that in any arbitrary \"well-formed\" proof the symbols lead by axioms, definitions, and substitution to the symbols of the conclusion.\n\nFirst clue: \"Let us put the description of M into the first standard form of §6\". Section 6 describes the very specific \"encoding\" of machine M on the tape of a \"universal machine\" U. This requires the reader to know some idiosyncrasies of Turing's universal machine U and the encoding scheme.\n\n(i) The universal machine is a set of \"universal\" instructions that reside in an \"instruction table\". Separate from this, on U's tape, a \"computing machine\" M will reside as \"M-code\". The universal table of instructions can print on the tape the symbols A, C, D, 0, 1, u, v, w, x, y, z, : . The various machines M can print these symbols only indirectly by commanding U to print them.\n\n(ii) The \"machine code\" of M consists of only a few letters and the semicolon, i.e. D, C, A, R, L, N, ; . Nowhere within the \"code\" of M will the numerical \"figures\" (symbols) 1 and 0 ever appear. If M wants U to print a symbol from the collection blank, 0, 1 then it uses one of the following codes to tell U to print them. To make things more confusing, Turing calls these symbols S0, S1, and S2, i.e.\n\n(iii) A \"computing machine\", whether it is built directly into a table (as his first examples show), or as machine-code M on universal-machine U's tape, prints its number on blank tape (to the right of M-code, if there is one) as 1s and 0s forever proceeding to the right.\n\n(iv) If a \"computing machine\" is U+\"M-code\", then \"M-code\" appears first on the tape; the tape has a left end and the \"M-code\" starts there and proceeds to the right on alternate squares. When the M-code comes to an end (and it must, because of the assumption that these M-codes are finite algorithms), the \"figures\" will begin as 1s and 0s on alternate squares, proceeding to the right forever. Turing uses the (blank) alternate squares (called \"E\"- \"eraseable\"- squares) to help U+\"M-code\" keep track of where the calculations are, both in the M-code and in the \"figures\" that the machine is printing.\n\n(v) A \"complete configuration\" is a printing of all symbols on the tape, including M-code [?] and \"figures\" up to that point, together with the figure currently being scanned (with a pointer-character printed to the left of the scanned symbol ?). If we have interpreted Turing's meaning correctly, this will be a hugely long set of symbols. But whether the entire M-code must be repeated is unclear; only a printing of the current M-code instruction is necessary plus the printing of all figures with a figure-marker).\n\n(vi) Turing reduced the vast possible number of instructions in \"M-code\" (again: the code of M to appear on the tape) to a small canonical set, one of three similar to this: {qi Sj Sk R ql} e.g. \"If machine is executing instruction #qi and symbol Sj is on the square being scanned, then Print symbol Sk and go Right and then go to instruction ql\": The other instructions are similar, encoding for \"Left\" L and \"No motion\" N. It is this set that is encoded by the string of symbols qi = DA...A, Sj = DC...C, Sk = DC...C, R, ql = DA...A. Each instruction is separated from another one by the semicolon. For example, {q5, S1 S0 L q3} means: Instruction #5: If scanned symbol is 0 then print blank, go Left, then go to instruction #3. It is encoded as follows\n\nSecond clue: Turing is using ideas introduced in Gödel's paper, that is, the \"Gödelization\" of (at least part of) the formula for Un(M). This clue appears only as a footnote on page 138 (\"Undecidable\"): \"A sequence of r primes is denoted by ^(r)\" (\"ibid\".) [Here, r inside parentheses is \"raised\".] This \"sequence of primes\" appears in a formula called F^(n).\n\nThird clue: This reinforces the second clue. Turing's original attempt at the proof uses the expression\nEarlier in the paper Turing had previously used this expression (p. 138) and defined N(u) to mean \"u is a non-negative integer\" (\"ibid\".) (i.e. a Gödel number). But, with the Bernays corrections, Turing abandoned this approach (i.e. the use of N(u)) and the only place where \"the Gödel number\" appears explicitly is where he uses F^(n).\n\nWhat does this mean for the proof? The first clue means that a simple examination of the M-code on the tape will not reveal if a symbol 0 is ever printed by U+\"M-code\". A testing-machine might look for the appearance of DC in one of the strings of symbols that represent an instruction. But will this instruction ever be \"executed?\" Something has to \"run the code\" to find out. This something can be a machine, or it can be lines in a formal proof, i.e. Lemma #1.\n\nThe second and third clues mean that, as its foundation is Gödel's paper, the proof is difficult.\n\n\n\nFrankel has defined \"provable\" earlier in his book:\n\nThus a \"sentence\" is a string of symbols, and a theorem is a string of strings of symbols.\n\nTuring is confronted with the following tasks:\n\nThus the \"string of sentences\" will be strings of strings of symbols. The only allowed individual symbols will come from Godel's symbols defined in his paper.(In the following example we use the \"<\" and \">\" around a \"figure\" to indicate that the \"figure\" is the symbol being scanned by the machine).\n\nIn the following, we have to remind ourselves that every one of Turing's “computing machines” is a binary-number generator/creator that begins work on “blank tape”. Properly constructed, it always cranks away ad infinitum, but its instructions are always finite. In Turing's proofs, Turing's tape had a “left end” but extended right ad infinitum. For sake of example below we will assume that the “machine” is not a Universal machine, but rather the simpler “dedicated machine” with the instructions in the Table.\n\nOur example is based on a \"modified\" Post–Turing machine model of a Turing Machine. This model prints only the symbols 0 and 1. The blank tape is considered to be all b's. Our modified model requires us to add two more instructions to the 7 Post–Turing instructions. The abbreviations that we will use are:\nIn the cases of R, L, E, P0, and P1 after doing its task the machine continues on to the next instruction in numerical sequence; ditto for the jumps if their tests fail.\n\nBut, for brevity, our examples will only use three squares. And these will always start as there blanks with the scanned square on the left: i.e. bbb. With two symbols 1, 0 and blank we can have 27 distinct configurations:\n\nWe must be careful here, because it is quite possible that an algorithm will (temporarily) leave blanks in between figures, then come back and fill something in. More likely, an algorithm may do this intentionally. In fact, Turing's machine does this—it prints on alternate squares, leaving blanks between figures so it can print locator symbols.\n\nTuring always left alternate squares blank so his machine could place a symbol to the left of a figure (or a letter if the machine is the universal machine and the scanned square is actually in the “program”). In our little example we will forego this and just put symbols ( ) around the scanned symbol, as follows:\n\nLet us write a simple program:\n\nRemember that we always start with blank tape. The complete configuration prints the symbols on the tape followed by the next instruction:\n\nLet us add “jump” into the formula. When we do this we discover why the complete configuration must include the tape symbols. (Actually, we see this better, below.) This little program prints three “1”s to the right, reverses direction and moves left printing 0’s until it hits a blank. We will print all the symbols that our machine uses:\nHere at the end we find that a blank on the left has “come into play” so we leave it as part of the total configuration.\n\nGiven that we have done our job correctly, we add the starting conditions and see “where the theorem goes”. The resulting configuration—the number 110—is the PROOF.\n\n\n1 computable number — a number whose decimal is computable by a machine, i.e. by finite means (e.g. an algorithm)\n\n2 M — a machine with a finite instruction table and a scanning/printing head. M moves an infinite tape divided into squares each “capable of bearing a symbol”. The machine-instructions are only the following: move one square left, move one square right, on the scanned square print symbol p, erase the scanned square, if the symbol is p then do instruction aaa, if the scanned symbol is not p then do instruction aaa, if the scanned symbol is none then do instruction aaa, if the scanned symbol is any do instruction aaa [where “aaa” is an instruction-identifier].\n\n3 computing machine — an M that prints two kinds of symbols, symbols of the first type are called “figures” and are only binary symbols 1 and 0; symbols of the second type are any other symbols.\n\n4 figures — symbols 1 and 0, a.k.a. “symbols of the first kind”\n\n5 m-configuration — the instruction-identifier, either a symbol in the instruction table, or a string of symbols representing the instruction- number on the tape of the universal machine (e.g. \"DAAAAA = #5\")\n\n6 symbols of the second kind — any symbols other than 1 and 0\n\n7 circular — an unsuccessful computating machine. It fails to print, ad infinitum, the figures 0 or 1 that represent in binary the number it computes\n\n8 circle-free — a successful computating machine. It prints, ad infinitum, the figures 0 or 1 that represent in binary the number it computes\n\n9 sequence — as in “sequence computed by the machine”: symbols of the first kind a.k.a. figures a.k.a. symbols 0 and 1.\n\n10 computable sequence — can be computed by a circle-free machine\n\n11 S.D – Standard Description: a sequence of symbols A, C, D, L, R, N, “;” on a Turing machine tape\n\n12 D.N — Description Number: an S.D converted to a number: 1=A, 2=C, 3 =D, 4=L, 5=R, 6=N, 7=;\n\n13 M(n) — a machine whose D.N is number “n”\n\n14 satisfactory — a S.D or D.N that represents a circle-free machine\n\n15 U — a machine equipped with a “universal” table of instructions. If U is “supplied with a tape on the beginning of which is written the S.D of some computing machine M, U will compute the same sequence as M.”\n\n16 β’—“beta-primed”: A so-called “diagonal number” made up of the n-th figure (i.e. 0 or 1) of the n-th computable sequence [also: the computable number of H, see below]\n\n17 u — an unsatisfactory, i.e. circular, S.D\n\n18 s — satisfactory, i.e. circle-free S.D\n\n19 D — a machine contained in H (see below). When supplied with the S.D of any computing machine M, D will test M's S.D and if circular mark it with “u” and if circle-free mark it with “s”\n\n20 H — a computing machine. H computes B’, maintains R and N. H contains D and U and an unspecified machine (or process) that maintains N and R and provides D with the equivalent S.D of N. E also computes the figures of B’ and assembles the figures of B’.\n\n21 R — a record, or tally, of the quantity of successful (circle-free) S.D tested by D\n\n22 N — a number, starting with 1, to be converted into an S.D by machine E. E maintains N.\n\n23 K — a number. The D.N of H.\n\n\n5 m-configuration — the instruction-identifier, either a symbol in the instruction table, or a string of symbols representing the instruction's number on the tape of the universal machine (e.g. \"DAAAAA = instruction #5\"). In Turing's S.D the m-configuration appears twice in each instruction, the left-most string is the \"current instruction\"; the right-most string is the next instruction.\n\n24 complete configuration — the number (figure 1 or 0) of the scanned square, the complete sequence of all symbols on the tape, and the m-configuration (the instruction-identifier, either a symbol or a string of symbols representing a number, e.g. \"instruction DAAAA = #5\")\n\n25 RSi(x, y) — \"in the complete configuration x of M the symbol on square y is Si. \"complete configuration\" is definition #5,\n\n26 I(x, y) — \"in the complete configuration x of M the square y is scanned\"\n\n27 Kqm(x) — \"in the complete configuration x of M the machine-configuration (instruction number) is qm\"\n\n28 F(x,y) — \"y is the \"immediate\" successor of x\" (follows Gödel's use of \"f\" as the successor-function).\n\n29 G(x,y) — \"x precedes y\", not necessarily immediately\n\n30 Inst{qi, Sj Sk L ql} is an abbreviation, as are Inst{qi, Sj Sk R ql}, and Inst{qi, Sj Sk N ql}. See below.\n\nTuring reduces his instruction set to three “canonical forms” – one for Left, Right, and No-movement. Si and Sk are symbols on the tape.\nFor example, the operations in the first line are PSk = PRINT symbol Sk from the collection A, C, D, 0, 1, u, v, w, x, y, z, :, then move tape LEFT.\n\nThese he further abbreviated as:\n(N1) qi Sj Sk L qm\n(N2) qi Sj Sk R qm\n(N3) qi Sj Sk N qm\n\nIn Proof #3 he calls the first of these “Inst{qi Sj Sk L ql}”, and he shows how to write the entire machine S.D as the logical conjunction (logical OR): this string is called “Des(M)”, as in “Description-of-M”.\ni.e. if the machine prints 0 then 1's and 0's on alternate squares to the right ad infinitum it might have the table (a similar example appears on page 119):\nIf put them into the “ Inst( ) form” the instructions will be the following (remembering: S0 is blank, S1 = 0, S2 = 1):\nThe reduction to the Standard Description (S.D) will be:\nThis agrees with his example in the book (there will be a blank between each letter and number). Universal machine U uses the alternate blank squares as places to put \"pointers\".\n\n"}
{"id": "186023", "url": "https://en.wikipedia.org/wiki?curid=186023", "title": "Unifying theories in mathematics", "text": "Unifying theories in mathematics\n\nThere have been several attempts in history to reach a unified theory of mathematics. Some of the greatest mathematicians have expressed views that the whole subject should be fitted into one theory.\n\nThe process of unification might be seen as helping to define what constitutes mathematics as a discipline.\n\nFor example, mechanics and mathematical analysis were commonly combined into one subject during the 18th century, united by the differential equation concept; while algebra and geometry were considered largely distinct. Now we consider analysis, algebra, and geometry, but not mechanics, as parts of mathematics because they are primarily deductive formal sciences, while mechanics like physics must proceed from observation. There is no major loss of content, with analytical mechanics in the old sense now expressed in terms of symplectic topology, based on the newer theory of manifolds.\n\nThe term \"theory\" is used informally within mathematics to mean a self-consistent body of definitions, axioms, theorems, examples, and so on. (Examples include group theory, Galois theory, control theory, and K-theory.) In particular there is no connotation of \"hypothetical\". Thus the term \"unifying theory\" is more like a sociological term used to study the actions of mathematicians. It may assume nothing conjectural that would be analogous to an undiscovered scientific link. There is really no cognate within mathematics to such concepts as \"Proto-World\" in linguistics or the Gaia hypothesis.\n\nNonetheless there have been several episodes within the history of mathematics in which sets of individual theorems were found to be special cases of a single unifying result, or in which a single perspective about how to proceed when developing an area of mathematics could be applied fruitfully to multiple branches of the subject.\n\nA well-known example was the development of analytic geometry, which in the hands of mathematicians such as Descartes and Fermat showed that many theorems about curves and surfaces of special types could be stated in algebraic language (then new), each of which could then be proved using the same techniques. That is, the theorems were very similar algebraically, even if the geometrical interpretations were distinct.\n\nIn 1859 Arthur Cayley initiated a unification of metric geometries through use of the Cayley-Klein metrics. Later Felix Klein used such metrics to provide a foundation for non-Euclidean geometry.\n\nIn 1872, Felix Klein noted that the many branches of geometry which had been developed during the 19th century (affine geometry, projective geometry, hyperbolic geometry, etc.) could all be treated in a uniform way. He did this by considering the groups under which the geometric objects were invariant. This unification of geometry goes by the name of the Erlangen programme.\n\nEarly in the 20th century, many parts of mathematics began to be treated by delineating useful sets of axioms and then studying their consequences. Thus, for example, the studies of \"hypercomplex numbers\", such as considered by the Quaternion Society, were put onto an axiomatic footing as branches of ring theory (in this case, with the specific meaning of associative algebras over the field of complex numbers.) In this context, the quotient ring concept is one of the most powerful unifiers.\n\nThis was a general change of methodology, since the needs of applications had up until then meant that much of mathematics was taught by means of algorithms (or processes close to being algorithmic). Arithmetic is still taught that way. It was a parallel to the development of mathematical logic as a stand-alone branch of mathematics. By the 1930s symbolic logic itself was adequately included within mathematics.\n\nIn most cases, mathematical objects under study can be defined (albeit non-canonically) as sets or, more informally, as sets with additional structure such as an addition operation. Set theory now serves as a \"lingua franca\" for the development of mathematical themes.\n\nThe cause of axiomatic development was taken up in earnest by the Bourbaki group of mathematicians. Taken to its extreme, this attitude was thought to demand mathematics developed in its greatest generality. One started from the most general axioms, and then specialized, for example, by introducing modules over commutative rings, and limiting to vector spaces over the real numbers only when absolutely necessary. The story proceeded in this fashion, even when the specializations were the theorems of primary interest.\n\nIn particular, this perspective placed little value on fields of mathematics (such as combinatorics) whose objects of study are very often special, or found in situations which can only superficially be related to more axiomatic branches of the subject.\n\nCategory theory is a unifying theory of mathematics that was initially developed in the second half of the 20th century. In this respect it is an alternative and complement to set theory. A key theme from the \"categorical\" point of view is that mathematics requires not only certain kinds of objects (Lie groups, Banach spaces, etc.) but also mappings between them that preserve their structure.\n\nIn particular, this clarifies exactly what it means for mathematical objects to be considered to be \"the same\". (For example, are all equilateral triangles \"the same\", or does size matter?) Saunders Mac Lane proposed that any concept with enough 'ubiquity' (occurring in various branches of mathematics) deserved isolating and studying in its own right. Category theory is arguably better adapted to that end than any other current approach. The disadvantages of relying on so-called \"abstract nonsense\" are a certain blandness and abstraction in the sense of breaking away from the roots in concrete problems. Nevertheless, the methods of category theory have steadily advanced in acceptance, in numerous areas (from D-modules to categorical logic).\n\nOn a less grandiose scale, there are frequent instances in which it appears that sets of results in two different branches of mathematics are similar, and one might ask whether there is a unifying framework which clarifies the connections. We have already noted the example of analytic geometry, and more generally the field of algebraic geometry thoroughly develops the connections between geometric objects (algebraic varieties, or more generally schemes) and algebraic ones (ideals); the touchstone result here is Hilbert's Nullstellensatz which roughly speaking shows that there is a natural one-to-one correspondence between the two types of objects.\n\nOne may view other theorems in the same light. For example, the fundamental theorem of Galois theory asserts that there is a one-to-one correspondence between extensions of a field and subgroups of the field's Galois group. The Taniyama–Shimura conjecture for elliptic curves (now proven) establishes a one-to-one correspondence between curves defined as modular forms and elliptic curves defined over the rational numbers. A research area sometimes nicknamed Monstrous Moonshine developed connections between modular forms and the finite simple group known as the Monster, starting solely with the surprise observation that in each of them the rather unusual number 196884 would arise very naturally. Another field, known as the Langlands program, likewise starts with apparently haphazard similarities (in this case, between number-theoretical results and representations of certain groups) and looks for constructions from which both sets of results would be corollaries.\n\nA short list of these theories might include:\n\nA well-known example is the Taniyama–Shimura conjecture, now the modularity theorem, which proposed that each elliptic curve over the rational numbers can be translated into a modular form (in such a way as to preserve the associated L-function). There are difficulties in identifying this with an isomorphism, in any strict sense of the word. Certain curves had been known to be both elliptic curves (of genus 1) and modular curves, before the conjecture was formulated (about 1955). The surprising part of the conjecture was the extension to factors of Jacobians of modular curves of genus > 1. It had probably not seemed plausible that there would be 'enough' such rational factors, before the conjecture was enunciated; and in fact the numerical evidence was slight until around 1970, when tables began to confirm it. The case of elliptic curves with complex multiplication was proved by Shimura in 1964. This conjecture stood for decades before being proved in generality.\n\nIn fact the Langlands program (or philosophy) is much more like a web of unifying conjectures; it really does postulate that the general theory of automorphic forms is regulated by the L-groups introduced by Robert Langlands. His \"principle of functoriality\" with respect to the L-group has a very large explanatory value with respect to known types of \"lifting\" of automorphic forms (now more broadly studied as automorphic representations). While this theory is in one sense closely linked with the Taniyama–Shimura conjecture, it should be understood that the conjecture actually operates in the opposite direction. It requires the existence of an automorphic form, starting with an object that (very abstractly) lies in a category of motives.\n\nAnother significant related point is that the Langlands approach stands apart from the whole development triggered by monstrous moonshine (connections between elliptic modular functions as Fourier series, and the group representations of the Monster group and other sporadic groups). The Langlands philosophy neither foreshadowed nor was able to include this line of research.\n\nAnother case, which so far is less well-developed but covers a wide range of mathematics, is the conjectural basis of some parts of K-theory. The Baum–Connes conjecture, now a long-standing problem, has been joined by others in a group known as the isomorphism conjectures in K-theory. These include the Farrell–Jones conjecture and Bost conjecture.\n\n"}
{"id": "6290771", "url": "https://en.wikipedia.org/wiki?curid=6290771", "title": "Whitehead's point-free geometry", "text": "Whitehead's point-free geometry\n\nIn mathematics, point-free geometry is a geometry whose primitive ontological notion is \"region\" rather than point. Two axiomatic systems are set out below, one grounded in mereology, the other in mereotopology and known as \"connection theory\". A point can mark a space or objects.\n\nPoint-free geometry was first formulated in Whitehead (1919, 1920), not as a theory of geometry or of spacetime, but of \"events\" and of an \"extension relation\" between events. Whitehead's purposes were as much philosophical as scientific and mathematical.\n\nWhitehead did not set out his theories in a manner that would satisfy present-day canons of formality. The two formal first order theories described in this entry were devised by others in order to clarify and refine Whitehead's theories. The domain for both theories consists of \"regions.\" All unquantified variables in this entry should be taken as tacitly universally quantified; hence all axioms should be taken as universal closures. No axiom requires more than three quantified variables; hence a translation of first order theories into relation algebra is possible. Each set of axioms has but four existential quantifiers.\n\nThe axioms G1-G7 are, but for numbering, those of Def. 2.1 in Gerla and Miranda (2008) (see also Gerla (1995)). The identifiers of the form WPn, included in the verbal description of each axiom, refer to the corresponding axiom in Simons (1987: 83).\n\nThe fundamental primitive binary relation is \"Inclusion\", denoted by infix \"≤\". (\"Inclusion\" corresponds to the binary \"Parthood\" relation that is a standard feature of all mereological theories.) The intuitive meaning of \"x\"≤\"y\" is \"\"x\" is part of \"y\".\" Assuming that identity, denoted by infix \"=\", is part of the background logic, the binary relation \"Proper Part\", denoted by infix \"<\", is defined as:\n\nformula_1\n\nThe axioms are:\n\n\n\n\n\nA model of G1–G7 is an \"inclusion space\".\n\nDefinition (Gerla and Miranda 2008: Def. 4.1). Given some inclusion space, an abstractive class is a class \"G\" of regions such that \"G\" is totally ordered by Inclusion. Moreover, there does not exist a region included in all of the regions included in \"G\".\n\nIntuitively, an abstractive class defines a geometrical entity whose dimensionality is less than that of the inclusion space. For example, if the inclusion space is the Euclidean plane, then the corresponding abstractive classes are points and lines.\n\nInclusion-based point-free geometry (henceforth \"point-free geometry\") is essentially an axiomatization of Simons's (1987: 83) system W. In turn, W formalizes a theory in Whitehead (1919) whose axioms are not made explicit. Point-free geometry is W with this defect repaired. Simons (1987) did not repair this defect, instead proposing in a footnote that the reader do so as an exercise. The primitive relation of W is Proper Part, a strict partial order. The theory of Whitehead (1919) has a single primitive binary relation \"K\" defined as \"xKy\" ↔ \"y\"<\"x\". Hence \"K\" is the converse of Proper Part. Simons's WP1 asserts that Proper Part is irreflexive and so corresponds to G1. G3 establishes that inclusion, unlike Proper Part, is anti-symmetric.\n\nPoint-free geometry is closely related to a dense linear order D, whose axioms are G1-3, G5, and the totality axiom formula_9 Hence inclusion-based point-free geometry would be a proper extension of D (namely D∪{G4, G6, G7}), were it not that the D relation \"≤\" is a total order.\n\nIn his 1929 \"Process and Reality\", A. N. Whitehead proposed a different approach, one inspired by De Laguna (1922). Whitehead took as primitive the topological notion of \"contact\" between two regions, resulting in a primitive \"connection relation\" between events. Connection theory C is a first order theory that distills the first 12 of the 31 assumptions in chpt. 2 of \"Process and Reality\" into 6 axioms, C1-C6. C is a proper fragment of the theories proposed in Clarke (1981), who noted their mereological character. Theories that, like C, feature both inclusion and topological primitives, are called mereotopologies.\n\nC has one primitive relation, binary \"connection,\" denoted by the prefixed predicate letter \"C\". That \"x\" is included in \"y\" can now be defined as \"x\"≤\"y\" ↔ ∀z[\"Czx\"→\"Czy\"]. Unlike the case with inclusion spaces, connection theory enables defining \"non-tangential\" inclusion, a total order that enables the construction of abstractive classes. Gerla and Miranda (2008) argue that only thus can mereotopology unambiguously define a point.\n\nThe axioms C1-C6 below are, but for numbering, those of Def. 3.1 in Gerla and Miranda (2008).\n\n\n\n\n\n\n\nA model of C is a \"connection space\".\n\nFollowing the verbal description of each axiom is the identifier of the corresponding axiom in Casati and Varzi (1999). Their system SMT (\"strong mereotopology\") consists of C1-C3, and is essentially due to Clarke (1981). Any mereotopology can be made atomless by invoking C4, without risking paradox or triviality. Hence C extends the atomless variant of SMT by means of the axioms C5 and C6, suggested by chpt. 2 of \"Process and Reality\". For an advanced and detailed discussion of systems related to C, see Roeper (1997).\n\nBiacino and Gerla (1991) showed that every model of Clarke's theory is a Boolean algebra, and models of such algebras cannot distinguish connection from overlap. It is doubtful whether either fact is faithful to Whitehead's intent.\n\n\n\n"}
{"id": "51347294", "url": "https://en.wikipedia.org/wiki?curid=51347294", "title": "Wilhelm Winkler", "text": "Wilhelm Winkler\n\nWilhelm Winkler (June 29, 1884 – September 3, 1984) had successful careers as both an academic statistician (despite receiving no formal academic training in the field), and a program director in the Austrian government.\n\nWilhelm was the fifth of the eight children of Anne and music teacher Julius Winkler, a family situation that required him to work starting at age 13. He attended law school at Karl Friedrich University (now Charles University) in Prague, practiced law briefly in 1908, did a stint in the Austrian army, then settled into a position at the Statistical Bureau of Bohemia as the sole German-speaking statistician. While working there, he attended many university classes and reached the conclusion that \"the German statistical literature did not offer too many ideas. New life came into statistics from England and Russia where the importance of mathematical tools was recognized.\"\n\nWinkler re-enlisted in the Austrian army at the outbreak of World War I in 1914, and was decorated twice for bravery before being wounded in November 1915. During a lengthy recovery, he worked for the War Economy committee; his talents were recognized and he was appointed Secretary of State for Military Affairs at the end of the war in 1918 and he was a delegate to the Versailles Peace Conference. That year, he also married a Jewish woman named Clara Deutch. He joined the Austrian Central Statistics Office in 1920, and was promoted to director of its department of population statistics in 1925. Concurrently, he became a \"Privat-Dozent\" (assistant professor) at the University of Vienna in 1921 and an \"Ausserordentlicher Professor\" in 1929. He founded an institute for the study of minority populations, which published a constant stream of progressive and influential papers that made him unpopular with colleagues in his government job. Despite his lack of formal education, he was elected a member of the International Statistical Institute in 1926 where he actively promoted applied and precise mathematical formulations in contrast to the wordy generalizations that he had criticized 20 years earlier. As both the husband of a Jew and an outspoken critic of the unfair treatment of European minorities, Winkler was promptly fired from both his government and academic positions following the 1938 Nazi annexation of Austria. Despite severe persecution from the Nazi party, he wrote the textbook \"Basic Course in Demography\" during the occupation.\n\nAt the end of the war, he was rehired by the University of Vienna as the first full professor of statistics since 1883, and became Dean of the School of Law and Statecraft from 1950 to 1955. He was also restored as Austria's lead government statistician from 1945 to 1955. Despite these influential positions and growing international recognition, Winkler spent many years defending the statistical department from opposition within the university. The regressive attitude of Austrian and German academics towards statistics as a truly independent discipline meant that his contributions to international developments became more difficult. He did not retire until age 71, and continued to publish and vigorously promote statistics thereafter. He died just after his 100th birthday, having published 20 textbooks and over 200 papers, founded two statistical societies, edited two statistical journals, been awarded two honorary degrees, and reshaped the development of German-speaking statistics through his progressive education initiatives.\n\n"}
{"id": "24320887", "url": "https://en.wikipedia.org/wiki?curid=24320887", "title": "Yupana", "text": "Yupana\n\nA \"yupana\" (from Quechua yupay: count) is an abacus used to perform arithmetic operations dating back to the time of the Incas.\n\nThe term \"yupana\" refers to two distinct classes of objects:\n\n\nAlthough very different from each other, most of the scholars who have dealt with table-yupana, have then extended its reasoning and theories to the yupana of Poma de Ayala and vice versa, perhaps in an attempt to find a unifying thread or a common method. It should also be noted that the Nueva Coronica was discovered only in 1916 in the library of Copenhagen and that part of the studies on it were based on previous studies and theories regarding table-yupanas.\n\nSeveral chroniclers of the Indies described, unfortunately approximately, the Incan abacus and its operation.\n\nThe first was Guaman Poma de Ayala that in 1615 approximately, wrote:\n\nIn addition to providing this brief description, Poma de Ayala draws a picture of the yupana: a board of five rows and four columns in which are designed a series of white and black circles.\n\nThe father Jesuit \"José de Acosta\" wrote:\n\nFather \"Juan de Velasco\" wrote:\n\nThe first table-yupana which we know was found in 1869 in Chordeleg in the department of Cuenca (Ecuador). It is a rectangular table (33x27 cm) of wood which contains 17 compartments, of which 14 square, 2 rectangular and one octagonal. On two edges of the table there are other square compartments (12x12 cm) raised and symmetrically arranged one another, to which two square platforms (7x7 cm), are overlapped. These structures are called towers. The table presents a symmetry of the compartments with respect to the diagonal of the rectangle. The four sides of the board are also engraved with figures of human heads and a crocodile. As a result of this discovery, Charles Wiener began in 1877 a systematic study of these objects. Wiener came to the conclusion that the table-yupanas served to calculate the taxes that farmers paid to the Incan empire.\n\nFound at Caraz in 1878 - 1879, this table-yupana is different from that of Chordeleg as the material of construction is the stone and the central compartment of octagonal shape is replaced with a rectangular one; towers also have three shelves instead of two.\n\nA series of table-yupanas much different from the first, was described by Erland Nordenskiöld in 1931. These yupana, made of stone, present a series of rectangular and square compartments. The tower is composed of two rectangular compartments. The compartments are arranged symmetrically with respect to the axis of the smaller side of the table.\n\nThese yupana, made of stone, have 18 compartments of triangular shape, arranged around the table. On one side there is a rectangular tower with only one floor and three triangular compartments. In the central part there are four square compartments, coupled between them.\n\nIdentical to the yupana of Chordeleg, both for the material and the arrangement of the compartments, this table-yupana was found in the archaeological complex of Chan Chan in Peru in 1967.\n\nDiscovered in the province of Pisco (Peru), these table-yupanas are two tables in clay and bone. The first is rectangular (47x32 cm), has 22 square (5x5 cm) and three rectangular (16x18 cm) compartments, and has no towers. The second is rectangular (32x23 cm) containing 22 square compartments, two L-shaped and three rectangular in the center. The compartments are arranged symmetrically with respect to the axis of the longer side.\n\nDiscovered in the upper Ecuador by Max Uhle in 1922, this yupana is made of stone and its bins are drawn. It has the shape of a scale consisting of 10 overlapping rectangles: four on the first floor, three on the second, two in the third and one in the fourth. This yupana is the one that is closest to the picture by Poma de Ayala in Nueva Coronica, while having a line less and being half drawn.\n\nC. Florio presents a study \nwhich does not identify a yupana in these archaeological findings, but an object whose name is unknown and which has been forgotten. Instead, this object is to connect to the tocapu (an ideogram already used by pre-Incas civilizations) called “llave inca” (i.e. Inca key) and to the yanantin-masintin philosophy. The scholar reaches this conclusion starting from the lack of objective evidences which recognize a yupana in this object, a belief that consolidated over years only for the repeat of this hypothesis never demonstrated, and by crossing data from the Miccinelli Documents and the tocapu(s) catalogued by Victoria de la Jara. \nSupposing to colour the different compartments of the table-yupana (fig. A), C. Florio identifies a drawing (fig. B) very similar to a really existing tocapu (fig. C) and catalogued by Victoria de la Jara. In addition, in the tocapu reported in figure D, also catalogued by V. de la Jara, Florio identifies a stylization of the tocapu C and the departure point for creating the tocapu “llave inca” (Inca key). She finds the relation between the table-yupana and the Inca key also in their connection with the concept of duality: the table-yupana structure is clearly dual and Blas Valera in “Exul Immeritus Blas Valera populo suo” (one of the two Miccinelli Documents) describes the tocapu we call Inca key as representing the concept of the “opposite forces” and the “number 2”, both strictly linked to the concept of duality.\n\nAccording to C. Florio, the real yupana used by the Incas is that of Guáman Poma, but with more columns and rows. Guáman Poma would have represented just the part of the yupana useful for carrying out a specific calculation, which Florio identifies to be a multiplication (see below).\n\nIn 1931, Henry Wassen studied the yupana of Poma de Ayala, proposing for the first time a possible representation of the numbers on the board and the operations of addition and multiplication. He interpreted the white circles as gaps, carved into yupana in which to insert the seeds described by chroniclers: so the white circles correspond to empty gaps, while the blacks circles correspond to the same gaps filled with a black seed.\n\nThe numbering system at the base of the abacus was positional notation in base 10 (in line with the writings of the chroniclers of the Indies).\n\nThe representation of the numbers, then followed a vertical progression such that the units were positioned in the first row from the bottom, in the second the tens, hundreds in the third, and so on.\n\nWassen proposed a progression of values of the seeds that depends on their position in the table: 1, 5, 15, 30, respectively, depending on who occupy a gap in the first, second, third and fourth columns (see the table below). Only a maximum of five seeds could be included in a box belonging to the first column, so that the maximum value of said box was 5, multiplied by the power of the corresponding line. These seeds could be replaced with one seed of the next column, useful during arithmetic operations. According to the theory of Wassen, therefore, the operations of sum and product were carried out horizontally.\n\nThis theory received a lot of criticism due to the high complexity of the calculations and was therefore considered inadequate and soon abandoned.\n\nBy way of example, the following table shows the number 13457.\n\nThis first interpretation of the yupana of Poma de Ayala was the starting point for the theories developed by subsequent authors, up to the present day. In particular, no one ever moved away from the positional numbering system until 2008.\n\nEmilio Mendizabal was the first to propose in 1976 that the Inca were using, as well as the decimal representation, also a representation based on the progression 1,2,3,5. Mendizabal in the same publication pointed out that the series of numbers 1,2,3 and 5, in the drawing of Poma de Ayala, are part of the Fibonacci sequence, and stressed the importance of \"magic\" that had the number 5 for civilization the north of Peru, and the number 8 for the civilizations of the south of Peru.\n\nIn 1979, Carlos Radicati di Primeglio emphasized the difference of table-yupana from that of Poma de Ayala, describing the state of the art of the research and theories advanced so far. He also proposed the algorithms for calculating the four basic arithmetic operations for yupana of Poma de Ayala, according to a new interpretation for which it was possible to have up to nine seeds in each box with vertical progression for powers of ten. The choice of Radicati was to associate to each gap a value of 1.\n\nIn the following table is represented the number 13457\n\nIn 1981, the English textile engineer William Burns Glynn proposed a positional base 10 solution for the yupana of Poma de Ayala.\n\nGlynn, as Radicati, adopted the same Wassen's idea of full and empty gaps, as well as a vertical progression of the powers of ten, but proposed an architecture that allowed to greatly simplify the arithmetic operations.\n\nThe horizontal progression of the values of the seeds in its representation is 1, 1, 1 for the first three columns, so that in each row is possible to deposit a maximum of ten seeds (5 + 3 + 2 seeds). Ten seeds of any row is correspond to a single seed of the upper line.\n\nThe last column is dedicated to the \"memory\", which is a place where you can drop momentarily ten seeds, waiting to move them to the upper line. According to the author, this is very useful during arithmetic operations in order to reduce the possibility of error.\n\nThe solution of Glynn has been adopted in various teaching projects all over the world, and even today some of its variants are used in some schools of South America.\n\nIn the following table is represented the number 13457\n\nThe Italian engineer Nicolino de Pasquale in 2001 proposed a positional solution in base 40 of the yupana of Poma de Ayala, taking the representation theory of Fibonacci already proposed by Emilio Mendizabal and developing it for the four operations.\n\nDe Pasquale also adopts a vertical progression to represent numbers by powers of 40. The representation of the numbers is based on the fact that the sum of the values of the circles in each row gives as total 39, if each circle takes the value 5 in the first column, 3 in the second column, 2 in the third and 1 in the fourth one; it is thus possible to represent 39 numbers, united to neutral element ( zero or no seeds in the table); this forms the basis of 40 symbols necessary for the numbering system.\n\nOne of the possible representations of the number 13457 in the yupana by De Pasquale is shown in the following table:\n\nThe theory of De Pasquale opened, in the years after his birth, great controversy among researchers who divided mainly into two groups: one supporting the base 10 theory and another supporting the base 40 one. It should be noted in this regard that the Spanish chronicles of the time of the conquest of the Americas indicated that the Incas used a decimal system and that since 2003 the base 10 has been proposed as the basis for calculating both with the abacus and the quipu\n\nDe Pasquale has recently proposed the use of yupana as astronomical calendar running in mixed base 36/40 and provided its own interpretation of the Quechua word \"huno\", translating it as 0.1. This interpretation diverges from all the chroniclers of the Indies, starting from Domingo de Santo Tomas which in 1560 translated \"huno\" with \"chunga guaranga\" (ten thousand).\n\nIn 2008 Cinzia Florio proposes an alternative and revolutionary approach in respect to all the theories proposed so far. For the first time we deviate from the positional numbering system and we adopt the additive, or sign-value notation.\n\nRelying exclusively on the design of Poma de Ayala, the author explains the arrangement of white and black circles and interprets the use of the abacus as a board for making multiplications, in which the multiplicand is represented in the right column, the multiplier in the two central columns and the result (product) is shown in the left column. See the following table.\n\nThe theory differs from all the previous by several aspects: first, the white and black circles would not be any gaps that may be filled with a seed, but different colors of the seeds, representatives respectively tens and units (this according to the chronicler Juan de Velasco ).\n\nSecondly, the multiplicand is entered in the first column respecting the sign-value notation: so, the seeds can be entered in any order and the number is given by the sum of the values of these seeds.\n\nThe multiplier is represented as the sum of two factors, since the procedure for obtaining the product is based on the distributive property of multiplication over addition.\n\nThe table multiplier drawn by Poma de Ayala with that provision of the seeds, represent according to the author, the calculation: 32 x 5, where the multiplier 5 is decomposed into 3 + 2. The sequence of numbers 1,2,3,5 would be casual, contingent to the calculation done and not related to the Fibonacci series.\n\nKey: o = 10; • = 1; The operation represented is: 32 x 5 = 32 x (2 + 3) = (32 x 2) + (32 x 3) = 64 + 96 = 160\n\nThe numbers represented in the columns are, from left to right: 32 (the multiplicand), 64 = 32 x 2 and 32 x 3 = 96 (which together constitute the multiplicand, multiplied by the two factors in which the multiplier has been broken down) and finally 151. In this issue (error) are based all possible criticisms of this interpretation, since 151 is obviously not the sum of 96 and 64. Florio, however, notes that a mistake of Poma de Ayala, in designing a black circle instead of a white one, would have been possible. In this case, changing just a black circle with a white one in the last column, we obtain the number 160, which is exactly the product sought as the sum of the quantities present in the central columns.\n\nWith a yupana as the one designed by Poma de Ayala can not be represented every multiplicands, but it is necessary to extend the yupana vertically (adding rows) to represent numbers whose sum of digits exceeds 5. The same thing goes for the multipliers: to represent all the numbers is necessary to extend the number of columns. It should be emphasized that this interpretation, apart the supposed error calculation (or representation by the designer), is the only one that identifies in the yupana of Poma de Ayala a mathematical and consistent message (multiplication) and not a series of random numbers as in other interpretations.\n\n\n\n\n\n\n\n"}
{"id": "499002", "url": "https://en.wikipedia.org/wiki?curid=499002", "title": "Zenzizenzizenzic", "text": "Zenzizenzizenzic\n\nZenzizenzizenzic is an obsolete form of mathematical notation representing the eighth power of a number (that is, the zenzizenzizenzic of \"x\" is \"x\"), dating from a time when powers were written out in words rather than as superscript numbers. This term was suggested by Robert Recorde, a 16th-century Welsh writer of popular mathematics textbooks, in his 1557 work \"The Whetstone of Witte\" (although his spelling was \"zenzizenzizenzike\"); he wrote that it \"doeth represent the square of squares squaredly\".\n\nAt the time Recorde proposed this notation, there was no easy way of denoting the powers of numbers other than squares and cubes. The root word for Recorde's notation is zenzic, which is a German spelling of the medieval Italian word \"censo\", meaning \"squared\". Since the square of a square of a number is its fourth power, Recorde used the word zenzizenzic (spelled by him as \"zenzizenzike\") to express it. Some of the terms had prior use in Latin \"zenzicubicus\", \"zensizensicus\" and \"zensizenzum\". Similarly, as the sixth power of a number is equal to the square of its cube, Recorde used the word \"zenzicubike\" to express it; a more modern spelling, zenzicube, is found in Samuel Jeake's \"Logisticelogia\". Finally, the word \"zenzizenzizenzic\" denotes the square of the square of a number's square, which is its eighth power: in modern notation,\n\nRecorde proposed three mathematical terms by which any power (that is, index or exponent) greater than 1 could be expressed: \"zenzic\", i.e. squared; \"cubic\"; and \"sursolid\", i.e. raised to a prime number greater than three, the smallest of which is five. Sursolids were as follows: 5 was the first; 7, the second; 11, the third; 13, the fourth; etc.\n\nTherefore, a number raised to the power of six would be \"zenzicubic\", a number raised to the power of seven would be the second sursolid, hence \"bissursolid\" (not a multiple of two and three), a number raised to the twelfth power would be the \"zenzizenzicubic\" and a number raised to the power of ten would be \"the square of the (first) sursolid\". The fourteenth power was the square of the second sursolid, and the twenty-second was the square of the third sursolid.\n\nCuriously, Jeake's text appears to designate a written exponent of 0 as being equal to an \"absolute number, as if it had no Mark\", thus using the notation x to refer to x alone, while a written exponent of 1, in his text, denotes \"the Root of any number\", thus using the notation x to refer to what is now known to be x.\n\nThe word, as well as the system, is obsolete except as a curiosity; the Oxford English Dictionary has only one citation for it.\nAs well as being a mathematical oddity, it survives as a linguistic oddity: \"zenzizenzizenzic\" has more Zs than any other word in the OED.\n\nSamuel Jeake the Younger gives \"zenzizenzizenzizenzike\" (the square of the square of the square of the square) in a table in \"A Compleat Body of Arithmetick\":\n\n\n"}
{"id": "890891", "url": "https://en.wikipedia.org/wiki?curid=890891", "title": "Zero–one law", "text": "Zero–one law\n\nIn probability theory, a zero–one law is a result that states that an event must have probability 0 or 1 and no intermediate value. Sometimes, the statement is that the limit of certain probabilities must be 0 or 1.\n\nIt may refer to: \n"}
