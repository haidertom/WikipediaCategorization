{"id": "4412043", "url": "https://en.wikipedia.org/wiki?curid=4412043", "title": "Aniconism in Buddhism", "text": "Aniconism in Buddhism\n\nSince the beginning of the serious study of the history of Buddhist art in the 1890s, the earliest phase, lasting until the 1st century CE, has been described as aniconic; the Buddha was only represented through symbols such as an empty throne, Bodhi tree, a riderless horse with a parasol floating above an empty space (at Sanchi), Buddha's footprints, and the dharma wheel.\n\nAlthough there is still some debate, the first anthropomorphic representations of the Buddha himself are often considered a result of the Greco-Buddhist interaction, in particular in Gandhara, a theory first fully expounded by Alfred A. Foucher, but criticised from the start by Ananda Coomaraswamy. Foucher also accounted for the origins of the aniconic symbols themselves in small souvenirs carried away from the main pilgrimage sites and so becoming recognised and popularized as symbolic of the events associated with the site. Other explanations were that it was inappropriate to represent one who had attained nirvana.\n\nHowever, in 1990, the notion of aniconism in Buddhism was challenged by Susan Huntington, initiating a vigorous debate among specialists that still continues. She sees many early scenes claimed to be aniconic as in fact not depicting scenes from the life of the Buddha, but worship of cetiya (relics) or re-enactments by devotees at the places where these scenes occurred. Thus the image of the empty throne shows an actual relic-throne at Bodh Gaya or elsewhere. She points out that there is only one indirect reference for a specific aniconic doctrine in Buddhism to be found, and that pertaining to only one sect.\n\nAs for the archeological evidence, it shows some anthropomorphic sculptures of the Buddha actually existing during the supposedly aniconic period, which ended during the 1st century CE. Huntington also rejects the association of \"aniconic\" and \"iconic\" art with an emerging division between Theravada and Mahayana Buddhism. Huntington's views have been challenged by Vidya Dehejia and others. Although some earlier examples have been found in recent years, it is common ground that the large free-standing iconic images of the Buddha so prominent in later Buddhist art are not found in the earliest period; discussion is focused on smaller figures in relief panels, conventionally considered to represent scenes from the life of the Buddha, and now re-interpreted by Huntington and her supporters.\n\nIn later periods both the major schools of Buddhism have made great use of representational art, though Theravada temples and other sites typically concentrate on a single large sculpture of the Buddha, whereas Mahayana temples have larger numbers of images of a greater variety of figures with varying degrees of spiritual significance. However some schools, such as Zen Buddhism in Japan, have also shown a general tendency towards aniconism, though without specific prohibition of figurative images.\n\n\n"}
{"id": "37229379", "url": "https://en.wikipedia.org/wiki?curid=37229379", "title": "Anserated", "text": "Anserated\n\nAnserated refers to a condition where extremities of a creature end in the head of an eagle, lion etc.\n\n"}
{"id": "175914", "url": "https://en.wikipedia.org/wiki?curid=175914", "title": "Anthropology of religion", "text": "Anthropology of religion\n\nAnthropology of religion is the study of religion in relation to other social institutions, and the comparison of religious beliefs and practices across cultures.\n\nIn the early 11th century, Abū Rayhān Bīrūnī (973–1048), wrote detailed comparative studies on the anthropology of religions and cultures across the Middle East, Mediterranean and the Indian subcontinent. He discussed the peoples, customs, and religions of the Indian subcontinent.\n\nAnthropology circa 1940 assumed that religion is in complete continuity with magical thinking, and that it is a cultural product. The complete continuity between magic and religion has been a postulate of modern anthropology at least since early 1930s. The perspective of modern anthropology towards religion is the \"projection idea\", a methodological approach which assumes that every religion is created by the human community that worships it, that \"creative activity ascribed to God is projected from man.\" In 1841, Ludwig Feuerbach was the first to employ this concept as the basis for a systematic critique of religion. A prominent precursor in the formulation of this projection principle was Giambattista Vico, and an early formulation of it is found in ancient Greek writer Xenophanes, which observed that \"the gods of Ethiopians were inevitably black with flat noses while those of the Thracians were blond with blue eyes.\"\n\nIn 1912 Émile Durkheim, building on Feuerbach, considered religion \"a projection of the social values of society,\" \"a means of making symbolic statements about society,\" \"a symbolic language that makes statements about the social order\"; in short, \"religion is society worshiping itself\".\n\nIn the 19th century, cultural anthropology was dominated by an interest in cultural evolution; most anthropologists assumed that there was a simple distinction between \"primitive\" and \"modern\" religion and tried to provide accounts of how the former evolved into the latter. In the 20th century most anthropologists rejected this approach. Today the anthropology of religion reflects the influence of, or an engagement with, such theorists as Karl Marx, Sigmund Freud, Émile Durkheim, and Max Weber. They are especially concerned with how religious beliefs and practices may reflect political or economic forces; or the social functions of religious beliefs and practices.\n\nOne major problem in the anthropology of religion is the definition of religion itself. At one time anthropologists believed that certain religious practices and beliefs were more or less universal to all cultures at some point in their development, such as a belief in spirits or ghosts, the use of magic as a means of controlling the supernatural, the use of divination as a means of discovering occult knowledge, and the performance of rituals such as prayer and sacrifice as a means of influencing the outcome of various events through a supernatural agency, sometimes taking the form of shamanism or ancestor worship. According to Clifford Geertz, religion is\nToday, religious anthropologists debate, and reject, the cross-cultural validity of these categories (often viewing them as examples of European primitivism). Anthropologists have considered various criteria for defining religion – such as a belief in the supernatural or the reliance on ritual – but few claim that these criteria are universally valid.\n\nAnthony F. C. Wallace proposes four categories of religion, each subsequent category subsuming the previous. These are, however, synthetic categories and do not necessarily encompass all religions.\n\n\n"}
{"id": "13421841", "url": "https://en.wikipedia.org/wiki?curid=13421841", "title": "Architectural historian", "text": "Architectural historian\n\nAn architectural historian is a person who studies and writes about the history of architecture, and is regarded as an authority on it.\n\nAs many architectural historians are employed at universities and other facilities for post-secondary education, in addition to bachelor's degree, it is normal for colleges and universities to require the PhD degree for new full-time hires and a master's degree for part-timers.\n\nAccording to Secretary of the Interior's Guidelines the minimum professional qualifications in architectural history are a graduate degree in architectural history, art history, historic preservation, or closely related field, with coursework in American architectural history, or a bachelor's degree in architectural history, art history, historic preservation or closely related field plus one of the following:\n\n\nProfessional architectural historians typically work in colleges and universities, archival centers, government agencies, museums, and as freelance writers and consultants. In broad terms, they can be grouped into following two categories:\n\nCommon titles and job descriptions within Universities and research organizations might be as follows:\n\nMost non-academic positions in architectural history can be grouped into one of the following five categories...\n\n\nFollowing are averages of salary ranges as listed in position announcements, excluding additional benefits. The upper salary level listed in such announcements may represent qualifications exceeding the minimum requirements specified for the position.\n\nAccording to a survey conducted by the architectural history department, Savannah College of Art and Design, on professional career opportunities in architectural history, was compiled in January 2010 from positions listed January–December 2009, averages of salary ranges in United States are below.\n\nPositions requiring:\n\n"}
{"id": "1408731", "url": "https://en.wikipedia.org/wiki?curid=1408731", "title": "Art criticism", "text": "Art criticism\n\nArt criticism is the discussion or evaluation of visual art. Art critics usually criticise art in the context of aesthetics or the theory of beauty. A goal of art criticism is the pursuit of a rational basis for art appreciation but it is questionable whether such criticism can transcend prevailing socio-political circumstances.\n\nThe variety of artistic movements has resulted in a division of art criticism into different disciplines which may each use different criteria for their judgements. The most common division in the field of criticism is between historical criticism and evaluation, a form of art history, and contemporary criticism of work by living artists.\n\nDespite perceptions that art criticism is a much lower risk activity than making art, opinions of current art are always liable to drastic corrections with the passage of time. Critics of the past are often ridiculed for either favouring artists now derided (like the academic painters of the late 19th century) or dismissing artists now venerated (like the early work of the Impressionists). Some art movements themselves were named disparagingly by critics, with the name later adopted as a sort of badge of honour by the artists of the style (e.g., Impressionism, Cubism), with the original negative meaning forgotten.\n\nArtists have often had an uneasy relationship with their critics. Artists usually need positive opinions from critics for their work to be viewed and purchased; unfortunately for the artists, only later generations may understand it.\n\nArt is an important part of being human and can be found through all aspects of our lives, regardless of the culture or times. There are many different variables that determine one's judgment of art such as aesthetics, cognition or perception. Art can be objective or subjective based on personal preference toward aesthetics and form. It can be based on the elements and principle of design and by social and cultural acceptance. Art is a basic human instinct with a diverse range of form and expression. Art can stand-alone with an instantaneous judgment or can be viewed with a deeper more educated knowledge. Aesthetic, pragmatic, expressive, formalist, relativist, processional, imitation, ritual, cognition, mimetic and postmodern theories are some of many theories to criticize and appreciate art. Art criticism and appreciation can be subjective based on personal preference toward aesthetics and form, or it can be based on the elements and principle of design and by social and cultural acceptance.\n\nArt criticism has many and often numerous subjective viewpoints which are nearly as varied as there are people practising it. It is difficult to come by a more stable definition than the activity being related to the discussion and interpretation of art and its value. Depending on who is writing on the subject, \"art criticism\" itself may be obviated as a direct goal or it may include art history within its framework. Regardless of definitional problems, art criticism can refer to the history of the craft in its essays and art history itself may use critical methods implicitly. According to art historian R. Siva Kumar, \"The borders between art history and art criticism... are no more as firmly drawn as they once used to be. It perhaps began with art historians taking interest in modern art.\"\n\nArt criticism includes a descriptive aspect, where the work of art is sufficiently translated into words so as to allow a case to be made. The evaluation of a work of art that follows the description (or is interspersed with it) depends as much on the artist's output as on the experience of the critic. There is in an activity with such a marked subjective component a variety of ways in which it can be pursued. As extremes in a possible spectrum, while some favour simply remarking on the immediate impressions caused by an artistic object, others prefer a more systematic approach calling on technical knowledge, favoured aesthetic theory and the known sociocultural context the artist is immersed in to discern their intent.\n\nCritiques of art likely originated with the origins of art itself, as evidenced by texts found in the works of Plato, Vitruvius or Augustine of Hippo among others, that contain early forms of art criticism. Also, wealthy patrons have employed, at least since the start of Renaissance, intermediary art-evaluators to assist them in the procurement of commissions and/or finished pieces.\n\nArt criticism as a genre of writing, obtained its modern form in the 18th century. The earliest use of the term art criticism was by the English painter Jonathan Richardson in his 1719 publication \"An Essay on the Whole Art of Criticism\". In this work, he attempted to create an objective system for the ranking of works of art. Seven categories, including drawing, composition, invention and colouring, were given a score from 0 to 18, which were combined to give a final score. The term he introduced quickly caught on, especially as the English middle class began to be more discerning in their art acquisitions, as symbols of their flaunted social status.\n\nIn France and England in the mid 1700s, public interest in art began to become widespread, and art was regularly exhibited at the Salons in Paris and the Summer Exhibitions of London. The first writers to acquire an individual reputation as art critics in 18th-century France were Jean-Baptiste Dubos with his \"Réflexions critiques sur la poésie et sur la peinture\" (1718) which garnered the acclaim of Voltaire for the sagacity of his approach to aesthetic theory; and Étienne La Font de Saint-Yenne with \"Reflexions sur quelques causes de l'état présent de la peinture en France\" who wrote about the Salon of 1746, commenting on the socioeconomic framework of the production of the then popular Baroque art style, which led to a perception of anti-monarchist sentiments in the text.\n\nThe 18th-century French writer Denis Diderot greatly advanced the medium of art criticism. Diderot's \"The Salon of 1765\" was one of the first real attempts to capture art in words. According to art historian Thomas E. Crow, \"When Diderot took up art criticism it was on the heels of the first generation of professional writers who made it their business to offer descriptions and judgments of contemporary painting and sculpture. The demand for such commentary was a product of the similarly novel institution of regular, free, public exhibitions of the latest art\".\n\nMeanwhile, in England an exhibition of the Society of Arts in 1762 and later, in 1766, prompted a flurry of critical, though anonymous, pamphlets. Newspapers and periodicals of the period, such as the \"London Chronicle\", began to carry columns for art criticism; a form that took off with the foundation of the Royal Academy in 1768.\nIn the 1770s, the \"Morning Chronicle\" became the first newspaper to systematically review the art featured at exhibitions.\n\nFrom the 19th century onwards, art criticism became a more common vocation and even a profession, developing at times formalised methods based on particular aesthetic theories. In France, a rift emerged in the 1820s between the proponents of traditional neo-classical forms of art and the new romantic fashion. The Neoclassicists, under Étienne-Jean Delécluze defended the classical ideal and preferred carefully finished form in paintings. Romantics, such as Stendhal, criticized the old styles as overly formulaic and devoid of any feeling. Instead, they championed the new expressive, Idealistic, and emotional nuances of Romantic art. A similar, though more muted, debate also occurred in England.\n\nOne of the prominent critics in England at the time was William Hazlitt, a painter and essayist. He wrote about his deep pleasure in art and his belief that the arts could be used to improve mankind's generosity of spirit and knowledge of the world around it. He was one of a rising tide of English critics that began to grow uneasy with the increasingly abstract direction J. M. W. Turner's landscape art was moving in.\n\nOne of the great critics of the 19th century was John Ruskin. In 1843 he published \"Modern Painters\" in which he robustly defended the work of J. M. W. Turner from his critics, who charged Turner with being unfaithful to nature. Through painstaking analysis and attention to detail, Ruskin was able to demonstrate the very opposite, in what the art historian E. H. Gombrich called \"the most ambitious work of scientific art criticism ever attempted.\" Ruskin became renowned for his rich and flowing prose, and later in life he branched out to become an active and wide-ranging critic, publishing works on architecture and Renaissance art, including the \"Stones of Venice\".\nAnother dominating figure in 19th-century art criticism, was the French poet Charles Baudelaire, whose first published work was his art review \"Salon of 1845\", which attracted immediate attention for its boldness. Many of his critical opinions were novel in their time, including his championing of Eugène Delacroix. When Édouard Manet's famous \"Olympia\" (1865), a portrait of a nude courtesan, provoked a scandal for its blatant realism, Baudelaire worked privately to support his friend. He claimed that \"criticism should be partial, impassioned, political— that is to say, formed from an exclusive point of view, but also from a point of view that opens up the greatest number of horizons\". He tried to move the debate from the old binary positions of previous decades, declaring that \"the true painter, will be he who can wring from contemporary life its epic aspect and make us see and understand, with colour or in drawing, how great and poetic we are in our cravats and our polished boots\".\n\nIn 1877, John Ruskin derided \"Nocturne in Black and Gold: The Falling Rocket\" after the artist, James McNeill Whistler, showed it at Grosvenor Gallery: \"I have seen, and heard, much of Cockney impudence before now; but never expected to hear a ask two hundred guineas for flinging a pot of paint in the public's face.\" This criticism provoked Whistler into suing the critic for libel. The ensuing court case proved to be a Pyrrhic victory for Whistler.\n\nTowards the end of the 19th century a movement towards abstraction, as opposed to specific content, began to gain ground in England, notably championed by the playwright Oscar Wilde. By the early twentieth century these attitudes formally coalesced into a coherent philosophy, through the work of Bloomsbury Group members Roger Fry and Clive Bell. As an art historian in the 1890s, Fry became intrigued with the new modernist art and its shift away from traditional depiction. His 1910 exhibition of what he called post-Impressionist art attracted much criticism for its iconoclasm. He vigorously defended himself in a lecture, in which he argued that art had moved to attempt to discover the language of pure imagination, rather than the staid and, to his mind, dishonest scientific capturing of landscape. Fry's argument proved to be very influential at the time, especially among the progressive elite. Virginia Woolf remarked that: \"in or about December 1910 [the date Fry gave his lecture] human character changed.\"\n\nIndependently, and at the same time, Clive Bell argued in his 1914 book \"Art\" that all art work has its particular 'significant form', while the conventional subject matter was essentially irrelevant. This work laid the foundations for the formalist approach to art. In 1920, Fry argued that \"it’s all the same to me if I represent a Christ or a saucepan since it's the form, and not the object itself, that interests me.\" As well as being a proponent of formalism, he argued that the value of art lies in its ability to produce a distinctive aesthetic experience in the viewer. an experience he called \"aesthetic emotion\". He defined it as that experience which is aroused by significant form. He also suggested that the reason we experience aesthetic emotion in response to the significant form of a work of art was that we perceive that form as an expression of an experience the artist has. The artist's experience in turn, he suggested, was the experience of seeing ordinary objects in the world as pure form: the experience one has when one sees something not as a means to something else, but as an end in itself.\n\nHerbert Read was a champion of modern British artists such as Paul Nash, Ben Nicholson, Henry Moore and Barbara Hepworth and became associated with Nash's contemporary arts group Unit One. He focused on the modernism of Pablo Picasso and Georges Braque, and published an influential 1929 essay on the meaning of art in \"The Listener\". He also edited the trend-setting \"Burlington Magazine\" (1933–38) and helped organise the London International Surrealist Exhibition in 1936.\n\nAs in the case of Baudelaire in the 19th century, the poet-as-critic phenomenon appeared once again in the 20th, when French poet Apollinaire became the champion of Cubism. Later, French writer and hero of the Resistance André Malraux wrote extensively on art, going well beyond the limits of his native Europe. His conviction that the vanguard in Latin America lay in Mexican Muralism (Orozco, Rivera and Siqueiros) changed after his trip to Buenos Aires in 1958. After visiting the studios of several Argentine artists in the company of the young Director of the Museum of Modern Art of Buenos Aires Rafael Squirru, Malraux declared the new vanguard to lie in Argentina's new artistic movements. Squirru, a poet-critic who became Cultural Director of the OAS in Washington, D.C., during the 1960s, was the last to interview Edward Hopper before his death, contributing to a revival of interest in the American artist.\n\nIn the 1940s there were not only few galleries (The Art of This Century) but also few critics who were willing to follow the work of the New York Vanguard. There were also a few artists with a literary background, among them Robert Motherwell and Barnett Newman who functioned as critics as well.\n\nAlthough New York and the world were unfamiliar with the New York avant-garde, by the late 1940s most of the artists who have become household names today had their well established patron critics. Clement Greenberg advocated Jackson Pollock and the color field painters like Clyfford Still, Mark Rothko, Barnett Newman, Adolph Gottlieb and Hans Hofmann. Harold Rosenberg seemed to prefer the action painters such as Willem de Kooning and Franz Kline. Thomas B. Hess, the managing editor of \"ARTnews\", championed Willem de Kooning.\n\nThe new critics elevated their protégés by casting other artists as \"followers\" or ignoring those who did not serve their promotional goal. As an example, in 1958, Mark Tobey \"became the first American painter since Whistler (1895) to win top prize at the Biennale of Venice. New York's two leading art magazines were not interested. \"Arts\" mentioned the historic event only in a news column and \"Art News\" (Managing editor: Thomas B. Hess) ignored it completely. \"The New York Times\" and \"Life\" printed feature articles\".\n\nBarnett Newman, a late member of the Uptown Group wrote catalogue forewords and reviews and by the late 1940s became an exhibiting artist at Betty Parsons Gallery. His first solo show was in 1948. Soon after his first exhibition, Barnett Newman remarked in one of the Artists' Session at Studio 35: \"We are in the process of making the world, to a certain extent, in our own image\". Utilizing his writing skills, Newman fought every step of the way to reinforce his newly established image as an artist and to promote his work. An example is his letter to Sidney Janis on 9 April 1955: \n\nThe person thought to have had most to do with the promotion of this style was a New York Trotskyist, Clement Greenberg. As long time art critic for the \"Partisan Review\" and \"The Nation\", he became an early and literate proponent of Abstract Expressionism. Artist Robert Motherwell, well-heeled, joined Greenberg in promoting a style that fit the political climate and the intellectual rebelliousness of the era.\n\nClement Greenberg proclaimed Abstract Expressionism and Jackson Pollock in particular as the epitome of aesthetic value. Greenberg supported Pollock's work on formalistic grounds as simply the best painting of its day and the culmination of an art tradition going back via Cubism and Cézanne to Monet, in which painting became ever \"purer\" and more concentrated in what was \"essential\" to it, the making of marks on a flat surface.\n\nJackson Pollock's work has always polarised critics. Harold Rosenberg spoke of the transformation of painting into an existential drama in Pollock's work, in which \"what was to go on the canvas was not a picture but an event\". \"The big moment came when it was decided to paint 'just to paint'. The gesture on the canvas was a gesture of liberation from value—political, aesthetic, moral.\"\n\nOne of the most vocal critics of Abstract Expressionism at the time was \"New York Times\" art critic John Canaday. Meyer Schapiro and Leo Steinberg were also important postwar art historians who voiced support for Abstract Expressionism. During the early to mid sixties younger art critics Michael Fried, Rosalind Krauss and Robert Hughes added considerable insights into the critical dialectic that continues to grow around Abstract Expressionism.\n\nFeminist art criticism emerged in the 1970s from the wider feminist movement as the critical examination of both visual representations of women in art and art produced by women. It continues to be a major field of art criticism.\n\nArt critics today work not only in print media and in specialist art magazines as well as newspapers. Art critics appear also on the internet, TV, and radio, as well as in museums and galleries. Many are also employed in universities or as art educators for museums. Art critics curate exhibitions and are frequently employed to write exhibition catalogues. Art critics have their own organisation, a UNESCO non-governmental organisation, called the International Association of Art Critics which has around 76 national sections and a political non-aligned section for refugees and exiles.\n\nSince the early 21st century, online art critical websites and art blogs have cropped up around the world to add their voices to the art world. Many of these writers use social media resources like Facebook, Twitter, Tumblr and Google+ to introduce readers to their opinions about art criticism.\n\n\n"}
{"id": "228568", "url": "https://en.wikipedia.org/wiki?curid=228568", "title": "Art movement", "text": "Art movement\n\nAn art movement is a tendency or style in art with a specific common philosophy or goal, followed by a group of artists during a restricted period of time, (usually a few months, years or decades) or, at least, with the heyday of the movement defined within a number of years. Art movements were especially important in modern art, when each consecutive movement was considered as a new avant-garde.\n\nAccording to theories associated with modernism and the concept of postmodernism, art movements are especially important during the period of time corresponding to modern art. The period of time called \"modern art\" is posited to have changed approximately halfway through the 20th century and art made afterward is generally called contemporary art. Postmodernism in visual art begins and functions as a parallel to late modernism and refers to that period after the \"modern\" period called contemporary art. The postmodern period began during late modernism (which is a contemporary continuation of modernism), and according to some theorists postmodernism ended in the 21st century. During the period of time corresponding to \"modern art\" each consecutive movement was often considered a new avant-garde.\n\nAlso during the period of time referred to as \"modern art\" each movement was seen corresponding to a somewhat grandiose rethinking of all that came before it, concerning the visual arts. Generally there was a commonality of visual style linking the works and artists included in an art movement. Verbal expression and explanation of movements has come from the artists themselves, sometimes in the form of an art manifesto, and sometimes from art critics and others who may explain their understanding of the meaning of the new art then being produced.\n\nIn the visual arts, many artists, theorists, art critics, art collectors, art dealers and others mindful of the unbroken continuation of modernism and the continuation of modern art even into the contemporary era, ascribe to and welcome new philosophies of art as they appear. Postmodernist theorists posit that the idea of art movements are no longer as applicable, or no longer as discernible, as the notion of art movements had been before the postmodern era. There are many theorists however who doubt as to whether or not such an era was actually a fact; or just a passing fad.\n\nThe term refers to tendencies in visual art, novel ideas and architecture, and sometimes literature. In music it is more common to speak about genres and styles instead. See also cultural movement, a term with a broader connotation.\n\nAs the names of many art movements use the -ism suffix (for example cubism and futurism), they are sometimes referred to as \"isms\".\n\n\n"}
{"id": "27926471", "url": "https://en.wikipedia.org/wiki?curid=27926471", "title": "Athens Charter (preservation)", "text": "Athens Charter (preservation)\n\nThe Athens Charter for the Restoration of Historic Monuments is a seven-point manifesto adopted at the First International Congress of Architects and Technicians of Historic Monuments in Athens in 1931.\n\nThe Athens Charter for the Restoration of Historic Monuments was produced by the participants of the First International Congress \nof Architects and Technicians of Historic Monuments organized by the International Museums Office and held in Athens in 1931.\nThe seven points of the manifesto were:\n\n\n\n"}
{"id": "41005444", "url": "https://en.wikipedia.org/wiki?curid=41005444", "title": "Biblical literalist chronology", "text": "Biblical literalist chronology\n\nBiblical literalist chronology is the attempt to correlate the theological dates used in the Bible with the real chronology of actual events. The Bible measures time from the date of Creation (years are measured as anno mundi, or AM, meaning Year of the World), but there is no agreement on when this was, some of the better-known alternatives including Archbishop James Ussher, who placed it in 4004 BCE, Isaac Newton in 4000 BCE, Martin Luther in 3961 BCE, the traditional Jewish date of 3760 BCE, and the traditional Greek Orthodox date, based on the Septuagint, of 5009 BCE. To the foundation of the Temple of Solomon the passage of time is measured by simple addition of from the Creation; for later periods it measures time by the reigns of kings, but the data is conflicting and there is no agreement on how to resolve the problems. \n\nThe Jewish Bible (the Christian Old Testament) dates events either by simple arithmetic taking the creation of the world as the starting point, or, in the later books, by correlations between the reigns of kings in Israel and Judah. The data it provides falls into three periods:\nFor the biblical authors the chronology was theological in intent, functioning as prophecy and not as history. Biblical literalism, however, does not treat it this way, because literalists have a profound respect for the Bible as the word of God. This way of thinking had its origins in Christian fundamentalism, an early 20th century movement which opposed then-current non-supernatural interpretations of the life of Jesus by stressing, among other things, the verbal inspiration of scripture. The underlying concept, or fear, was that if everything in the Bible were not true, everything would collapse.\n\nThe creation of a literalist chronology of the Bible faces several hurdles, of which the following are the most significant:\n\nThe Bible measures events from the year of God's creation of the world, a type of calendar called Anno Mundi (\"Year of the World\"), shortened as AM. The task of a literal biblical chronology is to convert this to dates in the modern chronology expressed as years before or after Christ, BC and AD. There have been many attempts to do this, none of them universally accepted. The following tables (derived from Thomas L. Thompson, \"The Mythic Past\"; notes within the table as cited) divide the Bible's AM dates by the three periods into which they most naturally fall.\n\nThe following tabulation of years and dates is according to the literal letter of the text of the Bible alone. Links to multiple translations and versions are provided for verification. For comparison, known historically dated events are associated with the resultant literal dates. Dates according to the famous Ussher chronology appear in small type italics \"'\" (Latin: \"Year of the World\"), \"'\" (Latin: \"Before Christ\"). In ancient Israel a part year was designated as the previous king's last year and the new king's 1st year. The arithmetic can be checked by starting at the bottom of the table with the date of the destruction of the Temple in 587 and adding the number of years in the Scriptures (books of the \"Prophets\" and \"Chronicles\" through \"Genesis\") back up to the beginning. Dates with \"events in italics\" appearing in \"\" for historical comparison are according to Bernard Grun's \"The Timetables of History\". For the period after 587 BCE known historical dates are used as referents. Biblical source texts for stated numbers of years are referenced and linked. Reference sources are the RSVCE, The New American Bible \"The Timetables of History\" by Bernard Grun, and the \"Holman Illustrated Bible Dictionary\" (2003).\n\n\n"}
{"id": "14201791", "url": "https://en.wikipedia.org/wiki?curid=14201791", "title": "Chamber play", "text": "Chamber play\n\nA chamber play is a play of usually three acts which can be performed with a small cast and practically no sets or costumes in a small space. The form became popular in the early 20th century, with leading exponents being Max Reinhardt and August Strindberg. The first cinema adaptation was \"Kammerspielfilm\" in the 1920s, and the format was later adapted for cinema by Ingmar Bergman.\n\nThe name is derived from the term chamber music.\n\n"}
{"id": "55931", "url": "https://en.wikipedia.org/wiki?curid=55931", "title": "Chronology", "text": "Chronology\n\nChronology (from Latin \"chronologia\", from Ancient Greek , \"chrónos\", \"time\"; and , \"-logia\") is the science of arranging events in their order of occurrence in time. Consider, for example, the use of a timeline or sequence of events. It is also \"the determination of the actual temporal sequence of past events\".\n\nChronology is part of periodization. It is also part of the discipline of history, including earth history, the earth sciences, and study of the geologic time scale.\n\nChronology is the science of locating historical events in time. It relies upon chronometry, which is also known as timekeeping, and historiography, which examines the writing of history and the use of historical methods. Radiocarbon dating estimates the age of formerly living things by measuring the proportion of carbon-14 isotope in their carbon content. Dendrochronology estimates the age of trees by correlation of the various growth rings in their wood to known year-by-year reference sequences in the region to reflect year-to-year climatic variation. Dendrochronology is used in turn as a calibration reference for radiocarbon dating curves.\n\nThe familiar terms \"calendar\" and \"era\" (within the meaning of a coherent system of numbered calendar years) concern two complementary fundamental concepts of chronology. For example, during eight centuries the calendar belonging to the Christian era, which era was taken in use in the 8th century by Bede, was the Julian calendar, but after the year 1582 it was the Gregorian calendar. Dionysius Exiguus (about the year 500) was the founder of that era, which is nowadays the most widespread dating system on earth. An epoch is the date (year usually) when an era begins.\n\n\"Ab Urbe condita\" is Latin for \"from the founding of the City (Rome)\", traditionally set in 753 BC. It was used to identify the Roman year by a few Roman historians. Modern historians use it much more frequently than the Romans themselves did; the dominant method of identifying Roman years was to name the two consuls who held office that year. Before the advent of the modern critical edition of historical Roman works, AUC was indiscriminately added to them by earlier editors, making it appear more widely used than it actually was.\n\nIt was used systematically for the first time only about the year 400, by the Iberian historian Orosius. Pope Boniface IV, in about the year 600, seems to have been the first who made a connection between these this era and Anno Domini. (AD 1 = AUC 754.)\n\nDionysius Exiguus’ Anno Domini era (which contains only calendar years \"AD\") was extended by Bede to the complete Christian era (which contains, in addition all calendar years \"BC\", but no \"year zero\"). Ten centuries after Bede, the French astronomers Philippe de la Hire (in the year 1702) and Jacques Cassini (in the year 1740), purely to simplify certain calculations, put the Julian Dating System (proposed in the year 1583 by Joseph Scaliger) and with it an astronomical era into use, which contains a leap year zero, which precedes the year 1 (AD).\n\nWhile of critical importance to the historian, methods of determining chronology are used in most disciplines of science, especially astronomy, geology, paleontology and archaeology.\n\nIn the absence of written history, with its chronicles and , late 19th century archaeologists found that they could develop relative chronologies based on pottery techniques and styles. In the field of Egyptology, William Flinders Petrie pioneered sequence dating to penetrate pre-dynastic Neolithic times, using groups of contemporary artefacts deposited together at a single time in graves and working backwards methodically from the earliest historical phases of Egypt. This method of dating is known as seriation.\n\nKnown wares discovered at strata in sometimes quite distant sites, the product of trade, helped extend the network of chronologies. Some cultures have retained the name applied to them in reference to characteristic forms, for lack of an idea of what they called themselves: \"The Beaker People\" in northern Europe during the 3rd millennium BCE, for example. The study of the means of placing pottery and other cultural artifacts into some kind of order proceeds in two phases, classification and typology: Classification creates categories for the purposes of description, and typology seeks to identify and analyse changes that allow artifacts to be placed into sequences.\n\nLaboratory techniques developed particularly after mid-20th century helped constantly revise and refine the chronologies developed for specific cultural areas. Unrelated dating methods help reinforce a chronology, an axiom of corroborative evidence. Ideally, archaeological materials used for dating a site should complement each other and provide a means of cross-checking. Conclusions drawn from just one unsupported technique are usually regarded as unreliable.\n\nThe fundamental problem of chronology is to synchronize events. By synchronizing an event it becomes possible to relate it to the current time and to compare the event to other events. Among historians, a typical need to is to synchronize the reigns of kings and leaders in order to relate the history of one country or region to that of another. For example, the Chronicon of Eusebius (325 A.D.) is one of the major works of historical synchronism. This work has two sections. The first contains narrative chronicles of nine different kingdoms: Chaldean, Assyrian, Median, Lydian, Persian, Hebrew, Greek, Peloponnesian, Asian, and Roman. The second part is a long table synchronizing the events from each of the nine kingdoms in parallel columns. The adjacent image shows two pages from the second section.\n\nBy comparing the parallel columns, the reader can determine which events were contemporaneous, or how many years separated two different events. To place all the events on the same time scale, Eusebius used an Anno Mundi (A.M.) era, meaning that events were dated from the supposed beginning of the world as computed from the Book of Genesis in the Hebrew Pentateuch. According to the computation Eusebius used, this occurred in 5199 B.C. The Chronicon of Eusebius was widely used in the medieval world to establish the dates and times of historical events. Subsequent chronographers, such as George Syncellus (died circa 811), analyzed and elaborated on the Chronicon by comparing with other chronologies. The last great chronographer was Joseph Justus Scaliger (1540-1609) who reconstructed the lost Chronicon and synchronized all of ancient history in his two major works, \"De emendatione temporum\" (1583) and \"Thesaurus temporum\" (1606). Much of modern historical datings and chronology of the ancient world ultimately derives from these two works. Scaliger invented the concept of the Julian Day which is still used as the standard unified scale of time for both historians and astronomers.\n\nIn addition to the literary methods of synchronism used by traditional chronographers such as Eusebius, Syncellus and Scaliger, it is possible to synchronize events by archaeological or astronomical means. For example, the Eclipse of Thales, described in the first book of Herodotus can potentially be used to date the Lydian War because the eclipse took place during the middle of an important battle in that war. Likewise, various eclipses and other astronomical events described in ancient records can be used to astronomically synchronize historical events. Another method to synchronize events is the use of archaeological findings, such as pottery, to do sequence dating.\n\n\n\nAspects and examples of non-chronological story-telling:\n\n\n\n\n"}
{"id": "903846", "url": "https://en.wikipedia.org/wiki?curid=903846", "title": "Chronology of Jesus", "text": "Chronology of Jesus\n\nA chronology of Jesus aims to establish a timeline for the events of the life of Jesus. Scholars have correlated Jewish and Greco-Roman documents and astronomical calendars with the New Testament accounts to estimate dates for the major events in Jesus's life. \n\nTwo main approaches have been used to estimate the year of the birth of Jesus: one based on the accounts in the Gospels of his birth with reference to King Herod's reign, and the other by subtracting his stated age of \"about 30 years\" when he began preaching. Most scholars, on this basis, assume a date of birth between 6 and 4 BC.\n\nThree details have been used to estimate the year when Jesus began preaching: a mention of his age of \"about 30 years\" during \"the fifteenth year\" of the reign of Tiberius Caesar, another relating to the date of the building of the Temple in Jerusalem, and yet another concerning the death of John the Baptist. Hence, scholars estimate that Jesus began preaching and gathering followers around AD 28–29. According to the three synoptic gospels Jesus continued preaching for at least one year, and according to John the Evangelist for three years.\n\nFive methods have been used to estimate the date of the crucifixion of Jesus. One uses non-Christian sources such as Josephus and Tacitus. Another works backwards from the historically well-established trial of the Apostle Paul by the Roman proconsul Gallio in Corinth in AD 51/52 to estimate the date of Paul's conversion. Both methods result in AD 36 as an upper bound to the crucifixion. Thus, scholars generally agree that Jesus was crucified between AD 30 and AD 36. Isaac Newton's astronomical method calculates those ancient Passovers (always defined by a full moon) which are preceded by a Friday, as specified by all four Gospels; this leaves two potential crucifixion dates, 7 April AD 30 and 3 April AD 33. In the lunar eclipse method, the Apostle Peter's statement that the moon turned to blood at the crucifixion () is taken to refer to the lunar eclipse of 3 April AD 33; although astronomers are discussing whether the eclipse was visible as far west as Jerusalem. Recent astronomical research uses the contrast between the synoptic date of Jesus' last Passover on the one hand with John's date of the subsequent \"Jewish Passover\" on the other hand, to propose Jesus' Last Supper to have been on Wednesday, 1 April AD 33 and the crucifixion on Friday 3 April AD 33.\n\nThe Christian gospels do not claim to provide an exhaustive list of the events in the life of Jesus They were written as theological documents in the context of early Christianity rather than historical chronicles, and their authors showed little interest in an absolute chronology of Jesus or in synchronizing the episodes of his life with the secular history of the age. One indication that the gospels are theological documents rather than historical chronicles is that they devote about one-third of their text to just seven days, namely the last week of the life of Jesus in Jerusalem, also known as the Passion of Christ.\n\nNevertheless, the gospels provide some details regarding events which can be clearly dated, so one can establish date ranges regarding major events in Jesus' life by comparison with independent sources. A number of historical non-Christian documents, such as Jewish and Greco-Roman sources, have been used in historical analyses of the chronology of Jesus. Virtually all modern historians agree that Jesus existed, and regard his baptism and his crucifixion as historical events, and assume that approximate ranges for these events can be estimated.\n\nUsing these methods, most scholars assume a date of birth between 6 and 4 BC, and that Jesus' preaching began around AD 27–29 and lasted one to three years. They calculate the death of Jesus as having taken place between AD 30 and 36.\n\nThe date of birth of Jesus of Nazareth is not stated in the gospels or in any secular text, but most scholars assume a date of birth between 6 BC and 4 BC, but nobody knows the exact date. Two main methods have been used to estimate the year of the birth of Jesus: one based on the accounts of his birth in the gospels with reference to King Herod's reign, and another based on subtracting his stated age of \"about 30 years\" from the time when he began preaching () in \"the fifteenth year of the reign of Tiberius Caesar\" (): the two methods indicate a date of birth before Herod's death in 4 BC, and a date of birth around 2 BC, respectively.\n\nThe two nativity accounts of Jesus in the Gospel of Matthew and Gospel of Luke differ substantially from each other, and are considered to have been written independently. However, some consistent elements are evidently derived from a common early tradition:\n\nThus both Luke and Matthew independently associate Jesus' birth with the reign of Herod the Great. Matthew furthermore implies that Jesus was up to two years old when Herod reportedly ordered the Massacre of the Innocents, that is, the murder of all boys in Bethlehem up to the age of two (Matt 2:16). Most scholars agree that Herod died in 4 BC, although some have argued for 1 BC. In conclusion, most scholars accept a birth year for Jesus between 6 and 4 BC.\n\nAnother approach to estimating Jesus' year of birth is based on the statement in that he was \"about 30 years of age\" when starting his ministry. Jesus began to preach after being baptised by John the Baptist, and based on Luke’s gospel John only began baptising people in \"the fifteenth year of the reign of Tiberius Caesar\" (), which scholars estimate to have been in AD 28–29. Subtracting 30 years, it appears that Jesus was born in 1-2 BC. However, if the phrase \"about 30\" is interpreted to mean 32 years old, this could fit a date of birth just within the reign of Herod, who died in 4 BC.\n\nThis date is independently confirmed by John's reference in to the Temple being in its 46th year of construction during Passover when Jesus began his ministry, which corresponds to around 28–29 AD according to scholarly estimates.\n\nThe Gospel of John 8:57 mentions in passing an upper limit of 50 for Jesus' age when preaching: \"Then the Jews said to Him: You are not even fifty years old, and you claim to have seen Abraham?\" Fifty years is a round number which emphasises the discrepancy to Jesus's claim he had existed before Abraham, that is, for more than a thousand years.\n\nSome commentators have attempted to establish the date of birth by identifying the Star of Bethlehem with some known astronomical or astrological phenomenon. For example, astronomer Michael Molnar proposed 17 April 6 BC as the likely date of the Nativity, since that date corresponded to the heliacal rising and lunar occultation of Jupiter, while it was momentarily stationary in the constellation of Aries. According to Molnar, to knowledgeable astrologers of this time, this highly unusual combination of events would have indicated that a regal personage would be (or had been) born in Judea. Other research points to a 1991 report from the Royal Astronomical Society, which mentions that Chinese astronomers noted a \"comet\" that lasted 70 days in the Capricorn region of the sky, in March of 5 BC. Authors Dugard and O'Reilly consider this event as the likely Star of Bethlehem. However, there are many possible phenomena and none seems to match the Gospel account exactly.\n\nOne method for the estimation of the date of the beginning of the ministry of Jesus is based on the Gospel of Luke's specific statement in about the ministry of John the Baptist which preceded that of Jesus:\nNow in the fifteenth year of the reign of Tiberius Caesar, Pontius Pilate being governor of Judaea, and Herod being tetrarch of Galilee, and his brother Philip tetrarch of the region of Ituraea and Trachonitis, and Lysanias tetrarch of Abilene, in the highpriesthood of Annas and Caiaphas, the word of God came unto John the son of Zacharias in the wilderness.\nThe reign of Tiberius Caesar began on the death of his predecessor Augustus Caesar in September AD 14, implying that the ministry of John the Baptist began in late AD 28 or early AD 29. Riesner's alternative suggestion is that John the Baptist began his ministry in AD 26 or 27, because Tiberius ruled together with Augustus for two years before becoming the sole ruler. If so, the fifteenth year of Tiberius' reign would be counted from AD 12. Riesner's suggestion is however considered less likely, as all the major Roman historians who calculate the years of Tiberius' rule - namely Tacitus, Suetonius and Cassius Dio - count from AD 14 - the year of Augustus' death. In addition, coin evidence shows that Tiberius started to reign in AD 14.\n\nThe New Testament presents John the Baptist as the precursor to Jesus and the Baptism of Jesus as marking the beginning of Jesus' ministry. In his sermon in , delivered in the house of Cornelius the centurion, Apostle Peter refers to what had happened \"throughout all Judaea, beginning from Galilee, after the baptism which John preached\" and that Jesus had then gone about \"doing good\". Jesus' baptism account is followed directly by his 40 day fast and ordeal.\n\nAnother method for estimating the start of the ministry of Jesus without reliance on the Synoptic gospels is to relate the account in the Gospel of John about the visit of Jesus to Herod's Temple in Jerusalem with historical data about the construction of the Temple.\n\nHerod's Temple in Jerusalem was an extensive and long term construction on the Temple Mount, which was never fully completed even by the time it was destroyed by the Romans in AD 70. Having built entire cities such as Caesarea Maritima, Herod saw the construction of the Temple as a key, colossal monument. The dedication of the initial temple (sometimes called the inner Temple) followed a 17 or 18 month construction period, just after the visit of Augustus to Syria.\n\nJosephus () states that the temple's reconstruction was started by Herod in the 18th year of his reign. But there is some uncertainty about how Josephus referred to and computed dates, which event marked the start of Herod's reign, and whether the initial date should refer to the inner Temple, or the subsequent construction. Hence various scholars arrive at slightly different dates for the exact date of the start of the Temple construction, varying by a few years in their final estimation of the date of the Temple visit. Given that it took 46 years of construction, the best scholarly estimate for when Jesus preached is around the year AD 29.\n\nBoth the gospels and first-century historian Flavius Josephus, in his work Antiquities of the Jews, refer to Herod Antipas killing John the Baptist, and to the marriage of Herod and Herodias, establishing two key connections between Josephus and the biblical episodes. Josephus refers to the imprisonment and execution of John the Baptist by Herod Antipas and that Herodias left her husband to marry Herod Antipas, in defiance of Jewish law.\n\nJosephus and the gospels differ, however, on the details and motives, e.g. whether the execution was a consequence of the marriage of Herod Antipas and Herodias (as indicated in , ), or a pre-emptive measure by Herod which possibly took place before the marriage to quell a possible uprising based on the remarks of John, as Josephus suggests in .\n\nThe exact year of the marriage of Herod Antipas and Herodias is subject to debate among scholars. While some scholars place the year of the marriage in the range AD 27-31, others have approximated a date as late as AD 35, although such a late date has much less support. In his analysis of Herod's life, Harold Hoehner estimates that John the Baptist's imprisonment probably occurred around AD 30-31. The International Standard Bible Encyclopedia estimates the death of the Baptist to have occurred about AD 31-32.\n\nJosephus stated () that the AD 36 defeat of Herod Antipas in the conflicts with Aretas IV of Nabatea was widely considered by the Jews of the time as misfortune brought about by Herod's unjust execution of John the Baptist. Given that John the Baptist was executed before the defeat of Herod by Aretas, and based on the scholarly estimates for the approximate date of the marriage of Herod Antipas and Herodias, the last part of the ministry of John the Baptist and hence parts of the ministry of Jesus fall within the historical time span of AD 28-35, with the later year 35 having the least support among scholars.\n\nAll four canonical gospels state that Jesus was crucified during the prefecture of Pontius Pilate, the Roman governor of Roman Judaea.\n\nIn the \"Antiquities of the Jews\" (written about AD 93), Josephus states () that Jesus was crucified on the orders of Pilate. Most scholars agree that while this reference includes some later Christian interpolations, it originally included a reference to the execution of Jesus under Pilate.\n\nIn the second century the Roman historian Tacitus in \"The Annals\" (\"c.\" AD 116), described the persecution of Christians by Nero and stated () that Jesus had been executed on the orders of Pilate during the reign of Tiberius (Emperor from 18 September AD 14 – 16 March AD 37).\n\nAccording to Flavius Josephus, Pontius Pilate was governor of Judea from AD 26 until he was replaced by Marcellus, either in AD 36 or AD 37, establishing the date of the death of Jesus between AD 26 and AD 37.\n\nIn the Gospel of Luke, while Jesus is in Pilate's court, Pilate realizes that Jesus is a Galilean and thus is under the jurisdiction of Herod Antipas. Given that Herod was in Jerusalem at that time, Pilate decided to send Jesus to Herod to be tried.\n\nThis episode is described only in the Gospel of Luke (). While some scholars have questioned the authenticity of this episode, given that it is unique to the Gospel of Luke, the International Standard Bible Encyclopedia states that it fits well with the theme of the gospel.\n\nHerod Antipas, a son of Herod the Great, was born before 20 BC and was exiled in the summer of AD 39 following a lengthy intrigue involving Caligula and Agrippa I, the grandson of his father. This episode indicates that Jesus' death took place before AD 39.\n\nAnother approach to estimating an upper bound for the year of death of Jesus is the estimation of the date of conversion of Paul the Apostle which the New Testament accounts place some time after the death of Jesus. Paul's conversion is discussed in both the Letters of Paul and in the Acts of the Apostles.\n\nIn the First Epistle to the Corinthians (), Paul refers to his conversion. The Acts of the Apostles includes three separate references to his conversion experience, in , and .\n\nEstimating the year of Paul's conversion relies on working backwards from his trial before Junius Gallio in Achaea Greece () around AD 51–52, a date derived from the discovery and publication, in 1905, of four stone fragments as part of the Delphi Inscriptions, at Delphi across the Gulf from Corinth. The inscription preserves a letter from Claudius concerning Gallio dated during the 26th acclamation of Claudius, sometime between January 51 and August 52.\n\nOn this basis, most historians estimate that Gallio (brother of Seneca the Younger) became proconsul between the spring of AD 51 and the summer of AD 52, and that his position ended no later than AD 53. The trial of Paul is generally assumed to be in the earlier part of Gallio's tenure, based on the reference () to his meeting in Corinth with Priscilla and Aquila, who had been recently expelled from Rome based on Emperor Claudius' expulsion of Jews from Rome, which is dated to AD 49–50.\n\nAccording to the New Testament, Paul spent eighteen months in Corinth, approximately seventeen years after his conversion. states that Paul went back to Jerusalem fourteen years after his conversion, and various missions (at times with Barnabas) such as those in and appear in the Book of Acts. The generally accepted scholarly estimate for the date of conversion of Paul is AD 33–36, placing the death of Jesus before this date range.\n\nAll four Gospels agree to within about a day that the crucifixion was at the time of Passover, and all four Gospels agree that Jesus died a few hours before the commencement of the Jewish Sabbath, i.e. he died before nightfall on a Friday (Matt 27:62, 28:1, Mark 15:42, Luke 23:54, John 19:31,42). In the official festival calendar of Judaea, as used by the priests of the temple, Passover time was specified precisely. The slaughtering of the lambs for Passover occurred between 3pm and 5pm on the 14th day of the Jewish month Nisan (corresponding to March/April in our calendar). The Passover meal commenced at moonrise (necessarily a full moon) that evening, i.e., at the start of 15 Nisan (the Jewish day running from evening to evening) (Leviticus 23 v. 5; Numbers 28 v. 16). There is an apparent discrepancy of one day in the Gospel accounts of the crucifixion which has been the subject of considerable debate. In John's Gospel, it is stated that the day of Jesus' trial and execution was the day before Passover (John 18 v. 28 and 19 v. 14), Hence John places the crucifixion on 14 Nisan. Likewise the Apostle Paul, in his First Epistle to the Corinthians, implies Jesus died on a 14 Nisan (\"sacrificed as a Passover lamb\", 1 Cor 5:7), and was resurrected on the Jewish festival of the first fruits, i.e. on a 16 Nisan (1 Cor 15:20). The correct interpretation of the Synoptics is less clear. Thus some scholars believe that all 4 Gospels place the crucifixion on Friday, 14 Nisan, others believe that according to the Synoptics it occurred on Friday, 15 Nisan. The problem that then has to be solved is that of determining in which of the years of the reign of Pontius Pilate (AD 26–36) the 14th and 15th Nisan fell on a Friday.\n\nIn 1733, Isaac Newton considered only the range AD 31–36 and calculated that the Friday requirement is met only on Friday 3 April AD 33, and 23 April AD 34. The latter date can only have fallen on a Friday if an exceptional leap month had been introduced that year, but this was favoured by Newton. In the twentieth century, the standard view became that of J. K. Fotheringham, who in 1910 suggested 3 April AD 33 on the basis of its coincidence with a lunar eclipse. In the 1990s Bradley E. Schaefer and J. P. Pratt, following a similar method, arrived at the same date. Also according to Humphreys and Waddington, the lunar Jewish calendar leaves only two plausible dates within the reign of Pontius Pilate for Jesus' death, and both of these would have been a 14 Nisan as specified in the Gospel of John: Friday 7 April AD 30, and Friday 3 April AD 33.\n\nA more refined calculation takes into account that the Jewish calendar was based not on astronomical calculation but on observation, following criticism that it is possible to establish the phase of the moon on a particular day two thousand years ago but not whether it was obscured by clouds or haze. Including the possibility of a cloudy sky obscuring the moon, and assuming that the Jewish authorities would be aware that lunar months can only be either 29 or 30 days long (the time from one new moon to the next is 29.53 days), then the refined calculation states that the Friday requirement might also have been met, during Pontius Pilate's term of office, on 11 April AD 27. Another potential date arises if the Jewish authorities happened to add an irregular lunar leap month to compensate for a meteorologically delayed harvest season: this would yield one additional possibility during Pilate's time, which is Newton's favoured date of 23 April AD 34. Colin Humphreys calculates but rejects these AD 27 and AD 34 dates on the basis that the former is much too early to be compatible with Luke 3:1–2, and spring AD 34 is probably too late to be compatible with Paul's timeline, confirming Friday 7 April AD 30, and Friday 3 April AD 33 as the two feasible crucifixion dates.\n\nA lunar eclipse is potentially alluded to in (\"The sun shall be turned into darkness, And the moon into blood, Before the day of the Lord come\"), as pointed out by physicist Colin Humphreys and astronomer Graeme Waddington. There was in fact a lunar eclipse on 3 April AD 33, a date which coincides with one of Newton's astronomically possible crucifixion dates (see above). Humphreys and Waddington have calculated that in ancient Jerusalem this eclipse would have been visible at moonrise at 6.20pm as a 20% partial eclipse (a full moon with a potentially red \"bite\" missing at the top left of the moon's disc). They propose that a large proportion of the Jewish population would have witnessed this eclipse as they would have been waiting for sunset in the west and immediately afterwards the rise of the anticipated full moon in the east as the prescribed signal to start their household Passover meals. Humphreys and Waddington therefore suggest a scenario where Jesus was crucified and died at 3pm on 3 April AD 33, followed by a red partial lunar eclipse at moonrise at 6.20pm observed by the Jewish population, and that Peter recalls this event when preaching the resurrection to the Jews (). Astronomer Bradley Schaefer agrees with the eclipse date but disputes that the eclipsed moon would have been visible by the time the moon had risen in Jerusalem.\n\nA potentially related issue involves the reference in the Synoptic Gospels to a three-hour period of darkness over the whole land on the day of the crucifixion (according to Luke 23:45 τοῦ ἡλίου ἐκλιπόντος – the sun was darkened). Although some scholars view this as a literary device common among ancient writers rather than a description of an actual event, other writers have attempted to identify a meteorological event or a datable astronomical phenomenon which this could have referred to. It could not have been a solar eclipse, since this could not take place during the crucifixion at Passover, and in any case solar eclipses take minutes, not hours. In 1983, astronomers Humphreys and Waddington noted that the reference to a solar eclipse is missing in some versions of Luke and argued that the solar eclipse was a later faulty scribal amendment of what was actually the \"lunar\" eclipse of AD 33. This is a claim which historian David Henige describes as 'undefended' and 'indefensible'. Humphreys and a number of scholars have alternatively argued for the sun's darkening to have been caused by a \"khamsin\", i.e. a sand storm, which can occur between mid-March and May in the Middle East and which does typically last for several hours.\n\nIn a review of Humphreys' book, theologian William R Telford points out that the non-astronomical parts of his lunar eclipse argument are based on the assumption that the chronologies described in the New Testament are historical and based on eyewitness testimony, accepting uncritically statements such as the \"three different Passovers in John\" and Matthew's statement that Jesus died at the ninth hour. He also alleges that Humphreys uses two very dubious sources, namely Pilate's alleged letter to Tiberius and the writings of the fifth-century Bishop Cyril of Alexandria, which Humphreys however classifies as forgery or contemporary interpretation indicative of a tradition at the time.\n\nIn the crucifixion narrative, the synoptic gospels stress that Jesus celebrated a Passover meal (Mark 14:12ff, Luke 22:15) \"before\" his crucifixion, which contrasts sharply with the independent gospel of John who is explicit that the official \"Jewish\" Passover (John 11:55) started at nightfall \"after\" Jesus' death. In his 2011 book, Colin Humphreys proposes a resolution to this apparent discrepancy by positing that Jesus' \"synoptic\" Passover meal in fact took place two days before John's \"Jewish\" Passover because the former is calculated by the putative original Jewish lunar calendar (itself based on the Egyptian liturgical lunar calendar putatively introduced to the Israelites by Moses in the 13th century BC, and still used today by the Samaritans). The official \"Jewish\" Passover in contrast was determined by a Jewish calendar reckoning which had been modified during the Babylonian exile in the 6th century BC. This modified Jewish calendar is in use among most Jews today. One basic difference lies in the determination of the first day of the new month: while the Samaritans use the calculated (because by definition invisible) new moon, mainstream Jews use the first observation of the thin crescent of the waxing moon which is on average 30 hours later. The other basic difference lies in the fact that the Samaritan calendar uses a sunrise-to-sunrise day, while the official Jewish calendar uses a sunset-to-sunset day. Due to these differences, the Samaritan Passover is normally one day earlier than the Jewish Passover (and in some years two or more days earlier). The crucifixion year of Jesus can then be calculated by asking the question in which of the two astronomically possible years of AD 30 and AD 33 is there a time gap between the last supper and the crucifixion which is compatible with the gospel timeline of Jesus' last 6 days. The astronomical calculations show that a hypothetical AD 30 date would require an incompatible Monday Last Supper, while AD 33 offers a compatible Last Supper on Wednesday, 1 April AD 33, followed by a compatible crucifixion on Friday, 3 April AD 33.\n\nGiven these assumptions he argues that the calculated date of Wednesday 1 April AD 33 for the Last Supper allows all four gospel accounts to be astronomically correct, with Jesus celebrating Passover two days before his death according to the original Mosaic calendar, and the Jewish authorities celebrating Passover just after the crucifixion, using the modified Babylonian calendar. In contrast, the Christian church tradition of celebrating the Last Supper on Maundy Thursday would be an anachronism. The calculated chronology incidentally supports John's narrative that Jesus died at the same hour (Friday 3pm) on 3 April AD 33 that the Passover lambs were slaughtered.\n\nIn a review of Humphreys' book, theologian William R Telford counters that the separate day schema of the Gospel's Holy Week \"is an artificial as well as an inconsistent construction\". As Telford had pointed out in his own book in 1980, \"the initial three-day structure found in [Mark 11] is occasioned by the purely redactional linkage of the extraneous fig-tree story with the triumphal entry and cleansing of the temple traditions, and is not a chronology upon which one can base any historical reconstructions.\"\n\nThe estimation of the hour of the death of Jesus based on the New Testament accounts has been the subject of debate among scholars for centuries, since there was perceived to be a clear difference between the accounts in the Synoptic Gospels and that in the Gospel of John. Also, some scholars have argued that it is unlikely that the many events of the Passion could have taken place in the span from midnight to about 9 o'clock in the morning. The consensus of modern scholarship agrees with the four Gospels that the New Testament accounts represent a crucifixion occurring on a Friday, although a Wednesday crucifixion has also been proposed.\n\nThe debate can be summarised as follows. In the Synoptic account, the Last Supper takes place on the first night of Passover, defined in the Torah as occurring after daylight on 14 of Nisan, and the crucifixion is on 15 Nisan. However, in the Gospel of John the trial of Jesus takes place before the Passover meal and the sentencing takes place on the day of Preparation, before Passover. John's account places the crucifixion on 14 Nisan, since the law mandated the lamb had to be sacrificed between 3:00 pm and 5:00 pm and eaten before midnight on that day. This understanding fits well with Old Testament typology, in which Jesus entered Jerusalem to identify himself as the Paschal lamb on Nisan 10 was crucified and died at 3:00 in the afternoon of Nisan 14, at the same time the High Priest would have sacrificed the Paschal lamb, and rose before dawn the morning of Nisan 16, as a type of offering of the First Fruits. It is problematic to reconcile the chronology presented by John with the Synoptic tradition that the Last Supper was a Passover meal. Some scholars have presented arguments to reconcile the accounts, although Raymond E. Brown, reviewing these, concluded that they can not be easily reconciled. One involves the suggestion that for Jesus and his disciples, the Passover could have begun at dawn Thursday, while for traditional Jews it would not have begun until dusk that same day. Another is that John followed the Roman practice of calculating the new day beginning at midnight, rather than the Jewish reckoning. However, this Roman practice was used only for dating contracts and leases. D. A. Carson argues that 'preparation of the Passover' could mean any day of the Passover week. Some have argued that the modern precision of marking the time of day should not be read back into the gospel accounts, written at a time when no standardization of timepieces, or exact recording of hours and minutes was available. Andreas Köstenberger argues that in the first century time was often estimated to the closest three-hour mark, and that the intention of the author of the Mark Gospel was to provide the setting for the three hours of darkness while the Gospel of John seeks to stress the length of the proceedings, starting in the 'early morning'\" William Barclay has argued that the portrayal of the death of Jesus in the John Gospel is a literary construct, presenting the crucifixion as taking place at the time on the day of Passover when the sacrificial lamb would be killed, and thus portraying Jesus as the Lamb of God.\n\nColin Humphreys' widely publicised \"double passover\" astronomical analysis, published in 2011 and outlined above, places the hour of death of Jesus at 3pm on 3 April AD 33 and claims to reconcile the Gospel accounts for the \"six days\" leading up to the crucifixion. His solution is that the synoptic gospels and John's gospel use two distinct calendars (the official Jewish lunar calendar, and what is today the Samaritan lunar calendar, the latter used in Jesus' day also by the Essenes of Qumran and the Zealots). Humphrey's proposal was preceded in 1957 by the work of Annie Jaubert who suggested that Jesus held his Last Supper at Passover time according to the Qumran \"solar\" calendar. Humphreys rejects Jaubert's conclusion by demonstrating that the Qumran solar reckoning would always place Jesus' Last Supper \"after\" the Jewish Passover, in contradiction to all four gospels. Instead, Humphreys points out that the Essene community at Qumran additionally used a lunar calendar, itself evidently based on the Egyptian liturgical lunar calendar. Humphreys suggests that the reason why his two-calendar solution had not been discovered earlier is (a) widespread scholarly ignorance of the existence of the Egyptian liturgical lunar calendar (used alongside the well-known Egyptian administrative solar calendar, and presumably the basis for the 13th-century BC Jewish lunar calendar), and (b) the fact that the modern surviving small community of Samaritans did not reveal the calculations underlying their lunar calendar (preserving the Egyptian reckoning) to outsiders until the 1960s.\n\nIn a review of Humphreys' book, theologian William R Telford points out that the non-astronomical parts of his argument are based on the assumption that the chronologies described in the New Testament are historical and based on eyewitness testimony. In doing so, Telford says, Humphreys has built an argument upon unsound premises which \"does violence to the nature of the biblical texts, whose mixture of fact and fiction, tradition and redaction, history and myth all make the rigid application of the scientific tool of astronomy to their putative data a misconstrued enterprise.\"\n\nOther estimates of the chronology of Jesus have been proposed over the centuries, e.g. Maximus the Confessor, Eusebius, and Cassiodorus asserted that the death of Jesus occurred in AD 31. The 3rd/4th century Roman historian Lactantius states that Jesus was crucified on a particular day in AD 29, but that did not correspond to a full moon.\n\n\n"}
{"id": "47733606", "url": "https://en.wikipedia.org/wiki?curid=47733606", "title": "Collections management system", "text": "Collections management system\n\nA Collections Management System (CMS), sometimes called a Collections Information System, is software used by the collections staff of a collecting institution or by individual private collectors and collecting hobbyists or enthusiasts. Collecting institutions are primarily museums and archives and cover a very broad range from huge, international institutions, to very small or niche-specialty institutions such as local historical museums and preservation societies. Secondarily, libraries and galleries are also collecting institutions. Collections Management Systems (CMSs) allow individuals or collecting institutions to organize, control, and manage their collections' objects by “tracking all information related to and about” those objects. In larger institutions, the CMS may be used by collections staff such as registrars, collections managers, and curators to record information such as object locations, provenance, curatorial information, conservation reports, professional appraisals, and exhibition histories. All of this recorded information is then also accessed and used by other institutional departments such as “education, membership, accounting, and administration.\" \n\nThough early Collections Management Systems were cataloging databases, essentially digital versions of card catalogs, more recent and advanced systems are being used to improve communication between museum staff and to automate and manage collections-based tasks and workflows. Collections Management Systems are also used to provide access to information about an institution's collections and objects to academic researchers, institutional volunteers, and the public, increasingly through online methods.\n\nAmong the many commercially-produced Collections Management Systems are Archivists' Toolkit, Argus, Axiell's Collections Management Software, Gallery Systems’ The Museum System (TMS) and EmbARK products, PastPerfect Museum Software, and Re:discovery Software's Proficio. Some institutions, particularly smaller museums, have customized existing database management systems and relational database software such as FileMaker Pro and Microsoft Access to create homegrown Collections Management Systems. A recent trend has been the growing number of innovative web browser-based, cloud-based, and mobile-enabled systems and applications, such as CatalogIt. CollectionSpace— developed by multiple institutions led by the Museum of the Moving Image in New York — and CollectiveAccess— developed by Whirl-i-Gig— are free, open-source, and web-based systems. Commercial web-based systems include Axiell Collections, CatalogIt, Vernon Systems’ eHive, and zetcom’s MuseumPlus. Cloud-based systems include CatalogIt, CollectorSystems, Eloquent Museum, SKINsoft's S-museum and UniqueCollection.org. Mobile enabled systems, which allow secure access to all of the Collections Management System's capabilities via smartphone and tablet, in addition to desk/laptop computers, include CatalogIt. \n\nEver since machine-readable standards were developed for libraries in the 1960s, museums have had an interest in utilizing computers to record information about their collections. However, museums have very different needs from libraries; while bibliographic information about a library collection object is usually static, museum records are ever-changing because of the continuous need for new information about museum objects to be added to the records. As early as 1967, the Museum Computer Network (MCN), an informal group of New York museums, attempted to create a collections management database called GRIPHOS, and at a Metropolitan Museum of Art and IBM conference in 1968, speakers discussed current and proposed projects to automate collections management. In an effort to coordinate research into developing these systems, professional associations such as the Museum Data Bank Coordinating Committee (MDBCC), formed in 1972, were created to disseminate information about computers and databases to museums interested implementing computerized collections systems. During the 1980s, Collections Management Systems became more advanced with the rise of relational databases that “[relate] each piece of data to every other piece,\" and during this time some of today’s popular systems were originally developed for specific institutions “based on generic relational databases” — such as Gallery Systems' The Museum System for the Metropolitan Museum of Art and Re:discovery Software's Proficio for the Thomas Jefferson Foundation’s Monticello — before being released as commercial products. During the 1990s, with computers becoming faster and cheaper and with the rise of the Internet, collections management software became much more sophisticated, able to “present images, sort information in any one of a myriad of configurations, record exhibition information, track locations, and interface with a museum Website.\"\n\nThough the goal during the 1960s was to use computers for collections record-keeping for purposes of accountability, MCN Executive Director Everett Ellin warned that museum professionals should include public access as a goal because it would “not be worth the effort if museums only create a glorified record-keeping system.\" Collections Management Systems have become crucial tools in increasing public access to collections information, expanding the types of information that are recorded. What was once “a simple tool for collections care and inventory” has become “a robust and powerful instrument for saving all information about museum objects,\" including interpretive material, digital objects, and digital surrogates. Since some Collections Management Systems now incorporate Digital Asset Management and content information storage, many museum professionals have started to use the acronym CMS to stand for “Content Management System.\"\n\nIn 1997, art historian and museum information studies consultant Robert A. Baron outlined the requirements for Collections Management Systems, not as a list of the kinds of collections object information that should be recorded, but rather as a list of collections activities such as administration, loan, exhibition, preservation, and retrieval, tasks that museums had been responsible for long before the invention of computers, and many modern Collections Management Systems go beyond cataloging by aiding in the management of these processes and workflows. The Canadian Heritage Information Network (CHIN) Collections Management Software Criteria Checklist (CMSCC), which aims to be a comprehensive list of the kinds of information that a museum may want to record in a CMS, organizes that list by processes and actions rather than type of information. The checklist “outlines a number of features commonly included in a commercial CMS, which can assist a museum in determining which features have priority.”\n\nManaging and documenting information and tasks related to objects entering the museum, including acquisition or loan records, receipts, record of the reason for the deposit of the object, and record of the object’s return to its owner.\n\nThe management and documentation of objects added to the institution’s collection, including accession numbers, catalog numbers, object name or title, acquisition date, acquisition method, and transfer of title. There are many different accession numbering systems, and a CMS should allow an institution to use its existing numbering system.\n\nIdentification of objects for which the institution has a legal responsibility, including loaned objects and objects that have not been accessioned. Information recorded includes object location and status.\n\nRecords of an object’s current and past locations within the institution's premises so that it can be located, including dates of movement and authorizations for movement.\n\nInformation that describes and identifies objects, including creator/maker/artist, date(s) of creation, place of creation, provenance, object history, research on the object, and connections to other objects.\n\nThe management of information about an object’s conservation “from a curatorial and collections management perspective,\" including conservation requests, examination records, condition reports, records of preventative actions, and treatment histories.\n\nManagement of information about potential threats to collections objects, including documentation of specific threats, records of preventative measures, disaster plans and procedures, and emergency contacts.\n\nDocumentation of insurance needs for objects for which the institution is responsible (included loaned objects) as well as the monetary value of objects for insurance purposes. This may include the names and contact information of appraisers as well as appraisal history.\n\nManagement of an object’s exhibition or display, including exhibition history and documentation of research done on an object for an exhibition. More advanced Collections Management Systems may have the ability to present information from the system on a museum’s website or in an online exhibit.\n\nManagement of objects leaving the institution’s premises and being transferred to a different location, including location information, packing notes, crate dimensions, authorizations, customs information and documenting the means of transportation (including courier information).\n\nManaging the temporary transfer of responsibility of an object from the museum to another institution or vice versa, including loan agreements, loan history, records of costs and payments, packing lists, and records of overdue loans.\n\nManagement and documentation of objects being deaccessioned and leaving the institution’s collection, either by transfer, sale, exchange, or destruction/loss, including transfer of title, records of approval, and reason for disposal.\n\nA Collections Management System should be able to store data, edit data, delete data, access data through queries, sort data, and output data in the form of reports. Data is stored in the form of tables and is entered into the system (and sometimes edited) using forms. Queries are searches that help retrieve specific data from the system, and reports “are the means by which the results of a query are displayed or printed.\"\n\nAn efficient CMS, like a good relational database, should not have duplicate records and should not require that the same information be recorded in more than one place in the system. At the same time, the system should be flexible enough to accommodate more data as the collections expand. The user must also understand that not all information must be entered into a Collections Management System; for example, complex information such as complicated dimensions and measurements. Some institutions may not want to record confidential information such as private donor information in a CMS and instead keep it in a manual file or a separate, secure digital file, with pointers to the file’s location recorded in the CMS. However, others argue that such confidential information should be recorded in the CMS to protect the information in the event of a disaster where manual files may be destroyed.\n\nA CMS should have \"a built in backup and recovery process\" to protect data against not only equipment failure and disaster but also human error, which may result in loss or corruption of data. Redundant copies of the information should be stored in multiple locations, and the backup process may be automated.\n\nBecause a computerized system “demands a much greater degree of precision in the use of language for cataloging and data retrieval than does a manual system,” data and metadata standards should be applied in a Collections Management System. Data standards provide rules for how information is entered into the system, and data that has been entered into the system in a consistent manner allows for more accurate and precise information retrieval and for easier exchange of data between different systems.\n\nThe three types of data standards are structure, content, and value:\n\nWhile most of these data standards apply to the cataloging and description of cultural objects, efforts are also being made to create data standards for natural history collections. Based on Dublin Core, the Darwin Core standard is a data structure standard for biodiversity information whose “glossary of terms” are the “fields” and “elements” needed to catalog biological and natural history specimens and samples.\n\nRecognizing the importance of data standards to many users, some developers advertise that their Collections Management Systems are compliant with certain standards. For example, the Adlib Museum CMS is “certified as SPECTRUM compliant by the Collections Trust” and “also incorporates other international standards such as the ‘CIDOC’ guidelines and Getty ‘Object ID.’”\n\nA Collections Management System should have security measures that “ensure that only authorized persons are able to enter, edit, or view” information contained in the system. However, there is a growing demand for public access to some of the collections and object information contained in the CMS, which “helps fulfill a museum's mission to educate the public and prove that the objects held in public trust are used to public benefit” while also encouraging collections staff to “support basic collection stewardship” by ensuring that information about the object is accurate before being made publicly accessible. The system should allow the public to be able to make and refine searches of publicly accessible information in the system.\n\nA CMS should also allow collections staff to manage information on reproduction rights of the objects for which the institution is responsible, including type of copyright scheme being applied (for example, U.S. copyright or Creative Commons license), copyright ownership, and digital watermarks.\n\nSince every museum has different needs, a museum should make a needs assessment before selecting a Collections Management System. The museum should determine what collections processes it needs the system to manage. The museum should also identify who will be using the system and consider such factors as collection size (both present and future), staff technology skills, and budget/pricing. Another recommendation is to map out both the short- and long-term goals for the new CMS and then determine how the system can help increase the museum's efficiencies. \n\nCollections Management Systems have their origins in cataloging and registration, and consequently, most systems manage information and records “from a curatorial and collections management perspective.\" Conservation information in these systems is often limited to condition reporting and documentation of treatment history. While some advanced systems allow registrars to manage workflow tasks such as approvals and receipts, most systems are unable to manage conservation workflows. Many conservators also need a system that can not only store and manage conservation documentation but also easily share that information with other conservators and institutions.\n\nMany Collections Management System developers have responded to this need by adding requested conservation features to their products. For example, in 2009, Gallery Systems, the developer of The Museum System (TMS), formed a consortium of stakeholders called the Conservation Working Group, to create a set of features to add to the conservation module of TMS.\n\nSome conservators and institutions have taken a different approach, customizing existing software so that the system can manage conservation workflows. For example, at the Smithsonian National Postal Museum in 2012, former collections database administrator Kate Collen modified The Museum Systems’ conservation module so that it could manage object treatment processes, including assigning roles and responsibilities to multiple staff, ordering and prioritizing conservation tasks and treatments, separating treatment images from object images, automating registrar and lender approvals for treatments, and even tracking staff hours. This was achieved by renaming and remapping fields in the existing system, in some cases using fields for different purposes than originally intended by the software developer.\n\nSome software developers have been developing standalone systems specifically for the purpose of managing conservation information and tasks. Since 2000, Inventive Software Solutions has been developing the Conservation Tracker System for the Philadelphia Museum of Art to be “a comprehensive digital management tool for art conservation documentation.” Developed since 2009 as a program of the Andrew W. Mellon Foundation, ConservationSpace is a project “to develop an open-source software application that will address a core need of the conservation community for a shared solution to the problem of documentation management.” In 2013, Gallery Systems decided that adding incremental conservation features to The Museum System was no longer sufficient to meet the needs of conservators and began to develop a standalone web-based system to manage conservation processes called TMS Conservation Studio, which was released in summer of 2015.\n"}
{"id": "16663203", "url": "https://en.wikipedia.org/wiki?curid=16663203", "title": "Comedy (drama)", "text": "Comedy (drama)\n\nA comedy is entertainment consisting of jokes intended to make an audience laugh. For ancient Greeks and Romans a comedy was a stage-play with a happy ending. In the Middle Ages, the term expanded to include narrative poems with happy endings and a lighter tone. In this sense Dante used the term in the title of his poem, the \"Divine Comedy\" (Italian: \"Divina Commedia\").\n\nThe phenomena connected with laughter and that which provokes it has been carefully investigated by psychologists and agreed upon the predominating characteristics are incongruity or contrast in the object, and shock or emotional seizure on the part of the subject. It has also been held that the feeling of superiority is an essential factor: thus Thomas Hobbes speaks of laughter as a \"sudden glory.\" Modern investigators have paid much attention to the origin both of laughter and of smiling, as well as the development of the \"play instinct\" and its emotional expression.\n\nMuch comedy contains variations on the elements of surprise, incongruity, conflict, repetitiveness, and the effect of opposite expectations, but there are many recognized genres of comedy. Satire and political satire use ironic comedy used to portray persons or social institutions as ridiculous or corrupt, thus alienating their audience from the object of humor.\n\nParody borrows the form of some popular genre, artwork, or text but uses certain ironic changes to critique that form from within (though not necessarily in a condemning way). Screwball comedy derives its humor largely from bizarre, surprising (and improbable) situations or characters. Black comedy is defined by dark humor that makes light of so-called dark or evil elements in human nature. Similarly scatological humor, sexual humor, and race humor create comedy by violating social conventions or taboos in comedic ways.\n\nA comedy of manners typically takes as its subject a particular part of society (usually upper class society) and uses humor to parody or satirize the behavior and mannerisms of its members. Romantic comedy is a popular genre that depicts burgeoning romance in humorous terms, and focuses on the foibles of those who are falling in love.\n\nThe word \"comedy\" is derived from the Classical Greek κωμῳδία, which is a compound either of \"κῶμος\" (revel) or \"κώμη\" (village) and \"ᾠδή\" (singing): it is possible that \"κῶμος\" itself is derived from \"κώμη\", and originally meant a village revel. The adjective \"comic\" (Greek κωμικός), which strictly means that which relates to comedy is, in modern usage, generally confined to the sense of \"laughter-provoking\". The word came into modern usage through the Latin \"comoedia \"and Italian \"commedia\" and has, over time, passed through various shades of meaning.\n\nIn ancient Greece, comedy seems to have originated in songs or recitations apropos of fertility festivals or gatherings, or also in making fun at other people or stereotypes. In the \"Poetics\", Aristotle states that comedy originated in phallic rituals and festivals of mirth. It is basically an imitation of 'the ridiculous, which is a species of the ugly.' However, Aristotle taught that comedy is a good thing. It brings forth happiness, which for Aristotle is the ideal state, the final goal in any activity. He does believe that we humans feel pleasure oftentimes by doing the wrong thing, but he does not necessarily believe that comedy and humor is the wrong thing. It is also not true for Aristotle that a comedy must involve sexual humor to qualify as a comedy. A comedy is about the fortunate arise of a sympathetic character. A happy ending is all that is required in his opinion. \n\nOn the contrary, the Greek Philosopher Plato taught that comedy is a destruction to the self. He believed it produces an emotion that overrides rational self-control and learning. In The Republic (Plato), he says that the Guardians of the state should avoid laughter, \"for ordinarily when one abandons himself to violent laughter, his condition provokes a violent reaction.\" Plato says comedy should be tightly controlled if one wants to achieve the ideal state.\n\nNorthrop Frye described the comic genre as a drama that pits two societies against each other in an amusing agon or conflict. He depicted these two opposing sides as a \"Society of Youth\" and a \"Society of the Old\", \"The Anatomy of Criticism\". 1957, but this dichotomy is seldom described as an entirely satisfactory explanation. A later view characterizes the essential agon of comedy as a struggle between a powerless youth and the societal conventions that pose obstacles to his hopes; in this sense, the youth is understood to be constrained by his lack of social authority, and is left with little choice but to take recourse to ruses which engender very dramatic.\n\n\nfrom what has been discussed\n\n"}
{"id": "9955923", "url": "https://en.wikipedia.org/wiki?curid=9955923", "title": "Corporate entertainment", "text": "Corporate entertainment\n\nCorporate entertainment describes private events held by corporations or businesses for their staff, clients or stakeholders. These events can be for large audiences such as conventions and conferences, or smaller events such as retreats, holiday parties or even private concerts.\n\nIt is also commonly used to mean corporate hospitality, the process of entertaining guests at corporate events.\n\nThe companies that provides corporate entertainment are called corporate event planners or corporate booking agencies.\n\nThere are various types of corporate events that make use of entertainment. An Opening General Session may include entertainment that adds excitement and presents the overall theme of the meeting. Mixers or pre-dinner parties many times use entertainment meant to provide a backdrop for conversation, perhaps an acoustic ensemble or pre-recorded music. Awards or Gala events, usually the last event in a series of meetings, can make use of many options, from celebrity entertainers to exciting bands providing dance music or other options that will leave the attendees with a feeling of excitement and looking forward to the next meeting. There are many different types of corporate entertainment.\n\nCorporate entertainment can also include a day of team building activities. These activities include traditional camp activities like tug of war, scavenger hunts, and relay races. They could also include sports such as volleyball, soccer, or basketball. The goal of team building corporate entertainment is to have employees recognize how the challenges of the activities relate to the workplace. Team chemistry, identifying strengths and attributes, understanding how to work through solving problems as one, and reflecting makes for fruitful team building.\n\nAwards or gala events are usually lavish events that celebrate accomplishment or milestones of a person or group of people in similar industries. Often these events serve as fundraisers for a specific cause. In addition to celebrating and recognizing achievements, it allows attendees to network with others with similar backgrounds or professions.\n\nHoliday celebration events are ways for companies or departments to celebrate holidays and to show appreciation to employees. Entertainment at these events vary from raffles and door prizes, mystery dinners, music and an overall casual, social setting that can build social relationships. For Christmas celebrations, companies have used the \"A Christmas Story\" theme.\n\nCorporate seminars, workshops, symposiums, and conferences are more informative in nature and often focussed on educational purposes. A conference refers to a formal meeting where participants exchange their views on various topics. A seminar is a form of academic instruction, either at a university or offered by a commercial or professional organization. A workshop includes all the elements of the Seminar, but with the largest portion being emphasized on “hand-on-practice” or laboratory work. A symposium is a formal gathering in an academic setting where participants are experts in their fields. Entertainment for these events varies from kick-op brunches to start, special industry guest speakers, and mixers, dinners afterwards. There are also booths set up for trade shows to display a companies strengths and for better marketing.\n\nCorporate charity events, whether concerts, golf tournaments, or anything else, play an important role in how businesses interact with the community. Corporate charity events unite people from all levels of the organization; such events are another form of team building which positively influence other aspects of work.\n"}
{"id": "35343748", "url": "https://en.wikipedia.org/wiki?curid=35343748", "title": "Cultural group selection", "text": "Cultural group selection\n\nCultural group selection is an explanatory model within cultural evolution of how cultural traits evolve according to the competitive advantage they bestow upon a group. This multidisciplinary approach to the question of human culture engages research from the fields of anthropology, behavioural economics, evolutionary biology, evolutionary game theory, sociology, and psychology.\n\nWhile cultural norms are often beneficial to the individuals who hold them, they need not be. Norms can spread by cultural group selection when they are practiced within successful groups, and norms are more likely to spread from groups that are successful. But, for cultural group selection to occur, there must exist, between groups, cultural differences that when transmitted across time affect the persistence or proliferation of the groups. Cultural norms that provide these advantages will, in turn, lead to the displacement, absorption or even extinction of other, less successful cultural groups. However, game theoretic models suggest that if individuals are able to migrate between groups (which is common in small-scale societies), differences between groups should be difficult to maintain. Research in psychology reveals that humans have a particular set of traits, which include imitation, conformity, and in-group bias, that are capable of supporting the maintenance of these group differences over extended periods of time.\n\nCultural group selection gives a compelling explanation for how large-scale complex societies have formed. While altruistic behaviour such as kin selection and reciprocity can explain the behaviour of small social groups common in many species, it is unable to explain the large complex societies of unrelated, anonymous individuals that we see in the human species. However, one of the major distinctions between humans and other species is our reliance on social learning in acquiring behaviours. These instincts allow for the acquisition and persistence of culture. Through cultural group selection, culturally specific cooperative behaviour can evolve to support large societies. For example, in a study that spanned a variety of cultures, testing behaviour in Ultimatum, Dictator, and Third-party punishment games, it was found that standards of fairness and inclination to punish were correlated with both participation in world religions and market integration. This indicates how many of the behaviours necessary for complex societies are the result of cultural exposure rather than any evolution of our psychology.\n\nFor cultural knowledge and behaviour to persist across multiple generations, humans need to have the capacity to acquire, retain, and transmit cultural information. While many species engage in social learning, humans consistently rely upon it for behavioural cues and information about the environment. In a study comparing human children and young chimpanzees, it was shown that, when given a demonstration on how to retrieve a reward from a box, chimps copy relevant behaviour, while ignoring irrelevant behaviour, to solve the task. Meanwhile, human children will faithfully imitate both relevant and irrelevant behaviour to solve the same task. While this may seem like a negative quality, it is what allows for reliable, high-fidelity transmission of cultural information, and produces stable behavioural equilibria within cultural groups.\n\nMichael Tomasello suggests the following three adaptations are necessary for human culture:\n\nAt around 9–12 months infants begin engaging in joint attention. This involves following the gaze of an adult or using them as social reference points. Put simply, they become aware of the adult's attention and behaviour towards objects in the environment. In this sense, the child is beginning to understand people as goal-oriented intentional agents. This is vitally important for learning through imitation and, eventually, language acquisition.\n\nBy about 1 year of age, children begin to learn by imitation. At this point, children are capable of discriminating intentional actions from unintentional ones, and will attempt to accurately copy those intentional actions to accomplish tasks they've seen adults do. Because of imitative learning, children will copy those intentional acts which have no perceivable effect on the outcome, as well as strange or unnatural actions when easier methods are available. For example, an Andrew Meltzoff study found that 14-month-old children will, after seeing an adult do it, bend at the waist and press a panel with their head to turn on a light, instead of using their hands. According to Tomasello, imitative learning is necessary for learning the symbolic conventions of language.\n\nThrough imitatively learning, the child comprehends that linguistic symbols are intended to focus attention to some specific aspect of the shared experience. In doing this, the child must be able to take the perspective of the speaker. Due to the intersubjectivity of linguistic symbols, language allows one to communicate various perspectives and shift attention to one aspect of the world over another. In learning a language, a child is inheriting a vast set of linguistic symbols that have been passed down many generations. What is inherited then is the methods of shifting attention and perspective that were historically of importance to the people of that culture.\n\nWithout between-group variation, cultural group selection could not occur, as there would be no group differentiation to select for. While processes such as cultural drift, epidemics, and natural disasters increase between-group variation, migration and genetic mixing decrease between-group variation \"and\" increase within-group variation. Variation is only maintained when cultural groups have mechanisms that prevent the norms of outside groups from invading the cultural group. These ‘mechanisms’ are those uniquely human psychological traits and behaviours that encourage imitation, conformity, and in-group biases.\n\nAccording to Joseph Henrich, between-group variation is maintained by the following four mechanisms:\n\nConformist transmission refers to the psychological bias to preferentially imitate high frequency behaviors in the cultural group. This homogenizes the social group and reinforces widely held cultural norms. This explains why individuals within a social group hold the same beliefs and why these beliefs persist over time. While individuals will rely on copying high frequency behaviors under various conditions, this reliance increases when an individual is exposed to ambiguous environmental or social information. Conformist transmission can maintain between-group variation by reducing within-group variation, but it also facilitates the rapid spread of novel ideas, which increases between-group variation. Taken together, reduced within-group variation and increased between-group variation lead to the cultural divergence between groups that is the driving force of cultural group selection.\n\nPrestige-biased transmission is the tendency the copy those members of the group that are more successful. Preferentially copying successful members of the group allows individuals to avoid costly trial-and-error learning by imitating the better-than-average skills of the more prestigious cultural models. Individual can determine the rank of potential models by how much deference they are shown by the rest of the group. Deference is shown to high-prestige individuals to gain the opportunity to copy their successful models. We can see evidence for this bias in how new technologies, or economic practices spread to different groups according to how quick \"opinion leaders\" adopt them.\n\nMeanwhile, self-similarity transmission is the tendency to copy those individuals who are similar in language, appearance, social standing and other behavioral and cultural traits. In the context of prestige-biased transmission, self-similarity means that individuals will preferentially imitate those high-prestige individuals who are similar to them. From the perspective of an imitator, this trait is adaptive. By only imitating those high-prestige individuals who are similar, the imitator avoids adopting traits or behaviors that are not compatible with his or her knowledge or social environment.\n\nThese two social biases act together in reducing within-group variation. Additionally, prestige-biased transmission increases between-group variation by contributing to the spread of novel ideas.\n\nNon-conformists threaten to increase within-group variation by introducing deviant behaviours to the group and must receive costly punishment to maintain a homogenous social group. As a consequence of being punished, non-conformists will be less successful than other members of the group. Prestige-biased transmission would suggest that non-conformist behaviors would, therefore, not spread through the population. Papers on the topic suggest that this kind of punishment is prevalent across many different societies.\n\nNormative conformity is the act of changing one’s visible behaviour, simply to appear to match the majority, and without actually internalizing the groups opinions. This differs from conformist transmission since normative conformity does not consider frequency of a behaviour as an indicator of worth. The Asch conformity experiments are a perfect example of how robust this effect is and its replication across many cultures shows that this behaviour is very common. Henrich suggests that normative conformity may have evolved to respond to the spread of punishing behaviour toward non-conformists. By appearing similar to the group, one can gain the advantages of in-group membership, while also avoiding punishment. A curious byproduct of normative conformity is that it can contribute to the conformity transmission of norms that the transmitter does not hold, because they were mistakenly attributed by the imitator.\n\nAs Donald T. Campbell says, for cultural group selection to occur, there must be cultural differences between groups which affect their persistence or proliferation. This means groups are selected \"for\" or \"against\" according to their respective \"gains\" or \"losses\" relative to other groups.\n\nJoseph Henrich describes the three mechanisms through which this process occurs:\n\nDemographic swamping occurs when one or more cultural groups reproduces individuals faster than other groups in the region because of stable, culturally transmitted ideas or practices. This is the slowest kind of cultural groups selection as it depends on natural selection of between-group cultural variation operating on a scale of millennia. It has been suggested that this is how early agriculturalist displaced hunter-gatherer societies.\n\nDirect intergroup competition is the process by which cultural groups compete with each other over resources by engaging in warfare and raiding. The cultural practices and behaviour that gives an advantage to one group over another will proliferate at the expense of those who cannot compete. There are many possible traits that could contribute to a group's success, such as technological development, social and political organization, economic development, nationalism, etc. According to Joseph Soltis, it would take 500–1000 years for group selection to happen this way.\n\nIn prestige-biased group selection, when individuals have opportunities to copy people from nearby groups, they will preferentially imitate the members of groups that are more cooperative than their own. Since cooperative groups have a higher average payoff than non-cooperative groups, members of cooperative groups will be considered more prestigious and worthy of imitation.\n\n"}
{"id": "13963489", "url": "https://en.wikipedia.org/wiki?curid=13963489", "title": "Cultural materialism (anthropology)", "text": "Cultural materialism (anthropology)\n\nCultural materialism is an anthropological research orientation first introduced by Marvin Harris in his 1968 book \"The Rise of Anthropological Theory\", as a theoretical paradigm and research strategy. It is said to be the most enduring achievement of that work. Harris subsequently developed a full elaboration and defense of the paradigm in his 1979 book \"Cultural Materialism\". To Harris social change is dependent of three factors: a society's infrastructure, structure, and superstructure.\n\nHarris's concept of cultural materialism was influenced by the writings of Karl Marx and Friedrich Engels, as well as their theories as modified by Karl August Wittfogel and his 1957 book, \"Oriental Despotism\". Yet this materialism is distinct from Marxist dialectical materialism, as well as from philosophical materialism. Thomas Malthus's work encouraged Harris to consider reproduction of equal importance to production. The research strategy was also influenced by the work of earlier anthropologists including Herbert Spencer, Edward Tylor and Lewis Henry Morgan who, in the 19th century, first proposed that cultures evolved from the less complex to the more complex over time. Leslie White and Julian Steward and their theories of cultural evolution and cultural ecology were instrumental in the reemergence of evolutionist theories of culture in the 20th century and Harris took inspiration from them in formulating cultural materialism.\n\nCultural materialism is a scientific research strategy and as such utilizes the scientific method. Other important principles include operational definitions, Karl Popper's falsifiability, Thomas Kuhn's paradigms, and the positivism first proposed by Auguste Comte and popularized by the Vienna Circle. The primary question that arises in applying the techniques of science to understand the differences and similarities between cultures is how the research strategy \"treats the relationship between what people say and think as subjects and what they say and think and do as objects of scientific inquiry\". In response to this cultural materialism makes a distinction between behavioral events and ideas, values, and other mental events.\n\nIt also makes the distinction between emic and etic operations. Emic operations, within cultural materialism, are ones in which the descriptions and analyses are acceptable by the native as real, meaningful, and appropriate. Etic operations are ones in which the categories and concepts used are those of the observer and are able to generate scientific theories. The research strategy prioritizes etic behavior phenomena.\n\n\nWithin this division of culture, cultural materialism argues for what is referred to as the principle of probabilistic infrastructural determinism. The essence of its materialist approach is that the infrastructure is in almost all circumstances the most significant force behind the evolution of a culture. Structure and superstructure are not considered \"insignificant, epiphenomenal reflexes of infrastructural forces\". The structure and symbolic/ideational aspects act as regulating mechanisms within the system as a whole.\n\nThe research strategy predicts that it is more likely that in the long term infrastructure probabilistically determines structure, which probabilistically determines the superstructures, than otherwise. Thus, much as in earlier Marxist thought, material changes (such as in technology or environment) are seen as largely determining patterns of social organization and ideology in turn.\n\nIn spite of the debt owed to the economic theories of Marx and Engels, cultural materialism rejects the Marxist dialectic which in turn was based on the theories of the philosopher Georg Wilhelm Friedrich Hegel.\n\nDuring the 1980s, Marvin Harris had a productive interchange with behavioral psychologists, most notably Sigrid Glenn, regarding interdisciplinary work. Very recently, behavioral psychologists have produced a set of basic exploratory experiments in an effort toward this end. More recently young anthropologists have re-approached the work of Marvin Harris as part of a new anthropology of infrastructures.\n\n"}
{"id": "36859663", "url": "https://en.wikipedia.org/wiki?curid=36859663", "title": "Discrimination against non-binary gender people", "text": "Discrimination against non-binary gender people\n\nDiscrimination or prejudice against non-binary people, people who do not identify as exclusively masculine or feminine, is a form of sexism, as well as a specific type of transphobia. Both cisgender and binary transgender people (men and women), including members of lesbian, gay, bisexual, and transgender (LGBT) communities, can display such prejudice.\n\nIn the binary gender system, genderqueerness is unintelligible and abjected. Individuals who identify as a gender that does not fit the traditional binary system tend to experience higher levels of social discrimination. A 2012 study from the \"National LGBTQ Task Force\" showed that genderqueer and other non-binary individuals were more likely to suffer physical assaults (32% vs. 25%), experience police harassment (25% vs. 19%), and suffer sexual assaulted (15% vs. 19%) compared to transgender individuals who identified within the gender binary (i.e., trans men and trans women). Genderqueer individuals also reported higher rates of harassment in K-12 school (83% vs. 77%), and sexual assault in K-12 schools (16% vs. 11%). This study reported that genderqueer and other non-binary individuals were more likely to be people of color (30% vs. 23%) and younger (under 45) than binary transgender people (89% vs. 68%). Responders who identified as neither male nor female were less likely to be white and more likely to be multi racial, Black, or Asian, but less likely to be Latin-American/Spanish in origin compared to those who identified as male or female. The study showed that despite genderqueer and other non-nonbinary individuals having received significantly higher education than those who identified within the gender binary, they were more likely to be living in extreme poverty (under $10,000 yearly) than those who identified within the gender binary (21% vs. 14%). They were more likely to be involved in underground economies for income (20% vs. 15%) than those who identified within the gender binary. Respondents disclosed brutal effects of discrimination, which had grave impacts, as 43% of genderqueer participants reported attempting suicide compared to 40% of transgender individuals that identified within the gender binary.\n\nSocial discrimination in the context of discrimination against non-binary and gender non-conforming people includes hate-motivated violence and excusing of such. According to a 2016 study from \"The Journal of Sex Research,\" one of the most common themes of discrimination for genderqueer people is binarism. Also the incorrect use of preferred gender pronouns, which the study labeled ‘nonaffirmation’ occurs when others do not affirm one’s sense of gender identity. Participants within this study also reported experiencing gender policing. An article from the book \"Violence and Gender\", states that this experienced violence and discrimination leads to high levels of stress. This article stated that non-binary participants are less likely to experience hate speech (24.4% vs. 50%) compared to trans men and equally as likely (24.4% vs. 24.4%) as trans women, yet genderqueer/nonbinary participants, along with trans women are more likely than trans men individuals to be concerned about the safety of themselves and others.\n\nIn the United States of America, unemployment rates for transgender people are approximately twice as high as those for cisgender people. In the National Transgender Discrimination Survey conducted by the LGBTQ+ Task Force, it was found that almost all non-binary persons had experienced discrimination in the workplace. Their findings show that being out as a non-binary person negatively affects that person's employment outcomes. Though non-binary persons have higher unemployment rates than those who identify with a specified gender, masculine non-binary persons who still appear male, or are not \"passing as female\" generally have a harder time in the work environment.\n\nIn a 2012 study by the Center for American Progress, 42% of gay employees said they have experienced discrimination of some form in the workplace; 50% of participants reported being harassed at work and 47% reported an adverse job outcome. That includes being fired or denied a promotion. In addition, 32% felt forced to act “traditionally gendered” to keep their jobs and 22% were denied access to bathrooms of choice based in gender identity.\n\n19% of non-binary trans persons reported job loss due to anti-transgender bias, and 90% reported experiencing anti-transgender bias on the job. 78% of those who had transitioned during their time at the workplace were happy with their choice to do so, and reported feeling more comfortable at work, although they experienced more discrimination. \n\nNot only does discrimination against transgender people in the workplace affect transgender employees, but it also affects the entire workplace team, distracting the victim and the perpetrator from the job itself. In 2001 study by the West Lothian Transgender Support Group, it was found that around 50 percent of transgender people do not survive beyond their thirtieth birthday, with most taking their own lives due to discrimination and others losing their lives from violence of cisgender individuals. The study’s statistic is also known as “the 50 percent rule” . With that being said, transgender individuals in the U.S. often face workplace discrimination like conflicts related to their bathroom usage, backlash over transitioning genders and being “misgendered” by coworkers. The Center of American Progress in 2012 also found that there is also a substantial amount of public ignorance towards transgender communities, in comparison to LGB community peers. Because of that, negative psychological consequences occur as a result like mental health disparities, higher rates in attempted suicide, and paranoid thinking in public spaces . Columbia University’s study in 2003 found that ideas of perceived discrimination are consistent with models of minority stress. It was also found that sexual minorities, such as the transgender community, are vulnerable to physical and mental health difficulties due to an exposure to chronic life stressors. The study finds that the transgender community in the U.S. possesses pre-conceived notions of rejection, hostility and discrimination from gender identities outside their groups .\n\nTransgender & non-binary peoples generally seek greater care because of the stigma and the lack of knowledge about their experience on the behalf of rural physicians. With that being said, non-binary individuals, and members of the LGBTQ community are very tentative when sharing their sexual identities to health care providers in fear of receiving inadequate/unfair treatment. In the 2001 Journal of the Gay and Lesbian Medical Association, the study explores factors associated with disclosure. 88 individuals (76% non-binary) gave responses to a questionnaire asking about their most recent interaction with health care, and how their overall experience was. Of this group, more respondents answered that they avoided answering questions about their sexuality (38%) than honestly disclosing it to their health care provider (37%). The respondents who avoided the questions were in agreement that if they gave out their sexual identity, they would be treated differently or poorly. The overall rates of disclosure to health care providers are low because of the perception that health care settings/providers are threatening and unjust. \n\nIn the 2015 International Journal of Transgenderism, a big portion of non-binary individuals reported to have experienced discrimination from different types of medical services, including: doctors, emergency rooms, and ambulances. From the study, it was discovered that 20.4% of non-binary individuals experienced discrimination when trying to access doctors and hospitals, 11.9% faced discrimination when attempting to access emergency rooms, and 4.6% when attempting to access the service of an ambulance. Based on these statistics, there is a needed change in how health services treat non-binary patients to minimize the discrimination on these individuals. \n\nIn the UK, non-binary individuals also experience health discrimination. Under the law of the United Kingdom, individuals are considered by the state to be either male or female, the gender that is stated on their birth certificate. This means that non-binary gender is not recognized in UK law. In a 2015 survey conducted by the Scottish Trans Alliance, three main areas were focused on including, non-binary individuals' experiences of medical services. When asked if they had ever experienced problems getting the help that was needed because of their non-binary identity, 56% said that they had. Some examples of this discrimination included refusal of surgery, withholding of treatment, discharging from clinics for being \"untreatable,\" and no treatment due to not having protocol for non-binary individuals. In addition, more than half of the respondents answered that they experienced a delay in their treatment after being honest and open about their non-binary gender identities. \n\nSimilarly to the UK, a 2013 survey was designed to examine the healthcare experiences of non binary individuals, and all other members of the LGBTQ community. The survey asked participants to rate their mental and physical health, and how their experiences with psychiatrists, general practitioners, and surgeons were. They rated their experience in terms of comfort, discrimination, and information provided. 10 people given the gender male at birth and 78 given female at birth, yet all identifying as gender diverse or non-binary individuals, completed two separate surveys. 70% of the participants accessed a psychiatrist, and on average rated their experience as just below positive. The individuals assigned female at birth rated their experience worse than those assigned male at birth. After this data was recorded, an analysis of the responses suggested that the positive experiences were due to professional, helpful, knowledgeable, and caring practitioners. Negative experiences were due to the amount of ridiculous or offensive questions asked, and for little to no knowledge on their sexual identity. Overall, these findings indicated that medical professionals are falling short of adequately meeting the needs of non binary individuals. \n\nDespite being more likely to achieve higher levels of education when compared to the general public, 90% of non-binary individuals face discrimination, often in the form of harassment in the workplace. Nineteen percent of genderqueer individuals report job loss as a result of their identities. Anti-discrimination laws that prohibit discrimination specifically against non-binary individuals do not exist. However, Title VII and the current proposed version of the federal Employment Non-Discrimination Act use such terms as \"gender identity\" and \"gender expression\", categories under which non-binary individuals fall due to the fact that their gender expression cannot be defined as male or female.\n\nIn 2004, Jimmie Smith was terminated from the fire department in Salem, Ohio after revealing their diagnosis with Gender Identity Disorder and intentions to undergo a male to female transition. The district court determined the reason for termination was because of their \"transexuality\" and not their gender non-conformity. The case was appealed to the Sixth Circuit, which overturned that decision and clarified to courts that under Title VII, sex discrimination was to be considered broader than only the traditional assumptions of sex.\n\nTwelve states currently have legislation which bars discrimination based on gender identity. Despite these efforts, non-binary individuals are subject to higher rates of physical and sexual assault and police harassment than those who identify as men or women, likely due to their gender expression or presentation.\n\nAccording to the Transgender Law Center, 70% of transgender people are not able to update their identity documents and one-third of have been harassed, assaulted or turned away when seeking basic services,\nand one third are not able to update their documents post-transition.\nIn 2016, the U.S. State Department was sued for denying a passport to Dana Zzyym, who is a veteran and an intersex and non-binary person. Zzyym wrote \"intersex\" on their passport form instead of male or female, which were the only two available gender fields on the form. Zzyym was denied the passport, which led to LGBTQ advocacy organizations filing a lawsuit against the U.S. State Department on Zzyym's behalf. The advocacy group Lambda Legal argued for gender-neutral terms and a third option on U.S. passports, arguing that the existing passport fields violated the Due Process Clause and Equal Protection Clause of the U.S. Constitution. The State Department argued that adding additional gender fields to the passport form would prevent the agency's efforts to combat identity theft and passport fraud. The Tenth Circuit Court ruled in favor of Zzyym, the first time in U.S. history that the federal government recognized non-binary people.\n\nCalifornia, the District of Columbia, New York City, New York State, Iowa, Vermont, Oregon and Washington State have currently removed the surgical requirement to complete a change on a birth certificate. In these states, to change the gender on a birth certificate, one must fill out a standardized form but legal or medical approvals are not required. In Washington D.C., the applicant fills out the top half of the form and a health or social service professional must fill out the bottom half. A person may face obstacles obtaining a court order in order to make a change to documents in other states. Tennessee is the only state that has a specific statute that forbids altering the gender designation on a birth certificate due to gender surgery, while Idaho and Ohio have the same prohibition, but via court decision rather than by statute; and in Puerto Rico, a U.S. territory, a court ruled that gender markers could not be changed on identity documents under any circumstances.\n\nIn California, the Gender Recognition Act of 2017 was introduced in the State Senate in Sacramento in January 2017, and signed into law by governor Jerry Brown on October 19. The law recognizes a third gender option known as \"non-binary\" which may be used on state-issued documents such as driver's licenses to more accurately reflect a person's gender. Senate bill SB179 was originally drafted by State Senators Toni Atkins and Scott Wiener. The law also makes it easier for existing documents to be changed, by removing requirements for sworn statements by physicians and replacing it with a sworn attestation by the person seeking to make the change to their documents. The Executive Director of Equality California commented, \"It is up to an individual—not a judge or even a doctor—to define a person's gender identity.\"\n\nThe first two US citizens to receive a court decreed gender of non-binary were in Oregon and California. In Oregon, Jamie Shupe was able to declare their sex as non-binary in June 2016 after a brief legal battle. Following in Shupe's footsteps, California resident Sarah Kelly Keenan was also able to legally change their gender marker to non-binary in September 2016. After both Shupe and Keenan had success with their cases, more people have been inspired to take on the legal battle of changing their gender to a non-binary marker. With the help of organizations such as Intersex & Genderqueer Recognition Project dozens of these petitions have been granted and additional states have changed regulations to provide a third gender option on state ID, birth certificates, and/or court orders.\n\nNon-binary is not recognized as a legal gender in the United Kingdom. The Gender Recognition Act 2004 allowed people to apply to the Gender Recognition Panel for a change of gender after living as the gender they wished to show on all their legal documents and being given a diagnosis of gender dysphoria by at least two health professionals. However, this change of gender only allowed for a change from male to female or vice versa.\n\nIn 2006 the Identity Cards Act 2006 was introduced, which issued documents to UK residents and linked them back to the National Identity Register database. When the issue of transgender people and their assigned vs. actual gender came up, it was said that transgender people would be issued two cards, each with a separate male and female gender marker. It was also said that eventually the hope for some was that the identity cards would get rid of the gender markers altogether. The Identity Documents Act 2010 made all these cards invalid and called for their immediate destruction.\n\nIn 2002, the Northwest Territories was the first of Canada’s provinces to explicitly include gender identity as a protected group from discrimination under the law, followed by Manitoba in 2012. By 2015, every Canadian province and territory had included similar changes to their discrimination laws.\n\nIn 2017, Canada passed Bill C-16 which formally recognized non-binary gender people and granted them protection under the law towards discrimination on the grounds of “gender identity” and “gender expression.”\n\nThe Sex Discrimination Act of 1984 did not explicitly protect non-binary persons from discrimination until the Sex Discrimination Amendment (Sexual Orientation, Gender Identity and Intersex Status) Act of 2013, which prohibited any discrimination on the grounds of “gender identity” and “intersex status.” This amendment also removed the use of “other” and “opposite sex” in exchange for broader terms like “different sex.”\n\nIn 2014, the Australian High Court legally recognized non-binary as a category for people to identify with on legal documents. After a citizen named Norrie made a request for a third gender identity on legal documents and was eventually denied, Norrie chose to take the matter up with Australia's Human Rights Commission and their Court of Appeal. After a four-year long legal battle beginning in 2010, Norrie finally won the case. From this and the legalizing of the matter in New South Wales, the Australian Capital Territory made the decision to pass a law which recognized non-binary identities. Though this is a step in a positive direction for non-binary identifying Australians, the law currently lacks concise policies on marriage licenses and recognition of partnership for non-binary people. Because of this, Australians registered as non-binary may not be able to legally marry.\n\nIn addition to marriage issues, the non-binary marker for Australian citizens requires proof of gender confirmation surgery. Because non-binary people live outside of the gender binary, they may not wish to obtain gender confirmation surgery. The people not wishing to do so ultimately will not be able to register as non-binary until this portion of the law is amended.\n\nWith much of existing Australian legislature being crafted around a binary interpretation of sex, this “third-sex” approach has lead to complications with how laws interact with this new classification. In response, steps towards the de-emphasis of sex within legislation are being taken by removing sexual identification from legal areas that do not have a necessity for it.\n\n"}
{"id": "56027886", "url": "https://en.wikipedia.org/wiki?curid=56027886", "title": "Family resemblance (anthropology)", "text": "Family resemblance (anthropology)\n\nFamily resemblance refers to physical similarities shared between close relatives, especially between parents and children and between siblings. In psychology, the similarities of personality are also observed.\n\nHeritability, defined as a measure of family resemblance, causes traits to be genetically passed from parents to offspring (heredity), allowing evolutionarily advantageous traits to persist through generations. Despite sharing parents, siblings do not inherit identical genes, making studies on identical twins (who have identical DNA) especially effective at analyzing the role genetics play in phenotypic similarity. Studies have found that generational resemblance of many phenotypic traits results from the inheritance of multiples genes that collectively influence a trait (additive genetic variance). There is evidence of heritability in personality traits. For example, one study found that approximately half of personality differences in high-school aged fraternal and identical twins were due to genetic variation - and another study suggests that no one personality trait is more heritable than another.\n\nFamily resemblance is also shaped by environmental factors, temperature, light, nutrition, exposure to drugs, the time that different family members spend in shared and non-shared environments, are examples of factors found to influence phenotype. Phenotypes found to be largely environmentally determined in humans include personality, height, and weight. Twin studies have shown that more than half of the variation in a few major aspects of personality are environmentally determined, and that environmental factors even affect traits like immune response and how children handle stress. Additionally, anomalous findings, such as second-degree relatives of alcoholics, showing surprising similarities to them have led some researchers’ attempts in generating better models that account for the environmental impacts on influences like cultural inheritance, family structure and head of household, which have been shown to influence family resemblance.\n\n\n"}
{"id": "21455886", "url": "https://en.wikipedia.org/wiki?curid=21455886", "title": "Figure of thought", "text": "Figure of thought\n\nA figure of thought (, ) is a rhetorical device sometimes distinguished from figure of speech. In another sense the term has been used in the study of diagrams and drawings.\n\nIt may be difficult to draw the distinction between figures of speech and figures of thought, especially when the primary area of inquiry is poetry rather than a prose composition, which adheres to the rules of rhetorical theory that were for the most part created in their fullest articulation in the age of Quintilian (c. 35 – c. 100). In their approach to language, the Roman poets (Horace, Catullus, Propertius, Tibullus) did not distinguish between \"inventio\" and \"elocutio\", which explains somewhat our confusion between figures of thought and figures of speech. The latter are exemplified most immediately by conceptual substitutions, such as metaphor or synecdoche, but if we consider not just the mere \"linguistic\" aspect of the substitution and focus most closely on the concepts themselves, then we may perceive the comprehensiveness of the conceptual for the poet, who operates with words to extend and amplify the potential semantics of poetic output.\n\nAnanda Coomaraswamy used the term in relation to the philosophy of Plato:\n\"Plato’s dialectic makes continual use of figures of speech, which are really figures of thought.\"\nThe scholar of Latin literature Gordon Williams (died 2010) published a study titled \"Figures of Thought in Roman Poetry\" (1980), stating in the introduction:\n\"Language was subject to ordering by exhaustive description of vocabulary, syntax, and figures. The content was likewise subject to ordering by the rules of \"inventio\" (the technique by which all the latent or inherent possibilities in a given idea or cluster of ideas could be 'discovered' and exploited).\"\nA collection of drawings by Nikolaus Gansterer (2011) was titled \"Drawing a Hypothesis: Figures of Thought\".\n"}
{"id": "25598628", "url": "https://en.wikipedia.org/wiki?curid=25598628", "title": "Foregrounding", "text": "Foregrounding\n\nForegrounding is the practice of making something stand out from the surrounding words or images. It is \"the 'throwing into relief' of the linguistic sign against the background of the norms of ordinary language.\" The term was first associated with Paul Garvin in the 1960s, who used it as a translation of the Czech \"aktualisace\" (literally \"to actualise\"), borrowing the terms from the Prague school of the 1930s.\n\nThere are two main types of foregrounding: parallelism and deviation. Parallelism can be described as unexpected regularity, while deviation can be seen as unexpected irregularity. As the definition of foregrounding indicates, these are relative concepts. Something can only be unexpectedly regular or irregular within a particular context. This context can be relatively narrow, such as the immediate textual surroundings (referred to as a 'secondary norm') or wider such as an entire genre (referred to as a 'primary norm').\n\nFor example, the last line of a poem with a consistent metre may be foregrounded by changing the number of syllables it contains. This would be an example of a deviation from a secondary norm. In the following poem by E. E. Cummings, there are two types of deviation:\n\nFirstly, most of the poem deviates from 'normal' language (primary deviation). In addition, there is secondary deviation in that the penultimate line is unexpectedly different from the rest of the poem. Nursery rhymes, adverts and slogans often exhibit parallelism in the form of repetition and rhyme, but parallelism can also occur over longer texts. For example, jokes are often built on a mixture of parallelism and deviation. They often consist of three parts or characters. The first two are very similar (parallelism) and the third one starts out as similar, but our expectations are thwarted when it turns out different in end (deviation).\n\nForegrounding can occur on all levels of language (phonology, graphology, morphology, lexis, syntax, semantics and pragmatics). It is generally used to highlight important parts of a text, to aid memorability and/or to invite interpretation.\n\n"}
{"id": "15852487", "url": "https://en.wikipedia.org/wiki?curid=15852487", "title": "Frazer Lecture", "text": "Frazer Lecture\n\nThe Sir James George Frazer Memorial Lectureship in Social Anthropology is a British academic lecture series.\n\nIn 1920 a sum of £675 was raised by a Committee of the University of Cambridge for the purpose of commemorating Sir James Frazer’s contributions to learning. In accordance with the wishes of the subscribers, a Frazer Lectureship in Anthropology was founded, the annual income of the fund being assigned to the University of Oxford, University of Cambridge, University of Glasgow and University of Liverpool in rotation for this purpose.\n\n"}
{"id": "36196531", "url": "https://en.wikipedia.org/wiki?curid=36196531", "title": "Functional sentence perspective", "text": "Functional sentence perspective\n\nIn linguistics, Functional Sentence Perspective (FSP) is a theory describing the information structure of the sentence and language communication in general. It has been developed in the tradition of the Prague School of Functional and Structural Linguistics together with its sister theory, Topic-Focus Articulation.\n\nThe key concepts of FSP were laid down by Jan Firbas in the mid-1950s on the basis of the linguistic work of Vilém Mathesius, especially his idea of functional syntax in linguistic characterology of language.\n\nThe term Functional Sentence Perspective was created by Jan Firbas as a more convenient English equivalent of Mathesius’ Czech term :\n\nWithin Czech linguistics the Czech calque of the English term Functional Sentence Perspective funkční větná perspektiva is nowadays used to refer to the approach stemming from the writings of Jan Firbas and his followers, while the original Mathesius’ Czech term aktuální členění větné tends to be associated with the group of linguists developing the Topic-Focus Articulation, i.e. Petr Sgall, Eva Hajičová, Jarmila Panevová and their disciples, despite the fact that both terms are still sometimes used interchangeably in some Czech contributions to the topic of information structure of language. (Cf. Karlík - Nekula - Pleskalová (2002))\n\n\n\n\n\n\n"}
{"id": "48875047", "url": "https://en.wikipedia.org/wiki?curid=48875047", "title": "Geneva Centre for Education and Research in Humanitarian Action", "text": "Geneva Centre for Education and Research in Humanitarian Action\n\nThe Geneva Centre for Education and Research in Humanitarian Action () (CERAH) offers a wide range of comprehensive and specialized postgraduate training programmes for professionals active in the humanitarian sector. A joint Centre of the University of Geneva and the Graduate Institute of International and Development Studies, CERAH is firmly anchored in Geneva's rich academic environment. It is one of the few institutes dedicated to the study of humanitarian action. It offers modular and flexible academic training programmes, distance or residential ones, and scholarship opportunities.\n\nAs Geneva's academic platform for humanitarian action, CERAH's focus lies on capacity strengthening and the reinforcement of both individual and collective competencies with the ultimate goal of contributing to an improved quality of the humanitarian response. Its programmes allow participants to develop a strong understanding of various conceptual and operational aspects of humanitarian action and equip them to define and implement strategic humanitarian responses.\n\nOffering a variety of courses ranging from short courses (TSC) to a comprehensive Master's programme, CERAH provides flexible and modular opportunities for professionals to deepen their knowledge. The current educational offer encompasses seven postgraduate programmes (a master programme, one diploma, and five certificate courses) and a dozen of intensive courses on specific issues (TSC). Responding to its international audience, CERAH offers a distance-learning course in \"Designing Strategies and Projects for Humanitarian Action\" which allows participants to study and learn from their own context, without having to be in Geneva. During the course students develop an action plan, which they can directly implement in their work situation. In addition, CERAH offers a Massive Open Online Course on Humanitarian Communications, in partnership with the University of Geneva.\n\nHumanitarian studies lie at the crossroads of various disciplines. As a result, CERAH promotes a multi-disciplinary approach to learning, and draws on the expertise of a range of academics and practitioners.\n\nCERAH also undertakes critical research that aims to assess concepts, policies and responses in order to improve humanitarian responses.\n\nCERAH was founded in 1998 with the support of the University of Geneva and the Swiss Agency for Development and Cooperation. Its existence is a testimony to the gradual and collective effort over the past 19 years of bringing together a multitude of academic and humanitarian actors.\n\nThe Centre underwent several phases of transformation. At the time of its establishment, it was known as the Multifaculty Programme for Humanitarian Action (PPAH) and only offered a university diploma. It was set up to provide high-level, continuing university education to humanitarian practitioners. The Centre was transformed in 2004, following its partnership with the Graduate Institute of International Aid Development studies. Renamed as the Interdisciplinary Programme in Humanitarian Action (PIAH), it introduced an advanced masters programme in collaboration with the I International Committee of the Red Cross and Médecins Sans Frontières (MSF) Suisse. A reform process in 2008 led to the creation of CERAH, as we know it today. Changes at the international level as well as in the academic and humanitarian fields led the Geneva university community to envisage a more ambitious role for CERAH.\n\nIn subsequent years, particularly after 2011, under the leadership of Professor Doris Schopper, CERAH revised its postgraduate educational offer to better respond to the needs of humanitarian organizations and professionals. It led to the development of seven postgraduate degrees (1 MAS, 1 DAS, 5 CAS) and several one-week intensive seminars on specific issues.\n\nThe MAS in Humanitarian Action is a 10- to 12-month full-time programme of 60 European Credit Transfer System (ECTS) credits. The programme is focused on building in-depth understanding of the central conceptual and operational aspects of humanitarian action.\n\nThe multidisciplinary and interactive programme, delivered in English, comprises three parts:\nSince 2012, the MAS in Humanitarian Action is offered to international managers in the humanitarian and development sector (with at least 2 years of working experience and holding a higher education institution degree), who wish to deepen their competencies in specific areas and add an academic and analytical dimension to their professional skills. Its modular set-up allows for maximum flexibility. Participant can complete the MAS in 1, 2 or 3 years.\n\nThis programme was awarded unconditional accreditation by the Swiss Center of Accreditation and Quality Assurance in Higher Education (AAQ).\n\nThe Diploma of Advanced Studies in Humanitarian Action is a 19-week programme of 30 ECTS credits. This core course is divided in three modules and completed by an individual work (dissertation). Through the study of past and present humanitarian crises, participants acquire the tools needed to analyse, understand and engage in critical reflection on the response to humanitarian emergencies today.\n\nAcademics and experts from a wide range of NGOs and international organisations deliver lectures. The programme is participatory, based on case studies and discussions.\n\nCERAH also offers seven-week 10-ECTS certificate courses. The courses are designed for managers to improve their competencies and leadership in defining and implementing specific strategies, while focusing on problem-solving in professional realities.\n\nList of CAS courses available:\n\n\nWithin the CAS programmes, CERAH offers an 8-month distance-learning programme \"Designing Strategies and Projects in Humanitarian Action\", which comprises 15 ECTS. The course enhances the capacity of individual and institutional humanitarian actors to devise and implement effective humanitarian responses:\n\n\"Learn as you work, work as you learn.\" Specifically adapted to the needs of working humanitarian professionals, this course allows participants to study and learn from their own context. During the course students develop an action plan, which they can directly implement in their work situation. The programme is fairly autonomous where students develop their own learning objectives based on current challenges. At the end of the programme, participants develop relevant competencies to design and adapt humanitarian strategies and projects according to the specifics of each context.\n\nThe course involves e-learning, a residential session in Kampala (Uganda) and individual coaching.\n\nCERAH developed the Humanitarian Distance Learning programme to increase access to training particularly for national staff as well as to allow students to study from their own context.\n\nSpecific themes are proposed as 1-week Thematic Short Courses (TSC). Offering topics that matter (e.g. nutrition, sexual violence, forced migration, negotiation) the courses attract new audiences and eventually, encourage participants to enrol in other trainings.\n\nList of TSC courses available: \n\nThe Massive Online Open Course (MOOC) \"Humanitarian communication: addressing key challenges\" focuses on the challenges of communication in humanitarian settings and the means of addressing these. This 5-week online course is repeated throughout the academic year.\n\nCERAH staff conducts research on a range of themes linked to humanitarian action including health, law, protracted crises and the political economy of humanitarian crises.\n\nThe Humanitarian Encyclopedia is a flagship project from CERAH to explore the different ways key humanitarian concepts are understood across space, time and disciplines . This new project offers a conceptual framework for humanitarian action, and providing a dynamic platform for national and international practitioners, community leaders, policy makers and academics to reflect on humanitarian concepts and practice for the 21st century.\n"}
{"id": "45580833", "url": "https://en.wikipedia.org/wiki?curid=45580833", "title": "Geometric morphometrics in anthropology", "text": "Geometric morphometrics in anthropology\n\nThe study of geometric morphometrics in anthropology has made a major impact on the field of morphometrics by aiding in some of the technological and methodological advancements. Geometric morphometrics is an approach that studies shape using Cartesian landmark and semilandmark coordinates that are capable of capturing morphologically distinct shape variables. The landmarks can be analyzed using various statistical techniques separate from size, position, and orientation so that the only variables being observed are based on morphology. Geometric morphometrics is used to observe variation in numerous formats, especially those pertaining to evolutionary and biological processes, which can be used to help explore the answers to a lot of questions in physical anthropology. Geometric morphometrics is part of a larger subfield in anthropology, which has more recently been named virtual anthropology. Virtual anthropology looks at virtual morphology, the use of virtual copies of specimens to perform various quantitative analyses on shape (such as geometric morphometrics) and form...\n\nThe field of geometric morphometrics grew out of the accumulation of improvements of methods and approaches over several decades beginning with Francis Galton (1822-1911). Galton was a polymath and the president of the Anthropological Institute of Great Britain. In 1907 he invented a way to quantify facial shapes using a base-line registration approach for shape comparisons. This was later adapted by Fred Bookstein and termed “two-point coordinates” or “Bookstein-shape coordinates”.\n\nIn the 1940s, D’Arcy Wentworth Thompson (biologist and mathematician, 1860-1948) looked at ways to quantify that could be attached to biological shape based on developmental and evolutionary theories. This led to the first branch of multivariate morphometrics, which emphasized matrix manipulations involving variables. In the late 1970s and early 1980s, Fred Bookstein (currently a professor of Anthropology at the University of Vienna) began using Cartesian transformations and David George Kendall (statistician, 1918-2007) showed that figures that hold the same shape can be treated as separate points in a geometric space. Finally, in 1996, Leslie Marcus (paleontologist, 1930-2002) convinced colleagues to use morphometrics on the famous Ötzi skeleton, which helped expose the importance of the applications of these methods.\n\nTraditional morphometrics is the study of morphological variations between or within groups using multivariate statistical tools. Shape is defined by collecting and analyzing length measurements, counts, ratios, and angles. The statistical tools are able to quantify the covariation within and between samples. Some of the typical statistical tools used for traditional morphometrics are: principal components, factor analysis, canonical variate, and discriminant function analysis. It is also possible to study allometry, which is the observed change in shape when there is change in size. However, there are problems pertaining to size correction since linear distance is highly correlated with size. There have been multiple methods put forth to correct for this correlation, but these methods disagree and can end up with different results using the same dataset. Another problem is linear distances are not always defined by the same landmarks making it difficult to use for comparative purposes. For shape analysis itself, which is the goal of morphometrics, the biggest downside to traditional morphometrics is that it does not capture the complete variation of shape in space, which is what the measurements are supposed to be based on. For example, if one tried to compare the length and width for an oval and tear drop shape with the same dimensions they would be deemed as the same using traditional morphometrics. Geometric morphometrics tries to correct these problems by capturing more variability in shape.\n\nThere is a basic structure to successfully performing and completing every geometric morphometric study:\n\nThe first step is to define your landmark set. Landmarks have to be anatomically recognizable and the same for all specimens in the study. Landmarks should be selected to properly capture the shape trying to be observed and capable of being replicated. The sample size should be roughly three times the amount of landmarks chosen and they must be recorded in the same order for every specimen.\n\nSemilandmarks, also called sliding landmarks, are used when the location of a landmark along a curvature might not be identifiable or repeatable. Semilandmarks were created in order to take landmark based geometric morphometrics to the next step by capturing the shape of difficult areas such as smooth curves and surfaces. In order to obtain a semilandmark, the curvature still has to start and end on definable landmarks, capture observed morphology, remain homologous across specimens in the same steps seen above for regular landmarks, be equal in number, and equally distant apart. When this approach was first proposed, Bookstein suggested gaining semilandmarks by densely sampling landmarks along the surface in a mesh and slowly thinning out the landmarks until the desired curvature was obtained. Newer landmark programs aid in the process but there are still some steps that must be taken in order for the semilandmarks to be the same across the whole sample. Semilandmarks are not placed on the actual curve or surface but on tangent vectors to the curve or tangent planes to the surface. The sliding of semilandmarks in new programs is performed by either selecting a specimen to be the model specimen for the rest of the specimens or using a computational sample mean from tangent vectors. Semilandmarks are automatically placed in most programs when the observer chooses a starting and ending point on definable landmarks and sliding the semilandmarks between them until the shape is captured. The semilandmarks are then mapped onto the rest of the specimens in the sample. Since shape will differ between specimens, the observer has to manually go through and make sure the landmarks and semilandmarks are on the surface for the rest of the specimens. If not they must be moved to touch the surface, but this process still maintains the correct location. There is still room for improvement to these methods but this is the most consistent option at the moment. Once mapped on, these semilandmarks can be treated just like landmarks for statistical analysis.\n\nThis is a different approach to data collection than using landmarks and semilandmarks. In this approach, deformation grids are used to capture the morphological shape differences and changes. The general idea is that shape variations can be recorded from one specimen to another based on the distortion of a grid. Bookstein proposed the use of a thin-plate spline (TPS) interpolation, which is a computed deformation grid that calculates a mapping function between two individuals that measures point differences. Basically, the TPS interpolation has a template computed grid that is applied to specimens and the differences in shape can be read from the different deformations of the template. The TPS can be used for both two- and three-dimensional data, but has proved less effective for visualizing three-dimensional differences, but it can easily be applied to the pixels of an image or volumetric data from CT or MRI scans.\n\nLandmark and semilandmark coordinates can be recorded on each specimen, but size, orientation, and position can vary for each of those specimens adding in variables that distract from the analysis of shape. This can be fixed by using superimposition, with generalized procrusted analysis (GPA) being the most common application. GPA removes the variation of size, orientation, and position by superimposing the landmarks in a common coordinate system. The landmarks for all specimens are optimally translated, rotated, and scaled based on a least-squared estimation. The first step is translation and rotation to minimize the squared and summed differences (squared Procrustes distance) between landmarks on each specimen. Then the landmarks are individually scaled to the same unit Centroid size. Centroid size is the square root of the sum of squared distances of the landmarks in configuration to their mean location. The translation, rotation, and scaling bring the landmark configurations for all specimens into a common coordinate system so that the only differing variables are based on shape alone. The new superimposed landmarks can now be analyzed in multivariate statistical analyses.\n\nIn general, principal components analysis is used to construct overarching variables that take the place of multiple correlated variables in order to reveal the underlying structure of the dataset. This is helpful in geometric morphometrics where a large set of landmarks can create correlated relationships that might be difficult to differentiate without reducing them in order to look at the overall variability in the data. Reducing the number of variables is also necessary because the number of variables being observed and analyzed should not exceed sample size. Principal component scores are computed through an eigendecomposition of a sample’s covariance matrix and rotates the data to preserve procrustes distances. In other words, a principal components analysis preserves the shape variables that were scaled, rotated, and translated during the generalize procrustes analysis. The resulting principal component scores project the shape variables onto low-dimensional space based on eigenvectors. The scores can be plotted various ways to look at the shape variables, such as scatterplots. It is important to explore what shape variables are being observed to make sure the principal components being analyzed are pertinent to the questions being asked. Although the components might show shape variables not relevant to the question at hand, it is perfectly acceptable to leave those components out any further analysis for a specific project.\n\nPartial least squares is similar the principal components analysis in the fact that it reduces the number of variables being observed so patterns are more easily observed in the data, but it uses a linear regression model. PLS is an approach that looks at two or more sets of variables measured on the same specimens and extracts the linear combinations that best represent the pattern of covariance across the sets. The linear combinations will optimally describe the covariances and provide a low-dimensional output to compare the different sets. With the highest shape variation covariance, mean shape, and the other shape covariances that exists among the sets, this approach is ideal for looking at the significance of group differences. PLS has been used a lot in studies that look at things such as sexual dimorphism, or other general morphological differences found at the population, subspecies, and species level. It has also been used to look at functional, environmental, or behavioral differences that could influence the found shape covariance between sets\n\nMultiple or multivariate regression is an approach to look at the relationship between several independent or predictor variables and a dependent or influential variable. It is best used in geometric morphometrics when analyzing shape variables based on an external influence. For example, it can be used in studies with attached functional or environmental variables like age or the development over time in certain environments. The multivariate regression of shape based on the logarithm of centroid size (square root of the sum of squared distances of landmarks) is ideal for allometric studies. Allometry is the analysis of shape based on the biological parameters of growth and size. This approach is not affected by the number of dependent shape variables or their covariance, so the results of regression coefficients can be seen as a deformation in shape.\n\nThe human brain is unique from other species based on the size of the visual cortex, temporal lobe, and parietal cortex, and increased gyrification (folds of the brain). There have been many questions as to why these changes occurred and how they contributed to cognition and behavior, which are important questions in human evolution. Geometric morphometrics has been used to explore some of these questions using virtual endocasts (casts of the inside of the cranium) to gather information since brain tissue does not preserve in the fossil record. Geometric morphometrics can reveal small shape differences between brains such as differences between modern humans and Neanderthals whose brains were similar in size. Neubauer and colleagues looked at the endocasts of chimpanzees and modern humans to observe brain growth using 3D landmarks and semilandmarks. They found that there is an early “globularization phase” in human brain development that shows expansion of the parietal and cerebellar areas, which does not occur in chimpanzees. Gunz and colleagues extended the study further and found that the “globularization phase” does not occur in Neanderthals and instead Neanderthal brain growth is more similar to chimpanzees. This difference could point to some important changes in the human brain that led to different organization and cognitive functions\n\nThere have been many debates on the relationships between Middle Pleistocene hominin crania from Eurasia and Africa because they display a mosaic of both primitive and derived traits. Studies on cranial morphology for these specimens have created arguments that Eurasian fossils from the Middle Pleistocene are a transition between \"Homo erectus\" and later hominins like Neanderthals and modern humans. However, there are two sides to the argument with one side saying that the European and African fossils are from a single taxon while others say that the Neanderthal lineage should be included. Harvati and colleagues decided to attempt to quantify the craniofacial features of Neanderthals and European Middle Pleistocene fossils using 3D landmarks to try to add to the debate. They found that some features were more Neanderthal like while others were primitive and likely from the Middle Pleistocene African hominins, so the argument could still go either way. Freidline and colleagues further added to the debate by looking at both adult and subadult crania of modern and Pleistocene hominins using 3D landmarks and semilandmarks. They found similarities in facial morphology between Middle Pleistocene fossils from Europe and Africa and a divide in facial morphology during the Pleistocene based on time period. The study also found that some characteristics separating Neanderthals from Middle Pleistocene hominins, like the size of the nasal aperture and degree of midfacial prognathism, might be due to allometric differences\n\nCrania can be used to classify ancestry and sex to aid in forensic contexts such as crime scenes and mass fatalities. In 2010, Ross and colleagues were provided federal funds by the U.S. Department of Justice to compile data for population specific classification criteria using geometric morphometrics. Their aim was to create an extensive population database from 3D landmarks on human crania, to develop and validate population specific procedures for classification of unknown individuals, and develop software to use in forensic identification. They placed 3D landmarks on 75 craniofacial landmarks from European, African, and Hispanic populations of about 1000 individuals with a Microscribe digitizer. The software they developed, called 3D-ID, can classify unknown individuals into probable sex and ancestry, and allows for fragmentary and damaged specimens to be used. A copy of the full manuscript can be found here: Geometric Morphometric Tools for the Classification of Human Skulls\n\nGeometric morphometrics can also be used to capture the slight shape variations found in postcranial bones of the human body such as \"os coxae\". Bierry and colleagues used 3D CT reconstructions of modern adult pelvic bones for 104 individuals to look at the shape of the obturator foramen. After a normalization technique to take out the factor of size, they outlined the obturator foramen with landmarks and semilandmarks to capture its shape. They chose the obturator foramen because it tends to be oval in males and triangular in females. The results show a classification accuracy of 88.5% for males and 80.8% for females using a Discriminant Fourier Analysis. Another study done by Gonzalez and colleagues used geometric morphometrics to capture the complete shape of the ilium and ischiopubic ramus. They placed landmarks and semilandmarks on 2D photographic images of 121 left pelvic bones from a collection of undocumented skeletons at the Museu Anthropológico de Coimbra in Portugal. Since the pelvic bones were of unknown origin, they used a K-means Cluster Analysis to determine a sex category before performing a Discriminant Function analysis. The results had a classification accuracy for the greater sciatic notch of 90.9% and the ischiopubic ramus at 93.4 to 90.1%\n\nThe books listed below are the standard suggestions for anyone who wants to obtain a comprehensive understanding of morphometrics (referred to by colors):\n\n-The Red Book: Bookstein, F. L., B. Chernoff, R. Elder, J. Humphries, G. Smith, and R. Strauss. 1985. Morphometrics in Evolutionary Biology\n\n-The Blue Book: Rohlf, F. J. and F. L. Bookstein (eds.). 1990. Proceedings of the Michigan Morphometrics Workshop\n\n-The Orange Book: Bookstein, F. L. 1991. Morphometric Tools for Landmark Data. Geometry and Biology\n\n-The Black Book: Marcus, L. F., E. Bello, A. García-Valdecasas (eds.). 1993. Contributions to Morphometrics\n\n-The Green Book: Zelditch, M. L., D. L. Swiderski, H. D. Sheets, and W. L. Fink. 2004. Geometric Morphometrics for biologists: A Primer\n\n2D Equipment\n\n3D Equipment\n\n"}
{"id": "56637216", "url": "https://en.wikipedia.org/wiki?curid=56637216", "title": "Glyptology", "text": "Glyptology\n\nGlyptology is the study of engraved gems, or of engravings on gems. \n\n"}
{"id": "39870048", "url": "https://en.wikipedia.org/wiki?curid=39870048", "title": "Hill-slope enclosure", "text": "Hill-slope enclosure\n\nThe term hill-slope enclosure describes a type of late prehistoric earthwork found across South West England and also in Wales. Normally formed from a single bank, or ditch and bank, enclosing an area of less than 1 hectare, and not on the summit of a hill. They are often found on a spur of a larger hill or range of hills.\n\nThe original purpose of the hill-slope enclosure is obscure but it is thought that they were not primarily defensive structures. Surveys and excavations have revealed low densities of postholes and storage pits suggesting they functioned as defensible farmsteads and permanent livestock enclosures.\n\nThey may also have served different purposes at different times and they may have had symbolic and religious significance which is now impossible to determine.\n"}
{"id": "5768059", "url": "https://en.wikipedia.org/wiki?curid=5768059", "title": "Hitsuzendō", "text": "Hitsuzendō\n\nYokoyama Tenkei (1885–1966), inspired by the teachings of Yamaoka Tesshu (1836–1888), founded the Hitsuzendo line of thought as a \"practice to uncover one's original self through the brush.\" This was then further developed by Omori Sogen Roshi as a way of Zen practice. Hitsuzendo is practised standing, using a large brush and ink, usually on newspaper roll. In this way, the whole body is used to guide the brush, in contrast to writing at a table.\n\nCalligraphy was brought to Japan from China and Chinese masters such as Wang Xizhi 王羲之 (Jp: Ou Gishi; 303-361) have had a profound influence, especially on the \"karayō\" style which is still practiced today. The indigenous Japanese \"wayō tradition\" (和様書道, wayō-shodō) only appeared towards the end of the Heian era. However, the calligraphy of Zen scholars was often more concerned with spiritual qualities and individual expression and shunned technicalities which led to unique and distinctly personal styles. Japanese calligraphy has three basic styles: Kaisho 楷書, Gyōsho 行書, and Sōsho 草書.\n\nTrue creativity is not the product of consciousness but rather the \"phenomenon of life itself.\" True creation must arise from mu-shin 無心, the state of \"no-mind,\" in which thought, emotions, and expectations do not matter. Truly skilful Zen calligraphy is not the product of intense \"practice;\" rather, it is best achieved as the product of the \"no-mind\" state, a high level of spirituality, and a heart free of disturbances.\n\nTo write Zen calligraphic characters that convey truly deep meaning, one must focus intensely and become one with the meaning of the characters they create. In order to do this, one must free one's mind and heart of disturbances and focus only on the meaning of the character. Becoming one with what you create, essentially, is the philosophy behind Zen Calligraphy and other Japanese arts.\n\n\n"}
{"id": "1149806", "url": "https://en.wikipedia.org/wiki?curid=1149806", "title": "Homology (anthropology)", "text": "Homology (anthropology)\n\nIn anthropology and archaeology, homology is a type of analogy whereby two human beliefs, practices or artifacts are separated by time but share similarities due to genetic or historical connections. Specifically in anthropology, a homology is a structure that is shared through descent from a common ancestor.\n\nThe concept was explored by the American archaeologist William Duncan Strong in his direct historical approach to archaeological theory.\n\n"}
{"id": "16799902", "url": "https://en.wikipedia.org/wiki?curid=16799902", "title": "Hprints", "text": "Hprints\n\nhprints (pronounced in English as aitch prints) is an archive for electronic preprints of academic papers in the fields of arts and humanities. It can be accessed freely via the Internet since it is an open access repository aiming at making scholarly documents publicly available to the widest possible audience.\n\nThe aim of hprints is to make Nordic research available through an open access online electronic full text archive, but the limitation to Nordic countries is claimed to be mainly an initial restriction for funding reasons. The archive will primarily contain electronic research documents in the form of preprints, reprints, working papers, book chapters, conference reports, invited lecture manuscripts etc. The archive is set up, maintained and promoted by Copenhagen University Library and consortium members. The consortium original members were:\nSubmissions of electronic text material to the archive is decentral and take place at the local individual researcher, or research group level.\n\nHence hprints is a tool for scientific communication between academic scholars, who can upload full-text research material such as articles, papers, conference papers, book chapters etc. The content of the deposited material should be comparable to that of a scientific paper that a scholar would consider suitable for publication in for example a peer reviewed scientific journal.\n\nIt is possible to search and find the paper by defined topics through an Internet search. Secondly, all submitted papers are stored permanently and receive a stable web address, as for example the paper in this example:\n\nMay 2007 the Nordic funding agency for libraries, Nordbib, granted the hprints project 287,000 DKK as part of its financing programme \"Work Package 2: Focus area on Content and Accessibility\". The plan was to launch an archive one year from this date i.e. approximately June 2008: The hprints project wishes to provide a policy and a technical infrastructure that permits open access to research within the arts and humanities. The assumption was that this will result in a number of advantages with respect to the electronic accessibility and visibility of the arts and humanities research area.\n\nOctober 2007, the Advisory Board of the Nordbib \"hprints project\" chose the system to be used for the Nordic arts and humanities e-print archive. Three possible alternatives existed: EPrints from the University of Southampton, LUR from Lund University Libraries, and HAL from the French national research council (CNRS). Both EPrints and LUR are free open source software that can be set up locally or hosted commercially, while HAL is a functioning archive, to which portals can be set up.\n\nAt the hprints Advisory Board meeting in October, it was decided to collaborate with the French research council, Centre National de la Recherche Scientifique (CNRS). Hence, the hprints e-print archive for Nordic arts and humanities is set up as a Nordic HAL portal with its own layout and adapted to the requirements of hprints.\n\nMarch 2008 hprints opened for public access. Since the archive is a part of HAL and papers will be shared with the French national archive.\n\n\n"}
{"id": "6163435", "url": "https://en.wikipedia.org/wiki?curid=6163435", "title": "Human Traces", "text": "Human Traces\n\nHuman Traces is a 2005 novel by Sebastian Faulks, best known as the British author of \"Birdsong\" and \"Charlotte Gray\". The novel took Faulks five years to write. It tells of two friends who set up a pioneering asylum in 19th-century Austria, in tandem with the evolution of psychiatry and the start of the First World War.\n\nTracing the intertwined lives of Doctors Thomas Midwinter, who is English, and Jacques Rebière, from Brittany, France, \"Human Traces\" explores the development of psychiatry and psychoanalysis in the late 19th century, by way of excursions into first alienism then metaphysics, human evolution and neuroscience, before the search for what it means to be human takes us into a brief foray into the First World War. Central to the plot is the theory of bicameralism.\n\nWhilst some have criticised \"Human Traces\" as excessively expository, detailed and didactic, it has also been considered wide-ranging, ambitious and well written. It has enjoyed commercial success, having been a bestseller in the United Kingdom.\n\nFaulks himself says of his novel:\n\n'Human Traces was a Sisyphean task. After spending five years in libraries reading up on madness, psychiatry and psychoanalysis (my office had charts and timelines and things plastered all over the walls), the act of finishing it felt like a bereavement.\n"}
{"id": "46531067", "url": "https://en.wikipedia.org/wiki?curid=46531067", "title": "Identification in rhetoric", "text": "Identification in rhetoric\n\nContemporary rhetoric focuses on cultural contexts and general structures of rhetoric structures. Kenneth Burke is one of the most notable contemporary U.S. rhetoricians who made major contributions to the rhetoric of identification. One of his most foundational ideas is as follows, “rhetoric makes human unity possible, that language use is symbolic action, and that rhetoric is symbolic inducement.” Branching from this, Herrick states that identification in rhetoric is crucial to persuasion, and thus to cooperation, consensus, compromise, and action. Burke believed that the most serious human problem was to be alienated or separated, and rhetoric was to be that problem’s only solution. Much of his work was based on bringing people back together. “Identification is affirmed with earnestness precisely because there is division. Identification is compensatory to division.” Rhetoric’s goal, in regards to identification, is to bring people together of whom have been separated by estrangement or opposition.\n\nKenneth Burke plays an important part in learning and understanding the core values of rhetorical theory in identification. He introduces the notion by taking the Aristotelian approach into a \"world of particulars.\" Burke states that Aristotle treated rhetoric as purely verbal. But there are also areas of overlap. The flexibility of identification that Burke has created expands into elements beyond language. Burke wrote that “identification ranges from the politician who, addressing an audience of farmers, says, ‘I was a farm boy myself,’ through the mysteries of social status, to the mystic’s devout identification with the source of all being.” This symbolic interaction is possible because it recognizes the hidden sources of identification among human beings as symbol users. From this, Burke understands symbols as something that is around constantly, and that choosing to accept and learning to read them accurately is what needs to be understood.\n\nBurke’s theory of identification has been applied and expanded upon in Krista Ratcliffe’s Rhetorical Listening Framework. Ratcliffe proposes the “blurring of Burke’s and Fuss’s theories of identification, what becomes visible is multiple places for rhetorical listening. When applying Burke and Fuss’s theories, Ratcliffe proposes non-identification in cross-cultural communication and feminist pedagogy. Her critique of Western logic is that it is difficult to simultaneously pay attention to both commonalities and differences, but that is where non-identification exists and thus provides a place for rhetorical listening. Burke’s theory is critiqued by Ratcliffe for only focusing on identification; she argues that rhetorical listeners need to be accountable and take into consideration different points of view, which can be done through simultaneous listening to commonalities and differences.\n\nRatcliffe draws upon Diane Fuss because Fuss expands Burke’s theory of identification to gear toward examining the differences in identificaion. Fuss defines Identification as related to the issue of connection between opposite entities, such as the interrelation between self and other, subject and object, and insiders and outsiders. For Fuss, identification is difficult to pinpoint, as the distinction between opposite entities is porous, oftentimes “impossibly confused and finally untenable.” Fuss further builds the connection between identification and disidentification. Fuss defines disidentification as contingent on previous identification with another group, no matter how stereotypical the identification is, while at the same time the identification has receded from the subconscious. Ratcliffe argues that previously identification has been configured as a metaphor, which is manifested in Burke’s consubstantiality and Fuss’s (dis)identification. Ratcliffe notes that metaphor has been used to function as the dominant trope for identification; however, metaphor foregrounds commonalities more than differences. Ratcliff suggests theorizing identification via the use of metonymy to counter the privilege of communality. Intrinsic to the trope of metonymy is an attention to both commonalities and differences.\n\nPractical applications of Burke’s “identification” can be seen in the scholarly effort to reframe identifications. Assembling essays from the fifth Biennial Rhetoric Society of America Conference, Michelle Ballif addresses Ratcliffe’s call for rethinking Burke’s notion of identification “as a place of perpetual reframing that affects who, how, and what can be thought, spoken, written, and imagined.” While some of the essay contributors draw upon Burke’s theory to reinterpret social identifications, others turn to specific social actions to reread Burke’s “identification.” For instance, following Ratcliffe’s critique of Burke’s theory for its lack of attention to difference, Dominic J. Ashby destabilizes Burke’s relatively fixed and teleological construction of identification with “a fluid and contingent notion of self”—that is, “uchi/soto,\" or inside/outside in Japanese rhetoric—highlighting a simultaneous exclusion and inclusion of outsiders through an ongoing unfolding of group dynamics. By way of analyzing the Facebook news feed of “We are all Khaled Said,” Katherine Bridgman expands Burkean identification to “embodiment,” or the mutually coordinated experience between speakers and their audiences triggered by specific circumstances. Along a similar vein, critiquing Burke’s consubstantiality for being sexually indifferent, Janice Odom draws from Irigaray’s feminist theories to reframe identification as a playground of sexual dominance and surrender.\n\n"}
{"id": "37336292", "url": "https://en.wikipedia.org/wiki?curid=37336292", "title": "Infinite Ability", "text": "Infinite Ability\n\nInfinite Ability is a special interest group on disability within the Medical Humanities Group of the University College of Medical Sciences (University of Delhi). It was founded by Dr Satendra Singh in 2011. The main purpose behind the formation of the group was the promotion and coordination among medical persons with disabilities of medical humanitarian approaches that would focus on four competency-based learning objectives of narrative medicine: graphic medicine; interpersonal and communication skills; patient care, and professionalism.\n\nThe mission of the group is to explore disability through disability studies and creativity and to achieve it the group organized the first ever Theatre of the Oppressed workshop for medical students in India. The group was also instrumental in organizing a unique 'Blind with Camera' workshop for the visually impaired and blind students of University of Delhi in 2012. The workshop by Partho Bhowmick was followed by a two-week-long exhibition of photographs taken by visually impaired in accessible format.\nDr Satendra Singh, founder of the group and Coordinator of the Enabling Unit, challenged the erroneous correlation of Jonas Salk's birthday with World Polio Day. His publication in the journal 'Vaccine' clears the air with appropriate references and contributes to correction of literature. His persistent advocacy also lead Medical Council of India to send directives to all the medical institutions in India to make the medical institutions 'accessible' to persons with disabilities.\n\n"}
{"id": "47064780", "url": "https://en.wikipedia.org/wiki?curid=47064780", "title": "Island Chain Strategy", "text": "Island Chain Strategy\n\nThe Island Chain Strategy is a strategy first mentioned by American foreign policy commentator John Foster Dulles in 1951 during the Korean War. It suggests surrounding the Soviet Union and China by sea. \nThe island chain concept did not become a major theme in American policy, however it has become a major fixation of Chinese analysts to this day. The concept heightens Chinese fears that they will be encircled by American forces, and emphasizes the geographical and strategic importance of Taiwan. It helps shape Chinese naval options and strategies, as well as playing a role in economic policy.\n\nWithin Chinese writings the Island Chain Strategy is divided into 3 parts, namely First Island Chain, the Second Island Chain and the Third Island Chain.\n\nThe First Island Chain begins at the Kuril Islands, and finishes towards Borneo and the northern portion of the Philippines. It is the first chain to block socialist countries aligned with the USSR, and after Soviet Russia is dealt with the chain would then turn its focus on China. The key part of the first chain would be Taiwan.\n\nBecause the island chain is built up of a series of landmasses, it is also called the \"unsinkable aircraft carrier\", especially in reference to Taiwan.\n\nThe Second Island Chain can refer to two different interpretations, but the version most commonly used refers to the island chain which is formed by the Ogasawara Islands and Volcano Islands of Japan, in addition to Mariana Islands which is United States territory.\n\nAs it is located within the middle portion of the Pacific Ocean, it acts as a second strategic defense line for the United States.\n\nThe Third Island Chain is the final part of the strategy. Its island chain begins at the Aleutian Islands, and finishes up in Oceania. The key part of the Third Island Chain would be the Hawaiian Islands of the United States.\n\nThe primary target of the doctrine was the USSR; however, additional targets also included the People's Republic of China and Vietnam. After the USSR collapsed in 1991, China soon became the major target of the doctrine.\n\n"}
{"id": "16102540", "url": "https://en.wikipedia.org/wiki?curid=16102540", "title": "Libertarian anarchism", "text": "Libertarian anarchism\n\nLibertarian anarchism may refer to:\n\n"}
{"id": "1828083", "url": "https://en.wikipedia.org/wiki?curid=1828083", "title": "Linguistic turn", "text": "Linguistic turn\n\nThe linguistic turn was a major development in Western philosophy during the early 20th century, the most important characteristic of which is the focusing of philosophy and the other humanities primarily on the relationship between philosophy and language.\n\nVery different intellectual movements were associated with the \"linguistic turn\", although the term itself is commonly thought popularised by Richard Rorty's 1967 anthology \"The Linguistic Turn\", in which it means the turn towards linguistic philosophy. According to Rorty, who later dissociated himself from linguistic philosophy and analytic philosophy generally, the phrase \"the linguistic turn\" originated with philosopher Gustav Bergmann.\n\nTraditionally, the linguistic turn is taken to also mean the birth of analytic philosophy. One of the results of the linguistic turn was an increasing focus on logic and philosophy of language, and the cleavage between ideal language philosophy and ordinary language philosophy.\n\nAccording to Michael Dummett, the linguistic turn can be dated to Gottlob Frege's 1884 work \"The Foundations of Arithmetic\", specifically paragraph 62 where Frege explores the identity of a numerical proposition. \n\nIn order to answer a Kantian question about numbers, \"How are numbers given to us, granted that we have no idea or intuition of them?\" Frege invokes his \"context principle\", stated at the beginning of the book, that only in the context of a proposition do words have meaning, and thus finds the solution to be in defining \"the sense of a proposition in which a number word occurs.\" Thus an ontological and epistemological problem, traditionally solved along idealist lines, is instead solved along linguistic ones.\n\nThis concern for the logic of propositions and their relationship to \"facts\" was later taken up by the notable analytic philosopher Bertrand Russell in \"On Denoting\", and played a weighty role in his early work in logical atomism.\n\nLudwig Wittgenstein, an associate of Russell, was one of the progenitors of the linguistic turn. This follows from his ideas in his \"Tractatus Logico-Philosophicus\" that philosophical problems arise from a misunderstanding of the logic of language, and from his remarks on language games in his later work. His later work (specifically \"Philosophical Investigations\") significantly departs from the common tenets of analytic philosophy and might be viewed as having some resonance in the post-structuralist tradition. \n\nW. V. O. Quine describes the historical continuity of the linguistic turn with earlier philosophy in \"Two Dogmas of Empiricism\": \"Meaning is what essence becomes when it is divorced from the object of reference and wedded to the word.\"\n\nLater in the twentieth century, philosophers like Saul Kripke in \"Naming and Necessity\" drew metaphysical conclusions from closely analyzing language.\n\nDecisive for the linguistic turn in the humanities were the works of yet another tradition, namely the Continental structuralism of Ferdinand de Saussure. Structuralism was the initial outcome of Saussure's linguistic turn, which later led to poststructuralism with the input of Friedrich Nietzsche's ideas. Influential poststructuralist theorists include Judith Butler, Luce Irigaray, Julia Kristeva, Gilles Deleuze, Michel Foucault and Jacques Derrida. The power of language, more specifically of certain rhetorical tropes, in historical discourse was explored by Hayden White.\n\nThese various movements often lead to the notion that language 'constitutes' reality, a position contrary to intuition and to most of the Western tradition of philosophy. The traditional view (what Derrida called the 'metaphysical' core of Western thought) saw words as functioning labels attached to concepts. According to this view, there is something like 'the \"real\" chair', which exists in some external reality and corresponds roughly with a concept in human thought, \"chair\", to which the linguistic word \"chair\" refers. However, the founder of structuralism, Ferdinand de Saussure, held that definitions of concepts cannot exist independently from a linguistic system defined by difference, or, to put it differently, that a concept of something cannot exist without being named. Thus differences between meanings structure our perception; there is no \"real\" chair except insofar as we are manipulating symbolic systems. We would not even be able to recognize a chair \"as\" a chair without simultaneously recognising that a chair is \"not\" everything else - in other words a chair is defined as being a specific collection of characteristics which are themselves defined in certain ways, and so on, and all of this within the symbolic system of language. Thus, a large part of what we think of as \"reality\" is really a convention of naming and characterising, a convention which is itself called \"language\".\n\n\n\n"}
{"id": "32455437", "url": "https://en.wikipedia.org/wiki?curid=32455437", "title": "Manuscriptology", "text": "Manuscriptology\n\nManuscriptology is another word for codicology, namely the study of history and literature through the use of hand-written documents. \n\nThe term is in use particularly among scholars of South Asian cultural history because many South Asian manuscripts are not codices in the strict sense of the word. That is to say, South Asian manuscripts are typically written on unbound sheets of paper or palm leaves, in a landscape format. Vellum or parchment - typical writing supports used in the European codex - are unknown in South Asia. \n\nThere are exceptions. The codex format is used for manuscripts in Kashmir, for example, where the concept of the manuscript book was influenced from European models transmitted by Islamic culture.\n\n\n\n"}
{"id": "4088298", "url": "https://en.wikipedia.org/wiki?curid=4088298", "title": "Metanoia (rhetoric)", "text": "Metanoia (rhetoric)\n\nMetanoia (from the Greek , \"metanoia\", \"changing one's mind\") in the context of rhetoric is a device used to retract a statement just made, and then state it in a better way. As such, metanoia is similar to correction. Metanoia is used in recalling a statement in two ways—-to weaken the prior declaration or to strengthen it.\n\nMetanoia is later personified as a figure accompanying kairos, sometimes as a hag and sometimes as a young lady. Ausonius' epigrams describe her thus: \"I am a goddess to whom even Cicero himself did not give a name. I am the goddess who exacts punishment for what has and has not been done, so that people regret it. Hence my name is Metanoea.\" \n\nThe use of metanoia to weaken a statement is effective because the original statement still stands, along with the qualifying statement. For instance, when one says, \"I will murder you. You shall be punished,\" the force of the original statement (\"I will murder you\") remains, while a more realistic alternative has been put forward (\"you shall be punished\").\n\nWhen it is used to strengthen a statement, metanoia works to ease the reader from a moderate statement to a more radical one, as in this quote from Marcus Aurelius's \"Meditations\"\nI still fall short of it through my own fault, and through not observing\nthe admonitions of the gods, and, I may almost say, their direct instructions (Book One);\nHere Aurelius utilizes metanoia to move from a mild idea (\"not observing the admonitions of the gods\") to a more intense one (\"not observing... their direct instructions\"); the clause \"I may almost say\" introduces the metanoia.\n\n"}
{"id": "55223808", "url": "https://en.wikipedia.org/wiki?curid=55223808", "title": "Miscarriage and grief", "text": "Miscarriage and grief\n\nMiscarriage and grief are both an event and subsequent process of grieving that develops in response to a miscarriage. Almost all those experiencing a miscarriage experience grief. This event is often considered to be identical to the loss of a child and has been described as traumatic. \"Devastation\" is another descriptor of miscarriage. Grief differs from the emotion sadness. Sadness is an emotion along with grief, on the other hand, is a response to the loss a of the bond or affection was formed and is a process rather than one single emotional response. Grief is not equivalent to depression. Grief also has physical, cognitive, behavioral, social, cultural, and philosophical dimensions. Bereavement and mourning refer to the ongoing state of loss, and grief is the reaction to that loss. Emotional responses may be bitterness, anxiety, anger, surprise, fear, and disgust and blaming others; these responses may persist for months. Self-esteem can be diminished as another response to miscarriage. Not only does miscarriage tend to be a traumatic event, women describe their treatment afterwards to be worse than the miscarriage itself.\n\nA miscarriage can often be \"heart-breaking\". A miscarriage can effect the women, husband, partner, siblings, grandparents, the whole family system and friends. Almost all those experiencing a miscarriage go through a grieving process. Serious emotional impact is usually experienced immediately after the miscarriage. Some may go through the same loss when an ectopic pregnancy is terminated. In some, the realization of the loss can take weeks. Providing family support to those experiencing the loss can be challenging because some find comfort in talking about the miscarriage while others may find the event painful to discuss. The father of the baby can have the same sense of loss. Expressing feelings of grief and loss can sometimes be harder for men. Some women are able to begin planning their next pregnancy after a few weeks of having the miscarriage. For others, planning another pregnancy can be difficult. Organizations exist that provide information and counselling to help those who have had a miscarriage. Some women have a higher risk of developing prolonged grief and complicated grief than others.\n\nMiscarriage has an emotional effect and can also lead to psychological disorders. One discorder that can develop is primary maternal preoccupation. This is defined as a \" ...'special psychiatric condition' in which the pregnant woman identifies with her baby, highlights the crisis a woman faces when the baby with whom she is preoccupied and identified dies...\" Grieving manifests itself differently for each woman after miscarriage. It may often go unrecognized. The grief that follows a miscarriage resembles, but is not the same as, the grief experienced after the loss of a family member. Disbelief, depression, anger, and yearning, are described as being a part of the normal grieving process. These reactions remain from three to nine months after the loss. Forty-one percent of parents experience a normal, expected decline in grief in the first two years while 59% were delayed in the resolution of their grief.\n\nGrieving can create feelings of loneliness.\nThis grieving has been called a type of psychological trauma. Other serious consequences can develop including depression, anxiety disorder, post-traumatic stress disorder, and somatoform disorder. These responses all are associated with grieving after a miscarriage. Some women are able to complete the grieving process a few weeks after the miscarriage and start anticipating their next pregnancy. Planning another pregnancy is traumatic for others. The impact of a miscarriage can be \"crippling\" psychologically. Anger can be directed toward those who have had successful pregnancies and children. A woman can grieve the \"loss of a future child\" and question her own role as a mother. They may blame themselves or their partner for the miscarriage.\n\nUnsuccessful attempts to become pregnant through in vitro fertilization (IVF) can also illicit a similar grief response in women. Those experiencing a late miscarriage may have more significant distress compared to those who have experienced a miscarriage in the first trimester. Even depression can occur.\n\n\"Women today...are aught in a unique historical moment: technology encourages them to form emotional attachments to their pregnancies, but society has not developed traditions to cushion the shock when those attachmets are shattered.\"\n\nDescriptions of the miscarriage are expressed in non-clinical terms by those who have experienced the event.\n\nMiscarriage has been found to be a traumatic event and a major loss for women. Pregnancy loss, including induced abortion is a risk factor for mental illness. The impact of miscarriage can be underestimated. The trauma can be compounded if the miscarriage was accompanied by visible and relatively large amounts of blood loss.\nThe trauma of miscarriage can be compounded if the miscarriage was accompanied by visible and relatively large amounts of blood loss.\nBipolar disorders are associated with miscarriage. Depression and bilpolar disorder becomes evident after a miscarriage in 43% of women. Some women are more likely to experience complicated and prolonged grief than others.\n\nWomen experiencing miscarriage are at risk for grief reactions, anxiety or depression. Obsessiveness regarding the miscarriage can develop. Primary maternal preoccupation is also considered a consequence of miscarriage. This condition can occur if a woman who develop a close bond \"with her baby\" experiences the loss of the pregnancy.\n\nDifferent grieving \"styles\" can exist and vary between individuals. There can be a complete avoidance of dealing with the memories of the miscarriage and there can be an \"obsessive\" concentration on an event in the miscarriage. This is in contrast with the expected ability to \"reminisce about the loss of a loved one\". Complicated grief differs from the more common form of grief that occurs after a miscarriage. The grieving process associated with other events such as the loss of a spouse or parent is expected to decline in predictable and steady rate. This not true for those experiencing grief after a miscarriage because only 41% follow the expected decline in grief while most, 59% do not fit this pattern.\n\nMiscarriage is associated with post traumatic stress disorder.\nRisks for developing PTSD after miscarriage are: emotional pain, expressions of emotion, and low levels of social support. Even if relatively low levels of stress occur after the miscarriage, symptoms of PTSD including flashbacks, intrusive thoughts, dissociation and hyperarousal can later develop. The effects of stress can complicate miscarriage. Miscarriage is a stressful event and because stress is a risk factor for subsequent miscarriage, its presence can become part of cycle that continues. Lower stress levels are associated with more favorable outcomes in future pregnancies while higher stress levels increase the risk.\n\nPhysical recovery from miscarriage can have an effect on emotional disturbances. The body has to recover from the sudden pregnancy loss. In some instances ffatigue is present. Insomnia can be a problem. The miscarriage is very upsetting to the family and can generate very strong emotions. Some women may feel that the miscarriage occurred because they somehow had caused it. Others may blame the father or partner for the miscarriage. Coping with a miscarriage can very greatly between women and families. Some find it difficult to talk about the miscarriage. The narratives of women tend to coincide with quantified and measurable effects. Some women engage in activities that are believed to aid in recovery such as therapy, religion and art.\nCounseling can be offered but effective interventions to assist in recovery have been difficult to identify due to the reports of efficacy and ineffective counseling. Comparisons are hard to make. Despite the lack of studies that describe effective interventions for those with grief after a miscarriage, some clinicians still offer counselling and follow-up to help women recover and adapt to the loss.\n\nRecommendations to help recover from the event include:\n\nGenerally, the impact of experiencing miscarriage is underestimated. Other methods used to promote recovery are be relaxation techniques, guided imagery, and \"thought-stopping\". Even Gestalt role-playing has been used. Some women can \"emotionally relocate the child\", redefine a relationship \"with the missing child\", and engage in \"continuing the bond\" to incorporate the loss into their life experiences.\n\nWomen who have miscarried report that they were dissatisfied with the care they received from physicians and nurses. One observer highlights the insensitivity of some health care providers when they approach the grieving mother \"...by playing down her emotion as somehow an irrational response...\" Clinicians may not recognize the psychological impact of the miscarriage and can \"expect parents to move on with their lives.\"\n\nSince the experiences of women can vary so widely, sensitive nursing care afterward is appropriate.\n\nOne emotional response to miscarriage is the strong apprehension that can develop anticipating a subsequent pregnancy. Procreation abilities may also be questioned by the woman. Significant distress can develop in the other children in the family when they think a sibling has died. They may regard this as a baby they did not get to meet. They can also experience grief and guilt find it difficult to express these emotions to their parents. The siblings may feel a need to act as if everything is the same and that they are unaffected in an attempt to protect their parents from their own feelings. Children can also need help, understanding and the ability to make sense of the event.\n\nRituals that recognize the loss can be important in coping. Family and friends often conduct a memorial or burial service. Hospitals also can provide support and help memorialize the event. Depending on locale others desire to have a private ceremony. The religious faith of the woman and family impacts the grief process. Conversely, the lack of recognition that the miscarriage has occurred by family and friends can be troubling and add to the trauma of the event.\nGrieving after the loss of a child through miscarriage in other cultures can vary from western culture. An individual’s culture plays a large role in determining an inappropriate pattern of grief, and it is appropriate to take into account cultural norms before reaching a complicated grief diagnosis. There are cultural differences in emotional levels, how these are expressed and how long they are expressed. External symptoms of grief differ in non-Western cultures, presenting increased somatization. Narratives by Swedish women include their own perception of losing a child. Investigations describe their grief over their miscarriage: \"When miscarriage occurs it is not a gore, an embryo, or a fetus they lose, it is their child. They feel that they are the cause of the miscarriage through something they have done, eaten, or thought. They feel abandonment and they grieve for their profound loss; they are actually in bereavement.\" Native American women have cut their long hair following the death of a family member. The narratives of women tend to coincide with quantified and measurable effects. In women who are induced to have an abortion, an identical grieving process can occur. The emotional responses to a spontaneous abortion (miscarriage) and an elective abortion are sometimes identical. Spanish women experience grief in much the same way in the rest of Western culture. Some women find online forums helpful.\n\n\n\n"}
{"id": "174653", "url": "https://en.wikipedia.org/wiki?curid=174653", "title": "Parallel universes in fiction", "text": "Parallel universes in fiction\n\nA parallel universe is a hypothetical self-contained reality co-existing with one's own. A specific group of parallel universes are called a \"multiverse\", although this term can also be used to describe the possible parallel universes that constitute reality. While the terms \"parallel universe\" and \"alternative reality\" are generally synonymous and can be used interchangeably in most cases, there is sometimes an additional connotation implied with the term \"alternative reality\" that implies that the reality is a variant of our own. The term \"parallel universe\" is more general, without implying a relationship, or lack of relationship, with our own universe. A universe where the very laws of nature are different – for example, one in which there are no Laws of Motion – would in general count as a parallel universe but not an alternative reality and a concept between both fantasy world and earth.\n\nThe actual quantum-mechanical hypothesis of parallel universes is \"universes that are separated from each other by a single quantum event.\"\n\nFantasy has long borrowed an idea of \"another world\" from myth, legend and religion. Heaven, Hell, Olympus, and Valhalla are all \"alternative universes\" different from the familiar material realm. Plato reflected deeply on the parallel realities, resulting in Platonism, in which the upper reality is perfect while the lower earthly reality is an imperfect shadow of the heavenly. The lower reality is similar but with flaws.\n\nModern fantasy often presents the concept as a series of planes of existence where the laws of nature differ, allowing magical phenomena of some sort on some planes. This concept was also found in ancient Hindu mythology, in texts such as the Puranas, which expressed an infinite number of universes, each with its own gods. Similarly in Persian literature, \"The Adventures of Bulukiya\", a tale in the \"One Thousand and One Nights\", describes the protagonist Bulukiya learning of alternative worlds/universes that are similar to but still distinct from his own. In other cases, in both fantasy and science fiction, a parallel universe is a single other material reality, and its co-existence with ours is a rationale to bring a protagonist from the author's reality into the fantasy's reality, such as in \"The Chronicles of Narnia\" by C. S. Lewis or even the beyond-the-reflection travel in the two main works of Lewis Carroll. Or this single other reality can invade our own, as when Margaret Cavendish's English heroine sends submarines and \"birdmen\" armed with \"fire stones\" back through the portal from \"The Blazing World\" to Earth and wreaks havoc on England's enemies. In dark fantasy or horror the parallel world is often a hiding place for unpleasant things, and often the protagonist is forced to confront effects of this other world leaking into his own, as in most of the work of H. P. Lovecraft and the \"Doom\" computer game series, or \"Warhammer 40K\" miniature and computer games. In such stories, the nature of this other reality is often left mysterious, known only by its effect on our own world.\n\nThe concept also arises outside the framework of quantum mechanics, as is found in Jorge Luis Borges short story \"El jardín de senderos que se bifurcan\" (\"The Garden of Forking Paths\"), published in 1941 before the many-worlds interpretation had been invented. In the story, a Sinologist discovers a manuscript by a Chinese writer where the same tale is recounted in several ways, often contradictory, and then explains to his visitor (the writer's grandson) that his relative conceived time as a \"garden of forking paths\", where things happen in parallel in infinitely branching ways. One of the first Science fiction examples is Murray Leinster's \"Sidewise in Time\", in which portions of alternative universes replace corresponding geographical regions in this universe. \"Sidewise in Time\" describes it in the manner that similar to requiring both longitude and latitude coordinates in order to mark your location on Earth, so too does time: travelling along latitude is akin to time travel moving through past, present and future, while travelling along latitude is to travel perpendicular to time and to other realities, hence the name of the short story. Thus, another common term for a parallel universe is \"another dimension\", stemming from the idea that if the 4th dimension is time, the 5th dimension - a direction at a right angle to the fourth - are alternate realities.\n\nWhile this is a common treatment in Science fiction, it is by no means the only presentation of the idea, even in hard science fiction. Sometimes the parallel universe bears no historical relationship to any other world; instead, the laws of nature are simply different from those in our own, as in the novel \"Raft\" by Stephen Baxter, which posits a reality where the gravitational constant is much larger than in our universe. (Note, however, that Baxter explains later in \"Vacuum Diagrams\" that the protagonists in \"Raft\" are descended from people who came from the Xeelee Sequence universe.)\n\nOne motif is that the way time flows in a parallel universe may be very different, so that a character returning to one might find the time passed very differently for those he left behind. This is found in folklore: King Herla visited Fairy and returned three centuries later; although only some of his men crumbled to dust on dismounting, Herla and his men who did not dismount were trapped on horseback, this being one folkloric account of the origin of the Wild Hunt. C. S. Lewis made use of this in \"The Chronicles of Narnia\"; indeed, a character points out to two skeptics that there is no need for the time between the worlds to match up, but it would be very odd for the girl who claims to have visited a parallel universe to have dreamed up such a different time flow - from their perspective, the girl had only been gone for a few minutes though she was in Narnia for hours, and if she was making it up surely she would have spent a while longer hiding than a few minutes.\n\nThe division between science fiction and fantasy becomes fuzzier than usual when dealing with stories that explicitly leave the universe we are familiar with, especially when our familiar universe is portrayed as a subset of a multiverse. Picking a genre becomes less a matter of setting, and more a matter of theme and emphasis; the parts of the story the author wishes to explain and how they are explained. \"Narnia\" is clearly a fantasy, and the TV series \"Sliders\" is clearly science fiction, but works like the \"World of Tiers\" series or \"Glory Road\" tend to occupy a much broader middle ground.\n\nWhile technically incorrect, and looked down upon by hard science-fiction fans and authors, the idea of another \"dimension\" has become synonymous with the term \"parallel universe\". The usage is particularly common in movies, television and comic books and much less so in modern prose science fiction. The idea of a parallel world was first introduced in comic books with the publication of \"The Flash\" #123, \"Flash of Two Worlds\".\n\nIn written science fiction, \"new dimension\" more commonly – and more accurately – refer to additional coordinate axes, beyond the three spatial axes with which we are familiar. By proposing travel along these extra axes, which are not normally perceptible, the traveler can reach worlds that are otherwise unreachable and invisible.\nIn 1884, Edwin A. Abbott wrote the seminal novel exploring this concept called \"Flatland: A Romance of Many Dimensions\". It describes a world of two dimensions inhabited by living squares, triangles, and circles, called Flatland, as well as Pointland (0 dimensions), Lineland (1 dimension), and Spaceland (three dimensions) and finally posits the possibilities of even greater dimensions. Isaac Asimov, in his foreword to the Signet Classics 1984 edition, described \"Flatland\" as \"The best introduction one can find into the manner of perceiving dimensions.\"\n\nIn 1895, \"The Time Machine\" by H. G. Wells used time as an additional \"dimension\" in this sense, taking the four-dimensional model of classical physics and interpreting time as a space-like dimension in which humans could travel with the right equipment. Wells also used the concept of parallel universes as a consequence of time as the fourth dimension in stories like \"The Wonderful Visit\" and \"Men Like Gods\", an idea proposed by the astronomer Simon Newcomb, who talked about both time and parallel universes; \"Add a fourth dimension to space, and there is room for an indefinite number of universes, all alongside of each other, as there is for an indefinite number of sheets of paper when we pile them upon each other\".\n\nThere are many examples where authors have explicitly created additional spatial dimensions for their characters to travel in, to reach parallel universes. In \"Doctor Who\", the Doctor accidentally enters a parallel universe while attempting to repair the TARDIS console in \"Inferno\". The parallel universe was similar to the real universe but with some different aspects, Britain has a fascist government and the royal family has been executed. Douglas Adams, in the last book of the \"Hitchhiker's Guide to the Galaxy\" series, \"Mostly Harmless\", uses the idea of probability as an extra axis in addition to the classical four dimensions of space and time similar to the many-worlds interpretation of quantum physics. Though, according to the novel, they're not really parallel universes at all but only a model to capture the continuity of space, time and probability. Robert A. Heinlein, in \"The Number of the Beast\", postulated a six-dimensional universe. In addition to the three spatial dimensions, he invoked symmetry to add two new temporal dimensions, so there would be two sets of three. Like the fourth dimension of H. G. Wells' \"Time Traveller\", these extra dimensions can be traveled by persons using the right equipment.\n\nPerhaps the most common use of the concept of a parallel universe in science fiction is the concept of hyperspace. Used in science fiction, the concept of \"hyperspace\" often refers to a parallel universe that can be used as a faster-than-light shortcut for interstellar travel. Rationales for this form of hyperspace vary from work to work, but the two common elements are:\n\nSometimes \"hyperspace\" is used to refer to the concept of additional coordinate axes. In this model, the universe is thought to be \"crumpled\" in some higher spatial dimension and that traveling in this higher spatial dimension, a ship can move vast distances in the common spatial dimensions. An analogy is to crumple a newspaper into a ball and stick a needle straight through, the needle will make widely spaced holes in the two-dimensional surface of the paper. While this idea invokes a \"new dimension\", it is not an example of a parallel universe. It \"is\" a more scientifically plausible use of hyperspace. (See wormhole.)\n\nWhile use of hyperspace is common, it is mostly used as a plot device and thus of secondary importance. While a parallel universe may be invoked by the concept, the nature of the universe is not often explored. So, while stories involving hyperspace might be the most common use of the parallel universe concept in fiction, it is not the most common source of fiction \"about\" parallel universes.\n\nParallel universes may be the backdrop to or the consequence of time travel, their most common use in fiction if the concept is central to the story. A seminal example of both is in Fritz Leiber's novel \"The Big Time\" where there's a war across time between two alternative futures manipulating history to create a timeline that results in or realizes their own world.\n\nTime travelers in fiction often accidentally or deliberately create alternative histories, such as in \"The Guns of the South\" by Harry Turtledove where the Confederate Army is given thousands of AK-47 rifles and ends up winning the American Civil War. (However, Ward Moore reversed this staple of alternative history fiction in his \"Bring the Jubilee\" (1953), where an alternative world where the Confederate States of America won the Battle of Gettysburg and the American Civil War is destroyed after a historian and time traveler from the defeated United States of that world travels back to the scene of the battle and, by inadvertently causing the death of the Confederate officer whose troops occupied Little Round Top, changes the result so that the Union forces are victorious.) The alternative history novel \"1632\" by Eric Flint explicitly states, albeit briefly in a prologue, that the time travelers in the novel (an entire town from West Virginia) have created a new and separate universe when they're transported into the midst of the Thirty Years' War in 17th century Germany. (This sort of thing is known as an ISOT among alternative history fans, after S. M. Stirling's \"Island in the Sea of Time\": an ISOT is when territory or a large group of people is transported back in time to another historical period or place.)\n\nOrdinarily, alternative histories are not technically parallel universes. The concepts are similar but there are significant differences. Where characters travel to the past, they may cause changes in the timeline (creating a point of divergence) that result in changes to the present. The alternative present will be similar in different degrees to the original present as would be the case with a parallel universe. The main difference is that parallel universes co-exist whereas only one history or alternative history can exist at any one moment. Another difference is that moving to a parallel universe involves some inter-dimensional travel whereas alternative histories involve some type of time travel. (However, since the future is only potential and not actual, it is often conceived that more than one future may exist simultaneously.)\n\nThe concept of \"sidewise\" time travel, a term taken from Murray Leinster's \"Sidewise in Time\", is often used to allow characters to pass through many different alternative histories, all descendant from some common branch point. Often worlds that are similar to each other are considered closer to each other in terms of this sidewise travel. For example, a universe where World War II ended differently would be \"closer\" to us than one where Imperial China colonized the New World in the 15th century. H. Beam Piper used this concept, naming it \"paratime\" and writing a series of stories involving the Paratime Police who regulated travel between these alternative realities as well as the technology to do so. Keith Laumer used the same concept of \"sideways\" time travel in his 1962 novel \"Worlds of the Imperium\". More recently, novels such as Frederik Pohl's \"The Coming of the Quantum Cats\" and Neal Stephenson's \"Anathem\" explore human-scale readings of the \"many worlds\" interpretation of quantum mechanics, postulating that historical events or human consciousness spawns or allows \"travel\" among alternative universes.\n\nUniverse 'types' frequently explored in sidewise and alternative history works include worlds whose Nazis won the Second World War, as in \"The Man in the High Castle\" by Philip K. Dick, \"SS-GB\" by Len Deighton, and \"Fatherland\" by Robert Harris, and worlds whose Roman Empire never fell, as in \"Roma Eterna\" by Robert Silverberg and \"Romanitas\" by Sophia McDougall. The novel \"Warlords of Utopia\" by Lance Parkin explored a multiverse in which the universes whose Rome never fell go to war with all those whose Nazis won World War II. It fits loosely in the Faction Paradox series initiated by Lawrence Miles, several of whose novels featured an artificially created universe existing within another; specifically, within a bottle. \"Dead Romance\" explored the consequences of inhabitants of the 'real' universe entering the Universe-in-a-Bottle.\n\nIn Philip Pullman's trilogy \"His Dark Materials\", the protagonist begins in a world that is a Victorian counterpart to ours, although it takes place at the same time. It also appears that the Protestant Reformation happened differently with John Calvin becoming the last Pope.\n\nThe concept of Counter-Earth is typically similar to that of parallel universes but is actually a distinct idea. A counter-earth is a planet that shares Earth's orbit but is on the opposite side of the Sun and, therefore, cannot be seen from Earth. There would be no necessity that such a planet would be like Earth in any way though typically in fiction; it is usually nearly identical to Earth. Since Counter-Earth is always within the universe (and the Solar System), travel to it can be accomplished with ordinary space travel.\n\nGerry and Sylvia Anderson used this concept in their 1969 movie \"Doppelgänger\" (released outside Europe as \"Journey to the Far Side of the Sun\"), in which a Counter-Earth is detected by astronomers and a manned mission launched by a US-European space consortium to explore it.\n\nConvergent evolution is a biological concept whereby unrelated species acquire similar traits because they adapted to a similar environment and/or played similar roles in their ecosystems. In fiction, the concept is extended whereby similar planets will result in races with similar cultures and/or histories.\n\nTechnically this is not a type of parallel universe since such planets can be reached via ordinary space travel, but the stories are similar in some respects. \"\" frequently explored such worlds:\n\n\nA similar concept in biology is gene flow. In this case, a planet may start as different from Earth, but due to the influence of Earth culture, the planet comes to resemble Earth in some way; technically this is not a type of parallel universe since such planets can be reached via ordinary space travel, but the stories are similar in some respects. \"Star Trek\" used this theory as well: in \"\", a planet is discovered that has become very similar to Nazi Germany due to the influence of a historian that came to reside there (believing that the Nazi fascism itself was not evil and under benevolent leadership could be \"good government\"), while in \"\", the \"Enterprise\" crew visits a planet that, 100 years after a book \"Chicago Mobs of the Twenties\" that had been left behind by previous Earth craft, their society resembles mob ruled cities of the Prohibition era United States.\n\nSimulated realities are digital constructs featured in science fiction such as \"The Matrix\".\n\nFantasy authors often want to bring characters from the author's (and the reader's) reality into their created world. Before the mid-20th century, this was most often done by hiding fantastic worlds within hidden parts of the author's own universe. Peasants who seldom if ever traveled far from their villages could not conclusively say that it was impossible that an ogre or other fantastical beings could live an hour away, but increasing geographical knowledge meant that such locations had to be farther and farther off. Characters in the author's world could board a ship and find themselves on a fantastic island, as Jonathan Swift does in \"Gulliver's Travels\" or in the 1949 novel \"Silverlock\" by John Myers Myers, or be sucked up into a tornado and land in Oz. These \"lost world\" stories can be seen as geographic equivalents of a \"parallel universe\", as the worlds portrayed are separate from our own, and hidden to everyone except those who take the difficult journey there. The geographic \"lost world\" can blur into a more explicit \"parallel universe\" when the fantasy realm overlaps a section of the \"real\" world, but is much larger inside than out, as in Robert Holdstock's novel \"Mythago Wood\". Madeleine L'engle, \"Wrinkle in Time\" series: characters go from the present time to places in the universe.\n\nAfter the mid-20th century, perhaps influenced by ideas from science fiction, perhaps because exploration had made many places on the map too clear to write \"Here there be dragons\", many fantasy worlds became completely separate from the author's world. A common trope is a portal or artifact that connects worlds together, prototypical examples being the wardrobe in C. S. Lewis' \"The Lion, the Witch and the Wardrobe\", or the sigil in James Branch Cabell's \"The Cream of the Jest\". In Hayao Miyazaki's \"Spirited Away\", Chihiro Ogino and her parents climb over a small stream into the spirit world. The main difference between this type of story and the \"lost world\" above, is that the fantasy realm can only be reached by certain people, or at certain times, or after following certain rituals, or with the proper artifact.\n\nIn some cases, physical travel is not even possible, and the character in our reality travels in a dream or some other altered state of consciousness. Examples include the \"Dream Cycle\" stories by H. P. Lovecraft or the \"Thomas Covenant\" stories of Stephen R. Donaldson. Often, stories of this type have as a major theme the nature of reality itself, questioning if the dream-world can have the same \"reality\" as the waking world. Science fiction often employs this theme (usually without the dream-world being \"another\" universe) in the ideas of cyberspace and virtual reality.\n\nMost stories in this mold simply transport a character from the real world into the fantasy world where the bulk of the action takes place. Whatever gate is used – such as the tollbooth in \"The Phantom Tollbooth\" by Norton Juster, or the mirror in Lewis Carroll's \"Through the Looking-Glass\" – is left behind for the duration of the story, until the end, and then only if the protagonists will return.\n\nHowever, in a few cases the interaction between the worlds is an important element, so that the focus is not on one world or the other, but on both, and their interaction. After Rick Cook introduced a computer programmer into a high fantasy world, his \"Wizardry\" series steadily acquired more interactions between this world and ours. In Aaron Allston's \"Doc Sidhe\" our \"grim world\" is paralleled by a \"fair world\" where the elves live and history echoes ours. A major portion of the plot deals with preventing a change in interactions between the worlds. Margaret Ball, in \"No Earthly Sunne\", depicts the interaction of our world with Faerie, and the efforts of the Queen of Faerie to deal with the slow drifting apart of Earth and Faerie. Poul Anderson depicts Hell as a parallel universe in \"Operation Chaos\", and the need to transfer equivalent amounts of mass between the worlds explains why a changeling is left for a kidnapped child. Interactions between magical and scientific universes, and the protagonists' attempts to restore and maintain the balance between them, are major plot points in Piers Anthony's \"Apprentice Adept\" series; he depicts two worlds, the \"SF\" planet Proton and the fantasy-based Phaze, such that every person born in either world has a physical duplicate on the other world. Only when one duplicate has died can the other cross between the worlds. Several of his \"Xanth\" novels also revolve around interactions between the magical realm of Xanth and \"Mundania\".\n\nMultiple worlds, rather than a pair, increase the importance of the relationships. In \"The Lion, the Witch and the Wardrobe\", there are only our world and Narnia, but in other of C. S. Lewis's works, there are hints of other worlds, and in \"The Magician's Nephew\", the Wood between the Worlds shows many possibilities, and the plot is governed by transportation between worlds, and the effort to right problems stemming from them. In His Dark Materials by Philip Pullman, the two protagonist Lyra and Will find themselves lost amongst many worlds, and travel them looking for the other. In Andre Norton's Witch World, begun with a man from Earth being transported to this world, gates frequently lead to other worlds – or come from them. While an abundance of illusions, disguises, and magic that repels attention make certain parts of Witch World look like parallel worlds, some are clearly parallel in that time runs differently in them, and such gates pose a repeated problem in Witch World. In the radio sitcom \"Undone\", the main character, Edna Turner, prevents people from a parallel version of London called \"Undone\" from moving to London and making the city too weird. There are other parallel versions of London, and one of the main plots in the series is the attempt by The Prince to unite all versions of London together. Travel between the manyworlds is the central conceit of Ian McDonald's \"Everness\", where the protagonist travels to a parallel London in a world without fossil fuels.\n\nLinking rooms of various types (not all actual rooms) can hook together any number of worlds. The characters may chose only one, but the choice is all important in determining the worlds.\n\nThe idea of a multiverse is as fertile a subject for fantasy as it is for science fiction, allowing for epic settings and godlike protagonists. Among the most epic and far-ranging fantasy \"multiverses\" is that of Michael Moorcock. Like many authors after him, Moorcock was inspired by the many worlds interpretation of quantum mechanics, saying: \nUnlike many science-fiction interpretations, Moorcock's \"Eternal Champion\" stories go far beyond alternative history to include mythic and sword and sorcery settings as well as some worlds more similar to our own. However, the Eternal Champion himself is incarnate in all of them.\n\nRoger Zelazny used a mythic cosmology in his \"Chronicles of Amber\" series. His protagonist is a member of the royal family of Amber, whose members represent a godlike pantheon ruling over a prototypical universe that represents Order. All other universes are increasingly distorted \"shadows\" of it, ending finally at the other extreme, Chaos, which is the complete negation of the prototype. Travel between these \"shadow\" universes is only possible by beings descended from the blood of this pantheon. Those \"of the blood\" can walk through Shadow, imagining any possible reality and then walk to it, making their environment more similar to their desire as they go. It is argued between the characters whether these \"shadows\" even exist before they're imagined by a member of the royal family of Amber, or if the \"shadows'\" existence can be seen as an act of godlike creation.\n\nIn the \"World of Tiers\" novels by Philip José Farmer, the idea of godlike protagonists is even more explicit. The background of the stories is a multiverse where godlike beings have created a number of pocket universes that represent their own desires. Our own world is part of this series, but our own universe is revealed to be much smaller than it appears, ending at the edge of the Solar System.\n\nThe term 'polycosmos' was coined as an alternative to 'multiverse' by the author and editor Paul le Page Barnett, best known by the pseudonym John Grant, and is built from Greek rather than Latin morphemes. It is used by Barnett to describe a concept binding together a number of his works, its nature meaning that \"all characters, real or fictional [...] have to co-exist in all possible real, created or dreamt worlds; [...] they're playing hugely different roles in their various manifestations, and the relationships between them can vary quite dramatically, but the essence of them remains the same.\"\n\nThere also are multiverses in the Warcraft universe, \"The Chronicles of Narnia\", Terry Pratchett's \"Discworld\" series, and Diana Wynne Jones's \"Chrestomanci\", \"Howl's Moving Castle\" and \"Deep Secret\" books and standalone book \"A Sudden Wild Magic\".\n\nThere are many examples of the meta-fictional idea of having the author's created universe (or any author's universe) rise to the same level of \"reality\" as the universe we're familiar with. The theme is present in works as diverse as H.G. Wells' \"Men Like Gods\", Myers' \"Silverlock\", and Heinlein's \"Number of the Beast\". Fletcher Pratt and L. Sprague de Camp took the protagonist of the Harold Shea series through the worlds of Norse myth, Edmund Spenser's \"The Faerie Queene\", Ludovico Ariosto's \"Orlando Furioso\", and the \"Kalevala\" – without ever quite settling whether writers created these parallel worlds by writing these works, or received impressions from the worlds and wrote them down. In an interlude set in \"Xanadu\", a character claims that the universe is dangerous because the poem went unfinished, but whether this was his misapprehension or not is not established.\n\nSome fictional approaches definitively establish the independence of the parallel world, sometimes by having the world differ from the book's account; other approaches have works of fiction create and affect the parallel world: L. Sprague de Camp's \"Solomon's Stone\", taking place on an astral plane, is populated by the daydreams of mundane people, and in Rebecca Lickiss's \"Eccentric Circles\", an elf is grateful to Tolkien for transforming elves from dainty little creatures. These stories often place the author, or authors in general, in the same position as Zelazny's characters in Amber. Questioning, in a literal fashion, if writing is an act of creating a new world, or an act of discovery of a pre-existing world.\n\nOccasionally, this approach becomes self-referential, treating the literary universe of the work itself as explicitly parallel to the universe where the work was created. Stephen King's seven-volume \"Dark Tower\" series hinges upon the existence of multiple parallel worlds, many of which are King's own literary creations. Ultimately the characters become aware that they are only \"real\" in King's literary universe (this can be debated as an example of breaking the fourth wall), and even travel to a world – twice – in which (again, within the novel) they meet Stephen King and alter events in the real Stephen King's world outside of the books. An early instance of this was in works by Gardner Fox for DC Comics in the 1960s, in which characters from the Golden Age (which was supposed to be a series of comic books within the DC Comics universe) would cross over into the main DC Comics universe. One comic book did provide an explanation for a fictional universe existing as a parallel universe. The parallel world does \"exist\" and it resonates into the \"real world.\" Some people in the \"real world\" pick up on this resonance, gaining information about the parallel world which they then use to write stories.\n\nRobert Heinlein, in \"The Number of the Beast\", quantizes the many parallel fictional universes - in terms of \"fictons\". A number of fictional universes are accessible along one of the three axes of time which Dr. Jacob Burroughs' \"time twister\" can access. Each quantum level change - a \"ficton\" - along this time axis corresponds to a different universe from one of several bodies of fiction known to all four travellers in the inter-universal, time travelling vehicle \"Gay Deceiver\". Heinlein also \"breaks the fourth wall\" by having \"both Heinleins\" (Robert and his wife Virginia) visit an inter-universal science-fiction and fantasy convention in the book's last chapter. The convention was convened on Heinlein character Lazarus Long's estate on the planet \"Tertius\" to attract the evil \"Black Hats\" who pursued the main characters of \"The Number of the Beast\" through space and time in order to destroy Dr. Burroughs and his invention. Heinlein continues this literary conceit in \"The Cat Who Walks Through Walls\" and \"To Sail Beyond the Sunset\", using characters from throughout his science-fictional career, hauled forth from their own \"fictons\" to unite in the war against the \"Black Hats.\"\n\nHeinlein also wrote a stand-alone novel, \"\", whose two protagonists fall from alternative universe into alternative universe (often naked), and after a number of such adventures die and enter a stereotypically Fundamentalist Christian Heaven (with many of its internal contradictions explored in the novel). Their harrowing adventures through the universes are then revealed to have been \"destruction testing\" of their souls by Loki, sanctioned by the Creator person of the Christian God (Yahweh). The Devil appears as the most sympathetic of the gods in the story, who expresses contempt for the other gods' cavalier treatment of the story's main characters.\nThus, \"\" rings in the theological dimension (if only for the purpose of satirizing evangelical Christianity) of parallel universes, that their existence can be used by God (or a number of gods, Loki seems to have made himself available to do Yahweh's dirty work in this novel). It manages also to have a fictional multiverse angle in that references are made to Heinlein's early SF/fantasy short story \"They,\" a solipistic tale in which reality is constantly being transmogrified behind the scenes to throw the central character off his guard and keep him from seeing reality as it is, which was set in the same Heinlein fictional universe as \"The Moon is a Harsh Mistress\".\n\nElfland, or Faerie, the otherworldly home not only of elves and fairies but goblins, trolls, and other folkloric creatures, has an ambiguous appearance in folklore.\n\nOn one hand, the land often appears to be contiguous with 'ordinary' land. Thomas the Rhymer might, on being taken by the Queen of Faerie, be taken on a road like one leading to Heaven or Hell.\n\nThis is not exclusive to English or French folklore. In Norse mythology, Elfland (Alfheim) was also the name of what today is the Swedish province of Bohuslän. In the sagas, it said that the people of this petty kingdom were more beautiful than other people, as they were related to the elves, showing that not only the territory was associated with elves, but also the race of its people.\n\nWhile sometimes folklore seems to show fairy intrusion into human lands – \"Tam Lin\" does not show any otherworldly aspects about the land in which the confrontation takes place – at other times the otherworldly aspects are clear. Most frequently, time can flow differently for those trapped by the fairy dance than in the lands they come from; although, in an additional complication, it may only be an appearance, as many returning from Faerie, such as Oisín, have found that time \"catches up\" with them as soon as they have contact with ordinary lands.\n\nFantasy writers have taken up the ambiguity. Some writers depict the land of the elves as a full-blown parallel universe, with portals the only entry – as in Josepha Sherman's Prince of the Sidhe series or Esther Friesner's \"Elf Defense\" – and others have depicted it as the next land over, possibly difficult to reach for magical reasons – Hope Mirrlees's \"Lud-in-the-Mist\", or Lord Dunsany's \"The King of Elfland's Daughter\". In some cases, the boundary between Elfland and more ordinary lands is not fixed. Not only the inhabitants but Faerie itself can pour into more mundane regions. Terry Pratchett's \"Discworld\" series proposes that the world of the Elves is a \"parasite\" universe, that drifts between and latches onto others such as Discworld and our own world (referred to as \"Roundworld\" in the novels). In the young teenage book \"Mist\" by Kathryn James, the Elven world lies through a patch of mist in the woods. It was constructed when the Elven were thrown out of our world. Travel to and fro is possible by those in the know, but can have lethal consequences.\n\nIsekai, is a subgenre of Japanese fantasy light novels, manga, anime, and video games revolving around a normal person being transported to or trapped in a parallel universe. Often, this universe already exists in the protagonist's world as a fictional universe, but it may also be unbeknownst to them.\n\nThe most famous treatment of the alternative universe concept in film could be considered \"The Wizard of Oz\", which portrays a parallel world, famously separating the magical realm of the Land of Oz from the mundane world by filming it in Technicolor while filming the scenes set in Kansas in sepia. At times, alternative universes have been featured in small scale independent productions such as Kevin Brownlow and Andrew Mollo's \"It Happened Here\" (1964), featuring an alternative United Kingdom which had undergone Operation Sea Lion in 1940 and had been defeated and occupied by Nazi Germany. It focused on moral questions related to the professional ethics of Pauline, a nurse forced into Nazi collaboration.\n\nAnother common use of the theme is as a prison for villains or demons. The idea is used in the first two \"Superman\" movies starring Christopher Reeve where Kryptonian villains were sentenced to the Phantom Zone from where they eventually escaped. An almost exactly parallel use of the idea is presented in the campy cult film \"The Adventures of Buckaroo Banzai Across the 8th Dimension\", where the \"8th dimension\" is essentially a \"phantom zone\" used to imprison the villainous Red Lectroids. Uses in horror films include the 1986 film \"From Beyond\" (based on the H. P. Lovecraft story of the same name) where a scientific experiment induces the experimenters to perceive aliens from a parallel universe, with bad results. The 1987 John Carpenter film \"Prince of Darkness\" is based on the premise that the essence of a being described as Satan, trapped in a glass canister and found in an abandoned church in Los Angeles, is actually an alien being that is the 'son' of something even more evil and powerful, trapped in another universe. The protagonists accidentally free the creature, who then attempts to release his \"father\" by reaching in through a mirror.\n\nSome films present parallel realities that are actually different contrasting versions of the narrative itself. Commonly this motif is presented as different points of view revolving around a central (but sometimes unknowable) \"truth\", the seminal example being Akira Kurosawa's \"Rashomon\". Conversely, often in film noir and crime dramas, the alternative narrative is a fiction created by a central character, intentionally – as in \"The Usual Suspects\" – or unintentionally – as in \"Angel Heart\". Less often, the alternative narratives are given equal weight in the story, making them truly alternative universes, such as in the German film \"Run Lola Run\", the short-lived British West End musical \"Our House\" and the British film \"Sliding Doors\".\n\nMore recent films that have explicitly explored parallel universes are: the 2000 film \"The Family Man\", the 2001 cult movie \"Donnie Darko\", which deals with what it terms a \"tangent universe\" that erupts from our own universe; \"Super Mario Bros.\" (1993) has the eponymous heroes cross over into a parallel universe ruled by humanoids who evolved from dinosaurs; \"The One\" (2001) starring Jet Li, in which there is a complex system of realities in which Jet Li's character is a police officer in one universe and a serial killer in another, who travels to other universes to destroy versions of himself, so that he can take their energy; and \"\" (2004), the main character runs away from a totalitarian nightmare, and he enters into a cyber-afterlife alternative reality. The current \"Star Trek\" films are set in an alternative universe created by the first film's villain traveling back in time, thus allowing the franchise to be rebooted without affecting the continuity of any other \"Star Trek\" film or show. The 2011 science-fiction thriller \"Source Code\" employs the concepts of quantum reality and parallel universes. The characters in \"The Cloverfield Paradox\", the third installment of the franchise, accidentally create a ripple in the time-space continuum and travel into an alternate universe, where the monster and the events in the first film transpired. Disney has also experimented with this through some of their animated films such as \"Robin Hood\", \"A Goofy Movie\", \"Chicken Little\" and \"Zootopia\", where anthropomorphic animals take on the role of (in this case, nonexistent) humans and emulating the latter's characteristics, without abandoning their hereditary own.\n\nThe idea of parallel universes have received treatment in a number of television series, usually as a single story or episode in a more general science fiction or fantasy storyline.\n\nThe 1990s TV series \"Sliders\" depicts a group of adventurers visiting assorted parallel universes, as they attempt to find their \"home\" universe. Included in the 1st season is a universe where the world is stuck in the ice age, with no life anywhere. Another episode includes 'Honest Abe' never to be president, in which the United States loses World War I and World War II, and they are controlled by a senator, and technology is at an all-time low.\n\nOne of the earliest television plots to feature parallel time was a 1970 storyline on soap opera \"Dark Shadows\". Vampire Barnabas Collins found a room in Collinwood which served as a portal to parallel time, and he entered the room in order to escape from his current problems. A year later, the show again traveled to parallel time, the setting this time being 1841.\n\nA well known and often imitated example is the original \"\" episode entitled \"\". The episode introduced an alternative version of the \"Star Trek\" universe where the main characters were barbaric and cruel to the point of being evil. When the parallel universe concept is parodied, the allusion is often to this \"Star Trek\" episode. A previous episode for the \"Trek\" series first hinted at the potential of differing reality planes (and their occupants), titled \"The Alternative Factor\". A mad scientist from \"our\" universe, named Lazarus B., hunts down the sane Lazarus A.; resident of an antimatter-comprised continuum. His counterpart, in a state of paranoia, claims the double threatens his and the very cosmos' existence. With help from Captain Kirk, A traps B along with him in a \"anti\"-universe, for eternity, thus bringing balance to both matter oriented realms. A similar plot was used in the \"Codename: Kids Next Door\" episode Operation: P.O.O.L..\n\nThe mirror universe of \"Star Trek\" was further developed by later series in the franchise. In several episodes of \"\", the later evolution of the mirror universe is explored. A two-part episode of \"\", entitled \"In a Mirror, Darkly\", serves as a prequel, introducing the early developments of the Mirror Universe.\n\nIn the 1970s young adult British SF series The Tomorrow People, its second-season episode, \"A Rift in Time\" (March–April 1974) pitted the three telepath core characters and allies against time travelling interlopers from an alternative history where the Roman Empire developed the steam engine in the first century CE, had a technological headstart, did not fragment during the fifth century and underwent accelerated technological development. The Roman eagle standard was planted on the Moon in the fifth century and by its alternative twentieth century, it had mastered interstellar travel, had a galactic empire and time travel. Consequently, the Tomorrow People had to rectify this aberrant timeline by dismantling and disabling the anomalous steam engine.\n\nMultiple episodes of \"Red Dwarf\" use the concept. In \"Parallel Universe\" the crew meet alternative versions of themselves: the analogues of Lister, Rimmer and Holly are female, while the Cat's alternative is a dog. \"Dimension Jump\" introduces a heroic alternative Rimmer, a version of whom reappears in \"Stoke Me a Clipper\". The next episode, \"Ouroboros\", makes contact with a timeline in which Kochanski, rather than Lister, was the sole survivor of the original disaster; this alternative Kochanski then joins the crew for the remaining episodes.\n\n\"Buffy the Vampire Slayer\" experienced a Parallel universe where she was a mental patient in \"Normal Again\" and not really \"The Slayer\" at all. In the end, she has to choose between a universe where her mother and father are together and alive (mother) or one with her friends and sister in it where she has to fight for her life daily. In The Wish (Buffy the Vampire Slayer), Cordelia Chase inadvertently created a dystopian alternative reality in which Buffy had never moved from LA to Sunnydale. Her core-universe allies Xander Harris and Willow Rosenberg had become vampires in that timeline.\n\nThe plot of the season four episode of \"Charmed\", entitled \"Brain Drain\", features The Source of All Evil kidnapping Piper Halliwell and forcing her into a deep coma, where she experiences an alternative reality in which the Halliwell manor is actually a mental institution. She and her sisters serve as patients in this universe, their powers only a manifestation of their minds, a ruse put up to trick Piper into willingly relinquishing the sisters' magic.\n\nThe animated series, \"Futurama\", had an episode where the characters travel between \"Universe 1\" and \"Universe A\" via boxes containing each universe; and one of the major jokes is an extended argument between the two sets of characters over which set were the \"evil\" ones.\n\nThe idea of a parallel universe and the concept of déjà vu was a major plot line of the first-season finale of \"Fringe\", guest-starring Leonard Nimoy of \"\". The show has gone on to feature the parallel universe prominently.\n\nIn the 2010 season of \"Lost\", the result of characters traveling back in time to prevent the crash of Oceanic Flight 815 apparently creates a parallel reality in which the Flight never crashed, rather than resetting time itself in the characters' original timeline. The show continued to show two \"sets\" of the characters following different destinies, until it was revealed in the series finale that there was really only one reality created by the characters themselves to assist themselves in leaving behind the physical world and passing on to an afterlife after their respective deaths.\n\nIn the anime and manga series of \"Dragon Ball Z\", in the Androids Saga, Future Trunks returns to the past to give Goku medicine to prevent him from dying of a heart disease and warns him of the Androids, in the process creating parallel realities, leading to the appearance of Cell, who killed the same Future Trunks from a different splitting timeline to come back to the main timeline when the Androids are still alive for him to absorb. The Majin Buu Saga later depicts Kaio-Shin Realms and the Afterlife. Its sequel, \"Dragon Ball Super\", later features separate universes that are in pairs whose numbers add up to the total number of the universe: 13 in this case. Previously there were 18 universes, but Zen'o (the supreme ruler of the Dragon Ball Multiverse) destroyed 6 of them in a rage. Previously, Daizenshuu 7 stated that the typical Dragon Ball Universe had only 4 galaxies, but \"Dragon Ball Super\" effectively retcons this, where Whis says that the universe contains endless galaxies.\n\nThe anime \"Turn A Gundam\" attempted to combine all the parallel Gundam universes (other incarnations of the series, with similar themes but differing stories and characters, that had played out at different times since the debut of the concept in the 1970s) of the metaseries into one single reality.\n\nThe anime and manga series \"\" takes place in a parallel universe that is different from the one in the series' predecessor \"Eureka Seven\". The \"E7\" series started off in the year 12005, and the \"AO\" world, which takes place in the year 2025, would be the home of the two main characters' son.\n\nThe anime and manga series \"Katekyo Hitman Reborn!\" by Akira Amano features this idea in its third main arc, known as Future arc.\n\nThe anime \"Neon Genesis Evangelion\" features a parallel world in one of the final episodes. This parallel world is a sharp contrast to the harsh, dark \"reality\" of the show and presents a world where all the characters enjoy a much happier life. This parallel world would become the basis for the new Evangelion manga series \"\".\n\nThe anime series \"Bakugan\" features a parallel universe called Vestroia and is the homeworld of fantastic creatures called Bakugan. The series' hero Dan Kuso alongside his friends and teammates must save Earth and Vestroia from total destruction. Season 2 & 3 feature another universe where Dan and his team save the day. They go to another dimension or universe through a pathway. The other universe has also other life forms and other types of technology.\n\nIn another anime series, \"Digimon\", there is parallel universe called \"digital world\". The show's child protagonists meet digital monsters, or digimon, from this world and becomes partners and friends. In the third story arc of \"Digimon Fusion\", the Clockmaker (who is later revealed to be Bagramon) and his partner Clockmon travel through space-time to recruit heroes from previous series so they can help the Fusion Fighters to defeat Quartzmon before DigiQuartz can absorb each human and digital world in the multiverse.\n\nIn the anime series \"Umineko no Naku Koro ni\" the rounds of the battle between Battler and Beatrice take place in different dimensions, in order to show all kinds of possibilities (much to Battler's dismay) also the character Bernkastel is known for her ability to travel into different worlds by the usage of \"fragments\".\n\nIn the \"\" episode \"\", Lt. Worf traveled to several parallel universes when his shuttlecraft went through a time space fissure.\n\nThe \"Community\" episode Remedial Chaos Theory, six different timelines and one \"prime\" timeline are explored, each having a different outcome based on which member of the study group goes to get the pizza. One timeline, dubbed the \"Darkest Timeline\", results in the greatest amount of terrible incidents and ends with Abed donning a felt goatee bearing resemblance to Spock's in \"Mirror, Mirror\".\n\nIn the 2003 anime series of \"Fullmetal Alchemist\", there exists a gateway that can be conjured by alchemists that acts as a source of all knowledge and energy; towards the end of the series, it is revealed that this gateway connects the world of the anime with the real world, set during the first decades of the 20th century. It is revealed that the two worlds shared a common history until their histories diverged, apparently due to the success of alchemy in one world and that of modern physics in the other.\n\nSometimes a television series will use parallel universes as an ongoing subplot. \"\", \"\" and \"\" elaborated on the premise of the original series' \"Mirror\" universe and developed multi-episode story arcs based on the premise. Other examples are the science fiction series \"Stargate SG-1\", the fantasy/horror series \"Buffy the Vampire Slayer\", \"Supernatural\" and the romance/fantasy \"\".\n\nFollowing the precedent set by \"Star Trek\", these story arcs show alternative universes that have turned out \"worse\" than the \"original\" universe: in \"Stargate SG-1\" the first two encountered parallel realities featured Earth being overwhelmed by an unstoppable Goa'uld onslaught; in \"Buffy\", two episodes concern a timeline in which Buffy came to Sunnydale too late to stop the vampires from taking control; \"Lois & Clark\" repeatedly visits an alternative universe where Clark Kent's adoptive parents, Jonathan and Martha Kent, died when he was ten years of age, and Lois Lane is also apparently dead. Clark eventually becomes Superman, with help from the \"original\" Lois Lane, but he is immediately revealed as Clark Kent and so has no life of his own.\n\nIn addition to following \"Star Trek's\" lead, showing the \"evil\" variants of the main storyline gives the writers an opportunity to show what is at stake by portraying the worst that could happen and the consequences if the protagonists fail or the importance of a character's presence.\n\n\"Once Upon a Time\" often talks about alternative realms or universes in which all different forms of magic, and non-magic may occur, depending on the realm. According to the Mad Hatter (Sebastian Stan), they \"touch each other in a long line of lands, each just as real as the last.\" He referred to our world's tendency to deny such things as arrogant.\n\nIn the season 1 finale of \"The Flash\", the Reverse-Flash opens a singularity that connects his world to a parallel universe called Earth-2. In the second season, The Flash starts facing villains from that earth who also have doppelgangers on Prime Earth sent by Zoom. The array of Earth-2 villains consists of Atom Smasher, Sand Demon, King Shark, and Dr. Light; all are sent by Zoom to kill The Flash with the assurance of being taken back home. However, they are not the only ones who arrive from the singularity; this also includes the Earth-2 Flash after a close death and loss of speed from a confrontation with Zoom. When the Earth-2 Flash (called Jay Garrick) introduces himself to Team Flash, Barry (The Flash) distrusts him at first and places him in the metahuman pipeline at S.T.A.R. Labs. When The Flash starts having a hard time facing off against Sand Demon, he frees Jay so that he could help him as well as train him in his speed. With a new trick taught by Jay, Barry defeats Sand Demon. Later on, the Earth-2 counterpart of the Reverse-Flash, Harrison Wells, arrives in Prime Earth as well. He steals a weapon from Mercury Labs and saves Barry from the Earth-2 King Shark. When Jay confronts and sees Wells again, the argument gets heated between them before Barry intercedes.\n\nThe \"Alf Stewart Rape Dungeon\" series, created by artist Mr Doodleburger, uses footage from the Australian TV drama show Home and Away, but through the use of clever overlaid audio tracks, casts one of the main characters of the show, long running character Alf Stewart as a vicious violent character in a parallel version of Home and Away. \"see main article\" Alf Stewart Rape Dungeon Series\n\nThere have been a few series where parallel universes were central to the series itself.\n\nParallel universes in modern comics have become particularly rich and complex, in large part due to the continual problem of continuity faced by the major two publishers, Marvel Comics and DC Comics. The two publishers have used the multiverse concept to fix problems arising from integrating characters from other publishers into their own canon, and from having major serial protagonists having continuous histories lasting, as in the case of Superman, over 70 years. Additionally, both publishers have used new alternative universes to re-imagine their own characters. (See \"Multiverse (DC Comics)\" and \"Multiverse (Marvel Comics)\")\n\nDC Comics inaugurated its multiverse in the early 1960s, with the reintroduction of Golden Age superheroes the Justice Society of America now located on Earth-Two, and devised a \"mirror universe\" scenario of inverted morality and supervillain domination of Earth-Three shortly afterward, several years before \"\" devised its own darker alternative universe. There was a lull before DC inaugurated additional alternative universes in the seventies, such as Earth-X, where there was an Axis victory in World War II, Earth-S, home to the Fawcett Comics superheroes of the forties and fifties, such as Captain Marvel, and Earth-Prime, where superheroes only existed in fictional forms.\n\nTherefore, comic books in general are one of the few entertainment mediums where the concept of parallel universes are a major and ongoing theme. DC in particular periodically revisits the idea in major crossover storylines, such as \"Crisis on Infinite Earths\" and \"Infinite Crisis\", where Marvel has a series called \"What If...\" that's devoted to exploring alternative realities, which sometimes impact the \"main\" universe's continuity. DC's version of \"What If...\" is the Elseworlds imprint.\n\nDC Comics series \"52\" heralded the return of the Multiverse. \"52\" was a mega-crossover event tied to \"Infinite Crisis\" which was the sequel to the 1980s \"Crisis on Infinite Earths\". The aim was to yet again address many of the problems and confusions brought on by the Multiverse in the DCU. Now 52 Earths exist and including some Elseworld tales such as \"Kingdom Come\", DC's imprint WildStorm and an Earth devoted to the Charlton Comics heroes of DC. \"Countdown\" and \"Countdown Presents: The Search for Ray Palmer\" and the \"Tales of the Multiverse\" stories expand upon this new Multiverse.\n\nMarvel has also had many large crossover events which depicted an alternative universe, many springing from events in the X-Men books, such as 1981's \"Days of Future Past\", 1995's \"Age of Apocalypse\", and 2006's \"House Of M\". In addition the Squadron Supreme is a DC inspired Marvel Universe that has been used several times, often crossing over into the mainstream Universe in the Avengers comic. Exiles is an offshoot of the \"X-Men\" franchise that allows characters to hop from one alternative reality to another, leaving the original, main Marvel Universe intact. The Marvel UK line has long had multiverse stories including the Jaspers' Warp storyline of Captain Britain's first series (it was here that the designation Earth-616 was first applied to the mainstream Marvel Universe).\n\nMarvel Comics, as of 2000, launched their most popular parallel universe, the Ultimate Universe. It is a smaller subline to the mainstream titles and features Ultimate Spider-Man, Ultimate X-Men, Ultimate Fantastic Four and the Ultimates (their \"Avengers\").\n\nThe graphic novel Watchmen is set in an alternative history, in a 1985 where superheroes exist, the Vietnam War was won by the United States, and Richard Nixon is in his fifth term as President of the United States. The Soviet Union and the United States are still locked in an escalating \"Cold War\" as in our own world, but as the Soviet Union invades Afghanistan in this world and threatens Pakistan, nuclear war may be imminent.\n\nIn 1973, Tammy published \"The Clock and Cluny Jones\", where a mysterious grandfather clock hurls bully Cluny Jones into a harsh alternative reality where she becomes the bullied. This story was reprinted in Misty annual 1985 as \"Grandfather's Clock.\"\n\nIn 1978, Misty published \"The Sentinels\". The Sentinels were two crumbling apartment blocks that connected the mainstream world with an alternative reality where Hitler conquered Britain in 1940.\n\nIn 1981, Jinty published \"Worlds Apart.\" Six girls experience alternative worlds ruled by greed, sports-mania, vanity, crime, intellectualism, and fear. These are in fact their dream worlds becoming real after they are knocked out by a mysterious gas from a chemical tanker that crashed into their school. In 1977 Jinty also published \"Land of No Tears\" where a lame girl travels to a future world where people with things wrong with them are cruelly treated, and emotions are banned.\n\nThe parallel universe concept has also appeared prominently in the \"Sonic the Hedgehog\" comic series from Archie Comics. The first and most oft-recurring case of this is another \"mirror universe\" where Sonic and his various allies are evil or anti-heroic while the counterpart of the evil Dr. Robotnik is good. Another recurring universe featured in the series is a perpendicular dimension that runs through all others, known as the No Zone. The inhabitants of this universe monitor travel between the others, often stepping in with their Zone Cop police force to punish those who travel without authorization between worlds.\n\nIn more recent years, the comic has adapted the alternative dimension from the video games Sonic Rush and Sonic Rush Adventure, home to Sonic's ally Blaze the Cat. The continuities seen in various other Sonic franchises also exist in the comic, most notably those based on the cartoon series Sonic Underground and Sonic X. For some years, a number of other universes were also featured that parodied various popular franchises, such as Sailor Moon, Godzilla, and various titles from Marvel Comics. Archie has also used this concept as the basis for crossovers between Sonic and other titles that they publish, including Sabrina the Teenage Witch and Mega Man.\n\nThe various Transformers comics also feature the parallel universe concept, and feature the various continuities from different branches of the franchise as parallel worlds that occasionally make contact with each other. Quite notably, the annual Botcon fan convention introduced a comic storyline that featured Cliffjumper, an Autobot from the original Transformers series, entering an alternative universe where his fellow Autobots are evil and the Decepticons are good. This universe is known as the \"Shattered Glass\" universe, and continued on in comics and text based stories after its initial release.\n\nIn \"\" after the main protagonist, Link, defeats the dark lord, Ganon, he travels back in time to his childhood. This results in two alternative histories for Hyrule. In one a younger version Link travels to the land of Termina in \"\". In the other Link is no longer present allowing Ganon to return to go on a rampage that forced the gods of Hyrule to flood the world in \"\". There is also a scenario in which Link is killed by Ganon in the final battle, resulting in an alternative history in which Hyrule is put in an era of decline, leading to the events of \"\".\n\nIn the 1992 psychological horror point-and-click adventure game \"Dark Seed\", the main character Mike Dawson discovers a parallel universe by going through his living room mirror.\n\nThe Kingdom Hearts series features a Disney/Square Enix's Final Fantasy multiverse, in which various worlds are based on Disney films or concepts from the Final Fantasy line. The series also introduces the concepts of different \"Realms\" corresponding to Light, Darkness, Twilight, and Nothingness.\n\nIn the 1999 role-playing game \"Outcast\", a probe is sent to a parallel universe and is attacked by an \"entity\". Cutter Slade must escort a team of scientists across to the other world in order to retrieve and repair the damaged probe before the earth is consumed by a black hole.\n\nThe \"Half-Life\" series revolves heavily around alternate universes. Xen is a location in the first Half-Life game, accidentally discovered by scientists and described as a border world between dimensions, where the player must travel to stop an alien invasion. Half-Life 2 features a multidimensional empire called The Combine which has successfully conquered Earth and subdued humanity, among countless other universes and species.\n\nIn the survival horror video game series \"Silent Hill\", the town of Silent Hill fluctuates between the real world, where Silent Hill is seemingly just an ordinary tourist town, the Fog World, which is like the real world, except the town is shrouded in thick fog and is nearly uninhabited except for monsters and a few people, and a dark and dilapidated version of the town called the \"Other World\".\n\nIn the 1993 adventure PC game \"Myst\", the unnamed protagonist travels to multiple alternative worlds through the use of special books, which describe a world within and transport the user to that world when a window on the front page is touched.\n\nIn the 1996 adventure PC game \"\", after resolving several mind-blowing and unique puzzles, the player gets past \"The Tiki Guards\"; and a door opens up to \"The Void\" - actually a room to another universe, which houses the entirety of space.\n\nBoth titles of the \"When They Cry\" visual novel series (\"Higurashi\" and \"Umineko\" for short) contain the concept of parallel worlds. These series both involve some kind of murder mystery. As soon as the main character has 'lost', another parallel world, called a Fragment, is chosen to be observed. This continues until the entire mystery is solved.\n\n\"EarthBound\" features many areas of the game that can be considered alternative dimensions. The first is an illusion created by the Mani Mani Statue that transforms the metropolis of Fourside into a bizarre neon metropolis called Moonside, filled with unusual characters and enemies. The second is Magicant, the world of Ness's subconscious that is accessed after obtaining the Eight Melodies. Finally, toward the end of the game, the protagonists arrive at the Cave to the Past, where they travel back in time to the haunting past dimension of the cave to face Giygas.\n\n\"Super Mario Bros. 2\" features a \"Magic Potion\" item that when used, creates a doorway allowing the player to temporarily access \"Subspace\"; a mirrored silhouette version of the world where items can be found.\n\nAfter the completion of the Special World in \"Super Mario World\", the overworld transforms from a green-colored springtime to an orange-colored autumnal setting. Many enemies encountered in the game are transformed into bizarre counterparts.\n\n\"Super Mario 64\" features a world called \"Tiny Huge Island\" which has two variants: one scaled up, the other scaled down. The player can only access certain parts of the level to obtain certain stars depending on which variant they are into. The two variants can be switched between via portals in the world.\n\n\"Banjo-Kazooie\" features a world called \"Click Clock Wood\", which has spring, summer, autumn and winter variants. The environment develops between the seasons making some areas accessible or inaccessible, and actions taken in one season affect the outcome in others.\n\n\"\" features a dark and twisted parallel version of Hyrule called the \"Dark World\".\n\n\"\" use a similar concept to that which is used in \"\". In those games, the player must switch between the parallel past and present worlds (Ages) and between spring, summer, autumn and winter (Seasons) to progress through the game.\n\nIn the first half of \"\", areas of Hyrule are veiled by the Twilight Realm. These areas are dusky and brooding in appearance, Link cannot transform out of wolf form, characters only appear as spirits that cannot be communicated with, and enemies are twilight variations of their regular forms. Otherwise, the Twilight Realm is identical to regular Hyrule.\n\nEach Zone in \"Sonic CD\" has four variations: Past, Present, Bad Future and Good Future, each displaying some subtle and not-so subtle alterations. The series has also seen alternative dimensions in the case of the \"Sonic Rush\" series, in which Sonic encounters a hero from another world named Blaze the Cat whose nemesis is an alternative counterpart of his own foe, Dr. Eggman. The \"Sonic\" series also makes use of the concept of alternative timelines.\n\nThe story of \"Chrono Cross\" centers around travel between two alternative timelines, the original or \"Another World\" and \"Home World\" which is a branch created by the actions of the heroes of the game's predecessor, \"Chrono Trigger\".\n\nIn \"Super Paper Mario\", the town \"Flipside\" (which acts as the game's central hub) has an alternative mirrored version called \"Flopside\". While Flipside appears pristine and the residents there are typically cheerful, Flopside appears somewhat dilapidated and is populated by surly characters.\n\nThe series \"Legacy of Kain\" is played through several realms and timelines.\n\n\"Sudeki\" is set in a realm of light and a parallel realm of darkness.\n\n\"\" features an alternative hellish world called \"Oblivion\", as well as a painting you can climb into and a quest where you enter a dream world.\n\n\"\" takes place in Termina, a parallel world to Hyrule. Almost all of the characters from The Legend of Zelda: Ocarina of Time reappear in the game.\n\n\"The Darkness\" pivots around a world of darkness you travel to when you die, which is occupied by World War 1 soldiers.\n\n\"\" involves a world, \"Aether\", having an alternative self in the, \"Dark\" realm, universe, or dimension. The protagonist, Samus, finds out that she just dropped into a hopeless war for the Luminoth, the dominant species of Light Aether against the Ing, the dominant species of Dark Aether. She also finds her counterpart, Dark Samus or Metroid Prime's essence inside Samus's Phazon Suit.\n\n\"Crash Twinsanity\" features Crash, Cortex, and Nina traveling to the \"10th dimension,\" which could also be a parallel universe (suggested by the theme and how everything seems to be opposite).\n\n\"Minecraft\" features an alternative dimension called \"The Nether\", that includes a 'hell' like theme. It also contains a second alternative dimension called \"The End\", home world of the Endermen, a type of monster that spawns rarely in the main world.\n\n\"\" takes place in an alternative universe called \"This Side\" where in the events of Innocent Sin did not take place and the characters have never met in the past.\n\nThe \"Fallout\" series takes place in a subtly different universe. For example, the ship that landed the first men on the moon in 1969 is called \"Valiant 11\", rather than Apollo 11. This universe diverged from ours after World War II, which resulted in a lack of advanced computers, the Cold War, VHS, etc.\n\nThe MMORPG \"City of Heroes\" features a Player vs Player (PvP) zone called Recluse's Victory. It is an alternative future in a constant state of flux, as heroes and villains battle for the future of Earth.\n\nIn the text-based science fiction MMORPG \"OtherSpace\", refugees from Earth's universe were forced to migrate to a parallel universe called \"Hiverspace\", whose quantum divergence occurred billions of years in the past, after damage to the time/space continuum began to tear their own universe apart. Eventually, they were able to find a means back to a past universe whose quantum divergence from their original ones was relatively minor.\n\n2011 action-adventure video game \"Portal 2\" features a game-mode entitled \"Perpetual Testing Initiative\" (PeTI), where a plot item features protagonist \"Bendy\" through thousands of different worlds of which character Cave Johnson exist in different roles entitled \"The Multiverse\", and the PeTI's parallel universes are different from the main Half-Life/Portal timeline.\n\nThe 2012 visual novel/puzzle video game \"\" heavily uses the concept of multiple realities as the basis for its plot as well as its central gameplay mechanic of traversing through realities and altering history.\n\nThe 2013 first person shooter \"BioShock Infinite\" features the many worlds interpretation of quantum mechanics. The main character is named Booker Dewitt, an homage to physicist \"Bryce DeWitt\".\n\nThe world of the classic cult adventure games of \"The Longest Journey\" created by Ragnar Thornqast, along with its sequels, deals with the existence of two parallel universes – technological (Stark) and magical (Arcadia).\n\nThe 2014 crossover video game \"Heroes of the Storm\" features the iconic characters of Blizzard Entertainment. In the game, heroes and villains from \"Warcraft\", \"Diablo\", and \"StarCraft\" have been sucked into a trans-dimensional storm called \"Nexus\". Stranded in a strange limbo of clashing universes, these combatants are joined by the same fate to battle for dominance.\n\n\n"}
{"id": "8078743", "url": "https://en.wikipedia.org/wiki?curid=8078743", "title": "Participation inequality", "text": "Participation inequality\n\nIn social sciences, participation inequality consists of difference between levels of participation of various groups in certain activities. Common examples include:\n\nIn politics, participation inequality typically affects \"the kinds of individuals, such as the young, the poor and those with little formal education\" who tend to not take the initiative to participate in electoral and related events. State enumeration, such as was done in Canada before the implementation of the National Register of Electors in 1996, \"worked to augment voter turnout among all segments of society and thus mitigated a natural tendency toward participation inequality in electoral politics\".\n\nPolitical participation inequality refers to how populations differ in political participation when sorted by various characteristics. Most often these groupings are by social class, race, gender, or ethnicity. Widespread political participation inequality often describes when various groups are left out of the political sphere or excluded from various political rights.\n\nParticipation inequality usually helps political theorists determine where democracies fail or when political institutions are not democratically responsive. When political systems are too unequal in terms of political participation, it most generally means that there is a breakdown in the ability of all citizens to politically deliberate to distribute various scarce resources, implement comprehensive public policy, or enact needed social reforms. Nations with high amounts of participation inequality are generally characterized as undemocratic although there are certain nations, like India, where low participation inequality has not helped the democratic responsiveness of Indian institutions.\n\nIn his 1971 paper \"Polyarchy: Participation and Opposition\", Robert Dahl provided a basic framework to evaluate democracies or polyarchies (nearly/almost full democracies) based on their participation inequality. He argued that there are two dimensions: public contestation – the various rights and procedures guaranteed to citizens – and inclusiveness – how accessible these rights are to all citizens. More fully, public contestation describes the necessary functions for a liberal democracy: a competitive political atmosphere, ability to run for office, right to vote, right to assembly, etc. Inclusiveness describes what portion of the population is able to enjoy these rights and procedures.\n\nParticipation inequality is usually represented along the dimension of inclusiveness. So, if a nation were to allow only short people to vote, this political system would have a certain level of public contestation – the right to vote being available – and a certain dimension of inclusiveness – only short people being able to enjoy this right. This system of evaluating democracies enables comparisons of political regimes based on participation inequality by comparing inclusiveness between equally publicly contestable political systems.\n\nUsing Dahl’s framework, the first cause of participation inequality can be rooted in a political system’s public policy or in the Dahlian dimension of inclusiveness. Policies that exclude groups based on ethnic identity such as old apartheid South Africa or Iranian exclusion of Sunni political parties best conveys systemic political exclusion that is rooted in a regime’s citizenship requirements or public policy.\n\nThe more insidious cause of participation inequality stems from a third dimension that has been recently added to Dahl’s two-dimensional evaluation of political systems: institutions. In this framework, institutions implement political rights and procedures guaranteed by the state. Institutional causes for participation inequality can include literacy tests, extensive citizenship requirements, sparse voting booths in rural or poor areas, and a lack of public transportation. These all affect the ability of citizens to properly exercise guaranteed rights like voting.\n\nInstitutional causes of participation inequality can also be mitigated or exacerbated by cultural norms. Most often high voter turnout usually is hailed as a marker for a democratically responsive nation; however, in India “the turnout rate among the poor is almost as high as for those who are either middle class or rich. A detailed study of voter participation reported for the 2009 national elections shows that voter participation rates do not seem to vary by income status at all…Recent studies report similar findings from Africa and Latin America (Bratton 2008; Boot & Seligson 2008)”. Many of these studies conclude that in developing democracies voting acts as a reassurance of social status or worth in the eyes of the state. This cultural norm has not translated to more democratically responsive institutions in that “the governments created by these elections are known to neglect the interests of the poor and treat them disrespectfully compared to other income groups”. Nations like India are considered to be exceptions to the general rule that economic status has some bearing on voter participation.\n\nEconomic inequality and educational inequality have often been pointed to as common culprits for political participation inequality. In large part, these two types of inequality are often created and reiterated by political institutions, but most political theorists differentiate these causes for political participation as separate, largely because they are not fully solved by changes in political institutions. While the outcomes of political institutions highly vary from regime to regime, most of the literature finds that high amounts of economic inequality in developed countries depress voter turnout for poorer individuals and increase voter turnout for more affluent individuals (this depends on social cohesion of societies, correlating negatively with affluent political participation when economic inequality is high). Other literature finds that educational inequality depresses voter turnout depending on one’s income level and perceived relative educational status (how one perceives one’s social status and others’ education levels).\n\n"}
{"id": "52102822", "url": "https://en.wikipedia.org/wiki?curid=52102822", "title": "Political insult", "text": "Political insult\n\nPolitical insult refers to a statement from a politician about another one which contains disdainful purpose or notorious offense. They are not defined in any political protocol and moreover are strongly recommended not to be used in diplomatic language.\n\n"}
{"id": "14219022", "url": "https://en.wikipedia.org/wiki?curid=14219022", "title": "Richard W. Lyman Award", "text": "Richard W. Lyman Award\n\nThe Richard W. Lyman Award was presented for five years, from 2002 to 2006, by the National Humanities Center. It recognized scholars who have advanced the humanities through the use of information technology. \n\nThe award was named after Richard Wall Lyman, and was given only to male recipients.\n\n\n"}
{"id": "51130697", "url": "https://en.wikipedia.org/wiki?curid=51130697", "title": "Sex differences in narcissism", "text": "Sex differences in narcissism\n\nIn gender studies, the analysis of gender differences in narcissism shows that male narcissism and female narcissism differ in a number of aspects.\n\nJeffrey Kluger, in his 2014 book \"The Narcissist Next Door\" suggested that our society, still largely patriarchal, is more likely to tolerate male narcissism and aggressiveness than these of females. This assertion was voiced, although without definite proof, by a number of other researchers.\n\nIn 2015 a number of media outlets reported about a study at the University of Buffalo which analyzed 31 years of data of narcissism research and concluded that men consistently scored higher in the first two of three aspects of the Narcissistic Personality Inventory: leadership/authority, exploitative/entitlement, and grandiose/exhibitionism. The team leader of the research, Emily Grijalva, commented that on average this difference is slight (a one-quarter of a standard deviation) and there was almost no difference in the exhibitionism dimension (which covers such aspects as vanity, self-absorption and attention-seeking). She notices that a similar degree of difference is observed for other personality traits, e.g., slightly higher neuroticism for women or slightly higher risk-taking for men. The reasons of reported gender difference were outside the scope of the study, however the authors speculated that it is rooted in historically established social conventions about what is acceptable for a particular gender and what are the traditional social roles for genders.\n\nA number of earlier studies (on smaller scales) reported similar bias. A further indication for the trend was a 2008 finding that the lifetime narcissistic personality disorder is more prevalent for men (7.7%) than for women (4.8%).\n\n"}
{"id": "28479795", "url": "https://en.wikipedia.org/wiki?curid=28479795", "title": "Stand-up tragedy", "text": "Stand-up tragedy\n\nStand-up tragedy is a style of tragic performance where a performer performs in front of a live audience, speaking directly to them. The goal of Stand-up tragedy is to make the audience members cry.\n\nStand-up tragedy performances are usually long and employ the use of various media such as video, audio, highly emotional monologues and rants where the performer recites a fast-paced succession of tragic and disturbing stories. Stand-up tragedy is often performed in bars, nightclubs, private homes, art museums, galleries and universities.\n\nThe origin of the term Stand up tragedy is unknown. The comedian Brother Theodore (1906–2001) used the term to describe his comedic act which was dark, and had an absurdist edge. The Beat poet Lawrence Ferlinghetti (1919-) often refers to himself as a \"stand-up tragedian\",\n"}
{"id": "708181", "url": "https://en.wikipedia.org/wiki?curid=708181", "title": "Subtext", "text": "Subtext\n\nSubtext or undertone is any content of a creative work which is not announced explicitly by the characters or author, but is implicit or becomes something understood by the observer of the work as the production unfolds. Subtext can also refer to the thoughts and motives of the characters which are only covered in an aside. Subtext can also be used to imply controversial subjects without specifically alienating people from the fiction, often through use of metaphor. Especially in light of their inherently ambiguous and self-referential character, many authors have explicitly used subtexts (or subtexts about subtexts) in humor. \n\nSubtext is content underneath the dialogue. Under dialogue, there can be conflict, anger, competition, pride, showing off, or other implicit ideas and emotions. Subtext is the unspoken thoughts and motives of characters — what they really think and believe. \n\nSubtext is also a frequently used method of subtly inserting social or political commentary into fiction. Subtext is often also inserted in narratives where explicit themes are unable to be shown or expressed due to censorship or simply interest in appealing to a general audience. Frequently, these subtexts may include a sexual nature or possible references to sexual orientation. Their inclusion is such so that they are easily overlooked by younger viewers but may be caught by more mature viewers. Subtext also serves to add complexity to a premise that may superficially appeal to younger viewers but may also attract older fans, as is often the case with cartoons, science fiction and fantasy. It also may serve to aid in suspension of disbelief.\n\nSubtext includes information about the period and culture in which the author of a book is writing that may not be deliberately articulated but is conveyed through the text in speech, social customs or historical details. \n\nA more recently coined term, metamessage is considered by some authors to be synonymous with subtext. \"Metamessage\" is a term more commonly used in the analysis of business communication rather than of literary works.\n\nThe author David Baboulene, in his practical academic work on story theory, \"The Story Book\", defines subtext as \"the result of any form of gap in knowledge between any of the participants in a story; for example, between the author and a character, between two characters or between the audience and at least one character.\"\n\nAn example occurs in the 1978 movie Superman. Lois Lane has just met Clark Kent. The subtext is that she has taken an instant dislike to him. At the surface, however, their conversation seems only to solicit and supply information about the existence of others of Clark Kent's type. \"Any more at home like you?\" she inquires. \"Uh, not really, no\", Clark replies. \n\nIn the play \"Ghosts\" by Henrik Ibsen, subtext is important in gaining a greater understanding of the characters, as they cannot always speak freely due to the constrictions of social conventions at the time.\n\nA scene in Woody Allen's movie \"Annie Hall\", in which subtitles explain the characters' inner thoughts during an apparently innocent conversation, is an example of the subtext of a scene being made explicit.\n\nVictorian novels may feature confining social norms such as strict marriage conventions, taboos against births out of wedlock, inheritance to first born sons, etc., that form the subtext of plot and character. These issues can be deployed unconsciously, as in Wilkie Collins' \"The Woman in White\" or as part of a concealed critique of gender politics, as in Charlotte Brontë's \"Jane Eyre\".\n\nIn the episode \"My Best Friend's Bottom\" of the British comedy TV series \"Coupling\", \"Captain Subtext\" is a tool used in the narrative to explicitly make the viewers aware of the subtextual message in the dialogue. In it, the dialogue and the subtext have been deliberately made humorous.\n\nTelevision sci-fi such as the original \"Star Trek\" and \"Doctor Who\" (both of which implicitly avoided onscreen sexual situations) have often been discussed with respect to certain scenes or lines of dialogue.\n\nCues for the subtext are sometimes given in the main text in the form of \"intertexts\", which are allusions to the themes of other texts. An example is \"Blade Runner\", which can be interpreted as containing numerous biblical (intertextual) allusions, framing the subtext as a religiously inspired theme—the search for the Creator and the meaning of life beyond physical existence.\n\nHistorians have often identified an anticipated future revolution, often without the ruling party's understanding.\n\nSuch an example of the power and controversy of subtexts might include the deliverance theme pervasive in the songs, stories, and symbols of the slaves in the United States up through the Civil Rights era and, perhaps, still today. The slave prayers, with their theme of deliverance, may have seemed subversive, as striking at planter ideology and control \n\nSubtext messages have seen fairly widespread use as a way to combat censorship in literary works, for example in the former Communist bloc. The practice is of course much older; e.g. one find works from the middle ages criticizing the church establishment. Some of these works use a formal technique called \"double structure\" in which the same text can have different (usually antithetical) meanings by reading sentences or verses in two different orders.\n\nAccording to a 2008 organizational communication textbook, \"meta message\" is a term coined by lawyer Gerard Nierenberg in his 1995 book \"The Art of Negotiating\" to denote (in the words of the textbook) \"those messages that are conveyed between the lines of what we explicitly say or write, possibly due to the purpose, context, or timing of the message and/or the relationship between the people communicating\".\n\nThe term also appears in a 1972 book of Gregory Bateson, who suggested a somewhat similar distinction, although in the form of a potentially infinite hierarchy of messages, metamessages, meta-metamessages and so on. Bateson argued that any message needs to be interpreted in the frame of reference established by a superordinate message cueing how the textual message is intended. Alan Wolfe points out that Bateson's concepts and terminlogy are rather technical, and are thus commonly misinterpreted. In particular, in Bateson's work the metamessage is the framing message, not the actual (subtext) meaning assigned to the subordinate message in the context of the framing message. About two decades before introducing the metamessage terminology into his works, Bateson studied by what \"mood sign[al]\" (his earlier term for metamessage) subordinated messages are interpreted \"seriously, jokingly, sarcastically, as gestures of friendliness, as acts of aggression\" etc. Invoking Bertrand Russell's Theory of Logical Types, Bateson proposed that for every signal, there is always signal level above it which precisely determines its interpretation. Bateson's theory was however criticized as too rigid and lacking explanatory power for real-world communication phenomena in which signals of any kind (at any level) can be deceitful.\n\nMetamessages can be delivered by a wide variety of means, including verbal modifiers (like \"certainly\", \"only\", \"just\", etc.), and—in spoken communication—by paralanguage, e.g. by rhythm and pitch. Metamessages can also be conveyed by body language.\n\nThe famous pipe image from \"The Treachery of Images\" with the subtitle \"ceci n'est pas une pipe\" (meaning \"this is not a pipe\") is sometimes given as an example of metamessage conveyed by paralanguage.\n"}
{"id": "286347", "url": "https://en.wikipedia.org/wiki?curid=286347", "title": "Turkology", "text": "Turkology\n\nTurkology (or Turcology) is a complex of humanities sciences studying languages, history, literature, folklore, culture, and ethnology of people speaking Turkic languages and Turkic peoples in chronological and comparative context. This includes ethnic groups from the Sakha in East Siberia to the Balkan Turks and Gagauz in Moldova.\n\nEthnological information on Turkic tribes for the first time was systemized by the 11th-century Turkic philologist Mahmud al-Kashgari in the \"Dīwān ul-Lughat it-Turk\" (Dictionary of Turkic language). Multi-lingual dictionaries were compiled from the late 13th century for the practical application of participants in international trade and political life: Kipchak (Cuman)-Persian-Latin-German \"Codex Cumanicus\", \"Armenian-Kipchak\", and \"Russian-Kipchak\" dictionaries. By the Middle Ages the Turkology was centred around Byzantine/Greek historians, ambassadors and travelers, and geographers. In the 15th-17th centuries the main subject of Turkology was the study of the Ottoman Empire and the Turkish language, and the Turkic languages of Eastern Europe and Western Asia. In 1533 a first hand-written primer appeared, and by 1612 a printed grammar by Jerome Megizer was published, followed by F. Mesgnien-Meninski's 4-volume \"Thesaurus Linguarum Orientalium\" published in 1680.\n\nP. S. Pallas initiated a more scientific approach to Turkology with his \"Comparative dictionaries of all languages and dialects\" (1787) which included lexical materials from Tatar, Mishar, Nogai, Bashkir, and other Türkic languages. In the 19th century, Turkology was further developed by M. A. Kazembek's \"Grammar of the Turkish-Tatar language\" (1839), O. N. Betlingk \"Grammar of the Yakut language\" (1851). A major achievement was the deciphering at the end of the 19th century of the Early Middle Age Orkhon inscriptions by V. Thomsen and W. W. Radloff (1895). By the end of the 19th century, Turkology developed into a complex discipline that included linguistics, history, ethnology, archeology, arts and literature. In the 20th century the Turkology complex included physical anthropology, numismatics, genetics, ancient Turkic alphabetic scripts, typology, genesis, and etymology, onomastics and toponymy. The appearance of \"Türkische Bibliothek\" (1905–27) inaugurated specialised periodicals, followed by \"Mitteilungen zur Osmanischen Geschichte\" (1921–26). Scientific developments allowed calibrated dating, dendrochronology, metallurgy, chemistry, textile, and other specialized disciplines which contributed to the development of the Turkological studies. Deeper study of the ancient sources allowed better understanding of economical, social, mythological and cultural forces of the sedentary and nomadic societies. Linguistic studies uncovered pre-literate symbioses and mutual influences between different peoples.\n\nOn 9 August 1944 the Central Committee VKP(b), the ruling party of the USSR, published an edict prohibiting \"ancientization\" of Turkic history. The edict was followed by a consecutive wave of mass arrests, imprisoning and killing of the intelligentsia, massive creation of replacement \"scientists\", and re-writing of history pages on an industrial scale. Combined with the concurrent wholesale deportation of indigenous populations to remote areas in Middle Asia and Siberia, the wipe-out of the science was nearly complete, and the impact of the action subsided only partially in the newly independent countries after the collapse of the USSR. In the two decades after the Bolshevik's assuming power, the tradition of Turkological studies in Russia and dependent countries was practically wiped out.\n\nOn the other hand, this edict brought unintended benefits to Turkology. One was the nearly immediate linguistic development of an alternate lexicon which replaced the nouns and adjectives containing the word \"Türk\" by a wealth of euphemisms: \"nomads, Siberians, Paleosiberians, Middle Asians, Scythians, Altaians, Tuvians\", etc. that filled scientific publications. The other was \"writing into a drawer\", when results of the years of fruitful work were written down for future publication. When the bonds relaxed, the publications exploded. Another was a flight of scientists from European Russia into remote areas, which brought first class scientists to many intellectually starved outlying areas of Middle Asia. Another one was connected with the statewide efforts to re-invent the history, when a wealth of Turkological facts were found in the process of search for \"correct\" history. And another one was a built-up of the public interest for the forbidden subjects, that resulted that no print size could satisfy the demand. L.N.Gumilev and O.Suleimenov inflamed a surge in the new generation of Turkology scholars.\n\nWith the physical culling of the scholars from the society, concurrently was also organized a total extermination of all their published and unpublished works, their books were removed from the libraries and destroyed from private collections by intimidated population, articles and publications were culled, published photographs were retouched, private photographs were destroyed, published scientific references were erased, or publications with undesired references were destroyed. Very few of the early 20th century expedition diaries, ethnographical notes, reports and drafts for publications were ever recovered.\n\n\n\nA selection of English-language periodicals studying Turkology\n\n\n"}
{"id": "1853097", "url": "https://en.wikipedia.org/wiki?curid=1853097", "title": "Well-made play", "text": "Well-made play\n\nThe well-made play (, pronounced ) is a dramatic genre from nineteenth-century theatre first codified by French dramatist Eugène Scribe. Dramatists Victorien Sardou, Alexandre Dumas, fils, and Emile Augier wrote within the genre, each putting a distinct spin on the style. The well-made play was a popular form of entertainment. By the mid-19th century, however, it had already entered into common use as a derogatory term. Henrik Ibsen and the other realistic dramatists of the later 19th century (August Strindberg, Gerhart Hauptmann, Émile Zola, Anton Chekhov) built upon its technique of careful construction and preparation of effects in the genre problem play. \"Through their example\", Marvin Carlson explains, \"the well-made play became and still remains the traditional model of play construction.\"\nIn the English language, that tradition found its early 20th-century codification in Britain in the form of William Archer's \"Play-Making: A Manual of Craftmanship\" (1912), and in the United States with George Pierce Baker's \"Dramatic Technique\" (1919).\n\nThe form has a strong Neoclassical flavour, involving a tight plot and a climax that takes place close to the end of the play. The well-made play retains the shape of Aristotle's ideal Greek-tragedy model outlined in his \"Poetics\".\n\nThe well-made play can be broken down into a specific set of criteria. First, the story depends upon a key piece of information kept from some characters, but known to others (and to the audience). Most of the story takes place before the action of the play begins, making the beginning of the play a late point of attack. Exposition during act one explains actions that precede the opening scene, and generates the audience's sympathy for the hero (or heroes) over their rival (or rivals). The plot moves forward in a chain of actions that use minor reversals of fortune to create suspense. The pace builds towards a climactic obligatory scene, in which the hero triumphs. This scene contains a climactic reversal of fortune, or peripeteia. A dénouement follows, in which all remaining plot points are unraveled and resolved.\n\nA recurrent device that the well-made play employs is the use of letters or papers falling into unintended hands, in order to bring about plot twists and climaxes. The letters bring about an unexpected and climactic reversal of fortune, in which it is often revealed that someone is not who they pretend to be. Mistaken or mysterious identity as a basis for plot complications is referred to as \"qui pro quo\".\n\nEugene Scribe contributed over 300 plays and opera libretti to the dramatic literature canon. Thirty-five of these works are considered well-made-plays.\n\nHistory of French Neoclassic form lays a critical foundation for Scribe, who draws upon devices determined by the French Academy to create his dramatic structure. French Neoclassicism conceives of Verisimilitude, or the appearance of a plausible truth, as the aesthetic goal of a play. In 1638, the French Academy codified a system by which dramatists could achieve Verisimilitude in a verdict on the Le Cid debate. The monarchy enforced the standards of French Neoclassicism with a system of censorship under which funding and practice permits were issued to a limited number of theater companies. This system underwent small modifications, but remained essentially the same up until the French Revolution. Until then, restrictive laws inhibited the growth of new practices with the exception of those advocated by a few intrepid dramatists such as Voltaire, Diderot, and Beaumarchais. After the French Revolution, adherence to the form became an artistic choice instead of a political necessity.\n\nAlthough Scribe drew heavily upon Neoclassic devices, he used them in original ways that would not have been acceptable without new popular forms, such as those developed at the Boulevard theatres. In order to work around the formal monopoly of the Comédie Française in the middle of the 18th century, theater troupes experimenting with new dramatic forms sprang up along the Boulevard du Temple. Their aim was to escape the censors, and please the public. Popular reception of the boulevard theatres' explorations helped to crack the edifice of Neoclassic form. After the French Revolution, French theater opened to the influence of practices that had meanwhile developed in other places around Europe.\n\nScribe's development of a form that could be used repeatedly to turn out new material suited the demands of a growing middle class theater audience.\n\nScribe's influence on theater, according to Marvin J. Carlson, \"cannot be overestimated\". Carlson observes that, unlike other influential theater thinkers, Scribe did not write prefaces or manifestos declaiming his ideas. Scribe influenced theater, instead, with craftsmanship. He honed a dramatic form into a reliable mould that could be applied not only to different content, but to different content from a variety of playwrights. Carlson identifies a single instance of Scribe's critical commentary from a speech Scribe gave to the Académie française in 1836. Scribe expressed his view of what draws the audiences to theater:\n\n\"not for instruction or improvement, but for diversion and distraction, and that which diverts them [audience] most is not truth, but fiction. To see again what you have before your eyes daily will not please you, but that which is not available to you in every day life - the extraordinary and the romantic.\"\n\nAlthough Scribe advocated for a theater of amusement over didacticism, other writers, beginning with Alexandre Dumas, fils, adopted Scribe's structure to create didactic plays. In a letter to a critic, Dumas \"fils\" states,\"... if I can find some means to force people to discuss the problem, and the lawmaker to revise the law, I shall have done more than my duty as a writer, I shall have done my duty as a man.\". Dumas' thesis plays are plays written in the well-made style that take clear moral positions on social issues of the day. Emile Augier also used Scribe's formula to write plays addressing contemporary social issues, although he declares his moral position less strongly.\n\nBy the late 19th century, the well-made play had fallen out of critical favor. Shaw was among those who held the form in low regard, \"Why the devil should a man write like Scribe when he can write like Shakespeare or Moliere, Aristophanes or Euripides? Who was Scribe that he should dictate to me or anyone else how a play should be written?\" In reference to the form's tendency to favor amusing plot twists over complexly drawn characters, Shaw referred to the genre as Sardoodledom after Victorien Sardou, who also wrote in the well-made style.\n\nThe opening to the preface to \"Three Plays by Brieux\" offers another example of Shavian disdain for the well-made plays. Shaw identifies the process of creating them as an industry, and their creators as “literary mechanics” instead of artists. To convey how vulgar he finds a widely used playwrighting formula, Shaw interprets the aphorism \"Art for art's sake,\" as \"Success for money's sake.\"\n\nIn an essay published in PMLA in 1951, \"Pygmalion: Bernard Shaw’s Dramatic Theory and Practice\", Milton Crane reasons that Shaw’s disparagement of the classic well-made formula, and his desire to pry Ibsen’s work away from association with the works of Scribe and Sardou, serve a specific agenda. Crane argues that Shaw aims to prevent his own use of the well-made formula from linking his plays with work considered out of fashion. Shaw’s theory of the problem play and discussion ideas align his plays with Ibsen’s, and distinguishes them from stale plays of the past. Crane observes that Shaw, by his own admission, learned dramatic structure from contemporary popular theatre which was then dominated by the well-made formula. Crane goes on to argue how that formula is present in \"Pygmalion\", \"Man and Superman\", and \"The Doctor’s Dilemma\".\n\nShaw discusses the notion of the problem play in an essay of the same title published in 1895. He defines a problem play as one that puts a person or people in conflict with an institution, confronting a contemporary social question. He cites the \"Woman question\" as a contemporary example. Ibsen's engagement with the \"Woman question\" in \"A Doll's House\" and \"Ghosts\" qualifies those works as problem plays. Shaw distinguishes between the problem play and literature with conflicts reflecting a more universal view of the human condition. Works whose fundamental conflict does not pit human against institution, he argues, are more apt to remain relevant through generations. He cites \"Hamlet\", \"Faust\", and \"Les Misérables\" as examples of stories whose conflicts involve more eternal human questions. Shaw observes that the immediacy of the institutional question addressed in a problem play will render the play \"flat as ditchwater\" once society progresses and the issue is resolved. Although Ibsen was hailed by feminists, he did not regard himself as an advocate for any particular group.\n\nIbsen's aim, according to Raymond Williams, was to express tragedies in the human condition. Ibsen qualifies a human tragedy as the state \"[when a person] stands in a tight place; he cannot go forwards or backwards.” Williams also cites the specific characteristic that distinguishes his and Ibsen's modern drama from the preceding well-made formula. The well-made formula, Shaw observes, can be divided into three sections: Exposition, Situation, Unraveling. The plays of Ibsen and Shaw, Shaw himself asserts, do not end with a classic unraveling. Their work can be divided as: Exposition, Situation, Discussion.\n\nOscar Wilde's \"The Importance of Being Earnest\" exaggerates many of the conventions of the well-made play, such as the missing papers conceit (the hero, as an infant, was confused with the manuscript of a novel) and a final revelation (which, in this play, occurs about thirty seconds before the final curtain).\n\nHenrik Ibsen's \"A Doll's House\" follows most of the conceits of the well-made play, but transcends the genre when, after incriminating papers are recovered, Nora rejects the expected return to normality. Several of Ibsen's subsequent plays build on the general construction principles of the well-made play. \"The Wild Duck\" (1884) can be seen as a deliberate, meta-theatrical deconstruction of the Scribean formula. Ibsen sought a compromise between Naturalism and the well-made play which was fraught with difficulties since life does not fall easily into either form.\n\nAlthough George Bernard Shaw scorned the \"well-made play\", he accepted the form, and even thrived by it, for it concentrated his skills on the conversation among characters, his greatest asset as a dramatist. Other classic twists on the well-made play can be seen in his use of the General's coat and the hidden photograph in \"Arms and the Man\".\n\nAlso, J. B. Priestley's 1946 \"An Inspector Calls\" may in some ways be considered a \"well-made play\" in that its action happens before the play starts, and in the case of the older Birlings no moral change takes place. The similarity between Priestley's play and this rather conservative genre might strike some readers/audiences as surprising because Priestley was a socialist. However, his play, like Ibsen's \"A Doll's House\" transcends this genre by providing another plunge into chaos after the return to normality. He replaced the dramatic full stop with a question mark by revealing in the last scene that the 'inspector' who has exposed the complicity of a prosperous industrial family in the murder or suicide of a working-class girl, is not an inspector at all (perhaps a practical joker, an emanation of the world to come, or a manifestation of the world to come), and the curtain falls on the news that a real girl has died and a real inspector is on the way.\n\nThe techniques of well-made plays also lend themselves to comedies of situation, often farce. In \"The Quintessence of Ibsenism\", Bernard Shaw proposed that Ibsen converted this formula for use in \"serious\" plays by substituting discussion for the plausible dénouement or conclusion. Thus, plays become open-ended, as if there were life for the protagonists beyond the last act curtain.\n\n\n"}
{"id": "46300199", "url": "https://en.wikipedia.org/wiki?curid=46300199", "title": "Western studies (Germany)", "text": "Western studies (Germany)\n\nWestern studies or western research () in Germany traditionally refers to area studies concerned with the countries and areas on Germany's western and southwestern borders, including France (particularly its eastern and northern parts), the Benelux countries and Switzerland, as well as the westernmost \"border areas\" within Germany, i.e. areas near the Dutch, Belgian, Luxembourgish, French and Swiss borders. The concept of western studies arose during the First World War, and like other forms of area studies, it was often motivated by geostrategic considerations. The traditional concept of western studies was largely abandoned with the onset of the Cold War, West Germany's western alignment and the western European integration process. It has largely been succeeded by the broader field of European studies.\n\nIn the communist world, including for example the Soviet Union, the German Democratic Republic and the People's Republic of Poland, \"western studies\" remained popular until the fall of communism, but encompassed studies of the western or \"capitalist\" world more broadly, including all of western Europe according to the Cold War definition of the term and North America. The western equivalent was Soviet and Communist studies.\n"}
{"id": "12289130", "url": "https://en.wikipedia.org/wiki?curid=12289130", "title": "Zhuang studies", "text": "Zhuang studies\n\nZhuang studies (or Zhuangology; Standard Zhuang: Cuenghhag; ) is an interdisciplinary intellectual field concerned with the Zhuang people – their history, anthropology, religion, politics, languages, and literature. The majority of such research is being carried out in the People's Republic of China. Huang Xianfan (黄现璠) is considered by many to be the father of Zhuang studies.\n\nAreas commonly included under this rubric include history of Zhuang, literature of Zhuang, art of Zhuang, music of Zhuang, language of Zhuang, sociology of Zhuang, political science of Zhuang, economics of Zhuang, folklore of Zhuang, and ethnomusicology of Zhuang. It may be compared to other ethnic groups studies disciplines, such as Tai studies and Yao studies. Zhuang studies is sometimes included within a broader regional area of focus including: \"Lingnan studies\", \"Yue people studies\",\"South Asia studies\", or \"ASEAN Studies\".\n\nZhuang studies is a relatively new discipline.\n\nHuang Xianfan may be considered as the first Zhuangologist and he did much to make Zhuang known in China. Since 1950, Huang Xianfan led the group making a largest and deepest investigation on ethnic history and traditional culture in Guangxi history. They had collected a lot of valuable materials and laid a foundation for further research on Zhuang ethnic social and historical culture.That was a very important beginning for later development of Zhuang ethnic research and establishment of Guangxi institute of ethnic studies. Therefore, the inception of Zhuang studies as an authentic academic discipline is thus associated with the first ethnologist Huang Xianfan de Zhuang who is considered as its founder to present day, the other early zhuang studies of note being Huang Zengqing (Huang group's member and the first archaeological researcher of the Guangxi) who in 1957 occupied the first chair for Zhuang's archaeology studies in China and Zhou Zuoqiou, who was primarily the pioneering subject of the zhuang literature in Guangxi Normal University.\n\nThe Bagui School (The first ethnic school in China and pioneer is Huang Xianfan) was particularly significant for the development of the discipline since the early 1950s with Huang Xianfan, Huang Zengqing, Ban Xiouwen, Ou Yang Ruoxiou, Qin Cailuan, Qin Naichang, Qin Shengmin, He Longqun, Yu Shijie, Qin Deqing, Pan Qixu, Huang Hanjin and Zeng Chaoxiong.,\n\nIn 1957, the Guangxi government established the Guangxi institute of ethnic studies to promote Zhuang studies around China. In 1991 the Guangxi Zhuang Studies Society was established, and in April 1999 the first international Zhuang studies conference was held in Wuming with scholars from 8 different countries.\n\nOver the last few decades in other countries the studies of the Zhuang have opened towards other disciplines, resulting in works with interdisciplinary approach. As examples of such open-minded Zhuang researcher we might mention the American anthropologist Jeffrey Barlow, among others, who has done noted research and publications on lexical questions, about Zhuang culture and the modern history of Zhuang. Others are Japanese anthropologist Chikada Sigeyuki, Australian anthropologist David Holm, and many more.\n\n\n"}
