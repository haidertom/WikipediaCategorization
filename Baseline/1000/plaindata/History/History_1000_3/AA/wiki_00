{"id": "4238002", "url": "https://en.wikipedia.org/wiki?curid=4238002", "title": "1972 world oil market chronology", "text": "1972 world oil market chronology\n\n|-\n"}
{"id": "47508669", "url": "https://en.wikipedia.org/wiki?curid=47508669", "title": "1999 in Sri Lanka", "text": "1999 in Sri Lanka\n\nThe following lists events that happened during 1999 in Sri Lanka.\n\n\n"}
{"id": "690842", "url": "https://en.wikipedia.org/wiki?curid=690842", "title": "Age of Discovery", "text": "Age of Discovery\n\nThe Age of Discovery, or the Age of Exploration (approximately from the beginning of the 15th century until the end of the 18th century) is an informal and loosely defined term for the period in European history in which extensive overseas exploration emerged as a powerful factor in European culture and was the beginning of globalization. It also marks the rise of the period of widespread adoption in Europe of colonialism and mercantilism as national policies. Many lands previously unknown to Europeans were discovered by them during this period, though most were already inhabited. From the perspective of many non-Europeans, the Age of Discovery marked the arrival of invaders from previously unknown continents. \nGlobal exploration started with the Portuguese discoveries of the Atlantic archipelagos of Madeira and the Azores, the coast of Africa, and the discovery of the sea route to India in 1498; and the Crown of Castile (Spain) the trans-Atlantic Voyages of Christopher Columbus to the Americas between 1492 and 1502 and the first circumnavigation of the globe in 1519–1522. These discoveries led to numerous naval expeditions across the Atlantic, Indian and Pacific oceans, and land expeditions in the Americas, Asia, Africa and Australia that continued into the late 19th century, and ended with the exploration of the polar regions in the 20th century.\n\nEuropean overseas exploration led to the rise of global trade and the European colonial empires, with the contact between the \"Old World\" (Europe, Asia and Africa) and the \"New World\" (the Americas and Australia) producing the Columbian Exchange; a wide transfer of plants, animals, food, human populations (including slaves), communicable diseases and culture between the Eastern and Western Hemispheres. This represented one of the most-significant global events concerning ecology, agriculture and culture in history. The Age of Discovery and later European exploration allowed the global mapping of the world, resulting in a new world-view and distant civilizations coming into contact, but also led to the propagation of diseases that decimated populations not previously in contact with Eurasia and Africa and to the enslavement, exploitation, military conquest and economic dominance by Europe and its colonies over native populations. It also allowed for the expansion of Christianity throughout the world: with the spread of missionary activity, it eventually became the world's largest religion.\n\nThe Portuguese began systematically exploring the Atlantic coast of Africa from 1418, under the sponsorship of Prince Henry. Under the direction of Henry the Navigator, the Portuguese developed a new, much lighter ship, the caravel, which could sail further and faster, and, above all, was highly manoeuvrable and could sail much nearer the wind, or \"into the wind\". In 1488 Bartolomeu Dias reached the Indian Ocean by this route. In 1492 the Catholic Monarchs of Castile and Aragon funded Christopher Columbus's plan to sail west to reach the Indies by crossing the Atlantic. He landed on a continent uncharted by Europeans and seen as a new world, the Americas. To prevent conflict between Portugal and Castile (the crown under which Columbus made the voyage), the Treaty of Tordesillas was signed dividing the world into two regions of exploration, where each had exclusive rights to claim newly discovered lands.\n\nIn 1498, a Portuguese expedition commanded by Vasco da Gama reached India by sailing around Africa, opening up direct trade with Asia. While other exploratory fleets were sent from Portugal to northern North America, in the following years Portuguese India Armadas also extended this Eastern oceanic route, touching sometimes South America and by this way opening a circuit from the New World to Asia (starting in 1500, under the command of Pedro Alvares Cabral), and explored islands in the South Atlantic and Southern Indian Oceans. Soon, the Portuguese sailed further eastward, to the valuable Spice Islands in 1512, landing in China one year later. In 1513, Spanish Vasco Núñez de Balboa crossed the Isthmus of Panama and reached the \"other sea\" from the New World. Thus, Europe first received news of the eastern and western Pacific within a one-year span around 1512. East and west exploration overlapped in 1522, when a Castilian (Spanish) expedition, led by Portuguese navigator Ferdinand Magellan and later by Spanish Basque navigator Juan Sebastián Elcano, sailing westward, completed the first circumnavigation of the world, while Spanish \"conquistadors\" explored the interior of the Americas, and later, some of the South Pacific islands.\n\nSince 1495, the French and English and, much later, the Dutch entered the race of exploration after learning of these exploits, defying the Iberian monopoly on maritime trade by searching for new routes, first to the western coasts of North and South America, through the first English and French expeditions (starting with the first expedition of John Cabot in 1497 to the north, in the service of England, followed by the French expeditions to South America and later to North America), and into the Pacific Ocean around South America, but eventually by following the Portuguese around Africa into the Indian Ocean; discovering Australia in 1606, New Zealand in 1642, and Hawaii in 1778. Meanwhile, from the 1580s to the 1640s, Russians explored and conquered almost the whole of Siberia, and Alaska in the 1730s.\nBetween the 12th and 15th centuries the European economy was transformed by the interconnecting of river and sea trade routes, causing Europe to become one of the world's most prosperous trading networks. \n\nBefore the 12th century the main obstacle to trade east of the Strait of Gibraltar was lack of commercial incentive rather than inadequate ship design. Economic growth of Spain followed the reconquest of parts of Muslim Spain and the siege of Lisbon (1147 AD). The decline of Fatimid Caliphate naval strength that started before the First Crusade helped the maritime Italian states, mainly Venice, Genoa and Pisa, dominate trade in the eastern Mediterranean, with Italian merchants becoming wealthy and politically influential. The Norman Conquest of England in the late 11th century allowed for peaceful trade on the North Sea. The Hanseatic League, a confederation of merchant guilds and their towns in northern Germany along the North Sea and Baltic Sea, was instrumental in commercial development of the region. In the 12th century the region of Flanders, Hainault and Braband produced the finest quality textiles in northern Europe, which encouraged merchants from Genoa and Venice to sail there directly. Nicolozzo Spinola made the first recorded direct voyage from Genoa to Flanders in 1277.\n\nTechnological advancements that were important to the Age of Exploration were the adoption of the magnetic compass and advances in ship design. \n\nThe compass was an addition to the ancient method of navigation based on sightings of the sun and stars. The compass had been used for navigation in China by the 11th century and was adopted by the Arab traders in the Indian Ocean. The compass spread to Europe by the late 12th or early 13th century. Use of the compass for navigation in the Indian Ocean was first mentioned in 1232. The first mention of use of the compass in Europe was in 1180. The Europeans used a \"dry\" compass, with a needle on a pivot. The compass card was also a European invention.\n\nShips grew in size, required smaller crews and were able to sail longer distances without stopping. This led to significant lower long distance shipping costs by the 14th century.\n\nThe Periplus of the Erythraean Sea, a document dating from 40-60 AD, describes a newly discovered route through the Red Sea to India, with descriptions of the markets in towns around Red Sea, Persian Gulf and the Indian Ocean, including along the eastern coast of Africa, which states \"for beyond these places the unexplored ocean curves around toward the west, and running along by the regions to the south of Aethiopia and Libya and Africa, it mingles with the western sea (possible reference to the Atlantic Ocean)\". European medieval knowledge about Asia beyond the reach of the Byzantine Empire was sourced in partial reports, often obscured by legends, dating back from the time of the conquests of Alexander the Great and his successors. \nAnother source was the Radhanite Jewish trade networks of merchants established as go-betweens between Europe and the Muslim world during the time of the Crusader states.\nIn 1154, the Arab geographer Muhammad al-Idrisi created a description of the world and a world map, the Tabula Rogeriana, at the court of King Roger II of Sicily, but still Africa was only partially known to either Christians, Genoese and Venetians, or the Arab seamen, and its southern extent unknown. There were reports of great African Sahara, but the factual knowledge was limited for the Europeans to the Mediterranean coasts and little else since the Arab blockade of North Africa precluded exploration inland. Knowledge about the Atlantic African coast was fragmented and derived mainly from old Greek and Roman maps based on Carthaginian knowledge, including the time of Roman exploration of Mauritania. The Red Sea was barely known and only trade links with the Maritime republics, the Republic of Venice especially, fostered collection of accurate maritime knowledge.\n\nIndian Ocean trade routes were sailed by Arab traders. Between 1405 and 1421, the Yongle Emperor of Ming China sponsored a series of long range tributary missions under the command of Zheng He (Cheng Ho). The fleets visited Arabia, East Africa, India, Maritime Southeast Asia and Thailand. But the journeys, reported by Ma Huan, a Muslim voyager and translator, were halted abruptly after the emperor's death and were not followed up, as the Chinese Ming Dynasty retreated in the \"haijin\", a policy of isolationism, having limited maritime trade.\n\nBy 1400 a Latin translation of Ptolemy's \"Geographia\" reached Italy coming from Constantinople. The rediscovery of Roman geographical knowledge was a revelation, both for mapmaking and worldview, although reinforcing the idea that the Indian Ocean was landlocked.\n\nA prelude to the Age of Discovery was a series of European expeditions crossing Eurasia by land in the late Middle Ages. Although the Mongols had threatened Europe with pillage and destruction, Mongol states also unified much of Eurasia and, from 1206 on, the \"Pax Mongolica\" allowed safe trade routes and communication lines stretching from the Middle East to China. A series of Europeans took advantage of these to explore eastwards. Most were Italians, as trade between Europe and the Middle East was controlled mainly by the Maritime republics. The close Italian links to the Levant raised great curiosity and commercial interest in countries which lay further east.\n\nThere are a few accounts of merchants from North Africa and the Mediterranean region who traded in the Indian Ocean in late medieval times.\n\nChristian embassies were sent as far as Karakorum during the Mongol invasions of the Levant, from which they gained a greater understanding of the world. The first of these travellers was Giovanni da Pian del Carpine, dispatched by Pope Innocent IV to the Great Khan, who journeyed to Mongolia and back from 1241 to 1247. About the same time, Russian prince Yaroslav of Vladimir, and subsequently his sons Alexander Nevsky and Andrey II of Vladimir, travelled to the Mongolian capital. Though having strong political implications, their journeys left no detailed accounts. Other travellers followed, like French André de Longjumeau and Flemish William of Rubruck, who reached China through Central Asia. Marco Polo, a Venetian merchant, dictated an account of journeys throughout Asia from 1271 to 1295, describing being a guest at the Yuan Dynasty court of Kublai Khan in \"Travels\", and it was read throughout Europe.\n\nIn 1291, in a first Atlantic exploration attempt, merchant brothers Vadino and Ugolino Vivaldi sailed from Genoa with two galleys but disappeared off the Moroccan coast, feeding the fears of oceanic travel. From 1325 to 1354, a Moroccan scholar from Tangier, Ibn Battuta, journeyed through North Africa, the Sahara desert, West Africa, Southern Europe, Eastern Europe, the Horn of Africa, the Middle East and Asia, having reached China. After returning, he dictated an account of his journeys to a scholar he met in Granada, the \"Rihla\" (\"The Journey\"), the unheralded source on his adventures. Between 1357 and 1371 a book of supposed travels compiled by John Mandeville acquired extraordinary popularity. Despite the unreliable and often fantastical nature of its accounts it was used as a reference for the East, Egypt, and the Levant in general, asserting the old belief that Jerusalem was the centre of the world.\n\nFollowing the period of Timurid relations with Europe, in 1439 Niccolò de' Conti published an account of his travels as a Muslim merchant to India and Southeast Asia and, later in 1466–1472, Russian merchant Afanasy Nikitin of Tver travelled to India, which he described in his book \"A Journey Beyond the Three Seas\".\n\nThese overland journeys had little immediate effect. The Mongol Empire collapsed almost as quickly as it formed and soon the route to the east became more difficult and dangerous. The Black Death of the 14th century also blocked travel and trade. The rise of the Ottoman Empire further limited the possibilities of European overland trade.\n\nThe Chinese had wide connections through trade in Asia and had been sailing to Arabia, East Africa, and Egypt since the Tang Dynasty (AD 618–907). Between 1405 and 1421 the third Ming emperor Yongle sponsored a series of long range tributary missions in the Indian Ocean under the command of admiral Zheng He (Cheng Ho).\n\nA large fleet of new junk ships was prepared for these international diplomatic expeditions. The largest of these junks—that the Chinese termed \"bao chuan\" (treasure ships)—may have measured 121 metres (400 feet) stem to stern, and thousands of sailors were involved. The first expedition departed in 1405. At least seven well-documented expeditions were launched, each bigger and more expensive than the last. The fleets visited Arabia, East Africa, India, Malay Archipelago and Thailand (at the time called Siam), exchanging goods along the way. They presented gifts of gold, silver, porcelain and silk; in return, received such novelties as ostriches, zebras, camels, ivory and giraffes. After the emperor's death, Zheng He led a final expedition departing from Nanking in 1431 and returning to Beijing in 1433. It is very likely that this last expedition reached as far as Madagascar. The travels were reported by Ma Huan, a Muslim voyager and translator who accompanied Zheng He on three of the seven expeditions, his account published as \"Ying-Yai Sheng-Lam\" (Overall Survey of the Ocean's Shores) (1433).\n\nThese long distance journeys were not followed up, as the Chinese Ming dynasty retreated in the \"haijin\", a policy of isolationism, having limited maritime trade. Travels were halted abruptly after the emperor's death, as the Chinese lost interest in what they termed barbarian lands turning inward, and successor emperors felt the expeditions were harmful to the Chinese state; Hongxi Emperor ended further expeditions and Xuande Emperor suppressed much of the information about Zheng He's voyages.\n\nFrom the 8th century until the 15th century, the Republic of Venice and neighbouring maritime republics held the monopoly of European trade with the Middle East. The silk and spice trade, involving spices, incense, herbs, drugs and opium, made these Mediterranean city-states phenomenally rich. Spices were among the most expensive and demanded products of the Middle Ages, as they were used in medieval medicine, religious rituals, cosmetics, perfumery, as well as food additives and preservatives. They were all imported from Asia and Africa.\n\nMuslim traders—mainly descendants of Arab sailors from Yemen and Oman—dominated maritime routes throughout the Indian Ocean, tapping source regions in the Far East and shipping for trading emporiums in India, mainly Kozhikode, westward to Ormus in the Persian Gulf and Jeddah in the Red Sea. From there, overland routes led to the Mediterranean coasts. Venetian merchants distributed the goods through Europe until the rise of the Ottoman Empire, that eventually led to the fall of Constantinople in 1453, barring Europeans from important combined-land-sea routes.\n\nForced to reduce their activities in the Black Sea, and at war with Venice, the Genoese had turned to North African trade of wheat, olive oil (valued also as an energy source) and a search for silver and gold. Europeans had a constant deficit in silver and gold, as coin only went one way: out, spent on eastern trade that was now cut off. Several European mines were exhausted, the lack of bullion leading to the development of a complex banking system to manage the risks in trade (the very first state bank, \"Banco di San Giorgio\", was founded in 1407 at Genoa). Sailing also into the ports of Bruges (Flanders) and England, Genoese communities were then established in Portugal, who profited from their enterprise and financial expertise.\n\nEuropean sailing had been primarily close to land cabotage, guided by portolan charts. These charts specified proven ocean routes guided by coastal landmarks: sailors departed from a known point, followed a compass heading, and tried to identify their location by its landmarks. For the first oceanic exploration Western Europeans used the compass, as well as progressive new advances in cartography and astronomy. Arab navigational tools like the astrolabe and quadrant were used for celestial navigation.\n\nIn 1297, with the Portuguese part of the reconquista completed, King Dinis of Portugal took personal interest in exports and in 1317 he made an agreement with Genoese merchant sailor Manuel Pessanha (Pesagno), appointing him first admiral of the Portuguese navy, with the goal of defending the country against Muslim pirate raids. Outbreaks of bubonic plague led to severe depopulation in the second half of the 14th century: only the sea offered alternatives, with most population settling in fishing and trading coastal areas. Between 1325 and 1357 Afonso IV of Portugal encouraged maritime commerce and ordered the first explorations. The Canary Islands, already known to the Genoese, were claimed as officially discovered under patronage of the Portuguese but in 1344 Castile disputed them, expanding their rivalry into the sea.\n\nTo ensure their monopoly on trade, Europeans (beginning with the Portuguese) attempted to install a mediterranean system of trade which used military might and intimidation to divert trade through ports they controlled; there it could be taxed. In 1415, Ceuta was conquered by the Portuguese aiming to control navigation of the African coast. Young prince Henry the Navigator was there and became aware of profit possibilities in the Trans-Saharan trade routes. For centuries slave and gold trade routes linking West Africa with the Mediterranean passed over the Western Sahara Desert, controlled by the Moors of North Africa.\n\nHenry wished to know how far Muslim territories in Africa extended, hoping to bypass them and trade directly with West Africa by sea, find allies in legendary Christian lands to the south like the long-lost Christian kingdom of Prester John and to probe whether it was possible to reach the Indies by sea, the source of the lucrative spice trade. He invested in sponsoring voyages down the coast of Mauritania, gathering a group of merchants, shipowners and stakeholders interested in new sea lanes. Soon the Atlantic islands of Madeira (1419) and the Azores (1427) were reached. In particular, they were discovered by voyages launched by the command of Prince Henry the Navigator. The expedition leader himself, who established settlements on the island of Madeira, was João Gonçalves Zarco.\n\nAt the time, Europeans did not know what lay beyond Cape Non (Cape Chaunar) on the African coast, and whether it was possible to return once it was crossed. Nautical myths warned of oceanic monsters or an edge of the world, but Prince Henry's navigation challenged such beliefs: starting in 1421, systematic sailing overcame it, reaching the difficult Cape Bojador that in 1434 one of Prince Henry's captains, Gil Eanes, finally passed.\n\nA major advance was the introduction of the caravel in the mid-15th century, a small ship able to sail windward more than any other in Europe at the time. Evolved from fishing ships designs, they were the first that could leave the coastal cabotage navigation and sail safely on the open Atlantic. For celestial navigation the Portuguese used the Ephemerides, which experienced a remarkable diffusion in the 15th century. These were astronomical charts plotting the location of the stars over a distinct period of time. Published in 1496 by the Jewish astronomer, astrologer, and mathematician Abraham Zacuto, the Almanach Perpetuum included some of these tables for the movements of stars. These tables revolutionized navigation, allowing the calculation of latitude. Exact longitude, however, remained elusive, and mariners struggled to determine it for centuries. Using the caravel, systematic exploration continued ever more southerly, advancing on average one degree a year. Senegal and Cape Verde Peninsula were reached in 1445 and in 1446, Álvaro Fernandes pushed on almost as far as present-day Sierra Leone.\n\nIn 1453 the fall of Constantinople to the hands of the Ottomans was a blow to Christendom and the established business relations linking with the east. In 1455 Pope Nicholas V issued the bull \"Romanus Pontifex\" reinforcing the previous \"Dum Diversas\" (1452), granting all lands and seas discovered beyond Cape Bojador to King Afonso V of Portugal and his successors, as well as trade and conquest against Muslims and pagans, initiating a \"mare clausum\" policy in the Atlantic. The king, who had been inquiring of Genoese experts about a seaway to India, commissioned the Fra Mauro world map, which arrived in Lisbon in 1459.\n\nIn 1456 Diogo Gomes reached the Cape Verde archipelago. In the next decade several captains at the service of Prince Henry – including the Genoese Antonio da Noli and Venetian Alvise Cadamosto – discovered the remaining islands which were occupied during the 15th century. The Gulf of Guinea would be reached in the 1460s.\n\nIn 1460 Pedro de Sintra reached Sierra Leone. Prince Henry died in November that year after which, given the meagre revenues, exploration was granted to Lisbon merchant Fernão Gomes in 1469, who in exchange for the monopoly of trade in the Gulf of Guinea had to explore each year for five years. With his sponsorship, explorers João de Santarém, Pedro Escobar, Lopo Gonçalves, Fernão do Pó, and Pedro de Sintra made it even beyond those goals. They reached the Southern Hemisphere and the islands of the Gulf of Guinea, including São Tomé and Príncipe and Elmina on the Gold Coast in 1471. (In the Southern Hemisphere, they used the Southern Cross as the reference for celestial navigation.) There, in what came to be called the \"Gold Coast\" in what is today Ghana, a thriving alluvial gold trade was found among the natives and Arab and Berber traders.\n\nIn 1478 (during the War of the Castilian Succession), near the coast at Elmina was fought a large battle between a Castilian armada of 35 caravels and a Portuguese fleet for hegemony of the Guinea trade (gold, slaves, ivory and melegueta pepper). The war ended with a Portuguese naval victory followed by the official recognition by the Catholic Monarchs of Portuguese sovereignty over most of the disputed West African territories embodied in the Treaty of Alcáçovas, 1479. (See entry on Elmina.) This was the first colonial war among European powers.\n\nIn 1481 the recently crowned João II decided to build São Jorge da Mina factory. In 1482 the Congo River was explored by Diogo Cão, who in 1486 continued to Cape Cross (modern Namibia).\n\nThe next crucial breakthrough was in 1488, when Bartolomeu Dias rounded the southern tip of Africa, which he named \"Cape of Storms\" (Cabo das Tormentas), anchoring at Mossel Bay and then sailing east as far as the mouth of the Great Fish River, proving that the Indian Ocean was accessible from the Atlantic. Simultaneously Pêro da Covilhã, sent out travelling secretly overland, had reached Ethiopia having collected important information about the Red Sea and Quenia coast, suggesting that a sea route to the Indies would soon be forthcoming. Soon the cape was renamed by king John II of Portugal the \"Cape of Good Hope\" (Cabo da Boa Esperança), because of the great optimism engendered by the possibility of a sea route to India, proving false the view that had existed since Ptolemy that the Indian Ocean was land-locked.\n\nBased on much later stories of the phantom island known as Bacalao and the carvings on Dighton Rock some have speculated that Portuguese explorer João Vaz Corte-Real discovered Newfoundland in 1473, but the sources cited are considered by mainstream historians to be unreliable and unconvincing.\n\nPortugal's neighbouring fellow Iberian rival, Castile, had begun to establish its rule over the Canary Islands, located off the west African coast, in 1402, but then became distracted by internal Iberian politics and the repelling of Islamic invasion attempts and raids through most of the 15th century. Only late in the century, following the unification of the crowns of Castile and Aragon and the completion of the \"reconquista\", did an emerging modern Spain become fully committed to the search for new trade routes overseas. The Crown of Aragon had been an important maritime potentate in the Mediterranean, controlling territories in eastern Spain, southwestern France, major islands like Sicily, Malta, and the Kingdom of Naples and Sardinia, with mainland possessions as far as Greece. In 1492 the joint rulers conquered the Moorish kingdom of Granada, which had been providing Castile with African goods through tribute, and decided to fund Christopher Columbus's expedition in the hope of bypassing Portugal's monopoly on west African sea routes, to reach \"the Indies\" (east and south Asia) by travelling west. Twice before, in 1485 and 1488, Columbus had presented the project to king John II of Portugal, who rejected it.\n\nOn the evening of 3 August 1492, Columbus departed from Palos de la Frontera with three ships; one larger carrack, \"Santa María\", nicknamed \"Gallega\" (\"the Galician\"), and two smaller caravels, \"Pinta\" (\"the Painted\") and \"Santa Clara\", nicknamed \"Niña\". Columbus first sailed to the Canary Islands, where he restocked for what turned out to be a five-week voyage across the ocean, crossing a section of the Atlantic that became known as the Sargasso Sea.\n\nLand was sighted on 12 October 1492, and Columbus called the island (now The Bahamas) \"San Salvador\", in what he thought to be the \"West Indies\". Columbus also explored the northeast coast of Cuba (landed on 28 October) and the northern coast of Hispaniola, by 5 December. He was received by the native cacique Guacanagari, who gave him permission to leave some of his men behind.\nOn the return, a storm forced him to dock in Lisbon, on 4 March 1493. After a week in Portugal, he set sail for Spain and on 15 March 1493 arrived in Barcelona, where he reported to Queen Isabella and King Ferdinand. Word of his discovery of new lands rapidly spread throughout Europe.\n\nColumbus and other Spanish explorers were initially disappointed with their discoveries—unlike Africa or Asia, the Caribbean islanders had little to trade with the Castilian ships. The islands thus became the focus of colonization efforts. It was not until the continent itself was explored that Spain found the wealth it had sought.\n\nShortly after Columbus's return from what would later be called the \"West Indies\", a division of influence became necessary to avoid conflict between the Spanish and Portuguese. On 4 May 1493, two months after Columbus's arrival, the Catholic Monarchs received a bull (\"Inter caetera\") from Pope Alexander VI stating that all lands west and south of a pole-to-pole line 100 leagues west and south of the Azores or the Cape Verde Islands should belong to Castile and, later, all mainlands and islands then belonging to India. It did not mention Portugal, which could not claim newly discovered lands east of the line.\n\nKing John II of Portugal was not pleased with the arrangement, feeling that it gave him far too little land—preventing him from reaching India, his main goal. He then negotiated directly with King Ferdinand and Queen Isabella of Spain to move the line west, and allowing him to claim newly discovered lands east of it.\n\nAn agreement was reached in 1494, with the Treaty of Tordesillas that divided the world between the two powers. In this treaty the Portuguese received everything outside Europe east of a line that ran 370 leagues west of the Cape Verde islands (already Portuguese), and the islands discovered by Christopher Columbus on his first voyage (claimed for Castile), named in the treaty as Cipangu and Antilia (Cuba and Hispaniola). This gave them control over Africa, Asia and eastern South America (Brazil). The Spanish (Castile) received everything west of this line. At the time of negotiation, the treaty split the known world of Atlantic islands roughly in half, with the dividing line about halfway between Portuguese Cape Verde and the Spanish discoveries in the Caribbean.\n\nPedro Álvares Cabral encountered in 1500 what is now known as the Brazilian coast, originally thought to be a large island. Since it was east of the dividing line, he claimed it for Portugal and this was respected by the Spanish. Portuguese ships sailed west into the Atlantic to get favourable winds for the journey to India, and this is where Cabral was headed on his journey, in a corridor the treaty was negotiated to protect. Some suspect the Portuguese had secretly discovered Brazil earlier, and this is why they had the line moved eastward and how Cabral found it, but there is no reliable evidence of this. Others suspect Duarte Pacheco Pereira secretly discovered Brazil in 1498, but this not considered credible by mainstream historians.\n\nLater the Spanish territory would prove to include huge areas of the continental mainland of North and South America, though Portuguese-controlled Brazil would expand across the line, and settlements by other European powers ignored the treaty.\n\nVery little of the divided area had actually been seen by Europeans, as it was only divided by a geographical definition rather than control on the ground. Columbus's first voyage in 1492 spurred maritime exploration and, from 1497, a number of explorers headed west.\n\nThat year John Cabot, also a commissioned Italian, got letters patent from King Henry VII of England. Sailing from Bristol, probably backed by the local Society of Merchant Venturers, Cabot crossed the Atlantic from a northerly latitude hoping the voyage to the \"West Indies\" would be shorter and made a landfall somewhere in North America, possibly Newfoundland.\nIn 1499 João Fernandes Lavrador was licensed by the King of Portugal and together with Pêro de Barcelos they first sighted Labrador, which was granted and named after him. After returning he possibly went to Bristol to sail in the name of England. Nearly at the same time, between 1499 and 1502 brothers Gaspar and Miguel Corte Real explored and named the coasts of Greenland and also Newfoundland. Both explorations are noted in the 1502 Cantino planisphere.\n\nIn 1497, newly crowned King Manuel I of Portugal sent an exploratory fleet eastwards, fulfilling his predecessor's project of finding a route to the Indies. In July 1499 news spread that the Portuguese had reached the \"true indies\", as a letter was dispatched by the Portuguese king to the Spanish Catholic Monarchs one day after the celebrated return of the fleet.\n\nThe third expedition by Columbus in 1498 was the beginning of the first successful Castilian (Spanish) colonization in the West Indies, on the island of Hispaniola. Despite growing doubts, Columbus refused to accept that he had not reached the Indies. During the voyage he discovered the mouth of the Orinoco River on the north coast of South America (now Venezuela) and thought that the huge quantity of fresh water coming from it could only be from a continental land mass, which he was certain was the Asian mainland.\n\nAs shipping between Seville and the West Indies grew, knowledge of the Caribbean islands, Central America and the northern coast of South America grew.\nOne of these Spanish fleets, that of Alonso de Ojeda and Amerigo Vespucci in 1499–1500, reached land at the coast of what is now Guyana, when the two explorers seem to have separated in opposite directions. Vespucci sailed southward, discovering the mouth of the Amazon River in July 1499, and reaching 6°S, in present-day north east Brazil, before turning around.\n\nIn the beginning of 1500 Vicente Yáñez Pinzon was blown off course by a storm and reached what is now the north east coast of Brazil on 26 January 1500, exploring as far south as the present-day state of Pernambuco. His fleet was the first to fully enter the Amazon River estuary which he named \"Río Santa María de la Mar Dulce\" (\"Saint Mary's River of the Freshwater Sea\"). However, the land was too far east for the Castilians to claim under the Treaty of Tordesillas, but the discovery created Castilian (\"Spanish\") interest, with a second voyage by Pinzon in 1508 (an expedition that coasted the northern coast to the Central American coastal mainland, in search of a passage to the East) and a voyage in 1515–16 by a navigator of the 1508 expedition, Juan Díaz de Solís. The 1515–16 expedition was spurred on by reports of Portuguese exploration of the region (see below). It ended when de Solís and some of his crew disappeared when exploring a River Plate river in a boat, but what it found re-ignited Spanish interest, and colonization began in 1531.\n\nIn April 1500, the second Portuguese India Armada, headed by Pedro Álvares Cabral, with a crew of expert captains, including Bartolomeu Dias and Nicolau Coelho, encountered the Brazilian coast as it swung westward in the Atlantic while performing a large \"volta do mar\" to avoid becalming in the Gulf of Guinea. On 21 April 1500 a mountain was seen and was named \"Monte Pascoal\", and on 22 April Cabral landed on the coast. On 25 April the entire fleet sailed into the harbour they named \"Porto Seguro\" (Port Secure). Cabral perceived that the new land lay east of the line of Tordesillas, and sent an envoy to Portugal with the discovery in letters, including the letter of Pero Vaz de Caminha. Believing the land to be an island, he named it Ilha de Vera Cruz (Island of the True Cross). Some historians have suggested that the Portuguese may have encountered the South American bulge earlier while sailing the \"volta do mar\", hence the insistence of John II in moving the line west of Tordesillas in 1494—so his landing in Brazil may not have been an accident; although John's motivation may have simply been to increase the chance of claiming new lands in the Atlantic. From the east coast, the fleet then turned eastward to resume the journey to the southern tip of Africa and India. Cabral was the first captain to touch four continents, leading the first expedition that connected and united Europe, Africa, the New World, and Asia.\n\nAt the invitation of King Manuel I of Portugal, Amerigo Vespucci—a Florentine who had been working for a branch of the Medici Bank in Seville since 1491, fitting oceanic expeditions and travelling twice to The Guianas with Juan de la Cosa in the service of Spain—participated as observer in these exploratory voyages to the east coast of South America. The expeditions became widely known in Europe after two accounts attributed to him, published between 1502 and 1504, suggested that the newly discovered lands were not the Indies but a \"New World\", the \"Mundus novus\", Latin title of a contemporary document based on Vespucci letters to Lorenzo di Pierfrancesco de' Medici, which had become widely popular in Europe. It was soon understood that Columbus had not reached Asia but had found a new continent, the Americas. The Americas were named in 1507 by cartographers Martin Waldseemüller and Matthias Ringmann, probably after Amerigo Vespucci.\n\nIn 1501–1502, one of these Portuguese expeditions, led by Gonçalo Coelho (and/or André Gonçalves or Gaspar de Lemos), sailed south along the coast of South America to the bay of present-day Rio de Janeiro. Amerigo Vespucci's account states that the expedition reached the latitude \"South Pole elevation 52° S\", in the \"cold\" latitudes of what is now southern Patagonia (possibly near the Strait), before turning back. Vespucci wrote that they headed toward the southwest and south, following \"a long, unbending coastline\" (apparently coincident with the southern South American coast). This seems controversial, since he changed part of his description in the subsequent letter, stating a shift, from about 32° S (Southern Brazil), to south-southeast, to open sea; maintaining, however, that they reached 50°/52° S (if it was by his own decision or by D. Manuel's censors who had to pressure him to alter his account, because he had revealed far too much to Lorenzo de' Medici and into the public domain, is unknown).\n\nIn 1503, Binot Paulmier de Gonneville, challenging the Portuguese policy of \"mare clausum\", led one of the earliest French Normand and Breton expeditions to Brazil. He intended to sail to the East Indies, but near the Cape of Good Hope his ship was diverted to west by a storm, and landed in the present day state of Santa Catarina (southern Brazil), on 5 January 1504.\nIn 1511–1512, Portuguese captains João de Lisboa and Estevão de Fróis reached the River Plate estuary in present-day Uruguay and Argentina, and went as far south as the present-day Gulf of San Matias at 42°S (recorded in the \"Newen Zeytung auss Pressilandt\" meaning \"New Tidings from the Land of Brazil\"). The expedition reached a cape extending north to south which they called Cape of \"Santa Maria\" (Punta del Este, keeping the name the Cape nearby); and after 40°S they found a \"Cape\" or \"a point or place extending into the sea\", and a \"Gulf\" (in June and July). After they had navigated for nearly to round the cape, they again sighted the continent on the other side, and steered towards the northwest, but a storm prevented them from making any headway. Driven away by the \"Tramontane\" or north wind, they retraced their course. Also gives the first news of the \"White King\" and the \"people of the mountains\" to the interior (the Inca Empire), and a gift, an ax of silver, obtained from the Charrúa natives on their return (\"to the coast or side of \"Brazil\"\"), and \"to West\" (along the coast and the River Plate estuary), and offered to King Manuel I. Christopher de Haro, a Flemish of Sephardic origin (one of the financiers of the expedition along with D. Nuno Manuel), who would serve the Spanish Crown after 1516, believed that the navigators had discovered a southern \"strait\" to west and Asia.\n\nIn 1519, an expedition sent by the Spanish Crown to find a way to Asia was led by the experienced Portuguese navigator Ferdinand Magellan. The fleet explored the rivers and bays as it charted the South American coast until it found a way to the Pacific Ocean through the Strait of Magellan.\n\nIn 1524–1525, Aleixo Garcia, a Portuguese conquistador (possibly a veteran of the Solís expedition of 1516), led a private expedition of a few shipwrecked Castilian and Portuguese adventurers, that recruited about 2000 Guaraní Indians. They explored the territories of present-day southern Brazil, Paraguay and Bolivia, using the native trail network, the \"Peabiru\". They were also the first Europeans to cross the Chaco and reach the outer territories of the Inca Empire on the hills of the Andes, near Sucre.\n\nProtected from direct Spanish competition by the treaty of Tordesillas, Portuguese eastward exploration and colonization continued apace. Twice, in 1485 and 1488, Portugal officially rejected Christopher Columbus's idea of reaching India by sailing westwards. King John II of Portugal's experts rejected it, for they held the opinion that Columbus's estimation of a travel distance of was undervalued, and in part because Bartolomeu Dias departed in 1487 trying the rounding of the southern tip of Africa, therefore they believed that sailing east would require a far shorter journey. Dias's return from the Cape of Good Hope in 1488, and Pêro da Covilhã's travel to Ethiopia overland indicated that the richness of the Indian Sea was accessible from the Atlantic. A long-overdue expedition was prepared.\n\nUnder new king Manuel I of Portugal, on July 1497 a small exploratory fleet of four ships and about 170 men left Lisbon under the command of Vasco da Gama. By December the fleet passed the Great Fish River—where Dias had turned back—and sailed into unknown waters. On 20 May 1498, they arrived at Calicut. The efforts of Vasco da Gama to get favourable trading conditions were hampered by the low value of their goods, compared with the valuable goods traded there. Two years and two days after departure, Gama and a survivor crew of 55 men returned in glory to Portugal as the first ships to sail directly from Europe to India.\n\nIn 1500, a second, larger fleet of thirteen ships and about 1500 men were sent to India. Under command of Pedro Álvares Cabral they made a first landfall on the Brazilian coast; later, in the Indian Ocean, one of Cabral's ships reached Madagascar (1501), which was partly explored by Tristão da Cunha in 1507; Mauritius was discovered in 1507, Socotra occupied in 1506. In the same year Lourenço de Almeida landed in Sri Lanka, the eastern island named \"Taprobane\" in remote accounts of Alexander the Great's and 4th-century BC Greek geographer Megasthenes. On the Asiatic mainland the first factories (trading-posts) were established at Kochi and Calicut (1501) and then Goa (1510).\n\nIn 1511, Afonso de Albuquerque conquered Malacca for Portugal, then the centre of Asian trade. East of Malacca, Albuquerque sent several diplomatic missions: Duarte Fernandes as the first European envoy to the Kingdom of Siam (modern Thailand).\n\nGetting to know the secret location of the so-called \"spice islands\"—the Maluku Islands, mainly the Banda, then the single world source of nutmeg and cloves, was the main purpose for the travels in the Indian sea—he sent an expedition led by António de Abreu to Banda (via Java and the Lesser Sunda Islands), where they were the first Europeans to arrive in early 1512, after taking a route through which they also reached first the islands of Buru, Ambon and Seram. From Banda Abreu returned to Malacca, while his vice-captain Francisco Serrão, after a separation forced by a shipwreck and heading north, reached once again Ambon and sank off Ternate, where he obtained a license to build a Portuguese fortress-factory: the Fort of São João Baptista de Ternate, which founded the Portuguese presence in the Malay Archipelago.\n\nIn May 1513 Jorge Álvares, one of the Portuguese envoys, reached China. Although he was the first to land on Lintin Island in the Pearl River Delta, it was Rafael Perestrello—a cousin of the famed Christopher Columbus—who became the first European explorer to land on the southern coast of mainland China and trade in Guangzhou in 1516, commanding a Portuguese vessel with a crew from a Malaysian junk that had sailed from Malacca. Fernão Pires de Andrade visited Canton in 1517 and opened up trade with China. The Portuguese were defeated by the Chinese in 1521 at the Battle of Tunmen and in 1522 at the Battle of Xicaowan, during which the Chinese captured Portuguese breech-loading swivel guns and reverse engineered the technology, calling them \"Folangji\" 佛郎機 (Frankish) guns, since the Portuguese were called \"Folangji\" by the Chinese. After a few decades, hostilities between the Portuguese and Chinese ceased and in 1557 the Chinese allowed the Portuguese to occupy Macau.\n\nTo enforce a trade monopoly, Muscat, and Hormuz in the Persian Gulf, were seized by Afonso de Albuquerque in 1507 and in 1515, respectively. He also entered into diplomatic relations with Persia. In 1513 while trying to conquer Aden, an expedition led by Albuquerque cruised the Red Sea inside the Bab al-Mandab, and sheltered at Kamaran island. In 1521, a force under António Correia conquered Bahrain, ushering in a period of almost eighty years of Portuguese rule of the Gulf archipelago. In the Red Sea, Massawa was the most northerly point frequented by the Portuguese until 1541, when a fleet under Estevão da Gama penetrated as far as Suez.\n\nIn 1513, about south of Acandí, in present-day Colombia, Spanish Vasco Núñez de Balboa heard unexpected news of an \"other sea\" rich in gold, which he received with great interest. With few resources and using information given by \"caciques\", he journeyed across the Isthmus of Panama with 190 Spaniards, a few native guides, and a pack of dogs.\n\nUsing a small brigantine and ten native canoes, they sailed along the coast and made landfalls. On September 6, the expedition was reinforced with 1,000 men, fought several battles, entered a dense jungle and climbed the mountain range along the Chucunaque River from where this \"other sea\" could be seen. Balboa went ahead and, before noon September 25, he saw in the horizon an undiscovered sea, becoming the first European to have seen or reached the Pacific from the New World. The expedition descended towards the shore for a short reconnaissance trip, thus becoming the first Europeans to navigate the Pacific Ocean off the coast of the New World. After travelling more than , Balboa named the bay where they ended up \"San Miguel\". He named the new sea \"Mar del Sur\" (South Sea), since they had travelled south to reach it. Balboa's main purpose in the expedition was the search for gold-rich kingdoms. To this end, he crossed through the lands of \"caciques\" to the islands, naming the largest one \"Isla Rica\" (Rich Island, today known as Isla del Rey). He named the entire group \"Archipiélago de las Perlas\", which they still keep today.\n\nIn 1515–1516, the Spanish fleet led by Juan Díaz de Solís sailed down the east coast of South America as far as Río de la Plata, which Solís named shortly before he died, while trying to find a passage to the \"South Sea\".\n\nAt the same time, the Portuguese in Southeast Asia made the first European report on the western Pacific, having identified Luzon east of Borneo and named its inhabitants the \"Luções\", in the modern Philippines.\n\nBy 1516 several Portuguese navigators, conflicting with King Manuel I of Portugal, had gathered in Seville to serve the newly crowned Charles I of Spain. Among them were explorers Diogo and Duarte Barbosa, Estêvão Gomes, João Serrão and Ferdinand Magellan, cartographers Jorge Reinel and Diogo Ribeiro, cosmographers Francisco and Ruy Faleiro and the Flemish merchant Christopher de Haro. Ferdinand Magellan—who had sailed in India for Portugal up to 1513, when the Maluku Islands were reached, kept contact with Francisco Serrão living there—developed the theory that the islands were in the Tordesillas Spanish area, supported on studies by Faleiro brothers.\n\nAware of the efforts of the Spanish to find a route to India by sailing west, Magellan presented his plan to Charles I of Spain. The king and Christopher de Haro financed Magellan's expedition. A fleet was put together, and Spanish navigators such as Juan Sebastián Elcano joined the enterprise. On August 10, 1519, they departed from Seville with a fleet of five ships—the flagship \"Trinidad\" under Magellan's command, \"San Antonio\", \"Concepcion\", \"Santiago\" and \"Victoria\", the first being a caravel, and all others rated as carracks or \"naus\"—with a crew of about 237 men from several nations, with the goal of reaching the Maluku Islands by travelling west, trying to reclaim it under Spain's economic and political sphere.\nThe fleet sailed further and further south, avoiding the Portuguese territories in Brazil, and became the first to reach Tierra del Fuego at the tip of the Americas. On October 21, starting in Cape Virgenes, they began an arduous trip through a 373-mile (600 km) long strait that Magellan named \"Estrecho de Todos los Santos\", the modern Strait of Magellan. On November 28, three ships entered the Pacific Ocean—then named \"Mar Pacífico\" because of its apparent stillness. The expedition managed to cross the Pacific. Magellan died in the battle of Mactan in the Philippines, leaving the Spaniard Juan Sebastián Elcano the task of completing the voyage, reaching the Spice Islands in 1521. On September 6, 1522 \"Victoria\" returned to Spain, thus completing the first circumnavigation of the globe. Of the men who set out on five ships, only 18 completed the circumnavigation and managed to return to Spain in this single vessel led by Elcano. Seventeen others arrived later in Spain: twelve captured by the Portuguese in Cape Verde some weeks earlier, and between 1525 and 1527, and five survivors of the \"Trinidad\". Antonio Pigafetta, a Venetian scholar and traveller who had asked to be on board and become a strict assistant of Magellan, kept an accurate journal that become the main source for much of what we know about this voyage.\n\nThis round-the-world voyage gave Spain valuable knowledge of the world and its oceans which later helped in the exploration and settlement of the Philippines. Although this was not a realistic alternative to the Portuguese route around Africa (the Strait of Magellan was too far south, and the Pacific Ocean too vast to cover in a single trip from Spain) successive Spanish expeditions used this information to explore the Pacific Ocean and discovered routes that opened up trade between Acapulco, New Spain (present-day Mexico) and Manila in the Philippines.\n\nSoon after Magellan's expedition, the Portuguese rushed to seize the surviving crew and built a fort in Ternate. In 1525, Charles I of Spain sent another expedition westward to colonize the Maluku Islands, claiming that they were in his zone of the Treaty of Tordesillas. The fleet of seven ships and 450 men was led by García Jofre de Loaísa and included the most notable Spanish navigators: Juan Sebastián Elcano and Loaísa, who lost their lives then, and the young Andrés de Urdaneta.\n\nNear the Strait of Magellan one of the ships was pushed south by a storm, reaching 56° S, where they thought seeing \"earth's end\": so Cape Horn was crossed for the first time. The expedition reached the islands with great difficulty, docking at Tidore. The conflict with the Portuguese established in nearby Ternate was inevitable, starting nearly a decade of skirmishes.\n\nAs there was not a set eastern limit to the Tordesillas line, both kingdoms organized meetings to resolve the issue. From 1524 to 1529 Portuguese and Spanish experts met at Badajoz-Elvas trying to find the exact location of the antimeridian of Tordesillas, which would divide the world into two equal hemispheres. Each crown appointed three astronomers and cartographers, three pilots and three mathematicians. Lopo Homem, Portuguese cartographer and cosmographer was in the board, along with cartographer Diogo Ribeiro on the Spanish delegation. The board met several times, without reaching an agreement: the knowledge at that time was insufficient for an accurate calculation of longitude, and each group gave the islands to its sovereign. The issue was settled only in 1529, after a long negotiation, with the signing of Treaty of Zaragoza, that attributed the Maluku Islands to Portugal and the Philippines to Spain.\n\nBetween 1525 and 1528 Portugal sent several expeditions around the Maluku Islands. Gomes de Sequeira and Diogo da Rocha were sent north by the governor of Ternate Jorge de Menezes, being the first Europeans to reach the Caroline Islands, which they named \"Islands de Sequeira\". In 1526, Jorge de Meneses docked on Biak and Waigeo islands, Papua New Guinea. Based on these explorations stands the theory of Portuguese discovery of Australia, one among several competing theories about the early discovery of Australia, supported by Australian historian Kenneth McIntyre, stating it was discovered by Cristóvão de Mendonça and Gomes de Sequeira.\n\nIn 1527 Hernán Cortés fitted out a fleet to find new lands in the \"South Sea\" (Pacific Ocean), asking his cousin Álvaro de Saavedra Cerón to take charge. On October 31 of 1527 Saavedra sailed from New Spain, crossing the Pacific and touring the north of New Guinea, then named \"Isla de Oro\". In October 1528 one of the vessels reached the Maluku Islands. In his attempt to return to New Spain he was diverted by the northeast trade winds, which threw him back, so he tried sailing back down, to the south. He returned to New Guinea and sailed northeast, where he sighted the Marshall Islands and the Admiralty Islands, but again was surprised by the winds, which brought him a third time to the Moluccas. This westbound return route was hard to find, but was eventually discovered by Andrés de Urdaneta in 1565.\n\nRumours of undiscovered islands northwest of Hispaniola had reached Spain by 1511 and king Ferdinand II of Aragon was interested in forestalling further exploration. While Portuguese were making huge gains in the Indian Ocean, the Spanish invested in exploring inland in search of gold and valuable resources. The members of these expeditions, the \"conquistadors\", came from a variety of backgrounds including artisans, merchants, clergy, lesser nobility and freed slaves. They usually supplied their own equipment in exchange for a share in profits, having no direct connection with the royal army, and often no professional military training or experience.\n\nIn the Americas the Spanish found a number of empires that were as large and populous as those in Europe. However, small bodies of \"conquistadors\", with large armies of Indigenous Americans groups, managed to conquer these states. During this time, pandemics of European disease such as smallpox devastated the indigenous populations. Once Spanish sovereignty was established, the Spanish focused on the extraction and export of gold and silver.\n\nIn 1512, to reward Juan Ponce de León for exploring Puerto Rico in 1508, king Ferdinand urged him to seek these new lands. He would become governor of discovered lands, but was to finance himself all exploration. With three ships and about 200 men, Léon set out from Puerto Rico in March 1513. In April they sighted land and named it \"La Florida\"—because it was Easter (Florida) season—believing it was an island, becoming credited as the first European to land in the continent. The arrival location has been disputed between St. Augustine, Ponce de León Inlet and Melbourne Beach. They headed south for further exploration and on April 8 encountered a current so strong that it pushed them backwards: this was the first encounter with the Gulf Stream that would soon become the primary route for eastbound ships leaving the Spanish Indies bound for Europe. They explored down the coast reaching Biscayne Bay, Dry Tortugas and then sailing southwest in an attempt to circle Cuba to return, reaching Grand Bahama on July.\n\nIn 1517 Cuba's governor Diego Velázquez de Cuéllar commissioned a fleet under the command of Hernández de Córdoba to explore the Yucatán peninsula. They reached the coast where Mayans invited them to land, but were attacked at night and only a remnant of the crew returned. Velázquez then commissioned another expedition led by his nephew Juan de Grijalva, who sailed south along the coast to Tabasco, part of the Aztec empire. In 1518 Velázquez gave the mayor of the capital of Cuba, Hernán Cortés, the command of an expedition to secure the interior of Mexico but, due to an old gripe between them, revoked the charter.\n\nIn February 1519 Cortés went ahead anyway, in an act of open mutiny. With about 11 ships, 500 men, 13 horses and a small number of cannons he landed in Yucatán, in Mayan territory, claiming the land for the Spanish crown. From Trinidad he proceeded to Tabasco and won a battle against the natives. Among the vanquished was La Malinche, his future mistress, who knew both (Aztec) Nahuatl language and Maya, becoming a valuable interpreter and counsellor. Through her, Cortés learned about the wealthy Aztec Empire.\n\nIn July his men took over Veracruz and he placed himself under direct orders of new king Charles I of Spain. There Cortés asked for a meeting with Aztec Emperor Montezuma II, who repeatedly refused. They headed to Tenochtitlan and on the way made alliances with several tribes. In October, accompanied by about 3,000 Tlaxcaltec they marched to Cholula, the second largest city in central Mexico. Either to instill fear upon the Aztecs waiting for him or (as he later claimed) wishing to make an example when he feared native treachery, they massacred thousands of unarmed members of the nobility gathered at the central plaza and partially burned the city.\n\nArriving in Tenochtitlan with a large army, on November 8 they were peacefully received by Moctezuma II, who deliberately let Cortés enter the heart of the Aztec Empire, hoping to know them better to crush them later. The emperor gave them lavish gifts in gold which enticed them to plunder vast amounts. In his letters to King Charles, Cortés claimed to have learned then that he was considered by the Aztecs to be either an emissary of the feathered serpent god Quetzalcoatl or Quetzalcoatl himself—a belief contested by a few modern historians. But he soon learned that his men on the coast had been attacked, and decided to hostage Moctezuma in his palace, demanding a ransom as tribute to King Charles.\n\nMeanwhile, Velasquez sent another expedition, led by Pánfilo de Narváez, to oppose Cortès, arriving in Mexico in April 1520 with 1,100 men. Cortés left 200 men in Tenochtitlan and took the rest to confront Narvaez, whom he overcame, convincing his men to join him. In Tenochtitlán one of Cortés's lieutenants committed a massacre in the Great Temple, triggering local rebellion. Cortés speedily returned, attempting the support of Moctezuma but the Aztec emperor was killed, possibly stoned by his subjects. The Spanish fled for the Tlaxcaltec during the \"Noche Triste\", where they managed a narrow escape while their back guard was massacred. Much of the treasure looted was lost during this panicked escape. After a battle in Otumba they reached Tlaxcala, having lost 870 men. Having prevailed with the assistance of allies and reinforcements from Cuba, Cortés besieged Tenochtitlán and captured its ruler Cuauhtémoc in August 1521. As the Aztec Empire ended he claimed the city for Spain, renaming it Mexico City.\n\nA first attempt to explore western South America was undertaken in 1522 by Pascual de Andagoya. Native South Americans told him about a gold-rich territory on a river called Pirú. Having reached San Juan River (Colombia), Andagoya fell ill and returned to Panama, where he spread news about \"Pirú\" as the legendary El Dorado. These, along with the accounts of success of Hernán Cortés, caught the attention of Pizarro.\n\nFrancisco Pizarro had accompanied Balboa in the crossing of the Isthmus of Panama. In 1524 he formed a partnership with priest Hernando de Luque and soldier Diego de Almagro to explore the south, agreeing to divide the profits. They dubbed the enterprise the \"Empresa del Levante\": Pizarro would command, Almagro would provide military and food supplies, and Luque would be in charge of finances and additional provisions.\n\nOn 13 September 1524, the first of three expeditions left to conquer Peru with about 80 men and 40 horses. The expedition was a failure, reaching no farther than Colombia before succumbing to bad weather, hunger and skirmishes with hostile locals, where Almagro lost an eye. The place names bestowed along their route, \"Puerto deseado\" (desired port), \"Puerto del hambre\" (port of hunger) and \"Puerto quemado\" (burned port), attest to the difficulties of their journey. Two years later they began a second expedition with reluctant permission from the Governor of Panama. In August 1526, they left with two ships, 160 men and several horses. Upon reaching San Juan River they separated, Pizarro staying to explore the swampy coasts and Almagro sent back for reinforcements. Pizarro's main pilot sailed south and, after crossing the equator, captured a raft from Tumbes. To his surprise, it carried textiles, ceramic and much-desired gold, silver, and emeralds, becoming the central focus of the expedition. Soon Almagro joined with reinforcements and they resumed. After a difficult voyage facing strong winds and currents, they reached Atacames where they found a large native population under Inca rule, but they did not land.\n\nPizarro remained safe near the coast, while Almagro and Luque went back for reinforcements with proof of the rumoured gold. The new governor outright rejected a third expedition and ordered two ships to bring everyone back to Panama. Almagro and Luque grasped the opportunity to join Pizarro. When they arrived at the \"Isla de Gallo\", Pizarro drew a line in the sand, saying: \"There lies Peru with its riches; Here, Panama and its poverty. Choose, each man, what best becomes a brave Castilian.\" Thirteen men decided to stay and became known as \"The Famous Thirteen\". They headed for \"La Isla Gorgona\", where they remained for seven months before the arrival of provisions.\n\nThey decided to sail south and, by April 1528, reached the northwestern Peruvian Tumbes Region and were warmly received by local \"Tumpis\". Two of Pizarro's men reported incredible riches, including gold and silver decorations around the chief's house. They saw for the first time a llama which Pizarro called \"little camels\". The natives named the Spanish \"Children of the Sun\" for their fair complexion and brilliant armours. They decided then to return to Panama to prepare a final expedition. Before leaving they sailed south through territories they named such as Cabo Blanco, port of Payta, Sechura, Punta de Aguja, Santa Cruz, and Trujillo, reaching the ninth degree south.\n\nIn the spring of 1528 Pizarro sailed for Spain, where he had an interview with king Charles I. The king heard of his expeditions in lands rich in gold and silver and promised to support him. The \"Capitulación de Toledo\" authorized Pizarro to proceed with the conquest of Peru. Pizarro was then able to convince many friends and relatives to join: his brothers Hernándo Pizarro, Juan Pizarro, Gonzalo Pizarro and also Francisco de Orellana, who would later explore the Amazon River, as well as his cousin Pedro Pizarro.\n\nPizarro's third and final expedition left Panama for Peru on 27 December 1530. With three ships and one hundred and eighty men they landed near Ecuador and sailed to Tumbes, finding the place destroyed. They entered the interior and established the first Spanish settlement in Peru, San Miguel de Piura. One of the men returned with an Incan envoy and an invitation for a meeting. Since the last meeting, the Inca had begun a civil war and Atahualpa had been resting in northern Peru following the defeat of his brother Huáscar. After marching for two months, they approached Atahualpa. He refused the Spanish, however, saying he would \"be no man's tributary.\" There were fewer than 200 Spanish to his 80,000 soldiers, but Pizarro attacked and won the Incan army in the Battle of Cajamarca, taking Atahualpa captive at the so-called ransom room. Despite fulfilling his promise of filling one room with gold and two with silver, he was convicted for killing his brother and plotting against Pizarro, and was executed.\n\nIn 1533, Pizarro invaded Cuzco with indigenous troops and wrote to King Charles I: \"This city is the greatest and the finest ever seen in this country or anywhere in the Indies ... it is so beautiful and has such fine buildings that it would be remarkable even in Spain.\" After the Spanish had sealed the conquest of Peru, Jauja in fertile Mantaro Valley was established as Peru's provisional capital, but it was too far up in the mountains, and Pizarro founded the city of Lima on 18 January 1535, which Pizarro considered one of the most important acts in his life.\n\nIn 1543 three Portuguese traders accidentally became the first Westerners to reach and trade with Japan. According to Fernão Mendes Pinto, who claimed to be in this journey, they arrived at Tanegashima, where the locals were impressed by firearms that would be immediately made by the Japanese on a large scale.\n\nThe Spanish conquest of the Philippines was ordered by Philip II of Spain, and Andrés de Urdaneta was the designated commander. Urdaneta agreed to accompany the expedition but refused to command and Miguel López de Legazpi was appointed instead. The expedition set sail on November 1564. After spending some time on the islands, Legazpi sent Urdaneta back to find a better return route. Urdaneta set sail from San Miguel on the island of Cebu on June 1, 1565, but was obliged to sail as far as 38 degrees North latitude to obtain favourable winds.\nHe reasoned that the trade winds of the Pacific might move in a gyre as the Atlantic winds did. If in the Atlantic, ships made the \"Volta do mar\" to pick up winds that would bring them back from Madeira, then, he reasoned, by sailing far to the north before heading east, he would pick up trade winds to bring him back to North America. His hunch paid off, and he hit the coast near Cape Mendocino, California, then followed the coast south. The ship reached the port of Acapulco, on October 8, 1565, having travelled in 130 days. Fourteen of his crew died; only Urdaneta and Felipe de Salcedo, nephew of López de Legazpi, had strength enough to cast the anchors.\n\nThus, a cross-Pacific Spanish route was established, between Mexico and the Philippines. For a long time these routes were used by the Manila galleons, thereby creating a trade link joining China, the Americas, and Europe via the combined trans-Pacific and trans-Atlantic routes.\n\nNations outside Iberia refused to acknowledge the Treaty of Tordesillas. France, the Netherlands and England each had a long maritime tradition and had been engaging in privateering. Despite Iberian protections, the new technologies and maps soon made their way north.\n\nIn 1568 the Dutch rebelled against the rule of Philip II of Spain leading to the Eighty Years' War. War between England and Spain also broke out. In 1580 Philip II became King of Portugal, as heir to the Crown. The combined empires were simply too big to go unchallenged by European rivals.\n\nPhilip's troops conquered the important trading cities of Bruges and Ghent. Antwerp, then the most important port in the world, fell in 1585. The Protestant population was given two years to settle affairs before leaving the city. Many settled in Amsterdam. Those were mainly skilled craftsmen, rich merchants of the port cities and refugees that fled religious persecution, particularly Sephardi Jews from Portugal and Spain and, later, the Huguenots from France. The Pilgrim Fathers also spent time there before going to the New World. This mass immigration was an important driving force: a small port in 1585, Amsterdam quickly transformed into one of the most important commercial centres in the world. After the defeat of the Spanish Armada in 1588 there was a huge expansion of maritime trade even though the defeat of the English Armada would confirm the naval supremacy of the Spanish navy over the emergent competitors.\n\nThe emergence of Dutch maritime power was swift and remarkable: for years Dutch sailors had participated in Portuguese voyages to the east, as able seafarers and keen mapmakers. In 1592, Cornelis de Houtman was sent by Dutch merchants to Lisbon, to gather as much information as he could about the Spice Islands. In 1595, merchant and explorer Jan Huyghen van Linschoten, having travelled widely in the Indian Ocean at the service of the Portuguese, published a travel report in Amsterdam, the \"Reys-gheschrift vande navigatien der Portugaloysers in Orienten\" (\"Report of a journey through the navigations of the Portuguese in the East\"). This included vast directions on how to navigate between Portugal and the East Indies and to Japan. That same year Houtman followed this directions in the Dutch first exploratory travel that discovered a new sea route, sailing directly from Madagascar to Sunda Strait in Indonesia and signing a treaty with the Banten Sultan.\n\nDutch and British interest, fed on new information, led to a movement of commercial expansion, and the foundation of English (1600), and Dutch (1602) chartered companies. Dutch, French, and English sent ships which flouted the Portuguese monopoly, concentrated mostly on the coastal areas, which proved unable to defend against such a vast and dispersed venture.\n\nThe 1497 English expedition led by Italian Venetian John Cabot (Giovanni Caboto) was the first of a series of French and English missions exploring North America. Spain put limited efforts into exploring the northern part of the Americas, as its resources were concentrated in Central and South America where more wealth had been found. These expeditions were hoping to find an oceanic Northwest Passage to Asian trade. This was never discovered, but other possibilities were found, and in the early 17th century colonists from a number of Northern European states began to settle on the east coast of North America. In 1520–1521 the Portuguese João Álvares Fagundes, accompanied by couples of mainland Portugal and the Azores, explored Newfoundland and Nova Scotia (possibly reaching the Bay of Fundy on the Minas Basin), and established a fishing colony on the Cape Breton Island, that would last until at least the 1570s or near the end of the century.\n\nIn 1524, Italian Giovanni da Verrazzano sailed at the behest of Francis I of France, who was motivated by indignation over the division of the world between Portuguese and Spanish. Verrazzano explored the Atlantic Coast of North America, from South Carolina to Newfoundland, and was the first recorded European to visit what would later become the Virginia Colony and the United States. In the same year Estevão Gomes, a Portuguese cartographer who had sailed in Ferdinand Magellan's fleet, explored Nova Scotia, sailing South through Maine, where he entered New York Harbor, the Hudson River and eventually reached Florida in August 1525. As a result of his expedition, the 1529 Diogo Ribeiro world map outlines the East coast of North America almost perfectly. From 1534 to 1536, French explorer Jacques Cartier, believed to have accompanied Verrazzano to Nova Scotia and Brazil, was the first European to travel inland in North America, describing the Gulf of Saint Lawrence, which he named \"The Country of Canadas\", after Iroquois names, claiming what is now Canada for Francis I of France.\n\nEuropeans explored the Pacific Coast beginning in the mid-16th century. Francisco de Ulloa explored the Pacific coast of present-day Mexico including the Gulf of California, proving that Baja California was a peninsula. Despite his discoveries, the myth persisted in Europe that California was an island. His account provided the first recorded use of the name \"California\". João Rodrigues Cabrilho, a Portuguese navigator sailing for the Spanish Crown, was the first European to set foot in California, landing on September 28, 1542 on the shores of San Diego Bay and claiming California for Spain. He also landed on San Miguel, one of the Channel Islands, and continued as far as Point Reyes. After his death the crew continued exploring as far north as Oregon.\n\nThe English naval commander Francis Drake sailed along the coast in 1579 somewhere north of Cabrillo's landing site—the actual location of Drake's landing was secret and is still undetermined\n—and claimed the land for England, calling it Nova Albion. The term \"Nova Albion\" was therefore used on many European maps to designate territory north of the Spanish settlements.\n\nBetween 1609 and 1611, after several voyages on behalf of English merchants to explore a prospective Northeast Passage to India, Kingdom of England's Henry Hudson, under the auspices of the Dutch East India Company (VOC), explored the region around present-day New York City, while looking for a western route to Asia. He explored the Hudson River and laid the foundation for Dutch colonization of the region. Hudson's final expedition ranged farther north in search of the Northwest Passage, leading to his discovery of the Hudson Strait and Hudson Bay. After wintering in the James Bay, Hudson tried to press on with his voyage in the spring of 1611, but his crew mutinied and they cast him adrift.\n\nFrance, the Netherlands, and England were left without a sea route to Asia, either via Africa or South America. When it became apparent that there was no route through the heart of the Americas, attention turned to the possibility of a passage through northern waters, which English called the Northwest Passage. The desire to establish such a route motivated much of the European exploration of both coasts of North America and in Russia. In Russia the idea of a possible seaway connecting the Atlantic and the Pacific was first put forward by the diplomat Gerasimov in 1525, although Russian settlers on the coast of the White Sea, the Pomors, had been exploring parts of the route as early as the 11th century.\n\nIn 1553 English explorer Hugh Willoughby with chief pilot Richard Chancellor were sent out with three vessels in search of a passage by London's Company of Merchant Adventurers to New Lands. During the voyage across the Barents Sea, Willoughby thought he saw islands to the north, and islands called Willoughby's Land were shown on maps published by Plancius and Mercator into the 1640s. The vessels were separated by \"terrible whirlwinds\" in the Norwegian Sea and Willoughby sailed into a bay near the present border between Finland and Russia. His ships with the frozen crews, including Captain Willoughby and his journal, were found by Russian fishermen a year later. Richard Chancellor was able to drop anchor in the White Sea and trudge his way overland to Moscow and Ivan the Terrible's Court, opening trade with Russia and the Company of Merchant Adventurers became the Muscovy Company.\n\n5 June 1594, Dutch cartographer Willem Barentsz departed from Texel in a fleet of three ships to enter the Kara Sea, with the hopes of finding the Northeast Passage above Siberia. At Williams Island the crew encountered a polar bear for the first time. They managed to bring it on board, but the bear rampaged and was killed. Barentsz reached the west coast of Novaya Zemlya and followed it northward, before being forced to turn back in the face of large icebergs.\n\nThe following year, Prince Maurice of Orange named him chief pilot of a new expedition of six ships, loaded with merchant wares that the Dutch hoped to trade with China. The party came across Samoyed \"wild men\" but eventually turned back upon discovering the Kara Sea frozen. In 1596, the States-General offered a high reward for anybody who \"successfully\" navigated the Northeast Passage. The Town Council of Amsterdam purchased and outfitted two small ships, captained by Jan Rijp and Jacob van Heemskerk, to search for the elusive channel, under the command of Barents. They set off on May, and on June discovered Bear Island and Spitsbergen, sighting its northwest coast. They saw a large bay, later called Raudfjorden and entered Magdalenefjorden, which they named \"Tusk Bay\", sailing into the northern entrance of Forlandsundet, which they called \"Keerwyck\", but were forced to turn back because of a shoal. On 28 June they rounded the northern point of Prins Karls Forland, which they named \"Vogelhoek\", on account of the large number of birds, and sailed south, passing Isfjorden and Bellsund, which were labelled on Barentsz's chart as \"Grooten Inwyck\" and \"Inwyck\".\n\nThe ships once again reached Bear Island on 1 July, which led to a disagreement. They parted ways, with Barentsz continuing northeast, while Rijp headed north. Barentsz reached Novaya Zemlya and, to avoid becoming entrapped in ice, headed for the Vaigatch Strait but became stuck within the icebergs and floes. Stranded, the 16-man crew was forced to spend the winter on the ice. The crew used lumber from their ship to build a lodge they called \"Het Behouden Huys\" (The Kept House). Dealing with extreme cold, they used the merchant fabrics to make additional blankets and clothing and caught Arctic foxes in primitive traps, as well as polar bears. When June arrived, and the ice had still not loosened its grip on the ship, scurvy-ridden survivors took two small boats out into the sea. Barentsz died at sea on 20 June 1597, while studying charts. It took seven more weeks for the boats to reach Kola where they were rescued by a Russian merchant vessel. Only 12 crewmen remained, reaching Amsterdam in November. Two of Barentsz' crewmembers later published their journals, Jan Huyghen van Linschoten, who had accompanied him on the first two voyages, and Gerrit de Veer who had acted as the ship's carpenter on the last.\n\nIn 1608, Henry Hudson made a second attempt, trying to go across the top of Russia. He made it to Novaya Zemlya but was forced to turn back. Between 1609 and 1611, Hudson, after several voyages on behalf of English merchants to explore a prospective Northern Sea Route to India, explored the region around modern New York City while looking for a western route to Asia under the auspices of the Dutch East India Company (VOC).\n\n\"Terra Australis Ignota\" (Latin, \"the unknown land of the south\") was a hypothetical continent appearing on European maps from the 15th to the 18th centuries, with roots in a notion introduced by Aristotle. It was depicted on the mid-16th-century Dieppe maps, where its coastline appeared just south of the islands of the East Indies; it was often elaborately charted, with a wealth of fictitious detail. The discoveries reduced the area where the continent could be found; however, many cartographers held to Aristotle's opinion, like Gerardus Mercator (1569) and Alexander Dalrymple even so late as 1767 argued for its existence, with such arguments as that there should be a large landmass in the Southern Hemisphere as a counterweight to the known landmasses in the Northern Hemisphere. As new lands were discovered, they were often assumed to be parts of this hypothetical continent.\n\nJuan Fernandez, sailing from Chile in 1576, claimed he had discovered the Southern Continent. Luis Váez de Torres, a Galician navigator working for the Spanish Crown, proved the existence of a passage south of New Guinea, now known as Torres Strait. Pedro Fernandes de Queirós, a Portuguese navigator sailing for the Spanish Crown, saw a large island south of New Guinea in 1606, which he named La Australia del Espiritu Santo. He represented this to the King of Spain as the Terra Australis incognita. In fact, it was not Australia but an island in present-day Vanuatu.\n\nDutch navigator and colonial governor, Willem Janszoon sailed from the Netherlands for the East Indies for the third time on December 18, 1603, as captain of the \"Duyfken\" (or \"Duijfken\", meaning \"Little Dove\"), one of twelve ships of the great fleet of Steven van der Hagen. Once in the Indies, Janszoon was sent to search for other outlets of trade, particularly in \"the great land of Nova Guinea and other East and Southlands.\" On November 18, 1605, the \"Duyfken\" sailed from Bantam to the coast of western New Guinea. Janszoon then crossed the eastern end of the Arafura Sea, without seeing the Torres Strait, into the Gulf of Carpentaria. On February 26, 1606, he made landfall at the Pennefather River on the western shore of Cape York in Queensland, near the modern town of Weipa. This is the first recorded European landfall on the Australian continent. Janszoon proceeded to chart some of the coastline, which he thought was a southerly extension of New Guinea. In 1615, Jacob le Maire and Willem Schouten's rounding of Cape Horn proved that Tierra del Fuego was a relatively small island.\n\nIn 1642–1644 Abel Tasman, also a Dutch explorer and merchant in the service of the VOC, circumnavigated New Holland proving that Australia was not part of the mythical southern continent. He was the first known European expedition to reach the islands of Van Diemen's Land (now Tasmania) and New Zealand and to sight the Fiji islands, which he did in 1643. Tasman, his navigator Visscher, and his merchant Gilsemans also mapped substantial portions of Australia, New Zealand and the Pacific Islands.\n\nIn the mid-16th century the Tsardom of Russia conquered the Tatar khanates of Kazan and Astrakhan, thus annexing the entire Volga Region and opening the way to the Ural Mountains. The colonization of the new easternmost lands of Russia and further onslaught eastward was led by the rich merchants Stroganovs. Tsar Ivan IV granted vast estates near the Urals as well as tax privileges to Anikey Stroganov, who organized large scale migration to these lands. Stroganovs developed farming, hunting, saltworks, fishing, and ore mining on the Urals and established trade with Siberian tribes.\n\nAround 1577, Semyon Stroganov and other sons of Anikey Stroganov hired a Cossack leader called Yermak to protect their lands from the attacks of Siberian Khan Kuchum. By 1580 Stroganovs and Yermak came up with the idea of the military expedition to Siberia, in order to fight Kuchum in his own land. In 1581 Yermak began his voyage into the depths of Siberia. After a few victories over the khan's army, Yermak's people defeated the main forces of Kuchum on Irtysh River in a 3-day Battle of Chuvash Cape in 1582. The remains of the khan's army retreated to the steppes, and thus Yermak captured the Siberia Khanate, including its capital Qashliq near modern Tobolsk. Kuchum still was strong and suddenly attacked Yermak in 1585 in the dead of night, killing most of his people. Yermak was wounded and tried to swim across the Wagay River (Irtysh's tributary), but drowned under the weight of his own chain mail. The Cossacks had to withdraw from Siberia completely, but thanks to Yermak's having explored all the main river routes in West Siberia, Russians successfully reclaimed all his conquests just several years later.\nIn the early 17th century the eastward movement of Russians was slowed by the internal problems in the country during the Time of Troubles. However, very soon the exploration and colonization of the huge territories of Siberia was resumed, led mostly by Cossacks hunting for valuable furs and ivory. While Cossacks came from the Southern Urals, another wave of Russians came by the Arctic Ocean. These were Pomors from the Russian North, who already had been making fur trade with Mangazeya in the north of the Western Siberia for quite a long time. In 1607 the settlement of Turukhansk was founded on the northern Yenisei River, near the mouth of Lower Tunguska, and in 1619 Yeniseysky ostrog was founded on the mid-Yenisei at the mouth of the Upper Tunguska.\n\nBetween 1620 and 1624 a group of fur hunters led by Demid Pyanda left Turukhansk and explored some of the Lower Tunguska, wintering in the proximity of the Vilyuy and Lena rivers. According to later legendary accounts (folktales collected a century after the fact), Pyanda discovered the Lena River. He allegedly explored some of its length, reaching as far as central Yakutia. He returned up the Lena until it became too rocky and shallow, and portaged to the Angara River. In this way, Pyanda may have become the first Russian to meet Yakuts and Buryats. He built new boats and explored some of the Angara, finally reaching Yeniseysk and discovering that the Angara (a Buryat name) and Upper Tunguska (Verkhnyaya Tunguska, as initially known by Russians) are one and the same river.\n\nIn 1627 Pyotr Beketov was appointed Yenisei voevoda in Siberia. He successfully carried out the voyage to collect taxes from Zabaykalye Buryats, becoming the first Russian to step in Buryatia. He founded the first Russian settlement there, Rybinsky ostrog. Beketov was sent to the Lena River in 1631, where in 1632 he founded Yakutsk and sent his Cossacks to explore the Aldan and farther down the Lena, to found new fortresses, and to collect taxes.\n\nYakutsk soon turned into a major starting point for further Russian expeditions eastward, southward and northward. Maksim Perfilyev, who earlier had been one of the founders of Yeniseysk, founded Bratsky ostrog on the Angara in 1631, and in 1638 he became the first Russian to step into Transbaikalia, travelling there from Yakutsk.\nIn 1643 Kurbat Ivanov led a group of Cossacks from Yakutsk to the south of the Baikal Mountains and discovered Lake Baikal, visiting its Olkhon Island. Later Ivanov made the first chart and description of Baikal.\n\nIn 1639 a group of explorers led by Ivan Moskvitin became the first Russians to reach the Pacific Ocean and to discover the Sea of Okhotsk, having built a winter camp on its shore at the Ulya River mouth. The Cossacks learned from the locals about the large Amur River far to the south. In 1640 they apparently sailed south, explored the south-eastern shores of the Okhotsk Sea, perhaps reaching the mouth of the Amur River and possibly discovering the Shantar Islands on their way back. Based on Moskvitin's account, Kurbat Ivanov drew the first Russian map of the Far East in 1642.\n\nIn 1643, Vasily Poyarkov crossed the Stanovoy Range and reached the upper Zeya River in the country of the Daurs, who were paying tribute to the Manchu Chinese. After wintering, in 1644 Poyarkov pushed down the Zeya and became the first Russian to reach the Amur River. He sailed down the Amur and finally discovered the mouth of that great river from land. Since his Cossacks provoked the enmity of the locals behind, Poyarkov chose a different way back. They built boats and in 1645 sailed along the Sea of Okhotsk coast to the Ulya River and spent the next winter in the huts that had been built by Ivan Moskvitin six years earlier. In 1646 they returned to Yakutsk.\nIn 1644 Mikhail Stadukhin discovered the Kolyma River and founded Srednekolymsk. A merchant named Fedot Alekseyev Popov organized a further expedition eastward, and Semyon Dezhnyov became a captain of one of the kochi. In 1648 they sailed from Srednekolymsk down to the Arctic and after some time they rounded Cape Dezhnyov, thus becoming the first explorers to pass through the Bering Strait and to discover Chukotka and the Bering Sea. All their kochi and most of their men (including Popov himself) were lost in storms and clashes with the natives. A small group led by Dezhnyov reached the mouth of the Anadyr River and sailed up it in 1649, having built new boats from the wreckage. They founded Anadyrsk and were stranded there, until Stadukhin found them, coming from Kolyma by land. Subsequently, Stadukhin set off south in 1651 and discovered Penzhin Bay on the northern coast of the Okhotsk Sea. He also may have explored the western shores of Kamchatka.\n\nIn 1649–50 Yerofey Khabarov became the second Russian to explore the Amur River. Through Olyokma, Tungur and Shilka Rivers he reached Amur (Dauria), returned to Yakutsk and then back to Amur with a larger force in 1650–53. This time he was met with armed resistance. He built winter quarters at Albazin, then sailed down Amur and found Achansk, which preceded the present-day Khabarovsk, defeating or evading large armies of Daurian Manchu Chinese and Koreans on his way. He charted the Amur in his \"Draft of the Amur river\". Subsequently, Russians held on to the Amur Region until 1689, when by the Treaty of Nerchinsk this land was assigned to Chinese Empire (it was returned, however, by the Treaty of Aigun in 1858).\n\nIn 1659–65 Kurbat Ivanov was the next head of Anadyrsky ostrog after Semyon Dezhnyov. In 1660 he sailed from Anadyr Bay to Cape Dezhnyov. Atop his earlier pioneering charts, Ivanov is credited with creation of the early map of Chukotka and Bering Strait, which was the first to show on paper (very schematically) the yet undiscovered Wrangel Island, both Diomede Islands and Alaska, based on the data collected from the natives of Chukotka.\n\nSo, by the mid-17th century, Russians established the borders of their country close to modern ones, and explored almost the whole of Siberia, except the eastern Kamchatka and some regions north of the Arctic Circle. The conquest of Kamchatka later would be achieved in the early 1700s by Vladimir Atlasov, while the discovery of the Arctic coastline and Alaska would be completed by the Great Northern Expedition in 1733–1743.\n\nEuropean overseas expansion led to the contact between the Old and New Worlds producing the Columbian Exchange, named after Columbus. It involved the transfer of goods unique to one hemisphere to another. Europeans brought cattle, horses, and sheep to the New World, and from the New World Europeans received tobacco, potatoes and maize. Other items becoming important in global trade were the sugarcane and cotton crops of the Americas, and the gold and silver brought from the Americas not only to Europe but elsewhere in the Old World.\n\nThe new trans-oceanic links and their domination by the European powers led to the Age of Imperialism, where European colonial powers came to control most of the planet. The European appetite for trade, commodities, empire and slaves greatly affected many other areas of the world. Spain participated in the destruction of aggressive empires in the Americas, only to substitute its own, and forcibly replaced the original religions. The pattern of territorial aggression was repeated by other European empires, most notably the Dutch, Russian, French and British. Christianity replaced older \"pagan\" rituals, as were new languages, political and sexual cultures, and in some areas like North America, Australia, New Zealand and Argentina, the indigenous peoples were abused and driven off most of their lands, being reduced to small, dependent minorities.\n\nSimilarly, in coastal Africa, local states supplied the appetite of European slave traders, changing the complexion of coastal African states and fundamentally altering the nature of African slavery, causing impacts on societies and economies deep inland. (See Atlantic slave trade).\n\nAboriginal peoples were living in North America at this time and still do today. There were many conflicts between Europeans and Natives. The Europeans had many advantages over the natives. They gave them diseases that they had not been exposed to before and this wiped out 50–90% of their population. (See Population history of indigenous peoples of the Americas.)\n\nMaize and manioc were introduced into Africa in the 16th century by the Portuguese. They are now important staple foods, replacing native African crops. Alfred W. Crosby speculated that increased production of maize, manioc, and other New World crops led to heavier concentrations of population in the areas from which slavers captured their victims.\n\nIn the 16th-century economy of China, the Ming Dynasty was stimulated by trade with the Portuguese, Spanish, and Dutch. China became involved in a new global trade of goods, plants, animals, and food crops known as the Columbian Exchange. Trade with European powers and the Japanese brought in massive amounts of silver, which then replaced copper and paper banknotes as the common medium of exchange in China. During the last decades of the Ming the flow of silver into China was greatly diminished, thereby undermining state revenues and indeed the entire Ming economy. This damage to the economy was compounded by the effects on agriculture of the incipient Little Ice Age, natural calamities, crop failure, and sudden epidemics. The ensuing breakdown of authority and people's livelihoods allowed rebel leaders such as Li Zicheng to challenge Ming authority.\n\nNew crops that had come to Asia from the Americas via the Spanish colonizers in the 16th century contributed to the Asia's population growth. Although the bulk of imports to China were silver, the Chinese also purchased New World crops from the Spanish Empire. This included sweet potatoes, maize, and peanuts, foods that could be cultivated in lands where traditional Chinese staple crops—wheat, millet, and rice—could not grow, hence facilitating a rise in the population of China. In the Song Dynasty (960–1279), rice had become the major staple crop of the poor; after sweet potatoes were introduced to China around 1560, it gradually became the traditional food of the lower classes.\n\nThe arrival of the Portuguese to Japan in 1543 initiated the Nanban trade period, with the Japanese adopting several technologies and cultural practices, like the arquebus, European-style cuirasses, European ships, Christianity, decorative art, and language. After the Chinese had banned direct trade by Chinese merchants with Japan, the Portuguese filled this commercial vacuum as intermediaries between China and Japan. The Portuguese bought Chinese silk and sold it to the Japanese in return for Japanese-mined silver; since silver was more highly valued in China, the Portuguese could then use Japanese silver to buy even larger stocks of Chinese silk. However, by 1573—after the Spanish established a trading base in Manila—the Portuguese intermediary trade was trumped by the prime source of incoming silver to China from the Spanish Americas.\n\nItalian Jesuit Matteo Ricci (1552–1610) was the first European allowed into the Forbidden City. He taught the Chinese how to construct and play the spinet, translated Chinese texts into Latin and vice versa, and worked closely with his Chinese associate Xu Guangqi (1562–1633) on mathematical work.\n\nAs a wider variety of global luxury commodities entered the European markets by sea, previous European markets for luxury goods stagnated. The Atlantic trade largely supplanted pre-existing Italian and German trading powers which had relied on their Baltic, Russian and Islamic trade links. The new commodities also caused social change, as sugar, spices, silks and chinawares entered the luxury markets of Europe.\n\nThe European economic centre shifted from the Mediterranean to Western Europe. The city of Antwerp, part of the Duchy of Brabant, became \"the centre of the \"entire\" international economy\", and the richest city in Europe at this time. Centred in Antwerp first and then in Amsterdam, \"Dutch Golden Age\" was tightly linked to the Age of Discovery. Francesco Guicciardini, a Venetian envoy, stated that hundreds of ships would pass Antwerp in a day, and 2,000 carts entered the city each week. Portuguese ships laden with pepper and cinnamon would unload their cargo. With many foreign merchants resident in the city and governed by an oligarchy of banker-aristocrats forbidden to engage in trade, the economy of Antwerp was foreigner-controlled, which made the city very international, with merchants and traders from Venice, Ragusa, Spain and Portugal and a policy of toleration, which attracted a large Orthodox Jewish community. The city experienced three booms during its golden age, the first based on the pepper market, a second launched by New World silver coming from Seville (ending with the bankruptcy of Spain in 1557), and a third boom, after the Treaty of Cateau-Cambresis, in 1559, based on the textiles industry.\n\nDespite initial hostilities, by 1549 the Portuguese were sending annual trade missions to Shangchuan Island in China. In 1557 they managed to convince the Ming court to agree on a legal port treaty that would establish Macau as an official Portuguese trade colony. The Portuguese friar Gaspar da Cruz (c. 1520 February 5, 1570) wrote the first complete book on China and the Ming Dynasty that was published in Europe; it included information on its geography, provinces, royalty, official class, bureaucracy, shipping, architecture, farming, craftsmanship, merchant affairs, clothing, religious and social customs, music and instruments, writing, education, and justice.\nFrom China the major exports were silk and porcelain, adapted to meet European tastes. The Chinese export porcelains were held in such great esteem in Europe that, in English, \"china\" became a commonly–used synonym for \"porcelain\". Kraak porcelain (believed to be named after the Portuguese carracks in which it was transported) was among the first Chinese ware to arrive in Europe in mass quantities. Only the richest could afford these early imports, and Kraak often featured in Dutch still life paintings. Soon the Dutch East India Company established a lively trade with the East, having imported 6 million porcelain items from China to Europe between the years 1602 to 1682. The Chinese workmanship impressed many. Between 1575 and 1587 Medici porcelain from Florence was the first successful attempt to imitate Chinese porcelain. Although Dutch potters did not immediately imitate Chinese porcelain, they began to do it when the supply to Europe was interrupted, after the death of Wanli Emperor in 1620. Kraak, mainly the blue and white porcelain, was imitated all over the world by potters in Arita, Japan and Persia—where Dutch merchants turned when the fall of the Ming Dynasty rendered Chinese originals unavailable—and ultimately in Delftware. Dutch and later English Delftware inspired by Chinese designs persisted from about 1630 to the mid-18th century alongside European patterns.\n\nAntonio de Morga (1559–1636), a Spanish official in Manila, listed an extensive inventory of goods that were traded by Ming China at the turn of the 16th to 17th century, noting there were \"rarities which, did I refer to them all, I would never finish, nor have sufficient paper for it\". After noting the variety of silk goods traded to Europeans, Ebrey writes of the considerable size of commercial transactions: In one case a galleon to the Spanish territories in the New World carried over 50,000 pairs of silk stockings. In return China imported mostly silver from Peruvian and Mexican mines, transported via Manila. Chinese merchants were active in these trading ventures, and many emigrated to such places as the Philippines and Borneo to take advantage of the new commercial opportunities.\n\nThe increase in gold and silver experienced by Spain coincided with a major inflationary cycle both within Spain and Europe, known as the price revolution. Spain had amassed large quantities of gold and silver from the New World. In the 1520s large scale extraction of silver from Mexico's Guanajuato began. With the opening of the silver mines in Zacatecas and Bolivia's Potosí in 1546 large shipments of silver became the fabled source of wealth. During the 16th century, Spain held the equivalent of US$1.5 trillion (1990 terms) in gold and silver from New Spain. Being the most powerful European monarch at a time full of war and religious conflicts, the Habsburg rulers spent the wealth in wars and arts across Europe. \"I learnt a proverb here\", said a French traveller in 1603: \"Everything is dear in Spain except silver\". The spent silver, suddenly spread throughout a previously cash-starved Europe, caused widespread inflation. The inflation was worsened by a growing population with a static production level, low salaries and a rising cost of living, which damaged local industry. Increasingly, Spain became dependent on the revenues flowing in from the mercantile empire in the Americas, leading to Spain's first bankruptcy in 1557 due to rising military costs. Phillip II of Spain defaulted on debt payments in 1557, 1560, 1575 and 1596. The increase in prices as a result of currency circulation fuelled the growth of the commercial middle class in Europe, the \"bourgeoisie\", which came to influence the politics and culture of many countries.\n\nOne effect of the inflation, particularly in Great Britain, was that tenant farmers who held long term leases from lords saw real decreases in rent. Some lords opted to sell their leased land, giving rise to small land-owing farmers such as yeoman and gentlemen farmers.\n\n\n"}
{"id": "35740041", "url": "https://en.wikipedia.org/wiki?curid=35740041", "title": "Alan Ball Local History Awards", "text": "Alan Ball Local History Awards\n\nThe Alan Ball Local History Awards in the United Kingdom exist to recognise outstanding contributions in local history publishing (both in print and in new media), and to encourage the publishing of such works by public libraries and local authorities. The awards were established in the 1980s and are run by the Library Services Trust. They are named after the local history author and former chief librarian of the Harrow and Home Counties libraries. A maximum of three awards are made each year.\n\nThe following is the partial list of award winners.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "3759103", "url": "https://en.wikipedia.org/wiki?curid=3759103", "title": "Anno Lucis", "text": "Anno Lucis\n\nAnno Lucis (“in the Year of Light”) is a dating system used in Masonic ceremonial or commemorative proceedings, which is equivalent to the Gregorian year plus 4000. It is similar to \"Anno Mundi\".\n\nFor example, a date Anno Domini (A.D.) becomes Anno Lucis (A.L.) 4000. This calendar era, which would designate 4001 BCE as 'year zero', was adopted in the 18th century as a simplification of the \"Anno Mundi\" era dating system used in the Hebrew calendar and borrowing from other ideas of that time regarding the year of creation.\n\nAfter the Masoretic text was published, dating creation around 4000 BC became common, and it was received with wide support. Proposed calculations of the date of creation, using the Masoretic from the 10th century to the 18th century, were numerous and fluctuated by many decades. Notably, Isaac Newton's calculation pointed at the year 4000 BC. \n\nAmong the Masoretic creation estimates or calculations for the date of creation, Archbishop Ussher's specific chronology dating the creation to 4004 BC became the most accepted and popular in Christendom, mainly because this specific date was attached to the King James Bible. The Hebrew Calendar has traditionally, since the 4th century AD by Hillel II, dated the creation to 3761 BC, in accordance with the \"Seder Olam Rabbah\" compiled by Jose ben Halafta in AD 160, and in agreement with \"The Remaining Signs of Past Centuries\", in which the Muslim chronologist al-Biruni identifies \"anno mundi\" as 3448 years before the Seleucid era but not with \"Seder Olam Zutta\", which dates it to 4339 BC and was compiled in AD 804.\n\n"}
{"id": "7563097", "url": "https://en.wikipedia.org/wiki?curid=7563097", "title": "Archaic globalization", "text": "Archaic globalization\n\nArchaic globalization is a phase in the history of globalization, and conventionally refers to globalizing events and developments from the time of the earliest civilizations until roughly 1600 (the following period is known as early modern globalization). Archaic globalization describes the relationships between communities and states and how they were created by the geographical spread of ideas and social norms at both local and regional levels.\n\nStates began to interact and trade with others within close proximity as a way to acquire coveted goods that were considered a luxury. This trade led to the spread of ideas such as religion, economic structures and political ideals. Merchants became connected and aware of others in ways that had not been apparent. Archaic globalization is comparable to present day globalization on a much smaller scale. It not only allowed the spread of goods and commodities to other regions, but it also allowed people to experience other cultures. Cities that partook in trading were bound together by sea lanes, rivers, and great overland trade routes, some of which had been in use since antiquity. Trading was broken up according to geographic location, with centers between flanking places serving as \"break-in-bulk\" and exchange points for goods destined for more distant markets. During this time period the subsystems were more self-sufficient than they are today and therefore less vitally dependent upon one another for everyday survival. While long distance trading came with many trials and tribulations, still so much of it went on during this early time period. Linking the trade together involved eight interlinked subsystems that were grouped into three large circuits, which encompassed the western European, the Middle Eastern, and the Far Eastern circuits. This interaction during trading was early civilization's way to communicate and spread many ideas that caused modern globalization to emerge and allowed a new aspect to present-day society.\n\nGlobalization is the process of increasing interconnectedness between regions and individuals. Steps toward globalization include economic, political, technological, social, and cultural connections around the world. The term \"archaic\" can be described as early ideals and functions that were once historically apparent in society but may have disintegrated over time.\n\nThere are three main prerequisites for globalization to occur. The first is the idea of Eastern Origins, which shows how Western states have adapted and implemented learned principles from the East. Without the traditional ideas from the East, Western globalization would not have emerged the way it did. The second is distance. The interactions amongst states were not on a global scale and most often were confined to Asia, North Africa, the Middle East and certain parts of Europe. With early globalization it was difficult for states to interact with others that were not within close proximity. Eventually, technological advances allowed states to learn of others existence and another phase of globalization was able to occur. The third has to do with interdependency, stability and regularity. If a state is not dependent on another then there is no way for them to be mutually affected by one another. This is one of the driving forces behind global connections and trade; without either globalization would not have emerged the way it did and states would still be dependent on their own production and resources to function. This is one of the arguments surrounding the idea of early globalization. It is argued that archaic globalization did not function in a similar manner to modern globalization because states were not as interdependent on others as they are today.\n\nHistorians argue that a world system was in order before the rise of capitalism between the sixteenth and nineteenth centuries. This is referred to as the early age of capitalism where long-distance trade, market exchange and capital accumulation existed amongst states. In 800 AD Greek, Roman and Muslim empires emerged covering areas known today as China and the Middle East. Major religions such as Christianity, Islam and Buddhism spread to distant lands where many are still intact today. One of the most popular examples of distant trade routes can be seen with the silk route between China and the Mediterranean, movement and trade with art and luxury goods between Arab regions, South Asia and Africa. These relationships through trade mainly formed in the east and eventually led to the development of capitalism. It was at this time that power and land shifted from the nobility and church to the bourgeoisie and division of labor in production emerged. During the later part of the twelfth century and the beginning of the thirteenth century an international trade system was developed between states ranging from northwestern Europe to China.\n\nDuring the 1500s other Asian empires emerged, which included trading over longer distances than before. During the early exchanges between states, Europe had little to offer with the exception of slaves, metals, wood and furs. The push for selling of items in the east drove European production and helped integrate them into the exchange. The European expansion and growth of opportunities for trade made possible by the Crusades increased the renaissance of agriculture, mining, and manufacturing. Rapid urbanization throughout Europe allowed a connection from the North Sea to Venice. Advances in industrialization coupled with the rouse of population growth and the growing demands of the eastern trade, led to the growth of true trading emporia with outlets to the sea.\n\nThere is a 'multi-polar' nature to archaic globalization, which involved the active participation of non-Europeans. Because it predated the Great Divergence of the nineteenth century, in which Western Europe pulled ahead of the rest of the world in terms of industrial production and economic output, archaic globalization was a phenomenon that was driven not only by Europe but also by other economically developed Old World centers such as Gujarat, Bengal, coastal China and Japan.\n\nThese pre-capitalist movements were regional rather than global and for the most part temporary. This idea of early globalization was proposed by the historian A.G. Hopkins in 2001. Hopkins main points on archaic globalization can be seen with trade, and diaspora that developed from this, as well as religious ideas and empires that spread throughout the region. This new interaction amongst states led to interconnections between parts of the world which led to the eventual interdependency amongst these state actors. The main actors that partook in the spreading of goods and ideas were kings, warriors, priests and traders. Hopkins also addresses that during this time period mini-globalizations were prominent and that some collapsed or became more insular. These mini-globalizations are referred to as episodic and ruptured, with empires sometimes overreaching and having to retract. These mini-globalizations left remnants that allowed the West to adopt these new ideals, leading to the idea of Western Capitalism. The adopted ideals can be seen in the Western monetary system and are central to systems like capitalism that define modernity and modern globalization.\n\nArchaic globalization consists of three principles: universalizing kingship, expansion of religious movements, and medicinal understanding.\n\nWith the increase in trade and state linkage, economic exchange extended throughout the region and caused actors to form new relationships. This early economic development can be seen in Champagne Fairs, which were outdoor markets where traveling merchants came to sell their products and make purchases. Traditionally, market fairs used barter as opposed to money, once larger itinerant merchants began to frequent them, the need for currency became greater and a money changer needed to be established. Some historical scholars argue that this was the beginning of the role of banker and the institution of credit. An example can be seen with one individual in need of an item the urban merchant does not ordinarily stock. The product seeker orders the item, which the merchant promises to bring him next time. The product seeker either gives credit to the merchant by paying them in advance, gets credit from the merchant by promising to pay them once the item is in stock, or some type of concession is made through a down payment. If the product seeker does not have the amount required by the merchant he may borrow from the capital stored by the money changer or he may mortgage part of his expected harvest, either from the money charger or the merchant he is seeking goods from. This lengthy transaction eventually resulted in a complex economic system and once the weekly market began to expand from barter to the monetized system required by long-distance trading.\n\nA higher circuit of trade developed once urban traders from outside city limits travelled from distant directions to the market center in the quest to buy or sell goods. Merchants would then begin to meet at the same spot on a weekly basis allowing for them to arrange with other merchants to bring special items for exchange that were not demanded by the local agriculturalists but for markets in their home towns. When the local individuals placed advanced orders, customers from towns of different traders may begin to place order for items in a distant town that their trader can order from their counterpart. This central meeting point, becomes the focus of long-distance trade and how it began to increase.\n\nIn order for trade to be able to expand during this early time period, it required some basic functions of the market as well as the merchants. The first was security. Goods that were being transported began to have more value and the merchants needed to protect their coveted goods especially since they were often traveling through poor areas where the risk of theft was high. To overcome this problem merchants began to travel in caravans as a way to ensure their personal safety as well as the safety of their goods. The second prerequisite to early long distant trade had to be an agreement on a rate of exchange. Since many of the merchants came from distant lands with different monetary systems a system had to be put into place as a way to enforce repayment of previous goods, repay previous debt and to ensure contracts were upheld. Expansion was also able to thrive so long as it had a motive for exchange as a way to promote trade amongst foreign lands. Also, outside merchants access to trading sites was a critical factor in trade route growth.\n\nThe most popular goods produced were spices, which were traded over short distances, while manufactured goods were central to the system and could not have been aided without them. The invention of money in the form of gold coins in Europe and Middle East and paper money in China around the thirteenth century allowed trade to move more easily between the different actors. The main actors involved in this system viewed gold, silver, and copper as valuable on different levels. Nevertheless, goods were transferred, prices set, exchange rates agreed upon, contracts entered into, credit extended, partnerships formed and agreements that were made were kept on record and honored. During this time of globalization, credit was also used as a means for trading. The use of credit began in the form of blood ties but later led to the emergence the \"banker\" as a profession.\n\nWith the spread of people came new ideas, religion and goods throughout the land, which had never been apparent in most societies before the movement. Also, this globalization lessened the degree of feudal life by transitioning from self-sufficient society to a money economy. Most of the trade connecting North Africa and Europe was controlled by the Middle East, China and India around 1400. Because of the danger and great cost of long-distance travel in the pre-modern period, archaic globalization grew out of the trade in high-value commodities which took up a small amount of space. Most of the goods that were produced and traded were considered a luxury and many considered those with these coveted items to have a higher place on the societal scale.\n\nExamples of such luxury goods would include Chinese silks, exotic herbs, coffee, cotton, iron, Indian calicoes, Arabian horses, gems and spices or drugs such as nutmeg, cloves, pepper, ambergris and opium. The thirteenth century as well as present day favor luxury items due to the fact that small high-value goods can have high transport costs but still have a high value attached to them, whereas low-value heavy goods are not worth carrying very far. Purchases of luxury items such as these are described as archaic consumption since trade was largely popular for these items as opposed to everyday needs. The distinction between food, drugs and materia medica is often quite blurred in regards to these substances, which were valued not only for their rarity but because they appealed to humoral theories of health and the body that were prevalent throughout premodern Eurasia.\n\nDuring the time of archaic globalization there were three major trade routes which connected Europe, China and the Middle East. The northern most route went through mostly the Mongol Empire and was nearly 5000 miles long. Even though the route consisted of mostly vast stretches of desert with little to no resources, merchants still traveled it. The route was still traveled because during the 13th century Kubilai Khan united the Mongol Empire and charged only a small protective rent to travelers. Before the unification, merchants from the Middle East used the path but were stopped and taxed at nearly every village. The middle route went from the coast of Syria to Baghdad from there the traveler could follow the land route through Persia to India, or sail to India via the Persian Gulf. Between the 8th and 10th centuries, Baghdad was a world city but in the 11th century it began to decline due to natural disasters including floods, earthquakes, and fires. In 1258, Baghdad was taken over by the Mongols. The Mongols forced high taxes on the citizens of Baghdad which led to a decrease in production, causing merchants to bypass the city The third, southern most route, went through Mamluk controlled Egypt, After the fall of Baghdad, Cairo became the Islamic capital.\n\nSome major cities along these trading routes were wealthy and provided services for merchants and the international markets. Palmyra and Petra which are located on the fringes of the Syrian Desert, flourished mainly as power centers of trading. They would police the trade routes and be the source of supplies for the merchants caravans. They also became places where people of different ethnic and cultural backgrounds could meet and interact. These trading routes were the communication highways for the ancient civilizations and their societies. New inventions, religious beliefs, artistic styles, languages, and social customs, as well as goods and raw materials, were transmitted by people moving from one place to another to conduct business.\n\nProto-globalization is the period following archaic globalization which occurred from the 17th through the 19th centuries. The global routes established within the period of archaic globalization gave way to more distinguished expanding routes and more complex systems of trade within the period of proto-globalization. Familiar trading arrangements such as the East India Company appeared within this period, making larger-scale exchanges possible. Slave trading was especially extensive and the associated mass-production of commodities on plantations is characteristic of this time.\n\nAs a result of a measurable amount of polyethnic regions due to these higher frequency trade routes, war became prominent. Such wars include the French and Indian War, American Revolutionary War. and the Anglo-Dutch War between England and the Dutch Republic.\n\nThe modern form of globalization began to take form during the 19th century. The evolving beginnings of this period were largely responsible for the expansion of the West, capitalism and imperialism backed up by the nation-state and industrial technology. This began to emerge during the 1500s, continuing to expand exponentially over time as industrialization developed in the 18th century. The conquests of the British Empire and the Opium Wars added to the industrialization and formation of the growing global society because it created vast consumer regions.\n\nWorld War I is when the first phase of modern globalization began to take force. It is said by VM Yeates that the economic forces of globalization were part of the cause of the war. Since World War I, globalization has expanded greatly. The evolving improvements of multinational corporations, technology, science, and mass media have all been results of extensive worldwide exchanges. In addition, institutions such as the World Bank, the World Trade Organization and many international telecommunication companies have also shaped modern globalization. The World Wide Web has also played a large role in modern globalization. The Internet provides connectivity across national and international borders, aiding in the enlargement of a global network.\n\n"}
{"id": "3287371", "url": "https://en.wikipedia.org/wiki?curid=3287371", "title": "Aulic titulature", "text": "Aulic titulature\n\nAulic titulature is a term, derived from the Greek \"aulè\" and Latin aula (in the meaning \"palace\") for hierarchic systems of titles specifically in use for court protocol.\n\nIronically in the formal \"court\" titulature of the Hellenistic empires ruled by dynasties we know as Diadochs, the title \"diadochos\" was not customary for the Monarch, but has actually been proven to be the \"lowest\" in a system of official rank titles, known as aulic titulature, conferred - ex officio or nominatim - to actual courtiers as an honorary rank (for protocol) to various military and civilian officials. \n\nNotably in Lagid Egypt, diadochos was reported as the lowest aulic rank, under \"philos [basilikos]\" (\"friend [of the king]\"), \"archisomatophylax\" (\"arch-bodyguard\"), \"protos philos\" (\"first friend\"), \"homotimos\" (\"[nearly] equal dignitary\") and \"syggeneus\" (\"cognate of the crown\"), during the reign of Ptolemaios V Epiphanes. A similar system of titles was in place in other Hellenistic monarchies. In the Ptolemaic court, the aulic titulature is also distinguished from the titles awarded \"honoris causa\" since several are determined by \"aulic\" functions such as the chamberlain or the master of the hunt. \n\nScholars describe the \"aulic titulature\" as a complex system and that the meanings of the many known titles within it are unknown. One approach of understanding it is through the view that it is a form of formalised informality where a \"philos\"' power position, for instance, at court was indicated by his title and not necessarily fixed by it. While the hierarchisation in the court titulature and the status differentiation is seen as advantageous to the king, it is also believed to be an instrument for the top of the court society to close their ranks as they jockey for positions and privileges. It is commonly supposed that the institution of a system of court ranks and titles was intended to reinforce the bond between the monarch and his ministers by playing on the vanity of the courtiers. There are also accounts that show how the distribution of \"aulic\" titles served as a form of gift exchange and that the recipient was awarded gifts such as purple clothing, crowns, and horse trappings in order to show his rank or to derive his status from. \n"}
{"id": "12290408", "url": "https://en.wikipedia.org/wiki?curid=12290408", "title": "Australian History Awards", "text": "Australian History Awards\n\nThis biennial award has been named for A. W. Martin (1926–2002) and is administered jointly by the Australian National University and the Australian Historical Association. The award is to encourage \"early career historians\" for work relating to Australian History. Submissions for this award are to be work that is being prepared for publication and can be in any form, e.g. a monograph, a series of academic articles, an exhibition or documentary film, or some mix of these.\n\n\nThe publishers, Blackwell Publishing Asia, have sponsored a prize for the best postgraduate paper at a Regional Conference.\n\nThe AHA information states that the \"prize will be judged on two criteria: 1) oral presentation of the paper 2) written version of the conference paper. The written version of the conference paper (not a longer version) is to be submitted at the start of the conference. The winner of the prize will be announced at the close of the conference.\"\n\n\nThe WK Hancock Prize is run by Australian Historical Association (AHA) with the Department of Modern History, Macquarie University. It was instituted in 1987 in honour of Sir Keith Hancock and his life achievements.\n\nThe award is for the first book of history by an Australian scholar and for research using original sources. It is awarded biennially for a first book published in the preceding two years with the award presented at the AHA's National Biennial Conference.\n\n\n\n\n\n\n\n\n\nThe Jill Roe Prize is awarded annually to a postgraduate student for the best unpublished article of historical research. It was inaugurated in 2014 in honour of the late Jill Roe.\n\n\nThe John Barrett Award for Australian Studies is for the best written article published in the \"Journal of Australian Studies\", in the categories: the best article by a scholar (open) and the best article by a scholar (post-graduate).\n\nJohn Barrett Award: Open Category\n\nJohn Barrett Award: Postgraduate Category\n\nInaugurated in 2004, this award is named for Kay Daniels (1941–2001), historian and public servant, and recognises her interest in colonial and heritage history.\n\nThe biennial award will be administered by The Australian Historical Association.\n\n\nThe Serle Award was first presented in 2002. The award was established through the generosity of Mrs Jessie Serle for the historian Geoffrey Serle (1922–1998).\n\nThe Serle Award is for the best thesis by an \"early career researcher\" and will be payable on receipt of publisher’s proofs, which must be within twelve months of notification of the award.\n\nThe biennial award will be administered by The Australian Historical Association.\n\n\n\n\n"}
{"id": "25430186", "url": "https://en.wikipedia.org/wiki?curid=25430186", "title": "Aztec influence in Spain", "text": "Aztec influence in Spain\n\nAztec influence in Spain can be seen in both the cuisine of Spain and in its architecture.\n\nGuacamole, an avocado-based dip that was popular in Aztec cuisine as early as the 16th century, was brought back to Spain by the Conquistadors. Its reputation as an aphrodisiac derives from the words that combine to form the word \"ahuaca-molli\" (\"guacamole\" in the Aztec language): \"molli\" meant \"something mashed or pureed into a sauce\" and as well as meaning \"avocado\" \"ahuacatl\" meant \"testicle\".\nThe stone work of sun pattern, snakes, panther and birds above the main entrance to the church of Nuestra Señora de Regla, Pájara, Fuerteventura in the Canary Islands, is thought by some specialists to show Aztec influence.\n"}
{"id": "58691343", "url": "https://en.wikipedia.org/wiki?curid=58691343", "title": "Balts' Award", "text": "Balts' Award\n\nThe Balts' Award is an annual award given to recognise excellence and achievements in the areas of Latvian-Lithuanian culture, history and language.\n\nThe award was inaugurated in 2018.\n\n"}
{"id": "5523934", "url": "https://en.wikipedia.org/wiki?curid=5523934", "title": "Black Aggie", "text": "Black Aggie\n\nBlack Aggie is the folkloric name given to a statue formerly placed on the grave of General Felix Agnus in Druid Ridge Cemetery in Pikesville, Maryland. It is an unauthorized replica — rendered by Edward Ludwig Albert Pausch — of sculptor Augustus Saint-Gaudens' 1891 allegorical figure, popularly called \"Grief\", at the Adams Memorial in Rock Creek Cemetery in Washington, D.C. The statue is of a somber seated figure in a cowl or shroud.\n\nBeginning with its installation in 1926, the replica was surrounded by many urban legends, principally that someone spending a night in its lap would be haunted by the ghosts of those buried there; that the spirits of individuals buried at Druid Ridge would annually convene at the statue; that no grass would grow on the ground where the statue's shadow would lie during the daytime; or that the statue would animate itself during the night, whether by physically moving or by showing glowing red eyes.\n\nThese urban legends led to much unwelcome attention toward the statue; many people were caught breaking into the cemetery at night to visit it, and the pedestal was frequently vandalized. The Agnus family, disturbed by the attention the statue received, donated it to the Smithsonian in 1967. It sat for many years in storage at the National Museum of American Art (later named the Smithsonian American Art Museum) where an authorized recasting of the original Adams Memorial statue now sits.\n\nBlack Aggie was moved from her previous home at the museum to a courtyard behind the Dolley Madison House on Lafayette Square in Washington, D.C. where she currently stands. The bare, blank pedestal remains at the statue's former home at Druid Ridge Cemetery.\n\nAnother statue, similarly called \"Black Agnus\", is located at Green Mount Cemetery in Montpelier, Vermont. This one is of a man sitting and covered in a shawl, but his head is visible and he is looking up with closed eyes. This statue is copper rather than bronze, so it has a green patina.\n\n"}
{"id": "9464769", "url": "https://en.wikipedia.org/wiki?curid=9464769", "title": "Brusselization", "text": "Brusselization\n\nIn urban planning, Brusselization (UK and US) or Brusselisation (UK variant) (, ) is \"the indiscriminate and careless introduction of modern high-rise buildings into gentrified neighbourhoods\" and has become a byword for \"haphazard urban development and redevelopment\".\n\nThe notion applies to anywhere whose development follows the pattern of the uncontrolled development of Brussels in the 1960s and 1970s, that resulted from a lack of zoning regulations and the city authorities' laissez-faire approach to city planning.\n\nThe original Brusselization was the type of urban regeneration performed by the city of Brussels in connection with Expo 58. In order to prepare the city for Expo 58, buildings were torn down without regard either to their architectural or historical importance, high-capacity square office/apartment buildings were built, boulevards were created and tunnels dug. Among the most controversial was the large-scale demolition of townhouses for development of the high-rise business district in the Northern Quarter. All of these changes were designed to quickly increase the number of people working and living in the city and improve transportation.\n\nFurther radical changes resulted from Brussels's role as the center of the EU and NATO, beginning with the construction of the European Commission headquarters in 1959. The introduction of a high-speed rail network in the 1990s was the latest excuse to speculate on multiple rows of properties for modern office/hotel redevelopment, which led to the razing of neighborhood blocks near Brussels-South railway station.\n\nThese changes caused outcry amongst the citizens of Brussels and by environmentalist and preservationist organizations. The demolition of Victor Horta's Art Nouveau \"\" in 1965 was one focus of such protests, (see photograph on right for what now stands on its site), as was the construction of the IBM Tower in 1978.\n\nMany architects protested, and it was the architectural world that coined the name Brusselization for what was happening to Brussels. Architects such as and formulated an anti-capitalist urban planning theory, as a rejection of the rampant modernism that they saw overtaking Brussels.\n\nThe 1950s was not the first time that the city had been radically altered by major redevelopment. Two prior sweeping changes to the urban fabric of Brussels were the straight-lined central avenues modeled after Paris, which were created by covering and diverting the Senne river, and the North–South railway connection, which took around 40 years to finish (1911–52) and which had left swaths of the city center filled with debris and craters for decades. Another precedent is the erecting of the Palace of Justice, the largest building in the world constructed in the 1800s. André de Vries asserts that the penchant for heavy-handedness can be traced back to the reign of Leopold II in the late 19th century, and possibly even all the way back to the bombardment of the city by Louis XIV's troops in 1695. \"There is barely one building still standing\", he says, \"from before 1695, with the exception of some churches and the Town Hall\".\n\nLeopold II sought to give Brussels the image of a grand capital city of an imperial/colonial power. By the middle 20th century there was a tacit alliance between urban development entrepreneurs and local government, with a modernist agenda and with their sights set firmly on large-scale development projects. The citizens of Brussels were largely left out of the process.\n\nIn the early 1990s laws were introduced restricting the demolition of buildings that were deemed to have architectural or historical significance; and in 1999 the city authorities' urban development plan explicitly declared high-rise buildings to be architecturally incompatible with the existing aesthetics of the city centre. This led to the rise of what was termed \" — the destruction of the whole interior of a historic building while preserving its historic façade.\n\nThese laws were the Town Planning Act 1991, which gave local authorities the powers to refuse demolition requests on the grounds of historical, aesthetic, or cultural significance, and to designate architectural heritage zones; and the Heritage Conservation Act of 1993, which gave the government of the Brussels Capital Region the power to designate buildings to be protected for historic reasons. However, this system had its deficiencies. Whilst the Capital Region government could designate historic buildings, it was the nineteen municipal authorities within it that were responsible for demolition permits. Not until the introduction of a \" system was this internecine conflict resolved.\n\n\n\n"}
{"id": "1021695", "url": "https://en.wikipedia.org/wiki?curid=1021695", "title": "Charles Chiniquy", "text": "Charles Chiniquy\n\nCharles P. Chiniquy (30 July 1809 – 16 January 1899) was Canadian Catholic priest who left the Roman Catholic Church and became a Presbyterian minister. He rode the lecture circuit denouncing the Catholic Church. His themes were that it was pagan, that Catholics worship the Virgin Mary, and that its theology is anti-Christian. He warned of plots by the Vatican to take control of the United States by importing Catholic immigrants from Ireland, Germany and France. He suggested the Vatican was behind the assassination of Abraham Lincoln,\n\nChiniquy was born in 1809 in the village of Kamouraska, Quebec. He lost his father at an early age and was adopted by his uncle. As a young man, Chiniquy studied to become a Catholic priest at the Petit Seminaire (Little Seminary) in Nicolet, Quebec. He was ordained a Catholic priest in 1833. After his ordination, he served his church in Quebec and later immigrated to Illinois. During the 1840s, he led a very successful campaign throughout Quebec against alcohol and drunkenness.\n\nIn 1855, he was sued by a prominent Catholic layman named Peter Spink in Kankakee, Illinois. After the fall court term, Spink applied for a change of venue to the court in Urbana. Abraham Lincoln was then hired by Chiniquy to defend him. The spring court action in Urbana was the highest profile libel suit in Lincoln's career. The case was ended in the fall court session by agreement.\n\nChiniquy clashed with the Bishop of Chicago, Anthony O'Regan, over the bishop's treatment of Catholics in Chicago, particularly French Canadians. He declared that O'Regan was secretly backing Spink's suit against him. Chiniquy stated that in 1856 O'Regan threatened him with excommunication if he did not go to a new location where the bishop wanted him. Several months later the \"New York Times\" published a pastoral letter from Bishop O'Regan in which O'Regan stated that he had suspended Chiniquy and, since the priest had continued in his normal duties as a priest, the bishop excommunicated him by his letter. Chiniquy vigorously disputed that he had been excommunicated, saying publicly that the bishop was mistaken. Chiniquy left the Roman Catholic Church in 1858. He claimed that the church was pagan, that Roman Catholics worship the Virgin Mary, that its theology spoils the Gospel and that its theology is anti-Christian. He also claimed that the Vatican had planned to take over the United States by importing Catholic immigrants from Ireland, Germany and France.\n\nChiniquy claimed that he was falsely accused by his superiors (and that Abraham Lincoln had come to his rescue), that the American Civil War was a plot against the United States of America by the Vatican, and that the Vatican was behind the Confederate cause, the death of President Lincoln and that Lincoln's assassins were faithful Roman Catholics ultimately serving Pope Pius IX.\n\nAfter leaving the Catholic Church, Chiniquy dedicated his life to trying to win his fellow French Canadians, as well as others, from Catholicism to the Protestant faith. He wrote a number of books and tracts pointing out his views on the alleged errors in the faith and practises of the Roman Catholic Church. His two most influential works are \"Fifty Years in The Church of Rome\" and \"The Priest, The Woman and The Confessional\". These books raised concerns in the United States about the Catholic Church. According to one Canadian biographer, Chiniquy is Canada's best-selling author of all time. He joined the Orange Order and said of it \"I always found them staunch and true. I consider it a great honour to be an Orangeman. Every time I go on my knees I pray that God may bless them and make them as numerous and bright as the stars of the heaven above.\"\n\nHe died in Montreal, Quebec, Canada on January 16, 1899.\n\nTo this day, some of Chiniquy's works are still promoted among Protestants and Sola scriptura believers. One of his most well known modern day followers is Jack Chick, who created a comic-form adaptation of \"50 Years In The Church of Rome\" called \"The Big Betrayal\" and who draws heavily on Chiniquy's claims in his own anti-Catholic tracts.\n\nChiniquy, then a Roman Catholic priest, left Canada in the wake of a series of scandals. He was offered a fresh start by James Oliver Van de Velde, Bishop of Chicago, after Ignace Bourget, Bishop of Montreal, asked him to leave in 1851. Chiniquy settled in St. Anne, Illinois.\n\nChiniquy was suspended, on , for public insubordination by Van de Velde's successor, Bishop Anthony O'Regan. He continued to celebrate Mass and administer the other sacraments and was excommunicated on . About two years later, on , O'Regan's successor, Bishop James Duggan, formally reconfirmed his excommunication in St. Anne. Chiniquy then left the and, with many followers, joined the Presbyterian Church in the United States of America (PCUSA). He was admitted as a Presbyterian minister on . Within two years, Chiniquy, in trouble with the Presbytery of Chicago over his administration of charity funds and a college, according to Elizabeth Ann Kerr McDougall in the \"Dictionary of Canadian Biography\", sought a new connection in order to avoid an expensive presbytery trial. The college is identified in the \"Seventh Biennial Report of the Superintendent of Public Instruction of the State of Illinois\" as Saviour's College, founded in 1860; it is listed neither in \"Universities and Colleges\" nor \"Academies and Seminaries of various grades and courses\" but in the \"Theological Seminaries and Church Schools\" class of institutions. The report states it \"is designed to supply the educational wants of the colony brought by Father Chiniquy from Canada to this State, and to prepare men who will be fitted to preach the gospel in the regions whence he came.\" The report also quotes a description of the school, attributed to correspondence from a Montreal newspaper, unnamed in the report, that people, also unnamed in the report, \"examined the day school or college, as the people there delight to call it\" and wrote it had five classes ranging from students learning the alphabet to students learning the \"intricacies of French and English grammar, composition, and the other studies of the school, besides the elements of Algebra, Latin and Greek.\" Alexander F. Kemp was chairman of the Synod of the Canada Presbyterian Church committee which examined Chiniquy's admission application. According to Kemp, Chiniquy was involved in both presbytery and civil court proceedings connected with the administration of charitable funds and with what Kemp described as an educational institute. This led to the Presbytery of Chicago charging him with unministerial and unchristian conduct. Chiniquy was to answer these charges before the presbytery; at that stage of the proceedings he and his congregation resolved to separate from the Presbytery of Chicago, and the Old School , and to request recognition from the Canada Presbyterian Church. The Presbytery of Chicago charged Chiniquy with misrepresenting that a real college was in operation in St. Anne. After conducting an inquiry, Kemp suggested that Chiniquy and his congregation be admitted into the Canada Presbyterian Church.\n\nThe French Canadians founded There was in St. Anne, an incorporation of a religious society, by the name of the \"Christian Catholic Church at St. Anne\", incorporated in the State of Illinois; that society was a Protestant religious association. Two years later, when it joined the in 1860, it assumed the name \"First Presbyterian church of St. Anne\". \"You can exclude us from the Catholic Church of Rome\", they said to the Bishop of Chicago, \"but not from the Catholic Church of Christ\", hence the name Christian Catholic Church.\n\n\n"}
{"id": "99656", "url": "https://en.wikipedia.org/wiki?curid=99656", "title": "Creative destruction", "text": "Creative destruction\n\nCreative destruction (German: \"schöpferische Zerstörung\"), sometimes known as Schumpeter's gale, is a concept in economics which since the 1950s has become most readily identified with the Austrian economist Joseph Schumpeter who derived it from the work of Karl Marx and popularized it as a theory of economic innovation and the business cycle.\n\nAccording to Schumpeter, the \"gale of creative destruction\" describes the \"process of industrial mutation that incessantly revolutionizes the economic structure from within, incessantly destroying the old one, incessantly creating a new one\". In Marxian economic theory the concept refers more broadly to the linked processes of the accumulation and annihilation of wealth under capitalism.\n\nThe German Marxist sociologist Werner Sombart has been credited with the first use of these terms in his work \"Krieg und Kapitalismus\" (\"War and Capitalism\", 1913). In the earlier work of Marx, however, the idea of creative destruction or annihilation (German: \"Vernichtung\") implies not only that capitalism destroys and reconfigures previous economic orders, but also that it must ceaselessly devalue existing wealth (whether through war, dereliction, or regular and periodic economic crises) in order to clear the ground for the creation of new wealth.\n\nIn \"Capitalism, Socialism and Democracy\" (1942), Joseph Schumpeter developed the concept out of a careful reading of Marx’s thought (to which the whole of Part I of the book is devoted), arguing (in Part II) that the creative-destructive forces unleashed by capitalism would eventually lead to its demise as a system (see below). Despite this, the term subsequently gained popularity within neoliberal or free-market economics as a description of processes such as downsizing in order to increase the efficiency and dynamism of a company. The Marxian usage has, however, been retained and further developed in the work of social scientists such as David Harvey, Marshall Berman, Manuel Castells and Daniele Archibugi.\n\nAlthough the modern term \"creative destruction\" is not used explicitly by Marx, it is largely derived from his analyses, particularly in the work of Werner Sombart (whom Engels described as the only German professor who understood Marx's \"Capital\"), and of Joseph Schumpeter, who discussed at length the origin of the idea in Marx's work (see below).\n\nIn \"The Communist Manifesto\" of 1848, Karl Marx and Friedrich Engels described the crisis tendencies of capitalism in terms of \"the enforced destruction of a mass of productive forces\":\nModern bourgeois society, with its relations of production, of exchange and of property, a society that has conjured up such gigantic means of production and of exchange, is like the sorcerer who is no longer able to control the powers of the nether world whom he has called up by his spells. [...] It is enough to mention the commercial crises that by their periodical return put the existence of the whole of bourgeois society on trial, each time more threateningly. In these crises, \"a great part not only of existing production, but also of previously created productive forces, are periodically destroyed\". In these crises, there breaks out an epidemic that, in all earlier epochs, would have seemed an absurdity – the epidemic of over-production. Society suddenly finds itself put back into a state of momentary barbarism; it appears as if a famine, a universal war of devastation, had cut off the supply of every means of subsistence; industry and commerce seem to be destroyed; and why? Because there is too much civilisation, too much means of subsistence, too much industry, too much commerce. The productive forces at the disposal of society no longer tend to further the development of the conditions of bourgeois property; on the contrary, they have become too powerful for these conditions. […] And how does the bourgeoisie get over these crises? On the one hand by \"enforced destruction of a mass of productive forces\"; on the other, by the conquest of new markets, and by the more thorough exploitation of the old ones. That is to say, by paving the way for more extensive and more destructive crises, and by diminishing the means whereby crises are prevented.\nA few years later, in the \"Grundrisse\", Marx was writing of \"the violent destruction of capital not by relations external to it, but rather as a condition of its self-preservation\". In other words, he establishes a necessary link between the generative or creative forces of production in capitalism and the destruction of capital value as one of the key ways in which capitalism attempts to overcome its internal contradictions:\nThese contradictions lead to explosions, cataclysms, crises, in which [...] momentaneous suspension of labour and annihilation of a great portion of capital [...] violently lead it back to the point where it is enabled [to go on] fully employing its productive powers without committing suicide.\nIn the \"Theories of Surplus Value\" (\"Volume IV\" of \"Das Kapital\", 1863), Marx refines this theory to distinguish between scenarios where the destruction of (commodity) values affects either use values or exchange values or both together. The destruction of exchange value combined with the preservation of use value presents clear opportunities for new capital investment and hence for the repetition of the production-devaluation cycle:\nthe destruction of capital through crises means the depreciation of values which prevents them from later renewing their reproduction process as capital on the same scale. This is the ruinous effect of the fall in the prices of commodities. It does not cause the destruction of any use-values. What one loses, the other gains. Values used as capital are prevented from acting again as capital in the hands of the same person. The old capitalists go bankrupt. [...] A large part of the nominal capital of the society, i.e., of the exchange-value of the existing capital, is once for all destroyed, although this very destruction, since it does not affect the use-value, may very much expedite the new reproduction. This is also the period during which moneyed interest enriches itself at the cost of industrial interest.\nSocial geographer David Harvey sums up the differences between Marx's usage of these concepts and Schumpeter's: \"Both Karl Marx and Joseph Schumpeter wrote at length on the 'creative-destructive' tendencies inherent in capitalism. While Marx clearly admired capitalism's creativity he [...] strongly emphasised its self-destructiveness. The Schumpeterians have all along gloried in capitalism's endless creativity while treating the destructiveness as mostly a matter of the normal costs of doing business\".\n\nIn the Origin of Species, which was published in 1859, Charles Darwin wrote that the \"extinction of old forms is the almost inevitable consequence of the production of new forms.\" One notable exception to this rule is how the extinction of the dinosaurs facilitated the adaptive radiation of mammals. In this case creation was the consequence, rather than the cause, of destruction. \n\nIn philosophical terms, the concept of \"creative destruction\" is close to Hegel´s concept of sublation. In German economic discourse it was taken up from Marx's writings by Werner Sombart, particularly in his 1913 text \"Krieg und Kapitalismus\":\nAgain, however, \"from destruction a new spirit of creation arises;\" the scarcity of wood and the needs of everyday life... forced the discovery or invention of substitutes for wood, forced the use of coal for heating, forced the invention of coke for the production of iron.\nHugo Reinert has argued that Sombart's formulation of the concept was influenced by Eastern mysticism, specifically the image of the Hindu god Shiva, who is presented in the paradoxical aspect of simultaneous destroyer and creator. Conceivably this influence passed from Johann Gottfried Herder, who brought Hindu thought to German philosophy in his \"Philosophy of Human History\" (Ideen zur Philosophie der Geschichte der Menschheit) (Herder 1790–92), specifically volume III, pp. 41–64. via Arthur Schopenhauer and the Orientalist Friedrich Maier through Friedrich Nietzsche´s writings. Nietzsche represented the creative destruction of modernity through the mythical figure of Dionysus, a figure whom he saw as at one and the same time \"destructively creative\" and \"creatively destructive\". In the following passage from \"On the Genealogy of Morality\" (1887), Nietzsche argues for a universal principle of a cycle of creation and destruction, such that every creative act has its destructive consequence:\nBut have you ever asked yourselves sufficiently how much the erection of every ideal on earth has cost? How much reality has had to be misunderstood and slandered, how many lies have had to be sanctified, how many consciences disturbed, how much \"God\" sacrificed every time? If a temple is to be erected a temple must be destroyed: that is the law – let anyone who can show me a case in which it is not fulfilled! – Friedrich Nietzsche, \"On the Genealogy of Morality\"\n\nOther nineteenth-century formulations of this idea include Russian anarchist Mikhail Bakunin, who wrote in 1842, \"The passion for destruction is a creative passion, too!\" Note, however, that this earlier formulation might more accurately be termed \"destructive creation\", and differs sharply from Marx's and Schumpeter's formulations in its focus on the active destruction of the existing social and political order by human agents (as opposed to systemic forces or contradictions in the case of both Marx and Schumpeter).\n\nThe expression \"creative destruction\" was popularized by and is most associated with Joseph Schumpeter, particularly in his book \"Capitalism, Socialism and Democracy\", first published in 1942. Already in his 1939 book \"Business Cycles\", he attempted to refine the innovative ideas of Nikolai Kondratieff and his long-wave cycle which Schumpeter believed was driven by technological innovation. Three years later, in \"Capitalism, Socialism and Democracy\", Schumpeter introduced the term \"creative destruction\", which he explicitly derived from Marxist thought (analysed extensively in Part I of the book) and used it to describe the disruptive process of transformation that accompanies such innovation:\nCapitalism [...] is by nature a form or method of economic change and not only never is but never can be stationary. [...] The fundamental impulse that sets and keeps the capitalist engine in motion comes from the new consumers’ goods, the new methods of production or transportation, the new markets, the new forms of industrial organization that capitalist enterprise creates.[...] The opening up of new markets, foreign or domestic, and the organizational development from the craft shop and factory to such concerns as U.S. Steel illustrate the process of industrial mutation that incessantly revolutionizes the economic structure \"from within\", incessantly destroying the old one, incessantly creating a new one. This process of Creative Destruction is the essential fact about capitalism. It is what capitalism consists in and what every capitalist concern has got to live in.[... Capitalism requires] the perennial gale of Creative Destruction.\nIn Schumpeter's vision of capitalism, innovative entry by entrepreneurs was the disruptive force that sustained economic growth, even as it destroyed the value of established companies and laborers that enjoyed some degree of monopoly power derived from previous technological, organizational, regulatory, and economic paradigms. However, Schumpeter was pessimistic about the sustainability of this process, seeing it as leading eventually to the undermining of capitalism's own institutional frameworks:\nIn breaking down the pre-capitalist framework of society, capitalism thus broke not only barriers that impeded its progress but also flying buttresses that prevented its collapse. That process, impressive in its relentless necessity, was not merely a matter of removing institutional deadwood, but of removing partners of the capitalist stratum, symbiosis with whom was an essential element of the capitalist schema. [... T]he capitalist process in much the same way in which it destroyed the institutional framework of feudal society also undermines its own.\nSchumpeter nevertheless elaborated the concept, making it central to his economic theory, and it was later taken up as a major doctrine of the so-called Austrian School of free-market economic thought.\n\n Schumpeter (1949) in one of his examples used \"the railroadization of the Middle West as it was initiated by the Illinois Central.\" He wrote, \"The Illinois Central not only meant very good business whilst it was built and whilst new cities were built around it and land was cultivated, but it spelled the death sentence for the [old] agriculture of the West.\"\n\nCompanies that once revolutionized and dominated new industries – for example, Xerox in copiers or Polaroid in instant photography – have seen their profits fall and their dominance vanish as rivals launched improved designs or cut manufacturing costs. In technology, the cassette tape replaced the 8-track, only to be replaced in turn by the compact disc, which was undercut by downloads to MP3 players, which is now being usurped by web-based streaming services. Companies which made money out of technology which becomes obsolete do not necessarily adapt well to the business environment created by the new technologies.\n\nOne such example is the way in which online ad-supported news sites such as \"The Huffington Post\" are leading to creative destruction of the traditional newspaper. The \"Christian Science Monitor\" announced in January 2009 that it would no longer continue to publish a daily paper edition, but would be available online daily and provide a weekly print edition. The \"Seattle Post-Intelligencer\" became online-only in March 2009. At a national level in USA, employment in the newspaper business fell from 455,700 in 1990 to 225,100 in 2013. Over that same period, employment in internet publishing and broadcasting grew from 29,400 to 121,200. Traditional French alumni networks, which typically charge their students to network online or through paper directories, are in danger of creative destruction from free social networking sites such as Linkedin and Viadeo.\n\nIn fact, successful innovation is normally a source of temporary market power, eroding the profits and position of old firms, yet ultimately succumbing to the pressure of new inventions commercialised by competing entrants. Creative destruction is a powerful economic concept because it can explain many of the dynamics or kinetics of industrial change: the transition from a competitive to a monopolistic market, and back again. It has been the inspiration of endogenous growth theory and also of evolutionary economics.\n\nDavid Ames Wells (1890), who was a leading authority on the effects of technology on the economy in the late 19th century, gave many examples of creative destruction (without using the term) brought about by improvements in steam engine efficiency, shipping, the international telegraph network, and agricultural mechanization.\n\nGeographer and historian David Harvey in a series of works from the 1970s onwards (\"Social Justice and the City\", 1973; \"The Limits to Capital\", 1982; \"The Urbanization of Capital\", 1985; \"Spaces of Hope\", 2000; \"Spaces of Capital\", 2001; \"Spaces of Neoliberalization\", 2005; \"The Enigma of Capital and the Crises of Capitalism\", 2010), elaborated Marx's thought on the systemic contradictions of capitalism, particularly in relation to the production of the urban environment (and to the production of space more broadly). He developed the notion that capitalism finds a \"spatial fix\" for its periodic crises of overaccumulation through investment in fixed assets of infrastructure, buildings, etc.: \"The built environment that constitutes a vast field of collective means of production and consumption absorbs huge amounts of capital in both its construction and its maintenance. Urbanization is one way to absorb the capital surplus\". While the creation of the built environment can act as a form of crisis displacement, it can also constitute a limit in its own right, as it tends to freeze productive forces into a fixed spatial form. As capital cannot abide a limit to profitability, ever more frantic forms of \"time-space compression\" (increased speed of turnover, innovation of ever faster transport and communications' infrastructure, \"flexible accumulation\") ensue, often impelling technological innovation. Such innovation, however, is a double-edged sword:\n\nGlobalization can be viewed as some ultimate form of time-space compression, allowing capital investment to move almost instantaneously from one corner of the globe to another, devaluing fixed assets and laying off labour in one urban conglommeration while opening up new centres of manufacture in more profitable sites for production operations. Hence, in this continual process of creative destruction, capitalism does not resolve its contradictions and crises, but merely \"moves them around geographically\".\n\nIn his 1987 book \"All That is Solid Melts into Air: The Experience of Modernity\", particularly in the chapter entitled \"Innovative Self-Destruction\" (pp. 98–104), Marshall Berman provides a reading of Marxist \"creative destruction\" to explain key processes at work within modernity. The title of the book is taken from a well-known passage from \"The Communist Manifesto\". Berman elaborates this into something of a \"Zeitgeist\" which has profound social and cultural consequences:\n\nHere Berman emphasizes Marx's perception of the fragility and evanescence of capitalism's immense creative forces, and makes this apparent contradiction into one of the key explanatory figures of modernity.\n\nThe sociologist Manuel Castells, in his trilogy on \"\" (the first volume of which, \"\", appeared in 1996), reinterpreted the processes by which capitalism invests in certain regions of the globe, while divesting from others, using the new paradigm of \"informational networks\". In the era of globalization, capitalism is characterized by near-instantaneous flow, creating a new spatial dimension, \"the space of flows\". While technological innovation has enabled this unprecedented fluidity, this very process makes redundant whole areas and populations who are bypassed by informational networks. Indeed, the new spatial form of the mega-city or megalopolis, is defined by Castells as having the contradictory quality of being \"globally connected and locally disconnected, physically and socially\". Castells explicitly links these arguments to the notion of creative destruction:\n\nDeveloping the Schumpeterian legacy, the school of the Science Policy Research Unit of the University of Sussex has further detailed the importance of creative destruction exploring, in particular, how new technologies are often idiosyncratic with the existing productive regimes and will lead to bankruptcy companies and even industries that do not manage to sustain the rate of change. Chris Freeman and Carlota Perez have developed these insights. More recently, Daniele Archibugi and Andrea Filippetti have associated the 2008 economic crisis to the slow-down of opportunities offered by information and communication technologies (ICTs). Using as a metaphor the film \"Blade Runner\", Archibugi has argued that of the innovations described in the film in 1982, all those associated to ICTs have become part of our everyday life. But, on the contrary, none of those in the field of Biotech have been fully commercialized. A new economic recovery will occur when some key technological opportunities will be identified and sustained.\n\nIn 1992, the idea of creative destruction was put into formal mathematical terms by Philippe Aghion and Peter Howitt, giving an alternative model of endogenous growth compared to Paul Romer's expanding varieties model.\n\nIn 1995, Harvard Business School authors Richard L. Nolan and David C. Croson released \"Creative Destruction: A Six-Stage Process for Transforming the Organization.\" The book advocated downsizing to free up slack resources, which could then be reinvested to create competitive advantage.\n\nMore recently, the idea of \"creative destruction\" was utilized by Max Page in his 1999 book, \"The Creative Destruction of Manhattan, 1900–1940.\" The book traces Manhattan's constant reinvention, often at the expense of preserving a concrete past. Describing this process as \"creative destruction,\" Page describes the complex historical circumstances, economics, social conditions and personalities that have produced crucial changes in Manhattan's cityscape.\n\nIn addition to Max Page, others have used the term “creative destruction” to describe the process of urban renewal and modernization. T.C. Chang and Shirlena Huang referenced “creative destruction” in their paper \"Recreating place, replacing memory: Creative Destruction at the Singapore River.\" The authors explored the efforts to redevelop a waterfront area that reflected a vibrant new culture while paying sufficient homage to the history of the region. Rosemary Wakeman chronicled the evolution of an area in central Paris, France known as Les Halles. Les Halles housed a vibrant marketplace starting in the twelfth century. Ultimately, in 1971, the markets were relocated and the pavilions torn down. In their place, now stand a hub for trains, subways and buses. Les Halles is also the site of the largest shopping mall in France and the controversial Centre Georges Pompidou.\n\nThe term “creative destruction” has been applied to the arts. Alan Ackerman and Martin Puncher (2006) edited a collection of essays under the title \"Against Theater: Creative destruction on the modernist stage.\" They detail the changes and the causal motivations experienced in theater as a result of the modernization of both the production of performances and the underlying economics. They speak of how theater has reinvented itself in the face of anti-theatricality, straining the boundaries of the traditional to include more physical productions, which might be considered avant-garde staging techniques.\n\nIn his 1999 book, \"Still the New World, American Literature in a Culture of Creative Destruction\", Philip Fisher analyzes the themes of creative destruction at play in literary works of the twentieth century, including the works of such authors as Ralph Waldo Emerson, Walt Whitman, Herman Melville, Mark Twain, and Henry James, among others. Fisher argues that creative destruction exists within literary forms just as it does within the changing of technology.\n\nNeoconservative author Michael Ledeen argued in his 2002 book \"The War Against the Terror Masters\" that America is a revolutionary nation, undoing traditional societies: \"Creative destruction is our middle name, both within our own society and abroad. We tear down the old order every day, from business to science, literature, art, architecture, and cinema to politics and the law.\" His characterization of creative destruction as a model for social development has met with fierce opposition from paleoconservatives.\n\nCreative destruction has also been linked to sustainable development. The connection was explicitly mentioned for the first time by Stuart L. Hart and Mark B. Milstein in their 1999 article \"Global Sustainability and the Creative Destruction of Industries\", in which he argues new profit opportunities lie in a round of creative destruction driven by global sustainability. (An argument which they would later on strengthen in their 2003 article \"Creating Sustainable Value\" and, in 2005, with \"Innovation, Creative Destruction and Sustainability\".) Andrea L. Larson agreed with this vision a year later in \"Sustainable Innovation Through an Entrepreneurship Lens\", stating entrepreneurs should be open to the opportunities for disruptive improvement based on sustainability. In 2005, James Hartshorn (et al.) emphasized the opportunities for sustainable, disruptive improvement in the construction industry in his article \"Creative Destruction: Building Toward Sustainability\".\n\nThe following text appears to be the source of the phrase \"Schumpeter's Gale\" to refer to creative destruction:\n\nThe film \"Other People's Money\" (1991) provides contrasting views of creative destruction, presented in two speeches regarding the takeover of a publicly traded wire and cable company in a small New England town. One speech is by a corporate raider, and the other is given by the company CEO, who is principally interested in protecting his employees and the town.\n\n\n"}
{"id": "17261848", "url": "https://en.wikipedia.org/wiki?curid=17261848", "title": "Dacianos", "text": "Dacianos\n\nThe Dacianos formed the mythical group of European wanderers, said to be a caste of gypsies, who specialised in child-stealing and the manufacture of human freaks. They are also referred to as a criminal society that lasted until the 18th century, maiming children so they can be sold as professional beggars.\n\nThe \"Dacianos\" are cited to have inhabited parts of Spain for several hundred years and the term itself, along with \"gitanos,\" is a Spanish name for gypsies. They were also identified as the \"Comprachicos\" or \"Comprapequenos\" in Victor Hugo's \"The Man Who Laughs\". Hugo claimed that traces of this group can be found in the penal laws of Spain and England. Their origin is linked to gypsies called the Dacians, who settled Dacia, a Roman province and later a kingdom in present-day Hungary. Another theory claims that the \"Dacianos\" may have come from Dacca, a province of Pakistan.\n\n\n"}
{"id": "1433172", "url": "https://en.wikipedia.org/wiki?curid=1433172", "title": "Dhul-Qarnayn", "text": "Dhul-Qarnayn\n\nDhul-Qarnayn, ( \"\", ), \"he of the two horns\" (or “he of the two ages”), appears in Surah 18 verses 83-101 of the Quran as a figure empowered by Allah to erect a wall between mankind and Gog and Magog, the representation of chaos. The end of the world would be signaled by the release of Gog and Magog from behind the wall, and their destruction by God in a single night would usher in the Day of Resurrection (\"Yawm al-Qiyāmah)\". The story entered the Quran through the Alexander Romance, a legendary version of the career of Alexander the Great.\n\nThe story of Dhul-Qarnayn is related in chapter 18 (Surat al-Kahf, \"The Cave\") of the Quran. This chapter was revealed to Muhammad when his tribe, Quraysh, sent two men to discover whether the Jews, with their superior knowledge of the scriptures, could advise them on whether Muhammad was a true prophet of God. The rabbis told them to ask Muhammad about three things, one of them \"about a man who travelled and reached the east and the west of the earth, what was his story\". \"If he tells you about these things, then he is a prophet, so follow him, but if he does not tell you, then he is a man who is making things up, so deal with him as you see fit.\" (Verses ).\n\nThe verses of the chapter reproduced below show Dhul-Qarnayn traveling first to the Western edge of the world where he sees the sun set in a muddy spring, then to the furthest East where he sees it rise from the ocean, and finally northward to a place in the mountains where he finds a people oppressed by Gog and Magog:\n\nThe story of Dhul-Qarnayn has its origins in legends of Alexander the Great current in the Middle East in the early years of the Christian era. According to these legends the Scythians, the descendants of Gog and Magog, once defeated one of Alexander's generals, upon which Alexander built a wall in the Caucasus mountains to keep them out of civilised lands (the basic elements of the legend are found in Flavius Josephus). The Alexander Romance went through much further elaboration in subsequent centuries before eventually finding its way into the Quran through a Syrian version.\n\nAlexander was already known as \"the two-horned one\" in these early legends. The reasons for this are somewhat obscure: the scholar al-Tabari (839-923 CE) held it was because he went from one extremity (\"horn\") of the world to the other, but it may ultimately derive from the image of Alexander wearing the horns of the ram-god Zeus-Ammon, as popularised on coins throughout the Hellenistic Near East. The wall may have reflected a distant knowledge of the Great Wall of China (the 12th century scholar al-Idrisi drew a map for Roger of Sicily showing the \"Land of Gog and Magog\" in Mongolia), or of various Sassanid Persian walls built in the Caspian area against the northern barbarians, or a conflation of the two.\n\nDhul-Qarneyn also journeys to the western and eastern extremities (\"qarns\", tips) of the Earth. In the west he finds the sun setting in a \"muddy spring\", equivalent to the \"poisonous sea\" which Alexander found in the Syriac legend. In the Syriac original Alexander tested the sea by sending condemned prisoners into it, but the Quran changes this into a general administration of justice. In the east both the Syrian legend and the Quran have Alexander/Dhul-Qarneyn find a people who live so close to the rising sun that they have no protection from its heat.\n\n\"Qarn\" also means \"period\" or \"century\", and the name Dhul-Qarnayn therefore has a symbolic meaning as \"He of the Two Ages\", the first being the mythological time when the wall is built and the second the age of the end of the world when Allah's shariah, the divine law, is removed and Gog and Magog are to be set loose. Modern Islamic apocalyptic writers, holding to a literal reading, put forward various explanations for the absence of the wall from the modern world, some saying that Gog and Magog were the Mongols and that the wall is now gone, others that both the wall and Gog and Magog are present but invisible.\n\nDhul-Qarnayn the traveller was a favourite subject for later writers. In one of many Arabic and Persian versions of the meeting of Alexander with the Indian sages, the poet and philosopher Al-Ghazali (Abū Ḥāmid Muḥammad ibn Muḥammad al-Ghazālī, 1058–1111) wrote of how Dhul-Qarnayn came across a people who had no possessions but dug graves at the doors of their houses; their king explained that they did this because the only certainty in life is death. Ghazali's version later made its way into the \"Thousand and One Nights\".\n\nThe Sufi poet Rumi (Jalāl ad-Dīn Muhammad Rūmī, 1207-1273), perhaps the most famous of medieval Persian poets, described Dhul Qarnayn's eastern journey. The hero ascends Mount Qof, the \"mother\" of all other mountains (identified with the Alborz mountains on the northern border of Iran), which is made of emerald and forms a ring encircling the entire Earth with veins under every land. At Dhul Qarnayn's request the mountain explains the origin of earthquakes: when God wills, the mountain causes one of its veins to throb, and thus an earthquake results. Elsewhere on the great mountain Dhul Qarnayn meets Esrafil (the archangel Raphael), standing ready to blow the trumpet on the Day of Judgement.\n\nThe Malay-language \"Hikayat Iskandar Zulkarnain\" traces the ancestry of several Southeast Asian royal families, such as the Sumatra Minangkabau royalty, from Iskandar Zulkarnain, through Raja Rajendra Chola (Raja Suran, Raja Chola) in the \"Malay Annals\".\n\nMuslim and other commentators have identified Dhul Qarnayn with Alexander the Great, but some have objected that this cannot be so: Alexander lived only a short time, whereas Dhul-Qarnayn lived for 700 years as a sign of God's blessing; Alexander behaved very badly while Dhul-Qarnayn was a paragon; and Dhul-Qarnayn worshiped only one god, while Alexander worshiped many. Other candidates have been suggested:\n\n\n\n\n"}
{"id": "11744495", "url": "https://en.wikipedia.org/wiki?curid=11744495", "title": "Forgotten Voices", "text": "Forgotten Voices\n\nA series of audio tapes and books put together by the Imperial War Museum (IWM), the Forgotten Voices series brings the IWM's sound archive to life. The sound archive features thousands of interviews with people who survived wars in which the British were involved in the 20th Century. Each book has been compiled by an individual 'author', though with the exception of the introduction to each chapter, almost the entirety of each book is made up of the archive extracts.\n\nThe series currently comprises the following books: \n\n"}
{"id": "5126087", "url": "https://en.wikipedia.org/wiki?curid=5126087", "title": "Geistesgeschichte", "text": "Geistesgeschichte\n\nGeistesgeschichte (from German \"Geist\", \"spirit\" [here connoting the metaphysical realm, in contradistinction to the material], and \"Geschichte\", \"history\", \"science\") is a concept in the history of ideas denoting the branch of study concerned with the \"undercurrents\" of cultural manifestations, within the history of a people, that are peculiar to a specific timeframe.\n\nThe term is a largely untranslatable term, sometimes translated as \"intellectual history\" or \"history of ideas\", and sometimes used synonymously with \"Problemgeschichte\". The branch of study it denotes is often seen as having been inspired by the type of work done by Wilhelm Dilthey and his followers.\n\n"}
{"id": "40198682", "url": "https://en.wikipedia.org/wiki?curid=40198682", "title": "Genocide of indigenous peoples in Brazil", "text": "Genocide of indigenous peoples in Brazil\n\nThe process that has been described as the genocide of indigenous peoples in Brazil began with the Portuguese colonization of the Americas, when Pedro Álvares Cabral made landfall in what is now the country of Brazil in 1500. This started the process that led to the depopulation of the indigenous peoples in Brazil, because of disease and violent treatment by European settlers, and their gradual replacement with colonists from Europe and Africa. This process has been described as a genocide, and continues into the modern era with the ongoing destruction of indigenous peoples of the Amazonian region.\n\nOver eighty indigenous tribes were destroyed between 1900 and 1957, and the overall indigenous population declined by over eighty percent, from over one million to around two hundred thousand. The 1988 Brazilian Constitution recognises indigenous peoples' right to pursue their traditional ways of life and to the permanent and exclusive possession of their \"traditional lands\", which are demarcated as Indigenous Territories. In practice, however, Brazil's indigenous people still face a number of external threats and challenges to their continued existence and cultural heritage. The process of demarcation is slow—often involving protracted legal battles—and FUNAI do not have sufficient resources to enforce the legal protection on indigenous land.\n\nSince the 1980s there has been a boom in the exploitation of the Amazon Rainforest for mining, logging and cattle ranching, posing a severe threat to the region's indigenous population. Settlers illegally encroaching on indigenous land continue to destroy the environment necessary for indigenous peoples' traditional ways of life, provoke violent confrontations and spread disease. Peoples such as the Akuntsu and Kanoê have been brought to the brink of extinction within the last three decades. On 13 November 2012, the national indigenous peoples association from Brazil APIB submitted to the United Nation a human rights document with complaints about new proposed laws in Brazil that would further undermine their rights if approved.\n\nSeveral non-governmental organizations (NGOs) have been formed due to the ongoing persecution of the indigenous peoples in Brazil, and international pressure has been brought to bear on the state after the release of the Figueiredo Report which documented massive human rights violations.\n\nThe abuses have been described as genocide, ethnocide and cultural genocide.\n\nIn the 1940s the state and the Indian Protection Service (IPS) forcibly relocated the Aikanã, Kanôc, Kwazá and Salamái tribes to work on rubber plantations. During the journey many of the indigenous peoples starved to death, those who survived the journey were placed in an IPS settlement called Posto Ricardo Franco. These actions resulted in the near extinction of the Kanôc tribe.\n\nThe ethnocide of the Yanomami has been well documented, there are an estimated nine thousand currently living in Brazil in the Upper Orinoco drainage and a further fifteen thousand in Venezuela. The NGO Survival International has reported that throughout the 1980s up to forty thousand gold prospectors entered Yanomami territory bringing diseases the Yanomami had no immunity to, the prospectors shot and destroyed entire villages, and Survival International estimates that up to twenty per cent of the people were dead within seven years.\n\nThe Uru-Eu-Wau-Wau, whose territory has been protected by law since 1991, saw an influx of an estimated 800 people in 2007. The tribal leaders met with the civil authorities and demanded the trespassers be evicted. This tribe, initially contacted in 1981, saw a severe decline in population after disease was introduced by settlers and miners. Their numbers are now estimated at a few hundred.\n\nDuring the Portuguese colonization of the Americas, Cabral made landfall off the atlantic coast. Over the following decade the indigenous Tupí, Tapuya and other tribes which lived along the coast suffered large depopulation due to disease and violence. A process of miscegenation between Portuguese settlers and indigenous women also occurred. It is estimated that of the 2.5 million indigenous peoples who had lived in the region which now comprises Brazil, less than 10 per cent survived to the 1600s. The primarily reason for depopulation was diseases such as smallpox that advanced far beyond movement of European settlers.\n\nIn 1952 Brazil ratified the genocide convention and incorporated into their penal laws article II of the convention. While the statute was being drafted, Brazil argued against the inclusion of cultural genocide, claiming that some minority groups may use it to oppose the normal assimilation which occurs in a new country. According to professor of law at Vanderbilt University Larry May, the argument put forward by Brazil was significant, but cultural genocide should not be cast aside, and this type of genocide should be included within the definition of genocide.\n\nIn 1967 public prosecutor Jader de Figueiredo Correia, submitted the Figueiredo Report to the dictatorship which was then ruling the country. The report, which ran seven thousand pages, remained hidden for over forty years. Its release caused an international furore. The rediscovered documents are being examined by the National Truth Commission which has been tasked with the investigations of human rights violations which occurred in the periods 1947 through to 1988. The report reveals that the IPS had enslaved indigenous people, tortured children and stolen land. The Truth Commission is of the opinion that entire tribes in Maranhão were completely eradicated and in Mato Grosso, an attack on thirty Cinturão Largo left only two survivors. The report also states that landowners and members of the IPS had entered isolated villages and deliberately introduced smallpox. Of the one hundred and thirty four people accused in the report the state has as yet not tried a single one. The report also detailed instances of mass killings, rapes, and torture. Figueiredo stated that the actions of the IPS had left the indigenous peoples near extinction. The state abolished the IPS following the release of the report. The Red Cross launched an investigation after further allegations of ethnic cleansing were made after the IPS had been replaced.\n\nIn 1992 a group who had been prospecting for gold were tried for the attempted genocide of the Yanomami tribe. A report from an anthropologist, which was submitted as evidence during the trial, stated that the prospectors' entry into Yanomami territory had an adverse effect on their lives, as the prospectors carried diseases. They had also contaminated the rivers which the Yanomami used as a source of food. The UN reported that thousands of the Yanomami have been killed as the Brazilian government failed to enforce the law, and that even after though the Yanomami peoples territory had been demarcated the state had not provided the necessary resources to stop the illegal incursion of gold prospectors. These prospectors have caused massive forest fires which have led to the destruction of extensive areas of both croplands and rainforest.\n\nAt the 1992 Earth Summit in Brazil the Kari-Oka Declaration and the Indigenous Peoples Earth Charter were presented by the representatives of indigenous peoples from around the world. The Kari-Oka Declaration states \"We continue to maintain our rights as peoples despite centuries of deprivation, assimilation and genocide\". The declaration also asserted that the genocide convention must be amended so as to include the genocide of indigenous peoples. The International Work Group for Indigenous Affairs (IWGIA) was founded in 1968 in response to the genocide of indigenous peoples in Brazil and Paraguay, and in 1969 Survival International was founded in London as a response to the atrocities, theft of land and genocide occurring in the Brazilian Amazon. In 1972 anthropologists from Harvard university founded Cultural survival.\n\nThe World Bank has been subject to criticism over loans which have been used to help fund the dislocation of indigenous peoples and environmental destruction. The Polonoreste project caused wholesale deforestation, ecological damage on a wide scale, as well as the forced relocation of indigenous communities. The project led to an international campaign which resulted in the World Bank suspending loans.\n"}
{"id": "12223", "url": "https://en.wikipedia.org/wiki?curid=12223", "title": "Great man theory", "text": "Great man theory\n\nThe great man theory is a 19th-century idea according to which history can be largely explained by the impact of great men, or heroes; highly influential individuals who, due to either their personal charisma, intelligence, wisdom, or political skill used their power in a way that had a decisive historical impact. The theory was popularized in the 1840s by Scottish writer Thomas Carlyle, but in 1860 Herbert Spencer formulated a counter-argument that has remained influential throughout the 20th century to the present: Spencer said that such great men are the products of their societies, and that their actions would be impossible without the social conditions built before their lifetimes.\n\nCarlyle stated that \"The history of the world is but the biography of great men\", reflecting his belief that heroes shape history through both their personal attributes and divine inspiration. In his book \"On Heroes, Hero-Worship and the Heroic in History\", Carlyle saw history as having turned on the decisions of \"heroes\", giving detailed analysis of the influence of several such men (including Muhammad, Shakespeare, Martin Luther, Rousseau, Pericles, Napoleon, and Richard Wagner). Carlyle also felt that the study of great men was \"profitable\" to one's own heroic side; that by examining the lives led by such heroes, one could not help but uncover something about one's true nature.\n\nAmerican scholar Frederick Adams Woods supported the great man theory in his work \"The Influence of Monarchs: Steps in a New Science of History\". Woods investigated 386 rulers in Western Europe from the 12th century until the French revolution in the late 18th century and their influence on the course of historical events.\n\nThis theory is usually contrasted with \"history from below\", which emphasizes the life of the masses over the leader. An overwhelming wave of smaller events causes certain developments to occur. The Great Man approach to history was most fashionable with professional historians in the 19th century; a popular work of this school is the \"Encyclopædia Britannica Eleventh Edition\" (1911) which contains lengthy and detailed biographies about the great men of history, but very few general or social histories. For example, all information on the post-Roman \"Migrations Period\" of European History is compiled under the biography of Attila the Hun. This heroic view of history was also strongly endorsed by some philosophers, such as Leon Bloy, Hegel, Kierkegaard, Nietzsche, Spengler and Max Weber, but it fell out of favor after World War II.\n\nIn \"Untimely Meditations\", Nietzsche writes that \"the goal of humanity lies in its highest specimens\".\n\nIn \"Fear and Trembling\", Kierkegaard writes that \"to be able to fall down in such a way that the same second it looks as if one were standing and walking, to transform the leap of life into a walk, absolutely to express the sublime and the pedestrian—that only these knights of faith can do—this is the one and only prodigy.\"\n\nHegel, proceeding from providentialist theory, argued that \"what is real is reasonable\" and World-Historical individuals are World-Spirit's agents. Hegel wrote: \"Such are great historical men—whose own particular aims involve those large issues which are the will of the World-Spirit.\" Thus, according to Hegel, a great man does not create historical reality himself but only uncovers the inevitable future.\n\nOne of the most forceful critics of Carlyle's formulation of the great man theory was Herbert Spencer, who believed that attributing historical events to the decisions of individuals was a hopelessly primitive, childish, and unscientific position. He believed that the men Carlyle called \"great men\" were merely products of their social environment:\n\nTolstoy's \"War and Peace\" features criticism of Great Man Theories as a recurring theme in the philosophical digressions. According to Tolstoy, the significance of great individuals is imaginary; as a matter of fact they are only \"history's slaves\" realizing the decree of Providence.\n\nWilliam James in his lecture \"Great Men and Their Environment\" underlined the importance of the Great Man's congruence with the surroundings (in the broad sense), though his ultimate point was that environments and individuals shape each other reciprocally, just as environments and individual members of animal species do according to Darwinian theory.\n\nAmong modern critics of the theory, one, Sidney Hook, is supportive of the idea; he gives credit to those who shape events through their actions, and his book \"The Hero in History\" is devoted to the role of the hero and in history and influence of the outstanding persons.\n\nLeonid Grinin defines a historical figure (a great man) thus:\n\n"}
{"id": "5777097", "url": "https://en.wikipedia.org/wiki?curid=5777097", "title": "Historism", "text": "Historism\n\nHistorism is a philosophical and historiographical theory, founded in 19th-century Germany (as \"Historismus\") and especially influential in 19th- and 20th-century Europe. In those times there was not a single natural, humanitarian or philosophical science that would not reflect, in one way or another, the historical type of thought (cf. comparative historical linguistics etc.). It pronounces the historicity of humanity and its binding to tradition.\n\nHistorist historiography rejects historical teleology and bases its explanations of historical phenomena on sympathy and understanding (see Hermeneutics) for the events, acting persons, and historical periods. The historist approach takes to its extreme limits the common observation that human institutions (language, Art, religion, law, State) are subject to perpetual change.\n\n\"Historism\" is not to be confused with \"historicism\", nevertheless the English habits of using both words are very similar. (The term \"historism\" is sometimes reserved to identify the specific current called \"Historismus\" in the tradition of German philosophy and historiography.)\n\nBecause of the power held on the social sciences by logical positivism, historism or historicism is deemed unpopular.\n\nKarl Popper, one of the most distinguished critics of historicism, criticized historism, too. He differentiated between both phenomena as follows: The term \"historicism\" is used in his influential books \"The Poverty of Historicism\" and \"The Open Society and Its Enemies\" to describe “an approach to the social sciences which assumes that \"historical prediction\" is their primary aim, and which assumes that this aim is attainable by discovering the 'rhythms' or the 'patterns', the 'laws' or the 'trends' that underlie the evolution of history”. Popper wrote with reference to Hegel's theory of history, which he criticized extensively. By \"historism\" on the contrary, he means the tendency to regard every argument or idea as completely accounted for by its historical context, as opposed to assessing it by its merits. \"Historism\" does not aim for the 'laws' of history, but premises the individuality of each historical situation.\n\nOn the basis of Popper's definitions, the historian Stefan Berger proposes as a proper word usage: \n\nNotable exponents of historism were primarily the German 19th-century historians Leopold von Ranke and Johann Gustav Droysen, 20th-century historian Friedrich Meinecke, and the philosopher Wilhelm Dilthey. Dilthey was influenced by Ranke. The jurists Friedrich Carl von Savigny and Karl Friedrich Eichhorn were strongly influenced by the ideas of historism and founded the German Historical School of Law. The Italian philosopher and historian Benedetto Croce and his British colleague Robin George Collingwood were important European exponents of historism in the late 19th and early 20th century. Collingwood was influenced by Dilthey.\n\nRanke's arguments can be viewed as an antidote to the lawlike and quantitative approaches common in sociology and most other social sciences.\n\nThe principle of historism has a universal methodological significance in Marxism. The essence of this principle, in brief, is\nGeorg G. Iggers is one of the most important critical authors on historism. His book \"The German Conception of History: The National Tradition of Historical Thought from Herder to the Present\", first published in 1968 (by Wesleyan University Press, Middletown, Ct.) is a \"classic” among critiques of historism.\n\nAnother critique is presented by the German philosopher Friedrich Nietzsche, whose essay \"Vom Nutzen und Nachteil der Historie für das Leben\" (\"On the Use and Abuse of History for Life\", 1874; see \"The Untimely Meditations\") denounces “a malignant historical fever”. Nietzsche contends that the historians of his times, the historists, damaged the powers of human life by relegating it to the past instead of opening it to the future. For this reason, he calls for a return, beyond historism, to humanism.\n\n20th-century German historians promoting some aspects of historism are Ulrich Muhlack, Thomas Nipperdey and Jörn Rüsen.\n\nAlso the Spanish philosopher José Ortega y Gasset was influenced by historism.\n\n\n"}
{"id": "7705856", "url": "https://en.wikipedia.org/wiki?curid=7705856", "title": "History of Indigenous Australians", "text": "History of Indigenous Australians\n\nThe History of Indigenous Australians began at least 65,000 years ago when humans first populated Australia.\n\nThe origin of first humans to populate the southern continent remains a matter of conjecture and debate. Some anthropologist believe they could have arrived as a result of the earliest human migrations out of Africa. Although they likely migrated to the territory, later named Australia, though Southeast Asia they are not demonstrably related to any known Asian or Polynesian population. There is evidence of genetic and linguistic interchange between Australians in the far north and the Austronesian peoples of modern-day New Guinea and the islands, but this may be the result of recent trade and intermarriage.\n\nAt the time of first European contact, it is generally estimated that between 315,000 to 750,000 people lived in Australia, in diverse groups, but upper estimates place the total population as high as 1.25 million. A cumulative population of 1.6 billion people has been estimated to have lived in Australia over 65,000 years prior to British colonisation. The regions of heaviest Indigenous population were the same temperate coastal regions that are currently the most heavily populated. In the early 1900s it was commonly believed that the Aboriginal population of Australia was leading toward extinction. The population shrank from those present when colonisation occurred in 1788 to 50,000 in 1930; this was primarily due to an outbreak of smallpox and to a lesser extent from other diseases.\n\nPost-colonisation, the coastal Indigenous populations were soon absorbed, depleted or forced from their lands; the traditional aspects of Aboriginal life which remained persisted most strongly in areas such as the Great Sandy Desert where European settlement has been sparse. The greatest population density was to be found in the southern and eastern regions of the continent, the Murray River valley in particular. However, Aboriginal Australians maintained successful communities throughout Australia, from the cold and wet highlands of Tasmania to the more arid parts of the continental interior. Technologies, diets and hunting practices varied according to the local environment.\n\nIt is believed that the first early human migration to Australia was achieved when this landmass formed part of the Sahul continent, connected to the island of New Guinea via a land bridge. It is also possible that people came by island hopping via an island chain between Sulawesi and New Guinea and the other reaches North Western Australia via Timor. The exact timing of the arrival of the ancestors of the Aboriginal Australians has been a matter of dispute among archaeologists. The most generally accepted date for first arrival is between 40,000–80,000 years BP. Near Penrith in New South Wales, since 1971 numerous Aboriginal stone tools have been found in Cranebrook Terraces gravel sediments having dates of 45,000 to 50,000 years BP. When these results were new they were controversial, but more recent dating of the same strata in 1987 and 2003 has corroborated these dates. A 48,000 BCE date is based on a few sites in northern Australia dated using thermoluminescence.\n\nA large number of sites have been radiocarbon dated to around 38,000 BCE, leading some researchers to doubt the accuracy of the thermoluminescence technique. Radiocarbon dating is limited to a maximum age of around 40,000 years. Some estimates have been given as widely as from 30,000 to 68,000 BCE. Earlier dates are requiring new techniques such as optically stimulated luminescence (OSL) and accelerator mass spectrometry (AMS), and the evidence for an earlier date of arrival is growing. Charles Dortch has dated recent finds on Rottnest Island, Western Australia at 70,000 years BP. The rock shelters at Malakunanja II (a shallow rock-shelter about 50 kilometres inland from the present coast) and of Nauwalabila I (70 kilometres further south) show evidence of used pieces of ochre – evidence for paint used by artists 60,000 years ago. Using OSL Rhys Jones has obtained a date for stone tools in these horizons dating from 53,000–60,000 years ago.\n\nThermoluminescence dating of the Jinmium site in the Northern Territory suggested a date of 116,000 plus or minus 12,000 BCE. Although this result received wide press coverage, it is not accepted by most archaeologists. Only Africa has older physical evidence of habitation by modern humans. There is also evidence of a change in fire regimes in Australia, drawn from reef deposits in Queensland, between 70 and 100,000 years ago, and the integration of human genomic evidence from various parts of the world also supports a date of before 60,000 years for the arrival of Australian Aboriginal people in the continent.\n\nHumans reached Tasmania approximately 40,000 years ago by migrating across a land bridge from the mainland that existed during the last glacial maximum. After the seas rose about 12,000 years ago and covered the land bridge, the inhabitants there were isolated from the mainland until the arrival of European settlers.\n\nShort statured aboriginal tribes inhabited the rainforests of North Queensland, of which the best known group is probably the Tjapukai of the Cairns area. These rainforest people, collectively referred to as Barrineans, were once considered to be a relic of an earlier wave of Negrito migration to the Australian continent, but this theory no longer finds much favour.\n\nMungo Man, whose remains were discovered in 1974 near Lake Mungo in New South Wales, is the oldest human yet found in Australia. Although the exact age of Mungo Man is in dispute, the best consensus is that he is at least 40,000 years old. Stone tools also found at Lake Mungo have been estimated, based on stratigraphic association, to be about 50,000 years old. Since Lake Mungo is in south-eastern Australia, many archaeologists have concluded that humans must have arrived in north-west Australia at least several thousand years earlier.\n\nIn 2012, the results of large-scale genotyping has indicated that Aboriginal Australians, the indigenous peoples of New Guinea and the Mamanwa, an indigenous people of the southern Philippines are closely related, having diverged from a common origin approximately 36,000 years ago. The same studies show that Aboriginal genomes consist of up to 11% Indian DNA which is uniformly spread through Northern Australia, indicating a substantial gene flow between Indian populations and Northern Australia occurred around 4,230 years ago. Changes in tool technology and food processing appear in the archaeological record around this time, suggesting there may have been migration from India.\n\nWhen the north-west of Australia, which is closest to Asia, was first occupied, the region consisted of open tropical forests and woodlands. After around 10,000 years of stable climatic conditions, by which time the Aboriginal people had settled the entire continent, temperatures began cooling and winds became stronger, leading to the beginning of an ice age. By the glacial maximum, 25,000 to 15,000 years ago, the sea level had dropped to around 140 metres below its present level. Australia was connected to New Guinea and the Kimberley region of Western Australia was separated from Southeast Asia (\"Wallacea\") by a strait only approximately 90 km wide. Rainfall was 40% to 50% lower than modern levels, depending on region, while the lower CO levels (half pre-industrial levels) meant that vegetation required twice as much water for photosynthesis.\n\nThe Kimberley, including the adjacent exposed continental Sahul Shelf, was covered by vast grasslands dominated by flowering plants of the family Poaceae, with woodlands and semi-arid scrub covering the shelf joining New Guinea to Australia. Southeast of the Kimberley, from the Gulf of Carpentaria to northern Tasmania the land, including the western and southern margins of the now exposed continental shelves, was covered largely by extreme deserts and sand dunes. It is believed that during this period no more than 15% of Australia supported trees of any kind. While some tree cover remained in the southeast of Australia, the vegetation of the wetter coastal areas in this region was semi-arid savannah, while some tropical rainforests survived in isolated coastal areas of Queensland.\n\nTasmania was covered primarily by cold steppe and alpine grasslands, with snow pines at lower altitudes. There is evidence that there may have been a significant reduction in Australian Aboriginal populations during this time, and there would seem to have been scattered \"refugia\" in which the modern vegetation types and Aboriginal populations were able to survive. Corridors between these refugia seem to be routes by which people kept in contact, and they seem to have been the basis for what are now called \"Songlines\" today. With the end of the ice age, strong rains returned, until around 5,500 years ago, when the wet season cycle in the north ended, bringing with it a megadrought that lasted 1,500 years. The return of reliable rains around 4,000 years BP gave Australia its current climate.\n\nFollowing the Ice Age, Aboriginal people around the coast, from Arnhem Land, the Kimberley and the southwest of Western Australia, all tell stories of former territories that were drowned beneath the sea with the rising coastlines after the Ice Age. It was this event that isolated the Tasmanian Aboriginal people on their island, and probably led to the extinction of Aboriginal cultures on the Bass Strait Islands and Kangaroo Island in South Australia. In the interior, the end of the Ice Age may have led to the recolonisation of the desert and semi-desert areas by Aboriginal people of the Northern Territory. This in part may have been responsible for the spread of languages of the Pama–Nyungan language family and secondarily responsible for the spread of male initiation rites involving circumcision. There has been a long history of contact between Papuan peoples of the Western Province, Torres Strait Islanders and the Aboriginal people in Cape York.\n\nThe Aboriginal Australians lived through great climatic changes and adapted successfully to their changing physical environment. There is much ongoing debate about the degree to which they modified the environment. One controversy revolves around the role of indigenous people in the extinction of the marsupial megafauna (also see Australian megafauna). Some argue that natural climate change killed the megafauna. Others claim that, because the megafauna were large and slow, they were easy prey for human hunters. A third possibility is that human modification of the environment, particularly through the use of fire, indirectly led to their extinction. Oral history demonstrates \"the continuity of culture of Indigenous Australians\" for at least 10,000 years. This is shown by correlation of oral history stories with verifiable incidents including known changes in sea levels and their associated large changes in location of ocean shorelines; oral records of megafauna; and comets.\n\nThe introduction of the dingo, possibly as early as 3500 BCE, showed that contact with South East Asian peoples continued, as the closest genetic connection to the dingo seems to be the wild dogs of Thailand. This contact was not just one-way, as the presence of kangaroo ticks on these dogs demonstrates. Dingoes began and evolved in Asia. The earliest known dingo-like fossils are from Ban Chiang in north-east Thailand (dated at 5500 years BP) and from north Vietnam (5000 years BP). According to skull morphology, these fossils occupy a place between Asian wolves (prime candidates were the pale footed (or Indian) wolf \"Canis lupus pallipes\" and the Arabian wolf \"Canis lupus arabs\") and modern dingoes in Australia and Thailand.\n\nMost scientists presently believe that it was the arrival of the Australian Aboriginal people on the continent and their introduction of fire-stick farming that was responsible for these extinctions. Fossil research published in 2017 indicates that Aboriginal people and megafauna coexisted for \"at least 17,000 years\". Aboriginal Australians used fire for a variety of purposes: to encourage the growth of edible plants and fodder for prey; to reduce the risk of catastrophic bushfires; to make travel easier; to eliminate pests; for ceremonial purposes; for warfare and just to \"clean up country.\" There is disagreement, however, about the extent to which this burning led to large-scale changes in vegetation patterns.\n\nAboriginal Australians were limited to the range of foods occurring naturally in their area, but they knew exactly when, where and how to find everything edible. Anthropologists and nutrition experts who have studied the tribal diet in Arnhem Land found it to be well-balanced, with most of the nutrients modern dietitians recommend. But food was not obtained without effort. In some areas both men and women had to spend from half to two-thirds of each day hunting or foraging for food. Each day, the women of the group went into successive parts of one countryside with wooden digging sticks and plaited dilly bags or wooden coolamons. Larger animals and birds, such as kangaroos and emus, were speared or disabled with a thrown club, boomerang, or stone. Many Indigenous hunting devices were used to get within striking distance of prey. The men were excellent trackers and stalkers, approaching their prey running where there was cover, or 'freezing' and crawling when in the open. They were careful to stay downwind and sometimes covered themselves with mud to disguise their smell.\n\nFish were sometimes taken by hand by stirring up the muddy bottom of a pool until they rose to the surface, or by placing the crushed leaves of poisonous plants in the water to stupefy them. Fish spears, nets, wicker or stone traps were also used in different areas. Lines with hooks made from bone, shell, wood or spines were used along the north and east coasts. Dugong, turtle and large fish were harpooned, the harpooner launching himself bodily from the canoe to give added weight to the thrust. The mode of life and material cultures varied greatly from region to region. While Torres Strait Island populations were agriculturalists who supplemented their diet through the acquisition of wild foods, most Aboriginal Australians were hunter-gatherers. Aboriginal Australians along the coast and rivers were also expert fishermen. Some Aboriginal and Torres Strait Islander people relied on the dingo as a companion animal, using it to assist with hunting and for warmth on cold nights.\n\nIn present-day Victoria, for example, there were two separate communities with an economy based on eel-farming in complex and extensive irrigated pond systems; one on the Murray River in the state's north, the other in the south-west near Hamilton in the territory of the Djab Wurrung, which traded with other groups from as far away as the Melbourne area (see Gunditjmara). A primary tool used in hunting is the spear, launched by a woomera or spear-thrower in some locales. Boomerangs were also used by some mainland Indigenous Australians. The non-returnable boomerang (known more correctly as a Throwing Stick), more powerful than the returning kind, could be used to injure or even kill a kangaroo.\n\nOn mainland Australia no animal other than the dingo was domesticated, however domestic pigs were utilised by Torres Strait Islanders. The typical Aboriginal diet included a wide variety of foods, such as pig, kangaroo, emu, wombats, goanna, snakes, birds, many insects such as honey ants, Bogong moths and witchetty grubs. Many varieties of plant foods such as taro, coconuts, nuts, fruits and berries were also eaten.\n\nPermanent villages were the norm for most Torres Strait Island communities. In some areas mainland Aboriginal Australians also lived in semi-permanent villages, most usually in less arid areas where fishing could provide for a more settled existence. Most Indigenous communities were semi-nomadic, moving in a regular cycle over a defined territory, following seasonal food sources and returning to the same places at the same time each year. From the examination of middens, archaeologists have shown that some localities were visited annually by Indigenous communities for thousands of years. In the more arid areas Aboriginal Australians were nomadic, ranging over wide areas in search of scarce food resources. There is evidence of substantial change in indigenous culture over time. Rock painting at several locations in northern Australia has been shown to consist of a sequence of different styles linked to different historical periods. There is also prominent rock paintings found in the Sydney basin area which date to around 5,000 years.\n\nHarry Lourandos has been the leading proponent of the theory that a period of hunter-gatherer intensification occurred between 3000 and 1000 BCE. Intensification involved an increase in human manipulation of the environment (for example, the construction of eel traps in Victoria), population growth, an increase in trade between groups, a more elaborate social structure, and other cultural changes. A shift in stone tool technology, involving the development of smaller and more intricate points and scrapers, occurred around this time. This was probably also associated with the introduction to the mainland of the Australian dingo.\n\nMany Indigenous communities also have a very complex kinship structure and in some places strict rules about marriage. In traditional societies, men are required to marry women of a specific moiety. The system is still alive in many Central Australian communities. To enable men and women to find suitable partners, many groups would come together for annual gatherings (commonly known as corroborees) at which goods were traded, news exchanged, and marriages arranged amid appropriate ceremonies. This practice both reinforced clan relationships and prevented inbreeding in a society based on small semi-nomadic groups.\n\nIn 1770, Lieutenant James Cook claimed the east coast of Australia in the name of the United Kingdom and named it New South Wales. Cook's declaration was made unilaterally and without any consultation with First Australians, in spite of his direct written orders from The Admiralty, which instructed him to conclude a treaty with the inhabitants (if any) and obtain their permission for the expropriation of land. British colonisation of Australia began in Sydney in 1788. The most immediate consequence of British settlement – within weeks of the first colonists' arrival – was a wave of European epidemic diseases such as chickenpox, smallpox, influenza and measles, which spread in advance of the frontier of settlement. The worst-hit communities were the ones with the greatest population densities, where disease could spread more readily. In the arid centre of the continent, where small communities were spread over a vast area, the population decline was less marked. Disease was the principal cause of population decline.\n\nThe second consequence of British settlement was appropriation of land and water resources. The settlers took the view that Aboriginal Australians were nomads with no concept of land ownership, who could be driven off land wanted for farming or grazing and who would be just as happy somewhere else. In fact the loss of traditional lands, food sources and water resources was often fatal, particularly to communities already weakened by disease. Additionally, Aboriginal Australians groups had a deep spiritual and cultural connection to the land, so that in being forced to move away from traditional areas, cultural and spiritual practices necessary to the cohesion and well-being of the group could not be maintained. Proximity to settlers also brought venereal disease, to which Aboriginal Australians had no tolerance and which greatly reduced Aboriginal fertility and birthrates. Settlers also brought alcohol, opium and tobacco, and substance abuse has remained a chronic problem for Aboriginal communities ever since. Entire communities in the moderately fertile southern part of the continent simply vanished without trace, often before European settlers arrived or recorded their existence.\n\nDeadly infectious diseases like smallpox, influenza and tuberculosis were always major causes of Aboriginal deaths. Smallpox alone killed more than 50% of the Aboriginal population. In 1789, a disastrous smallpox epidemic broke out, killing up to 70% of the Indigenous people of the Sydney region. Based on information recorded in the journals of some members of the First Fleet, it has been surmised that the Aborigines of the Sydney region had never encountered the disease before and lacked immunity to it. Unable to understand or counter the sickness, they often fled, leaving the sick with some food and water to fend for themselves. As the clans fled, the epidemic spread further along the coast and into the hinterland. This had a disastrous effect on Aboriginal society; with many of the productive hunters and gatherers dead, those who survived the initial outbreak began to starve.\n\nLieutenant William Bradley recorded the first indications of the severity of the disaster that had struck the Aboriginal population of Sydney when he described his shock at the small number of them to be seen on the harbour and its shores compared with previous times. The British had not seen smallpox in anyone among themselves before the outbreak. Although there were fears about the health of some of the convicts on the First Fleet, these were subsequently dismissed by Surgeon-General John White who believed they were suffering from \"slight inflammatory complaints\". The origin of the smallpox epidemic is controversial, and it has been speculated that the surgeons on board the First Fleet brought vials of smallpox matter and either accidentally or intentionally released it as a \"biological weapon\". In 2014, writing in \"Journal of Australian Studies\", Christopher Warren concluded that British marines were most likely to have spread smallpox, possibly without informing Governor Phillip but conceded in his conclusion that \"today's evidence only provides for a balancing of probabilities and this is all that can be attempted.\"\n\nOn the mainland, prolonged conflict followed the frontier of European settlement. In 1834, John Dunmore Lang wrote: \"There is black blood at this moment on the hands of individuals of good repute in the colony of New South Wales of which all the waters of New Holland would be insufficient to wash out the indelible stains.\" In 1790, an Aboriginal leader Pemulwuy in Sydney resisted the Europeans, waging a guerrilla-style warfare on the settlers in a series of wars known as the Hawkesbury and Nepean Wars, which spanned 26 years, from 1790 to 1816. In 1838, twenty eight Aboriginal people were killed at the Myall Creek massacre; seven of the convict settlers responsible, six white men and one African man, were tried, convicted and hung for the murders. Many Aboriginal communities resisted the settlers, such as the Noongar of south-western Australia, led by Yagan, who was killed in 1833. The Kalkadoon of Queensland also resisted the settlers, and there was a massacre of over 200 people on their land at Battle Mountain in 1884. There was a massacre at Coniston in the Northern Territory in 1928. Poisoning of food and water has been recorded on several different occasions. The number of violent deaths at the hands of white people is still the subject of debate, with a figure of around 10,000 - 20,000 deaths being advanced by historians such as Henry Reynolds. However the methodology behind figures such as this one has been criticised due to the fact that only white deaths were documented in frontier conflicts, forcing historians to estimate a country-wide white-black death ratio in violent confrontations and infer from this the number of Aboriginal deaths. Reynolds, and other historians, estimate that up to 3,000 white people were killed by Aboriginal Australians in the frontier violence. By the 1870s all the fertile areas of Australia had been appropriated, and Aboriginal communities reduced to impoverished remnants living either on the fringes of European communities or on lands considered unsuitable for settlement.\n\nThe Palawa, or Indigenous people of Tasmania, were particularly hard-hit. Nearly all of them, apparently numbering somewhere between 2,000 and 15,000 when white settlement began, were dead by the 1870s. It is widely claimed that this was the result of a genocidal policy, in the form of the \"Black War\". Other historians dispute this. Geoffrey Blainey wrote that, in Tasmania, by 1830: \"Disease had killed most of them but warfare and private violence had also been devastating.\" Josephine Flood wrote: \"The catastrophic death rate was due to new diseases, particularly pulmonary and sexually transmitted ones.\" Historian Keith Windschuttle also disagrees that violence was the principal cause. He argues that there are plausible recorded accounts of approximately 120 Aboriginal Tasmanians killed in 1803–47, that there were an unknown number of unrecorded killings and that many of these were killed in 'self-defence' by settlers. Windschuttle argues some accounts of killings are implausible for a variety of reasons such as incidents involving improbably large death tolls given the muzzle-loading, single-shot muskets in use and that the low number of plausible recorded killings is one indicator of a relatively low level of conflict. Another scholar, H. A. Willis, has subsequently disputed Windschuttle's figures and has documented 188 Palawa killed by settlers in 1803–34 alone, with possibly another 145 killed during the same period. Such counts do not consider undocumented violence and must be regarded as minimum estimates. It is also claimed, but untrue, that the last Aboriginal Tasmanian was Truganini, who died in 1876. This belief stems from a distinction between \"full bloods\" and \"half castes\" that is now generally regarded as racist. Palawa people survived, in missions set up on the islands of Bass Strait.\nNevertheless, some initial contact between Aboriginal people and Europeans was peaceful, starting with the Guugu Yimithirr people who met James Cook near Cooktown in 1770. Bennelong served as interlocutor between the Eora people of Sydney and the British colony, and was the first Aboriginal Australian to travel to England, staying there between 1792 and 1795. Aboriginal people were known to help European explorers, such as John King, who lived with a tribe for two and a half months after the ill-fated Burke and Wills expedition of 1861. Also living with Indigenous people was William Buckley, an escaped convict, who was with the Wautharong people near Melbourne for thirty-two years, before being found in 1835. Many Indigenous people adapted to European culture, working as stock hands or labourers. The first Australian cricket team, which toured England in 1868, was principally made up of Indigenous players.\n\nAs the European pastoral industries developed, several economic changes came about. The appropriation of prime land and the spread of European livestock over vast areas made a traditional Indigenous lifestyle less viable, but also provided a ready alternative supply of fresh meat for those prepared to incur the settlers' anger by hunting livestock. The impact of disease and the settlers' industries had a profound impact on the Indigenous Australians' way of life. With the exception of a few in the remote interior, all surviving Indigenous communities gradually became dependent on the settler population for their livelihood.\n\nIn south-eastern Australia, during the 1850s, large numbers of white pastoral workers deserted employment on stations for the Australian goldrushes. Indigenous women, men and children became a significant source of labour. Most Indigenous labour was unpaid, instead Indigenous workers received rations in the form of food, clothing and other basic necessities. In the later 19th century, settlers made their way north and into the interior, appropriating small but vital parts of the land for their own exclusive use (waterholes and soaks in particular), and introducing sheep, rabbits and cattle, all three of which ate out previously fertile areas and degraded the ability of the land to carry the native animals that were vital to Indigenous economies. Indigenous hunters would often spear sheep and cattle, incurring the wrath of graziers, after they replaced the native animals as a food source. As large sheep and cattle stations came to dominate northern Australia, Indigenous workers were quickly recruited. Several other outback industries, notably pearling, also employed Aboriginal workers.\n\nIn many areas Christian missions provided food and clothing for Indigenous communities and also opened schools and orphanages for Indigenous children. In some places colonial governments provided some resources.\n\nIn spite of the impact of disease, violence and the spread of foreign settlement and custom, some Indigenous communities in remote desert and tropical rainforest areas survived according to traditional means until well into the 20th century. In 1914 around 800 Aboriginal people answered the call to arms, despite restrictions on Indigenous Australians serving in the military. As the war continued, these restrictions were relaxed as more recruits were needed. Many enlisted by claiming they were Māori or Indian.\n\nBy the 1920s, the Indigenous population had declined to between 50,000 and 90,000, and the belief that the Indigenous Australians would soon die out was widely held, even among Australians sympathetic to their situation. But by about 1930, those Indigenous Australians who had survived had acquired better resistance to imported diseases, and birthrates began to rise again as communities were able to adapt to changed circumstances. From the 1940s, the availability of penicillin to treat imported diseases also had a marked effect on reversing the population decline.\n\nIn the Northern Territory, significant frontier conflict continued. Both isolated Europeans and visiting Asian fishermen were killed by hunter gatherers until the start of World War II in 1939. It is known that some European settlers in the centre and north of the country shot Indigenous people during this period. One particular series of killings became known as the Caledon Bay crisis, and became a watershed in the relationship between Indigenous and non-Indigenous Australians.\n\nIn the early 20th century, anthropologists' influence dominated society's view of aboriginals in Australia. They were viewed as a different race that was not as evolved as Europeans. Starting in the 1880 and continuing into the 20th century, debate continued on where between ape and man could the aboriginal be situated in evolutionary terms. In the mid-1920s, there was a shift in focus away from physical anthropological issues of race and towards a cultural anthropological concerns established by field-work. New studies described aboriginals' social organisation, religious belief and practice. Alfred Radcliffe-Brown, the father of modern social anthropology, published his \"Social Organization of Australian Tribes\" in 1931.\n\nBy the end of World War II, many Indigenous men had served in the military and were paid an equitable salary. However, Aboriginal workers remained unfree labourers, paid only small amounts of cash in addition to rations, and had their movements severely restricted by regulations and/or police action. On 4 February 1939, Jack Patten led a strike at Cummeragunja Mission in New South Wales. The people of Cummeragunja were protesting their harsh treatment under what was a draconian system. A once successful farming enterprise was taken from their control, and residents were forced to subsist on meager rations. Approximately 200 people left their homes, taking part in the Cummeragunja walk-off, and the majority crossed the border into Victoria, never to return home.\n\nOn 1 May 1946, Aboriginal station workers in the Pilbara region of Western Australia started the 1946 Pilbara strike and never returned to work. Mass layoffs across northern Australia followed the Federal Pastoral Industry Award of 1968, which required the payment of a minimum wage to Aboriginal station workers, as they were not paid by the Pastoralist discretion, many however were not and those who were had their money held by the government. Many of the workers and their families became refugees or fringe dwellers, living in camps on the outskirts of towns and cities.\n\nIn 1949, the right to vote in federal elections was extended to Indigenous Australians who had served in the armed forces, or were enrolled to vote in state elections. At that time, those Indigenous Australians who lived in Queensland, Western Australia and the Northern Territory were still ineligible to vote in state elections, consequently they did not have the right to vote in federal elections.\n\nAll Indigenous Australians were given the right to vote in Commonwealth elections in Australia by the Menzies government in 1962. The first federal election in which all Aboriginal Australians could vote was held in November 1963. The right to vote in state elections was granted in Western Australia in 1962 and Queensland was the last state to do so in 1965.\n\nThe 1967 referendum, passed with a 90% majority, allowed Indigenous Australians to be included in the Commonwealth parliament's power to make special laws for specific races, and to be included in counts to determine electoral representation. This has been the largest affirmative vote in the history of Australia's referendums.\n\nIn 1971, Yolngu people at Yirrkala sought an injunction against Nabalco to cease mining on their traditional land. In the resulting historic and controversial Gove land rights case, Justice Blackburn ruled that Australia had been terra nullius before European settlement, and that no concept of Native title existed in Australian law. Although the Yolngu people were defeated in this action, the effect was to highlight the absurdity of the law, which led first to the Woodward Commission, and then to the Aboriginal Land Rights Act.\n\nIn 1972, the Aboriginal Tent Embassy was established on the steps of Parliament House in Canberra, in response to the sentiment among Indigenous Australians that they were \"strangers in their own country\". A Tent Embassy still exists on the same site.\n\nIn 1975, the Whitlam government drafted the Aboriginal Land Rights Act, which aimed to restore traditional lands to Indigenous people. After the dismissal of the Whitlam government by the Governor-General, a reduced-scope version of the Act (known as the Aboriginal Land Rights Act 1976) was introduced by the coalition government led by Malcolm Fraser. While its application was limited to the Northern Territory, it did grant \"inalienable\" freehold title to some traditional lands.\n\nIn 1984, a group of Pintupi people who were living a traditional hunter-gatherer desert-dwelling life were tracked down in the Gibson Desert in Western Australia and brought into a settlement. They are believed to have been the last uncontacted tribe in Australia.\n\nA 1987 federal government report described the history of the \"Aboriginal Homelands Movement\" or \"Return to Country movement\" as \"a concerted attempt by Aboriginal people in the 'remote' areas of Australia to leave government settlements, reserves, missions and non-Aboriginal townships and to re-occupy their traditional country.\"\n\nIn 1992, the Australian High Court handed down its decision in the Mabo Case, declaring the previous legal concept of \"terra nullius\" to be invalid. This decision legally recognised certain land claims of Indigenous Australians in Australia prior to British Settlement. Legislation was subsequently enacted and later amended to recognise Native Title claims over land in Australia.\n\nIn 1998, as the result of an inquiry into the forced removal of Indigenous children (see Stolen generation) from their families, a National Sorry Day was instituted, to acknowledge the wrong that had been done to Indigenous families. Many politicians, from both sides of the house, participated, with the notable exception of the Prime Minister, John Howard.\n\nIn 1999 a referendum was held to change the Australian Constitution to include a preamble that, amongst other topics, recognised the occupation of Australia by Indigenous Australians prior to British Settlement. This referendum was defeated, though the recognition of Indigenous Australians in the preamble was not a major issue in the referendum discussion, and the preamble question attracted minor attention compared to the question of becoming a republic.\n\nIn 2004, the Australian Government abolished The Aboriginal and Torres Strait Islander Commission (ATSIC), which had been Australia's top Indigenous organisation. The Commonwealth cited corruption and, in particular, made allegations concerning the misuse of public funds by ATSIC's chairman, Geoff Clark, as the principal reason. Indigenous specific programmes have been mainstreamed, that is, reintegrated and transferred to departments and agencies serving the general population. The Office of Indigenous Policy Coordination was established within the then Department of Immigration and Multicultural and Indigenous Affairs, and now with the Department of Families, Community Services and Indigenous Affairs to coordinate a \"whole of government\" effort.\n\nIn June 2005, Richard Frankland, founder of the 'Your Voice' political party, in an open letter to Prime Minister John Howard, advocated that the eighteenth-century conflicts between Aboriginal and colonial Australians \"be recognised as wars and be given the same attention as the other wars receive within the Australian War Memorial\". In its editorial on 20 June 2005, Melbourne newspaper, The Age, said that \"Frankland has raised an important question,\" and asked whether moving \"work commemorating Aborigines who lost their lives defending their land ... to the War Memorial [would] change the way we regard Aboriginal history.\"\n\nIn 2008, Prime Minister Kevin Rudd made a formal apology for the Stolen Generations.\n\n\n\n"}
{"id": "49859746", "url": "https://en.wikipedia.org/wiki?curid=49859746", "title": "Humanistic historiography", "text": "Humanistic historiography\n\nHumanistic historiography is a method in historiography. This method is based on the principles of humanism. The new style of (humanistic) historiography was established by the Florentine History of Bruni (published from 1416 to 1449), and certain characteristics of the model still determined the treatment of political history in Machiavelli's \"Istorie Firoentine\", as well as his delimitation of political subject matter at large.\n\nLet us briefly enumerate these characteristics. The humanists used Livy as their model. This choice had certain consequences insofar as the treatment of history had to concentrate on such exciting events as wars and revolutions to the exclusion of the permanent factors and the long-range developments that determine the texture of history.\n\nMoreover, in the interest of rhetorical and dramatic effectiveness, the individual had to become the center of action to such a degree that again the permanent determinants that in fact leave not so much room for heroic freedom were obscured.\n\nThe Roman model had, furthermore, the effect of a radical secularization of political problems. The humanistic concentration on the history of the republic in the Roman manner entailed the break with the Christian view of history. The rigidly closed stream of secular state history did not admit a divine Providence governing a universal history. Such problems as the translatio imperii and the speculation of the four world monarchies disappeared without a word of discussion.\n\nIn the eighteenth century, when Voltaire started his secularization of history, the polemic against the Christian position of Bossuet was of absorbing interest. The humanists of the fifteenth century ignored the Christian problem as if it did not exist.\n\n"}
{"id": "27315806", "url": "https://en.wikipedia.org/wiki?curid=27315806", "title": "Illuminating Hadrian's Wall", "text": "Illuminating Hadrian's Wall\n\nIlluminating Hadrian's Wall was a public event on Hadrian's Wall which took place 13 March 2010 and saw the route of the wall lit with beacons. The event was organised by Hadrian's Wall Heritage Ltd. and coincided with the 1600th anniversary of the end of Roman rule in Britain. \n\nThe 84 mile route was lit by 500 gas beacons, flares and torches at 250m intervals, with the assistance of more than 1000 volunteers. Approximately 120 landowners allowed access onto their lands for the event to take place.\n\nThe project was led by Hadrian’s Wall Heritage Ltd and supported by several other groups, which form part of North East England’s programme of festivals and events. The event marked the beginning of British Tourism week as supported by the Carlisle Tourism Partnership and the 500 points of light were filmed by a helicopter at dusk.\n"}
{"id": "32979455", "url": "https://en.wikipedia.org/wiki?curid=32979455", "title": "International Society for the History of Medicine", "text": "International Society for the History of Medicine\n\nThe International Society for the History of Medicine is a non profit international society devoted to the academic study of the history of medicine, including the organization of international congresses.\n\nThe society is present in 50 countries, holds delegations in 38 countries, and has about 800 members. It also includes national societies in Argentina, Belgium, Chile, Finland, France, Greece, Mexico, Morocco, Romania, Turkey, and the United Kingdom. Membership is open to both physicians and historians.\n\nThe society holds a biennial International Congress, and, beginning in 2001, an international meeting in the years the main conference is not held.See list Communications to the international congresses are peer reviewed.\n\nThe ISHM publishes twice a year \"Vesalius\", subtitled \"Acta Internationalia Historiae Medicinae\", an academic journal publishing some abstracts from its International Congresses and International Meetings for the History of Medicine, and some other scientific communications.\n\n"}
{"id": "10089791", "url": "https://en.wikipedia.org/wiki?curid=10089791", "title": "John Lyman Book Awards", "text": "John Lyman Book Awards\n\nThe John Lyman Book Awards are given annually by the North American Society for Oceanic History to recognise excellence in published books making a major contribution to the study and understanding of maritime and naval history. They are named after Professor John Lyman of the University of North Carolina.\n\nThe awards are presented in six categories:\n\n\n\n"}
{"id": "39845988", "url": "https://en.wikipedia.org/wiki?curid=39845988", "title": "Knowledge society", "text": "Knowledge society\n\nA knowledge society generates, shares and makes available to all members of the society knowledge that may be used to improve the human condition. A knowledge society differs from an information society in that the former serves to transform information into resources that allow society to take effective action while the latter only creates and disseminates the raw data. The capacity to gather and analyze information has existed throughout human history. However, the idea of the present-day knowledge society is based on the vast increase in data creation and information dissemination that results from the innovation of information technologies. The UNESCO World Report addresses the definition, content and future of knowledge societies.\n\nThe growth of Information and communication technology (ICT) has significantly increased the world’s capacity for creation of raw data and the speed at which it is produced. The advent of the Internet delivered unheard-of quantities of information to people. The evolution of the internet from Web 1.0 to Web 2.0 offered individuals tools to connect with each other worldwide as well as become content users and producers. Innovation in digital technologies and mobile devices offers individuals a means to connect anywhere anytime where digital technologies are accessible. Tools of ICT have the potential to transform education, training, employment and access to life-sustaining resources for all members of society.\nHowever, this capacity for individuals to produce and use data on a global scale does not necessarily result in knowledge creation. Contemporary media delivers seemingly endless amounts of information and yet, the information alone does not create knowledge. For knowledge creation to take place, reflection is required to create awareness, meaning and understanding. The improvement of human circumstances requires critical analysis of information to develop the knowledge that assists humankind. Absent reflection and critical thinking, information can actually become \"non-knowledge\", that which is false or inaccurate. The anticipated Semantic Web 3.0 and Ubiquitous Web 4.0 will move both information and knowledge creation forward in their capacities to use intelligence to digitally create meaning independent of user-driven ICT.\n\nThe social theory of a knowledge society explains how knowledge is fundamental to the politics, economics, and culture of modern society. Associated ideas include the knowledge economy created by economists and the learning society created by educators. Knowledge is a commodity to be traded for economic prosperity. In a knowledge society, individuals, communities, and organizations produce knowledge-intensive work. Peter Drucker viewed knowledge as a key economic resource and coined the term knowledge worker in 1969. Fast forward to the present day, and in this knowledge-intensive environment, knowledge begets knowledge, new competencies develop, and the result is innovation. \nA knowledge society promotes human rights and offers equal, inclusive, and universal access to all knowledge creation. The UNESCO World Report establishes four principles that are essential for development of an equitable knowledge society:\n\nHowever, they acknowledge that the digital divide is an obstacle to achievement of genuine knowledge societies. Access to the internet is available to 39 percent of the world’s population. This statistic represents growth as well as a continued gap. Among the many challenges that contribute to a global digital divide are issues regarding economic resources, geography, age, gender, language, education, social and cultural background, employment and disabilities.\n\nTo reduce the span of the digital divide, leaders and policymakers worldwide must first develop and understanding of knowledge societies and second, create and deploy initiatives that will universally benefit all populations. The public expects politicians and public institutions to act rationally and rely on relevant knowledge for decision-making. Yet, in many cases, there are no definitive answers for some of the issues that impact humankind. Science is no longer viewed as the provider of unquestionable knowledge and sometimes raises more uncertainty in its search for knowledge. The very advancement of knowledge creates the existence of increased ignorance or non-knowledge. This means that public policy must learn to manage doubt, probability, risk and uncertainty while making the best decisions possible.\n\nTo confront the uncertainty that comes from an increase in both knowledge and the resulting lack of knowledge, members of a society disagree and make decisions using justification and observation of consequences. Public policy may operate with the intent to prevent the worst possible outcome versus find the perfect solution. Democratization of expert knowledge occurs when a knowledge society produces and relies on more experts. Expert knowledge is no longer exclusive to certain individuals, professional or organizations. If in a knowledge society, knowledge is a public good to which all people have access, any individual may also serve as a creator of knowledge and receive credit as an expert. Since politicians rely on expert knowledge for decision making, the layperson who may lack specialized knowledge might hold a view that serves as expertise to the political process.\n\nAs technologies are deployed to improve global information access, the role of education will continue to grow and change. Education is viewed as a basic human right. For a society where reading and counting are a requisite for daily living, skills in reading, writing, and basic arithmetic are critical for future learning. However, in a knowledge society, education is not restricted to school. The advent of ICT allows learners to seek information and develop knowledge at any time and any place where access is available and unrestricted. In these circumstances, the skill of learning to learn is one of the most important tools to help people acquire formal and informal education. In a knowledge society supported by ICT, the ability to locate, classify and sort information is essential. Equipped with this skill, the use of ICT becomes an active versus a passive endeavor and integral to literacy and lifelong learning.\n\nOne marker of a knowledge society is continuous innovation that demands lifelong learning, knowledge development, and knowledge sharing. The institution of education will need to become responsive to changing demands. Education professionals will need to learn along with everyone else, and as leaders of changing designs in learning, they will serve as a bridge between technology and teaching. The ability to individually reflect on personal learning requirements and seek knowledge in whatever method is appropriate characterizes lifelong learning. One model that supports this type of learning is the W. Edwards Deming Plan-do-check-act cycle that promotes continuous improvement. Educational professionals will need to prepare learners to be accountable for their own lifelong learning.\n\n"}
{"id": "10878467", "url": "https://en.wikipedia.org/wiki?curid=10878467", "title": "Law of social cycle", "text": "Law of social cycle\n\nThe law of social cycle is a social cycle theory developed by Prabhat Ranjan Sarkar. It is based on the theory of human historical motivity based on \"the ancient spiritual ideas of the Vedas\". The theory was developed in the 1950s and expanded by Ravi Batra since the 1970s, Johan Galtung and Sohail Inayatullah since the 1990s and others.\n\nThe theory first appeared in Sarkar's book \"Human Society\", Vol. 2 in the late 1950s and has since been reproduced and expanded on in many books. The theory has probably received the widest publication in the West in the many books of Ravi Batra, a disciple of Sarkar, notably \"The Downfall of Capitalism and Communism, a New Study of History\", \"The Great Depression of 1990\" and \"The New Golden Age: The Coming Revolution against Political Corruption and Economic Chaos\". Johan Galtung and Sohail Inayatullah have also written about Sarkars' social cycle theory in the book \"Macrohistory and Macrohistorians\". The theory owes to the work of Sri Aurobindo, \"The Human Cycle\", which was published in 1949 but originally written in 1916–1918 under the title \"The Psychology of Social Development\".\n\nThe law of social cycle is a theory of Varna, arising out of the Indian episteme (Inayatullah, 2002). This law states that while people in any society are all relatively similar, they have generally the same goals, desires and ambitions but differ in the way they go about achieving their goals. An individual's specific methods for achieving success depend on his physical and psychological makeup. Essentially, there are four different psychological types of people, warriors, intellectuals, acquisitors and labourers, who find basic fulfillment in four different kinds of ways.\n\nWarriors, or \"Kshatriya\" in Sanskrit, have strong bodies, vigorous physical energy and a sharp intellect. Warriors tend to develop the skills that take advantage of their inherent gifts of stamina, courage and vigor. Their mentality is one that is not averse to taking physical risks. Examples of people in our society with the warrior mentality include policemen, firemen, soldiers, professional athletes, skilled carpenters, and tradesmen. They all achieve success through their physical skills and a deep understanding of their profession.\n\nIntellectuals, or \"Vipra\", have a more developed intellect than the warriors, but generally lack the physical strength and vigor. Intellectuals are happiest when they try to achieve success by developing and expressing their intellectual skills and talents. Teachers, writers, professors, scientists, artists, musicians, philosophers, doctors and lawyers, and above all, priests, are professions intellectuals tend to pursue.\n\nAcquisitors, or \"Vaishya\", have a penchant for acquiring money. If money can be made the acquisitors will find a way to make it. They are not considered as bright as the intellectuals, nor as strong as the warriors, but they are keen when it comes to making and accumulating money and material possessions. Such people are the traders, businessmen, managers, entrepreneurs, bankers, brokers, and landlords in our society.\n\nLaborers, or \"Shudra\", are altogether different from the first three groups. Laborers lack the energy and vigor of the warriors, the keen intellect of the intellectuals, or the ambition and drive of the accumulators. In spite of the fact that their contribution to society is profound – in fact, society could not function without them – the other groups generally look down upon and tend to exploit them. The laborers are the peasants, serfs, clerks, short order cooks, waiters, janitors, doormen, cabdrivers, garbage collectors, truck drivers, night watchmen and factory workers who keep society running smoothly by working diligently and without complaint.\n\nGroups of each type of people make up the social classes in society. Sarkar simplifies society into four classes, divided by inherent traits:\n\nAccording to Batra (1978), the West is currently in the age of acquisitors, also known as Capitalism. This age succeeded the 'age of intellectuals', which gave birth to the Enlightenment and the British parliamentary system. Before that the West went through the 'age of warriors' and the age of discovery. Feudalism, an earlier 'age of acquisitors', reigned before that. It had replaced the 'age of intellectuals', with restrictions on religious thought and also gave birth to the Renaissance period. Before that, Rome ruled the West under the aegis of warriors.\n\nTo Sarkar, each age would run its course, with the social motivity going too far, causing much grief to the majority of people (Sarkar, 1967). The situation could go on unchecked for a long time, before things got so bad that a spontaneous revolution and overthrow of the system took place. In fact, as this was the reason for social change, it was clear that no single class of people could remain dominant indefinitely. Social power was destined to pass from one class to next in the prescribed order, or cycle. The 'age of warriors', which brings strict order to society and a return to fundamental values, essentially leads to excessive focus on strong man rule and warfare. It is followed by an 'age of intellectuals', which bring a sense of liberation in the mental sphere but soon replace that freedom with the yoke of newer ideas. Over time this age merges into an 'age of acquisitors', which brings progress in the material sphere, but this is soon replaced by increased physical and mental exploitation. The Servile Wars spelled the doom of the Roman Republic. Labour conflict could be the undoing of Capitalism, according to this theory. And so the cycle moves on its endless round, until the civilisation ceases to exist or is taken over by a superior or more powerful civilisation.\n\nSarkar's essential view on the implications of each age was to develop a way to avoid the dynamic of exploitation, when the social motivity of one class goes unchecked and too far (Sarkar, 1967). In such cases, it falls on moralists to accelerate the movement to the next age to shorten the exploitative phase of each age.\n\nIn Sarkar's vision social progress is seen to be established on the basis of a new vision of human progress. Sarkar's theory focuses on four basic ages of warriors, intellectuals and acquisitors, as well as a brief age of labourers. During such ages humanity has faced an eternal struggle with each epoch deteriorating into a harmful exploitative phase. Sarkar devises an exit strategy from such a development, based on the role of enlightened moralists, the Sadvipras. It is their role, based on their self-less virtues and ideation on the divine, to apply energy and accelerate social progress when the evolutionary process is caught up in a stasis whereby the ruling class has abandoned its original virtues and through an intense focus on their social agenda inflict misery on the other sections of society.\n\nFor this, Sarkar trained nuns and monks of his \"socio-spiritual movement\" Ananda Marga and developed the socio-economic Progressive Utilization Theory (PROUT).\n\n\n"}
{"id": "13786015", "url": "https://en.wikipedia.org/wiki?curid=13786015", "title": "Legacy of the Indo-Greeks", "text": "Legacy of the Indo-Greeks\n\nThe legacy of the Indo-Greeks starts with the formal end of the Indo-Greek Kingdom from the 1st century CE, as the Greek communities of central Asia and northwestern India lived under the control of the Kushan branch of the Yuezhi, apart from a short-lived invasion of the Indo-Parthian Kingdom. The Kushans founded the Kushan Empire, which was to prosper for several centuries. In the south, the Greeks were under the rule of the Western Kshatrapas.\n\nIt is unclear how much longer the Greeks managed to maintain a distinct presence in the Indian sub-continent.\n\nThe 36 Indo-Greek kings known through epigraphy or through their coins belong to the period between 180 BCE to 10–20 CE. There are a few hints of a later Indo-Greek political presence in the Indian subcontinent.\n\nTheodamas, known from an inscription on a signet, may have been an Indo-Greek ruler in the Bajaur area in the 1st century CE.\n\nIn the 3rd century, the Scythian Western Satraps seem to have relied on Greeks, such as Yavanesvara (\"Lord of the Greeks\"), who may have been organized in more or less independent \"poleis\".\n\nSome sort of Greek political organization is thought to have existed in the first half of the 4th century after the rule of the Satavahanas. This is also suggested by the Puranas (the Matsya Purana, the Vayu Purana, the Brahmanda Purana, the Vishnu Purana, the Bhagavata Purana) which give a list of the dynasties who ruled following the decline of the Satavahanas: this list includes 8 Yavana kings, thought to be some dynasty of Greek descent, although they are not otherwise known. According to one theory however, the Southern Indian dynasty of the Chalukyas was named after \"Seleukia\" (the Seleucids), their conflict with the Pallava of Kanchi being but a continuation of the conflict between ancient Seleukia and \"Parthians\", the proposed ancestors of Pallavas. Dr. Lewis's theory, based on the mere similarity of names, has not found acceptance at all because the Pallavas were in constant conflict with the Kadambas, prior to the rise of Chalukyas.\n\nSome Greek cities seem to have remained intact under Parthian rule: Isidorus of Charax in his 1st century CE \"Parthian stations\" itinerary described \"Alexandropolis, the metropolis of Arachosia\" as being Greek:\n\nAlso, the city of Alexandria Bucephalus on the Jhelum River is still mentioned in the 1st century Periplus of the Erythraean Sea, as well as in the Roman Peutinger Table.\n\nGreek mercenary soldiers from northwestern India are mentioned in the accounts of the Pandyan Kingdom in Madurai, and described in admiring terms: \"The valiant-eyed Yavanas, whose bodies were strong and of terrible aspect\".\n\nAt the beginning of the 2nd century CE, the Central India Satavahana king Gautamiputra Satakarni (r. 106–130 CE) was described as the \"Destroyer of Sakas (\"Western Kshatrapas\"), Yavanas (\"Indo-Greeks\") and Pahlavas (\"Indo-Parthians\")\" in his inscriptions, suggesting a continued presence of the Indo-Greeks until that time.\nAround 200 CE, the Manu Smriti describes the downfall of the Yavanas, as well as many others:\n\n\"43. But in consequence of the omission of the sacred rites, and of their not consulting Brahmanas, the following tribes of Kshatriyas have gradually sunk in this world to the condition of Shudras;\"\n\"44. (Viz.) the Paundrakas, the Chodas, the Dravidas, the Kambojas, the Yavanas, the Shakas, the Paradas, the Pahlavas, the Chinas, the Kiratas, the Daradas and the Khashas.\" (Manusmritti, X.43–44)\n\nThere are important references to the warring Mleccha hordes of the Yavanas, Sakas, Kambojas, Pahlavas, etc. in the Bala Kanda of the Valmiki Ramayana.\n\nIndologists like Dr H. C. Raychadhury, Dr B. C. Law, Satya Shrava and others see, in these verses, the clear glimpses of the struggles of the Hindus with the mixed invading hordes of the barbaric Sakas, Yavanas, Pahlavas, Kambojas, etc. from north-west. The time frame for these struggles is the 2nd century BCE downwards. Dr Raychadhury fixes the date of the present version of the Valmiki Ramayana around/after the 2nd century CE.\n\nThe invading hordes of the Sakas, Kambojas, Yavanas, Pahlavas, Abhiras, etc. from the north-west had entered Punjab, \"United Province\", Sindhu, Rajasthan and Gujarat in large numbers, wrested political control of northern India from the Indo-Aryans and had established their respective kingdoms and principalities in the land of the Indo-Aryans.\n\nThere is also a distinct prophetic statement in the Mahabharata which says that the Mlechha (Barbaric) kings of the Sakas, Yavanas, Kambojas, Bahlikas, Abhiras, etc. will rule unrighteously in Kaliyuga.\n\nAccording to Dr H. C. Ray Chaudhury, \"this is too clear a statement to be ignored\" or explained away.\n\nThis statement, couched in the form of prophecy in true puranic style, alludes to a historical situation (2nd and 1st century BC downwards) which followed the collapse of Maurya and Shunga dynasties in North India.\nThis chaotic situation of Aryan India is said to have ended with the destruction of these Mlechcha Saka, Kamboja, Yavana and Parsika hordes by king Vikramaditya of Ujjaini (c. 60 BC) as is related by Brihat-Katha-Manjari of the Kashmiri Pandit Kshemendra and Kathasaritsagara of Somadeva, and the establishment of the \"Vikrama era\".\n\nA few common Greek words were adopted in Sanskrit, such as words related to writing and warfare:\nThe \"Avaca\" Kharosthi inscription, found on a Buddhist relic casket, indicates that the old Greek military title of \"strategos\" (\"commander\") had apparently endured the Indo-Scythian invasion and was being used by the Apracarajas of Bajaur during the 1st century CE (the inscription mentions the dedication date of the casket as \"the year 63 of the late Maharaja Aya\", Aya being the Indo-Scythian ruler Azes I, who started the Vikrama era in 58 BCE, therefore suggesting a date around 5 CE). The dedication mentions \"vaga stratego puyaite viyayamitro ya\" i.e. \"The Lord Commander (Stratego) Viyayamitra is honored too\".\n\nThe Greek philosopher Apollonius of Tyana is related by Philostratus in \"Life of Apollonius Tyana\" to have visited India, and specifically the city of Taxila around 46 CE. He describes constructions of the Greek type,\nprobably referring to Sirkap, and explains that the Indo-Parthian king of Taxila, named Phraotes, received a Greek education at the court of his father and spoke Greek fluently:\n\nLastly, from the Rabatak inscription we have the following information, tending to indicate that Greek was still in official use until the time of Kanishka (c. 120 CE):\n\nA Greek \"Yona\" calendar era seems to have been in use in Northwestern Indian for several centuries following the foundation of the Indo-Greek kingdom. A recently discovered inscription in Kharoshthi on a Buddhist reliquary gives a relationship between several eras of the period:\n\nAs the Azes era is usually considered identical to the Vikrama era starting in 58 BCE, the Yona era would correspond to 186 BCE, which falls in the reign of Demetrius I, although dates ranging from 186 to 150 BCE are still debated. The inscription would date to c. 15 CE.\n\nA second inscription, called the Maghera inscription, found in the Mathura district, is dated to the year 116 of the \"Era of the Greeks\" (\"Yavanarajyasya sodasuttare varsasate 100 10 6), which would correspond to 70 BCE.\n\nThe names of the months belonging to the Ancient Macedonian calendar remained in use under the Indo-Scythians and the Kushans until around the 2nd century CE. For example the Indo-Scythian Taxila copper plate inscription uses the Macedonian month of \"Panemos\". Later, the Dast-i Nawur inscription mentioning the Kushan king Vima Kadphises (reigned circa 90–100 CE) is dated to the 279th year (possibly in the Yona era, which would make it 93 CE, but alternatively in \"the Great Arya era\" mentioned by Kanishka in the Rabatak inscription, possibly an era started by Mithridates I which would give 108 CE), and the 15th day of the month of \"Gorpaios\" (Γορπιαίος), which is the 11th month of the Macedonian calendar, corresponding to the moon of August.\n\nOne of the earliest Indian writings on astronomy and astrology (although not the earliest, as the \"Vedanga Jyotisha\" is dated to around 135 BCE), titled the \"Yavanajataka\" or \"The Saying of the Greeks\", is a translation from Greek to Sanskrit made by \"Yavanesvara\" (\"Lord of the Greeks\") in 149–150 CE under the rule of the Western Kshatrapa king Rudrakarman I. The Yavanajataka contains instructions on calculating astrological charts (horoscopes) from the time and place of one's birth. Astrology flourished in the Hellenistic world (particularly Alexandria) and the Yavanajataka reflects astrological techniques developed in the Greek-speaking world. Various astronomical and mathematical methods, such as the calculation of the 'horoskopos' (the zodiac sign on the eastern horizon), were used in the service of astrology.\n\nAnother set of treatises, the Paulisa Siddhanta and the Romaka Siddhantas, are attributed to later Greco-Roman influence in India. The Paulisa Siddhanta has been tentatively identified with the works of Paulus Alexandrinus, who wrote a well-known astrological hand-book.\n\nIndian astronomy is widely acknowledged to be influenced by the Alexandrian school, and its technical nomenclature is essentially Greek. Several other Indian texts show appreciation for the scientific knowledge of the \"Yavana\" Greeks.\n\nOverall, the coinage of the Indo-Greeks remained extremely influential for several centuries throughout the Indian subcontinent:\n\n\nThe latest use of the Greek script on coins corresponds to the rule of the Turkish Shahi of Kabul, around 850.\n\nLimited population genetics studies have been made on genetic markers such as Y-DNA in the populations of the Indian subcontinent, to estimate the contribution of the Greeks to the genetic pool. Although some of the markers which are present in a large proportion of Greeks today have not been found, the Greek genetic contribution to the Punjab region has been estimated to be up to 15%:\n\nSome pockets of Greek populations probably remained for some time, and to this day, some communities in the Hindu Kush claim to be descendants of the Greeks, such as the Kalash and Hunza in Pakistan, and the neighbouring Nuristani in Afghanistan. \n\nAlthough the political power of the Greeks had waned in the north, mainly due to nomadic invasions, trade relations between the Mediterranean and India continued for several centuries. The trade started by Eudoxus of Cyzicus in 130 BCE kept on increasing, and according to Strabo (II.5.12), by the time of Augustus, up to 120 ships were setting sail every year from Myos Hormos to India. So much gold was used for this trade, and apparently recycled by the Kushans for their own coinage, that Pliny (NH VI.101) complained about the drain of specie to India. In practice, this trade was still handled by Greek middlemen, as all the recorded names of ship captains for the period are Greek.\n\nAlso various exchanges are recorded between India and Rome during this period. In particular, embassies from India, as well as several missions from \"Sramanas\" to the Roman emperors are known (see Buddhism and the Roman world). Finally, Roman goods and works of art found their way to the Kushans, as archaeological finds in Begram have confirmed.\n\nThe \"Kanishka casket\", dated to the first year of Kanishka's reign in 127 CE, was signed by a Greek artist named \"Agesilas\", who oversaw work at Kanishka's stupas (caitya), confirming the direct involvement of Greeks with Buddhist realizations at such a late date.\n\nGreek representations and artistic styles, with some possible admixtures from the Roman world, continued to maintain a strong identity down to the 3rd–4th century, as indicated by the archaeological remains of such sites as Hadda in eastern Afghanistan.\n\nThe Greco-Buddhist image of the Buddha was transmitted progressively through Central Asia and China until it reached Japan in the 6th century.\n\nNumerous elements of Greek mythology and iconography, introduced in northwestern India by the Indo-Greeks through their coinage at the very least, were then adopted throughout Asia within a Buddhist context, especially along the Silk Road. The Japanese Buddhist deity Shukongoshin, one of the wrath-filled protector deities of Buddhist temples in Japan, is an interesting case of transmission of the image of the famous Greek god Herakles to the Far-East along the Silk Road. The image of Herakles was introduced in India with the coinage of Demetrius and several of his successors, used in Greco-Buddhist art to represent Vajrapani the protector of the Buddha, and was then used in Central Asia, China and Japan to depict the protector gods of Buddhist temples.\n\nThe impact of the Indo-Greeks on Indian thought and religion is unknown, although many influences have been suggested. Scholars believe that Mahayana Buddhism as a distinct movement began around the 1st century BCE in the North-western Indian subcontinent, corresponding to the time and place of Indo-Greek florescence. Intense multi-cultural influences have indeed been suggested in the appearance of Mahayana. According to Richard Foltz, \"Key formative influences on the early development of the Mahayana and Pure Land movements, which became so much part of East Asian civilization, are to be sought in Buddhism's earlier encounters along the Silk Road\". As Mahayana Buddhism emerged, it received \"influences from popular Hindu devotional cults (bhakti), Persian and Greco-Roman theologies which filtered into India from the northwest\". Many of the early Mahayana theories of reality and knowledge can be related to Greek philosophical schools of thought: Mahayana Buddhism has been described as \"the form of Buddhism which (regardless of how Hinduized its later forms became) seems to have originated in the Greco-Buddhist communities of India, through a conflation of the Greek Democritean-Sophistic-Skeptical tradition with the rudimentary and unformalized empirical and skeptical elements already present in early Buddhism\".\nHowever, this view can hardly explain the origin of the bodhisattva ideal, already delineated in the Aagamas, which also already contained a well-developed theory of selflessness (anaatman) and emptiness (shunyaata), none of these essential Mahayaana tenets being traceable to Greek roots.\n\n"}
{"id": "18687", "url": "https://en.wikipedia.org/wiki?curid=18687", "title": "Leninism", "text": "Leninism\n\nLeninism is the political theory for the organisation of a revolutionary vanguard party and the achievement of a dictatorship of the proletariat as political prelude to the establishment of socialism.\n\nDeveloped by and named for the Russian revolutionary Vladimir Lenin, Leninism comprises socialist political and economic theories, developed from Marxism and Lenin's interpretations of Marxist theories, for practical application to the socio-political conditions of the Russian Empire of the early 20th century. Functionally, the Leninist vanguard party was to provide the working class with the political consciousness (education and organisation) and revolutionary leadership necessary to depose capitalism in Imperial Russia. After the October Revolution of 1917, Leninism was the dominant version of Marxism in Russia and in establishing soviet democracy the Bolshevik régime suppressed socialists who opposed the revolution, such as the Mensheviks and factions of the Socialist Revolutionary Party. The Russian Civil War (1917–1922) thus included left-wing uprisings against the Bolsheviks (1918–1924) that were suppressed in the Russian Socialist Federative Soviet Republic (RSFSR) before incorporation to the Union of Soviet Socialist Republics (USSR) in 1922.\n\nLeninism was composed as and for revolutionary praxis and originally was neither a rigorously proper philosophy nor a discrete political theory. After the Russian Revolution and in \"History and Class Consciousness: Studies in Marxist Dialectics\" (1923), György Lukács developed and organised Lenin's pragmatic revolutionary practices and ideology into the formal philosophy of vanguard-party revolution (Leninism). As a political-science term, \"Leninism\" entered common usage in 1922 after infirmity ended Lenin's participation in governing the Russian Communist Party. At the Fifth Congress of the Communist International in July 1924, Grigory Zinoviev popularized the term \"Leninism\" to denote \"vanguard-party revolution\". From 1917 to 1922, Leninism was the Russian application of Marxist economics and political philosophy, effected and realised by the Bolsheviks, the vanguard party who led the fight for the political independence of the working class. In the 1925–1929 period, Joseph Stalin established Leninism as the official and only legitimate form of Marxism in Russia by amalgamating the political philosophies as Marxism–Leninism, which then became the state ideology of the Soviet Union.\n\nIn the 19th century, \"The Communist Manifesto\" (1848), by Karl Marx and Friedrich Engels, called for the international political unification of the European working classes in order to achieve a communist revolution and proposed that because the socio-economic organization of communism was of a higher form than that of capitalism, a workers' revolution would first occur in the economically advanced, industrialized countries. Marxist social democracy was strongest in Germany throughout the 19th century and the Social Democratic Party of Germany inspired Lenin and other Russian Marxists.\n\nIn the early 20th century, the socio-economic backwardness of Imperial Russia (1721–1917)—uneven and combined economic development—facilitated rapid and intensive industrialization, which produced a united, working-class proletariat in a predominantly rural, agrarian, peasant society. Moreover, because the industrialization was financed mostly with foreign capital, Imperial Russia did not possess a revolutionary bourgeoisie with political and economic influence upon the workers and the peasants (as occurred in the French Revolution, 1789). Although Russia's political economy principally was agrarian and semi-feudal, the task of democratic revolution therefore fell to the urban, industrial working class as the only social class capable of effecting land reform and democratization, in view that the Russian propertied classes would attempt to suppress any revolution, in town and country.\n\nIn April 1917, Lenin published the April Theses, the political strategy of the October Revolution (7–8 November 1917), which proposed that the Russian revolution was not an isolated national event, but a fundamentally international event—the first world socialist revolution. Thus Lenin's practical application of Marxism and working-class urban revolution to the social, political and economic conditions of the agrarian peasant society that was Tsarist Russia sparked the \"revolutionary nationalism of the poor\" to depose the absolute monarchy of the three-hundred-year Romanov dynasty (1613–1917).\n\nIn the course of developing the Russian application of Marxism, the pamphlet \"Imperialism, the Highest Stage of Capitalism\" (1916) presented Lenin's analysis of an economic development predicted by Karl Marx, namely that capitalism would become a global financial system, wherein advanced industrial countries export financial capital to their colonial countries, to finance the exploitation of their natural resources and the labour of the native populations. Such superexploitation of the poor (undeveloped) countries allows the wealthy (developed) countries to maintain some homeland workers politically content with a slightly higher standard of living and so ensure peaceful labour–capital relations in the capitalist homeland (see labour aristocracy and globalization). Hence, a proletarian revolution of workers and peasants could not occur in the developed capitalist countries while the imperialist global-finance system remained intact; thus an underdeveloped country would feature the first proletarian revolution; and in the early 20th century, Imperial Russia was the politically weakest country in the capitalist global-finance system.\n\nIn the \"United States of Europe Slogan\" (1915), Lenin said: \n\nIn \"\" (1920), Lenin said: \n\nIn Chapter II: \"Proletarians and Communists\" of \"The Communist Manifesto\" (1848), Marx and Engels presented the idea of the vanguard party as solely qualified to politically lead the proletariat in revolution: \n\nHence, the purpose of the Leninist vanguard party is to establish a democratic dictatorship of the proletariat; supported by the working class, the vanguard party would lead the revolution to depose the incumbent Tsarist government; and then transfer power of government to the working class, which change of ruling class—from bourgeoisie to proletariat—makes possible the full development of socialism. In the pamphlet \"What Is To Be Done?\" (1902), Lenin proposed that a revolutionary vanguard party, mostly recruited from the working class, should lead the political campaign because it was the only way that the proletariat could successfully achieve a revolution; unlike the economist campaign of trade-union-struggle advocated by other socialist political parties; and later by the anarcho-syndicalists. Like Marx, Lenin distinguished between the aspects of a revolution, the \"economic campaign\" (labour strikes for increased wages and work concessions), which featured diffused plural leadership; and the \"political campaign\" (socialist changes to society), which required the decisive revolutionary leadership of the Bolshevik vanguard party.\n\nAs epitomised in the slogan \"Freedom in Discussion, Unity in Action\", Lenin followed the example of the First International (IWA, International Workingmen's Association, 1864–1876) and organised the Bolsheviks as a democratically centralised vanguard party, wherein free political-speech was recognised legitimate until policy consensus. Afterwards, every member of the party would be expected to uphold the official policy established in consensus. In the pamphlet \"Freedom to Criticise and Unity of Action\" (1905), Lenin said: \n\nFull, inner-party democratic debate was Bolshevik Party practice under Lenin, even after the banning of party factions in 1921. Although a guiding influence in policy, Lenin did not exercise absolute power and continually debated and discussed to have his point of view accepted. Under Stalin, the inner-party practice of democratic free debate did not continue after the death of Lenin in 1924.\n\nBefore the Revolution, despite supporting political reform (including Bolsheviks elected to the Duma, when opportune), Lenin proposed that capitalism could ultimately only be overthrown with revolution, not with gradual reforms—from within (Fabianism) and from without (social democracy)—which would fail because the ruling capitalist social class, who hold economic power (the means of production), determine the nature of political power in a bourgeois society. As epitomised in the slogan \"For a Democratic Dictatorship of the Proletariat and Peasantry\", a revolution in the underdeveloped Russian Empire required an allied proletariat of town and country (urban workers and peasants) because the urban workers would be too few to successfully assume power in the cities on their own. Moreover, owing to the middle-class aspirations of much of the peasantry, Leon Trotsky proposed that the proletariat should lead the revolution as the only way for it to be truly socialist and democratic. Although Lenin initially disagreed with Trotsky's formulation, he adopted it before the Russian Revolution in October 1917.\n\nIn the Russian socialist society, government by direct democracy was effected by elected soviets (workers' councils), which \"soviet government\" form Lenin described as the manifestation of the Marxist \"democratic dictatorship of the proletariat\". As political organisations, the soviets would comprise representatives of factory workers' and trade union committees, but would exclude capitalists as a social class in order to ensure the establishment of a proletarian government, by and for the working class and the peasants. About the political disenfranchisement of the Russian capitalist social classes, Lenin said that \"depriving the exploiters of the franchise is a purely Russian question, and not a question of the dictatorship of the proletariat, in general. [...] In which countries [...] democracy for the exploiters will be, in one or another form, restricted [...] is a question of the specific national features of this or that capitalism\". In chapter five of \"The State and Revolution\" (1917), Lenin describes the dictatorship of the proletariat as such: \n\nAbout democracy, Lenin further stated the following in \"The State and Revolution\": \n\nSoviet constitutionalism was the collective government form of the Russian dictatorship of the proletariat, the opposite of the government form of the dictatorship of capital (privately owned means of production) practised in bourgeois democracies. In the soviet political system, the (Leninist) vanguard party would be one of many political parties competing for elected power. Nevertheless, the circumstances of the Red vs. White Russian Civil War and terrorism by the opposing political parties and in aid of the White Armies' counter-revolution led to the Bolshevik government banning other parties, thus the vanguard party became the sole, legal political party in Russia. Lenin did not regard such political suppression as philosophically inherent to the dictatorship of the proletariat, yet the Stalinists retrospectively claimed that such factional suppression was original to Leninism.\n\nThe Soviet Union nationalised industry and established a foreign-trade monopoly to allow the productive co-ordination of the national economy and so prevent Russian national industries from competing against each other. To feed the populaces of town and country, Lenin instituted War Communism (1918–1921) as a necessary condition—adequate supplies of food and weapons—for fighting the Russian Civil War (1917–1923). Later in March 1921, he established the New Economic Policy (NEP, 1921–1929), which allowed measures of private commerce, internal free trade and replaced grain requisitions with an agricultural tax under the management of state banks. The purpose of the NEP was to resolve food-shortage riots among the peasantry and allowed measures of private enterprise, wherein the profit motive encouraged the peasants to harvest the crops required to feed the people of town and country; and to economically re-establish the urban working class, who had lost many men (workers) to the counter-revolutionary Civil War. With the NEP, the socialist nationalisation of the economy could then be developed to industrialise Russia, strengthen the working class and raise standards of living, thus the NEP would advance socialism against capitalism. Lenin regarded the appearance of new socialist states in the developed countries as necessary to the strengthening Russia's economy and the eventual development of socialism. In that, he was encouraged by the German Revolution of 1918–1919, the Italian insurrection and general strikes of 1920 and industrial unrest in Britain, France and the United States.\n\nLenin recognized and accepted the existence of nationalism among oppressed peoples, advocated their national rights to self-determination and opposed the ethnic chauvinism of \"Greater Russia\" because such ethnocentrism was a cultural obstacle to establishing the proletarian dictatorship in the territories of the deposed Russian Empire (1721–1917). In \"The Right of Nations to Self-determination\" (1914), Lenin said: \n\nThe internationalist philosophies of Bolshevism and of Marxism are based upon class struggle transcending nationalism, ethnocentrism and religion, which are intellectual obstacles to class consciousness because the bourgeois ruling classes manipulated said cultural \"status quo\" to politically divide the proletarian working classes. To overcome the political barrier of nationalism, Lenin said it was necessary to acknowledge the existence of nationalism among oppressed peoples and to guarantee their national independence as the right of secession; and that based upon national self-determination, it was natural for socialist states to transcend nationalism and form a federation. In \"The Question of Nationalities, or \"Autonomisation\"\" (1923), Lenin said the following: \n\nThe role of the Marxist vanguard party was to politically educate the workers and peasants to dispel the societal false consciousness of religion and nationalism that constitute the cultural \"status quo\" taught by the bourgeoisie to the proletariat to facilitate their economic exploitation of peasant and worker. Influenced by Lenin, the Central Committee of the Bolshevik Party stated that the development of the socialist workers' culture should not be \"hamstrung from above\" and opposed the \"Proletkult\" (1917–1925) organisational control of the national culture.\n\nIn post-Revolutionary Russia, Stalinism (socialism in one country) and Trotskyism (permanent world revolution) were the principal philosophies of communism that claimed legitimate ideological descent from Leninism, thus within the Communist Party, each ideological faction denied the political legitimacy of the opposing faction.\n\nUntil shortly before his death, Lenin worked to counter the disproportionate political influence of Joseph Stalin in the Communist Party and in the bureaucracy of the Soviet government, partly because of abuses he had committed against the populace of Georgia and partly because the autocratic Stalin had accumulated administrative power disproportionate to his office of General Secretary of the Communist Party. The counter-action against Stalin aligned with Lenin's advocacy of the right of self-determination for the national and ethnic groups of the former Tsarist Empire, which was a key theoretic concept of Leninism. Lenin warned that Stalin has \"unlimited authority concentrated in his hands, and I am not sure whether he will always be capable of using that authority with sufficient caution\" and formed a factional bloc with Leon Trotsky to remove Stalin as the General Secretary of the Communist Party.\n\nTo that end followed proposals reducing the administrative powers of party posts in order to reduce bureaucratic influence upon the policies of the Communist Party. Lenin advised Trotsky to emphasize Stalin's recent bureaucratic alignment in such matters (e.g. undermining the anti-bureaucratic workers' and peasants' Inspection) and argued to depose Stalin as General Secretary. Despite advice to refuse \"any rotten compromise\", Trotsky did not heed Lenin's advice and General Secretary Stalin retained power over the Communist Party and the bureaucracy of the soviet government.\n\nAfter Lenin's death (21 January 1924), Trotsky ideologically battled the influence of Stalin, who formed ruling blocs within the Russian Communist Party (with Grigory Zinoviev and Lev Kamenev, then with Nikolai Bukharin and then by himself) and so determined soviet government policy from 1924 onwards. The ruling blocs continually denied Stalin's opponents the right to organise as an opposition faction within the party—thus the re-instatement of democratic centralism and free speech within the Communist Party were key arguments of Trotsky's Left Opposition and the later Joint Opposition.\nIn the course of instituting government policy, Stalin promoted the doctrine of socialism in one country (adopted 1925), wherein the Soviet Union would establish socialism upon Russia's economic foundations (and support socialist revolutions elsewhere). Conversely, Trotsky held that socialism in one country would economically constrain the industrial development of the Soviet Union and thus required assistance from the new socialist countries that had arisen in the developed world—which was essential for maintaining Soviet democracy—in 1924 much undermined by civil war and counter-revolution. Furthermore, Trotsky's theory of permanent revolution proposed that socialist revolutions in underdeveloped countries would go further towards dismantling feudal régimes and establish socialist democracies that would not pass through a capitalist stage of development and government. Hence, revolutionary workers should politically ally with peasant political organisations, but not with capitalist political parties. In contrast, Stalin and allies proposed that alliances with capitalist political parties were essential to realising a revolution where communists were too few. However, said Stalinist practice failed, especially in the Northern Expedition portion of the Chinese Revolution (1925–1927), wherein it resulted in the right-wing Kuomintang's massacre of the Chinese Communist Party. Despite the failure, Stalin's policy of mixed-ideology political alliances nonetheless became Comintern policy.\n\n\nUntil exiled from Russia in 1929, Trotsky helped develop and led the Left Opposition (and the later Joint Opposition) with members of the Workers' Opposition, the Decembrists and (later) the Zinovievists. Trotskyism ideologically predominated the political platform of the Left Opposition, which demanded the restoration of soviet democracy, the expansion of democratic centralism in the Communist Party, national industrialisation, international permanent revolution and socialist internationalism. The Trotskyist demands countered Stalin's political dominance of the Russian Communist Party, which was officially characterised by the \"cult of Lenin\", the rejection of permanent revolution and the doctrine of socialism in one country. The Stalinist economic policy vacillated between appeasing capitalist kulak interests in the countryside and destroying them. Initially, the Stalinists also rejected the national industrialisation of Russia, but then pursued it in full, sometimes brutally. In both cases, the Left Opposition denounced the regressive nature of the policy towards the kulak social class of wealthy peasants and the brutality of forced industrialisation. Trotsky described the vacillating Stalinist policy as a symptom of the undemocratic nature of a ruling bureaucracy.\n\nDuring the 1920s and the 1930s, Stalin fought and defeated the political influence of Trotsky and of the Trotskyists in Russia, by means of slander, antisemitism, programmed censorship, expulsions, exile (internal and external) and imprisonment. The anti–Trotsky campaign culminated in the executions (official and unofficial) of the Moscow Trials (1936–1938), which were part of the Great Purge of Old Bolsheviks (who had led the Revolution). Once established as ruler of the Soviet Union, General Secretary Stalin re-titled the official socialism in one country doctrine as Marxism–Leninism to establish ideologic continuity with Leninism whilst opponents continued calling it Stalinism.\n\nIn political practice, Leninism (vanguard-party revolution), despite its origin as communist revolutionary praxis, was adopted throughout the political spectrum.\n\nIn the event, the practical application of Maoism to the socio-economic conditions of Third World countries produced revolutionary vanguard parties, such as the Communist Party of Peru – Red Fatherland.\n\nIn \"The Nationalities Question in the Russian Revolution\" (1918), Marxist Rosa Luxemburg criticized the Bolsheviks and their policies for: the suppression of the All Russian Constituent Assembly (January 1918); the partitioning of the feudal estates to the peasant communes; and the right of self-determination of every national people of the Russias. Luxemburg said that the strategic (geopolitical) mistakes of the Bolsheviks would create great dangers for the Russian Revolution, such as the bureaucratisation that would arise to administrate the oversized country that was Bolshevik Russia. In defence of expedient revolutionary practise, Lenin criticised in \"\" (1920) the political and ideological complaints of the anti-Bolshevik critics who claimed ideologically correct stances that were to the political-left of Lenin.\n\nIn Marxist philosophy, the term \"left communism\" identifies a range of communist political perspectives that are left-wing among communists. Left communism criticizes the ideology that the Bolshevik Party practiced as a revolutionary vanguard at certain periods of their history. Ideologically, left communists present their perspective and approach as more authentically Marxist and more oriented to the proletariat than it is the Leninism of the Communist International at their first (1919) and second (1920) congresses. Proponents of left communism include Amadeo Bordiga, Herman Gorter, Antonie Pannekoek, Otto Rühle, Sylvia Pankhurst and Paul Mattick.\n\nHistorically, the Dutch–German communist left has been most critical of Lenin and Leninism. The Italian communist left instead still identified as Leninists; Bordiga said: \"All this work of demolishing opportunism and \"deviationism\" (Lenin: \"What Is To Be Done?\") is today the basis of party activity. The party follows revolutionary tradition and experiences in this work during these periods of revolutionary reflux and the proliferation of opportunist theories which had as their violent and inflexible opponents Marx, Engels, Lenin and the Italian Left.\". Paul Mattick continues in the council communist tradition which begun by the Dutch–German left and so is also critical of Leninism. Contemporary left-communist organisations, such as the Internationalist Communist Tendency and the International Communist Current, view Lenin as an important and influential theorist, but remain critical of Leninism as political praxis. The Bordigist ideology of the International Communist Party follow Bordiga's strict adherence to Leninism. The recent communisation current has been influenced by left communism and is critical of Lenin and Leninism, being more ideologically aligned with the Dutch–German left than the Italian left, wherein the theorist of communisation Gilles Dauvé criticised Leninism as a \"by-product of Kautskyism\".\n\nIn \"The Soviet Union Versus Socialism\" (1986), Noam Chomsky argued that Stalinism was a logical extension of Leninism, and not an ideological deviation from Lenin's policies. It resulted in collectivization and enforced the law with a police state, functions of the state continually supported with a totalitarian political ideology.\n\n\n\n\n\nWorks by Vladimir Lenin:\n\nOther thematic links:\n"}
{"id": "1828442", "url": "https://en.wikipedia.org/wiki?curid=1828442", "title": "List of Erasmus's correspondents", "text": "List of Erasmus's correspondents\n\nOne of the best sources for the world of European Renaissance Humanism in the early 16th century is the correspondence of Erasmus. Among those with whom he exchanged letters are:\n\n"}
{"id": "27646456", "url": "https://en.wikipedia.org/wiki?curid=27646456", "title": "List of Fellows of the American Academy in Rome 1971–1990", "text": "List of Fellows of the American Academy in Rome 1971–1990\n\nList of Fellows of the American Academy in Rome is a list of those who have been awarded the Rome Prize.\nThe Rome Prize is a prestigious American award made annually by the American Academy in Rome, through a national competition, to 15 emerging artists (working in Architecture, Landscape Architecture, Design, Historic Preservation and Conservation, Literature, Musical Composition, or Visual Arts) and to 15 scholars (working in Ancient, Medieval, Renaissance and early Modern, or Modern Italian Studies).\n\n"}
{"id": "2469009", "url": "https://en.wikipedia.org/wiki?curid=2469009", "title": "List of historical societies", "text": "List of historical societies\n\nThis is a partial List of historical and heritage societies from around the world. The sections provided are not mutually exclusive. Many historical societies websites are their museums' websites. List is organized by location and later by specialization.\n\n\n\n\n\n\n\n\nThe Royal Western Australian Historical Society is the overarching society for the whole state.\nPerth:\n\nPeel:\n\nWheatbelt:\n\nSouth West:\n\nGreat Southern:\n\nMid West:\n\nKimberley:\n\nGoldfields-Esperance:\n\nGascoyne:\n\nPilbara:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "146649", "url": "https://en.wikipedia.org/wiki?curid=146649", "title": "Living history", "text": "Living history\n\nLiving history is an activity that incorporates historical tools, activities and dress into an interactive presentation that seeks to give observers and participants a sense of stepping back in time. Although it does not necessarily seek to reenact a specific event in history, living history is similar to, and sometimes incorporates, historical reenactment. Living history is an educational medium used by living history museums, historic sites, heritage interpreters, schools and historical reenactment groups to educate the public or their own members in particular areas of history, such as clothing styles, pastimes and handicrafts, or to simply convey a sense of the everyday life of a certain period in history.\n\nLiving history approach to gain authenticity is less about replaying a certain event according to a planned script as in other reenactment fields. It is more about an immersion of players in a certain era, to catch, in the sense of Walter Benjamin the 'spiritual message expressed in every monument's and every site's own \"trace\" and \"aura\"', even in the Age of Mechanical Reproduction.\n\nAn early example of the spiritual and futuristic side of living history can be found in Guido von List's book \"Der Wiederaufbau von Carnuntum\" (1900), which suggested rebuilding the Roman Carnuntum military camp in Vienna's neighborhood as a sort of amusement park (compare \"Westworld\"). List, himself a right wing neopagan, asked his staff of landlords, waiters and rangers to be dressed in historical gear. He also asked to have any visitors redressed in costumes and described rituals to signify \"in-game\" and \"out-game\" status to enhance the immersion experience. E.g. the role of the garment is of interest till today.\n\nThe term 'living history' describes the performance of bringing history to life for the general public in a rather freewheeling manner. The players are less confined in their actions, but often have to stay at a certain place or building. Historical presentation includes a continuum from well researched attempts to recreate a known historical event for educational purposes, through representations with theatrical elements, to competitive events for purposes of entertainment. The line between amateur and professional presentations at living history museums can be blurred, same as the border to Live action role-playing games.\n\nWhile the pros latter routinely use museum professionals and trained interpreters to help convey the story of history to the public, some museums and historic sites employ living history groups with high standards of authenticity for the same role at special events. Such events do not necessarily include a mock battle but aim at portraying the life, and more importantly the lifestyle, of people of the period. This often includes both military and civilian impressions. Occasionally, storytelling or acting sketches take place to involve or explain the everyday life or military activity to the viewing public. More common are craft and cooking demonstrations, song and leisure activities, and lectures. Combat training or duels can also be encountered even when larger combat demonstrations are not present.\n\nIn the United States, on the National Park Service land, NPS policy \"does not allow for battle reenactments (simulated combat with opposing lines and casualties) on NPS property.\" There are exceptions i.e. Saylors Creek, Gettysburg. These are highly controlled with exacting safety factors, as well as, exacting historical truths.\n\nIn Germany medieval reenactment is usually associated with living history and renaissance faires and festivals, which are found in nearly each city. So e.g. the Peter and Paul festival in Bretten. the Landshut Wedding or the Schloss Kaltenberg knights tournament. The majority of combat reenactment groups are battlefield reenactment groups, some of which have become isolated to some degree because of a strong focus on authenticity.\n\nEvents with the professional reenactment-group Ulfhednar lead to a controversy in German archaeology. The German Polish living history group was supported by large museums and scholars and, since 2000 has largely coined the image of early history in Germany and international. Among others, a paper with the programmatic title \"Under the crocheted Swastika, Germanic Living History and rightwing affects\" started the dispute 2009. On the other hand, communist Eastern German had some problems with accepting \"indianistic\" living history reenactors, a widespread variety in Eastern Germany, which were closely monitored by the security forces.\nThat sort of 'second hand' living history is as well part of western Germany folklore and tries for a high level of authenticity.\n\nActivities may be confined to wearing period dress and perhaps explaining relevant historical information, either in role (also called first-person interpretation) or out of character (also called third-person interpretation). While many museums allow their staff to move in and out of character to better answer visitor questions, some encourage their staff to stay in role at all times.\n\nLiving history portrayal often involves demonstrating everyday activities such as cooking, cleaning, medical care, or particular skills and handicrafts. Depending on the historical period portrayed, these might include spinning, sewing, loom weaving, tablet weaving, inkle weaving or tapestry weaving, cloth dyeing, basket weaving, rope making, leather-working, shoemaking, metalworking, glassblowing, woodworking or other crafts. Considerable research is often applied to identifying authentic techniques and often recreating replica tools and equipment.\n\nHistorical reenactment groups often attempt to organize such displays in an encampment or display area at an event, and have a separate area for combat reenactment activities. While some such exhibits may be conducted in character as a representation of typical everyday life, others are specifically organized to inform the public and so might include an emphasis on handicrafts or other day-to-day activities, which are convenient to stage and interesting to watch, and may be explained out of character. During the 1990s, reenactment groups, primarily American Civil War groups, began to show interest in this style of interpretation and began using it at their reenactments.\n\nAs David Thelen has written, many Americans use the past in their daily lives, while simultaneously viewing the place where they often encounter history – the school – with varying levels of distrust and disconnectedness. Living history can be a tool used to bridge the gap between school and daily life to educate people on historical topics. Living history is not solely an objective retelling of historical facts. Its importance lies more in presenting visitors with a sense of a way of life, than in recreating exact events, accurate in every detail.\n\nMany factors contribute to creating a setting in which visitors to living history sites can become active participants in their historical education. Two of the most important are the material culture and the interpreters. Material culture both grounds the audience in the time and place being portrayed, and provides a jumping-off point for conversation. “Interpreters” are the individuals who embody historical figures at living history sites. It is their responsibility to take the historical research that has been done on the sites and decide what meaning it has. These meanings are often a melding of fact and folklore.\n\nFolklore is an important aspect of living histories because it provides stories which visitors relate to. Whether it is an interpreter embodying a past individual’s personal story or discussing a superstition of the time, these accounts allow the audience to see these past figures not as names on a page, but as actual people. However, folklore is also more than stories. Objects, such as dolls or handmade clothing, among others, are considered “folk artifacts,” which are grouped under the heading of “material culture.”\n\nIndividuals can participate in living histories as a type of experiential learning in which they make discoveries firsthand, rather than reading about the experience of others. Living history can also be used to supplement and extend formal education. Collaborations between professional historians who work at living history sites and teachers can lead to greater enthusiasm about studying history at all grade levels. Many living history sites profess a dedication to education within their mission statements. For instance, the motto of Colonial Williamsburg, “That the Future May Learn from the Past,” proclaims the site’s commitment to public edification, as does the portion of the website created for the sole purpose of aiding teachers in instruction on the village.\n\nCertain educators, such as James Percoco in his Springfield, Virginia high school class, have chosen to integrate public history into their curricula. Since 1991, Percoco has led a class entitled “Applied History,” in which his students have contributed over 20,000 hours of service to various institutions of public history. Formal education can help visitors interpret what they see at living history sites. By providing a structured way of looking at living histories, as well as questions to think about during visits, formal education can enrich the experience, just as living histories can enrich learning in the classroom.\n\nSome museums such as Middelaldercentret in Denmark provides living history for school children as a part of their education.\n\n\n\n"}
{"id": "8383286", "url": "https://en.wikipedia.org/wiki?curid=8383286", "title": "Long Peace", "text": "Long Peace\n\n\"Long Peace\" is a term for the unprecedented historical period following the end of World War II in 1945 to the present day. The period of the Cold War (1945–1991) was marked by the absence of major wars between the great powers of the period, the United States and the USSR. First recognized in 1986, such a period of \"relative peace\" between major powers has not been documented in human history since the Roman Empire.\n\nIn the 1990s, it was thought that the Long Peace was a unique result of the Cold War. However, when the Cold War ended the same trends continued in what has also been called the \"New Peace\". This period has exhibited more than a quarter of a century of even greater stability and peacefulness, and has also shown continued improvements in related measurements such as the number of coups, the amount of repression, and the durability of peace settlements. Though civil wars and lesser military conflicts have occurred, there has been a continued absence of direct conflict between any of the largest GDP economies; instead, wealthier countries have fought limited small-scale regional conflicts with poorer countries. Conflict involving smaller economies have also gradually tapered off. Overall, the number of international wars decreased from a rate of six per year in the 1950s to one per year in the 2000s, and the number of fatalities decreased from 240 reported deaths per million to less than 10 reported deaths per million.\n\nMajor factors cited as reasons for the Long Peace have included the deterrence effect of nuclear weapons, the economic incentives towards cooperation caused by globalization and international trade, the worldwide increase in the number of democracies, the World Bank's efforts in reduction of poverty, and the effects of the empowerment of women and peacekeeping by the United Nations. However, none of these are sufficient explanations on their own, so additional or combined factors are likely. Other proposed explanations have included the proliferation of human rights, increasing education and quality of life, changes in the way that people view conflicts (such as the presumption that wars of aggression are unjustified), the success of non-violent action, and demographic factors such as the reduction in birthrates.\n\nIn the book \"The Better Angels of Our Nature\", Steven Pinker says that this is part of a trend that has continued since the beginning of recorded history, and other experts have made similar arguments. While there is general agreement among experts that we are in a Long Peace and that wars have declined since the 1950s, Pinker's broader thesis has been contested. Critics have also said that we need a longer period of relative peace in order to be certain, or have emphasized minor reversals in specific trends, such as the increase in battle deaths between 2011 and 2014 due to the Syrian Civil War. While Pinker's work has received some publicity, most information about the Long Peace and related trends remains outside public awareness, and some data demonstrates a widespread misperception that the world has become more dangerous.\n\n"}
{"id": "1115738", "url": "https://en.wikipedia.org/wiki?curid=1115738", "title": "Long nineteenth century", "text": "Long nineteenth century\n\nThe long 19th century is a term coined for the period between the years 1789 and 1914 by Russian literary critic and author Ilya Ehrenburg and British Marxist historian and author Eric Hobsbawm. The concept is an adaption of Fernand Braudel's 1949 notion of \"le long seizième siècle\" (\"the long 16th century\" 1450–1640). and \"a recognized category of literary history\", although a period often broadly and diversely defined by different scholars. Numerous authors, before and after Hobsbawm's 1995 publication, have applied similar forms of book titles or descriptions to indicate a selective time frame for their works, such as: S. Kettering, \"French Society: 1589–1715 – the long seventeenth century\", E. Anthony Wrigley, \"British population during the ‘long’ eighteenth century, 1680–1840\", or D. Blackbourn, \"The long nineteenth century: A history of Germany, 1780–1918\".\nHowever, the term has been used in support of historical publications in order to \"connect with broader audiences\" and is regularly cited in studies and discussions across academic disciplines, such as history, linguistics and the arts.\n\nHobsbawm lays out his analysis in \"\" (1962), \"\" (1975), and \"\" (1987). Hobsbawn starts his long 19th century with the French Revolution, which sought to establish universal and egalitarian citizenship in France, and ends it with the outbreak of World War I, upon the conclusion of which in 1918 the long-enduring European power balance of the 19th century proper (1801–1900) was eliminated. In a sequel to the above-mentioned trilogy, \"The Age of Extremes: The Short Twentieth Century, 1914–1991\" (1994), Hobsbawm details the short 20th century beginning with World War I and ending with the fall of the Soviet Union.\n\nA more generalized version of the long 19th century, lasting from 1750 to 1914, is often used by Peter N. Stearns in the context of the world history school.\n\nIn religious contexts, specifically those concerning the history of the Catholic Church, the long 19th century was a period of centralization of papal power over the Catholic Church. This centralization was in opposition to the increasingly centralized nation states and contemporary revolutionary movements and used many of the same organizational and communication techniques as its rivals. The church's long 19th century extended from the French Revolution (1789) until the death of Pope Pius XII (1958).\n\n"}
{"id": "18006435", "url": "https://en.wikipedia.org/wiki?curid=18006435", "title": "Mark Lynton History Prize", "text": "Mark Lynton History Prize\n\nThe Mark Lynton History Prize is an annual award in the amount of $10,000 given to a book \"of history, on any subject, that best combines intellectual or scholarly distinction with felicity of expression\". The prize is one of three awards given as part of the J. Anthony Lukas Book Prize administered by the Nieman Foundation for Journalism and by the Columbia University School of Journalism.\n\nThe prize is named in honor of Mark Lynton, a refugee from Nazi Germany, Second World War officer, and automobile industry executive. In 1939 Lynton was a Jewish German-born student, studying history at Cambridge when he and other German nationals were rounded up and interned in detention camps in England and Canada as enemy aliens, suspected of being Nazi sympathizers. When Lynton was released he joined the British Army, became a tank commander, and was later promoted to Major in the occupying force, Army of the Rhine, where he helped interrogate high-ranking Nazi officers. Lynton memorialized his odyssey in his memoir, \"Accidental Journey: A Cambridge Internee's Memoir of World War II\". The prize was established by his wife, Marion, children, Lili and Michael, and grandchildren, Lucinda, Eloise Lynton and Maisie Lynton, to honor Lynton who was an avid reader of history. The Lynton family has underwritten the Lukas Prize Project since its inception in 1998.\n\n\n"}
{"id": "12238644", "url": "https://en.wikipedia.org/wiki?curid=12238644", "title": "Myth of the flat Earth", "text": "Myth of the flat Earth\n\nThe myth of the flat Earth is a modern misconception that Earth was widely believed to be flat rather than spherical during the Middle Ages in Europe.\n\nDuring the Early Middle Ages, virtually all scholars maintained the spherical viewpoint, which had been first expressed by the Ancient Greeks. From at least the 14th century, belief in a flat Earth among educated Europeans was almost nonexistent, despite fanciful depictions in art, such as the exterior of Hieronymus Bosch's famous triptych \"The Garden of Earthly Delights\", in which a disc-shaped Earth is shown floating inside a transparent sphere.\n\nAccording to Stephen Jay Gould, \"there never was a period of 'flat Earth darkness' among scholars (regardless of how the public at large may have conceptualized our planet both then and now). Greek knowledge of sphericity never faded, and all major medieval scholars accepted the Earth's roundness as an established fact of cosmology.\" Historians of science David Lindberg and Ronald Numbers point out that \"there was scarcely a Christian scholar of the Middle Ages who did not acknowledge [Earth's] sphericity and even know its approximate circumference\".\n\nHistorian Jeffrey Burton Russell says the flat-Earth error flourished most between 1870 and 1920, and had to do with the ideological setting created by struggles over biological evolution. Russell claims \"with extraordinary few exceptions no educated person in the history of Western Civilization from the third century B.C. onward believed that the Earth was flat\", and ascribes popularization of the flat-Earth myth to histories by John William Draper, Andrew Dickson White, and Washington Irving.\n\nIn \"Inventing the Flat Earth: Columbus and Modern Historians\", Jeffrey Russell describes the Flat Earth theory as a fable used to impugn pre-modern civilization and creationism.\n\nJames Hannam wrote:\n\nFrench dramatist Cyrano de Bergerac in chapter 5 of his \"Comical History of the States and Empires of the Moon\" (published 2 years posthumously in 1657) quotes St. Augustine as saying \"that in his day and age the Earth was as flat as a stove lid and that it floated on water like half of a sliced orange.\" Robert Burton, in his \"The Anatomy of Melancholy\" wrote:\nThus, there is evidence that accusations of Flatearthism, though somewhat whimsical (Burton ends his digression with a legitimate quotation of St. Augustine: \"Better doubt of things concealed, than to contend about uncertainties, where Abraham's bosom is, and hell fire\") were used to discredit opposing authorities several centuries before the 19th. Another early mention in literature is Ludvig Holberg's comedy \"Erasmus Montanus\" (1723). Erasmus Montanus meets considerable opposition when he claims the Earth is round, since all the peasants hold it to be flat. He is not allowed to marry his fiancée until he cries \"The earth is flat as a pancake\". In Thomas Jefferson's book \"Notes on the State of Virginia\" (1784), framed as answers to a series of questions (queries), Jefferson uses the \"Query\" regarding religion to attack the idea of state-sponsored official religions. In the chapter, Jefferson relates a series of official erroneous beliefs about nature forced upon people by authority. One of these is the episode of Galileo's struggles with authority, which Jefferson erroneously frames in terms of the shape of the globe:\n\nThe 19th century was a period in which the perception of an antagonism between religion and science was especially strong. The disputes surrounding the Darwinian revolution contributed to the birth of the conflict thesis, a view of history according to which any interaction between religion and science would almost inevitably lead to open hostility, with religion usually taking the part of the aggressor against new scientific ideas.\n\nIn 1828, Washington Irving's highly romanticised biography, \"A History of the Life and Voyages of Christopher Columbus\", was published and mistaken by many for a scholarly work. In Book II, Chapter IV of this biography, Irving gave a largely fictional account of the meetings of a commission established by the Spanish sovereigns to examine Columbus's proposals. One of his more fanciful embellishments was a highly unlikely tale that the more ignorant and bigoted members on the commission had raised scriptural objections to Columbus's assertions that the Earth was spherical.\n\nThe issue in the 1490s was not the shape of the Earth, but its size, and the position of the east coast of Asia, as Irving in fact points out. Historical estimates from Ptolemy onwards placed the coast of Asia about 180° east of the Canary Islands. Columbus adopted an earlier (and rejected) distance of 225°, added 28° (based on Marco Polo's travels), and then placed Japan another 30° further east. Starting from Cape St. Vincent in Portugal, Columbus made Eurasia stretch 283° to the east, leaving the Atlantic as only 77° wide. Since he planned to leave from the Canaries (9° further west), his trip to Japan would only have to cover 68° of longitude.\n\nColumbus mistakenly assumed that the mile referred to in the Arabic estimate of 56⅔ miles for the size of a degree was the same as the actually much shorter Italian mile of . His estimate for the size of the degree and for the circumference of the Earth was therefore about 25% too small. The combined effect of these mistakes was that Columbus estimated the distance to Japan to be only about 5,000 km (or only to the eastern edge of the Caribbean) while the true figure is about 20,000 km. The Spanish scholars may not have known the exact distance to the east coast of Asia, but they believed that it was significantly further than Columbus's projection; and this was the basis of the criticism in Spain and Portugal, whether academic or amongst mariners, of the proposed voyage.\n\nThe disputed point was not the shape of the Earth, nor the idea that going west would eventually lead to Japan and China, but the ability of European ships to sail that far across open seas. The small ships of the day (Columbus's three ships varied between 20.5 and 23.5 m – or 67 to 77 feet – in length and carried about 90 men) simply could not carry enough food and water to reach Japan. The ships barely reached the eastern Caribbean islands. Already the crews were mutinous, not because of some fear of \"sailing off the edge\", but because they were running out of food and water with no chance of any new supplies within sailing distance. They were on the edge of starvation. What saved Columbus was the unknown existence of the Americas precisely at the point he thought he would reach Japan. His ability to resupply with food and water from the Caribbean islands allowed him to return safely to Europe. Otherwise his crews would have died, and the ships foundered.\n\nIn 1834, a few years after the publication of Irving's book, Jean Antoine Letronne, a French academic of strong antireligious ideas, misrepresented the church fathers and their medieval successors as believing in a flat earth in his \"On the Cosmographical Ideas of the Church Fathers\". Then in 1837, the English philosopher of science William Whewell, in his \"History of the Inductive Sciences\", identified Lactantius, author of \"Institutiones Divinae\" (c. 310), and Cosmas Indicopleustes, author of \"Christian Topography\" (c. 548), as evidence of a medieval belief in a Flat Earth. Lactantius had been ridiculed much earlier by Copernicus in \"De revolutionibus\" of 1543 as someone who \"Speaks quite childishly about the Earth's shape, when he mocks those who declared that the Earth has the form of a globe\".\n\nOther historians quickly followed Whewell, although they could identify few other examples. The American chemist John William Draper wrote a \"History of the Conflict between Religion and Science\" (1874), employing the claim that the early Church fathers thought the Earth was flat as evidence of the hostility of the Church to the advancement of science. The story of widespread religious belief in the flat Earth was repeated by Andrew Dickson White in his 1876 \"The Warfare of Science\" and elaborated twenty years later in his two-volume \"History of the Warfare of Science with Theology in Christendom\", which exaggerated the number and significance of medieval flat Earthers to support White's model of warfare between dogmatic theology and scientific progress. As Draper and White's metaphor of ongoing warfare between the scientific progress of the Enlightenment and the religious obscurantism of the \"Dark Ages\" became widely accepted, it spread the idea of medieval belief in the flat Earth.\n\nThe widely circulated engraving of a man poking his head through the firmament surrounding the Earth to view the Empyrean, executed in the style of the 16th century, was published in Camille Flammarion's \"L'Atmosphère: Météorologie Populaire\" (Paris, 1888, p. 163). The engraving illustrates the statement in the text that a medieval missionary claimed that \"he reached the horizon where the Earth and the heavens met\". In its original form, the engraving included a decorative border that places it in the 19th century. In later publications, some of which claimed that the engraving dates to the 16th century, the border was removed.\n\nSince the early 20th century, a number of books and articles have documented the flat earth error as one of a number of widespread misconceptions in popular views of the Middle Ages. Both E. M. W. Tillyard's book \"The Elizabethan World Picture\" and C. S. Lewis' \"The Discarded Image\" are devoted to a broad survey of how the universe was viewed in Renaissance and medieval times, and both extensively discuss how the educated classes knew the world was round. Lewis draws attention to the fact that in Dante's \"The Divine Comedy\" about an epic voyage through hell, purgatory, and heaven, the earth is spherical with gravity being towards the center of the earth. As the Devil is frozen in a block of ice in the center of the earth, Dante and Virgil climb down the Devil's torso, but up from the Devil's waist to his feet, as his waist is at the center of the earth.\n\nJeffrey Burton Russell rebutted the prevalence of belief in the flat Earth in a monograph and two papers. Louise Bishop states that virtually every thinker and writer of the 1000-year medieval period affirmed the spherical shape of the Earth.\n\nAlthough the misconception was frequently refuted in historical scholarship since at least 1920, it persisted in popular culture and in some school textbooks into the 21st century. An American schoolbook by Emma Miller Bolenius published in 1919 has this introduction to the suggested reading for Columbus Day (12 October):\n\nA 2009 survey of schoolbooks from Austria and Germany showed that the Flat Earth myth became dominant in the second half of the 20th century and persists in most historical textbooks for German and Austrian schools.\n\nAs recently as 1983 Daniel Boorstin published a historical survey, \"The Discoverers\", which presented the Flammarion engraving on its cover and proclaimed that \"from AD 300 to at least 1300 ... Christian faith and dogma suppressed the useful image of the world that had been so ... scrupulously drawn by ancient geographers.\" Boorstin dedicated a chapter to the flat earth, in which he portrayed Cosmas Indicopleustes as the founder of Christian geography. The flat earth model has often been incorrectly supposed to be church doctrine by those who wish to portray the Catholic Church as being anti-progress or hostile to scientific inquiry. This narrative has been repeated even in academic circles, such as in April 2016, when Boston College theology professor and ex-priest Thomas Groome erroneously stated that \"the Catholic Church never said the earth is round, but just stopped saying it was flat.\"\n\nThe 1937 popular song \"They All Laughed\" contains the couplet \"They all laughed at Christopher Columbus/When he said the world was round\". In the Warner Bros. \"Merrie Melodies\" cartoon \"Hare We Go\" (1951) Christopher Columbus and Ferdinand the Catholic quarrel about the shape of the Earth; the king states the Earth is flat. In Walt Disney's 1963 animation \"The Sword in the Stone\", wizard Merlin (who has traveled into the future) explains to a young Arthur that \"man will discover in centuries to come\" that the Earth is round, and rotates.\n\nHistorical writers have identified a number of historical circumstances that contributed to the origin and widespread acceptance of the flat-earth myth. American historian Jeffrey Burton Russell traced the nineteenth-century origins of what he called the Flat Error to a group of anticlerical French scholars, particularly to Antoine-Jean Letronne and, indirectly, to his teachers Jean-Baptiste Gail and Edme Mentelle. Mentelle had described the Middle Ages as twelve ignorant centuries of \"profound night\", a theme exemplified by the flat-earth myth in Letronne's \"On the Cosmological Opinions of the Church Fathers\".\n\nHistorian of science Edward Grant saw a fertile ground for the development of the flat-Earth myth in a more general assault upon the Middle Ages and upon scholastic thought, which can be traced back to Francesco Petrarch in the fourteenth century. Grant sees \"one of the most extreme assaults against the Middle Ages\" in Draper's \"History of the Intellectual Development of Europe\", which appeared a decade before Draper presented the flat-Earth myth in his \"History of the Conflict Between Religion and Science\".\n\nAndrew Dickson White's motives were more complex. As the first president of Cornell University, he had advocated that it be established without any religious ties but be \"an asylum for science\". In addition, he was a strong advocate for Darwinism, saw religious figures as the main opponents of the Darwinian evolution, and sought to project that conflict of theology and science back through the entire Christian Era. But as some historians have pointed out, the nineteenth-century conflict over Darwinism incorporated disputes over the relative authority of professional scientists and clergy in the fields of science and education. White made this concern manifest in the preface to his \"History of the Warfare of Science and Theology in Christendom\", where he explained the lack of advanced instruction in many American colleges and universities by their \"sectarian character\".\n\nThe flat-Earth myth, like other myths, took on artistic form in the many works of art displaying Columbus defending the sphericity of the Earth before the Council of Salamanca. American artists depicted a forceful Columbus challenging the \"prejudices, the mingled ignorance and erudition, and the pedantic bigotry\" of the churchmen. Abrams sees this image of a Romantic hero, a practical man of business, and a Yankee go-getter as crafted to appeal to nineteenth-century Americans.\n\nRussell suggests that the flat-earth error was able to take such deep hold on the modern imagination because of prejudice and presentism. He specifically mentions \"the Protestant prejudice against the Middle Ages for Being Catholic ... the Rationalist prejudice against Judeo-Christianity as a whole\", and \"the assumption of the superiority of 'our' views to those of older cultures\".\n\n\n"}
{"id": "409192", "url": "https://en.wikipedia.org/wiki?curid=409192", "title": "New Chronology (Fomenko)", "text": "New Chronology (Fomenko)\n\nThe New Chronology is a pseudohistorical theory which argues that the conventional chronology of Middle Eastern and European history is fundamentally flawed, and that events attributed to the civilizations of the Roman Empire, Ancient Greece and Ancient Egypt actually occurred during the Middle Ages, more than a thousand years later. The central concepts of the New Chronology are derived from the ideas of Russian scholar Nikolai Morozov (1854–1946), although work by French scholar Jean Hardouin (1646–1729) can be viewed as an earlier predecessor. However, the New Chronology is most commonly associated with Russian mathematician Anatoly Fomenko (born 1945), although published works on the subject are actually a collaboration between Fomenko and several other mathematicians. The concept is most fully explained in \"History: Fiction or Science?\", originally published in Russian.\n\nThe New Chronology also contains \"a reconstruction\", an alternative chronology, radically shorter than the standard historical timeline, because all ancient history is \"folded\" onto the Middle Ages. According to Fomenko's claims, the written history of humankind goes only as far back as AD 800, there is almost no information about events between AD 800–1000, and most known historical events took place in AD 1000–1500.\n\nThe New Chronology is rejected by mainstream historians and is inconsistent with absolute and relative dating techniques used in the wider scholarly community. The majority of scientific commentators consider The New Chronology to be pseudoscientific. Interest in the academia in the theory stems mainly from its popularity which has compelled historians and other scientists to argue against its methods and proposed world history. A second point of interest from the mainstream academic community is to understand why it has become so popular as to perhaps have the sympathy of 30 percent of Russians. It is not really known to which extent readers of New Chronology texts regard it as history or fiction. Nor are there reliable statistics on who the readers are.\n\nThe theory emerged alongside other alternate histories and conspiracy literature in the period of increased freedom of speech that followed the break-up of the Soviet Union. While other authors have written on New Chronology theory, such as Fomenko's junior partner G.V. Nosovskiy and Bulgarian mathematician Iordan Tabov who expanded the theory in regards to the Balkans, the theory is mostly discussed in reference to Fomenko's writings.\n\nThe idea of chronologies that differ from the conventional chronology can be traced back to at least the early 17th century. Jean Hardouin then suggested that many ancient historical documents were much younger than commonly believed to be. In 1685 he published a version of Pliny the Elder's \"Natural History\" in which he claimed that most Greek and Roman texts had been forged by Benedictine monks. When later questioned on these results, Hardouin stated that he would reveal the monks' reasons in a letter to be revealed only after his death. The executors of his estate were unable to find such a document among his posthumous papers. In the 17th century, Sir Isaac Newton, examining the current chronology of Ancient Greece, Ancient Egypt and the Ancient Near East, expressed discontent with prevailing theories and in \"The Chronology of Ancient Kingdoms Amended\" proposed one of his own, which, basing its study on Apollonius of Rhodes's \"Argonautica\", changed the traditional dating of the Argonautic Expedition, the Trojan War, and the Founding of Rome.\n\nIn 1887, Edwin Johnson expressed the opinion that early Christian history was largely invented or corrupted in the 2nd and 3rd centuries.\n\nIn 1909 Otto Rank made note of duplications in literary history of a variety of cultures:\n\nalmost all important civilized peoples have early woven myths around and glorified in poetry their heroes, mythical kings and princes, founders of religions, of dynasties, empires and cities—in short, their national heroes. Especially the history of their birth and of their early years is furnished with phantastic traits; the amazing similarity, nay literal identity, of those tales, even if they refer to different, completely independent peoples, sometimes geographically far removed from one another, is well known and has struck many an investigator.\n\nFomenko became interested in Morozov's theories in 1973. In 1980, together with a few colleagues from the mathematics department of Moscow State University, he published several articles on \"new mathematical methods in history\" in peer-reviewed journals. The articles stirred a lot of controversy, but ultimately Fomenko failed to win any respected historians to his side. By the early 1990s, Fomenko shifted his focus from trying to convince the scientific community via peer-reviewed publications to publishing books. Beam writes that Fomenko and his colleagues were discovered by the Soviet scientific press in the early 1980s, leading to \"a brief period of renown\"; a contemporary review from the Soviet journal \"Questions of History\" complained, \"Their constructions have nothing in common with Marxist historical science.\"\n\nBy 1996 his theory had grown to cover Russia, Turkey, China, Europe, and Egypt.\n\nCentral to Fomenko's New Chronology is his claim of the existence of a vast Slav-Turk empire, which he called the \"Russian Horde\", which he says played the dominant role in Eurasian history before the 17th century. The various peoples identified in ancient and medieval history, from the Scythians, Huns, Goths and Bulgars, through the Polyane, Duleby, Drevliane, Pechenegs, to in more recent times, the Cossacks, Ukrainians, and Belarusians, are nothing but elements of the single Russian Horde. For the New Chronologists, peoples such as the Ukrainians, Belarusians, Mongols, and others who assert their national independence from Russia, are suffering from a historical delusion.\n\nFomenko claims that the most probable prototype of the historical Jesus was Andronikos I Komnenos (allegedly AD 1152 to 1185), the emperor of Byzantium, known for his failed reforms; his traits and deeds reflected in 'biographies' of many real and imaginary persons. The historical Jesus is a composite figure and reflection of the Old-Testament prophet Elisha (850–800 BC?), Pope Gregory VII (1020?–1085), Saint Basil of Caesarea (330–379), and even Li Yuanhao (also known as Emperor Jingzong or \"Son of Heaven\" - emperor of Western Xia, who reigned in 1032–48), Euclides, Bacchus and Dionysius. Fomenko explains the seemingly vast differences in the biographies of these figures as resulting from difference in languages, points of view and time-frame of the authors of said accounts and biographies. He claims that the historical Jesus may have been born in 1152 and was crucified around AD 1185 on the Joshua's Hill, overlooking the Bosphorus.\n\nFomenko also merges the cities and histories of Jerusalem, Rome and Troy into \"New Rome\" = Gospel Jerusalem (in the 12th and 13th centuries) = Troy = Yoros Castle. To the south of Yoros Castle is Joshua's Hill which Fomenko alleges is the hill Calvary depicted in the Bible.\n\nFomenko claims the Hagia Sophia is actually the biblical Temple of Solomon. He identifies Solomon as sultan Suleiman the Magnificent (1494–1566).\n\nOn the other hand, according to Fomenko the word \"Rome\" is a placeholder and can signify any one of several different cities and kingdoms. He claims the \"First Rome\" or \"Ancient Rome\" or \"Mizraim\" is an ancient Egyptian kingdom in the delta of the Nile with its capital in Alexandria. The second and most famous \"New Rome\" is Constantinople. The third \"Rome\" is constituted by three different cities: Constantinople (again), Rome in Italy, and Moscow. According to his claims, Rome in Italy was founded around AD 1380 by Aeneas and Moscow as the third Rome was the capital of the great \"Russian Horde\". \n\nIn volumes 1, 2, 3 and 4 of \"History: Fiction or Science?\", Fomenko and his colleagues make numerous claims:\n\nOne might wonder why we should want to revise the chronology of ancient history today and base our revision on new empirical-statistical methods. It would be worthwhile to remind the reader that in the XVI-XVII century chronology was considered to be a subdivision of mathematics.\n\nThe vocabulary of Egyptian astronomical symbols once applied to horoscopes from temples allows for extraction of unique dates of eclipses. Astronomical data therein contained is sufficient for unique dating. There are symbols allowing for astronomical interpretation and the symbols do not change from one temple horoscope to another. The horoscopes from temples contain data about eclipses visible in Egypt allowing their exact pinpointing on the time axis.\n\nAs we have already noted, the inability of the latter day commentators to comprehend the astronomical symbolism of the Apocalypse is directly resulting from the loss of knowledge about the correct chronology and the distortions introduced by historians of the XVI-XVIII century. Another possibility is that there was an unspoken general taboo on what concerned a subject quite as dangerous, which resulted in the misdating of the Apocalypse. One way or another, the understanding of the astronomical descriptions that the Apocalypse contains got lost at some point. The Apocalypse had lost its distinctive astronomical hue in the eyes of the readers. However, its “astronomical component” is not simply exceptionally important – it alone suffices for the dating of the book itself.\n\nThe vocabulary of Babylonian astronomical symbols once applied to clay tablets don't allow for extraction of unique dates of eclipses. Astronomical data therein contained is not sufficient for unique dating. Either there not enough symbols allowing for astronomical interpretation or the symbols change from one clay tablet to another. The clay tablets contain data about eclipses visible in Babylon that could have taken place every 30-40 years, therefore don’t allow there exact pinpointing on the time axis.\n\nChinese eclipse observations can neither confirm nor refute any chronology of China at all, be it veracious or erroneous.\nOne of Fomenko's simplest methods is statistical correlation of texts. His basic assumption is that a text which describes a sequence of events will devote more space to more important events (for example, a period of war or an unrest will have much more space devoted to than a period of peaceful, non-eventful years), and that this irregularity will remain visible in other descriptions of the period. For each analysed text, a function is devised which maps each year mentioned in the text with the number of pages (lines, letters) devoted in the text to its description (which could be zero). The function of the two texts are then compared.\n\nFor example, Fomenko compares the contemporary history of Rome written by Titus Livius with a modern history of Rome written by Russian historian V. S. Sergeev, calculating that the two have high correlation, and thus that they describe the same period of history, which is undisputed. He also compares modern texts which describe different periods, and calculates low correlation, as expected. However, when he compares, for example, the ancient history of Rome and the medieval history of Rome, he calculates a high correlation, and concludes that ancient history of Rome is a copy of medieval history of Rome, thus clashing with mainstream accounts.\n\nIn a somewhat similar manner, Fomenko compares two dynasties of rulers using statistical methods. First, he creates a database of rulers, containing relevant information on each of them. Then, he creates \"survey codes\" for each pair of the rulers, which contain a number which describes degree of the match of each considered property of two rulers. For example, one of the properties is the way of death: if two rulers were both poisoned, they get value of +1 in their property of the way of death; if one ruler was poisoned and another killed in combat, they get -1; and if one was poisoned, and another died of illness, they get 0 (Fomenko claims there is possibility that chroniclers were not impartial and that different descriptions nonetheless describe the same person). An important property is the length of the rule.\n\nFomenko lists a number of pairs of unrelated dynasties – for example, dynasties of kings of Israel and emperors of late Western Roman Empire (AD 300-476) – and claims that this method demonstrates correlations between their reigns. (Graphs which show just the length of the rule in the two dynasties are the most widely known; however, Fomenko's conclusions are also based on other parameters, as described above.) He also claims that the regnal history from the 17th to 20th centuries never shows correlation of \"dynastic flows\" with each other, therefore Fomenko insists history was multiplied and outstretched into imaginary antiquity to justify this or other \"royal\" pretensions.\n\nFomenko uses for the demonstration of correlation between the reigns exclusively the data from the \"Chronological Tables\" of J. Blair (Moscow 1808–09). Fomenko says that Blair’s tables are all the more valuable to us since they were compiled in an epoch adjacent to the time of Scaligerian chronology. According to Fomenko these tables contain clearer signs of “Scaligerite activity” which were subsequently buried under layers of paint and plaster by historians of the 19th and 20th centuries.\n\nFomenko examines astronomical events described in ancient texts and claims that the chronology is actually medieval. For example:\n\n\nOn archaeological dating methods, Fomenko claims:\n\nDendrochronology is rejected with a claim that, for dating of objects much older than the oldest still living trees, it isn't an absolute, but a relative dating method, and thus dependent on traditional chronology. Fomenko specifically points to a break of dendrochronological scales around AD 1000.\n\nFomenko also cites a number of cases where carbon dating of a series of objects of known age gave significantly different dates. He also alleges undue cooperation between physicists and archaeologists in obtaining the dates, since most radiocarbon dating labs only accept samples with an age estimate suggested by historians or archaeologists. Fomenko also claims that carbon dating over the range of AD 1 to 2000 is inaccurate because it has too many sources of error that are either guessed at or completely ignored, and that calibration is done with a statistically meaningless number of samples.\nConsequently, Fomenko concludes that carbon dating is not accurate enough to be used on historical scale.\n\nFomenko rejects numismatic dating as circular, being based on the traditional chronology, and points to cases of similar coins being minted in distant periods, unexplained long periods with no coins minted and cases of mismatch of numismatic dating with historical accounts.\n\nFomenko's historical ideas have been universally rejected by mainstream scholars, who brand them as pseudoscience, but were popularized by former world chess champion Garry Kasparov. Billington writes that the theory \"might have quietly blown away in the wind tunnels of academia\" if not for Kasparov's writing in support of it in the magazine \"Ogoniok\". Kasparov met Fomenko during the 1990s, and found that Fomenko's conclusions concerning certain subjects were identical to his own regarding the popular view (which is not the view of academics) that art and culture died during the Dark Ages and were not revived until the Renaissance. Kasparov also felt it illogical that the Romans and the Greeks living under the banner of Byzantium could fail to use the mounds of scientific knowledge left them by Ancient Greece and Rome, especially when it was of urgent military use. However, Kasparov does not support the reconstruction part of the New Chronology. Russian critics tended to see Fomenko's New Chronology as \"an embarrassment and a potent symbol of the depths to which the Russian academy and society have generally sunk ... since the fall of Communism\". Western critics see his views as part of a renewed Russian imperial ideology, \"keeping alive an imperial consciousness and secular messianism in Russia\".\n\nIn 2004 at the Moscow International Book Fair, Anatoly Fomenko with his coauthor Gleb Nosovsky were awarded for their books on \"New Chronology\" the anti-prize called (literally 'paragraph', a Russian slang word meaning 'disaster' or 'fiasco') in the category \"Pochotnaya bezgramota\" (the term is a pun upon \"Pochotnaya gramota\" (Certificate of Honor) and may be translated either \"Certificate of Dishonor\" or literally, \"Respectable Illiteracy\" ) for the worst book published in Russia.\n\nCritics have accused Fomenko of altering the data to improve the fit with his ideas and have noted that he violates a key rule of statistics by selecting matches from the historical record which support his chronology, while ignoring those which do not, creating artificial, better-than-chance correlations, and that these practices undermine Fomenko's statistical arguments. The new chronology was given a comprehensive critical analysis in a round table on \"The 'Myths' of New Chronology\" chaired by the dean of the department of history of Moscow State University in December 1999. One of the participants in that round table, the distinguished Russian archaeologist, Valentin Yanin, compared Fomenko's work to \"the sleight of hand trickery of a David Copperfield\". Linguist Andrey Zaliznyak argued that by using the Fomenko's approaches one can \"prove\" any historical correspondence, for example, between Ancient Egyptian pharaohs and French kings.\n\nJames Billington, formerly professor of Russian history at Harvard and Princeton and the Librarian of Congress from 1987-2015 placed Fomenko's work within the context of the political movement of Eurasianism, which sought to tie Russian history closely to that of its Asian neighbors. Billington describes Fomenko as ascribing the belief in past hostility between Russia and the Mongols to the influence of Western historians. Thus, by Fomenko's chronology, \"Russia and Turkey are parts of a previously single empire.\" A French reviewer of Billington's book noted approvingly his concern with the phantasmagorical conceptions of Fomenko about the global \"new chronology\".\n\nH.G. van Bueren, professor emeritus of astronomy at the University of Utrecht, concluded his scathing review of Fomenko's work on the application of mathematics and astronomy to historical data as follows:\n\nWhile Fomenko rejects commonly accepted dating methods, archaeologists, conservators and other scientists make extensive use of such techniques which have been rigorously examined and refined during decades of use.\n\nIn the specific case of dendrochronology, Fomenko claims that this fails as an absolute dating method because of gaps in the record. However, independent dendrochronological sequences beginning with living trees from various parts of North America and Europe extend back 12,400 years into the past. Furthermore, the mutual consistency of these independent dendrochronological sequences has been confirmed by comparing their radiocarbon and dendrochronological ages. These and other data have provided a calibration curve for radiocarbon dating whose internal error does not exceed ±163 years over the entire 26,000 years of the curve.\n\nIn fact, archaeologists have developed a \"fully anchored\" dendrochronology series going back past 10,000 BCE. \"The absolutely dated tree-ring chronology now extends back to 12,410 cal BP (10,461 BC).\"\n\nCritics of Fomenko's theory claim that his use of historical sources is highly selective and ignores the basic principles of sound historical scholarship.\nFomenko ... provides no fair-minded review of the historical literature about a topic with which he deals, quotes only those sources that serve his purposes, uses evidence in ways that seem strange to professionally-trained historians and asserts the wildest speculation as if it has the same status as the information common to the conventional historical literature.\nThey also note that his method of statistically correlating of texts is very rough, because it does not take into account the many possible sources of variation in length outside of \"importance\". They maintain that differences in language, style, and scope, as well as the frequently differing views and focuses of historians, which are manifested in a different notion of \"important events\", make quantifying historical writings a dubious proposition at best. What's more, Fomenko's critics allege that the parallelisms he reports are often derived by alleged forcing by Fomenko of the data – rearranging, merging, and removing monarchs as needed to fit the pattern.\n\nFor example, on the one hand Fomenko asserts that the vast majority of ancient sources are either irreparably distorted duplicate accounts of the same events or later forgeries. In his identification of Jesus with Pope Gregory VII he ignores the otherwise vast dissimilarities between their reported lives and focuses on the similarity of their appointment to religious office by baptism. (The evangelical Jesus is traditionally believed to have lived for 33 years, and he was an adult at the time of his encounter with John the Baptist. In contrast, according to the available primary sources, Pope Gregory VII lived for at least 60 years and was born 8 years after the death of Fomenko's John-the-Baptist equivalent John Crescentius.)\n\nCritics allege that many of the supposed correlations of regnal durations are the product of the selective parsing and blending of the dates, events, and individuals mentioned in the original text. Another point raised by critics is that Fomenko does not explain his altering the data (changing the order of rulers, dropping rulers, combining rulers, treating interregna as rulers, switching between theologians and emperors, etc.) preventing a duplication of the effort and effectively making this whole theory an ad hoc hypothesis.\n\nCritics point out that Fomenko's discussion of astronomical phenomena tends to be selective, choosing isolated examples that support the New Chronology and ignoring the large bodies of data that provide statistically supported evidence for the conventional dating. For his dating of the Almagest star catalog, Fomenko arbitrarily selected eight stars from the more than 1000 stars in the catalog, one of which (Arcturus) has a large systematic error. This star has a dominant effect on Fomenko's dating. Statistical analysis using the same method for all \"fast\" stars points to the antiquity of the Almagest star catalog. Rawlins points out further that Fomenko's statistical analysis got the wrong date for the \"Almagest\" because he took as constant Earth's obliquity when it is a variable that changes at a very slow, but known, rate.\n\nFomenko's studies ignore the abundance of dated astronomical records in cuneiform texts from Mesopotamia. Among these texts is a series of Babylonian astronomical diaries, which records precise astronomical observations of the Moon and planets, often dated in terms of the reigns of known historical figures extending back to the 6th century BCE. Astronomical retrocalculations for all these moving objects allow us to date these observations, and consequently the rulers' reigns, to within a single day. The observations are sufficiently redundant that only a small portion of them are sufficient to date a text to a unique year in the period 750 BCE to 100 CE. The dates obtained agree with the accepted chronology. In addition, F. R. Stephenson has demonstrated through a systematic study of a large number of Babylonian, Ancient and Medieval European, and Chinese records of eclipse observations that they can be dated consistently with conventional chronology at least as far back as 600 BCE. In contrast to Fomenko's missing centuries, Stephenson's studies of eclipse observations find an accumulated uncertainty in the timing of the rotation of the earth of 420 seconds at 400 BCE, and only 80 seconds at 1000 CE.\n\nFomenko states that world history prior to 1600 was deliberately falsified for political reasons. The consequences of this conspiracy theory are twofold. Documents that conflict with New Chronology are said to have been edited or fabricated by conspirators; the Vatican, the Holy Roman Empire and pro-German Romanov dynasty. New Chronology taps traditionally Russian anti-Western thoughts and ideas of Germany as a chief enemy. Further, the theory is Russocentric diminishing achievements of other cultures and claiming major civilization accomplishments as Russian and by proposing a giant \"Russian Horde\" empire and eliminating historical time before its existence. The theory also claimed to undermine nationalism in countries neighboring Russia by positioning divisions and conflicts as fabricated. Unlike other popular conspiracy theories New Chronology is not anti-semitic \"per se\", but it contains claims that may be unwelcome by Jewish communities like that the Old Testament is newer than the New Testament, placing Jerusalem in Constantinople and projecting stereotypes of Jews by proposing that Jews originate from bankers in the Russian Horde that adopted the religion of Judaism, itself a derivative of Christianity and not the other way round. \n\nThe theory provides an alternate history account of the \"true\" history centered around a world empire called the \"Russian Horde\". The scope of the New Chronology has been compared to J. R. R. Tolkien's fantasy world. Thousands of pages has been written about it and authors address a wide range of objections.\n\nFomenko has published and sold over one million copies of his books in his native Russia. Many Internet forums have appeared which aim to supplement his work with additional amateur research. His critics have suggested that Fomenko's version of history appealed to the Russian reading public by keeping alive an imperial consciousness to replace their disillusionment with the failures of Communism and post-Communist corporate oligarchies.\n\n\nVol.1: The Development of the Statistical Tools. Vol.2: The Analysis of Ancient and Medieval\nRecords. – Kluwer Academic Publishers. The Netherlands, 1994.\n\n"}
{"id": "1519656", "url": "https://en.wikipedia.org/wiki?curid=1519656", "title": "Nonzero: The Logic of Human Destiny", "text": "Nonzero: The Logic of Human Destiny\n\nNonzero: The Logic of Human Destiny is a 1999 book by Robert Wright, in which the author argues that biological evolution and cultural evolution are shaped and directed first and foremost by \"non-zero-sumness\" i.e., the prospect of creating new interactions that are not zero-sum.\n\nThe principal argument of \"Nonzero\" is to demonstrate that natural selection results in increasing complexity within the world and greater rewards for cooperation. Since, as Wright puts it, the realization of such prospects is dependent upon increased levels of globalization, communication, cooperation, and trust, what is thought of as human intelligence is really just a long step in an evolutionary process of organisms (as well as their networks and individual parts) getting better at processing information.\n\nThrough this lens, and an overview of human and global history, Wright typifies the argument against the views of noted paleontologist Stephen Jay Gould. Gould wrote that \"Humans are here by the luck of the draw.\" Wright acknowledges one aspect of Gould's argument—that the evolutionary process was not such that it would inevitably create humans as we know them today (\"five fingers, five toes, and so on\") but that evolution would almost certainly result in the creation of highly intelligent, communicating organisms, who would in turn develop tools and advanced technologies.\n\nEvidence for natural selection driving improvements in information processing is given throughout, including the case of the bombardier beetle, an insect that developed the ability to spray its attackers with harsh chemicals. This, in turn, favored predators via natural selection who had techniques to avoid the spray. As Wright puts it, \"complexity breeds complexity.\" This is the often referred to evolutionary phenomenon of the \"arms race,\" wherein competing organisms stack up their developments in competition with one another.\n\nVia this increasing complexity, according to \"Nonzero\", higher intelligence was thus destined to happen, perhaps even \"inevitable\" (see discussion of inevitability below). Though the stated thesis is that evolution is headed in the direction of \"non-zero-sumness,\" Wright argues that the realization of such prospects is dependent upon improvements in information processing, thus neatly carving out a reason for the creation and cultural evolution of the human species.\n\nWright argues that as complexity in human society increases, the ability to reap \"non-zero-sum gains\" increases. For example, electronic communications enable trade at a global level, and allow various societies to trade in items they could not produce or obtain otherwise, resulting in benefits for everyone: new goods. Similarly, global governments allow global solutions to common problems. Were aliens to attack, or the Arctic glaciers to melt, the world would be able to use its communicative technologies to band societies together and defend itself at large. In fact, this view of the world as an organic entity itself is touched upon in the penultimate chapter of the book, and is similar to that of Gaia theory.\n\nOf course, when societies band together to fight a common enemy, that enemy is not always an Arctic glacier, but rather, other human societies. Wright discusses this as well, arguing that war between nations often resulted in technological and cultural evolution. For example, World War II spurred the development of the Manhattan Project and, in turn, nuclear power and related research—a technology that may ultimately benefit the world at large. Further, societies with advanced governments were more likely to succeed in war, spreading government systems as a technology in and of itself.\n\nThe book is composed in three sections, each one more or less independent, but contributing to the development of his overall thesis.\n\nThis section is a sound summary of human cultural development, fairly conventional, except for his references to game theory and the occasional interjection of metaphysical speculation.\n\nThis section is again a broadly conventional overview of current understanding of the development of life on earth. He argues from game-theory that increasing complexity is inevitably going to result from the operation of evolution by natural selection. More controversially, he argues that intelligence, social co-operation and cultural development are also bound to emerge sooner or later.\n\nThis brief section is the most controversial part of the book, which he admits is speculative and presents with a degree of humility. The main thrust of his argument is that we may be on the threshold of a new phase of development involving the creation of a unified global consciousness, along the lines suggested in the writings of Jesuit Pierre Teilhard de Chardin.\n\nEven the development of weapons systems themselves (and Wright's discussion of their increasing complexity over time) left him open to criticism, put into words by Steven Pinker, a linguist/cognitive scientist specializing in evolutionary psychology:\n\nSimilarly, the idea of greater and greater non-zero-sum gains benefitting the world at large is also debated, as such technologies allow the injury of ever larger numbers of people. While Wright believes that the goal of natural selection is increasing non-zero-sum gains, it is also clear that these gains might not benefit everyone. Though this does not in any way invalidate Wright's thesis, it does dampen the optimism Wright appears to hold for non-zero-sum dynamics. Indeed, in a world of separated, village-like units, atrocities within Joseph Stalin's Soviet Union or Adolf Hitler's Third Reich could not have occurred. (Of course, life within those village-like units had its own inherent problems, and the question of which point in history was better is addressed by arguments within teleology—whether history has a direction, and thus if history has shown consistent progress.) Wright believes that overall there has been net progress (with some exceptions), and further, that this progress will continue. In response to Wright's assumption that cooperation and communication will continue to increase, Pinker writes:\n\nPinker also challenges Wright's core thesis, echoing the case made by Stephen Jay Gould, that human-like organisms are no more than a coincidence:\n\nWright acknowledges several of these criticisms within \"Nonzero\" itself and in turn responds with his purpose in writing the book—that by acknowledging options to reap non-zero-sum gains, societies might work to decrease zero-sum losses, like the loss of resources used in the pursuit of armed conflict.\n\nIn response to Pinker's comments regarding the inevitability of human-like intelligence (as versus to the elephant trunk), Wright replies:\n\nThere is also question of whether non-zero-sum gains will—or even should—benefit all members of society under any system of egalitarianism. Wright does argue that increased levels of communication will inevitably lead to a decrease in enmity between some populations. Still, this does not answer the question of whether some members of society will ever \"catch-up\" in terms of technological connectedness, or if some might be barred entirely by some kind of oppressive (but still productive) political system. Wright states on p. 329 of \"Nonzero\" (Vintage Paperback edition) that \"one can well imagine, as the Internet nurtures more and more communities of interest, true friendships more and more crossing the most dangerous fault lines—boundaries of religion, of nationality, of ethnicity, of culture.\" Wright then states in his endnote to the section, \"a big question is whether boundaries of social class will be so easily crossed — or whether, on the other hand, differences of social class within a society might sharpen as people invest more of their energy in virtual communities consisting of like-minded people.\"\n\nThough Wright clearly does not posit an answer to the question of struggles among economic classes—whether they be because of or in spite of natural selection—some argue it is relevant to Wright's treatment of evolution as resulting in greater and greater moral progress, and thus strangely ignored, given that Wright is the author of another book examining human morality \"The Moral Animal\".\n\nWright argues for the possibility of divine purpose (and thus for the concept of God as a creating entity) but is against creationism, and theories on intelligent design. He argued against the concepts in articles related to \"Nonzero\".\n\nLike most biologists, Wright firmly rejects the notion of divine biological manipulation. But Wright does leave open the possibility of divine intervention in the case of human consciousness, which he does not see as being easily explained by natural selection. Consciousness—humans' ability to ponder their own existence—seems a strange outgrowth of the evolutionary process for Wright. He describes the alternative as humans that are devoid of consciousness and behave like zombies that form romantic relationships, eat, sleep, and have discussions only because they are programmed to via cultural and genetic transmission.\n\nWright argues that consciousness is still a mystery in terms of evolutionary purpose, and leaves open the possibility that a divine entity introduced the phenomenon of consciousness. Wright also debates whether or not entities aside from humans possess consciousness. Wright does not explain how a biological entity could evolve a level of intelligence like that existing in humans without the intelligence inherently including consciousness.\n\nWright also briefly questions the possibilities regarding what created natural selection, but Wright himself refers to his comments as highly speculative.\n\nWright's idea of \"divinity\" is further explored in his follow-up book, \"The Evolution of God\". He does not argue that an intelligent being is behind it all, but that the existence of a process that could be called \"divine\" is suggested, much the way the existence of electrons is suggested by the inner workings of a computer (despite no one ever seeing one).\n\n\"Nonzero: The Logic of Human Destiny\", January 2001 , \n\n\"The Evolution of God\", June 2009 (Hardcover, 1st edition)\n\n"}
{"id": "2291063", "url": "https://en.wikipedia.org/wiki?curid=2291063", "title": "Nuwaubian Nation", "text": "Nuwaubian Nation\n\nThe Nuwaubian Nation or Nuwaubian movement () was an American religious cult founded and led by Dwight York. York began founding Black Muslim groups in New York in 1967. He changed his teachings and the names of his groups many times, incorporating concepts from Judaism, Christianity, and many esoteric beliefs.\n\nIn the late 1980s, he abandoned the Muslim theology of his movement in favor of Kemetism and UFO religion. In 1991 he took his community to settle in upstate New York; then they moved near to Eatonton, the county seat of Putnam County in Georgia. His followers built an ancient Egypt-themed compound called Tama-Re and changed their name to the \"United Nuwaubian Nation of Moors.\"\n\nBy 2000, the \"United Nuwaubian Nation of Moors\" had some 500 adherents. They drew thousands of visitors for \"Savior's Day\" (York's birthday). Adherence declined steeply after York was convicted of numerous counts of child molestation and financing violations, and sentenced to 135 years in federal prison in April 2004. The Tama-Re compound was sold under government forfeiture and demolished. The Southern Poverty Law Center described York as a \"black supremacist cult leader\", and has designated the organization as a \"hate group\".\n\nThe group has taken numerous names, including Ansaru Allah Community, Holy Tabernacle Ministries, United Nuwaubian Nation of Moors (after the move to Georgia), Yamassee Native American Moors of the Creek Nation (also used in Georgia when York claimed indigenous ancestry via Egyptian migration and intermarriage with the ancient Olmec) and Nuwaubian Nation of Moors.\n\nThe Nuwaubian Nation was centered exclusively on the person of its founder, Malachi (Dwight) York, who legally changed his name several times, and has used dozens of aliases.\n\nYork was born on June 26, 1935 (also reported as 1945). He began his ministry in the late 1960s, from 1967 preaching to a group he called the Pan-African \"Nubians\" (viz. African Americans) in Brooklyn.\n\nYork founded numerous esoteric or quasi-religious fraternal orders under various names during the 1970s and 1980s, at first along pseudo-Islamic lines, later moving to a loose Afrocentric ancient Egypt theme, eclectically mixing ideas taken from Black nationalism, cryptozoology and UFO religions and popular conspiracy theories.\nDuring the 1980s, he was also active as a musician, as \"Dr. York\" publishing under the \"Passion Records\" label.\n\nYork published some 450 booklets (dubbed \"scrolls\") under numerous pseudonyms. During the late 1990s, he styled himself a messianic founder-prophet of his movement, sometimes claiming divine status or extraterrestrial origin, appearing on his Savior's Day celebrations at Tama-Re.\n\nYork was arrested in May 2002, and in 2003 he pleaded guilty to child sexual abuse after being indicted on 197 counts of child molestation, including charges of sex trafficking of minors across state lines. He was imprisoned. In 2004, he was convicted to a 135-year sentence for transporting minors across state lines in the course of sexually molesting them, racketeering, and financial reporting charges. His convictions were upheld on appeal. York's case was reported as the largest prosecution for child molestation ever directed at a single person in the history of the United States, both in terms of number of victims and number of incidents. The case was described in the book \"Ungodly: A True Story of Unprecedented Evil\" (2007) by Bill Osinski, a reporter who had covered the Nuwaubians in Georgia during the late 1990s.\n\nSome factions of the Black supremacist subculture in the United States appeared to continue to support York as of 2010, portraying his conviction as a conspiracy by the \"White Power Structure\". Malik Zulu Shabazz, chairman of the New Black Panther Party and York's lawyer, described York as \"a great leader of our people [… and] victim of an open conspiracy by our enemy.\"\n\nDuring the 1970s, the group set up bookstores and chapters in Trinidad; Baltimore; and Washington, D.C.. According to former follower Saadik Redd, York had between 2,000 and 3,000 followers during the 1970s. Its headquarters was in Bushwick, Brooklyn, until 1983. A portion of the community moved to Sullivan County, New York, to a site they called Camp Jazzir Abba. More people stayed in Brooklyn until about 1991.\n\nA Muslim cleric, Bilal Philips, published \"The Ansar Cult in America\" in 1988, denouncing the movement as un-Islamic. Phillips relied heavily on testimonies of former adherents in describing the group's beliefs and practices.\n\nIn the late 1980s, York borrowed from numerous religious and esoteric traditions beyond Islam, creating the \"Nuwaubian\" movement. York styled his movement in a mixture of Ancient Egypt and Native American themes. York changed his legal name again, from \"Issa Al Haadi Al Mahdi\" to \"Malachi York,\" effective March 12, 1993.\n\nFormer follower Robert J. Rohan had a critical view of York's changes, as noted in this interview:\n\nAmong its themes, the Nuwaubians borrowed a claim to indigenous ancestry, perhaps from the Washitaw Nation (a Louisiana Black separatist group led by an eccentric 'empress'). They claimed to be indigenous people, named Yamasee (claiming affiliation with the confederation of Muscogee (Creek) Native American nations in the Georgia area) as well as \"Moors.\" They claimed a prehistoric migration to America \"before the continents drifted apart\". At this point, the group called itself \"Yamassee Native American Moors of the Creek Nation\". During the early 2000s, York presided at Tama-Re styled as \"Our Own Pharoah NETER A'aferti Atum-Re\", leader and chief mystagogue of \"The Ancient Egiptian Order.\"\n\nInitially the Nuwaubians were considered eccentric but tolerable. But tensions increased locally when they distributed leaflets attacking whites and claiming racial persecution in a zoning conflict. They had set up a nightclub in a warehouse on their property. They alienated many residents of the area, both black and white.\n\nTensions with county authorities increased in 1998, when the county sought an injunction against construction and uses that violated zoning. At the same time, the Nuwaubian community increased its leafletting of Eatonton and surrounding areas, charging white officials with racial discrimination and striving to increase opposition to them. Threats mounted and an eviscerated dog carcass was left at the home of the county attorney.\n\nWithin Putnam County, the Nuwaubians lost black support, in part by trying to take over the NAACP chapter. But outside, they appealed to national activists, claiming to be racially persecuted in the county. During this period, the group maintained Holy Tabernacle stores \"in more than a dozen cities in the U.S., the United Kingdom and Trinidad,\" and continued to gain revenues from them. York purchased a $557,000 mansion for his own use in Athens, Georgia, about 60 miles away, where the University of Georgia is located.\n\nIn 2001, the group put up their own candidates, associated with the Republican Party, for public office, including sheriff. Their candidates were defeated.\n\nIn conjunction with a Nuwaubian Nation parade held in Augusta, Georgia in February 2001, the office of Augusta mayor Bob Young (1999–2005) published a proclamation written by the Nuwaubian organization, stating the group's beliefs. Quotes include \"the Nuwbuns were the dark, brown-to-black-skin, wooly-hair original Eygyptians.\" \"[T]he Black race's greatness has been accepted in America and many books as people of Timbuktu Africa or the Olmecians from Uganda, Africa, who migrated and walked here to North and South America to set up colonies way before the continental drift.\"\n\nIn an interview with a reporter from \"The Augusta Chronicle,\" Mayor Young said that he had not personally read the statement prior to its release. He explained that his office customarily releases proclamations drafted and submitted for publication by civic groups without subjecting them to substantial content review. He suggested that such proclamations do not constitute official positions of the mayor's office or statements of the mayor's views.\n\nOn May 8, 2002, Tama-Re was raided by a joint force of FBI and ATF agents, state police, and local law enforcement. Although there were fears that the raid would end in violence, no shots were fired during the operation, although tear gas was used by the FBI's Hostage Rescue Team. \n\nYork, along with his wife, was arrested outside of the property the same day on federal charges of child molestation and racketeeering, including transport of minors for sexual use. He was convicted in 2004 by a jury in federal court and sentenced to 135 years in federal prison. His appeal failed, and the US Supreme Court declined to hear the last appeal. Tama-Re was sold in asset forfeiture under the verdict, and the new owners demolished the structures. With the revelations of York's conduct, many followers abandoned the group, although some factions of the Nuwaubian Nation still exist.\nYork is currently incarcerated in ADX Florence, a maximum-security federal prison in Florence, Colorado. He will be eligible for parole in 2122.\n\nIn 2004, seven officers of the Macon, Georgia police department resigned from their jobs in protest against the prosecution of York. Five of those officers were later hired by the Clarke County, Georgia jail as guards. Four of them were fired in 2006 (the fifth resigned) in the wake of charges that they were smuggling Nuwaubianist literature into the jail, corresponding with the prisoner York, encouraging inmates to rebel against white guards, and showing favoritism to Nuwaubian prisoners. The jail commander was fired after he began an investigation of Nuwaubianist influence at the jail. He has said he believes that he was fired because he undertook this investigation.\n\nAs \"Dr. York,\" the movement leader was active as a vocalist and music producer in Brooklyn before leaving the area. During this time, his Nuwaubian teachings had an effect upon hip hop and Black culture in New York. Journalist Adam Heimlich of the \"New York Press\" suggested the following were influenced by York: Jaz-O, Doug E. Fresh, Afrika Bambaataa, Kelvin Mercer (Posdnuos) from De La Soul, Prodigy from Mobb Deep, and MF Doom.\n\nIn his article on York's cult, Heimlich reviewed some of the leader's published works. He wrote that York had borrowed from a variety of sources for his ideas:\n\nAmong the indie hip hop ranks, there are Nuwaubians who perform what they call Nu-wop, such as Daddi Kuwsh, Twinity, Nefu Amun Hotep, 9thScientist, Scienz of Life, Ntelek, Jedi Mind Tricks, Aslaam Mahdi, 720 Pure Sufi, Tos El Bashir and The Lost Children of Babylon. On Where Light's \"Swords of Malachai\", Rasul lets loose: 'When my tongue swings in the form of a double-edged sword, it brings forth Nuwaubu, which is right Knowledge, wisdom and understanding.'\"\n\nIn an article for \"Honor Nation,\" A. L. JakeAl Reum speculated that the controversial Native American kitsch costumes and props from OutKast's 46th Annual Grammy Awards performance in 2004 were inspired by the Nuwaubian belief about the Native Americans being \"Moors\" in origin.\n\nSouthern Poverty Law Center described the Nuwaubianism belief system as \"mix[ing] black supremacist ideas with worship of the Egyptians and their pyramids, a belief in UFOs and various conspiracies related to the Illuminati and the Bilderbergers\" and quoted York's letter dated Nov. 10, 2004 as: \"The Caucasian has not been chosen to lead the world. They lack true emotions in their creation. We never intended them to be peaceful. They were bred to be killers, with low reproduction levels and a short life span.\" Another explanation has Caucasians descend from Cain: \"Adam and Eve were sent to the Aegean Islands between Asia and Europe, where they started having children, and each couple's first born child was an Albino and those Albinos are called Cain in the Bible, and Cain is short for Caucasian.\"\n\nIn 1994 Ghazi Y. Khankan, director of the New York office of the Council on American–Islamic Relations, commented about York and his group based on their history in Brooklyn. He said, \"It's a cult, in my opinion, and in Islam there are no cults. They consider their leader a prophet, which means they have deviated from the Islamic way.\" The superficial similarity of York's beliefs to those of the Heaven's Gate cult led to some worried newspaper articles after that group's mass suicide during the appearance of Comet Hale–Bopp in 1997, in which the cult was reported to have said that a spacecraft was following the comet.\n\nYork taught a number of \"revealing\" pseudo-etymologies of English words, for instance:\n\n\n\n"}
{"id": "620396", "url": "https://en.wikipedia.org/wiki?curid=620396", "title": "Origin of language", "text": "Origin of language\n\nThe evolutionary emergence of language in the human species has been a subject of speculation for several centuries. The topic is difficult to study because of the lack of direct evidence. Consequently, scholars wishing to study the origins of language must draw inferences from other kinds of evidence such as the fossil record, archaeological evidence, contemporary language diversity, studies of language acquisition, and comparisons between human language and systems of communication existing among animals (particularly other primates). Many argue that the origins of language probably relate closely to the origins of modern human behavior, but there is little agreement about the implications and directionality of this connection.\n\nThis shortage of empirical evidence has led many scholars to regard the entire topic as unsuitable for serious study. In 1866, the Linguistic Society of Paris banned any existing or future debates on the subject, a prohibition which remained influential across much of the western world until late in the twentieth century. Today, there are various hypotheses about how, why, when, and where language might have emerged. Despite this, there is scarcely more agreement today than a hundred years ago, when Charles Darwin's theory of evolution by natural selection provoked a rash of armchair speculation on the topic. Since the early 1990s, however, a number of linguists, archaeologists, psychologists, anthropologists, and others have attempted to address with new methods what some consider one of the hardest problems in science.\n\nOne can sub-divide approaches to the origin of language according to some underlying assumptions:\n\n\nNoam Chomsky, a prominent proponent of discontinuity theory, argues that a single chance mutation occurred in one individual in the order of 100,000 years ago, installing the language faculty (a component of the mid-brain) in \"perfect\" or \"near-perfect\" form. \nA majority of linguistic scholars hold continuity-based theories, but they vary in how they envision language development. Among those who see language as mostly innate, some—notably Steven Pinker—avoid speculating about specific precursors in nonhuman primates, stressing simply that the language faculty must have evolved in the usual gradual way. Others in this intellectual camp—notably Ib Ulbæk—hold that language evolved not from primate communication but from primate cognition, which is significantly more complex.\n\nThose who see language as a socially learned tool of communication, such as Michael Tomasello, see it developing from the cognitively controlled aspects of primate communication, these being mostly gestural as opposed to vocal. Where vocal precursors are concerned, many continuity theorists envisage language evolving from early human capacities for song.\n\nTranscending the continuity-versus-discontinuity divide, some scholars view the emergence of language as the consequence of some kind of social transformation that, by generating unprecedented levels of public trust, liberated a genetic potential for linguistic creativity that had previously lain dormant. \"Ritual/speech coevolution theory\" exemplifies this approach. Scholars in this intellectual camp point to the fact that even chimpanzees and bonobos have latent symbolic capacities that they rarely—if ever—use in the wild. Objecting to the sudden mutation idea, these authors argue that even if a chance mutation were to install a language organ in an evolving bipedal primate, it would be adaptively useless under all known primate social conditions. A very specific social structure—one capable of upholding unusually high levels of public accountability and trust—must have evolved before or concurrently with language to make reliance on \"cheap signals\" (words) an evolutionarily stable strategy.\n\nBecause the emergence of language lies so far back in human prehistory, the relevant developments have left no direct historical traces; neither can comparable processes be observed today. Despite this, the emergence of new sign languages in modern times—Nicaraguan Sign Language, for example—may potentially offer insights into the developmental stages and creative processes necessarily involved. Another approach inspects early human fossils, looking for traces of physical adaptation to language use. In some cases, when the DNA of extinct humans can be recovered, the presence or absence of genes considered to be language-relevant —FOXP2, for example—may prove informative. Another approach, this time archaeological, involves invoking symbolic behavior (such as repeated ritual activity) that may leave an archaeological trace—such as mining and modifying ochre pigments for body-painting—while developing theoretical arguments to justify inferences from symbolism in general to language in particular.\n\nThe time range for the evolution of language and/or its anatomical prerequisites extends, at least in principle, from the phylogenetic divergence of \"Homo\" (2.3 to 2.4 million years ago) from \"Pan\" (5 to 6 million years ago) to the emergence of full behavioral modernity some 50,000–150,000 years ago. Few dispute that \"Australopithecus\" probably lacked vocal communication significantly more sophisticated than that of great apes in general, but scholarly opinions vary as to the developments since the appearance of \"Homo\" some 2.5 million years ago. Some scholars assume the development of primitive language-like systems (\"proto-language\") as early as \"Homo habilis\", while others place the development of symbolic communication only with \"Homo erectus\" (1.8 million years ago) or with \"Homo heidelbergensis\" (0.6 million years ago) and the development of language proper with \"Homo sapiens,\" currently estimated at less than 200,000 years ago.\n\nUsing statistical methods to estimate the time required to achieve the current spread and diversity in modern languages, Johanna Nichols—a linguist at the University of California, Berkeley—argued in 1998 that vocal languages must have begun diversifying in our species at least 100,000 years ago. A further study by Q. D. Atkinson suggests that successive population bottlenecks occurred as our African ancestors migrated to other areas, leading to a decrease in genetic and phenotypic diversity. Atkinson argues that these bottlenecks also affected culture and language, suggesting that the further away a particular language is from Africa, the fewer phonemes it contains. By way of evidence, Atkinson claims that today's African languages tend to have relatively large numbers of phonemes, whereas languages from areas in Oceania (the last place to which humans migrated), have relatively few. Relying heavily on Atkinson's work, a subsequent study has explored the rate at which phonemes develop naturally, comparing this rate to some of Africa's oldest languages. The results suggest that language first evolved around 50,000–150,000 years ago, which is around the time when modern \"Homo sapiens\" evolved. Estimates of this kind are not universally accepted, but jointly considering genetic, archaeological, palaeontological and much other evidence indicates that language probably emerged somewhere in sub-Saharan Africa during the Middle Stone Age, roughly contemporaneous with the speciation of \"Homo sapiens.\"\n\n In 1861, historical linguist Max Müller published a list of speculative theories concerning the origins of spoken language:\n\n\nMost scholars today consider all such theories not so much wrong—they occasionally offer peripheral insights—as naïve and irrelevant. The problem with these theories is that they are so narrowly mechanistic. They assume that once our ancestors had stumbled upon the appropriate ingenious \"mechanism\" for linking sounds with meanings, language automatically evolved and changed.\n\nFrom the perspective of signalling theory, the main obstacle to the evolution of language-like communication in nature is not a mechanistic one. Rather, it is the fact that symbols—arbitrary associations of sounds or other perceptible forms with corresponding meanings—are unreliable and may well be false. As the saying goes, \"words are cheap\". The problem of reliability was not recognized at all by Darwin, Müller or the other early evolutionary theorists.\n\nAnimal vocal signals are, for the most part, intrinsically reliable. When a cat purrs, the signal constitutes direct evidence of the animal's contented state. We trust the signal, not because the cat is inclined to be honest, but because it just cannot fake that sound. Primate vocal calls may be slightly more manipulable, but they remain reliable for the same reason—because they are hard to fake. Primate social intelligence is \"Machiavellian\"—self-serving and unconstrained by moral scruples. Monkeys and apes often attempt to deceive each other, while at the same time remaining constantly on guard against falling victim to deception themselves. Paradoxically, it is theorized that primates' resistance to deception is what blocks the evolution of their signalling systems along language-like lines. Language is ruled out because the best way to guard against being deceived is to ignore all signals except those that are instantly verifiable. Words automatically fail this test.\n\nWords are easy to fake. Should they turn out to be lies, listeners will adapt by ignoring them in favor of hard-to-fake indices or cues. For language to work, then, listeners must be confident that those with whom they are on speaking terms are generally likely to be honest. A peculiar feature of language is \"displaced reference\", which means reference to topics outside the currently perceptible situation. This property prevents utterances from being corroborated in the immediate \"here\" and \"now\". For this reason, language presupposes relatively high levels of mutual trust in order to become established over time as an evolutionarily stable strategy. This stability is born of a longstanding mutual trust and is what grants language its authority. A theory of the origins of language must therefore explain why humans could begin trusting cheap signals in ways that other animals apparently cannot (see signalling theory).\n\nThe \"mother tongues\" hypothesis was proposed in 2004 as a possible solution to this problem. W. Tecumseh Fitch suggested that the Darwinian principle of 'kin selection'—the convergence of genetic interests between relatives—might be part of the answer. Fitch suggests that languages were originally 'mother tongues'. If language evolved initially for communication between mothers and their own biological offspring, extending later to include adult relatives as well, the interests of speakers and listeners would have tended to coincide. Fitch argues that shared genetic interests would have led to sufficient trust and cooperation for intrinsically unreliable signals—words—to become accepted as trustworthy and so begin evolving for the first time.\n\nCritics of this theory point out that kin selection is not unique to humans. Other primate mothers also share genes with their progeny, as do all other animals, so why is it only humans who speak? Furthermore, it is difficult to believe that early humans restricted linguistic communication to genetic kin: the incest taboo must have forced men and women to interact and communicate with more distant relatives. So even if we accept Fitch's initial premises, the extension of the posited 'mother tongue' networks from close relatives to more distant relatives remains unexplained. Fitch argues, however, that the extended period of physical immaturity of human infants and the postnatal growth of the human brain give the human-infant relationship a different and more extended period of intergenerational dependency than that found in any other species.\n\nIb Ulbæk invokes another standard Darwinian principle—'reciprocal altruism'—to explain the unusually high levels of intentional honesty necessary for language to evolve. 'Reciprocal altruism' can be expressed as the principle that \"if you scratch my back, I'll scratch yours\". In linguistic terms, it would mean that \"if you speak truthfully to me, I'll speak truthfully to you\". Ordinary Darwinian reciprocal altruism, Ulbæk points out, is a relationship established between frequently interacting individuals. For language to prevail across an entire community, however, the necessary reciprocity would have needed to be enforced universally instead of being left to individual choice. Ulbæk concludes that for language to evolve, society as a whole must have been subject to moral regulation.\n\nCritics point out that this theory fails to explain when, how, why or by whom 'obligatory reciprocal altruism' could possibly have been enforced. Various proposals have been offered to remedy this defect. A further criticism is that language doesn't work on the basis of reciprocal altruism anyway. Humans in conversational groups don't withhold information to all except listeners likely to offer valuable information in return. On the contrary, they seem to want to advertise to the world their access to socially relevant information, broadcasting that information without expectation of reciprocity to anyone who will listen.\n\nGossip, according to Robin Dunbar in his book \"Grooming, Gossip and the Evolution of Language\", does for group-living humans what manual grooming does for other primates—it allows individuals to service their relationships and so maintain their alliances on the basis of the principle: \"if you scratch my back, I'll scratch yours\". Dunbar argues that as humans began living in increasingly larger social groups, the task of manually grooming all one's friends and acquaintances became so time-consuming as to be unaffordable. In response to this problem, humans developed 'a cheap and ultra-efficient form of grooming'—\"vocal grooming\". To keep allies happy, one now needs only to 'groom' them with low-cost vocal sounds, servicing multiple allies simultaneously while keeping both hands free for other tasks. Vocal grooming then evolved gradually into vocal language—initially in the form of 'gossip'. Dunbar's hypothesis seems to be supported by the fact that the structure of language shows adaptations to the function of narration in general.\n\nCritics of this theory point out that the very efficiency of 'vocal grooming'—the fact that words are so cheap—would have undermined its capacity to signal commitment of the kind conveyed by time-consuming and costly manual grooming. A further criticism is that the theory does nothing to explain the crucial transition from vocal grooming—the production of pleasing but meaningless sounds—to the cognitive complexities of syntactical speech.\n\nThe ritual/speech coevolution theory was originally proposed by social anthropologist Roy Rappaport before being elaborated by anthropologists such as Chris Knight, Jerome Lewis, Nick Enfield, Camilla Power and Ian Watts. Cognitive scientist and robotics engineer Luc Steels is another prominent supporter of this general approach, as is biological anthropologist/neuroscientist Terrence Deacon.\n\nThese scholars argue that there can be no such thing as a 'theory of the origins of language'. This is because language is not a separate adaptation but an internal aspect of something much wider—namely, human symbolic culture as a whole. Attempts to explain language independently of this wider context have spectacularly failed, say these scientists, because they are addressing a problem with no solution. Can we imagine a historian attempting to explain the emergence of credit cards independently of the wider system of which they are a part? Using a credit card makes sense only if you have a bank account institutionally recognized within a certain kind of advanced capitalist society—one where electronic communications technology and digital computers have already been invented and fraud can be detected and prevented. In much the same way, language would not work outside a specific array of social mechanisms and institutions. For example, it would not work for a nonhuman ape communicating with others in the wild. Not even the cleverest nonhuman ape could make language work under such conditions.\n\nLanguage consists of digital contrasts whose cost is essentially zero. As pure social conventions, signals of this kind cannot evolve in a Darwinian social world — they are a theoretical impossibility. Being intrinsically unreliable, language works only if you can build up a reputation for trustworthiness within a certain kind of society—namely, one where symbolic cultural facts (sometimes called 'institutional facts') can be established and maintained through collective social endorsement. In any hunter-gatherer society, the basic mechanism for establishing trust in symbolic cultural facts is collective \"ritual\". Therefore, the task facing researchers into the origins of language is more multidisciplinary than is usually supposed. It involves addressing the evolutionary emergence of human symbolic culture as a whole, with language an important but subsidiary component.\n\nCritics of the theory include Noam Chomsky, who terms it the 'non-existence' hypothesis—a denial of the very existence of language as an object of study for natural science. Chomsky's own theory is that language emerged in an instant and in perfect form, prompting his critics in turn to retort that only something that does not exist—a theoretical construct or convenient scientific fiction—could possibly emerge in such a miraculous way. The controversy remains unresolved.\n\nWhile it is possible to imitate the making of tools like those made by early Homo under circumstances of demonstration, research on primate tool cultures show that non-verbal cultures are vulnerable to environmental change. In particular, if the environment in which a skill can be used disappears for a longer period of time than an individual ape's or early human's lifespan, the skill will be lost if the culture is imitative and non-verbal. Chimpanzees, macaques and capuchin monkeys are all known to lose tool techniques under such circumstances. Researchers on primate culture vulnerability therefore argue that since early Homo species as far back as Homo habilis retained their tool cultures despite many climate change cycles at the timescales of centuries to millennia each, these species had sufficiently developed language abilities to verbally describe complete procedures, and therefore grammar and not only two-word \"proto-language\".\n\nThe theory that early Homo species had sufficiently developed brains for grammar is also supported by researchers who study brain development in children, noting that grammar is developed while connections across the brain are still significantly lower than adult level. These researchers argue that these lowered system requirements for grammatical language make it plausible that the genus Homo had grammar at connection levels in the brain that were significantly lower than those of Homo sapiens and that more recent steps in the evolution of the human brain were not about language.\n\nStructural linguistics is an approach to the study of language founded by Ferdinand de Saussure and popularised through his posthumously published book \"Course in General Linguistics\" (1916).\n\nAccording to structural anthropologist Claude Lévi-Strauss, language and meaning—in opposition to \"knowledge, which develops slowly and progressively\"—must have appeared in an instant:\n\nWhatever may have been the moment and the circumstances of its appearance in the ascent of animal life, language can only have arisen all at once. Things cannot have begun to signify gradually. In the wake of a transformation which is not a subject of study for the social sciences, but for biology and psychology, a shift occurred from a stage when nothing had a meaning to another stage when everything had meaning.\n\nLévi-Strauss's hypothesis is a necessary consequence of Saussure's view of language as a formal system of differential elements: if a signifier only acquires meaning through its difference from other signifiers, then a hypothetical \"first signifier\" always already implies another signifier (\"everything else\" or \"the rest of the universe\") from which the first signifier is different. Thus, language, according to structuralism, must have appeared all at once and not gradually since a semi-language is impossible.\n\nAccording to Chomsky's single mutation theory, the emergence of language resembled the formation of a crystal; with digital infinity as the seed crystal in a super-saturated primate brain, on the verge of blossoming into the human mind, by physical law, once evolution added a single small but crucial keystone. Whilst some suggest it follows from this theory that language appeared rather suddenly within the history of human evolution, Chomsky, writing with computational linguist and computer scientist Robert C. Berwick, suggests it is completely compatible with modern biology. They note \"none of the recent accounts of human language evolution seem to have completely grasped the shift from conventional Darwinism to its fully stochastic modern version—specifically, that there are stochastic effects not only due to sampling like directionless drift, but also due to directed stochastic variation in fitness, migration, and heritability—indeed, all the \"forces\" that affect individual or gene frequencies. ... All this can affect evolutionary outcomes—outcomes that as far as we can make out are not brought out in recent books on the evolution of language, yet would arise immediately in the case of any new genetic or individual innovation, precisely the kind of scenario likely to be in play when talking about language's emergence.\"\n\nCiting evolutionary geneticist Svante Pääbo they concur that a substantial difference must have occurred to differentiate \"Homo sapiens\" from Neanderthals to \"prompt the relentless spread of our species who had never crossed open water up and out of Africa and then on across the entire planet in just a few tens of thousands of years. ... What we do not see is any kind of \"gradualism\" in new tool technologies or innovations like fire, shelters, or figurative art.\" Berwick and Chomsky therefore suggest language emerged approximately between 200,000 years ago and 60,000 years ago (between the arrival of the first anatomically modern humans in southern Africa, and the last exodus from Africa, respectively). \"That leaves us with about 130,000 years, or approximately 5,000–6,000 generations of time for evolutionary change. This is not 'overnight in one generation' as some have (incorrectly) inferred—but neither is it on the scale of geological eons. It's time enough—within the ballpark for what Nilsson and Pelger (1994) estimated as the time required for the full evolution of a vertebrate eye from a single cell, even without the invocation of any 'evo-devo' effects.\"\n\nThe gestural theory states that human language developed from gestures that were used for simple communication.\n\nTwo types of evidence support this theory.\n\nResearch has found strong support for the idea that verbal language and sign language depend on similar neural structures. Patients who used sign language, and who suffered from a left-hemisphere lesion, showed the same disorders with their sign language as vocal patients did with their oral language. Other researchers found that the same left-hemisphere brain regions were active during sign language as during the use of vocal or written language.\n\nPrimate gesture is at least partially genetic: different nonhuman apes will perform gestures characteristic of their species, even if they have never seen another ape perform that gesture. For example, gorillas beat their breasts. This shows that gestures are an intrinsic and important part of primate communication, which supports the idea that language evolved from gesture.\n\nFurther evidence suggests that gesture and language are linked. In humans, manually gesturing has an effect on concurrent vocalizations, thus creating certain natural vocal associations of manual efforts. Chimpanzees move their mouths when performing fine motor tasks. These mechanisms may have played an evolutionary role in enabling the development of intentional vocal communication as a supplement to gestural communication. Voice modulation could have been prompted by preexisting manual actions.\n\nThere is also the fact that, from infancy, gestures both supplement and predict speech. This addresses the idea that gestures quickly change in humans from a sole means of communication (from a very young age) to a supplemental and predictive behavior that we use despite being able to communicate verbally. This too serves as a parallel to the idea that gestures developed first and language subsequently built upon it.\n\nTwo possible scenarios have been proposed for the development of language, one of which supports the gestural theory:\nThe first perspective that language evolved from the calls of our ancestors seems logical because both humans and animals make sounds or cries. One evolutionary reason to refute this is that, anatomically, the center that controls calls in monkeys and other animals is located in a completely different part of the brain than in humans. In monkeys, this center is located in the depths of the brain related to emotions. In the human system, it is located in an area unrelated to emotion. Humans can communicate simply to communicate—without emotions. So, anatomically, this scenario does not work. Therefore, we resort to the idea that language was derived from gesture (we communicated by gesture first and sound was attached later).\n\nThe important question for gestural theories is why there was a shift to vocalization. Various explanations have been proposed: \nA comparable hypothesis states that in 'articulate' language, gesture and vocalisation are intrinsically linked, as language evolved from equally intrinsically linked dance and song.\nHumans still use manual and facial gestures when they speak, especially when people meet who have no language in common. There are also, of course, a great number of sign languages still in existence, commonly associated with deaf communities. These sign languages are equal in complexity, sophistication, and expressive power, to any oral language. The cognitive functions are similar and the parts of the brain used are similar. The main difference is that the \"phonemes\" are produced on the outside of the body, articulated with hands, body, and facial expression, rather than inside the body articulated with tongue, teeth, lips, and breathing. (Compare the motor theory of speech perception.)\n\nCritics of gestural theory note that it is difficult to name serious reasons why the initial pitch-based vocal communication (which is present in primates) would be abandoned in favor of the much less effective non-vocal, gestural communication. However, Michael Corballis has pointed out that it is supposed that primate vocal communication (such as alarm calls) cannot be controlled consciously, unlike hand movement, and thus is not credible as precursor to human language; primate vocalization is rather homologous to and continued in involuntary reflexes (connected with basic human emotions) such as screams or laughter (the fact that these can be faked does not disprove the fact that genuine involuntary responses to fear or surprise exist). Also, gesture is not generally less effective, and depending on the situation can even be advantageous, for example in a loud environment or where it is important to be silent, such as on a hunt. Other challenges to the \"gesture-first\" theory have been presented by researchers in psycholinguistics, including David McNeill.\n\nProponents of the motor theory of language evolution have primarily focused on the visual domain and communication through observation of movements. The \"Tool-use sound hypothesis\" suggests that the production and perception of sound also contributed substantially, particularly \"incidental sound of locomotion\" (\"ISOL\") and \"tool-use sound\" (\"TUS\"). Human bipedalism resulted in rhythmic and more predictable \"ISOL\". That may have stimulated the evolution of musical abilities, auditory working memory, and abilities to produce complex vocalizations, and to mimic natural sounds. Since the human brain proficiently extracts information about objects and events from the sounds they produce, \"TUS\", and mimicry of \"TUS\", might have achieved an iconic function. The prevalence of sound symbolism in many extant languages supports this idea. Self-produced TUS activates multimodal brain processing (motor neurons, hearing, proprioception, touch, vision), and \"TUS\" stimulates primate audiovisual mirror neurons, which is likely to stimulate the development of association chains. Tool use and auditory gestures involve motor-processing of the forelimbs, which is associated with the evolution of vertebrate vocal communication. The production, perception, and mimicry of \"TUS\" may have resulted in a limited number of vocalizations or protowords that were associated with tool use. A new way to communicate about tools, especially when out of sight, would have had selective advantage. A gradual change in acoustic properties and/or meaning could have resulted in arbitrariness and an expanded repertoire of words. Humans have been increasingly exposed to \"TUS\" over millions of years, coinciding with the period during which spoken language evolved.\n\nIn humans, functional MRI studies have reported finding areas homologous to the monkey mirror neuron system in the inferior frontal cortex, close to Broca's area, one of the language regions of the brain. This has led to suggestions that human language evolved from a gesture performance/understanding system implemented in mirror neurons. Mirror neurons have been said to have the potential to provide a mechanism for action-understanding, imitation-learning, and the simulation of other people's behavior. This hypothesis is supported by some cytoarchitectonic homologies between monkey premotor area F5 and human Broca's area. Rates of vocabulary expansion link to the ability of children to vocally mirror non-words and so to acquire the new word pronunciations. Such speech repetition occurs automatically, quickly and separately in the brain to speech perception. Moreover, such vocal imitation can occur without comprehension such as in speech shadowing and echolalia. Further evidence for this link comes from a recent study in which the brain activity of two participants was measured using fMRI while they were gesturing words to each other using hand gestures with a game of charades—a modality that some have suggested might represent the evolutionary precursor of human language. Analysis of the data using Granger Causality revealed that the mirror-neuron system of the observer indeed reflects the pattern of activity of in the motor system of the sender, supporting the idea that the motor concept associated with the words is indeed transmitted from one brain to another using the mirror system.\n\nNot all linguists agree with the above arguments, however. In particular, supporters of Noam Chomsky argue against the possibility that the mirror neuron system can play any role in the hierarchical recursive structures essential to syntax.\n\nAccording to Dean Falk's 'putting the baby down' theory, vocal interactions between early hominid mothers and infants sparked a sequence of events that led, eventually, to our ancestors' earliest words. The basic idea is that evolving human mothers, unlike their counterparts in other primates, couldn't move around and forage with their infants clinging onto their backs. Loss of fur in the human case left infants with no means of clinging on. Frequently, therefore, mothers had to put their babies down. As a result, these babies needed to be reassured that they were not being abandoned. Mothers responded by developing 'motherese'—an infant-directed communicative system embracing facial expressions, body language, touching, patting, caressing, laughter, tickling and emotionally expressive contact calls. The argument is that language somehow developed out of all this.\n\nIn \"The Mental and Social Life of Babies\", psychologist Kenneth Kaye noted that no usable adult language could have evolved without interactive communication between very young children and adults. \"No symbolic system could have survived from one generation to the next if it could not have been easily acquired by young children under their normal conditions of social life.\"\n\nThe ‘from where to what’ model is a language evolution model that is derived primarily from the organization of language processing in the brain. According to recent models, language is processed in 2 separate pathways: the auditory ventral stream (red arrows in figure) and auditory dorsal stream (blue arrows in figure). The auditory ventral stream passes from the anterior auditory cortex to the temporal pole and from there to the inferior frontal gyrus (Broca’s area). The role of this pathway is established with sound recognition in both humans and other primates (and is accordingly known as the ‘auditory what pathway’). The auditory dorsal stream passes from the posterior auditory cortex to the inferior parietal lobule and from there to the inferior frontal gyrus. This pathway was traditionally called the Wernicke-Broca pathway. Whereas in non-human primates this pathway is responsible only for sound localization (and is known as the auditory ‘where’ pathway’), in humans it has several additional functions, such as: speech repetition and production, audio-visual integration (Such as during lip-reading), perception and production of intonations, phonological long-term memory (long-term memory storage for the names of words) and phonological working memory (temporary storage of the names of words). Some evidence also indicates a role in discrimination of individuals by their voices. In accordance with the ‘from where to what’ model, each of these functions of the auditory dorsal stream indicates of an intermediate stage in the evolution of language. Supporting the hypothesis that developments of the auditory dorsal stream resulted with the emergence of language is a diffusion imaging study that compared macaque monkeys, chimpanzees and humans and reported of strengthening of the auditory dorsal stream from monkeys to chimpanzees and from chimpanzees to humans, whereas little changes are noted for the auditory ventral stream between the three species. A study that compared the skulls of early members of the species homo (Homo habilis) to their predecessors (Australopithecus) and to contemporary apes reported only of increase in size of the auditory dorsal stream (inferior parietal lobule and inferior frontal gyrus).\n\nThe ‘from where to what’ model argues that the co-localization of sound localization, audio-visual integration and discrimination of voices is evidence that speech originated for the purpose of exchanging contact calls (stage 1 in figure). These calls are used by con-specifics in order to announce to the troop of their presence or location. In this scenario, speech could have began when a mother and offspring accidentally separated in the forest, and the two took turns emitting contact calls until they were re-united. This model is consistent with studies that induced mutations in mice to genes that cause speech dyspraxia in humans (FOXP2, SRPX2) and resulted with infant mice no longer emitting contact calls with their mothers. Like human speech, the detection and emission of contact call in monkeys is also left hemisphere dominant and lesion to the left, but not right, hemisphere interfered with the discrimination of contact calls. Further demonstrating the role of the auditory dorsal stream are studies of marmoset monkeys that sacrificed monkeys after hearing a contact call, emitting a contact call or both. The researchers reported of significant increase in the number of active neurons in the auditory dorsal stream when the monkeys heard and then responded to contact calls. Studies that recorded activity from the inferior frontal gyrus of monkeys also reported of activity immediately prior to emitting a contact call. \n\nContact calls are similar to human speech as they are both vocal and practice turn taking. However, the contact calls of monkeys and apes are mostly rigid in their structure (although Masataka reported of infant macaque monkeys learning to modify the pitch of their contact call to imitate mothers; and Hihara reported of macaque monkeys learning to use contact call to request specific objects). A possible transition from contact call to speech is that due to a mutation in the auditory dorsal stream, early hominans (i.e., Homo habilis) became capable of modifying the contact calls with intonations (stage 2 in figure). This enabled infants to emit two types of contact calls, one that signals the mother the infant is safe but desires her attention and another that signals immediate danger. Such a development would have provided the mother with an advantage as it informs her whether she needs to drop everything she carries and rush to the baby, or she can take her time. As generations passed and vocal control improved, mothers and offspring became capable of communicating with very simple yes-no question answer conversations (stage 3 in figure). In such a scenario, a baby is emitting a low-level distress call to signal desire to eat berries, and the mother responding with a low-level distress call to permit the activity or high-level distress call to prohibit it. This use of intonations in order to emit two types of calls, one for low level of distress and another for high level of distress could explain why humans today use intonations to transform words into questions or commands (for example, converting the word ‘food’ into a question or command with different intonations). Consistent with this model, a study that examined patients with deterioration of the auditory dorsal stream (phonological dementia) reported of impaired ability to discriminate questions from statements using intonations. Similarly, a study that used diffused weighted imaging to identify the auditory ventral and dorsal streams in healthy people reported that interfering with the auditory dorsal stream using TMS resulted with individuals failing to discriminate questions from statements using intonations. \n\nIn a follow up article, based on the roles of the auditory dorsal stream in vocal mimicry, lip-reading and phonological working memory and long-term memory, a few additional intermediate stages in the evolution of language are proposed. In accordance with the model, as generations passed, vocal control increased from just modifying calls with intonations to emitting novel calls (stage 4 in figure). During this time, infants learned these call by imitating their parents’ lip-movements (stage 5 in figure). This hypothesis explains the role of the auditory dorsal stream in many studies of lip-speech integration as occurs in lip-reading. A role for reading lips as a mean for the acquisition of novel calls can also explain the distinctive large human lips, which are not found with other apes. Supporting the model are studies of patients with damage to the auditory dorsal stream that were reported with impaired ability to repeat sentences and nonsense words (conduction aphasia), or impaired ability to name objects (anomia).\n\nLearning calls by offspring imitating the lip-movements of their parents eventually reached a maximum limit of efficiency. At this point, the offspring were able to learn new vocalizations soon after hearing them, and the memory lasted for their entire life (stage 6 in figure). Such a transition could explain the tendency of babies, at their first year, to mimic their parents by imitating their lip-movements and that after the first year this mimicry process ends. New calls, such as foreign phonemes, learned after the first few years are also much more challenging to learn. The development of a memory store for vocalizations in the parietal lobe of the auditory dorsal stream could have provided the neurological infra-structure for rehearsing lists of calls, thus resulting with poly-syllabic words (stage 7 in figure). Eventually the rehearsal of lists of syllables enabled the rehearsal of lists of words, which made the communication with sentences possible. \n\n'Grammaticalisation' is a continuous historical process in which free-standing words develop into grammatical appendages, while these in turn become ever more specialized and grammatical. An initially 'incorrect' usage, in becoming accepted, leads to unforeseen consequences, triggering knock-on effects and extended sequences of change. Paradoxically, grammar evolves because, in the final analysis, humans care less about grammatical niceties than about making themselves understood. If this is how grammar evolves today, according to this school of thought, we can legitimately infer similar principles at work among our distant ancestors, when grammar itself was first being established.\n\nIn order to reconstruct the evolutionary transition from early language to languages with complex grammars, we need to know which hypothetical sequences are plausible and which are not. In order to convey abstract ideas, the first recourse of speakers is to fall back on immediately recognizable concrete imagery, very often deploying metaphors rooted in shared bodily experience. A familiar example is the use of concrete terms such as 'belly' or 'back' to convey abstract meanings such as 'inside' or 'behind'. Equally metaphorical is the strategy of representing temporal patterns on the model of spatial ones. For example, English speakers might say 'It is going to rain,' modeled on 'I am going to London.' This can be abbreviated colloquially to 'It's gonna rain.' Even when in a hurry, we don't say 'I'm gonna London'—the contraction is restricted to the job of specifying tense. From such examples we can see why grammaticalization is consistently unidirectional—from concrete to abstract meaning, not the other way around.\n\nGrammaticalization theorists picture early language as simple, perhaps consisting only of nouns. Even under that extreme theoretical assumption, however, it is difficult to imagine what would realistically have prevented people from using, say, 'spear' as if it were a verb ('Spear that pig!'). People might have used their nouns as verbs or their verbs as nouns as occasion demanded. In short, while a noun-only language might seem theoretically possible, grammaticalization theory indicates that it cannot have remained fixed in that state for any length of time.\n\nCreativity drives grammatical change. This presupposes a certain attitude on the part of listeners. Instead of punishing deviations from accepted usage, listeners must prioritize imaginative mind-reading. Imaginative creativity—emitting a leopard alarm when no leopard was present, for example—is not the kind of behavior which, say, vervet monkeys would appreciate or reward. Creativity and reliability are incompatible demands; for 'Machiavellian' primates as for animals generally, the overriding pressure is to demonstrate reliability. If humans escape these constraints, it is because in our case, listeners are primarily interested in mental states.\n\nTo focus on mental states is to accept fictions—inhabitants of the imagination—as potentially informative and interesting. Take the use of metaphor. A metaphor is, literally, a false statement. Think of Romeo's declaration, 'Juliet is the sun!' Juliet is a woman, not a ball of plasma in the sky, but human listeners are not (or not usually) pedants insistent on point-by-point factual accuracy. They want to know what the speaker has in mind. Grammaticalization is essentially based on metaphor. To outlaw its use would be to stop grammar from evolving and, by the same token, to exclude all possibility of expressing abstract thought.\n\nA criticism of all this is that while grammaticalization theory might explain language change today, it does not satisfactorily address the really difficult challenge—explaining the initial transition from primate-style communication to language as we know it. Rather, the theory assumes that language already exists. As Bernd Heine and Tania Kuteva acknowledge: \"Grammaticalization requires a linguistic system that is used regularly and frequently within a community of speakers and is passed on from one group of speakers to another\". Outside modern humans, such conditions do not prevail.\n\nHuman language is used for self-expression; however, expression displays different stages. The consciousness of self and feelings represents the stage immediately prior to the external, phonetic expression of feelings in the form of sound, i.e., language. Intelligent animals such as dolphins, Eurasian magpies, and chimpanzees live in communities, wherein they assign themselves roles for group survival and show emotions such as sympathy. When such animals view their reflection (mirror test), they recognize themselves and exhibit self-consciousness. Notably, humans evolved in a quite different environment than that of these animals. Human survival became easier with the development of tools, shelter, and fire, thus facilitating further advancement of interaction, self-expression, and tool-making. The increasing brain size allowed advanced provisioning and tools and the technological advances during the Palaeolithic era that built upon the previous evolutionary innovations of bipedalism and hand versatility allowed the development of human language.\n\nAccording to a study investigating the song differences between white-rumped munias and its domesticated counterpart (Bengalese finch), the wild munias use a highly stereotyped song sequence, whereas the domesticated ones sing a highly unconstrained song. In wild finches, song syntax is subject to female preference—sexual selection—and remains relatively fixed. However, in the Bengalese finch, natural selection is replaced by breeding, in this case for colorful plumage, and thus, decoupled from selective pressures, stereotyped song syntax is allowed to drift. It is replaced, supposedly within 1000 generations, by a variable and learned sequence. Wild finches, moreover, are thought incapable of learning song sequences from other finches. In the field of bird vocalization, brains capable of producing only an innate song have very simple neural pathways: the primary forebrain motor center, called the robust nucleus of arcopallium, connects to midbrain vocal outputs, which in turn project to brainstem motor nuclei. By contrast, in brains capable of learning songs, the arcopallium receives input from numerous additional forebrain regions, including those involved in learning and social experience. Control over song generation has become less constrained, more distributed, and more flexible.\n\nOne way to think about human evolution is that we are self-domesticated apes. Just as domestication relaxed selection for stereotypic songs in the finches—mate choice was supplanted by choices made by the aesthetic sensibilities of bird breeders and their customers—so might our cultural domestication have relaxed selection on many of our primate behavioral traits, allowing old pathways to degenerate and reconfigure. Given the highly indeterminate way that mammalian brains develop—they basically construct themselves \"bottom up\", with one set of neuronal interactions setting the stage for the next round of interactions—degraded pathways would tend to seek out and find new opportunities for synaptic hookups. Such inherited de-differentiations of brain pathways might have contributed to the functional complexity that characterizes human language. And, as exemplified by the finches, such de-differentiations can occur in very rapid time-frames.\n\nA distinction can be drawn between speech and language. Language is not necessarily spoken: it might alternatively be written or signed. Speech is among a number of different methods of encoding and transmitting linguistic information, albeit arguably the most natural one.\n\nSome scholars view language as an initially cognitive development, its 'externalisation' to serve communicative purposes occurring later in human evolution. According to one such school of thought, the key feature distinguishing human language is recursion, (in this context, the iterative embedding of phrases within phrases). Other scholars—notably Daniel Everett—deny that recursion is universal, citing certain languages (e.g. Pirahã) which allegedly lack this feature.\n\nThe ability to ask questions is considered by some to distinguish language from non-human systems of communication. Some captive primates (notably bonobos and chimpanzees), having learned to use rudimentary signing to communicate with their human trainers, proved able to respond correctly to complex questions and requests. Yet they failed to ask even the simplest questions themselves. Conversely, human children are able to ask their first questions (using only question intonation) at the babbling period of their development, long before they start using syntactic structures. Although babies from different cultures acquire native languages from their social environment, all languages of the world without exception—tonal, non-tonal, intonational and accented—use similar rising \"question intonation\" for yes–no questions. This fact is a strong evidence of the universality of question intonation. In general, according to some authors, sentence intonation/pitch is pivotal in spoken grammar and is the basic information used by children to learn the grammar of whatever language.\n\nOne of the intriguing abilities that language users have is that of high-level reference (or deixis), the ability to refer to things or states of being that are not in the immediate realm of the speaker. This ability is often related to theory of mind, or an awareness of the other as a being like the self with individual wants and intentions. According to Chomsky, Hauser and Fitch (2002), there are six main aspects of this high-level reference system:\n\n\nSimon Baron-Cohen (1999) argues that theory of mind must have preceded language use, based on evidence of use of the following characteristics as much as 40,000 years ago: intentional communication, repairing failed communication, teaching, intentional persuasion, intentional deception, building shared plans and goals, intentional sharing of focus or topic, and pretending. Moreover, Baron-Cohen argues that many primates show some, but not all, of these abilities. Call and Tomasello's research on chimpanzees supports this, in that individual chimps seem to understand that other chimps have awareness, knowledge, and intention, but do not seem to understand false beliefs. Many primates show some tendencies toward a theory of mind, but not a full one as humans have.\nUltimately, there is some consensus within the field that a theory of mind is necessary for language use. Thus, the development of a full theory of mind in humans was a necessary precursor to full language use.\n\nIn one particular study, rats and pigeons were required to press a button a certain number of times to get food. The animals showed very accurate distinction for numbers less than four, but as the numbers increased, the error rate increased. Matsuzawa (1985) attempted to teach chimpanzees Arabic numerals. The difference between primates and humans in this regard was very large, as it took the chimps thousands of trials to learn 1–9 with each number requiring a similar amount of training time; yet, after learning the meaning of 1, 2 and 3 (and sometimes 4), children easily comprehend the value of greater integers by using a successor function (i.e. 2 is 1 greater than 1, 3 is 1 greater than 2, 4 is 1 greater than 3; once 4 is reached it seems most children have an \"a-ha!\" moment and understand that the value of any integer \"n\" is 1 greater than the previous integer). Put simply, other primates learn the meaning of numbers one by one, similar to their approach to other referential symbols, while children first learn an arbitrary list of symbols (1, 2, 3, 4...) and then later learn their precise meanings. These results can be seen as evidence for the application of the \"open-ended generative property\" of language in human numeral cognition.\n\nHockett (1966) details a list of features regarded as essential to describing human language. In the domain of the lexical-phonological principle, two features of this list are most important:\n\n\nThe sound system of a language is composed of a finite set of simple phonological items. Under the specific phonotactic rules of a given language, these items can be recombined and concatenated, giving rise to morphology and the open-ended lexicon. A key feature of language is that a simple, finite set of phonological items gives rise to an infinite lexical system wherein rules determine the form of each item, and meaning is inextricably linked with form. Phonological syntax, then, is a simple combination of pre-existing phonological units. Related to this is another essential feature of human language: lexical syntax, wherein pre-existing units are combined, giving rise to semantically novel or distinct lexical items.\n\nCertain elements of the lexical-phonological principle are known to exist outside of humans. While all (or nearly all) have been documented in some form in the natural world, very few coexist within the same species. Bird-song, singing nonhuman apes, and the songs of whales all display phonological syntax, combining units of sound into larger structures apparently devoid of enhanced or novel meaning. Certain other primate species do have simple phonological systems with units referring to entities in the world. However, in contrast to human systems, the units in these primates' systems normally occur in isolation, betraying a lack of lexical syntax. There is new evidence to suggest that Campbell's monkeys also display lexical syntax, combining two calls (a predator alarm call with a \"boom\", the combination of which denotes a lessened threat of danger), however it is still unclear whether this is a lexical or a morphological phenomenon.\n\nPidgins are significantly simplified languages with only rudimentary grammar and a restricted vocabulary. In their early stage pidgins mainly consist of nouns, verbs, and adjectives with few or no articles, prepositions, conjunctions or auxiliary verbs. Often the grammar has no fixed word order and the words have no inflection.\n\nIf contact is maintained between the groups speaking the pidgin for long periods of time, the pidgins may become more complex over many generations. If the children of one generation adopt the pidgin as their native language it develops into a creole language, which becomes fixed and acquires a more complex grammar, with fixed phonology, syntax, morphology, and syntactic embedding. The syntax and morphology of such languages may often have local innovations not obviously derived from any of the parent languages.\n\nStudies of creole languages around the world have suggested that they display remarkable similarities in grammar and are developed uniformly from pidgins in a single generation. These similarities are apparent even when creoles do not share any common language origins. In addition, creoles share similarities despite being developed in isolation from each other. Syntactic similarities include subject–verb–object word order. Even when creoles are derived from languages with a different word order they often develop the SVO word order. Creoles tend to have similar usage patterns for definite and indefinite articles, and similar movement rules for phrase structures even when the parent languages do not.\n\nField primatologists can give us useful insights into great ape communication in the wild. An important finding is that nonhuman primates, including the other great apes, produce calls that are graded, as opposed to categorically differentiated, with listeners striving to evaluate subtle gradations in signalers' emotional and bodily states. Nonhuman apes seemingly find it extremely difficult to produce vocalizations in the absence of the corresponding emotional states. In captivity, nonhuman apes have been taught rudimentary forms of sign language or have been persuaded to use lexigrams—symbols that do not graphically resemble the corresponding words—on computer keyboards. Some nonhuman apes, such as Kanzi, have been able to learn and use hundreds of lexigrams.\n\nThe Broca's and Wernicke's areas in the primate brain are responsible for controlling the muscles of the face, tongue, mouth, and larynx, as well as recognizing sounds. Primates are known to make \"vocal calls\", and these calls are generated by circuits in the brainstem and limbic system.\n\nIn the wild, the communication of vervet monkeys has been the most extensively studied. They are known to make up to ten different vocalizations. Many of these are used to warn other members of the group about approaching predators. They include a \"leopard call\", a \"snake call\", and an \"eagle call\". Each call triggers a different defensive strategy in the monkeys who hear the call and scientists were able to elicit predictable responses from the monkeys using loudspeakers and prerecorded sounds. Other vocalizations may be used for identification. If an infant monkey calls, its mother turns toward it, but other vervet mothers turn instead toward that infant's mother to see what she will do.\n\nSimilarly, researchers have demonstrated that chimpanzees (in captivity) use different \"words\" in reference to different foods. They recorded vocalizations that chimps made in reference, for example, to grapes, and then other chimps pointed at pictures of grapes when they heard the recorded sound.\n\nA study published in \"Homo: Journal of Comparative Human Biology\" in 2017 claims that \"A. ramidus\", a hominin dated at approximately 4.5Ma, shows the first evidence of an anatomical shift in the hominin lineage suggestive of increased vocal capability. This study compared the skull of \"A. ramidus\" with twenty nine chimpanzee skulls of different ages and found that in numerous features \"A. ramidus\" clustered with the infant and juvenile measures as opposed to the adult measures. Significantly, such affinity with the shape dimensions of infant and juvenile chimpanzee skull architecture was argued may have resulted in greater vocal capability. This assertion was based on the notion that the chimpanzee vocal tract ratios that prevent speech are a result of growth factors associated with puberty—growth factors absent in \"A. ramidus\" ontogeny. \"A. ramidus\" was also found to have a degree of cervical lordosis more conducive to vocal modulation when compared with chimpanzees as well as cranial base architecture suggestive of increased vocal capability.\n\nWhat was significant in this study was the observation that the changes in skull architecture that correlate with reduced aggression are the same changes necessary for the evolution of early hominin vocal ability. In integrating data on anatomical correlates of primate mating and social systems with studies of skull and vocal tract architecture that facilitate speech production, the authors argue that paleoanthropologists to date have failed to grasp the important relationship between early hominin social evolution and language capacity.\n\nWhile the skull of \"A. ramidus\", according to the authors, lacks the anatomical impediments to speech evident in chimpanzees, it is unclear what the vocal capabilities of this early hominin were. While they suggest \"A. ramidus\"—based on similar vocal tract ratios—may have had vocal capabilities equivalent to a modern human infant or very young child, they concede this is obviously a debatable and speculative hypothesis. However, they do claim that changes in skull architecture through processes of social selection were a necessary prerequisite for language evolution. As they write:\n\nRegarding articulation, there is considerable speculation about the language capabilities of early \"Homo\" (2.5 to 0.8 million years ago). Anatomically, some scholars believe features of bipedalism, which developed in australopithecines around 3.5 million years ago, would have brought changes to the skull, allowing for a more L-shaped vocal tract. The shape of the tract and a larynx positioned relatively low in the neck are necessary prerequisites for many of the sounds humans make, particularly vowels.\nOther scholars believe that, based on the position of the larynx, not even Neanderthals had the anatomy necessary to produce the full range of sounds modern humans make. It was earlier proposed that differences between \"Homo sapiens\" and Neanderthal vocal tracts could be seen in fossils, but the finding that the Neanderthal hyoid bone (see below) was identical to that found in \"Homo sapiens\" has weakened these theories. Still another view considers the lowering of the larynx as irrelevant to the development of speech.\n\nSteven Mithen proposed the term \"Hmmmmm\" for the pre-linguistic system of communication used by archaic \"Homo.\" beginning with \"Homo ergaster\" and reaching the highest sophistication in the Middle Pleistocene with \"Homo heidelbergensis\" and \"Homo neanderthalensis.\" \"Hmmmmm\" is an acronym for \"h\"olistic (non-compositional), \"m\"anipulative (utterances are commands or suggestions, not descriptive statements), \"m\"ulti-\"m\"odal (acoustic as well as gestural and facial), \"m\"usical, and \"m\"imetic.\n\n\"Homo heidelbergensis\" was a close relative (most probably a migratory descendant) of \"Homo ergaster.\" Some researchers believe this species to be the first hominin to make controlled vocalizations, possibly mimicking animal vocalizations, and that as \"Homo heidelbergensis\" developed more sophisticated culture, proceeded from this point and possibly developed an early form of symbolic language.\n\nThe discovery in 1989 of the (Neanderthal) Kebara 2 hyoid bone suggests that Neanderthals may have been anatomically capable of producing sounds similar to modern humans. The hypoglossal nerve, which passes through the hypoglossal canal, controls the movements of the tongue, which may have enabled voicing for size exaggeration (see size exaggeration hypothesis below) or may reflect speech abilities.\n\nHowever, although Neanderthals may have been anatomically able to speak, Richard G. Klein in 2004 doubted that they possessed a fully modern language. He largely bases his doubts on the fossil record of archaic humans and their stone tool kit. For 2 million years following the emergence of \"Homo habilis,\" the stone tool technology of hominins changed very little. Klein, who has worked extensively on ancient stone tools, describes the crude stone tool kit of archaic humans as impossible to break down into categories based on their function, and reports that Neanderthals seem to have had little concern for the final aesthetic form of their tools. Klein argues that the Neanderthal brain may have not reached the level of complexity required for modern speech, even if the physical apparatus for speech production was well-developed. The issue of the Neanderthal's level of cultural and technological sophistication remains a controversial one.\n\nBased on computer simulations used to evaluate that evolution of language that resulted in showing three stages in the evolution of syntax, Neanderthals are thought to have been in stage 2, showing they had something more evolved than proto-language but not quite as complex as the language of modern humans.\n\nAnatomically modern humans begin to appear in the fossil record in Ethiopia some 200,000 years ago.\nAlthough there is still much debate as to whether behavioural modernity emerged in Africa at around the same time, a growing number of archaeologists nowadays invoke the southern African Middle Stone Age use of red ochre pigments—for example at Blombos Cave—as evidence that modern anatomy and behaviour co-evolved. These archaeologists argue strongly that if modern humans at this early stage were using red ochre pigments for ritual and symbolic purposes, they probably had symbolic language as well.\n\nAccording to the recent African origins hypothesis, from around 60,000 – 50,000 years ago a group of humans left Africa and began migrating to occupy the rest of the world, carrying language and symbolic culture with them.\n\nThe larynx or voice box is an organ in the neck housing the vocal folds, which are responsible for phonation. In humans, the larynx is \"descended\". Our species is not unique in this respect: goats, dogs, pigs and tamarins lower the larynx temporarily, to emit loud calls. Several deer species have a permanently lowered larynx, which may be lowered still further by males during their roaring displays. Lions, jaguars, cheetahs and domestic cats also do this. However, laryngeal descent in nonhumans (according to Philip Lieberman) is not accompanied by descent of the hyoid; hence the tongue remains horizontal in the oral cavity, preventing it from acting as a pharyngeal articulator.\n\nDespite all this, scholars remain divided as to how \"special\" the human vocal tract really is. It has been shown that the larynx does descend to some extent during development in chimpanzees, followed by hyoidal descent. As against this, Philip Lieberman points out that only humans have evolved permanent and substantial laryngeal descent in association with hyoidal descent, resulting in a curved tongue and two-tube vocal tract with 1:1 proportions. Uniquely in the human case, simple contact between the epiglottis and velum is no longer possible, disrupting the normal mammalian separation of the respiratory and digestive tracts during swallowing. Since this entails substantial costs—increasing the risk of choking while swallowing food—we are forced to ask what benefits might have outweighed those costs. The obvious benefit—so it is claimed—must have been speech. But this idea has been vigorously contested. One objection is that humans are in fact \"not\" seriously at risk of choking on food: medical statistics indicate that accidents of this kind are extremely rare. Another objection is that in the view of most scholars, speech as we know it emerged relatively late in human evolution, roughly contemporaneously with the emergence of \"Homo sapiens.\" A development as complex as the reconfiguration of the human vocal tract would have required much more time, implying an early date of origin. This discrepancy in timescales undermines the idea that human vocal flexibility was \"initially\" driven by selection pressures for speech, thus not excluding that it was selected for e.g. improved singing ability.\n\nTo lower the larynx is to increase the length of the vocal tract, in turn lowering formant frequencies so that the voice sounds \"deeper\"—giving an impression of greater size. John Ohala argues that the function of the lowered larynx in humans, especially males, is probably to enhance threat displays rather than speech itself. Ohala points out that if the lowered larynx were an adaptation for speech, we would expect adult human males to be better adapted in this respect than adult females, whose larynx is considerably less low. In fact, females invariably outperform males in verbal tests, falsifying this whole line of reasoning. W. Tecumseh Fitch likewise argues that this was the original selective advantage of laryngeal lowering in our species. Although (according to Fitch) the initial lowering of the larynx in humans had nothing to do with speech, the increased range of possible formant patterns was subsequently co-opted for speech. Size exaggeration remains the sole function of the extreme laryngeal descent observed in male deer. Consistent with the size exaggeration hypothesis, a second descent of the larynx occurs at puberty in humans, although only in males. In response to the objection that the larynx is descended in human females, Fitch suggests that mothers vocalising to protect their infants would also have benefited from this ability.\n\nIn 2011, Quentin Atkinson published a survey of phonemes from 500 different languages as well as language families and compared their phonemic diversity by region, number of speakers and distance from Africa. The survey revealed that African languages had the largest number of phonemes, and Oceania and South America had the smallest number. After allowing for the number of speakers, the phonemic diversity was compared to over 2000 possible origin locations. Atkinson's \"best fit\" model is that language originated in central and southern Africa between 80,000 and 160,000 years ago. This predates the hypothesized southern coastal peopling of Arabia, India, southeast Asia, and Australia. It would also mean that the origin of language occurred at the same time as the emergence of symbolic culture.\n\nThe search for the origin of language has a long history rooted in mythology. Most mythologies do not credit humans with the invention of language but speak of a divine language predating human language. Mystical languages used to communicate with animals or spirits, such as the language of the birds, are also common, and were of particular interest during the Renaissance.\n\nVāc is the Hindu goddess of speech, or \"speech personified\". As Brahman's \"sacred utterance\", she has a cosmological role as the \"Mother of the Vedas\". The Aztecs' story maintains that only a man, Coxcox, and a woman, Xochiquetzal, survived a flood, having floated on a piece of bark. They found themselves on land and begat many children who were at first born unable to speak, but subsequently, upon the arrival of a dove, were endowed with language, although each one was given a different speech such that they could not understand one another.\n\nIn the Old Testament, the Book of Genesis (11) says that God prevented the Tower of Babel from being completed through a miracle that made its construction workers start speaking different languages. After this, they migrated to other regions, grouped together according to which of the newly created languages they spoke, explaining the origins of languages and nations outside of the fertile crescent.\n\nHistory contains a number of anecdotes about people who attempted to discover the origin of language by experiment. The first such tale was told by Herodotus (\"Histories\" 2.2). He relates that Pharaoh Psammetichus (probably Psammetichus I, 7th century BC) had two children raised by a shepherd, with the instructions that no one should speak to them, but that the shepherd should feed and care for them while listening to determine their first words. When one of the children cried \"bekos\" with outstretched arms the shepherd concluded that the word was Phrygian, because that was the sound of the Phrygian word for \"bread\". From this, Psammetichus concluded that the first language was Phrygian. King James V of Scotland is said to have tried a similar experiment; his children were supposed to have spoken Hebrew.\n\nBoth the medieval monarch Frederick II and Akbar are said to have tried similar experiments; the children involved in these experiments did not speak. The current situation of deaf people also points into this direction.\n\nModern linguistics does not begin until the late 18th century, and the Romantic or animist theses of Johann Gottfried Herder and Johann Christoph Adelung remained influential well into the 19th century. The question of language origin seemed inaccessible to methodical approaches, and in 1866 the Linguistic Society of Paris famously banned all discussion of the origin of language, deeming it to be an unanswerable problem. An increasingly systematic approach to historical linguistics developed in the course of the 19th century, reaching its culmination in the Neogrammarian school of Karl Brugmann and others.\n\nHowever, scholarly interest in the question of the origin of language has only gradually been rekindled from the 1950s on (and then controversially) with ideas such as universal grammar, mass comparison and glottochronology.\n\nThe \"origin of language\" as a subject in its own right emerged from studies in neurolinguistics, psycholinguistics and human evolution. The \"Linguistic Bibliography\" introduced \"Origin of language\" as a separate heading in 1988, as a sub-topic of psycholinguistics. Dedicated research institutes of evolutionary linguistics are a recent phenomenon, emerging only in the 1990s.\n\n"}
{"id": "10323935", "url": "https://en.wikipedia.org/wiki?curid=10323935", "title": "Parametric determinism", "text": "Parametric determinism\n\nParametric determinism is a Marxist interpretation of the course of history. It was formulated by Ernest Mandel and can be viewed as one variant of Karl Marx's historical materialism or as a philosophy of history.\n\nIn an article critical of the analytical Marxism of Jon Elster, Mandel explains the idea as follows:\n\nIn formal-logical determinism, human action is considered \"either\" rational, and hence logically explicable, \"or else\" arbitrary and random (in which case human actions can be comprehended at best only as patterns of statistical distributions, i.e. as degrees of variability relative to some constants). But in dialectical determinism, human action may be \"non-arbitrary\" and \"determinate\", hence reasonable, even although it is \"not\" explicable exclusively in terms of deductive inference. The action selected by people from a limited range of options may not be the \"most logical\" or \"most optimal\" one, but it can be shown to be \"non-arbitrary\" and \"reasonable\" under the circumstances, if the total context is considered.\n\nWhat this means is that, in human situations, typically \"several \"logics\" are operating at the same time\" which together determine the outcomes of those situations:\n\n\nIf one considered only one of these aspects, one might judge people's actions \"irrational\", but if all three aspects are taken into account, what people do may appear \"very reasonable\". Dialectical theory aims to demonstrate this, by linking different \"logical levels\" together as a total picture, in a non-arbitrary way. \"Different logical levels\" means that particular determinants regarded as irrelevant at one level of analysis are excluded, but are relevant and included at another level of analysis with a somewhat different (or enlarged) set of assumptions.—depending on the kind of problem being investigated.\n\nFor example, faced with a situation, the language which people use to talk about it, reveals that they can jump very quickly from one context to another related context, knowing very well that at least some of the inferences that can be drawn in the one context are not operative in the other context. That's because they know that the assumptions in one context differ to some degree from the other. Nevertheless, the two contexts can coexist, and can be contained in the same situation, which we can demonstrate by identifying the mediating links. This is difficult to formalize precisely, yet people do it all the time, and think it perfectly \"reasonable\". For another example, people will say \"you can only understand this if you are in the situation yourself\" or \"on the ground.\" What they mean is that the meaning of the totality of interacting factors involved can only be understood by experiencing them. Standing outside the situation, things seem irrational, but being there, they appear very reasonable.\n\nDialectical theory does not mean that, in analyzing the complexity of human action, inconvenient facts are simply and arbitrarily set aside. It means, rather, that those facets of the subjectmatter which are not \"logically required\" at a given stage of the analysis are set aside. Yet, and this is the point, as the analysis progresses, the previously disregarded aspects are integrated step by step into the analysis, in a consistent way. The proof of the validity of the procedure is that, at the end, the theory has made the subjectmatter fully self-explanatory, since all salient aspects have been given their appropriate place in the theory, so that all of it becomes comprehensible, without resort to shallow tautologies. This result can obviously be achieved only after the research has already been done, and the findings can be arranged in a convincing way. A synthesis cannot be achieved without a preceding analysis. So dialectical analysis is not a \"philosopher's stone\" that provides a quick short-cut to the \"fount of wisdom\", but a mode of presenting findings of the analysis after knowledge has been obtained through inquiry and research, and dialectical relationships have been verified. Because only then does it become clear where the story should begin and end, so that all facets are truly explained. According to Ernest Mandel, \"Marx's method is much richer than the procedures of ' successive concretization' or 'approximation' typical of academic science.\"\n\nIn mainstream social theory, the problem of \"several logics\" in human action is dealt with by game theory, a kind of modelling which specifies the choices and options which actors have within a defined setting, and what the effects are of their decisions. The main limitation of that approach is, that the model is only as good as the assumptions on which it is based, while the choice of assumptions is often eclectic or fairly arbitrary. Dialectical theory attempts to overcome this problem, by paying attention to the sources of assumptions, and by integrating the assumptions in a consistent way.\n\nOne common problem in historical analysis is to understand to what extent the results of human actions can be attributed to free choices and decisions people made (or free will), and to what extent they are a product of social or natural forces beyond their control.\n\nTo solve this problem theoretically, Mandel suggests that in almost any human situation, some factors (\"parameters\") are beyond the control of individuals, while some other conditions are under their control (arguably, one group of people could \"impose parameters\" on another, analogous to parents imposing constraints on children). Some things can under the circumstances be changed by human action, according to choice, but others cannot or will not be, and can thus be regarded as constants. A variable can vary, yet it cannot vary in any direction whatever but only within the given parameters. In a general sense, a \"parameter\" is a given condition imposed on a situation, or a controlled variable, but more specifically it refers to a condition which, in some way, \"limits the amount and type of variability there can be\".\n\nThose given, objective parameters which are beyond people's control (and thus cannot normally be changed by them) \"limit\" the realm of possibilities in the future; they \"rule out\" some conceivable future developments or alternatively make them \"more likely to happen\". In that sense human action is \"determined\" and \"determinate\". If that wasn't so, then it would be impossible to predict anything much about human behaviour.\n\nSome of these parameters refer to limits imposed by the physical world, others to limits imposed by the social set-up or social structure that individuals and groups operate within. The dominant ideology or religion could also be a given parameter. If for example most people follow a certain faith, this shapes their whole cultural life, and is something to be reckoned with that isn't easily changed.\n\nAt the same time, however, the given parameters cannot usually determine \"in total\" what an individual or group will do, because they have at least some (and sometimes a great deal) of personal or behavioural autonomy. They can think about their situation, and make some free choices and decisions about what they will do, within the framework of what is objectively possible for them (the choices need not be \"rational\" or \"fully conscious\" ones, they could just be \"non-arbitrary\" choices influenced by emotions and desires). Sentient (self-aware) organisms, of which human beings are the most evolved sort, are able to vary their own response to given situations according to internally evaluated and decided options.\n\nIn this sense, Karl Marx had written:\n\n\"The past\" (what really happened before, as distinct from its results in the present) is not something which can be changed at all in the present, only reinterpreted, and therefore the past is a given constant which delimits what can possibly happen in the present and in the future. If the future seems relatively \"open-ended\" that is just because in the time-interval between now and the future, new options and actions could significantly alter what exactly the future will be. Yet the variability of possible outcomes in the future is not infinite, but delimited by what happened before.\n\nTen implications of this view are as follows:\n\nAccording to the theory of parametric determinism, the \"human problem\" in this context is usually not that human beings lack free choice or free will, or that they cannot in principle change their situation (at least to some extent), but rather is their \"awareness\" of the options open to them, and their \"belief\" in their own ability to act on them—influenced as they may be, by their ideology, experience and emotions.\n\nPerceptions of what people can change or act upon may vary a great deal, they might overestimate it, or underestimate it. Thus it may take scientific inquiry to find out what perceptions are realistic. By discovering what the determinism is, we can learn better how we can be free. Simply put, we could \"bang our head against a wall\", but we could also go over the wall, through a door in the wall, or around the wall. At crucial points, humans can \"make history\" actively with a high awareness of what they are doing, changing the course of history, but they can also \"be made by history\" to the extent that they passively conform to (or are forced to conform to) a situation which is mostly not of their own making and which they may not understand.\n\nAs regards the latter, Mandel referred to the condition of alienation in the sense of a diminished belief in the ability to have control over one's own life, or feeling estranged from one's real nature and purpose in life. People might reify aspects of their situation. They might regard something as inevitable (\"God's will\") or judge \"nothing could be done to prevent it\" when the real point is that, for specific reasons, nobody was prepared to do anything about it—something could have been done, but it wasn't. Thus \"historical inevitability\" can also be twisted into a convenient apology to justify a course of events.\n\nIn this process of making choices within a given objective framework of realistic options, plenty of illusions are also possible, insofar as humans may have all kinds of gradations of (maybe false) awareness about their true situation. They may, as Mandel argues, not even be fully aware of what motivates their own actions, quite aside from not knowing fully what the consequences of their actions will be. A revolutionary seeking to overthrow the old order to make way for a new one obviously faces many \"unknowns\".\n\nTherefore, human action can have \"unintended consequences\", including effects which are completely opposite to what was intended. This means that popular illusions can also shape the outcomes of historical events. If most people believe something to be the case, even although it is not true, this fact can also become a parameter limiting what can happen or influencing what will happen.\n\nBecause terrible illusions can occur, some historians are skeptical about the ability of people to change the world for the better in any real and lasting way. Postmodernism casts doubt on the existence of progress in history as such—if e.g. Egyptians built the Great Pyramid of Giza in 2500 BC, and Buzz Aldrin and Neil Armstrong landed on the moon in 1969, this represents no progress for humanity.\n\nHowever, Mandel argued that this skepticism is itself based on perceptions of what people are able to know about their situation and their history. Ultimately, the skeptic believes that it is impossible for people to have sufficient knowledge of a kind that they can really change the human condition for the better, except perhaps in very small ways. It just is what it is. This skeptical view does not necessarily imply a very \"deterministic\" view of history however; history could also be viewed as an unpredictable chaos or too complex to fathom.\n\nHowever, most politicians and political activists (including Mandel himself) at least do not believe that history generally is an unpredictable chaos, because in that case their own standpoints would be purely arbitrary and be \"perceived\" as purely arbitrary. Usually, they would argue, the chaos is limited in space and time, because in perpetual chaos, human life can hardly continue anyway; in that case, people become reactive beasts. Since people mostly do want to survive, they need some order and predictability. One can understand what really happened in history reasonably well, if one tries. Human beings can understand human experience because they are human, and the more relevant experience they obtain, the better they can understand it.\n\nConscious human action, Mandel argues, is mainly non-arbitrary and practical, it has a certain \"logic\" to it even if people are not (yet) fully aware of this. The reality they face is \"ordered\" in basic ways, and therefore can be meaningfully understood. Masses of people might go into a \"mad frenzy\" sometimes that might be difficult to explain in rational terms, but this is the exception, not the rule. What is true is that a situation of chaos and disorder (when nothing in society seems to work properly anymore) can powerfully accentuate the irrational and non-rational aspects of human behaviour. In such situations, people with very unreasonable ideas can rise to power. This is, according to Mandel, part of the explanation of fascism.\n\nThe concept of parametric determinism has as its corollary the concept of \"historical latency\". It is not just that different historical outcomes are possible, but that each epoch of human history contains quite a few different developmental \"potentials\". The indications of these potentials can be empirically identified, and are not simply a speculation about \"what could conceivably happen\".\n\nBut they are \"latent\" factors in the situation, insofar as they will not necessarily be realised or actualised. Their realisation depends on human action, on the recognition of the potential that is there, and the decision to do something about it. Thus, Mandel argues that both socialism and barbarism exist as broad \"latent\" developmental possibilities within modern capitalist society, even if they are not realised, and whether and which of these will be realised, depends on human choices and human actions.\n\nEffective action to change society, he argues, has to set out from the real possibilities there are for an alternative way of doing things, not from abstract speculations about a better world. Some things are realistically possible, but not just \"anything\" is possible. The analytical challenge—often very difficult—is therefore to understand correctly what the real possibilities are, and which course of action would have the most fruitful effect. One can do only what one is able to do and no more, but much depends on choices about how to spend one's energies.\n\nTypically in wars and revolutions, when people exert themselves to the maximum and have to improvise, it is discovered that people can accomplish far more than they previously thought they could do (also captured in the saying \"necessity is the mother of invention\"). The whole way people think is suddenly changed. But in times of cultural pessimism, general exhaustion prevails and people are generally skeptical or cynical about their ability to achieve or change very much at all. If the bourgeoisie beats down the workers and constrains their freedom, so that workers have to work more and harder for less and less pay, pessimistic moods can prevail for quite some time. If, on the other hand, the bourgeois economy is expanding, the mood of society can become euphoric, and people believe that just about anything is possible. A famous leftwing slogan in May 1968 was \"tout est possible\" (\"anything is possible\"). Similarly, in the boom of the later 1990s, many people in rich countries believed that all human problems could finally be resolved.\n\nThat is just to say that what is possible to achieve can be both pessimistically underestimated and optimistically exaggerated at any time. Truly conservative people will emphasize how little potential there is for change, while rebels, visionaries, progressives and revolutionaries will emphasize how much could be changed. An important role for social scientific inquiry and historiography is therefore to relativise all this, and place it in a more objective perspective by looking at the relevant facts.\n\nWhile Mandel himself made some successful predictions about the future of world society (for instance, he is famous for predicting at the beginning of the 1960s, like Milton Friedman did, that the postwar economic boom would end at the close of the decade), his Trotskyist critics (including his biographer Jan Willem Stutje) argue, with the benefit of hindsight, that he was far too optimistic and hopeful about the possibility of a workers' revolution in Eastern Europe and the Soviet Union during the Mikhail Gorbachev era and after—and more generally, that his historical optimism distorted his political perspectives, so that he became too \"certain\" about a future that he could not be so certain about, or else crucially ambivalent.\n\nThis is arguably a rather shallow criticism insofar as the situation could well have developed in different directions, which is precisely what Mandel himself argued; in politics, one could only try to make the most of the situation at the time, and here pessimism was not conducive to action. But the more substantive criticism is that many of Mandel's future scenarios were simply not realistic, and that in reality things turned out rather differently from what he thought. This raises several questions:\n\n\nIn answering these criticisms, Mandel himself would probably have referred to what he often called the \"laboratory of history\". That is, we can check the historical record, to see who predicted what, the grounds given for the prediction, and the results. On that basis, we can verify empirically what kind of thinking (and what kind of people) will produce the most accurate predictions, and what we can really predict with \"usable accuracy\". One reason why he favoured Marxism was because he believed it provided the best intellectual tools for predicting the future of society. He often cited Leon Trotsky as an example of a good Marxist able to predict the future. Trotsky wrote in 1925 that:\n\nThis may all seem a trivial \"academic\" or \"scholastic\" debate, similar to retrospective speculations about \"what could have been different\", but it has very important implications for the socialist idea of a planned economy. Obviously, if it is not possible to predict much about human behaviour with usable accuracy, then not much economic planning is feasible either—since a plan requires at least some expectation that its result \"can and will be realised in the future\", even if the plan is regularly adjusted for new (and unanticipated) circumstances. In general, Mandel believed that the degree of predictability in human life was very much dependent on the way society itself was organised. If e.g. many producers competed with each other for profits and markets, based on privatized knowledge and business secrets, there was much unpredictability in what would happen. If the producers coordinated their efforts co-operatively, much would be predictable.\n\nA deeper problem, to which Mandel alludes with his book \"Trotsky: A study in the dynamic of his thought\", is that \"if\" we regard certain conditions as possible to change for the better, we \"might\" be able to change them, even if currently people believe it is impossible—whereas if we regard them as unchangeable, we are unlikely to change them at all, even although they could possibly be changed ( a similar insight occurs in pragmatism). That is, we make things possible, by doing something about them rather than do nothing. This, however, implies that even when we try our best to be objective and realistic about history or anything else, we remain subjects influenced by \"subjective perceptions\" or elements of fear, hope, will or faith that defy reason or practicality.\n\nIt is, simply put, very \"difficult\" to bring scientific truths and political action together, as Marxists aim to do, in such a way that we really change the things we can change for the better to the maximum, and do not try to change things we really cannot change anyway (Marxists call this \"the unity of theory and practice\"). In other words, the will to change things can involve subjective perceptions of a kind for which even the best historical knowledge may offer no assistance or guide. And all perceptions of \"history-making\" may inescapably involve ideology, thus—according to skeptics—casting some doubt on the very ability of people to distinguish objectively between what can be changed, and what cannot. The boundary between the two might be rather blurry. This is the basis of Karl Popper's famous philosophy of social change by \"small steps\" only.\n\nMandel's reply to this skepticism essentially was to agree that there were always \"unknowns\" or \"fuzzy\" areas in human experience; for people to accomplish anything at all or \"make their own history\", required taking a risk, calculated or otherwise. One could indeed see one's life as a \"wager\" ultimately staked on a belief, scientifically grounded or otherwise. However, he argued it was one thing to realise all that, but another to say that the \"unknowns\" are \"unknowable\". Thus, for good or for ill, \"you don't know, what you haven't tried\" and more specifically \"you don't know, what you haven't tried to obtain knowledge about\". The limits of knowledge and human possibilities could not be fixed in advance by philosophy; they had to be \"discovered\" through the test of practice. This attitude recalls Marx's famous comment that \"All social life is essentially \"practical\". All mysteries which lead theory to mysticism find their rational solution in human practice, and in the comprehension of this practice.\". Mandel believed, with Marx, that \"ignorance never helped anybody\" except those who profited from its existence (\"never underestimate human gullibility, including your own\").\n\nThe general task of revolutionary science was to overcome ignorance about human life, and this could not very well be done by reconciling people with their allegedly \"predetermined\" fate at every opportunity. We all know we will die eventually, but that says little yet about what we can achieve before that point. Skepticism has its uses, but what those uses are, can only be verified from experience; a universal skepticism would be just as \"arbitrary\" as the belief that \"anything is possible\"—it did not lead to any new experience from which something could be learnt, including learning about the possibilities of human freedom. And such learning could only occur through making conscious choices and decisions within given parameters, i.e. in a \"non-arbitrary\" (non-chaotic) environment, permitting at least some predictability and allowing definite experiential conclusions.\n\nMandel often reiterated that most people do not learn all that much from texts or from history, they learn from their own experience. They might be affected by history without knowing it. But anybody concerned with large-scale social change was almost automatically confronted with the need to place matters in broader historical perspective. One had to understand deeply the limits, consequences and implications of human action. Likewise, politicians making decisions affecting large numbers of people could hardly do without a profound sense of history.\n\n\n"}
{"id": "38563314", "url": "https://en.wikipedia.org/wiki?curid=38563314", "title": "Primitive communism", "text": "Primitive communism\n\nPrimitive communism is a concept originating from Karl Marx and Friedrich Engels who argued that hunter-gatherer societies were traditionally based on egalitarian social relations and common ownership. A primary inspiration for both Marx and Engels were Lewis Henry Morgan's descriptions of \"communism in living\" as practised by the Iroquois Nation of North America. In Marx's model of socioeconomic structures, societies with primitive communism had no hierarchical social class structures or capital accumulation.\n\nEngels offered the first detailed theorization of primitive communism in 1884, with publication of \"The Origin of the Family, Private Property, and the State\". Marx and Engels used the term more broadly than Marxists did later, and applied it not only to hunter-gatherers but also to some subsistence agriculture communities. There is also no agreement among later scholars, including Marxists, on the historical extent, or longevity, of primitive communism.\n\nMarx and Engels also noted how capitalist accumulation latched itself onto social organizations of \"primitive communism\". For instance, in private correspondence the same year that \"The Origin of the Family\" was published, Engels attacked European colonialism, describing the Dutch regime in Java directly organizing agricultural production and profiting from it, \"on the basis of the old communistic village communities\". He added that cases like the Dutch East Indies, British India and the Russian Empire showed \"how today primitive communism furnishes ... the finest and broadest basis of exploitation\".\n\nIn a primitive communist society, all able bodied persons would have engaged in obtaining food, and everyone would share in what was produced by hunting and gathering. There would be no private property, which is distinguished from personal property such as articles of clothing and similar personal items, because primitive society produced no surplus; what was produced was quickly consumed. The few things that existed for any length of time (tools, housing) were held communally, in Engels' view in association with matrilocal residence and matrilineal descent. There would have been no state.\n\nDomestication of animals and plants following the Neolithic Revolution through herding and agriculture was seen as the turning point from primitive communism to class society as it was followed by private ownership and slavery, with the inequality that they entailed. In addition, parts of the population specialized in different activities, such as manufacturing, culture, philosophy, and science which is said to lead to the development of social classes.\nEgalitarian and communist-like hunter gatherer societies have been studied and described by many well-known social anthropologists including James Woodburn, Richard Lee, Alan Barnard and, more recently, Jerome Lewis. Anthropologists such as Christopher Boehm, Chris Knight and Jerome Lewis offer theoretical accounts to explain how communistic, assertively egalitarian social arrangements might have emerged in the prehistoric past. Despite differences in emphasis, these and other anthropologists follow Engels in arguing that evolutionary change—resistance to primate-style sexual and political dominance—culminated eventually in a revolutionary transition. Richard Borshay Lee criticizes the mainstream and dominant culture's long-time bias against the possible existence of primitive communism, deriding \"Bourgeois ideology [that] would have us believe that primitive communism doesn't exist. In popular consciousness it is lumped with romanticism, exoticism: the noble savage.\"\n\n\n\n\n"}
{"id": "504008", "url": "https://en.wikipedia.org/wiki?curid=504008", "title": "Psychobiography", "text": "Psychobiography\n\nPsychobiography aims to understand historically significant individuals, such as artists or political leaders, through the application of psychological theory and research.\n\nThrough its merging of personality psychology and historical evidence, psychobiography may be considered a historical form of therapeutic case study: it represents a growing field in the realm of biography. Psychopathography is sometimes used as a term to indicate that the person being analyzed was not mentally healthy, \"path\" coming from \"pathos\" (πάθος)—Ancient Greek for suffering or illness. \n\nPsychobiography is a field within the realms of psychology and biography that analyzes the lives of historically significant individuals through psychological theory and research. Its goal is to develop a better understanding of notable individuals by applying psychological theories to their biographies to further explain the motives behind some of the subjects actions and decisions. Popular subjects of psychobiographies include figures such as Adolf Hitler, Vincent van Gogh, William Shakespeare, Martin Luther King, Jr., Abraham Lincoln, and Saddam Hussein. A typical biography is often very descriptive, and tries to record every notable event that happened in a person's lifetime, whereas a psychobiography primarily focuses on some particular events, and tries to better understand why they happened. This field's potential has not only aided in developing a better understanding to many notable biographies throughout history, but has also inspired direction and insight into the field of psychology.\n\nOne of the first great examples of this field's utility was Dr. Henry Murray's report on the analysis of Adolf Hitler's personality during the end of World War II. Forced to psychoanalyze from a distance, Dr. Murray used multiple sources, including Hitler's genealogy, Hitler's own writings, and biographies of Hitler, so that the Allied forces could understand his personality to better predict his behavior. By applying a theory of personality that consisted of 20 psychogenic needs, Dr. Murray presumed Hitler's personality as \"counteractive narcism\", and was able to correctly predict the German leader's suicide in the face of his country's defeat. This work by Dr. Murray not only helped establish personality psychology as a behavioral science, but it also showed how the field of psychobiography could be applied as a means of psychoanalysis.\n\nSigmund Freud's analysis of Leonardo da Vinci (titled \"Leonardo da Vinci, A Memory of His Childhood\") is generally considered the first \"modern\" psychobiography. Persons who have been the subject of psychobiographical research include Freud, Adolf Hitler, Sylvia Plath, Carl Jung, Vincent van Gogh, Martin Luther, Abraham Lincoln, Elvis Presley, Søren Kierkegaard, Friedrich Nietzsche, Andrew Jackson, and Richard Nixon.\n\nMajor psychobiographical authors include Erik Erikson, James William Anderson, Henry Murray, George Atwood, and William Runyan.\n\nMany psychobiographies are Freudian or psychodynamic in orientation, but other commonly used theories include narrative models of identity such as the life story model, script theory, object relations, and existentialism/phenomenology; and psychobiographers are increasingly looking for explanatory complexity through an eclectic approach.\n\nThough there were other psychobiographies written before Freud's \"Leonardo da Vinci and A Memory of His Childhood\" in 1910, it is considered the most significant contribution of its time, despite its flaws. Psychobiographies about William Shakespeare (Jones, 1910), Giovanni Segantini (Abraham, 1912), Richard Wagner (Graf, 1911), Amenhotep IV (Abraham, 1912), Martin Luther (Smith, 1913), and Socrates (Karpas, 1915) were also published between 1910 and 1915, but are not as well known. Between 1920 and 1926, psychobiographies of Margaret Fuller (Anthony, 1920), Samuel Adams (Harlow, 1923), Edgar Allan Poe (Krutch, 1926), and Abraham Lincoln (Clark, 1923) were published by authors from a psychoanalytic perspective without a background in psychoanalysis. During the 1930s Tolstoy, Dostoevsky, Molière, Sand, Goethe, Coleridge, Nietzsche, Poe, Rousseau, Caesar, Lincoln, Napoleon, Darwin, and Alexander the Great were the subjects of psychobiographies, and soon afterward in 1943 a psychobiography of Adolf Hitler, predicting his suicide, was written during World War II, but was not published until 1972. Recent, significant contributions between 1960 and 1990 include psychobiographies of Henry James (Edel, 1953–72), Isaac Newton (Manuel, 1968), Mohandas Gandhi (Erikson, 1969), Max Weber (Mitzman, 1969), Emily Dickinson (Cody, 1971), Joseph Stalin (Tucker, 1973), James and John Stuart Mill (Mazlish, 1975), T. E. Lawrence (Mack, 1976), Adolf Hitler (Waite, 1977), Beethoven (Solomon, 1977), Samuel Johnson (Bate, 1977), Alice James (Strouse, 1980), Wilhelm Reich (Sharaf, 1983), and William James (Feinstein, 1984). Some psychobiographies at this time were also written about groups of people, focusing on an aspect they had in common such as American presidents, philosophers, utopians, revolutionary leaders, and personality theorists. These psychobiographies are the most well known, but since 1910 there have been over 4000 psychobiographies published.\n\nAs psychobiography gained recognition, authors from a variety of professions contributed their own work from alternate perspectives and varying methods of analysis of the psychobiographical subjects, significantly expanding psychobiography beyond the psychoanalytical perspective. Apart from psychoanalysts and psychiatrists who wrote the first psychobiographies, there have been historians, political scientists, personality psychologists, literary critics, sociologists, and anthropologists that have contributed to the growth of the field.\nPsychobiography has also conflicted with contemporary views of science since its origin because it contains no controlled variables or experimentation. In its early years it was dismissed as unscientific and not a legitimate addition to the field of psychology due to the push towards experimentation focused on physiological and biological factors, and away from philosophical psychology, to establish it as a natural science. The value of psychobiography to psychology is comparable to evolutionary psychology, archeology, and historical geology, offering detailed analyses of subjects with an emphasis on contextual information, but due to the qualitative nature of this information it remains a challenge to validate psychobiographical works as empirically based applications of psychology.\n\nThe discipline of psychobiography has developed various methodological guidelines for psychobiographical study. Some of the most prominent are these:\n\n\nScholars untrained in the discipline who do not follow these guidelines continue to produce psychobiographical studies.\n\nFreud's psychoanalytic approach (Freudian perspective) is not commonly used in its entirety in psychobiography, but it has had a lasting influence on the analysis of behavior in other areas of psychology. To sift through a lifetime of information and locate significant areas in the subject's development requires a system of identification, and psychoanalysis provided the base for this. Primacy, the initial exposure or experience, was recognized by Freud as an important factor in personality development and has remained an important aspect of personality psychology, psychotherapy, and psychobiography. Frequency, repeated exposure or actions, is also important, but its significance can vary. If the frequency of an action is low then it is seen as unimportant, and if the frequency is too high it becomes passive and overlooked, also becoming less important in psychobiography. Freud's knowledge of the importance of frequency is shown in the analysis of dreams, slips, errors, and humor by recognizing that repetition leads people to disregard these behaviors or stimuli. The importance of error in psychobiography, including slips and distortions, is also rooted in Freudian psychoanalysis and is used to identify hidden motives.\n\nElms has contributed to psychobiography through many published works including psychobiographies on Allport (1972), Freud (1980), Skinner (1981), and Murray (1987). He has also written about the subject of psychobiography in \"Psychobiography and Case Study Methods\" and \"Uncovering Lives: The Uneasy Alliance of Biography and Psychology\" defining psychobiography and its methods, and explaining the value of psychobiography in psychology.\n\nPsychobiography has faced criticism from the very start, crystallised above all in the production of what Erikson caricatured as \"originology\"—the explaining away of significant public events and actions as the product of some minute childhood detail.\n\nBad psychobiography—using mechanical psychologising, a selective mining of the facts, overdeterminism, and a tendency to pathologise—is considered easy to write. Anna Freud condemned the study of Woodrow Wilson Freud himself co-authored with William Bullitt on just such grounds, and the haphazard historical evolution of the disciple has not helped reduce its prevalence.\n\n\n\n"}
{"id": "38502856", "url": "https://en.wikipedia.org/wiki?curid=38502856", "title": "Revisionism (Marxism)", "text": "Revisionism (Marxism)\n\nWithin the Marxist movement, the word revisionism is used to refer to various ideas, principles and theories that are based on a significant revision of fundamental Marxist premises.\n\nThe term is most often used by those Marxists who believe that such revisions are unwarranted and represent a \"watering down\" or abandonment of Marxism—one such common example is the negation of class struggle. As such, revisionism often carries pejorative connotations and the term has been used by many different factions. It is typically applied to others and rarely as a self-description. By extension, people who view themselves as fighting against revisionism have often self-identified as anti-revisionists.\n\nThe term \"revisionism\" has been used in a number of contexts to refer to different revisions (or claimed revisions) of Marxist theory.\n\nIn the late 19th century, revisionism was used to describe democratic socialist writers such as Eduard Bernstein, who sought to revise Karl Marx's ideas about the transition to socialism and claimed that a revolution through force was not necessary to achieve a socialist society. The views of Bernstein gave rise to reformist theory, which asserts that socialism can be achieved through gradual peaceful reforms from within a capitalist system.\n\nIn the 1920s and 1930s, the International Left Opposition led by Leon Trotsky, which had been expelled from the Communist International, accused the leadership of the Comintern and Soviet Union of revising the internationalist principles of Marxism and Leninism in favor of the aspirations of an elite bureaucratic caste which had come to power in the Soviet Union. The Trotskyists saw the nascent Stalinist bureaucracy as a roadblock on the proletariat's path to world socialist revolution and to the shifting policies of the Comintern, they counterposed the Marxist theory of permanent revolution. Meanwhile, the Soviet authorities labeled the Trotskyists as \"revisionists\" and eventually expelled them from the Communist Party of the Soviet Union, whereupon the Trotskyists founded their Fourth International.\n\nIn the 1940s and 1950s within the international communist movement, revisionism was a term used by Marxist-Leninists to describe communists who focused on consumer goods production instead of heavy industry; accepted national differences instead of promoting proletarian internationalism; and encouraged liberal reforms instead of remaining faithful to established doctrine. Revisionism was also one of the charges leveled at Titoists as punishment for their pursuit of a relatively independent communist ideology, amidst a series of post-World War II purges beginning in 1949 in Eastern Europe by the Soviet administration under Stalin. After Stalin's death, a more democratic form of socialism briefly became acceptable in Hungary during Imre Nagy's government (1953–1955) and in Poland during Władysław Gomułka's government, containing ideas that the rest of the Soviet bloc and the Soviet Union itself variously considered revisionist, although neither Nagy nor Gomułka described themselves as revisionists, since to do so would have been self-deprecating.\n\nAfter the 1956 Secret Speech that denounced Stalin, many communist activists, astounded and disheartened by what they saw as the betrayal of Marxist–Leninist principles by the very people who had founded them, resigned from western communist parties in protest. These quitters were sometimes accused of revisionism by those communists who remained in these parties, although some of these same loyalists also shortly thereafter split from the same communist parties in the 1960s to become the New Left indicating that they too were disillusioned by the actions of the Soviet Union by that point in time. Most of those who left in the 1960s started aligning themselves with Mao Zedong as opposed to the Soviet Union. An example was E. P. Thompson's \"New Reasoner\".\n\nIn the early 1960s, Mao Zedong and the Communist Party of China revived the term revisionism ( \"xiūzhèng zhǔyì\", \"doctrine correction\") to attack Nikita Khrushchev and the Soviet Union over various ideological and political issues, as part of the Sino-Soviet split. The Chinese routinely described the Soviets as \"modern revisionists\" through the 1960s. This usage was copied by the various Maoist groups that split off from communist parties around the world. In 1978, the Sino-Albanian split occurred, which caused Enver Hoxha, the General Secretary of Albania, to also condemn Maoism as revisionist. This caused a split in the Maoist movement, with some following the Albanian Party of Labour's line, most notably the Communist Party of New Zealand and the Communist Party of Canada (Marxist–Leninist).\n\n"}
{"id": "22286701", "url": "https://en.wikipedia.org/wiki?curid=22286701", "title": "The Mysterious Numbers of the Hebrew Kings", "text": "The Mysterious Numbers of the Hebrew Kings\n\nThe Mysterious Numbers of the Hebrew Kings (1951) is a reconstruction of the chronology of the kingdoms of Israel and Judah by Edwin R. Thiele. The book was originally his doctoral dissertation and is widely regarded as the definitive work on the chronology of Hebrew Kings. The book is considered the classic and comprehensive work in reckoning the accession of kings, calendars, and co-regencies, based on biblical and extra-biblical sources.\n\nThe chronology of the kings of Israel and Judah rests primarily on a series of reign lengths and cross references within the books of Kings and Chronicles, in which the accession of each king is dated in terms of the reign of his contemporary in either the southern Kingdom of Judah or the northern Kingdom of Israel, and fitting them into the chronology of other ancient civilizations.\n\nHowever, some of the biblical cross references did not seem to match, so that a reign which is said to have lasted for 20 years results in a cross reference that would give a result of either 19 or 21 years. Thiele noticed that the cross references given during the long reign of King Asa of Judah had a cumulative error of 1 year for each succeeding reign of the kings of Israel: the first cross-reference resulted in an error of 1 year, the second gave an error of 2 years, the third of 3 years and so on. He explained this pattern as a result of two different methods of reckoning regnal years: the \"accession year\" method in one and the \"non-accession year\" method in the other. Under the accession year method, if a king died in the middle of a year, the period to the end of that year would be called the \"accession year\" of the new king, whose Year 1 would begin at the new year. Under the non-accession year method the period to the end of the year would be Year 1 of the new king and Year 2 would begin at the start of the new year. Israel appears to have used the non-accession method, while Judah used the accession method until Athaliah seized power in Judah, when Israel's non-accession method appears to have been adopted in Judah.\n\nIn addition, Thiele also concluded that Israel counted years starting in the spring month of Nisan, while Judah counted years starting in the autumn month of Tishri. The cumulative impact of differing new years and different methods of calculating reigns explained, to Thiele, most of the apparent inconsistencies in the cross references.\n\nUnknown to Thiele when he first published his findings, these same conclusions that the northern kingdom used non-accession years and a spring New Year while the southern kingdom used accession years and a fall New Year had been discovered by Valerius Coucke of Belgium some years previously, a fact which Thiele acknowledges in his \"Mysterious Numbers\".\n\nBased on his conclusions, Thiele showed that the 14 years between Ahab and Jehu were really 12 years. This enabled him to date their reigns precisely, for Ahab is mentioned in the Kurk Stele which records the Assyrian advance into Syria/Israel at the Battle of Qarqar in 853 BC, and Jehu is mentioned on the Black Obelisk of Shalmaneser III paying tribute in 841 BC. As these two events are dated by Assyrian chronology as being 12 years apart, Ahab must have fought the Assyrians in his last year and Jehu paid tribute in his first year.\n\nThiele was able to reconcile the Biblical chronological data from the books of Kings and Chronicles with the exception of synchronisms between Hoshea of Israel and Hezekiah of Judah towards the end of the kingdom of Israel and reluctantly concluded that at that point the ancient authors had made a mistake. Oddly, it is at that precise point that he himself makes a mistake, by failing to realize that Hezekiah had a coregency with his father Ahaz, which explains the Hoshea/Hezekiah synchronisms. This correction has been supplied by subsequent writers who built on Thiele’s work, including Thiele’s colleague Siegfried Horn, TC Mitchell and Kenneth Kitchen, and Leslie McFall.\n\nThiele's method in arriving at his chronology has been contrasted with the analytical method employed by Julius Wellhausen and other scholars who follow some form of the documentary hypothesis. Wellhausen taught that the chronological data of the books of Kings and Chronicles were artificially put together at a date much later than the events they were ostensibly describing and were basically not historical. This was a necessary consequence of his \"a priori\" assumption that the biblical books as we have them today were the work of late-date editors who could not possibly have known the correct history of the times they were writing about. Theodore Robinson summarized this position as follows: \"Wellhausen is surely right in believing that the synchronisms in Kings are worthless, being merely a late compilation from the actual figures given.\"\n\nWellhausen's methodology in interpreting the Scriptures and the history of Israel has therefore been classed by RK Harrison as a deductive approach; that is, one that starts with presuppositions and derives a historical reconstruction from those presuppositions. A necessary consequence of this approach has been that no general agreement has been reached on the chronology of the Hebrew kingdom period as calculated by authors who adopted this method. \"The disadvantage of the deductive approach is that nothing is settled for certain; the results obtained are as diverse as the presuppositions of the scholars, since diverse presuppositions produce diverse results.\" In contrast, Thiele's method of determining the chronology of the Hebrew kings was based on induction, that is, making it a matter of first priority to determine the actual methods used by ancient scribes and court recorders in recording the years of kings, as described above. Thiele's inductive method, then, was based on inscriptional evidence from the ancient Near East, and not on the presuppositions followed by liberal scholarship. It is Thiele's method that has produced the determinative studies for the chronology of the kingdom period, not the presupposition-based method, so that even those interpreters who continue in late-date theories for the authorship of Scripture have recognized the credibility of Thiele's scholarship in determining the date for the division of the kingdom after the death of Solomon, as cited above. The work of Thiele and other textual scholars who have followed an inductive (evidence-based) approach is therefore significant in providing an alternative to the methods of the documentary hypothesis, and the success of that approach has been seen as theologically significant in supporting a high view of the inspiration of Scripture, particularly regarding its integrity in the abundant and complex historical data related to the kingdom period.\n\nIf the chronological data of the MT [ Masoretic text ] were not authentic—the actual dates and synchronisms for these various kings—then neither Thiele nor McFall nor anyone else could have constructed a chronology from them that in every case is faithful to the original texts and in every proven instance is consistent with Assyrian and Babylonian chronology. This mathematical demonstration should sit in judgment over the various theories of text formation: If a theory of text formation cannot explain how the chronological data of the MT has produced a chronology that in every respect seems authentic for the four centuries of the monarchic period, then that theory must be rejected as another example of a presupposition-based approach that cannot meet the rational criteria for credibility.\n\nThiele's chronological reconstruction has not been accepted by all scholars, nor has any other scholar’s work in this field. Yet the work of Thiele and those who followed in his steps has achieved acceptance across a wider spectrum than that of any comparable chronology, so that Assyriologist DJ Wiseman wrote “The chronology most widely accepted today is one based on the meticulous study by Thiele,” and, more recently, Leslie McFall: “Thiele’s chronology is fast becoming the consensus view among Old Testament scholars, if it has not already reached that point.” Although criticism has been leveled at numerous specific points in his chronology, his work has won considerable praise even from those who disagree with his final conclusions. Nevertheless, even scholars sharing Thiele's religious convictions have maintained that there are weaknesses in his argument such as unfounded assumptions and assumed circular reasoning.\n\nThis citation, from a critic of Thiele's system, demonstrates the difference mentioned above between the deductive approach based on presuppositions and an inductive approach based on data, not a priori assumptions. Thiele is criticized here for basing his theories on data or evidence, not on presuppositions.\n\nDespite these criticisms Thiele's methodological treatment remains the typical starting point of scholarly treatments of the subject, and his work is considered to have established the date of the division of the Israelite kingdom. This has found independent support in the work of J. Liver, Frank M. Cross, and others studying the chronology of the kings of Tyre. Thiele's work has found widespread recognition and use across various related scholarly disciplines. His date of 931 BCE, in conjunction with the synchronism between Rehoboam and Pharaoh Shishak in 1 Kings 14:25, is used by Egyptologists to give absolute dates to Egypt’s 22nd Dynasty, and his work has also been used by scholars in other disciplines to establish Assyrian and Babylonian dates. Criticism of Thiele's reconstruction led to further research which has refined or even departed from his synthesis. Notable studies of this type include work by Tadmor and McFall.\n\nScholarly attitudes towards the Biblical record of the Israelite monarchies from the late nineteenth century to the mid-twentieth century were largely disparaging, treating the records as essentially fictional and dismissing the value of the regnal synchronisms. In contrast, modern scholarly attitudes to the monarchical chronology and synchronisms in 1 and 2 Kings has been far more positive subsequent to the work of Thiele and those who have developed his thesis further, a change in attitude to which recent archaeology has contributed.\n\n"}
{"id": "23723524", "url": "https://en.wikipedia.org/wiki?curid=23723524", "title": "Transgender Oral History Project", "text": "Transgender Oral History Project\n\nThe Transgender Oral History Project is an initiative by and for the transgender community. TOHP collects interviews and produces multimedia content featuring a stories of transgender-identified people, and exists to empower trans folks through sharing stories of their lives. The Transgender Oral History Project is also active in the community, hosting events in many states including Massachusetts, Illinois, Iowa, Seattle, Philadelphia, and New York City.\n\nAccording to the official website, the Transgender Oral History Project's goals are to build community, encourage inter-generational discussion, framing contemporary issues that transgender people faced within a broader context, highlight individuals, communities, and organizations struggling with trans issues that are not addressed by mainstream discourses and portray how political, social, and historical circumstances impact transgender lives.\n\nThe Trans Oral History project was founded in 2009 by André Pérez as began documenting the evolution of the first ever New England Transgender Pride March. He went on to create a multimedia exhibit entitled, \"Community in Transition: 40 Years of Struggle\" that incorporated archival materials from the Sexual Minorities Archives and the first set of interviews from the Transgender Oral History Project. This exhibit has been featured at Marlboro College, University of Illinois Chicago, and the Translating Identities Conference.\n\nIn 2010, a poster describing the Compton's Cafeteria riot was featured in the anthology, Celebrate People's History, published by the Just Seeds Collective.\n\nIn 2011, the Trans Oral History Project participated in a two-month residency at the University of Illinois, Chicago's LGBTQ Resource Center. TOHP collective members lead a participatory workshop series and created a multimedia exhibition featuring interview materials.\n\nIn 2014, I Live for Trans Education: A Youth Toolkit officially launched. I Live featured mini documentaries paired with interactive activities to teach about issues that impact the transgender community. The toolkit is a resource for trans educators, youth workers, and youth leaders to educate about issues that impact the trans community from an intersectional perspective. TOHP also began partnering with StoryCorps, the largest oral history project in North America, to record and preserve stories. A TOHP interview was featured on WBEZ in Chicago. The Trans Oral History Project now serves as a community archive for StoryCorps' recordings with transgender individuals, and is in the process of integrating those interviews into their publicly accessible digital archive of transgender stories.\n\nMembers of the Trans History Collective have also led educational workshops in community settings, academic institutions, and national conferences. The Transgender Oral History Project collaborates with other organizations in the area to host regular skills shares that teach media production skills to trans* and gender variant people.\n\nSome of the events the Transgender Oral History Project has hosted are:\n\n\n"}
{"id": "30276560", "url": "https://en.wikipedia.org/wiki?curid=30276560", "title": "Wallblake House", "text": "Wallblake House\n\nWallblake House is a heritage plantation house and museum annex in The Valley, Anguilla in the northeastern Caribbean. Built in 1787 by Will Blake, a sugar planter, it is stated to be the oldest structure on the island. Although gutted by the French in the late 1790s, it was rebuilt by the British and today has been fully restored, with its kitchen complex, stables and slave quarters intact. A church in the vicinity contains a stone fascia with open-air side walls and a ceiling, which is the form of a hull of a ship.\n\nWallblake House is one of the ten heritage houses in The Valley that was refurbished over a seven-year period and completed in 2004, at a cost of EC$250,000 (about US$92,000). The Wallblake Trust gained the support of the Catholic Church, many local enthusiasts and NGOS. The Heritage Trail Committee has raised the status of this house consequent to an agreement between the Wallblake Trust and the Anguilla Heritage Trail. It is Anguilla's only surviving plantation house.\n\nThe house was built in the mid to late 1700s. The name \"Walblake\" is probably a distortion of Valentine Blake, whose property in the Valley is mentioned in a deed from the 1690s. The construction date, 1787, is noted from an inscription on an old brick on the northern kitchen wing. The first historical event that occurred at the house was the French invasion by Victor Hugues of this island in 1796 when the Wallblake House witnessed a “crippled Anguillian” known as Hodge, taking shelter in its cellar. However, he could not escape the French soldiers who caught and executed him. This was followed by their gutting the property. The execution of the injured Anguillian further lead to a reparation reflex reaction by the Anguillians as they executed the French prisoners of war who had been detained in the Old Court House on Crocus Hill, without trial. However, the French were not successful in their invasion effort as the local Angullians put up a brave fight and were supported by the British ship, the HMS \"Lapwing\", arriving on the scene at the right time. After this incident, the Wallblake estate was rebuilt. The house was owned by the planter Valentine Blake for some time.\n\nIn the 1800s, when Anguilla experienced severe drought, the estate resorted to raising economic crops such as sugar and cotton over an area of of plantation, but with little success, the same being true with the other Anguillian plantations. Thereafter, the estate saw several owners. In the 1900s, it was with Carter Rey, a rich business baron who had bought the estate from the Lake family. Next, it was owned by his younger brother Frank Rey. In 1959, Marie Rey Lake, who had converted from the Anglican Church to being a Roman Catholic, donated the house to the Catholic Church, which continues to own it till this day. The house was leased to the Department of Tourism in 1978 for a time when they refurbished it. After the lease expired, the house was returned to the Roman Catholic Church and currently functions as a rectory.\n\nNow the heritage monument is being planned to depict the history of the island and the Anguilla’s Heritage Trail. In this effort, Lilli Azevedo, an archaeologist and Heritage Trail Committee member who is providing the narration support, has planned to give expositions of the archaeological findings of Fountain Cavern related to the Amerindian archaeology of Anguilla.\n\nThe house has a stone foundation. The roof is formed with Guyanese hardwood and is shingled. The upper section is wooden. The original structure was built with dressed stones that were probably brought from East End or even Scrub Island. The lime mortar for jointing was made from a mixture of burnt coral and shells with admixtures of molasses and marl. The original timber has been retained in the upper floors. The structure has double paneling. Intricate carvings on its edges give the effect of a \"tray ceiling\", that is, the appearance of inverted trays hung from the roof as if rope is tied to the edges to hide any defects in its construction.\n\nThe heritage building has been restored to its original design and colour scheme. The elegant and decorative designs that existed in the original building have been fully retained.\n\nThe grounds have a bakery, cistern, and stable block. Tall, Spanish bayonet trees are on the property. An adjacent church has a unique decorative stone front facade.\n\nSet behind a white picket fence, Wallblake is now a private house, and living quarters to the priest from St Gerard's Roman Catholic Church. However, tours can be arranged. However, it also serves as a museum annex, as well as a venue for art shows, flower shops and marriage receptions. The International Airport in The Valley, just to the south of the house was also named as Wallblake Airport, now renamed as Clayton J. Lloyd International Airport.\n\n"}
{"id": "53793439", "url": "https://en.wikipedia.org/wiki?curid=53793439", "title": "Witness seminar", "text": "Witness seminar\n\nA witness seminar is a method of collecting oral history material, whereby a number of people connected to an event or topic meet to share recollections of their involvement. The results may be recorded or videoed and an edited transcript published.\n\nThe concept was conceived and formalised by the Institute of Contemporary British History (now the Centre for Contemporary British History) and was subsequently adopted by The History of Modern Biomedicine Group, and published as volumes in the \"Wellcome Witnesses to Contemporary Medicine\" series.\n\n"}
