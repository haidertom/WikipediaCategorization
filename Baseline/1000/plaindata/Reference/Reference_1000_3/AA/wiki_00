{"id": "20831654", "url": "https://en.wikipedia.org/wiki?curid=20831654", "title": "Alan Palmer", "text": "Alan Palmer\n\nAlan Warwick Palmer (born 1926) is a British author of historical and biographical books.\n\nPalmer was educated at Bancroft's School, Woodford Green, London, and Oriel College, Oxford. He spent 19 years as senior history teacher at Highgate School before becoming a full-time writer and researcher. His late wife, Veronica Palmer collaborated on several of his books.\n\nHe was elected a Fellow of the Royal Society of Literature in 1980.\n\n\n\n"}
{"id": "925519", "url": "https://en.wikipedia.org/wiki?curid=925519", "title": "Autogram", "text": "Autogram\n\nAn autogram (Greek: αὐτός = self, γράμμα = letter) is a sentence that describes itself in the sense of providing an inventory of its own characters. They were invented by Lee Sallows, who also coined the word \"autogram\". An essential feature is the use of full cardinal number names such as “one”, “two”, etc., in recording character counts. Autograms are also called ‘self-enumerating’ or ‘self-documenting’ sentences. Often, letter counts only are recorded while punctuation signs are ignored, as in this example:\n\nThe first autogram to be published was composed by Sallows in 1982 and appeared in Douglas Hofstadter's \"Metamagical Themas\" column in \"Scientific American\".\n\nThe task of producing an autogram is perplexing because the object to be described cannot be known until its description is first complete.\n\nA type of autogram that has attracted special interest is the autogramic pangram, a self-enumerating sentence in which every letter of the alphabet occurs at least once. Certain letters do not appear in either of the two autograms above, which are therefore not pangrams. The first ever self-enumerating pangram appeared in a Dutch newspaper and was composed by Rudy Kousbroek. Sallows, who lives in the Netherlands, was challenged by Kousbroek to produce a self-enumerating ‘translation’ of this pangram into English—an impossible-seeming task. This prompted Sallows to construct an electronic Pangram Machine. Eventually the machine succeeded, producing the example below which was published in Scientific American in October 1984:\n\nSallows wondered if one could produce a pangram that counts its letters as percentages of the whole sentence–a particularly difficult task since such percentages usually won't be exact integers. He mentioned the problem to Chris Patuzzo and in late 2015 Patuzzo produced the following solution:\n\nAutograms exist that exhibit extra self-descriptive features. Besides counting each letter, here the total number of letters appearing is also named:\n\nJust as an autogram is a sentence that describes itself, so there exist closed chains of sentences each of which describes its predecessor in the chain. Viewed thus, an autogram is such a chain of length 1. Here follows a chain of length 2:\nA special kind of autogram is the ‘reflexicon’ (short for “reflexive lexicon”), which is a self-descriptive word list that describes its own letter frequencies. The constraints on reflexicons are much tighter than on autograms because the freedom to choose alternative words such as “contains”, “comprises”, “employs”, and so on, is lost. However, a degree of freedom still exists through appending entries to the list that are strictly superfluous.\n\nFor example, “Sixteen e's, six f's, one g, three h's, nine i's, nine n's, five o's, five r's, sixteen s's, five t's, three u's, four v's, one w, four x's” is a reflexicon, but it includes what Sallows calls “dummy text” in the shape of “one g” and “one w”. The latter might equally be replaced with “one #”, where “#” can be any typographical sign not already listed. Sallows has made an extensive computer search and conjectures that there exist but three and only three pure (i.e., no dummy text) English reflexicons.\n\n"}
{"id": "2887701", "url": "https://en.wikipedia.org/wiki?curid=2887701", "title": "Bible (screenwriting)", "text": "Bible (screenwriting)\n\nA bible (also known as a story bible, show bible, series bible, or pitch bible) is a reference document used by screenwriters for information on a television series' characters, settings, and other elements.\n\nShow bibles are updated with information on the characters after the information has been established on screen. For example, the \"Frasier\" show bible was \"scrupulously maintained\", and anything established on air — \"the name of Frasier's mother, Niles' favorite professor, Martin's favorite bar...even a list of Maris' [dozens of] food allergies\" — was reflected in the bible. The updated bible then serves as a resource for writers to keep everything within the series consistent. \n\nOther show bibles are used as sales documents to help a television network or studio understand a series, and are sometimes given to new writers when they join the writing staff for the same reason. These types of bibles discuss the backstories of the main characters and the history of the series' fictional universe.\n\nTelevision series often rely on writers' assistants and script coordinators to serve as \"walking bibles\" in remembering details about a series.\n\nIn the United States, writing the show bible of a produced series earns that writer the 24 units of required credit necessary to qualify for membership in the Writers Guild of America.\n\n\n"}
{"id": "6767022", "url": "https://en.wikipedia.org/wiki?curid=6767022", "title": "Carol Ballard", "text": "Carol Ballard\n\nCarol Ballard is an author of more than 80 non-fiction books. Specializing in informational books for children and teens, her focus is toward the 7- to 14-year-old group.\n\nAfter graduating from Leeds University in plant sciences, Ballard did post-graduate research and was awarded a PhD in Immunology. She has many years experience as a science teacher and co-ordinator and has written articles for teachers on various aspects of science teaching, and teachers' materials for classroon use.\n\nIn addition to her writing, Carol works as a freelance consultant for publishers on educational and scientific matters. She also has her own business, Kite Books, which produces worksheets and teachers' resources.\n\n\n"}
{"id": "54083241", "url": "https://en.wikipedia.org/wiki?curid=54083241", "title": "Citation dynamics", "text": "Citation dynamics\n\nCitation dynamics describes the number of references received by the article or other scientific work over time. The citation dynamics is usually described by the bang, that take place 2–3 years after the work has been published, and the burst size spans several orders of magnitude. The presence of bursts is not consistent with other models based on preferential attachment. Those models are able to account for the skewed citation distribution but their reference accumulation is gradual.\n\nThe dynamics of scientific production has changed significantly over the past years. Due to technological progress, the number of published papers has been increasing exponentially until now. This, along with a much shorter time needed for the article to be published, has affected the citation dynamics of the modern papers. Furthermore, if the reference list of the study includes papers published in different years, older papers tend to have more citations. This may not necessarily because they are better but just because they had more time to accumulate those references.\n\nIt has been found that citation distributions are best described by a shifted power-law. The probability that paper formula_1 is cited at time formula_2 after publication as:\n\nwhere formula_4 serves as the outcome variable for each particular paper formula_1 at time formula_2. Fitness, formula_7, captures the inherent differences between papers, accounting for the perceived novelty and importance of a discovery. formula_8 represents the cumulative number of citations acquired by a paper formula_1 at time formula_2 and formula_11 is a log-normal survival probability. The probability is equal\n\nwhere formula_2 is time; formula_14 is longevity, capturing the decay rate; and formula_15 indicates immediacy, governing the time for a paper to reach its citation peak.\nThe ultimate impact formula_16 represents the total number or citations that the paper receives during its lifetime.\n\nWhere formula_15 is a global parameter that has the same value for all publications. formula_19 represents the relative fitness of the paper. From the above formula, we can see that the total number of references that the paper can receive during its lifetime depends only on its relative fitness which is very hard to quantify.\n\n"}
{"id": "14308145", "url": "https://en.wikipedia.org/wiki?curid=14308145", "title": "Comparative bullet-lead analysis", "text": "Comparative bullet-lead analysis\n\nComparative bullet-lead analysis (CBLA), also known as compositional bullet-lead analysis, is a now discredited and abandoned forensic technique which used chemistry to link crime scene bullets to ones possessed by suspects on the theory that each batch of lead had a unique elemental makeup.\n\nThe technique was first used after U.S. President John F. Kennedy's assassination in 1963. From the early 1980s through 2004 the US Federal Bureau of Investigation conducted about 2,500 analyses on cases submitted by law-enforcement groups. The results of these analyses had often been questioned by defence lawyers and the press, so the FBI finally asked the United States National Academy of Science's Board on Science, Technology, and Economic Policy to research the scientific merit of the process.\n\nIn 2004 the Board's study was summarized in \"Forensic Analysis: Weighing Bullet Lead Evidence.\" The Board determined that the chemical analyses were being performed correctly and were probably sufficient to determine correlation between two bullets from separate sources (the analysis used plasma-optical emission spectroscopy to identify trace elements in the bullets). The report also concluded that the seven trace elements selected for the analyses (arsenic, antimony, tin, copper, bismuth, silver and cadmium) are acceptable for sample correlation. The report finally concluded that the procedure is the best available method for such correlations. The greatest caveat in the report was that the statistical tests as applied by the FBI could cause confusion and misinterpretation when transmitted to prosecutors or when explained to a trial jury. Because of the significance of this weakness, the report concluded that the analysis should be used with caution. This report helped the FBI decide in 2004 to voluntarily cease offering the analysis to law-enforcement entities. The National Academy of Sciences never required that the FBI stop using the test.\n\n\"CNN PRESENTS Encore Presentation: Reasonable Doubt\" examined the unreliability of this technique. It has been discontinued as of September 1, 2005.\n\nThe U.S. government has fought releasing the list of the estimated 2,500 cases over three decades in which it performed the analysis, which may have led to false convictions. According to the FBI, only 20% of the 2,500 tests performed introduced the CBLA results into evidence at trial.\n\nOn 17 December 2008, Jimmy Ates was released from a Florida prison after serving ten years on the conviction of having murdered his wife, a conviction obtained largely on the strength of a bullet-lead analysis. His conviction was overturned as a consequence of the 2004 report.\n\n"}
{"id": "16264661", "url": "https://en.wikipedia.org/wiki?curid=16264661", "title": "Comparative case", "text": "Comparative case\n\nThe comparative case (abbreviated ) is a grammatical case used in languages such as Mari and Chechen to mark a likeness to something. \n\nIt is not to be confused with the comparative degree, a much more widely used paradigm used to signify heightening of adjectives and adverbs.\n\nIn Mari, the comparative case is marked with the suffix -ла ('-la') For example, if something were to taste like fish (кол - 'kol'), the form used would be колла - 'kolla'). It is also used in regard to languages, when denoting the language a person is speaking, writing, or hearing. Then, however, the accentuation varies slightly from the standard case. Usually, the suffix is not stressed. When it is used with languages, however, it is stressed.\n\nIn Chechen, it is marked with the suffix \"-l\". For example, \"sha\" is 'ice', \"shiila\" is 'cold', and \"shal shiila\" is 'cold as ice'.\n\n"}
{"id": "983601", "url": "https://en.wikipedia.org/wiki?curid=983601", "title": "Comparative genomic hybridization", "text": "Comparative genomic hybridization\n\nComparative genomic hybridization is a molecular cytogenetic method for analysing copy number variations (CNVs) relative to ploidy level in the DNA of a test sample compared to a reference sample, without the need for culturing cells. The aim of this technique is to quickly and efficiently compare two genomic DNA samples arising from two sources, which are most often closely related, because it is suspected that they contain differences in terms of either gains or losses of either whole chromosomes or subchromosomal regions (a portion of a whole chromosome). This technique was originally developed for the evaluation of the differences between the chromosomal complements of solid tumor and normal tissue, and has an improved resolution of 5–10 megabases compared to the more traditional cytogenetic analysis techniques of giemsa banding and fluorescence in situ hybridization (FISH) which are limited by the resolution of the microscope utilized.\n\nThis is achieved through the use of competitive fluorescence in situ hybridization. In short, this involves the isolation of DNA from the two sources to be compared, most commonly a test and reference source, independent labelling of each DNA sample with fluorophores (fluorescent molecules) of different colours (usually red and green), denaturation of the DNA so that it is single stranded, and the hybridization of the two resultant samples in a 1:1 ratio to a normal metaphase spread of chromosomes, to which the labelled DNA samples will bind at their locus of origin. Using a fluorescence microscope and computer software, the differentially coloured fluorescent signals are then compared along the length of each chromosome for identification of chromosomal differences between the two sources. A higher intensity of the test sample colour in a specific region of a chromosome indicates the gain of material of that region in the corresponding source sample, while a higher intensity of the reference sample colour indicates the loss of material in the test sample in that specific region. A neutral colour (yellow when the fluorophore labels are red and green) indicates no difference between the two samples in that location.\n\nCGH is only able to detect unbalanced chromosomal abnormalities. This is because balanced chromosomal abnormalities such as reciprocal translocations, inversions or ring chromosomes do not affect copy number, which is what is detected by CGH technologies. CGH does, however, allow for the exploration of all 46 human chromosomes in single test and the discovery of deletions and duplications, even on the microscopic scale which may lead to the identification of candidate genes to be further explored by other cytological techniques.\n\nThrough the use of DNA microarrays in conjunction with CGH techniques, the more specific form of array CGH (aCGH) has been developed, allowing for a locus-by-locus measure of CNV with increased resolution as low as 100 kilobases. This improved technique allows for the aetiology of known and unknown conditions to be discovered.\n\nThe motivation underlying the development of CGH stemmed from the fact that the available forms of cytogenetic analysis at the time (giemsa banding and FISH) were limited in their potential resolution by the microscopes necessary for interpretation of the results they provided. Furthermore, giemsa banding interpretation has the potential to be ambiguous and therefore has lowered reliability, and both techniques require high labour inputs which limits the loci which may be examined.\n\nThe first report of CGH analysis was by Kallioniemi and colleagues in 1992 at the University of California, San Francisco, who utilised CGH in the analysis of solid tumors. They achieved this by the direct application of the technique to both breast cancer cell lines and primary bladder tumors in order to establish complete copy number karyotypes for the cells. They were able to identify 16 different regions of amplification, many of which were novel discoveries.\n\nSoon after in 1993, du Manoir et al. reported virtually the same methodology. The authors painted a series of individual human chromosomes from a DNA library with two different fluorophores in different proportions to test the technique, and also applied CGH to genomic DNA from patients affected with either Downs syndrome or T-cell prolymphocytic leukemia as well as cells of a renal papillary carcinoma cell line. It was concluded that the fluorescence ratios obtained were accurate and that differences between genomic DNA from different cell types were detectable, and therefore that CGH was a highly useful cytogenetic analysis tool.\n\nInitially, the widespread use of CGH technology was difficult, as protocols were not uniform and therefore inconsistencies arose, especially due to uncertainties in the interpretation of data. However, in 1994 a review was published which described an easily understood protocol in detail and the image analysis software was made available commercially, which allowed CGH to be utilised all around the world.\nAs new techniques such as microdissection and degenerate oligonucleotide primed polymerase chain reaction (DOP-PCR) became available for the generation of DNA products, it was possible to apply the concept of CGH to smaller chromosomal abnormalities, and thus the resolution of CGH was improved.\n\nThe implementation of array CGH, whereby DNA microarrays are used instead of the traditional metaphase chromosome preparation, was pioneered by Solinas-Tolodo et al. in 1997 using tumor cells and Pinkel et al. in 1998 by use of breast cancer cells. This was made possible by the Human Genome Project which generated a library of cloned DNA fragments with known locations throughout the human genome, with these fragments being used as probes on the DNA microarray. Now probes of various origins such as cDNA, genomic PCR products and bacterial artificial chromosomes (BACs) can be used on DNA microarrays which may contain up to 2 million probes. Array CGH is automated, allows greater resolution (down to 100 kb) than traditional CGH as the probes are far smaller than metaphase preparations, requires smaller amounts of DNA, can be targeted to specific chromosomal regions if required and is ordered and therefore faster to analyse, making it far more adaptable to diagnostic uses.\n\nThe DNA on the slide is a reference sample, and is thus obtained from a karyotypically normal man or woman, though it is preferential to use female DNA as they possess two X chromosomes which contain far more genetic information than the male Y chromosome. Phytohaemagglutinin stimulated peripheral blood lymphocytes are used. 1mL of heparinised blood is added to 10ml of culture medium and incubated for 72 hours at 37 °C in an atmosphere of 5% CO. Colchicine is added to arrest the cells in mitosis, the cells are then harvested and treated with hypotonic potassium chloride and fixed in 3:1 methanol/acetic acid.\n\nOne drop of the cell suspension should then be dropped onto an ethanol cleaned slide from a distance of about 30 cm, optimally this should be carried out at room temperature at humidity levels of 60–70%. Slides should be evaluated by visualisation using a phase contrast microscope, minimal cytoplasm should be observed and chromosomes should not be overlapping and be 400–550 bands long with no separated chromatids and finally should appear dark rather than shiny. Slides then need to be air dried overnight at room temperature, and any further storage should be in groups of four at −20 °C with either silica beads or nitrogen present to maintain dryness. Different donors should be tested as hybridization may be variable. Commercially available slides may be used, but should always be tested first.\n\nStandard phenol extraction is used to obtain DNA from test or reference (karyotypically normal individual) tissue, which involves the combination of Tris-Ethylenediaminetetraacetic acid and phenol with aqueous DNA in equal amounts. This is followed by separation by agitation and centrifugation, after which the aqueous layer is removed and further treated using ether and finally ethanol precipitation is used to concentrate the DNA.\n\nMay be completed using DNA isolation kits available commercially which are based on affinity columns.\n\nPreferentially, DNA should be extracted from fresh or frozen tissue as this will be of the highest quality, though it is now possible to use archival material which is formalin fixed or paraffin wax embedded, provided the appropriate procedures are followed. 0.5-1 µg of DNA is sufficient for the CGH experiment, though if the desired amount is not obtained DOP-PCR may be applied to amplify the DNA, however it in this case it is important to apply DOP-PCR to both the test and reference DNA samples to improve reliability.\n\nNick translation is used to label the DNA and involves cutting DNA and substituting nucleotides labelled with fluorophores (direct labelling) or biotin or oxigenin to have fluophore conjugated antibodies added later (indirect labelling). It is then important to check fragment lengths of both test and reference DNA by gel electrophoresis, as they should be within the range of 500kb-1500kb for optimum hybridization.\n\nUnlabelled Life Technologies Corporation's Cot-1 DNA® (placental DNA enriched with repetitive sequences of length 50bp-100bp)is added to block normal repetitive DNA sequences, particularly at centromeres and telomeres, as these sequences, if detected, may reduce the fluorescence ratio and cause gains or losses to escape detection.\n\n8–12µl of each of labelled test and labelled reference DNA are mixed and 40 µg Cot-1 DNA® is added, then precipitated and subsequently dissolved in 6µl of hybridization mix, which contains 50% formamide to decrease DNA melting temperature and 10% dextran sulphate to increase the effective probe concentration in a saline sodium citrate (SSC) solution at a pH of 7.0.\n\nDenaturation of the slide and probes are carried out separately. The slide is submerged in 70% formamide/2xSSC for 5–10 minutes at 72 °C, while the probes are denatured by immersion in a water bath of 80 °C for 10 minutes and are immediately added to the metaphase slide preparation. This reaction is then covered with a coverslip and left for two to four days in a humid chamber at 40 °C.\n\nThe coverslip is then removed and 5 minute washes are applied, three using 2xSSC at room temperature, one at 45 °C with 0.1xSSC and one using TNT at room temperature. The reaction is then preincubated for 10 minutes then followed by a 60-minute, 37 °C incubation, three more 5 minute washes with TNT then one with 2xSSC at room temperature. The slide is then dried using an ethanol series of 70%/96%/100% before counterstaining with DAPI (0.35 μg/ml), for chromosome identification, and sealing with a coverslip.\n\nA fluorescence microscope with the appropriate filters for the DAPI stain as well as the two fluorophores utilised is required for visualisation, and these filters should also minimise the crosstalk between the fluorophores, such as narrow band pass filters. The microscope must provide uniform illumination without chromatic variation, be appropriately aligned and have a “plan” type of objective which is apochromatic and give a magnification of x63 or x100.\n\nThe image should be recorded using a camera with spatial resolution at least 0.1 µm at the specimen level and give an image of at least 600x600 pixels. The camera must also be able to integrate the image for at least 5 to 10 seconds, with a minimum photometric resolution of 8 bit.\n\nDedicated CGH software is commercially available for the image processing step, and is required to subtract background noise, remove and segment materials not of chromosomal origin, normalize the fluorescence ratio, carry out interactive karyotyping and chromosome scaling to standard length. A “relative copy number karyotype” which presents chromosomal areas of deletions or amplifications is generated by averaging the ratios of a number of high quality metaphases and plotting them along an ideogram, a diagram identifying chromosomes based on banding patterns. Interpretation of the ratio profiles is conducted either using fixed or statistical thresholds (confidence intervals). When using confidence intervals, gains or losses are identified when 95% of the fluorescence ratio does not contain 1.0.\n\nExtreme care must be taken to avoid contamination of any step involving DNA, especially with the test DNA as contamination of the sample with normal DNA will skew results closer to 1.0, thus abnormalities may go undetected. FISH, PCR and flow cytometry experiments may be employed to confirm results.\n\nArray comparative genomic hybridization (also microarray-based comparative genomic hybridization, matrix CGH, array CGH, aCGH) is a molecular cytogenetic technique for the detection of chromosomal copy number changes on a genome wide and high-resolution scale. Array CGH compares the patient's genome against a reference genome and identifies differences between the two genomes, and hence locates regions of genomic imbalances in the patient, utilizing the same principles of competitive fluorescence in situ hybridization as traditional CGH.\n\nWith the introduction of array CGH, the main limitation of conventional CGH, a low resolution, is overcome. In array CGH, the metaphase chromosomes are replaced by cloned DNA fragments (+100–200 kb) of which the exact chromosomal location is known. This allows the detection of aberrations in more detail and, moreover, makes it possible to map the changes directly onto the genomic sequence.\n\nArray CGH has proven to be a specific, sensitive, fast and highthroughput technique, with considerable advantages compared to other methods used for the analysis of DNA copy number changes making it more amenable to diagnostic applications. Using this method, copy number changes at a level of 5–10 kilobases of DNA sequences can be detected. , even high-resolution CGH (HR-CGH) arrays are accurate to detect structural variations (SV) at resolution of 200 bp. This method allows one to identify new recurrent chromosome changes such as microdeletions and duplications in human conditions such as cancer and birth defects due to chromosome aberrations.\n\nArray CGH is based on the same principle as conventional CGH. In both techniques, DNA from a reference (or control) sample and DNA from a test (or patient) sample are differentially labelled with two different fluorophores and used as probes that are cohybridized competitively onto nucleic acid targets. In conventional CGH, the target is a reference metaphase spread. In array CGH, these targets can be genomic fragments cloned in a variety of vectors (such as BACs or plasmids), cDNAs, or oligonucleotides.\n\nFigure 2. is a schematic overview of the array CGH technique. DNA from the sample to be tested is labeled with a red fluorophore (Cyanine 5) and a reference DNA sample is labeled with green fluorophore (Cyanine 3). Equal quantities of the two DNA samples are mixed and cohybridized to a DNA microarray of several thousand evenly spaced cloned DNA fragments or oligonucleotides, which have been spotted in triplicate on the array. After hybridization, digital imaging systems are used to capture and quantify the relative fluorescence intensities of each of the hybridized fluorophores. The resulting ratio of the fluorescence intensities is proportional to the ratio of the copy numbers of DNA sequences in the test and reference genomes. If the intensities of the flurochromes are equal on one probe, this region of the patient's genome is interpreted as having equal quantity of DNA in the test and reference samples; if there is an altered Cy3:Cy5 ratio this indicates a loss or a gain of the patient DNA at that specific genomic region.\n\nArray CGH has been implemented using a wide variety of techniques. Therefore, some of the advantages and limitations of array CGH are dependent on the technique chosen.\nThe initial approaches used arrays produced from large insert genomic DNA clones, such as BACs. The use of BACs provides sufficient intense signals to detect single-copy changes and to locate aberration boundaries accurately. However, initial DNA yields of isolated BAC clones are low and DNA amplification techniques are necessary. These techniques include ligation-mediated polymerase chain reaction (PCR), degenerate primer PCR using one or several sets of primers, and rolling circle amplification. Arrays can also be constructed using cDNA. These arrays currently yield a high spatial resolution, but the number of cDNAs is limited by the genes that are encoded on the chromosomes, and their sensitivity is low due to cross-hybridization. This results in the inability to detect single copy changes on a genome wide scale. The latest approach is spotting the arrays with short oligonucleotides. The amount of oligos is almost infinite, and the processing is rapid, cost-effective, and easy. Although oligonucleotides do not have the sensitivity to detect single copy changes, averaging of ratios from oligos that map next to each other on the chromosome can compensate for the reduced sensitivity. It is also possible to use arrays which have overlapping probes so that specific breakpoints may be uncovered.\n\nThere are two approaches to the design of microarrays for CGH applications: whole genome and targeted.\n\nWhole genome arrays are designed to cover the entire human genome. They often include clones that provide an extensive coverage across the genome; and arrays that have contiguous coverage, within the limits of the genome. Whole-genome arrays have been constructed mostly for research applications and have proven their outstanding worth in gene discovery. They are also very valuable in screening the genome for DNA gains and losses at an unprecedented resolution.\n\nTargeted arrays are designed for a specific region(s) of the genome for the purpose of evaluating that targeted segment. It may be designed to study a specific chromosome or chromosomal segment or to identify and evaluate specific DNA dosage abnormalities in individuals with suspected microdeletion syndromes or subtelomeric rearrangements. The crucial goal of a targeted microarray in medical practice is to provide clinically useful results for diagnosis, genetic counseling, prognosis, and clinical management of unbalanced cytogenetic abnormalities.\n\nConventional CGH has been used mainly for the identification of chromosomal regions that are recurrently lost or gained in tumors, as well as for the diagnosis and prognosis of cancer. This approach can also be used to study chromosomal aberrations in fetal and neonatal genomes. Furthermore, conventional CGH can be used in detecting chromosomal abnormalities and have been shown to be efficient in diagnosing complex abnormalities associated with human genetic disorders.\n\nCGH data from several studies of the same tumor type show consistent patterns of non-random genetic aberrations. Some of these changes appear to be common to various kinds of malignant tumors, while others are more tumor specific. For example, gains of chromosomal regions lq, 3q and 8q, as well as losses of 8p, 13q, 16q and 17p, are common to a number of tumor types, such as breast, ovarian, prostate, renal and bladder cancer (Figure. 3). Other alterations, such as 12p and Xp gains in testicular cancer, 13q gain 9q loss in bladder cancer, 14q loss in renal cancer and Xp loss in ovarian cancer are more specific, and might reflect the unique selection forces operating during cancer development in different organs. Array CGH is also frequently used in research and diagnostics of B cell malignancies, such as chronic lymphocytic leukemia.\n\nCri du Chat (CdC) is a syndrome caused by a partial deletion of the short arm of chromosome 5. Several studies have shown that conventional CGH is suitable to detect the deletion, as well as more complex chromosomal alterations. For example, Levy et al. (2002) reported an infant with a cat-like cry, the hallmark of CdC, but having an indistinct karyotype. CGH analysis revealed a loss of chromosomal material from 5p15.3 confirming the diagnosis clinically. These results demonstrate that conventional CGH is a reliable technique in detecting structural aberrations and, in specific cases, may be more efficient in diagnosing complex abnormalities.\n\nArray CGH applications are mainly directed at detecting genomic abnormalities in cancer. However, array CGH is also suitable for the analysis of DNA copy number aberrations that cause human genetic disorders. That is, array CGH is employed to uncover deletions, amplifications, breakpoints and ploidy abnormalities. Earlier diagnosis is of benefit to the patient as they may undergo appropriate treatments and counseling to improve their prognosis.\n\nGenetic alterations and rearrangements occur frequently in cancer and contribute to its pathogenesis. Detecting these aberrations by array CGH provides information on the locations of important cancer genes and can have clinical use in diagnosis, cancer classification and prognostification. However, not all of the losses of genetic material are pathogenetic, since some DNA material is physiologically lost during the rearrangement of immunoglobulin subgenes. In a recent study, array CGH has been implemented to identify regions of chromosomal aberration (copy-number variation) in several mouse models of breast cancer, leading to identification of cooperating genes during myc-induced oncogenesis.\n\nArray CGH may also be applied not only to the discovery of chromosomal abnormalities in cancer, but also to the monitoring of the progression of tumors. Differentiation between metastatic and mild lesions is also possible using FISH once the abnormalities have been identified by array CGH.\n\nPrader–Willi syndrome (PWS) is a paternal structural abnormality involving 15q11-13, while a maternal aberration in the same region causes Angelman syndrome (AS). In both syndromes, the majority of cases (75%) are the result of a 3–5 Mb deletion of the PWS/AS critical region. These small aberrations cannot be detected using cytogenetics or conventional CGH, but can be readily detected using array CGH. As a proof of principle Vissers et al. (2003) constructed a genome wide array with a 1 Mb resolution to screen three patients with known, FISH-confirmed microdeletion syndromes, including one with PWS. In all three cases, the abnormalities, ranging from 1.5 to 2.9Mb, were readily identified. Thus, array CGH was demonstrated to be a specific and sensitive approach in detecting submicroscopic aberrations.\n\nWhen using overlapping microarrays, it is also possible to uncover breakpoints involved in chromosomal aberrations.\n\nThough not yet a widely employed technique, the use of array CGH as a tool for preimplantation genetic screening is becoming an increasingly popular concept. It has the potential to detect CNVs and aneuploidy in eggs, sperm or embryos which may contribute to failure of the embryo to successfully implant, miscarriage or conditions such as Down syndrome (trisomy 21). This makes array CGH a promising tool to reduce the incidence of life altering conditions and improve success rates of IVF attempts. The technique involves whole genome amplification from a single cell which is then used in the array CGH method. It may also be used in couples carrying chromosomal translocations such as balanced reciprocal translocations or Robertsonian translocations, which have the potential to cause chromosomal imbalances in their offspring.\n\nA main disadvantage of conventional CGH is its inability to detect structural chromosomal aberrations without copy number changes, such as mosaicism, balanced chromosomal translocations, and inversions. CGH can also only detect gains and losses relative to the ploidy level. In addition, chromosomal regions with short repetitive DNA sequences are highly variable between individuals and can interfere with CGH analysis. Therefore, repetitive DNA regions like centromeres and telomeres need to be blocked with unlabeled repetitive DNA (e.g. Cot1 DNA) and/or can be omitted from screening. Furthermore, the resolution of conventional CGH is a major practical problem that limits its clinical applications. Although CGH has proven to be a useful and reliable technique in the research and diagnostics of both cancer and human genetic disorders, the applications involve only gross abnormalities. Because of the limited resolution of metaphase chromosomes, aberrations smaller than 5–10 Mb cannot be detected using conventional CGH.\nFor the detection of such abnormalities, a high-resolution technique is required.\nArray CGH overcomes many of these limitations. Array CGH is characterized by a high resolution, its major advantage with respect to conventional CGH. The standard resolution varies between 1 and 5 Mb, but can be increased up to approximately 40 kb by supplementing the array with extra clones. However, as in conventional CGH, the main disadvantage of array CGH is its inability to detect aberrations that do not result in copy number changes and is limited in its ability to detect mosaicism. The level of mosaicism that can be detected is dependent on the sensitivity and spatial resolution of the clones. At present, rearrangements present in approximately 50% of the cells is the detection limit. For the detection of such abnormalities, other techniques, such as SKY (Spectral karyotyping) or FISH have to still be used.\n\n\n"}
{"id": "9435784", "url": "https://en.wikipedia.org/wiki?curid=9435784", "title": "Comparative physiology", "text": "Comparative physiology\n\nComparative physiology is a subdiscipline of physiology that studies and exploits the diversity of functional characteristics of various kinds of organisms. It is closely related to evolutionary physiology and environmental physiology. Many universities offer undergraduate courses that cover comparative aspects of animal physiology. According to Clifford Ladd Prosser, \"Comparative Physiology\nis not so much a defined discipline as a viewpoint, a philosophy.\"\n\nOriginally, physiology focused primarily on human beings, in large part from a desire to improve medical practices. When physiologists first began comparing different species it was sometimes out of simple curiosity to understand how organisms work but also stemmed from a desire to discover basic physiological principles. This use of specific organisms convenient to study specific questions is known as the Krogh Principle.\n\nC. Ladd Prosser, a founder of modern comparative physiology, outlined a broad agenda for comparative physiology in his 1950 edited volume (see summary and discussion in Garland and Carter):\n\n1. To describe how different kinds of animals meet their needs.\n\n2. The use of physiological information to reconstruct phylogenetic relationships of organisms.\n\n3. To elucidate how physiology mediates interactions between organisms and their environments.\n\n4. To identify \"model systems\" for studying particular physiological functions.\n\n5. To use the \"kind of animal\" as an experimental variable.\n\nComparative physiologists often study organisms that live in \"extreme\" environments (e.g., deserts) because they expect to find especially clear examples of evolutionary adaptation. One example is the study of water balance in desert-inhabiting mammals, which have been found to exhibit kidney specializations.\n\nSimilarly, comparative physiologists have been attracted to \"unusual\" organisms, such as very large or small ones. As an example, of the latter, hummingbirds have been studied. As another example, giraffe have been studied because of their long necks and the expectation that this would lead to specializations related to the regulation of blood pressure. More generally, ectothermic vertebrates have been studied to determine how blood acid-base balance and pH change as body temperature changes.\n\nIn the United States, research in comparative physiology is funded by both the National Institutes of Health and the National Science Foundation.\n\nA number of scientific societies feature sections on comparative physiology, including:\n\nKnut Schmidt-Nielsen (1915–2007) was a major figure in vertebrate comparative physiology, serving on the faculty at Duke University for many years and training a large number of students (obituary). He also authored several books, including an influential text, all known for their accessible writing style.\n\nGrover C. Stephens (1925–2003) was a well-known invertebrate comparative physiologist, serving on the faculty of the University of Minnesota until becoming the founding chairman of the Department of Organismic Biology at the University of California at Irvine in 1964. He was the mentor for numerous graduate students, many of whom have gone on to further build the field (obituary). He authored several books and in addition to being an accomplished biologist was also an accomplished pianist and philosopher.\n\n\n\n"}
{"id": "380406", "url": "https://en.wikipedia.org/wiki?curid=380406", "title": "Comparative psychology", "text": "Comparative psychology\n\nComparative psychology refers to the scientific study of the behavior and mental processes of non-human animals, especially as these relate to the phylogenetic history, adaptive significance, and development of behavior. Research in this area addresses many different issues, uses many different methods and explores the behavior of many different species from insects to primates.\n\nComparative psychology is sometimes assumed to emphasize cross-species comparisons, including those between humans and animals. However, some researchers feel that direct comparisons should not be the sole focus of comparative psychology and that intense focus on a single organism to understand its behavior is just as desirable; if not more so. Donald Dewsbury reviewed the works of several psychologists and their definitions and concluded that the object of comparative psychology is to establish principles of generality focusing on both proximate and ultimate causation. \n\nUsing a comparative approach to behavior allows one to evaluate the target behavior from four different, complementary perspectives, developed by Niko Tinbergen. First, one may ask how pervasive the behavior is across species (i.e. how common is the behavior between animal species?). Second, one may ask how the behavior contributes to the lifetime reproductive success of the individuals demonstrating the behavior (i.e. does the behavior result in animals producing more offspring than animals not displaying the behavior)? Theories addressing the ultimate causes of behavior are based on the answers to these two questions.\n\nThird, what mechanisms are involved in the behavior (i.e. what physiological, behavioral, and environmental components are necessary and sufficient for the generation of the behavior)? Fourth, a researcher may ask about the development of the behavior within an individual (i.e. what maturational, learning, social experiences must an individual undergo in order to demonstrate a behavior)? Theories addressing the proximate causes of behavior are based on answers to these two questions. For more details see Tinbergen's four questions.\n\nThe 9th century scholar al-Jahiz wrote works on the social organization and communication methods of animals like ants. The 11th century Arabic writer Ibn al-Haytham (Alhazen) wrote the \"Treatise on the Influence of Melodies on the Souls of Animals\", an early treatise dealing with the effects of music on an imals. In the treatise, he demonstrates how a camel's pace could be hastened or retarded with the use of music, and shows other examples of how music can affect animal behavior, experimenting with horses, birds and reptiles. Through to the 19th century, a majority of scholars in the Western world continued to believe that music was a distinctly human phenomenon, but experiments since then have vindicated Ibn al-Haytham's view that music does indeed have an effect on animals.\n\nCharles Darwin was central in the development of comparative psychology; it is thought that psychology should be spoken in terms of \"pre-\" and \"post-Darwin\" because his contributions were so influential. theory led to several hypotheses, one being that the factors that set humans apart, such as higher mental, moral and spiritual faculties, could be accounted for by evolutionary principles. In response to the vehement opposition to Darwinism was the \"anecdotal movement\" led by George Romanes who set out to demonstrate that animals possessed a \"rudimentary human mind\". Romanes is most famous for two major flaws in his work: his focus on anecdotal observations and entrenched anthropomorphism.\n\nNear the end of the 19th century, several scientists existed whose work was also very influential. Douglas Alexander Spalding was called the \"first experimental biologist\", and worked mostly with birds; studying instinct, imprinting, and visual and auditory development. Jacques Loeb emphasized the importance of objectively studying behavior, Sir John Lubbock is credited with first using mazes and puzzle devices to study learning and Conwy Lloyd Morgan is thought to be \"the first ethologist in the sense in which we presently use the word\".\n\nThroughout the long history of comparative psychology, repeated attempts have been made to enforce a more disciplined approach, in which similar studies are carried out on animals of different species, and the results interpreted in terms of their different phylogenetic or ecological backgrounds. Behavioral ecology in the 1970s gave a more solid base of knowledge against which a true comparative psychology could develop. However, the broader use of the term \"comparative psychology\" is enshrined in the names of learned societies and academic journals, not to mention in the minds of psychologists of other specialisms, so the label of the field is never likely to disappear completely.\n\nA persistent question with which comparative psychologists have been faced is the relative intelligence of different species of animal. Indeed, some early attempts at a genuinely comparative psychology involved evaluating how well animals of different species could learn different tasks. These attempts floundered; in retrospect it can be seen that they were not sufficiently sophisticated, either in their analysis of the demands of different tasks, or in their choice of species to compare. However, the definition of \"intelligence\" in comparative psychology is deeply affected by anthropomorphism, and focuses on simple tasks, complex problems, reversal learning, learning sets, and delayed alternation are plagued with practical and theoretical problems. In the literature, \"intelligence\" is defined as whatever is closest to human performance and neglects behaviors that humans are usually incapable of (e.g. echolocation). Specifically, comparative researchers encounter problems associated with individual differences, differences in motivation, differences in reinforcement, differences in sensory function, differences in motor capacities, and species-typical preparedness (i.e. some species have evolved to acquire some behaviors quicker than other behaviors).\n\nA wide variety of species have been studied by comparative psychologists. However, a small number have dominated the scene. Ivan Pavlov's early work used dogs; although they have been the subject of occasional studies, since then they have not figured prominently. Increasing interest in the study of abnormal animal behavior has led to a return to the study of most kinds of domestic animal. Thorndike began his studies with cats, but American comparative psychologists quickly shifted to the more economical rat, which remained the almost invariable subject for the first half of the 20th century and continues to be used.\n\nSkinner introduced the use of pigeons, and they continue to be important in some fields. There has always been interest in studying various species of primate; important contributions to social and developmental psychology were made by Harry F. Harlow's studies of maternal deprivation in rhesus monkeys. Cross-fostering studies have shown similarities between human infants and infant chimpanzees. Kellogg and Kellogg (1933) aimed to look at heredity and environmental effects of young primates. They found that a cross-fostered chimpanzee named Gua was better at recognizing human smells and clothing and that the Kelloggs' infant (Donald) recognised humans better by their faces. The study ended 9 months after it had begun, after the infant began to imitate the noises of Gua.\n\nNonhuman primates have also been used to show the development of language in comparison with human development. For example, Gardner (1967) successfully taught the female chimpanzee Washoe 350 words in American Sign Language. Washoe subsequently passed on some of this teaching to her adopted offspring, Loulis. A criticism of Washoe's acquisition of sign language focused on the extent to which she actually understood what she was signing. Her signs may have just based on an association to get a reward, such as food or a toy. Other studies concluded that apes do not understand linguistic input, but may form an intended meaning of what is being communicated. All great apes have been reported to have the capacity of allospecific symbolic production.\n\nInterest in primate studies has increased with the rise in studies of animal cognition. Other animals thought to be intelligent have also been increasingly studied. Examples include various species of corvid, parrots — especially the grey parrot — and dolphins. Alex (Avian Learning EXperiment) is a well known case study (1976–2007) which was developed by Pepperberg, who found that the African gray parrot Alex did not only mimic vocalisations but understood the concepts of same and different between objects. The study of non-human mammals has also included the study of dogs. Due to their domestic nature and personalities, dogs have lived closely with humans, and parallels in communication and cognitive behaviours have therefore been recognised and further researched. Joly-Mascheroni and colleagues (2008) demonstrated that dogs may be able to catch human yawns and suggested a level of empathy in dogs, a point that is strongly debated. Pilley and Reid found that a Border Collie named Chaser was able to successfully identify and retrieve 1022 distinct objects/toys.\n\nResearchers who study animal cognition are interested in understanding the mental processes that control complex behavior, and much of their work parallels that of cognitive psychologists working with humans. For example, there is extensive research with animals on attention, categorization, concept formation, memory, spatial cognition, and time estimation. Much research in these and other areas is related directly or indirectly to behaviors important to survival in natural settings, such as navigation, tool use, and numerical competence. Thus, comparative psychology and animal cognition are heavily overlapping research categories.\n\nVeterinary surgeons recognize that the psychological state of a captive or domesticated animal must be taken into account if its behavior and health are to be understood and optimized.\n\nCommon causes of disordered behavior in captive or pet animals are lack of stimulation, inappropriate stimulation, or overstimulation. These conditions can lead to disorders, unpredictable and unwanted behavior, and sometimes even physical symptoms and diseases. For example, rats who are exposed to loud music for a long period will ultimately develop unwanted behaviors that have been compared with human psychosis, like biting their owners.\n\nThe way dogs behave when understimulated is widely believed to depend on the breed as well as on the individual animal's character. For example, huskies have been known to ruin gardens and houses if they are not allowed enough activity. Dogs are also prone to psychological damage if they are subjected to violence. If they are treated very badly, they may become dangerous.\n\nThe systematic study of disordered animal behavior draws on research in comparative psychology, including the early work on conditioning and instrumental learning, but also on ethological studies of natural behavior. However, at least in the case of familiar domestic animals, it also draws on the accumulated experience of those who have worked closely with the animals.\n\nThe relationship between humans and animals has long been of interest to anthropologists as one pathway to an understanding the evolution of human behavior. Similarities between the behavior of humans and animals have sometimes been used in an attempt to understand the evolutionary significance of particular behaviors. Differences in the treatment of animals have been said to reflect a society's understanding of human nature and the place of humans and animals in the scheme of things. Domestication has been of particular interest. For example, it has been argued that, as animals became domesticated, humans treated them as property and began to see them as inferior or fundamentally different from humans.\nIngold remarks that in all societies children have to learn to differentiate and separate themselves from others. In this process, strangers may be seen as \"not people,\" and like animals. Ingold quoted Sigmund Freud: \"Children show no trace of arrogance which urges adult civilized men to draw a hard-and-fast line between their own nature and that of all other animals. Children have no scruples over allowing animals to rank as their full equals.\" With maturity however, humans find it hard to accept that they themselves are animals, so they categorize, separating humans from animals, and animals into wild animals and tame animals, and tame animals into house pets and livestock. Such divisions can be seen as similar to categories of humans: who is part of a human community and someone who isn't, that is, the outsider.\n\n\"The New York Times\" ran an article that showed the psychological benefits of animals, more specifically of children with their pets. It's been proven that having a pet does in fact improve kids' social skills. In the article, Dr. Sue Doescher, a psychologist involved in the study, stated, \"It made the children more cooperative and sharing.\" It was also shown that these kids were more confident with themselves and able to be more empathic with other children.\n\nFurthermore, in an edition of \"Social Science and Medicine\" it was stated, \"A random survey of 339 residents from Perth, Western Australia were selected from three suburbs and interviewed by telephone. Pet ownership was found to be positively associated with some forms of social contact and interaction, and with perceptions of neighborhood friendliness. After adjustment for demographic variables, pet owners scored higher on social capital and civic engagement scales.\" Results like these let us know that owning a pet provides opportunities for neighborly interaction, among many other chances for socialization among people.\n\nNoted comparative psychologists, in this broad sense, include:\n\nMany of these were active in fields other than animal psychology; this is characteristic of comparative psychologists.\n\nFields of psychology and other disciplines that draw upon, or overlap with, comparative psychology include:\n\n\n"}
{"id": "1719952", "url": "https://en.wikipedia.org/wiki?curid=1719952", "title": "Comparative research", "text": "Comparative research\n\nComparative research is a research methodology in the social sciences that aims to make comparisons across different countries or cultures. A major problem in comparative research is that the data sets in different countries may not use the same categories, or define categories differently (for example by using different definitions of poverty).\n\nAs Moutsios argues, cross-cultural and comparative research should be seen as part of the scientific spirit that arose in Greece in the 6th century and the overall appreciation of knowledge and learning that was characteristic of the 5th century. In other words, it is part of the emergence of \"episteme\" and \"philo-sophia\", as a love for knowledge that is independent from material benefits. \"Episteme\", as a form and activity in the field of \"logos\", marked the break of cognitive closure and advanced empirical inquiry, logical argumentation and the search for truth. And the high esteem for intellectual activity gave rise to a genuine curiosity about other cultures – which has lain thereafter at the heart of comparative inquiry.\n\nMoreover, behind the Greek comparative gaze also was the philosophical and political questioning which characterised the life of the democratic \"polis\". Philosophical inquiry, from the Milesians down to the Sophists, questioned the representations and the cognitive traditions of their own people; the inquiry of the traditions of other peoples was, as Herodotus’ \"Histories\" demonstrate, an activity associated with the ethos of philosophical critique that characterised democratic life in Greece. Similarly, questioning of the Greek laws and institutions and its related values and practices (e.g. \"isegoria\" and \"parrhesia\"), as part of Greek politics, is associated with the effort of the first historians to reflect on home institutions through researching those of others.\n\nAccording also to Karl Deutsch, we have been using this form of investigation for over 2,000 years. Comparing things is essential to basic scientific and philosophic inquiry, which has been done for a long time. Most authors are more conservative in their estimate of how long comparative research has been with us. It is largely an empty debate over the definition of the tradition with those questioning whether comparing things counts as comparative research.\n\nTextbooks on this form of study were beginning to appear by the 1880s, but its rise to extreme popularity began after World War II. There are numerous reasons that comparative research has come to take a place of honour in the toolbox of the social scientist. Globalization has been a major factor, increasing the desire and possibility for educational exchanges and intellectual curiosity about other cultures. Information technology has enabled greater production of quantitative data for comparison, and international communications technology has facilitated this information to be easily spread.\n\nComparative research, simply put, is the act of comparing two or more things with a view to discovering something about one or all of the things being compared. This technique often utilizes multiple disciplines in one study. When it comes to method, the majority agreement is that there is no methodology peculiar to comparative research. The multidisciplinary approach is good for the flexibility it offers, yet comparative programs do have a case to answer against the call that their research lacks a \"seamless whole.\" \n\nThere are certainly methods that are far more common than others in comparative studies, however. Quantitative analysis is much more frequently pursued than qualitative, and this is seen by the majority of comparative studies which use quantitative data. The general method of comparing things is the same for comparative research as it is in our everyday practice of comparison. Like cases are treated alike, and different cases are treated differently; the extent of difference determines how differently cases are to be treated. If one is able to sufficiently distinguish two carry the research conclusions will not be very helpful. \n\nSecondary analysis of quantitative data is relatively widespread in comparative research, undoubtedly in part because of the cost of obtaining primary data for such large things as a country's policy environment. This study is generally aggregate data analysis. Comparing large quantities of data (especially government sourced) is prevalent. A typical method of comparing welfare states is to take balance of their levels of spending on social welfare.\n\nIn line with how a lot of theorizing has gone in the last century, comparative research does not tend to investigate \"grand theories,\" such as Marxism. It instead occupies itself with middle-range theories that do not purport to describe our social system in its entirety, but a subset of it. A good example of this is the common research program that looks for differences between two or more social systems, then looks at these differences in relation to some other variable coexisting in those societies to see if it is related. The classic case of this is Esping-Andersen's research on social welfare systems. He noticed there was a difference in types of social welfare systems, and compared them based on their level of decommodification of social welfare goods. He found that he was able to class welfare states into three types, based on their level of decommodification. He further theorized from this that decommodification was based on a combination of class coalitions and mobilization, and regime legacy. Here, Esping-Andersen is using comparative research: he takes many western countries and compares their level of decommodification, then develops a theory of the divergence based on his findings.\n\nComparative research can take many forms. Two key factors are space and time. Spatially, cross-national comparisons are by far the most common, although comparisons within countries, contrasting different areas, cultures or governments also subsist and are very constructive, especially in a country like New Zealand, where policy often changes depending on which race it pertains to. Recurrent interregional studies include comparing similar or different countries or sets of countries, comparing one's own country to others or to the whole world.\n\nThe historical comparative research involves comparing different time-frames. The two main choices within this model are comparing two stages in time (either snapshots or time-series), or just comparing the same thing over time, to see if a policy's effects differ over a stretch of time.\n\nWhen it comes to subject matter of comparative inquiries, many contend there is none unique to it. This may indeed be true, but a brief perusal of comparative endeavours reveals there are some topics more recurrent than others. Determining whether socioeconomic or political factors are more important in explaining government action is a familiar theme. In general, however, the only thing that is certain in comparative research issues is the existence of differences to be analysed.\n\n\n"}
{"id": "11797804", "url": "https://en.wikipedia.org/wiki?curid=11797804", "title": "Comparison (grammar)", "text": "Comparison (grammar)\n\nComparison is a feature in the morphology or syntax of some languages, whereby adjectives and adverbs are inflected or modified to indicate the relative degree of the property defined by the adjective or adverb. The comparative expresses a comparison between two (or more) entities or groups of entities in quality, quantity, or degree; the superlative is the form of an adverb or adjective that is the greatest degree of a given descriptor.\n\nThe grammatical category associated with comparison of adjectives and adverbs is degree of comparison. The usual degrees of comparison are the \"positive\", which simply denotes a property (as with the English words \"big\" and \"fully\"); the \"comparative\", which indicates \"greater degree (as \"bigger\" and \"more fully\"); and the \"superlative\", which indicates \"greatest degree (as \"biggest\" and \"most fully\"). Some languages have forms indicating a very large degree of a particular quality (called elative in Semitic linguistics). Other languages (e.g. English) can express lesser degree, e.g. \"beautiful\", \"less beautiful\", \"least beautiful\".\n\nThe comparative is frequently associated with adjectives and adverbs because these words take the \"-er\" suffix or modifying word \"more\" or \"less\" (e.g., \"faster\", \"more intelligent\", \"less wasteful\"); it can also, however, appear when no adjective or adverb is present, for instance with nouns (e.g., \"more men than women\"). One preposition, \"near\", also has a superlative form, as in \"Find the restaurant nearest your house\".\n\nComparatives and superlatives may be formed morphologically, by inflection, as with the English and German \"-er\" and \"-(e)st\" forms, or syntactically, as with the English \"more...\" and \"most...\" and the French \"plus...\" and \"le plus...\" forms. Common adjectives and adverbs often produce irregular forms, such as \"better\" and \"best\" (from \"good\") and \"less\" and \"least\" (from \"little/few\") in English, and \"meilleur\" (from \"bon\") and \"mieux\" (from the adverb \"bien\") in French.\n\nMost if not all languages have some means of forming the comparative, although these means can vary significantly from one language to the next.\n\nComparatives are often used with a conjunction or other grammatical means to indicate with what the comparison is being made, as with \"than\" in English, \"als\" in German, etc. In Russian and Greek (Ancient, Koine and Modern) this can be done by placing the compared noun in the genitive case. With superlatives, the class of things being considered for comparison may be indicated, as in \"the best swimmer out of all the girls\".\n\nLanguages also possess other structures for comparing adjectives and adverbs; English examples include \"as... as\" and \"less/least...\".\n\nА few languages apply comparison to nouns and even verbs. One such language is Bulgarian, where expressions like \"по̀ човек (po chovek), най човек (nay chovek), по-малко човек (po malko chovek)\" (literally \"more person\", \"most person\", \"less person\" but normally \"better kind of a person\", \"best kind of person\", \"not that good kind of a person\") and \"по̀ обичам (po obicham), най-малко обичам (nay malko obicham)\" (\"I like more\", \"I like the least\") are quite usual.\n\nIn many languages, including English, traditional grammar requires the comparative form to be used when exactly two things are being considered, even in constructions where the superlative would be used when considering a larger number. For instance, \"May the better man win\" would be considered correct if there are only two individuals competing. However, this rule is not always observed in informal usage; the form \"May the best man win\" will often be used in that situation, as it would if there were three or more competitors involved.\n\nIn some contexts, such as advertising or political speeches, absolute and relative comparatives are intentionally employed in a way that invites a comparison, and yet the basis of comparison is not established. This is a common rhetorical device used to create an implication of significance where one may not actually be present. Although such usage is common, it is sometimes considered ungrammatical.\n\nFor example:\n\nEnglish has two parallel systems of comparison, a morphological one formed using the suffixes \"-er\" (the \"comparative\") and \"-est\" (the \"superlative\"), with some irregular forms; and a syntactic one, formed with the adverbs \"more\" and \"most\".\n\nAs a general rule, words with one syllable require the suffix (except for the four words: fun, real, right, wrong), words with three or more syllables require \"more\" or \"most\", and words with two syllables may use one system or the other; which words use which system is a matter of idiom. Some adjectives, \"e.g.\" 'polite', can use either form, with different frequencies according to context.\n\nMorphological comparison uses the suffixes \"-er\" (the \"comparative\") and \"-est\" (the \"superlative\"). These inflections are of Germanic origin and are cognate with the Latin suffixes -\"ior\" and -\"issimus\" and Ancient Greek -\"īōn\" and -\"istos\". They are typically added to shorter words, words of Anglo-Saxon origin, and borrowed words which have been fully assimilated into the English vocabulary. Usually the words which take these inflections have fewer than three syllables.\n\nThis system also contains a number of irregular forms, some of which, like \"good\", \"better\", and \"best\", contain suppletive forms. These irregular forms include:\n\nThe second system of comparison in English appends the grammatical particles \"more\" and \"most\", themselves the irregular comparatives of \"many\" and \"much\", to the adjective or adverb being modified. This series can be compared to a system containing the diminutives \"less\" and \"least\".\n\nThis system is most commonly used with words of French or Latin derivation; with adjectives and adverbs formed with suffixes other than \"-ly\" (e.g., \"beautiful\"); and with longer, technical, or infrequently used words. For example:\n\nSome adjectives, the absolute or ungradable adjectives do not appear to logically allow degrees. Some qualities are either \"present\" or \"absent\", such as being Cretaceous or igneous, so it appears illogical to call anything \"very Cretaceous\", or to characterize something as \"more igneous\" than something else.\n\nSome grammarians object to the use of the superlative or comparative with words such as \"full\", \"complete\", \"unique\", or \"empty\", which by definition already denote either a totality, an absence, or an absolute. However, such words are routinely and frequently qualified in contemporary speech and writing. This type of usage conveys more of a figurative than a literal meaning, because in a strictly literal sense, something cannot be more or less unique or empty to a greater or lesser degree.\n\nMany prescriptive grammars and style guides include adjectives for inherently superlative qualities to be ungradable. Thus, they reject expressions such as \"more perfect\", \"most unique\", and \"most parallel\" as illogical pleonasms: after all, if something is unique, it is one of a kind, so nothing can be \"very unique\", or \"more unique\" than something else.\n\nOther style guides argue that terms like \"perfect\" and \"parallel\" never apply \"exactly\" to things in real life, so they are commonly used to mean \"nearly perfect\", \"nearly parallel\", and so on; in this sense, \"more perfect\" (\"i.e.\", more nearly perfect, closer to perfect) and \"more parallel\" (\"i.e.\", more nearly parallel, closer to parallel) are meaningful.\n\nIn most Balto-Slavic languages (such as Czech, Polish, Lithuanian and Latvian), the comparative and superlative forms are also declinable adjectives.\n\nIn Bulgarian, comparative and superlative forms are formed with the clitics \"по-\" (\"more\") and \"най-\" (\"most\"):\n\nIn Czech, Polish, Slovak and Slovene, comparative is formed from the base form of an adjective with a suffix and superlative is formed with a circumfix (equivalent to adding a prefix to the comparative).\n\nIn Russian, comparative and superlative forms are usually formed with a suffix:\n\nIn contrast to English, the relative and the superlative are joined into the same degree (the superlative), which can be of two kinds: comparative (e.g. \"the most beautiful\") and absolute (e.g. \"very beautiful\").\n\nFrench: The superlative is created from the comparative by inserting the definitive article (la, le, or les), or the possessive article (\"mon\", \"ton\", \"son\", etc.), before \"plus\" or \"moins\" and the adjective determining the noun. For instance: \"Elle est la plus belle femme\" → (she is the most beautiful woman); \"Cette ville est la moins chère de France\" → (this town is the least expensive in France); \"C'est sa plus belle robe\" → (It is her most beautiful dress). It can also be created with the suffix \"-issime\" but only with certain words, for example: \"C'est un homme richissime\" → (That is the most rich man). Its use is often rare and ironic.\n\nPortuguese and Italian distinguish comparative superlative \"(superlativo relativo)\" and absolute superlative \"(superlativo absoluto/assoluto).\nFor the comparative superlative they use the words \"mais\" and \"più\" between the article and the adjective, like \"most\" in English.\nFor the absolute superlative they either use \"muito\"/\"molto\" and the adjective or modify the adjective by taking away the final vowel and adding \"issimo\" (singular masculine), \"issima\" (singular feminine), \"íssimos\"/\"issimi\" (plural masculine), or \"íssimas\"/\"issime\" (plural feminine). For example:\nThere are some irregular forms for some words ending in \"-re\" and \"-le\" (deriving from Latin words ending in \"-er\" and \"-ilis\") that have a superlative form similar to the Latin one. In the first case words lose the ending \"-re\" and they gain the endings \"errimo\" (singular masculine), \"errima\" (singular feminine), \"érrimos\"/\"errimi\" (plural masculine), or \"érrimas\"/\"errime\" (plural feminine); in the second case words lose the \"-l\"/\"-le\" ending and gain \"ílimo\"/\"illimo\" (singular masculine), \"ílima\"/\"illima\" (singular feminine), \"ílimos\"/\"illimi\" (plural masculine), or \"íli\nRomanian, similar to Portuguese and Italian, distinguishes comparative and absolute superlatives. The comparative uses the word \"mai\" before the adjective, which operates like \"more\" or \"-er\" in English. For example: \"luminos\" → bright, \"mai luminos\" → brighter. To weaken the adjective, the word \"puțin\" (little) is added between \"mai\" and the adjective, for example \"mai puțin luminos\" → less bright. For absolute superlatives, the gender-dependent determinant \"cel\" precedes \"mai,\" conjugated as \"cel / cei\" for male singular / plural and \"cea / cele\" for female singular / plural. For example: \"cea mai luminoasă stea\" → the brightest star; \"cele mai frumoase fete\" → the most beautiful girls; \"cel mai mic morcov\" → the smallest carrot.\n\nScottish Gaelic: When comparing one entity to another in the present or the future tense, the adjective is changed by adding an \"e\" to the end and \"i\" before the final consonant(s) if the final vowel is broad. Then, the adjective is preceded by \"nas\" to say \"more,\" and \"as\" to say \"most.\" (The word \"na\" is used to mean \"than\".) Adjectives that begin with \"f\" are lenited. and \"as\" use different syntax constructions. For example:\nTha mi nas àirde na mo pheathraichean.\" → I am taller than my sisters.\nIs mi as àirde.\" → I am the tallest.\n\nAs in English, some forms are irregular, i.e. nas fheàrr (better), nas miosa (worse), etc.\n\nIn other tenses, \"nas\" is replaced by \"na bu\" and \"as\" by \"a bu,\" both of which lenite the adjective if possible. If the adjective begins with a vowel or an \"f\" followed by a vowel, the word \"bu\" is reduced to \"b\"'. For example:\n\n\nWelsh is similar to English in many respects. The ending \"-af\" is added onto regular adjectives in a similar manner to the English \"-est\", and with (most) long words \"mwyaf\" precedes it, as in the English \"most\". Also, many of the most common adjectives are irregular. Unlike English, however, when comparing just two things, the superlative \"must\" be used, e.g. of two people - \"John ydy'r talaf\" (John is the tallest).\n\nIn Akkadian cuneiform, (on a 12 paragraph clay tablet), from the time period of the 1350 BC Amarna letters (a roughly 20-year body of letters), two striking examples of the superlative extend the common grammatical use. The first is the numeral \"10,\" as well as \"7 and 7.\" The second is a verb-spacement adjustment.\n\nThe term \"7 and 7\" means 'over and over'. The phrase itself is a superlative, but an addition to some of the Amarna letters adds \"more\" at the end of the phrase (EA 283, \"Oh to see the King-(pharaoh)):\" \"... I fall at the feet of the king, my lord. I fall at the feet of the king, my lord, 7 and 7 times\" more, \"...\". The word 'more' is Akkadian \"mila\", and by Moran is 'more' or 'overflowing'. The meaning in its letter context is \"...over and over again, overflowing,\" (as 'gushingly', or 'obsequiously', as an underling of the king).\n\nThe numeral 10 is used for \"ten times greater\" in EA 19, \"Love and Gold\", one of King Tushratta's eleven letters to the Pharaoh-(Amenhotep IV-\"Akhenaton\"). The following quote using 10, also closes out the small paragraph by the second example of the superlative, where the verb that ends the last sentence is spread across the letter in s-p-a-c-i-n-g, to accentuate the last sentence, and the verb itself (i.e. the relational kingly topic of the paragraph):\n\nThe actual last paragraph line contains three words: 'may it be', 'flourish', and 'us'. The verb flourish (from napāhu?, \"to light up, to rise\"), uses: -e-le-né-ep-pi-, and the spaces. The other two words on the line, are made from two characters, and then one: \"...may it be, flourish-our (relations).\"\n\nIn Estonian, the superlative form can usually be formed in two ways. One is a periphrastic construction with \"kõige\" followed by the comparative form. This form exists for all adjectives. For example: the comparative form of \"sinine\" 'blue' is \"sinisem\" and therefore the periphrastic superlative form is \"kõige sinisem\". There is also a synthetic (\"short\") superlative form, which is formed by adding \"-m\" to the end of the plural partitive case. For \"sinine\" the plural partitive form is \"siniseid\" and so \"siniseim\" is the short superlative. The short superlative does not exist for all adjectives and, in contrast to the \"kõige\"-form, has a lot of exceptions.\n\n"}
{"id": "1266596", "url": "https://en.wikipedia.org/wiki?curid=1266596", "title": "Comparison of Dewey and Library of Congress subject classification", "text": "Comparison of Dewey and Library of Congress subject classification\n\nThis is a conversion chart showing how the Dewey Decimal and Library of Congress Classification systems organize resources by concept, in part for the purpose of assigning . These two systems account for over 95% of the classification in United States libraries, and are used widely around the world.\n\nThe chart includes all ninety-nine second level (two-digit) DDC classes (040 is not assigned), and should include all second level (two-digit) LCC classes. Where a class in one system maps to several classes in other system, it will be listed multiple times (e.g. DDC class 551).\n\nAdditional information on these classification plans is available at:\n\n\n"}
{"id": "1338683", "url": "https://en.wikipedia.org/wiki?curid=1338683", "title": "Corecursion", "text": "Corecursion\n\nIn computer science, corecursion is a type of operation that is dual to recursion. Whereas recursion works analytically, starting on data further from a base case and breaking it down into smaller data and repeating until one reaches a base case, corecursion works synthetically, starting from a base case and building it up, iteratively producing data further removed from a base case. Put simply, corecursive algorithms use the data that they themselves produce, bit by bit, as they become available, and needed, to produce further bits of data. A similar but distinct concept is \"generative recursion\" which may lack a definite \"direction\" inherent in corecursion and recursion.\n\nWhere recursion allows programs to operate on arbitrarily complex data, so long as they can be reduced to simple data (base cases), corecursion allows programs to produce arbitrarily complex and potentially infinite data structures, such as streams, so long as it can be produced from simple data (base cases) in a sequence of \"finite\" steps. Where recursion may not terminate, never reaching a base state, corecursion starts from a base state, and thus produces subsequent steps deterministically, though it may proceed indefinitely (and thus not terminate under strict evaluation), or it may consume more than it produces and thus become non-\"productive\". Many functions that are traditionally analyzed as recursive can alternatively, and arguably more naturally, be interpreted as corecursive functions that are terminated at a given stage, for example recurrence relations such as the factorial.\n\nCorecursion can produce both finite and infinite data structures as results, and may employ self-referential data structures. Corecursion is often used in conjunction with lazy evaluation, to produce only a finite subset of a potentially infinite structure (rather than trying to produce an entire infinite structure at once). Corecursion is a particularly important concept in functional programming, where corecursion and codata allow total languages to work with infinite data structures.\n\nCorecursion can be understood by contrast with recursion, which is more familiar. While corecursion is primarily of interest in functional programming, it can be illustrated using imperative programming, which is done below using the generator facility in Python. In these examples local variables are used, and assigned values imperatively (destructively), though these are not necessary in corecursion in pure functional programming. In pure functional programming, rather than assigning to local variables, these computed values form an invariable sequence, and prior values are accessed by self-reference (later values in the sequence reference earlier values in the sequence to be computed). The assignments simply express this in the imperative paradigm and explicitly specify where the computations happen, which serves to clarify the exposition.\n\nA classic example of recursion is computing the factorial, which is defined recursively by \"0! := 1\" and \"n! := n × (n - 1)!\".\n\nTo \"recursively\" compute its result on a given input, a recursive function calls (a copy of) \"itself\" with a different (\"smaller\" in some way) input and uses the result of this call to construct its result. The recursive call does the same, unless the \"base case\" has been reached. Thus a call stack develops in the process. For example, to compute \"fac(3)\", this recursively calls in turn \"fac(2)\", \"fac(1)\", \"fac(0)\" (\"winding up\" the stack), at which point recursion terminates with \"fac(0) = 1\", and then the stack unwinds in reverse order and the results are calculated on the way back along the call stack to the initial call frame \"fac(3)\" that uses the result of \"fac(2) = 2\" to calculate the final result as \"3 × 2 = 3 × fac(2) =: fac(3)\" and finally return \"fac(3) = 6\". In this example a function returns a single value.\n\nThis stack unwinding can be explicated, defining the factorial \"corecursively\", as an iterator, where one \"starts\" with the case of formula_1, then from this starting value constructs factorial values for increasing numbers \"1, 2, 3...\" as in the above recursive definition with \"time arrow\" reversed, as it were, by reading it \"backwards\" as The corecursive algorithm thus defined produces a \"stream\" of \"all\" factorials. This may be concretely implemented as a generator. Symbolically, noting that computing next factorial value requires keeping track of both \"n\" and \"f\" (a previous factorial value), this can be represented as:\nor in Haskell, \n\nmeaning, \"starting from formula_3, on each step the next values are calculated as formula_4\". This is mathematically equivalent and almost identical to the recursive definition, but the formula_5 emphasizes that the factorial values are being built \"up\", going forwards from the starting case, rather than being computed after first going backwards, \"down\" to the base case, with a formula_6 decrement. Note also that the direct output of the corecursive function does not simply contain the factorial formula_7 values, but also includes for each value the auxiliary data of its index \"n\" in the sequence, so that any one specific result can be selected among them all, as and when needed.\n\nNote the connection with denotational semantics, where the denotations of recursive programs is built up corecursively in this way.\n\nIn Python, a recursive factorial function can be defined as:\n\nThis could then be called for example as codice_1 to compute \"5!\".\n\nA corresponding corecursive generator can be defined as:\n\nThis generates an infinite stream of factorials in order; a finite portion of it can be produced by:\n\nThis could then be called to produce the factorials up to \"5!\" via:\n\nIf we're only interested in a certain factorial, just the last value can be taken, or we can fuse the production and the access into one function,\n\nAs can be readily seen here, this is practically equivalent (just by substituting codice_2 for the only codice_3 there) to the accumulator argument technique for tail recursion, unwound into an explicit loop. Thus it can be said that the concept of corecursion is an explication of the embodiment of iterative computation processes by recursive definitions, where applicable.\n\nIn the same way, the Fibonacci sequence can be represented as:\nNote that because the Fibonacci sequence is a recurrence relation of order 2, the corecursive relation must track two successive terms, with the formula_9 corresponding to shift forward by one step, and the formula_10 corresponding to computing the next term. This can then be implemented as follows (using parallel assignment):\n\nIn Haskell, \n\nTree traversal via a depth-first approach is a classic example of recursion. Dually, breadth-first traversal can very naturally be implemented via corecursion.\n\nWithout using recursion or corecursion specifically, one may traverse a tree by starting at the root node, placing its child nodes in a data structure, then iterating by removing node after node from the data structure while placing each removed node's children back into that data structure. If the data structure is a stack (LIFO), this yields depth-first traversal, and if the data structure is a queue (FIFO), this yields breadth-first traversal.\n\nUsing recursion, a (post-order) depth-first traversal can be implemented by starting at the root node and recursively traversing each child subtree in turn (the subtree based at each child node) – the second child subtree does not start processing until the first child subtree is finished. Once a leaf node is reached or the children of a branch node have been exhausted, the node itself is visited (e.g., the value of the node itself is outputted). In this case, the call stack (of the recursive functions) acts as the stack that is iterated over.\n\nUsing corecursion, a breadth-first traversal can be implemented by starting at the root node, outputting its value, then breadth-first traversing the subtrees – i.e., passing on the \"whole list\" of subtrees to the next step (not a single subtree, as in the recursive approach) – at the next step outputting the value of all of their root nodes, then passing on their child subtrees, etc. In this case the generator function, indeed the output sequence itself, acts as the queue. As in the factorial example (above), where the auxiliary information of the index (which step one was at, \"n\") was pushed forward, in addition to the actual output of \"n\"!, in this case the auxiliary information of the remaining subtrees is pushed forward, in addition to the actual output. Symbolically:\nmeaning that at each step, one outputs the list of values of root nodes, then proceeds to the child subtrees. Generating just the node values from this sequence simply requires discarding the auxiliary child tree data, then flattening the list of lists (values are initially grouped by level (depth); flattening (ungrouping) yields a flat linear list). In Haskell, \nThese can be compared as follows. The recursive traversal handles a \"leaf node\" (at the \"bottom\") as the base case (when there are no children, just output the value), and \"analyzes\" a tree into subtrees, traversing each in turn, eventually resulting in just leaf nodes – actual leaf nodes, and branch nodes whose children have already been dealt with (cut off \"below\"). By contrast, the corecursive traversal handles a \"root node\" (at the \"top\") as the base case (given a node, first output the value), treats a tree as being \"synthesized\" of a root node and its children, then produces as auxiliary output a list of subtrees at each step, which are then the input for the next step – the child nodes of the original root are the root nodes at the next step, as their parents have already been dealt with (cut off \"above\"). Note also that in the recursive traversal there is a distinction between leaf nodes and branch nodes, while in the corecursive traversal there is no distinction, as each node is treated as the root node of the subtree it defines.\n\nNotably, given an infinite tree, the corecursive breadth-first traversal will traverse all nodes, just as for a finite tree, while the recursive depth-first traversal will go down one branch and not traverse all nodes, and indeed if traversing post-order, as in this example (or in-order), it will visit no nodes at all, because it never reaches a leaf. This shows the usefulness of corecursion rather than recursion for dealing with infinite data structures.\n\nIn Python, this can be implemented as follows.\nThe usual post-order depth-first traversal can be defined as:\n\nThis can then be called by codice_4 to print the values of the nodes of the tree in post-order depth-first order.\n\nThe breadth-first corecursive generator can be defined as:\n\nThis can then be called to print the values of the nodes of the tree in breadth-first order:\n\nInitial data types can be defined as being the least fixpoint (up to isomorphism) of some type equation; the isomorphism is then given by an initial algebra. Dually, final (or terminal) data types can be defined as being the greatest fixpoint of a type equation; the isomorphism is then given by a final coalgebra.\n\nIf the domain of discourse is the category of sets and total functions, then final data types may contain infinite, non-wellfounded values, whereas initial types do not. On the other hand, if the domain of discourse is the category of complete partial orders and continuous functions, which corresponds roughly to the Haskell programming language, then final types coincide with initial types, and the corresponding final coalgebra and initial algebra form an isomorphism.\n\nCorecursion is then a technique for recursively defining functions whose range (codomain) is a final data type, dual to the way that ordinary recursion recursively defines functions whose domain is an initial data type.\n\nThe discussion below provides several examples in Haskell that distinguish corecursion. Roughly speaking, if one were to port these definitions to the category of sets, they would still be corecursive. This informal usage is consistent with existing textbooks about Haskell. Also note that the examples used in this article predate the attempts to define corecursion and explain what it is.\n\nThe rule for \"primitive corecursion\" on codata is the dual to that for primitive recursion on data. Instead of descending on the argument by pattern-matching on its constructors (that \"were called up before\", somewhere, so we receive a ready-made datum and get at its constituent sub-parts, i.e. \"fields\"), we ascend on the result by filling-in its \"destructors\" (or \"observers\", that \"will be called afterwards\", somewhere - so we're actually calling a constructor, creating another bit of the result to be observed later on). Thus corecursion \"creates\" (potentially infinite) codata, whereas ordinary recursion \"analyses\" (necessarily finite) data. Ordinary recursion might not be applicable to the codata because it might not terminate. Conversely, corecursion is not strictly necessary if the result type is data, because data must be finite.\n\nIn \"Programming with streams in Coq: a case study: the Sieve of Eratosthenes\" we find\n\nwhere primes \"are obtained by applying the primes operation to the stream (Enu 2)\". Following the above notation, the sequence of primes (with a throwaway 0 prefixed to it) and numbers streams being progressively sieved, can be represented as \nor in Haskell, \n\nThe authors discuss how the definition of codice_5 is not guaranteed always to be \"productive\", and could become stuck e.g. if called with codice_6 as the initial stream.\n\nHere is another example in Haskell. The following definition produces the list of Fibonacci numbers in linear time:\nThis infinite list depends on lazy evaluation; elements are computed on an as-needed basis, and only finite prefixes are ever explicitly represented in memory. This feature allows algorithms on parts of codata to terminate; such techniques are an important part of Haskell programming.\n\nThis can be done in Python as well:\nThe definition of codice_7 can be inlined, leading to this:\n\nThis example employs a self-referential \"data structure\". Ordinary recursion makes use of self-referential \"functions\", but does not accommodate self-referential data. However, this is not essential to the Fibonacci example. It can be rewritten as follows:\n\nThis employs only self-referential \"function\" to construct the result. If it were used with strict list constructor it would be an example of runaway recursion, but with non-strict list constructor this guarded recursion gradually produces an indefinitely defined list.\n\nCorecursion need not produce an infinite object; a corecursive queue is a particularly good example of this phenomenon. The following definition produces a breadth-first traversal of a binary tree in linear time:\n\nThis definition takes an initial tree and produces a list of subtrees. This list serves dual purpose as both the queue and the result ( produces its output notches after its input back-pointer, , along the ). It is finite if and only if the initial tree is finite. The length of the queue must be explicitly tracked in order to ensure termination; this can safely be elided if this definition is applied only to infinite trees. \n\nAnother particularly good example gives a solution to the problem of breadth-first labeling. The function codice_8 visits every node in a binary tree in a breadth first fashion, and replaces each label with an integer, each subsequent integer is bigger than the last by one. This solution employs a self-referential data structure, and the binary tree can be finite or infinite.\n\nAn apomorphism (such as an anamorphism, such as unfold) is a form of corecursion in the same way that a paramorphism (such as a catamorphism, such as fold) is a form of recursion.\n\nThe Coq proof assistant supports corecursion and coinduction using the CoFixpoint command.\n\nCorecursion, referred to as \"circular programming,\" dates at least to , who credits John Hughes and Philip Wadler; more general forms were developed in . The original motivations included producing more efficient algorithms (allowing 1 pass over data in some cases, instead of requiring multiple passes) and implementing classical data structures, such as doubly linked lists and queues, in functional languages.\n\n\n"}
{"id": "1902180", "url": "https://en.wikipedia.org/wiki?curid=1902180", "title": "Digital reference", "text": "Digital reference\n\nDigital reference (or virtual reference) is a service by which a library reference service is conducted online, and the reference transaction is a computer-mediated communication. It is the remote, NextNextcomputer-mediated delivery of reference information provided by library professionals to users who cannot access or do not want face-to-face communication. Virtual reference service is most often an extension of a library's existing reference service program. The word \"reference\" in this context refers to the task of providing assistance to library users in finding information, answering questions, and otherwise fulfilling users’ information needs. Reference work often but not always involves using reference works, such as dictionaries, encyclopedias, etc. This form of reference work expands reference services from the physical reference desk to a \"virtual\" reference desk where the patron could be writing from home, work or a variety of other locations.\n\nThe terminology surrounding virtual reference services may involve multiple terms used for the same definition. The preferred term for remotely delivered, computer-mediated reference services is \"virtual reference\", with the secondary non-preferred term \"digital reference\" having gone out of use in recent years. \"Chat reference\" is often used interchangeably with virtual reference, although it represents only one aspect of virtual reference. Virtual reference includes the use of both synchronous (i.e., IM, videoconferencing) and asynchronous communication (i.e., texting and email). Here, \"synchronous virtual reference\" refers to any real-time computer-mediated communication between patron and information professional. Asynchronous virtual reference is all computer-mediated communication that is sent and received at different times.\n\nThe earliest digital reference services were launched in the mid-1980s, primarily by academic and medical libraries, and provided by e-mail. These early-adopter libraries launched digital reference services for two main reasons: to extend the hours that questions could be submitted to the reference desk, and to explore the potential of campus-wide networks, which at that time was a new technology.\n\nWith the advent of the graphical World Wide Web, libraries quickly adopted webforms for question submission. Since then, the percentage of questions submitted to services via webforms has outstripped the percentage submitted via email.\n\nIn the early- to mid-1990s, digital reference services began to appear that were not affiliated with any library. These digital reference services are often referred to as \"AskA\" services. Examples of AskA services are the Internet Public Library, Ask Dr. Math, and Ask Joan of Art.\n\nProviding remote-based services for patrons has been a steady practice of libraries over the years. For example, before the widespread use of chat software, reference questions were often answered via phone, fax, email and audio conferencing. Email is the oldest type of virtual reference service used by libraries. Library services in America and the UK are just now gaining visibility in their use of virtual reference services using chat software. However, a survey in America revealed that by 2001 over 200 libraries were using chat reference services. \nThe rapid global proliferation of information technology (IT) often leaves libraries at a disadvantage in terms of keeping their services current. However, libraries are always striving to understand their user demographics in order to provide the best possible services. Therefore, libraries continue to take notes from current cyberculture and are continually incorporating a diversified range of interactive technologies in their service repertoires. Virtual reference represents only one small part of a larger library mission to meet the needs of a new generation, sometimes referred to as the \"Google Generation\", of users who have grown up with the internet. For instance, virtual reference may be used in conjunction with embedded Web 2.0 (online social media such as Facebook, YouTube, blogs, del.icio.us, Flickr, etc.) applications in a library's suite of online services. As technological innovations continue, libraries will be watching to find new, more personalized ways of interacting with remote reference users.\n\nThe range of cost-per-transaction of reference interactions has been found to be large, due to the differences in librarian salaries and infrastructural costs required by reference interviews.\n\nWebforms are created for digital reference services in order to help the patron be more productive in asking their question. This document helps the librarian locate exactly what the patron is asking for. Creation of webforms requires design consideration. Because webforms substitute for the reference interview, receiving as much information as possible from the patron is a key function.\n\nAspects commonly found within webforms:\n\n\nSeveral applications exist for providing chat-based reference. Some of these applications are: QuestionPoint, OmniReference, Tutor.com, LibraryH3lp, AspiringKidz.com, and Vienova.com. These applications bear a resemblance to commercial help desk applications. These applications possess functionality such as: chat, co-browsing of webpages, webpage and document pushing, customization of pre-scripted messages, storage of chat transcripts, and statistical reporting.\n\nInstant messaging (IM) services are used by some libraries as a low-cost means of offering chat-based reference, since most IM services are free. Utilizing IM for reference services allows a patron to contact the library from any location via the internet. This service is like the traditional reference interview because it is a live interaction between the patron and the librarian. On the other side the reference interview is different because the conversation does not float away but instead is in print on the screen for the librarian to review if needed to better understand the patron. IM reference services may be for the use of in-house patrons as well as patrons unable to go to the library. If library computers support IM chat programs, patrons may IM from within the library to avoid losing their use of a computer or avoid making embarrassing questions public.\n\nSuccessful IM reference services will:\n\nAt times, IM becomes challenging because of lack of non-verbal cues such as eye contact, and the perceived time pressure. Moreover, formulating the question online without the give and take of nonverbal cues and face to face conversation presents an added obstacle. In addition, to provide effective reference service through IM, it is important to meet higher level of information literacy standards. These standards include evaluating the information and its source, synthesizing the information to create new ideas or products, and understanding the societal, legal, and economic issues surrounding its use.\n\nThe article Live, Digital Reference Marketplace by Buff Hirko contains a comparison of the features of applications for chat-based reference.\n\nSee the entries in the Library Success Wiki's Online Reference Section, including software recommended for web-based chat reference, IM reference, SMS (text messaging) reference, and other types like digital audio or video reference.\n\nVirtual service software programs offered by libraries are often unique, and tailored to the individual library's needs. However, each program may have several distinct features. A knowledge base is a chunk of information that users can access independently. An example of this is a serialized listing of frequently asked questions (FAQ) that a user can read and use at his or her leisure.\n\nOnline chat, or instant messaging (IM) has become a very popular Web-based feature. Instant messaging is a real time conversation that utilizes typed text instead of language. Users may feel a sense of satisfaction with the use of this tool because of their personalized interaction with staff.\n\nThe use of electronic mail (email) in responding to reference questions in libraries has been in use for years. Also, in some cases with the IM feature, a question may be asked that cannot be resolved in online chat. In this instance the staff member may document the inquiring patron’s email address and will the user a response.\n\nWith the increase in use of text messaging (Short Message Service or SMS), some libraries are also adopting text messaging in their virtual reference services. Librarians can use mobile phones, text-to-instant messaging or web-based services to respond to reference questions via text messaging.\n\nCo-browsing, or cooperative browsing, is a virtual reference function that involves interactive control of a user’s web browser. This function enables the librarian to see what the patron has on his or her computer screen. Several types of co-browsing have been offered in mobile devices of late; libraries may have software that incorporates dual modes of co-browsing in a variety of formats. For instance, it is possible to browse on a mobile device within and between documents (such as Word), webpages, and images.\n\nVirtual reference services are growing in popularity in the UK with more institutions accepting queries via email, instant messaging and other chat based services. A study of the use of virtual reference within UK academic institutions showed that 25% currently offer a form of virtual reference, with 54% of academic institutions surveyed considering adding this service.\n\nUK public libraries were instrumental in some of the first steps towards UK-wide internet collaboration amongst libraries with the EARL Consortium (Electronic Access to Resources in Libraries) in 1995, in a time where internet access was a rare commodity for both library staff and the public. Resources were collated and lines of communication opened between libraries across the UK, paving the way for services all over the world to follow suit. There are now a number of area-specific reference services across the UK including Ask A Librarian (UK-wide, established in 1997), Ask Cymru (Welsh and English language service), Enquire (Government funded through the People's Network, also UK-wide), and Ask Scotland. Ask Scotland was created by the Scottish Government's advisory body on libraries, SLIC (Scottish Library and Information Council), and funded by the Public Library Quality Improvement Fund (PLQIF) in June 2009. It uses the Online Computer Library Center's QuestionPoint software.\n\nThe definition formulated by the American Library Association's (ALA) 2004 MARS Digital Reference Guidelines Ad Hoc Committee contains three components:\n\n\nIn January 2011 QuestionPoint and the American Library Association were in talks about offering a National Ask A Librarian service across the whole United States of America. At present the Ask services in the US are run at a local level.\n\nIn Europe some countries offer services in both their own national language and in English. European countries include: Finland, the Netherlands (in Dutch only), Denmark, and France.\n\nOther countries which offer virtual reference services include: Australia, New Zealand, Canada, and the state of Colorado in the United States.\n\nA collaboration between UK and Australian library services, entitled Chasing the Sun, has been initiated using QuestionPoint software so that an all-hours digital reference chat service can be offered. Targeted at health libraries where reference queries from health professionals could occur at any time of the day or night due to medical emergencies, the collaboration between the two countries means that someone will be on hand to field the query at any time. Although the UK libraries involved are currently based in England the programme may expand to other countries and health services if successful.\n\n\n\n\nThe following provide software and technology infrastructure for digital/virtual reference.\n\n\n\n\n\n"}
{"id": "1054566", "url": "https://en.wikipedia.org/wiki?curid=1054566", "title": "Ditloid", "text": "Ditloid\n\nA ditloid is a type of word puzzle, in which a phrase, quotation, date, or fact must be deduced from the numbers and abbreviated letters in the clue. Common words such as 'the', 'in', 'a', 'an', 'of', 'to', etc. are not normally abbreviated. The name 'ditloid' was given by the \"Daily Express\" newspaper, originating from the clue: 1 = DitLoID ≡ \"1 Day in the Life of Ivan Denisovich\".\n\nWill Shortz originated the current form of this puzzle and first published it in the May–June 1981 issue of \"Games\" magazine, calling it the Equation Analysis Test. In its annual 1981 issue of \"What's hot and what's not,\" \"Us\" magazine named the Equation Analysis Test in the \"what's hot\" category – the only nonperson so recognized. Shortz reports:\nSome anonymous person had retyped the puzzle from \"Games\" (word for word, except for my byline),\nphotocopied it, and passed it along. This page was then rephotocopied ad infinitum, like a chain letter,\nand circulated around the country. \"Games\" readers who hadn't seen the original even started sending\nit back to \"Games\" as something the magazine ought to consider publishing!\nShortz based the puzzle on the Formula Analysis Test - Revised Form published in Morgan Worthy's 1975 book \"AHA! A Puzzle Approach to Creative Thinking\" (Chicago: Nelson Hall). Worthy's equations were in a different format, for example:\n\nWorthy gives the source of his inspiration and speculates about the perennial popularity\nof this puzzle:\nI got the idea for linguistic equations from graffiti someone had\nwritten in the form of an obscene formula on a restroom wall at the\nUniversity of Florida. When the answer suddenly came to me, I realized\nthe format was a good one for eliciting the \"aha effect\". After that I\nused such items as exercise material when teaching workshops on\ncreative thinking.\nMy guess is that one reason a person enjoys linguistic equations is\nthat the answer hits him or her all at once rather than being solved in\nan incremental fashion. It is similar to what happens when we suddenly\nsee an embedded figure pop into focus; the satisfaction is visceral\nrather than just intellectual. My experience was that people often had\nthe answer to an item come to them when they were not consciously\nthinking about the puzzles, but relaxed, such as in the shower or about\nto fall asleep.\nAnother factor is that with well-written items, success does not hinge\non obscure information. Ideally, a person should never have to feel, \"I\ncould never have gotten that one no matter how long I worked on it.\"\nThere is something ego enhancing about knowing you have the answer\ninside and just need to find it.\n"}
{"id": "58632079", "url": "https://en.wikipedia.org/wiki?curid=58632079", "title": "Encyclopedia of Forensic and Legal Medicine 2nd Edition", "text": "Encyclopedia of Forensic and Legal Medicine 2nd Edition\n\nThe Encyclopedia of Forensic and Legal Medicine 2nd Edition is a reference source and pioneering 4 set encyclopedia of forensics and medico-legal knowledge published by Academic Press, Elsevier in 2016. This has been edited by the renowned British forensic specialist Jason Payne-James and Australian forensic pathologist Roger W. Byard and an international editorial board. \nThis reference work includes more than 300 articles contributed by forensic medicine and forensic science experts from all over the world. The encyclopedia is a complete reference source of articles covering from forensics, criminal investigations, health-care, legal, judicial, ballistics, toxicology,fingerprinting, DNA typing, disaster victim identification to autopsy and postmortem examination.\n\nThe encyclopedia is especially meant for forensic, medical, chemistry, physics, laboratory technologists and anthropology students and specialists such as forensic experts, lawyers, judicial officers, judges, police and investigating offices, nurses, medical officers etc. All the articles of the encyclopedia are available through Science direct and Scopus.\n"}
{"id": "33487458", "url": "https://en.wikipedia.org/wiki?curid=33487458", "title": "Guide to information sources", "text": "Guide to information sources\n\nA Guide to information sources (or a bibliographic guide, a literature guide, a guide to reference materials, a subject gateway, etc.) is a kind of metabibliography. Ideally it is not just a listing of bibliographies, reference works and other information sources, but more like a textbook introducing users to the information sources in a given field (in general).\n\nSuch guides may have many different forms: Comprehensive or highly selective, printed or electronic sources, annoteted listings or written chapters etc.\n\nOften used as curriculum tools for bibliographic instruction, the guides help library users find materials or help those unfamiliar with a discipline understand the key sources.\n\nAby, Stephen H., Nalen, James & Fielding, Lori (2005). Sociology; a guide to reference and information sources. 3rd ed. Westport, Conn.: Libraries Unlimited.\n\nAdams, Stephen R. (2005). \"Information Sources in Patents\"; 2nd ed. (Guides to Information Sources). München: K. G. Saur \n\nBlewett, Daniel K (2008). American military history; a guide to reference and information sources. 2nd ed. Westport, CT : Libraries Unlimited.\n\nJacoby, JoAnn & Kibbee, Josephine Z. (2007). Cultural anthropology; a guide to reference and information sources. 2nd ed. Westport, Conn.: Libraries Unlimited.\n\nSchmidt, Diane & Bell, George H. (2003). Guide to reference and information sources in the zoological sciences. Westport, Conn. : Libraries Unlimited.\n\nO'Hare, Christine (2007). \"Business Information Sources\". London: Library Assn Pub Ltd\n\nOstwald, W (1919). Die chemische Literatur und die Organisation der Wissenschaft. Leipzig : W. Ostwald & C. Drucker. (This is considered the first \"guide to information sources\").\n\nStebbins, Leslie F. (2006). Student guide to research in the digital age; how to locate and evaluate information sources. Westport, Conn.: Libraries Unlimited.\n\nWebb, W. H. et al. (Ed.). (1986). Sources of information in the social sciences. A Guide to the literature. 3. ed. Chicago : American Library Association.\n\nZell, Hans M. (ed.). (2003). The African studies companion; a guide to information sources. 3rd rev. and expanded ed. Glais Bheinn : Hans Zell.\n\n\n"}
{"id": "4491358", "url": "https://en.wikipedia.org/wiki?curid=4491358", "title": "Handbook", "text": "Handbook\n\nA handbook is a type of reference work, or other collection of instructions, that is intended to provide ready reference. The term originally applied to a small or portable book containing information useful for its owner, but the Oxford English Dictionary defines the current sense as \"any book...giving information such as facts on a particular subject, guidance in some art or occupation, instructions for operating a machine, or information for tourists.\" \n\nA handbook is sometimes referred to as a vade mecum (Latin, \"go with me\") or pocket reference. It may also be referred to as an enchiridion.\n\nHandbooks may deal with any topic, and are generally compendiums of information in a particular field or about a particular technique. They are designed to be easily consulted and provide quick answers in a certain area. For example, the MLA Handbook for Writers of Research Papers is a reference for how to cite works in MLA style, among other things. Examples of engineering handbooks include \"Perry's Chemical Engineers' Handbook\", \"Marks Standard Handbook for Mechanical Engineers\", and the \"CRC Handbook of Chemistry and Physics\".\n\n"}
{"id": "20819040", "url": "https://en.wikipedia.org/wiki?curid=20819040", "title": "Hashtag", "text": "Hashtag\n\nA hashtag is a type of metadata tag used on social networks such as Twitter and other microblogging services, allowing users to apply dynamic, user-generated tagging which makes it possible for others to easily find messages with a specific theme or content. Users create and use hashtags by placing the number sign or pound sign codice_1 usually in front of a word or unspaced phrase in a message. The hashtag may contain letters, digits, and underscores. Searching for that hashtag will yield each message that has been tagged with it. A hashtag archive is consequently collected into a single stream under the same hashtag. For example, on the photo-sharing service Instagram, the hashtag \"#bluesky\" allows users to find all the posts that have been tagged using that hashtag. \n\nThe use of hashtags was first proposed by Chris Messina in a 2007 tweet that, although initially decried by Twitter as a \"thing for nerds\", eventually led to their use spreading like wild-fire through the platform. Messina, who made no attempt to copyright the use because he felt \"they were born of the internet, and owned by no one\", has subsequently been credited as the godfather of the hashtag. By the end of the decade hashtags could be seen in most emerging as well as established social media platforms including Instagram, Facebook, Reddit, and YouTube. So much so that Instagram had to officially place a \"30 hashtags\" limit on its posts to prevent people from abusing their use, a limit which Instagrammers eventually circumvented by posting hashtags in the comments section of their posts. As of 2018 more than 85% of the top 50 websites by traffic on the Internet use hashtags and their use is highly common with millennials, Gen Z, politicians, influencers, and celebrities worldwide. Because of its widespread use, \"hashtag\" was added to the \"Oxford English Dictionary\" in June 2014. The term \"hashtag\" is also sometimes erroneously used to refer to the hash symbol itself when used in the context of a hashtag. Formal taxonomies can be developed from the folk taxonomy rendered machine-readable by the markup that hashtags provide; this process is called folksonomy.\nThe US pound sign, number sign or hash symbol \"#\" is often used in information technology to highlight a special meaning. (\"Pound sign\" in the UK means \"£\"; \"#\" is called hash, gate, and occasionally octothorpe.) In 1970, for example, the number sign was used to denote \"immediate\" address mode in the assembly language of the PDP-11 when placed next to a symbol or a number. In 1978, Brian Kernighan and Dennis Ritchie used \"#\" in the C programming language for special keywords that had to be processed first by the C preprocessor. In the 1986 SGML standard, ISO 8879:1986 (q.v.), # is a reserved name indicator (rni) which precedes keyword syntactic literals, --e.g., the primitive content token #PCDATA, used for parsed character data.\n\nThe International Telecommunication Union approved in November 1988 recommendation E.161 that put the hash sign on the right side of the 0 in the 4 x 3 button arrangement for push buttons on telephones. This same arrangement is still used today in most software phones (see Android dialer for example). The ITU recommendation had 2 design options for the hash: a European version where the hash sign was built with a 90-degree angle and a North-American version with an 80-degree angle. The North-American version seems to have prevailed as most hash signs in Europe now follow the 80-degree inclination.\n\nThe pound sign was adopted for use within IRC networks circa 1988 to label groups and topics. Channels or topics that are available across an entire IRC network are prefixed with a hash symbol # (as opposed to those local to a server, which use an ampersand '&').\n\nThe use of the pound sign in IRC inspired Chris Messina to propose a similar system to be used on Twitter to tag topics of interest on the microblogging network. He posted the first hashtag on Twitter:\n\nMessina’s suggestion to use the hashtag was not adopted by Twitter, but the practice took off after hashtags were widely used in tweets relating to the 2007 San Diego forest fires in Southern California.\n\nAccording to Messina, he suggested use of the hashtag to make it easy for \"lay\" users to search for content and find specific relevant updates; they were for people who do not have the technological knowledge to navigate the site. Therefore, the hashtag \"was created organically by Twitter users as a way to categorize messages.\" Today they are for anyone, either with or without technical knowledge, to easily impose enough annotation to be useful without needing a more formal system or adhering to many technical details.\n\nInternationally, the hashtag became a practice of writing style for Twitter posts during the 2009–2010 Iranian election protests; Twitter users inside and outside Iran used both English- and Persian-language hashtags in communications during the events.\n\nThe first published use of the term \"hash tag\" was in a blog post by Stowe Boyd, \"Hash Tags = Twitter Groupings,\" on August 26, 2007, according to lexicographer Ben Zimmer, chair of the American Dialect Society's New Words Committee.\n\nBeginning July 2, 2009, Twitter began to hyperlink all hashtags in tweets to Twitter search results for the hashtagged word (and for the standard spelling of commonly misspelled words). In 2010, Twitter introduced \"Trending Topics\" on the Twitter front page, displaying hashtags that are rapidly becoming popular. Twitter has an algorithm to tackle attempts to spam the trending list and ensure that hashtags trend naturally.\n\nAlthough the hashtag started out most popularly on Twitter as the main social media platform for this use, the use has extended to other social media sites including Instagram, Facebook, Flickr, Tumblr, and Google+.\n\nA hashtag must begin with a hash character followed by other characters, and is terminated by a space, or end of message. It is always safe to precede the “#” with a space, and to include letters without diacritics, digits, and underscores. In many cases other characters are also allowed, in particular accented characters used in many languages, but handling may vary from one client to another, and from time to time as standards evolve. A discussion of hashtag standards suggests that if #Romeo&Juliet is used, different Twitter clients might link to #Romeo, #Romeo&, or #Romeo&Juliet. Hashtags are not case sensitive; a search for “#hashtag” will find “#HashTag”. The use of embedded capitals (CamelCase) increases readability and avoids confusion; a (real) pen shop would be advised to use #PenIsland rather than all lower-case. On microblogging and social networking sites hashtags can be inserted anywhere within a text, often at the beginning or the end, but also within the text, usually as a word (e.g. “It is #sunny today”).\n\nLanguages which do not use letters are handled slightly differently. In China, microblogs Sina Weibo and Tencent Weibo use a double-hashtag-delimited #HashName# format, since the lack of spacing between Chinese characters necessitates a closing tag. Twitter uses a different syntax for Chinese characters and orthographies with similar spacing conventions: the hashtag contains unspaced characters, separated from preceding and following text by spaces (e.g. '我 #爱 你' instead of '我#爱你') or by zero-width non-joiner characters before and after the hashtagged element, to retain a linguistically natural appearance (displaying as unspaced '我‌#爱‌你', but with invisible non-joiners delimiting the hashtag).\n\nIt is considered acceptable to tag a post once when contributing to a specific conversation. Two hashtags are considered acceptable when adding a location to the conversation. Three hashtags are seen by some as the \"absolute maximum\", and any contribution exceeding this risks \"raising the ire of the community.\"\n\nAs well as frustrating other users, the misuse of hashtags can lead to account suspensions. Twitter warns that adding hashtags to unrelated tweets, or repeated use of the same hashtag without adding to a conversation, could cause an account to be filtered from search, or suspended.\n\nJimmy Fallon and Justin Timberlake performed a sketch parodying the often incorrect and misunderstood use of hashtags on \"Late Night with Jimmy Fallon\" in September 2013.\n\nHashtags are mostly used in unmoderated, ad hoc discussion forums; any combination of characters led by a hash symbol is a hashtag, and any hashtag, if promoted by enough individuals, can \"trend\" and attract more individual users to discussion. On Twitter, when a hashtag becomes extremely popular, it will appear in the \"Trending Topics\" area of a user's homepage. The trending topics can be organized by geographic area or by all of Twitter. Hashtags are neither registered nor controlled by any one user or group of users. They cannot be \"retired\" from public usage, meaning that any given hashtag can theoretically be used in perpetuity. They do not contain any set definitions, meaning that a single hashtag can be used for any number of purposes, as chosen by the creators of them.\n\nHashtags intended for discussion of a particular event tend to use an obscure wording to avoid being caught up with generic conversations on similar subjects, such as a cake festival using #cakefestival rather than simply #cake. However, this can also make it difficult for topics to become \"trending topics\" because people often use different spelling or words to refer to the same topic. For topics to trend, there has to be a consensus, whether silent or stated, that the hashtag refers to that specific topic.\n\nHashtags also function as beacons in order for users to find and \"follow\" (subscribe) or \"list\" (organize into public contact lists) other users of similar interest.\n\nTelevision broadcasters such as Channel 4 have employed the hashtag during the transmission of programmes such as First Dates and The Undateables. Research has shown that audience numbers go up when individuals can be interactive by tweeting while viewing a programme.\n\nHashtags can be used on the social network Instagram, by posting a picture and hashtagging it with its subject. As an example, a photo of oneself and a friend posted to the social network can be hashtagged #bffl or #friends. Instagram has banned certain hashtags, some because they are too generic, such as #photography #iPhone #iphoneography, and therefore do not fulfill a purpose. They have also blocked hashtags that can be linked to illegal activities, such as drug use. The ban against certain hashtags has a consequential role in the way that particular subaltern communities are built and maintained on Instagram. Despite Instagram's content policies, users are finding creative ways of maintaining their practices and ultimately circumventing censorship.\n\nFamous Youtube bloggers often use hashtags to promote their videos to a wide audience. Thus, by leaving various hashtags under the video, they are trying to increase their views and gain as many likes as possible. Usually, hashtags are left under the video itself in a special line. By clicking on the hashtag you go directly to the link to the video, which are similar in topic.\n\nHashtags are also used informally to express context around a given message, with no intent to categorize the message for later searching, sharing, or other reasons. One of the functions of the hashtag is to serve as a reflexive meta-commentary, which contributes to the idea of how written communication in new media can be paralleled to how pragmatic methodology is applied to speech.\n\nThis can help express contextual cues or offer more depth to the information or message that appears with the hashtag. \"My arms are getting darker by the minute. #toomuchfaketan\". Another function of the hashtag can be used to express personal feelings and emotions. For example, with \"It's Monday!! #excited #sarcasm\" in which the adjectives are directly indicating the emotions of the speaker. It can also be used as a disclaimer of the information that the hashtag accompanies, as in, \"BREAKING: US GDP growth is back! #kidding\". In this case, the hashtag provides an essential piece of information in which the meaning of the utterance is changed entirely by the disclaimer hashtag. This may also be conveyed with #sarcasm, as in the previous example. Self-mockery is another informal function of the hashtag used by writers, as in this tweet: \"Feeling great about myself till I met an old friend who now races at the Master's level. Yup, there's today's #lessoninhumility,\" where the informality of the hashtag provides commentary on the tweet itself.\n\nThe feature has been added to other, non-short-message-oriented services, such as the user comment systems on YouTube and Gawker Media. In the case of the latter, hashtags for blog comments and directly submitted comments were used to maintain a more constant rate of user activity even when paid employees were not logged into the website. Real-time search aggregators such as the former Google Real-Time Search also support hashtags in syndicated posts, meaning that hashtags inserted into Twitter posts can be hyperlinked to incoming posts falling under that same hashtag; this has further enabled a view of the \"river\" of Twitter posts that can result from search terms or hashtags.\n\nThe use of hashtags has extended to televisiona concept that began rising in prominence in the early 2010s. Broadcasters may display a hashtag as an on-screen bug, encouraging viewers to participate in a backchannel of discussion via social media prior to, during, or after the program. Television commercials have sometimes contained hashtags for similar purposes. Hashtag bugs appear on either corner of the screen, or they may appear at the end of an advertisement.\n\nWhile personalities associated with broadcasts, such as hosts and correspondents, also promote their corporate or personal Twitter usernames to receive mentions and replies to posts, usage of related or \"branded\" hashtags alongside Twitter usernames (e.g., #edshow as well as @edshow) is increasingly encouraged as a microblogging style to \"trend\" the hashtag (and, hence, the discussion topic) in Twitter and other search engines. Broadcasters also make use of such a style to index select posts for live broadcast. Chloe Sladden, Twitter's director of media partnerships, identified two types of television-formatted usage of hashtags: hashtags which identify a series being broadcast (i.e. #SunnyFX) and instantaneous, \"temporary\" hashtags issued by television personalities to gauge topical responses from viewers during broadcasts. Some have speculated that hashtags might take the place of (or co-exist with) the Nielsen television ratings system.\n\nAn example of trending \"temporary\" hashtags garnering viewers during broadcasts is observed on \"The Tonight Show\" with Jimmy Fallon, a variety talk show on NBC. Every Wednesday, Fallon hosts a segment on his show called \"Tonight Show Hashtags,\" which engages viewers by inviting them via Twitter to post humorous stories based on a specific hashtag topic, such as #WhydidIsaythat, #Worstfirstdate, to #Onetimeinclass, reflecting on funny experiences in daily life. By using hashtags, Fallon creates a sense of community and solidarity among his viewers and draws a wider range of viewers through an online platform while they watch a classic, non-interactive television program. Because of its popularity, the \"Tonight Show Hashtags\" are usually the 'most tweeted hashtag' on Twitter, which promotes the show. By engaging viewers with a lighthearted subject and simple hashtags, Fallon can gauge topical responses from viewers during broadcasts and also use the hashtags to brand his show.\n\nThe increased usage of hashtags as brand promotion devices has been compared to the promotion of branded \"keywords\" by AOL in the late 1990s and early 2000s, as such keywords were also promoted at the end of television commercials and series episodes.\n\nThe late-night television comedy game show @midnight with Chris Hardwick on Comedy Central features a daily game entitled \"Hashtag Wars,\" in which three comedians compete against one another to come up with phrases based on a given hashtag theme.\n\nSome hashtags have become famous worldwide. For instance the slogan \"Je suis Charlie,\" which was first used on Twitter as the hashtag #jesuischarlie and #iamcharlie to indicate solidarity with \"Charlie Hebdo\" offices attacked in Paris, spread to the internet at large.\n\nSince February 2013 Twitter and American Express have collaborated to enable users to pay for discounted goods online by tweeting a special hashtag. American Express members can sync their card with Twitter and pay for offers by tweeting; American Express tweets a response to the member that confirms the purchase.\n\nOrganized real-world events have used hashtags and ad hoc lists for discussion and promotion among participants. Hashtags are used as beacons by event participants to find each other, both on Twitter and, in many cases, during actual physical events.\n\nCompanies and advocacy organizations have taken advantage of hashtag-based discussions for promotion of their products, services or campaigns.\n\nPolitical protests and campaigns in the early 2010s, such as #OccupyWallStreet and #LibyaFeb17, have been organized around hashtags or have made extensive usage of hashtags for the promotion of discussion. Hashtags have also been used to promote official events; the Finnish Ministry of Foreign Affairs officially titled the 2018 Russia–United States summit as the \"#HELSINKI2018 Meeting\".\n\nHashtags are often used by consumers on social media platforms to complain about the customer service experience with large companies. The term \"bashtag\" has been created to describe situations in which a user refers to a corporate social media hashtag to criticise the company or to tell others about poor customer service. For example, in January 2012, McDonald's created the #McDStories hashtag so that customers could share positive experiences about the restaurant chain. But, the marketing effort was cancelled after two hours when McDonald's received numerous complaint tweets rather than the positive stories they were anticipating.\n\nThe use of hashtags also reveals what feelings or sentiment an author attaches to a statement. This can range from the obvious, where a hashtag directly describes the state of mind, to the less obvious. For example, words in hashtags are the strongest predictor of whether or not a statement is sarcastic—a difficult AI problem.\n\nThe YouTuber Spencer FC used the hashtag for the name and crest of his YouTube-based association football team, Hashtag United F.C..\n\nSince the 2012–13 season, the National Basketball Association (NBA) has allowed fans to vote players in as All-Star Game starters on Twitter and Facebook using #NBAVOTE. The tweets and Facebook posts must include #NBAVOTE along with the player's first and last name or Twitter handle.\n\nDuring the April 2011 Canadian party leader debate, Jack Layton, then-leader of the New Democratic Party, referred to Conservative Prime Minister Stephen Harper's crime policies as \"a hashtag fail\" (presumably #fail).\n\nThe term \"hashtag rap\", coined by Kanye West, was developed in the 2010s to describe a style of rapping which, according to Rizoh of the \"Houston Press,\" uses \"three main ingredients: a metaphor, a pause, and a one-word punch line, often placed at the end of a rhyme\". Rappers Nicki Minaj, Big Sean, Drake, and Lil Wayne are credited with the popularization of hashtag rap, while the style has been criticized by Ludacris, The Lonely Island, and various music writers.\n\nOn September 13, 2013, a hashtag, #TwitterIPO, appeared in the headline of a \"New York Times\" front-page article regarding Twitter's initial public offering.\n\nBird's Eye foods released in 2014 a shaped mashed potato food that included forms of @-symbols and hashtags, called \"Mashtags\".\n\nHashtags have been used verbally to make a humorous point in informal conversations, such as \"I’m hashtag confused!\" In August 2012, British journalist Tom Meltzer reported in \"The Guardian\" about a new hand gesture that mimicked the hashtag, sometimes called the \"finger hashtag\", in which both hands form a peace sign, and then the fingers are crossed to form the symbol of a hashtag. The emerging gesture was reported about in \"Wired\" by Nimrod Kamer, and during 2013, it was seen on TV as used by Jimmy Fallon, and on \"The Colbert Report,\" among other programs. Writing in 2015, Paola Maria Caleff considered this usage a fad, but noted that people talking the way that they write was a consequence of computer-mediated communication.\n\n\n\n"}
{"id": "23452847", "url": "https://en.wikipedia.org/wiki?curid=23452847", "title": "Hebrew abbreviations", "text": "Hebrew abbreviations\n\nAbbreviations () are a common part of the Hebrew language, with many organizations, places, people and concepts known by their abbreviations.\n\nAcronyms in Hebrew use a special punctuation mark called gershayim (״). This mark is placed between the last two letters of the non-inflected form of the acronym (e.g. \"report\" in singular is \",\" hence the plural \"\"). Acronyms can be formed from strings of single initial letters, e.g. \"\" pazátsta (for ), or multiple initial letters, e.g. (for , the Holy Land) or ráshlats (for , Rishon LeZion).\n\nIf the acronym is read as is, then the spelling should be with a final form letter. If, on the other hand, the acronym is read as the complete phrase or read as the individual letters, then it should be spelled with a medial form letter. In practice, this rule is more often than not ignored, and the acronyms spelled either way.\n\nAbbreviations that are truncations of a single word, consisting of the first letter or first several letters of that word (as opposed to acronyms formed from initials or truncations of more than one word) are denoted using the punctuation mark geresh () by placing the sign after the last letter of the abbreviation (e.g. \"Ms.\": \"\"). However, in practice, single and double quotes are often used instead of the special punctuation marks (for which most keyboards do not have keys), with the single quote used both in acronyms and abbreviations.\n\nOften (and especially when they describe a noun), Hebrew acronyms are pronounced by the insertion of a vowel sound (usually ) between the letters. These vowels often appear in transliterations to other scripts. Examples include Shas (), Tanakh () and Shabak (). There are exceptions to the use of \"a\", such as Etzel ().\n\nWhen one of the letters is vav or yud, these may be read as vowels (\"u\"/“o” and \"i\") instead: (\"duakh\"/\"dokh\" = , judgement and account); (\"admor\" = , hasidic rebbe; (\"shut\" = , questions and answers); (\"sakum\" = , knife spoon and fork); (\"tapuz\" = , orange, lit. golden apple); (\"um\" = , the United Nations); Bilu; Lehi. (An exception is , Beitar, pronounced \"beytar\".)\n\nHebrew numbers (e.g. year numbers in the Hebrew calendar) are written the same way as acronyms, with gershayim before the last character, but pronounced as separate letter names. For example,  (5775 AM, or 2014-2015 CE) is pronounced hei-tav-shin-ayin-hei.\n\nAcronyms have been widely used in Hebrew since at least the Middle Ages. Several important rabbis are referred to with acronyms of their names. For example, Rabbi Shlomo ben Yitzchak is known as Rashi, Rav Moshe ben Maimon (Maimonides) is commonly known as \"Rambam\" (Hebrew: ), Rabbi Moshe ben Nahman (Nahmanides) is likewise known as the \"Ramban\" (Hebrew: ), and Baal Shem Tov is called the \"Besht\" (Hebrew: ).\n\nA number of such acronyms differ only in their last letter. They all begin with \"Mahara-\", as an acronym of the words ... (\"Morenu Ha-Rav rabi ...\", Our teacher the Rabbi ...).\" \n\nThe usage of Hebrew acronyms extends to liturgical groupings: the word \"Tanakh\" (Hebrew: תנ״ך) is an acronym for Torah (Five Books of Moses), Nevi'im (Book of Prophets), and Ketuvim (Hagiographa).\n\nMost often, though, one will find use of acronyms as acrostics, in both prayer, poetry (see Piyyut), and kabbalistic works. Because each Hebrew letter also has a numeric value, embedding an acrostic may give an additional layer of meaning to these works.\n\nOne purpose of acrostics was as a mnemonic or a way for an author to weave his name as a signature, or some other spiritual thought, into his work, at a time when much was memorized. Examples of prayers which contain acrostics include:\n\n\nישי נוימן, גורמים פגרמטיים, סמנטיים וגרפופונמיים במילוּן קיצורי הכתב, החוג הישראלי לבלשנו ת 18, 2011\n"}
{"id": "652730", "url": "https://en.wikipedia.org/wiki?curid=652730", "title": "Inc.", "text": "Inc.\n\nInc. or inc may refer to:\n\n\n"}
{"id": "597476", "url": "https://en.wikipedia.org/wiki?curid=597476", "title": "Info", "text": "Info\n\nInfo is shorthand for \"information\". It may also refer to:\n\n\n"}
{"id": "9549311", "url": "https://en.wikipedia.org/wiki?curid=9549311", "title": "Integrative and Comparative Biology", "text": "Integrative and Comparative Biology\n\nIntegrative and Comparative Biology is the scientific journal for the Society for Integrative and Comparative Biology (formerly the American Society of Zoologists). Prior to volume 42 (2002), the journal was known as American Zoologist .\n\n\n"}
{"id": "33447383", "url": "https://en.wikipedia.org/wiki?curid=33447383", "title": "Metabibliography", "text": "Metabibliography\n\nA metabibliography (or biblio-bibliography) is a bibliography of bibliographies.\n\nBibliographies serve the finding of relevant documents. Metabibliographies serve the finding of the relevant bibliographies in which the relevant documents may be found. One might quote Patrick Wilson:\n\n\"For if knowledge is power, power over knowledge is power to increase one's power; and if the stock of writings is thought of mainly as it represents a stock of knowledge, it is natural to propose treating it as a \"resource\" to be subjected to rational control, managemenet and utilization.\" (Wilson, 1968, p. 145).\n\nMetabibliographies are valuable for building reference collections, but usually of less interest to the average user, who rely on bibliographies selected by others.\n\n\n\n"}
{"id": "5629066", "url": "https://en.wikipedia.org/wiki?curid=5629066", "title": "Nomina sacra", "text": "Nomina sacra\n\nIn Christian scribal practice, nomina sacra (singular: nomen sacrum from Latin sacred name) is the abbreviation of several frequently occurring divine names or titles, especially in Greek manuscripts of Holy Scripture. A nomen sacrum consists of two or more letters from the original word spanned by an overline.\n\nMetzger lists 15 such expressions from Greek papyri: the Greek counterparts of \"God\", \"Lord\", \"Jesus\", \"Christ\", \"Son\", \"Spirit\", \"David\", \"Cross\", \"Mother\", \"Father\", \"Israel\", \"Savior\", \"Man\", \"Jerusalem\", and \"Heaven\". These \"nomina sacra\" are all found in Greek manuscripts of the 3rd century and earlier, except \"Mother\", which appears in the 4th.\n\n\"Nomina sacra\" also occur in some form in Latin, Coptic, Armenian (indicated by the \"pativ\"), Gothic, Old Nubian, and Cyrillic (indicated by the \"titlo\").\n\n\"Nomina sacra\" are consistently observed in even the earliest extant Christian writings, along with the codex form rather than the roll, implying that when these were written, in approximately the second century, the practice had already been established for some time. However, it is not known precisely when and how the \"nomina sacra\" first arose.\n\nThe initial system of \"nomina sacra\" apparently consisted of just four or five words, called \"nomina divina\": the Greek words for \"Jesus\", \"Christ\", \"Lord\", \"God\", and possibly \"Spirit\". The practice quickly expanded to a number of other words regarded as sacred.\n\nIn the system of \"nomina sacra\" that came to prevail, abbreviation is by \"contraction\", meaning that the first and last letter (at least) of each word are used. In a few early cases, an alternate practice is seen of abbreviation by \"suspension\", meaning that the initial two letters (at least) of the word are used; e.g., the opening verses of Revelation in write (\"Jesus Christ\") as . Contraction, however, offered the practical advantage of indicating the case of the abbreviated noun.\n\nIt is evident that the use of \"nomina sacra\" was an act of reverence rather than a purely practical space-saving device, as they were employed even where well-established abbreviations of far more frequent words such as \"and\" were avoided, and the \"nomen sacrum\" itself was written with generous spacing. Furthermore, early scribes often distinguished between mundane and sacred occurrences of the same word, e.g. a \"spirit\" vs. the \"Spirit\", and applied \"nomina sacra\" only to the latter (at times necessarily revealing an exegetical choice), although later scribes would mechanically abbreviate all occurrences.\n\nScholars have advanced a number of theories on the origin of the \"nomina sacra\". An obvious parallel that likely offered some inspiration is the Jewish practice of writing the divine name of God, commonly rendered as Jehovah or Yahweh in English, as the Hebrew tetragrammaton (transliterated as YHWH) even in Greek Scriptures. The Septuagint manuscript LXX P.Oxy.VII.1007 uses two Paleo-Hebrew \"yodh's\" with a horizontal line through them for YHWH (an abbreviated form of the Name of God translitered as ). Pavlos Vasileiadis, a Doctor of Theology at the Aristotle University of Thessaloniki, quoting Gerard Gertoux, states that \"the subsequent use of the contracted forms of the original nomina sacra κ[ύριο]ς [()] and θ[εό]ς [()] within Christian manuscripts probably reflects the Jewish practice of replacing the Tetragrammaton by י[הו]ה.\", transliterated in koine Greek as ιά.\n\nGreek culture also employed a number of ways of abbreviating even proper names, though none in quite the same form as the \"nomina sacra\". Inspiration for the contracted forms (using the first and last letter) has also been seen in Revelation, where Jesus speaks of himself as \"the beginning and the end\" and \"the first and the last\" as well \"the Alpha and the Omega\". Greek numerals have been suggested as the origin of the overline spanning the whole \"nomen sacrum\", with the suspended form being simply the ordinary way of writing \"eighteen\", for example.\n\n"}
{"id": "1091767", "url": "https://en.wikipedia.org/wiki?curid=1091767", "title": "Non-well-founded set theory", "text": "Non-well-founded set theory\n\nNon-well-founded set theories are variants of axiomatic set theory that allow sets to contain themselves and otherwise violate the rule of well-foundedness. In non-well-founded set theories, the foundation axiom of ZFC is replaced by axioms implying its negation.\n\nThe study of non-well-founded sets was initiated by Dmitry Mirimanoff in a series of papers between 1917 and 1920, in which he formulated the distinction between well-founded and non-well-founded sets; he did not regard well-foundedness as an axiom. Although a number of axiomatic systems of non-well-founded sets were proposed afterwards, they did not find much in the way of applications until Peter Aczel’s hyperset theory in 1988.\n\nThe theory of non-well-founded sets has been applied in the logical modelling of non-terminating computational processes in computer science (process algebra and final semantics), linguistics and natural language semantics (situation theory), philosophy (work on the Liar Paradox), and in a different setting, non-standard analysis.\n\nIn 1917, Dmitry Mirimanoff introduced the concept of well-foundedness of a set:\n\nIn ZFC, there is no infinite descending ∈-sequence by the axiom of regularity. In fact, the axiom of regularity is often called the \"foundation axiom\" since it can be proved within ZFC (that is, ZFC without the axiom of regularity) that well-foundedness implies regularity. In variants of ZFC without the axiom of regularity, the possibility of non-well-founded sets with set-like ∈-chains arises. For example, a set \"A\" such that \"A\" ∈ \"A\" is non-well-founded.\n\nAlthough Mirimanoff also introduced a notion of isomorphism between possibly non-well-founded sets, he considered neither an axiom of foundation nor of anti-foundation. In 1926, Paul Finsler introduced the first axiom that allowed non-well-founded sets. After Zermelo adopted Foundation into his own system in 1930 (from previous work of von Neumann 1925–1929) interest in non-well-founded sets waned for decades. An early non-well-founded set theory was Willard Van Orman Quine’s New Foundations, although it is not merely ZF with a replacement for Foundation.\n\nSeveral proofs of the independence of Foundation from the rest of ZF were published in 1950s particularly by Paul Bernays (1954), following an announcement of the result in earlier paper of his from 1941, and by Ernst Specker who gave a different proof in his Habilitationsschrift of 1951, proof which was published in 1957. Then in 1957 Rieger's theorem was published, which gave a general method for such proof to be carried out, rekindling some interest in non-well-founded axiomatic systems. The next axiom proposal came in a 1960 congress talk of Dana Scott (never published as a paper), proposing an alternative axiom now called SAFA. Another axiom proposed in the late 1960s was Maurice Boffa's axiom of superuniversality, described by Aczel as the highpoint of research of its decade. Boffa's idea was to make foundation fail as badly as it can (or rather, as extensionality permits): Boffa's axiom implies that every extensional set-like relation is isomorphic to the elementhood predicate on a transitive class.\n\nA more recent approach to non-well-founded set theory, pioneered by M. Forti and F. Honsell in the 1980s, borrows from computer science the concept of a bisimulation. Bisimilar sets are considered indistinguishable and thus equal, which leads to a strengthening of the axiom of extensionality. In this context, axioms contradicting the axiom of regularity are known as anti-foundation axioms, and a set that is not necessarily well-founded is called a hyperset.\n\nFour mutually independent anti-foundation axioms are well-known, sometimes abbreviated by the first letter in the following list:\nThey essentially correspond to four different notions of equality for non-well-founded sets. The first of these, AFA, is based on accessible pointed graphs (apg) and states that two hypersets are equal if and only if they can be pictured by the same apg. Within this framework, it can be shown that the so-called Quine atom, formally defined by Q={Q}, exists and is unique.\n\nEach of the axioms given above extends the universe of the previous, so that: V ⊆ A ⊆ S ⊆ F ⊆ B. In the Boffa universe, the distinct Quine atoms form a proper class.\n\nIt is worth emphasizing that hyperset theory is an extension of classical set theory rather than a replacement: the well-founded sets within a hyperset domain conform to classical set theory.\n\nAczel’s hypersets were extensively used by Jon Barwise and John Etchemendy in their 1987 book \"The Liar\", on the liar's paradox; The book is also good introduction to the topic of non-well-founded sets.\n\nBoffa’s superuniversality axiom has found application as a basis for axiomatic nonstandard analysis.\n\n\n\n"}
{"id": "330432", "url": "https://en.wikipedia.org/wiki?curid=330432", "title": "Note (typography)", "text": "Note (typography)\n\nA note is a string of text placed at the bottom of a page in a book or document or at the end of a chapter, volume or the whole text. The note can provide an author's comments on the main text or citations of a reference work in support of the text, or both.\n\nFootnotes are notes at the foot of the page while endnotes are collected under a separate heading at the end of a chapter, volume, or entire work. Unlike footnotes, endnotes have the advantage of not affecting the layout of the main text, but may cause inconvenience to readers who have to move back and forth between the main text and the endnotes.\n\nIn some editions of the Bible, notes are placed in a narrow column in the middle of each page between two columns of biblical text.\n\nIn English, a footnote is normally flagged by a superscripted number immediately following that portion of the text the note references, each such footnote being numbered sequentially. Occasionally a number between brackets or parentheses is used instead, thus: [1], which can also be superscripted, as in Wikipedia's own citation style rendered within this very page.\n\nTypographical devices such as the asterisk (*) or dagger (†) may also be used to point to footnotes; the traditional order of these symbols in English is *, †, ‡, §, ‖, ¶. Other symbols, including the #, Δ, ◊, ↓, and ☞, have also been used. In documents like timetables, many different symbols, letters and numbers may be used to refer the reader to particular notes.\n\nNotes are most often used as an alternative to long explanatory notes that can be distracting to readers. Most literary style guidelines (including the Modern Language Association and the American Psychological Association) recommend limited use of foot and endnotes. However, publishers often encourage note references in lieu of parenthetical references. Aside from use as a bibliographic element, notes are used for additional information or explanatory notes that might be too digressive for the main text. Footnotes are heavily utilized in academic institutions to support claims made in academic essays covering myriads of topics.\n\nIn particular, footnotes are the normal form of citation in historical journals. This is due, firstly, to the fact that the most important references are often to archive sources or interviews which do not readily fit standard formats, and secondly, to the fact that historians expect to see the exact nature of the evidence which is being used at each stage.\n\nThe MLA (Modern Language Association) requires the superscript numbers in the main text to be placed following the punctuation in the phrase or clause the note is in reference to. The exception to this rule occurs when a sentence contains a dash, in which case the superscript would precede it.\n\nAside from their technical use, authors use notes for a variety of reasons:\n\nThe US Government Printing Office Style Manual devotes over 660 words to the topic of footnotes. NASA has guidance for footnote usage in its historical documents.\nAssociate Justice Stephen Breyer of the Supreme Court of the United States is famous in the American legal community for his writing style, in which he never uses notes. He prefers to keep all citations within the text (which is permitted in American legal citation). Richard A. Posner has also written against the use of notes in judicial opinions. Bryan A. Garner, however, advocates using notes instead of inline citations.\n\nHTML, the predominant markup language for web pages, has no mechanism for marking up notes. Despite a number of different proposals over the years, and repeated pleas from the user base, the working group has been unable to reach a consensus on it. Because of this, MediaWiki, for example, has had to introduce its own codice_1 tag for citing references in notes, an idea which has since also been implemented for generic use by the \"Nelson\" HTML preprocessor.\n\nIt might be argued that the hyperlink partially eliminates the need for notes, being the web's way to refer to another document. However, it does not allow citing to offline sources and if the destination of the link changes, the link can become dead or irrelevant.\n\nThe sign is historically equal to the asterisks used by Aristarchus of Samothrace at the Mouseion at Alexandria. It was used for the critical editions of Homer's writings where it \"marked a verse incorrectly repeated in another passage\" and was used together with other signs such as the obelus.\n\nThe London printer Richard Jugge is generally credited as the inventor of the footnote, first used in the Bishops' Bible of 1568.\n\nEarly printings of the Douay Bible used two closely spaced colons (actually squared four dot punctuation mark U+2E2C) to indicate a marginal note.\n\nAt times, notes have been used for their comical effect, or as a literary device.\n\n\n\n"}
{"id": "24673687", "url": "https://en.wikipedia.org/wiki?curid=24673687", "title": "Polymath (disambiguation)", "text": "Polymath (disambiguation)\n\nA polymath is a person whose expertise spans a significant number of different subject areas and who has extraordinarily broad and comprehensive knowledge.\n\nPolymath may also refer to:\n\n"}
{"id": "8912106", "url": "https://en.wikipedia.org/wiki?curid=8912106", "title": "Reference scenario", "text": "Reference scenario\n\nA reference scenario is an imagined situation where a library patron brings a question to a librarian and there is then a conversation, called in the field a reference interview, where the librarian works to help the patron find what he or she wants. These scenarios are used in training future librarians how to help patrons. Basically, a scenario is as short as a couple of sentences, including a question and a situation that underlies that question.\n\nA great deal of reference teaching puts students to researching the answers to made-up questions. This focuses the student on learning about the reference sources at hand by using them to answer those questions. Scenarios are something different. They focus the student on the interaction with patrons. In class practice sessions, one student can be the patron and the other the librarian, as long as the one practicing as the librarian doesn't know the whole scenario in advance.\n\nScenarios are valued because often the question asked is not the end of the patron's information hunt, but the start. Patrons often start by voicing a question that they think the library can answer, rather than the question they are really seeking to answer. Or they pose a question that the librarian doesn't understand. Reference librarian skills are very much about mediating a gap between what the patron wants and what the library can provide. This can involve the librarian making him or herself a partner in the patron's search, teaching them what the library really has to offer, or even just clarifying a confusing word: Does the patron want information about soaps to clean with or soaps as in soap operas?\n\n\n"}
{"id": "56067306", "url": "https://en.wikipedia.org/wiki?curid=56067306", "title": "SDS-PAGE", "text": "SDS-PAGE\n\nSDS-PAGE (sodium dodecyl sulfate–polyacrylamide gel electrophoresis) is a variant of polyacrylamide gel electrophoresis, an analytical method in biochemistry for the separation of charged molecules in mixtures by their molecular masses in an electric field. It uses sodium dodecyl sulfate (SDS) molecules to help identify and isolate protein molecules.\n\nSDS-PAGE is a discontinuous electrophoretic system developed by Ulrich K. Laemmli which is commonly used as a method to separate proteins with molecular masses between 5 and 250 KDa. The publication describing it is the most frequently cited paper by a single author, and the second most cited overall.\n\nSDS-PAGE is an electrophoresis method that allows protein separation by mass. The medium (also referred to as ′matrix′) is a polyacrylamide-based discontinuous gel. In addition, SDS (sodium dodecyl sulfate) is used. About 1.4 grams of SDS bind to a gram of protein, corresponding to one SDS molecule per two amino acids. SDS acts as a surfactant, covering the proteins' intrinsic charge and conferring them very similar charge-to-mass ratios. The intrinsic charges of the proteins are negligible in comparison to the SDS loading, and the positive charges are also greatly reduced in the basic pH range of a separating gel. Upon application of a constant electric field, the protein migrate towards the anode, each with a different speed, depending on its mass. This simple procedure allows precise protein separation by mass.\n\nSDS tends to form spherical micelles in aqueous solutions above a certain concentration called the critical micellar concentration (CMC). Above the critical micellar concentration of 7 to 10 millimolar in solutions, the SDS simultaneously occurs as single molecules (monomer) and as micelles, below the CMC SDS occurs only as monomers in aqueous solutions. At the critical micellar concentration, a micelle consists of about 62 SDS molecules. However, only SDS monomers bind to proteins via hydrophobic interactions, whereas the SDS micelles are anionic on the outside and do not adsorb any protein. SDS is amphipathic in nature, which allows it to unfold both polar and nonpolar sections of protein structure. In SDS concentrations above 0.1 millimolar, the unfolding of proteins begins, and above 1 mM, most proteins are denatured. Due to the strong denaturing effect of SDS and the subsequent dissociation of protein complexes, quaternary structures can generally not be determined with SDS. Exceptions are e.g. proteins that were previously stabilised by covalent cross-linking and the SDS-resistant protein complexes, which are stable even in the presence of SDS (the latter, however, only at room temperature). To denature the SDS-resistant complexes a high activation energy is required, which is achieved by heating. SDS resistance is based on a metastability of the protein fold. Although the native, fully folded, SDS-resistant protein does not have sufficient stability in the presence of SDS, the chemical equilibrium of denaturation at room temperature occurs slowly. Stable protein complexes are characterised not only by SDS resistance but also by stability against proteases and an increased biological half-life.\n\nAlternatively, polyacrylamide gel electrophoresis can also be performed with the cationic surfactants CTAB in a CTAB-PAGE, or 16-BAC in a BAC-PAGE.\n\nThe SDS-PAGE method is composed of gel preparation, sample preparation, electrophoresis, protein staining or western blotting and analysis of the generated banding pattern.\n\nWhen using different buffers in the gel (discontinuous gel electrophoresis), the gels are made up to one day prior to electrophoresis, so that the diffusion does not lead to a mixing of the buffers. The gel is produced by radical polymerisation in a mold consisting of two sealed glass plates with spacers between the glass plates. In a typical mini-gel setting, the spacers have a thickness of 0.75 mm or 1.5 mm, which determines the loading capacity of the gel. For pouring the gel solution, the plates are usually clamped in a stand which temporarily seals the otherwise open underside of the glass plates with the two spacers. For the gel solution, acrylamide is mixed as gel-former (usually 4% V/V in the stacking gel and 10-12 % in the separating gel), methylenebisacrylamide as a cross-linker, stacking or separating gel buffer, water and SDS. By adding the catalyst TEMED and the radical initiator ammonium persulfate (APS) the polymerisation is started. The solution is then poured between the glass plates without creating bubbles. Depending on the amount of catalyst and radical starter and depending on the temperature, the polymerisation lasts between a quarter of an hour and several hours. The lower gel (separating gel) is poured first and covered with a few drops of a barely water-soluble alcohol (usually buffer-saturated butanol or isopropanol), which eliminates bubbles from the meniscus and protects the gel solution of the radical scavenger oxygen. After the polymerisation of the separating gel, the alcohol is discarded and the residual alcohol is removed with filter paper. After addition of APS and TEMED to the stacking gel solution, it is poured on top of the solid separation gel. Afterwards, a suitable sample comb is inserted between the glass plates without creating bubbles. The sample comb is carefully pulled out after polymerisation, leaving pockets for the sample application. For later use of proteins for protein sequencing, the gels are often prepared the day before electrophoresis to reduce reactions of unpolymerised acrylamide with cysteines in proteins.\n\nBy using a gradient mixer, gradient gels with a gradient of acrylamide (usually from 4 to 12%) can be cast, which have a larger separation range of the molecular masses. Commercial gel systems (so-called \"pre-cast gels\") usually use the buffer substance Bis-tris methane with a pH value between 6.4 and 7.2 both in the stacking gel and in the separating gel. These gels are delivered cast and ready-to-use. Since they use only one buffer (continuous gel electrophoresis) and have a nearly neutral pH, they can be stored for several weeks. The more neutral pH slows the hydrolysis and thus the decomposition of the polyacrylamide. Furthermore, there are fewer acrylamide-modified cysteines in the proteins. Due to the constant pH in collecting and separating gel there is no stacking effect. Proteins in BisTris gels can not be stained with ruthenium complexes. This gel system has a comparatively large separation range, which can be varied by using MES or MOPS in the running buffer.\n\nDuring sample preparation, the sample buffer, and thus SDS, is added in excess to the proteins, and the sample is then heated to 95 °C for five minutes, or alternatively 70°C for ten minutes. Heating disrupts the secondary and tertiary structures of the protein by disrupting hydrogen bonds and stretching the molecules. Optionally, disulfide bridges can be cleaved by reduction. For this purpose, reducing thiols such as β-mercaptoethanol (β-ME, 5% by volume), dithiothreitol (DTT, 10 millimolar) or dithioerythritol (DTE, 10 millimolar) are added to the sample buffer. After cooling to room temperature, each sample is pipetted into its own well in the gel, which was previously immersed in electrophoresis buffer in the electrophoresis apparatus.\n\nIn addition to the samples, a molecular-weight size marker is usually loaded onto the gel. This consists of proteins of known sizes and thereby allows the estimation (with an error of ± 10%) of the sizes of the proteins in the actual samples, which migrate in parallel in different tracks of the gel. The size marker is often pipetted into the first or last pocket of a gel.\n\nFor separation, the denatured samples are loaded onto a gel of polyacrylamide, which is placed in an electrophoresis buffer with suitable electrolytes. Thereafter, a voltage (usually around 100 V, 10-20 V per cm gel length) is applied, which causes a migration of negatively charged molecules through the gel in the direction of the positively charged anode. The gel acts like a sieve. Small proteins migrate relatively easily through the mesh of the gel, while larger proteins are more likely to be retained and thereby migrate more slowly through the gel, thereby allowing proteins to be separated by molecular size. The electrophoresis lasts between half an hour to several hours depending on the voltage and length of gel used.\n\nThe fastest-migrating proteins (with a molecular weight of less than 5 KDa) form the buffer front together with the anionic components of the electrophoresis buffer, which also migrate through the gel. The area of the buffer front is made visible by adding the comparatively small, anionic dye bromophenol blue to the sample buffer. Due to the relatively small molecule size of bromophenol blue, it migrates faster than proteins. By optical control of the migrating colored band, the electrophoresis can be stopped before the dye and also the samples have completely migrated through the gel and leave it.\n\nThe most commonly used method is the discontinuous SDS-PAGE. In this method, the proteins migrate first into a collecting gel with neutral pH, in which they are concentrated and then they migrate into a separating gel with basic pH, in which the actual separation takes place. Stacking and separating gels differ by different pore size (4-6 % T and 10-20 % T), ionic strength and pH values (pH 6.8 or pH 8.8). The electrolyte most frequently used is an SDS-containing Tris-glycine-chloride buffer system. At neutral pH, glycine predominantly forms the zwitterionic form, at high pH the glycines lose positive charges and become predominantly anionic. In the collection gel, the smaller, negatively charged chloride ions migrate in front of the proteins (as leading ions) and the slightly larger, negatively and partially positively charged glycinate ions migrate behind the proteins (as initial trailing ions), whereas in the comparatively basic separating gel both ions migrate in front of the proteins. The pH gradient between the stacking and separation gel buffers leads to a stacking effect at the border of the stacking gel to the separation gel, since the glycinate partially loses its slowing positive charges as the pH increases and then, as the former trailing ion, overtakes the proteins and becomes a leading ion, which causes the bands of the different proteins (visible after a staining) to become narrower and sharper - the stacking effect. For the separation of smaller proteins and peptides, the TRIS-Tricine buffer system of Schägger and von Jagow is used due to the higher spread of the proteins in the range of 0.5 to 50 KDa.\n\nAt the end of the electrophoretic separation, all proteins are sorted by size and can then be analyzed by other methods, e. g. protein staining such as Coomassie staining (most common and easy to use), silver staining (highest sensitivity), stains all staining, Amido black 10B staining, Fast green FCF staining, fluorescent stains such as epicocconone stain and SYPRO orange stain, and immunological detection such as the Western Blot. The fluorescent dyes have a comparatively higher linearity between protein quantity and color intensity of about three orders of magnitude above the detection limit, i. e. the amount of protein can be estimated by color intensity. When using the fluorescent protein dye trichloroethanol, a subsequent protein staining is omitted if it was added to the gel solution and the gel was irradiated with UV light after electrophoresis.\n\nProtein staining in the gel creates a documentable banding pattern of the various proteins. Glycoproteins have differential levels of glycosylations and adsorb SDS more unevenly at the glycosylations, resulting in broader and blurred bands. Membrane proteins, because of their transmembrane domain, are often composed of the more hydrophobic amino acids, have lower solubility in aqueous solutions, tend to bind lipids, and tend to precipitate in aqueous solutions due to hydrophobic effects when sufficient amounts of detergent are not present. This precipitation manifests itself for membrane proteins in a SDS-PAGE in \"tailing\" above the band of the transmembrane protein. In this case, more SDS can be used (by using more or more concentrated sample buffer) and the amount of protein in the sample application can be reduced. An overloading of the gel with a soluble protein creates a semicircular band of this protein (e. g. in the marker lane of the image at 66 KDa), allowing other proteins with similar molecular weights to be covered. A low contrast (as in the marker lane of the image) between bands within a lane indicates either the presence of many proteins (low purity) or, if using purified proteins and a low contrast occurs only below one band, it indicates a proteolytic degradation of the protein, which first causes degradation bands, and after further degradation produces a homogeneous color (\"smear\") below a band. The documentation of the banding pattern is usually done by photographing or scanning. For a subsequent recovery of the molecules in individual bands, a gel extraction can be performed.\n\nAfter protein staining and documentation of the banding pattern, the polyacrylamide gel can be dried for archival storage. Proteins can be extracted from it at a later date. The gel is either placed in a drying frame (with or without the use of heat) or in a vacuum dryer. The drying frame consists of two parts, one of which serves as a base for a wet cellophane film to which the gel and a one percent glycerol solution are added. Then a second wet cellophane film is applied bubble-free, the second frame part is put on top and the frame is sealed with clips. The removal of the air bubbles avoids a fragmentation of the gel during drying. The water evaporates through the cellophane film. In contrast to the drying frame, a vacuum dryer generates a vacuum and heats the gel to about 50 °C.\n\nFor a more accurate determination of the molecular weight, the relative migration distances of the individual protein bands are measured in the separating gel. The measurements are usually performed in triplicate for increased accuracy. The relative mobility (called Rf value or Rm value) is the quotient of the distance of the band of the protein and the distance of the buffer front. The distances of the bands and the buffer front are each measured from the beginning of the separation gel. The distance of the buffer front roughly corresponds to the distance of the bromophenol blue contained in the sample buffer. The relative distances of the proteins of the size marker are plotted semi-logarithmically against their known molecular weights. By comparison with the linear part of the generated graph or by a regression analysis, the molecular weight of an unknown protein can be determined by its relative mobility. Bands of proteins with glycosylations can be blurred. Proteins with many basic amino acids (e. g. histones) can lead to an overestimation of the molecular weight or even not migrate into the gel at all, because they move slower in the electrophoresis due to the positive charges or even to the opposite direction. Accordingly, many acidic amino acids can lead to accelerated migration of a protein and an underestimation of its molecular mass.\n\nThe SDS-PAGE in combination with a protein stain is widely used in biochemistry for the quick and exact separation and subsequent analysis of proteins. It has comparatively low instrument and reagent costs and is an easy-to-use method. Because of its low scalability, it is mostly used for analytical purposes and less for preparative purposes, especially when larger amounts of a protein are to be isolated.\n\nAdditionally, SDS-PAGE is used in combination with the western blot for the determination of the presence of a specific protein in a mixture of proteins - or for the analysis of post-translational modifications. Post-translational modifications of proteins can lead to a different relative mobility (i.e. a \"band shift\") or to a change in the binding of a detection antibody used in the western blot (i.e. a band disappears or appears).\n\nIn mass spectrometry of proteins, SDS-PAGE is a widely used method for sample preparation prior to spectrometry, mostly using in-gel digestion. In regards to determining the molecular mass of a protein, the SDS-PAGE is a bit more exact than an analytical ultracentrifugation, but less exact than a mass spectrometry or - ignoring post-translational modifications - a calculation of the protein molecular mass from the DNA sequence.\n\nIn medical diagnostics, SDS-PAGE is used as part of the HIV test and to evaluate proteinuria. In the HIV test, HIV proteins are separated by SDS-PAGE and subsequently detected by Western Blot with HIV-specific antibodies of the patient, if they are present in his blood serum. SDS-PAGE for proteinuria evaluates the levels of various serum proteins in the urine, e.g. Albumin, Alpha-2-macroglobulin and IgG.\n\nSDS-PAGE is the most widely used method for gel electrophoretic separation of proteins. Two-dimensional gel electrophoresis sequentially combines isoelectric focusing or BAC-PAGE with a SDS-PAGE. Native PAGE is used if native protein folding is to be maintained. For separation of membrane proteins, BAC-PAGE or CTAB-PAGE may be used as an alternative to SDS-PAGE. For electrophoretic separation of larger protein complexes, agarose gel electrophoresis can be used, e.g. the SDD-AGE. Some enzymes can be detected via their enzyme activity by zymography.\n\nWhile being one of the more precise and low-cost protein separation and analysis methods, the SDS-PAGE denatures proteins. Where non-denaturing conditions are necessary, proteins are separated by a native PAGE or different chromatographic methods with subsequent photometric quantification, for example affinity chromatography (or even tandem affinity purification), size exclusion chromatography, ion exchange chromatography. Proteins can also be separated by size in a tangential flow filtration or a ultrafiltration. Single proteins can be isolated from a mixture by affinity chromatography or by a pull-down assay. Some historically early and cost effective but crude separation methods usually based upon a series of extractions and precipitations using kosmotropic molecules, for example the ammonium sulfate precipitation and the polyethyleneglycol precipitation.\n\nIn 1948, Arne Tiselius was awarded the Nobel Prize in Chemistry for the discovery of the principle of electrophoresis as the migration of charged and dissolved atoms or molecules in an electric field. The use of a solid matrix (initially paper discs) in a zone electrophoresis improved the separation. The discontinuous electrophoresis of 1964 by L. Ornstein and B. J. Davis made it possible to improve the separation by the stacking effect. The use of cross-linked polyacrylamide hydrogels, in contrast to the previously used paper discs or starch gels, provided a higher stability of the gel and no microbial decomposition. The denaturing effect of SDS in continuous polyacrylamide gels and the consequent improvement in resolution was first described in 1965 by David F. Summers in the working group of James E. Darnell to separate poliovirus proteins. The current variant of the SDS-PAGE was described in 1970 by Ulrich K. Laemmli and initially used to characterise the proteins in the head of bacteriophage T4.\n\n"}
{"id": "1130951", "url": "https://en.wikipedia.org/wiki?curid=1130951", "title": "Scribal abbreviation", "text": "Scribal abbreviation\n\nScribal abbreviations or sigla (singular: siglum) are the abbreviations used by ancient and medieval scribes writing in Latin, and later in Greek and Old Norse. In modern manuscript editing (substantive and mechanical) \"sigla\" are the symbols used to indicate the source manuscript (e.g. variations in text between different such manuscripts) and to identify the copyist(s) of a work. See Critical apparatus.\n\nAbbreviated writing, using \"sigla\", arose partly from the limitations of the workable nature of the materials (stone, metal, parchment, etc.) employed in record-making and partly from their availability. Thus, lapidaries, engravers, and copyists made the most of the available writing space. Scribal abbreviations were infrequent when writing materials were plentiful, but by the 3rd and 4th centuries AD, writing materials were scarce and costly.\n\nDuring the Roman Republic, several abbreviations, known as \"sigla\" (plural of \"siglum\" = symbol or abbreviation), were in common use in inscriptions, and they increased in number during the Roman Empire. Additionally, in this period shorthand entered general usage. The earliest known Western shorthand system was that employed by the Greek historian Xenophon in the memoir of Socrates, and it was called \"notae socratae\". In the late Roman Republic, the Tironian notes were developed possibly by Marcus Tullius Tiro, Cicero's amanuensis, in 63 BC to record information with fewer symbols; Tironian notes include a shorthand/syllabic alphabet notation different from the Latin minuscule hand and square and rustic capital letters. The notation was akin to modern stenographic writing systems. It used symbols for whole words or word roots and grammatical modifier marks, and it could be used to write either whole passages in shorthand or only certain words. In medieval times, the symbols to represent words were widely used; and the initial symbols, as few as 140 according to some sources, were increased to 14,000 by the Carolingians, who used them in conjunction with other abbreviations. However, the alphabet notation had a \"murky existence\" (C. Burnett), as it was often associated with witchcraft and magic, and it was eventually forgotten. Interest in it was rekindled by the Archbishop of Canterbury Thomas Becket in the 12th century and later in the 15th century, when it was rediscovered by Johannes Trithemius, abbot of the Benedictine abbey of Sponheim, in a psalm written entirely in Tironian shorthand and a Ciceronian lexicon, which was discovered in a Benedictine monastery (\"notae benenses\").\n\nTo learn the Tironian note system, scribes required formal schooling in some 4,000 symbols; this later increased to some 5,000 symbols and then to some 13,000 in the medieval period (4th to 15th centuries AD); the meanings of some characters remain uncertain. \"Sigla\" were mostly used in lapidary inscriptions; in some places and historical periods (such as medieval Spain) scribal abbreviations were overused to the extent that some are indecipherable.\n\nThe abbreviations were not constant but changed from region to region. Scribal abbreviations increased in usage and reached their height in the Carolingian Renaissance (8th to 10th centuries). The most common abbreviations, called \"notae communes\", were used across most of Europe, but others appeared in certain regions. In legal documents, legal abbreviations, called \"notae juris\", appear but also capricious abbreviations, which scribes manufactured \"ad hoc\" to avoid repeating names and places in a given document.\n\nScribal abbreviations can be found in epigraphy, sacred and legal manuscripts, written in Latin or in a vernacular tongue (but less frequently and with fewer abbreviations), either calligraphically or not.\n\nIn epigraphy, common abbreviations were comprehended in two observed classes:\n\nBoth forms of abbreviation are called \"suspensions\" (as the scribe suspends the writing of the word). A separate form of abbreviation is by \"contraction\" and was mostly a Christian usage for sacred words, Nomina Sacra; non-Christian sigla usage usually limited the number of letters the abbreviation comprised and omitted no intermediate letter. One practice was rendering an overused, formulaic phrase only as a siglum: DM for \"Dis Manibus\" (\"Dedicated to the Manes\"); IHS from the first three letters of \"ΙΗΣΟΥΣ\"; and RIP for \"requiescat in pace\" (\"Rest in Peace\") because the long-form written usage of the abbreviated phrase, by itself, was rare. According to Trabe, these abbreviations are not really meant to lighten the burden of the scribe but rather to shroud in reverent obscurity the holiest words of the Christian religion.\n\nAnother practice was repeating the abbreviation's final consonant a given number of times to indicate a group of as many persons: AVG denoted \"Augustus\", thus, AVGG denoted \"Augusti duo\"; however, lapidaries took typographic liberties with that rule, and instead of using COSS to denote \"Consulibus duobus\", they invented the CCSS form. Still, when occasion required referring to three or four persons, the complex doubling of the final consonant yielded to the simple plural siglum. To that effect, a \"vinculum\" (overbar) above a letter or a letter-set also was so used, becoming a universal medieval typographic usage. Likewise the \"tilde\" (~), an undulated, curved-end line, came into standard late-medieval usage.\n\nBesides the \"tilde\" and macron marks, above and below letters, modifying cross-bars and extended strokes were employed as scribal abbreviation marks, mostly for prefixes and verb, noun and adjective suffixes. The \"typographic\" abbreviations should not be confused with the \"phrasal\" abbreviations: i.e. (\"id est\" — \"that is\"); loc. cit. (\"loco citato\" — \"in the passage already cited\"); viz. (\"vide licet\" — \"namely\", \"that is to say\", \"in other words\" — formed with \"vi\" and the \"yogh\"-like glyph [Ꝫ], [ꝫ], the siglum for the suffix -et and the conjunction et) and et cetera.\n\nMoreover, besides scribal abbreviations, ancient texts also contained variant typographic characters, including ligatures (e.g. Æ, Œ, etc.), the long s (ſ), and the half r, resembling an Arabic numeral two (\"2\"). The \"u\" and \"v\" characters originated as scribal variants for their respective letters, likewise the \"i\" and \"j\" pair. Modern publishers printing Latin-language works replace variant typography and sigla with full-form Latin spellings; the convention of using \"u\" and \"i\" for vowels and \"v\" and \"j\" for consonants is a late typographic development.\n\nSome ancient and medieval sigla are still used in English and other European languages; the Latin ampersand (&) replaces the conjunction \"and\" in English, \"et\" in Latin and French, and \"y\" in Spanish (but its use in Spanish is frowned upon, since the \"y\" is already smaller and easier to write). The Tironian sign ⁊, resembling the digit seven (\"7\"), represents the conjunction \"et\" and is written only to the x-height; in current Irish language usage, the siglum denotes the conjunction \"agus\" (\"and\"). Other scribal abbreviations in modern typographic use are the percentage sign (%), from the Italian \"per cento\" (\"per hundred\"); the permille sign (‰), from the Italian \"per mille\" (\"per thousand\"); the pound sign (₤, £ and #, all descending from ℔ or lb, \"librum\") and the dollar sign ($), which possibly derives from the Spanish word \"Peso\". The commercial at symbol (@), originally denoting \"at the rate/price of\", is a ligature derived from the English preposition \"at\"; from the 1990s, its use outside commerce became widespread, as part of e-mail addresses.\n\nTypographically, the ampersand (\"&\"), representing the word \"et\", is a space-saving ligature of the letters \"e\" and \"t\", its component graphemes. Since the establishment of movable-type printing in the 15th century, founders have created many such ligatures for each set of record type (font) to communicate much information with fewer symbols. Moreover, during the Renaissance (14th to 17th centuries), when Ancient Greek language manuscripts introduced that tongue to Western Europe, its scribal abbreviations were converted to ligatures in imitation of the Latin scribal writing to which readers were accustomed. Later, in the 16th century, when the culture of publishing included Europe's vernacular languages, Graeco-Roman scribal abbreviations disappeared, an ideologic deletion ascribed to the anti-Latinist Protestant Reformation (1517–1648).\n\nThe common abbreviation \"Xmas,\" for Christmas, is a remnant of an old scribal abbreviation that substituted the Greek letter chi (Χ, resembling Latin X and representing the first letter in the Greek word for Christ, Χριστος) for the word Christ.\n\nAfter the invention of printing, manuscript copying abbreviations continued to be employed in Church Slavonic and are still in use in printed books as well as on icons and inscriptions. Many common long roots and nouns describing sacred persons are abbreviated and written under the special diacritic symbol titlo, as shown in the figure at the right. That corresponds to the Nomina sacra (Latin: \"Sacred names\") tradition of using contractions for certain frequently-occurring names in Greek ecclesiastical texts. However, sigla for personal nouns are restricted to \"good\" beings and the same words, when referring to \"bad\" beings, are spelled out; for example, while \"God\" in the sense of the one true God is abbreviated as \"\", \"god\" referring to \"false\" gods is spelled out. Likewise, the word for \"angel\" is generally abbreviated as \"\", but the word for \"angels\" is spelled out for \"performed by evil angels\" in Psalm 77.\n\nAdriano Cappelli's \"Lexicon Abbreviaturarum\", enumerates the various medieval brachigraphic signs found in Latin and Italian vulgar texts, which originate from the Roman sigla, a symbol to express a word, and Tironian notes. Quite rarely, abbreviations did not carry marks to indicate that an abbreviation has occurred: if they did, they were often copying errors. For example, \"e.g.\" is written with periods, but modern terms, such as \"PC\", may be written in uppercase.\n\nIt should be noted that the original manuscripts were not written in a modern sans-serif or serif font but in Roman capitals, rustic, uncial, insular, Carolingian or blackletter styles. For more, refer to Western calligraphy or a beginner's guide.\n\nAdditionally, the abbreviations employed varied across Europe. In Nordic texts, for instance, two runes were used in text written in the Latin alphabet, which are ᚠ for \"fé\" \"cattle, goods\" and ᛘ for \"maðr\" \"man\".\n\nCappelli divides abbreviations into six overlapping categories:\n\nSuspended terms are those of which only the first part is written, and the last part is substituted by a mark, which can be of two types:\n\nThe largest class of suspensions consists of single letters standing in for words that begin with that letter.\n\nA dot at the baseline after a capital letter may stand for a title if it is used such as in front of names or a person's name in medieval legal documents. However, not all sigla use the beginning of the word.\nFor plural words, the siglum is often doubled: \"F.\" = \"frater\" and \"FF.\" = \"fratres\". Tripled sigla often stand for three: \"DDD\" = \"domini tres\".\n\nLetters lying on their sides, or mirrored (backwards), often indicate female titles, but a mirrored C, Ↄ, stands generally for \"con\" or \"contra\" (the latter sometimes with a macron above, \"Ↄ̄\").\n\nTo avoid confusion with abbreviations and numerals, the latter are often written with a bar above. In some contexts, however, numbers with a line above indicate that number is to be multiplied by a thousand, and several other abbreviations also have a line above them, such as \"ΧΡ\" (Greek letters chi+rho) = \"Christus\" or \"IHS\" = \"Jesus\".\n\nStarting in the 8th or the 9th century, single letter sigla grew less common and were replaced by longer, less-ambiguous sigla, with bars above them.\n\nAbbreviations by contraction have one or more middle letters omitted. They were often represented with a general mark of abbreviation (above), such as a line above. They can be divided into two subtypes:\n\nSuch marks inform the reader of the identity of the missing part of the word without affecting (\"independent\" of) the meaning. Some of them may be interpreted as alternative contextual glyphs of their respective letters.\n\nThe meaning of the marks depends on the letter on which they appear.\n\nA superscript letter generally referred to the letter omitted, but, in some instances, as in the case of vowel letters, it could refer to a missing vowel combined with the letter \"r\", before or after it. It is only in some English dialects that the letter \"r\" before another consonant largely silent and the preceding vowel is \"r-coloured\".\n\nHowever, \"a\", \"i\", and \"o\" above \"g\" meant \"gͣ\" \"gna\", \"gͥ\" \"gni\" and \"gͦ\" \"gno\" respectively. Although in English, the \"g\" is silent in \"gn\", but in other languages, it is pronounced. Vowel letters above \"q\" meant \"qu\" + vowel: \"qͣ\", \"qͤ\", \"qͥ\", \"qͦ\", \"qͧ\".\n\n\nVowels were the most common superscripts, but consonants could be placed above letters without ascenders; the most common were \"c\", e.g. \"nͨ\". A cut \"l\" above an \"n\", \"nᷝ\", meant \"nihil\" for instance.\n\nThese marks are nonalphabetic letters carrying a particular meaning. Several of them continue in modern usage, as in the case of monetary symbols. In Unicode, they are referred to as \"letter-like glyphs\". Additionally, several authors are of the view that the Roman numerals themselves were, for example, nothing less than abbreviations of the words for those numbers. Other examples of symbols still in some use are alchemical and zodiac symbols, which were, in any case, employed only in alchemy and astrology texts, which made their appearance beyond that special context rare.\n\nIn addition to the signs used to signify abbreviations, medieval manuscripts feature some glyphs that are now uncommon but were not sigla.\nMany more ligatures were used to reduce the space occupied, a characteristic that is particularly prominent in blackletter scripts.\nSome such as r rotunda, long s and uncial or insular variants (Insular G), Claudian letters were in common use, as well as letters derived from other scripts such as Nordic runes: thorn (þ=th) and eth (ð=dh).\nAn illuminated manuscript would feature miniatures, decorated initials or \"littera notabilior\", which later resulted in the bicamerality of the script (case distinction).\n\nVarious typefaces have been designed to allow scribal abbreviations and other archaic glyphs to be replicated in print. They include \"record type\", which was first developed in the 1770s to publish Domesday Book and was fairly widely used for the publication of medieval records in Britain until the end of the 19th century.\n\nIn the Unicode Standard v. 5.1 (4 April 2008), 152 medieval and classical glyphs were given specific locations outside of the Private Use Area. Specifically, they are located in the charts \"Combining Diacritical Marks Supplement\" (26 characters), \"Latin Extended Additional\" (10 characters), \"Supplemental Punctuation\" (15 characters), \"Ancient Symbols\" (12 characters) and especially \"Latin Extended-D\" (89 characters).\nThese consist in both precomposed characters and modifiers for other characters, called combining diacritical marks (such as writing in LaTeX or using overstrike in MS Word).\n\nCharacters are \"the smallest components of written language that have semantic value\" but glyphs are \"the shapes that characters can have when they are rendered or displayed\".\n\n\n\n"}
{"id": "4106285", "url": "https://en.wikipedia.org/wiki?curid=4106285", "title": "Self-referential encoding", "text": "Self-referential encoding\n\nEvery day, people are presented with endless amounts of information, and in an effort to help keep track and organize this information, people must be able to recognize, differentiate and store information. One way to do that is to organize information as it pertains to the self. The overall concept of self-reference suggests that people interpret incoming information in relation to themselves, using their self-concept as a background for new information. Examples include being able to attribute personality traits to oneself or to identify recollected episodes as being personal memories of the past. The implications of self-referential processing are evident in many psychological phenomena. For example, the \"cocktail party effect\" notes that people attend to the sound of their names even during other conversation or more prominent, distracting noise. Also, people tend to evaluate things related to themselves more positively (This is thought to be an aspect of implicit self-esteem). For example, people tend to prefer their own initials over other letters. The self-reference effect (SRE) has received the most attention through investigations into memory. The concepts of self-referential encoding and the SRE rely on the notion that relating information to the self during the process of encoding it in memory facilitates recall, hence the effect of self-reference on memory. In essence, researchers have investigated the potential mnemonic properties of self-reference.\n\nResearch includes investigations into self-schema, self-concept and self-awareness as providing the foundation for self-reference's role in memory. Multiple explanations for the self-reference effect in memory exist, leading to a debate about the underlying processes involved in the self-reference effect. In addition, through the exploration of the self-reference effect, other psychological concepts have been discovered or supported, including simulation theory and the effect.\nAfter researchers developed a concrete understanding of the self-reference effect, many expanded their investigations to consider the self-reference effect in particular groups like those with autism spectrum disorders or those experiencing depression.\n\nSelf-knowledge can be categorized by structures in memory or schemata. A self-schema is a set of facts or beliefs that one has about themselves. For any given trait, an individual may or may not be \"schematic\"; that is, the individual may or may not think about themselves as to where they stand on that trait. For example, people who think of themselves as very overweight or who identify themselves to a greater extent based on their body weight would be considered \"schematic\" on the attribute of body weight. Thus, many everyday events, such as going out for a meal or discussing a friend's eating habits, could induce thoughts about the self. When people relate information to something that has to do with the self, it facilitates memory. Self-descriptive adjectives that fit into one's self-schema are easier to remember than adjectives not viewed as related to the self. Thus, the self-schema is an aspect of oneself that is used as an encoding structure that brings upon memory of information consistent with one's self-schema. Memories that are elaborate and well encoded are usually the result of self-referent correlations during the process of remembering. During the process of encoding, trait representations are encoded in long term memory either directly or indirectly. When they are directly encoded, it is in terms of relating to the self, and when it is indirectly encoded it is done through spouts of episodic information instead of information about the self.\n\nSelf-schema is often used as somewhat of a database for encoding personal data. The self-schema is also used by paying selective attention to outside information and internalizing that information more deeply in one's memory depending on how much that information relates to their schema. When self-schema is engaged, traits that go along with one's view of themselves are better remembered and recalled. These traits are also often recalled much better when processed with respect to the self. Similarly, items that are encoded with the self are based on one's self-schema. Processing the information should balance out when recalled for individuals who have a self-schema that goes along with the information.\n\nSelf-schemas do not necessarily only involve individual traits. People self-categorize at different levels that range from more personal to more social. Self-schemas have three main categories which play a role: the personal self, the relational self, and the collective self. The personal self deals with individual level characteristics, the relational self deals with intimate relationship partners, and the collective self deals with group identities, relating to self-important social groups to which one belongs (e.g., one's family or university). Information that is related to any type of self-schema, including group-related knowledge structures facilitates memory.\n\nIn order for the self to be an effective encoding mechanism, it must be a uniform, consistent, well-developed schema. It has been shown that identity exploration leads to the development of self-knowledge which facilitates self-judgments. Identity exploration led to shorter decision times, higher confidence ratings and more intrusions in memory tasks. Previous researchers hypothesized that words compatible with a person's self-schema are easily accessible in memory and are more likely than incompatible words to intrude on a schema-irrelevant memory task. In one experiment, when participants were asked to decide if certain adjectives were \"like me\" or \"not like me,\" they made the decisions faster when the words were compatible with their self-schema.\n\nHowever, despite the existence of the self-reference effect when considering schemata consistent adjectives, the connection between the self and memory can lead to a larger number of mistakes in recognition, commonly referred to as false alarms. Rogers et al. (1979) found that people are more likely to falsely recognize adjectives they had previously designated to be self-descriptive. Expanding on this, Strube et al. (1986) found that false alarms occurred more for self-schema consistent content, presumably because the presence of such words in the schema makes them more accessible in memory.\n\nIn addition to investigating the self-reference effect in regards to schemata consistent information, Strube et al. discussed how counter schemata information relates to this framework. They noted that the pattern of making correct decisions more rapidly did not hold when considering words that countered a person's self-schema, presumably because they were difficult to integrate into memory due to lack of a preexisting structure. That is, they lacked the organizational structure of encoding because they did not fall into the \"like me\" category, and elaboration would not work because prior connections to the adjective did not exist.\n\nTwo of the most common functions of the self receiving significant attention in research are the self-acting to organize the individual's understanding of the social environment, and the self functioning to regulate behavior through self-evaluation. The concept of self-awareness is considered to be the foundational principle for both functions of the self. Some research presents self-awareness in terms of self-focused attention whereas Hull and Levy suggest that self-awareness refers to the encoding of information based on its relevance to the self. Based on the latter interpretation of self-awareness, individuals must identify the aspects of situations that are relevant to themselves and their behavior will be shaped accordingly. Hull and Levy suggest that self-awareness corresponds to the encoding of information cued by self-symbolic stimuli, and examine the idea of self-awareness as a method of encoding. They structured an investigation that examined self-referent encoding in individuals with different levels of self-awareness, predicting that individuals with higher levels of self-consciousness would encode self-relevant information more deeply than other information, and that they would encode it more deeply than individuals with low levels of self-consciousness. The results of their investigation supported their hypothesis that self-focused attention is not enough to explain the role of self-awareness on attribution. Their results suggest that self-awareness leads to increased sensitivity to the situationally defined meanings of behavior, and therefore organizes the individual's understanding of the social environment. The research presented by Hull and Levy led to future research on the encoding of information associated with self-awareness.\n\nIn later research, Hull and colleagues examined the associations between self-referential encoding, self-consciousness and the extent to which a stimulus is consistent with self-knowledge. They first assumed that the encoding of a stimulus is facilitated if an individual's working memory already contains information consistent with the stimulus, and suggested that self-consciousness as an encoding mechanism relies on an individual's self-knowledge. It is known that situational and dispositional factors may activate certain pools of knowledge, moving them into working memory, and guiding the processing of certain stimulus information.\n\nIn order to better understand the idea of activating information in memory, Hull et al. presented an example of how information is activated. They referred to the sentence \"The robber took the money from the bank\". In English, the word bank has two applicable meanings in the context of this sentence (monetary institution and river shore). However, the monetary institution meaning of the word is more highly activated in this context due to the addition of the words robber and money to the sentence, because they are associatively relevant and therefore pull the monetary institution definition for bank into working memory. Once information is added to working memory, meanings and associations are more easily drawn. Therefore, the meaning of this example sentence is almost universally understood.\n\nIn reference to self-consciousness and self-reference, the connection between self-consciousness and self-referent encoding relies on such information activation. Research suggests that self-consciousness activates knowledge relating to the self, thereby guiding the processing of self-relevant information. Three experiments conducted by Hull and colleagues provided evidence that a manipulation of accessible self-knowledge impacts self-referent encoding based on the self-relevance of such information, individual differences in the accessibility of self-knowledge (self-consciousness) impacts perception, and a mediation relationship exists between self-consciousness and individual differences in self-referential encoding.\n\nSimilar to how self-awareness impacts the availability of self-knowledge and the encoding of self-relevant information, through the development of the self-schema, people develop and maintain certain personality characteristics leading to a variety of behavior patterns. Research has been done on the differences between Type A and Type B behavior patterns, focusing on how people in each group respond to environmental information and their interpretation of the performance of others and themselves. It has been found that Type A behavior is characterized by competitive achievement striving, time urgency and hostility, whereas Type B is usually defined as an absence of Type A characteristics. When investigating causal attributions for hypothetical positive and negative outcomes, Strube et al. found that Type A individuals were more self-serving, in that they took greater responsibility for positive than negative effects. Strube and colleagues argued that this could be a result of the fact that schema-consistent information is more easily remembered and the ease with which past successes and failures are recalled, determined by self-schema, would impact attributions. It is reasonable to believe that Type A's might recall successes more easily and hence be more self-serving.\n\nInfluential psychologists Craik and Lockhart laid the groundwork for research focused on self-referential encoding and memory. In 1972 they proposed their Depth of Processing framework which suggests that memory retention depends on how the stimulus material was encoded in memory. Their original research considered structural, phonemic, and semantic encoding tasks, and showed that semantic encoding is the best method to aid in recall. They asked participants to rate 40 descriptive adjectives on one of four tasks; Structural (Big font or small font?), Phonemic (Rhymes with xxx?), Semantic (Means same as xxx?), or Self-reference (Describes you?). This was then followed by an \"incidental recall task\". This is where participants are asked, without prior warning, to recall as many of the words they had seen as possible within a given time limit. Craik and Tulving's original experiment showed that structural and phonemic tasks lead only to \"shallow\" encoding, while the semantic tasks lead to \"deep\" encoding and resulted in better recall.\n\nHowever, in 1977, it was shown that self-relevant or self-descriptive encoding leads to even better recall than semantic tasks. Experts suggest that the call on associative memory required by semantic tasks is what provides the advantage over structural or phonemic tasks, but is not enough to surpass the benefit provided by self-referential encoding. The fact that self-reference was shown to be a stronger memory encoding method than semantic tasks is what led to more significant interest in the field One early and significant experiment aimed to place self-reference on Craik and Lockhart's depth of processing hierarchy, and suggested that self-reference was a more beneficial encoding method than semantic tasks. In this experiment, participants filled out self-ratings on 84 adjectives. Months later, these participants were revisited and were randomly shown 42 of those words. They then had to select the group of 42 \"revisited\" words out of the total original list. The researchers argued that if the \"self\" was involved in memory retrieval, participants would incorrectly recognize words that were more self-descriptive In another experiment, subjects answered yes or no to cue questions about 40 adjective in 4 tasks (structural, phonemic, semantic and self-referential) and later had to recall the adjectives. This experiment validated the strength of self-reference as an encoding method, and indicated it developed a stronger memory trace than the semantic task.\n\nResearchers are implementing a new strategy by developing different encoding tasks that enhance memory very similarly to self-referential encoding. Symons (1990) had findings that went against the norm when he was unable to find evidence of self-schematicity in the self-reference effect. Another finding was that when referencing gender and religion, there was a low memory recall when compared with referencing the self. A meta-analysis by Symons and Johnson (1997) showed self-reference resulting in better memory in comparison to tasks relying on semantic encoding or other-referent encoding. According to Symons and Johnson, self-referencing questions elicit elaboration and organization in memory, both of which creating a deeper encoding and thus facilitate memory.\n\nTheorists that favor the view that the self has a special role believe that the self leads to more in depth processing, leading to easier recall during self-reference tasks. Theorists also promote the self-schema as being one of the sole inhibitors that allow for recall from deep memory. Thorndyke and Hayes-Roth had the goal of focusing on the process made by the active memory schemata. Sex-typed individuals recall trait adjectives that go along with their sex role more quickly than trait adjectives that are not. During the process of free recall, these individuals also showed more patterns for gender clustering than other sexually typed individuals.\n\nAs research on self-referential encoding became more prolific, some psychologists took an opportunity to delineate specific self-referential encoding tasks. It is noted that descriptive tasks are those that require participants to determine if a stimulus word can be classified as \"self-descriptive.\" Autobiographical tasks are those that require participants to use the stimulus word as a cue to recall an autobiographical memory. Results from experiments that differentiated between these types of self-referential encoding found that they both produced better recall than semantic tasks, and neither was more advantageous than the other. However, research does suggest that the two types of self-referential encoding do rely on different processes to facilitate memory. In most experiments discussed, these types of self- referential encoding were not differentiated.\n\nIn a typical self-reference task, adjectives are presented and classified as either self-descriptive or not. For example, in a study by Dobson and Shaw, adjectives about the self that were preselected were given to the participants and they decide whether or not the adjectives are self-descriptive. The basis for making certain judgments, decisions, inferences and decisions is a self-referent encoding task. If two items are classified as self-descriptive there is no reason one trait would not be equally as easy to retrieve as the other on a self-reference task.\n\nWhile a significant amount of research supports the existence of the self-reference effect, the processes behind it are not well understood. However, multiple hypotheses have been introduced, and two main arguments have been developed: the elaborative processing hypothesis and the organizational processing hypothesis. Encodings in reference to the self are so elaborate because of the information one has about the self. Information encoded with the self is better remembered than information encoded with reference to something else.\n\nElaboration refers to the encoding of a single word by forming connections between it and other material already stored in memory. By creating these connections between the stimulus word and other material already in memory, multiple routes for retrieval of the stimulus word are formed. Based on the depth of processing framework, memory retention increases as elaboration during encoding increases. The Elaborative Processing Hypothesis would suggest that any encoding task that leads to the development of the most trace elaboration or associations is the best for memory retention. Additional research on the depth of processing hierarchy suggests that self-reference is the superior method of information encoding. The elaborative hypothesis would suggest this is because self-reference creates the most elaborate trace, due to the many links that can be made between the stimulus and information about the self already in memory.\n\nThe organizational processing hypothesis was proposed by Klein and Kihlstrom. This hypothesis suggests that encoding is best prompted by considering stimulus words in relation to one another. This thought process and relational thinking creates word to word associations. These inter-item associations are paths in memory that can be used during retrieval. Also, the category labels that define the relations between stimulus items can be used as item cues. Evidence of the organizational component of encoding is demonstrated through the clustering of words during recall. Word clustering during recall indicates that relational information was used to store the words in memory. Rogers, Kuiper and Kirker showed that self-referential judgments were more likely to encourage organization than semantic ones. Therefore, they suggested the self-reference effect was likely due to the organizational processing endured by self-referential encoding.\n\nStructural, phonemic and semantic tasks within the depth of processing paradigm require words to be considered individually, and lend themselves to an elaborative approach. As such, it can be argued that self-referential encoding is superior because it leads to an indirect division of words into categories: words that describe me versus words that do not. Due to this connection between self-reference and organizational processing, further research has been done on this area. Klein and Kihlstrom's research suggests first that, like previous research, self-reference led to better recall than semantic and structural encoding. Second, they found that self-referentially encoded words were more clustered in recall than words from other tasks, suggesting higher levels of organizational processing. From this they concluded that the organization, not encoding task, is what makes self-referential encoding superior \n\nPsychologists Einstein and Hunt showed that both elaborative processing and organizational processing facilitate recall. However, their research argues that the effectiveness of either approach depends on how related the stimulus words are to one another. A list of highly related stimulus words would be better encoded using the elaborative method. The relations between the words would be evident to subjects; therefore, they would not gain any additional pathways for retrieval by encoding the words based on their categorical membership. Instead, the other information gained through elaborative processing would be more beneficial. On the other hand, a list of stimulus words with little relation would be better stored to memory through the organizational method. Since the words have no obvious connection to one another, subjects would likely encode them individually, using an elaborative approach. Since relational information wouldn't be readily detected, focusing on it would add to memory by creating new traces for retrieval. Superior recall was better explained by a combination of elaboration and organization.\nUltimately, the exact processes behind self-referential encoding that makes it superior to other encoding tasks are still under debate. Research suggests that if elaborative processing is behind self-referential encoding, a self-referential task should have the same effect as an elaborative task, whereas if organizational processing underlies the self-reference effect self-referential encoding tasks should function like organizational tasks. To test this, Klein and Loftus ran a 3x2 study testing organizational, elaborative and self-referential encoding with lists of 30 related or unrelated words. When participants were asked to memorize the unrelated list, recall and clustering were higher for the organizational task, which produced almost equal results to the self-referential task, suggesting that has an organizational basis. For the list of related words, the elaborative task led to better recall and had matched results to the self-reference task, suggesting an elaborative basis. This research, then, suggests that the self-reference effect cannot be explained by a single type of processing. Instead, self-referential encoding must lead to information in memory that incorporates item specific and relational information.\n\nOverall, the SRE relies on the unique mnemonic aspects of the self. Ultimately, if the research is suggesting that the self has superior elaborative or organizational properties, information related to the self should be more easily remembered and recalled. The research presented suggests that self-referential encoding is superior because it promotes organization and elaboration simultaneously, and provides self-relevant categories that promote recall.\n\nThe field of social brain science is aimed at examining the neural foundations of social behavior. Neuroimaging and neuropsychology have led to the examination of neuroanatomy and its connection to psychological topics. Through this research, neuropsychologists have found a connection between social cognitive functioning and the medial prefrontal cortex (mPFC). In addition, the mPFC has been connected to reflection and introspection about personal mental states. Supporting these findings, it has been shown that damage to the mPFC is connected to impairments with self-reflection, introspection and daydreaming, as well as social competence, but not other areas of functioning. As such, the mPFC has been connected to self-referential processing.\n\nThe research discussed by those focusing on the neuroanatomy of self-referential processing included similar tasks to the memory and depth of processing research discussed previously. When participants were asked to judge adjectives based in whether or not they were self-descriptive, it was noted that the more self-relevant the trait, the stronger the activation of the mPFC. In addition, it was shown that the mPFC was activated during the appraisal of one's own personality traits, as well as during trait retrieval. One study showed that the more activity in the mPFC during self-referential judgments, the more likely the word was to be remembered on a subsequent surprise memory test. These results suggest that the mPFC is involved in both self-referential processing and in creating self-relevant memories.\n\nMedial prefrontal cortex (mPFC) activation occurs during processing of self-relevant information. When self-referent judgment is more relatable and less negative, the mFPC is activated. Finding support clear cut circuits that have high levels of activation when cognitive and emotional aspects of self-reflection are present. The caudate nucleus has not been associated with self-reference before, however, Fossati and colleagues found activity while participants were retrieving self-relevant trait adjectives. The ventral anterior cingulate cortex (vACC) is also a part of the brain that becomes activated when there are signs of self-referencing and processing. The vACC is activated when self-descriptive information is negative. There is also pCC (posterior cingulate cortex) activity seen in neuroimaging studies during self-referential processing.\n\nGiven all of the neurological support for the effect of self-reference on encoding and memory, there is still a debate in the psychological community about whether or not the self-reference effect signifies a special functional role played by the self in cognition. Generally, this question is met by people that have two opposing views on the processes behind self-reference. On one side of the debate, people believe that the self has special mnemonic abilities because it is a unique cognitive structure. On the other side, people support the arguments described above that suggest there is no special structure, but instead, the self-reference effect is simply a part of the standard depth of processing hierarchy. Since the overall hypothesis is the same for both sides of the debate, that self-relevant material leads to enhanced memory, it is difficult to test them using strictly behavioral measures. Therefore, PET and fMRI scans have been used to see the neural marker of self-referential mental activity.\n\nPrevious studies have shown that areas of the left prefrontal cortex are activated during semantic encoding. Therefore, if the self-reference effect works the same way, as part of the depth of processing hierarchy, the same brain region should be activated when judging traits related to the self. However, if the self has unique mnemonic properties, then self-referential tasks should activate brain regions distinct from those activated during semantic tasks. The field is still at is infancy, but future work on this hypothesis might help to settle the debate about the underlying processes of self-referential encoding.\n\nWhile not able to completely settle the debate over the foundation of self-referential processing, studies on the neurological aspect of personality trait judgments did lead to a related, significant result. It has been shown that judging personality traits about oneself and a close friend activated overlapping brain regions, and the activated regions have all been implicated in self-reference. Noting the similarity between making self-judgments and judgments about close others led to the introduction of the simulation theory of empathy. Simulation theory rests on the idea that one can make inferences about others by using the knowledge they have about themselves. In essence, the theory suggests that people use self-reflection to understand or predict the mental state of others. The more similar a person perceives another to be, the more active the mPFC has shown to be, suggesting more deep or intricate self-reference. However, this effect can cause people to make inaccurate judgments about others or to believe that their own opinions are representative of others in general. This misrepresentation is referred to as the false-consensus effect.\n\nIn addition to simulation theory, other expansions of the self-reference effect have been examined. Through studying the self, researchers have found that the self consists of many independent cognitive representations. For example, the personal self composed of individual characteristics is separate from the relational self which is based on relationships with significant others. These two forms of self are again separate from the collective self which corresponds to a particular group identity. Noting the existence of the collective self and the different group identities that combine to form such a self-representation led researchers to question if information stored in reference to a social group identity has the same effects in memory as information stored in reference to the individual self. In essence, researchers questioned if the self-reference effect can be extended to include situations where the self is more socially defined, producing a group-reference effect.\n\nPrevious research supports the idea that the group-reference effect should exist from a theoretical standpoint. First, the self-expansion model argues that individuals incorporate characteristics of their significant others (or other in-group members into the development of their self-concept. From this model, it is reasonable to conclude that characteristics that are common to both oneself and their significant others (or in-group members) would be more accessible. Second, the previous research discussed suggests that the self-reference effect is due to some combination of organizational, elaborative, mental cueing or evaluative properties of self-referential encoding tasks. Given that we have significant stores of knowledge about our social identities, and such collective identities provide an organizational framework, it is reasonable to assume that a group-reference task would operate similar to that of a self-reference task.\n\nIn order to test these claims, Johnson and colleagues aimed to test whether the self-reference effect generalized to group level identities. Their first study was structured to simply assess if group-reference influenced subsequent memory. In their experiment, they used membership at a particular university as the group of reference. They included group-reference, self-reference and semantic tasks. The experiment replicated the self-reference effect, consistent with previous research. In addition, evidence for a group-reference effect was found. Group-referenced encoding produced better recall than the semantic tasks, and the level of recall from the group-referenced task was not significantly different from the self-referenced task.\n\nDespite finding evidence of a group-reference effect, Johnson and colleagues pointed out that people identify with numerous groups, each with unique characteristics. Therefore, in order to reach conclusive evidence of a group-reference effect, alternative group targets need to be considered. In a second experiment by Johnson et al., the group of reference was modified to be the family of the individual. This group has fewer exemplars than the pool of university students, and affective considerations of the family as a group should be strong. No specific instructions or definitions were provided for family, allowing individuals to consider either the group as a whole (prototype) or specific exemplars (group). When the experiment was repeated using family as the group of reference, group-reference produced recall as much as self-reference. The mean number of recall for the group-reference was higher than self-reference. Participants indicated that they considered both the prototype and individual exemplars when responding to the questions, suggesting that the magnitude of the group-reference effect might not be dependent on the number of exemplars in the target group.\nBoth experiments presented by Johnson et al. found evidence for the group-reference effect. However, these conclusions are limited to the target groups of university students and family. Other research included gender (males and females) and religion (Jewish) as the reference groups and the group-reference effect on memory was not as evident. The group-reference recall for these two groups was not significantly more advantageous than the semantic task. Questioning what characteristics of reference groups that lead to the group-reference effect, a meta-analysis of all four group-reference conditions was performed. This analysis found that self-reference emerged as the most powerful encoding device; however, evidence was found to support the existence of a group-reference effect. The size of the reference groups and number of specific, individual exemplars was hypothesized to influence the existence of the group-reference effect. In addition, accessibility and level of knowledge about group members may also impact such an effect. So, while university students is a much larger group than family, individual exemplars may be more readily accessible than those in a religious group. Similarly, different cognitive representations were hypothesized to influence the group-reference effect. When a larger group is considered, people may be more likely to consider a prototype which may lead to fewer elaborations and cues later on. Smaller groups may lead to relying on the prototype and specific exemplars. Finally, desirability judgments that influence later processing may be influenced by self-reference and certain group-reference tasks. Individuals may be more sensitive to evaluative implications for the personal self and some group identities, but not others.\n\nGroups are also a major part of the self; therefore we attribute the role that different groups play in our self-concept also play a role in the self-reference effect. We process information about group members similarly to how we process for ourselves. Recall of remarks referencing our home and our self and group to familiarity of those aspects of our self. Reference to the self and social group and the identity that comes along with being a part of a social group are equally affective for memory. This is especially true when the groups are small, rather than large.\n\nUltimately, the group-reference effect provides evidence to explain the tendency to notice or pay attention to and remember statements made in regard to our home when traveling in a foreign place. Considering the proposal that groups form part of the self, this phenomenon can be considered an extension of the self-reference effect. Similar to the memorable nature of references to a person's individual self, references to social identities are seemed to be privileged in memory as well.\n\nOnce the foundation of research on self-referential encoding was established, psychologists began to explore how the concept applied to different groups of people, and connected to different phenomena.\n\nIndividuals diagnosed with autism spectrum disorders (ASDs) can display a wide range of symptoms. Some of the most common characteristics of individuals with ASDs include impairments with social functioning, language and communication difficulties, repetitive behaviors and restricted interests. In addition, it is often noted that these individuals are more \"self-focused.\" That is, they have difficulty seeing things from another's perspective. Despite being self-focused, though, research has shown that individuals with ASD's often have difficulty identifying or describing their emotions or the emotions of others. When asked to describe their daily experiences, responses from individuals on the autism spectrum tended to focus more on physical descriptions rather than mental and emotional states. In regards to their social interactions and behavior differences, it is thought that these individuals lack top down control, and therefore, their bottom up decisions remain unchecked. This simply suggests that these individuals cannot use their prior knowledge and memory to make sense of new input, but instead react to each new input individually, compiling them to make a whole picture \n\nNoting the difficulty individuals with ASDs experience with self-awareness, it was thought that they might have difficulty with self-related memory processes. Psychologists questioned if these individuals would show the typical self-reference effect in memory. In one Depth of Processing Study, participants were asked questions about the descriptiveness of certain stimulus words. However, unlike previous DOP studies that focused on phonemic, structural, semantic and self-referential tasks, the tasks were altered for this experiment. To test the referential abilities of individuals with ASD's, the encoding tasks were divided into: \"the self,\" asking to what extent a stimulus word described oneself, \"similar close other,\" asking to what extent a stimulus word was descriptive of one's best friend, \"dissimilar non-close other,\" asking to what extent a stimulus word was descriptive of Harry Potter, and a control group that was asked to determine the number of syllables in each word. Following these encoding tasks, participants were given thirty minutes before a surprise memory task. It was found that individuals with ASD's had no impairment in memory for words encoded in the syllable or dissimilar non-close other condition. However, they had decreased memory for words related to the self.\n\nTherefore, while research suggests that self-referentially encoded information is encoded more deeply than other information, the research on individuals with ASD's showed no advantage for memory recognition with self-reference tasks over semantic encoding tasks. This suggests that individuals with ASD's don't preferentially encode self-relevant information. Psychologists have investigated the biological basis for the decreased self-reference effect among individuals with Autism Spectrum Disorders and have suggested that it may be due to less specialized neural activity in the mPFC for those individuals. However, while individuals with ASD's showed smaller self-reference effects than the control group, some evidence of a self-reference effect was evident in some cases. This indicates that self-referent impairments are a matter of degree, not total absence.\n\nLombardo and his colleagues measured empathy among individuals with ASD's, and showed that these individuals scored lower than the control group on all empathy measures. This may be a result of the difficulty for these individuals to understand or take the perspective of others, in conjunction with their difficulty identifying emotions. This has implications for simulation theory, because these individuals are unable to use their self-knowledge to make conclusions about similar others.\n\nUltimately, the research suggests that people with ASD's might benefit from being more self-focused. The better their ability to reflect on themselves, the better the can mentalize with others.\n\nThere are three possible relations between cognitive processes and anxiety and depression. The first is whether cognitive processes are actually caused by the onset of clinically diagnosed symptoms of major depression or just generalized sadness or anxiousness. The second is whether emotional disorders such as depression and anxiety are able to be considered as caused by cognitions. And the third is whether different specific cognitive processes are able to be considered associates of different disorders. Kovacs and Beck (1977) posited a schematic model of depression where an already depressed self was primed by outside prompts that negatively impacted cognitive illusions of the world in the eye of oneself. These prompts only led participants to a more depressive series of emotions and behavior. The results from the study done by Derry and Kuiper supported Beck's theory that a negative self-schema is present in people, especially those with depressive disorder. Depressed individuals attribute depressive adjectives to themselves more than nondepressive adjectives. Those suffering from a more mild case of depression have trouble deciphering between the traits of themselves and others which results in a loss of their self-esteem and their negative self-evaluation. A depressive schema is what causes the negativity reported by those suffering from depression. Kuiper and Derry found that self-referent recall enhancement was limited only to nondepressed content.\n\nGenerally, self-focus is association with negative emotions. In particular private self-focus is more strongly associated with depression than public self-focus. Results from brain-imaging studies shows\nthat during self-referential processing, those with major depressive disorder show greater activation in the medial prefrontal cortex, suggesting that depressed individuals may be exhibiting greater cognitive control than\nnon-depressed individuals when processing self-relevant information.\n"}
{"id": "858507", "url": "https://en.wikipedia.org/wiki?curid=858507", "title": "Self-referential humor", "text": "Self-referential humor\n\nSelf-referential humor, also known as self-reflexive humor or meta humor, is a type of comedic expression that—either directed toward some other subject, or openly directed toward itself—intentionally alludes to the very person who is expressing the humor in a comedic fashion, or to some specific aspect of that same comedic expression. Self-referential humor expressed discreetly and surrealistically is a form of bathos. In general, self-referential humor often uses hypocrisy, oxymoron, or paradox to create a contradictory or otherwise absurd situation that is humorous to the audience. \n\nSelf-referential humor is sometimes combined with breaking the fourth wall to explicitly make the reference directly to the audience, or make self-reference to an element of the medium that the characters should not be aware of.\n\nOld Comedy of Classical Athens is held to be the first—in the extant sources—form of self-referential comedy. Aristophanes, whose plays form the only remaining fragments of Old Comedy, used fantastical plots, grotesque and inhuman masks and status reversals of characters to slander prominent politicians and court his audience's approval.\n\nRAS syndrome refers to the redundant use of one or more of the words that make up an acronym or initialism with the abbreviation itself, thus in effect repeating one or more words. However, \"RAS\" stands for Redundant Acronym Syndrome; therefore, the full phrase yields \"Redundant Acronym Syndrome syndrome\" and is self-referencing in a comical manner. It also reflects an excessive use of TLAs (Three Letter Acronyms).\n\nMeta has come to be used, particularly in art, to refer to something that is self-referential. Popularised by Douglas Hofstadter who wrote several books on himself and the subject of self-reference, meta-jokes are a popular form of humor.\n\n"}
{"id": "29663614", "url": "https://en.wikipedia.org/wiki?curid=29663614", "title": "Species affinis", "text": "Species affinis\n\nSpecies affinis (commonly abbreviated to: sp. aff., aff., or affin.) is taxonomic terminology in zoology and botany. In open nomenclature it indicates that available material or evidence suggests that the proposed species is \"related to\", has an \"affinity\" to, but is \"not identical to\", the species with the binomial name that follows. The Latin word \"affinis\" can be translated as \"closely related to\", or \"akin to\".\n\nAn author who inserts \"n.sp.,\" or \"sp. nov., aff\" before a species name thereby states the opinion that the specimen is a new, previously undescribed species, but that there may not (yet) be enough information to complete a formal description. To use aff. alone, implies that the specimen differs suggestively from the holotype but that further progress is necessary to confirm that it is a novel species.\n\nAn example would be: a gastropod shell listed as \"Lucapina\" aff. \"aegis\" would mean that this shell somewhat resembles the shell of \"Lucapina aegis\", but is thought more likely to be another species, either closely related to, or closely resembling \"Lucapina aegis\". In a suitable context it also may suggest the possibility that the shell belongs to a species that has not yet been described.\n\nThe use of aff. is similar to other indicators of open nomenclature such as cf., sp., or ?, but the latter indicate that the species is \"uncertain\" rather than undescribed.\n\n"}
{"id": "3423601", "url": "https://en.wikipedia.org/wiki?curid=3423601", "title": "Stumpers-L", "text": "Stumpers-L\n\nThe Stumpers-L electronic mailing list, was a resource available for librarians and others to discuss reference questions which they were unable to answer using available resources. It was succeeded by the similar Project Wombat.\n\nStumpers-L began in 1992, created by Ann Feeney, a library school graduate student at Rosary College in River Forest, Illinois, in the United States. It was moved to Concordia University, Chicago, then back to Rosary, which was then renamed Dominican University. From 2002 to 2005 it was maintained by the Dominican University Graduate School of Library and Information Science program. At the end of 2005 Dominican University ceased hosting the list. A replacement list, known as Project Wombat, commenced in January 2006, and is hosted by Project Gutenberg.\n\nOriginally the Stumpers-L archive was a gopher resource, but migrated to the World Wide Web once the web became more universally used in the mid-1990s.\n\nTypical Stumpers-L topics include:\n\nA book of Stumpers-L questions and answers was published in 1998 by Random House, edited by Fred Shapiro of Yale and titled \"Stumpers! Answers to Hundreds of Questions That Stumped The Experts\" (). Shapiro was an active member; other prominent members include Barbara and David P. Mikkelson, the co-editors of \"Snopes.com.\n\nThe unofficial mascot of the Stumpers-L list is the wombat.\n\n"}
{"id": "1707086", "url": "https://en.wikipedia.org/wiki?curid=1707086", "title": "Tag (metadata)", "text": "Tag (metadata)\n\nIn information systems, a tag is a keyword or term assigned to a piece of information (such as an Internet bookmark, digital image, database record, or computer file). This kind of metadata helps describe an item and allows it to be found again by browsing or searching. Tags are generally chosen informally and personally by the item's creator or by its viewer, depending on the system, although they may also be chosen from a controlled vocabulary.\n\nTagging was popularized by websites associated with Web 2.0 and is an important feature of many Web 2.0 services. It is now also part of other database systems, desktop applications, and operating systems.\n\nPeople use tags to aid classification, mark ownership, note boundaries, and indicate online identity. Tags may take the form of words, images, or other identifying marks. An analogous example of tags in the physical world is museum object tagging. People were using textual keywords to classify information and objects long before computers. Computer based search algorithms made the use of such keywords a rapid way of exploring records.\n\nTagging gained popularity due to the growth of social bookmarking, image sharing, and social networking websites. These sites allow users to create and manage labels (or \"tags\") that categorize content using simple keywords. Websites that include tags often display collections of tags as tag clouds, as do some desktop applications. On websites that aggregate the tags of all users, an individual user's tags can be useful both to them and to the larger community of the website's users.\n\nTagging systems have sometimes been classified into two kinds: \"top-down\" and \"bottom-up\". Top-down taxonomies are created by an authorized group of designers (sometimes in the form of a controlled vocabulary), whereas bottom-up taxonomies (called folksonomies) are created by all users. This definition of \"top down\" and \"bottom up\" should not be confused with the distinction between a \"single hierarchical\" tree structure (in which there is one correct way to classify each item) versus \"multiple non-hierarchical\" sets (in which there are multiple ways to classify an item); the structure of both top-down and bottom-up taxonomies may be either hierarchical, non-hierarchical, or a combination of both. Some researchers and applications have experimented with combining hierarchical and non-hierarchical tagging to aid in information retrieval. Others are combining top-down and bottom-up tagging, including in some large library catalogs (OPACs) such as WorldCat.\n\nWhen tags or other taxonomies have further properties (or semantics) such as relationships and attributes, they constitute an ontology.\n\nMetadata tags as described in this article should not be confused with the use of the word \"tag\" in some software to refer to an automatically generated cross-reference; examples of the latter are \"tags tables\" in Emacs and \"smart tags\" in Microsoft Office.\n\nThe use of keywords as part of an identification and classification system long predates computers. Paper data storage devices, notably edge-notched cards, that permitted classification and sorting by multiple criteria were already in use prior to the twentieth century, and faceted classification has been used by libraries since the 1930s.\n\nIn the late 1970s and early 1980s, the Unix text editor Emacs offered a companion software program called \"Tags\" that could automatically build a table of cross-references called a \"tags table\" that Emacs could use to jump between a function call and that function's definition. This use of the word \"tag\" did not refer to metadata tags, but was an early use of the word \"tag\" in software to refer to a word index.\n\nOnline databases and early websites deployed keyword tags as a way for publishers to help users find content. In the early days of the World Wide Web, the codice_1 meta element was used by web designers to tell web search engines what the web page was about, but these keywords were only visible in a web page's source code and were not modifiable by users.\n\nIn 2003, the social bookmarking website Delicious provided a way for its users to add \"tags\" to their bookmarks (as a way to help find them later); Delicious also provided browseable aggregated views of the bookmarks of all users featuring a particular tag. Within a couple of years, the photo sharing website Flickr allowed its users to add their own text tags to each of their pictures, constructing flexible and easy metadata that made the pictures highly searchable. The success of Flickr and the influence of Delicious popularized the concept, and other social software websites—such as YouTube, Technorati, and Last.fm—also implemented tagging. In 2005, the Atom web syndication standard provided a \"category\" element for inserting subject categories into web feeds, and in 2007 Tim Bray proposed a \"tag\" URN.\n\nMany blog systems (and other web content management systems) allow authors to add free-form tags to a post, along with (or instead of) placing the post into a predetermined category. For example, a post may display that it has been tagged with codice_2 and codice_3. Each of those tags is usually a web link leading to an index page listing all of the posts associated with that tag. The blog may have a sidebar listing all the tags in use on that blog, with each tag leading to an index page. To reclassify a post, an author edits its list of tags. All connections between posts are automatically tracked and updated by the blog software; there is no need to relocate the page within a complex hierarchy of categories.\n\nSome desktop applications and web applications feature their own tagging systems, such as email tagging in Gmail and Mozilla Thunderbird, bookmark tagging in Firefox, audio tagging in iTunes or Winamp, and photo tagging in various applications. Some of these applications display collections of tags as tag clouds.\n\nThere are various systems for applying tags to the files in a computer's file system. In Apple's macOS, the operating system has allowed users to assign multiple arbitrary tags as extended file attributes to any file or folder ever since OS X 10.9 was released in 2013, and before that time the open-source OpenMeta standard provided similar tagging functionality in macOS. Several semantic file systems that implement tags are available for the Linux kernel, including Tagsistant. Microsoft Windows allows users to set tags only on Microsoft Office documents and some kinds of picture files.\n\nCross-platform file tagging standards include Extensible Metadata Platform (XMP), an ISO standard for embedding metadata into popular image, video and document file formats, such as JPEG and PDF, without breaking their readability by applications that do not support XMP. XMP largely supersedes the earlier IPTC Information Interchange Model. Exif is a standard that specifies the image and audio file formats used by digital cameras, including some metadata tags. TagSpaces is an open-source cross-platform application for tagging files; it inserts tags into the filename.\n\nAn \"official tag\" is a keyword adopted by events and conferences for participants to use in their web publications, such as blog entries, photos of the event, and presentation slides. Search engines can then index them to make relevant materials related to the event searchable in a uniform way. In this case, the tag is part of a controlled vocabulary.\n\nA researcher may work with a large collection of items (e.g. press quotes, a bibliography, images) in digital form. If he/she wishes to associate each with a small number of themes (e.g. to chapters of a book, or to sub-themes of the overall subject), then a group of tags for these themes can be attached to each of the items in the larger collection. In this way, freeform classification allows the author to manage what would otherwise be unwieldy amounts of information.\n\nA triple tag or machine tag uses a special syntax to define extra semantic information about the tag, making it easier or more meaningful for interpretation by a computer program. Triple tags comprise three parts: a namespace, a predicate, and a value. For example, codice_4 is a tag for the geographical longitude coordinate whose value is 50.123456. This triple structure is similar to the Resource Description Framework model for information.\n\nThe triple tag format was first devised for geolicious in November 2004, to map Delicious bookmarks, and gained wider acceptance after its adoption by Mappr and GeoBloggers to map Flickr photos. In January 2007, Aaron Straup Cope at Flickr introduced the term \"machine tag\" as an alternative name for the triple tag, adding some questions and answers on purpose, syntax, and use.\n\nSpecialized metadata for geographical identification is known as \"geotagging\"; machine tags are also used for other purposes, such as identifying photos taken at a specific event or naming species using binomial nomenclature.\n\nA hashtag is a kind of metadata tag marked by the prefix codice_5, sometimes known as a \"hash\" symbol. This form of tagging is used on microblogging and social networking services such as Twitter, Facebook, Google+, VK and Instagram.\n\nA knowledge tag is a type of meta-information that describes or defines some aspect of a piece of information (such as a document, digital image, database table, or web page). Knowledge tags are more than traditional non-hierarchical keywords or terms; they are a type of metadata that captures knowledge in the form of descriptions, categorizations, classifications, semantics, comments, notes, annotations, hyperdata, hyperlinks, or references that are collected in tag profiles (a kind of ontology). These tag profiles reference an information resource that resides in a distributed, and often heterogeneous, storage repository.\n\nKnowledge tags are part of a knowledge management discipline that leverages Enterprise 2.0 methodologies for users to capture insights, expertise, attributes, dependencies, or relationships associated with a data resource. Different kinds of knowledge can be captured in knowledge tags, including factual knowledge (that found in books and data), conceptual knowledge (found in perspectives and concepts), expectational knowledge (needed to make judgments and hypothesis), and methodological knowledge (derived from reasoning and strategies). These forms of knowledge often exist outside the data itself and are derived from personal experience, insight, or expertise. Knowledge tags are considered an expansion of the information itself that adds additional value, context, and meaning to the information. Knowledge tags are valuable for preserving organizational intelligence that is often lost due to turnover, for sharing knowledge stored in the minds of individuals that is typically isolated and unharnessed by the organization, and for connecting knowledge that is often lost or disconnected from an information resource.\n\nIn a typical tagging system, there is no explicit information about the meaning or semantics of each tag, and a user can apply new tags to an item as easily as applying older tags. Hierarchical classification systems can be slow to change, and are rooted in the culture and era that created them; in contrast, the flexibility of tagging allows users to classify their collections of items in the ways that they find useful, but the personalized variety of terms can present challenges when searching and browsing.\n\nWhen users can freely choose tags (creating a folksonomy, as opposed to selecting terms from a controlled vocabulary), the resulting metadata can include homonyms (the same tags used with different meanings) and synonyms (multiple tags for the same concept), which may lead to inappropriate connections between items and inefficient searches for information about a subject. For example, the tag \"orange\" may refer to the fruit or the color, and items related to a version of the Linux kernel may be tagged \"Linux\", \"kernel\", \"Penguin\", \"software\", or a variety of other terms. Users can also choose tags that are different inflections of words (such as singular and plural), which can contribute to navigation difficulties if the system does not include stemming of tags when searching or browsing. Larger-scale folksonomies address some of the problems of tagging, in that users of tagging systems tend to notice the current use of \"tag terms\" within these systems, and thus use existing tags in order to easily form connections to related items. In this way, folksonomies may collectively develop a partial set of tagging conventions.\n\nDespite the apparent lack of control, research has shown that a simple form of shared vocabulary emerges in social bookmarking systems. Collaborative tagging exhibits a form of complex systems dynamics (or self-organizing dynamics). Thus, even if no central controlled vocabulary constrains the actions of individual users, the distribution of tags converges over time to stable power law distributions. Once such stable distributions form, simple folksonomic vocabularies can be extracted by examining the correlations that form between different tags. In addition, research has suggested that it is easier for machine learning algorithms to learn tag semantics when users tag \"verbosely\"—when they annotate resources with a wealth of freely associated, descriptive keywords.\n\nTagging systems open to the public are also open to tag spam, in which people apply an excessive number of tags or unrelated tags to an item (such as a YouTube video) in order to attract viewers. This abuse can be mitigated using human or statistical identification of spam items. The number of tags allowed may also be limited to reduce spam.\n\nSome tagging systems provide a single text box to enter tags, so to be able to tokenize the string, a must be used. Two popular separators are the space character and the comma. To enable the use of separators in the tags, a system may allow for higher-level separators (such as quotation marks) or escape characters. Systems can avoid the use of separators by allowing only one tag to be added to each input widget at a time, although this makes adding multiple tags more time-consuming.\n\nA syntax for use within HTML is to use the rel-tag microformat which uses the \"rel\" attribute with value \"tag\" (i.e., codice_6) to indicate that the linked-to page acts as a tag for the current context.\n"}
{"id": "1007243", "url": "https://en.wikipedia.org/wiki?curid=1007243", "title": "Tertiary source", "text": "Tertiary source\n\nA tertiary source is an index or textual consolidation of primary and secondary sources. Some tertiary sources are not to be used for academic research, unless they can also be used as secondary sources, or to find other sources.\n\nDepending on the topic of research, a scholar may use a bibliography, dictionary, or encyclopedia as either a tertiary or a secondary source. This causes difficulty in defining many sources as either one type or the other.\n\nIn some academic disciplines the differentiation between a secondary and tertiary source is relative. \n\nIn the United Nations International Scientific Information System (UNISIST) model, a secondary source is a bibliography, whereas a tertiary source is a synthesis of primary sources.\n\nAs tertiary sources, encyclopedias, textbooks, and compendia attempt to summarize, collect, and consolidate the source materials into an overview, but may also present subjective, or biased commentary and analysis (which are characteristics of secondary sources).\n\nIndexes, bibliographies, concordances, and databases may not provide much textual information, but as aggregates of primary and secondary sources, they are often considered tertiary sources. So although tertiary sources are both primary and secondary, they are more towards a secondary source because of commentary and bias.\n\nAlmanacs, travel guides, field guides, and timelines are also examples of tertiary sources.\n\nSurvey or overview articles are usually tertiary, though review articles in peer-reviewed academic journals are secondary (not be confused with film, book, etc. reviews, which are primary-source opinions).\n\nSome usually primary sources, such as user guides and manuals, are secondary or tertiary (depending on the nature of the material) when written by third parties.\n\n"}
{"id": "39726999", "url": "https://en.wikipedia.org/wiki?curid=39726999", "title": "The Rough Guide to True Crime", "text": "The Rough Guide to True Crime\n\nThe Rough Guide to True Crime is a non-fiction paperback reference guide to national and international true crime cases by American crime writer Cathy Scott. It was released in the UK and US in August 2009 by Penguin Books through its Rough Guides imprint.\n\n\"The Rough Guide to True Crime\" is a compilation of a variety of cases, including historic crimes, with sections broken down by the type of offenses and who committed them. It includes black-and-white photos as illustration. Psychological profiles are included throughout by forensic expert Dr. Louis B. Schlesinger, who explains the psychology of serial killers, murderers, hit men and burglars. The book features serial killer Jeffrey Dahmer, mob hitman Richard \"The Iceman\" Kuklinski, John Wayne Glover \"The Granny Killer,\" and British \"Doctor of Death\" Harold Shipman.\n\nScott's story from \"The Rough Guide to True Crime\" about mob enforcer Herbert Blitzstein was selected for inclusion in the July 2012 retrospective of crime writing, \"Masters of True Crime: Chilling Stories of Murder and the Macabre\".\n\nThe author appeared on BlogTalkRadio's \"True Murder\" show and described some of the crimes included in the book that were committed in the 19th century as \"a different time in America, where people like Billy the Kid could walk in and just rob a bank\" and get away with it. And while \"there was nothing glamorous about what they did, they are a part of lore.\"\n\nThe book was featured at BookExpo America 2009's trade fair in DK Publishing's booth in New York City.\n\nIn a review, \"True Crime Book Reviews\" wrote, \"From the Moors murders and Harold Shipman, to the murder of 2pac, this guide illuminates the psychology in play behind the most intriguing crimes in history, from the absurd to the appalling. \"The Rough Guide to True Crime\" explores the best of the haunting genre of True Crime.\"\n\n\n"}
{"id": "30334", "url": "https://en.wikipedia.org/wiki?curid=30334", "title": "Thesaurus", "text": "Thesaurus\n\nIn general usage, a thesaurus is a reference work that lists words grouped together according to similarity of meaning (containing synonyms and sometimes antonyms), in contrast to a dictionary, which provides definitions for words, and generally lists them in alphabetical order. The main purpose of such reference works for users \"to find the word, or words, by which [an] idea may be most fitly and aptly expressed\" – to quote Peter Mark Roget, architect of the best known thesaurus in the English language.\n\nAlthough including synonyms, a thesaurus should not be taken as a complete list of all the synonyms for a particular word. The entries are also designed for drawing distinctions between similar words and assisting in choosing exactly the right word. Unlike a dictionary, a thesaurus entry does not give the definition of words.\n\nIn library science and information science, thesauri have been widely used to specify domain models. Recently, thesauri have been implemented with Simple Knowledge Organization System (SKOS).\n\nThe word \"thesaurus\" is derived from 16th-century New Latin, in turn from Latin \"thēsaurus\", which is the Latinisation of the Greek (\"thēsauros\"), \"treasure, treasury, storehouse\". The word \"thēsauros\" is of uncertain etymology. Douglas Harper derives it from the root of the Greek verb τιθέναι \"tithenai\", \"to put, to place.\" Robert Beekes rejected an Indo-European derivation and suggested a Pre-Greek suffix .\n\nFrom the 16th to the 19th centuries, the term \"thesaurus\" was applied to any dictionary or encyclopedia, as in the \"Thesaurus linguae latinae\" (1532), and the \"Thesaurus linguae graecae\" (1572). The meaning \"collection of words arranged according to sense\" is first attested in 1852 in Roget's title and \"thesaurer\" is attested in Middle English for \"treasurer\".\n\nIn antiquity, Philo of Byblos authored the first text that could now be called a thesaurus. In Sanskrit, the Amarakosha is a thesaurus in verse form, written in the 4th century. Eventhough Amarakosha mentions 18 prior works, they have all been lost.\n\nThe first modern thesaurus was \"Roget's Thesaurus\", first compiled in 1805 by Peter Mark Roget, and published in 1852. Since its publication it has never been out of print and is still a widely used work across the English-speaking world. Entries in \"Roget's Thesaurus\" are listed conceptually rather than alphabetically.\nRoget described his thesaurus in the foreword to the first edition:\n\nIt is now nearly fifty years since I first projected a system of verbal classification similar to that on which the present work is founded. Conceiving that such a compilation might help to supply my own deficiencies, I had, in the year 1805, completed a classed catalogue of words on a small scale, but on the same principle, and nearly in the same form, as the Thesaurus now published.\nThesauri have been used to perform automatic word-sense disambiguation and text simplification for machine translation systems.\n\n"}
{"id": "9032406", "url": "https://en.wikipedia.org/wiki?curid=9032406", "title": "Tupper's self-referential formula", "text": "Tupper's self-referential formula\n\nTupper's self-referential formula is a formula that visually represents itself when graphed at a specific location in the (\"x\", \"y\") plane.\n\nThe formula was defined by Jeff Tupper and appears as an example in Tupper's 2001 SIGGRAPH paper on reliable two-dimensional computer graphing algorithms.\n\nAlthough the formula is called \"self-referential\", Tupper did not name it as such.\n\nThe formula is an inequality defined as:\n\nor, as plaintext,\nwhere ⌊ ⌋ denotes the floor function, and mod is the modulo operation.\n\nLet \"k\" equal the following 543-digit integer:\n\nIf one graphs the set of points (\"x\", \"y\") in 0 ≤ \"x\" < 106 and \"k\" ≤ \"y\" < \"k\" + 17 satisfying the inequality given above, the resulting graph looks like this (the axes in this plot have been reversed, otherwise the picture would be upside-down and mirrored):\n\nThe formula is a general-purpose method of decoding a bitmap stored in the constant \"k\", and it could actually be used to draw any other image. When applied to the unbounded positive range 0 ≤ \"y\", the formula tiles a vertical swath of the plane with a pattern that contains all possible 17-pixel-tall bitmaps. One horizontal slice of that infinite bitmap depicts the drawing formula itself, but this is not remarkable, since other slices depict all other possible formulae that might fit in a 17-pixel-tall bitmap. Tupper has created extended versions of his original formula that rule out all but one slice.\n\nThe constant \"k\" is a simple monochrome bitmap image of the formula treated as a binary number and multiplied by 17. If \"k\" is divided by 17, the least significant bit encodes the upper-right corner (\"k\", 0); the 17 least significant bits encode the rightmost column of pixels; the next 17 least significant bits encode the 2nd-rightmost column, and so on.\n\n\n"}
{"id": "303405", "url": "https://en.wikipedia.org/wiki?curid=303405", "title": "Universal set", "text": "Universal set\n\nIn set theory, a universal set is a set which contains all objects, including itself. In set theory as usually formulated, the conception of a universal set leads to a paradox (Russell's paradox) and is consequently not allowed. However, some non-standard variants of set theory include a universal set.\n\nThere is no standard notation for the universal set of a given set theory. Common symbols include V, U and ξ.\n\nZermelo–Fraenkel set theory and related set theories, which are based on the idea of the cumulative hierarchy, do not allow for the existence of a universal set. It is directly contradicted by the axiom of regularity, and its existence would cause paradoxes which would make the theory inconsistent.\n\nRussell's paradox prevents the existence of a universal set in Zermelo–Fraenkel set theory and other set theories that include Zermelo's axiom of comprehension.\nThis axiom states that, for any formula formula_1 and any set , there exists another set \nthat contains exactly those elements of that satisfy formula_3. If a universal set  existed and the axiom of comprehension could be applied to it, then\nthere would also exist another set formula_4, the set of all sets that do not contain themselves. However, as Bertrand Russell observed, this set is paradoxical. If it contains itself, then it should not contain itself, and vice versa. For this reason, it cannot exist.\n\nA second difficulty with the idea of a universal set concerns the power set of the set of all sets. Because this power set is a set of sets, it would necessarily be a subset of the set of all sets, provided that both exist. However, this conflicts with Cantor's theorem that the power set of any set (whether infinite or not) always has strictly higher cardinality than the set itself.\n\nThe difficulties associated with a universal set can be avoided either by using a variant of set theory in which the axiom of comprehension is restricted in some way, or by using a universal object that is not considered to be a set.\n\nThere are set theories known to be consistent (if the usual set theory is consistent) in which the universal set does exist (and formula_5 is true). In these theories, Zermelo's axiom of comprehension does not hold in general, and the axiom of comprehension of naive set theory is restricted in a different way. A set theory containing a universal set is necessarily a non-well-founded set theory.\nThe most widely studied set theory with a universal set is Willard Van Orman Quine's New Foundations. Alonzo Church and also published work on such set theories. Church speculated that his theory might be extended in a manner consistent with Quine's,\n\nAnother example is positive set theory, where the axiom of comprehension is restricted to hold only for the positive formulas (formulas that do not contain negations). Such set theories are motivated by notions of closure in topology.\n\nThe idea of a universal set seems intuitively desirable in the Zermelo–Fraenkel set theory, particularly because most versions of this theory do allow the use of quantifiers over all sets (see universal quantifier). One way of allowing an object that behaves similarly to a universal set, without creating paradoxes, is to describe and similar large collections as proper classes rather than as sets. One difference between a universal set and a universal class is that the universal class does not contain itself, because proper classes cannot be elements of other classes. Russell's paradox does not apply in these theories because the axiom of comprehension operates on sets, not on classes.\n\nThe category of sets can also be considered to be a universal object that is, again, not itself a set. It has all sets as elements, and also includes arrows for all functions from one set to another. \nAgain, it does not contain itself, because it is not itself a set.\n\n\n"}
