{"id": "1171", "url": "https://en.wikipedia.org/wiki?curid=1171", "title": "Abbreviation", "text": "Abbreviation\n\nAn abbreviation (from Latin \"brevis\", meaning \"short\" ) is a shortened form of a word or phrase. It consists of a group of letters taken from the word or phrase. For example, the word \"abbreviation\" can itself be represented by the abbreviation \"abbr.\", \"abbrv.\", or \"abbrev.\"\n\nIn strict analysis, abbreviations should not be confused with contractions, crasis, acronyms, or initialisms, with which they share some semantic and phonetic functions, though all four are connected by the term \"abbreviation\" in loose parlance.An abbreviation is a shortening by any method; a contraction is a reduction of size by the drawing together of the parts. A contraction of a word is made by omitting certain letters or syllables and bringing together the first and last letters or elements; an abbreviation may be made by omitting certain portions from the interior or by cutting off a part. A contraction is an abbreviation, but an abbreviation is not necessarily a contraction. Acronyms and initialisms are regarded as subsets of abbreviations (e.g. by the Council of Science Editors). They are abbreviations that consist of the initial letters or parts of words.\n\nAbbreviations have a long history, created so that spelling out a whole word could be avoided. This might be done to save time and space, and also to provide secrecy. Shortened words were used and initial letters were commonly used to represent words in specific applications. In classical Greece and Rome, the reduction of words to single letters was common. In Roman inscriptions, \"Words were commonly abbreviated by using the initial letter or letters of words, and most inscriptions have at least one abbreviation.\" However, \"some could have more than one meaning, depending on their context. (For example, \"A\" can be an abbreviation for many words, such as \"ager\", \"amicus\", \"annus\", \"as\", \"Aulus\", \"Aurelius\", \"aurum\" and \"avus\".)\"\n\nAbbreviations in English were frequently used from its earliest days. Manuscripts of copies of the old English poem \"Beowulf\" used many abbreviations, for example \"7\" or \"&\" for \"and\", and \"y\" for \"since\", so that \"not much space is wasted\". The standardisation of English in the 15th through 17th centuries included such a growth in the use of abbreviations. At first, abbreviations were sometimes represented with various suspension signs, not only periods. For example, sequences like ‹er› were replaced with ‹ɔ›, as in ‹mastɔ› for \"master\" and ‹exacɔbate› for \"exacerbate\". While this may seem trivial, it was symptomatic of an attempt by people manually reproducing academic texts to reduce the copy time. An example from the Oxford University Register, 1503:\n\nThe Early Modern English period, between the 15th and 17th centuries, had abbreviations like \"y\" for \"Þ\", used for the word \"the\": \"hence, by later misunderstanding, Ye Olde Tea Shoppe.\"\n\nDuring the growth of philological linguistic theory in academic Britain, abbreviating became very fashionable. The use of abbreviation for the names of J. R. R. Tolkien and his friend C. S. Lewis, and other members of the Oxford literary group known as the Inklings, are sometimes cited as symptomatic of this. Likewise, a century earlier in Boston, a fad of abbreviation started that swept the United States, with the globally popular term OK generally credited as a remnant of its influence.\n\nAfter World War II, the British greatly reduced the use of the full stop and other punctuation points after abbreviations in at least semi-formal writing, while the Americans more readily kept such use until more recently, and still maintain it more than Britons. The classic example, considered by their American counterparts quite curious, was the maintenance of the internal comma in a British organisation of secret agents called the \"Special Operations, Executive\"—\"S.O., E\"—which is not found in histories written after about 1960.\n\nBut before that, many Britons were more scrupulous at maintaining the French form. In French, the period only follows an abbreviation if the last letter in the abbreviation is \"not\" the last letter of its antecedent: \"M.\" is the abbreviation for \"monsieur\" while \"Mme\" is that for \"madame\". Like many other cross-channel linguistic acquisitions, many Britons readily took this up and followed this rule themselves, while the Americans took a simpler rule and applied it rigorously.\n\nOver the years, however, the lack of convention in some style guides has made it difficult to determine which two-word abbreviations should be abbreviated with periods and which should not. The U.S. media tend to use periods in two-word abbreviations like United States (U.S.), but not personal computer (PC) or television (TV). Many British publications have gradually done away with the use of periods in abbreviations.\n\nMinimization of punctuation in typewritten material became economically desirable in the 1960s and 1970s for the many users of carbon-film ribbons since a period or comma consumed the same length of non-reusable expensive ribbon as did a capital letter.\n\nWidespread use of electronic communication through mobile phones and the Internet during the 1990s allowed for a marked rise in colloquial abbreviation. This was due largely to increasing popularity of textual communication services such as instant- and text messaging. SMS, for instance, supports message lengths of 160 characters at most (using the GSM 03.38 character set). This brevity gave rise to an informal abbreviation scheme sometimes called Textese, with which 10% or more of the words in a typical SMS message are abbreviated. More recently Twitter, a popular social networking service, began driving abbreviation use with 140 character message limits.\n\nIn modern English, there are several conventions for abbreviations, and the choice may be confusing. The only rule universally accepted is that one should be \"consistent\", and to make this easier, publishers express their preferences in a style guide. Questions which arise include those in the following subsections.\n\nIf the original word was capitalized then the first letter of its abbreviation should retain the capital, for example Lev. for \"Leviticus\". When a word is abbreviated to more than a single letter and was originally spelled with lower case letters then there is no need for capitalization. However, when abbreviating a phrase where only the first letter of each word is taken, then all letters should be capitalized, as in YTD for \"year-to-date\", PCB for \"printed circuit board\" and FYI for \"for your information\". However, see the following section regarding abbreviations that have become common vocabulary: these are no longer written with capital letters.\n\nA period (full stop) is often used to signify an abbreviation, but opinion is divided as to when and if this should happen.\n\nAccording to Hart's Rules, the traditional rule is that abbreviations (in the narrow sense that includes only words with the ending, and not the middle, dropped) terminate with a full stop, whereas contractions (in the sense of words missing a middle part) do not, but there are exceptions. Fowler's Modern English Usage says full stops are used to mark both abbreviations and contractions, but recommends against this practice: advising them only for abbreviations and lower-case initialisms and not for upper-case initialisms and contractions.\n\nIn American English, the period is usually included regardless of whether or not it is a contraction, e.g. \"Dr.\" or \"Mrs.\". In some cases, periods are optional, as in either \"US\" or \"U.S.\" for \"United States\", \"EU\" or \"E.U.\" for \"European Union\", and \"UN\" or \"U.N.\" for \"United Nations\". There are some house styles, however—American ones included—that remove the periods from almost all abbreviations. For example:\n\nAcronyms that were originally capitalized (with or without periods) but have since entered the vocabulary as generic words are no longer written with capital letters nor with any periods. Examples are sonar, radar, lidar, laser, snafu, and scuba.\n\nToday, spaces are generally not used between single-letter abbreviations of words in the same phrase, so one almost never encounters \"U. S.\"\n\nWhen an abbreviation appears at the end of a sentence, only one period is used: \"The capital of the United States is Washington, D.C\".\n\nThere is a question about how to pluralize abbreviations, particularly acronyms. Often a writer will add an 's' following an apostrophe, as in \"PC's\". However, this style is not preferred by many style guides. For instance, Kate Turabian, writing about style in academic writings, allows for an apostrophe to form plural acronyms \"only when an abbreviation contains internal periods or both capital and lowercase letters\". Turabian would therefore prefer \"DVDs\" and \"URLs\" and \"Ph.D.'s\", while the Modern Language Association explicitly says, \"do not use an apostrophe to form the plural of an abbreviation\". Also, the American Psychological Association specifically says, \"without an apostrophe\".\n\nHowever, the 1999 style guide for \"The New York Times\" states that the addition of an apostrophe is necessary when pluralizing all abbreviations, preferring \"PC's, TV's and VCR's\".\n\nFollowing those who would generally omit the apostrophe, to form the plural of run batted in, simply add an s to the end of RBI.\n\n\nFor all other rules, see below:\n\nTo form the plural of an abbreviation, a number, or a capital letter used as a noun, simply add a lowercase \"s\" to the end. Apostrophes following decades and single letters are also common.\n\nTo indicate the plural of the abbreviation or symbol of a unit of measure, the same form is used as in the singular.\n\nWhen an abbreviation contains more than one full point, \"Hart's Rules\" recommends putting the \"s\" after the final one.\nHowever, subject to any house style or consistency requirement, the same plurals may be rendered less formally as:\n\nAccording to \"Hart's Rules\", an apostrophe may be used in rare cases where clarity calls for it, for example when letters or symbols are referred to as objects.\nHowever, the apostrophe can be dispensed with if the items are set in italics or quotes:\n\nIn Latin, and continuing to the derivative forms in European languages as well as English, single-letter abbreviations had the plural being a doubling of the letter for note-taking. Most of these deal with writing and publishing. A few longer abbreviations use this as well.\n\nPublications based in the U.S. tend to follow the style guides of \"The Chicago Manual of Style\" and the Associated Press. The U.S. Government follows a style guide published by the U.S. Government Printing Office. The National Institute of Standards and Technology sets the style for abbreviations of units.\n\nMany British publications follow some of these guidelines in abbreviation:\n\n\nWriters often use shorthand to denote units of measure. Such shorthand can be an abbreviation, such as \"in\" for \"inch\" or can be a symbol such as \"km\" for \"kilometre/kilometer\".\n\nThe shorthand \"in\" applies to English only—in Afrikaans for example, the shorthand \"dm\" is used for the equivalent Afrikaans word \"duim\". Since both \"in\" and \"dm\" are contractions of the same word, but in different languages, they are abbreviations. A symbol on the other hand, defined as \"Mark or character taken as the conventional sign of some object or idea or process\" applies the appropriate shorthand by \"substitution\" rather than by \"contraction\". Since the shorthand for kilometre/kilometer (\"\" in Portuguese or \"\" in Greek) is \"km\" in both languages and the letter \"k\" does not appear in the expansion of either translation, \"km\" is a symbol as it is a substitution rather than a contraction. It is a logogram rather than an abbreviation.\n\nIn the International System of Units (SI) manual the word \"symbol\" is used consistently to define the shorthand used to represent the various SI units of measure. The manual also defines the way in which units should be written, the principal rules being:\n\nA syllabic abbreviation is usually formed from the initial syllables of several words, such as \"Interpol\" = International\" + police\". It is a variant of the acronym. Syllabic abbreviations are usually written using lower case, sometimes starting with a capital letter, and are always pronounced as words rather than letter by letter. Syllabic abbreviations should be distinguished from portmanteaus, which combine two words without necessarily taking whole syllables from each.\n\nSyllabic abbreviations are not widely used in English. Some UK government ministries such as Ofcom (Office of Communications\") and Oftel (Office of Telecommunications\") use this style.\n\nNew York City has various neighborhoods named by syllabic abbreviation, such as Tribeca (Triangle below Canal Street\") and SoHo (South of Houston Street\"). This usage has spread into other American cities, giving SoMa, San Francisco (South of Market\") and LoDo, Denver (Lower Downtown\"), among others.\n\nOn the other hand, syllabic abbreviations prevailed both in Germany under the Nazis and in the Soviet Union for naming the plethora of new bureaucratic organisations. For example, \"Gestapo\" stands for Geheime Staats-Polizei\", or \"secret state police\". Similarly, Leninist organisations such as the \"Comintern\" (\"Communist International\") and \"Komsomol\" (Kommunisticheskii Soyuz Molodyozhi\", or \"Communist youth union\") used Russian language syllabic abbreviations. This has given syllabic abbreviations negative connotations in some countries, (as in Orwell's Newspeak), notwithstanding that such abbreviations were used in Germany even before the Nazis came to power, e.g., \"\" for \"Schutzpolizei\", and are still used, e.g. \"\" for \"\".\n\nIn the modern Russian language words like \"Minoborony\" (from Ministerstvo oborony — Ministry of Defence) and \"Minobrnauki\" (from Ministerstvo obrazovaniya i nauki — Ministry of Education and Science) are still commonly used.\n\nSyllabic abbreviations were also typical for the German language used in the German Democratic Republic, e.g. \"Stasi\" for Staatssicherheit\" (\"state security\", the secret police) or \"Vopo\" for \"Volkspolizist\" (\"people's policeman\"). Other uses are in company or product names such as Aldi, from the name of the founder, Theo Albrecht, and the German word Diskont\" (discount) or Haribo, from the name of the founder and the headquarters of the company, Hans Riegl Bonn.\n\nSyllabic abbreviations are \"de rigueur\" in Spanish; examples abound in organization names such as Pemex for Petróleos Mexicanos\" (\"Mexican Petroleums\") or Fonafifo for Fondo Nacional de Financimiento Forestal\" (National Forestry Financing Fund).\n\nEast Asian languages whose writing systems use Chinese characters form abbreviations similarly by using key Chinese characters from a term or phrase. For example, in Japanese the term for the United Nations, \"kokusai rengō\" (国際連合) is often abbreviated to \"kokuren\" (国連). (Such abbreviations are called (略語) in Japanese; see also Japanese abbreviated and contracted words). The syllabic abbreviation is frequently used for universities: for instance, \"Běidà\" (北大) for \"Běijīng Dàxué\" (北京大学, Peking University) and \"Tōdai\" (東大) for \"Tōkyō daigaku\" (東京大学, University of Tokyo). The English phrase \"Gung ho\" originated as a Chinese abbreviation.\n\nPartially syllabic abbreviations are preferred by the US Navy, as it increases readability amidst the large number of initialisms that would otherwise have to fit into the same acronyms. Hence \"DESRON 6\" is used (in the full capital form) to mean \"Destroyer Squadron 6\", while \"COMNAVAIRLANT\" would be \"Commander, Naval Air Force (in the) Atlantic.\"\n\n"}
{"id": "26334944", "url": "https://en.wikipedia.org/wiki?curid=26334944", "title": "Auxiliary sciences of history", "text": "Auxiliary sciences of history\n\nAuxiliary (or ancillary) sciences of history are scholarly disciplines which help evaluate and use historical sources and are seen as auxiliary for historical research. Many of these areas of study, classification and analysis were originally developed between the 16th and 19th centuries by antiquaries, and would then have been regarded as falling under the broad heading of antiquarianism. \"History\" was at that time regarded as a largely literary skill. However, with the spread of the principles of empirical source-based history championed by the Göttingen School of History in the late 18th century and later by Leopold von Ranke from the mid-19th century onwards, they have been increasingly regarded as falling within the skill-set of the trained historian.\n\nAuxiliary sciences of history include, but are not limited to:\n\n"}
{"id": "398493", "url": "https://en.wikipedia.org/wiki?curid=398493", "title": "BRD (Germany)", "text": "BRD (Germany)\n\nBRD (; English: Federal Republic of Germany); () is an unofficial abbreviation commonly used between 1968 and 1990 by the communist regime of the German Democratic Republic (East Germany) to refer to the Federal Republic of Germany, informally known at the time as West Germany. The East German regime previously used the term \"German Federal Republic\" to refer to its western counterpart.\n\nUnlike the English equivalent FRG, which was used as an IOC country code and a FIFA trigramme, the use of \"BRD\" was strongly discouraged by the authorities of the Federal Republic of Germany itself, because it was considered to be a derogatory communist term. The term was not banned by law, but its use was discouraged or forbidden in schools in Western Germany. After German reunification, the country is usually referred to simply as Germany (\"\"), and hence the need for abbreviations is greatly diminished. The most widely used abbreviation for West Germany was its ISO 3166-1 alpha-2 country code \"DE\", which has remained the country code of reunified Germany.\n\nThe official name was and is \"Bundesrepublik Deutschland\" (\"Federal Republic of Germany\"). The name, even though in the beginning referring only to the republic established in the Trizone, was to reflect a name for all of Germany, therefore it was particularly to include the term \"Deutschland\" (\"Germany\"). This corresponded to the spirit of the then West German constitution, the Basic Law, allowing all states or \"Länder\", then under Allied control, to join the new Federal Republic. In 1949 the original eleven states in the Trizone and West Berlin did so. However the latter was prevented by Allied objection on account of the city being a quadripartite allied occupation area. The Saarland joined with effect from 1 January 1957, while the \"new states\" of the East did so with effect from 3 October 1990, including reunited Berlin.\n\nTherefore, the term Germany had an importance as part of the official name, which is reflected in the naming conventions which developed in the Cold War. Starting in June 1949 the abbreviation was sometimes used in the Federal Republic of Germany without any special connotations. The initialism \"BRD\" began to enter into such regular usage in West German scientific and ministerial circles, that it was added to the western edition of the German language dictionary Duden in 1967. The German Democratic Republic at first used the name \"Westdeutschland\" or \"West Germany\" (abbreviated \"WD\") for the Federal Republic of Germany, but since the 1950s the East German government insisted on calling West Germany \"Deutsche Bundesrepublik\" or \"German Federal Republic\" (abbreviated \"DBR\"), because they also considered East Germany part of Germany, and thus would not permit the West German government to use the name \"Germany\".\n\nThis changed in 1968 with the new constitution of the German Democratic Republic. The communists no longer strove for German reunification, and the name \"BRD\" was introduced as a propaganda counter-term to the term \"DDR\", trying to express the equality of the states. Conversely, the West would speak of the \"sogenannte DDR\" or \"so-called 'DDR'\" when it had to be belittled.\n\nAt that time, the initialism \"BRD\" had been adopted by \"Neues Deutschland\", the ruling Socialist Unity Party's daily newspaper, while East German official sources adopted that initialism as standard in 1973.\n\nThe East German decision to abandon the idea of a single German nation was accompanied by omitting the terms \"Deutschland\" (\"Germany\") and \"deutsch\" (\"German\") in a number of terms, for example:\n\n\nHowever, the ruling party's full name, \"Sozialistische Einheitspartei Deutschlands\" or \"Socialist Unity Party of Germany\" remained unchanged, as did that of its newspaper \"Neues Deutschland\" (\"New Germany\") .\nTherefore, using the abbreviation \"BRD\" fitted perfectly into the official East German policy of downplaying the concept of a united Germany. In 1974, the GDR had replaced the vehicle registration code \"D\", hitherto shared with the Federal Republic, for \"DDR\" and demanded that West Germany recognise the division by likewise accepting \"BRD\". \nThis was rejected by the West, where some motorists displayed bumper stickers with the slogan \"BRD - Nein Danke!\" (\"BRD? No Thanks!\"). Thus in the West the initialism became even more objectionable and using it was often considered either unreflecting or even expressing naïve Communist sympathies.\nAs a result, the initialism reached only occasional frequency in West German parlance. In order to be precise West Germans increasingly used the terms \"Bundesrepublik\" or \"Bundesgebiet\" (\"Federal Republic\", or \"Federal Territory\") to refer to the country and \"Bundesbürger\" (\"Federal Citizen[s]\") as to its citizens, with the pertaining adjective \"bundesdeutsch\" (federally German).\n\nTo distance themselves from the term \"BRD\", until German reunification, the government of the Federal Republic of Germany and media sometimes used the abbreviations \"BR Deutschland,\" \"BR-Dt.\", \"BRDt.\",\nWest Germany had always claimed to be \"the\" Germany, and did not like the comparison to \"DDR\", or two separate German states. This claim was also reflected in the Hallstein Doctrine determining its foreign and interior policy until the early 1970s. Named after Walter Hallstein, State secretary at the Foreign Office, this was a key doctrine in the foreign policy of West Germany after 1955, which prescribed that the Federal Republic of Germany would not establish or maintain diplomatic relations with any state that recognised the GDR. Although this changed after 1973, with the Federal Republic no longer asserting an exclusive mandate over the whole of Germany, West Germany only established \"de facto\" diplomatic relations with East Germany. Under the terms of the Basic Treaty in 1972, Bonn and East Berlin exchanged \"permanent missions\", headed by \"permanent representatives\", rather than \"de jure\" embassies headed by ambassadors. Similarly, relations with the GDR were not conducted through the Foreign Office, but through a separate Federal Ministry for Intra-German Relations, to which the East German mission was accredited.\n\nIn 1965 the Federal Minister of All-German Affairs (later Intra-German Relations) issued the \"Directives for the appellation of Germany\" recommending that the use of \"BRD\" be avoided. On 31 May 1974 the heads of the federal and state governments recommended that the full name should always be used in official publications. In November 1979 the federal government informed the Bundestag that the West German public broadcasters ARD and ZDF agreed not to use the initialism.\n\nUnder the West German federal system, the states were generally responsible for school education, and by the 1970s, some of them had either already recommended omitting the initialism, or, in the case of Bavaria, forbidden it. Similarly, a decree by the educational authorities in the state of Schleswig-Holstein of 4 October 1976 declared the term to be \"nicht wünschenswert\" or \"undesirable\". The conference of all the states ministers for school education decided on 12 February 1981 to not print the initialism in books, maps, and atlases for schools. with pupils being required to write \"Bundesrepublik Deutschland\" in full and use of the term being deemed an error. The different usages were so ingrained that one could deduce a person's or source's political leaning from the name used for West Germany, with far-left movements in the country using \"BRD\".\n\nHowever, as the Association for the German Language found, this debate on the initialism had little influence on changing the West German parlance with the usage of the initialism - in any event limited - unaffected by the debate.\n\nA similar ideological question was the question whether to use \"Berlin (West)\" (the officially preferred name) or \"West Berlin\", and even whether to write \"West Berlin\" in German as two hyphenated words - \"West-Berlin\" - or as one word - \"Westberlin\".\n\nMost Westerners called the Western sectors \"Berlin\", unless further distinction was necessary. The West German Federal government initially called West Berlin \"Groß-Berlin\" or \"Greater Berlin\", but changed this \"Berlin (West)\", although it also used the hyphenated \"West-Berlin\". However, the East German government commonly referred to it as \"Westberlin\". Starting from 31 May 1961, East Berlin was officially called \"Berlin, Hauptstadt der DDR\" (Berlin, Capital of the GDR), replacing the formerly used term \"Democratic Berlin\", or simply \"Berlin\", by East Germany, and \"Berlin (Ost)\" by the West German Federal government. Other names used by West German media included \"Ost-Berlin\" and \"Ostberlin\" (both meaning \"East Berlin\") as well as \"Ostsektor\" or \"Eastern Sector\". These different naming conventions for the divided parts of Berlin, when followed by individuals, governments, or media, commonly indicated their political leanings, with the centre-right \"Frankfurter Allgemeine Zeitung\" using \"Ost-Berlin\" and the centre-left \"Süddeutsche Zeitung\" using \"Ostberlin\".\n\nThe naming of the German Democratic Republic was also a controversial issue, West Germans at first preferring the names \"Mitteldeutschland\" (\"Middle Germany\") and \"Sowjetische Besatzungszone\" (Soviet Occupation Zone) abbreviated as \"SBZ\". This only changed under Willy Brandt when West German authorities started using the official name, \"Deutsche Demokratische Republik\" or \"DDR\", but many conservative German newspapers, like \"Bild\", owned by the Springer company, always wrote \"DDR\" in scare quotes until 1 August 1989.\n\nIn 1995, a disagreement arose between reunified Germany and newly independent Slovakia, as Germany objected to the use of the Slovak language name \"Nemecká spolková republika\" (literally \"German Federal Republic\") owing to its Cold War connotations, instead of \"Spolková republika Nemecko\". This was almost identical to the equivalent \"Spolková republika Německo\" in Czech, a language closely related to Slovak, but the Slovak authorities claimed that \"Federal Republic of Germany\" could not be translated grammatically into Slovak. However, the Slovak government had used it until the previous year, leading to suggestions in the Bratislava newspaper \"Narodna Obroda\" that they were using \"German Federal Republic\" to show their displeasure with German attitudes to the country.\n"}
{"id": "1047161", "url": "https://en.wikipedia.org/wiki?curid=1047161", "title": "Chapters and verses of the Bible", "text": "Chapters and verses of the Bible\n\nThe Bible is a compilation of many shorter books written at different times by a variety of authors, and later assembled into the biblical canon. Since the early 13th century, most copies and editions of the Bible present all but the shortest of these books with divisions into chapters, generally a page or so in length. Since the mid-16th century editors have further subdivided each chapter into verses - each consisting of a few short lines or sentences. Sometimes a sentence spans more than one verse, as in the case of , and sometimes there is more than one sentence in a single verse, as in the case of .\n\nAs the chapter and verse divisions did not appear in the original texts, they form part of the paratext of the Bible.\n\nThe Jewish divisions of the Hebrew text differ at various points from those used by Christians. For instance, in Jewish tradition, the ascriptions to many Psalms are regarded as independent verses or parts of the subsequent verses, making 116 more verses, whereas established Christian practice treats each Psalm ascription as independent and unnumbered. Some chapter divisions also occur in different places, e.g. Hebrew Bibles have where Christian translations have .\n\nEarly manuscripts of the biblical texts did not contain the chapter and verse divisions in the numbered form familiar to modern readers. In antiquity Hebrew texts were divided into paragraphs (parashot) that were identified by two letters of the Hebrew alphabet. Peh פ indicated an \"open\" paragraph that began on a new line, while Samekh ס indicated a \"closed\" paragraph that began on the same line after a small space. These two letters begin the Hebrew words open (patuach\") and closed (sagoor\"), and are, themselves, open פ and closed ס. The earliest known copies of the Book of Isaiah from the Dead Sea Scrolls used parashot divisions, although they differ slightly from the Masoretic divisions. (This is different from the use of consecutive letters of the Hebrew alphabet to structure certain poetic compositions, known as acrostics, such as several of the Psalms and most of the Book of Lamentations.)\n\nThe Hebrew Bible was also divided into some larger sections. In Israel the Torah (its first five books) were divided into 154 sections so that they could be read through aloud in weekly worship over the course of three years. In Babylonia it was divided into 53 or 54 sections (Parashat ha-Shavua) so it could be read through in one year. The New Testament was divided into topical sections known as \"kephalaia\" by the fourth century. Eusebius of Caesarea divided the gospels into parts that he listed in tables or \"canons\". Neither of these systems corresponds with modern chapter divisions. (See fuller discussions below.)\n\nChapter divisions, with titles, are also found in the 9th century Tours manuscript, Paris Bibliothèque Nationale MS Lat. 3, the so-called Bible of Rorigo.\n\nArchbishop Stephen Langton and Cardinal Hugo de Sancto Caro developed different schemas for systematic division of the Bible in the early 13th century. It is the system of Archbishop Langton on which the modern chapter divisions are based.\n\nWhile chapter divisions have become nearly universal, editions of the Bible have sometimes been published without them. Such editions, which typically use thematic or literary criteria to divide the biblical books instead, include John Locke's \"Paraphrase and Notes on the Epistles of St. Paul\" (1707), Alexander Campbell's \"The Sacred Writings\" (1826), Daniel Berkeley Updike’s fourteen-volume \"The Holy Bible Containing the Old and New Testaments and the Apocrypha,\" Richard Moulton's \"The Modern Reader's Bible\" (1907), Ernest Sutherland Bates's \"The Bible Designed to Be Read as Living Literature\" (1936), \"The Books of the Bible\" (2007) from the International Bible Society (Biblica), Adam Lewis Greene’s five-volume \"Bibliotheca\" (2014), and the six-volume ESV Reader's Bible (2016) from Crossway Books.\n\nSince at least 916 the Tanakh has contained an extensive system of multiple levels of section, paragraph, and phrasal divisions that were indicated in Masoretic vocalization and cantillation markings. One of the most frequent of these was a special type of punctuation, the \"sof passuq\", symbol for a full stop or sentence break, resembling the colon (:) of English and Latin orthography. With the advent of the printing press and the translation of the Bible into English, Old Testament versifications were made that correspond predominantly with the existing Hebrew full stops, with a few isolated exceptions. Most attribute these to Rabbi Isaac Nathan ben Kalonymus's work for the first Hebrew Bible concordance around 1440.\n\nThe first person to divide New Testament chapters into verses was Italian Dominican biblical scholar Santi Pagnini (1470–1541), but his system was never widely adopted. His verse divisions in the New Testament were far longer than those known today. Robert Estienne created an alternate numbering in his 1551 edition of the Greek New Testament which was also used in his 1553 publication of the Bible in French. Estienne's system of division was widely adopted, and it is this system which is found in almost all modern Bibles. Estienne produced a 1555 Vulgate that is the first Bible to include the verse numbers integrated into the text. Before this work, they were printed in the margins.\n\nThe first English New Testament to use the verse divisions was a 1557 translation by William Whittingham (c. 1524–1579). The first Bible in English to use both chapters and verses was the Geneva Bible published shortly afterwards in 1560. These verse divisions soon gained acceptance as a standard way to notate verses, and have since been used in nearly all English Bibles and the vast majority of those in other languages. (Nevertheless, some Bibles have removed the verse numbering, including the ones noted above that also removed chapter numbers; a recent example of an edition that removed only verses, not chapters, is \"The Message: The Bible in Contemporary Language\" by Eugene H. Peterson.)\n\nThe Hebrew Masoretic text of the Bible notes several different kinds of subdivisions within the biblical books:\n\nMost important are the verse endings. According to the Talmudic tradition, the division of the text into verses is of ancient origin. In Masoretic versions of the Bible, the end of a verse is indicated by a small mark in its final word called a \"silluq\" (which means \"stop\"). Less formally, verse endings are usually also indicated by two horizontal dots following the word with a \"silluq\".\n\nThe Masoretic textual tradition also contains section endings called \"parashot\", which are usually indicated by a space within a line (a \"closed\" section) or a new line beginning (an \"open\" section). The division of the text reflected in the \"parashot\" is usually thematic. Unlike chapters, the \"parashot\" are not numbered, but some of them have special titles.\n\nIn early manuscripts (most importantly in Tiberian Masoretic manuscripts, such as the Aleppo codex), an \"open\" section may also be represented by a blank line, and a \"closed\" section by a new line that is slightly indented (the preceding line may also not be full). These latter conventions are no longer used in Torah scrolls and printed Hebrew Bibles. In this system, the one rule differentiating \"open\" and \"closed\" sections is that \"open\" sections must \"always\" start at the beginning of a new line, while \"closed\" sections \"never\" start at the beginning of a new line.\n\nAnother division of the biblical books found in the Masoretic text is the division of the \"sedarim\". This division is not thematic, but is almost entirely based upon the \"quantity\" of text. For the Torah, this division reflects the triennial cycle of reading that was practiced by the Jews of the Land of Israel.\n\nThe Byzantines also introduced a concept roughly similar to chapter divisions, called \"kephalaia\" (singular \"kephalaion\", literally meaning \"heading\"). This system, which was in place no later than the 5th century, is not identical to the present chapters. Unlike the modern chapters, which tend to be of roughly similar length, the distance from one \"kephalaion\" mark to the next varied greatly in length both within a book and from one book to the next. For example, the Sermon on the Mount, comprising three chapters in the modern system, has but one \"kephalaion\" mark, while the single modern chapter 8 of the Gospel of Matthew has several, one per miracle. Moreover, there were far fewer \"kephalaia\" in the Gospel of John than in the Gospel of Mark, even though the latter is the shorter text. In the manuscripts, the \"kephalaia\" with their numbers, their standard titles (\"titloi\") and their page numbers would be listed at the beginning of each biblical book; in the book's main body, they would be marked only with arrow-shaped or asterisk-like symbols in the margin, not in the text itself.\n\nThe titles usually referred to the first event or the first theological point of the section only, and some \"kephalaia\" are manifestly incomplete if one stops reading at the point where the next \"kephalaion\" begins (for example, the combined accounts of the miracles of the Daughter of Jairus and of the healing of the woman with a haemorrhage gets two marked \"kephalaia\", one titled \"of the daughter of the synagogue ruler\" at the beginning when the ruler approaches Jesus and one titled \"of the woman with the flow of blood\" where the woman enters the picture – well before the ruler's daughter is healed and the storyline of the previous \"kephalaion\" is thus properly concluded). Thus the \"kephalaia\" marks are rather more like a system of bookmarks or links into a continuous text, helping a reader to quickly find one of several well-known episodes, than like a true system of chapter divisions.\n\nCardinal Hugo de Sancto Caro is often given credit for first dividing the Latin Vulgate into chapters in the real sense, but it is the arrangement of his contemporary and fellow cardinal Stephen Langton who in 1205 created the chapter divisions which are used today. They were then inserted into Greek manuscripts of the New Testament in the 16th century. Robert Estienne (Robert Stephanus) was the first to number the verses within each chapter, his verse numbers entering printed editions in 1551 (New Testament) and 1571 (Hebrew Bible).\n\nThe division of the Bible into chapters and verses has received criticism from some traditionalists and modern scholars. Critics state that the text is often divided in an incoherent way, or at inappropriate rhetorical points, and that it encourages citing passages out of context. Nevertheless, the chapter and verse numbers have become indispensable as technical references for Bible study.\n\nSeveral modern publications of the Bible have eliminated numbering of chapters and verses. Biblica published such a version of the NIV in 2007 and 2011. In 2014, Crossway published the ESV Reader's Bible and \"Bibliotheca\" published a modified ASV. Projects such as Icthus also exist which strip chapter and verse numbers from existing translations.\n\nThe number of words can vary depending upon aspects such as whether the Hebrew alphabet in Psalm 119, the superscriptions listed in some of the Psalms, and the subscripts traditionally found at the end of the Pauline epistles, are included.\nExcept where stated, the following apply to the King James Version of the Bible in its modern 66-book Protestant form including the New Testament and the protocanonical Old Testament, not the deuterocanonical books.\n\n\n\n\n\n"}
{"id": "97585", "url": "https://en.wikipedia.org/wiki?curid=97585", "title": "Citation", "text": "Citation\n\nA citation is a reference to a published or unpublished source. More precisely, a citation is an abbreviated alphanumeric expression embedded in the body of an intellectual work that denotes an entry in the bibliographic references section of the work for the purpose of acknowledging the relevance of the works of others to the topic of discussion at the spot where the citation appears. Generally the combination of both the in-body citation and the bibliographic entry constitutes what is commonly thought of as a citation (whereas bibliographic entries by themselves are not). References to single, machine-readable assertions in electronic scientific articles are known as nanopublications, a form of microattribution.\n\nCitations have several important purposes: to uphold intellectual honesty (or avoiding plagiarism), to attribute prior or unoriginal work and ideas to the correct sources, to allow the reader to determine independently whether the referenced material supports the author's argument in the claimed way, and to help the reader gauge the strength and validity of the material the author has used. As Roark and Emerson have argued, citations relate to the way authors perceive the substance of their work, their position in the academic system, and the moral equivalency of their place, substance, and words. Despite these attributes, many drawbacks and shortcoming of citation practices have been reported, including for example honorary citations, circumstantial citations, discriminatory citations, selective and arbitrary citations.\n\nThe forms of citations generally subscribe to one of the generally accepted citations systems, such as the Oxford, Harvard, MLA, American Sociological Association (ASA), American Psychological Association (APA), and other citations systems, because their syntactic conventions are widely known and easily interpreted by readers. Each of these citation systems has its advantages and disadvantages. Editors often specify the citation system to use.\n\nBibliographies, and other list-like compilations of references, are generally not considered citations because they do not fulfill the true spirit of the term: deliberate acknowledgement by other authors of the priority of one's ideas.\n\nA bibliographic citation is a reference to a book, article, web page, or other published item. Citations should supply detail to identify the item uniquely. Different citation systems and styles are used in scientific citation, legal citation, prior art, the arts, and the humanities.\n\nCitation content can vary depending on the type of source and may include:\n\nAlong with information such as author(s), date of publication, title and page numbers, citations may also include unique identifiers depending on the type of work being referred to.\n\nBroadly speaking, there are two types of citation systems, the Vancouver system and parenthetical referencing. However, the Council of Science Editors (CSE) adds a third, the\" citation-name system\".\n\nThe Vancouver system uses sequential numbers in the text, either bracketed or superscript or both. The numbers refer to either footnotes (notes at the end of the page) or endnotes (notes on a page at the end of the paper) that provide source detail. The notes system may or may not require a full bibliography, depending on whether the writer has used a full-note form or a shortened-note form.\n\nFor example, an excerpt from the text of a paper using a notes system \"without\" a full bibliography could look like:\n\nThe note, located either at the foot of the page (footnote) or at the end of the paper (endnote) would look like this:\n\nIn a paper with a full bibliography, the shortened note might look like:\n\nThe bibliography entry, which is required with a shortened note, would look like this:\n\nIn the humanities, many authors also use footnotes or endnotes to supply anecdotal information. In this way, what looks like a citation is actually supplementary material, or suggestions for further reading.\n\nParenthetical referencing, also known as Harvard referencing, has full or partial, in-text, citations enclosed in circular brackets and embedded in the paragraph.\n\nAn example of a parenthetical reference:\n\nDepending on the choice of style, fully cited parenthetical references may require no end section. Other styles include a list of the citations, with complete bibliographical references, in an end section, sorted alphabetically by author. This section is often called \"References\", \"Bibliography\", \"Works cited\" or \"Works consulted\".\n\nIn-text references for online publications may differ from conventional parenthetical referencing. A full reference can be hidden, only displayed when wanted by the reader, in the form of a tooltip. This style makes citing easier and improves the reader's experience.\n\nSuperscripted numbers are inserted at the point of reference, just as in the citation‐sequence system, but the citations are numbered according to the order of cited works at the end of the paper or book; this list is often sorted alphabetically by author.\n\nCitation styles can be broadly divided into styles common to the Humanities and the Sciences, though there is considerable overlap. Some style guides, such as the Chicago Manual of Style, are quite flexible and cover both parenthetical and note citation systems. Others, such as MLA and APA styles, specify formats within the context of a single citation system. These may be referred to as citation formats as well as citation styles. The various guides thus specify order of appearance, for example, of publication date, title, and page numbers following the author name, in addition to conventions of punctuation, use of italics, emphasis, parenthesis, quotation marks, etc., particular to their style.\n\nA number of organizations have created styles to fit their needs; consequently, a number of different guides exist. Individual publishers often have their own in-house variations as well, and some works are so long-established as to have their own citation methods too: Stephanus pagination for Plato; Bekker numbers for Aristotle; citing the Bible by book, chapter and verse; or Shakespeare notation by play.\n\n\nIn some areas of the Humanities, footnotes are used exclusively for references, and their use for conventional footnotes (explanations or examples) is avoided. In these areas, the term \"footnote\" is actually used as a synonym for \"reference\", and care must be taken by editors and typesetters to ensure that they understand how the term is being used by their authors.\n\n\n\n\nIn their research on footnotes in scholarly journals in the field of communication, Michael Bugeja and Daniela V. Dimitrova have found that citations to online sources have a rate of decay (as cited pages are taken down), which they call a \"half-life\", that renders footnotes in those journals less useful for scholarship over time.\n\nOther experts have found that published replications do not have as many citations as original publications.\n\nAnother important issue is citation errors, which often occur due to carelessness on either the researcher or journal editor's part in the publication procedure. Experts have found that simple precautions, such as consulting the author of a cited source about proper citations, reduce the likelihood of citation errors and thus increase the quality of research.\n\nResearch suggests the impact of an article can be, partly, explained by superficial factors and not only by the scientific merits of an article. Field-dependent factors are usually listed as an issue to be tackled not only when comparison across disciplines are made, but also when different fields of research of one discipline are being compared. For example, in medicine, among other factors, the number of authors, the number of references, the article length, and the presence of a colon in the title influence the impact; while in sociology the number of references, the article length, and title length are among the factors.\n\nCitation patterns are also known to be affected by unethical behavior of both the authors and journal staff. Such behavior is called impact factor boosting, and was reported to involve even the top-tier journals. Specifically the high-ranking journals of medical science, including the Lancet, JAMA and New England Journal of Medicine, are thought to be associated with such behavior, with up to 30% of citations to these journals being generated by commissioned opinion articles. On the other hand, the phenomenon of citation cartels is rising. Citation cartels are defined as groups of authors that cite each other disproportionately more than they do other groups of authors who work on the same subject.\n\n"}
{"id": "54083241", "url": "https://en.wikipedia.org/wiki?curid=54083241", "title": "Citation dynamics", "text": "Citation dynamics\n\nCitation dynamics describes the number of references received by the article or other scientific work over time. The citation dynamics is usually described by the bang, that take place 2–3 years after the work has been published, and the burst size spans several orders of magnitude. The presence of bursts is not consistent with other models based on preferential attachment. Those models are able to account for the skewed citation distribution but their reference accumulation is gradual.\n\nThe dynamics of scientific production has changed significantly over the past years. Due to technological progress, the number of published papers has been increasing exponentially until now. This, along with a much shorter time needed for the article to be published, has affected the citation dynamics of the modern papers. Furthermore, if the reference list of the study includes papers published in different years, older papers tend to have more citations. This may not necessarily because they are better but just because they had more time to accumulate those references.\n\nIt has been found that citation distributions are best described by a shifted power-law. The probability that paper formula_1 is cited at time formula_2 after publication as:\n\nwhere formula_4 serves as the outcome variable for each particular paper formula_1 at time formula_2. Fitness, formula_7, captures the inherent differences between papers, accounting for the perceived novelty and importance of a discovery. formula_8 represents the cumulative number of citations acquired by a paper formula_1 at time formula_2 and formula_11 is a log-normal survival probability. The probability is equal\n\nwhere formula_2 is time; formula_14 is longevity, capturing the decay rate; and formula_15 indicates immediacy, governing the time for a paper to reach its citation peak.\nThe ultimate impact formula_16 represents the total number or citations that the paper receives during its lifetime.\n\nWhere formula_15 is a global parameter that has the same value for all publications. formula_19 represents the relative fitness of the paper. From the above formula, we can see that the total number of references that the paper can receive during its lifetime depends only on its relative fitness which is very hard to quantify.\n\n"}
{"id": "46902218", "url": "https://en.wikipedia.org/wiki?curid=46902218", "title": "Citation network", "text": "Citation network\n\nCitation Network is a social network which contains paper sources and linked by co-citation relationships. Egghe & Rousseau once (1990, p. 228) explain \"when a document \"d\" cites a document \"d\", we can show this by an arrow going from the node representing \"d\" to the document representing \"d\". In this way the documents from a collection D form a directed graph, which is called a 'citation graph' or 'citation network' \".\n\nCitation is a reference to a published or unpublished source (not always the original source). More precisely, a citation is an abbreviated alphanumeric expression embedded in the body of an intellectual work that denotes an entry in the bibliographic references section of the work for the purpose of acknowledging the relevance of the works of others to the topic of discussion at the spot where the citation appears. Generally the combination of both the in-body citation and the bibliographic entry constitutes what is commonly thought of as a citation (whereas bibliographic entries by themselves are not). References to single, machine-readable assertions in electronic scientific articles are known as nanopublications, a form of microattribution.\nCitation networks, the principal focus of this study, are one kind of social networks that have been studied quantitatively almost from the moment citation databases first became available. In 1965, Derek J. de Solla Price described the inherent linking characteristic of the SCI in his seminal paper titled \"Networks of Scientific Papers\". The links between citing and cited papers became dynamic when the SCI began to be published online. In 1973, Henry Small published his work on co-citation analysis which became a self-organizing classification system that led to document clustering experiments and eventually what is called \"Research Reviews\".\n\n"}
{"id": "17077434", "url": "https://en.wikipedia.org/wiki?curid=17077434", "title": "Comparative Toxicogenomics Database", "text": "Comparative Toxicogenomics Database\n\nThe Comparative Toxicogenomics Database (CTD) is a public website and research tool launched in November 2004 that curates scientific data describing relationships between chemicals/drugs, genes/proteins, diseases, taxa, phenotypes, GO annotations, pathways, and interaction modules.\nThe database is maintained by the Department of Biological Sciences at North Carolina State University.\n\nThe Comparative Toxicogenomics Database (CTD) is a public website and research tool that curates scientific data describing relationships between chemicals, genes/proteins, diseases, taxa, phenotypes, GO annotations, pathways, and interaction modules, launched on November 12, 2004. \nThe database is maintained by the Department of Biological Sciences at North Carolina State University.\n\nOne of the primary goals of CTD is to advance the understanding of the effects of environmental chemicals on human health on the genetic level, a field called toxicogenomics.\n\nThe etiology of many chronic diseases involves interactions between environmental factors and genes that modulate important physiological processes. Chemicals are an important component of the environment. Conditions such as asthma, cancer, diabetes, hypertension, immunodeficiency, and Parkinson's disease are known to be influenced by the environment; however, the molecular mechanisms underlying these correlations are not well understood. CTD may help resolve these mechanisms. The most up-to-date extensive list of peer-reviewed scientific articles about CTD is available at their publications page\n\nCTD is a unique resource where biocurators read the scientific literature and manually curate four types of core data:\n\n\nBy integrating the above four data sets, CTD automatically constructs putative chemical-gene-phenotype-disease networks to illuminate molecular mechanisms underlying environmentally-influenced diseases.\n\nThese inferred relationships are statistically scored and ranked and can be used by scientists and computational biologists to generate and verify testable hypotheses about toxicogenomic mechanisms and how they relate to human health.\n\nUsers can search CTD to explore scientific data for chemicals, genes, diseases, or interactions between any of these three concepts. Currently, CTD integrates toxicogenomic data for vertebrates and invertebrates.\n\nCTD integrates data from or hyperlinks to these databases:\n\n"}
{"id": "16264661", "url": "https://en.wikipedia.org/wiki?curid=16264661", "title": "Comparative case", "text": "Comparative case\n\nThe comparative case (abbreviated ) is a grammatical case used in languages such as Mari and Chechen to mark a likeness to something. \n\nIt is not to be confused with the comparative degree, a much more widely used paradigm used to signify heightening of adjectives and adverbs.\n\nIn Mari, the comparative case is marked with the suffix -ла ('-la') For example, if something were to taste like fish (кол - 'kol'), the form used would be колла - 'kolla'). It is also used in regard to languages, when denoting the language a person is speaking, writing, or hearing. Then, however, the accentuation varies slightly from the standard case. Usually, the suffix is not stressed. When it is used with languages, however, it is stressed.\n\nIn Chechen, it is marked with the suffix \"-l\". For example, \"sha\" is 'ice', \"shiila\" is 'cold', and \"shal shiila\" is 'cold as ice'.\n\n"}
{"id": "12185843", "url": "https://en.wikipedia.org/wiki?curid=12185843", "title": "Comparative cognition", "text": "Comparative cognition\n\nComparative cognition is the comparative study of the mechanisms and origins of cognition in various species, and is sometimes seen as more general than, or similar to, comparative psychology.\nFrom a biological point of view, work is being done on the brains of fruit flies that should yield techniques precise enough to allow an understanding of the workings of the human brain on a scale appreciative of individual groups of neurons rather than the more regional scale previously used. Similarly, gene activity in the human brain is better understood through examination of the brains of mice by the Seattle-based Allen Institute for Brain Science (see link below), yielding the freely available Allen Brain Atlas. This type of study is related to comparative cognition, but better classified as one of comparative genomics. Increasing emphasis in psychology and ethology on the biological aspects of perception and behavior is bridging the gap between genomics and behavioral analysis.\n\nIn order for scientists to better understand cognitive function across a broad range of species they can systematically compare cognitive abilities between closely and distantly related species Through this process they can determine what kinds of selection pressure has led to different cognitive abilities across a broad range of animals. For example, it has been hypothesized that there is convergent evolution of the higher cognitive functions of corvids and apes, possibly due to both being omnivorous, visual animals that live in social groups.\n\n\n"}
{"id": "4481195", "url": "https://en.wikipedia.org/wiki?curid=4481195", "title": "Comparative cultural studies", "text": "Comparative cultural studies\n\nComparative cultural studies is a contextual approach to the study of culture in a global and intercultural context. Focus is placed on the theory, method, and application of the study process(es) rather than on the \"what\" of the object(s) of study.\n\nIn comparative cultural studies, selected tenets of comparative literature are merged with selected tenets of the field of cultural studies (including culture theories, (radical) constructivism, communication theories, and systems theories) with the objective to study culture and culture products (including but not restricted to literature, communication, media, art, etc.). This is performed in a contextual and relational construction and with a plurality of methods and approaches, interdisciplinary, and, if and when required, including teamwork. In comparative cultural studies, it is the processes of communicative action(s) in culture and the how of these processes that constitute the main objectives of research and study. However, scholarship in comparative cultural studies does not exclude textual analysis proper of other established fields of study. In comparative cultural studies, ideally, the framework of and methodologies available in the systemic and empirical study of culture are favored. Scholarship in comparative cultural studies includes the theoretical, as well as methodological and applied postulate to move and to dialogue between cultures, languages, literature, and disciplines: attention to other cultures against essentialist notions and practices and beyond the paradigm of the nation-state is a basic and founding element of the framework and its application.\n\n\n"}
{"id": "1719952", "url": "https://en.wikipedia.org/wiki?curid=1719952", "title": "Comparative research", "text": "Comparative research\n\nComparative research is a research methodology in the social sciences that aims to make comparisons across different countries or cultures. A major problem in comparative research is that the data sets in different countries may not use the same categories, or define categories differently (for example by using different definitions of poverty).\n\nAs Moutsios argues, cross-cultural and comparative research should be seen as part of the scientific spirit that arose in Greece in the 6th century and the overall appreciation of knowledge and learning that was characteristic of the 5th century. In other words, it is part of the emergence of \"episteme\" and \"philo-sophia\", as a love for knowledge that is independent from material benefits. \"Episteme\", as a form and activity in the field of \"logos\", marked the break of cognitive closure and advanced empirical inquiry, logical argumentation and the search for truth. And the high esteem for intellectual activity gave rise to a genuine curiosity about other cultures – which has lain thereafter at the heart of comparative inquiry.\n\nMoreover, behind the Greek comparative gaze also was the philosophical and political questioning which characterised the life of the democratic \"polis\". Philosophical inquiry, from the Milesians down to the Sophists, questioned the representations and the cognitive traditions of their own people; the inquiry of the traditions of other peoples was, as Herodotus’ \"Histories\" demonstrate, an activity associated with the ethos of philosophical critique that characterised democratic life in Greece. Similarly, questioning of the Greek laws and institutions and its related values and practices (e.g. \"isegoria\" and \"parrhesia\"), as part of Greek politics, is associated with the effort of the first historians to reflect on home institutions through researching those of others.\n\nAccording also to Karl Deutsch, we have been using this form of investigation for over 2,000 years. Comparing things is essential to basic scientific and philosophic inquiry, which has been done for a long time. Most authors are more conservative in their estimate of how long comparative research has been with us. It is largely an empty debate over the definition of the tradition with those questioning whether comparing things counts as comparative research.\n\nTextbooks on this form of study were beginning to appear by the 1880s, but its rise to extreme popularity began after World War II. There are numerous reasons that comparative research has come to take a place of honour in the toolbox of the social scientist. Globalization has been a major factor, increasing the desire and possibility for educational exchanges and intellectual curiosity about other cultures. Information technology has enabled greater production of quantitative data for comparison, and international communications technology has facilitated this information to be easily spread.\n\nComparative research, simply put, is the act of comparing two or more things with a view to discovering something about one or all of the things being compared. This technique often utilizes multiple disciplines in one study. When it comes to method, the majority agreement is that there is no methodology peculiar to comparative research. The multidisciplinary approach is good for the flexibility it offers, yet comparative programs do have a case to answer against the call that their research lacks a \"seamless whole.\" \n\nThere are certainly methods that are far more common than others in comparative studies, however. Quantitative analysis is much more frequently pursued than qualitative, and this is seen by the majority of comparative studies which use quantitative data. The general method of comparing things is the same for comparative research as it is in our everyday practice of comparison. Like cases are treated alike, and different cases are treated differently; the extent of difference determines how differently cases are to be treated. If one is able to sufficiently distinguish two carry the research conclusions will not be very helpful. \n\nSecondary analysis of quantitative data is relatively widespread in comparative research, undoubtedly in part because of the cost of obtaining primary data for such large things as a country's policy environment. This study is generally aggregate data analysis. Comparing large quantities of data (especially government sourced) is prevalent. A typical method of comparing welfare states is to take balance of their levels of spending on social welfare.\n\nIn line with how a lot of theorizing has gone in the last century, comparative research does not tend to investigate \"grand theories,\" such as Marxism. It instead occupies itself with middle-range theories that do not purport to describe our social system in its entirety, but a subset of it. A good example of this is the common research program that looks for differences between two or more social systems, then looks at these differences in relation to some other variable coexisting in those societies to see if it is related. The classic case of this is Esping-Andersen's research on social welfare systems. He noticed there was a difference in types of social welfare systems, and compared them based on their level of decommodification of social welfare goods. He found that he was able to class welfare states into three types, based on their level of decommodification. He further theorized from this that decommodification was based on a combination of class coalitions and mobilization, and regime legacy. Here, Esping-Andersen is using comparative research: he takes many western countries and compares their level of decommodification, then develops a theory of the divergence based on his findings.\n\nComparative research can take many forms. Two key factors are space and time. Spatially, cross-national comparisons are by far the most common, although comparisons within countries, contrasting different areas, cultures or governments also subsist and are very constructive, especially in a country like New Zealand, where policy often changes depending on which race it pertains to. Recurrent interregional studies include comparing similar or different countries or sets of countries, comparing one's own country to others or to the whole world.\n\nThe historical comparative research involves comparing different time-frames. The two main choices within this model are comparing two stages in time (either snapshots or time-series), or just comparing the same thing over time, to see if a policy's effects differ over a stretch of time.\n\nWhen it comes to subject matter of comparative inquiries, many contend there is none unique to it. This may indeed be true, but a brief perusal of comparative endeavours reveals there are some topics more recurrent than others. Determining whether socioeconomic or political factors are more important in explaining government action is a familiar theme. In general, however, the only thing that is certain in comparative research issues is the existence of differences to be analysed.\n\n\n"}
{"id": "1266596", "url": "https://en.wikipedia.org/wiki?curid=1266596", "title": "Comparison of Dewey and Library of Congress subject classification", "text": "Comparison of Dewey and Library of Congress subject classification\n\nThis is a conversion chart showing how the Dewey Decimal and Library of Congress Classification systems organize resources by concept, in part for the purpose of assigning . These two systems account for over 95% of the classification in United States libraries, and are used widely around the world.\n\nThe chart includes all ninety-nine second level (two-digit) DDC classes (040 is not assigned), and should include all second level (two-digit) LCC classes. Where a class in one system maps to several classes in other system, it will be listed multiple times (e.g. DDC class 551).\n\nAdditional information on these classification plans is available at:\n\n\n"}
{"id": "31994535", "url": "https://en.wikipedia.org/wiki?curid=31994535", "title": "Comparison of Nazism and Stalinism", "text": "Comparison of Nazism and Stalinism\n\nA number of authors have carried out comparisons of Nazism and Stalinism, in which they have considered the similarities and differences of the two ideologies and political systems, what relationship existed between the two regimes, and why both of them came to prominence at the same time. During the 20th century, the comparison of Stalinism and Nazism was made on the topics of totalitarianism, ideology, and personality cult. Both regimes were seen in contrast to the liberal West, with an emphasis on the similarities between the two. The American political scientists Zbigniew Brzezinski, Hannah Arendt and Carl Friedrich and historian Robert Conquest were prominent advocates of applying the \"totalitarian\" concept to compare Nazism and Stalinism.\n\nOne of the first scholars to publish a comparative study of Nazi Germany and Stalin’s Soviet Union was Hannah Arendt. In her 1951 work, \"The Origins of Totalitarianism\", Arendt puts forward the idea of totalitarianism as a distinct type of political movement and form of government, which “differs essentially from other forms of political oppression known to us such as despotism, tyranny and dictatorship.” Furthermore, Arendt distinguishes between a totalitarian movement (such as a political party with totalitarian aims) and a totalitarian government. Not all totalitarian movements succeed in creating totalitarian governments once they gain power. In Arendt’s view, although many totalitarian movements existed in Europe in the 1920s and 1930s, only the governments of Stalin and Hitler succeeded in fully implementing their totalitarian aims. \n\nArendt traced the origin of totalitarian movements to the nineteenth century, focusing especially on antisemitism and imperialism. She emphasized the connection between the rise of European nation-states and the growth of antisemitism, which was due to the fact that the Jews represented an “inter-European, non-national element in a world of growing or existing nations.” Conspiracy theories abounded, and the Jews were accused of being part of various international schemes to ruin European nations. Small antisemitic political parties formed in response to this perceived Jewish threat, and, according to Arendt, these were the first political organizations in Europe that claimed to represent the interests of the whole nation as opposed to the interests of a class or other social group. The later totalitarian movements would copy or inherit this claim to speak for the whole nation, with the implication that any opposition to them constituted treason.\n\nEuropean imperialism of the nineteenth century also paved the way for totalitarianism, by legitimizing the concept of endless expansion. After Europeans had engaged in imperialist expansion on other continents, political movements developed which aimed to copy the methods of imperialism on the European continent itself. Arendt refers specifically to the “pan-movements” of pan-Germanism and pan-Slavism, which promised continental empires to nations that had little hope of overseas expansion. According to Arendt, “Nazism and Bolshevism owe more to Pan-Germanism and Pan-Slavism (respectively) than to any other ideology or political movement.”\n\nArendt argues that both the Nazi and Bolshevik movements “recruited their members from [a] mass of apparently indifferent people whom all other parties had given up,” and who “had reason to be equally hostile to all parties.” For this reason, totalitarian movements did not need to use debate or persuasion, and did not need to refute the arguments of the other parties. Their target audience did not have to be persuaded to despise the other parties or the democratic system, because it consisted of people who already despised mainstream politics. As a result, totalitarian movements were free to use violence and terror against their opponents without fear that this might alienate their own supporters. Instead of arguing against their opponents, they adopted deterministic views of human behavior and presented opposing ideas as “originating in deep natural, social, or psychological sources beyond the control of the individual and therefore beyond the power of reason.” The Nazis in particular, during the years before their rise to power, engaged in “killing small socialist functionaries or influential members of opposing parties” both as a means to intimidate opponents and as a means of demonstrating to their supporters that they were a party of action, “different from the ‘idle talkers’ of other parties.”\n\nTotalitarian governments make extensive use of propaganda, and are often characterized by having a strong distinction between what they tell their own supporters and the propaganda they produce for others. Arendt distinguishes these two categories as \"indoctrination\" and \"propaganda\". Indoctrination consists of the message that a totalitarian government promotes internally, to the members of the ruling party and that segment of the population which supports the government. Propaganda consists of the message that a totalitarian government seeks to promote in the outside world, and also among those parts of its own society which may not support the government. Thus, “the necessities for propaganda are always dictated by the outside world,” while the opportunities for indoctrination depend on “the totalitarian governments’ isolation and security from outside interference.” \n\nThe type of indoctrination used by the Soviets and the Nazis was characterized by claims of “scientific” truth, and appeals to “objective laws of nature.” Both movements took a deterministic view of human society and claimed that their ideologies were based on scientific discoveries regarding race (in the case of the Nazis) or the forces governing human history (in the case of the Soviets). Arendt identifies this as being in certain ways similar to modern advertising, in which companies claim that scientific research shows their products to be superior, but more generally she argues that it is an extreme version of “that obsession with science which has characterized the Western world since the rise of mathematics and physics in the sixteenth century.” By their use of pseudoscience as the main justification for their actions, Nazism and Stalinism are distinguished from earlier historical despotic regimes, who appealed instead to religion or sometimes did not try to justify themselves at all. According to Arendt, totalitarian governments did not merely use these appeals to supposed scientific laws as propaganda to manipulate others. Rather, totalitarian leaders like Hitler and Stalin genuinely believed that they were acting in accordance with immutable natural laws, to such an extent that they were willing to sacrifice the self-interest of their regimes for the sake of enacting those supposed laws. For instance, the Nazis treated the inhabitants of occupied territories with extreme brutality and planned to depopulate Eastern Europe in order to make way for colonists from the German “master race,” despite the fact that this actively harmed their war effort. Stalin repeatedly purged the Communist Party of people who deviated even slightly from the party line, even when this weakened the party or the Soviet government, because he believed that they represented the interests of “dying classes” and their demise was historically inevitable.\n\nArendt also identifies the central importance of an all-powerful leader in totalitarian movements. As in other areas, she distinguishes between totalitarian leaders (such as Hitler and Stalin) and non-totalitarian dictators or autocratic leaders. The totalitarian leader does not rise to power by personally using violence or through any special organizational skills, but rather by controlling appointments of personnel within the party, so that all other prominent party members owe their positions to him. With loyalty to the leader becoming the primary criterion for promotion, ambitious party members compete with each other in trying to express their loyalty, and a cult of personality develops around the leader. Even when the leader is not particularly competent and the members of his inner circle are aware of his deficiencies, they remain committed to him out of fear that without him the entire power structure would collapse.\n\nOnce in power, according to Arendt, totalitarian movements face a major dilemma: they built their support on the basis of anger against the status quo and on impossible or dishonest promises, but now they have become the new status quo and are expected to carry out their promises. They deal with this problem by engaging in a constant struggle against external and internal enemies, real or imagined, so as to enable them to say that, in a sense, they have not yet gained the power they need to fulfill their promises. According to Arendt, totalitarian governments must be constantly fighting enemies in order to survive. This explains their apparently irrational behavior, for example when Hitler continued to make territorial demands even after he was offered everything he asked for in the Munich Agreement, or when Stalin unleashed the Great Terror despite the fact that he faced no significant internal opposition.\n\nArendt points out the widespread use of concentration camps by totalitarian governments, arguing that they are the most important manifestation of the need to find enemies to fight against, and are therefore “more essential to the preservation of the regime’s power than any of its other institutions.” Although forced labor was commonly imposed on inmates of concentration camps, Arendt argues that their primary purpose was not any kind of material gain for the regime: “The only permanent economic function of the camps has been the financing of their own supervisory apparatus; thus from the economic point of view the concentration camps exist mostly for their own sake.” The Nazis in particular carried this to the point of “open anti-utility,” by expending large sums of money, resources and manpower – during a war – for the purpose of building and staffing extermination camps and transporting people to them. This sets apart the concentration camps of totalitarian regimes from older human institutions that bear some similarity to them, such as slavery. Slaves were abused and killed for the sake of profit; concentration camp inmates were abused and killed because a totalitarian government needed to justify its existence. Finally, Arendt points out that concentration camps under both Hitler and Stalin included large numbers of inmates who were innocent of any crime – not only in the ordinary sense of the word, but even by the standards of the regimes themselves. That is to say, most of the inmates had not actually committed any action against the regime.\n\nThroughout her analysis, Arendt emphasized the modernity and novelty of the governmental structures set up by Stalin and Hitler, arguing that they represented “an entirely new form of government” which is likely to manifest itself again in various other forms in the future. She also cautioned against the belief that future totalitarian movements would necessarily share the ideological foundations of Nazism or Stalinism, writing that “all ideologies contain totalitarian elements.”\n\nThe totalitarian paradigm in the comparative study of Nazi Germany and the Soviet Union was further developed by Carl Friedrich and Zbigniew Brzezinski, who wrote extensively on this topic both individually and in collaboration. Similar to Hannah Arendt, they state that “totalitarian dictatorship is a new phenomenon; there has never been anything quite like it before.” Friedrich and Brzezinski classify totalitarian dictatorship as a type of autocracy, but argue that it is different in important ways from most other historical autocracies. In particular, it is distinguished by a reliance on modern technology and mass legitimation. Unlike Arendt, Friedrich and Brzezinski apply the notion of totalitarian dictatorship not only to the regimes of Hitler and Stalin, but also to the USSR throughout its entire existence, as well as the regime of Benito Mussolini in Italy and the People’s Republic of China under Mao Zedong.\n\nCarl Friedrich noted that the “possibility of equating the dictatorship of Stalin in the Soviet Union and that of Hitler in Germany” has been a deeply controversial topic and a subject of debate almost from the beginning of those dictatorships. Various other aspects of the two regimes have also been the subject of intense scholarly debate, such as whether Nazi and Stalinist ideologies were genuinely believed and pursued by the respective governments, or whether the ideologies were merely convenient justifications for dictatorial rule. Friedrich himself argues in favor of the former view.\n\nFriedrich and Brzezinski argue that Nazism and Stalinism are not only similar to each other, but also represent a continuation or a return to the tradition of European absolute monarchy on certain levels. In the absolute monarchies of the seventeenth and eighteenth centuries, the monarch ultimately held all decisional power, and was considered accountable only to God. In Stalinism and Nazism, the leader likewise held all real power, and was considered accountable only to various intangible entities such as “the people”, “the masses” or “the Volk.” Thus the common feature of autocracies – whether monarchical or totalitarian – is the concentration of power in the hands of a leader who cannot be held accountable by any legal mechanisms, and who is supposed to be the embodiment of the will of an abstract entity. Friedrich and Brzezinski also identify other features common to all autocracies, such as “the oscillation between tight and loose control.” The regime alternates between periods of intense repression and periods of relative freedom, often represented by different leaders. This depends in part on the personal character of different leaders, but Friedrich and Brzezinski believe that there is also an underlying political cycle, in which rising discontent leads to increased repression up to the point at which the opposition is eliminated, then controls are relaxed until the next time that popular dissatisfaction begins to grow.\n\nThus, placing Stalinism and Nazism within the broader historical tradition of autocratic government, Friedrich and Brzezinski hold that “totalitarian dictatorship, in a sense, is the adaptation of autocracy to twentieth-century industrial society.” However, at the same time, they insist that totalitarian dictatorship is a “\"novel\" type of autocracy” and argue that twentieth century totalitarian regimes (such as those of Hitler and Stalin) had more in common with each other than with any other form of government, including historical autocracies of the past. Totalitarianism can only exist after the creation of modern technology, because such technology is essential for propaganda, for surveillance of the population, and for the operation of a secret police. Furthermore, when speaking of the differences and similarities between fascist and communist regimes, Friedrich and Brzezinski insist that the two kinds of totalitarian governments are “basically alike” but “not wholly alike” – they are more similar to each other than to other forms of government, but they are not the same. Among the major differences between them, Friedrich and Brzezinski identify in particular the fact that communists seek “the world revolution of the proletariat,” while fascists wish to “establish the imperial predominance of a particular nation or race.” \n\nIn terms of the similarities between Nazism and Stalinism, Friedrich lists five main aspects that they hold in common: First, an official ideology that is supposed to be followed by all members of society, at least passively, and which promises to serve as a perfect guide towards some ultimate goal. Second, a single political party, composed of the most enthusiastic supporters of the official ideology, representing an elite group within society (no more than 10 percent of the population), and organized along strictly regimented lines. Third, “a technologically conditioned near-complete monopoly of control of all means of effective armed combat” in the hands of the party or its representatives. Fourth, a similar monopoly held by the party over the mass media and all technological forms of communication. Fifth, “a system of terroristic police control” that is not only used to defend the regime against real enemies, but also to persecute various groups of people who are only suspected of being enemies or who may potentially become enemies in the future.\n\nTwo first pillars of any totalitarian government, according to Friedrich and Brzezinski, are the dictator and the Party. The dictator, whether Stalin, Hitler or Mussolini, holds supreme power. Friedrich and Brzezinski explicitly reject the claim that the Party, or any other institution, could provide a significant counterweight to the power of the dictator in Nazism or Stalinism. The dictator needs the Party in order to be able to rule, so he may be careful not to make decisions that would go directly against the wishes of other leading Party members, but ultimate authority rests with him and not with them. Like Arendt, Friedrich and Brzezinski also identify the cult of personality surrounding the leader as an essential element of a totalitarian dictatorship, and reference Stalin’s personality cult in particular. They also draw attention to the fact that Hitler and Stalin were expected to provide ideological direction for their governments and not merely practical leadership. Friedrich and Brzezinski write that “unlike military dictators in the past, but like certain types of primitive chieftains, the totalitarian dictator is both ruler and high priest.” That is to say, he not only governs, but also provides the principles on which his government is to be based. This is partly due to the way that totalitarian governments arise. They come about when a militant ideological movement seizes power, so the first leader of a totalitarian government is usually the ideologue who built the movement that seized power, and subsequent leaders try to emulate him.\n\nThe totalitarian dictator needs loyal lieutenants to carry out his orders faithfully and with a reasonable degree of efficiency. Friedrich and Brzezinski identify parallels between the men in Hitler and Stalin’s entourage, arguing that both dictators used similar people to perform similar tasks. Thus, for example, Martin Bormann and Georgy Malenkov were both capable administrators and bureaucrats, while Heinrich Himmler and Lavrentiy Beria were ruthless secret police chiefs responsible for suppressing any potential challenge to the dictator’s power. Both Hitler and Stalin promoted rivalry and distrust among their lieutenants so as to ensure that none of them would become powerful enough to challenge the dictator himself. This is the cause of an important weakness of the totalitarian regimes: the problem of succession. Friedrich points out that neither the Nazi nor the Stalinist government ever established any official line of succession or any mechanism to decide who would replace the dictator after his death. The dictator, being the venerated “father of the people,” was regarded as irreplaceable. There could never be any heir apparent, because such an heir would have been a threat to the power of the dictator while he was alive. Thus the dictator’s inevitable death would always leave behind a major power vacuum and cause a political crisis. In the case of the Nazi regime, since Hitler died mere days before the final defeat of Germany in the war, this never became a major issue. In the case of the USSR, Stalin’s death led to a prolonged power struggle.\n\nFriedrich and Brzezinski also identify key similarities between the Nazi and Stalinist political parties, which set them apart from other types of political parties. Both the Nazi Party and the CPSU under Stalin had very strict membership requirements and did not accept members on the basis of mere agreement with the Party’s ideology and goals. Rather, they strictly tested potential members, in a manner similar to exclusive clubs, and often engaged in political purges of the membership, expelling large numbers of people from their ranks (and sometimes arresting and executing those expelled, such as in the Great Purge or the Night of the Long Knives). Thus, the totalitarian party cultivates the idea that to be a member is a privilege which needs to be earned, and total obedience to the leader is required in order to maintain this privilege. While both Nazism and Stalinism required party members to display such total loyalty in practice, they differed in the way they dealt with it in theory. Nazism openly proclaimed the hierarchical ideal of absolute obedience to the Führer as one of its key ideological principles (the \"Führerprinzip\"). Stalinism, meanwhile, denied that it did anything similar, and claimed instead to uphold democratic principles, with the Party Congress (made up of elected delegates) supposedly being the highest authority. However, Stalinist elections typically featured only a single candidate, and the Party Congress met very rarely and simply approved Stalin’s decisions. Thus, regardless of the differences in their underlying ideological claims, the Nazi and Stalinist parties were organized in practice along similar lines, with a rigid hierarchy and centralized leadership.\n\nEach totalitarian party and dictator is supported by a specific totalitarian ideology. Friedrich and Brzezinski argue, in agreement with Arendt, that Nazi and Stalinist leaders really believed in their respective ideologies and did not merely use them as tools to gain power. Several major policies, such as the Stalinist collectivization of agriculture or the Nazi “final solution”, cannot be explained by anything other than a genuine commitment to achieve ideological goals, even at great cost. The ideologies were different and their goals were different, but what they had in common was a utopian commitment to reshaping the world, and a determination to fight by any means necessary against a real or imagined enemy. This stereotyped enemy could be described as “the fat rich Jew or the Jewish Bolshevik” for the Nazis, or “the war-mongering, atom-bomb-wielding American Wallstreeter” for the Soviets.\n\nAccording to Friedrich and Brzezinski, the most important difference between Nazi and Stalinist ideology lies in the degree of universality involved. Stalinism, and communist ideology in general, is universal in its appeal and addresses itself to all the “workers of the world.” Nazism, on the other hand, and fascist ideology in general, can only address itself to one particular race or nation – the “master race” that is destined to dominate all others. Therefore, “in communism social justice appears to be the ultimate value, unless it be the classless society that is its essential condition; in fascism, the highest value is dominion, eventually world dominion, and the strong and pure nation-race is \"its\" essential condition, as seen by its ideology.” This means that fascist or Nazi movements from different countries will be natural enemies, rather than natural allies, as they each seek to extend the dominion of their own nation at the expense of others. Friedrich and Brzezinski see this as a weakness inherent in fascist and Nazi ideology, while communist universalism is a source of ideological strength for Stalinism.\n\nFriedrich and Brzezinski also draw attention to the symbols used by Nazis and Stalinists to represent themselves. The Soviet Union adopted the hammer and sickle, a newly-created symbol, “invented by the leaders of the movement and pointing to the future.” Meanwhile, Nazi Germany used the swastika, “a ritual symbol of uncertain origin, quite common in primitive societies.” Thus, one is trying to project itself as being oriented towards a radically new future, while the other is appealing to a mythical heroic past.\n\nTotalitarian dictatorships maintain themselves in power through the use of propaganda and terror, which Friedrich and Brzezinski believe to be closely connected. Terror may be enforced with arrests and executions of dissenters, but it can also take more subtle forms, such as the threat of losing one’s job, social stigma and defamation. “Terror” can refer to any widespread method used to intimidate people into submission as a matter of daily life. According to Friedrich and Brzezinski, the most effective terror is invisible to the people it affects. They simply develop a habit of acting in a conformist manner and not questioning authority, without necessarily being aware that this is what they are doing. Thus, terror creates a society dominated by apparent consensus, where the vast majority of the population appears to support the government. Propaganda is then used to maintain this appearance of popular consent. \n\nTotalitarian propaganda is one of the features that distinguishes totalitarian regimes as modern forms of government and separates them from older autocracies, since a totalitarian government holds complete control over all means of communication (not only public communication such as the mass media, but also private communication such as letters and telephone calls, which are strictly monitored). The methods of propaganda were very similar in the Stalinist USSR and in Nazi Germany. Both Joseph Goebbels and Soviet propagandists sought to demonize their enemies and present a picture of a united people standing behind its leader to confront foreign threats. In both cases there was no attempt to convey complex ideological nuances to the masses, with the message being instead about a simplistic struggle between good and evil. Both Nazi and Stalinist regimes produced two very different sets of propaganda – one for internal consumption and one for potential sympathizers in other countries. And both regimes would sometimes radically change their propaganda line as they made peace with a former enemy or got into a war with a former ally. Yet, paradoxically, a totalitarian government’s complete control over communications renders that government highly misinformed. With no way for anyone to express criticism, the dictator has no way of knowing how much support he actually has among the general populace. With all government policies always declared successful in propaganda, officials are unable to determine what actually worked and what didn’t. Both Stalinism and Nazism suffered from this problem, especially during the war between them. As the war turned against Germany, there was growing opposition to Hitler’s rule, including within the ranks of the military, but Hitler was never aware of this until it was too late (see: 20 July plot). In 1948, during the early days of the Berlin Blockade, the Soviet leadership apparently believed that the population of West Berlin was sympathetic to Soviet Communism and that they would request to join the Soviet zone. Given enough time, the gap between real public opinion and what the totalitarian government believes about public opinion can grow so wide that the government is no longer able to even produce effective propaganda, because it does not know what the people actually think and so it does not know what to tell them. Friedrich and Brzezinski refer to this as the “ritualization of propaganda”: the totalitarian regime continues to produce propaganda as a political ritual, with little real impact on public opinion.\n\nThe totalitarian use of mass arrests, executions and concentration camps – also noted by Arendt – was analyzed at length by Friedrich and Brzezinski. They hold that “totalitarian terror maintains, in institutionalized form, the civil war that originally produced the totalitarian movement and by means of which the regime is able to proceed with its program, first of social disintegration and then of social reconstruction.” Both Stalinism and Nazism saw themselves as engaging in a life-or-death struggle against implacable enemies. But to declare that the struggle had been won would have meant to declare that most of the totalitarian features of the government were no longer needed. A secret police force, for instance, has no reason to exist if there are no dangerous traitors who need to be found. Thus the struggle, or “civil war” against internal enemies, must be institutionalized and must continue indefinitely. In the Stalinist USSR, the repressive apparatus was eventually turned against members of the Communist Party itself in the Great Purge and the show trials that accompanied it. Nazism, by contrast, had a much shorter lifespan in power, and Nazi terror generally maintained an outward focus, with the extermination of the Jews always given top priority. The Nazis did not turn inward towards purging their own party except in a limited way on two occasions (the Night of the Long Knives and the aftermath of the 20 July plot). \n\nThe peak of totalitarian terror was reached with the Nazi concentration camps. These ranged from labor camps to extermination camps, and they are described by Friedrich and Brzezinski as aiming to “eliminate all actual, potential, and imagined enemies of the regime.” As the field of Holocaust studies was still in its early stages at the time of their writing, they do not describe the conditions in detail, but do refer to the camps as involving “extreme viciousness.” They also compare these camps with the Soviet Gulag system, and highlight the use of concentration camps as a method of punishment and execution by Nazi and Stalinist regimes alike. However, unlike Hannah Arendt, who held that the Gulag camps served no economic purpose, Friedrich and Brzezinski argue that they provided an important source of cheap labor for the Stalinist economy.\n\nThe comparative study of Nazism and Stalinism was carried further by other groups of scholars, such as Moshe Lewin and Ian Kershaw together with their collaborators. Writing after the dissolution of the USSR, Lewin and Kershaw take a longer historical perspective and regard Nazism and Stalinism not so much as examples of a new type of society (like Arendt, Friedrich and Brzezinski did), but more as historical “anomalies” – unusual deviations from the typical path of development that most industrial societies are expected to follow. Therefore, the task of comparing Nazism and Stalinism is, to them, a task of explaining why Germany and Russia (along with other countries) deviated from the historical norm. At the outset, Lewin and Kershaw identify similarities between the historical situations in Germany and Russia prior to the First World War and during that war. Both countries were ruled by authoritarian monarchies, who were under pressure to make concessions to popular demands. Both countries had “powerful bureaucracies and strong military traditions.” Both had “powerful landowning classes,” while also being in the process of rapid industrialization and modernization. And both countries had expansionist foreign policies with a particular interest in Central and Eastern Europe. Lewin and Kershaw do not claim that these factors made Stalinism or Nazism inevitable, but rather that they help to explain why the Stalinist and Nazi regimes developed similar features.\n\nIan Kershaw admitted that Stalinism and Nazism are comparable in “the nature and extent of their inhumanity,” but noted that the two regimes were different in a number of aspects Lewin and Kershaw question the usefulness of grouping the Stalinist and Nazi regimes together under a “totalitarian” category, saying that it remains an open question whether the similarities between them are greater or smaller than the differences. In particular, they criticize what they see as the ideologically-motivated attempt to determine which regime killed more people, saying that apologists of each regime are trying to defend their side by claiming the other was responsible for more deaths.\n\nLewin and Kershaw place the cult of personality at the center of their comparison of Nazism and Stalinism, writing that both regimes “represented a new genre of political system centred upon the artificial construct of a leadership cult – the ‘heroic myth’ of the ‘great leader’, no longer a king or emperor but a ‘man of the people.” With regard to Stalinism, they emphasize its bureaucratic character, and its “merging of the most modern with the most archaic traits” by combining modern technology and the latest methods of administration and propaganda with the ancient practice of arbitrary rule by a single man. They compare this with the Prussian military tradition in Germany, which had been called “bureaucratic absolutism” in the eighteenth century, and which played a significant role in the organization of the Nazi state in the twentieth century.\n\nKershaw agrees with Mommsen that there was a fundamental difference between Nazism and Stalinism regarding the importance of the leader. Stalinism had an absolute leader, but he was not essential. He could be replaced by another. Nazism, on the other hand, was a “classic charismatic leadership movement,” defined entirely by its leader. Stalinism had an ideology which existed independently of Stalin. But for Nazism, “Hitler \"was\" ideological orthodoxy” – Nazi ideals were by definition whatever Hitler said they were. In Stalinism, the bureaucratic apparatus was the foundation of the system, while in Nazism, the person of the leader was the foundation.\n\nMoshe Lewin also focuses on the comparison between the personality cults of Hitler and Stalin, and their respective roles in Nazi Germany and the Soviet Union. He refers to them as the “Hitler myth” and the “Stalin myth,” and argues that they served different functions within their two regimes. The function of the “Hitler myth” was to legitimize Nazi rule. The function of the “Stalin myth” was to legitimize not Soviet rule itself, but Stalin’s leadership within the Party. Stalin’s personality cult existed precisely because Stalin knew that he was replaceable, and feared that he might be replaced, and so needed to bolster his authority as much as possible. While the “Hitler myth” was essential to Nazi Germany, the “Stalin myth” was essential only to Stalin, not to the Soviet Union itself.\n\nTogether with fellow historian Hans Mommsen, Lewin argues that the Stalinist and Nazi regimes featured an “intrinsic structural contradiction” which led to “inherent self-destructiveness”: they depended on a highly organized state bureaucracy which was trying to set up complex rules and procedures for every aspect of life, yet this bureaucracy was under the complete personal control of a despot who made policy decisions as he saw fit, routinely changing his mind on major issues, without any regard for the rules and institutions which his own bureaucracy had set up. The bureaucracy and the leader needed each other, but also undermined each other with their different priorities. Mommsen sees this as being a much greater problem in Nazi Germany than in Stalin’s Soviet Union, as the Nazis inherited large parts of the traditional German bureaucracy, while the Soviets largely built their own bureaucracy from the ground up. He argues that many of the irrational features of the Nazi regime – such as wasting resources on exterminating undesirable populations instead of using those resources in the war effort – were caused by the dysfunction of the Nazi state rather than by fanatical commitment to Nazi ideology. In accordance with the Führerprinzip, all decisional power in the Nazi state ultimately rested with Hitler. But Hitler often issued only vague and general directives, forcing other Nazi leaders lower down in the hierarchy to guess what precisely the Führer wanted. This confusion produced competition between Nazi officials, as each of them attempted to prove that he was a more dedicated Nazi than his rivals, by engaging in ever more extreme policies. This competition to please Hitler was, according to Mommsen, the real cause of Nazi irrationality. Hitler was aware of it, and deliberately encouraged it out of a “social-darwinist conviction that the best man would ultimately prevail.” Mommsen argues that this represents a structural difference between the regimes of Hitler and Stalin. In spite of its purges, Stalin’s regime was more effective in building a stable bureaucracy, such that it was possible for the system to sustain itself and continue even without Stalin. The Nazi regime, on the other hand, was much more personalized and depended entirely on Hitler, being unable to build any lasting institutions.\n\nKershaw also saw major personal differences between Stalin and Hitler and their respective styles of rule. He describes Stalin as “a committee man, chief oligarch, man of the machine” and a “creature of his party,” who came to power only thanks to his party and his ability to manipulate the levers of power within that party. Hitler, by contrast, came to power based on his charisma and mass appeal, and in the Nazi regime it was the leader that created the party instead of the other way around. According to Kershaw, “Stalin was a highly interventionist dictator, sending a stream of letters and directives determining or interfering with policy,” while Hitler “was a non-interventionist dictator as far as government administration was concerned,” preferring to involve himself in military affairs and plans for conquest rather than the daily routine of government work, and giving only broad verbal instructions to his subordinates regarding civilian affairs, which they were expected to translate into policy. Furthermore, although both regimes featured all-pervasive cults of personality, there was a qualitative difference between those cults. Stalin’s personality cult was “superimposed upon the Marxist-Leninist ideology and Communist Party,” and could be abandoned (or replaced with a personality cult around some other leader) without major changes to the regime. On the other hand, “the ‘Hitler myth’ was structurally indispensable to, in fact the very basis of, and scarcely distinguishable from, the Nazi Movement and its \"Weltanschauung\".” The belief in the person of Adolf Hitler as the unique savior of the German nation was the very foundation of Nazism, to such an extent that Nazism found it impossible to even imagine a successor to Hitler. Thus, in Kershaw’s analysis, Stalinism was a fundamentally bureaucratic system while Nazism was the embodiment of “charismatic authority” as described by Max Weber. Stalinism could exist without its leader. Nazism could not. \n\nThe topic of comparisons between Nazism and Stalinism was also studied in the 1990s and 2000s by historians Henry Rousso, Nicolas Werth and Philippe Burrin.\n\nRousso defends the work of Carl Friedrich by pointing out that Friedrich himself had only said that Stalinism and Nazism were comparable, not that they were identical. Rousso also argues that the popularity of the concept of totalitarianism (the way that large numbers of people have come to routinely refer to certain governments as “totalitarian”) should be seen as evidence that the concept is useful, that it really describes a specific type of government which is different from other dictatorships. At the same time, however, Rousso notes that the concept of totalitarianism is descriptive rather than analytical: the regimes described as totalitarian do not have a common origin and did not arise in similar ways. Nazism is unique among totalitarian regimes in having taken power in “a country endowed with an advanced industrial economy and with a system of political democracy (and an even older political pluralism).” All other examples of totalitarianism (including the Stalinist regime) took power, according to Rousso, “in an agrarian economy, in a poor society without a tradition of political pluralism, not to mention democracy, and where diverse forms of tyranny had traditionally prevailed.” He sees this as a weakness of the concept of totalitarianism, because it merely describes the similarities between Stalinism and Nazism without dealing with the very different ways they came to power. On the other hand, Rousso agrees with Hannah Arendt that “totalitarian regimes constitute something new in regard to classical tyranny, authoritarian regimes, or other forms of ancient and medieval dictatorships,” and he says that the main strength of the concept of totalitarianism is the way it highlights this inherent novelty of the regimes involved.\n\nNicolas Werth and Philippe Burrin have worked together on comparative assessments of Stalinism and Nazism, with Werth covering the Stalinist regime and Burrin covering Nazi Germany. One of the topics they have studied is the question of how much power the dictator really held in the two regimes. Werth identifies two main historiographical approaches in the study of the Stalinist regime: Those who emphasize the power and control exercised by Joseph Stalin himself, attributing most of the actions of the Soviet government to deliberate plans and decisions made by him, and those who argue that Stalin had no pre-determined course of action in mind, that he was reacting to events as they unfolded, and that the Soviet bureaucracy had its own agenda which often differed from Stalin’s wishes. Werth regards these as two mistaken extremes, one making Stalin seem all-powerful, the other making him seem like a weak dictator. But he believes that the competing perspectives are useful in drawing attention to the tension between two different forms of organization in the Stalinist USSR: an “administrative system of command,” bureaucratic and resistant to change but effective in running the Soviet state, and the strategy of “running the country in a crudely despotic way by Stalin and his small cadre of directors.” Thus, Werth agrees with Lewin that there was an inherent conflict between the priorities of the Soviet bureaucracy and Stalin’s accumulation of absolute power in his own hands. According to Werth, it was this unresolved and unstated conflict that led to the Great Purge and to the use of terror by Stalin’s regime against its own party and state cadres.\n\nIn studying similar issues with regard to the Nazi regime, Philippe Burrin draws attention to the debate between the “Intentionalist” and “Functionalist” schools of thought, which dealt with the question of whether the Nazi regime represented an extension of Hitler’s autocratic will, faithfully obeying his wishes, or whether it was an essentially chaotic and uncontrollable system that functioned on its own with little direct input from the Führer. Like Kershaw and Lewin, Burrin says that the relationship between the leader and his party’s ideology was different in Nazism compared to Stalinism: “One can rightly state that Nazism cannot be dissociated from Hitlerism, something that is difficult to affirm for Bolshevism and Stalinism.” Unlike Stalin, who inherited an existing system with an existing ideology and presented himself as the heir to the Leninist political tradition, Hitler created both his movement and its ideology by himself, claiming to be “someone sent by Providence, a Messiah whom the German people had been expecting for centuries, even for two thousand years, as Heinrich Himmler enjoyed saying.” Thus, there could be no real conflict between the Party and the leader in Nazi Germany, because the Nazi Party’s entire reason for existence was to support and follow Hitler. However, there was a potential for division between the leader and the state bureaucracy, due to the way that Nazism came to power – as part of an alliance with traditional conservative elites, industrialists, and the army. Unlike the USSR, Nazi Germany did not build its own state, but rather inherited the state machinery of the previous government. This provided the Nazis with an immediate supply of capable and experienced managers and military commanders, but on the other hand it also meant that the Nazi regime had to rely on the cooperation of people who had not been Nazis prior to Hitler’s rise to power, and whose loyalty was questionable. It was only during the war, when Nazi Germany conquered large territories and had to create Nazi administrations for them, that brand new Nazi bureaucracies were created without any input or participation from traditional German elites. This produced a surprising difference between Nazism and Stalinism: When the Stalinist USSR conquered territory, it created smaller copies of itself and installed them as the governments of the occupied countries. When Nazi Germany conquered territory, on the other hand, it did not attempt to create copies of the German government back home. Instead, it experimented with different power structures and policies, often reflecting a “far more ample Nazification of society than what the balance of power authorized in the Reich.”\n\nAnother major topic investigated by Werth and Burrin was the violence and terror employed by the regimes of Hitler and Stalin. Werth reports that the Stalinist USSR underwent an “extraordinary brutalization of the relations between state and society” for the purpose of rapid modernization and industrialization, to “gain one hundred years in one decade, and to metamorphose the country into a great industrial power.” This transformation was accomplished at the cost of massive violence and a sociopolitical regression into what Werth calls “military-feudal exploitation.” The types of violence employed by the Stalinist regime included loss of civil rights, mass arrests, deportations of entire ethnic groups from one part of the USSR to another, forced labor in the Gulag, mass executions (especially during the Great Terror of 1937-38), and most of all the great famine of 1932-33, known as the Holodomor. All levels of Soviet society were affected by Stalinist repression, from the top to the bottom. At the top, high-ranking members of the Communist Party were arrested and executed under the claim that they had plotted against Stalin (and in some cases they were forced to confess to imaginary crimes in show trials). At the bottom, the peasantry suffered the Holodomor famine (especially in Ukraine), and even outside of the famine years they were faced with very high grain quotas.\n\nWerth identifies four categories of people that became the targets of Stalinist violence in the USSR. He lists them from smallest to largest. The first and smallest group consisted of many of Stalin’s former comrades-in-arms, who had participated in the revolution and were known as “Old Bolsheviks.” They were dangerous to Stalin because they had known him before his rise to power and could expose the many false claims made by his personality cult. The second group consisted of mid-level Communist Party officials, who were subject to mass arrests and executions in the late 1930s, particularly during the Great Purge. Eliminating them served a dual purpose: It helped Stalin to centralize power in the Kremlin (as opposed to regional centers), and it also provided him with “corrupt officials” that he could blame for earlier repressions and unpopular policies. Werth draws parallels between this and the old Tsarist tradition of blaming “bad bureaucrats” – rather than the Tsar – for unpopular government actions. The third group was made up of ordinary citizens from all walks of life who resorted to petty crime in order to provide for themselves in the face of worsening living standards (for example by taking home some wheat from the fields or tools from the factory). This type of petty crime became very widespread, and was often punished as if it were intentional sabotage motivated by political opposition to the USSR. The fourth and largest category consisted of ethnic groups that were subject to deportation, famine, or arbitrary arrests under the suspicion of being collectively disloyal to Stalin or to the Soviet state. This included the Holodomor famine directed at the Ukrainians, the deportation of ethnic groups suspected of pro-German sympathies (such as the Volga Germans, the Crimean Tatars, the Chechens and others), and eventually also persecution of ethnic Jews, especially as Stalin grew increasingly antisemitic near the end of his life.\n\nBurrin’s study of violence carried out by the Nazi regime begins with the observation that “violence is at the heart of Nazism,” and that Nazi violence is “established as a doctrine and exalted in speech.” This marks a point of difference between Nazism and Stalinism, according to Burrin. In Stalinism, there was a gulf between ideology and reality when it came to violence. The Soviet regime continuously denied that it was repressive, proclaimed itself a defender of peace, and sought to conceal all the evidence to the contrary. In Nazism, on the other hand, “doctrine and reality were fused from the start.” Nazism not only practiced violent repression and war, but advocated it in principle as well, considering war to be a positive force in human civilization and openly seeking ”living space” and the domination of the European continent by ethnic Germans.\n\nBurrin identifies three motivations for Nazi violence: political repression, exclusion and social repression, and racial politics. The first of these, political repression, is common in many dictatorships. The Nazis aimed to eliminate their real or imagined political opponents, first in the Reich and later in the occupied territories during the war. Some of these opponents were executed, while others were imprisoned in concentration camps. The first targets of political repression, immediately after Hitler’s rise to power in 1933, were the parties of the Left in general and the Communists in particular. Then, after the mid-1930s, repression was extended to members of the clergy, and later to the conservative opposition as well (especially after the failed attempt to assassinate Hitler in 1944). The death penalty was used on a wide scale, even before the war. During the war, political repression was greatly expanded both inside Germany and especially in the newly occupied territories. Political prisoners in the concentration camps numbered only about 25,000 at the beginning of the war. By January 1945 they had swelled to 714,211 – most of them non-Germans accused of plotting against the Reich.\n\nThe second type of Nazi violence, motivated by exclusion and social repression, was the violence aimed at purging German society of people whose lifestyle was considered incompatible with the social norms of the Nazi regime (even if the people involved were racially pure and able-bodied). Such people were divided into two categories: homosexuals and “asocials.” The “asocials” were only vaguely defined, and included “Gypsies, tramps, beggars, prostitutes, alcoholics, the jobless who refused any employment, and those who left their work frequently or for no reason.”\n\nThe third and final type of Nazi violence, by far the most extensive, was violence motivated by Nazi racial policies. This was aimed both inward, to cleanse the “Aryan race” of “degenerate” elements and life unworthy of life, as well as outward, to seek the extermination of “inferior races”. Germans considered physically or mentally unfit were among the first victims. One of the first laws of the Nazi regime mandated the forced sterilization of people suffering from physical handicaps or who had psychiatric conditions deemed to be hereditary. Later, sterilization was replaced by murder of the mentally ill and of people with severe disabilities, as part of a “euthanasia” program called Aktion T4. Burrin notes that this served no practical political purpose – the people being murdered could not have possibly been political opponents of the regime – so the motivation was purely a matter of racial ideology. The most systematic and by far the most large-scale acts of Nazi violence, however, were directed at “racially inferior” non-German populations. As laid out in \"Generalplan Ost\", the Nazis wished to eliminate most of the Slavic populations of Eastern Europe, partly through deportation and partly through murder, in order to secure land for ethnic German settlement and colonization. But even more urgently, the Nazis wished to exterminate the Jews of Europe, whom they regarded as the implacable racial enemy of the Germans. This culminated in the Holocaust, the Nazi genocide of the Jews. Unlike in the case of all other target populations, the Jews were to be exterminated completely, with no individual exceptions for any reason.\n\nIn \"Beyond Totalitarianism: Stalinism and Nazism Compared\", editors Michael Geyer and Sheila Fitzpatrick disputed the concept of totalitarianism, noting that the term entered political discourse first as a term of self-description by the Italian Fascists and was only later used as a framework to compare Nazi Germany with the Soviet Union. They argued that the totalitarian states were not as monolithic or as ideology-driven as they seemed. Geyer and Fitzpatrick describe Nazi Germany and the Stalinist USSR as “immensely powerful, threatening, and contagious dictatorships” who “shook the world in their antagonism.” Without calling them totalitarian, they identified their common features, including genocide, an all-powerful party, a charismatic leader, and pervasive invasion of privacy. However, they argue that Stalinism and Nazism did not represent a new and unique type of government, but rather that they can be placed in the broader context of the turn to dictatorship in Europe in the interwar period. The reason they appear extraordinary is because they were the “most prominent, most hard-headed, and most violent” of the European dictatorships of the 20th century. They are comparable because of their “shock and awe” and sheer ruthlessness, but underneath superficial similarities they were fundamentally different and that “when it comes to one-on-one comparison, the two societies and regimes may as well have hailed from different worlds.”\n\nAccording to Geyer and Fitzpatrick, the similarities between Nazism and Stalinism stem from the fact that they were both “ideology driven” and sought to subordinate all aspects of life to their respective ideologies. The differences stem from the fact that their ideologies were opposed to each other and regarded each other as enemies. Another major difference is that Stalin created a stable and long-lasting regime, while Nazi Germany had a “short-lived, explosive nature.” Notably, the stable state created by Stalinism was based on an entirely new elite, while Nazism, despite having the support of the traditional elite, failed to achieve stability.\n\nHowever, the two regimes did borrow ideas from one another, especially regarding propaganda techniques (most of all in architecture and cinema), but also in terms of state surveillance and antisemitism. At the same time, they both vigorously denied borrowing anything from each other. While their methods of propaganda were similar, the content was different. For instance, Soviet wartime propaganda revolved around the idea of resisting imperial aggression, while Nazi propaganda was about wars of racial conquest. Geyer and Fitzpatrick also take note of the fact that both Stalinism and Nazism sought to create a New Man, an “entirely modern, illiberal, and self-fashioned personage,” even though they had different visions about what being a “New Man” would mean.\n\nAmong the other authors contributing to the volume edited by Geyer and Fitzpatrick, David Hoffmann and Annette Timm discuss biopolitics and the pro-natalist policies of the Nazi and Stalinist regimes. Both governments were highly concerned over low fertility rates in their respective populations, and applied extensive and intrusive social engineering techniques to increase the number of births. Reproductive policies in the Soviet Union and Nazi Germany were administered through their health care systems—both regimes saw health care as a key pillar to their designs to develop a new society. While the Soviet Union had to design a public health care system from scratch, Nazi Germany built upon the pre-existing public health care system in Germany that had existed since 1883, when Otto von Bismarck's legislation had created the world's first national public health care program. The Nazis centralized the German health care system in order to enforce Nazi ideological components upon it, and replaced existing voluntary and government welfare agencies with new ones that were devoted to racial hygiene and other components of Nazi ideology.\n\nThe Nazi and Stalinist attempt to control family size was not unique, as many other European states practiced eugenics at this time, and the Stalinist and Nazi ideals were vastly different. In fact, they had more in common with third parties than with each other: Nazi Germany’s policies were rather similar to those in Scandinavia at the time, while the USSR’s policies resembled those in Catholic countries.The common point between Nazi and Stalinist practices was the connection of reproduction policies with the ideological goals of the state — \"part of the project of a rational, hypermodern vision for the re-organization of society\". There were nevertheless substantial differences between the two regimes' approaches. Stalin's Soviet Union never officially supported eugenics as the Nazis did—the Soviet government called eugenics a \"fascist science\"—although there were in fact Soviet eugenicists. The two regimes also had different approaches to the relationship between family and paid labor—Nazism promoted the male single-breadwinner family while Stalinism promoted the dual-wage-earner household.\n\nIn another contribution to the same volume, Christian Gerlach and Nicolas Werth discuss the topic of mass violence, and the way that it was used by both Stalinism and Nazism. Both Stalin's Soviet Union and Nazi Germany were violent societies where mass violence was accepted by the state, such as in the Great Terror of 1937 to 1938 in the Soviet Union and the Holocaust in Nazi Germany and its occupied territories in World War II.\n\nBoth the Stalinist Soviet Union and Nazi Germany utilized internment camps led by agents of the state – the NKVD in the Soviet Union and the SS in Nazi Germany. They also both engaged in violence against minorities based on xenophobia – the xenophobic violence of the Nazis was outspoken but rationalized as being against \"asocial\" elements while the xenophobic violence of the Stalinists was disguised as being against \"anti-soviet\", \"counter-revolutionary\" and \"socially harmful\" elements – a term which often targeted diaspora nationalities. The Stalinist Soviet Union established \"special settlements\" where the \"socially harmful\" or \"socially dangerous\" who included ex-convicts, criminals, vagrants, the disenfranchised and \"declassed elements\" were expelled to. These \"special settlements\" were largely in Siberia, the far north, the Urals, or other inhospitable territories. In July 1933, the Soviet Union made a mass arrest of 5000 Romani people effectively on the basis of their ethnicity, who were deported that month to the \"special settlements\" in Western Siberia. In 1935, the Soviet Union arrested 160,000 homeless people and juvenile delinquents and sent many of them to NKVD labor colonies where they did forced labor.\n\nThe Nazi regime was founded upon a racialist view of politics and envisioned the deportation or extermination of the majority of the population of Eastern Europe in order to open up “living space” for ethnic German settlers. This was mainly intended to be carried out after an eventual German victory in the war, but steps had already started being taken while the war was still ongoing. For instance, by the end of 1942, the Nazis had deported 365,000 Poles and Jews from their original homes in western Poland (now German-annexed) and into the General Government. A further 194,000 Poles were internally displaced (not deported to another territory but expelled from their homes). The Nazis had also deported 100,000 persons from Alsace, Lorraine, and Luxembourg, as well as 54,000 Slovenians.\n\nStalinism in practice in the Soviet Union pursued ethnic deportations from the 1930s to the early 1950s, with a total of 3 million Soviet citizens being subjected to ethnic-based resettlement. The first major ethnic deportation took place from December 1932 to January 1933, during which some 60,000 Kuban Cossacks were collectively criminally charged as a whole with association with resistance to socialism and affiliation with Ukrainian nationalism. From 1935 to 1936, the Soviet Union deported Soviet citizens of Polish and German origins living in the western districts of Ukraine, and Soviet citizens of Finnish origins living on the Finland-Soviet Union border. These deportations from 1935 to 1936 affected tens of thousands of families. From September to October 1937, Soviet authorities deported the Korean minority from its Far Eastern region that bordered on Japanese-controlled Korea. Soviet authorities claimed the territory was \"rich soil for the Japanese to till\" – implying a Soviet suspicion that the Koreans could potentially join forces with the Japanese to unite the land with Japanese-held Korea. Over 170,000 Koreans were deported to remote parts of Soviet Central Asia from September to October 1937. These ethnically-based deportations reflected a new trend in Stalinist policy, a \"Soviet xenophobia\" based on ideological grounds that suspected that these people were susceptible to foreign influence, and which was also based on a resurgent Russian nationalism.\n\nAfter Nazi Germany declared war on the Soviet Union in 1941, the Soviet Union initiated another major round of ethnic deportations. The first group targeted were Soviet Germans. Between September 1941 and February 1942, 900,000 people – over 70 percent of the entire Soviet German community – were deported to Kazakhstan and Siberia in mass operations. A second wave of mass deportations took place between November 1943 and May 1944, in which Soviet authorities expelled six ethnic groups (the Balkars, Chechens, Crimean Tatars, Ingush, Karachai, and Kalmyks) that together numbered 900,000. There were also smaller-scale operations involving ethnic cleansing of diaspora minorities during and after World War II, in which tens of thousands of Crimean Bulgarians, Greeks, Iranians, Khemshils, Kurds, and Meskhetian Turks were deported from the Black Sea and Transcaucasian border regions.\n\nTwo ethnic groups that were specifically targeted for persecution by Stalin's Soviet Union were the Chechens and the Ingush. Unlike the other nationalities that could be suspected of connection to foreign states which shared their ethnic background, the Chechens and the Ingush were completely indigenous people of the Soviet Union. Rather than being accused of collaboration with foreign enemies, these two ethnic groups were considered to have cultures which did not fit in with Soviet culture – such as accusing Chechens of being associated with “banditism” – and the authorities claimed that the Soviet Union had to intervene in order to “remake” and “reform” these cultures. In practice this meant heavily armed punitive operations carried out against Chechen “bandits” that failed to achieve forced assimilation, culminating in an ethnic cleansing operation in 1944, which involved the arrests and deportation of over 500,000 Chechens and Ingush from the Caucasus to Central Asia and Kazakhstan. The deportations of the Chechens and Ingush also involved the outright massacre of thousands of people, and severe conditions placed upon the deportees – they were put in unsealed train cars, with little to no food for a four-week journey during which many died from hunger and exhaustion.\n\nThe main difference between Nazi and Stalinist deportations was in their purpose: while Nazi Germany sought ethnic cleansing to allow settlement by Germans into the cleansed territory, Stalin's Soviet Union pursued ethnic cleansing in order to remove minorities from strategically important areas.\n\nOther historians and political scientists have also made comparisons between Nazism and Stalinism as part of their work.\n\nStanley Payne, in his work on fascism, said that although the Nazi Party was ideologically opposed to communism, Adolf Hitler and other Nazi leaders frequently expressed recognition that only in Soviet Russia were their revolutionary and ideological counterparts to be found. Both placed a major emphasis on creating a \"party-army,\" with the regular armed forces controlled by the party. In the case of the Soviet Union this was done through the political commissars, while Nazi Germany introduced a roughly equivalent leadership role for \"National Socialist Guidance Officers\" in 1943.\n\nFrançois Furet, in his work on communism, noted that Hitler personally admired Soviet leader Joseph Stalin, and on numerous occasions publicly praised Stalin for seeking to purify the Communist Party of the Soviet Union of Jewish influences, especially by purging Jewish communists such as Leon Trotsky, Grigory Zinoviev, Lev Kamenev and Karl Radek.\n\nRichard Pipes draws attention to Stalin and his antisemitism in a parallel with Nazi antisemitism. He notes that soon after the 1917 October Revolution, the Soviet Union undertook practices to break up Jewish culture, religion and language. In the fall of 1918, the Soviet Communist Party set up the Jewish section Yevsektsiya, with a stated mission of “destruction of traditional Jewish life, the Zionist movement, and Hebrew culture.” By 1919, the Bolsheviks began to confiscate Jewish properties, Hebrew schools, libraries, books, and synagogues in accordance with newly imposed anti-religious laws, turning their buildings into \"Communist centers, clubs or restaurants.\" After Joseph Stalin rose to power, antisemitism continued to be endemic throughout Russia, although official Soviet policy condemned it. On August 12, 1952, Stalin's personal antisemitism became more visible, as he ordered the execution of the most prominent Yiddish authors in the Soviet Union, in an event known as the \"Night of the Murdered Poets\". Shortly before his death, Stalin also organized the anti-Semitic campaign known as the Doctors' plot.\n\nA number of research institutions are focusing on the analysis of fascism/Nazism and Stalinism/communism, and the comparative approach, including the Hannah Arendt Institute for the Research on Totalitarianism in Germany, the Institute for the Study of Totalitarian Regimes in the Czech Republic and the Institute of National Remembrance in Poland.\n\nIn comparing the deaths caused by both Stalin and Hitler's policies, some historians have asserted that archival evidence released after the collapse of the USSR confirms that Stalin did not kill more people than Hitler. American historian Timothy D. Snyder, for example, after assessing such data, says that while the Nazi regime killed approximately 11 million non-combatants (which rises to above 12 million if \"foreseeable deaths from deportation, hunger, and sentences in concentration camps are included\"), Stalin's deliberately killed about 6 million (rising to 9 million if foreseeable deaths arising from policies are taken into account). Australian historian and archival researcher Stephen G. Wheatcroft posits that \"The Stalinist regime was consequently responsible for about a million purposive killings, and through its criminal neglect and irresponsibility it was probably responsible for the premature deaths of about another two million more victims amongst the repressed population, i.e. in the camps, colonies, prisons, exile, in transit and in the POW camps for Germans. These are clearly much lower figures than those for whom Hitler's regime was responsible.\" Wheatcroft also says that, unlike Hitler, Stalin's \"purposive killings\" fit more closely into the category of \"execution\" than \"murder\", given he thought the accused were indeed guilty of crimes against the state and insisted on documentation, whereas Hitler simply wanted to kill Jews and communists because of who they were, and insisted on no documentation and was indifferent at even a pretence of legality for these actions.\n\nKristen R. Ghodsee, an ethnographer of post-Cold War Eastern Europe, contends that the efforts to institutionalize the \"double genocide thesis\", or the moral equivalence between the Nazi Holocaust (race murder) and the victims of communism (class murder), and in particular the recent push at the beginning of the global financial crisis for commemoration of the latter in Europe, can be seen as the response by economic and political elites to fears of a leftist resurgence in the face of devastated economies and extreme inequalities in both the East and West as the result of neoliberal capitalism. She notes that any discussion of the achievements under communism, including literacy, education, women’s rights, and social security is usually silenced, and any discourse on the subject of communism is focused almost exclusively on Stalin's crimes and the \"double genocide thesis\", an intellectual paradigm summed up as such: \"1) any move towards redistribution and away from a completely free market is seen as communist; 2) anything communist inevitably leads to class murder; and 3) class murder is the moral equivalent of the Holocaust.\" By linking all leftist and socialist ideals to the excesses of Stalinism, Ghodsee concludes, the elites in the West hope to discredit and marginalize all political ideologies that could \"threaten the primacy of private property and free markets.\"\n\nThe comparison of Stalinism and Nazism remains a neglected field of academic study.\n\nThe comparison of Nazism and Stalinism has long provoked political controversy, and it led to the historians' dispute within Germany in the 1980s.\n\nIn the 1920s, the Social Democratic Party of Germany (SPD), under the leadership of Chancellor Hermann Müller, adopted the view that \"red equals brown\", i.e. that the communists and Nazis posed an equal danger to liberal democracy. In 1930, Kurt Schumacher said that the two movements enabled each other. He argued that the Communist Party of Germany, which was staunchly Stalinist, were \"red-painted Nazis.\" This comparison was mirrored by the social fascism theory advanced by the Soviet government and the Comintern (including the Communist Party of Germany), which accused social democracy of enabling fascism and went as far as to call social democrats \"social fascists.\" After the 1939 Molotov–Ribbentrop Pact was announced, \"The New York Times\" published an editorial arguing that \"Hitlerism is brown communism, Stalinism is red fascism.\"\n\nMarxist theories of fascism have seen fascism as a form of reaction to socialism and a feature of capitalism. Several modern historians have tried to pay more attention to the economic, political and ideological differences between these two regimes than to their similarities. \n\nThe 2008 Prague Declaration on European Conscience and Communism, initiated by the Czech government and signed by figures such as Václav Havel, called for \"a common approach regarding crimes of totalitarian regimes, inter alia Communist regimes\" and for\nThe Communist Party of Greece opposes the Prague Declaration and has criticized \"the new escalation of the anti-communist hysteria led by the EU council, the European Commission and the political staff of the bourgeois class in the European Parliament.\" The Communist Party of Britain opined that the Prague Declaration \"is a rehash of the persistent attempts by reactionary historians to equate Soviet Communism and Hitlerite Fascism, echoing the old slanders of British authors George Orwell and Robert Conquest.\"\n\nThe 2008 documentary film \"The Soviet Story\", commissioned by the Union for Europe of the Nations group in the European Parliament, published archival records which listed thousands of German Jews who were arrested in the Soviet Union by the NKVD (People's Commissariat for Internal Affairs) from 1937 to 1941 and handed over to Gestapo or SS officials in Germany. These German Jews had originally sought asylum in the USSR. The documentary film accuses Stalin's regime of being an accomplice in Hitler's Holocaust by arresting these asylum seekers and sending them back to Germany.\n\nSince 2009, the European Union has officially commemorated the European Day of Remembrance for Victims of Stalinism and Nazism, proclaimed by the European Parliament in 2008 and endorsed by the Organization for Security and Co-operation in Europe in 2009, and officially known as the Black Ribbon Day in some countries (including Canada).\n\nThe former President of the European Parliament and Christian Democratic Union member, Hans-Gert Pöttering, argued that \"both totalitarian systems (Stalinism and Nazism) are comparable and terrible.\"\n\nIn some Eastern European countries the denial of both Nazi and Communist crimes has been explicitly outlawed, and Czech foreign minister Karel Schwarzenberg has argued that \"there is a fundamental concern here that totalitarian systems be measured by the same standard.\" However, the European Commission rejected calls for similar EU-wide legislation, due to the lack of consensus among member states.\n\nA statement adopted by Russia's legislature said that comparisons of Nazism and Stalinism are \"blasphemous towards all of the anti-fascist movement veterans, Holocaust victims, concentration camp prisoners and tens of millions of people ... who sacrificed their lives for the sake of the fight against the Nazis' anti-human racial theory.\"\n\nBritish journalist Seumas Milne posits that the impact of the post-Cold War narrative that Stalin and Hitler were twin evils, and therefore Communism is as monstrous as Nazism, \"has been to relativise the unique crimes of Nazism, bury those of colonialism and feed the idea that any attempt at radical social change will always lead to suffering, killing and failure.\"\n\n\n"}
{"id": "32639223", "url": "https://en.wikipedia.org/wiki?curid=32639223", "title": "Comparison of online charity donation services in the United Kingdom", "text": "Comparison of online charity donation services in the United Kingdom\n\nThe page is a comparison of notable online charity donation services in the UK.\n\nThe table below gives examples of the various transaction fees for a £10 donation using each organisation, assuming they claim back the tax for the charity using gift aid. (Charities may also be charged set-up fees and monthly fees as detailed above.)\n\n\n"}
{"id": "1996367", "url": "https://en.wikipedia.org/wiki?curid=1996367", "title": "Comparison of web template engines", "text": "Comparison of web template engines\n\nThe following table lists the various Web Template Engines used in Web template systems and a brief rundown of their features.\n\n\n"}
{"id": "1833848", "url": "https://en.wikipedia.org/wiki?curid=1833848", "title": "Cross-reference", "text": "Cross-reference\n\nThe term cross-reference can refer to either:\n\nIn a document, especially those authored in a Content management system,\na cross-reference has two major aspects:\n\nThe visible form contains text, graphics, and other indications that:\n\nThe technical mechanism that resides within the system:\n\nIf the cross reference mechanism is well designed, the reader will be able to follow each cross reference to the referenced content whether the content is presented in print or electronically.\n\nAn author working in a content management system is responsible for identifying subjects of interest that cross documents, and creating appropriate systems of cross references to support readers who seek to understand those subjects. For an individual cross reference, an author should ensure that location and content of the target of the cross reference are clearly identified, and the reader can easily determine how to follow the cross reference in each medium in which publication is supported.\n\nContent strategy practitioners (known as content strategists) specialize in planning content to meet business needs, taking into account the processes for creating and maintaining the content, and the systems that support the content.\n\n"}
{"id": "7931", "url": "https://en.wikipedia.org/wiki?curid=7931", "title": "Dictionary", "text": "Dictionary\n\nA dictionary, sometimes known as a wordbook, is a collection of words in one or more specific languages, often arranged alphabetically (or by radical and stroke for ideographic languages), which may include information on definitions, usage, etymologies, pronunciations, translation, etc. or a book of words in one language with their equivalents in another, sometimes known as a lexicon. It is a lexicographical reference that shows inter-relationships among the data.\n\nA broad distinction is made between general and specialized dictionaries. Specialized dictionaries include words in specialist fields, rather than a complete range of words in the language. Lexical items that describe concepts in specific fields are usually called terms instead of words, although there is no consensus whether lexicology and terminology are two different fields of study. In theory, general dictionaries are supposed to be semasiological, mapping word to definition, while specialized dictionaries are supposed to be onomasiological, first identifying concepts and then establishing the terms used to designate them. In practice, the two approaches are used for both types. There are other types of dictionaries that do not fit neatly into the above distinction, for instance bilingual (translation) dictionaries, dictionaries of synonyms (thesauri), and rhyming dictionaries. The word dictionary (unqualified) is usually understood to refer to a general purpose monolingual dictionary.\n\nThere is also a contrast between \"prescriptive\" or \"descriptive\" dictionaries; the former reflect what is seen as correct use of the language while the latter reflect recorded actual use. Stylistic indications (e.g. \"informal\" or \"vulgar\") in many modern dictionaries are also considered by some to be less than objectively descriptive.\n\nAlthough the first recorded dictionaries date back to Sumerian times (these were bilingual dictionaries), the systematic study of dictionaries as objects of scientific interest themselves is a 20th-century enterprise, called lexicography, and largely initiated by Ladislav Zgusta. The birth of the new discipline was not without controversy, the practical dictionary-makers being sometimes accused by others of \"astonishing\" lack of method and critical-self reflection.\n\nThe oldest known dictionaries were Akkadian Empire cuneiform tablets with bilingual Sumerian–Akkadian wordlists, discovered in Ebla (modern Syria) and dated roughly 2300 BCE. The early 2nd millennium BCE \"Urra=hubullu\" glossary is the canonical Babylonian version of such bilingual Sumerian wordlists. A Chinese dictionary, the c. 3rd century BCE \"Erya\", was the earliest surviving monolingual dictionary; although some sources cite the c. 800 BCE Shizhoupian as a \"dictionary\", modern scholarship considers it a calligraphic compendium of Chinese characters from Zhou dynasty bronzes. Philitas of Cos (fl. 4th century BCE) wrote a pioneering vocabulary \"Disorderly Words\" (Ἄτακτοι γλῶσσαι, \"\") which explained the meanings of rare Homeric and other literary words, words from local dialects, and technical terms. Apollonius the Sophist (fl. 1st century CE) wrote the oldest surviving Homeric lexicon. The first Sanskrit dictionary, the Amarakośa, was written by Amara Sinha c. 4th century CE. Written in verse, it listed around 10,000 words. According to the \"Nihon Shoki\", the first Japanese dictionary was the long-lost 682 CE \"Niina\" glossary of Chinese characters. The oldest existing Japanese dictionary, the c. 835 CE \"Tenrei Banshō Meigi\", was also a glossary of written Chinese. In \"Frahang-i Pahlavig\", Aramaic heterograms are listed together with their translation in Middle Persian language and phonetic transcription in Pazand alphabet. A 9th-century CE Irish dictionary, Sanas Cormaic, contained etymologies and explanations of over 1,400 Irish words. In India around 1320, Amir Khusro compiled the Khaliq-e-bari which mainly dealt with Hindustani and Persian words.\nArabic dictionaries were compiled between the 8th and 14th centuries CE, organizing words in rhyme order (by the last syllable), by alphabetical order of the radicals, or according to the alphabetical order of the first letter (the system used in modern European language dictionaries). The modern system was mainly used in specialist dictionaries, such as those of terms from the Qur'an and hadith, while most general use dictionaries, such as the \"Lisan al-`Arab\" (13th century, still the best-known large-scale dictionary of Arabic) and \"al-Qamus al-Muhit\" (14th century) listed words in the alphabetical order of the radicals. The \"Qamus al-Muhit\" is the first handy dictionary in Arabic, which includes only words and their definitions, eliminating the supporting examples used in such dictionaries as the \"Lisan\" and the \"Oxford English Dictionary\".\nIn medieval Europe, glossaries with equivalents for Latin words in vernacular or simpler Latin were in use (e.g. the Leiden Glossary). The \"Catholicon\" (1287) by Johannes Balbus, a large grammatical work with an alphabetical lexicon, was widely adopted. It served as the basis for several bilingual dictionaries and was one of the earliest books (in 1460) to be printed. In 1502 Ambrogio Calepino's \"Dictionarium\" was published, originally a monolingual Latin dictionary, which over the course of the 16th century was enlarged to become a multilingual glossary. In 1532 Robert Estienne published the \"Thesaurus linguae latinae\" and in 1572 his son Henri Estienne published the \"Thesaurus linguae graecae\", which served up to the 19th century as the basis of Greek lexicography. The first monolingual dictionary written in Europe was the Spanish, written by Sebastián Covarrubias' \"Tesoro de la lengua castellana o española\", published in 1611 in Madrid, Spain. In 1612 the first edition of the \"Vocabolario degli Accademici della Crusca\", for Italian, was published. It served as the model for similar works in French and English. In 1690 in Rotterdam was published, posthumously, the \"Dictionnaire Universel\" by Antoine Furetière for French. In 1694 appeared the first edition of the \"Dictionnaire de l'Académie française\". Between 1712 and 1721 was published the \"Vocabulario portughez e latino\" written by Raphael Bluteau. The Real Academia Española published the first edition of the \"Diccionario de la lengua española\" in 1780, but their \"Diccionario de Autoridades\", which included quotes taken from literary works, was published in 1726. The \"Totius Latinitatis lexicon\" by Egidio Forcellini was firstly published in 1777; it has formed the basis of all similar works that have since been published.\n\nThe first edition of \"A Greek-English Lexicon\" by Henry George Liddell and Robert Scott appeared in 1843; this work remained the basic dictionary of Greek until the end of the 20th century. And in 1858 was published the first volume of the Deutsches Wörterbuch by the Brothers Grimm; the work was completed in 1961. Between 1861 and 1874 was published the \"Dizionario della lingua italiana\" by Niccolò Tommaseo. Between 1862 and 1874 was published the six volumes of \"A magyar nyelv szótára\" (Dictionary of Hungarian Language) by Gergely Czuczor and János Fogarasi. Émile Littré published the Dictionnaire de la langue française between 1863 and 1872. In the same year 1863 appeared the first volume of the \"Woordenboek der Nederlandsche Taal\" which was completed in 1998. Also in 1863 Vladimir Ivanovich Dahl published the \"Explanatory Dictionary of the Living Great Russian Language\". The Duden dictionary dates back to 1880, and is currently the prescriptive source for the spelling of German. The decision to start work on the \"Svenska Akademiens ordbok\" was taken in 1787.\n\nThe earliest dictionaries in the English language were glossaries of French, Spanish or Latin words along with their definitions in English. The word \"dictionary\" was invented by an Englishman called John of Garland in 1220 — he had written a book \"Dictionarius\" to help with Latin \"diction\". An early non-alphabetical list of 8000 English words was the \"Elementarie\", created by Richard Mulcaster in 1582.\n\nThe first purely English alphabetical dictionary was \"A Table Alphabeticall\", written by English schoolteacher Robert Cawdrey in 1604. The only surviving copy is found at the Bodleian Library in Oxford. This dictionary, and the many imitators which followed it, was seen as unreliable and nowhere near definitive. Philip Stanhope, 4th Earl of Chesterfield was still lamenting in 1754, 150 years after Cawdrey's publication, that it is \"a sort of disgrace to our nation, that hitherto we have had no… standard of our language; our dictionaries at present being more properly what our neighbors the Dutch and the Germans call theirs, word-books, than dictionaries in the superior sense of that title.\" \n\nIn 1616, John Bullokar described the history of the dictionary with his \"English Expositor\". \"Glossographia\" by Thomas Blount, published in 1656, contains more than 10,000 words along with their etymologies or histories. Edward Phillips wrote another dictionary in 1658, entitled \"The New World of English Words: Or a General Dictionary\" which boldly plagiarized Blount's work, and the two denounced each other. This created more interest in the dictionaries. John Wilkins' 1668 essay on philosophical language contains a list of 11,500 words with careful distinctions, compiled by William Lloyd. Elisha Coles published his \"English Dictionary\" in 1676.\n\nIt was not until Samuel Johnson's \"A Dictionary of the English Language\" (1755) that a more reliable English dictionary was produced. Many people today mistakenly believe that Johnson wrote the first English dictionary: a testimony to this legacy. By this stage, dictionaries had evolved to contain textual references for most words, and were arranged alphabetically, rather than by topic (a previously popular form of arrangement, which meant all animals would be grouped together, etc.). Johnson's masterwork could be judged as the first to bring all these elements together, creating the first \"modern\" dictionary.\n\nJohnson's dictionary remained the English-language standard for over 150 years, until the Oxford University Press began writing and releasing the \"Oxford English Dictionary\" in short fascicles from 1884 onwards. It took nearly 50 years to complete this huge work, and they finally released the complete \"OED\" in twelve volumes in 1928. It remains the most comprehensive and trusted English language dictionary to this day, with revisions and updates added by a dedicated team every three months. One of the main contributors to this modern dictionary was an ex-army surgeon, William Chester Minor, a convicted murderer who was confined to an asylum for the criminally insane.\n\nIn 1806, American Noah Webster published his first dictionary, \"\". In 1807 Webster began compiling an expanded and fully comprehensive dictionary, \"An American Dictionary of the English Language;\" it took twenty-seven years to complete. To evaluate the etymology of words, Webster learned twenty-six languages, including Old English (Anglo-Saxon), German, Greek, Latin, Italian, Spanish, French, Hebrew, Arabic, and Sanskrit.\n\nWebster completed his dictionary during his year abroad in 1825 in Paris, France, and at the University of Cambridge. His book contained seventy thousand words, of which twelve thousand had never appeared in a published dictionary before. As a spelling reformer, Webster believed that English spelling rules were unnecessarily complex, so his dictionary introduced American English spellings, replacing \"colour\" with \"color\", substituting \"wagon\" for \"waggon\", and printing \"center\" instead of \"centre\". He also added American words, like \"skunk\" and \"squash\", that did not appear in British dictionaries. At the age of seventy, Webster published his dictionary in 1828; it sold 2500 copies. In 1840, the second edition was published in two volumes.\n\nIn a general dictionary, each word may have multiple meanings. Some dictionaries include each separate meaning in the order of most common usage while others list definitions in historical order, with the oldest usage first.\n\nIn many languages, words can appear in many different forms, but only the undeclined or unconjugated form appears as the headword in most dictionaries. Dictionaries are most commonly found in the form of a book, but some newer dictionaries, like StarDict and the \"New Oxford American Dictionary\" are dictionary software running on PDAs or computers. There are also many online dictionaries accessible via the Internet.\n\nAccording to the \"Manual of Specialized Lexicographies\", a specialized dictionary, also referred to as a technical dictionary, is a dictionary that focuses upon a specific subject field. Following the description in \"The Bilingual LSP Dictionary\", lexicographers categorize specialized dictionaries into three types: A multi-field dictionary broadly covers several subject fields (e.g. a business dictionary), a single-field dictionary narrowly covers one particular subject field (e.g. law), and a sub-field dictionary covers a more specialized field (e.g. constitutional law). For example, the 23-language Inter-Active Terminology for Europe is a multi-field dictionary, the American National Biography is a single-field, and the African American National Biography Project is a sub-field dictionary. In terms of the coverage distinction between \"minimizing dictionaries\" and \"maximizing dictionaries\", multi-field dictionaries tend to minimize coverage across subject fields (for instance, \"Oxford Dictionary of World Religions\" and \"Yadgar Dictionary of Computer and Internet Terms\") whereas single-field and sub-field dictionaries tend to maximize coverage within a limited subject field (\"The Oxford Dictionary of English Etymology\").\n\nAnother variant is the glossary, an alphabetical list of defined terms in a specialized field, such as medicine (medical dictionary).\n\nThe simplest dictionary, a defining dictionary, provides a core glossary of the simplest meanings of the simplest concepts. From these, other concepts can be explained and defined, in particular for those who are first learning a language. In English, the commercial defining dictionaries typically include only one or two meanings of under 2000 words. With these, the rest of English, and even the 4000 most common English idioms and metaphors, can be defined.\n\nLexicographers apply two basic philosophies to the defining of words: \"prescriptive\" or \"descriptive\". Noah Webster, intent on forging a distinct identity for the American language, altered spellings and accentuated differences in meaning and pronunciation of some words. This is why American English now uses the spelling \"color\" while the rest of the English-speaking world prefers \"colour\". (Similarly, British English subsequently underwent a few spelling changes that did not affect American English; see further at American and British English spelling differences.)\n\nLarge 20th-century dictionaries such as the \"Oxford English Dictionary\" (OED) and \"Webster's Third\" are descriptive, and attempt to describe the actual use of words. Most dictionaries of English now apply the descriptive method to a word's definition, and then, outside of the definition itself, and information alerting readers to attitudes which may influence their choices on words often considered vulgar, offensive, erroneous, or easily confused. \"Merriam-Webster\" is subtle, only adding italicized notations such as, \"sometimes offensive\" or \"stand\" (nonstandard). \"American Heritage\" goes further, discussing issues separately in numerous \"usage notes.\" \"Encarta\" provides similar notes, but is more prescriptive, offering warnings and admonitions against the use of certain words considered by many to be offensive or illiterate, such as, \"an offensive term for...\" or \"a taboo term meaning...\".\n\nBecause of the widespread use of dictionaries in schools, and their acceptance by many as language authorities, their treatment of the language does affect usage to some degree, with even the most descriptive dictionaries providing conservative continuity. In the long run, however, the meanings of words in English are primarily determined by usage, and the language is being changed and created every day. As Jorge Luis Borges says in the prologue to \"El otro, el mismo\": \"It is often forgotten that (dictionaries) are artificial repositories, put together well after the languages they define. The roots of language are irrational and of a magical nature.\"\n\nSometimes the same dictionary can be descriptive in some domains and prescriptive in others. For example, according to Ghil'ad Zuckermann, the \"Oxford English-Hebrew Dictionary\" is \"at war with itself\": whereas its coverage (lexical items) and glosses (definitions) are descriptive and colloquial, its vocalization is prescriptive. This internal conflict results in absurd sentences such as \"hi taharóg otí kshetiré me asíti lamkhonít\" (she'll tear me apart when she sees what I've done to the car). Whereas \"hi taharóg otí\", literally 'she will kill me', is colloquial, me (a variant of ma 'what') is archaic, resulting in a combination that is unutterable in real life.\n\nA historical dictionary is a specific kind of descriptive dictionary which describes the development of words and senses over time, usually using citations to original source material to support its conclusions.\n\nIn contrast to traditional dictionaries, which are designed to be used by human beings, dictionaries for natural language processing (NLP) are built to be used by computer programs. The final user is a human being but the direct user is a program. Such a dictionary does not need to be able to be printed on paper. The structure of the content is not linear, ordered entry by entry but has the form of a complex network (see Diathesis alternation). Because most of these dictionaries are used to control machine translations or cross-lingual information retrieval (CLIR) the content is usually multilingual and usually of huge size. In order to allow formalized exchange and merging of dictionaries, an ISO standard called Lexical Markup Framework (LMF) has been defined and used among the industrial and academic community.\n\n\nIn many languages, such as the English language, the pronunciation of some words is not consistently apparent from their spelling. In these languages, dictionaries usually provide the pronunciation. For example, the definition for the word \"dictionary\" might be followed by the International Phonetic Alphabet spelling . American English dictionaries often use their ownpronunciation respelling systems with diacritics, for example \"dictionary\" is respelled as \"dĭk′shə-nĕr′ē\" in the American Heritage Dictionary. The IPA is more commonly used within the British Commonwealth countries. Yet others use their own pronunciation respelling systems without diacritics: for example, \"dictionary\" may be respelled as . Some online or electronic dictionaries provide audio recordings of words being spoken.\n\nHistories and descriptions of the dictionaries of other languages on Wikipedia include:\n\n\nThe age of the Internet brought online dictionaries to the desktop and, more recently, to the smart phone. David Skinner in 2013 noted that \"Among the top ten lookups on Merriam-Webster Online at this moment are 'holistic, pragmatic, caveat, esoteric' and 'bourgeois.' Teaching users about words they don’t already know has been, historically, an aim of lexicography, and modern dictionaries do this well.\"\nThere exist a number of websites which operate as online dictionaries, usually with a specialized focus. Some of them have exclusively user driven content, often consisting of neologisms. Some of the more notable examples include:\n\n\n\n"}
{"id": "8366559", "url": "https://en.wikipedia.org/wiki?curid=8366559", "title": "Difference theory", "text": "Difference theory\n\nDifference theory has roots in the studies of John Gumperz, who examined differences in cross-cultural communication. While difference theory deals with cross-gender communication, the male and female genders are often presented as being two separate cultures, hence the relevance of Gumperz's studies. In her development of the difference theory, Deborah Tannen drew on the work of Daniel Maltz and Ruth Borker, in particular their 1982 paper, \"A Cultural Approach to Male-Female Miscommunication\", which itself drew on the work of Gumperz. Mary Talbot makes reference to the term \"gender-specific culture\" in her critique of the difference theory, and this idea of genders being culturally separated is embodied by the 1992 publication \"Men Are from Mars, Women Are from Venus\". Difference theory is often compared with dominance theory and deficit theory, and together with the more contemporary dynamic theory they make up four of the theories most widely referred to and compared in the study of language and gender.\n\nThe reason for the popularity of Tannen's book \"You Just Don't Understand\", and the resultant popularisation of difference theory, is generally attributed to the style of Tannen's work, in which she adopts a neutral position on differences in genderlect by making no value-judgements about use of language by either gender. Talbot comments that this means the book provides explanations for domestic disputes without \"pointing the finger\" at anyone.\n\nDifference theory as postulated by Tannen is generally summarised into six categories, each of which pairs contrasting uses of language by males and females.\n\nTannen states that, for men, the world is a competitive place in which conversation and speech are used to build status, whereas for women the world is a network of connections, and that they use language to seek and offer support. In demonstrating this, Tannen uses the example of her husband and herself, who at one point had jobs in different cities. She remarks that whenever someone commented on this, she interpreted it as being an offer of sympathy or support. Her husband, on the other hand, took such comments as being criticisms and attempts to put him down. Tannen remarks that this displays the different approaches that women and men take in terms of status and support. Furthermore, men are also more likely to interrupt to get their point across and hence gain status.\n\nWomen seek comfort and sympathy for their problems, whilst men will seek a solution to the problem.\n\nTannen states that men's conversation is message-oriented, i.e. based upon communicating information. For women, conversation is much more important for building relationships and strengthening social links.\n\nMen will use direct imperatives (\"close the door\", \"switch on the light\") when speaking to others. Women encourage the use of superpolite forms, however (\"let's\", \"would you mind if ...?\").\n\nTannen asserts that most women avoid conflict in language at all costs, and instead attempt to resolve disagreements without any direct confrontation, to maintain positive connection and rapport. Men, on the other hand, are more likely to use confrontation as a way of resolving differences and thereby negotiating status. Tannen supports this view by making reference to the work of Walter J. Ong, whose 1981 publication, \"Fighting for Life\", asserts that \"expressed adversativeness\" is more an element of male culture than female culture. Tannen stresses that both forms of communication are valid ways of creating involvement and forming bonds.\n\nDifference theory asserts that in general men favour independence, while women are more likely to seek intimacy. Tannen demonstrates this with the example of a husband making a decision without consulting his wife. She theorises that he does so because he doesn't want to feel a loss of independence that would come from saying, \"Let me consult this with my wife first.\" Women, by contrast, like to demonstrate that they have to consult with their partner, as this is seen to be proof of the intimacy of the relationship. Tannen asserts that women, seeing the world as a network of connections and relationships, view intimacy as key to achieving consensus and avoiding the appearance of superiority, whereas men, who are more likely to view the world in terms of status, see independence as being key to establishing their status. Tannen also clarifies that while both men and women seek independence and intimacy, men tend to be focused on the former, while women tend to focus on the latter.\n\nGeneral criticisms are that Tannen's observations are largely anecdotal and cannot be said for all conjugal conversations, let alone mixed-gender interactions as a whole.\n\n\n"}
{"id": "1902180", "url": "https://en.wikipedia.org/wiki?curid=1902180", "title": "Digital reference", "text": "Digital reference\n\nDigital reference (or virtual reference) is a service by which a library reference service is conducted online, and the reference transaction is a computer-mediated communication. It is the remote, NextNextcomputer-mediated delivery of reference information provided by library professionals to users who cannot access or do not want face-to-face communication. Virtual reference service is most often an extension of a library's existing reference service program. The word \"reference\" in this context refers to the task of providing assistance to library users in finding information, answering questions, and otherwise fulfilling users’ information needs. Reference work often but not always involves using reference works, such as dictionaries, encyclopedias, etc. This form of reference work expands reference services from the physical reference desk to a \"virtual\" reference desk where the patron could be writing from home, work or a variety of other locations.\n\nThe terminology surrounding virtual reference services may involve multiple terms used for the same definition. The preferred term for remotely delivered, computer-mediated reference services is \"virtual reference\", with the secondary non-preferred term \"digital reference\" having gone out of use in recent years. \"Chat reference\" is often used interchangeably with virtual reference, although it represents only one aspect of virtual reference. Virtual reference includes the use of both synchronous (i.e., IM, videoconferencing) and asynchronous communication (i.e., texting and email). Here, \"synchronous virtual reference\" refers to any real-time computer-mediated communication between patron and information professional. Asynchronous virtual reference is all computer-mediated communication that is sent and received at different times.\n\nThe earliest digital reference services were launched in the mid-1980s, primarily by academic and medical libraries, and provided by e-mail. These early-adopter libraries launched digital reference services for two main reasons: to extend the hours that questions could be submitted to the reference desk, and to explore the potential of campus-wide networks, which at that time was a new technology.\n\nWith the advent of the graphical World Wide Web, libraries quickly adopted webforms for question submission. Since then, the percentage of questions submitted to services via webforms has outstripped the percentage submitted via email.\n\nIn the early- to mid-1990s, digital reference services began to appear that were not affiliated with any library. These digital reference services are often referred to as \"AskA\" services. Examples of AskA services are the Internet Public Library, Ask Dr. Math, and Ask Joan of Art.\n\nProviding remote-based services for patrons has been a steady practice of libraries over the years. For example, before the widespread use of chat software, reference questions were often answered via phone, fax, email and audio conferencing. Email is the oldest type of virtual reference service used by libraries. Library services in America and the UK are just now gaining visibility in their use of virtual reference services using chat software. However, a survey in America revealed that by 2001 over 200 libraries were using chat reference services. \nThe rapid global proliferation of information technology (IT) often leaves libraries at a disadvantage in terms of keeping their services current. However, libraries are always striving to understand their user demographics in order to provide the best possible services. Therefore, libraries continue to take notes from current cyberculture and are continually incorporating a diversified range of interactive technologies in their service repertoires. Virtual reference represents only one small part of a larger library mission to meet the needs of a new generation, sometimes referred to as the \"Google Generation\", of users who have grown up with the internet. For instance, virtual reference may be used in conjunction with embedded Web 2.0 (online social media such as Facebook, YouTube, blogs, del.icio.us, Flickr, etc.) applications in a library's suite of online services. As technological innovations continue, libraries will be watching to find new, more personalized ways of interacting with remote reference users.\n\nThe range of cost-per-transaction of reference interactions has been found to be large, due to the differences in librarian salaries and infrastructural costs required by reference interviews.\n\nWebforms are created for digital reference services in order to help the patron be more productive in asking their question. This document helps the librarian locate exactly what the patron is asking for. Creation of webforms requires design consideration. Because webforms substitute for the reference interview, receiving as much information as possible from the patron is a key function.\n\nAspects commonly found within webforms:\n\n\nSeveral applications exist for providing chat-based reference. Some of these applications are: QuestionPoint, OmniReference, Tutor.com, LibraryH3lp, AspiringKidz.com, and Vienova.com. These applications bear a resemblance to commercial help desk applications. These applications possess functionality such as: chat, co-browsing of webpages, webpage and document pushing, customization of pre-scripted messages, storage of chat transcripts, and statistical reporting.\n\nInstant messaging (IM) services are used by some libraries as a low-cost means of offering chat-based reference, since most IM services are free. Utilizing IM for reference services allows a patron to contact the library from any location via the internet. This service is like the traditional reference interview because it is a live interaction between the patron and the librarian. On the other side the reference interview is different because the conversation does not float away but instead is in print on the screen for the librarian to review if needed to better understand the patron. IM reference services may be for the use of in-house patrons as well as patrons unable to go to the library. If library computers support IM chat programs, patrons may IM from within the library to avoid losing their use of a computer or avoid making embarrassing questions public.\n\nSuccessful IM reference services will:\n\nAt times, IM becomes challenging because of lack of non-verbal cues such as eye contact, and the perceived time pressure. Moreover, formulating the question online without the give and take of nonverbal cues and face to face conversation presents an added obstacle. In addition, to provide effective reference service through IM, it is important to meet higher level of information literacy standards. These standards include evaluating the information and its source, synthesizing the information to create new ideas or products, and understanding the societal, legal, and economic issues surrounding its use.\n\nThe article Live, Digital Reference Marketplace by Buff Hirko contains a comparison of the features of applications for chat-based reference.\n\nSee the entries in the Library Success Wiki's Online Reference Section, including software recommended for web-based chat reference, IM reference, SMS (text messaging) reference, and other types like digital audio or video reference.\n\nVirtual service software programs offered by libraries are often unique, and tailored to the individual library's needs. However, each program may have several distinct features. A knowledge base is a chunk of information that users can access independently. An example of this is a serialized listing of frequently asked questions (FAQ) that a user can read and use at his or her leisure.\n\nOnline chat, or instant messaging (IM) has become a very popular Web-based feature. Instant messaging is a real time conversation that utilizes typed text instead of language. Users may feel a sense of satisfaction with the use of this tool because of their personalized interaction with staff.\n\nThe use of electronic mail (email) in responding to reference questions in libraries has been in use for years. Also, in some cases with the IM feature, a question may be asked that cannot be resolved in online chat. In this instance the staff member may document the inquiring patron’s email address and will the user a response.\n\nWith the increase in use of text messaging (Short Message Service or SMS), some libraries are also adopting text messaging in their virtual reference services. Librarians can use mobile phones, text-to-instant messaging or web-based services to respond to reference questions via text messaging.\n\nCo-browsing, or cooperative browsing, is a virtual reference function that involves interactive control of a user’s web browser. This function enables the librarian to see what the patron has on his or her computer screen. Several types of co-browsing have been offered in mobile devices of late; libraries may have software that incorporates dual modes of co-browsing in a variety of formats. For instance, it is possible to browse on a mobile device within and between documents (such as Word), webpages, and images.\n\nVirtual reference services are growing in popularity in the UK with more institutions accepting queries via email, instant messaging and other chat based services. A study of the use of virtual reference within UK academic institutions showed that 25% currently offer a form of virtual reference, with 54% of academic institutions surveyed considering adding this service.\n\nUK public libraries were instrumental in some of the first steps towards UK-wide internet collaboration amongst libraries with the EARL Consortium (Electronic Access to Resources in Libraries) in 1995, in a time where internet access was a rare commodity for both library staff and the public. Resources were collated and lines of communication opened between libraries across the UK, paving the way for services all over the world to follow suit. There are now a number of area-specific reference services across the UK including Ask A Librarian (UK-wide, established in 1997), Ask Cymru (Welsh and English language service), Enquire (Government funded through the People's Network, also UK-wide), and Ask Scotland. Ask Scotland was created by the Scottish Government's advisory body on libraries, SLIC (Scottish Library and Information Council), and funded by the Public Library Quality Improvement Fund (PLQIF) in June 2009. It uses the Online Computer Library Center's QuestionPoint software.\n\nThe definition formulated by the American Library Association's (ALA) 2004 MARS Digital Reference Guidelines Ad Hoc Committee contains three components:\n\n\nIn January 2011 QuestionPoint and the American Library Association were in talks about offering a National Ask A Librarian service across the whole United States of America. At present the Ask services in the US are run at a local level.\n\nIn Europe some countries offer services in both their own national language and in English. European countries include: Finland, the Netherlands (in Dutch only), Denmark, and France.\n\nOther countries which offer virtual reference services include: Australia, New Zealand, Canada, and the state of Colorado in the United States.\n\nA collaboration between UK and Australian library services, entitled Chasing the Sun, has been initiated using QuestionPoint software so that an all-hours digital reference chat service can be offered. Targeted at health libraries where reference queries from health professionals could occur at any time of the day or night due to medical emergencies, the collaboration between the two countries means that someone will be on hand to field the query at any time. Although the UK libraries involved are currently based in England the programme may expand to other countries and health services if successful.\n\n\n\n\nThe following provide software and technology infrastructure for digital/virtual reference.\n\n\n\n\n\n"}
{"id": "1054566", "url": "https://en.wikipedia.org/wiki?curid=1054566", "title": "Ditloid", "text": "Ditloid\n\nA ditloid is a type of word puzzle, in which a phrase, quotation, date, or fact must be deduced from the numbers and abbreviated letters in the clue. Common words such as 'the', 'in', 'a', 'an', 'of', 'to', etc. are not normally abbreviated. The name 'ditloid' was given by the \"Daily Express\" newspaper, originating from the clue: 1 = DitLoID ≡ \"1 Day in the Life of Ivan Denisovich\".\n\nWill Shortz originated the current form of this puzzle and first published it in the May–June 1981 issue of \"Games\" magazine, calling it the Equation Analysis Test. In its annual 1981 issue of \"What's hot and what's not,\" \"Us\" magazine named the Equation Analysis Test in the \"what's hot\" category – the only nonperson so recognized. Shortz reports:\nSome anonymous person had retyped the puzzle from \"Games\" (word for word, except for my byline),\nphotocopied it, and passed it along. This page was then rephotocopied ad infinitum, like a chain letter,\nand circulated around the country. \"Games\" readers who hadn't seen the original even started sending\nit back to \"Games\" as something the magazine ought to consider publishing!\nShortz based the puzzle on the Formula Analysis Test - Revised Form published in Morgan Worthy's 1975 book \"AHA! A Puzzle Approach to Creative Thinking\" (Chicago: Nelson Hall). Worthy's equations were in a different format, for example:\n\nWorthy gives the source of his inspiration and speculates about the perennial popularity\nof this puzzle:\nI got the idea for linguistic equations from graffiti someone had\nwritten in the form of an obscene formula on a restroom wall at the\nUniversity of Florida. When the answer suddenly came to me, I realized\nthe format was a good one for eliciting the \"aha effect\". After that I\nused such items as exercise material when teaching workshops on\ncreative thinking.\nMy guess is that one reason a person enjoys linguistic equations is\nthat the answer hits him or her all at once rather than being solved in\nan incremental fashion. It is similar to what happens when we suddenly\nsee an embedded figure pop into focus; the satisfaction is visceral\nrather than just intellectual. My experience was that people often had\nthe answer to an item come to them when they were not consciously\nthinking about the puzzles, but relaxed, such as in the shower or about\nto fall asleep.\nAnother factor is that with well-written items, success does not hinge\non obscure information. Ideally, a person should never have to feel, \"I\ncould never have gotten that one no matter how long I worked on it.\"\nThere is something ego enhancing about knowing you have the answer\ninside and just need to find it.\n"}
{"id": "58632079", "url": "https://en.wikipedia.org/wiki?curid=58632079", "title": "Encyclopedia of Forensic and Legal Medicine 2nd Edition", "text": "Encyclopedia of Forensic and Legal Medicine 2nd Edition\n\nThe Encyclopedia of Forensic and Legal Medicine 2nd Edition is a reference source and pioneering 4 set encyclopedia of forensics and medico-legal knowledge published by Academic Press, Elsevier in 2016. This has been edited by the renowned British forensic specialist Jason Payne-James and Australian forensic pathologist Roger W. Byard and an international editorial board. \nThis reference work includes more than 300 articles contributed by forensic medicine and forensic science experts from all over the world. The encyclopedia is a complete reference source of articles covering from forensics, criminal investigations, health-care, legal, judicial, ballistics, toxicology,fingerprinting, DNA typing, disaster victim identification to autopsy and postmortem examination.\n\nThe encyclopedia is especially meant for forensic, medical, chemistry, physics, laboratory technologists and anthropology students and specialists such as forensic experts, lawyers, judicial officers, judges, police and investigating offices, nurses, medical officers etc. All the articles of the encyclopedia are available through Science direct and Scopus.\n"}
{"id": "1720724", "url": "https://en.wikipedia.org/wiki?curid=1720724", "title": "Fumblerules", "text": "Fumblerules\n\nA fumblerule is a rule of language or linguistic style, humorously written in such a way that it breaks this rule. Fumblerules are a form of self-reference.\n\nThe science editor George L. Trigg published a list of such rules in 1979. The term \"fumblerules\" was coined in a list of such rules compiled by William Safire on Sunday, 4 November 1979, in his column \"On Language\" in the \"New York Times\". Safire later authored a book titled \"Fumblerules: A Lighthearted Guide to Grammar and Good Usage\", which was reprinted in 2005 as \"\".\n\n\n\n"}
{"id": "33487458", "url": "https://en.wikipedia.org/wiki?curid=33487458", "title": "Guide to information sources", "text": "Guide to information sources\n\nA Guide to information sources (or a bibliographic guide, a literature guide, a guide to reference materials, a subject gateway, etc.) is a kind of metabibliography. Ideally it is not just a listing of bibliographies, reference works and other information sources, but more like a textbook introducing users to the information sources in a given field (in general).\n\nSuch guides may have many different forms: Comprehensive or highly selective, printed or electronic sources, annoteted listings or written chapters etc.\n\nOften used as curriculum tools for bibliographic instruction, the guides help library users find materials or help those unfamiliar with a discipline understand the key sources.\n\nAby, Stephen H., Nalen, James & Fielding, Lori (2005). Sociology; a guide to reference and information sources. 3rd ed. Westport, Conn.: Libraries Unlimited.\n\nAdams, Stephen R. (2005). \"Information Sources in Patents\"; 2nd ed. (Guides to Information Sources). München: K. G. Saur \n\nBlewett, Daniel K (2008). American military history; a guide to reference and information sources. 2nd ed. Westport, CT : Libraries Unlimited.\n\nJacoby, JoAnn & Kibbee, Josephine Z. (2007). Cultural anthropology; a guide to reference and information sources. 2nd ed. Westport, Conn.: Libraries Unlimited.\n\nSchmidt, Diane & Bell, George H. (2003). Guide to reference and information sources in the zoological sciences. Westport, Conn. : Libraries Unlimited.\n\nO'Hare, Christine (2007). \"Business Information Sources\". London: Library Assn Pub Ltd\n\nOstwald, W (1919). Die chemische Literatur und die Organisation der Wissenschaft. Leipzig : W. Ostwald & C. Drucker. (This is considered the first \"guide to information sources\").\n\nStebbins, Leslie F. (2006). Student guide to research in the digital age; how to locate and evaluate information sources. Westport, Conn.: Libraries Unlimited.\n\nWebb, W. H. et al. (Ed.). (1986). Sources of information in the social sciences. A Guide to the literature. 3. ed. Chicago : American Library Association.\n\nZell, Hans M. (ed.). (2003). The African studies companion; a guide to information sources. 3rd rev. and expanded ed. Glais Bheinn : Hans Zell.\n\n\n"}
{"id": "4491358", "url": "https://en.wikipedia.org/wiki?curid=4491358", "title": "Handbook", "text": "Handbook\n\nA handbook is a type of reference work, or other collection of instructions, that is intended to provide ready reference. The term originally applied to a small or portable book containing information useful for its owner, but the Oxford English Dictionary defines the current sense as \"any book...giving information such as facts on a particular subject, guidance in some art or occupation, instructions for operating a machine, or information for tourists.\" \n\nA handbook is sometimes referred to as a vade mecum (Latin, \"go with me\") or pocket reference. It may also be referred to as an enchiridion.\n\nHandbooks may deal with any topic, and are generally compendiums of information in a particular field or about a particular technique. They are designed to be easily consulted and provide quick answers in a certain area. For example, the MLA Handbook for Writers of Research Papers is a reference for how to cite works in MLA style, among other things. Examples of engineering handbooks include \"Perry's Chemical Engineers' Handbook\", \"Marks Standard Handbook for Mechanical Engineers\", and the \"CRC Handbook of Chemistry and Physics\".\n\n"}
{"id": "1930406", "url": "https://en.wikipedia.org/wiki?curid=1930406", "title": "Impredicativity", "text": "Impredicativity\n\nSomething that is impredicative, in mathematics, logic and philosophy of mathematics, is a self-referencing definition. Roughly speaking, a definition is impredicative if it invokes (mentions or quantifies over) the set being defined, or (more commonly) another set that contains the thing being defined. There is no generally accepted precise definition of what it means to be predicative or impredicative. Authors have given different but related definitions.\n\nThe opposite of impredicativity is predicativity, which essentially entails building stratified (or ramified) theories where quantification over lower levels results in variables of some new type, distinguished from the lower types that the variable ranges over. A prototypical example is intuitionistic type theory, which retains ramification so as to discard impredicativity.\n\nRussell's paradox is a famous example of an impredicative construction—namely the set of all sets that do not contain themselves. The paradox is that such a set cannot exist: If it would exist, the question could be asked whether it contains itself or not — if it does then by definition it should not, and if it does not then by definition it should.\n\nThe greatest lower bound of a set , , also has an impredicative definition: if and only if for all elements of , is less than or equal to , and any less than or equal to all elements of is less than or equal to . This definition quantifies over the set (potentially infinite, depending on the order in question) whose members are the lower bounds of , one of which being the glb itself. Hence predicativism would reject this definition.\n\nThe terms \"predicative\" and \"impredicative\" were introduced by , though the meaning has changed a little since then. \n\nSolomon Feferman provides a historical review of predicativity, connecting it to current outstanding research problems.\n\nThe vicious circle principle was suggested by Henri Poincaré (1905-6, 1908) and Bertrand Russell in the wake of the paradoxes as a requirement on legitimate set specifications. Sets that do not meet the requirement are called \"impredicative\".\n\nThe first modern paradox appeared with Cesare Burali-Forti's 1897 \"A question on transfinite numbers\" and would become known as the Burali-Forti paradox. Cantor had apparently discovered the same paradox in his (Cantor's) \"naive\" set theory and this become known as Cantor's paradox. Russell's awareness of the problem originated in June 1901 with his reading of Frege's treatise of mathematical logic, his 1879 \"Begriffsschrift\"; the offending sentence in Frege is the following:\nIn other words, given the function is the variable and is the invariant part. So why not substitute the value for itself? Russell promptly wrote Frege a letter pointing out that:\nFrege promptly wrote back to Russell acknowledging the problem:\nWhile the problem had adverse personal consequences for both men (both had works at the printers that had to be emended), van Heijenoort observes that \"The paradox shook the logicians' world, and the rumbles are still felt today. ... Russell's paradox, which uses the bare notions of set and element, falls squarely in the field of logic. The paradox was first published by Russell in \"The principles of mathematics\" (1903) and is discussed there in great detail ...\". Russell, after six years of false starts, would eventually answer the matter with his 1908 theory of types by \"propounding his \"axiom of reducibility\". It says that any function is coextensive with what he calls a \"predicative\" function: a function in which the types of apparent variables run no higher than the types of the arguments\". But this \"axiom\" was met with resistance from all quarters.\n\nThe rejection of impredicatively defined mathematical objects (while accepting the natural numbers as classically understood) leads to the position in the philosophy of mathematics known as predicativism, advocated by Henri Poincaré and Hermann Weyl in his \"Das Kontinuum\". Poincaré and Weyl argued that impredicative definitions are problematic only when one or more underlying sets are infinite.\n\nErnst Zermelo in his 1908 \"A new proof of the possibility of a well-ordering\" presents an entire section \"b. \"Objection concerning nonpredicative definition\"\" where he argued against \"Poincaré (1906, p. 307) [who states that] a definition is 'predicative' and logically admissible only if it \"excludes\" all objects that are dependent upon the notion defined, that is, that can in any way be determined by it\". He gives two examples of impredicative definitions – (i) the notion of Dedekind chains and (ii) \"in analysis wherever the maximum or minimum of a previously defined \"completed\" set of numbers is used for further inferences. This happens, for example, in the well-known Cauchy proof of the fundamental theorem of algebra, and up to now it has not occurred to anyone to regard this as something illogical\". He ends his section with the following observation: \"A definition may very well rely upon notions that are equivalent to the one being defined; indeed, in every definition \"definiens\" and \"definiendum\" are equivalent notions, and the strict observance of Poincaré's demand would make every definition, hence all of science, impossible\".\n\nZermelo's example of minimum and maximum of a previously defined \"completed\" set of numbers reappears in Kleene 1952:42-42 where Kleene uses the example of Least upper bound in his discussion of impredicative definitions; Kleene does not resolve this problem. In the next paragraphs he discusses Weyl's attempt in his 1918 \"Das Kontinuum\" (\"The Continuum\") to eliminate impredicative definitions and his failure to retain the \"theorem that an arbitrary non-empty set of real numbers having an upper bound has a least upper bound (cf. also Weyl 1919)\".\n\nRamsey argued that \"impredicative\" definitions can be harmless: for instance, the definition of \"tallest person in the room\" is impredicative, since it depends on a set of things of which it is an element, namely the set of all persons in the room. Concerning mathematics, an example of an impredicative definition is the smallest number in a set, which is formally defined as: if and only if for all elements of , is less than or equal to , and is in .\n\nBurgess (2005) discusses predicative and impredicative theories at some length, in the context of Frege's logic, Peano arithmetic, second order arithmetic, and axiomatic set theory.\n\n\n"}
{"id": "161388", "url": "https://en.wikipedia.org/wiki?curid=161388", "title": "Indirect self-reference", "text": "Indirect self-reference\n\nIndirect self-reference describes an object referring to itself \"indirectly\".\n\nFor example, define the function f such that f(x) = x(x). Any function passed as an argument to f is invoked with itself as an argument, and thus in any use of that argument is indirectly referring to itself.\n\nThis example is similar to the Scheme expression \"((lambda(x)(x x)) (lambda(x)(x x)))\", which is expanded to itself by beta reduction, and so its evaluation loops indefinitely despite the lack of explicit looping constructs. An equivalent example can be formulated in lambda calculus.\n\nIndirect self-reference is special in that its self-referential quality is not explicit, as it is in the sentence \"this sentence is false.\" The phrase \"this sentence\" refers directly to the sentence as a whole. An indirectly self-referential sentence would replace the phrase \"this sentence\" with an expression that effectively still referred to the sentence, but did not use the pronoun \"this.\"\n\nAn example will help to explain this. Suppose we define the quine of a phrase to be the quotation of the phrase followed by the phrase itself. So, the quine of:\nwould be:\nwhich, incidentally, is a true statement.\n\nNow consider the sentence:\n\nThe quotation here, plus the phrase \"when quined,\" indirectly refers to the entire sentence. The importance of this fact is that the remainder of the sentence, the phrase \"makes quite a statement,\" can now make a statement about the sentence as a whole. If we had used a pronoun for this, we could have written something like \"this sentence makes quite a statement.\"\n\nIt seems silly to go through this trouble when pronouns will suffice (and when they make more sense to the casual reader), but in systems of mathematical logic, there is generally no analog of the pronoun. It is somewhat surprising, in fact, that self-reference can be achieved at all in these systems.\n\nUpon closer inspection, it can be seen that in fact, the Scheme example above uses a quine, and f(x) is actually the quine function itself.\n\nIndirect self-reference was studied in great depth by W. V. Quine (after whom the operation above is named), and occupies a central place in the proof of Gödel's incompleteness theorem. Among the paradoxical statements developed by Quine is the following:\n\n"}
{"id": "17878314", "url": "https://en.wikipedia.org/wiki?curid=17878314", "title": "Information source", "text": "Information source\n\nAn information source is a person, thing, or place from which information comes, arises, or is obtained. Information souces can be known as primary or secondary. That source might then inform a person about something or provide knowledge about it. Information sources are divided into separate distinct categories, primary, secondary, tertiary, and so on.\n\n"}
{"id": "9549311", "url": "https://en.wikipedia.org/wiki?curid=9549311", "title": "Integrative and Comparative Biology", "text": "Integrative and Comparative Biology\n\nIntegrative and Comparative Biology is the scientific journal for the Society for Integrative and Comparative Biology (formerly the American Society of Zoologists). Prior to volume 42 (2002), the journal was known as American Zoologist .\n\n\n"}
{"id": "4807639", "url": "https://en.wikipedia.org/wiki?curid=4807639", "title": "Microsoft Bookshelf", "text": "Microsoft Bookshelf\n\nMicrosoft Bookshelf was a reference collection introduced in 1987 as part of Microsoft's extensive work in promoting CD-ROM technology as a distribution medium for electronic publishing. The original MS-DOS version showcased the massive storage capacity of CD-ROM technology, and was accessed while the user was using one of 13 different word processor programs that Bookshelf supported. Subsequent versions were produced for Windows and became a commercial success as part of the Microsoft Home brand. It was often bundled with personal computers as a cheaper alternative to the Encarta Suite. The Encarta Deluxe Suite / Reference Library versions also bundled Bookshelf.\n\nMicrosoft Bookshelf was discontinued in 2000. In later editions of the Encarta suite (Encarta 2000 and onwards), Bookshelf was replaced with a dedicated \"Encarta Dictionary\", a superset of the printed edition. There has been some controversy over the decision, since the dictionary lacks the other books provided in Bookshelf which many found to be a useful reference, such as the dictionary of quotations (replaced with a quotations section in \"Encarta\" that links to relevant articles and people) and the Internet Directory, although the directory is now a moot point since many of the sites listed in offline directories no longer exist.\n\nThe original 1987 edition contained \"The Original Roget's Thesaurus of English Words and Phrases\", \"The American Heritage Dictionary of the English Language\", World Almanac and Book of Facts, Bartlett's Familiar Quotations, The Chicago Manual of Style (13th Edition), the U.S. ZIP Code Directory, Houghton Mifflin Usage Alert, Houghton Mifflin Spelling Verifier and Corrector, Business Information Sources, and Forms and Letters. Titles in non-US versions of Bookshelf were different. For example, the 1997 UK edition included the Chambers Dictionary, Bloomsbury Treasury of Quotations, and Hutchinson Concise Encyclopedia.\n\nThe Windows release of Bookshelf added a number of new reference titles, including \"The Concise Columbia Encyclopedia\" and an Internet Directory. Other titles were added and some were dropped in subsequent years. By 1994, the English-language version also contained the \"Columbia Dictionary of Quotations\"; \"The Concise Columbia Encyclopedia\"; the \"Hammond Intermediate World Atlas\"; and \"The People's Chronology\". By 2000, the collection came to include the \"Encarta Desk Encyclopedia\", the \"Encarta Desk Atlas\", the \"Encarta Style Guide\" and a specialized \"Computer and Internet Dictionary\" by Microsoft Press.\n\nBookshelf 1.0 used a proprietary hypertext engine that Microsoft acquired when it bought the company Cytation in 1986. Also used for Microsoft Stat Pack and Microsoft Small Business Consultant, it was a Terminate and Stay Resident (TSR) program that ran alongside a dominant program, unbeknownst to the dominant program. Like Apple's similar Hypercard reader, Bookshelf engine's files used a single compound document, containing large numbers of subdocuments (\"cards\" or \"articles\"). They both differ from current browsers which normally treat each \"page\" or \"article\" as a separate file.\n\nThough similar to Apple's Hypercard reader in many ways, the Bookshelf engine had several key differences. Unlike Hypercard files, Bookshelf files required compilation and complex markup codes. This made the files more difficult to pirate, addressing a key concern of early electronic publishers. Furthermore, Bookshelf's engine was designed to run as fast as possible on slow first-generation CD-ROM drives, some of which required as much as a half-second to move the drive head. Such hardware constraints made Hypercard impractical for high-capacity CD-ROMs. Bookshelf also had full text searching capability, which made it easy to find needed information.\n\nCollaborating with DuPont, the Microsoft CD-ROM division developed a Windows version of its engine for applications as diverse as document management, online help, and a CD-ROM encyclopedia. In a skunkworks project, these developers worked secretly with Multimedia Division developers so that the engine would be usable for more ambitious multimedia applications. Thus they integrated a multimedia markup language, full text search, and extensibility using software objects, all of which are commonplace in modern internet browsing.\n\nIn 1992, Microsoft started selling the Bookshelf engine to third-party developers, marketing the product as Microsoft Multimedia Viewer. The idea was that such a tool would help a burgeoning growth of CD-ROM titles that would spur demand for Windows. Although the engine had multimedia capabilities that would not be matched by Web browsers until the late 1990s, Microsoft Viewer did not enjoy commercial success as a standalone product. However, Microsoft continued to use the engine for its Encarta and WinHelp applications, though the multimedia functions are rarely used in Windows help files.\n\nIn 1993, the developers who were working on the next generation viewer were moved to the Cairo systems group which was charged with delivering Bill Gates' 'vision' of 'Information at your fingertips'. This advanced browser was a fully componentized application using what are now known as Component Object Model objects, designed for hypermedia browsing across large networks and whose main competitor was thought to be Lotus Notes. Long before Netscape appeared, this team, known as the WEB (web enhanced browser) team had already shipped a network capable hypertext browser capable of doing everything that HTML browsers would not be able to do until the turn of the century. Nearly all technologies of Cairo shipped. The WEB browser was not one of them, though it influenced the design of many other common Microsoft technologies.\n\n\"BYTE\" in 1989 listed Microsoft Bookshelf as among the \"Excellence\" winners of the BYTE Awards, stating that it \"is the first substantial application of CD-ROM technology\" and \"a harbinger of personal library systems to come\".\n\n"}
{"id": "6908619", "url": "https://en.wikipedia.org/wiki?curid=6908619", "title": "Museum of Comparative Zoology", "text": "Museum of Comparative Zoology\n\nThe Museum of Comparative Zoology, full name \"The Louis Agassiz Museum of Comparative Zoology\", often abbreviated simply to \"MCZ\", is the zoology museum located on the grounds of Harvard University in Cambridge, Massachusetts. It is one of three natural history research museums at Harvard whose public face is the Harvard Museum of Natural History. Harvard MCZ's collections consist of some 21 million specimens, of which several thousand are on rotating display at the public museum. The current director of the Museum of Comparative Zoology is James Hanken, the Louis Agassiz Professor of Zoology at Harvard University.\n\nMany of the exhibits in the public museum have not only zoological interest but also historical significance. Past exhibits have included a fossil sand dollar which was found by Charles Darwin in 1834, Captain Cook's mamo, and two pheasants that once belonged to George Washington, now on loan to Mount Vernon in Virginia.\n\nThe Harvard Museum of Natural History is physically connected to the Peabody Museum of Archaeology and Ethnology; for visitors, one admission ticket grants access to both museums. The research collections of the Museum of Comparative Zoology are not open to the public.\n\nThe Museum of Comparative Zoology was founded in 1859 through the efforts of zoologist Louis Agassiz, and the museum used to be referred to as \"The Agassiz\" after its founder. Agassiz designed the collection to illustrate the variety and comparative relationships of animal life.\n\nThe Radcliffe Zoological Laboratory was created in 1894 when Radcliffe College rented a space on the fifth floor of the Museum of Comparative Zoology at Harvard University to convert into a women's laboratory. Prior to this acquisition, Radcliffe science laboratories were taught using inadequate facilities, converting spaces such as bathrooms in old houses into physics laboratories, which Harvard professors often refused to teach in.The laboratory space was converted from an office or storage closet, and was sandwiched between other invertebrate storage rooms on the fifth floor.\n\nThe museum comprises twelve departments: Biological Oceanography, Entomology, Herpetology, Ichthyology, Invertebrate Paleontology, Invertebrate Zoology, Mammalogy, Marine invertebrates, Malacology, Ornithology, Population Genetics, and Vertebrate Paleontology. The Ernst Mayr Library and its archives join in supporting the work of the museum. The Ernst Mayr Library is a founding member of the Biodiversity Heritage Library.\n\nThe museum publishes two journals: the \"Bulletin of the Museum of Comparative Zoology at Harvard College\", first published in 1869, and \"Breviora\", first published in 1956.\n\nIn contrast to numerous more modern museums, the Harvard Museum of Natural History has many hundreds of stuffed animals on display, from the collections of the Museum of Comparative Zoology. Notable exhibits include whale skeletons, the largest turtle shell ever found (eight feet long), \"the Harvard mastodon\", a long \"Kronosaurus\" skeleton, the skeleton of a dodo, and a coelacanth preserved in fluid. The two-story Great Mammal Hall was renovated in 2009 in celebration of the 150th anniversary of founding of the Museum of Comparative Zoology.\n\nNew and changing exhibitions in the Harvard Museum of Natural History include \"Evolution\" (2008); \"The Language of Color\" (2008 to 2013); \"Arthropods: Creatures that Rule\" (2006); \"New England Forests\" (2011); and \"Mollusks: Shelled Masters of the Marine Realm\" (2012).\n\n"}
{"id": "5629066", "url": "https://en.wikipedia.org/wiki?curid=5629066", "title": "Nomina sacra", "text": "Nomina sacra\n\nIn Christian scribal practice, nomina sacra (singular: nomen sacrum from Latin sacred name) is the abbreviation of several frequently occurring divine names or titles, especially in Greek manuscripts of Holy Scripture. A nomen sacrum consists of two or more letters from the original word spanned by an overline.\n\nMetzger lists 15 such expressions from Greek papyri: the Greek counterparts of \"God\", \"Lord\", \"Jesus\", \"Christ\", \"Son\", \"Spirit\", \"David\", \"Cross\", \"Mother\", \"Father\", \"Israel\", \"Savior\", \"Man\", \"Jerusalem\", and \"Heaven\". These \"nomina sacra\" are all found in Greek manuscripts of the 3rd century and earlier, except \"Mother\", which appears in the 4th.\n\n\"Nomina sacra\" also occur in some form in Latin, Coptic, Armenian (indicated by the \"pativ\"), Gothic, Old Nubian, and Cyrillic (indicated by the \"titlo\").\n\n\"Nomina sacra\" are consistently observed in even the earliest extant Christian writings, along with the codex form rather than the roll, implying that when these were written, in approximately the second century, the practice had already been established for some time. However, it is not known precisely when and how the \"nomina sacra\" first arose.\n\nThe initial system of \"nomina sacra\" apparently consisted of just four or five words, called \"nomina divina\": the Greek words for \"Jesus\", \"Christ\", \"Lord\", \"God\", and possibly \"Spirit\". The practice quickly expanded to a number of other words regarded as sacred.\n\nIn the system of \"nomina sacra\" that came to prevail, abbreviation is by \"contraction\", meaning that the first and last letter (at least) of each word are used. In a few early cases, an alternate practice is seen of abbreviation by \"suspension\", meaning that the initial two letters (at least) of the word are used; e.g., the opening verses of Revelation in write (\"Jesus Christ\") as . Contraction, however, offered the practical advantage of indicating the case of the abbreviated noun.\n\nIt is evident that the use of \"nomina sacra\" was an act of reverence rather than a purely practical space-saving device, as they were employed even where well-established abbreviations of far more frequent words such as \"and\" were avoided, and the \"nomen sacrum\" itself was written with generous spacing. Furthermore, early scribes often distinguished between mundane and sacred occurrences of the same word, e.g. a \"spirit\" vs. the \"Spirit\", and applied \"nomina sacra\" only to the latter (at times necessarily revealing an exegetical choice), although later scribes would mechanically abbreviate all occurrences.\n\nScholars have advanced a number of theories on the origin of the \"nomina sacra\". An obvious parallel that likely offered some inspiration is the Jewish practice of writing the divine name of God, commonly rendered as Jehovah or Yahweh in English, as the Hebrew tetragrammaton (transliterated as YHWH) even in Greek Scriptures. The Septuagint manuscript LXX P.Oxy.VII.1007 uses two Paleo-Hebrew \"yodh's\" with a horizontal line through them for YHWH (an abbreviated form of the Name of God translitered as ). Pavlos Vasileiadis, a Doctor of Theology at the Aristotle University of Thessaloniki, quoting Gerard Gertoux, states that \"the subsequent use of the contracted forms of the original nomina sacra κ[ύριο]ς [()] and θ[εό]ς [()] within Christian manuscripts probably reflects the Jewish practice of replacing the Tetragrammaton by י[הו]ה.\", transliterated in koine Greek as ιά.\n\nGreek culture also employed a number of ways of abbreviating even proper names, though none in quite the same form as the \"nomina sacra\". Inspiration for the contracted forms (using the first and last letter) has also been seen in Revelation, where Jesus speaks of himself as \"the beginning and the end\" and \"the first and the last\" as well \"the Alpha and the Omega\". Greek numerals have been suggested as the origin of the overline spanning the whole \"nomen sacrum\", with the suspended form being simply the ordinary way of writing \"eighteen\", for example.\n\n"}
{"id": "10550174", "url": "https://en.wikipedia.org/wiki?curid=10550174", "title": "Observer's Books", "text": "Observer's Books\n\nThe Observer's Books were a series of small, pocket-sized books, published by Frederick Warne & Co in the United Kingdom from 1937 to 2003. They covered a variety of topics including hobbies, art, history and wildlife. The aim of these books was to interest the observer and they have also been popular amongst children. Some of them have become collector's items. For the dedicated collector this could be a lifetime's work as there are over 800 variations, some of which are now rare. The values of the books can vary from 50 pence to hundreds of pounds. \n\nThe books were produced with paper dust covers up until 1969. Each one had a unique pattern of squiggly lines at the top but these were not especially practical because they were easy to rip and stain. From 1970, the covers were protected with a glossy coating. These types are often referred to as \"Glossies\". From the late 1970s, Warne decided to laminate the covers to the actual books to make them sturdier and more resistant to wear.\n\nThe first Observer's guide was published in 1937, and was on the subject of British birds. This is now rare, and a mint copy with a dust cover is worth hundreds of pounds. The same year, Warne published a second Observer's book on British wild flowers. A mint copy of this book is worth around £220. When the popularity of these was recognized, several more titles were added 'uniform in the series', but during World War II production was limited due to paper and labour shortages. Even so, by 1941 Warne had published the first six Observer's books.\n\nIn 1942 a special edition book was brought out on \"airplanes\" . This book had no number in the series, as it was brought out to help people spot enemy warplanes. It was reprinted in 1943 and 1945. \n\nThe first few Observer's titles had focused on nature, but gradually subjects like geology, music and architecture were introduced. 'Spotter' titles like \"Aircraft\", \"Automobiles\" and \"Railway Locomotives\" proved popular. During the 1950s and 60s collecting sets of these books was popular among children and adults alike. \n\nWhen Warne was acquired by Penguin books in 1983, Warne brought out new editions of the Observer's books. These were slightly bigger than the original books, and were in paperback, not hardback. The same year Penguin, with permission of Warne, started printing their own, more up-to-date Observer's books. These again were slightly larger than the originals, but were hardbacks. Like the later original Observer's books, the dust covers were laminated to the actual book. There were two types of the Penguin Observer's books: Bloomsbury Observer's, and Claremont Observer's, (of which there were only 12 different editions).\n\nAfter a hiatus of 17 years, Peregrine Books published the appropriately titled \"Observer's Book of Observer's Books\" in 1999, in a format that matched the original editions and was numbered 99 so as to follow on from the last 'official' title. As the title implies, it is a guide to the series with details of its history, authors, and print-runs. As a sign of the series' popularity, this potentially obscure book has been reprinted no fewer than six times. More recently the series has been rounded up to 100 with the publication of \"Wayside and Woodland\" in 2003.\n"}
{"id": "18134289", "url": "https://en.wikipedia.org/wiki?curid=18134289", "title": "Qualitative comparative analysis", "text": "Qualitative comparative analysis\n\nIn statistics, qualitative comparative analysis (QCA) is a data analysis technique for determining which logical conclusions a data set supports. The analysis begins with listing and counting all the combinations of variables observed in the data set, followed by applying the rules of logical inference to determine which descriptive inferences or implications the data supports. The technique was originally developed by Charles Ragin in 1987.\n\nIn the case of categorical variables, QCA begins by listing and counting all types of cases which occur, where each type of case is defined by its unique combination of values of its independent and dependent variables. For instance, if there were four categorical variables of interest, {A,B,C,D}, and A and B were dichotomous (could take on two values), C could take on five values, and D could take on three, then there would be 60 possible types of observations determined by the possible combinations of variables, not all of which would necessarily occur in real life. By counting the number of observations that exist for each of the 60 unique combination of variables, QCA can determine which descriptive inferences or implications are empirically supported by a data set. Thus, the input to QCA is a data set of any size, from small-N to large-N, and the output of QCA is a set of descriptive inferences or implications the data supports.\n\nIn QCA's next step, inferential logic or Boolean algebra is used to simplify or reduce the number of inferences to the minimum set of inferences supported by the data. This reduced set of inferences is termed the \"prime implicates\" by QCA adherents. For instance, if the presence of conditions A and B is always associated with the presence of a particular value of D, regardless of the observed value of C, then the value that C takes is irrelevant. Thus, all five inferences involving A and B and any of the five values of C may be replaced by the single descriptive inference \"(A and B) implies the particular value of D\".\n\nTo establish that the prime implicants or descriptive inferences derived from the data by the QCA method are causal requires establishing the existence of causal mechanism using another method such as process tracing, formal logic, intervening variables, or established multidisciplinary knowledge. The method is used in social science and is based on the binary logic of Boolean algebra, and attempts to ensure that all possible combinations of variables that can be made across the cases under investigation are considered.\n\nThe technique of listing case types by potential variable combinations assists with case selection by making investigators aware of all possible case types that would need to be investigated, at a minimum, if they exist, in order to test a certain hypothesis or to derive new inferences from an existing data set. In situations where the available observations constitute the entire population of cases, this method alleviates the small N problem by allowing inferences to be drawn by evaluating and comparing the number of cases exhibiting each combination of variables. The small N problem arises when the number of units of analysis (e.g. countries) available is inherently limited. For example: a study where countries are the unit of analysis is limited in that are only a limited number of countries in the world (less than 200), less than necessary for some (probabilistic) statistical techniques. By maximizing the number of comparisons that can be made across the cases under investigation, causal inferences are according to Ragin possible. This technique allows the identification of multiple causal pathways and interaction effects that may not be detectable via statistical analysis that typically requires its data set to conform to one model. Thus, it is the first step to identifying subsets of a data set conforming to particular causal pathway based on the combinations of covariates prior to quantitative statistical analyses testing conformance to a model; and helps qualitative researchers to correctly limit the scope of claimed findings to the type of observations they analyze.\n\nAs this is a logical (deterministic) and not a statistical (probabilistic) technique, with \"crisp-set\" QCA (csQCA), the original application of QCA, variables can only have two values, which is problematic as the researcher has to determine the values of each variable. For example: GDP per capita has to be divided by the researcher in two categories (e.g. low = 0 and high = 1). But as this variable is essentially a continuous variable, the division will always be arbitrary. A second, related problem is that the technique does not allow an assessment of the effect of the relative strengths of the independent variables (as they can only have two values). Ragin, and other scholars such as Lasse Cronqvist, have tried to deal with these issues by developing new tools that extend QCA, such as multi-value QCA (mvQCA) and fuzzy set QCA (fsQCA). Note: Multi-value QCA is simply QCA applied to observations having categorical variables with more than two values. Crisp-Set QCA can be considered a special case of Multi-value QCA. \n\nStatistical methodologists have argued that QCA's strong assumptions render its findings both fragile and prone to type I error. Simon Hug argues that deterministic hypotheses and error-free measures are exceedingly rare in social science and uses Monte Carlo simulations to demonstrate the fragility of QCA results if either assumption is violated. Chris Krogslund, Donghyun Danny Choi, and Mathias Poertner further demonstrate that QCA results are highly sensitive to minor parametric and model-susceptibility changes and are vulnerable to type I error. Bear F. Braumoeller further explores the vulnerability of the QCA family of techniques to both type I error and multiple inference. Braumoeller also offers a formal test of the null hypothesis and demonstrates that even very convincing QCA findings may be the result of chance.\n\nQCA can be performed probabilistically or deterministically with observations of categorical variables. For instance, the existence of a descriptive inference or implication is supported deterministically by the absence of any counter-example cases to the inference; i.e. if a researcher claims condition X implies condition Y, then, deterministically, there must not exist any counterexample cases having condition X, but not condition Y. However, if the researcher wants to claim that condition X is a probabilistic 'predictor' of condition Y, in another similar set of cases, then the proportion of counterexample cases to an inference to the proportion of cases having that same combination of conditions can be set at a threshold value of for example 80% or higher. For each prime implicant that QCA outputs via its logical inference reduction process, the \"coverage\" — percentage out of all observations that exhibit that implication or inference — and the \"consistency\" — the percentage of observations conforming to that combination of variables having that particular value of the dependent variable or outcome — are calculated and reported, and can be used as indicators of the strength of such a explorative probabilistic inference. In real-life complex societal processes, QCA enables the identification of multiple sets of conditions that are consistently associated with a particular output value in order to explore for causal predictors.\n\nFuzzy set QCA aims to handle variables, such as GDP per capita, where the number of categories, decimal values of monetary units, becomes too large to use mvQCA, or in cases were uncertainty or ambiguity or measurement error in the classification of a case needs to be acknowledged.\n\nQCA has now become used in many more fields than political science which Ragin first developed the method for. Today the method has been used in:\n"}
{"id": "25727", "url": "https://en.wikipedia.org/wiki?curid=25727", "title": "Reference work", "text": "Reference work\n\nA reference work is a book or periodical (or its electronic equivalent) to which one can refer for information. The information is intended to be found quickly when needed. Reference works are usually \"referred\" to for particular pieces of information, rather than read beginning to end. The writing style used in these works is informative; the authors avoid use of the first person, and emphasize facts. Many reference works are compiled by a team of contributors whose work is coordinated by one or more editors rather than by an individual author. Indices are commonly provided in many types of reference work. Updated editions are usually published as needed, in some cases annually (e.g. \"Whitaker's Almanack\", \"Who's Who\"). Reference works include dictionaries, thesauruses, encyclopedias, almanacs, bibliographies, and catalogs (e.g. catalogs of libraries, museums or the works of individual artists). Many reference works are available in electronic form and can be obtained as application software, CD-ROMs, DVDs, or online through the Internet.\n\nA reference work is useful to its users if they attribute some degree of trust.\n\nIn comparison, a reference book or reference-only book in a library is one that may only be used in the library and may not be borrowed from the library. Many such books are reference works (in the first sense), which are, usually, used briefly or photocopied from, and therefore, do not need to be borrowed. Keeping reference books in the library assures that they will always be available for use on demand. Some reference-only books are too valuable to permit borrowers to take them out. Reference-only items may be shelved in a reference collection located separately from circulating items. Some libraries consist entirely, or to a large extent, of books which may not be borrowed.\n\nAn electronic resource is a piece of information that is stored electronically, which is usually found on a computer, including information that is available on the internet. Libraries offer numerous types of electronic resources, such as subject research guides, indices, electronic books and texts, electronic journals, library catalogs, reference sources, statistical sources, sound recordings, and image databases.\n\n\nSheehy's Guide is less international in its scope than Walford: \"It seems that Walford is a somewhat better balanced work than Winchell, and is certainly much more comprehensive\"--\"American Reference Books Annual\", quoted in Walford, A. J. (1981) \"Walford's Concise Guide to Reference Material\". London: Library Association ; p. 19.\n"}
{"id": "47089125", "url": "https://en.wikipedia.org/wiki?curid=47089125", "title": "Roving reference", "text": "Roving reference\n\nRoving reference, also called roaming reference, is a library service model in which, instead of being positioned at a static reference desk, a librarian moves throughout the library to locate patrons with questions or concerns and offer them help in finding or using library resources.\n\nRoving reference as a library service practice was first formalized in the late 1980s and early 1990s. A 1999 report from the International Federation of Library Associations identified several advantages and disadvantages with roving reference in the pre-mobile era. The roving model allowed librarians to engage with \"the majority of users who have questions in mind [who] do not approach the reference desk for assistance\". However, libraries reported that some staff were uncomfortable with the practice, and that there were concerns about user privacy.\n\nBeginning in the 2000s, librarians used laptops or laptop carts to engage in technology-supported roaming reference. Since the development of mobile technologies, roving reference can be facilitated with the use of such technologies, such as tablet computers, which allow librarians to readily check the online public access catalogue or the library's electronic databases while away from their desk. This has contributed to the increased popularization of roving-reference programs as supplements for more traditional reference desks. The model has also been extended to service beyond the library building (library outreach), for example in a dormitory or faculty building at an academic institution.\n"}
{"id": "56067306", "url": "https://en.wikipedia.org/wiki?curid=56067306", "title": "SDS-PAGE", "text": "SDS-PAGE\n\nSDS-PAGE (sodium dodecyl sulfate–polyacrylamide gel electrophoresis) is a variant of polyacrylamide gel electrophoresis, an analytical method in biochemistry for the separation of charged molecules in mixtures by their molecular masses in an electric field. It uses sodium dodecyl sulfate (SDS) molecules to help identify and isolate protein molecules.\n\nSDS-PAGE is a discontinuous electrophoretic system developed by Ulrich K. Laemmli which is commonly used as a method to separate proteins with molecular masses between 5 and 250 KDa. The publication describing it is the most frequently cited paper by a single author, and the second most cited overall.\n\nSDS-PAGE is an electrophoresis method that allows protein separation by mass. The medium (also referred to as ′matrix′) is a polyacrylamide-based discontinuous gel. In addition, SDS (sodium dodecyl sulfate) is used. About 1.4 grams of SDS bind to a gram of protein, corresponding to one SDS molecule per two amino acids. SDS acts as a surfactant, covering the proteins' intrinsic charge and conferring them very similar charge-to-mass ratios. The intrinsic charges of the proteins are negligible in comparison to the SDS loading, and the positive charges are also greatly reduced in the basic pH range of a separating gel. Upon application of a constant electric field, the protein migrate towards the anode, each with a different speed, depending on its mass. This simple procedure allows precise protein separation by mass.\n\nSDS tends to form spherical micelles in aqueous solutions above a certain concentration called the critical micellar concentration (CMC). Above the critical micellar concentration of 7 to 10 millimolar in solutions, the SDS simultaneously occurs as single molecules (monomer) and as micelles, below the CMC SDS occurs only as monomers in aqueous solutions. At the critical micellar concentration, a micelle consists of about 62 SDS molecules. However, only SDS monomers bind to proteins via hydrophobic interactions, whereas the SDS micelles are anionic on the outside and do not adsorb any protein. SDS is amphipathic in nature, which allows it to unfold both polar and nonpolar sections of protein structure. In SDS concentrations above 0.1 millimolar, the unfolding of proteins begins, and above 1 mM, most proteins are denatured. Due to the strong denaturing effect of SDS and the subsequent dissociation of protein complexes, quaternary structures can generally not be determined with SDS. Exceptions are e.g. proteins that were previously stabilised by covalent cross-linking and the SDS-resistant protein complexes, which are stable even in the presence of SDS (the latter, however, only at room temperature). To denature the SDS-resistant complexes a high activation energy is required, which is achieved by heating. SDS resistance is based on a metastability of the protein fold. Although the native, fully folded, SDS-resistant protein does not have sufficient stability in the presence of SDS, the chemical equilibrium of denaturation at room temperature occurs slowly. Stable protein complexes are characterised not only by SDS resistance but also by stability against proteases and an increased biological half-life.\n\nAlternatively, polyacrylamide gel electrophoresis can also be performed with the cationic surfactants CTAB in a CTAB-PAGE, or 16-BAC in a BAC-PAGE.\n\nThe SDS-PAGE method is composed of gel preparation, sample preparation, electrophoresis, protein staining or western blotting and analysis of the generated banding pattern.\n\nWhen using different buffers in the gel (discontinuous gel electrophoresis), the gels are made up to one day prior to electrophoresis, so that the diffusion does not lead to a mixing of the buffers. The gel is produced by radical polymerisation in a mold consisting of two sealed glass plates with spacers between the glass plates. In a typical mini-gel setting, the spacers have a thickness of 0.75 mm or 1.5 mm, which determines the loading capacity of the gel. For pouring the gel solution, the plates are usually clamped in a stand which temporarily seals the otherwise open underside of the glass plates with the two spacers. For the gel solution, acrylamide is mixed as gel-former (usually 4% V/V in the stacking gel and 10-12 % in the separating gel), methylenebisacrylamide as a cross-linker, stacking or separating gel buffer, water and SDS. By adding the catalyst TEMED and the radical initiator ammonium persulfate (APS) the polymerisation is started. The solution is then poured between the glass plates without creating bubbles. Depending on the amount of catalyst and radical starter and depending on the temperature, the polymerisation lasts between a quarter of an hour and several hours. The lower gel (separating gel) is poured first and covered with a few drops of a barely water-soluble alcohol (usually buffer-saturated butanol or isopropanol), which eliminates bubbles from the meniscus and protects the gel solution of the radical scavenger oxygen. After the polymerisation of the separating gel, the alcohol is discarded and the residual alcohol is removed with filter paper. After addition of APS and TEMED to the stacking gel solution, it is poured on top of the solid separation gel. Afterwards, a suitable sample comb is inserted between the glass plates without creating bubbles. The sample comb is carefully pulled out after polymerisation, leaving pockets for the sample application. For later use of proteins for protein sequencing, the gels are often prepared the day before electrophoresis to reduce reactions of unpolymerised acrylamide with cysteines in proteins.\n\nBy using a gradient mixer, gradient gels with a gradient of acrylamide (usually from 4 to 12%) can be cast, which have a larger separation range of the molecular masses. Commercial gel systems (so-called \"pre-cast gels\") usually use the buffer substance Bis-tris methane with a pH value between 6.4 and 7.2 both in the stacking gel and in the separating gel. These gels are delivered cast and ready-to-use. Since they use only one buffer (continuous gel electrophoresis) and have a nearly neutral pH, they can be stored for several weeks. The more neutral pH slows the hydrolysis and thus the decomposition of the polyacrylamide. Furthermore, there are fewer acrylamide-modified cysteines in the proteins. Due to the constant pH in collecting and separating gel there is no stacking effect. Proteins in BisTris gels can not be stained with ruthenium complexes. This gel system has a comparatively large separation range, which can be varied by using MES or MOPS in the running buffer.\n\nDuring sample preparation, the sample buffer, and thus SDS, is added in excess to the proteins, and the sample is then heated to 95 °C for five minutes, or alternatively 70°C for ten minutes. Heating disrupts the secondary and tertiary structures of the protein by disrupting hydrogen bonds and stretching the molecules. Optionally, disulfide bridges can be cleaved by reduction. For this purpose, reducing thiols such as β-mercaptoethanol (β-ME, 5% by volume), dithiothreitol (DTT, 10 millimolar) or dithioerythritol (DTE, 10 millimolar) are added to the sample buffer. After cooling to room temperature, each sample is pipetted into its own well in the gel, which was previously immersed in electrophoresis buffer in the electrophoresis apparatus.\n\nIn addition to the samples, a molecular-weight size marker is usually loaded onto the gel. This consists of proteins of known sizes and thereby allows the estimation (with an error of ± 10%) of the sizes of the proteins in the actual samples, which migrate in parallel in different tracks of the gel. The size marker is often pipetted into the first or last pocket of a gel.\n\nFor separation, the denatured samples are loaded onto a gel of polyacrylamide, which is placed in an electrophoresis buffer with suitable electrolytes. Thereafter, a voltage (usually around 100 V, 10-20 V per cm gel length) is applied, which causes a migration of negatively charged molecules through the gel in the direction of the positively charged anode. The gel acts like a sieve. Small proteins migrate relatively easily through the mesh of the gel, while larger proteins are more likely to be retained and thereby migrate more slowly through the gel, thereby allowing proteins to be separated by molecular size. The electrophoresis lasts between half an hour to several hours depending on the voltage and length of gel used.\n\nThe fastest-migrating proteins (with a molecular weight of less than 5 KDa) form the buffer front together with the anionic components of the electrophoresis buffer, which also migrate through the gel. The area of the buffer front is made visible by adding the comparatively small, anionic dye bromophenol blue to the sample buffer. Due to the relatively small molecule size of bromophenol blue, it migrates faster than proteins. By optical control of the migrating colored band, the electrophoresis can be stopped before the dye and also the samples have completely migrated through the gel and leave it.\n\nThe most commonly used method is the discontinuous SDS-PAGE. In this method, the proteins migrate first into a collecting gel with neutral pH, in which they are concentrated and then they migrate into a separating gel with basic pH, in which the actual separation takes place. Stacking and separating gels differ by different pore size (4-6 % T and 10-20 % T), ionic strength and pH values (pH 6.8 or pH 8.8). The electrolyte most frequently used is an SDS-containing Tris-glycine-chloride buffer system. At neutral pH, glycine predominantly forms the zwitterionic form, at high pH the glycines lose positive charges and become predominantly anionic. In the collection gel, the smaller, negatively charged chloride ions migrate in front of the proteins (as leading ions) and the slightly larger, negatively and partially positively charged glycinate ions migrate behind the proteins (as initial trailing ions), whereas in the comparatively basic separating gel both ions migrate in front of the proteins. The pH gradient between the stacking and separation gel buffers leads to a stacking effect at the border of the stacking gel to the separation gel, since the glycinate partially loses its slowing positive charges as the pH increases and then, as the former trailing ion, overtakes the proteins and becomes a leading ion, which causes the bands of the different proteins (visible after a staining) to become narrower and sharper - the stacking effect. For the separation of smaller proteins and peptides, the TRIS-Tricine buffer system of Schägger and von Jagow is used due to the higher spread of the proteins in the range of 0.5 to 50 KDa.\n\nAt the end of the electrophoretic separation, all proteins are sorted by size and can then be analyzed by other methods, e. g. protein staining such as Coomassie staining (most common and easy to use), silver staining (highest sensitivity), stains all staining, Amido black 10B staining, Fast green FCF staining, fluorescent stains such as epicocconone stain and SYPRO orange stain, and immunological detection such as the Western Blot. The fluorescent dyes have a comparatively higher linearity between protein quantity and color intensity of about three orders of magnitude above the detection limit, i. e. the amount of protein can be estimated by color intensity. When using the fluorescent protein dye trichloroethanol, a subsequent protein staining is omitted if it was added to the gel solution and the gel was irradiated with UV light after electrophoresis.\n\nProtein staining in the gel creates a documentable banding pattern of the various proteins. Glycoproteins have differential levels of glycosylations and adsorb SDS more unevenly at the glycosylations, resulting in broader and blurred bands. Membrane proteins, because of their transmembrane domain, are often composed of the more hydrophobic amino acids, have lower solubility in aqueous solutions, tend to bind lipids, and tend to precipitate in aqueous solutions due to hydrophobic effects when sufficient amounts of detergent are not present. This precipitation manifests itself for membrane proteins in a SDS-PAGE in \"tailing\" above the band of the transmembrane protein. In this case, more SDS can be used (by using more or more concentrated sample buffer) and the amount of protein in the sample application can be reduced. An overloading of the gel with a soluble protein creates a semicircular band of this protein (e. g. in the marker lane of the image at 66 KDa), allowing other proteins with similar molecular weights to be covered. A low contrast (as in the marker lane of the image) between bands within a lane indicates either the presence of many proteins (low purity) or, if using purified proteins and a low contrast occurs only below one band, it indicates a proteolytic degradation of the protein, which first causes degradation bands, and after further degradation produces a homogeneous color (\"smear\") below a band. The documentation of the banding pattern is usually done by photographing or scanning. For a subsequent recovery of the molecules in individual bands, a gel extraction can be performed.\n\nAfter protein staining and documentation of the banding pattern, the polyacrylamide gel can be dried for archival storage. Proteins can be extracted from it at a later date. The gel is either placed in a drying frame (with or without the use of heat) or in a vacuum dryer. The drying frame consists of two parts, one of which serves as a base for a wet cellophane film to which the gel and a one percent glycerol solution are added. Then a second wet cellophane film is applied bubble-free, the second frame part is put on top and the frame is sealed with clips. The removal of the air bubbles avoids a fragmentation of the gel during drying. The water evaporates through the cellophane film. In contrast to the drying frame, a vacuum dryer generates a vacuum and heats the gel to about 50 °C.\n\nFor a more accurate determination of the molecular weight, the relative migration distances of the individual protein bands are measured in the separating gel. The measurements are usually performed in triplicate for increased accuracy. The relative mobility (called Rf value or Rm value) is the quotient of the distance of the band of the protein and the distance of the buffer front. The distances of the bands and the buffer front are each measured from the beginning of the separation gel. The distance of the buffer front roughly corresponds to the distance of the bromophenol blue contained in the sample buffer. The relative distances of the proteins of the size marker are plotted semi-logarithmically against their known molecular weights. By comparison with the linear part of the generated graph or by a regression analysis, the molecular weight of an unknown protein can be determined by its relative mobility. Bands of proteins with glycosylations can be blurred. Proteins with many basic amino acids (e. g. histones) can lead to an overestimation of the molecular weight or even not migrate into the gel at all, because they move slower in the electrophoresis due to the positive charges or even to the opposite direction. Accordingly, many acidic amino acids can lead to accelerated migration of a protein and an underestimation of its molecular mass.\n\nThe SDS-PAGE in combination with a protein stain is widely used in biochemistry for the quick and exact separation and subsequent analysis of proteins. It has comparatively low instrument and reagent costs and is an easy-to-use method. Because of its low scalability, it is mostly used for analytical purposes and less for preparative purposes, especially when larger amounts of a protein are to be isolated.\n\nAdditionally, SDS-PAGE is used in combination with the western blot for the determination of the presence of a specific protein in a mixture of proteins - or for the analysis of post-translational modifications. Post-translational modifications of proteins can lead to a different relative mobility (i.e. a \"band shift\") or to a change in the binding of a detection antibody used in the western blot (i.e. a band disappears or appears).\n\nIn mass spectrometry of proteins, SDS-PAGE is a widely used method for sample preparation prior to spectrometry, mostly using in-gel digestion. In regards to determining the molecular mass of a protein, the SDS-PAGE is a bit more exact than an analytical ultracentrifugation, but less exact than a mass spectrometry or - ignoring post-translational modifications - a calculation of the protein molecular mass from the DNA sequence.\n\nIn medical diagnostics, SDS-PAGE is used as part of the HIV test and to evaluate proteinuria. In the HIV test, HIV proteins are separated by SDS-PAGE and subsequently detected by Western Blot with HIV-specific antibodies of the patient, if they are present in his blood serum. SDS-PAGE for proteinuria evaluates the levels of various serum proteins in the urine, e.g. Albumin, Alpha-2-macroglobulin and IgG.\n\nSDS-PAGE is the most widely used method for gel electrophoretic separation of proteins. Two-dimensional gel electrophoresis sequentially combines isoelectric focusing or BAC-PAGE with a SDS-PAGE. Native PAGE is used if native protein folding is to be maintained. For separation of membrane proteins, BAC-PAGE or CTAB-PAGE may be used as an alternative to SDS-PAGE. For electrophoretic separation of larger protein complexes, agarose gel electrophoresis can be used, e.g. the SDD-AGE. Some enzymes can be detected via their enzyme activity by zymography.\n\nWhile being one of the more precise and low-cost protein separation and analysis methods, the SDS-PAGE denatures proteins. Where non-denaturing conditions are necessary, proteins are separated by a native PAGE or different chromatographic methods with subsequent photometric quantification, for example affinity chromatography (or even tandem affinity purification), size exclusion chromatography, ion exchange chromatography. Proteins can also be separated by size in a tangential flow filtration or a ultrafiltration. Single proteins can be isolated from a mixture by affinity chromatography or by a pull-down assay. Some historically early and cost effective but crude separation methods usually based upon a series of extractions and precipitations using kosmotropic molecules, for example the ammonium sulfate precipitation and the polyethyleneglycol precipitation.\n\nIn 1948, Arne Tiselius was awarded the Nobel Prize in Chemistry for the discovery of the principle of electrophoresis as the migration of charged and dissolved atoms or molecules in an electric field. The use of a solid matrix (initially paper discs) in a zone electrophoresis improved the separation. The discontinuous electrophoresis of 1964 by L. Ornstein and B. J. Davis made it possible to improve the separation by the stacking effect. The use of cross-linked polyacrylamide hydrogels, in contrast to the previously used paper discs or starch gels, provided a higher stability of the gel and no microbial decomposition. The denaturing effect of SDS in continuous polyacrylamide gels and the consequent improvement in resolution was first described in 1965 by David F. Summers in the working group of James E. Darnell to separate poliovirus proteins. The current variant of the SDS-PAGE was described in 1970 by Ulrich K. Laemmli and initially used to characterise the proteins in the head of bacteriophage T4.\n\n"}
{"id": "23499848", "url": "https://en.wikipedia.org/wiki?curid=23499848", "title": "Secondary source", "text": "Secondary source\n\nIn scholarship, a secondary source is a document or recording that relates or discusses information originally presented elsewhere. A secondary source contrasts with a primary source, which is an original source of the information being discussed; a primary source can be a person with direct knowledge of a situation, or a document created by such a person. \n\nA secondary source is one that gives information about a primary source. In this source, the original information is selected, modified and arranged in a suitable format. Secondary sources involve generalization, analysis, interpretation, or evaluation of the original information. \nThe most accurate classification for any given source is not always obvious. \"Primary\" and \"secondary\" are relative terms, and some sources may be classified as primary or secondary, depending on how they are used. A third level, the tertiary source, such as an encyclopedia or dictionary, resembles a secondary source in that it contains analysis, but attempts to provide a broad introductory overview of a topic.\n\nInformation can be taken from a wide variety of objects, but this classification system is only useful for a class of sources that are called symbolic sources. Symbolic sources are sources that are intended to communicate information to someone. Common symbolic sources include written documents such as letters and notes, but not, for example, bits of broken pottery and scraps of food excavated from a midden, regardless of how much information can be extracted from an ancient trash heap, or how little can be extracted from a written document. \n\nMany sources can be considered either primary or secondary, depending on the context in which they are used. Moreover, the distinction between \"primary\" and \"secondary\" sources is subjective and contextual, so that precise definitions are difficult to make. For example, if a historical text discusses old documents to derive a new historical conclusion, it is considered to be a primary source for the new conclusion, but a secondary source of information found in the old documents. Other examples in which a source can be both primary and secondary include an obituary or a survey of several volumes of a journal counting the frequency of articles on a certain topic.\n\nWhether a source is regarded as primary or secondary in a given context may change, depending upon the present state of knowledge within the field. For example, if a document refers to the contents of a previous but undiscovered letter, that document may be considered \"primary\", since it is the closest known thing to an original source, but if the letter is later found, it may then be considered \"secondary\".\n\nAttempts to map or model scientific and scholarly communication need the concepts of primary, secondary and further \"levels\". One such model is the UNISIST model of information dissemination. Within such a model these concepts are defined in relation to each other, and the acceptance of this way of defining the concepts are connected to the acceptance of the model.\n\nSome other modern languages use more than one word for the English word \"source\". German usually uses \"Sekundärliteratur\" (\"secondary literature\") for secondary sources for historical facts, leaving \"Sekundärquelle\" (\"secondary source\") to historiography. A \"Sekundärquelle\" is a source which can tell about a lost \"Primärquelle\" (\"primary source\"), such as a letter quoting from minutes which are no longer known to exist, and so cannot be consulted by the historian.\n\nIn general, secondary sources are self-described as review articles or meta-analysis.\n\nPrimary source materials are typically defined as \"original research papers written by the scientists who actually conducted the study.\" An example of primary source material is the Purpose, Methods, Results, Conclusions sections of a research paper (in IMRAD style) in a scientific journal by the authors who conducted the study. In some fields, a secondary source may include a summary of the literature in the Introduction of a scientific paper, a description of what is known about a disease or treatment in a chapter in a reference book, or a synthesis written to review available literature. A survey of previous work in the field in a primary peer-reviewed source is secondary source information. This allows secondary sourcing of recent findings in areas where full review articles have not yet been published.\n\nA book review that contains the judgment of the reviewer about the book is a primary source for the reviewer's opinion, and a secondary source for the contents of the book. A summary of the book within a review is a secondary source.\n\nIn library and information sciences, secondary sources are generally regarded as those sources that summarize or add commentary to primary sources in the context of the particular information or idea under study.\n\nAn important use of secondary sources in the field of mathematics has been to make difficult mathematical ideas and proofs from primary sources more accessible to the public; in other sciences tertiary sources are expected to fulfill the introductory role.\n\nSecondary sources in history and humanities are usually books or scholarly journals, from the perspective of a later interpreter, especially by a later scholar. In the humanities, a peer reviewed article is always a secondary source.\nThe delineation of sources as primary and secondary first arose in the field of historiography, as historians attempted to identify and classify the sources of historical writing. In scholarly writing, an important objective of classifying sources is to determine the independence and reliability of sources. In original scholarly writing, historians rely on primary sources, read in the context of the scholarly interpretations.\n\nFollowing the Rankean model established by German scholarship in the 19th century, historians use archives of primary sources. Most undergraduate research projects rely on secondary source material, with perhaps snippets of primary sources.\n\nIn the legal field, source classification is important because the persuasiveness of a source usually depends upon its history. Primary sources may include cases, constitutions, statutes, administrative regulations, and other sources of binding legal authority, while secondary legal sources may include books, the headnotes of case reports, articles, and encyclopedias. Legal writers usually prefer to cite primary sources because only primary sources are authoritative and precedential, while secondary sources are only persuasive at best.\n\n\"A secondary source is a record or statement of an event or circumstance made by a non-eyewitness or by someone not closely connected with the event or circumstances, recorded or stated verbally either at or sometime after the event, or by an eye-witness at a time after the event when the fallibility of memory is an important factor.\" Consequently, according to this definition, a first-hand account written long after the event \"when the fallibility of memory is an important factor\" is a secondary source, even though it may be the first published description of that event.\n\nAn autobiography can be a secondary source in history or the humanities when used for information about topics other than its subject. For example, many first hand accounts of events in World War I written in the post-war years were influenced by the then prevailing perception of the war which was significantly different from contemporary opinion.\n\n\n"}
{"id": "28545", "url": "https://en.wikipedia.org/wiki?curid=28545", "title": "Self-reference", "text": "Self-reference\n\nSelf-reference occurs in natural or formal languages when a sentence, idea or formula refers to itself. The reference may be expressed either directly—through some intermediate sentence or formula—or by means of some encoding. In philosophy, it also refers to the ability of a subject to speak of or refer to itself: to have the kind of thought expressed by the first person nominative singular pronoun, the word \"I\" in English.\n\nSelf-reference is studied and has applications in mathematics, philosophy, computer programming, and linguistics. Self-referential statements are sometimes paradoxical, and can also be considered recursive.\n\nIn classical philosophy, paradoxes were created by self-referential concepts such as the omnipotence paradox of asking if it was possible for a being to exist so powerful that it could create a stone that it could not lift. The Epimenides paradox, 'All Cretans are liars' when uttered by an ancient Greek Cretan was one of the first recorded versions. Contemporary philosophy sometimes employs the same technique to demonstrate that a supposed concept is meaningless or ill-defined.\n\nIn mathematics and computability theory, self-reference (also known as Impredicativity) is the key concept in proving limitations of many systems. Gödel's theorem uses it to show that no formal consistent system of mathematics can ever contain all possible mathematical truths, because it cannot prove some truths about its own structure. The halting problem equivalent, in computation theory, shows that there is always some task that a computer cannot perform, namely reasoning about itself. These proofs relate to a long tradition of mathematical paradoxes such as Russell's paradox and Berry's paradox, and ultimately to classical philosophical paradoxes.\n\nIn game theory undefined behaviors can occur where two players must model each other's mental states and behaviors, leading to infinite regress.\n\nIn computer programming, self-reference occurs in reflection, where a program can read or modify its own instructions like any other data. Numerous programming languages support reflection to some extent with varying degrees of expressiveness. Additionally, self-reference is seen in recursion (related to the mathematical recurrence relation) in functional programming, where a code structure refers back to itself during computation. 'Taming' self-reference from potentially paradoxical concepts into well-behaved recursions has been one of the great successes of computer science, and is now used routinely in, for example, writing compilers using the 'meta-language' ML. Using a compiler to compile itself is known as bootstrapping. Self-modifying code is possible to write (programs which operate on themselves), both with assembler and with functional languages such as Lisp, but is generally discouraged in real-world programming. Computing hardware makes fundamental use of self-reference in flip-flops, the basic units of digital memory, which convert potentially paradoxical logical self-relations into memory by expanding their terms over time. Thinking in terms of self-reference is a pervasive part of programmer culture, with many programs and acronyms named self-referentially as a form of humor, such as GNU ('Gnu's not Unix') and PINE ('Pine is not Elm'). The GNU Hurd is named for a pair of mutually self-referential acronyms.\n\nTupper's self-referential formula is a mathematical curiosity which plots an image of its own formula.\n\nThe biology of self-replication is self-referential, as embodied by DNA and RNA replication mechanisms. Models of self-replication are found in the computational Game of life, and have inspired engineering systems such as the RepRap self-replicating 3d printer.\n\nSelf-reference occurs in literature and film when an author refers to his or her own work in the context of the work itself. Examples include Cervantes's \"Don Quixote\", Shakespeare's \"A Midsummer Night's Dream\", \"The Tempest\" and \"Twelfth Night\", Denis Diderot's \"Jacques le fataliste et son maître\", Italo Calvino's \"If on a winter's night a traveler\", many stories by Nikolai Gogol, \"Lost in the Funhouse\" by John Barth, Luigi Pirandello's \"Six Characters in Search of an Author\" and Federico Fellini's \"8½\". Perhaps the earliest example is in Homer's Iliad, where Helen of Troy laments: \"for generations still unborn/we will live in song\" (appearing in the song itself).\n\nSelf-reference in art is closely related to the concepts of breaking the fourth wall and meta-reference, which often involve self-reference. The short stories of Jorge Luis Borges play with self-reference and related paradoxes in many ways. Samuel Beckett's Krapp's Last Tape consists entirely of the protagonist listening to and making recordings of himself, mostly about other recordings. During the 1990s and 2000s filmic self-reference was a popular part of the rubber reality movement, notably in Charlie Kaufman's films Being John Malkovich and Adaptation, the latter pushing the concept arguably to its breaking point as it attempts to portray its own creation.\n\nVarious creation myths invoke self-reference to solve the problem of what created the creator. For example the Egyptian creation myth has a god swallowing his own semen to create himself. Ouroboros is a mythical dragon which eats itself.\n\nThe surrealist painter René Magritte is famous for his self-referential works. His painting \"The Treachery of Images\", includes the words \"this is not a pipe\", the truth of which depends entirely on whether the word \"ceci\" (in English, \"this\") refers to the pipe depicted—or to the painting or the word or sentence itself. M.C. Escher's art also contains many self-referential concepts such as hands drawing themselves.\n\nA word that describes itself is called an \"autological word\" (or \"autonym\"). This generally applies to adjectives, for example sesquipedalian (i.e. \"sesquipedalian\" is a sesquipedalian word), but can also apply to other parts of speech, such as TLA, as a three-letter abbreviation for \"three-letter abbreviation\".\n\nA sentence which inventories its own letters and punctuation marks is called an autogram.\n\nThere is a special case of meta-sentence in which the content of the sentence in the metalanguage and the content of the sentence in the object language are the same. Such a sentence is referring to itself. However some meta-sentences of this type can lead to paradoxes. \"This is a sentence.\" can be considered to be a self-referential meta-sentence which is obviously true. However \"This sentence is false\" is a meta-sentence which leads to a self-referential paradox. Such sentences can lead to problems, for example, in law, where statements bringing laws into existence can contradict one another or themselves. Kurt Gödel claimed to have found such a paradox in the US constitution at his citizenship ceremony.\n\nSelf-reference occasionally occurs in the media when it is required to write about itself, for example the BBC reporting on job cuts at the BBC. Notable encyclopedias may be required to feature articles about themselves, such as Wikipedia's article on Wikipedia.\n\nFumblerules are a list of rules of good grammar and writing, demonstrated through sentences that violate those very rules, such as \"Avoid cliches like the plague\" and \"Don't use no double negatives\". The term was coined in a published list of such rules by William Safire.\n\nSeveral academic disciplines are sometime required to study themselves in forms of self-reference, for example historiography (or \"meta-history\") is history's study of its own past; meta-sociology occurs when sociologists study the power structures in their own academic institutions; and meta-mathematics is the study of mathematics itself as a formal system, using its own methods. In law, self-reference may become an issue when laws are required to regulate the making of new laws, especially around constitutional issues. (The game of nomic begins as a model of this process.) The prefix \"meta\" is often used to denote this type of self-reference.\n\n\n"}
{"id": "12153317", "url": "https://en.wikipedia.org/wiki?curid=12153317", "title": "Sixpenny Library", "text": "Sixpenny Library\n\nErnest Benn Limited’s Sixpenny Library is a complete series of reference books published in the late 1920s and early 1930s. The library included over one hundred and eighty volumes. The series was edited by William Rose, who solicited current authorities in such areas as history, literature, religion, psychology, science, and economics. Some contributing authors were Hilaire Belloc, Maurice Baring, J.B. Priestley, Sir (later Lord) Robert Baden-Powell, Sir Oliver Lodge, S.V Keeling and Sir Ernest Benn himself. \"The Spectator\", in November 1927, after announcing some the latest additions to \"Messrs Benn's excellent Sixpenny Library\" devoted a further paragraph to his contribution on Trade (both of which are free to read online). Partial lists of the books published in the series can be found here and here.\n\nThe books were praised by critics for their excellence, brevity, and inexpensive price.\n"}
{"id": "3423601", "url": "https://en.wikipedia.org/wiki?curid=3423601", "title": "Stumpers-L", "text": "Stumpers-L\n\nThe Stumpers-L electronic mailing list, was a resource available for librarians and others to discuss reference questions which they were unable to answer using available resources. It was succeeded by the similar Project Wombat.\n\nStumpers-L began in 1992, created by Ann Feeney, a library school graduate student at Rosary College in River Forest, Illinois, in the United States. It was moved to Concordia University, Chicago, then back to Rosary, which was then renamed Dominican University. From 2002 to 2005 it was maintained by the Dominican University Graduate School of Library and Information Science program. At the end of 2005 Dominican University ceased hosting the list. A replacement list, known as Project Wombat, commenced in January 2006, and is hosted by Project Gutenberg.\n\nOriginally the Stumpers-L archive was a gopher resource, but migrated to the World Wide Web once the web became more universally used in the mid-1990s.\n\nTypical Stumpers-L topics include:\n\nA book of Stumpers-L questions and answers was published in 1998 by Random House, edited by Fred Shapiro of Yale and titled \"Stumpers! Answers to Hundreds of Questions That Stumped The Experts\" (). Shapiro was an active member; other prominent members include Barbara and David P. Mikkelson, the co-editors of \"Snopes.com.\n\nThe unofficial mascot of the Stumpers-L list is the wombat.\n\n"}
{"id": "1007243", "url": "https://en.wikipedia.org/wiki?curid=1007243", "title": "Tertiary source", "text": "Tertiary source\n\nA tertiary source is an index or textual consolidation of primary and secondary sources. Some tertiary sources are not to be used for academic research, unless they can also be used as secondary sources, or to find other sources.\n\nDepending on the topic of research, a scholar may use a bibliography, dictionary, or encyclopedia as either a tertiary or a secondary source. This causes difficulty in defining many sources as either one type or the other.\n\nIn some academic disciplines the differentiation between a secondary and tertiary source is relative. \n\nIn the United Nations International Scientific Information System (UNISIST) model, a secondary source is a bibliography, whereas a tertiary source is a synthesis of primary sources.\n\nAs tertiary sources, encyclopedias, textbooks, and compendia attempt to summarize, collect, and consolidate the source materials into an overview, but may also present subjective, or biased commentary and analysis (which are characteristics of secondary sources).\n\nIndexes, bibliographies, concordances, and databases may not provide much textual information, but as aggregates of primary and secondary sources, they are often considered tertiary sources. So although tertiary sources are both primary and secondary, they are more towards a secondary source because of commentary and bias.\n\nAlmanacs, travel guides, field guides, and timelines are also examples of tertiary sources.\n\nSurvey or overview articles are usually tertiary, though review articles in peer-reviewed academic journals are secondary (not be confused with film, book, etc. reviews, which are primary-source opinions).\n\nSome usually primary sources, such as user guides and manuals, are secondary or tertiary (depending on the nature of the material) when written by third parties.\n\n"}
{"id": "9032406", "url": "https://en.wikipedia.org/wiki?curid=9032406", "title": "Tupper's self-referential formula", "text": "Tupper's self-referential formula\n\nTupper's self-referential formula is a formula that visually represents itself when graphed at a specific location in the (\"x\", \"y\") plane.\n\nThe formula was defined by Jeff Tupper and appears as an example in Tupper's 2001 SIGGRAPH paper on reliable two-dimensional computer graphing algorithms.\n\nAlthough the formula is called \"self-referential\", Tupper did not name it as such.\n\nThe formula is an inequality defined as:\n\nor, as plaintext,\nwhere ⌊ ⌋ denotes the floor function, and mod is the modulo operation.\n\nLet \"k\" equal the following 543-digit integer:\n\nIf one graphs the set of points (\"x\", \"y\") in 0 ≤ \"x\" < 106 and \"k\" ≤ \"y\" < \"k\" + 17 satisfying the inequality given above, the resulting graph looks like this (the axes in this plot have been reversed, otherwise the picture would be upside-down and mirrored):\n\nThe formula is a general-purpose method of decoding a bitmap stored in the constant \"k\", and it could actually be used to draw any other image. When applied to the unbounded positive range 0 ≤ \"y\", the formula tiles a vertical swath of the plane with a pattern that contains all possible 17-pixel-tall bitmaps. One horizontal slice of that infinite bitmap depicts the drawing formula itself, but this is not remarkable, since other slices depict all other possible formulae that might fit in a 17-pixel-tall bitmap. Tupper has created extended versions of his original formula that rule out all but one slice.\n\nThe constant \"k\" is a simple monochrome bitmap image of the formula treated as a binary number and multiplied by 17. If \"k\" is divided by 17, the least significant bit encodes the upper-right corner (\"k\", 0); the 17 least significant bits encode the rightmost column of pixels; the next 17 least significant bits encode the 2nd-rightmost column, and so on.\n\n\n"}
{"id": "411562", "url": "https://en.wikipedia.org/wiki?curid=411562", "title": "Xmas", "text": "Xmas\n\nXmas is a common abbreviation of the word \"Christmas\". It is sometimes pronounced , but \"Xmas\", and variants such as \"Xtemass\", originated as handwriting abbreviations for the typical pronunciation . The \"X\" comes from the Greek letter \"Chi\", which is the first letter of the Greek word \"Χριστός\", which in English is \"Christ\".\nThe \"-mas\" part is from the Latin-derived Old English word for \"Mass\".\n\nThere is a common misconception that the word \"Xmas\" stems from a secular attempt to remove the religious tradition from Christmas by taking the \"Christ\" out of \"Christmas\", but its use dates back to the 16th century.\n\n\"Xmas\" is deprecated by some modern style guides, including those at the \"New York Times\", \"The Times\", \"The Guardian\", and the BBC. Millicent Fenwick, in the 1948 \"Vogue's Book of Etiquette\", states that \"'Xmas' should never be used\" in greeting cards. \"The Cambridge Guide to Australian English Usage\" states that the spelling should be considered informal and restricted to contexts where concision is valued, such as headlines and greeting cards. \"The Christian Writer's Manual of Style\", while acknowledging the ancient and respectful use of \"Xmas\" in the past, states that the spelling should never be used in formal writing.\n\nEarly use of \"Xmas\" includes Bernard Ward's \"History of St. Edmund's college, Old Hall\" (originally published circa 1755). An earlier version, \"X'temmas\", dates to 1551. Around 1100 the term was written as \"Xp̄es mæsse\" in the \"Anglo-Saxon Chronicle\". \"Xmas\" is found in a letter from George Woodward in 1753. Lord Byron used the term in 1811, as did Samuel Coleridge (1801) and Lewis Carroll (1864). In the United States, the fifth American edition of William Perry's \"Royal Standard English Dictionary\", published in Boston in 1800, included in its list of \"Explanations of Common Abbreviations, or Contraction of Words\" the entry: \"Xmas. Christmas.\" Oliver Wendell Holmes, Jr. used the term in a letter dated 1923. Since at least the late 19th century, \"Xmas\" has been in use in various other English-language nations. Quotations with the word can be found in texts first written in Canada, and the word has been used in Australia, and in the Caribbean. \"Merriam-Webster's Dictionary of English Usage\" stated that modern use of the term is largely limited to advertisements, headlines and banners, where its conciseness is valued. The association with commerce \"has done nothing for its reputation\", according to the dictionary.\n\nIn the United Kingdom, the former Church of England Bishop of Blackburn, Alan Chesters, recommended to his clergy that they avoid the spelling.\nIn the United States, in 1977 New Hampshire Governor Meldrim Thomson sent out a press release saying that he wanted journalists to keep the \"Christ\" in Christmas, and not call it Xmas—which he called a \"pagan\" spelling of Christmas.\n\nThe abbreviation of Christmas as \"Xmas\" is the source of disagreement among Christians who observe the holiday. \n\nThe December 1957 \"News and Views\" published by the Church League of America, a conservative organization co-founded in 1937 by George Washington Robnett, attacked the use of Xmas in an article titled \"X=The Unknown Quantity\". The claims were picked up later by Gerald L. K. Smith, who in December 1966 claimed that Xmas was a \"blasphemous omission of the name of Christ\" and that \"'X' is referred to as being symbolical of the unknown quantity.\" Smith further argued that Jews introduced Santa Claus to suppress the New Testament accounts of Jesus, and that the United Nations, at the behest of \"world Jewry\", had \"outlawed the name of Christ\". There is, however, a well documented history of use of \"Χ\" (actually a chi) as an abbreviation for \"Christ\" (Χριστός) and possibly also a symbol of the cross. The abbreviation appears on many Orthodox Christian religious icons.\n\nDennis Bratcher, writing for a website for Christians, states \"there are always those who loudly decry the use of the abbreviation 'Xmas' as some kind of blasphemy against Christ and Christianity\". Among them are evangelist Franklin Graham and CNN journalist Roland S. Martin. Graham stated in an interview: \"for us as Christians, this is one of the most holy of the holidays, the birth of our savior Jesus Christ. And for people to take Christ out of Christmas. They're happy to say merry Xmas. Let's just take Jesus out. And really, I think, a war against the name of Jesus Christ.\" Roland Martin likewise relates the use of \"Xmas\" to his growing concerns of increasing commercialization and secularization of one of Christianity's highest holy days. Bratcher posits that those who dislike abbreviating the word are unfamiliar with a long history of Christians using X in place of \"Christ\" for various purposes.\n\nThe word \"Christ\" and its compounds, including \"Christmas\", have been abbreviated in English for at least the past 1,000 years, long before the modern \"Xmas\" was commonly used. \"Christ\" was often written as \"Xρ\" or \"Xt\"; there are references in the \"Anglo-Saxon Chronicle\" as far back as 1021. This X and P arose as the uppercase forms of the Greek letters χ (Ch) and ρ (R) used in ancient abbreviations for Χριστος (Greek for \"Christ\"). The labarum, an amalgamation of the two Greek letters rendered as ☧, is a symbol often used to represent Christ in Catholic, Protestant, and Orthodox Christian Churches.\n\nThe \"Oxford English Dictionary\" (\"OED\") and the \"OED Supplement\" have cited usages of \"X-\" or \"Xp-\" for \"Christ-\" as early as 1485. The terms \"Xtian\" and less commonly \"Xpian\" have also been used for \"Christian\". The \"OED\" further cites usage of \"Xtianity\" for \"Christianity\" from 1634. According to \"Merriam-Webster's Dictionary of English Usage\", most of the evidence for these words comes from \"educated Englishmen who knew their Greek\".\n\nIn ancient Christian art, χ and χρ are abbreviations for Christ's name. In many manuscripts of the \"New Testament\" and icons, Χ is an abbreviation for Χριστος, as is XC (the first and last letters in Greek, using the lunate sigma); compare IC for Jesus in Greek.\n\nOther proper names containing the name \"Christ\" besides those mentioned above are sometimes abbreviated similarly, either as \"X\" or \"Xt\", both of which have been used historically, e.g., \"Xtopher\" or \"Xopher\" for \"Christopher\", or \"Xtina\" or \"Xina\" for the name \"Christina\".\n\nIn the 17th and 18th centuries, \"Xene\" and \"Exene\" were common spellings for the given name Christine. The American singer Christina Aguilera has sometimes gone by the name \"Xtina\". Similarly, Exene Cervenka has been a noted American singer-songwriter since 1977.\n\nThis usage of \"X\" to spell the syllable \"kris\" (rather than the sounds \"ks\") has extended to \"xtal\" for \"crystal\", and on florists' signs to \"xant\" for \"chrysanthemum\", even though these words are not etymologically related to \"Christ\": \"crystal\" comes from a Greek word meaning \"ice\" (and not even using the letter χ), and \"chrysanthemum\" comes from Greek words meaning \"golden flower\", while \"Christ\" comes from a Greek word meaning \"anointed\".\n\nIn the animated television series \"Futurama\", which is set in the 31st century, Xmas is the official name for the day formerly known as Christmas (which, in the episode \"Xmas Story\", is said to have become an \"archaic pronunciation\").\n\nIn the American version of the board game \"Monopoly\", players can draw a card from the Community Chest which reads: \"Xmas fund matures. Collect $100\".\n\n\n"}
