{"id": "1171", "url": "https://en.wikipedia.org/wiki?curid=1171", "title": "Abbreviation", "text": "Abbreviation\n\nAn abbreviation (from Latin \"brevis\", meaning \"short\" ) is a shortened form of a word or phrase. It consists of a group of letters taken from the word or phrase. For example, the word \"abbreviation\" can itself be represented by the abbreviation \"abbr.\", \"abbrv.\", or \"abbrev.\"\n\nIn strict analysis, abbreviations should not be confused with contractions, crasis, acronyms, or initialisms, with which they share some semantic and phonetic functions, though all four are connected by the term \"abbreviation\" in loose parlance.An abbreviation is a shortening by any method; a contraction is a reduction of size by the drawing together of the parts. A contraction of a word is made by omitting certain letters or syllables and bringing together the first and last letters or elements; an abbreviation may be made by omitting certain portions from the interior or by cutting off a part. A contraction is an abbreviation, but an abbreviation is not necessarily a contraction. Acronyms and initialisms are regarded as subsets of abbreviations (e.g. by the Council of Science Editors). They are abbreviations that consist of the initial letters or parts of words.\n\nAbbreviations have a long history, created so that spelling out a whole word could be avoided. This might be done to save time and space, and also to provide secrecy. Shortened words were used and initial letters were commonly used to represent words in specific applications. In classical Greece and Rome, the reduction of words to single letters was common. In Roman inscriptions, \"Words were commonly abbreviated by using the initial letter or letters of words, and most inscriptions have at least one abbreviation.\" However, \"some could have more than one meaning, depending on their context. (For example, \"A\" can be an abbreviation for many words, such as \"ager\", \"amicus\", \"annus\", \"as\", \"Aulus\", \"Aurelius\", \"aurum\" and \"avus\".)\"\n\nAbbreviations in English were frequently used from its earliest days. Manuscripts of copies of the old English poem \"Beowulf\" used many abbreviations, for example \"7\" or \"&\" for \"and\", and \"y\" for \"since\", so that \"not much space is wasted\". The standardisation of English in the 15th through 17th centuries included such a growth in the use of abbreviations. At first, abbreviations were sometimes represented with various suspension signs, not only periods. For example, sequences like ‹er› were replaced with ‹ɔ›, as in ‹mastɔ› for \"master\" and ‹exacɔbate› for \"exacerbate\". While this may seem trivial, it was symptomatic of an attempt by people manually reproducing academic texts to reduce the copy time. An example from the Oxford University Register, 1503:\n\nThe Early Modern English period, between the 15th and 17th centuries, had abbreviations like \"y\" for \"Þ\", used for the word \"the\": \"hence, by later misunderstanding, Ye Olde Tea Shoppe.\"\n\nDuring the growth of philological linguistic theory in academic Britain, abbreviating became very fashionable. The use of abbreviation for the names of J. R. R. Tolkien and his friend C. S. Lewis, and other members of the Oxford literary group known as the Inklings, are sometimes cited as symptomatic of this. Likewise, a century earlier in Boston, a fad of abbreviation started that swept the United States, with the globally popular term OK generally credited as a remnant of its influence.\n\nAfter World War II, the British greatly reduced the use of the full stop and other punctuation points after abbreviations in at least semi-formal writing, while the Americans more readily kept such use until more recently, and still maintain it more than Britons. The classic example, considered by their American counterparts quite curious, was the maintenance of the internal comma in a British organisation of secret agents called the \"Special Operations, Executive\"—\"S.O., E\"—which is not found in histories written after about 1960.\n\nBut before that, many Britons were more scrupulous at maintaining the French form. In French, the period only follows an abbreviation if the last letter in the abbreviation is \"not\" the last letter of its antecedent: \"M.\" is the abbreviation for \"monsieur\" while \"Mme\" is that for \"madame\". Like many other cross-channel linguistic acquisitions, many Britons readily took this up and followed this rule themselves, while the Americans took a simpler rule and applied it rigorously.\n\nOver the years, however, the lack of convention in some style guides has made it difficult to determine which two-word abbreviations should be abbreviated with periods and which should not. The U.S. media tend to use periods in two-word abbreviations like United States (U.S.), but not personal computer (PC) or television (TV). Many British publications have gradually done away with the use of periods in abbreviations.\n\nMinimization of punctuation in typewritten material became economically desirable in the 1960s and 1970s for the many users of carbon-film ribbons since a period or comma consumed the same length of non-reusable expensive ribbon as did a capital letter.\n\nWidespread use of electronic communication through mobile phones and the Internet during the 1990s allowed for a marked rise in colloquial abbreviation. This was due largely to increasing popularity of textual communication services such as instant- and text messaging. SMS, for instance, supports message lengths of 160 characters at most (using the GSM 03.38 character set). This brevity gave rise to an informal abbreviation scheme sometimes called Textese, with which 10% or more of the words in a typical SMS message are abbreviated. More recently Twitter, a popular social networking service, began driving abbreviation use with 140 character message limits.\n\nIn modern English, there are several conventions for abbreviations, and the choice may be confusing. The only rule universally accepted is that one should be \"consistent\", and to make this easier, publishers express their preferences in a style guide. Questions which arise include those in the following subsections.\n\nIf the original word was capitalized then the first letter of its abbreviation should retain the capital, for example Lev. for \"Leviticus\". When a word is abbreviated to more than a single letter and was originally spelled with lower case letters then there is no need for capitalization. However, when abbreviating a phrase where only the first letter of each word is taken, then all letters should be capitalized, as in YTD for \"year-to-date\", PCB for \"printed circuit board\" and FYI for \"for your information\". However, see the following section regarding abbreviations that have become common vocabulary: these are no longer written with capital letters.\n\nA period (full stop) is often used to signify an abbreviation, but opinion is divided as to when and if this should happen.\n\nAccording to Hart's Rules, the traditional rule is that abbreviations (in the narrow sense that includes only words with the ending, and not the middle, dropped) terminate with a full stop, whereas contractions (in the sense of words missing a middle part) do not, but there are exceptions. Fowler's Modern English Usage says full stops are used to mark both abbreviations and contractions, but recommends against this practice: advising them only for abbreviations and lower-case initialisms and not for upper-case initialisms and contractions.\n\nIn American English, the period is usually included regardless of whether or not it is a contraction, e.g. \"Dr.\" or \"Mrs.\". In some cases, periods are optional, as in either \"US\" or \"U.S.\" for \"United States\", \"EU\" or \"E.U.\" for \"European Union\", and \"UN\" or \"U.N.\" for \"United Nations\". There are some house styles, however—American ones included—that remove the periods from almost all abbreviations. For example:\n\nAcronyms that were originally capitalized (with or without periods) but have since entered the vocabulary as generic words are no longer written with capital letters nor with any periods. Examples are sonar, radar, lidar, laser, snafu, and scuba.\n\nToday, spaces are generally not used between single-letter abbreviations of words in the same phrase, so one almost never encounters \"U. S.\"\n\nWhen an abbreviation appears at the end of a sentence, only one period is used: \"The capital of the United States is Washington, D.C\".\n\nThere is a question about how to pluralize abbreviations, particularly acronyms. Often a writer will add an 's' following an apostrophe, as in \"PC's\". However, this style is not preferred by many style guides. For instance, Kate Turabian, writing about style in academic writings, allows for an apostrophe to form plural acronyms \"only when an abbreviation contains internal periods or both capital and lowercase letters\". Turabian would therefore prefer \"DVDs\" and \"URLs\" and \"Ph.D.'s\", while the Modern Language Association explicitly says, \"do not use an apostrophe to form the plural of an abbreviation\". Also, the American Psychological Association specifically says, \"without an apostrophe\".\n\nHowever, the 1999 style guide for \"The New York Times\" states that the addition of an apostrophe is necessary when pluralizing all abbreviations, preferring \"PC's, TV's and VCR's\".\n\nFollowing those who would generally omit the apostrophe, to form the plural of run batted in, simply add an s to the end of RBI.\n\n\nFor all other rules, see below:\n\nTo form the plural of an abbreviation, a number, or a capital letter used as a noun, simply add a lowercase \"s\" to the end. Apostrophes following decades and single letters are also common.\n\nTo indicate the plural of the abbreviation or symbol of a unit of measure, the same form is used as in the singular.\n\nWhen an abbreviation contains more than one full point, \"Hart's Rules\" recommends putting the \"s\" after the final one.\nHowever, subject to any house style or consistency requirement, the same plurals may be rendered less formally as:\n\nAccording to \"Hart's Rules\", an apostrophe may be used in rare cases where clarity calls for it, for example when letters or symbols are referred to as objects.\nHowever, the apostrophe can be dispensed with if the items are set in italics or quotes:\n\nIn Latin, and continuing to the derivative forms in European languages as well as English, single-letter abbreviations had the plural being a doubling of the letter for note-taking. Most of these deal with writing and publishing. A few longer abbreviations use this as well.\n\nPublications based in the U.S. tend to follow the style guides of \"The Chicago Manual of Style\" and the Associated Press. The U.S. Government follows a style guide published by the U.S. Government Printing Office. The National Institute of Standards and Technology sets the style for abbreviations of units.\n\nMany British publications follow some of these guidelines in abbreviation:\n\n\nWriters often use shorthand to denote units of measure. Such shorthand can be an abbreviation, such as \"in\" for \"inch\" or can be a symbol such as \"km\" for \"kilometre/kilometer\".\n\nThe shorthand \"in\" applies to English only—in Afrikaans for example, the shorthand \"dm\" is used for the equivalent Afrikaans word \"duim\". Since both \"in\" and \"dm\" are contractions of the same word, but in different languages, they are abbreviations. A symbol on the other hand, defined as \"Mark or character taken as the conventional sign of some object or idea or process\" applies the appropriate shorthand by \"substitution\" rather than by \"contraction\". Since the shorthand for kilometre/kilometer (\"\" in Portuguese or \"\" in Greek) is \"km\" in both languages and the letter \"k\" does not appear in the expansion of either translation, \"km\" is a symbol as it is a substitution rather than a contraction. It is a logogram rather than an abbreviation.\n\nIn the International System of Units (SI) manual the word \"symbol\" is used consistently to define the shorthand used to represent the various SI units of measure. The manual also defines the way in which units should be written, the principal rules being:\n\nA syllabic abbreviation is usually formed from the initial syllables of several words, such as \"Interpol\" = International\" + police\". It is a variant of the acronym. Syllabic abbreviations are usually written using lower case, sometimes starting with a capital letter, and are always pronounced as words rather than letter by letter. Syllabic abbreviations should be distinguished from portmanteaus, which combine two words without necessarily taking whole syllables from each.\n\nSyllabic abbreviations are not widely used in English. Some UK government ministries such as Ofcom (Office of Communications\") and Oftel (Office of Telecommunications\") use this style.\n\nNew York City has various neighborhoods named by syllabic abbreviation, such as Tribeca (Triangle below Canal Street\") and SoHo (South of Houston Street\"). This usage has spread into other American cities, giving SoMa, San Francisco (South of Market\") and LoDo, Denver (Lower Downtown\"), among others.\n\nOn the other hand, syllabic abbreviations prevailed both in Germany under the Nazis and in the Soviet Union for naming the plethora of new bureaucratic organisations. For example, \"Gestapo\" stands for Geheime Staats-Polizei\", or \"secret state police\". Similarly, Leninist organisations such as the \"Comintern\" (\"Communist International\") and \"Komsomol\" (Kommunisticheskii Soyuz Molodyozhi\", or \"Communist youth union\") used Russian language syllabic abbreviations. This has given syllabic abbreviations negative connotations in some countries, (as in Orwell's Newspeak), notwithstanding that such abbreviations were used in Germany even before the Nazis came to power, e.g., \"\" for \"Schutzpolizei\", and are still used, e.g. \"\" for \"\".\n\nIn the modern Russian language words like \"Minoborony\" (from Ministerstvo oborony — Ministry of Defence) and \"Minobrnauki\" (from Ministerstvo obrazovaniya i nauki — Ministry of Education and Science) are still commonly used.\n\nSyllabic abbreviations were also typical for the German language used in the German Democratic Republic, e.g. \"Stasi\" for Staatssicherheit\" (\"state security\", the secret police) or \"Vopo\" for \"Volkspolizist\" (\"people's policeman\"). Other uses are in company or product names such as Aldi, from the name of the founder, Theo Albrecht, and the German word Diskont\" (discount) or Haribo, from the name of the founder and the headquarters of the company, Hans Riegl Bonn.\n\nSyllabic abbreviations are \"de rigueur\" in Spanish; examples abound in organization names such as Pemex for Petróleos Mexicanos\" (\"Mexican Petroleums\") or Fonafifo for Fondo Nacional de Financimiento Forestal\" (National Forestry Financing Fund).\n\nEast Asian languages whose writing systems use Chinese characters form abbreviations similarly by using key Chinese characters from a term or phrase. For example, in Japanese the term for the United Nations, \"kokusai rengō\" (国際連合) is often abbreviated to \"kokuren\" (国連). (Such abbreviations are called (略語) in Japanese; see also Japanese abbreviated and contracted words). The syllabic abbreviation is frequently used for universities: for instance, \"Běidà\" (北大) for \"Běijīng Dàxué\" (北京大学, Peking University) and \"Tōdai\" (東大) for \"Tōkyō daigaku\" (東京大学, University of Tokyo). The English phrase \"Gung ho\" originated as a Chinese abbreviation.\n\nPartially syllabic abbreviations are preferred by the US Navy, as it increases readability amidst the large number of initialisms that would otherwise have to fit into the same acronyms. Hence \"DESRON 6\" is used (in the full capital form) to mean \"Destroyer Squadron 6\", while \"COMNAVAIRLANT\" would be \"Commander, Naval Air Force (in the) Atlantic.\"\n\n"}
{"id": "1230569", "url": "https://en.wikipedia.org/wiki?curid=1230569", "title": "Acronym Finder", "text": "Acronym Finder\n\nAcronym Finder (AF) is a free online searchable dictionary and database of abbreviations (acronyms, initialisms, and others) and their meanings.\n\nThe entries are classified into categories such as \"Information Technology, Military/Government, Science, Slang/Pop Culture\" etc. It also contains a database of US and Canadian postal codes. For abbreviations with multiple meanings they are listed by popularity with the most common one being listed first. it claims to have over a million \"human-edited\" and verified definitions.\n\nAcronym Finder was registered and the database put online by Michael K. Molloy of Colorado in 1997 but he began compiling it in 1985 working as a computer systems officer for the USAF. Molloy first saw the need of an acronym list while integrating computers at the Randolph Air Force Base in Texas His first acronym list running up-to 30 pages. When he had retired and put AF online in 1997, his list already had 43,000 acronyms. It began mainly as a list of Military/Government abbreviations before expanding to other areas.\n\nMolloy and his wife served as the editors of the website verifying user submissions for abbreviations and adding others they found to the database. Molloy has also provided opinions on abbreviations such as \"MSG\" which Madison Square Garden wanted as a domain name (\"msg.com\") claiming trademark to the abbreviated letters. He stated that MSG also stood for more common things such as monosodium glutamate and message among others. The Garden in the end settled out of court and came to own msg.com.\n\nThe website was maintained under Mountain Data Systems, LLC by Molloy before being sold off and eventually coming under the ownership of Farlex, Inc. publishers of Thefreedictionary.com.\n\nThe website contains a database of meanings and expansions for abbreviations, acronyms, initialisms mainly in English but includes some entries in other languages such as French, German, Spanish etc. as well. It is freely accessible. The entries are further classified into categories such as \"Information Technology, Military/Government, Science, Slang/Pop Culture\" etc. It also contains a database of US and Canadian postal codes which are shown on a Map along with location information. Abbreviations with multiple expansions are listed by popularity with the most common one being presented first, these can be sorted alphabetically as well.\n\nAnyone can contribute to the database by submitting abbreviations and their meanings, these are reviewed by an by editor and categorized before being added to the database. While the database has been described as fairly accurate errors have been found in the meanings and expansions of abbreviations. The website does not list sources for the abbreviations and their meanings but it does identify people who have contributed more than 50 abbreviations to the database.\n\nThe database only contains abbreviations and their expansions and does not list other data such as grammatical category, context, source, field of the abbreviation etc.\n\nFarlex, Inc. the current owner of the website also publishes mobile apps for the Android and iOS operating systems.\n\nAcronym Finder also includes a \"Systematic Buzz Phrase Projector\", a light-hearted tool that randomly generates jargon-like phrases and abbreviations — usually initialisms that would be unpronounceable as acronyms — and meanings from 30 cleverly chosen buzz words.\n\nThe website is supported through advertisements.\n\nThe website is listed as a quick reference tool in directories like Stanford Library, Library of Congress, USC Library. It has been cited as the largest database of acronyms and has been used in computational studies for its database.\n\nListings of abbreviations on the website have also been used as a defense that an abbreviation is in public use and cannot be trademarked. While in some trademark cases citations for AF have been accepted it has been described as an unreliable reference in others.\n\nIt has garnered criticism for the fact that anyone can submit abbreviations to the site and the content is user generated. Mike Molloy the site's original owner had defended that each submission is verified before being added to the database.\n\n"}
{"id": "3556316", "url": "https://en.wikipedia.org/wiki?curid=3556316", "title": "Apples and oranges", "text": "Apples and oranges\n\nA comparison of apples and oranges occurs when two items or groups of items are compared that cannot be practically compared.\n\nThe idiom, \"comparing apples and oranges\", refers to the apparent differences between items which are popularly thought to be incomparable or incommensurable, such as apples and oranges. The idiom may also be used to indicate that a false analogy has been made between two items, such as where an \"apple\" is faulted for not being a good \"orange\".\n\nThe idiom is not unique to English. In Quebec French, it may take the form \"comparer des pommes avec des oranges\" (to compare apples and oranges), while in European French the idiom says \"comparer des pommes et des poires\" (to compare apples and pears). In Latin American Spanish, it is usually \"comparar papas y boniatos\" (comparing potatoes and sweet potatoes) or commonly for all varieties of Spanish \"comparar peras con manzanas\" (comparing pears and apples). In some other languages the term for 'orange' derives from 'apple', suggesting not only that a direct comparison between the two is possible, but that it is implicitly present in their names. Fruit other than apples and oranges can also be compared; for example, apples and pears are compared in Danish, Dutch, German, Spanish, Swedish, Croatian, Czech, Romanian, Hungarian, Italian, Slovene, Luxembourgish, Serbian, and Turkish. In fact, in the Spanish-speaking world, a common idiom is \"sumar peras con manzanas\", that is, \"to add pears and apples\"; the same thing applies in Italian (\"sommare le mele con le pere\") and Romanian (\"a aduna merele cu perele\"). In Portuguese, the expression is \"comparar laranjas com bananas\" (compare orange to banana). In Czech, the idiom \"míchat jablka s hruškami\" literally means 'to mix apples and pears'.\n\nSome languages use completely different items, such as the Serbian \"Поредити бабе и жабе\" (comparing grandmothers and toads), or the Romanian \"baba şi mitraliera\" (the grandmother and the machine gun); \"vaca şi izmenele\" (the cow and the longjohns); or \"țiganul şi carioca\" (the gypsy and the marker), or the Welsh \"mor wahanol â mêl a menyn\" (as different as honey and butter), while some languages compare dissimilar properties of dissimilar items. For example, an equivalent Danish idiom, \"Hvad er højest, Rundetårn eller et tordenskrald?\" means \"What is highest, the Round Tower or a thunderclap?\", referring to the size of the former and the sound of the latter. In Russian, the phrase \"сравнивать тёплое с мягким\" (to compare warm and soft) is used. In Argentina, a common question is \"¿En qué se parecen el amor y el ojo del hacha?\" (What do love and the eye of an axe have in common?) and emphasizes dissimilarity between two subjects; in Colombia, a similar (though more rude) version is common: \"confundir la mierda con la pomada\" (to confuse shit with ointment). In Polish, the expression \"co ma piernik do wiatraka?\" is used, meaning \"What has (is) gingerbread to a windmill?\". In Chinese, a phrase that has the similar meaning is 风马牛不相及 (fēng mǎ niú bù xiāng jí), literally meaning \"horses and cattles won't mate with each other\", and later used to describe things that are totally unrelated and incomparable.\n\nA number of more exaggerated comparisons are sometimes made, in cases in which the speaker believes the two objects being compared are radically different. For example, \"oranges with orangutans\", \"apples with dishwashers\", and so on. In English, different fruits, such as pears, plums, or lemons are sometimes substituted for oranges in this context.\n\nSometimes the two words sound similar, for example, Romanian \"merele cu perele\" (apples and pears) and the Hungarian \"szezont a fazonnal\" (the season with the fashion).\n\nAt least two tongue-in-cheek scientific studies have been conducted on the subject, each of which concluded that apples can be compared with oranges fairly easily and on a low budget and the two fruits are quite similar.\n\nThe first study, conducted by Scott A. Sandford of the NASA Ames Research Center, used infrared spectroscopy to analyze both apples and oranges. The study, which was published in the satirical science magazine \"Annals of Improbable Research\", concluded: \"[...] the comparing apples and oranges defense should no longer be considered valid. This is a somewhat startling revelation. It can be anticipated to have a dramatic effect on the strategies used in arguments and discussions in the future.\"\n\nA second study, written by Stamford Hospital's surgeon-in-chief James Barone and published in the \"British Medical Journal,\" noted that the phrase \"apples and oranges\" was appearing with increasing frequency in the medical literature, with some notable articles comparing \"Desflurane and propofol\" and \"Salmeterol and ipratropium\" with \"apples and oranges\". The study also found that both apples and oranges were sweet, similar in size, weight, and shape, that both are grown in orchards, and both may be eaten, juiced, and so on. The only significant differences found were in terms of seeds (the study used seedless oranges), the involvement of Johnny Appleseed, and color.\n\nThe \"Annals of Improbable Research\" subsequently noted that the \"earlier investigation was done with more depth, more rigour, and, most importantly, more expensive equipment\" than the \"British Medical Journal\" study.\n\nOn April Fools' Day 2014, \"The Economist\" compared worldwide production of apples and oranges from 1983 to 2013, however noted them to be \"unrelated variables\".\n\nWhile references to comparing apples and oranges are often a rhetorical device, references to adding apples and oranges are made in the case of teaching students the proper uses of units. Here, the admonition not to \"add apples and oranges\" refers to the requirement that two quantities with different units may not be combined by addition, although they may always be combined in ratio form by multiplication, so that multiplying ratios of apples and oranges is allowed. Similarly, the concept of this distinction is often used metaphorically in elementary algebra.\n\nThe admonition is really more of a mnemonic, since in general counts of objects have no intrinsic unit and, for example, a number count of apples may be dimensionless or have dimension \"fruit\"; in either of these two cases, apples and oranges may indeed be added.\n\n"}
{"id": "398493", "url": "https://en.wikipedia.org/wiki?curid=398493", "title": "BRD (Germany)", "text": "BRD (Germany)\n\nBRD (; English: Federal Republic of Germany); () is an unofficial abbreviation commonly used between 1968 and 1990 by the communist regime of the German Democratic Republic (East Germany) to refer to the Federal Republic of Germany, informally known at the time as West Germany. The East German regime previously used the term \"German Federal Republic\" to refer to its western counterpart.\n\nUnlike the English equivalent FRG, which was used as an IOC country code and a FIFA trigramme, the use of \"BRD\" was strongly discouraged by the authorities of the Federal Republic of Germany itself, because it was considered to be a derogatory communist term. The term was not banned by law, but its use was discouraged or forbidden in schools in Western Germany. After German reunification, the country is usually referred to simply as Germany (\"\"), and hence the need for abbreviations is greatly diminished. The most widely used abbreviation for West Germany was its ISO 3166-1 alpha-2 country code \"DE\", which has remained the country code of reunified Germany.\n\nThe official name was and is \"Bundesrepublik Deutschland\" (\"Federal Republic of Germany\"). The name, even though in the beginning referring only to the republic established in the Trizone, was to reflect a name for all of Germany, therefore it was particularly to include the term \"Deutschland\" (\"Germany\"). This corresponded to the spirit of the then West German constitution, the Basic Law, allowing all states or \"Länder\", then under Allied control, to join the new Federal Republic. In 1949 the original eleven states in the Trizone and West Berlin did so. However the latter was prevented by Allied objection on account of the city being a quadripartite allied occupation area. The Saarland joined with effect from 1 January 1957, while the \"new states\" of the East did so with effect from 3 October 1990, including reunited Berlin.\n\nTherefore, the term Germany had an importance as part of the official name, which is reflected in the naming conventions which developed in the Cold War. Starting in June 1949 the abbreviation was sometimes used in the Federal Republic of Germany without any special connotations. The initialism \"BRD\" began to enter into such regular usage in West German scientific and ministerial circles, that it was added to the western edition of the German language dictionary Duden in 1967. The German Democratic Republic at first used the name \"Westdeutschland\" or \"West Germany\" (abbreviated \"WD\") for the Federal Republic of Germany, but since the 1950s the East German government insisted on calling West Germany \"Deutsche Bundesrepublik\" or \"German Federal Republic\" (abbreviated \"DBR\"), because they also considered East Germany part of Germany, and thus would not permit the West German government to use the name \"Germany\".\n\nThis changed in 1968 with the new constitution of the German Democratic Republic. The communists no longer strove for German reunification, and the name \"BRD\" was introduced as a propaganda counter-term to the term \"DDR\", trying to express the equality of the states. Conversely, the West would speak of the \"sogenannte DDR\" or \"so-called 'DDR'\" when it had to be belittled.\n\nAt that time, the initialism \"BRD\" had been adopted by \"Neues Deutschland\", the ruling Socialist Unity Party's daily newspaper, while East German official sources adopted that initialism as standard in 1973.\n\nThe East German decision to abandon the idea of a single German nation was accompanied by omitting the terms \"Deutschland\" (\"Germany\") and \"deutsch\" (\"German\") in a number of terms, for example:\n\n\nHowever, the ruling party's full name, \"Sozialistische Einheitspartei Deutschlands\" or \"Socialist Unity Party of Germany\" remained unchanged, as did that of its newspaper \"Neues Deutschland\" (\"New Germany\") .\nTherefore, using the abbreviation \"BRD\" fitted perfectly into the official East German policy of downplaying the concept of a united Germany. In 1974, the GDR had replaced the vehicle registration code \"D\", hitherto shared with the Federal Republic, for \"DDR\" and demanded that West Germany recognise the division by likewise accepting \"BRD\". \nThis was rejected by the West, where some motorists displayed bumper stickers with the slogan \"BRD - Nein Danke!\" (\"BRD? No Thanks!\"). Thus in the West the initialism became even more objectionable and using it was often considered either unreflecting or even expressing naïve Communist sympathies.\nAs a result, the initialism reached only occasional frequency in West German parlance. In order to be precise West Germans increasingly used the terms \"Bundesrepublik\" or \"Bundesgebiet\" (\"Federal Republic\", or \"Federal Territory\") to refer to the country and \"Bundesbürger\" (\"Federal Citizen[s]\") as to its citizens, with the pertaining adjective \"bundesdeutsch\" (federally German).\n\nTo distance themselves from the term \"BRD\", until German reunification, the government of the Federal Republic of Germany and media sometimes used the abbreviations \"BR Deutschland,\" \"BR-Dt.\", \"BRDt.\",\nWest Germany had always claimed to be \"the\" Germany, and did not like the comparison to \"DDR\", or two separate German states. This claim was also reflected in the Hallstein Doctrine determining its foreign and interior policy until the early 1970s. Named after Walter Hallstein, State secretary at the Foreign Office, this was a key doctrine in the foreign policy of West Germany after 1955, which prescribed that the Federal Republic of Germany would not establish or maintain diplomatic relations with any state that recognised the GDR. Although this changed after 1973, with the Federal Republic no longer asserting an exclusive mandate over the whole of Germany, West Germany only established \"de facto\" diplomatic relations with East Germany. Under the terms of the Basic Treaty in 1972, Bonn and East Berlin exchanged \"permanent missions\", headed by \"permanent representatives\", rather than \"de jure\" embassies headed by ambassadors. Similarly, relations with the GDR were not conducted through the Foreign Office, but through a separate Federal Ministry for Intra-German Relations, to which the East German mission was accredited.\n\nIn 1965 the Federal Minister of All-German Affairs (later Intra-German Relations) issued the \"Directives for the appellation of Germany\" recommending that the use of \"BRD\" be avoided. On 31 May 1974 the heads of the federal and state governments recommended that the full name should always be used in official publications. In November 1979 the federal government informed the Bundestag that the West German public broadcasters ARD and ZDF agreed not to use the initialism.\n\nUnder the West German federal system, the states were generally responsible for school education, and by the 1970s, some of them had either already recommended omitting the initialism, or, in the case of Bavaria, forbidden it. Similarly, a decree by the educational authorities in the state of Schleswig-Holstein of 4 October 1976 declared the term to be \"nicht wünschenswert\" or \"undesirable\". The conference of all the states ministers for school education decided on 12 February 1981 to not print the initialism in books, maps, and atlases for schools. with pupils being required to write \"Bundesrepublik Deutschland\" in full and use of the term being deemed an error. The different usages were so ingrained that one could deduce a person's or source's political leaning from the name used for West Germany, with far-left movements in the country using \"BRD\".\n\nHowever, as the Association for the German Language found, this debate on the initialism had little influence on changing the West German parlance with the usage of the initialism - in any event limited - unaffected by the debate.\n\nA similar ideological question was the question whether to use \"Berlin (West)\" (the officially preferred name) or \"West Berlin\", and even whether to write \"West Berlin\" in German as two hyphenated words - \"West-Berlin\" - or as one word - \"Westberlin\".\n\nMost Westerners called the Western sectors \"Berlin\", unless further distinction was necessary. The West German Federal government initially called West Berlin \"Groß-Berlin\" or \"Greater Berlin\", but changed this \"Berlin (West)\", although it also used the hyphenated \"West-Berlin\". However, the East German government commonly referred to it as \"Westberlin\". Starting from 31 May 1961, East Berlin was officially called \"Berlin, Hauptstadt der DDR\" (Berlin, Capital of the GDR), replacing the formerly used term \"Democratic Berlin\", or simply \"Berlin\", by East Germany, and \"Berlin (Ost)\" by the West German Federal government. Other names used by West German media included \"Ost-Berlin\" and \"Ostberlin\" (both meaning \"East Berlin\") as well as \"Ostsektor\" or \"Eastern Sector\". These different naming conventions for the divided parts of Berlin, when followed by individuals, governments, or media, commonly indicated their political leanings, with the centre-right \"Frankfurter Allgemeine Zeitung\" using \"Ost-Berlin\" and the centre-left \"Süddeutsche Zeitung\" using \"Ostberlin\".\n\nThe naming of the German Democratic Republic was also a controversial issue, West Germans at first preferring the names \"Mitteldeutschland\" (\"Middle Germany\") and \"Sowjetische Besatzungszone\" (Soviet Occupation Zone) abbreviated as \"SBZ\". This only changed under Willy Brandt when West German authorities started using the official name, \"Deutsche Demokratische Republik\" or \"DDR\", but many conservative German newspapers, like \"Bild\", owned by the Springer company, always wrote \"DDR\" in scare quotes until 1 August 1989.\n\nIn 1995, a disagreement arose between reunified Germany and newly independent Slovakia, as Germany objected to the use of the Slovak language name \"Nemecká spolková republika\" (literally \"German Federal Republic\") owing to its Cold War connotations, instead of \"Spolková republika Nemecko\". This was almost identical to the equivalent \"Spolková republika Německo\" in Czech, a language closely related to Slovak, but the Slovak authorities claimed that \"Federal Republic of Germany\" could not be translated grammatically into Slovak. However, the Slovak government had used it until the previous year, leading to suggestions in the Bratislava newspaper \"Narodna Obroda\" that they were using \"German Federal Republic\" to show their displeasure with German attitudes to the country.\n"}
{"id": "3181897", "url": "https://en.wikipedia.org/wiki?curid=3181897", "title": "Brand Book", "text": "Brand Book\n\nA Brand Book records all livestock brands registered with an organization. In the U.S. most states have branding laws that require brands to be registered before use. This may be a state agency (usually affiliated with each state's Department of Agriculture) or a private association regulated by the state. Most states with such laws have a Brand Book for the entire state. Texas, an exception, registers brands at the county level. These book are usually provided free to law enforcement personnel and County Extension Agents. Some states have their Brand Books available online.\n\nA typical Brand Book will usually have an image of the brand, the location of the brand on the animal, and the type of animal that will be branded, as well as the owner of the brand. Many Brand Books also record earmarks.\n\nBrand Books are used by law enforcement officials, brand inspectors, and association investigators to record and track livestock movement, deter loss of livestock by straying or theft, and prosecute thieves.\n\n\n"}
{"id": "6767022", "url": "https://en.wikipedia.org/wiki?curid=6767022", "title": "Carol Ballard", "text": "Carol Ballard\n\nCarol Ballard is an author of more than 80 non-fiction books. Specializing in informational books for children and teens, her focus is toward the 7- to 14-year-old group.\n\nAfter graduating from Leeds University in plant sciences, Ballard did post-graduate research and was awarded a PhD in Immunology. She has many years experience as a science teacher and co-ordinator and has written articles for teachers on various aspects of science teaching, and teachers' materials for classroon use.\n\nIn addition to her writing, Carol works as a freelance consultant for publishers on educational and scientific matters. She also has her own business, Kite Books, which produces worksheets and teachers' resources.\n\n\n"}
{"id": "1047161", "url": "https://en.wikipedia.org/wiki?curid=1047161", "title": "Chapters and verses of the Bible", "text": "Chapters and verses of the Bible\n\nThe Bible is a compilation of many shorter books written at different times by a variety of authors, and later assembled into the biblical canon. Since the early 13th century, most copies and editions of the Bible present all but the shortest of these books with divisions into chapters, generally a page or so in length. Since the mid-16th century editors have further subdivided each chapter into verses - each consisting of a few short lines or sentences. Sometimes a sentence spans more than one verse, as in the case of , and sometimes there is more than one sentence in a single verse, as in the case of .\n\nAs the chapter and verse divisions did not appear in the original texts, they form part of the paratext of the Bible.\n\nThe Jewish divisions of the Hebrew text differ at various points from those used by Christians. For instance, in Jewish tradition, the ascriptions to many Psalms are regarded as independent verses or parts of the subsequent verses, making 116 more verses, whereas established Christian practice treats each Psalm ascription as independent and unnumbered. Some chapter divisions also occur in different places, e.g. Hebrew Bibles have where Christian translations have .\n\nEarly manuscripts of the biblical texts did not contain the chapter and verse divisions in the numbered form familiar to modern readers. In antiquity Hebrew texts were divided into paragraphs (parashot) that were identified by two letters of the Hebrew alphabet. Peh פ indicated an \"open\" paragraph that began on a new line, while Samekh ס indicated a \"closed\" paragraph that began on the same line after a small space. These two letters begin the Hebrew words open (patuach\") and closed (sagoor\"), and are, themselves, open פ and closed ס. The earliest known copies of the Book of Isaiah from the Dead Sea Scrolls used parashot divisions, although they differ slightly from the Masoretic divisions. (This is different from the use of consecutive letters of the Hebrew alphabet to structure certain poetic compositions, known as acrostics, such as several of the Psalms and most of the Book of Lamentations.)\n\nThe Hebrew Bible was also divided into some larger sections. In Israel the Torah (its first five books) were divided into 154 sections so that they could be read through aloud in weekly worship over the course of three years. In Babylonia it was divided into 53 or 54 sections (Parashat ha-Shavua) so it could be read through in one year. The New Testament was divided into topical sections known as \"kephalaia\" by the fourth century. Eusebius of Caesarea divided the gospels into parts that he listed in tables or \"canons\". Neither of these systems corresponds with modern chapter divisions. (See fuller discussions below.)\n\nChapter divisions, with titles, are also found in the 9th century Tours manuscript, Paris Bibliothèque Nationale MS Lat. 3, the so-called Bible of Rorigo.\n\nArchbishop Stephen Langton and Cardinal Hugo de Sancto Caro developed different schemas for systematic division of the Bible in the early 13th century. It is the system of Archbishop Langton on which the modern chapter divisions are based.\n\nWhile chapter divisions have become nearly universal, editions of the Bible have sometimes been published without them. Such editions, which typically use thematic or literary criteria to divide the biblical books instead, include John Locke's \"Paraphrase and Notes on the Epistles of St. Paul\" (1707), Alexander Campbell's \"The Sacred Writings\" (1826), Daniel Berkeley Updike’s fourteen-volume \"The Holy Bible Containing the Old and New Testaments and the Apocrypha,\" Richard Moulton's \"The Modern Reader's Bible\" (1907), Ernest Sutherland Bates's \"The Bible Designed to Be Read as Living Literature\" (1936), \"The Books of the Bible\" (2007) from the International Bible Society (Biblica), Adam Lewis Greene’s five-volume \"Bibliotheca\" (2014), and the six-volume ESV Reader's Bible (2016) from Crossway Books.\n\nSince at least 916 the Tanakh has contained an extensive system of multiple levels of section, paragraph, and phrasal divisions that were indicated in Masoretic vocalization and cantillation markings. One of the most frequent of these was a special type of punctuation, the \"sof passuq\", symbol for a full stop or sentence break, resembling the colon (:) of English and Latin orthography. With the advent of the printing press and the translation of the Bible into English, Old Testament versifications were made that correspond predominantly with the existing Hebrew full stops, with a few isolated exceptions. Most attribute these to Rabbi Isaac Nathan ben Kalonymus's work for the first Hebrew Bible concordance around 1440.\n\nThe first person to divide New Testament chapters into verses was Italian Dominican biblical scholar Santi Pagnini (1470–1541), but his system was never widely adopted. His verse divisions in the New Testament were far longer than those known today. Robert Estienne created an alternate numbering in his 1551 edition of the Greek New Testament which was also used in his 1553 publication of the Bible in French. Estienne's system of division was widely adopted, and it is this system which is found in almost all modern Bibles. Estienne produced a 1555 Vulgate that is the first Bible to include the verse numbers integrated into the text. Before this work, they were printed in the margins.\n\nThe first English New Testament to use the verse divisions was a 1557 translation by William Whittingham (c. 1524–1579). The first Bible in English to use both chapters and verses was the Geneva Bible published shortly afterwards in 1560. These verse divisions soon gained acceptance as a standard way to notate verses, and have since been used in nearly all English Bibles and the vast majority of those in other languages. (Nevertheless, some Bibles have removed the verse numbering, including the ones noted above that also removed chapter numbers; a recent example of an edition that removed only verses, not chapters, is \"The Message: The Bible in Contemporary Language\" by Eugene H. Peterson.)\n\nThe Hebrew Masoretic text of the Bible notes several different kinds of subdivisions within the biblical books:\n\nMost important are the verse endings. According to the Talmudic tradition, the division of the text into verses is of ancient origin. In Masoretic versions of the Bible, the end of a verse is indicated by a small mark in its final word called a \"silluq\" (which means \"stop\"). Less formally, verse endings are usually also indicated by two horizontal dots following the word with a \"silluq\".\n\nThe Masoretic textual tradition also contains section endings called \"parashot\", which are usually indicated by a space within a line (a \"closed\" section) or a new line beginning (an \"open\" section). The division of the text reflected in the \"parashot\" is usually thematic. Unlike chapters, the \"parashot\" are not numbered, but some of them have special titles.\n\nIn early manuscripts (most importantly in Tiberian Masoretic manuscripts, such as the Aleppo codex), an \"open\" section may also be represented by a blank line, and a \"closed\" section by a new line that is slightly indented (the preceding line may also not be full). These latter conventions are no longer used in Torah scrolls and printed Hebrew Bibles. In this system, the one rule differentiating \"open\" and \"closed\" sections is that \"open\" sections must \"always\" start at the beginning of a new line, while \"closed\" sections \"never\" start at the beginning of a new line.\n\nAnother division of the biblical books found in the Masoretic text is the division of the \"sedarim\". This division is not thematic, but is almost entirely based upon the \"quantity\" of text. For the Torah, this division reflects the triennial cycle of reading that was practiced by the Jews of the Land of Israel.\n\nThe Byzantines also introduced a concept roughly similar to chapter divisions, called \"kephalaia\" (singular \"kephalaion\", literally meaning \"heading\"). This system, which was in place no later than the 5th century, is not identical to the present chapters. Unlike the modern chapters, which tend to be of roughly similar length, the distance from one \"kephalaion\" mark to the next varied greatly in length both within a book and from one book to the next. For example, the Sermon on the Mount, comprising three chapters in the modern system, has but one \"kephalaion\" mark, while the single modern chapter 8 of the Gospel of Matthew has several, one per miracle. Moreover, there were far fewer \"kephalaia\" in the Gospel of John than in the Gospel of Mark, even though the latter is the shorter text. In the manuscripts, the \"kephalaia\" with their numbers, their standard titles (\"titloi\") and their page numbers would be listed at the beginning of each biblical book; in the book's main body, they would be marked only with arrow-shaped or asterisk-like symbols in the margin, not in the text itself.\n\nThe titles usually referred to the first event or the first theological point of the section only, and some \"kephalaia\" are manifestly incomplete if one stops reading at the point where the next \"kephalaion\" begins (for example, the combined accounts of the miracles of the Daughter of Jairus and of the healing of the woman with a haemorrhage gets two marked \"kephalaia\", one titled \"of the daughter of the synagogue ruler\" at the beginning when the ruler approaches Jesus and one titled \"of the woman with the flow of blood\" where the woman enters the picture – well before the ruler's daughter is healed and the storyline of the previous \"kephalaion\" is thus properly concluded). Thus the \"kephalaia\" marks are rather more like a system of bookmarks or links into a continuous text, helping a reader to quickly find one of several well-known episodes, than like a true system of chapter divisions.\n\nCardinal Hugo de Sancto Caro is often given credit for first dividing the Latin Vulgate into chapters in the real sense, but it is the arrangement of his contemporary and fellow cardinal Stephen Langton who in 1205 created the chapter divisions which are used today. They were then inserted into Greek manuscripts of the New Testament in the 16th century. Robert Estienne (Robert Stephanus) was the first to number the verses within each chapter, his verse numbers entering printed editions in 1551 (New Testament) and 1571 (Hebrew Bible).\n\nThe division of the Bible into chapters and verses has received criticism from some traditionalists and modern scholars. Critics state that the text is often divided in an incoherent way, or at inappropriate rhetorical points, and that it encourages citing passages out of context. Nevertheless, the chapter and verse numbers have become indispensable as technical references for Bible study.\n\nSeveral modern publications of the Bible have eliminated numbering of chapters and verses. Biblica published such a version of the NIV in 2007 and 2011. In 2014, Crossway published the ESV Reader's Bible and \"Bibliotheca\" published a modified ASV. Projects such as Icthus also exist which strip chapter and verse numbers from existing translations.\n\nThe number of words can vary depending upon aspects such as whether the Hebrew alphabet in Psalm 119, the superscriptions listed in some of the Psalms, and the subscripts traditionally found at the end of the Pauline epistles, are included.\nExcept where stated, the following apply to the King James Version of the Bible in its modern 66-book Protestant form including the New Testament and the protocanonical Old Testament, not the deuterocanonical books.\n\n\n\n\n\n"}
{"id": "744504", "url": "https://en.wikipedia.org/wiki?curid=744504", "title": "Circular reference", "text": "Circular reference\n\nA circular reference is a series of references where the last object references the first, resulting in a closed loop.\nA circular reference is not to be confused with the logical fallacy of a circular argument. Although a circular reference will often be unhelpful and reveal no information, such as two entries in a book index referring to each other, it is not necessarily so that a circular reference is of no use. Dictionaries, for instance, must always ultimately be a circular reference since all words in a dictionary are defined in terms of other words, but a dictionary nevertheless remains a useful reference. Sentences containing circular references can still be meaningful;\n\nis circular but not without meaning. Indeed, it can be argued that self-reference is a necessary consequence of Aristotle's Law of non-contradiction, a fundamental philosophical axiom. In this view, without self-reference, logic and mathematics become impossible, or at least, lack usefulness.\n\nCircular references can appear in computer programming when one piece of code requires the result from another, but that code needs the result from the first. For example:\n\nFunction A will show the time the sun last set based on the current date, which it can obtain by calling Function B. Function B will calculate the date based on the number of times the moon has orbited the earth since the last time Function B was called. So, Function B asks Function C just how many times that is. Function C doesn't know, but can figure it out by calling Function A to get the time the sun last set.\n\nThe entire set of functions is now worthless because none of them can return any useful information whatsoever. This leads to what is technically known as a livelock. It also appears in spreadsheets when two cells require each other's result. For example, if the value in Cell A1 is to be obtained by adding 5 to the value in Cell B1, and the value in Cell B1 is to be obtained by adding 3 to the value in Cell A1, no values can be computed. (Even if the specifications are A1:=B1+5 and B1:=A1-5, there is still a circular reference. It doesn't help that, for instance, A1=3 and B1=-2 would satisfy both formulae, as there are infinitely many other possible values of A1 and B1 that can satisfy both instances.)\n\nA circular reference represents a big problem in computing.\n\nIn ISO Standard SQL circular integrity constraints are implicitly supported within a single table. Between multiple tables circular constraints (e.g. foreign keys) are permitted by defining the constraints as deferrable (See CREATE TABLE for PostgreSQL and DEFERRABLE Constraint Examples for Oracle). In that case the constraint is checked at the end of the transaction not at the time the DML statement is executed. To update a circular reference two statements can be issued in a single transaction that will satisfy both references once the transaction is committed.\n\nA distinction should be made with processes containing a circular reference between those that are incomputable and those that are an iterative calculation with a final output. The latter may fail in spreadsheets not equipped to handle them but are nevertheless still logically valid.\n\nCircular reference in worksheets can be a very useful technique for solving implicit equations such as the Colebrook equation and many others, which might otherwise require tedious Newton-Raphson algorithms in VBA or use of macros.\n\n"}
{"id": "10018490", "url": "https://en.wikipedia.org/wiki?curid=10018490", "title": "Citation Style Language", "text": "Citation Style Language\n\nThe Citation Style Language (CSL) is an open XML-based language to describe the formatting of citations and bibliographies. Reference management programs using CSL include Zotero, Mendeley and Papers.\n\nCSL was created by Bruce D'Arcus for use with OpenOffice.org, and an XSLT-based \"CiteProc\" CSL processor. CSL was further developed in collaboration with Zotero developer Simon Kornblith. Since 2008, the core development team consists of D'Arcus, Frank Bennett and Rintze Zelle.\n\nThe releases of CSL are 0.8 (March 21, 2009), 0.8.1 (February 1, 2010), 1.0 (March 22, 2010), and 1.0.1 (September 3, 2012). CSL 1.0 was a backward-incompatible release, but styles in the 0.8.1 format can be automatically updated to the CSL 1.0 format.\n\nOn its release in 2006, Zotero became the first application to adopt CSL. In 2008 Mendeley was released with CSL support, and in 2011, Papers and Qiqqa gained support for CSL-based citation formatting.\n\n\nThe CSL project maintains a CSL 1.0 style repository, which contains over 9000 styles (more than 1700 unique styles).\n\n"}
{"id": "17077434", "url": "https://en.wikipedia.org/wiki?curid=17077434", "title": "Comparative Toxicogenomics Database", "text": "Comparative Toxicogenomics Database\n\nThe Comparative Toxicogenomics Database (CTD) is a public website and research tool launched in November 2004 that curates scientific data describing relationships between chemicals/drugs, genes/proteins, diseases, taxa, phenotypes, GO annotations, pathways, and interaction modules.\nThe database is maintained by the Department of Biological Sciences at North Carolina State University.\n\nThe Comparative Toxicogenomics Database (CTD) is a public website and research tool that curates scientific data describing relationships between chemicals, genes/proteins, diseases, taxa, phenotypes, GO annotations, pathways, and interaction modules, launched on November 12, 2004. \nThe database is maintained by the Department of Biological Sciences at North Carolina State University.\n\nOne of the primary goals of CTD is to advance the understanding of the effects of environmental chemicals on human health on the genetic level, a field called toxicogenomics.\n\nThe etiology of many chronic diseases involves interactions between environmental factors and genes that modulate important physiological processes. Chemicals are an important component of the environment. Conditions such as asthma, cancer, diabetes, hypertension, immunodeficiency, and Parkinson's disease are known to be influenced by the environment; however, the molecular mechanisms underlying these correlations are not well understood. CTD may help resolve these mechanisms. The most up-to-date extensive list of peer-reviewed scientific articles about CTD is available at their publications page\n\nCTD is a unique resource where biocurators read the scientific literature and manually curate four types of core data:\n\n\nBy integrating the above four data sets, CTD automatically constructs putative chemical-gene-phenotype-disease networks to illuminate molecular mechanisms underlying environmentally-influenced diseases.\n\nThese inferred relationships are statistically scored and ranked and can be used by scientists and computational biologists to generate and verify testable hypotheses about toxicogenomic mechanisms and how they relate to human health.\n\nUsers can search CTD to explore scientific data for chemicals, genes, diseases, or interactions between any of these three concepts. Currently, CTD integrates toxicogenomic data for vertebrates and invertebrates.\n\nCTD integrates data from or hyperlinks to these databases:\n\n"}
{"id": "1809113", "url": "https://en.wikipedia.org/wiki?curid=1809113", "title": "Comparative biology", "text": "Comparative biology\n\nComparative biology uses natural variation and disparity to understand the patterns of life at all levels—from genes to communities—and the critical role of organisms in ecosystems. Comparative biology is a cross-lineage approach to understanding the phylogenetic history of individuals or higher taxa and the mechanisms and patterns that drives it. Comparative biology encompasses Evolutionary Biology, Systematics, Neontology, Paleontology, Ethology, Anthropology, and Biogeography as well as historical approaches to Developmental biology, Genomics, Physiology, Ecology and many other areas of the biological sciences.The comparative approach also has numerous applications in human health, genetics, biomedicine, and conservation biology. The biological relationships (phylogenies, pedigree) are important for comparative analyses and usually represented by a phylogenetic tree or cladogram to differentiate those features with single origins (Homology) from those with multiple origins (Homoplasy).\n\n"}
{"id": "16264661", "url": "https://en.wikipedia.org/wiki?curid=16264661", "title": "Comparative case", "text": "Comparative case\n\nThe comparative case (abbreviated ) is a grammatical case used in languages such as Mari and Chechen to mark a likeness to something. \n\nIt is not to be confused with the comparative degree, a much more widely used paradigm used to signify heightening of adjectives and adverbs.\n\nIn Mari, the comparative case is marked with the suffix -ла ('-la') For example, if something were to taste like fish (кол - 'kol'), the form used would be колла - 'kolla'). It is also used in regard to languages, when denoting the language a person is speaking, writing, or hearing. Then, however, the accentuation varies slightly from the standard case. Usually, the suffix is not stressed. When it is used with languages, however, it is stressed.\n\nIn Chechen, it is marked with the suffix \"-l\". For example, \"sha\" is 'ice', \"shiila\" is 'cold', and \"shal shiila\" is 'cold as ice'.\n\n"}
{"id": "2051798", "url": "https://en.wikipedia.org/wiki?curid=2051798", "title": "Comparative contextual analysis", "text": "Comparative contextual analysis\n\nComparative contextual analysis is a methodology for comparative research where contextual interrogation precedes any analysis of similarity and difference. It is a thematic process directed and designed to explore relationships of agency rather than institutional or structural frameworks. See structure and agency and theory of structuration.\n\n\n"}
{"id": "4481195", "url": "https://en.wikipedia.org/wiki?curid=4481195", "title": "Comparative cultural studies", "text": "Comparative cultural studies\n\nComparative cultural studies is a contextual approach to the study of culture in a global and intercultural context. Focus is placed on the theory, method, and application of the study process(es) rather than on the \"what\" of the object(s) of study.\n\nIn comparative cultural studies, selected tenets of comparative literature are merged with selected tenets of the field of cultural studies (including culture theories, (radical) constructivism, communication theories, and systems theories) with the objective to study culture and culture products (including but not restricted to literature, communication, media, art, etc.). This is performed in a contextual and relational construction and with a plurality of methods and approaches, interdisciplinary, and, if and when required, including teamwork. In comparative cultural studies, it is the processes of communicative action(s) in culture and the how of these processes that constitute the main objectives of research and study. However, scholarship in comparative cultural studies does not exclude textual analysis proper of other established fields of study. In comparative cultural studies, ideally, the framework of and methodologies available in the systemic and empirical study of culture are favored. Scholarship in comparative cultural studies includes the theoretical, as well as methodological and applied postulate to move and to dialogue between cultures, languages, literature, and disciplines: attention to other cultures against essentialist notions and practices and beyond the paradigm of the nation-state is a basic and founding element of the framework and its application.\n\n\n"}
{"id": "983601", "url": "https://en.wikipedia.org/wiki?curid=983601", "title": "Comparative genomic hybridization", "text": "Comparative genomic hybridization\n\nComparative genomic hybridization is a molecular cytogenetic method for analysing copy number variations (CNVs) relative to ploidy level in the DNA of a test sample compared to a reference sample, without the need for culturing cells. The aim of this technique is to quickly and efficiently compare two genomic DNA samples arising from two sources, which are most often closely related, because it is suspected that they contain differences in terms of either gains or losses of either whole chromosomes or subchromosomal regions (a portion of a whole chromosome). This technique was originally developed for the evaluation of the differences between the chromosomal complements of solid tumor and normal tissue, and has an improved resolution of 5–10 megabases compared to the more traditional cytogenetic analysis techniques of giemsa banding and fluorescence in situ hybridization (FISH) which are limited by the resolution of the microscope utilized.\n\nThis is achieved through the use of competitive fluorescence in situ hybridization. In short, this involves the isolation of DNA from the two sources to be compared, most commonly a test and reference source, independent labelling of each DNA sample with fluorophores (fluorescent molecules) of different colours (usually red and green), denaturation of the DNA so that it is single stranded, and the hybridization of the two resultant samples in a 1:1 ratio to a normal metaphase spread of chromosomes, to which the labelled DNA samples will bind at their locus of origin. Using a fluorescence microscope and computer software, the differentially coloured fluorescent signals are then compared along the length of each chromosome for identification of chromosomal differences between the two sources. A higher intensity of the test sample colour in a specific region of a chromosome indicates the gain of material of that region in the corresponding source sample, while a higher intensity of the reference sample colour indicates the loss of material in the test sample in that specific region. A neutral colour (yellow when the fluorophore labels are red and green) indicates no difference between the two samples in that location.\n\nCGH is only able to detect unbalanced chromosomal abnormalities. This is because balanced chromosomal abnormalities such as reciprocal translocations, inversions or ring chromosomes do not affect copy number, which is what is detected by CGH technologies. CGH does, however, allow for the exploration of all 46 human chromosomes in single test and the discovery of deletions and duplications, even on the microscopic scale which may lead to the identification of candidate genes to be further explored by other cytological techniques.\n\nThrough the use of DNA microarrays in conjunction with CGH techniques, the more specific form of array CGH (aCGH) has been developed, allowing for a locus-by-locus measure of CNV with increased resolution as low as 100 kilobases. This improved technique allows for the aetiology of known and unknown conditions to be discovered.\n\nThe motivation underlying the development of CGH stemmed from the fact that the available forms of cytogenetic analysis at the time (giemsa banding and FISH) were limited in their potential resolution by the microscopes necessary for interpretation of the results they provided. Furthermore, giemsa banding interpretation has the potential to be ambiguous and therefore has lowered reliability, and both techniques require high labour inputs which limits the loci which may be examined.\n\nThe first report of CGH analysis was by Kallioniemi and colleagues in 1992 at the University of California, San Francisco, who utilised CGH in the analysis of solid tumors. They achieved this by the direct application of the technique to both breast cancer cell lines and primary bladder tumors in order to establish complete copy number karyotypes for the cells. They were able to identify 16 different regions of amplification, many of which were novel discoveries.\n\nSoon after in 1993, du Manoir et al. reported virtually the same methodology. The authors painted a series of individual human chromosomes from a DNA library with two different fluorophores in different proportions to test the technique, and also applied CGH to genomic DNA from patients affected with either Downs syndrome or T-cell prolymphocytic leukemia as well as cells of a renal papillary carcinoma cell line. It was concluded that the fluorescence ratios obtained were accurate and that differences between genomic DNA from different cell types were detectable, and therefore that CGH was a highly useful cytogenetic analysis tool.\n\nInitially, the widespread use of CGH technology was difficult, as protocols were not uniform and therefore inconsistencies arose, especially due to uncertainties in the interpretation of data. However, in 1994 a review was published which described an easily understood protocol in detail and the image analysis software was made available commercially, which allowed CGH to be utilised all around the world.\nAs new techniques such as microdissection and degenerate oligonucleotide primed polymerase chain reaction (DOP-PCR) became available for the generation of DNA products, it was possible to apply the concept of CGH to smaller chromosomal abnormalities, and thus the resolution of CGH was improved.\n\nThe implementation of array CGH, whereby DNA microarrays are used instead of the traditional metaphase chromosome preparation, was pioneered by Solinas-Tolodo et al. in 1997 using tumor cells and Pinkel et al. in 1998 by use of breast cancer cells. This was made possible by the Human Genome Project which generated a library of cloned DNA fragments with known locations throughout the human genome, with these fragments being used as probes on the DNA microarray. Now probes of various origins such as cDNA, genomic PCR products and bacterial artificial chromosomes (BACs) can be used on DNA microarrays which may contain up to 2 million probes. Array CGH is automated, allows greater resolution (down to 100 kb) than traditional CGH as the probes are far smaller than metaphase preparations, requires smaller amounts of DNA, can be targeted to specific chromosomal regions if required and is ordered and therefore faster to analyse, making it far more adaptable to diagnostic uses.\n\nThe DNA on the slide is a reference sample, and is thus obtained from a karyotypically normal man or woman, though it is preferential to use female DNA as they possess two X chromosomes which contain far more genetic information than the male Y chromosome. Phytohaemagglutinin stimulated peripheral blood lymphocytes are used. 1mL of heparinised blood is added to 10ml of culture medium and incubated for 72 hours at 37 °C in an atmosphere of 5% CO. Colchicine is added to arrest the cells in mitosis, the cells are then harvested and treated with hypotonic potassium chloride and fixed in 3:1 methanol/acetic acid.\n\nOne drop of the cell suspension should then be dropped onto an ethanol cleaned slide from a distance of about 30 cm, optimally this should be carried out at room temperature at humidity levels of 60–70%. Slides should be evaluated by visualisation using a phase contrast microscope, minimal cytoplasm should be observed and chromosomes should not be overlapping and be 400–550 bands long with no separated chromatids and finally should appear dark rather than shiny. Slides then need to be air dried overnight at room temperature, and any further storage should be in groups of four at −20 °C with either silica beads or nitrogen present to maintain dryness. Different donors should be tested as hybridization may be variable. Commercially available slides may be used, but should always be tested first.\n\nStandard phenol extraction is used to obtain DNA from test or reference (karyotypically normal individual) tissue, which involves the combination of Tris-Ethylenediaminetetraacetic acid and phenol with aqueous DNA in equal amounts. This is followed by separation by agitation and centrifugation, after which the aqueous layer is removed and further treated using ether and finally ethanol precipitation is used to concentrate the DNA.\n\nMay be completed using DNA isolation kits available commercially which are based on affinity columns.\n\nPreferentially, DNA should be extracted from fresh or frozen tissue as this will be of the highest quality, though it is now possible to use archival material which is formalin fixed or paraffin wax embedded, provided the appropriate procedures are followed. 0.5-1 µg of DNA is sufficient for the CGH experiment, though if the desired amount is not obtained DOP-PCR may be applied to amplify the DNA, however it in this case it is important to apply DOP-PCR to both the test and reference DNA samples to improve reliability.\n\nNick translation is used to label the DNA and involves cutting DNA and substituting nucleotides labelled with fluorophores (direct labelling) or biotin or oxigenin to have fluophore conjugated antibodies added later (indirect labelling). It is then important to check fragment lengths of both test and reference DNA by gel electrophoresis, as they should be within the range of 500kb-1500kb for optimum hybridization.\n\nUnlabelled Life Technologies Corporation's Cot-1 DNA® (placental DNA enriched with repetitive sequences of length 50bp-100bp)is added to block normal repetitive DNA sequences, particularly at centromeres and telomeres, as these sequences, if detected, may reduce the fluorescence ratio and cause gains or losses to escape detection.\n\n8–12µl of each of labelled test and labelled reference DNA are mixed and 40 µg Cot-1 DNA® is added, then precipitated and subsequently dissolved in 6µl of hybridization mix, which contains 50% formamide to decrease DNA melting temperature and 10% dextran sulphate to increase the effective probe concentration in a saline sodium citrate (SSC) solution at a pH of 7.0.\n\nDenaturation of the slide and probes are carried out separately. The slide is submerged in 70% formamide/2xSSC for 5–10 minutes at 72 °C, while the probes are denatured by immersion in a water bath of 80 °C for 10 minutes and are immediately added to the metaphase slide preparation. This reaction is then covered with a coverslip and left for two to four days in a humid chamber at 40 °C.\n\nThe coverslip is then removed and 5 minute washes are applied, three using 2xSSC at room temperature, one at 45 °C with 0.1xSSC and one using TNT at room temperature. The reaction is then preincubated for 10 minutes then followed by a 60-minute, 37 °C incubation, three more 5 minute washes with TNT then one with 2xSSC at room temperature. The slide is then dried using an ethanol series of 70%/96%/100% before counterstaining with DAPI (0.35 μg/ml), for chromosome identification, and sealing with a coverslip.\n\nA fluorescence microscope with the appropriate filters for the DAPI stain as well as the two fluorophores utilised is required for visualisation, and these filters should also minimise the crosstalk between the fluorophores, such as narrow band pass filters. The microscope must provide uniform illumination without chromatic variation, be appropriately aligned and have a “plan” type of objective which is apochromatic and give a magnification of x63 or x100.\n\nThe image should be recorded using a camera with spatial resolution at least 0.1 µm at the specimen level and give an image of at least 600x600 pixels. The camera must also be able to integrate the image for at least 5 to 10 seconds, with a minimum photometric resolution of 8 bit.\n\nDedicated CGH software is commercially available for the image processing step, and is required to subtract background noise, remove and segment materials not of chromosomal origin, normalize the fluorescence ratio, carry out interactive karyotyping and chromosome scaling to standard length. A “relative copy number karyotype” which presents chromosomal areas of deletions or amplifications is generated by averaging the ratios of a number of high quality metaphases and plotting them along an ideogram, a diagram identifying chromosomes based on banding patterns. Interpretation of the ratio profiles is conducted either using fixed or statistical thresholds (confidence intervals). When using confidence intervals, gains or losses are identified when 95% of the fluorescence ratio does not contain 1.0.\n\nExtreme care must be taken to avoid contamination of any step involving DNA, especially with the test DNA as contamination of the sample with normal DNA will skew results closer to 1.0, thus abnormalities may go undetected. FISH, PCR and flow cytometry experiments may be employed to confirm results.\n\nArray comparative genomic hybridization (also microarray-based comparative genomic hybridization, matrix CGH, array CGH, aCGH) is a molecular cytogenetic technique for the detection of chromosomal copy number changes on a genome wide and high-resolution scale. Array CGH compares the patient's genome against a reference genome and identifies differences between the two genomes, and hence locates regions of genomic imbalances in the patient, utilizing the same principles of competitive fluorescence in situ hybridization as traditional CGH.\n\nWith the introduction of array CGH, the main limitation of conventional CGH, a low resolution, is overcome. In array CGH, the metaphase chromosomes are replaced by cloned DNA fragments (+100–200 kb) of which the exact chromosomal location is known. This allows the detection of aberrations in more detail and, moreover, makes it possible to map the changes directly onto the genomic sequence.\n\nArray CGH has proven to be a specific, sensitive, fast and highthroughput technique, with considerable advantages compared to other methods used for the analysis of DNA copy number changes making it more amenable to diagnostic applications. Using this method, copy number changes at a level of 5–10 kilobases of DNA sequences can be detected. , even high-resolution CGH (HR-CGH) arrays are accurate to detect structural variations (SV) at resolution of 200 bp. This method allows one to identify new recurrent chromosome changes such as microdeletions and duplications in human conditions such as cancer and birth defects due to chromosome aberrations.\n\nArray CGH is based on the same principle as conventional CGH. In both techniques, DNA from a reference (or control) sample and DNA from a test (or patient) sample are differentially labelled with two different fluorophores and used as probes that are cohybridized competitively onto nucleic acid targets. In conventional CGH, the target is a reference metaphase spread. In array CGH, these targets can be genomic fragments cloned in a variety of vectors (such as BACs or plasmids), cDNAs, or oligonucleotides.\n\nFigure 2. is a schematic overview of the array CGH technique. DNA from the sample to be tested is labeled with a red fluorophore (Cyanine 5) and a reference DNA sample is labeled with green fluorophore (Cyanine 3). Equal quantities of the two DNA samples are mixed and cohybridized to a DNA microarray of several thousand evenly spaced cloned DNA fragments or oligonucleotides, which have been spotted in triplicate on the array. After hybridization, digital imaging systems are used to capture and quantify the relative fluorescence intensities of each of the hybridized fluorophores. The resulting ratio of the fluorescence intensities is proportional to the ratio of the copy numbers of DNA sequences in the test and reference genomes. If the intensities of the flurochromes are equal on one probe, this region of the patient's genome is interpreted as having equal quantity of DNA in the test and reference samples; if there is an altered Cy3:Cy5 ratio this indicates a loss or a gain of the patient DNA at that specific genomic region.\n\nArray CGH has been implemented using a wide variety of techniques. Therefore, some of the advantages and limitations of array CGH are dependent on the technique chosen.\nThe initial approaches used arrays produced from large insert genomic DNA clones, such as BACs. The use of BACs provides sufficient intense signals to detect single-copy changes and to locate aberration boundaries accurately. However, initial DNA yields of isolated BAC clones are low and DNA amplification techniques are necessary. These techniques include ligation-mediated polymerase chain reaction (PCR), degenerate primer PCR using one or several sets of primers, and rolling circle amplification. Arrays can also be constructed using cDNA. These arrays currently yield a high spatial resolution, but the number of cDNAs is limited by the genes that are encoded on the chromosomes, and their sensitivity is low due to cross-hybridization. This results in the inability to detect single copy changes on a genome wide scale. The latest approach is spotting the arrays with short oligonucleotides. The amount of oligos is almost infinite, and the processing is rapid, cost-effective, and easy. Although oligonucleotides do not have the sensitivity to detect single copy changes, averaging of ratios from oligos that map next to each other on the chromosome can compensate for the reduced sensitivity. It is also possible to use arrays which have overlapping probes so that specific breakpoints may be uncovered.\n\nThere are two approaches to the design of microarrays for CGH applications: whole genome and targeted.\n\nWhole genome arrays are designed to cover the entire human genome. They often include clones that provide an extensive coverage across the genome; and arrays that have contiguous coverage, within the limits of the genome. Whole-genome arrays have been constructed mostly for research applications and have proven their outstanding worth in gene discovery. They are also very valuable in screening the genome for DNA gains and losses at an unprecedented resolution.\n\nTargeted arrays are designed for a specific region(s) of the genome for the purpose of evaluating that targeted segment. It may be designed to study a specific chromosome or chromosomal segment or to identify and evaluate specific DNA dosage abnormalities in individuals with suspected microdeletion syndromes or subtelomeric rearrangements. The crucial goal of a targeted microarray in medical practice is to provide clinically useful results for diagnosis, genetic counseling, prognosis, and clinical management of unbalanced cytogenetic abnormalities.\n\nConventional CGH has been used mainly for the identification of chromosomal regions that are recurrently lost or gained in tumors, as well as for the diagnosis and prognosis of cancer. This approach can also be used to study chromosomal aberrations in fetal and neonatal genomes. Furthermore, conventional CGH can be used in detecting chromosomal abnormalities and have been shown to be efficient in diagnosing complex abnormalities associated with human genetic disorders.\n\nCGH data from several studies of the same tumor type show consistent patterns of non-random genetic aberrations. Some of these changes appear to be common to various kinds of malignant tumors, while others are more tumor specific. For example, gains of chromosomal regions lq, 3q and 8q, as well as losses of 8p, 13q, 16q and 17p, are common to a number of tumor types, such as breast, ovarian, prostate, renal and bladder cancer (Figure. 3). Other alterations, such as 12p and Xp gains in testicular cancer, 13q gain 9q loss in bladder cancer, 14q loss in renal cancer and Xp loss in ovarian cancer are more specific, and might reflect the unique selection forces operating during cancer development in different organs. Array CGH is also frequently used in research and diagnostics of B cell malignancies, such as chronic lymphocytic leukemia.\n\nCri du Chat (CdC) is a syndrome caused by a partial deletion of the short arm of chromosome 5. Several studies have shown that conventional CGH is suitable to detect the deletion, as well as more complex chromosomal alterations. For example, Levy et al. (2002) reported an infant with a cat-like cry, the hallmark of CdC, but having an indistinct karyotype. CGH analysis revealed a loss of chromosomal material from 5p15.3 confirming the diagnosis clinically. These results demonstrate that conventional CGH is a reliable technique in detecting structural aberrations and, in specific cases, may be more efficient in diagnosing complex abnormalities.\n\nArray CGH applications are mainly directed at detecting genomic abnormalities in cancer. However, array CGH is also suitable for the analysis of DNA copy number aberrations that cause human genetic disorders. That is, array CGH is employed to uncover deletions, amplifications, breakpoints and ploidy abnormalities. Earlier diagnosis is of benefit to the patient as they may undergo appropriate treatments and counseling to improve their prognosis.\n\nGenetic alterations and rearrangements occur frequently in cancer and contribute to its pathogenesis. Detecting these aberrations by array CGH provides information on the locations of important cancer genes and can have clinical use in diagnosis, cancer classification and prognostification. However, not all of the losses of genetic material are pathogenetic, since some DNA material is physiologically lost during the rearrangement of immunoglobulin subgenes. In a recent study, array CGH has been implemented to identify regions of chromosomal aberration (copy-number variation) in several mouse models of breast cancer, leading to identification of cooperating genes during myc-induced oncogenesis.\n\nArray CGH may also be applied not only to the discovery of chromosomal abnormalities in cancer, but also to the monitoring of the progression of tumors. Differentiation between metastatic and mild lesions is also possible using FISH once the abnormalities have been identified by array CGH.\n\nPrader–Willi syndrome (PWS) is a paternal structural abnormality involving 15q11-13, while a maternal aberration in the same region causes Angelman syndrome (AS). In both syndromes, the majority of cases (75%) are the result of a 3–5 Mb deletion of the PWS/AS critical region. These small aberrations cannot be detected using cytogenetics or conventional CGH, but can be readily detected using array CGH. As a proof of principle Vissers et al. (2003) constructed a genome wide array with a 1 Mb resolution to screen three patients with known, FISH-confirmed microdeletion syndromes, including one with PWS. In all three cases, the abnormalities, ranging from 1.5 to 2.9Mb, were readily identified. Thus, array CGH was demonstrated to be a specific and sensitive approach in detecting submicroscopic aberrations.\n\nWhen using overlapping microarrays, it is also possible to uncover breakpoints involved in chromosomal aberrations.\n\nThough not yet a widely employed technique, the use of array CGH as a tool for preimplantation genetic screening is becoming an increasingly popular concept. It has the potential to detect CNVs and aneuploidy in eggs, sperm or embryos which may contribute to failure of the embryo to successfully implant, miscarriage or conditions such as Down syndrome (trisomy 21). This makes array CGH a promising tool to reduce the incidence of life altering conditions and improve success rates of IVF attempts. The technique involves whole genome amplification from a single cell which is then used in the array CGH method. It may also be used in couples carrying chromosomal translocations such as balanced reciprocal translocations or Robertsonian translocations, which have the potential to cause chromosomal imbalances in their offspring.\n\nA main disadvantage of conventional CGH is its inability to detect structural chromosomal aberrations without copy number changes, such as mosaicism, balanced chromosomal translocations, and inversions. CGH can also only detect gains and losses relative to the ploidy level. In addition, chromosomal regions with short repetitive DNA sequences are highly variable between individuals and can interfere with CGH analysis. Therefore, repetitive DNA regions like centromeres and telomeres need to be blocked with unlabeled repetitive DNA (e.g. Cot1 DNA) and/or can be omitted from screening. Furthermore, the resolution of conventional CGH is a major practical problem that limits its clinical applications. Although CGH has proven to be a useful and reliable technique in the research and diagnostics of both cancer and human genetic disorders, the applications involve only gross abnormalities. Because of the limited resolution of metaphase chromosomes, aberrations smaller than 5–10 Mb cannot be detected using conventional CGH.\nFor the detection of such abnormalities, a high-resolution technique is required.\nArray CGH overcomes many of these limitations. Array CGH is characterized by a high resolution, its major advantage with respect to conventional CGH. The standard resolution varies between 1 and 5 Mb, but can be increased up to approximately 40 kb by supplementing the array with extra clones. However, as in conventional CGH, the main disadvantage of array CGH is its inability to detect aberrations that do not result in copy number changes and is limited in its ability to detect mosaicism. The level of mosaicism that can be detected is dependent on the sensitivity and spatial resolution of the clones. At present, rearrangements present in approximately 50% of the cells is the detection limit. For the detection of such abnormalities, other techniques, such as SKY (Spectral karyotyping) or FISH have to still be used.\n\n\n"}
{"id": "9435784", "url": "https://en.wikipedia.org/wiki?curid=9435784", "title": "Comparative physiology", "text": "Comparative physiology\n\nComparative physiology is a subdiscipline of physiology that studies and exploits the diversity of functional characteristics of various kinds of organisms. It is closely related to evolutionary physiology and environmental physiology. Many universities offer undergraduate courses that cover comparative aspects of animal physiology. According to Clifford Ladd Prosser, \"Comparative Physiology\nis not so much a defined discipline as a viewpoint, a philosophy.\"\n\nOriginally, physiology focused primarily on human beings, in large part from a desire to improve medical practices. When physiologists first began comparing different species it was sometimes out of simple curiosity to understand how organisms work but also stemmed from a desire to discover basic physiological principles. This use of specific organisms convenient to study specific questions is known as the Krogh Principle.\n\nC. Ladd Prosser, a founder of modern comparative physiology, outlined a broad agenda for comparative physiology in his 1950 edited volume (see summary and discussion in Garland and Carter):\n\n1. To describe how different kinds of animals meet their needs.\n\n2. The use of physiological information to reconstruct phylogenetic relationships of organisms.\n\n3. To elucidate how physiology mediates interactions between organisms and their environments.\n\n4. To identify \"model systems\" for studying particular physiological functions.\n\n5. To use the \"kind of animal\" as an experimental variable.\n\nComparative physiologists often study organisms that live in \"extreme\" environments (e.g., deserts) because they expect to find especially clear examples of evolutionary adaptation. One example is the study of water balance in desert-inhabiting mammals, which have been found to exhibit kidney specializations.\n\nSimilarly, comparative physiologists have been attracted to \"unusual\" organisms, such as very large or small ones. As an example, of the latter, hummingbirds have been studied. As another example, giraffe have been studied because of their long necks and the expectation that this would lead to specializations related to the regulation of blood pressure. More generally, ectothermic vertebrates have been studied to determine how blood acid-base balance and pH change as body temperature changes.\n\nIn the United States, research in comparative physiology is funded by both the National Institutes of Health and the National Science Foundation.\n\nA number of scientific societies feature sections on comparative physiology, including:\n\nKnut Schmidt-Nielsen (1915–2007) was a major figure in vertebrate comparative physiology, serving on the faculty at Duke University for many years and training a large number of students (obituary). He also authored several books, including an influential text, all known for their accessible writing style.\n\nGrover C. Stephens (1925–2003) was a well-known invertebrate comparative physiologist, serving on the faculty of the University of Minnesota until becoming the founding chairman of the Department of Organismic Biology at the University of California at Irvine in 1964. He was the mentor for numerous graduate students, many of whom have gone on to further build the field (obituary). He authored several books and in addition to being an accomplished biologist was also an accomplished pianist and philosopher.\n\n\n\n"}
{"id": "2466507", "url": "https://en.wikipedia.org/wiki?curid=2466507", "title": "Comparative sociology", "text": "Comparative sociology\n\nComparative sociology involves comparison of the social processes between nation states, or across different types of society (for example capitalist and socialist). There are two main approaches to comparative sociology: some seek similarity across different countries and cultures whereas others seek variance. For example, structural Marxists have attempted to use comparative methods to discover the general processes that underlie apparently different social orderings in different societies. The danger of this approach is that the different social contexts are overlooked in the search for supposed universal structures.\n\nOne sociologist who employed comparative methods to understand variance was Max Weber, whose studies attempted to show how differences between cultures explained the different social orderings that had emerged (see for example \"The Protestant Ethic and the Spirit of Capitalism\" and Sociology of religion).\n\nThere is some debate within sociology regarding whether the label of 'comparative' is suitable. Emile Durkheim argued in \"The Rules of Sociological Method\" (1895) that all sociological research was in fact comparative since social phenomenon are always held to be typical, representative or unique, all of which imply some sort of comparison. In this sense, all sociological analysis is comparative and it has been suggested that what is normally referred to as comparative research, may be more appropriately called cross-national research.\n\n"}
{"id": "32639223", "url": "https://en.wikipedia.org/wiki?curid=32639223", "title": "Comparison of online charity donation services in the United Kingdom", "text": "Comparison of online charity donation services in the United Kingdom\n\nThe page is a comparison of notable online charity donation services in the UK.\n\nThe table below gives examples of the various transaction fees for a £10 donation using each organisation, assuming they claim back the tax for the charity using gift aid. (Charities may also be charged set-up fees and monthly fees as detailed above.)\n\n\n"}
{"id": "16759434", "url": "https://en.wikipedia.org/wiki?curid=16759434", "title": "Comparison of the Amundsen and Scott Expeditions", "text": "Comparison of the Amundsen and Scott Expeditions\n\nBetween December 1911 and January 1912, both Roald Amundsen (leading his South Pole expedition) and Robert Falcon Scott (leading the Terra Nova Expedition) reached the South Pole within a month of each other. But while Scott and his four companions died on the return journey, Amundsen's party managed to reach the geographic south pole first and subsequently return to their base camp at Framheim without loss of life, suggesting that they were better prepared for the expedition. The contrasting fates of the two teams seeking the same prize at the same time invites comparison.\n\nThe outcomes of the two expeditions were as follows.\n\nHistorically, several factors have been discussed and many contributing factors claimed, including:\n\nSullivan states that it was the last factor that probably was decisive. he states \"Man is a poor beast of burden, as was shown in the terrible experience of Scott, Shackleton, and Wilson in their thrust to the south of 1902–3. However, Scott relied chiefly on man-hauling in 1911–12 because ponies could not ascend the glacier midway to the Pole. The Norwegians correctly estimated that dog teams could go all the way. Furthermore, they used a simple plan, based on their native skill with skis and on dog-driving methods that were tried and true. In a similar fashion to the way the moon was reached by expending a succession of rocket stages and then casting each aside; the Norwegians used the same strategy, sacrificing the weaker animals along the journey to feed the other animals and the men themselves.\"\n\nScott and his financial backers saw the expedition as having a scientific basis, while also wishing to reach the pole. However, it was recognised by all involved that the South Pole was the primary objective (\"The Southern Journey involves the most important object of the Expedition\" – Scott), and had priority in terms of resources, such as the best ponies and all the dogs and motor sledges as well as involvement of the vast majority of the expedition personnel. Scott and his team knew the expedition would be judged on his attainment of the pole (\"The ... public will gauge the result of the scientific work of the expedition largely in accordance with the success or failure of the main object\" – Scott). He was prepared to make a second attempt the following year (1912–13) if this attempt failed and had Indian Army mules and additional dogs delivered in anticipation. In fact the mules were used by the team that discovered the dead bodies of Scott, Henry Robertson Bowers, and Edward Adrian Wilson in November 1912, but proved even less useful than the ponies, according to Cherry-Garrard.\n\nAmundsen's expedition was planned to reach the South Pole. This was a plan he conceived in 1909. Amundsen's expedition did conduct geographical work under Kristian Prestrud who conducted an expedition to King Edward VII Land while Amundsen was undertaking his attempt at the pole.\n\nAmundsen camped on the Ross Ice Shelf at the Bay of Whales which is 60 miles (96 km) closer to the pole than Scott's camp (which was 350 miles west of Amundsen). Amundsen had deduced that, as the Trans-Antarctic Mountains ran northwest to southeast then if he were to meet a mountain range on his route then the time spent at the high altitude of the Antarctic plateau would be less than Scott's.\nScott's base was at Cape Evans on Ross Island, with access to the Trans-Antarctic mountain range to the west, and was a better base for geological exploration. He had based his previous expedition in the same area. However, he knew it to be poor as a route to the pole as he had to start before sea ice melted and had suffered delay in returning while waiting for the sea ice to freeze. They also had to make detours around Ross Island and its known crevassed areas which meant a longer journey. The crossing of the Ross Ice Shelf was an onerous task for the ponies. Scott had advanced considerable stores across the ice shelf the year before to allow the ponies to carry lighter loads over the early passage across the ice. Even so, he had to delay the departure of the ponies until 1 November rather than 24 October when the dogs and motor sledges set off.\nConsequently, the Motor Party spent 6 days at the Mount Hooper Depot waiting for Scott to arrive.\n\nThe major comparison between Scott and Amundsen has focused on the choice of draft transport —dog versus pony/man-hauling. In fact Scott took dogs, ponies and three \"motor sledges\". Scott spent nearly seven times the amount of money on his motor sledges than on the dogs and horses combined. They were therefore a vital part of the expedition. Unfortunately, Scott decided to leave behind the engineer, Lieutenant Commander Reginald William Skelton who had created and trialled the motor sledges. This was due to the selection of Lieutenant E.R.G.R. \"Teddy\" Evans as the expedition's second in command. As Evans was junior in rank to Skelton, he insisted that Skelton could not come on the expedition. Scott agreed to this request and Skelton's experience and knowledge was lost. One of the original three motor sledges was a failure even before the expedition set out; the heavy sledge was lost through thin ice on unloading it from the ship. The two remaining motor sledges failed relatively early in the main expedition because of repeated faults. Skelton's experience might have been valuable in overcoming the failures.\n\nScott had used dogs on his first (Discovery) expedition and felt they had failed. On that journey, Scott, Shackleton, and Wilson started with three sledges and 13 dogs. But on that expedition, the men had not properly understood how to travel on snow with the use of dogs. The party had skis but were too inexperienced to make good use of them. As a result, the dogs travelled so fast that the men could not keep up with them. The Discovery expedition had to increase their loads to slow the dogs down. Additionally, the dogs were fed Norwegian dried fish, which did not agree with them and soon they began to deteriorate. The whole team of dogs eventually died (and were eaten), and the men took over hauling the sleds.\n\nScott's opinion was reinforced by Shackleton's experience on his Nimrod expedition that got to within of the pole. Shackleton used ponies. Scott planned to use ponies only to the base of the Beardmore Glacier (one-quarter of the total journey) and man-haul the rest of the journey. Scott's team had developed snow shoes for his ponies, and trials showed they could significantly increase daily progress. However, Lawrence Oates, whom Scott had made responsible for the ponies, was reluctant to use the snow shoes and Scott failed to insist on their use.\n\nThere was plenty of evidence that dogs could succeed in the achievements of William Speirs Bruce in his Arctic, Antarctic, and Scottish National Antarctic Expedition, Amundsen in the \"Gjøa\" North West passage expedition, Fridtjof Nansen's crossing of Greenland, Robert Peary's three attempts at the North Pole, Eivind Astrup's work supporting Peary, Frederick Cook's discredited North Pole expedition, and Otto Sverdrup's explorations of Ellesmere Island. Moreover, Scott ignored the direct advice he received (while attending trials of the motor sledges in Norway) from Nansen, the most famous explorer of the day, who told Scott to take \"dogs, dogs and more dogs\".\n\nAt the time of the events, the expert view in England had been that dogs were of dubious value as a means of Antarctic transport. Broadly speaking, Scott saw two ways in which dogs may be used—they may be taken with the idea of bringing them all back safe and sound, or they may be treated as pawns in the game, from which the best value is to be got regardless of their lives. He stated that if, and only if, the comparison was made with a dog sledge journey which aimed to preserve the dogs' lives, 'I am inclined to state my belief that in the polar regions properly organised parties of men will perform as extended journeys as teams of dogs.' On the other hand, if the lives of the dogs were to be sacrificed, then 'the dog-team is invested with a capacity for work which is beyond the emulation of men. To appreciate this is a matter of simple arithmetic'. But efficiency notwithstanding, he expressed \"reluctance\" to use dogs in this way: \"One cannot calmly contemplate the murder of animals which possess such intelligence and individuality, which have frequently such endearing qualities, and which very possibly one has learnt to regard as friends and companions.\"\n\nAmundsen, by contrast, took an entirely utilitarian approach. Amundsen planned from the start to have weaker animals killed to feed the other animals and the men themselves. He expressed the opinion that it was less cruel to feed and work dogs correctly before shooting them, than it would be to starve and overwork them to the point of collapse. Amundsen and his team had similar affection for their dogs as those expressed above by the English, but they \"also had agreed to shrink from nothing in order to achieve our goal\". The British thought such a procedure was distasteful, though they were willing to eat their ponies.\n\nAmundsen had used the opportunity of learning from the Inuit while on his \"Gjøa\" North West passage expedition of 1905. He recruited experienced dog drivers. To make the most of the dogs he paced them and deliberately kept daily mileages shorter than he need have for 75 percent of the journey, and his team spent up to 16 hours a day resting. His dogs could eat seals and penguins hunted in the Antarctic while Scott's pony fodder had to be brought all the way from England in their ship. It has been later shown that seal meat with the blubber attached is the ideal food for a sledge dog. Amundsen went with 52 dogs, and came back with 11.\n\nWhat Scott did not realise is a sledge dog, if it is to do the same work as a man, will require the same amount of food. Furthermore, when sledge dogs are given insufficient food they become difficult to handle. The advantage of the sledge dog is its greater mobility. Not only were the Norwegians accustomed to skiing, which enabled them to keep up with their dogs, but they also understood how to feed them and not overwork them.\n\nScott took the Norwegian pilot and skier Tryggve Gran to the Antarctic on the recommendation of Nansen to train his expedition to ski, but although a few of his party began to learn, he made no arrangements for compulsory training for the full party. Gran (possibly because he was Norwegian) was not included in the South Pole party, which could have made a difference. Gran was, one year later, the first to locate the deceased Scott and his remaining companions in their tent just some 18 km (11 miles) short of One Ton depot, that might have saved their lives had they reached it.\n\nScott would subsequently complain in his diary, while well into his journey and therefore too late to take any corrective action and after over 10 years since the Discovery expedition, that \"Skis are the thing, and here are my tiresome fellow countrymen too prejudiced to have prepared themselves for the event\".\n\nAmundsen on his side recruited a team of well experienced skiers, all Norwegians who had skied from an early age. He also recruited a champion skier, Olav Bjaaland, as the front runner. The Amundsen party gained weight on their return travel from the South Pole.\n\nScott and Shackleton's experience in 1903 and 1907 gave them first-hand experience of average conditions in Antarctica. Simpson, Scott's meteorologist 1910–1912, charted the weather during their expedition, often taking two readings a day. On their return to the Ross Ice Shelf, Scott's group experienced prolonged low temperatures from 27 February until 10 March which have only been matched once in 15 years of current records. The exceptional severity of the weather meant they failed to make the daily distances they needed to get to the next depot. This was a serious position as they were short of fuel and food. When Scott, Wilson, and Bowers died (Petty Officer Edgar Evans and Lawrence Oates had died earlier during the return from the South Pole) they were short of One-Ton Depot, which was from Corner Camp, where they would have been safe.\n\nOn the other hand, Cherry-Garrard had travelled nearly in the same area, during the same time period and same temperatures, using a dog team. Scott also blamed \"a prolonged blizzard\". But while there is evidence to support the low temperatures, there is only evidence for a \"normal\" two- to four-day blizzard, and not the ten days that Scott claims.\n\nDuring depot laying in February 1911, Roald Amundsen had his first (and last) of his route marked like a Norwegian ski course using marker flags initially every eight miles. He added to this by using food containers painted black, resulting in a marker every mile. From 82 degrees on, Amundsen built a cairn every three miles with a note inside recording the cairn's position, the distance to the next depot, and direction to the next cairn. In order not to miss a depot considering the snow and great distances, Amundsen took precautions. Each depot laid out up to 85 degrees (laid out every degree of latitude) had a line of bamboo flags laid out transversely every half-mile for five miles on either side of the depot, ensuring that the returning party could locate the designated depot.\n\nScott relied on depots much less frequently laid out. For one distance where Amundsen laid seven depots, Scott laid only two. Routes were marked by the walls made at lunch and evening stops to protect the ponies. Depots had a single flag. As a result, Scott has much concern recorded in his diaries over route finding, and experienced close calls about finding depots. It is also clear that Scott's team did not travel on several days, because the swirling snow hid their three-month-old outward tracks. With better depot and route marking they would have been able to travel on more days with a following wind which would have filled the sail attached to their sledge, and so travel further, and might have reached safety.\n\nBy the time they arrived at the pole, the health of Scott's team had significantly deteriorated, whereas Amundsen's team actually gained weight during the expedition. While Scott's team managed to maintain the scheduled pace for most of the return leg, and hence was virtually always on full rations, their condition continued to worsen rapidly. (The only delay occurred when they were held for four days by a blizzard, and had to open their summit rations early as a consequence.)\n\nApsley Cherry-Garrard in his analysis of the expedition estimated that even under optimistic assumptions the summit rations contained only a little more than half the calories actually required for the man-hauling of sledges. A carefully planned 2006 re-enactment of both Amundsen's and Scott's travels, sponsored by the BBC, confirmed Cherry-Garrard's theory. The British team had to abort their tour due to the severe weight loss of all members. The experts hinted that Scott's reports of unusually bad surfaces and weather conditions might in part have been due to their exhausted state which made them feel the sledge weights and the chill more severely.\n\nScott's calculations for the supply requirements were based on a number of expeditions, both by members of his team (e.g., Wilson's trip with Cherry-Garrard and Bowers to the Emperor penguin colony which had each man on a different type of experimental ration), and by Shackleton. Apparently, Scott didn't take the strain of prolonged man-hauling at high altitudes sufficiently into account.\n\nSince the rations contained no B and C vitamins, the only source of these vitamins during the trek was from the slaughter of ponies or dogs. This made the men progressively malnourished, manifested most clearly in the form of scurvy.\n\nScott also had to fight with a shortage of fuel due to leakage from stored fuel cans which used leather washers. This was a phenomenon that had been noticed previously by other expeditions, but Scott took no measures to prevent it. Amundsen, in contrast, had learned the lesson and had his fuel cans soldered closed. A fuel depot he left on Betty's Knoll was found 50 years later still full.\n\nDehydration may also have been a factor. Amundsen's team had plenty of fuel due to better planning and soldered fuel cans. Scott had a shortage of fuel and was unable to melt as much water as Amundsen. At the same time Scott's team were more physically active in man-hauling the sledges.\n\nIt has been said (by the present-day explorer Ranulph Fiennes amongst others) that Scott's team was appropriately dressed for man-hauling in their woolen and wind-proof clothing, and as Amundsen was skiing it was appropriate he wore furs. Skiing at the pace of a dog team is a strenuous activity. Yet Amundsen never complained about the clothing being too hot. That is because the furs are worn loosely so air circulates and sweat evaporates. Scott's team, on the other hand, made regular complaints about the cold.\n\nAmundsen's team did initially have problems with their boots. However, the depot-laying trips of January and February 1911 and an abortive departure to the South Pole on 8 September 1911 allowed changes to be made before it was too late.\n\nScott's team suffered regularly from snow blindness and sometimes this affected over half the team at any one time. By contrast, there was no recorded case of snow blindness during the whole of Amundsen's expedition. On the return journey, Amundsen's team rested during the \"day\" (when the sun was in front of them) and travelled during the \"night\" (when the sun was behind them) to minimise the effects of snow blindness.\n\nIn 1921, 'Teddy' Evans wrote in his book \"South with Scott\" that Scott had left the following written orders at Cape Evans.\n\nHe did however place a lesser importance upon this journey than that of replenishing the food rations at One Ton Depot.\n\nHe continued his instructions in the next paragraph \"You will of course understand that whilst the object of your third journey is important, that of the second is vital. At all hazards three X.S. units of provision must be got to One Ton Camp by the date named (19th January), and if the dogs are unable to perform this task, a man party must be organised.\" with that qualification he closed his notes regarding his instructions for the dogs.\n\nExpedition member Apsley Cherry-Garrard did not mention Scott's order in his 1922 book \"The Worst Journey in the World\". However, in the 1948 preface to his book, he discusses Scott's order. Cherry-Garrard writes that he and Edward Atkinson reached Cape Evans on 28 January. Scott had estimated Atkinson would reach camp by 13 January. Atkinson, now the senior officer discovered that the dog handler Cecil Meares had resigned from the expedition and that neither Meares nor anyone else had resupplied dog food to the depots. Cherry-Garrard also wrote \"In my opinion he [Atkinson] would not have been fit to take out the dogs in the first week of February\".\n\nOn 13 February, Atkinson set off on the first lap southwards to Hut Point with the dog assistant, Dimitri Gerov, and the dogs to avoid being cut off by disintegrating sea ice. Atkinson and Gerov were still at Hut Point when, on 19 February, Tom Crean arrived on foot from the Barrier and reported that Lt Edward Evans was lying seriously ill in a tent some to the south, and in urgent need of rescue. Atkinson decided that this mission was his priority, and set out with the dogs to bring Evans back. This was achieved; the party was back at Hut Point on 22 February.\n\nAtkinson sent a note back to the Cape Evans base camp requesting either the meteorologist Wright or Cherry-Garrard to take over the task of meeting Scott with the dogs. Chief meteorologist Simpson was unwilling to release Wright from his scientific work, and Atkinson therefore selected Apsley Cherry-Garrard. It was still not in Atkinson's mind that Cherry-Garrard's was a relief mission, and according to Cherry-Garrard's account, told him to \"use his judgement\" as to what to do in the event of not meeting the polar party by One Ton, and that Scott's orders were that the dogs must not be risked. Cherry-Garrard left with Gerov and the dogs on 26 February, carrying extra rations for the polar party to be added to the depot and 24 days' of dog food. They arrived at One Ton Depot on 4 March and did not proceed further south. Instead, he and Gerov, after waiting there for Scott for several days, apparently mostly in blizzard conditions (although no blizzard was recorded by Scott some 100 miles further south until 10 March), they returned to Hut Point on 16 March, in poor physical condition and without news of the polar party.\n\nOn the return journey from the pole, Scott reached the 82.30°S meeting point for the dog teams three days ahead of schedule, around 27 February 1912. Scott's diary for that day notes \"We are naturally always discussing possibility of meeting dogs, where and when, etc. It is a critical position. We may find ourselves in safety at the next depot, but there is a horrid element of doubt.\" By 10 March it became clear that the dog teams were not coming: \"The dogs which would have been our salvation have evidently failed. Meares [the dog-driver] had a bad trip home I suppose. It's a miserable jumble.\"\n\nAround 25 March, awaiting death in his tent at latitude 79.30°S, Scott speculated, in a farewell letter to his expedition treasurer Sir Edgar Speyer, that he had overshot the meeting point with the dog relief teams, writing \"We very nearly came through, and it's a pity to have missed it, but lately I have felt that we have overshot our mark. No-one is to blame and I hope no attempt will be made to suggest that we had lacked support.\" (Farewell letter to Sir Edgar Speyer, cited from Karen May 2012.)\n\n"}
{"id": "1996367", "url": "https://en.wikipedia.org/wiki?curid=1996367", "title": "Comparison of web template engines", "text": "Comparison of web template engines\n\nThe following table lists the various Web Template Engines used in Web template systems and a brief rundown of their features.\n\n\n"}
{"id": "590473", "url": "https://en.wikipedia.org/wiki?curid=590473", "title": "Contraction (grammar)", "text": "Contraction (grammar)\n\nA contraction is a shortened version of the written and spoken forms of a word, syllable, or word group, created by omission of internal letters and sounds.\n\nIn linguistic analysis, contractions should not be confused with crasis, abbreviations nor acronyms (including initialisms), with which they share some semantic and phonetic functions, though all three are connoted by the term \"abbreviation\" in loose parlance. Contraction is also distinguished from clipping, where beginnings and endings are omitted.\n\nThe definition overlaps with the term portmanteau (a linguistic \"blend\"), but a distinction can be made between a portmanteau and a contraction by noting that contractions are formed from words that would otherwise appear together in sequence, such as \"do\" and \"not\", whereas a portmanteau word is formed by combining two or more existing words that all relate to a singular concept which the portmanteau describes.\n\nEnglish has a number of contractions, mostly involving the elision of a vowel (which is replaced by an apostrophe in writing), as in \"I'm\" for \"I am\", and sometimes other changes as well, as in \"won't\" for \"will not\" or \"ain't\" for \"am not\". These contractions are commonly used in speech and in informal writing, though tend to be avoided in more formal writing (with limited exceptions, such as the mandatory form of \"o'clock\").\n\nThe main contractions are listed in the following table (for more explanation see English auxiliaries and contractions).\nSome other simplified pronunciations of common word groups, which can often equally be described as cases of elision, may also be considered (non-standard) contractions (not enshrined into the written standard language, but frequently expressed in written form anyway), such as \"wanna\" for \"want to\", \"gonna\" for \"going to\", \"y'all\" for \"you all\", \"ya'll\" for \"ya all\" in the Southern United States and others common forms in colloquial speech.\n\nIn subject–auxiliary inversion, the contracted negative forms behave as if they were auxiliaries themselves, changing place with the subject. For example, the interrogative form of \"He won't go\" is \"Won't he go\", whereas the uncontracted equivalent is \"Will he not go?\", with \"not\" following the subject.\n\nContractions exist in Classical Chinese, some of which are used in modern Chinese.\nContractions also appear in Cantonese, for example, 乜嘢 and 咩.\n\nThe French language has a variety of contractions, similar to English but mandatory, as in \"C'est la vie\" (\"That's life\"), where \"c'est\" stands for \"ce\" + \"est\" (\"that is\"). The formation of these contractions is called elision.\n\nIn general, any monosyllabic word ending in \"e caduc\" (schwa) will contract if the following word begins with a vowel, \"h\" or \"y\" (as \"h\" is silent and absorbed by the sound of the succeeding vowel; \"y\" sounds like \"i\"). In addition to \"ce\" → \"c'-\" (demonstrative pronoun \"that\"), these words are \"que\" → \"qu'-\" (conjunction, relative pronoun, or interrogative pronoun \"that\"), \"ne\" → \"n'-\" (\"not\"), \"se\" → \"s'-\" (\"himself\", \"herself\", \"itself\", \"oneself\" before a verb), \"je\" → \"j'-\" (\"I\"), \"me\" → \"m'-\" (\"me\" before a verb), \"te\" → \"t'- \" (informal singular \"you\" before a verb), \"le\" or \"la\" → \"l'-\" (\"the\"; or \"he/she\", \"it\" before a verb or after an imperative verb and before the word \"y\" or \"en\"), and \"de\" → \"d'-\" (\"of\"). Unlike with English contractions, however, these contractions are mandatory: one would never say (or write) \"*ce est\" or \"*que elle\".\n\n\"Moi\" (\"myself\") and \"toi\" (informal \"yourself\") mandatorily contract to \"m'-\" and \"t'-\" respectively after an imperative verb and before the word \"y\" or \"en\".\n\nIt is also mandatory to avoid the repetition of a sound when the conjunction \"si\" (\"if\") is followed by \"il\" (\"he\", \"it\") or \"ils\" (\"they\"), which begin with the same vowel sound \"i\": \"*si il\" → \"s'il\" (\"if it\", if he\"); \"*si ils\" → \"s'ils\" (\"if they\").\n\nCertain prepositions are also mandatorily merged with masculine and plural direct articles: \"au\" for \"à le\", \"aux\" for \"à les\", \"du\" for \"de le\", and \"des\" for \"de les\". However, the contraction of \"cela\" (demonstrative pronoun \"that\") to \"ça\" is optional and informal.\n\nIn informal speech, a personal pronoun may sometimes be contracted onto a following verb. For example, \"je ne sais pas\" (, \"I don't know\") may be pronounced roughly \"chais pas\" (), with the \"ne\" being completely elided and the of \"je\" being mixed with the of \"sais\". It is also common in informal contexts to contract \"tu\" to \"t'-\" before a vowel, e.g., \"t'as mangé\" for \"tu as mangé\".\n\nIn Modern Hebrew, the prepositional prefixes -בְּ /bə-/ 'in' and -לְ /lə-/ 'to' contract with the definite article prefix -ה (/ha-/) to form the prefixes -ב /ba/ 'in the' and -ל /la/ 'to the'. In colloquial Israeli Hebrew, the preposition את (/ʔet/), which indicates a definite direct object, and the definite article prefix -ה (/ha-/) are often contracted to 'ת (/ta-/) when the former immediately precedes the latter. Thus ראיתי את הכלב (/ʁaˈʔiti ʔet haˈkelev/, \"I saw the dog\") may become ראיתי ת'כלב (/ʁaˈʔiti taˈkelev/).\n\nIn Italian, prepositions merge with direct articles in predictable ways. The prepositions \"a\", \"da\", \"di\", \"in\", \"su\", \"con\" and \"per\" combine with the various forms of the definite article, namely \"il\", \"lo\", \"la\", \"l',\" \"i\", \"gli\", \"gl',\" and \"le\".\n\n\nThe words \"ci\" and \"è\" (form of \"essere\", to be) and the words \"vi\" and \"è\" are contracted into \"c'è\" and \"v'è\" (both meaning \"there is\").\n\nThe words \"dove\" and any word that begins with \"e\" are contracted into one single, deleting the e of the principal word, dove (dov'). Equally \"come\" does be made so.\nAs well other words may be contracted the same these two, like \"quale\", and other ones, etcetera.\n\nSpanish has two mandatory phonetic contractions between prepositions and articles: \"al\" (to the) for \"a el\", and \"del\" (of the) for \"de el\" (not to be confused with \"a él\", meaning \"to him\", and \"de él\", meaning \"his\" or, more literally, \"of him\").\n\nOther contractions were common in writing until the 17th century, the most usual being \"de\" + personal and demonstrative pronouns: \"destas\" for \"de estas\" (of these, fem.), \"daquel\" for \"de aquel\" (of that, masc.), \"dél\" for \"de él\" (of him) etc.; and the feminine article before words beginning with \"a-\": \"l'alma\" for \"la alma\", now \"el alma\" (the soul). Several sets of demonstrative pronouns originated as contractions of \"aquí\" (here) + pronoun, or pronoun + \"otro/a\" (other): \"aqueste\", \"aqueso\", \"estotro\" etc. The modern \"aquel\" (that, masc.) is the only survivor of the first pattern; the personal pronouns \"nosotros\" (we) and \"vosotros\" (pl. you) are remnants of the second. In medieval texts unstressed words very often appear contracted: \"todol\" for \"todo el\" (all the, masc.), \"ques\" for \"que es\" (which is); etc. including with common words, like d'ome (d'home/d'homme) instead de ome (home/homme), and so on.\n\nThough not strictly a contraction, a special form is used when combining con with mí, ti or sí which is written as \"conmigo\" for *\"con mí\" (with me), \"contigo\" for *\"con ti\" (with you sing.), \"consigo\" for *\"con sí\" (with himself/herself/itself/themselves (themself).\n\nFinally, one can hear \"pa\"' for \"para\", deriving as \"pa'l\" for \"para el\", but these forms are only considered appropriate in informal speech.\n\nIn Portuguese, contractions are common and much more numerous than those in Spanish. Several prepositions regularly contract with certain articles and pronouns. For instance, \"de\" (of) and \"por\" (by; formerly \"per\") combine with the definite articles \"o\" and \"a\" (masculine and feminine forms of \"the\" respectively), producing \"do\", \"da\" (of the), \"pelo\", \"pela\" (by the). The preposition \"de\" contracts with the pronouns \"ele\" and \"ela\" (he, she), producing \"dele\", \"dela\" (his, her). In addition, some verb forms contract with enclitic object pronouns: e.g., the verb \"amar\" (to love) combines with the pronoun \"a\" (her), giving \"amá-la\" (to love her).\n\nAnother contraction in portuguese which is similar to English ones is the combination of the pronoun \"da\" with words starting in \"a\", resulting in changing the first letter \"a\" for an apostrophe and joining both words. Examples: \"Estrela d'alva\" (A popular phrase to refer to Venus that means \"Alb star\", as a reference to its brightness) ; \"Caixa d'água\" (water tank).\n\nIn informal, spoken German prepositional phrases, one can often merge the preposition and the article; for example, \"von dem\" becomes \"vom\", \"zu dem\" becomes \"zum\", or \"an das\" becomes \"ans\". Some of these are so common that they are mandatory. In informal speech, \"aufm\" for \"auf dem\", \"unterm\" for \"unter dem\", etc. are also used, but would be considered to be incorrect if written, except maybe in quoted direct speech, in appropriate context and style.\n\nThe pronoun \"es\" often contracts to \"s\" (usually written with the apostrophe) in certain contexts. For example, the greeting \"Wie geht es?\" is usually encountered in the contracted form \"Wie geht's?\".\n\nRegional dialects of German, and various local languages which usually were already used long before today's Standard German was created, do use contractions usually more frequently than German, but varying widely between different local languages. The informally spoken German contractions are observed almost everywhere, most often accompanied by additional ones, such as \"in den\" becoming \"in'n\" (sometimes \"im\") or \"haben wir\" becoming \"hamwer\", \"hammor\", \"hemmer\", or \"hamma\" depending on local intonation preferences. Bavarian German features several more contractions such as \"gesund sind wir\" becoming \"xund samma\" which are schematically applied to all word or combinations of similar sound. (One must remember, however, that German \"wir\" exists alongside Bavarian \"mir\", or \"mia\", with the same meaning.) The Munich-born footballer Franz Beckenbauer has as his catchphrase \"Schau mer mal\" (\"Schauen wir einmal\" - in English \"let's have a look\"). A book about his career had as its title the slightly longer version of the phrase, \"Schau'n Mer Mal\".\n\nSuch features are found in all central and southern language regions. A sample from Berlin: \"Sag einmal, Meister, kann man hier einmal hinein?\" is spoken as \"Samma, Meesta, kamma hier ma rin?\"\n\nSeveral West Central German dialects along the Rhine River have built contraction patterns involving long phrases and entire sentences. In speech, words are often concatenated, and frequently the process of \"liaison\" is used. So, \"[Dat] kriegst Du nicht\" may become \"Kressenit\", or \"Lass mich gehen, habe ich gesagt\" may become \"Lomejon haschjesaat\".\n\nMostly, there are no binding orthographies for local dialects of German, hence writing is left to a great extent to authors and their publishers. Outside quotations, at least, they usually pay little attention to print more than the most commonly spoken contractions, so as not to degrade their readability. The use of apostrophes to indicate omissions is a varying and considerably less frequent process than in English-language publications.\n\nThe use of contractions is not allowed in any form of standard Norwegian spelling, however, it is fairly common to shorten or contract words in spoken language. Yet, the commonness varies from dialect to dialect and from sociolect to sociolect—it depends on the formality etc. of the setting. Some common, and quite drastic, contractions found in Norwegian speech are \"jakke\" for \"jeg har ikke\", meaning \"I do not have\" and \"dække\" for \"det er ikke\", meaning \"there is not\". The most frequently used of these contractions—usually consisting of two or three words contracted into one word, contain short, common and often monosyllabic words like , , , , or . The use of the apostrophe (') is much less common than in English, but is sometimes used in contractions to show where letters have been dropped.\n\nIn extreme cases, long, entire sentences may be written as one word. An example of this is \"Det ordner seg av seg selv\" in standard written Bokmål, meaning \"It will sort itself out\" could become \"dånesæsæsjæl\" (note the letters Å and Æ, and the word \"sjæl\", as an eye dialect spelling of ). R-dropping, being present in the example, is especially common in speech in many areas of Norway , but plays out in different ways, as does elision of word-final phonemes like .\n\nBecause of the many dialects of Norwegian and their widespread use it is often difficult to distinguish between non-standard writing of standard Norwegian and eye dialect spelling. It is almost universally true that these spellings try to convey the way each word is pronounced, but it is rare to see language written that does not adhere to at least some of the rules of the official orthography. Reasons for this include words spelled unphonemically, ignorance of conventional spelling rules, or adaptation for better transcription of that dialect's phonemes.\n\nLatin contains several examples of contractions. One such case is preserved in the verb \"nolo\" (I am unwilling/do not want) which was formed by a contraction of \"non volo\" (\"volo\" meaning “I want”). Similarly this is observed in the first person plural and third person plural forms (nolumus and nolunt respectively).\n\nSome contractions in rapid speech include ～っす (\"-ssu\") for です (\"desu\") and すいません (\"suimasen\") for すみません (\"sumimasen\"). では (\"dewa\") is often contracted to じゃ (\"ja\"). In certain grammatical contexts the particle の (\"no\") is contracted to simply ん (\"n\").\n\nWhen used after verbs ending in the conjunctive form ～て (\"-te\"), certain auxiliary verbs and their derivations are often abbreviated. Examples:\n<nowiki>*</nowiki> this abbreviation is never used in the polite conjugation, to avoid the resultant ambiguity between an abbreviated \"ikimasu\" (go) and the verb \"kimasu\" (come).\n\nThe ending ～なければ (\"-nakereba\") can be contracted to ～なきゃ (\"-nakya\") when it is used to indicate obligation. It is often used without an auxiliary, e.g., 行かなきゃ（いけない） (\"ikanakya (ikenai)\") \"I have to go.\"\n\nOther times, contractions are made to create new words or to give added or altered meaning:\n\nVarious dialects of Japanese also use their own specific contractions which are often unintelligible to speakers of other dialects.\n\nIn the Polish language pronouns have contracted forms which are more prevalent in their colloquial usage. Examples are \"go\" and \"mu\". The non-contracted forms are \"jego\" (unless it is used as a possessive pronoun) and \"jemu\", respectively. The clitic \"-ń\" which stands for \"niego\" (him) as in \"dlań\" (\"dla niego\") is more common in literature. The non-contracted forms are generally used as a means to accentuate.\n\nUyghur, a Turkic language spoken in Central Asia, includes some verbal suffixes that are actually contracted forms of compound verbs (serial verbs). For instance, \"sëtip alidu\" (sell-manage, \"manage to sell\") is usually written and pronounced \"sëtivaldu\", with the two words forming a contraction and the [p] leniting into a [v] or [w].\n\nIn Filipino, most contractions need other words to be contracted correctly. Only words that end with vowels can make a contraction with words like \"at\" and \"ay.\" In this chart, the \"@\" represents any vowel.\n"}
{"id": "327803", "url": "https://en.wikipedia.org/wiki?curid=327803", "title": "Crossword abbreviations", "text": "Crossword abbreviations\n\nCryptic crosswords often use abbreviations to clue individual letters or short fragments of the overall solution. These include:\n\n\nThe abbreviation is not always a short form of the word used in the clue. For example:\n\n\nTaking this one stage further, the clue word can hint at the word or words to be abbreviated rather than giving the word itself. For example:\n\n\nMore obscure clue words of this variety include:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "7931", "url": "https://en.wikipedia.org/wiki?curid=7931", "title": "Dictionary", "text": "Dictionary\n\nA dictionary, sometimes known as a wordbook, is a collection of words in one or more specific languages, often arranged alphabetically (or by radical and stroke for ideographic languages), which may include information on definitions, usage, etymologies, pronunciations, translation, etc. or a book of words in one language with their equivalents in another, sometimes known as a lexicon. It is a lexicographical reference that shows inter-relationships among the data.\n\nA broad distinction is made between general and specialized dictionaries. Specialized dictionaries include words in specialist fields, rather than a complete range of words in the language. Lexical items that describe concepts in specific fields are usually called terms instead of words, although there is no consensus whether lexicology and terminology are two different fields of study. In theory, general dictionaries are supposed to be semasiological, mapping word to definition, while specialized dictionaries are supposed to be onomasiological, first identifying concepts and then establishing the terms used to designate them. In practice, the two approaches are used for both types. There are other types of dictionaries that do not fit neatly into the above distinction, for instance bilingual (translation) dictionaries, dictionaries of synonyms (thesauri), and rhyming dictionaries. The word dictionary (unqualified) is usually understood to refer to a general purpose monolingual dictionary.\n\nThere is also a contrast between \"prescriptive\" or \"descriptive\" dictionaries; the former reflect what is seen as correct use of the language while the latter reflect recorded actual use. Stylistic indications (e.g. \"informal\" or \"vulgar\") in many modern dictionaries are also considered by some to be less than objectively descriptive.\n\nAlthough the first recorded dictionaries date back to Sumerian times (these were bilingual dictionaries), the systematic study of dictionaries as objects of scientific interest themselves is a 20th-century enterprise, called lexicography, and largely initiated by Ladislav Zgusta. The birth of the new discipline was not without controversy, the practical dictionary-makers being sometimes accused by others of \"astonishing\" lack of method and critical-self reflection.\n\nThe oldest known dictionaries were Akkadian Empire cuneiform tablets with bilingual Sumerian–Akkadian wordlists, discovered in Ebla (modern Syria) and dated roughly 2300 BCE. The early 2nd millennium BCE \"Urra=hubullu\" glossary is the canonical Babylonian version of such bilingual Sumerian wordlists. A Chinese dictionary, the c. 3rd century BCE \"Erya\", was the earliest surviving monolingual dictionary; although some sources cite the c. 800 BCE Shizhoupian as a \"dictionary\", modern scholarship considers it a calligraphic compendium of Chinese characters from Zhou dynasty bronzes. Philitas of Cos (fl. 4th century BCE) wrote a pioneering vocabulary \"Disorderly Words\" (Ἄτακτοι γλῶσσαι, \"\") which explained the meanings of rare Homeric and other literary words, words from local dialects, and technical terms. Apollonius the Sophist (fl. 1st century CE) wrote the oldest surviving Homeric lexicon. The first Sanskrit dictionary, the Amarakośa, was written by Amara Sinha c. 4th century CE. Written in verse, it listed around 10,000 words. According to the \"Nihon Shoki\", the first Japanese dictionary was the long-lost 682 CE \"Niina\" glossary of Chinese characters. The oldest existing Japanese dictionary, the c. 835 CE \"Tenrei Banshō Meigi\", was also a glossary of written Chinese. In \"Frahang-i Pahlavig\", Aramaic heterograms are listed together with their translation in Middle Persian language and phonetic transcription in Pazand alphabet. A 9th-century CE Irish dictionary, Sanas Cormaic, contained etymologies and explanations of over 1,400 Irish words. In India around 1320, Amir Khusro compiled the Khaliq-e-bari which mainly dealt with Hindustani and Persian words.\nArabic dictionaries were compiled between the 8th and 14th centuries CE, organizing words in rhyme order (by the last syllable), by alphabetical order of the radicals, or according to the alphabetical order of the first letter (the system used in modern European language dictionaries). The modern system was mainly used in specialist dictionaries, such as those of terms from the Qur'an and hadith, while most general use dictionaries, such as the \"Lisan al-`Arab\" (13th century, still the best-known large-scale dictionary of Arabic) and \"al-Qamus al-Muhit\" (14th century) listed words in the alphabetical order of the radicals. The \"Qamus al-Muhit\" is the first handy dictionary in Arabic, which includes only words and their definitions, eliminating the supporting examples used in such dictionaries as the \"Lisan\" and the \"Oxford English Dictionary\".\nIn medieval Europe, glossaries with equivalents for Latin words in vernacular or simpler Latin were in use (e.g. the Leiden Glossary). The \"Catholicon\" (1287) by Johannes Balbus, a large grammatical work with an alphabetical lexicon, was widely adopted. It served as the basis for several bilingual dictionaries and was one of the earliest books (in 1460) to be printed. In 1502 Ambrogio Calepino's \"Dictionarium\" was published, originally a monolingual Latin dictionary, which over the course of the 16th century was enlarged to become a multilingual glossary. In 1532 Robert Estienne published the \"Thesaurus linguae latinae\" and in 1572 his son Henri Estienne published the \"Thesaurus linguae graecae\", which served up to the 19th century as the basis of Greek lexicography. The first monolingual dictionary written in Europe was the Spanish, written by Sebastián Covarrubias' \"Tesoro de la lengua castellana o española\", published in 1611 in Madrid, Spain. In 1612 the first edition of the \"Vocabolario degli Accademici della Crusca\", for Italian, was published. It served as the model for similar works in French and English. In 1690 in Rotterdam was published, posthumously, the \"Dictionnaire Universel\" by Antoine Furetière for French. In 1694 appeared the first edition of the \"Dictionnaire de l'Académie française\". Between 1712 and 1721 was published the \"Vocabulario portughez e latino\" written by Raphael Bluteau. The Real Academia Española published the first edition of the \"Diccionario de la lengua española\" in 1780, but their \"Diccionario de Autoridades\", which included quotes taken from literary works, was published in 1726. The \"Totius Latinitatis lexicon\" by Egidio Forcellini was firstly published in 1777; it has formed the basis of all similar works that have since been published.\n\nThe first edition of \"A Greek-English Lexicon\" by Henry George Liddell and Robert Scott appeared in 1843; this work remained the basic dictionary of Greek until the end of the 20th century. And in 1858 was published the first volume of the Deutsches Wörterbuch by the Brothers Grimm; the work was completed in 1961. Between 1861 and 1874 was published the \"Dizionario della lingua italiana\" by Niccolò Tommaseo. Between 1862 and 1874 was published the six volumes of \"A magyar nyelv szótára\" (Dictionary of Hungarian Language) by Gergely Czuczor and János Fogarasi. Émile Littré published the Dictionnaire de la langue française between 1863 and 1872. In the same year 1863 appeared the first volume of the \"Woordenboek der Nederlandsche Taal\" which was completed in 1998. Also in 1863 Vladimir Ivanovich Dahl published the \"Explanatory Dictionary of the Living Great Russian Language\". The Duden dictionary dates back to 1880, and is currently the prescriptive source for the spelling of German. The decision to start work on the \"Svenska Akademiens ordbok\" was taken in 1787.\n\nThe earliest dictionaries in the English language were glossaries of French, Spanish or Latin words along with their definitions in English. The word \"dictionary\" was invented by an Englishman called John of Garland in 1220 — he had written a book \"Dictionarius\" to help with Latin \"diction\". An early non-alphabetical list of 8000 English words was the \"Elementarie\", created by Richard Mulcaster in 1582.\n\nThe first purely English alphabetical dictionary was \"A Table Alphabeticall\", written by English schoolteacher Robert Cawdrey in 1604. The only surviving copy is found at the Bodleian Library in Oxford. This dictionary, and the many imitators which followed it, was seen as unreliable and nowhere near definitive. Philip Stanhope, 4th Earl of Chesterfield was still lamenting in 1754, 150 years after Cawdrey's publication, that it is \"a sort of disgrace to our nation, that hitherto we have had no… standard of our language; our dictionaries at present being more properly what our neighbors the Dutch and the Germans call theirs, word-books, than dictionaries in the superior sense of that title.\" \n\nIn 1616, John Bullokar described the history of the dictionary with his \"English Expositor\". \"Glossographia\" by Thomas Blount, published in 1656, contains more than 10,000 words along with their etymologies or histories. Edward Phillips wrote another dictionary in 1658, entitled \"The New World of English Words: Or a General Dictionary\" which boldly plagiarized Blount's work, and the two denounced each other. This created more interest in the dictionaries. John Wilkins' 1668 essay on philosophical language contains a list of 11,500 words with careful distinctions, compiled by William Lloyd. Elisha Coles published his \"English Dictionary\" in 1676.\n\nIt was not until Samuel Johnson's \"A Dictionary of the English Language\" (1755) that a more reliable English dictionary was produced. Many people today mistakenly believe that Johnson wrote the first English dictionary: a testimony to this legacy. By this stage, dictionaries had evolved to contain textual references for most words, and were arranged alphabetically, rather than by topic (a previously popular form of arrangement, which meant all animals would be grouped together, etc.). Johnson's masterwork could be judged as the first to bring all these elements together, creating the first \"modern\" dictionary.\n\nJohnson's dictionary remained the English-language standard for over 150 years, until the Oxford University Press began writing and releasing the \"Oxford English Dictionary\" in short fascicles from 1884 onwards. It took nearly 50 years to complete this huge work, and they finally released the complete \"OED\" in twelve volumes in 1928. It remains the most comprehensive and trusted English language dictionary to this day, with revisions and updates added by a dedicated team every three months. One of the main contributors to this modern dictionary was an ex-army surgeon, William Chester Minor, a convicted murderer who was confined to an asylum for the criminally insane.\n\nIn 1806, American Noah Webster published his first dictionary, \"\". In 1807 Webster began compiling an expanded and fully comprehensive dictionary, \"An American Dictionary of the English Language;\" it took twenty-seven years to complete. To evaluate the etymology of words, Webster learned twenty-six languages, including Old English (Anglo-Saxon), German, Greek, Latin, Italian, Spanish, French, Hebrew, Arabic, and Sanskrit.\n\nWebster completed his dictionary during his year abroad in 1825 in Paris, France, and at the University of Cambridge. His book contained seventy thousand words, of which twelve thousand had never appeared in a published dictionary before. As a spelling reformer, Webster believed that English spelling rules were unnecessarily complex, so his dictionary introduced American English spellings, replacing \"colour\" with \"color\", substituting \"wagon\" for \"waggon\", and printing \"center\" instead of \"centre\". He also added American words, like \"skunk\" and \"squash\", that did not appear in British dictionaries. At the age of seventy, Webster published his dictionary in 1828; it sold 2500 copies. In 1840, the second edition was published in two volumes.\n\nIn a general dictionary, each word may have multiple meanings. Some dictionaries include each separate meaning in the order of most common usage while others list definitions in historical order, with the oldest usage first.\n\nIn many languages, words can appear in many different forms, but only the undeclined or unconjugated form appears as the headword in most dictionaries. Dictionaries are most commonly found in the form of a book, but some newer dictionaries, like StarDict and the \"New Oxford American Dictionary\" are dictionary software running on PDAs or computers. There are also many online dictionaries accessible via the Internet.\n\nAccording to the \"Manual of Specialized Lexicographies\", a specialized dictionary, also referred to as a technical dictionary, is a dictionary that focuses upon a specific subject field. Following the description in \"The Bilingual LSP Dictionary\", lexicographers categorize specialized dictionaries into three types: A multi-field dictionary broadly covers several subject fields (e.g. a business dictionary), a single-field dictionary narrowly covers one particular subject field (e.g. law), and a sub-field dictionary covers a more specialized field (e.g. constitutional law). For example, the 23-language Inter-Active Terminology for Europe is a multi-field dictionary, the American National Biography is a single-field, and the African American National Biography Project is a sub-field dictionary. In terms of the coverage distinction between \"minimizing dictionaries\" and \"maximizing dictionaries\", multi-field dictionaries tend to minimize coverage across subject fields (for instance, \"Oxford Dictionary of World Religions\" and \"Yadgar Dictionary of Computer and Internet Terms\") whereas single-field and sub-field dictionaries tend to maximize coverage within a limited subject field (\"The Oxford Dictionary of English Etymology\").\n\nAnother variant is the glossary, an alphabetical list of defined terms in a specialized field, such as medicine (medical dictionary).\n\nThe simplest dictionary, a defining dictionary, provides a core glossary of the simplest meanings of the simplest concepts. From these, other concepts can be explained and defined, in particular for those who are first learning a language. In English, the commercial defining dictionaries typically include only one or two meanings of under 2000 words. With these, the rest of English, and even the 4000 most common English idioms and metaphors, can be defined.\n\nLexicographers apply two basic philosophies to the defining of words: \"prescriptive\" or \"descriptive\". Noah Webster, intent on forging a distinct identity for the American language, altered spellings and accentuated differences in meaning and pronunciation of some words. This is why American English now uses the spelling \"color\" while the rest of the English-speaking world prefers \"colour\". (Similarly, British English subsequently underwent a few spelling changes that did not affect American English; see further at American and British English spelling differences.)\n\nLarge 20th-century dictionaries such as the \"Oxford English Dictionary\" (OED) and \"Webster's Third\" are descriptive, and attempt to describe the actual use of words. Most dictionaries of English now apply the descriptive method to a word's definition, and then, outside of the definition itself, and information alerting readers to attitudes which may influence their choices on words often considered vulgar, offensive, erroneous, or easily confused. \"Merriam-Webster\" is subtle, only adding italicized notations such as, \"sometimes offensive\" or \"stand\" (nonstandard). \"American Heritage\" goes further, discussing issues separately in numerous \"usage notes.\" \"Encarta\" provides similar notes, but is more prescriptive, offering warnings and admonitions against the use of certain words considered by many to be offensive or illiterate, such as, \"an offensive term for...\" or \"a taboo term meaning...\".\n\nBecause of the widespread use of dictionaries in schools, and their acceptance by many as language authorities, their treatment of the language does affect usage to some degree, with even the most descriptive dictionaries providing conservative continuity. In the long run, however, the meanings of words in English are primarily determined by usage, and the language is being changed and created every day. As Jorge Luis Borges says in the prologue to \"El otro, el mismo\": \"It is often forgotten that (dictionaries) are artificial repositories, put together well after the languages they define. The roots of language are irrational and of a magical nature.\"\n\nSometimes the same dictionary can be descriptive in some domains and prescriptive in others. For example, according to Ghil'ad Zuckermann, the \"Oxford English-Hebrew Dictionary\" is \"at war with itself\": whereas its coverage (lexical items) and glosses (definitions) are descriptive and colloquial, its vocalization is prescriptive. This internal conflict results in absurd sentences such as \"hi taharóg otí kshetiré me asíti lamkhonít\" (she'll tear me apart when she sees what I've done to the car). Whereas \"hi taharóg otí\", literally 'she will kill me', is colloquial, me (a variant of ma 'what') is archaic, resulting in a combination that is unutterable in real life.\n\nA historical dictionary is a specific kind of descriptive dictionary which describes the development of words and senses over time, usually using citations to original source material to support its conclusions.\n\nIn contrast to traditional dictionaries, which are designed to be used by human beings, dictionaries for natural language processing (NLP) are built to be used by computer programs. The final user is a human being but the direct user is a program. Such a dictionary does not need to be able to be printed on paper. The structure of the content is not linear, ordered entry by entry but has the form of a complex network (see Diathesis alternation). Because most of these dictionaries are used to control machine translations or cross-lingual information retrieval (CLIR) the content is usually multilingual and usually of huge size. In order to allow formalized exchange and merging of dictionaries, an ISO standard called Lexical Markup Framework (LMF) has been defined and used among the industrial and academic community.\n\n\nIn many languages, such as the English language, the pronunciation of some words is not consistently apparent from their spelling. In these languages, dictionaries usually provide the pronunciation. For example, the definition for the word \"dictionary\" might be followed by the International Phonetic Alphabet spelling . American English dictionaries often use their ownpronunciation respelling systems with diacritics, for example \"dictionary\" is respelled as \"dĭk′shə-nĕr′ē\" in the American Heritage Dictionary. The IPA is more commonly used within the British Commonwealth countries. Yet others use their own pronunciation respelling systems without diacritics: for example, \"dictionary\" may be respelled as . Some online or electronic dictionaries provide audio recordings of words being spoken.\n\nHistories and descriptions of the dictionaries of other languages on Wikipedia include:\n\n\nThe age of the Internet brought online dictionaries to the desktop and, more recently, to the smart phone. David Skinner in 2013 noted that \"Among the top ten lookups on Merriam-Webster Online at this moment are 'holistic, pragmatic, caveat, esoteric' and 'bourgeois.' Teaching users about words they don’t already know has been, historically, an aim of lexicography, and modern dictionaries do this well.\"\nThere exist a number of websites which operate as online dictionaries, usually with a specialized focus. Some of them have exclusively user driven content, often consisting of neologisms. Some of the more notable examples include:\n\n\n\n"}
{"id": "58632079", "url": "https://en.wikipedia.org/wiki?curid=58632079", "title": "Encyclopedia of Forensic and Legal Medicine 2nd Edition", "text": "Encyclopedia of Forensic and Legal Medicine 2nd Edition\n\nThe Encyclopedia of Forensic and Legal Medicine 2nd Edition is a reference source and pioneering 4 set encyclopedia of forensics and medico-legal knowledge published by Academic Press, Elsevier in 2016. This has been edited by the renowned British forensic specialist Jason Payne-James and Australian forensic pathologist Roger W. Byard and an international editorial board. \nThis reference work includes more than 300 articles contributed by forensic medicine and forensic science experts from all over the world. The encyclopedia is a complete reference source of articles covering from forensics, criminal investigations, health-care, legal, judicial, ballistics, toxicology,fingerprinting, DNA typing, disaster victim identification to autopsy and postmortem examination.\n\nThe encyclopedia is especially meant for forensic, medical, chemistry, physics, laboratory technologists and anthropology students and specialists such as forensic experts, lawyers, judicial officers, judges, police and investigating offices, nurses, medical officers etc. All the articles of the encyclopedia are available through Science direct and Scopus.\n"}
{"id": "17878314", "url": "https://en.wikipedia.org/wiki?curid=17878314", "title": "Information source", "text": "Information source\n\nAn information source is a person, thing, or place from which information comes, arises, or is obtained. Information souces can be known as primary or secondary. That source might then inform a person about something or provide knowledge about it. Information sources are divided into separate distinct categories, primary, secondary, tertiary, and so on.\n\n"}
{"id": "15293025", "url": "https://en.wikipedia.org/wiki?curid=15293025", "title": "Informationsdienst Wissenschaft", "text": "Informationsdienst Wissenschaft\n\nInformationsdienst Wissenschaft e.V. or idw (The Science Information Service) operates an Internet platform, which bundles the press reports and dates of important events from about 1,000 scientific institutions, including universities, technical colleges, governmental and non-governmental research institutes and institutes to support research or scientific administration. idw (a registered charitable society) also operates an expert broker, the idw expert finder, which is exclusively for journalists. This makes idw one of the most comprehensive sources of science news in the German-speaking area. Foreign journalists and institutions (mostly European) now use idw as well. \n\nThe two main objectives of idw are:\n\nThe information in idw can be accessed free of charge - either directly on idw’s www pages, or by using an individually configurable RSS feed or as an e-mail subscriber. Any user can request the information covering the topics and regions which interest him. All idw services can be used free of cost - the current news ticker, the science calendar, research in the archive (which contains more than 350,000 press releases), and the list of institutions linked to idw. idw also provides journalists with instruments for contacting experts, and maintains a database with science photos.\nThe members' press offices have various possibilities of communicating with journalists. Membership is only offered to German or foreign institutions which perform research or teaching, or which support science or are active in science in some other way.\n\nThe original idea of idw was to provide experts for journalists. Using the American ProfNet as example, the press officers of Universitaet Bayreuth, the Ruhr University Bochum and the Clausthal University of Technology, in collaboration with Computing Centre of Clausthal University of Technology/TU Clausthal, developed a concept for a German language network, by means of the new media. The concept was technically implemented by the staff of the Computing Centre of the Clausthal University of Technology. A total of nine staff members in Bayreuth, Bochum and Clausthal are responsible for programming, maintaining and developing the idw operating system, for user services and further development of the content.\n\nThe initial phase (1996–1999) was guaranteed by project support from the Federal Ministry for Education and Research (BMBF). The technical development of the idw was supported by the Ministry, together with the Stifterverband fuer die Deutsche Wissenschaft (Donor Association for German Science). idw has been working closely for years with the initiative Wissenschaft im Dialog (Science in Dialogue). idw has been economically independent since 2000 and is financed by contributions from member institutions. It has been organised as a registered charitable society (gemeinnütziger e. V.) since 2002.\n\nidw has developed as a recognised and accepted source for German language science and for science journalism. It has become an instrument for public relations work for scientific institutions. \nAbout 37,000 subscribers (figure for June 2018) receive regular reports from idw, including some 7,900 journalists. About 1,000 institutions publish their press reports and dates of important events via idw.\n\n"}
{"id": "5995840", "url": "https://en.wikipedia.org/wiki?curid=5995840", "title": "L. G. Pine", "text": "L. G. Pine\n\nLeslie Gilbert Pine (22 December 1907 – 15 May 1987) was a British author, lecturer, and researcher in the areas of genealogy, nobility, history, heraldry and animal welfare. He was born in 1907 in Bristol, England and died in Bury St. Edmunds, Suffolk in 1987. He was the son of Lilian Grace Beswetherick and Henry Moorshead Pine (a tea merchant).\n\nFrom 1935 to 1940 he served as an assistant editor at Burke's Peerage Ltd. During World War II he was an officer in the Royal Air Force intelligence branch, serving in North Africa, Italy, Greece, and India; he retired with the rank of Squadron Leader. After the war and until 1960, he was Burke's executive director. Pine edited \"Burke's Peerage,\" 1949-1959; \"Burke's Landed Gentry (of Great Britain),\" 1952; \"Burke's Landed Gentry (of Ireland),\" 1958; and, \"Burke's Distinguished Families of America,\" 1939, 1947. He also edited \"The International Year Book and Statesmen's Who's Who,\" 1953-1960; \"Author's and Writer's Who's Who,\" 1948, 1960; \"Who's Who in Music,\" 1949; and, \"Who's Who in the Free Churches,\" 1951.\n\nA graduate of London University, he became a Barrister-at-Law, Inner Temple, in 1953. Pine was a member of the International Institute of Genealogy and Heraldry, Fellow of the Society of Antiquaries of Scotland, a Fellow of the Ancient Monuments Society, a Life Fellow of the Institute of Journalists, a Freeman of the City of London, and a Liveryman of the Glaziers' Company. In 1959 he was the unsuccessful Conservative candidate for Bristol Central.\n\nHe was managing editor of a British hunting magazine, \"Shooting Times\", from 1960 to 1964. He later authored an important book highly critical of sport hunting, \"After Their Blood\", in which he wrote: \"It is our duty as men and women of God’s redeemed creation to try not to increase the suffering of the world, but to lessen it. To get rid of bloodsports will be a great step toward this end.\"\n\nIn 1948 Leslie Pine married Grace V. Griffin (20 August 1914- ). Their only child, Richard Pine, was born in London on 21 August 1949.\n\nHis books include:\n\n\nPine is also the primary contributor to the article \"genealogy\" in \"Encyclopædia Britannica\".\n\n"}
{"id": "30795401", "url": "https://en.wikipedia.org/wiki?curid=30795401", "title": "Liar paradox in early Islamic tradition", "text": "Liar paradox in early Islamic tradition\n\nMany early Islamic philosophers and logicians discussed the liar paradox. Their work on the subject began in the 10th century and continued to Athīr al-Dīn al-Abharī and Nasir al-Din al-Tusi of the middle 13th century and beyond. Although the Liar paradox has been well known in Greek and Latin traditions, the works of Arabic scholars have only recently been translated into English.\n\nEach group of early Islamic philosophers discussed different problems presented by the paradox. They pioneered unique solutions that were not influenced by Western ideas.\n\nAthīr al-Dīn Mufaḍḍal (b. ʿUmar Abharī, d. 663/1264) was a Persian philosopher, astronomer and mathematician from the city of Abhar in Persia. There is some speculation that his works on the Liar paradox could have been known to Western logicians, and in particular to Thomas Bradwardine.\n\nHe analyzed the Liar sentence as follows:\n\nIn other words, Athīr says that if the Liar sentence is false, which means that the Liar falsely declares that all he says at the moment is false, then the Liar sentence is true; and, if the Liar sentence is true, which means that the Liar truthfully declares that all he says at the moment is false, then the Liar sentence is false. In any case, the Liar sentence is both true and false at the same time, which is a paradox.\n\nAthīr offers the following solution for the paradox:\n\nAccording to the traditional idealization that presumably was used by Athīr, the sentence as an universal proposition is false only, when \"either it has a counter-instance or its subject term is empty\".\n\n\nThe Liar sentence, however, has neither an empty subject nor counter-instance. This fact creates obstacles for Athīr's view, who must show what is unique about the Liar sentence, and how the Liar sentence still could be only true or false in view of the \"true\" and \"false\" conditions set up in the universal proposition's description. Athīr tries to solve the paradox by applying to it the laws of negation of a conjunction and negation of a disjunction.\n\nAhmed Alwishah, who has a Ph.D. in Islamic Philosophy and David Sanson, who has a Ph.D. in Philosophy explain that Athīr actually claims that:\n\n(1) \"It is not the case that, if the Liar Sentence is not both true and false, then it is true.\"\n\nAlwishah and Sanson continue:\n\"The general principle behind (1) is clear enough: the negation of a conjunction does not entail the negation of a conjunct; so from not both true and false you cannot infer not false and so true. Abharī appears to be saying that the Liar rests on an elementary scope fallacy! But, of course, Abharī is not entitled to (1). In some cases, the negation of a conjunction does entail the negation of a conjunct: 'not both P and P' for example, entails 'not P'. As a general rule, the negation of a conjunction entails the negation of each conjunct whenever the conjuncts are logically equivalent, i.e., whenever the one follows from the other and vice verse. So Abharī is entitled to (1) only if he is entitled to assume that ‘The Liar Sentence is true’ and ‘The Liar Sentence is false’ are not logically equivalent.\"\n\nThe Liar sentence is a universal proposition (The Liar says All I say ...), so \"if it is (non–vacuously) false it must have a counter–instance\". But in this case scenario, when the only thing that the liar is saying is the single sentence declaring that what he is saying at the moment is false, the only available counter–instance is the Liar sentence itself. When staging the paradox Abharī said: \"if it is not true, then it is necessary that one of his sentences at this moment is true, as long as he utters something. But, he says nothing at this moment other than this sentence. Thus, this sentence is necessarily true and false\" So the explanation provided by Abharī himself demonstrates that both \"'The Liar Sentence is false' and 'The Liar Sentence is true' are logically equivalent. If they are logically equivalent, then, contrary to (1), the negation of the conjunction does entail the negation of each conjunct. Abharī’s 'solution; therefore fails.\"\n\nNaṣīr al-Dīn al-Ṭūsī was a Persian polymath and prolific writer: an astronomer, biologist, chemist, mathematician, philosopher, physician, physicist, scientist, theologian and Marja Taqleed. He adhered to the Ismaili, and subsequently Twelver Shī‘ah Islamic belief systems. The Arab scholar Ibn Khaldun (1332–1406) considered Tusi to be the greatest of the later Persian scholars.\n\nṬūsī's work on the paradox begins with a discussion of the paradox and the solution offered by Abharī, with which Ṭūsī disagrees. As Alwishah and Sanson point out \"Ṭūsī argues that whatever fancy thing (conjunction, conditional) Abharī wants to identify as the truth condition for the Liar Sentence, it will not matter, because pace Abharī, we can generate the paradox without inferring, from the negation of a complex truth condition, the negation of one of its parts. We can argue directly that its being false entails the negation of its being false, and so entails its being true.\"\n\nṬūsī then prepares a stage for his own solution of the Liar paradox, writing that:\nHe does not see a reason that could prevent a declarative sentence to declare something about another declarative sentence.\n\nWith an example of two declarative sentences, (D1) \"It is false\" and (D2) \"Zayd is sitting\", Ṭūsī explains how one declarative sentence (D1) can declare another declarative sentence (D2) to be false: \"It is false that Zayd is sitting\". There is no paradox in the above two declarative sentences because they have different subjects. To generate a paradox a declarative sentence must declare something about itself. If (D1) falsely declares itself to be not (D1) then this false declaration referencing to itself as being \"false\" creates a paradox.\n\nṬūsī writes: \n\nThe above conclusions are very important to the history of Liar Paradox. Alwishah and Sanson point out: \"It is hard to overemphasize how remarkable this passage is. The contemporary reader will be familiar with the idea that the Liar Paradox is a paradox of selfreference. But Ṭūsī is, as far as we know, the first person to express this idea. This passage has no precedent in any tradition. Ṭūsī has performed three remarkable feats in short order. First, his Liar Sentence is singular: its subject is itself, and it declares itself to be false. Gone, then, is the choice between universal or particular Liar Sentence, and the associated problem of adding further assumptions to generate a genuine paradox. Second, he has characterized the paradox as one of self-reference. Third, he has identified a key assumption that might be responsible for generating the entire problem: the assumption that a declarative sentence, by its nature, can declare-something-about anything.\"\n\nRecognizing that, if a declarative sentence that declares itself being false, is false, this does not necessitate it being true. Ṭūsī says that it would be absurd to say that this declarative sentence is true only because it is not false. Ṭūsī writes:\n\nṬūsī then interprets the definitions of \"true\" and \"false\", in an attempt to prove that those definitions should not be taken into consideration when dealing with a declarative sentence that declares itself, as its own subject, to be false.\n\nAl-Baghdādī's definition of \"truth\" and \"falsity\" says that: \"truth is an agreement with the subject, and falsity is the opposite of that\". Ṭūsī argues that this definition cannot be applied to a declarative sentence that declares its own subject to be false because then there are at least two opposite parts that are in disagreement with each other. The same subject cannot be in disagreement with itself. Therefore a self–referenced declarative sentence that declares itself to be false is neither false nor true, and truth/falsity definitions are not applicable to those sentences.\n\nṬūsī stopped short from offering a solution for the Liar sentences discussed by Āmidī \"All that I say at this moment is false\". This sentence presents a different case scenario because it can be interpreted as declaring something about itself, and something about another sentence. The solution for this paradox is absent from Ṭūsī's papers.\n"}
{"id": "33447383", "url": "https://en.wikipedia.org/wiki?curid=33447383", "title": "Metabibliography", "text": "Metabibliography\n\nA metabibliography (or biblio-bibliography) is a bibliography of bibliographies.\n\nBibliographies serve the finding of relevant documents. Metabibliographies serve the finding of the relevant bibliographies in which the relevant documents may be found. One might quote Patrick Wilson:\n\n\"For if knowledge is power, power over knowledge is power to increase one's power; and if the stock of writings is thought of mainly as it represents a stock of knowledge, it is natural to propose treating it as a \"resource\" to be subjected to rational control, managemenet and utilization.\" (Wilson, 1968, p. 145).\n\nMetabibliographies are valuable for building reference collections, but usually of less interest to the average user, who rely on bibliographies selected by others.\n\n\n\n"}
{"id": "1091767", "url": "https://en.wikipedia.org/wiki?curid=1091767", "title": "Non-well-founded set theory", "text": "Non-well-founded set theory\n\nNon-well-founded set theories are variants of axiomatic set theory that allow sets to contain themselves and otherwise violate the rule of well-foundedness. In non-well-founded set theories, the foundation axiom of ZFC is replaced by axioms implying its negation.\n\nThe study of non-well-founded sets was initiated by Dmitry Mirimanoff in a series of papers between 1917 and 1920, in which he formulated the distinction between well-founded and non-well-founded sets; he did not regard well-foundedness as an axiom. Although a number of axiomatic systems of non-well-founded sets were proposed afterwards, they did not find much in the way of applications until Peter Aczel’s hyperset theory in 1988.\n\nThe theory of non-well-founded sets has been applied in the logical modelling of non-terminating computational processes in computer science (process algebra and final semantics), linguistics and natural language semantics (situation theory), philosophy (work on the Liar Paradox), and in a different setting, non-standard analysis.\n\nIn 1917, Dmitry Mirimanoff introduced the concept of well-foundedness of a set:\n\nIn ZFC, there is no infinite descending ∈-sequence by the axiom of regularity. In fact, the axiom of regularity is often called the \"foundation axiom\" since it can be proved within ZFC (that is, ZFC without the axiom of regularity) that well-foundedness implies regularity. In variants of ZFC without the axiom of regularity, the possibility of non-well-founded sets with set-like ∈-chains arises. For example, a set \"A\" such that \"A\" ∈ \"A\" is non-well-founded.\n\nAlthough Mirimanoff also introduced a notion of isomorphism between possibly non-well-founded sets, he considered neither an axiom of foundation nor of anti-foundation. In 1926, Paul Finsler introduced the first axiom that allowed non-well-founded sets. After Zermelo adopted Foundation into his own system in 1930 (from previous work of von Neumann 1925–1929) interest in non-well-founded sets waned for decades. An early non-well-founded set theory was Willard Van Orman Quine’s New Foundations, although it is not merely ZF with a replacement for Foundation.\n\nSeveral proofs of the independence of Foundation from the rest of ZF were published in 1950s particularly by Paul Bernays (1954), following an announcement of the result in earlier paper of his from 1941, and by Ernst Specker who gave a different proof in his Habilitationsschrift of 1951, proof which was published in 1957. Then in 1957 Rieger's theorem was published, which gave a general method for such proof to be carried out, rekindling some interest in non-well-founded axiomatic systems. The next axiom proposal came in a 1960 congress talk of Dana Scott (never published as a paper), proposing an alternative axiom now called SAFA. Another axiom proposed in the late 1960s was Maurice Boffa's axiom of superuniversality, described by Aczel as the highpoint of research of its decade. Boffa's idea was to make foundation fail as badly as it can (or rather, as extensionality permits): Boffa's axiom implies that every extensional set-like relation is isomorphic to the elementhood predicate on a transitive class.\n\nA more recent approach to non-well-founded set theory, pioneered by M. Forti and F. Honsell in the 1980s, borrows from computer science the concept of a bisimulation. Bisimilar sets are considered indistinguishable and thus equal, which leads to a strengthening of the axiom of extensionality. In this context, axioms contradicting the axiom of regularity are known as anti-foundation axioms, and a set that is not necessarily well-founded is called a hyperset.\n\nFour mutually independent anti-foundation axioms are well-known, sometimes abbreviated by the first letter in the following list:\nThey essentially correspond to four different notions of equality for non-well-founded sets. The first of these, AFA, is based on accessible pointed graphs (apg) and states that two hypersets are equal if and only if they can be pictured by the same apg. Within this framework, it can be shown that the so-called Quine atom, formally defined by Q={Q}, exists and is unique.\n\nEach of the axioms given above extends the universe of the previous, so that: V ⊆ A ⊆ S ⊆ F ⊆ B. In the Boffa universe, the distinct Quine atoms form a proper class.\n\nIt is worth emphasizing that hyperset theory is an extension of classical set theory rather than a replacement: the well-founded sets within a hyperset domain conform to classical set theory.\n\nAczel’s hypersets were extensively used by Jon Barwise and John Etchemendy in their 1987 book \"The Liar\", on the liar's paradox; The book is also good introduction to the topic of non-well-founded sets.\n\nBoffa’s superuniversality axiom has found application as a basis for axiomatic nonstandard analysis.\n\n\n\n"}
{"id": "25407", "url": "https://en.wikipedia.org/wiki?curid=25407", "title": "Recursion", "text": "Recursion\n\nRecursion occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no loop or infinite chain of references can occur.\n\nIn mathematics and computer science, a class of objects or methods exhibit recursive behavior when they can be defined by two properties:\n\nFor example, the following is a recursive definition of a person's ancestors:\n\nThe Fibonacci sequence is a classic example of recursion:\n\nformula_1\n\nformula_2\n\nformula_3\n\nMany mathematical axioms are based upon recursive rules. For example, the formal definition of the natural numbers by the Peano axioms can be described as: \"0 is a natural number, and each natural number has a successor, which is also a natural number.\" By this base case and recursive rule, one can generate the set of all natural numbers.\n\nRecursively defined mathematical objects include functions, sets, and especially fractals.\n\nThere are various more tongue-in-cheek \"definitions\" of recursion; see recursive humor.\n\nRecursion is the process a procedure goes through when one of the steps of the procedure involves invoking the procedure itself. A procedure that goes through recursion is said to be 'recursive'.\n\nTo understand recursion, one must recognize the distinction between a procedure and the running of a procedure. A procedure is a set of steps based on a set of rules. The running of a procedure involves actually following the rules and performing the steps. An analogy: a procedure is like a written recipe; running a procedure is like actually preparing the meal.\n\nRecursion is related to, but not the same as, a reference within the specification of a procedure to the execution of some other procedure. For instance, a recipe might refer to cooking vegetables, which is another procedure that in turn requires heating water, and so forth. However, a recursive procedure is where (at least) one of its steps calls for a new instance of the very same procedure, like a sourdough recipe calling for some dough left over from the last time the same recipe was made. This immediately creates the possibility of an endless loop; recursion can only be properly used in a definition if the step in question is skipped in certain cases so that the procedure can complete, like a sourdough recipe that also tells you how to get some starter dough in case you've never made it before. Even if properly defined, a recursive procedure is not easy for humans to perform, as it requires distinguishing the new from the old (partially executed) invocation of the procedure; this requires some administration of how far various simultaneous instances of the procedures have progressed. For this reason recursive definitions are very rare in everyday situations. An example could be the following procedure to find a way through a maze. Proceed forward until reaching either an exit or a branching point (a dead end is considered a branching point with 0 branches). If the point reached is an exit, terminate. Otherwise try each branch in turn, using the procedure recursively; if every trial fails by reaching only dead ends, return on the path that led to this branching point and report failure. Whether this actually defines a terminating procedure depends on the nature of the maze: it must not allow loops. In any case, executing the procedure requires carefully recording all currently explored branching points, and which of their branches have already been exhaustively tried.\n\nLinguist Noam Chomsky among many others has argued that the lack of an upper bound on the number of grammatical sentences in a language, and the lack of an upper bound on grammatical sentence length (beyond practical constraints such as the time available to utter one), can be explained as the consequence of recursion in natural language. This can be understood in terms of a recursive definition of a syntactic category, such as a sentence. A sentence can have a structure in which what follows the verb is another sentence: \"Dorothy thinks witches are dangerous\", in which the sentence \"witches are dangerous\" occurs in the larger one. So a sentence can be defined recursively (very roughly) as something with a structure that includes a noun phrase, a verb, and optionally another sentence. This is really just a special case of the mathematical definition of recursion.\n\nThis provides a way of understanding the creativity of language—the unbounded number of grammatical sentences—because it immediately predicts that sentences can be of arbitrary length: \"Dorothy thinks that Toto suspects that Tin Man said that...\". There are many structures apart from sentences that can be defined recursively, and therefore many ways in which a sentence can embed instances of one category inside another. Over the years, languages in general have proved amenable to this kind of analysis.\n\nRecently, however, the generally accepted idea that recursion is an essential property of human language has been challenged by Daniel Everett on the basis of his claims about the Pirahã language. Andrew Nevins, David Pesetsky and Cilene Rodrigues are among many who have argued against this. Literary self-reference can in any case be argued to be different in kind from mathematical or logical recursion.\n\nRecursion plays a crucial role not only in syntax, but also in natural language semantics. The word \"and\", for example, can be construed as a function that can apply to sentence meanings to create new sentences, and likewise for noun phrase meanings, verb phrase meanings, and others. It can also apply to intransitive verbs, transitive verbs, or ditransitive verbs. In order to provide a single denotation for it that is suitably flexible, \"and\" is typically defined so that it can take any of these different types of meanings as arguments. This can be done by defining it for a simple case in which it combines sentences, and then defining the other cases recursively in terms of the simple one. \n\nA recursive grammar is a formal grammar that contains recursive production rules.\n\nRecursion is sometimes used humorously in computer science, programming, philosophy, or mathematics textbooks, generally by giving a circular definition or self-reference, in which the putative recursive step does not get closer to a base case, but instead leads to an infinite regress. It is not unusual for such books to include a joke entry in their glossary along the lines of:\n\nA variation is found on page 269 in the index of some editions of Brian Kernighan and Dennis Ritchie's book \"The C Programming Language\"; the index entry recursively references itself (\"recursion 86, 139, 141, 182, 202, 269\"). The earliest version of this joke was in \"Software Tools\" by Kernighan and Plauger, and also appears in \"The UNIX Programming Environment\" by Kernighan and Pike. It did not appear in the first edition of \"The C Programming Language\".\n\nAnother joke is that \"To understand recursion, you must understand recursion.\" In the English-language version of the Google web search engine, when a search for \"recursion\" is made, the site suggests \"Did you mean: \"recursion\".\" An alternative form is the following, from Andrew Plotkin: \"If you already know what recursion is, just remember the answer. Otherwise, find someone who is standing closer to Douglas Hofstadter than you are; then ask him or her what recursion is.\"\n\nRecursive acronyms can also be examples of recursive humor. PHP, for example, stands for \"PHP Hypertext Preprocessor\", WINE stands for \"WINE Is Not an Emulator.\" and GNU stands for \"GNU's not Unix\".\n\nThe canonical example of a recursively defined set is given by the natural numbers:\n\nAnother interesting example is the set of all \"true reachable\" propositions in an axiomatic system.\n\n\nThis set is called 'true reachable propositions' because in non-constructive approaches to the foundations of mathematics, the set of true propositions may be larger than the set recursively constructed from the axioms and rules of inference. See also Gödel's incompleteness theorems.\n\nFinite subdivision rules are a geometric form of recursion, which can be used to create fractal-like images. A subdivision rule starts with a collection of polygons labelled by finitely many labels, and then each polygon is subdivided into smaller labelled polygons in a way that depends only on the labels of the original polygon. This process can be iterated. The standard `middle thirds' technique for creating the Cantor set is a subdivision rule, as is barycentric subdivision.\n\nA function may be partly defined in terms of itself. A familiar example is the Fibonacci number sequence: \"F\"(\"n\") = \"F\"(\"n\" − 1) + \"F\"(\"n\" − 2). For such a definition to be useful, it must lead to non-recursively defined values, in this case \"F\"(0) = 0 and \"F\"(1) = 1.\n\nA famous recursive function is the Ackermann function, which—unlike the Fibonacci sequence—cannot easily be expressed without recursion.\n\nApplying the standard technique of proof by cases to recursively defined sets or functions, as in the preceding sections, yields structural induction, a powerful generalization of mathematical induction widely used to derive proofs in mathematical logic and computer science.\n\nDynamic programming is an approach to optimization that restates a multiperiod or multistep optimization problem in recursive form. The key result in dynamic programming is the Bellman equation, which writes the value of the optimization problem at an earlier time (or earlier step) in terms of its value at a later time (or later step).\n\nIn set theory, this is a theorem guaranteeing that recursively defined functions exist. Given a set \"X\", an element \"a\" of \"X\" and a function formula_7, the theorem states that there is a unique function formula_8 (where formula_4 denotes the set of natural numbers including zero) such that\nfor any natural number \"n\".\n\nTake two functions formula_8 and formula_13 such that:\n\nwhere \"a\" is an element of \"X\".\n\nIt can be proved by mathematical induction that formula_18 for all natural numbers \"n\":\n\nBy induction, formula_18 for all formula_25.\n\nA common method of simplification is to divide a problem into subproblems of the same type. As a computer programming technique, this is called divide and conquer and is key to the design of many important algorithms. Divide and conquer serves as a top-down approach to problem solving, where problems are solved by solving smaller and smaller instances. A contrary approach is dynamic programming. This approach serves as a bottom-up approach, where problems are solved by solving larger and larger instances, until the desired size is reached.\n\nA classic example of recursion is the definition of the factorial function, given here in C code:\n\nIf not having reached the base case and returning with value every instantiation of the above function creates a new instance of the function, passing to it an input reduced by (), and returns the result of this (recursive) call, multiplied by its own value of , analogously to the mathematical definition of the factorial.\n\nRecursion in computer programming is exemplified when a function is defined in terms of simpler, often smaller versions of itself. The solution to the problem is then devised by combining the solutions obtained from the simpler versions of the problem. One example application of recursion is in parsers for programming languages. The great advantage of recursion is that an infinite set of possible sentences, designs or other data can be defined, parsed or produced by a finite computer program.\n\nRecurrence relations are equations to define one or more sequences recursively. Some specific kinds of recurrence relation can be \"solved\" to obtain a non-recursive definition.\n\nUse of recursion in an algorithm has both advantages and disadvantages. The main advantage is usually simplicity. The main disadvantage is often that the algorithm may require large amounts of memory if the depth of the recursion is very large.\n\nThe Russian Doll or Matryoshka Doll is a physical artistic example of the recursive concept.\n\nRecursion has been used in paintings since Giotto's \"Stefaneschi Triptych\", made in 1320. Its central panel contains the kneeling figure of Cardinal Stefaneschi, holding up the triptych itself as an offering.\n\nM. C. Escher's \"Print Gallery\" (1956) is a print which depicts a distorted city which contains a gallery which recursively contains the picture, and so \"ad infinitum\".\n\n\n"}
{"id": "36983", "url": "https://en.wikipedia.org/wiki?curid=36983", "title": "Recursive acronym", "text": "Recursive acronym\n\nA recursive acronym is an acronym that refers to itself. The term was first used in print in 1979 in Douglas Hofstadter's book \"Gödel, Escher, Bach: An Eternal Golden Braid\", in which Hofstadter invents the acronym GOD, meaning \"GOD Over Djinn\", to help explain infinite series, and describes it as a recursive acronym. Other references followed, however the concept was used as early as 1968 in John Brunner's science fiction novel \"Stand on Zanzibar\". In the story, the acronym EPT (Education for Particular Task) later morphed into \"Eptification for Particular Task\".\n\nRecursive acronyms typically form backwardly: either an existing ordinary acronym is given a new explanation of what the letters stand for, or a name is turned into an acronym by giving the letters an explanation of what they stand for, in each case with the first letter standing recursively for the whole acronym.\n\nIn computing, an early tradition in the hacker community (especially at MIT) was to choose acronyms and abbreviations that referred humorously to themselves or to other abbreviations. Perhaps the earliest example in this context, from 1960 the backronym \"Mash Until No Good\" was created to describe Mung, and a while after it was revised to \"Mung Until No Good\". It lived on as a recursive command in the editing language TECO. In 1977 or 1978 came TINT (\"TINT Is Not TECO\"), an editor for MagicSix written (and named) by Ted Anderson. This inspired the two MIT Lisp Machine editors called EINE (\"EINE Is Not Emacs\", German for \"one\") and ZWEI (\"ZWEI Was EINE Initially\", German for \"two\"). These were followed by Richard Stallman's GNU (GNU's Not Unix). Many others also include negatives, such as denials that the thing defined is or resembles something else (which the thing defined does in fact resemble or is even derived from), to indicate that, despite the similarities, it was distinct from the program on which it was based.\n\nAn earlier example appears in a 1976 textbook on data structures, in which the pseudo-language SPARKS is used to define the algorithms discussed in the text. \"SPARKS\" is claimed to be a non-acronymic name, but \"several cute ideas have been suggested\" as expansions of the name. One of the suggestions is \"Smart Programmers Are Required to Know SPARKS\". (this example is tail recursive)\n\n\n\nSome organizations have been named or renamed in this way:\n\n\n"}
{"id": "20110874", "url": "https://en.wikipedia.org/wiki?curid=20110874", "title": "Reference", "text": "Reference\n\nReference is a relation between objects in which one object designates, or acts as a means by which to connect to or link to, another object. The first object in this relation is said to \"refer to\" the second object. It is called a \"name\" for the second object. The second object, the one to which the first object refers, is called the \"referent\" of the first object. A name is usually a phrase or expression, or some other symbolic representation. Its referent may be anything – a material object, a person, an event, an activity, or an abstract concept.\n\nReferences can take on many forms, including: a thought, a sensory perception that is audible (onomatopoeia), visual (text), olfactory, or tactile, emotional state, relationship with other, spacetime coordinate, symbolic or alpha-numeric, a physical object or an energy projection. In some cases, methods are used that intentionally hide the reference from some observers, as in cryptography.\n\nReferences feature in many spheres of human activity and knowledge, and the term adopts shades of meaning particular to the contexts in which it is used. Some of them are described in the sections below.\n\nThe word \"reference\" is derived from Middle English \"referren\", from Middle French \"référer\", from Latin \"referre\", \"to carry back\", formed from the prefix \"re\"- and \"ferre\", \"to bear\". A number of words derive from the same root, including \"refer\", \"referee\", \"referential\", \"referent\", \"referendum\".\n\nThe verb \"refer (to)\" and its derivatives may carry the sense of \"link to\" or \"connect to\", as in the meanings of \"reference\" described in this article. Another sense is \"consult\"; this is reflected in such expressions as reference work, reference desk, job reference, etc.\n\nIn semantics, reference is generally construed as the relationships between nouns or pronouns and objects that are named by them. Hence, the word \"John\" refers to the person John. The word \"it\" refers to some previously specified object. The object referred to is called the \"referent\" of the word. Sometimes the word-object relation is called \"denotation\"; the word denotes the object. The converse relation, the relation from object to word, is called \"exemplification\"; the object exemplifies what the word denotes. In syntactic analysis, if a word refers to a previous word, the previous word is called the \"antecedent\".\n\nGottlob Frege argued that reference cannot be treated as identical with meaning: \"Hesperus\" (an ancient Greek name for the evening star) and \"Phosphorus\" (an ancient Greek name for the morning star) both refer to Venus, but the astronomical fact that '\"Hesperus\" is \"Phosphorus\"' can still be informative, even if the \"meanings\" of \"Hesperus\" and \"Phosphorus\" are already known. This problem led Frege to distinguish between the sense and reference of a word. Some cases seem to be too complicated to be classified within this framework; the acceptance of the notion of secondary reference may be necessary to fill the gap. See also Opaque context.\n\nThe very concept of the linguistic sign is the combination of content and expression, the former of which may refer entities in the world or refer more abstract concepts, e.g. thought.\nCertain parts of speech exist only to express reference, namely anaphora such as pronouns. The subset of reflexives expresses co-reference of two participants in a sentence. These could be the agent (actor) and patient (acted on), as in \"The man washed himself\", the theme and recipient, as in \"I showed Mary to herself\", or various other possible combinations.\n\nIn computer science, references are data types that refer to an object elsewhere in memory and are used to construct a wide variety of data structures, such as linked lists. Generally, a reference is a value that enables a program to directly access the particular data item. Most programming languages support some form of reference. For the specific type of reference used in the C++ language, see reference (C++).\n\nThe notion of reference is also important in relational database theory; see referential integrity.\n\nReferences to many types of printed matter may come in an electronic or machine-readable form. For books, there exists the ISBN and for journal articles, the Digital object identifier (DOI) is gaining relevance. Information on the Internet may be referred to by a Uniform Resource Identifier (URI).\n\nIn terms of mental processing, a self-reference is used in psychology to establish identification with a mental state during self-analysis. This seeks to allow the individual to develop own frames of reference in a greater state of immediate awareness. However, it can also lead to circular reasoning, preventing evolution of thought.\n\nAccording to Perceptual Control Theory (PCT), a reference condition is the state toward which a control system's output tends to alter a controlled quantity. The main proposition is that \"All behavior is oriented all of the time around the control of certain quantities with respect to specific reference conditions.\"\n\nIn academics and scholarship, an author-title-date information in bibliographies and footnotes, specifying complete works of other people. Copying of material by another author without proper citation or without required permissions is plagiarism.\n\nKeeping a diary allows an individual to use references for personal organization, whether or not anyone else understands the systems of reference used. However, scholars have studied methods of reference because of their key role in communication and co-operation between \"different\" people, and also because of misunderstandings that can arise. Modern academic study of reference has been developing since the 19th century.\n\nIn scholarship, a reference may be a citation of a text that has been used in the creation of a piece of work such as an essay, report, or oration. Its primary purpose is to allow people who read such work to examine the author's sources, either for validity or to learn more about the subject. Such items are often listed at the end of an article or book in a section marked \"Bibliography\" or \"References\". A bibliographical section often contains works not cited by the author, but used as background reading or listed as potentially useful to the reader. A reference section contains only those works cited by the author(s) in the main text.\n\nIn patent law, a reference is a document that can be used to show the state of knowledge at a given time and that therefore may make a claimed invention obvious or anticipated. Examples of references are patents of any country, magazine articles, Ph.D. theses that are indexed and thus accessible to those interested in finding information about the subject matter, and to some extent Internet material that is similarly accessible.\n\nIn art, a reference is an item from which a work is based. This may include:\nAnother example of reference is samples of various musical works being incorporated into a new one.\n\n\n"}
{"id": "5550409", "url": "https://en.wikipedia.org/wiki?curid=5550409", "title": "Reference interview", "text": "Reference interview\n\nA reference interview is a conversation between a librarian and a library user, usually at a reference desk, in which the librarian responds to the user's initial explanation of his or her information need by first attempting to clarify that need and then by directing the user to appropriate information resources.\n\nBopp & Smith (1995) defines the reference interview as the \"conversation between a member of the library reference staff and a library user for the purpose of clarifying the user’s needs and aiding the user in meeting those needs\". \n\nAccording to ODLIS, the reference interview is \"the interpersonal communication that occurs between a reference librarian and a library user to determine the person's specific information need(s), which may turn out to be different from the reference question as initially posed...A reference interview may occur in person, by telephone, or electronically (usually via e-mail) at the request of the user, but a well-trained reference librarian will sometimes initiate communication if a hesitant user appears to need assistance\".\n\nThe reference interview is structured to help the librarian provide answers to the library user. In general, the interview is composed of the following stages.\n\n\nThese stages may occur in loops, for example when a clarification of the question leads to the need to establish more background information on the query topic. These steps are designed to put the user at their ease, and then help ensure that they have correctly explained what they require. When the reference librarian believes that the query is fully understood, they attempt to provide resources that help satisfy it. An important and often overlooked final step is checking that the information or service provided was indeed what the library user required.\n\nThe purpose behind the reference interview structure is to ensure that the library user's information need is satisfied. The librarian can use a number of interview techniques to help identify the user's exact need. Poor reference interview skills may lead to misinterpretation of the real question, a lack of real help and an unsatisfied library user.\n\nLibrarians use many techniques to help identify a user’s information need. With body language, repetition and paraphrasing of what the user says, the interviewer can encourage the user to give more information about what they need. Asking open questions establishes context and helps to identify exactly what is required. A lack of follow-up, or checking that the user found what they required, is arguably one of the most common mistakes made in the reference interview.\n\nOne of the biggest problems with providing an effective reference service is that of badly formed queries. In this instance, the user's reference question doesn't match up to the information they actually need. Badly formed queries may lead to user frustration, as they perceive that the reference interview is not solving their problem. \n\nMany of the techniques used in the reference interview are geared towards developing a badly formed query until a sense of the user's true information need is gained. A great degree of care must be taken when helping users to develop their query. The librarian typically has little insight into the social and psychological barriers that might be preventing the user from explaining their question accurately. Anything from anxiety from an approaching deadline to lack of confidence with language can get in the way.\n\nAs libraries have begun to adopt electronic technology into their operations, the idea of the virtual reference interview has come to light. Virtual reference is a reference service initiated electronically, often in real-time. The user and librarian do not meet face-to-face. Virtual reference services can be conducted, for example, in internet chat, videoconferencing, email, co-browsing and instant messaging. \n\nUptake of virtual reference has not been as swift as some had predicted. The complexity of virtual reference may be to blame, as users want information quickly and with the minimum of fuss. Some evidence suggests that the problem lies with poor uptake and training among library staff.\n\nLibrary users are not always comfortable with reference services, let alone satisfied with them. Unobtrusive user studies suggest that only around 55% to 65% of users leave a reference interview satisfied with the result and willing to return. Demographics, social factors and users’ preconceptions about libraries all contribute to this figure. Embarrassment, shyness, and anxiety can prevent a user from approaching the reference desk, and poor signposting and explanation of services can mean that some customers aren't aware that the reference service exists. To be as effective as possible, libraries must be proactive in publicizing their services and reducing the stigma of asking for help.\n\nFor a long time, the value of the reference interview has stood unquestioned. More recently, with technological developments streamlining some of the tasks which once comprised the interview, some researchers are beginning to question the validity of the reference interview, and the investment that a reference librarian represents. Others argue that reference services should broaden their target audience. As people increasingly use the internet to make major, life-affecting decisions, so they also require the services of professionals who are able to provide help in this environment. If this proves to be the case, it will become more vital that the reference interview be conducted professionally and successfully. In the age of information overload, a successful reference interview may empower users to confidently make such decisions in their lives.\n\n\n\n"}
{"id": "25727", "url": "https://en.wikipedia.org/wiki?curid=25727", "title": "Reference work", "text": "Reference work\n\nA reference work is a book or periodical (or its electronic equivalent) to which one can refer for information. The information is intended to be found quickly when needed. Reference works are usually \"referred\" to for particular pieces of information, rather than read beginning to end. The writing style used in these works is informative; the authors avoid use of the first person, and emphasize facts. Many reference works are compiled by a team of contributors whose work is coordinated by one or more editors rather than by an individual author. Indices are commonly provided in many types of reference work. Updated editions are usually published as needed, in some cases annually (e.g. \"Whitaker's Almanack\", \"Who's Who\"). Reference works include dictionaries, thesauruses, encyclopedias, almanacs, bibliographies, and catalogs (e.g. catalogs of libraries, museums or the works of individual artists). Many reference works are available in electronic form and can be obtained as application software, CD-ROMs, DVDs, or online through the Internet.\n\nA reference work is useful to its users if they attribute some degree of trust.\n\nIn comparison, a reference book or reference-only book in a library is one that may only be used in the library and may not be borrowed from the library. Many such books are reference works (in the first sense), which are, usually, used briefly or photocopied from, and therefore, do not need to be borrowed. Keeping reference books in the library assures that they will always be available for use on demand. Some reference-only books are too valuable to permit borrowers to take them out. Reference-only items may be shelved in a reference collection located separately from circulating items. Some libraries consist entirely, or to a large extent, of books which may not be borrowed.\n\nAn electronic resource is a piece of information that is stored electronically, which is usually found on a computer, including information that is available on the internet. Libraries offer numerous types of electronic resources, such as subject research guides, indices, electronic books and texts, electronic journals, library catalogs, reference sources, statistical sources, sound recordings, and image databases.\n\n\nSheehy's Guide is less international in its scope than Walford: \"It seems that Walford is a somewhat better balanced work than Winchell, and is certainly much more comprehensive\"--\"American Reference Books Annual\", quoted in Walford, A. J. (1981) \"Walford's Concise Guide to Reference Material\". London: Library Association ; p. 19.\n"}
{"id": "40849944", "url": "https://en.wikipedia.org/wiki?curid=40849944", "title": "Sources for the historicity of Jesus", "text": "Sources for the historicity of Jesus\n\nChristian sources, such as the New Testament books in the Christian Bible, include detailed stories about Jesus but scholars differ on the historicity of specific episodes described in the Biblical accounts of Jesus. The only two events subject to \"almost universal assent\" are that Jesus was baptized by John the Baptist and was crucified by the order of the Roman Prefect Pontius Pilate.\n\nNon-Christian sources that are used to study and establish the historicity of Jesus include Jewish sources such as Josephus, and Roman sources such as Tacitus. These sources are compared to Christian sources such as the Pauline Epistles and the Synoptic Gospels. These sources are usually independent of each other (e.g. Jewish sources do not draw upon Roman sources), and similarities and differences between them are used in the authentication process.\n\nIn a review of the state of research, the Jewish scholar Amy-Jill Levine stated that \"no single picture of Jesus has convinced all, or even most scholars\" and that all portraits of Jesus are subject to criticism by some group of scholars.\n\nThe writings of the 1st century Romano-Jewish historian Flavius Josephus include references to Jesus and the origins of Christianity. Josephus' \"Antiquities of the Jews\", written around 93–94 CE, includes two references to Jesus in Books and .\n\nOf the two passages, the James passage in Book 20 is used by scholars to support the existence of Jesus, the \"Testimonium Flavianum\" in Book 18 his crucifixion. Josephus' James passage attests to the existence of Jesus as a historical person and that some of his contemporaries considered him the Messiah. According to Bart Ehrman, Josephus' passage about Jesus was altered by a Christian scribe, including the reference to Jesus as the Messiah.\n\nA textual argument against the authenticity of the James passage is that the use of the term \"Christos\" there seems unusual for Josephus. An argument based on the flow of the text in the document is that, given that the mention of Jesus appears in the \"Antiquities\" before that of the John the Baptist, a Christian interpolator may have inserted it to place Jesus in the text before John. A further argument against the authenticity of the James passage is that it would have read well even without a reference to Jesus.\n\nThe passage deals with the death of \"James the brother of Jesus\" in Jerusalem. Whereas the works of Josephus refer to at least twenty different people with the name Jesus, this passage specifies that this Jesus was the one \"who was called Christ\". Louis Feldman states that this passage, above others, indicates that Josephus did say something about Jesus.\n\nModern scholarship has almost universally acknowledged the authenticity of the reference in of the \"Antiquities\" to \"the brother of Jesus, who was called Christ, whose name was James\", and considers it as having the highest level of authenticity among the references of Josephus to Christianity.\n\nThe \"Testimonium Flavianum\" (meaning the testimony of Flavius [Josephus]) is the name given to the passage found in of the \"Antiquities\" in which Josephus describes the condemnation and crucifixion of Jesus at the hands of the Roman authorities. Scholars have differing opinions on the total or partial authenticity of the reference in the passage to the execution of Jesus by Pontius Pilate. The general scholarly view is that while the \"Testimonium Flavianum\" is most likely not authentic in its entirety, it is broadly agreed upon that it originally consisted of an authentic nucleus with a reference to the execution of Jesus by Pilate which was then subject to Christian interpolation. Although the exact nature and extent of the Christian redaction remains unclear, there is broad consensus as to what the original text of the \"Testimonium\" by Josephus would have looked like.\n\nThe references found in \"Antiquities\" have no parallel texts in the other work by Josephus such as the \"Jewish War\", written twenty years earlier, but some scholars have provided explanations for their absence, such as that the \"Antiquities\" covers a longer time period and that during the twenty-year gap between the writing of the \"Jewish Wars\" (c. 70 CE) and \"Antiquities\" (after 90 CE) Christians had become more important in Rome and were hence given attention in the \"Antiquities\".\n\nA number of variations exist between the statements by Josephus regarding the deaths of James and the New Testament accounts. Scholars generally view these variations as indications that the Josephus passages are not interpolations, because a Christian interpolator would more likely have made them correspond to the Christian traditions. Robert Eisenman provides numerous early Christian sources that confirm the Josephus testament, that James was the brother of Jesus.\n\nThe Roman historian and senator Tacitus referred to Christ, his execution by Pontius Pilate and the existence of early Christians in Rome in his final work, \"Annals\" (c. AD 116), . The relevant passage reads: \"called Christians by the populace. Christus, from whom the name had its origin, suffered the extreme penalty during the reign of Tiberius at the hands of one of our procurators, Pontius Pilatus.\"\n\nScholars generally consider Tacitus's reference to the execution of Jesus by Pontius Pilate to be both authentic, and of historical value as an independent Roman source about early Christianity that is in unison with other historical records. William L. Portier has stated that the consistency in the references by Tacitus, Josephus and the letters to Emperor Trajan by Pliny the Younger reaffirm the validity of all three accounts.\n\nTacitus was a patriotic Roman senator and his writings shows no sympathy towards Christians. Andreas Köstenberger and separately Robert E. Van Voorst state that the tone of the passage towards Christians is far too negative to have been authored by a Christian scribe – a conclusion shared by John P. Meier Robert E. Van Voorst states that \"of all Roman writers, Tacitus gives us the most precise information about Christ\".\n\nJohn Dominic Crossan considers the passage important in establishing that Jesus existed and was crucified, and states: \"That he was crucified is as sure as anything historical can ever be, since both Josephus and Tacitus... agree with the Christian accounts on at least that basic fact.\" Bart D. Ehrman states: \"Tacitus's report confirms what we know from other sources, that Jesus was executed by order of the Roman governor of Judea, Pontius Pilate, sometime during Tiberius's reign.\" Eddy and Boyd state that it is now \"firmly established\" that Tacitus provides a non-Christian confirmation of the crucifixion of Jesus.\n\nAlthough the majority of scholars consider it to be genuine, a few scholars question the authenticity of the passage given that Tacitus was born 25 years after Jesus' death.\n\nSome scholars have debated the historical value of the passage given that Tacitus does not reveal the source of his information. Gerd Theissen and Annette Merz argue that Tacitus at times had drawn on earlier historical works now lost to us, and he may have used official sources from a Roman archive in this case; however, if Tacitus had been copying from an official source, some scholars would expect him to have labeled Pilate correctly as a \"prefect\" rather than a \"procurator\". Theissen and Merz state that Tacitus gives us a description of widespread prejudices about Christianity and a few precise details about \"Christus\" and Christianity, the source of which remains unclear. However, Paul R. Eddy has stated that given his position as a senator Tacitus was also likely to have had access to official Roman documents of the time and did not need other sources.\n\nMichael Martin notes that the authenticity of this passage of the Annals has also been disputed on the grounds that Tacitus would not have used the word “messiah” in an authentic Roman document.\n\nWeaver notes that Tacitus spoke of the persecution of Christians, but no other Christian author wrote of this persecution for a hundred years.\n\nHotema notes that this passage was not quoted by any Church father up to the 15th century, although the passage would have been very useful to them in their work; and that the passage refers to the Christians in Rome being a multitude, while at that time the Christian congregation in Rome would actually have been very small.\n\nRichard Carrier has put forward the ideas that the 'Christ, the author of this name, was executed by the procurator Pontius Pilate in the reign of Tiberius' line is a Christian interpolation and that Tacitus wrote about Chrestians not Christians.\n\nScholars have also debated the issue of hearsay in the reference by Tacitus. Charles Guignebert argued that \"So long as there is that possibility [that Tacitus is merely echoing what Christians themselves were saying], the passage remains quite worthless\". R. T. France states that the Tacitus passage is at best just Tacitus repeating what he had heard through Christians. However, Paul R. Eddy has stated that as Rome's preeminent historian, Tacitus was generally known for checking his sources and was not in the habit of reporting gossip. Tacitus was a member of the Quindecimviri sacris faciundis, a council of priests whose duty it was to supervise foreign religious cults in Rome, which as Van Voorst points out, makes it reasonable to suppose that he would have acquired knowledge of Christian origins through his work with that body.\n\nMara (son of Sarapion) was a Stoic philosopher from the Roman province of Syria. Sometime between 73 AD and the 3rd century, Mara wrote a letter to his son (also called Sarapion) which may contain an early non-Christian reference to the crucifixion of Jesus.\n\nThe letter refers to the unjust treatment of \"three wise men\": the murder of Socrates, the burning of Pythagoras, and the execution of \"the wise king\" of the Jews. The author explains that in all three cases the wrongdoing resulted in the future punishment of those responsible by God and that when the wise are oppressed, not only does their wisdom triumph in the end, but God punishes their oppressors.\n\nThe letter includes no Christian themes and the author is presumed to be a pagan. Some scholars see the reference to the execution of the \"wise king\" of the Jews as an early non-Christian reference to Jesus. Criteria that support the non-Christian origin of the letter include the observation that \"king of the Jews\" was not a Christian title, and that the letter's premise that Jesus lives on based on the wisdom of his teachings is in contrast to the Christian concept that Jesus continues to live through his resurrection.\n\nScholars such as Robert Van Voorst see little doubt that the reference to the execution of the \"king of the Jews\" is about the death of Jesus. Others such as Craig A. Evans see less value in the letter, given its uncertain date, and the possible ambiguity in the reference.\n\nThe Roman historian Suetonius (c. 69 – after 122 CE) made references to early Christians and their leader in his work \"Lives of the Twelve Caesars\" (written 121 CE). The references appear in and which describe the lives of Roman Emperors Claudius and Nero. The Nero 16 passage refers to the abuses by Nero and mentions how he inflicted punishment on Christians – which is generally dated to around AD 64. This passage shows the clear contempt of Suetonius for Christians - the same contempt expressed by Tacitus and Pliny the younger in their writings, but does not refer to Jesus himself.\n\nThe earlier passage in Claudius, may include a reference to Jesus, but is subject to debate among scholars. In Suetonius refers to the expulsion of Jews by Claudius and states:\n\nThe reference in Claudius 25 involves the agitations in the Jewish community which led to the expulsion of some Jews from Rome by Claudius, and is likely the same event mentioned in the Acts of the Apostles (). Most historians date this expulsion to around AD 49–50. Suetonius refers to the leader of the Christians as \"Chrestus\", a term also used by used by Tacitus, referred in Latin dictionaries as a (amongst other things) version of 'Christus'. However, the wording used by Suetonius implies that Chrestus was alive at the time of the disturbance and was agitating the Jews in Rome. This weakens the historical value of his reference as a whole, and there is no overall scholarly agreement about its value as a reference to Jesus. However, the confusion of Suetonius also points to the lack of Christian interpolation, for a Christian scribe would not have confused the Jews with Christians.\n\nMost scholars assume that in the reference Jesus is meant and that the disturbances mentioned were due to the spread of Christianity in Rome. However, scholars are divided on the value of the Suetonius' reference. Some scholars such as Craig A. Evans, John Meier and Craig S. Keener see it as a likely reference to Jesus. Others such as Stephen Benko and H. Dixon Slingerland see it as having little or no historical value.\n\nMenahem Stern states Suetonius definitely was referring to Jesus; because he would have added \"a certain\" to Chrestus if he had meant some unknown agitator.\n\nThe Babylonian Talmud in a few cases includes possible references to Jesus using the terms \"Yeshu\", \"Yeshu ha-Notzri\", \"ben Stada\", and \"ben Pandera\". Some of these references probably date back to the Tannaitic period (70–200 CE). In some cases, it is not clear if the references are to Jesus, or other people, and scholars continue to debate their historical value, and exactly which references, if any, may be to Jesus.\n\nRobert Van Voorst states that the scarcity of Jewish references to Jesus is not surprising, given that Jesus was not a prominent issue for the Jews during the first century, and after the devastation caused by the Siege of Jerusalem in the year 70, Jewish scholars were focusing on preserving Judaism itself, rather than paying much attention to Christianity.\n\nRobert Eisenman argues that the derivation of Jesus of Nazareth from \"ha-Notzri\" is impossible on etymological grounds, as it would suggest rather \"the Nazirite\" rather than \"the Nazarene\".\n\nVan Voorst states that although the question of who was referred to in various points in the Talmud remains subject to debate among scholars, in the case of \"Sanhedrin 43a\" (generally considered the most important reference to Jesus in rabbinic literature), Jesus can be confirmed as the subject of the passage, not only from the reference itself, but from the context that surrounds it, and there is little doubt that it refers to the death of Jesus of Nazareth. Christopher M. Tuckett states that if it is accepted that death narrative of Sanhedrin 43a refers to Jesus of Nazareth then it provides evidence of Jesus' existence and execution.\n\nAndreas Kostenberger states that the passage is a Tannaitic reference to the trial and death of Jesus at Passover and is most likely earlier than other references to Jesus in the Talmud. The passage reflects hostility toward Jesus among the rabbis and includes this text:\n\nIt is taught: On the eve of Passover they hung Yeshu and the crier went forth for forty days beforehand declaring that \"[Yeshu] is going to be stoned for practicing witchcraft, for enticing and leading Israel astray. Anyone who knows something to clear him should come forth and exonerate him.\" But no one had anything exonerating for him and they hung him on the eve of Passover. \n\nPeter Schäfer states that there can be no doubt that the narrative of the execution of Jesus in the Talmud refers to Jesus of Nazareth, but states that the rabbinic literature in question are not Tannaitic but from a later Amoraic period and may have drawn on the Christian gospels, and may have been written as responses to them. Bart Ehrman and separately Mark Allan Powell state that given that the Talmud references are quite late, they can give no historically reliable information about the teachings or actions of Jesus during his life.\n\nAnother reference in early second century Rabbinic literature (Tosefta Hullin II 22) refers to Rabbi Eleazar ben Dama who was bitten by a snake, but was denied healing in the name of Jesus by another Rabbi for it was against the law, and thus died. This passage reflects the attitude of Jesus' early Jewish opponents, i.e. that his miracles were based on evil powers.\n\nEddy and Boyd, who question the value of several of the Talmudic references state that the significance of the Talmud to historical Jesus research is that it never denies the existence of Jesus, but accuses him of sorcery, thus indirectly confirming his existence. R. T. France and separately Edgar V. McKnight state that the divergence of the Talmud statements from the Christian accounts and their negative nature indicate that they are about a person who existed. Craig Blomberg states that the denial of the existence of Jesus was never part of the Jewish tradition, which instead accused him of being a sorcerer and magician, as also reflected in other sources such as Celsus. Andreas Kostenberger states that the overall conclusion that can be drawn from the references in the Talmud is that Jesus was a historical person whose existence was never denied by the Jewish tradition, which instead focused on discrediting him.\n\nPliny the Younger (c. 61 – c. 112), the provincial governor of Pontus and Bithynia, wrote to Emperor Trajan \"c\". 112 concerning how to deal with Christians, who refused to worship the emperor, and instead worshiped \"Christus\". Charles Guignebert, who does not doubt that Jesus of the Gospels lived in Gallilee in the 1st century, nevertheless dismisses this letter as acceptable evidence for a historical Jesus.\n\nThallus, of whom very little is known, and none of whose writings survive, wrote a history allegedly around the middle to late first century CE, to which Eusebius referred. Julius Africanus, writing \"c\" 221, links a reference in the third book of the \"History\" to the period of darkness described in the crucifixion accounts in three of the Gospels . It is not known whether Thallus made any mention to the crucifixion accounts; if he did, it would be the earliest noncanonical reference to a gospel episode, but its usefulness in determining the historicity of Jesus is uncertain. The dating of Thallus is dependent on him writing about an event during the 207th Olympiad (49–52 AD), which means he wrote after that date, not near that date. This depends on the text being corrupt, which would mean Thallus could have been writing after the 217th Olympiad (89–92 AD), or even the 167th Olympiad (112–109 BC). He is first referenced by Theophilus, writing around 180 AD, which means Thallus could have written any time between 109 BC and 180 AD. All we know is Thallus mentioned a solar eclipse, and as solar eclipses are not possible at Passover, that would mean Thallus was not talking about the crucifixion of Jesus at all.\n\nPhlegon of Tralles, AD 80–140, similar to Thallus, Julius Africanus mentions a historian named Phlegon who wrote a chronicle of history around AD 140, where he records:\n“Phlegon records that, in the time of Tiberius Caesar, at full moon, there was a full eclipse of the sun from the sixth to the ninth hour.” (Africanus, Chronography, 18:1) Phlegon is also mentioned by Origen (an early church theologian and scholar, born in Alexandria):\n“Now Phlegon, in the thirteenth or fourteenth book, I think, of his Chronicles, not only ascribed to Jesus a knowledge of future events . . . but also testified that the result corresponded to His predictions.” (Origen Against Celsus, Book 2, Chapter 14)\n“And with regard to the eclipse in the time of Tiberius Caesar, in whose reign Jesus appears to have been crucified, and the great earthquakes which then took place … ” (Origen Against Celsus, Book 2, Chapter 33)\n“Jesus, while alive, was of no assistance to himself, but that he arose after death, and exhibited the marks of his punishment, and showed how his hands had been pierced by nails.” (Origen Against Celsus, Book 2, Chapter 59). However, Eusebius in The Chronicon (written in the 4th century AD) records what Phlegon said verbatim. \"Now, in the fourth year of the 202nd Olympiad [32 AD], a great eclipse of the sun occurred at the sixth hour [noon] that excelled every other before it, turning the day into such darkness of night that the stars could be seen in heaven, and the earth moved in Bithynia, toppling many buildings in the city of Nicaea.\" Phlegon never mentions Jesus or the 3 hour darkness. He also mentions a solar eclipse, which can not occur at Passover. Apart from the year (which may be a corruption), this description fits an earthquake and eclipse that occurred in North West Turkey on November, 29 AD.\n\nCelsus writing late in the second century produced the first full-scale attack on Christianity. Celsus' document has not survived but in the third century Origen replied to it, and what is known of Celsus' writing is through the responses of Origen. According to Origen, Celsus accused Jesus of being a magician and a sorcerer. While the statements of Celsus may be seen as valuable, they have little historical value, given that the wording of the original writings can not be examined.\n\nThe Dead Sea Scrolls are first century or older writings that show the language and customs of some Jews of Jesus' time. Scholars such as Henry Chadwick see the similar uses of languages and viewpoints recorded in the New Testament and the Dead Sea Scrolls as valuable in showing that the New Testament portrays the first century period that it reports and is not a product of a later period. However, the relationship between the Dead Sea scrolls and the historicity of Jesus has been the subject of highly controversial theories, and although new theories continue to appear, there is no overall scholarly agreement about their impact on the historicity of Jesus, despite the usefulness of the scrolls in shedding light on first-century Jewish traditions.\n\nThe following sources are disputed, and of limited historical value, but they are at least proof of Christians existing and being known and talked about in the first and second centuries.\n\nThere is a limestone burial box from the 1st century known as the James Ossuary with the Aramaic inscription, \"James, son of Joseph, brother of Jesus.\" The authenticity of the inscription was challenged by the Israel Antiquities Authority, who filed a complaint with the Israeli police. In 2012, the owner of the ossuary was found not guilty, with the judge ruling that the authenticity of the ossuary inscription had not been proven either way. It has been suggested it was a forgery.\n\nVarious books, memoirs and stories were written about Jesus by the early Christians. The most famous are the gospels of Matthew, Mark, Luke and John. All but one of these are believed to have been written within 50–70 years of the death of Jesus, with the Gospel of Mark believed to be the earliest, and the last the Gospel of John. Blainey writes that the oldest surviving record written by an early Christian is a short letter by St Paul: the First Epistle to the Thessalonians, which appeared about 25 years after the death of Jesus. This letter, while important in describing issues for the development of Gentilic Christianity, contains little of significance for understanding the life of the historic Jesus.\n\nBart Ehrman, Robert Eisenman and others critical of traditional Christian views, in assessing the problems involved in conducting historical Jesus research, say the Gospels are full of discrepancies, were written decades after Jesus' death, by authors who had not witnessed any events in Jesus' life. They go on to say the Gospels were authored not by eyewitnesses who were contemporary with the events that they narrate but rather by people who did not know Jesus, see anything he did, or hear anything he taught, and that the authors did not even share a language with Jesus. The accounts they produced are not disinterested; they are narratives produced by Christians who actually believed in Jesus, and were not immune from slanting the stories in light of their biases. Ehrman points out that the texts are widely inconsistent, full of discrepancies and contradictions in both details and larger portraits of who Jesus was.\n\nIn the context of Christian sources, even if all other texts are ignored, the Pauline epistles can provide some information regarding Jesus. This information does not include a narrative of the life of Jesus, and refers to his existence as a person, but adds few specific items apart from his death by crucifixion. This information comes from those letters of Paul whose authenticity is not disputed. Paul was not a companion of Jesus and claims his information comes from the holy spirit acquired after Jesus' death.\n\nOf the thirteen letters that bear Paul's name, seven are considered authentic by almost all scholars, and the others are generally considered pseudepigraphic. The 7 undisputed letters (and their approximate dates) are: 1 Thessalonians (c. 51 CE), Philippians (c. 52–54 CE), Philemon (c. 52–54 CE), 1 Corinthians (c. 53–54 CE), Galatians (c. 55 CE), 2 Corinthians (c. 55–56 CE) and Romans (c. 55–58 CE). The authenticity of these letters is accepted by almost all scholars, and they have been referenced and interpreted by early authors such as Origen and Eusebius.\n\nGiven that the Pauline epistles are generally dated to AD 50 to AD 60, they are the earliest surviving Christian texts that include information about Jesus. These letters were written approximately twenty to thirty years after the generally accepted time period for the death of Jesus, around AD 30–36. The letters were written during a time when Paul recorded encounters with the disciples of Jesus, e.g. states that several years after his conversion Paul went to Jerusalem and stayed with Apostle Peter for fifteen days. During this time, Paul disputed the nature of Jesus' message with Jesus's brother James, concerning the importance of adhering to kosher food restrictions and circumcision, important features of determining Jewish identity.\n\nThe Pauline letters were not intended to provide a narrative of the life of Jesus, but were written as expositions of Christian teachings. In Paul's view, the earthly life of Jesus was of a lower importance than the theology of his death and resurrection,a theme that permeates Pauline writings. However, the Pauline letters clearly indicate that for Paul Jesus was a real person (born of a woman as in Gal 4.4), a Jew (\"born under the law\", Romans 1.3) who had disciples (1 Corinthians 15.5), who was crucified (as in 1 Corinthians 2.2 and Galatians 3.1) and who resurrected from the dead (1 Corinthians 15.20, Romans 1.4 and 6.5, Philippians 3:10–11). And the letters reflect the general concept within the early Gentillic Christian Church that Jesus existed, was crucified and was raised from the dead.\n\nThe references by Paul to Jesus do not in themselves prove the existence of Jesus, but they do establish that the existence of Jesus was the accepted norm within the early Christians (including the Christian community in Jerusalem, given the references to collections there) twenty to thirty years after the death of Jesus, at a time when those who could have been acquainted with him could still be alive.\n\nThe seven Pauline epistles that are widely regarded as authentic include the following information that along with other historical elements are used to study the historicity of Jesus:\n\nThe existence of only these references to Jesus in the Pauline epistles has given rise to criticism of them by G. A. Wells, who is generally accepted as a leader of the movement to deny the historicity of Jesus. When Wells was still denying the existence of Jesus, he criticized the Pauline epistles for not mentioning items such as John the Baptist or Judas or the trial of Jesus and used that argument to conclude that Jesus was not a historical figure.\n\nJames D. G. Dunn addressed Wells' statement and stated that he knew of no other scholar that shared that view, and most other scholars had other and more plausible explanations for the fact that Paul did not include a narrative of the life of Jesus in his letters, which were primarily written as religious documents rather than historical chronicles at a time when the life story of Jesus could have been well known within the early Church. Dunn states that despite Wells' arguments, the theories of the non-existence of Jesus are a \"thoroughly dead thesis\".\n\nWhile Wells no longer denies the existence of Jesus, he has responded to Dunn, stating that his arguments from silence not only apply to Paul but all early Christian authors, and that he still has a low opinion of early Christian texts, maintaining that for Paul Jesus may have existed a good number of decades before.\n\nThe Pauline letters sometimes refer to creeds, or confessions of faith, that predate their writings. For instance reads: \"For what I received I passed on to you as of first importance: that Christ died for our sins according to the Scriptures, that he was buried, that he was raised on the third day according to the Scriptures.\" refers to Romans 1:2 just before it which mentions an existing gospel, and in effect may be treating it as an earlier creed.\n\nOne of the keys to identifying a pre-Pauline tradition is given in \n\nHere Paul refers to others before him who preached the creed. James Dunn states that indicates that in the 30s Paul was taught about the death of Jesus a few years earlier.\n\nThe Pauline letters thus contain Christian creed elements of pre-Pauline origin. The antiquity of the creed has been located by many Biblical scholars to less than a decade after Jesus' death, originating from the Jerusalem apostolic community. Concerning this creed, Campenhausen wrote, \"This account meets all the demands of historical reliability that could possibly be made of such a text,\" whilst A. M. Hunter said, \"The passage therefore preserves uniquely early and verifiable testimony. It meets every reasonable demand of historical reliability.\"\n\nThese creeds date to within a few years of Jesus' death, and developed within the Christian community in Jerusalem. Although embedded within the texts of the New Testament, these creeds are a distinct source for Early Christianity. This indicates that existence and death of Jesus was part of Christian belief a few years after his death and over a decade before the writing of the Pauline epistles.\n\nThe four canonical gospels, Matthew, Mark, Luke, and John, are the main sources for the biography of Jesus' life, the teachings and actions attributed to him. Three of these (Matthew, Mark, and Luke) are known as the synoptic Gospels, from the Greek σύν (syn \"together\") and ὄψις (opsis \"view\"), given that they display a high degree of similarity in content, narrative arrangement, language and paragraph structure. The presentation in the fourth canonical gospel, i.e. John, differs from these three in that it has more of a thematic nature rather than a narrative format. Scholars generally agree that it is impossible to find any direct literary relationship between the synoptic gospels and the Gospel of John.\n\nThe authors of the New Testament generally showed little interest in an absolute chronology of Jesus or in synchronizing the episodes of his life with the secular history of the age. The gospels were primarily written as theological documents in the context of early Christianity with the chronological timelines as a secondary consideration. One manifestation of the gospels being theological documents rather than historical chronicles is that they devote about one third of their text to just seven days, namely the last week of the life of Jesus in Jerusalem. Although the gospels do not provide enough details to satisfy the demands of modern historians regarding exact dates, scholars have used them to reconstruct a number of portraits of Jesus. However, as stated in the gospels do not claim to provide an exhaustive list of the events in the life of Jesus.\n\nScholars have varying degrees of certainty about the historical reliability of the accounts in the gospels, and the only two events whose historicity is the subject of almost universal agreement among scholars are the baptism and crucifixion of Jesus. Scholars such as E.P. Sanders and separately Craig A. Evans go further and assume that two other events in the gospels are historically certain, namely that Jesus called disciples, and caused a controversy at the Temple.\n\nEver since the Augustinian hypothesis, scholars continue to debate the order in which the gospels were written, and how they may have influenced each other, and several hypothesis exist in that regard, e.g. the Markan priority hypothesis holds that the Gospel of Mark was written first c. 70 CE. In this approach, Matthew is placed at being sometime after this date and Luke is thought to have been written between 70 and 100 CE. However, according to the competing, and more popular, Q source hypothesis, the gospels were not independently written, but were derived from a common source called Q. The two-source hypothesis then proposes that the authors of Matthew and Luke drew on the Gospel of Mark as well as on Q.\n\nThe gospels can be seen as having three separate lines: A literary line which looks at it from a textual perspective, secondly a historical line which observes how Christianity started as a renewal movement within Judaism and eventually separated from it, and finally a theological line which analyzes Christian teachings. Within the historical perspective, the gospels are not simply used to establish the existence of Jesus as sources in their own right alone, but their content is compared and contrasted to non-Christian sources, and the historical context, to draw conclusions about the historicity of Jesus.\n\nTwo possible patristic sources that may refer to eye witness encounters with Jesus are the early references of Papias and Quadratus, reported by Eusebius of Caesarea in the 4th century.\n\nThe works of Papias have not survived, but Eusebius quotes him as saying:\n\nRichard Bauckham states that while Papias was collecting his information (c. 90), Aristion and the elder John (who were Jesus' disciples) were still alive and teaching in Asia minor, and Papias gathered information from people who had known them. However, the exact identity of the \"elder John\" is wound up in the debate on the authorship of the Gospel of John, and scholars have differing opinions on that, e.g. Jack Finegan states that Eusebius may have misunderstood what Papias wrote, and the elder John may be a different person from the author of the fourth gospel, yet still a disciple of Jesus. Gary Burge, on the other hand sees confusion on the part of Eusebius and holds the elder John to be different person from the apostle John.\n\nThe letter of Quadratus (possibly the first Christian apologist) to emperor Hadrian (who reigned 117 – 138) is likely to have an early date and is reported by Eusebius in his \"Ecclesiastical History\" 4.3.2 to have stated:\n\nBy \"our Savior\" Quadratus means Jesus and the letter is most likely written before AD 124. Bauckham states that by \"our times\" he may refer to his early life, rather than when he wrote (117–124), which would be a reference contemporary with Papias. Bauckham states that the importance of the statement attributed to Quadratus is that he emphasizes the \"eye witness\" nature of the testimonies to interaction with Jesus. Such \"eye witness statements\" abound in early Christian writings, particularly the pseudonymous Christian Apocrypha, Gospels and Letters, in order to give them credibility.\n\nA number of later Christian texts, usually dating to the second century or later, exist as New Testament apocrypha, among which the gnostic gospels have been of major recent interest among scholars. The 1945 discovery of the Nag Hammadi library created a significant amount of scholarly interest and many modern scholars have since studied the gnostic gospels and written about them. However, the trend among the 21st century scholars has been to accept that while the gnostic gospels may shed light on the progression of early Christian beliefs, they offer very little to contribute to the study of the historicity of Jesus, in that they are rather late writings, usually consisting of sayings (rather than narrative, similar to the hypothesised Q documents), their authenticity and authorship remain questionable, and various parts of them rely on components of the New Testament. The focus of modern research into the historical Jesus has been away from gnostic writings and towards the comparison of Jewish, Greco-Roman and canonical Christian sources.\n\nAs an example, Bart Ehrman states that gnostic writings of the Gospel of Thomas (part of the Nag Hammadi library) have very little value in historical Jesus research, because the author of that gospel placed no importance on the physical experiences of Jesus (e.g. his crucifixion) or the physical existence of believers, and was only interested in the secret teachings of Jesus rather than any physical events. Similarly, the Apocryphon of John (also part of the Nag Hammadi library) has been useful in studying the prevailing attitudes in the second century, and questions of authorship regarding the Book of revelation, given that it refers to , but is mostly about the post ascension teachings of Jesus in a vision, not a narrative of his life. Some scholars such as Edward Arnal contend that the Gospel of Thomas continues to remain useful for understanding how the teachings of Jesus were transmitted among early Christians, and sheds light on the development of early Christianity.\n\nThere is overlap between the sayings of Jesus in the apocryphal texts and canonical Christian writings, and those not present in the canonical texts are called agrapha. There are at least 225 agrapha but most scholars who have studied them have drawn negative conclusions about the authenticity of most of them and see little value in using them for historical Jesus research. Robert Van Voorst states that the vast majority of the agrapha are certainly inauthentic. Scholars differ on the number of authentic agrapha, some estimating as low as seven as authentic, others as high as 18 among the more than 200, rendering them of little value altogether. While research on apocryphal texts continues, the general scholarly opinion holds that they have little to offer to the study of the historicity of Jesus given that they are often of uncertain origin, and almost always later documents of lower value.\n\n\n"}
{"id": "29663614", "url": "https://en.wikipedia.org/wiki?curid=29663614", "title": "Species affinis", "text": "Species affinis\n\nSpecies affinis (commonly abbreviated to: sp. aff., aff., or affin.) is taxonomic terminology in zoology and botany. In open nomenclature it indicates that available material or evidence suggests that the proposed species is \"related to\", has an \"affinity\" to, but is \"not identical to\", the species with the binomial name that follows. The Latin word \"affinis\" can be translated as \"closely related to\", or \"akin to\".\n\nAn author who inserts \"n.sp.,\" or \"sp. nov., aff\" before a species name thereby states the opinion that the specimen is a new, previously undescribed species, but that there may not (yet) be enough information to complete a formal description. To use aff. alone, implies that the specimen differs suggestively from the holotype but that further progress is necessary to confirm that it is a novel species.\n\nAn example would be: a gastropod shell listed as \"Lucapina\" aff. \"aegis\" would mean that this shell somewhat resembles the shell of \"Lucapina aegis\", but is thought more likely to be another species, either closely related to, or closely resembling \"Lucapina aegis\". In a suitable context it also may suggest the possibility that the shell belongs to a species that has not yet been described.\n\nThe use of aff. is similar to other indicators of open nomenclature such as cf., sp., or ?, but the latter indicate that the species is \"uncertain\" rather than undescribed.\n\n"}
{"id": "1707086", "url": "https://en.wikipedia.org/wiki?curid=1707086", "title": "Tag (metadata)", "text": "Tag (metadata)\n\nIn information systems, a tag is a keyword or term assigned to a piece of information (such as an Internet bookmark, digital image, database record, or computer file). This kind of metadata helps describe an item and allows it to be found again by browsing or searching. Tags are generally chosen informally and personally by the item's creator or by its viewer, depending on the system, although they may also be chosen from a controlled vocabulary.\n\nTagging was popularized by websites associated with Web 2.0 and is an important feature of many Web 2.0 services. It is now also part of other database systems, desktop applications, and operating systems.\n\nPeople use tags to aid classification, mark ownership, note boundaries, and indicate online identity. Tags may take the form of words, images, or other identifying marks. An analogous example of tags in the physical world is museum object tagging. People were using textual keywords to classify information and objects long before computers. Computer based search algorithms made the use of such keywords a rapid way of exploring records.\n\nTagging gained popularity due to the growth of social bookmarking, image sharing, and social networking websites. These sites allow users to create and manage labels (or \"tags\") that categorize content using simple keywords. Websites that include tags often display collections of tags as tag clouds, as do some desktop applications. On websites that aggregate the tags of all users, an individual user's tags can be useful both to them and to the larger community of the website's users.\n\nTagging systems have sometimes been classified into two kinds: \"top-down\" and \"bottom-up\". Top-down taxonomies are created by an authorized group of designers (sometimes in the form of a controlled vocabulary), whereas bottom-up taxonomies (called folksonomies) are created by all users. This definition of \"top down\" and \"bottom up\" should not be confused with the distinction between a \"single hierarchical\" tree structure (in which there is one correct way to classify each item) versus \"multiple non-hierarchical\" sets (in which there are multiple ways to classify an item); the structure of both top-down and bottom-up taxonomies may be either hierarchical, non-hierarchical, or a combination of both. Some researchers and applications have experimented with combining hierarchical and non-hierarchical tagging to aid in information retrieval. Others are combining top-down and bottom-up tagging, including in some large library catalogs (OPACs) such as WorldCat.\n\nWhen tags or other taxonomies have further properties (or semantics) such as relationships and attributes, they constitute an ontology.\n\nMetadata tags as described in this article should not be confused with the use of the word \"tag\" in some software to refer to an automatically generated cross-reference; examples of the latter are \"tags tables\" in Emacs and \"smart tags\" in Microsoft Office.\n\nThe use of keywords as part of an identification and classification system long predates computers. Paper data storage devices, notably edge-notched cards, that permitted classification and sorting by multiple criteria were already in use prior to the twentieth century, and faceted classification has been used by libraries since the 1930s.\n\nIn the late 1970s and early 1980s, the Unix text editor Emacs offered a companion software program called \"Tags\" that could automatically build a table of cross-references called a \"tags table\" that Emacs could use to jump between a function call and that function's definition. This use of the word \"tag\" did not refer to metadata tags, but was an early use of the word \"tag\" in software to refer to a word index.\n\nOnline databases and early websites deployed keyword tags as a way for publishers to help users find content. In the early days of the World Wide Web, the codice_1 meta element was used by web designers to tell web search engines what the web page was about, but these keywords were only visible in a web page's source code and were not modifiable by users.\n\nIn 2003, the social bookmarking website Delicious provided a way for its users to add \"tags\" to their bookmarks (as a way to help find them later); Delicious also provided browseable aggregated views of the bookmarks of all users featuring a particular tag. Within a couple of years, the photo sharing website Flickr allowed its users to add their own text tags to each of their pictures, constructing flexible and easy metadata that made the pictures highly searchable. The success of Flickr and the influence of Delicious popularized the concept, and other social software websites—such as YouTube, Technorati, and Last.fm—also implemented tagging. In 2005, the Atom web syndication standard provided a \"category\" element for inserting subject categories into web feeds, and in 2007 Tim Bray proposed a \"tag\" URN.\n\nMany blog systems (and other web content management systems) allow authors to add free-form tags to a post, along with (or instead of) placing the post into a predetermined category. For example, a post may display that it has been tagged with codice_2 and codice_3. Each of those tags is usually a web link leading to an index page listing all of the posts associated with that tag. The blog may have a sidebar listing all the tags in use on that blog, with each tag leading to an index page. To reclassify a post, an author edits its list of tags. All connections between posts are automatically tracked and updated by the blog software; there is no need to relocate the page within a complex hierarchy of categories.\n\nSome desktop applications and web applications feature their own tagging systems, such as email tagging in Gmail and Mozilla Thunderbird, bookmark tagging in Firefox, audio tagging in iTunes or Winamp, and photo tagging in various applications. Some of these applications display collections of tags as tag clouds.\n\nThere are various systems for applying tags to the files in a computer's file system. In Apple's macOS, the operating system has allowed users to assign multiple arbitrary tags as extended file attributes to any file or folder ever since OS X 10.9 was released in 2013, and before that time the open-source OpenMeta standard provided similar tagging functionality in macOS. Several semantic file systems that implement tags are available for the Linux kernel, including Tagsistant. Microsoft Windows allows users to set tags only on Microsoft Office documents and some kinds of picture files.\n\nCross-platform file tagging standards include Extensible Metadata Platform (XMP), an ISO standard for embedding metadata into popular image, video and document file formats, such as JPEG and PDF, without breaking their readability by applications that do not support XMP. XMP largely supersedes the earlier IPTC Information Interchange Model. Exif is a standard that specifies the image and audio file formats used by digital cameras, including some metadata tags. TagSpaces is an open-source cross-platform application for tagging files; it inserts tags into the filename.\n\nAn \"official tag\" is a keyword adopted by events and conferences for participants to use in their web publications, such as blog entries, photos of the event, and presentation slides. Search engines can then index them to make relevant materials related to the event searchable in a uniform way. In this case, the tag is part of a controlled vocabulary.\n\nA researcher may work with a large collection of items (e.g. press quotes, a bibliography, images) in digital form. If he/she wishes to associate each with a small number of themes (e.g. to chapters of a book, or to sub-themes of the overall subject), then a group of tags for these themes can be attached to each of the items in the larger collection. In this way, freeform classification allows the author to manage what would otherwise be unwieldy amounts of information.\n\nA triple tag or machine tag uses a special syntax to define extra semantic information about the tag, making it easier or more meaningful for interpretation by a computer program. Triple tags comprise three parts: a namespace, a predicate, and a value. For example, codice_4 is a tag for the geographical longitude coordinate whose value is 50.123456. This triple structure is similar to the Resource Description Framework model for information.\n\nThe triple tag format was first devised for geolicious in November 2004, to map Delicious bookmarks, and gained wider acceptance after its adoption by Mappr and GeoBloggers to map Flickr photos. In January 2007, Aaron Straup Cope at Flickr introduced the term \"machine tag\" as an alternative name for the triple tag, adding some questions and answers on purpose, syntax, and use.\n\nSpecialized metadata for geographical identification is known as \"geotagging\"; machine tags are also used for other purposes, such as identifying photos taken at a specific event or naming species using binomial nomenclature.\n\nA hashtag is a kind of metadata tag marked by the prefix codice_5, sometimes known as a \"hash\" symbol. This form of tagging is used on microblogging and social networking services such as Twitter, Facebook, Google+, VK and Instagram.\n\nA knowledge tag is a type of meta-information that describes or defines some aspect of a piece of information (such as a document, digital image, database table, or web page). Knowledge tags are more than traditional non-hierarchical keywords or terms; they are a type of metadata that captures knowledge in the form of descriptions, categorizations, classifications, semantics, comments, notes, annotations, hyperdata, hyperlinks, or references that are collected in tag profiles (a kind of ontology). These tag profiles reference an information resource that resides in a distributed, and often heterogeneous, storage repository.\n\nKnowledge tags are part of a knowledge management discipline that leverages Enterprise 2.0 methodologies for users to capture insights, expertise, attributes, dependencies, or relationships associated with a data resource. Different kinds of knowledge can be captured in knowledge tags, including factual knowledge (that found in books and data), conceptual knowledge (found in perspectives and concepts), expectational knowledge (needed to make judgments and hypothesis), and methodological knowledge (derived from reasoning and strategies). These forms of knowledge often exist outside the data itself and are derived from personal experience, insight, or expertise. Knowledge tags are considered an expansion of the information itself that adds additional value, context, and meaning to the information. Knowledge tags are valuable for preserving organizational intelligence that is often lost due to turnover, for sharing knowledge stored in the minds of individuals that is typically isolated and unharnessed by the organization, and for connecting knowledge that is often lost or disconnected from an information resource.\n\nIn a typical tagging system, there is no explicit information about the meaning or semantics of each tag, and a user can apply new tags to an item as easily as applying older tags. Hierarchical classification systems can be slow to change, and are rooted in the culture and era that created them; in contrast, the flexibility of tagging allows users to classify their collections of items in the ways that they find useful, but the personalized variety of terms can present challenges when searching and browsing.\n\nWhen users can freely choose tags (creating a folksonomy, as opposed to selecting terms from a controlled vocabulary), the resulting metadata can include homonyms (the same tags used with different meanings) and synonyms (multiple tags for the same concept), which may lead to inappropriate connections between items and inefficient searches for information about a subject. For example, the tag \"orange\" may refer to the fruit or the color, and items related to a version of the Linux kernel may be tagged \"Linux\", \"kernel\", \"Penguin\", \"software\", or a variety of other terms. Users can also choose tags that are different inflections of words (such as singular and plural), which can contribute to navigation difficulties if the system does not include stemming of tags when searching or browsing. Larger-scale folksonomies address some of the problems of tagging, in that users of tagging systems tend to notice the current use of \"tag terms\" within these systems, and thus use existing tags in order to easily form connections to related items. In this way, folksonomies may collectively develop a partial set of tagging conventions.\n\nDespite the apparent lack of control, research has shown that a simple form of shared vocabulary emerges in social bookmarking systems. Collaborative tagging exhibits a form of complex systems dynamics (or self-organizing dynamics). Thus, even if no central controlled vocabulary constrains the actions of individual users, the distribution of tags converges over time to stable power law distributions. Once such stable distributions form, simple folksonomic vocabularies can be extracted by examining the correlations that form between different tags. In addition, research has suggested that it is easier for machine learning algorithms to learn tag semantics when users tag \"verbosely\"—when they annotate resources with a wealth of freely associated, descriptive keywords.\n\nTagging systems open to the public are also open to tag spam, in which people apply an excessive number of tags or unrelated tags to an item (such as a YouTube video) in order to attract viewers. This abuse can be mitigated using human or statistical identification of spam items. The number of tags allowed may also be limited to reduce spam.\n\nSome tagging systems provide a single text box to enter tags, so to be able to tokenize the string, a must be used. Two popular separators are the space character and the comma. To enable the use of separators in the tags, a system may allow for higher-level separators (such as quotation marks) or escape characters. Systems can avoid the use of separators by allowing only one tag to be added to each input widget at a time, although this makes adding multiple tags more time-consuming.\n\nA syntax for use within HTML is to use the rel-tag microformat which uses the \"rel\" attribute with value \"tag\" (i.e., codice_6) to indicate that the linked-to page acts as a tag for the current context.\n"}
{"id": "26681002", "url": "https://en.wikipedia.org/wiki?curid=26681002", "title": "Text annotation", "text": "Text annotation\n\nText Annotation is the practice and the result of adding a note or gloss to a text, which may include highlights or underlining, comments, footnotes, tags, and links. Text annotations can include notes written for a reader's private purposes, as well as shared annotations written for the purposes of collaborative writing and editing, commentary, or social reading and sharing. In some fields, text annotation is comparable to metadata insofar as it is added post hoc and provides information about a text without fundamentally altering that original text. Text annotations are sometimes referred to as marginalia, though some reserve this term specifically for hand-written notes made in the margins of books or manuscripts. Annotations are extremely useful and help to develop knowledge of English literature.\n\nThis article covers both private and socially shared text annotations, including hand-written and information technology-based annotation. For information on annotation of Web content, including images and other non-textual content, see also Web annotation.\n\nText annotation may be as old as writing on media, where it was possible to produce an additional copy with a reasonable effort. It became a prominent activity around 1000 AD in Talmudic commentaries and Arabic rhetorics treaties. In the Medieval era, scribes who copied manuscripts often made marginal annotations that then circulated with the manuscripts and were thus shared with the community; sometimes annotations were copied over to new versions when such manuscripts were later recopied.\n\nWith the rise of the printing press and the relative ease of circulating and purchasing individual (rather than shared) copies of texts, the prevalence of socially shared annotations declined and text annotation became a more private activity consisting of a reader interacting with a text. Annotations made on shared copies of texts (such as library books) are sometimes seen as devaluing the text, or as an act of defacement. Thus, print technologies support the circulation of annotations primarily as formal scholarly commentary or textual footnotes or endnotes rather than marginal, handwritten comments made by private readers, though handwritten comments or annotations were common in collaborative writing or editing.\n\nComputer-based technologies have provided new opportunities for individual and socially shared text annotations that support multiple purposes, including readers’ individual reading goals, learning, social reading, writing and editing, and other practices. Text annotation in Information Technology (IT) systems raises technical issues of access, linkage, and storage that are generally not relevant to paper-based text annotation, and thus research and development of such systems often addresses these areas.\n\nText annotations can serve a variety of functions for both private and public reading and communication practices. In their article \"From the Margins to the Center: The Future of Annotation,\" scholars Joanna Wolfe and Christine Neuwirth identify four primary functions that text annotations commonly serve in the modern era, including: (1)\"facilitat[ing] reading and later writing tasks,\" which includes annotations that support reading for both personal and professional purposes; (2)\"eavesdrop[ping] on the insights of other readers,\" which involves sharing of annotations; (3)\"provid[ing] feedback to writers or promote communication with collaborators,\" which can include personal, professional, and education-related feedback; and (4)\"call[ing] attention to topics and important passages,\" for which scholarly annotations, footnotes, and call-outs often function. Regarding the ways that annotations can support individual reading tasks, Catherine Marshall points out that the ways that readers annotate texts depends on the purpose, motivation, and context of reading. Readers may annotate to help interpret a text, to call attention to a section for future reference or reading, to support memory and recall, to help focus attention on the text as they read, to work out a problem related to the text, or create annotations not specifically related to the text at all.\n\nEducational research in text annotation has examined the role that both private and shared text annotations can play in supporting learning goals and communication. Much educational research examines how students’ private annotation of texts supports comprehension and memory; for example, research indicates that annotating texts causes more in-depth processing of information, which results in greater recall of information.\n\nOther areas of educational research investigate the benefits of socially shared text annotations for collaborative learning, both for paper-based and IT-based annotation sharing. For example, studies by Joanna Wolfe have investigated the benefits of exposure to others’ annotations on student readers and writers. In a 2000 study, Wolfe found that exposing students to others’ annotations influenced their perceptions of the annotators, which in turn shaped their responses to the material and their written products. In a later study, Wolfe found that viewing others’ written comments on a paper text, especially pairs of annotations that present opposing responses to the text, can help students engage in the type of critical reading and stance-taking necessary for effective argumentative writing.\n\nWhile shared annotations can benefit individual readers, it is important to note that, \"since the 1920s, literacy theory has increasingly emphasized the importance of social factors in the development of literacy.\" Thus, shared annotations can not only help one to better understand the content of a particular text, but may also aid in the acquirement of literacy skills. For example, a mother may leave marks inside a book to draw the attention of her child to a particular theme or concept; thanks to the development of audio annotations, parents may now leave notes for children who are just starting to read and may struggle with textual annotations.\n\nMore recent research in the effects of shared text annotations has focused on the learning applications for web-based annotation systems, some of which were developed based on design recommendations from studies outlined above. For example, Ananda Gunawardena, Aaron Tan, and David Kaufer conducted a pilot study to examine whether annotating documents in Classroom Salon, a web-based annotation and social reading platform, encouraged active reading, error detection, and collaboration in a computer science course at Carnegie Mellon University. This study suggested a correlation between students’ overall performance in the course and their ability to identify errors in a text that they annotated in Classroom Salon; it also found that students were likely to change their annotations in response to annotations made by others in the course.\n\nSimilarly, the web-based annotation tool HyLighter was used in a first-year writing course and shown to improve the development of students’ mental models of texts, including supporting reading comprehension, critical thinking, and the ability to develop a thesis. The collaboration with peers and experts around a shared text improved these skills and brought the communities’ understanding closer together.\n\nA meta-analysis of empirical studies into the higher-education uses of social annotation (SA) tools indicates such tools have been tested in several courses, among them English, sport psychology, and hypermedia. Studies have indicated that social annotation functions, including commenting, information sharing, and highlighting, can support instruction designed to foster collaborative learning and communication, as well as reading comprehension, metacognition, and critical analysis. Several studies indicated that students enjoyed using social annotation tools, and that it improved motivation in the course.\n\nText annotations have long been used in writing and revision processes as a way for reviewers to suggest changes and communicate about a text. In book publishing, for example, the collaboration of authors and editors to develop and revise a manuscript frequently involves exchanges of both in-line revisions or notes as well as marginal annotations. Similarly, copyeditors often make marginal annotations or notes that explain or suggest revisions or are directed at the author as questions or suggestions (commonly called \"queries\"). Asynchronous collaborative writing and document development often depend on text annotations as a way not only to suggest revisions but also to exchange ideas during document development or to facilitate group decision making, though such processes are often complicated by the use of different communication technologies (such as phone calls or emails as well as document sharing) for distinct tasks. Text annotations can also function to allow group or community members to communicate about a shared text, such as a doctor annotating a patient's chart.\n\nMuch research into the functionality and design of collaborative IT-based writing systems, which often support text annotation, has occurred in the area of computer-supported cooperative work.\n\nResearch in the design and development of annotation systems uses specific terminology to refer to distinct structural components of annotations and also distinguishes among options for digital annotation displays.\n\nThe structural components of any annotation can be roughly divided into three primary elements: a \"body\", an \"anchor\", and a \"marker\". The body of an annotation includes reader-generated symbols and text, such as handwritten commentary or stars in the margin. The anchor is what indicates the extent of the original text to which the body of the annotation refers; it may include circles around sections, brackets, highlights, underlines, and so on. Annotations may be anchored to very broad stretches of text (such as an entire document) or very narrow sections (such as a specific letter, word, or phrase). The marker is the visual appearance of the anchor, such as whether it is a grey underline or a yellow highlight. An annotation that has a body (such as a comment in the margin) but no specific anchor has no marker.\n\nIT-based annotation systems utilize a variety of display options for annotations, including:\nAnnotation interfaces may also allow highlighting or underlining, as well as threaded discussions. Sharing and communicating through annotations anchored to specific documents is sometimes referred to as \"anchored discussion\".\n\nIT-based annotation systems include standalone and client-server systems. In the 1980s and 1990s, a number of such systems were built in the context of libraries, patent offices, and legal text processing. Their design led researchers to produce taxonomies of annotation forms. Text annotation research has taken place at several institutions, including Xerox research centers in Palo Alto and Grenoble (France), the Hitachi Central Research Lab (in particular for annotation of patents), and in relation with the construction of the new French National Library between 1989 and 1995 at the Institut de Recherche en Informatique de Toulouse and in the company AIS (Advanced Innovation Systems).\n\nAnnotation functionality has been present in text processing software for many years through inline notes displayed as pop-ups, footnotes, and endnotes; however, it is only recently that functionality for displaying annotations as marginalia has appeared in programs such as OpenOffice.org/LibreOffice Writer and Microsoft Word. Personal or standalone annotation include word processing software that supports embedded or anchored text annotations as well as Adobe Acrobat, which in addition to commenting allows highlights, stamps, and other types of markup.\n\nTim Berners-Lee had already implemented the concept of directly editing web documents in 1990 in WorldWideWeb, the first web browser, but later ported versions removed this collaborative ability. An early version of NCSA Mosaic in 1993 also included a collaborative annotation capability, though it was quickly removed. Web Distributed Authoring and Versioning, WebDAV, was then reintroduced as an extension.\n\nA different approach to distributed authoring consists in first gathering many annotations from a wide public, and then integrate them all in order to produce a further version of a document. This approach was pioneered by Stet, the system put in place to gather comments on drafts of version 3 of the GNU General Public License. This system arose after a specific requirement, which it served egregiously, but was not so easily configurable as to be convenient for annotating any other document on the web. The co-ment system uses annotation interface concepts similar to Stet's, but it is based on an entirely new implementation, using Django/Python on the server side and various AJAX libraries such as JQuery on the client side. Both Stet and co-ment are licensed under the GNU Affero General Public License.\n\nSince 2011, the non-profit Hypothes Is Project has offered the free, open web annotation service Hypothes.is. The service features annotation via a Chrome extension, bookmarklet or proxy server, as well as integration into a LMS or CMS. Both webpages and PDFs can be annotated. Other web-based text annotation systems are collaborative software for distributed text editing and versioning, which also feature annotation and commenting interfaces. For example, HyLighter supports synchronous and asynchronous interactions, general commenting, comment tagging, threaded discussions and comment filtering. Other annotation tools under these category are more focused on NLP tasks as Named-entity recognition, relationship extraction or normalization. Some tools support manual tagging of data or automatic annotations via supervised learning.\n\nSpecialized Web-based text annotations exist in the context of scientific publication, either for refereeing or post-publication. The on-line journal PLoS ONE, published by the Public Library of Science, has developed its own Web-based system where scientists and the public can comment on published articles. The annotations are displayed as pop-ups with an anchor in the text.\n\n\n"}
