{"id": "13480983", "url": "https://en.wikipedia.org/wiki?curid=13480983", "title": "ATP Rankings", "text": "ATP Rankings\n\nThe ATP Rankings are the objective merit-based method used by the Association of Tennis Professionals (ATP) for determining the qualification for entry as well as the seeding of players in all singles and doubles tournaments. The first rankings for singles were published on 23 August 1973 while the doubles players were ranked for the first time on 1 March 1976. Ranking points are awarded according to the stage of tournament reached, and the prestige of the tournament, with the four Grand Slams awarding the most points. The rankings are updated every Monday, and points are dropped 52 weeks after being awarded (with the exception of the ATP Finals, from which points are dropped on the Monday following the last ATP World Tour event of the following year.\n\nThe ATP began as the men's trade union in 1972, through the combined efforts of Jack Kramer, Cliff Drysdale, and Donald Dell, and rose to prominence when 81 of its members boycotted the 1973 Wimbledon Championships. Just two months later, in August, the ATP introduced its ranking system intended to objectify tournament entry criteria, which up to that point was controlled by national federations and tournament directors.\n\nThe ATP's new ranking system was quickly adopted by men's tennis. While virtually all ATP members were in favor of objectifying event participation, the system's first No. 1, Ilie Năstase, lamented that \"everyone had a number hanging over them,\" fostering a more competitive and less collegial atmosphere among the players.\n\nThe original ATP ranking criteria, which persisted through the 1980s, was based on averaging each player's results, though the details were revised a number of times. Starting in 1990, in conjunction with the expansion of ATP purview as the new men's tour operator, the ranking criteria was replaced with a 'best of' system modeled after competitive downhill skiing. This 'best of' system originally used 14 events but expanded to 18 in 2000.\n\nA player's ATP Ranking is based on the total points he accrued in the following 19 tournaments (18 if he did not qualify for the ATP Finals):\nThe requirement to play in four ATP World Tour 500 events does not apply to a player who was outside the top 30 in the previous year-end ranking; however, no more than four of his results from 500 level events may be counted. For a better result within the same tour type to be transposed one has to wait for the expiry of the first worse result from previous year. It only expires at the drop date of that tournament and only if the player reached a worse result or has not entered the current year.\n\nRanking points gained in a tournament are dropped 52 weeks later, with the exception of the ATP Finals, from which points are dropped on the Monday following the last ATP World Tour event of the following year.\n\nThe Monte-Carlo Masters 1000 became optional in 2009, but if a player chooses to participate in it, its result is counted and his fourth-best result in an ATP 500 event is ignored (his three best ATP 500 results remain). From 2009 until 2015, if a player did not play enough ATP 500 events and did not have an ATP 250 or Challenger appearance with a better result, the Davis Cup was counted in the 500's table. The World Team Cup was also included before its cancellation in 2012.\n\nFor the Davis Cup, from 2009 until 2015, points were distributed for the World Group countries. Instead of having an exact drop date they were gradually updated at each phase of the competition, comparing the player's results with his results from the previous year. E.g. if a player played two matches in a semifinal but plays one the next year only that one missing match will be extracted from his points).\n\nA player who is out of competition for 30 or more days, due to a verified injury, will not receive any penalty. The ATP Finals will count as an additional 19th tournament in the ranking of its eight qualifiers at season's end.\n\nFor every Grand Slam tournament or mandatory ATP World Tour Masters 1000 tournament for which a player is not in the main draw, and was not (and, in the case of a Grand Slam tournament, would not have been, had he and all other players entered) a main draw direct acceptance on the original acceptance list, and never became a main draw direct acceptance, the number of his results from all other eligible tournaments in the ranking period that count for his ranking is increased by one.\n\nOnce a player is accepted in the main draw of a Grand Slam tournament or ATP World Tour Masters 1000 tournament, his result in this tournament counts for his ranking, regardless of whether he participates. A player's withdrawal from an ATP World Tour 500 event, regardless of whether the withdrawal was on time, results in a zero point included as one of his best of four results. Further non-consecutive withdrawals results in a zero point allocation replacing the next best positive result for each additional withdrawal.\n\nPlayers with multiple consecutive withdrawals who are out of competition for 30 days or longer because of injury are not subject to a ranking penalty as long as verified and approved medical forms are provided; or, a player will not have the ranking penalty imposed if he completes the Promotional Activities requirement as specified under \"Repeal of Withdrawal Fines and/or Penalties\" or if the on-site withdrawal procedures apply. Players may also appeal withdrawal penalties to a Tribunal who will determine whether the penalties are affirmed or set aside.\n\nBetween 2000 and 2012, ranking points were awarded based on results in the Summer Olympics. This was changed before the 2016 Olympics where no ranking points were awarded.\n\nWith these rules, a player playing and winning the mandatory 4 Grand Slams and 8 ATP Masters 1000 events, a further 5 ATP 500 events and the Monte-Carlo Masters 1000 can amass a total of 19,500 points before the ATP Finals and end the calendar year with a maximum of 21,000 points. Novak Djokovic's haul of 16,585 points in the 2015 season is the best in history.\n\nSince the introduction of the ATP rankings the method used to calculate a player's ranking points has changed several times.\n\n\nIn addition qualifiers and main draw entry players will then also receive the points in brackets for the rounds they reached.\n\nStarting in 2016, points were no longer awarded for Davis Cup ties, nor for the tennis tournament at the Summer Olympics.\n\nThe following is a list of players who have achieved the number one position in singles since the inception of the rankings in 1973:\n\"Last update: 26 November 2018\"\n\nNotes<br>\nIn 2009 a new point system was introduced where points were roughly doubled.\n\nThe following is a list of players who were ranked world No.5 or higher but not No.1 in the period since the 1973 introduction of the ATP computer rankings:\n\n\n"}
{"id": "41799316", "url": "https://en.wikipedia.org/wiki?curid=41799316", "title": "Barack Obama on mass surveillance", "text": "Barack Obama on mass surveillance\n\nU.S. president Barack Obama has received widespread criticism due to his support of government surveillance. President Obama had released many statements on mass surveillance as a result.\n\nAs a senator, Obama condemned the Patriot Act for violating the rights of American citizens. He argued that it allowed government agents to perform extensive and in-depth searches on American citizens without a search warrant. He also argued that it was possible to secure the United States against terrorist attacks while preserving individual liberty. In 2011, Obama signed a four-year renewal of the Patriot Act, specifically provisions allowing roaming wiretaps and government searches of business records. Obama argued that the renewal was needed to protect the United States from terrorist attacks. However, the renewal was criticized by several members of Congress who argued that the provisions did not do enough to curtail excessive searches. Obama also received criticism for his reversal on privacy protection.\n\nIn June 2013, reports from a cache of top secret documents leaked by ex-NSA contractor Edward Snowden revealed that the U.S. National Security Agency (NSA) and its international partners had created a global system of surveillance that was responsible for the mass collection of information on American and foreign citizens.\n\nObama initially defended NSA mass surveillance programs when they were first leaked. He argued that NSA surveillance was transparent and claimed that the NSA is unable and had made no attempt to monitor the phone calls and e-mails of American citizens. Following Snowden's admittance to leaking classified documents regarding national surveillance, Obama attempted to ignore the issue of NSA surveillance. It was speculated that Obama did this to avoid complicating the Department of Justice investigation into Snowden.\n\nIn August 2013, Obama argued that his administration was already in the process of reviewing the NSA surveillance programs when they were leaked by Snowden. Obama stated that it would have been best for the American people to have never learned about the programs. He also criticized Snowden for not using existing systems within the federal government for whistleblowers. The latter statement was criticized as Snowden would have been directed to one of the committees responsible for protecting the secrecy of NSA surveillance if he had used the existing whistle-blower system. However, he also promised to make public information about government surveillance and work with Congress to increase public confidence in the government.\n\nOn January 17, 2014, President Obama gave a public address on mass surveillance. \n\nObama's speech was criticized for being deliberately vague and not going far enough to protect civil liberties.\n\nRepresentatives for Google, Facebook and Yahoo stated that Obama's proposed reforms represented positive progress, but that they did not ultimately do enough to protect privacy rights. A representative for Mozilla noted that mass surveillance had damaged the open Internet and caused balkanization and distrust.\n\nSen. Rand Paul criticized the remarks, saying: \n\nDianne Feinstein, a member of the Senate Intelligence Committee, stated that all but two or three of the members of her committee support Obama. Likewise, she criticized \"privacy people\" for not understanding the threat terrorists pose to the United States. Mike Rogers, the chair of the House Intelligence Committee, praised Obama's stance on NSA surveillance. Peter King, another member of the House Intelligence Committee, questioned the need for the proposed reform of NSA surveillance, but admitted that they were necessary to calm down the \"ACLU types\".\n\nReactions from global leaders were limited. Great Britain and Russia, both states with extensive surveillance programs, offered no comments. Dilma Rousseff, the current president of Brazil and an outspoken critic of NSA surveillance, also refused to comment. In Germany, a government spokesperson demanded greater protection for non-Americans in reaction to the speech. Der Spiegel accused the NSA of turning the internet into a weapons system. The European Union stated that Obama's pledge to reform the phone data collection is a step in the right direction, but demanded that actual laws be passed regarding this reform.\n\nThe Electronic Frontier Foundation and The Day We Fight Back released a report card\" evaluating Obama's reform: \n\nA full point was awarded in each category where Obama fully made the promised reform. However, partial points were awarded for reforms that had not been fully completed, but where the EFF and The Day We Fight Back felt that progress as being made. Obama received praise for adding independent advocates to the Foreign Intelligence Surveillance Act (FISA) courts and opposing the FISA Improvements Act. However, it was also noted that Obama had not made any progress on giving metadata storage responsibility to a third party, ending the undermining of encryption standards, increasing transparency within the NSA and protecting whistleblowers.\n\nOn January 18, Obama spoke to ZDF in an attempt to improve the United States relations with Germany, which a German foreign office official said were \"worse than … the low-point in 2003 during the Iraq War\" due to the surveillance leaks. Obama promised that he would not let revelations about mass surveillance damage German-American relations and admitted that it would take a long time for the United States to regain the trust of the German people. However, he maintained that the surveillance was necessary for international security.\n\nGerman reactions to the speeches given by Obama on January 17 and 18 ranged from skeptical to outright hostile. Members of the German media argued that they were hopeful that Obama would bring about needed reform. However, they also noted that his statements were vague and argued that they did not represent legitimate reform. Many German political leaders responded with outright hostility. Thomas Oppermann, the chairman of the German Social Democrats, demanded a no-spy treaty and stated that American surveillance constituted a crime. The German attorney general argued that there were grounds for a criminal investigation into the NSA's tapping of Angela Merkel's cell phone.\n\nOn March 25, 2014, Obama promised to end the NSA's collection and storage of bulk phone-call data. Despite this promise, his administration continued to seek reauthorization of the telephone metadata program. It is approved every 90 days by the FISC, with the most recent authority set to expire June 1, 2015. In a plan submitted by the Obama Administration to Congress, the NSA would be required to conduct searches of data at phone companies. They would also need to receive a warrant from a federal judge to conduct the search.\n\nThe overhaul proposal received support from the American Civil Liberties Union. A representative of the organization claimed that it was a crucial first step in reining in NSA surveillance. The overhaul was criticized by several officials, however, because it would force telephone carriers to store customers metadata that they previously not legally obligated to keep. Reactions from the carriers were generally positive. A representative of Sprint Corporation stated that the carrier was examining the president's proposal with great interest.\n\nAs of March 2015, the administration's proposals have not been implemented and the NSA retains the authority to collect and store telephone record metadata.\n\nOn May 24, 2017, a declassified FISA report marked \"Top Secret\" was published, noting that the NSA routinely violated the 4th Amendment of Americans and abused intelligence tools to do so. The Obama administration self-disclosed the problems at a closed-door hearing on Oct. 26 before the Foreign Intelligence Surveillance Court, two weeks before the 2016 election. The report labeled the matter a “very serious Fourth Amendment issue,\" citing an \"institutional lack of candor\" on the part of the administration. It also criticized the NSA as having “disregard” for rules and “deficient” oversight.\n\nMore than 5 percent, or one out of every 20 searches seeking upstream Internet data on Americans inside the NSA’s so-called Section 702 database, violated the safeguards the Obama administration vowed to follow in 2011. In addition, there was a three-fold increase in NSA data searches about Americans and a rise in the unmasking of U.S. person’s identities in intelligence reports after the administration loosened privacy rules in 2011. Many of the searches involved any and all mentions of foreign targets.\n\nOfficials like former National Security Adviser Susan Rice have argued their activities were legal under the so-called minimization rule changes the Obama administration made, and that the intelligence agencies were strictly monitored to avoid abuses. The FISA court and the NSA's own internal watchdog entity disputes this claim, stating that the administration conducting such queries were \"in violation of that prohibition, with much greater frequency than had been previously disclosed to the Court.”\n\nThe FISA report also indicated hundreds of incidences in which the FBI illegally shared raw surveillance data illegally obtained by the NSA with private entities. Earlier in May, then-FBI Director James Comey told lawmakers his agency used sensitive espionage data gathered about Americans without a warrant only when it was “lawfully collected, carefully overseen and checked.” The ruling in the report declared that “The Court is nonetheless concerned about the FBI’s apparent disregard of minimization rules and whether the FBI is engaging in similar disclosures of raw Section 702 information that have not been reported.”\n\nIn a declassified report from 2015, the internal watchdog had concerns as early as 2012 that the FBI was submitting \"deficient” reports indicating it had a clean record complying with spy data gathered on Americans without a warrant. While Section 702 of the Foreign Surveillance Act, last updated by Congress in 2008, allowed the NSA to share with the FBI spy data collected without a warrant, the FISA report indicates FBI compliance problems began months after the updated legislation was implemented. The FBI’s very first compliance report in 2009 declared it had not found any instances in which agents accessed NSA intercepts supposedly gathered overseas about an American who in fact was on U.S. soil. The Inspector General, however, said it reviewed the same data and easily found evidence that the FBI accessed NSA data gathered on a person who likely was in the United States, making it illegal to review without a warrant.\n\nOn April 28, the NSA issued a rare press release indicating it will no longer monitor all internet communications that mention a foreign intelligence target.\n\nNeema Singh Guliani, the ACLU's legislative counsel in Washington, DC stated, “I think what this emphasizes is the shocking lack of oversight of these programs.\" Chris Farrell, Director of Investigations for the watchdog group Judicial Watch asserted, \"This is an abuse of power and authority like we have never seen in this country.\"\n\n"}
{"id": "6230543", "url": "https://en.wikipedia.org/wiki?curid=6230543", "title": "British DX Club", "text": "British DX Club\n\nThe British DX Club (abbreviated form \"BDXC\") is an association of radio hobbyists, based in the United Kingdom. It caters mainly for, though not exclusively, DXers and Short Wave listeners. It was founded in 1974 and was originally known as the \"Twickenham DX Club\" (after the Middlesex, UK, town where it was originally based), but re-launched in 1979 as the British DX Club. The name change was made to reflect its growing national and international membership which currently stands at around 500. To distinguish it from similar organisations in other countries, the club's abbreviated name for international use is BDXC-UK.\n\nBDXC publishes a monthly magazine \"Communication\", which is registered with the British Library (ISSN 0958-2142). The main contents of a typical magazine consist of a mixture of DX \"loggings\", details of radio station frequencies and programmes, letters and articles of general interest on broadcasting topics. These topics include:\n\nUK News, Webwatch, DX News, Propagation, DRM News, Mediumwave Report, Collectors Corner (vintage Radio's etc.), The Audio Circle, Beyond The Horizon, Mediumwave Logbook, Tropical Logbook, HF Logbook, Alternative Airwaves (Pirate Radio), and members contributions.\n\nIn 1976, the club launched a monthly audio magazine on cassette tape, BDXC Audio Circle (formerly known as BDXC Tape Circle). This is now also distributed on Compact Disc and as an MP3 downloadable file for subscribing members only.\n\nThe BDXC also has an email news group for club members to distribute news and DX 'catches' to subscribed members. The Audio Circle also has its own email group.\n\nBDXC and its members are important contributors to each edition of the World Radio Television Handbook (WRTH) an annual publication listing broadcasting times and frequencies of most of the world's national and international broadcasters. Information on other UK DX clubs is also included in WRTH.\n\n"}
{"id": "58889745", "url": "https://en.wikipedia.org/wiki?curid=58889745", "title": "Bryum argenteum", "text": "Bryum argenteum\n\nBryum argenteum, the silvergreen bryum moss or silvery thread moss, is a species of moss in the family Bryaceae. It is one of the most common urban mosses of inner cities and can be easily recognized without a microscope.\nThe species is silvery-green or whitish-green colored when dry. This is because the broadly ovate shaped single leaflets in the tip do not form chlorophyll. The costa extends beyond the middle of the leaf. In damp, undisturbed locations, the branches may also form a more horizontal growth habit. The upper cells of the leaf surface are elongated rhomboid shaped. The capsule of the sporophyte is short cylindrical, appears broader at the base and is dark red to black colored.\n\nIt has a high ability to tolerate drought and pollution of urban environments. \"B. argenteum\" is considered a desiccation tolerant species that can withstand total drying. While it is a common characteristic in mosses, \"B. argenteum\" was one of the first bryophytes experimentally determined to be desiccation tolerant.\n\nAn adaptable plant, it has a cosmopolitan distribution and is found in Europe, North America, the deserts of Australia and in Antarctica. \n\nIt thrives in areas of high anthropogenic activity, growing on rocks, in gaps of paving stones, on asphalt, and on roadsides. It grows especially well in inner cities or in industrial areas. Being a nitrogen loving species, it is also found on nitrophilic soils in urban areas. It is found growing among lawns as well as in other moss communities.\n\nThe species is often spread by vegetative fragments clinging to the shoes of people and the feet or hooves of animals.\nAnother method of spread is in the production and sale of liners. Liners infested with \"B. argentem\", often in association with \"Marchantia polymorpha\", are commonly grown in one region of the country, transported to another region to continue growth, and are shipped to a retail location before being planted. Plants have the potential to pick up or disperse these species at each point of transfer.\n"}
{"id": "31950461", "url": "https://en.wikipedia.org/wiki?curid=31950461", "title": "Centre for Health and International Relations", "text": "Centre for Health and International Relations\n\nThe Centre for Health and International Relations (CHAIR) was founded (2003) in the belief that there are compelling reasons for linking international relations, foreign policy, security and health. CHAIR is based in the Department of International Politics, Aberystwyth University, Aberystwyth, Wales. The founder and director is Professor Colin McInnes.\n\nIn addition to research into the global politics of health broadly defined, CHAIR is also involved in research in the following areas:\n\n\nAssociated staff working on the ongoing 'The Transformation of Global Health Governance: Competing World Views and Crises' project from the London School of Hygiene and Tropical Medicine:\n\n"}
{"id": "23773961", "url": "https://en.wikipedia.org/wiki?curid=23773961", "title": "Common heritage of mankind", "text": "Common heritage of mankind\n\nCommon heritage of mankind (also termed the common heritage of humanity, common heritage of humankind or common heritage principle) is a principle of international law which holds that defined territorial areas and elements of humanity's common heritage (cultural and natural) should be held in trust for future generations and be protected from exploitation by individual nation states or corporations.\n\nIn his essay \"Toward Perpetual Peace\", Immanuel Kant claimed that the expansion of hospitality with regard to \"use of the right to the earth's surface which belongs to the human race in common\" would \"finally bring the human race ever closer to a cosmopolitan constitution\". The concept of \"Common Heritage of Mankind\", however, was first mentioned in the preamble to the 1954 Hague Convention for the Protection of Cultural Property in the Event of Armed Conflict. \n\nThe concept of 'Mankind' is also mentioned in outer space treaties. 'Mankind' as a subject in international law also appears in the Preamble of the United Nations Charter, the Preamble of the North Atlantic Treaty (1949) and the Treaty on the Non-Proliferation of Nuclear Weapons (1968).\n\nIn 1970, United Nations General Assembly Resolution 2749, the \"Declaration of Principles Governing the Seabed and Ocean Floor\", was adopted by 108 nation states and stated that the deep seabed should be preserved for peaceful purposes and is the \"Common Heritage of Mankind.\"\n\nIn 1982, the Common Heritage of Mankind concept was stated to relate to \"the seabed and ocean floor and subsoil thereof, beyond the limits of national jurisdiction\" under Article 136 of the United Nations Law of the Sea Treaty (UNCLOS).\n\nPayoyo argues that the \"common heritage of humanity\" principle in Part XI of the Law of the Sea Treaty should favour developing states (who were the voice of conscience in establishing it), and not merely in some transient 'affirmative action' manner. He claims, however, that the 1994 \"Implementation Agreement\" facilitated control by industrialised countries of the International Seabed Authority (ISA), allowing access by the private sector to the deep sea bed and inhibiting constructive dialogue on sustainable development.\n\nMaltese Ambassador Arvid Pardo, one of the founders of the \"common heritage of humanity\" concept under international law, has claimed that it challenges the \"structural relationship between rich and poor countries\" and amounts to a \"revolution not merely in the law of the sea, but also in international relations\". One of the main architects of the principle under international space law has claimed that it is \"the most important legal principle achieved by man throughout thousands of years during which law has existed as the regulating element of social exchange\". This praise relates to the fact that international law in the \"common heritage of humanity\" principle is seeking to protect, respect and fulfill the interests of human beings independently of any politically motivated sovereign state; the concept covering all humans wherever they are living, as well as future generations.\n\nFrakes has identified five core components of the Common Heritage of Humanity concept. First, there can be no private or public appropriation; no one legally owns common heritage spaces. Second, representatives from all nations must manage resources contained in such a territorial or conceptual area on behalf of all since a commons area is considered to belong to everyone; this practically necessitating a special agency to coordinate shared management. Third, all nations must actively share with each other the benefits acquired from exploitation of the resources from the commons heritage region, this requiring restraint on the profit-making activities of private corporate entities; this linking the concept to that of global public good. Fourth, there can be no weaponry or military installations established in territorial commons areas. Fifth, the commons should be preserved for the benefit of future generations, and to avoid a \"tragedy of the commons\" scenario. Academic claims have been made that where the principle requires the establishment of an international resource management regime, prior to establishment of such a regime a moratorium on resource exploitation should be enforced. Such a position does not appear to have been supported by most states during the respective drafting negotiations.\n\nA similar principle of international law holds that the world's cultural and natural heritage (as nominated for listing by nation states) must be protected by states parties to the UNESCO World Heritage Convention.\n\nA case study in the use of these provisions was provided by the Franklin Dam non-violent protest campaign against the construction of a dam of Australia's last wild river; they being held by the Australian High Court to provide a valid basis for legislation protecting the Franklin River. Justice Lionel Murphy wrote in that case (\"Commonwealth v Tasmania\") about the Common Heritage of Humanity principle: \"The preservation of the world's heritage must not be looked at in isolation but as part of the co-operation between nations which is calculated to achieve intellectual and moral solidarity of mankind and so reinforce the bonds between people which promote peace and displace those of narrow nationalism and alienation which promote war ... [t]he encouragement of people to think internationally, to regard the culture of their own country as part of world culture, to conceive a physical, spiritual and intellectual world heritage, is important in the endeavour to avoid the destruction of humanity.\"\n\nThe UNESCO \"Universal Declaration on the Human Genome and Human Rights\" declares in Article 1 that: \"The human genome underlies the fundamental unity of all members of the human family, as well as the recognition of their inherent dignity and diversity. In a symbolic sense, it is the heritage of humanity.\" Article 4 states: \"The human genome in its natural state shall not give rise to financial gains.\" Such Declarations do not create binding obligations under international law (unless over time there is sufficient opinio juris and state practise to make them part of international customary law) so the impact of such principles of commercialisation of the human genome will be problematic. Whether the principle prohibits the patenting of the human genome is contested by the corporate sector.\n\nProclaimed on November 12, 1997, the UNESCO \"Declaration on the Responsibilities of the Present Generations Towards Future Generations\" is an international agreement (potentially part of international customary law) which includes provisions related to the \"common heritage of mankind\".\n\nIt was argued at the World Summit on the Information Society and has been advocated by academics that global communication between individuals over the internet should be regarded as part of the Common Heritage of Mankind. From a spiritual or natural law perspective, it has been argued that for world peace to be achieved, laws and government policies should create the social preconditions whereby conscience, properly understood, can be delinked from (often destructive) fundamentalist religious ideologies, and associated with a universal consciousness, access to which is the Common Heritage of Humanity. Such thinking with associated implications about how a sustainable world in the future should be regulated is common to members of the Global Ecovillage Network. Equatorial countries have proposed that the geostationary orbit over the high seas should be declared the \"common heritage of mankind\". It has been argued that a World government would manage common heritage areas according to principles of \"planetary democracy\". The international law concept of common heritage of humanity has also been linked with cosmopolitanism. Common heritage of humanity as a concept of international law is supported by many of the principles in the Earth Charter civil society Initiative\n\nKemal Baslar has stated that the Common Heritage of Mankind principle \"is a philosophical idea that questions the regimes of globally important resources regardless of their situation, and requires major changes in the world to apply its provisions. In other words, the application and enforcement of the common heritage of mankind require a critical reexamination of many well-established principles and doctrines of classical international law, such as acquisition of territory, consent-based sources of international law, sovereignty, equality, resource allocation and international personality.\"\n\nThe \"common heritage of humanity\" principle in international law has been viewed as one solution to the tragedy of the commons dilemma described in an influential article by that name written by Garrett Hardin in the journal \"Science\" in 1968. The article critically analyzes a dilemma in which multiple individuals, acting independently after rationally consulting self-interest, ultimately destroy a shared limited resource even when each acknowledges that outcome is not in anyone's long-term interest. Hardin's conclusion that commons areas are practicably achievable only in conditions of low population density and so their continuance requires state restriction on the freedom to breed, created controversy particularly through his deprecation of the role of conscience in achieving justice and equality in society. Hardin's views have been noted by scholars and policy-makers supporting privatization of common spaces and suggesting economic rationalism on such social and ecosystems. Though there are many that point out that as what we are seeking is a social contract, privatisation would actually annihilate any possibility of rational use - the land would simply be in enclosure. Hardin's views are based on Malthusian ideas of competition and over population, we have now accepted that it is the nature of man's consumption (not his numbers) that is causing the destruction of the environment.\n\nThe extent to which the Common Heritage of Mankind principle does or should control the activities of private multinational corporations as well as nation states, particularly with regard to mining activities, remains controversial. Underdeveloped nations often see the principle as a means of protecting critical resources from exploitation by capitalist nations and their corporations. As world oil, coal and mineral reserves are depleted there will be increasing pressure to commercially exploit Common Heritage of Mankind areas. It appears at the present time that exploration of outer space is unlikely to initially proceed under the jurisdiction of a supranational organization, but rather through the coordination of national space programs. It has been argued that photosynthesis in its natural or artificial forms should be considered the common heritage of humanity.\n\n"}
{"id": "19630739", "url": "https://en.wikipedia.org/wiki?curid=19630739", "title": "Continent", "text": "Continent\n\nA continent is one of several very large landmasses of the world. Generally identified by convention rather than any strict criteria, up to seven regions are commonly regarded as continents. Ordered from largest in area to smallest, they are: Asia, Africa, North America, South America, Antarctica, Europe, and Australia.\n\nGeologically, the continents largely correspond to areas of continental crust that are found on the continental plates. However, some areas of continental crust are regions covered with water not usually included in the list of continents. Zealandia is one such area (see submerged continents below).\n\nIslands are frequently grouped with a neighbouring continent to divide all the world's land into geopolitical regions. Under this scheme, most of the island countries and territories in the Pacific Ocean are grouped together with the continent of Australia to form a geopolitical region called \"Oceania\".\n\nBy convention, \"continents are understood to be large, continuous, discrete masses of land, ideally separated by expanses of water.\" Several of the seven conventionally recognized continents are not discrete landmasses separated completely by water. The criterion \"large\" leads to arbitrary classification: Greenland, with a surface area of is considered the world's largest island, while Australia, at is deemed the smallest continent.\n\nEarth's major landmasses all have coasts on a single, continuous World Ocean, which is divided into a number of principal oceanic components by the continents and various geographic criteria.\n\nThe most restricted meaning of \"continent\" is that of a continuous area of land or mainland, with the coastline and any land boundaries forming the edge of the continent. In this sense the term \"continental Europe\" (sometimes referred to in Britain as \"the Continent\") is used to refer to mainland Europe, excluding islands such as Great Britain, Ireland, Malta and Iceland, and the term \"continent of Australia\" may refer to the mainland of Australia, excluding Tasmania and New Guinea. Similarly, the \"continental United States\" refers to the 48 contiguous states and the District of Columbia in central North America and may include Alaska in the northwest of the continent (the two being separated by Canada), while excluding Hawaii, Puerto Rico, and Guam in the oceans.\n\nFrom the perspective of geology or physical geography, \"continent\" may be extended beyond the confines of continuous dry land to include the shallow, submerged adjacent area (the continental shelf) and the islands on the shelf (continental islands), as they are structurally part of the continent.\n\nFrom this perspective, the edge of the continental shelf is the true edge of the continent, as shorelines vary with changes in sea level. In this sense the islands of Great Britain and Ireland are part of Europe, while Australia and the island of New Guinea together form a continent.\n\nAs a cultural construct, the concept of a continent may go beyond the continental shelf to include oceanic islands and continental fragments. In this way, Iceland is considered part of Europe and Madagascar part of Africa. Extrapolating the concept to its extreme, some geographers group the Australian continental plate with other islands in the Pacific into one continent called Oceania. This divides the entire land surface of Earth into continents or quasi-continents.\n\nThe ideal criterion that each continent is a discrete landmass is commonly relaxed due to historical conventions. Of the seven most globally recognized continents, only Antarctica and Australia are completely separated from other continents by the ocean. Several continents are defined not as absolutely distinct bodies but as \"\"more or less\" discrete masses of land\". Asia and Africa are joined by the Isthmus of Suez, and North and South America by the Isthmus of Panama. In both cases, there is no complete separation of these landmasses by water (disregarding the Suez Canal and Panama Canal, which are both narrow and shallow, as well as being artificial). Both these isthmuses are very narrow compared to the bulk of the landmasses they unite.\n\nNorth America and South America are treated as separate continents in the seven-continent model. However, they may also be viewed as a single continent known as America or the Americas. This viewpoint was common in the United States until World War II, and remains prevalent in some Asian six-continent models. This remains the more common vision in Latin American countries, Spain, Portugal, France, Italy and Greece, where they are taught as a single continent.\n\nThe criterion of a discrete landmass is completely disregarded if the continuous landmass of Eurasia is classified as two separate continents: Europe and Asia. Physiographically, Europe and South Asia are peninsulas of the Eurasian landmass. However, Europe is widely considered a continent with its comparatively large land area of , while South Asia, with less than half that area, is considered a subcontinent. The alternative view—in geology and geography—that Eurasia is a single continent results in a six-continent view of the world. Some view separation of Eurasia into Asia and Europe as a residue of Eurocentrism: \"In physical, cultural and historical diversity, China and India are comparable to the entire European landmass, not to a single European country. [...].\" However, for historical and cultural reasons, the view of Europe as a separate continent continues in several categorizations.\n\nIf continents are defined strictly as discrete landmasses, embracing all the contiguous land of a body, then Africa, Asia, and Europe form a single continent which may be referred to as Afro-Eurasia. This produces a four-continent model consisting of Afro-Eurasia, America, Antarctica and Australia.\n\nWhen sea levels were lower during the Pleistocene ice ages, greater areas of continental shelf were exposed as dry land, forming land bridges. At those times Australia–New Guinea was a single, continuous continent. Likewise, the Americas and Afro-Eurasia were joined by the Bering land bridge. Other islands such as Great Britain were joined to the mainlands of their continents. At that time there were just three discrete continents: Afro-Eurasia-America, Antarctica, and Australia-New Guinea.\n\nThere are several ways of distinguishing the continents:\n\n\nThe term \"Oceania\" refers to a group of island countries and territories in the Pacific Ocean, together with the continent of Australia. Pacific islands with ties to other continents (such as Japan, Hawaii or Easter Island) are usually grouped with those continents rather than Oceania. This term is used in several different continental models instead of Australia.\n\nThe following table summarizes the area and population of each continental region using the seven continent model.\n\nThe total land area of all continents is , or 29.1% of earth's surface ().\n\nAside from the conventionally known continents, the scope and meaning of the term \"continent\" varies. Supercontinents, largely in evidence earlier in the geological record, are landmasses that comprise more than one craton or continental core. These have included Laurasia, Gondwana, Vaalbara, Kenorland, Columbia, Rodinia, and Pangaea.\n\nCertain parts of continents are recognized as subcontinents, especially the large peninsulas separated from the main continental landmass by geographical features. The most notable examples are the Indian subcontinent and the Arabian Peninsula. The Southern Cone of South America and Alaskan peninsula of North America are other examples.\n\nIn many of these cases, the \"subcontinents\" concerned are on different tectonic plates from the rest of the continent, providing a geological justification for the terminology. Greenland, generally reckoned as the world's largest island on the northeastern periphery of the North American Plate, is sometimes referred to as a subcontinent. This is a significant departure from the more conventional view of a subcontinent as comprising a very large peninsula on the fringe of a continent.\n\nWhere the Americas are viewed as a single continent (America), it is divided into two subcontinents (North America and South America) or three (with Central America being the third). When Eurasia is regarded as a single continent, Europe is treated as a subcontinent.\n\nSome areas of continental crust are largely covered by the sea and may be considered submerged continents. Notable examples are Zealandia, emerging from the sea primarily in New Zealand and New Caledonia, and the almost completely submerged Kerguelen Plateau in the southern Indian Ocean.\n\nSome islands lie on sections of continental crust that have rifted and drifted apart from a main continental landmass. While not considered continents because of their relatively small size, they may be considered microcontinents. Madagascar, the largest example, is usually considered an island of Africa but has been referred to as \"the eighth continent\" from a .\n\n\"Continents\" may be defined differently for specific purposes. The Biodiversity Information Standards organization has developed the World Geographical Scheme for Recording Plant Distributions, used in many international plant databases. This scheme divides the world into nine \"botanical continents\". Some match the traditional geographical continents, but some differ significantly. Thus the Americas are divided between Northern America (Mexico northwards) and Southern America (Central America and the Caribbean southwards) rather than between North America and South America.\n\nThe term \"continent\" translates Greek , properly \"landmass, terra firma\", the proper name of Epirus and later especially used of Asia (i.e. Asia Minor),\nThe first distinction between continents was made by ancient Greek mariners who gave the names Europe and Asia to the lands on either side of the waterways of the Aegean Sea, the Dardanelles strait, the Sea of Marmara, the Bosporus strait and the Black Sea. The names were first applied just to lands near the coast and only later extended to include the hinterlands. But the division was only carried through to the end of navigable waterways and \"... beyond that point the Hellenic geographers never succeeded in laying their finger on any inland feature in the physical landscape that could offer any convincing line for partitioning an indivisible Eurasia ...\"\n\nAncient Greek thinkers subsequently debated whether Africa (then called \"Libya\") should be considered part of Asia or a third part of the world. Division into three parts eventually came to predominate. From the Greek viewpoint, the Aegean Sea was the center of the world; Asia lay to the east, Europe to the north and west, and Africa to the south. The boundaries between the continents were not fixed. Early on, Europe–Asia boundary was taken to run from the Black Sea along the Rioni River (known then as the \"Phasis\") in Georgia. Later it was viewed as running from the Black Sea through Kerch Strait, the Sea of Azov and along the Don River (known then as the \"Tanais\") in Russia. The boundary between Asia and Africa was generally taken to be the Nile River. Herodotus in the 5th century BC, however, objected to the unity of Egypt being split into Asia and Africa (\"Libya\") and took the boundary to lie along the western border of Egypt, regarding Egypt as part of Asia. He also questioned the division into three of what is really a single landmass, a debate that continues nearly two and a half millennia later.\n\nEratosthenes, in the 3rd century BC, noted that some geographers divided the continents by rivers (the Nile and the Don), thus considering them \"islands\". Others divided the continents by isthmuses, calling the continents \"peninsulas\". These latter geographers set the border between Europe and Asia at the isthmus between the Black Sea and the Caspian Sea, and the border between Asia and Africa at the isthmus between the Red Sea and the mouth of Lake Bardawil on the Mediterranean Sea.\nThrough the Roman period and the Middle Ages, a few writers took the Isthmus of Suez as the boundary between Asia and Africa, but most writers continued to consider it the Nile or the western border of Egypt (Gibbon). In the Middle Ages, the world was usually portrayed on T and O maps, with the T representing the waters dividing the three continents. By the middle of the 18th century, \"the fashion of dividing Asia and Africa at the Nile, or at the Great Catabathmus [the boundary between Egypt and Libya] farther west, had even then scarcely passed away\".\n\nChristopher Columbus sailed across the Atlantic Ocean to the West Indies in 1492, sparking a period of European exploration of the Americas. But despite four voyages to the Americas, Columbus never believed he had reached a new continent—he always thought it was part of Asia.\n\nIn 1501, Amerigo Vespucci and Gonçalo Coelho attempted to sail around what they considered the southern end of the Asian mainland into the Indian Ocean, passing through Fernando de Noronha. After reaching the coast of Brazil, they sailed a long way further south along the coast of South America, confirming that this was a land of continental proportions and that it also extended much further south than Asia was known to. On return to Europe, an account of the voyage, called \"Mundus Novus\" (\"New World\"), was published under Vespucci's name in 1502 or 1503, although it seems that it had additions or alterations by another writer. Regardless of who penned the words, \"Mundus Novus\" credited Vespucci with saying, \"I have discovered a continent in those southern regions that is inhabited by more numerous people and animals than our Europe, or Asia or Africa\", the first known explicit identification of part of the Americas as a continent like the other three.\n\nWithin a few years, the name \"New World\" began appearing as a name for South America on world maps, such as the Oliveriana (Pesaro) map of around 1504–1505. Maps of this time though, still showed North America connected to Asia and showed South America as a separate land.\n\nIn 1507 Martin Waldseemüller published a world map, \"Universalis Cosmographia\", which was the first to show North and South America as separate from Asia and surrounded by water. A small inset map above the main map explicitly showed for the first time the Americas being east of Asia and separated from Asia by an ocean, as opposed to just placing the Americas on the left end of the map and Asia on the right end. In the accompanying book \"Cosmographiae Introductio\", Waldseemüller noted that the earth is divided into four parts, Europe, Asia, Africa and the fourth part, which he named \"America\" after Amerigo Vespucci's first name. On the map, the word \"America\" was placed on part of South America.\n\nFrom the 16th century the English noun \"continent\" was derived from the term \"continent land\", meaning continuous or connected land and translated from the Latin \"terra continens\". The noun was used to mean \"a connected or continuous tract of land\" or mainland. It was not applied only to very large areas of land—in the 17th century, references were made to the \"continents\" (or mainlands) of Isle of Man, Ireland and Wales and in 1745 to Sumatra. The word \"continent\" was used in translating Greek and Latin writings about the three \"parts\" of the world, although in the original languages no word of exactly the same meaning as \"continent\" was used.\n\nWhile \"continent\" was used on the one hand for relatively small areas of continuous land, on the other hand geographers again raised Herodotus's query about why a single large landmass should be divided into separate continents. In the mid-17th century, Peter Heylin wrote in his \"Cosmographie\" that \"A Continent is a great quantity of Land, not separated by any Sea from the rest of the World, as the whole Continent of Europe, Asia, Africa.\" In 1727, Ephraim Chambers wrote in his \"Cyclopædia,\" \"The world is ordinarily divided into two grand continents: the old and the new.\" And in his 1752 atlas, Emanuel Bowen defined a continent as \"a large space of dry land comprehending many countries all joined together, without any separation by water. Thus Europe, Asia, and Africa is one great continent, as America is another.\" However, the old idea of Europe, Asia and Africa as \"parts\" of the world ultimately persisted with these being regarded as separate continents.\n\nFrom the late 18th century, some geographers started to regard North America and South America as two parts of the world, making five parts in total. Overall though, the fourfold division prevailed well into the 19th century.\n\nEuropeans discovered Australia in 1606, but for some time it was taken as part of Asia. By the late 18th century, some geographers considered it a continent in its own right, making it the sixth (or fifth for those still taking America as a single continent). In 1813, Samuel Butler wrote of Australia as \"New Holland, an immense island, which some geographers dignify with the appellation of another continent\" and the \"Oxford English Dictionary\" was just as equivocal some decades later.\n\nAntarctica was sighted in 1820 during the First Russian Antarctic Expedition and described as a continent by Charles Wilkes on the United States Exploring Expedition in 1838, the last continent identified, although a great \"Antarctic\" (antipodean) landmass had been anticipated for millennia. An 1849 atlas labelled Antarctica as a continent but few atlases did so until after World War II.\n\nFrom the mid-19th century, atlases published in the United States more commonly treated North and South America as separate continents, while atlases published in Europe usually considered them one continent. However, it was still not uncommon for American atlases to treat them as one continent up until World War II.\n\nFrom the 1950s, most U.S. geographers divided the Americas into two continents. With the addition of Antarctica, this made the seven-continent model. However, this division of the Americas never appealed to Latin Americans, who saw their region spanning an as a single landmass, and there the conception of six continents remains dominant, as it does in scattered other countries.\n\nSome geographers regard Europe and Asia together as a single continent, dubbed \"Eurasia\". In this model, the world is divided into six continents, with North America and South America considered separate continents.\n\nGeologists use the term \"continent\" in a different manner from geographers. In geology a continent is defined by continental crust: a platform of metamorphic and igneous rock, largely of granitic composition. Some geologists restrict the term 'continent' to portions of the crust built around stable Precambrian \"shield\", typically 1.5 to 3.8 billion years old, called a craton. The craton itself is an accretionary complex of ancient mobile belts (mountain belts) from earlier cycles of subduction, continental collision and break-up from plate tectonic activity. An outward-thickening veneer of younger minimally deformed sedimentary rock covers much of the craton. The margins of geologic continents are characterized by currently active or relatively recently active mobile belts and deep troughs of accumulated marine or deltaic sediments. Beyond the margin, there is either a continental shelf and drop off to the basaltic ocean basin or the margin of another continent, depending on the current plate-tectonic setting of the continent. A continental boundary does not have to be a body of water. Over geologic time, continents are periodically submerged under large epicontinental seas, and continental collisions result in a continent becoming attached to another continent. The current geologic era is relatively anomalous in that so much of the continental areas are \"high and dry\"; that is, many parts of the continents that were once below sea level are now elevated well above it due to changes in sea levels and the subsequent uplifting of those continental areas from tectonic activity.\n\nSome argue that continents are accretionary crustal \"rafts\" that, unlike the denser basaltic crust of the ocean basins, are not subjected to destruction through the plate tectonic process of subduction. This accounts for the great age of the rocks comprising the continental cratons. By this definition, Eastern Europe, India and some other regions could be regarded as continental masses distinct from the rest of Eurasia because they have separate ancient shield areas (i.e. East European craton and Indian craton). Younger mobile belts (such as the Ural Mountains and Himalayas) mark the boundaries between these regions and the rest of Eurasia.\n\nThere are many microcontinents, or continental fragments, that are built of continental crust but do not contain a craton. Some of these are fragments of Gondwana or other ancient cratonic continents: Zealandia, which includes New Zealand and New Caledonia; Madagascar; the northern Mascarene Plateau, which includes the Seychelles. Other islands, such as several in the Caribbean Sea, are composed largely of granitic rock as well, but all continents contain both granitic and basaltic crust, and there is no clear boundary as to which islands would be considered microcontinents under such a definition. The Kerguelen Plateau, for example, is largely volcanic, but is associated with the breakup of Gondwanaland and is considered a microcontinent, whereas volcanic Iceland and Hawaii are not. The British Isles, Sri Lanka, Borneo, and Newfoundland are margins of the Laurasian continent—only separated by inland seas flooding its margins.\n\nPlate tectonics offers yet another way of defining continents. Today, Europe and most of Asia constitute the unified Eurasian Plate, which is approximately coincident with the geographic Eurasian continent excluding India, Arabia, and far eastern Russia. India contains a central shield, and the geologically recent Himalaya mobile belt forms its northern margin. North America and South America are separate continents, the connecting isthmus being largely the result of volcanism from relatively recent subduction tectonics. North American continental rocks extend to Greenland (a portion of the Canadian Shield), and in terms of plate boundaries, the North American plate includes the easternmost portion of the Asian landmass. Geologists do not use these facts to suggest that eastern Asia is part of the North American continent, even though the plate boundary extends there; the word continent is usually used in its geographic sense and additional definitions (\"continental rocks,\" \"plate boundaries\") are used as appropriate.\n\nThe movement of plates has caused the formation and break-up of continents over time, including occasional formation of a supercontinent that contains most or all of the continents. The supercontinent Columbia or Nuna formed during a period of 2.0–1.8 billion years ago and broke up about 1.5–1.3 billion years ago. The supercontinent Rodinia is thought to have formed about 1 billion years ago and to have embodied most or all of Earth's continents, and broken up into eight continents around 600 million years ago. The eight continents later re-assembled into another supercontinent called Pangaea; Pangaea broke up into Laurasia (which became North America and Eurasia) and Gondwana (which became the remaining continents).\n\nThe following table lists the seven continents with their highest and lowest points on land, sorted in decreasing highest points.\n\n† The lowest exposed points are given for North America and Antarctica. The lowest non-submarine bedrock elevations in these continents are the trough beneath Jakobshavn Glacier () and Bentley Subglacial Trench (), but these are covered by kilometers of ice.\n\nSome sources list the Kuma–Manych Depression (a remnant of the Paratethys) as the geological border between Europe and Asia. This would place the Caucasus outside of Europe, thus making Mont Blanc (elevation 4810 m) in the Graian Alps the highest point in Europe – the lowest point would still be the shore of the Caspian Sea.\n\n\n"}
{"id": "15822342", "url": "https://en.wikipedia.org/wiki?curid=15822342", "title": "Continental fragment", "text": "Continental fragment\n\nContinental crustal fragments, partially synonymous with microcontinents, are fragments of continents that have been broken off from main continental masses forming distinct islands, often several hundred kilometers from their place of origin. All continents are fragments; , due to Australia being the smallest continent. They are not known to contain a craton or fragment of a craton. Continental fragments include some seamounts and underwater plateaus.\n\nSome microcontinents are fragments of Gondwana or other ancient cratonic continents: these include Madagascar; the northern Mascarene Plateau, which includes the Seychelles; the island of Timor, etc. Other islands, such as several in the Caribbean Sea, are composed largely of granitic rock as well, but all continents contain both granitic and basaltic crust, and there is no clear dividing line between islands and microcontinents under such a definition. The Kerguelen Plateau is a large igneous province formed by a volcanic hot spot; however, it was associated with the breakup of Gondwana and was for a time above water, so it is considered a microcontinent, though not a continental fragment. Other hotspot islands such as Iceland and Hawaii are considered neither microcontinents nor continental fragments. Not all islands can be considered microcontinents: the British Isles, Sri Lanka, Borneo, and Newfoundland, for example, are each within the continental shelf of an adjacent continent, separated from the mainland by inland seas flooding its margins.\n\nSeveral islands in the eastern Indonesian archipelago are considered continental fragments, although this designation is controversial. These include Sumba, Timor (Nusa Tenggara), Banggai-Sulu Islands (Sulawesi), Obi, southern Bacan, and the Buru-Seram-Ambon complex (Maluku).\n\n\n"}
{"id": "1582312", "url": "https://en.wikipedia.org/wiki?curid=1582312", "title": "Core countries", "text": "Core countries\n\nIn world systems theory, the core countries are the industrialized capitalist countries on which periphery countries and semi-periphery countries depend. Core countries control and benefit from the global market. They are usually recognized as wealthy nations with a wide variety of resources and are in a favorable location compared to other states. They have strong state institutions, a powerful military and powerful global political alliances.\n\nCore countries do not always stay core permanently. Throughout history, core nations have been changing and new ones have been added to the core list. The most influential countries in the past have been what would be considered core. These were the Asian, Indian and Middle Eastern empires in the ages up to the 16th century, prominently India and China were the richest regions in the world until the 15th century, when the European powers took the lead, although the major Asian powers such as China were still very influential in the region. Europe remained ahead of the pack until the 20th century, when the two World Wars turned disastrous for the European economies. It is then that the victorious United States and Soviet Union, up to late 1980s, became the two hegemons, creating a bipolar world order.\nThe heart of civilisation consists of Western Europe, North America, Australasia and Japan. The population of the core is by far the wealthiest and best educated on the planet.\n\nCore countries control and profit the most from the world system, and thus they are the \"core\" of the world system. These countries possess the ability to exercise control over other countries or groups of countries with several kinds of power such as military, economic, and political power.\n\nThe United States, Canada, the countries of the European Union, Australia, South Korea and Japan are examples of present core countries that have the most power in the world economic system. Core countries tend to have both strong state machinery and a developed national culture.\n\nBefore the 13th century, many empires were considered to be \"core\" nations, such as the Persian, Indian, and Roman empires, the Muslim Caliphates, the Chinese and Egyptian dynasties, the various Mesopotamian kingdoms, and so on.\n\nIn Asia, the Chinese Empire was considered the middle kingdom and controlled the region. The two empires communicated and traded through the Silk Route, which takes its name from the extensive trade of Chinese silk.\n\nIndia until the 13th century, often referred to as Greater India, extended its religious, cultural, and trading influence on vast Asian regions from Iran and Afghanistan to Malaysia, Indonesia and Cambodia. With Buddhism and Hinduism, two of the most followed religions in Asia and the World as a whole, having originated there, India's cultural impact spread throughout Asia. A notable example is China, where Buddhism became the prominent religion. Sanskrit was a prominent scholarly language in all the southeastern kingdoms until the 10th century C.E.. Angkor Vat of Cambodia, the largest temple complex in the world, was originally a Hindu temple and later transformed into a Buddhist monastery.\n\nPax Mongolica is a particularly important period which started in 1206 and ended, according to contradicting sources, between late 14th and early 15th centuries. The trade during this period took on a truly multi-continental dimension, efficient and safe trade routes were established, and many of the modern rules of trade were emerging. The Mongol Empire was the largest contiguous empire in the history of the world. It stretched from as far east as China all the way to Europe, taking up large parts of Central Asia, Middle East, and India.\nMany trade routes went through the Mongol Empire territory, even though they were not the easiest ones to travel, due to the rough Asian terrain. Yet, they attracted many merchants, because these routes were relatively cheap and safe to travel. The Mongols controlled their territories through military force and taxation. In many regions of the Mongol territory, Mongol rule is remembered as brutal and destructive. Yet, some argue that many economic and cultural improvements were made during the Mongol Empire's rule.\n\nThe Ottoman Empire, which emerged in 1299, quickly became a power to be reckoned with. By 1450, the Ottoman Empire took up the connecting territory between the Black and Mediterranean seas. Despite lasting three times longer than the Mongol Empire, the Ottoman Empire never came to be anywhere near as expansive.\n\nPrior to the 16th century, feudalism took over Western European society and pushed Western Europe on a road to capitalist development. Population and commerce grew rapidly within the feudal system during the years of 1150–1300. Through the years 1300–1450, an economic downfall came about. The feudalism growth had come to an end. According to Wallerstein, \"the feudal crisis was most likely brought on by the involvement of the three following factors below:\n\nThe feudal crisis lead to the development of the world economic system. The world economic system came about during the late 15th and early 16th centuries. The most dominant of Northwestern Europe were England, France, and the Netherlands (see map of Western Europe on the right). These countries took on the definition of a core country. They developed a strong central government, bureaucracies, and grew their military power. These countries were then able to control the international commerce and create a profit for themselves. All of western Europe attempted bureaucratization, homogenization of the local population, development of a stronger military, and involvement of the country in a vast number of different economic activities. After these attempts to gain the \"core\" status, north-western European states locked in their positions as core states by 1640. England dominated the pack, as Spain and Italy fell to semi-peripheral status.\n\nOne factor that helped the core countries dominate over the other countries is long-distance trade with the Americas and the East. This trade produced profits of 200–300%. In order to enter this trade market, countries needed a great amount of capital and state help. The smaller countries could not make this happen, and this widened the gap between the \"core\" and \"semi-periphery\" countries. These core positions held strong up and throughout the 18th century, even as the core regions started to produce a mixture of agricultural and industrial goods. At the beginning of 1700, manufacture of goods in industrial productions started to take off. Industrial production soon took over the agricultural production up to the year 1900.\n\nAs nations continued to grow technologically, especially through printing journals and newspapers, communication was more widespread. Thus, the global society was united through this force. In order to assure a good life for their citizens, countries needed to rely on trade and on technological advancements, which ultimately determined how well in the world a country stood.\n\nKeeping in mind the interactions of nations in this period, John W. Cell notes in his essay entitled \"Europe and the World in an Expanding World Economy, 1700—1850\", that war and trade were somewhat dependent on each other. Nations had to defend their ships while also establishing territories elsewhere to ensure successful trade for themselves. By the middle of the 17th century, the \"foundations of the modern world system had been laid.\"\n\nAt the beginning of the 18th century, Europe had not yet dominated in the world economy on account of the fact that its military did not match that of Asia or of the Middle East. However, through organizing its economics and improving technology in industry, European countries took the lead as the most powerful nations in the late 18th century and remained in this position until late in the 20th century.\n\nIn the 18th century, Asia was making and distributing goods that were valued by other areas, namely cotton, silk and tea. Europe on the other hand, was not producing products of interest to the other parts of the world. Hence, although Europe was wealthy, this dynamic shows that there may be a reversal of power because it was consistently expanding money, yet hardly bringing in currency. America's crops were not initially appealing to Europeans. Tobacco's demand had to be advertised, and eventually Europe became interested in this particular plant. In time, there was rather regular trans-Atlantic trade between the Americas and Europe for such crops as tobacco, cotton, and also goods available in South America.\n\nThe 18th century was profoundly marked by the slave trade. Slavery was present in civilizations on all continents throughout post-hunter-gatherer history. The importation of slaves from the Old World started on continental North America in August 1619 as a form of indentured servitude, and continued in the next centuries. Slavery also occurred in Africa previous to Europeans capitalizing on selling slaves. Africans were sometimes hired to collect others off the coast, and bring them back to European ships. Because of this trade, the dependent nations remained dependent as their populations were suffering from the slave trade.\n\nThis trade of humans was incredibly profitable for the Europeans, perpetuating their success and \"rule\" of the seas. Immediately following the early 19th century, the southern U.S. population consisted of 37.5% slaves.\n\nAt the beginning of the 19th century, Europe still dominated as the core region of the world. France attempted to obtain European hegemony under the rule of Napoleon Bonaparte.\n\nIn 1871, Germany became united and established themselves as the leading industrial nation on the European mainland. Their desire to dominate the mainland helped them to become a core nation. After the First World War, Europe was decimated, and the position for new core nations was opening up. This culminated with the defeat of Nazi Germany in the Second World War, when Britain was forced to sacrifice its hegemony, allowing the United States and the Soviet Union to become world superpowers and major cores. The USSR lost its core status following its collapse in 1991.\nThe following are core according to Chase-Dunn, Kawano, Brewer (2000).\n\nAnd this is the core listing according to Babones (2005), who notes that this list is composed of countries that \"have been consistently classified into a single one of the three zones [core, semi-periphery or periphery] of the world economy over the entire 28-year study period\".\n\nThe World Systems Theory argues that a nation's future is decided by their stance in the global economy. A global capitalistic market demands the needs for wealthy (core) states and poor (periphery) states. Core states benefit from the hierarchical structure of international trade and labor. World systems theory follows the logic that international wars or multinational financial disputes can be explained as attempts to change a location within the global market for a specific state or groups of states; these changes can have the objective to gain more control over the global market (to become a core country), while causing another nation to lose control over the world market. As the two groups grew apart in power, world systems theorists to established another group, the semi-periphery, to act as the middle group.\n\nSemi-periphery countries usually surround the core countries both in a physical and fundamental sense. The semi-periphery countries act as the middle men between the core and the periphery countries - by giving the wealthy countries what they receive from the poor countries. The periphery countries are the poorer countries usually specializing in farming and have access natural resources - which the core countries use to profit from.\n\nIn order for a country to remain a core or to become a core, possible investors must be kept in mind when nation's policies are planned. Core countries change with time due to many different factors including changes in geographic favoritism and regional affluence. Alterations in financing plans by companies will also play a part as they change to react to the continuously evolving world market.\n\nIn order for a country to be considered a core country nominee, the country must possess an independent, stable government and potential for growth in the global market and advances in technology. Although these three factors will not completely decide where a company chooses to invest – they do play extremely large roles in such decisions. A main key to becoming or remaining a core is determined by the country's government policies to encourage funding from outside.\n\nThe main function of the core countries is to command and financially benefit from the world system better than the rest of the world. Core countries could also be viewed as the capitalist class while the periphery countries could be viewed as a disordered working class. In a capitalism-driven market, core countries exchange goods with the poor nations at an unequal rate greatly in favor of the core countries.\n\nThe periphery countries’ purpose is to provide agricultural and natural resources along with the lower division of labor for larger corporations of semi-periphery and core countries. As a result of the lower priced division of labor and natural resources available, the core nations’ companies buy these products for a relatively low cost and then sell them for much higher. The periphery countries only receive low amounts of money for what they sell and must pay higher prices for anything they buy from outside their own region. Because of this continuous order, periphery countries can never earn enough to cover the costs of their imports while setting aside money to invest in better technologies. Core countries support this pattern by giving loans to the poor regions for specific investments in a raw material or type of agriculture, rather than help such regions establish themselves and balance out the world market.\n\nA disadvantage to core nations is to remain a member of the core grouping, the government must retain or create new policies that encourage investments to keep in their country and not relocate. This can make it difficult for governments to change national standards that may sacrifice high profits.\n\nAn example of a change that capitalism does not favor is the abolition of slavery. During the early industrialization and growth of America, exports produced by slaves played a huge role in making businesses the most profit. Such movements to abolish slavery and spread equality caused an internal war within the United States.\n\n"}
{"id": "715200", "url": "https://en.wikipedia.org/wiki?curid=715200", "title": "Democratic globalization", "text": "Democratic globalization\n\nDemocratic globalisation is a social movement towards an institutional system of global democracy. This would, in their view, bypass nation-states, corporate oligopolies, ideological NGOs, cults and mafias. One of its most prolific proponents is the British political thinker David Held. In the last decade he published a dozen books regarding the spread of democracy from territorially defined nation states to a system of global governance that encapsulates the entire world. For some, democratic mundialisation is a variant of democratic globalisation stressing the need for the direct election of world leaders and members of global institutions by citizens worldwide; for others, it is just another name for democratic globalisation.\n\nThese proponents state that democratic globalisation's purpose is to:\n\nSupporters of the democratic globalization movement draw a distinction between their movement and the one most popularly known as the 'anti-globalization' movement, claiming that their movement avoids ideological agenda about economics and social matters. Democratic globalization supporters state that the choice of political orientations should be left to the world citizens, via their participation in world democratic institutions.\nSome proponents in the \"anti-globalization movement\" do not necessarily disagree with this position. For example, George Monbiot, normally associated with the anti-globalization movement (who prefers the term Global Justice Movement) in his work \"Age of Consent\" has proposed similar democratic reforms of most major global institutions, suggesting direct democratic elections of such bodies, and suggests a form of \"world government.\"\n\nDemocratic globalization supports the extension of political democratization to economic and financial globalization. It is based upon an idea that free international transactions benefit the global society as a whole. They believe in financially\nopen economies, where the government and central bank must be transparent in order to retain the confidence of the markets, since transparency spells doom for autocratic regimes. They promote democracy that makes leaders more accountable to the citizenry through the removal of restrictions on such transactions.\n\nThe democratic globalization movement started to get public attention when New York Times reported its demonstration to contest a World Trade Organization (WTO) in Seattle, Washington, November 1999. This gathering was to criticize unfair trade and undemocratic globalization of the WTO, World Bank, World Economic Forum (WEF), the International Monetary Fund. Its primary tactics were public rallies, street theater and civil disobedience.\n\nDemocratic globalization, proponents claim, would be reached by creating democratic global institutions and changing international organizations (which are currently intergovernmental institutions controlled by the nation-states), into global ones controlled by world citizens. The movement suggests to do it gradually by building a limited number of democratic global institutions in charge of a few crucial fields of common interest. Its long-term goal is that these institutions federate later into a full-fledged democratic world government.\n\nThus, it supports the International Campaign for the Establishment of a United Nations Parliamentary Assembly, that would allow for participation of member nations' legislators and, eventually, direct election of United Nations (UN) parliament members by citizens worldwide.\n\nSome supporters of the democratic globalization movement draw a distinction between their movement and the one most popularly known as the 'anti-globalization' movement, claiming that their movement avoids ideological agenda about economics and social matters although, in practice, it is often difficult to distinguish between the two camps. Democratic globalization supporters state that the choice of political orientations should be left to the world citizens, via their participation in world democratic institutions and direct vote for world presidents (see presidentialism).\n\nSome supporters of the \"anti-globalization movement\" do not necessarily disagree with this position. For example, George Monbiot, normally associated with the anti-globalization movement (who prefers the term Global Justice Movement) in his work \"Age of Consent\" has proposed similar democratic reforms of most major global institutions, suggesting direct democratic elections of such bodies by citizens, and suggests a form of \"federal world government\".\n\nDemocratic globalization, proponents claim, would be reached by creating democratic global institutions and changing international organizations (which are currently intergovernmental institutions controlled by the nation-states), into global ones controlled by voting by the citizens. The movement suggests to do it gradually by building a limited number of democratic global institutions in charge of a few crucial fields of common interest. Its long-term goal is that these institutions federate later into a full-fledged democratic world government.\n\nThey propose the creation of world services for citizens, like world civil protection and prevention (from natural hazards) services.\n\nThe concept of democratic globalization has supporters from all fields. Many of the campaigns and initiatives for global democracy, such as the UNPA campaign, list quotes by and names of their supporters on their websites.\n\nSome of the most prolific proponents are the British political thinker David Held and the Italian political theorist Daniele Archibugi. In the last decade they published several books regarding the spread of democracy from territorially defined nation states to a system of global governance that encapsulates the entire planet. Richard Falk has developed the idea from an international law perspective, Ulrich Beck from a sociological approach and Jürgen Habermas has elaborate the normative principles.\n\n\nJim Stark has initiated a process for a Democratic World Parliament through a Global Referendum. As of August 20, 2013, 22,126 people have voted. So far, the votes are 95.3% in favor of creating a democratic world parliament. Portable voting booths are available at http://voteworldparliament.org/shadowbox/getballot.html. Online voting at Mr. Stark's website is at voteworldparliament.org. Mr. Stark has published a companion book to the online referendum entitled \"Rescue Plan for Planet Earth\".\n\n\n\n"}
{"id": "33256286", "url": "https://en.wikipedia.org/wiki?curid=33256286", "title": "Demographics of the world", "text": "Demographics of the world\n\nDemographics of the world include population density, ethnicity, education level, health measures, economic status, religious affiliations and other aspects of the human population of the planet Earth. \n\nThe overall total population of the world is approximately 7.5 billion, as of March 2018. \n\nIts overall population density is 50 people per km² (129.28 per sq. mile), excluding Antarctica. Nearly two-thirds of the population lives in Asia and is predominantly urban and suburban, with more than 2.5 billion in the countries of China and India combined. The world's fairly low literacy rate (83.7%) is attributable to poverty. Lower literacy rates are common in South Asia, West Asia, and Sub-Saharan Africa.\n\nThe world's largest ethnic group is Han Chinese with Mandarin being the world's most spoken language in terms of native speakers.\n\nHuman migration has been shifting toward cities and urban centers, with the urban population jumping from 29% in 1950, to 50.5% in 2005. Working backwards from the United Nations prediction that the world will be 51.3 percent urban by 2010, Dr. Ron Wimberley, Dr. Libby Morris and Dr. Gregory Fulkerson estimated 23 May 2007 to be the first time the urban population outnumbered the rural population in history.\nChina and India are the most populous countries, as the birth rate has consistently dropped in developed countries and until recently remained high in developing countries. Tokyo is the largest urban conglomeration in the world.\n\nThe total fertility rate of the World is estimated as 2.52 children per woman, which is above the global average for the replacement fertility rate of approximately 2.33 (as of 2003). However, world population growth is unevenly distributed, with the total fertility rate going from .91 in Macau, to 7.68 in Niger. The United Nations estimated an annual population increase of 1.14% for the year of 2000.\nThe current world population growth is approximately 1.09%\nPeople under 18 years of age made up over a quarter of the world population (29.3%), and people age 65 and over made up less than one-tenth (7.9%) in 2011.\n\nThe world population more than tripled during the 20th century from about 1.65 billion in 1900 to 5.97 billion in 1999.\n\nIt reached the 2 billion mark in 1927, the 3 billion mark in 1960, 4 billion in 1974, and 5 billion in 1987. Currently, population growth is fastest among low wealth, Least Developed Countries countries.\n\nThe UN projects a world population of 9.15 billion in 2050, which is a 32.69% increase from 2010 (6.89 billion).\n\nHistorical migration of human populations begins with the movement of \"Homo erectus\" out of Africa across Eurasia about a million years ago. \"Homo sapiens\" appear to have occupied all of Africa about 150,000 years ago, moved out of Africa 50,000 - 60,000 years ago, and had spread across Australia, Asia and Europe by 30,000 years BC. Migration to the Americas took place 20,000 to 15,000 years ago, and by 2,000 years ago, most of the Pacific Islands were colonized.\n\nUntil c. 10,000 years ago, humans lived as hunter-gatherers. They generally lived in small nomadic groups known as band societies. The advent of agriculture prompted the Neolithic Revolution, when access to food surplus led to the formation of permanent human settlements. About 6,000 years ago, the first proto-states developed in Mesopotamia, Egypt's Nile Valley and the Indus Valley. Early human settlements were dependent on proximity to water and, depending on the lifestyle, other natural resources used for subsistence. But humans have a great capacity for altering their habitats by means of technology.\n\nSince 1800, the human population has increased from one billion to over seven billion, In 2004, some 2.5 billion out of 6.3 billion people (39.7%) lived in urban areas. In February 2008, the U.N. estimated that half the world's population would live in urban areas by the end of the year. Problems for humans living in cities include various forms of pollution and crime, especially in inner city and suburban slums. Both overall population numbers and the proportion residing in cities are expected to increase significantly in the coming decades.\n\nThe World has hundreds of major cities spread across 6 continents. Most are in coastal regions.\n\n, the World had 62 metropolitan areas with a population of over 3,000,000 people each.\n\nAs of 2010, about 3 billion people live in or around urban areas.\n\nThe following table shows the populations of the top ten conglomerations.\n\nThe world's population is 7 billion and Earth's total area (including land and water) is 510 million square kilometers (197 million square miles). Therefore, the worldwide human population density is 7 billion ÷ 510 million = 13.7 per km² (35.5 per sq. mile). If only the Earth's land area of 150 million km² (58 million sq. miles) is taken into account, then human population density increases to 46.7 per km² (117.2 per sq. mile). This calculation includes all continental and island land area, including Antarctica. If Antarctica is also excluded, then population density rises to 50 people per km² (129.28 per sq. mile). Considering that over half of the Earth's land mass consists of areas inhospitable to human inhabitation, such as deserts and high mountains, and that population tends to cluster around seaports and fresh water sources, this number by itself does not give any meaningful measurement of human population density.\n\nSeveral of the most densely populated territories in the world are city-states, microstates or dependencies. These territories share a relatively small area and a high urbanization level, with an economically specialized city population drawing also on rural resources outside the area, illustrating the difference between high population density and overpopulation.\n\nThe table below lists religions classified by philosophy; however, religious philosophy is not always the determining factor in local practice. Please note that this table includes heterodox movements as adherents to their larger philosophical category, although this may be disputed by others within that category. For example, Cao Đài is listed because it claims to be a separate category from Buddhism, while Hòa Hảo is not, even though they are similar new religious movements.\n\nThe population numbers below are computed by a combination of census reports, random surveys (in countries where religion data is not collected in census, for example United States or France), and self-reported attendance numbers, but results can vary widely depending on the way questions are phrased, the definitions of religion used and the bias of the agencies or organizations conducting the survey. Informal or unorganized religions are especially difficult to count. Some organizations may wildly inflate their numbers.\n\nSince the late 19th century, the demographics of religion have changed a great deal. Some countries with a historically large Christian population have experienced a significant decline in the numbers of professed active Christians: see demographics of atheism. Symptoms of the decline in active participation in Christian religious life include declining recruitment for the priesthood and monastic life, as well as diminishing attendance at church. On the other hand, since the 19th century, large areas of sub-Saharan Africa have been converted to Christianity, and this area of the world has the highest population growth rate. In the realm of Western civilization, there has been an increase in the number of people who identify themselves as secular humanists. In many countries, such as the People's Republic of China, communist governments have discouraged religion, making it difficult to count the actual number of believers. However, after the collapse of communism in numerous countries of Eastern Europe and the former Soviet Union, religious life has been experiencing resurgence there, both in the form of traditional Eastern Christianity and in the forms of Neopaganism and Far Eastern religions.\n\nFollowing is some available data based on the work of the \"World Christian Encyclopedia\":\n\nStudies conducted by the Pew Research Center have found that, generally, poorer nations had a larger proportion of citizens who found religion to be very important than richer nations, with the exceptions of the United States and Kuwait.\n\nThe average age of marriage varies greatly from country to country and has varied through time. Women tend to marry earlier than men and currently varies from 17.6 for women in Niger, to 32.4 for women in Denmark while men range from 22.6 in Mozambique to 35.1 in Sweden.\n\nThe average number of hospital beds per 1,000 population is 2.94. Compare to Switzerland (18.3) and Mexico (1.1)\n\n96% of the urban population has access to improved drinking water, while only 78% of rural inhabitants have improved drinking water. A total average of 87% of urban and rural have access to improved drinking water.\n\n4% of the urban population does not have access to improved drinking water, leaving 22% of rural people without improved drinking water with a total world population of 13% not having access to drinking water.\n\n76% of the urban population has access to sanitation facilities, while only 45% of the rural population has access. A total world average of 39% do not have access to sanitation facilities.\n\nAs of 2009, there are an estimated 33.3 million people living with HIV/AIDS, which is approximately 0.8% of the world population, and there have been an estimated 1.8 million deaths attributed to HIV/AIDS.\n\nAs of 2010, 925 million people are undernourished.\n\nLife Expectancy at Birth:\n\nInfant Mortality\n\nThe following demographic statistics are from the CIA World Factbook, unless otherwise indicated.\n\nAccording to the 2006 CIA World Factbook, around 27% of the world's population is below 15 years of age.\n\nAccording to a report by the Global Social Change Research Project, worldwide, the percent of the population age 0-14 declined from 34% in 1950 to 27% in 2010. On the other hand, the percent elderly (60+) increased during the same period from 8% to 11%.\n\nGlobally, the growth rate of the human population has been declining since peaking in 1962 and 1963 at 2.20% per annum. In 2009, the estimated annual growth rate was 1.1%. The CIA World Factbook gives the world annual birthrate, mortality rate, and growth rate as 1.915%, 0.812%, and 1.092% respectively The last one hundred years have seen a rapid increase in population due to medical advances and massive increase in agricultural productivity made possible by the Green Revolution.\nThe actual annual growth in the number of humans fell from its peak of 88.0 million in 1989, to a low of 73.9 million in 2003, after which it rose again to 75.2 million in 2006. Since then, annual growth has declined. In 2009, the human population increased by 74.6 million, which is projected to fall steadily to about 41 million per annum in 2050, at which time the population will have increased to about 9.2 billion. Each region of the globe has seen great reductions in growth rate in recent decades, though growth rates remain above 2% in some countries of the Middle East and Sub-Saharan Africa, and also in South Asia, Southeast Asia, and Latin America.\n\nSome countries experienced negative population growth, especially in Eastern Europe mainly due to low fertility rates, high death rates and emigration. In Southern Africa, growth is slowing due to the high number of HIV-related deaths. Some Western Europe countries might also encounter negative population growth. Japan's population began decreasing in 2005.\n\nPopulation in the world increased from 1990 to 2008 with 1,423 million and 27% growth. Measured by persons, the increase was highest in India (290 million) and China (192 million). Population growth was highest in Qatar (174%) and United Arab Emirates (140%).\n\nData required on total number of births per year, and distribution by country.\n\nAs of 2009, the average birth rate (unclear whether this is the weighted average rate per country [with each country getting a weight of 1], or the unweighted average of the entire world population) for the whole world is 19.95 per year per 1000 total population, a 0.48% decline from 2003's world birth rate of 20.43 per 1000 total population. \n\nAccording to the CIA - The World Factbook, the country with the highest birth rate currently is Niger at 51.26 births per 1000 people. The country with the lowest birth rate is Japan at 7.64 births per 1000 people. Hong Kong, a Special Administrative Region of China, is at 7.42 births per 1000 people. As compared to the 1950s, birth rate was at 36 births per 1000 in the 1950s, birth rate has declined by 16 births per 1000 people. In July 2011, the U.S. National Institutes of Health announced that the adolescent birth rate continues to decline. \n\nBirth rates vary even within the same geographic areas. In Europe, as of July 2011, Ireland's birth rate is 16.5 per cent, which is 3.5 per cent higher than the next-ranked country, the UK. France has a birth rate of 12.8 per cent while Sweden is at 12.3 per cent. In July 2011, the UK's Office for National Statistics (ONS) announced a 2.4% increase in live births in the UK in 2010 alone. This is the highest birth rate in the UK in 40 years. By contrast, the birth rate in Germany is only 8.3 per 1,000, which is so low that both the UK and France, which have significantly smaller populations, produced more births in 2010. Birth rates also vary within the same geographic area, based on different demographic groups. For example, in April 2011, the U.S. CDC announced that the birth rate for women over the age of 40 in the U.S. rose between 2007 and 2009, while it fell among every other age group during the same time span. In August 2011, Taiwan's government announced that its birth rate declined in the previous year, despite the fact that it implemented a host of approaches to encourage its citizens to have babies.\n\nBirth rates ranging from 10-20 births per 1000 are considered low, while rates from 40-50 births per 1000 are considered high. There are problems associated with both an extremely high birth rate and an extremely low birth rate. High birth rates can cause stress on the government welfare and family programs to support a youthful population. Additional problems faced by a country with a high birth rate include educating a growing number of children, creating jobs for these children when they enter the workforce, and dealing with the environmental effects that a large population can produce. Low birth rates can put stress on the government to provide adequate senior welfare systems and also the stress on families to support the elders themselves. There will be less children or working age population to support the constantly growing aging population.\n\nThe ten countries with the highest crude death rate, according to the 2015 CIA World Factbook estimates, are:\n\nSee list of countries by death rate for worldwide statistics.\n\nAccording to the World Health Organization, the 10 leading causes of death in 2002 were:\n\n\nCauses of death vary greatly between first and third world countries.\n\nAccording to Jean Ziegler (the United Nations Special Rapporteur on the Right to Food for 2000 to March 2008), mortality due to malnutrition accounted for 58% of the total mortality in 2006: \"In the world, approximately 62 millions people, all causes of death combined, die each year. In 2006, more than 36 millions died of hunger or diseases due to deficiencies in micronutrients\".\n\nOf the roughly 150,000 people who died each day across the globe, about two thirds—100,000 per day—died of age-related causes in 2001, according to an article which counts all deaths \"due to causes that kill hardly anyone under the age of 40\" as age-related.<ref name=\"doi10.2202/1941-6008.1011\"></ref> In industrialized nations, the proportion was even higher according to that article, reaching 90%.\n\nThe Northern Mariana Islands have the highest female ratio with 0.77 males per female. Qatar has the highest male ratio, with 2.87 males/female. For the group aged below 15, Sierra Leone has the highest female ratio with 0.96 males/female, and the Republic of Georgia and the People's Republic of China are tied for the highest male ratio with 1.13 males/female (according to the 2006 CIA World Factbook).\n\nThe value for the entire world population is 1.02 males/female, with 1.07 at birth, 1.06 for those under 15, 1.02 for those between 15 and 64, and 0.78 for those over 65.\n\nThe \"First World\" G7 members all have a sex ratio in the range of 0.95–0.98 for the total population, of 1.05–1.07 at birth, of 1.05–1.06 for the group below 15, of 1.00–1.04 for the group aged 15–64, and of 0.70–0.75 for those over 65.\n\nCountries on the Arabian Peninsula tend to have a 'natural' ratio of about 1.05 at birth but a very high ratio of males for those over 65 (Saudi Arabia 1.13, United Arab Emirates 2.73, Qatar 2.84), indicating either an above-average mortality rate for females or a below-average mortality for males, or, more likely in this case, a large population of aging male guest workers. Conversely, countries of Eastern Europe (the Baltic states, Belarus, Ukraine, Russia) tend to have a 'normal' ratio at birth but a very low ratio of males among those over 65 (Russia 0.46, Latvia 0.48, Ukraine 0.52); similarly, Armenia has a far above average male ratio at birth (1.17), and a below-average male ratio above 65 (0.67). This effect may be caused by emigration and higher male mortality as result of higher post-Soviet era deaths; it may also be related to the enormous (by western standards) rate of alcoholism in the former Soviet states. Another possible contributory factor is an aging population, with a higher than normal proportion of relatively elderly people: we recall that due to higher differential mortality rates the ratio of males to females reduces for each year of age.\n\nThere is an inverse correlation between income and fertility, wherein developed countries usually have a much lower fertility rate. Various fertility factors may be involved, such as education and urbanization. Mortality rates are low, birth control is understood and easily accessible, and costs are often deemed very high because of education, clothing, feeding, and social amenities. With wealth, contraception becomes affordable. However, in countries like Iran where contraception was made artificially affordable before the economy accelerated, birth rate also rapidly declined. Further, longer periods of time spent getting higher education often mean women have children later in life. Female labor participation rate also has substantial negative impact on fertility. However, this effect is neutralized among Nordic or liberalist countries.\n\nIn undeveloped countries on the other hand, families desire children for their labour and as caregivers for their parents in old age. Fertility rates are also higher due to the lack of access to contraceptives, generally lower levels of female education, and lower rates of female employment in industry.\n\n8.7% (2010 est.)\n8.2% (2009 est.)\nnote: 30% combined unemployment and underemployment in many non-industrialized countries; developed countries typically 4%-12% unemployment (2007 est.)\n\nThe demonym for Earth's inhabitants is Earthling or, as either a noun or an adjective, Terran.\n\nWorldwide, English is used widely as a lingua franca and can be seen to be the dominant language at this time. The world's largest language by native speakers is Mandarin Chinese which is a first language of around 960 million people, or 12.44% of the population, predominantly in Greater China. Spanish is spoken by around 330 to 400 million people, predominantly in the Americas and Spain. Arabic is spoken by around 280 million people. Hindi is spoken by about 200 million speakers, mostly in India. Bengali is spoken by around 230 million people, predominantly in India and Bangladesh. Portuguese is spoken by about 230 million speakers in Portugal, Brazil, East Timor, and Southern Africa.\n\nThere are numerous other languages, grouped into nine major families:\n\n\nThere are also hundreds of non-verbal sign languages.\n\nTotal population: 83.7% over the age of 15 can read and write, 88.3% male and 79.2% female \nnote: over two-thirds of the world's 793 million illiterate adults are found in only eight countries (Bangladesh, China, Egypt, Ethiopia, India, Indonesia, Nigeria, and Pakistan); of all the illiterate adults in the world, two-thirds are women; extremely low literacy rates are concentrated in three regions, the Arab states, South and West Asia, and Sub-Saharan Africa, where around one-third of the men and half of all women are illiterate (2005-09 est.) \n\nAs of 2008, the school life expectancy (primary to tertiary education) for a man or woman is 11 years. \n"}
{"id": "1291656", "url": "https://en.wikipedia.org/wiki?curid=1291656", "title": "Early modern period", "text": "Early modern period\n\nThe early modern period of modern history follows the late Middle Ages of the post-classical era. Although the chronological limits of the period are open to debate, the timeframe spans the period after the late portion of the post-classical age (c. 1500), known as the Middle Ages, through the beginning of the Age of Revolutions (c. 1800) and is variously demarcated by historians as beginning with the Fall of Constantinople in 1453, with the Renaissance period, and with the Age of Discovery (especially with the voyages of Christopher Columbus beginning in 1492, but also with Vasco da Gama's discovery of the sea route to the East in 1498), and ending around the French Revolution in 1789.\n\nHistorians in recent decades have argued that from a worldwide standpoint, the most important feature of the early modern period was its globalizing character. The period witnessed the exploration and colonization of the Americas and the rise of sustained contacts between previously isolated parts of the globe. The historical powers became involved in global trade, as the exchange of goods, plants, animals, and food crops extended to the Old World and the New World. The Columbian Exchange greatly affected the human environment.\n\nNew economies and institutions emerged, becoming more sophisticated and globally articulated over the course of the early modern period. This process began in the medieval North Italian city-states, particularly Genoa, Venice, and Milan. The early modern period also included the rise of the dominance of the economic theory of mercantilism. The European colonization of the Americas, Asia, and Africa occurred during the 15th to 19th centuries, and spread Christianity around the world.\n\nThe early modern trends in various regions of the world represented a shift away from medieval modes of organization, politically and economically. Feudalism declined in Europe, while the period also included the Protestant Reformation, the disastrous Thirty Years' War, the Commercial Revolution, the European colonization of the Americas, and the Golden Age of Piracy.\n\nBy the 16th century the economy under the Ming Dynasty was stimulated by trade with the Portuguese, the Spanish, and the Dutch, while Japan engaged in the Nanban trade after the arrival of the first European Portuguese during the Azuchi-Momoyama period.\n\nOther notable trends of the early modern period include the development of experimental science, accelerated travel due to improvements in mapping and ship design, increasingly rapid technological progress, secularized civic politics, and the emergence of nation states. Historians typically date the end of the early modern period when the French Revolution of the 1790s began the \"late modern\" period.\n\nAround the beginning of the Ming dynasty (1368—1644), China was leading the world in mathematics as well as science. However, Europe soon caught up to China's scientific and mathematical achievements and surpassed them. The reason behind China's lag in advancement has speculated by many scholars. A historian named Colin Ronan claims that though there is no one specific answer, there must be a connection between China's urgency for new discoveries being weaker than Europe's and China's inability to capitalize on its early advantages. Ronan believes that China's Confucian bureaucracy and traditions led to China not having a scientific revolution, which led China to have fewer scientists who would break the existing orthodoxies, like Galileo Galilei. Despite inventing gunpowder in the 9th century, it was in Europe that the classic handheld firearms, matchlocks, were invented, with evidence of use around the 1480s. China was using the matchlocks by 1540, after the Portuguese brought their matchlocks to Japan in the early 1500s. China during the Ming Dynasty established a bureau to maintain its calendar. The bureau was necessary because the calendars were linked to celestial phenomena and that needs regular maintenance because twelve lunar months have 344 or 355 days, so occasional leap months have to be added in order to maintain 365 days per year.\n\nIn the 16th century the Ming dynasty flourished over maritime trade with the Portuguese, Spanish and Dutch Empires. The trade brought in a massive amount of silver, which China at the time needed desperately. Prior to China's global trade, its economy ran on a paper money. However, in the 14th century, China's paper money system suffered a crisis, and by the mid-15th century, crashed. The silver imports helped fill the void left by the broken paper money system, which helps explain why the value of silver in China was twice as high as the value of silver in Spain during the end of the 16th century.\n\nThe Ming Dynasty suffered an economic collapse in the seventeenth-century because of heavy inflation of silver, and the European trade depression of the 1620s. The economy sunk to the point where all of China's trading partner cut ties with them: Philip IV restricted shipments of exports from Acapulco, the Japanese cut off all trade with Macau, and the Dutch severed connections between Gao and Macau.\n\nThe damage to the economy was compounded by the effects on agriculture of the incipient Little Ice Age, natural calamities, crop failure and sudden epidemics. The ensuing breakdown of authority and people's livelihoods allowed rebel leaders, such as Li Zicheng, to challenge Ming authority.\n\nThe Ming Dynasty fell around 1644 to the Qing Dynasty, the last ruling dynasty of China, ruling from 1644 to 1912 (with a brief, abortive restoration in 1917). During its reign, the Qing Dynasty became highly integrated with Chinese culture.\n\nFollowing contact with the Portuguese on Tanegashima Isle in 1543, the Japanese adopted several of the technologies and cultural practices of their visitors, whether in the military area (the arquebus, European-style cuirasses, European ships), religion (Christianity), decorative art, language (integration to Japanese of a Western vocabulary) and culinary: the Portuguese introduced tempura and valuable refined sugar.\n\nThe Azuchi–Momoyama period saw the political unification that preceded the establishment of the Tokugawa shogunate. Although a start date of 1573 is often given, in more broad terms, the period begins with Oda Nobunaga's entry into Kyoto in 1568, when he led his army to the imperial capital in order to install Ashikaga Yoshiaki as the 15th, and ultimately final, shōgun of the Ashikaga shogunate, and it lasts until the coming to power of Tokugawa Ieyasu after his victory over supporters of the Toyotomi clan at the Battle of Sekigahara in 1600.\n\nThe Edo period from 1600 to 1868 characterized early modern Japan. The Tokugawa shogunate was a feudalist regime of Japan established by Tokugawa Ieyasu and ruled by the \"shōguns\" of the Tokugawa clan. The period gets its name from the capital city, Edo, now called Tokyo. The Tokugawa shogunate ruled from Edo Castle from 1603 until 1868, when it was abolished during the Meiji Restoration in the late Edo period (often called the Late Tokugawa shogunate).\n\nIn 1392, General Yi Seong-gye established the Joseon dynasty (1392–1910) with a largely bloodless coup. Yi Seong-gye moved the capital of Korea to the location of modern-day Seoul. The dynasty was heavily influenced by Confucianism, which also played a large role to shaping Korea's strong cultural identity. King Sejong the Great (1418–1450), one of the only two kings in Korea's history to earn the title of great in their posthumous titles, reclaimed Korean territory to the north and created the Korean alphabet, Hangeul.\n\nDuring the end of the 16th century, Korea was invaded twice by Japan, first in 1592 and again in 1597. Japan failed both times due to Admiral Yi Sun-sin, Korea's revered naval genius, who lead the Korean Navy using advanced metal clad ships called turtle ships. Because the ships were armed with cannons, Admiral Yi's navy was able to demolish the Japanese invading fleets, destroying hundreds of ships in Japan's second invasion. During the 17th century, Korea was invaded again, this time by the Manchurian, who would later take over China as the Qing Dynasty. In 1637, King Injo was forced to surrender to the Qing forces, and was ordered to send princesses as concubine to the Qing Prince Dorgon.\n\nAfter invasions from Manchuria, Joseon experienced nearly 200 years of peace. However, whatever power the kingdom recovered during its isolation further waned as the 18th century came to a close, and Korea was faced with internal strife, power struggles, international pressure and rebellions at home. The Joseon dynasty declined rapidly in the late 19th century.\n\nOn the Indian subcontinent, the Lodi dynasty ruled over the Delhi Sultanate during its last phase. The dynasty founded by Bahlul Lodi ruled from 1451 to 1526. The dynasty's last ruler, Ibrahim Lodhi, was defeated and killed by Babur in the first Battle of Panipat.\n\nThe Vijayanagara Empire was based in the Deccan Plateau, but its power was diminished after a major military defeat in 1565 by the Deccan sultanates. The empire is named after its capital city of Vijayanagara.\n\nThe rise of the Great Mughal Empire is usually dated from 1526, around the end of the Middle Ages. It was an Islamic Persianate imperial power that ruled most of the area as Hindustan by the late 17th and the early 18th centuries. The empire dominated South and Southwestern Asia.\n\nAt the start of the modern era, the Spice Route between India and China crossed Majapahit, an archipelagic empire based on the island of Java. It was the last of the major Hindu empires of Maritime Southeast Asia and is considered one of the greatest states in Indonesian history. Its influence extended to states in Sumatra, the Malay Peninsula, Borneo and eastern Indonesia, but the effectiveness of the influence is the subject of debate. Majapahit found itself unable to control the rising power of the Sultanate of Malacca, which grew to stretch from Muslim Malay settlements of Bukit (Phuket), Setol (Satun), Pantai ni (Pattani) bordering Ayutthaya Kingdom of Siam (Thailand) in the north to Sumatra in the southwest. The Portuguese invaded its capital in 1511 and in 1528 the Sultanate of Johor was established by a Malaccan prince to succeed Malacca.\n\nDuring the early modern era, the Ottoman state enjoyed an expansion and consolidation of power, leading to a \"Pax Ottomana\". This was perhaps the golden age of the Ottoman Empire. The Ottomans expanded southwest into North Africa while battling with the re-emergent Persian Shi'a Safavid Empire to the east.\n\nIn the Saracen sphere, the Ottomans seized Egypt in 1517 and established the regencies of Algeria, Tunisia, and Tripoli (between 1519 and 1551), Morocco remaining an independent Arabized Berber state under the Sharifan dynasty.\n\nIn the Ethiopian Highlands, the Solomonic dynasty established itself in the 13th century. Claiming direct descent from the old Axumite royal house, the Solomonic ruled the region well into modern history. In the 16th century, Shewa and the rest of Abyssinia were conquered by the forces of Ahmed Gurey of the Adal Sultanate to the northwest. The conquest of the area by the Oromo ended in the contraction of both Adal and Abyssinia, changing regional dynamics for centuries to come.\n\nThe Ajuran Empire, which was one of the largest and strongest empires in the Horn of Africa, began to decline in the 17th century, and several powerful successor states came to prominence. The Geledi Sultanate, established by Ibrahim Adeer, was a notable successor of the Ajuran Sultanate. The Sultanate reached its apex under the successive reigns of Sultan Yusuf Mahamud Ibrahim (reigned 1798 to 1848), who successfully consolidated Geledi power during the Bardera wars, and Sultan Ahmed Yusuf, who forced regional powers such as the Omani Empire to pay tribute. The Majeerteen Sultanate was a Somali Sultanate in the Horn of Africa. Ruled by King Osman Mahamuud during its golden age, it controlled much of northern and central Somalia in the 19th and early 20th centuries. The polity had all of the organs of an integrated modern state and maintained a robust trading network. Along with the Sultanate of Hobyo ruled by Sultan Yusuf Ali Kenadid, the Majeerteen Sultanate was eventually annexed into Italian Somaliland in the early 20th century, following the military Campaign of the Sultanates.\n\nThe Songhai Empire took control of the trans-Saharan trade at the beginning of the modern era. It seized Timbuktu in 1468 and Jenne in 1473, building the regime on trade revenues and the cooperation of Muslim merchants. The empire eventually made Islam the official religion, built mosques, and brought Muslim scholars to Gao.\n\nAround the beginning of the modern era, the Benin Kingdom was an independent trading power in the southeastern coastline of West Africa, blocking the access of other inland nations to the coastal ports. Benin may have housed 100,000 inhabitants at its height, spreading over twenty-five square kilometres, enclosed by three concentric rings of earthworks. By the late 15th century Benin was in contact with Portugal. At its apogee in the 16th and 17th centuries, Benin encompassed parts of southeastern Yorubaland and the western Igbo.\n\nThe Safavid Empire was a great Shia Persianate empire after the Islamic conquest of Persia and established of Islam, marking an important point in the history of Islam in the east. The Safavid dynasty was founded about 1501. From their base in Ardabil, the Safavids established control over all of Persia and reasserted the Iranian identity of the region, thus becoming the first native dynasty since the Sassanids to establish a unified Iranian state. Problematic for the Safavids was the powerful Ottoman Empire. The Ottomans, a Sunni dynasty, fought several campaigns against the Safavids.\n\nWhat fueled the growth of Safavid economy was its position between the burgeoning civilizations of Europe to its west and Islamic Central Asia to its east and north. The Silk Road, which led from Europe to East Asia, revived in the 16th century. Leaders also supported direct sea trade with Europe, particularly England and The Netherlands, which sought Persian carpet, silk, and textiles. Other exports were horses, goat hair, pearls, and an inedible bitter almond hadam-talka used as a spice in India. The main imports were spice, textiles (woolens from Europe, cotton from Gujarat), metals, coffee, and sugar. Despite their demise in 1722, the Safavids left their mark by establishing and spreading Shi'a Islam in major parts of the Caucasus and West Asia.\n\nIn the 16th to early 18th centuries, Central Asia was under the rule of Uzbeks, and the far eastern portions were ruled by the local Pashtuns. Between the 15th and 16th centuries, various nomadic tribes arrived from the steppes, including the Kipchaks, Naymans, Kanglis, Khongirad, and Manguds. These groups were led by Muhammad Shaybani, who was the Khan of the Uzbeks.\n\nThe lineage of the Afghan Pashtuns stretches back to the Hotaki dynasty. Following Muslim Arab and Turkic conquests, Pashtun \"ghazis\" (warriors for the faith) invaded and conquered much of northern India during the Lodhi dynasty and Suri dynasty. Pashtun forces also invaded Persia, and the opposing forces were defeated in the Battle of Gulnabad. The Pashtuns later formed the Durrani Empire.\n\nThis era in Western Europe is referred to as the early modern European period and includes the Protestant Reformation, the European wars of religion, the Age of Discovery and the beginning of European colonialism, the rise of strong centralized governments, the beginnings of recognizable nation-states that are the direct antecedents of today's states, the Age of Enlightenment, and from the associated scientific advances the first phase of the Industrial Revolution. The emergence of cultural and political dominance of the Western world during this period is known as the Great Divergence.\n\nThe early modern period is taken to end with the French Revolution, the Napoleonic Wars, and the dissolution of the Holy Roman Empire at the Congress of Vienna.\nAt the end of the early modern period, the British and Russian empires had emerged as world powers from the multipolar contest of colonial empires, while the three great Asian empires of the early modern period, Ottoman Turkey, Mughal India and Qing China, all entered a period of stagnation or decline.\n\nThe expression \"early modern\" is at times incorrectly used as a substitute for the term Renaissance. However, \"Renaissance\" is properly used in relation to a diverse series of cultural developments that occurred over several hundred years in many different parts of Europe — especially central and northern Italy — and it spans the transition from late medieval civilization to the opening of the early modern period. In the visual arts and architecture, the term 'early modern' is not a common designation as the Renaissance period is clearly distinct from what came later. Only in the study of literature is the early modern period a standard designation. European music of the period is generally divided between Renaissance and Baroque. Similarly, philosophy is divided between Renaissance philosophy and the Enlightenment. In other fields, there is far more continuity through the period such as warfare and science.\n\nWhen gunpowder was introduced to Europe, it was immediately used almost exclusively in weapons and explosives for warfare. Though it was invented in China, gunpowder arrived in Europe already formulated for military use and European countries took advantage of it and were the first to create the classic firearms. The advances made in gunpowder and firearms was directly tied to the decline in the use of plate armor because of the inability of the armor to protect one from bullets.\n\nIn the early modern period, the Holy Roman Empire was a union of territories in Central Europe under a Holy Roman Emperor the first of which was Otto I. The last was Francis II, who abdicated and dissolved the Empire in 1806 during the Napoleonic Wars. Despite its name, for much of its history the Empire did not include Rome within its borders.\n\nThe Renaissance was a cultural movement that spanned roughly the 14th to the 17th century, beginning in Italy in the Late Middle Ages and later spreading to the rest of Europe. The term is also used more loosely to refer to the historic era, but since the changes of the Renaissance were not uniform across Europe, this is a general use of the term. As a cultural movement, it encompassed a rebellion of learning based on classical sources, the development of linear perspective in painting, and gradual but widespread educational reform.\n\nJohannes Gutenberg is credited as the first European to use movable type printing, around 1439, and as the global inventor of the mechanical printing press. Nicolaus Copernicus formulated a comprehensive heliocentric cosmology (1543), which displaced the Earth from the center of the universe. His book, \"De revolutionibus orbium coelestium\" (\"On the Revolutions of the Celestial Spheres\") began modern astronomy and sparked the Scientific Revolution. Another notable individual was Machiavelli, an Italian political philosopher, considered a founder of modern political science. Machiavelli is most famous for a short political treatise, The Prince, a work of realist political theory.\n\nAmong the notable royalty of the time, Charles the Bold, known as \"Charles the Bold (or Rash)\" to his enemies, he was the last Valois Duke of Burgundy, and his early death was a pivotal, if under-recognized, moment in European history. Charles has often been regarded as the last representative of the feudal spirit — a man who possessed no other quality than a blind bravery. Upon his death, Charles left an unmarried nineteen-year-old daughter, Mary of Burgundy, as his heir. Her marriage would have enormous implications for the political balance of Europe. The Habsburg Emperor secured the match for his son, the future Maximilian I, Holy Roman Emperor, with the aid of Mary's stepmother, Margaret. In 1477, the territory of the Duchy of Burgundy was annexed by France. In the same year, Mary married Maximilian, Archduke of Austria, giving the Habsburgs control of the remainder of the Burgundian Inheritance.\n\nClaude de Lorraine was the first Duke of Guise, from 1528 to his death. Claude distinguished himself at the battle of Marignano (1515), and was long in recovering from the twenty-two wounds he received in the battle. In 1521, he fought at Fuenterrabia, and Louise of Savoy ascribed the capture of the place to his efforts. In 1523 he became governor of Champagne and Burgundy, after defeating at Neufchâteau the imperial troops who had invaded this province. In 1525 he destroyed the Anabaptist peasant army, which was overrunning Lorraine, at Lupstein, near Saverne (Zabern). On the return of Francis I from captivity in 1528, Claude was made Duke of Guise in the peerage of France, though up to this time only princes of the royal house had held the title of duke and peer of France. The Guises, as cadets of the sovereign house of Lorraine and descendants of the house of Anjou, claimed precedence of the Bourbon princes of Condé and Conti.\n\nThe 3rd Duke of Alba was a nobleman of importance in the early modern period, nicknamed the \"Iron Duke\" by the Protestants of the Low Countries because of his harsh rule and cruelty. Tales of atrocities committed during his military operations in Flanders became part of Dutch and English folklore, forming a central component of the Black Legend.\n\nIn England, Henry VIII was the King of England and a significant figure in the history of the English monarchy. Although in the greater part of his reign he brutally suppressed the influence of the Protestant Reformation in England, a movement having some roots with John Wycliffe in the 14th century, he is more popularly known for his political struggles with Rome. These struggles ultimately led to the separation of the Church of England from papal authority, the Dissolution of the Monasteries, and establishing himself as the Supreme Head of the Church of England. Though Henry reportedly became a Protestant on his death-bed, he advocated Catholic ceremony and doctrine throughout his life. Royal support for the English Reformation began with his heirs, the devout Edward VI and the renowned Elizabeth I, whilst daughter Mary I temporarily reinstated papal authority over England. Henry also oversaw the legal union of England and Wales with the Laws in Wales Acts 1535–1542. He is also noted for his six wives, two of whom were beheaded.\n\nChristianity was challenged at the beginning of the modern period with the fall of Constantinople in 1453 and later by various movements to reform the church (including Lutheran, Zwinglian, and Calvinist), followed by the Counter Reformation.\n\nThe Hussite Crusades involved the military actions against and amongst the followers of Jan Hus in Bohemia ending ultimately with the Battle of Grotniki. Also known as the Hussite Wars, they were arguably the first European war in which hand-held gunpowder weapons such as muskets made a decisive contribution. The Taborite faction of the Hussite warriors were basically infantry, and their many defeats of larger armies with heavily armored knights helped effect the infantry revolution. In totality, the Hussite Crusades were inconclusive.\n\nThe last crusade, the \"Crusade of 1456\", was organized to counter the expanding Ottoman Empire and lift the Siege of Belgrade, and was led by John Hunyadi and Giovanni da Capistrano. The siege eventually escalated into a major battle, during which Hunyadi led a sudden counterattack that overran the Turkish camp, ultimately compelling the wounded Sultan Mehmet II to lift the siege and retreat. The siege of Belgrade has been characterized as having \"decided the fate of Christendom\". The noon bell ordered by Pope Callixtus III commemorates the victory throughout the Christian world to this day.\n\nNearly a hundred years later, the Peace of Augsburg officially ended the idea that all Christians could be united under one church. The principle of \"cuius regio, eius religio\" (\"whose the region is, [it shall have] his religion\") established the religious, political and geographic divisions of Christianity, and this was established in international law with the Treaty of Westphalia in 1648, which legally ended the concept of a single Christian hegemony, i.e. the \"One, Holy, Catholic, and Apostolic Church\" of the Nicene Creed. Each government determined the religion of their own state. Christians living in states where their denomination was \"not\" the established church were guaranteed the right to practice their faith in public during allotted hours and in private at their will. With the Treaty of Westphalia, the Wars of Religion came to an end, and in the Treaty of Utrecht of 1713 the concept of the sovereign national state was born. The \"Corpus Christianum\" has since existed with the modern idea of a tolerant and diverse society consisting of many different communities.\n\nThe modern Inquisition refers to any one of several institutions charged with trying and convicting heretics (or other offenders against canon law) within the Catholic Church. In the modern era, the first manifestation was the Spanish Inquisition of 1478 to 1834. The Inquisition prosecuted individuals accused of a wide array of crimes related to heresy, including sorcery, blasphemy, Judaizing and witchcraft, as well for censorship of printed literature. Because of its objective — combating heresy — the Inquisition had jurisdiction only over baptized members of the Church (which, however, encompassed the vast majority of the population in Catholic countries). Secular courts could still try non-Christians for blasphemy (most of the witch trials went through secular courts).\n\nThe Protestant Reformation and rise of modernity in the early 16th century entailed the start of a series of changes in the \"Corpus Christianum\". Martin Luther challenged the Catholic Church with his Ninety-Five Theses, generally accepted as the beginning of the Reformation, a Christian reform movement in Europe, though precursors such as Jan Hus predate him. The Protestant movement of the 16th century occurred under the protection of the Electorate of Saxony, an independent hereditary electorate of the Holy Roman Empire. The Elector Frederick III established a university at Wittenberg in 1502. The Augustinian monk Martin Luther became professor of philosophy there in 1508. At the same time, he became one of the preachers at the castle church of Wittenberg.\n\nOn 31 October 1517, Luther posted his \"Ninety-Five Theses\" on the door of the All Saints' Church, which served as a notice board for university-related announcements. These were points for debate that criticized the Church and the Pope. The most controversial points centered on the practice of selling indulgences (especially by Johann Tetzel) and the Church's policy on purgatory. The reform movement soon split along certain doctrinal lines. Religious disagreements between various leading figures led to the emergence of rival Protestant churches. The most important denominations to emerge directly from the Reformation were the Lutherans, and the Reformed/Calvinists/Presbyterians. The process of reform had decidedly different causes and effects in other countries. In England, where it gave rise to Anglicanism, the period became known as the English Reformation. Subsequent Protestant denominations generally trace their roots back to the initial reforming movements.\n\nThe Diet of Worms in 1521, presided by Emperor Charles V, declared Martin Luther a heretic and an outlaw (although Charles V was more preoccupied with maintaining his vast empire than with arresting Luther). As a result of Charles V's distractions in East Europe and in Spain, he agreed through the Diet of Speyer in 1526 to allow German princes to effectively decide themselves whether to enforce the Edict of Worms or not, for the time being. After returning to the empire, Charles V attended the Diet of Augsburg in 1530 to order all Protestants in the empire to revert to Catholicism. In response, the Protestant territories in and around Germany formed the Schmalkaldic League to fight against the Catholic Holy Roman Empire. Charles V left again to handle the advance of the Ottoman Turks. He returned in 1547 to launch a military campaign against the Schmalkaldic League and to issue an imperial law requiring all Protestants to return to Catholic practices (with a few superficial concessions to Protestant practices). Warfare ended when Charles V relented in the Peace of Passau (1552) and in the Peace of Augsburg (1555), which formalized the law that the rulers of a land decide its religion.\n\nOf the late Inquisitions in the modern era, there were two different manifestations:\nThis Portuguese inquisition was a local analogue of the more famous Spanish Inquisition. The Roman Inquisition covered most of the Italian peninsula as well as Malta and also existed in isolated pockets of papal jurisdiction in other parts of Europe, including Avignon.\n\nThe Catholic Reformation began in 1545 when the Council of Trent was called in reaction to the \"Protestant Rebellion\". The idea was to reform the state of worldliness and disarray that had befallen some of the clergy of the Church, while reaffirming the spiritual authority of the Catholic Church and its position as the sole true Church of Christ on Earth. The effort sought to prevent further damage to the Church and her faithful at the hands of the newly formed Protestant denominations.\n\nIn development of the Third Rome ideas, the Grand Duke Ivan IV (the \"Awesome\" or \"the Terrible\") was officially crowned the first Tsar (\"Caesar\") of Russia in 1547. The Tsar promulgated a new code of laws (Sudebnik of 1550), established the first Russian feudal representative body (Zemsky Sobor) and introduced local self-management into the rural regions. During his long reign, Ivan IV nearly doubled the already large Russian territory by annexing the three Tatar khanates (parts of disintegrated Golden Horde): Kazan and Astrakhan along the Volga River, and Sibirean Khanate in South Western Siberia. Thus by the end of the 16th century Russia was transformed into a multiethnic, multiconfessional and transcontinental state.\n\nThe Age of Discovery was a period from the early 15th century and continuing into the early 17th century, during which European ships traveled around the world to search for new trading routes and partners to feed burgeoning capitalism in Europe. They also were in search of trading goods such as gold, silver and spices. In the process, Europeans encountered peoples and mapped lands previously unknown to them. This factor in the early European modern period was a globalizing character; the 'discovery' of the Americas and the rise of sustained contacts between previously isolated parts of the globe was an important historical event.\n\nThe search for new routes was based on the fact that the Silk Road was controlled by the Ottoman Empire, which was an impediment to European commercial interests, and other Eastern trade routes were not available to the Europeans due to Muslim control. The ability to outflank the Muslim states of North Africa was seen as crucial to European survival. At the same time, the Iberians learnt much from their Arab neighbors. The northwestern region of Eurasia has a very long coastline, and has arguably been more influenced by its \"maritime history\" than any other continent. Europe is uniquely situated between several navigable seas, and intersected by navigable rivers running into them in a way that greatly facilitated the influence of maritime traffic and commerce. In the maritime history of Europe, the carrack and caravel both incorporated the lateen sail that made ships far more maneuverable. By translating the Arab versions of lost ancient Greek geographical works into Latin, European navigators acquired a deeper knowledge of the shape of Africa and Asia.\n\nMercantilism was the dominant school of economic thought throughout the early modern period (from the 16th to the 18th century). This led to some of the first instances of significant government intervention and control over the economy, and it was during this period that much of the modern capitalist system was established. Internationally, mercantilism encouraged the many European wars of the period and fueled European imperialism. Belief in mercantilism began to fade in the late 18th century, as the arguments of Adam Smith and the other classical economists won out.\n\nThe Commercial Revolution was a period of economic expansion, colonialism, and mercantilism that lasted from approximately the 16th century until the early 18th century. Beginning with the Crusades, Europeans rediscovered spices, silks, and other commodities rare in Europe. This development created a new desire for trade, which expanded in the second half of the Middle Ages. European nations, through voyages of discovery, were looking for new trade routes in the fifteenth and sixteenth centuries, which allowed the European powers to build vast, new international trade networks. Nations also sought new sources of wealth. To deal with this new-found wealth, new economic theories and practices were created. Because of competing national interest, nations had the desire for increased world power through their colonial empires. The Commercial Revolution is marked by an increase in general commerce, and in the growth of non-manufacturing pursuits, such as banking, insurance, and investing.\n\nIn the Old World, the most desired trading goods were gold, silver, and spices. Western Europeans used the compass, new sailing ship technologies, new maps, and advances in astronomy to seek a viable trade route to Asia for valuable spices that Mediterranean powers could not contest.\n\nIn terms of shipping advances, the most important developments were the creation of the carrack and caravel designs in Portugal. These vessels evolved from medieval European designs from the North Sea and both the Christian and Islamic Mediterranean. They were the first ships that could leave the relatively placid and calm Mediterranean, Baltic or North Sea and sail safely on the open Atlantic.\n\nWhen the carrack and then the caravel were developed in Iberia, European thoughts returned to the fabled East. These explorations have a number of causes. Monetarists believe the main reason the Age of Exploration began was because of a severe shortage of bullion in Europe. The European economy was dependent on gold and silver currency, but low domestic supplies had plunged much of Europe into a recession. Another factor was the centuries-long conflict between the Iberians and the Muslims to the south.\n\nThe Golden Age of Piracy is a designation given to one or more outbursts of piracy in the early modern period, spanning from the mid-17th century to the mid-18th century. The buccaneering period covers approximately the late 17th century. The period is characterized by Anglo-French seamen based on Jamaica and Tortuga attacking Spanish colonies and shipping in the Caribbean and eastern Pacific. A sailing route known as the Pirate Round was followed by certain Anglo-American pirates at the turn of the 18th century, associated with long-distance voyages from Bermuda and the Americas to rob Muslim and East India Company targets in the Indian Ocean and Red Sea. The post-Spanish Succession period extending into the early 18th century, when Anglo-American sailors and privateers left unemployed by the end of the War of the Spanish Succession turned en masse to piracy in the Caribbean, the American eastern seaboard, the West African coast, and the Indian Ocean.\n\nThe 15th to 18th century period is marked by the first European colonies, the rise of strong centralized governments, and the beginnings of recognizable European nation states that are the direct antecedents of today's states. Although the Renaissance included revolutions in many intellectual pursuits, as well as social and political upheaval, it is perhaps best known for European artistic developments and the contributions of such polymaths as Leonardo da Vinci and Michelangelo, who inspired the term \"Renaissance man\".\n\nDuring the Baroque period the Thirty Years' War in Central Europe decimated the population by up to 20%. In 1648, the Peace of Westphalia, consisting of the treaties of Osnabrück and Münster, signed on May 15 and October 24, respectively, ended several wars in Europe and established the beginning of sovereign states. The treaties involved the Holy Roman Emperor, Ferdinand III (Habsburg), the Kingdoms of Spain, France and Sweden, the Netherlands and their respective allies among the princes and the Republican Imperial States of the Holy Roman Empire.\n\nThe Peace of Westphalia resulted from the first modern diplomatic congress. Until 1806, the regulations became part of the constitutional laws of the Holy Roman Empire. The Treaty of the Pyrenees, signed in 1659, ended the war between France and Spain and is often considered part of the overall accord.\n\nThe Age of Absolutism describes the monarchical power that was unrestrained by any other institutions, such as churches, legislatures, or social elites of the European monarchs during the transition from feudalism to capitalism. Monarchs described as absolute can especially be found in the 17th century through the 19th century. Nations that adopted Absolutism include France, Prussia, and Russia. Nobles tended to trade privileges for allegiance throughout the eighteenth century, so that the interests of the nobility aligned with that of the crown. Absolutism is characterized by the ending of feudal partitioning, consolidation of power with the monarch, rise of state power, unification of the state laws, drastic increase in tax revenue collected by the monarch, and a decrease in the influence of nobility.\n\nFor much of the reign of Louis XIV, who was known as the \"Sun King\" (French: \"le Roi Soleil\"), France stood as the leading power in Europe, engaging in three major wars—the Franco-Dutch War, the War of the League of Augsburg, and the War of the Spanish Succession—and two minor conflicts—the War of Devolution, and the War of the Reunions. Louis believed in the Divine Right of Kings, the theory that the King was crowned by God and accountable to him alone. Consequently, he has long been considered the archetypal absolute monarch. Louis XIV continued the work of his predecessor to create a centralized state, governed from the capital to sweep away the remnants of feudalism that persisted in parts of France. He succeeded in breaking the power of the provincial nobility, much of which had risen in revolt during his minority called the Fronde, and forced many leading nobles to live with him in his lavish Palace of Versailles.\n\nMen who featured prominently in the political and military life of France during this period include Mazarin, Jean-Baptiste Colbert, Turenne, Vauban. French culture likewise flourished during this era, producing a number of figures of great renown, including Molière, Racine, Boileau, La Fontaine, Lully, Le Brun, Rigaud, Louis Le Vau, Jules Hardouin Mansart, Claude Perrault and Le Nôtre.\n\nBefore the Age of Revolution, the English Civil War was a series of armed conflicts and political machinations between Parliamentarians and Royalists. The first and second civil wars pitted the supporters of King Charles I against the supporters of the Long Parliament, while the third war saw fighting between supporters of King Charles II and supporters of the Rump Parliament. The Civil War ended with the Parliamentary victory at the Battle of Worcester. The monopoly of the Church of England on Christian worship in England ended with the victors consolidating the established Protestant Ascendancy in Ireland. Constitutionally, the wars established the precedent that an English monarch cannot govern without Parliament's consent. The English Restoration, or simply put as the Restoration, began in 1660 when the English, Scottish and Irish monarchies were all restored under Charles II after the Commonwealth of England that followed the English Civil War. The Glorious Revolution of 1688 establishes modern parliamentary democracy in England.\n\nThe War of the Spanish Succession was a war fought between 1701 and 1714, in which several European powers combined to stop a possible unification of the Kingdoms of Spain and France under a single Bourbon monarch, upsetting the European balance of power. It was fought mostly in Europe, but it included Queen Anne's War in North America. The war was marked by the military leadership of notable generals like the duc de Villars, the Jacobite Duke of Berwick, the Duke of Marlborough and Prince Eugene of Savoy.\n\nThe Peace of Utrecht established after a series of individual peace treaties signed in the Dutch city of Utrecht concluded between various European states helped end the War of the Spanish Succession. The representatives who met were Louis XIV of France and Philip V of Spain on the one hand, and representatives of Queen Anne of Great Britain, the Duke of Savoy, and the United Provinces on the other. The treaty enregistred the defeat of French ambitions expressed in the wars of Louis XIV and preserved the European system based on the balance of power. The Treaty of Utrecht marked the change from Spanish to British naval supremacy.\n\nThe term \"colonialism\" is normally used with reference to discontiguous overseas empires rather than contiguous land-based empires, European or otherwise. European colonisation during the 15th to 19th centuries resulted in the spread of Christianity to Sub-Saharan Africa, the Americas, Australia and the Philippines.\n\nChristopher Columbus discovered the Americas in 1492. Subsequently, the major sea powers in Europe sent expeditions to the New World to build trade networks and colonies and to convert the native peoples to Christianity. Pope Alexander VI divided newly discovered lands outside Europe between Spain and Portugal along a north-south meridian 370 leagues west of the Cape Verde islands (off the west coast of Africa). The division was never accepted by the rulers of England or France. (See also the Treaty of Tordesillas, which followed the papal decree.)\n\nWhat is now called Latin America, a designation first used in the late 19th century, was claimed by Spain and Portugal. The Western Hemisphere, the New World, was divided between the two Iberian powers by the Treaty of Tordesillas in what until the late 16th-century, was an area that could be called \"Ibero-America.\" Spain called its overseas empire there \"The Indies,\" with Portugal calling its territory in South America Brazil, after the dyewood found there. Spain concentrated building its empire where there were large indigenous populations, \"Indians,\" who could be compelled to work and large deposits of precious metals, mainly silver. Both New Spain (colonial Mexico) and Peru fit those criteria and the Spanish crown established viceroyalties to rule those two large areas. As Spanish settlements and the economy grew in size and complexity, the Spanish established viceroyalties in the eighteenth century during administrative reforms Rio de la Plata (southeastern South America) and New Granada (northern South America).\n\nInitially, Portuguese settlements (Brazil) in the coastal northeast were of lesser importance in the larger Portuguese overseas empire, where lucrative commerce and small settlements devoted to trade were established in coastal Africa, India and China. With sparse indigenous populations that could not be coerced to work and no known deposits of precious metals, Portugal sought a high-value, low-bulk export product and found it in sugarcane. Black African slave labour from Portugal's West African possessions was imported to do the grueling agricultural work. As the wealth of the Ibero-America increased, some Western European powers (Dutch, French, British, Danish) sought to duplicate the model in areas that the Iberians had not settled in numbers. They seized Caribbean islands from the Spanish and transferred the model of sugar production on plantations with slave labour and settled in northern areas of North America in what are now the Eastern Seaboard of the United States and Canada.\n\nNorth America outside the zone of Spanish settlement was a contested area in the 17th century. Spain had founded small settlements in Florida and Georgia but nowhere near the size of those in New Spain or the Caribbean islands. France, The Netherlands, and Great Britain held several colonies in North America and the West Indies from the 17th century, 100 years after the Spanish and Portuguese established permanent colonies. The British colonies in North America were founded between 1607 (Virginia) and 1733 (Georgia). The Dutch explored the east coast of North America and began founding settlements in what they called New Netherland (now New York State.). France colonized what is now Eastern Canada, founding Quebec City in 1608. France's loss in the Seven Years' War resulted in the transfer of New France to Great Britain. The Thirteen Colonies, in lower British North America, rebelled against British rule in 1775, largely due to the taxation that Great Britain was imposing on the colonies. The British colonies in Canada remained loyal to the crown, and a provisional government formed by the Thirteen Colonies proclaimed their independence on July 4, 1776 and subsequently became the original 13 United States of America. With the 1783 Treaty of Paris ending the American Revolutionary War, Britain recognised the former Thirteen Colonies' independence.\n\nA recent development in early modern history is the creation of Atlantic World as a category. The term generally encompasses western Europe, West Africa, North and South and America and the Caribbean islands. It seeks to show both local and regional development and the connections between the various geographical regions.\n\nConcerning the development of Eastern philosophies, much of Eastern philosophy had been in an advanced state of development from study in the previous centuries. The various philosophies include Indian philosophy, Chinese philosophy, Iranian philosophy, Japanese philosophy, and Korean philosophy.\n\nThe Islamic Golden Age reached its peak in the High Middle Ages, stopped short by the Mongol invasions of the 13th century. The re-establishment of three major Muslim empires by the 16th century (the aforementioned Ottoman Safavid and Mughal Empires) gave rise to a Muslim cultural revival. The Safavids established Twelver Shi'a Islam as Iran's official religion, thus giving Iran a separate identity from its Sunni neighbors.\n\nThe early modern period was initiated by the Protestant Reformation and the collapse of the unity of the medieval Western Church.\nThe theology of Calvinism in particular has been argued as instrumental to the rise of capitalism (\"The Protestant Ethic and the Spirit of Capitalism\").\n\nThe Counter-Reformation was a period of Catholic revival in response to the Protestant Reformation during the mid-16th to mid-17th centuries. The Counter-Reformation was a comprehensive effort, involving ecclesiastical or structural reforms as well as a political dimension and spiritual movements.\n\nSuch reforms included the foundation of seminaries for the proper training of priests in the spiritual life and the theological traditions of the Church, the reform of religious life by returning orders to their spiritual foundations and new spiritual movements focusing on the devotional life and a personal relationship with Christ, including the Spanish mystics and the French school of spirituality. It also involved political activities that included the Roman Inquisition.\n\nNew religious orders were a fundamental part of this trend. Orders such as the Capuchins, Ursulines, Theatines, Discalced Carmelites, the Barnabites, and especially the Jesuits strengthened rural parishes, improved popular piety, helped to curb corruption within the church and set examples that would be a strong impetus for Catholic renewal.\n\nWith the adoption of large-scale printing after 1500, Italian Renaissance Humanism spread northward to France, Germany, Holland and England, where it became associated with the Protestant Reformation. In France, pre-eminent Humanist Guillaume Budé (1467–1540) applied the philological methods of Italian Humanism to the study of antique coinage and to legal history, composing a detailed commentary on Justinian's Code. Although a royal absolutist (and not a republican like the early Italian \"umanisti\"), Budé was active in civic life, serving as a diplomat for Francis I and helping to found the Collège des Lecteurs Royaux (later the Collège de France). Meanwhile, Marguerite de Navarre, the sister of Francis I, herself a poet, novelist and religious mystic, gathered around her and protected a circle of vernacular poets and writers, including Clément Marot, Pierre de Ronsard and François Rabelais.\n\nThe philosophy of 17th-century Europe marks the departure from medieval scholasticism and the often occultist approach of Renaissance philosophy.\nThe period was typified in Europe by the great system-builders, philosophers who presented unified systems of epistemology, metaphysics, logic, and ethics and often politics and the physical sciences as well.\n\nImmanuel Kant classified his predecessors into two schools: the rationalists and the empiricists, The three main rationalists are normally taken to have been René Descartes, Baruch Spinoza, and Gottfried Leibniz.\n\nThe first great advances towards modern science were made in the mid-17th century, most notably the theory of gravity by Isaac Newton (1643–1727). Newton, Spinoza, John Locke (1632–1704) and Pierre Bayle (1647–1706) were philosophers sparking the Age of Enlightenment in the following century.\n\nThe Great Divergence is epitomized by the \"Age of Enlightenment\" (or \"Age of Reason\").\nThe Enlightenment, starting in the 1750s, flourished until about 1790–1800, after which the emphasis on reason gave way to Romanticism's emphasis on emotion and a Counter-Enlightenment gained force.\n\nThe centre of the Enlightenment was France, where it was based in the salons and culminated in the great \"Encyclopédie\" (1751–1772), edited by Denis Diderot (1713–1784) with contributions by hundreds of leading philosophes (intellectuals) such as Voltaire (1694–1778) and Montesquieu (1689–1755). The French Enlightenment was received in Germany, notably fostered by Frederick the Great, the king of Prussia, and gave rise to a flowering of German philosophy, represented foremost by Immanuel Kant.\n\nThe French and German developments were further influential in Scottish, Russian, Spanish and Polish philosophy.\n\nIn modern history, the end of the early period falls in the late 18th century, as an Age of Revolutions dawns, beginning with those in North America and France. Subsequent important political changes occurred throughout Europe, including upheavals following the Napoleonic Wars, the redrawing of the map of Europe through the Second Treaty of Paris, the rise of new concepts of nationalism and the reorganization in military forces. The end of the early modern period is usually also associated with the Industrial Revolution, which began in Britain in the mid-18th century.\n\n\n\n\n\n\n\n"}
{"id": "1765418", "url": "https://en.wikipedia.org/wiki?curid=1765418", "title": "Ecosystem ecology", "text": "Ecosystem ecology\n\nEcosystem ecology is the integrated study of living (biotic) and non-living (abiotic) components of ecosystems and their interactions within an ecosystem framework. This science examines how ecosystems work and relates this to their components such as chemicals, bedrock, soil, plants, and animals.\n\nEcosystem ecology examines physical and biological structures and examines how these ecosystem characteristics interact with each other. Ultimately, this helps us understand how to maintain high quality water and economically viable commodity production. A major focus of ecosystem ecology is on functional processes, ecological mechanisms that maintain the structure and services produced by ecosystems. These include primary productivity (production of biomass), decomposition, and trophic interactions.\n\nStudies of ecosystem function have greatly improved human understanding of sustainable production of forage, fiber, fuel, and provision of water. Functional processes are mediated by regional-to-local level climate, disturbance, and management. Thus ecosystem ecology provides a powerful framework for identifying ecological mechanisms that interact with global environmental problems, especially global warming and degradation of surface water.\n\nThis example demonstrates several important aspects of ecosystems:\n\nThese characteristics also introduce practical problems into natural resource management. Who will manage which ecosystem? Will timber cutting in the forest degrade recreational fishing in the stream? These questions are difficult for land managers to address while the boundary between ecosystems remains unclear; even though decisions in one ecosystem will affect the other. We need better understanding of the interactions and interdependencies of these ecosystems and the processes that maintain them before we can begin to address these questions.\n\nEcosystem ecology is an inherently interdisciplinary field of study. An individual ecosystem is composed of populations of organisms, interacting within communities, and contributing to the cycling of nutrients and the flow of energy. The ecosystem is the principal unit of study in ecosystem ecology.\n\nPopulation, community, and physiological ecology provide many of the underlying biological mechanisms influencing ecosystems and the processes they maintain. Flowing of energy and cycling of matter at the ecosystem level are often examined in ecosystem ecology, but, as a whole, this science is defined more by subject matter than by scale. Ecosystem ecology approaches organisms and abiotic pools of energy and nutrients as an integrated system which distinguishes it from associated sciences such as biogeochemistry.\n\nBiogeochemistry and hydrology focus on several fundamental ecosystem processes such as biologically mediated chemical cycling of nutrients and physical-biological cycling of water. Ecosystem ecology forms the mechanistic basis for regional or global processes encompassed by landscape-to-regional hydrology, global biogeochemistry, and earth system science.\n\nEcosystem ecology is philosophically and historically rooted in terrestrial ecology. The ecosystem concept has evolved rapidly during the last 100 years with important ideas developed by Frederic Clements, a botanist who argued for specific definitions of ecosystems and that physiological processes were responsible for their development and persistence. Although most of Clements ecosystem definitions have been greatly revised, initially by Henry Gleason and Arthur Tansley, and later by contemporary ecologists, the idea that physiological processes are fundamental to ecosystem structure and function remains central to ecology.\n\nIn this model, energy flows through the whole system were dependent on biotic and abiotic interactions of each individual component (species, inorganic pools of nutrients, etc.). Later work demonstrated that these interactions and flows applied to nutrient cycles, changed over the course of succession, and held powerful controls over ecosystem productivity. Transfers of energy and nutrients are innate to ecological systems regardless of whether they are aquatic or terrestrial. Thus, ecosystem ecology has emerged from important biological studies of plants, animals, terrestrial, aquatic, and marine ecosystems.\n\nEcosystem services are ecologically mediated functional processes essential to sustaining healthy human societies. Water provision and filtration, production of biomass in forestry, agriculture, and fisheries, and removal of greenhouse gases such as carbon dioxide (CO) from the atmosphere are examples of ecosystem services essential to public health and economic opportunity. Nutrient cycling is a process fundamental to agricultural and forest production.\n\nHowever, like most ecosystem processes, nutrient cycling is not an ecosystem characteristic which can be “dialed” to the most desirable level. Maximizing production in degraded systems is an overly simplistic solution to the complex problems of hunger and economic security. For instance, intensive fertilizer use in the midwestern United States has resulted in degraded fisheries in the Gulf of Mexico. Regrettably, a “Green Revolution” of intensive chemical fertilization has been recommended for agriculture in developed and developing countries. These strategies risk alteration of ecosystem processes that may be difficult to restore, especially when applied at broad scales without adequate assessment of impacts. Ecosystem processes may take many years to recover from significant disturbance.\n\nFor instance, large-scale forest clearance in the northeastern United States during the 18th and 19th centuries has altered soil texture, dominant vegetation, and nutrient cycling in ways that impact forest productivity in the present day. An appreciation of the importance of ecosystem function in maintenance of productivity, whether in agriculture or forestry, is needed in conjunction with plans for restoration of essential processes. Improved knowledge of ecosystem function will help to achieve long-term sustainability and stability in the poorest parts of the world.\n\nBiomass productivity is one of the most apparent and economically important ecosystem functions. Biomass accumulation begins at the cellular level via photosynthesis. Photosynthesis requires water and consequently global patterns of annual biomass production are correlated with annual precipitation. Amounts of productivity are also dependent on the overall capacity of plants to capture sunlight which is directly correlated with plant leaf area and N content.\n\nNet primary productivity (NPP) is the primary measure of biomass accumulation within an ecosystem. Net primary productivity can be calculated by a simple formula where the total amount of productivity is adjusted for total productivity losses through maintenance of biological processes:\n\nNPP is difficult to measure but a new technique known as eddy co-variance has shed light on how natural ecosystems influence the atmosphere. Figure 4 shows seasonal and annual changes in CO concentration measured at Mauna Loa, Hawaii from 1987 to 1990. CO concentration steadily increased, but within-year variation has been greater than the annual increase since measurements began in 1957.\n\nThese variations were thought to be due to seasonal uptake of CO during summer months. A newly developed technique for assessing ecosystem NPP has confirmed seasonal variation are driven by seasonal changes in CO uptake by vegetation. This has led many scientists and policy makers to speculate that ecosystems can be managed to ameliorate problems with global warming. This type of management may include reforesting or altering forest harvest schedules for many parts of the world.\n\nDecomposition and nutrient cycling are fundamental to ecosystem biomass production. Most natural ecosystems are nitrogen (N) limited and biomass production is closely correlated with N turnover.\nTypically external input of nutrients is very low and efficient recycling of nutrients maintains productivity. Decomposition of plant litter accounts for the majority of nutrients recycled through ecosystems (Figure 3). Rates of plant litter decomposition are highly dependent on litter quality; high concentration of phenolic compounds, especially lignin, in plant litter has a retarding effect on litter decomposition. More complex C compounds are decomposed more slowly and may take many years to completely breakdown. Decomposition is typically described with exponential decay and has been related to the mineral concentrations, especially manganese, in the leaf litter.\nGlobally, rates of decomposition are mediated by litter quality and climate. Ecosystems dominated by plants with low-lignin concentration often have rapid rates of decomposition and nutrient cycling (Chapin et al. 1982). Simple carbon (C) containing compounds are preferentially metabolized by decomposer microorganisms which results in rapid initial rates of decomposition, see Figure 5A, models that depend on constant rates of decay; so called “k” values, see Figure 5B. In addition to litter quality and climate, the activity of soil fauna is very important \n\nHowever, these models do not reflect simultaneous linear and non-linear decay processes which likely occur during decomposition. For instance, proteins, sugars and lipids decompose exponentially, but lignin decays at a more linear rate Thus, litter decay is inaccurately predicted by simplistic models.\n\nA simple alternative model presented in Figure 5C shows significantly more rapid decomposition that the standard model of figure 4B. Better understanding of decomposition models is an important research area of ecosystem ecology because this process is closely tied to nutrient supply and the overall capacity of ecosystems to sequester CO from the atmosphere.\n\nTrophic dynamics refers to process of energy and nutrient transfer between organisms. Trophic dynamics is an important part of the structure and function of ecosystems. Figure 3 shows energy transferred for an ecosystem at Silver Springs, Florida. Energy gained by primary producers (plants, P) is consumed by herbivores (H), which are consumed by carnivores (C), which are themselves consumed by “top- carnivores”(TC).\n\nOne of the most obvious patterns in Figure 3 is that as one moves up to higher trophic levels (i.e. from plants to top-carnivores) the total amount of energy decreases. Plants exert a “bottom-up” control on the energy structure of ecosystems by determining the total amount of energy that enters the system.\n\nHowever, predators can also influence the structure of lower trophic levels from the top-down. These influences can dramatically shift dominant species in terrestrial and marine systems The interplay and relative strength of top-down vs. bottom-up controls on ecosystem structure and function is an important area of research in the greater field of ecology.\n\nTrophic dynamics can strongly influence rates of decomposition and nutrient cycling in time and in space. For example, herbivory can increase litter decomposition and nutrient cycling via direct changes in litter quality and altered dominant vegetation. Insect herbivory has been shown to increase rates of decomposition and nutrient turnover due to changes in litter quality and increased frass inputs. \nHowever, insect outbreak does not always increase nutrient cycling. Stadler showed that C rich honeydew produced during aphid outbreak can result in increased N immobilization by soil microbes thus slowing down nutrient cycling and potentially limiting biomass production. North atlantic marine ecosystems have been greatly altered by overfishing of cod. Cod stocks crashed in the 1990s which resulted in increases in their prey such as shrimp and snow crab Human intervention in ecosystems has resulted in dramatic changes to ecosystem structure and function. These changes are occurring rapidly and have unknown consequences for economic security and human well-being.\n\nThe biosphere has been greatly altered by the demands of human societies. Ecosystem ecology plays an important role in understanding and adapting to the most pressing current environmental problems. Restoration ecology and ecosystem management are closely associated with ecosystem ecology. Restoring highly degraded resources depends on integration of functional mechanisms of ecosystems.\n\nWithout these functions intact, economic value of ecosystems is greatly reduced and potentially dangerous conditions may develop in the field. For example, areas within the mountainous western highlands of Guatemala are more susceptible to catastrophic landslides and crippling seasonal water shortages due to loss of forest resources. In contrast, cities such as Totonicapán that have preserved forests through strong social institutions have greater local economic stability and overall greater human well-being.\n\nThis situation is striking considering that these areas are close to each other, the majority of inhabitants are of Mayan descent, and the topography and overall resources are similar. This is a case of two groups of people managing resources in fundamentally different ways. Ecosystem ecology provides the basic science needed to avoid degradation and to restore ecosystem processes that provide for basic human needs.\n"}
{"id": "41316536", "url": "https://en.wikipedia.org/wiki?curid=41316536", "title": "End of history", "text": "End of history\n\nThe end of history is a political and philosophical concept that supposes that a particular political, economic, or social system may develop that would constitute the end-point of humanity's sociocultural evolution and the final form of human government. A variety of authors have argued that a particular system is the \"end of history\" including Thomas More in \"Utopia\", Georg Wilhelm Friedrich Hegel, Karl Marx, Vladimir Solovyov, Alexandre Kojève and Francis Fukuyama in the 1992 book, \"The End of History and the Last Man\".\n\nThe concept of an end of history differs from ideas of an end of the world as expressed in various religions, which may forecast a complete destruction of the Earth or of life on Earth, and the end of the human race as we know it. The end of history instead proposes a state in which human life continues indefinitely into the future without any further major changes in society, system of governance, or economics.\n\nThe phrase, 'the end of history' was first used by French philosopher and mathematician Antoine Augustin Cournot in 1861 \"to refer to the end of the historical dynamic with the perfection of civil society\". \"Arnold Gehlen adopted it in 1952 and it has been taken up more recently by Heidegger and Vattimo\".\n\nThe formal development of an idea of an \"end of history\" is most closely associated with Hegel, although Hegel discussed the idea in ambiguous terms, making it unclear whether he thought such a thing was a certainty or a mere possibility.\n\nA postmodern understanding of the term differs in that \"The idea of an 'end of history' does not imply that nothing more will ever happen. Rather, what the postmodern sense of an end of history tends to signify is, in the words of contemporary historian Keith Jenkins, the idea that 'the peculiar ways in which the past was historicized (was conceptualized in modernist, linear and essentially metanarrative forms) has now come to an end of its productive life; the all-encompassing \"experiment of modernity\" ... is passing away into our postmodern condition'.\"\n\n\n"}
{"id": "8141606", "url": "https://en.wikipedia.org/wiki?curid=8141606", "title": "English-language radio", "text": "English-language radio\n\nEnglish-language radio refers to radio stations that broadcast primarily in the English language and are located in countries where English is not an official language or majority language. Often referred to as \"English-speaking radio\" or \"Expat radio\" the broadcasts enables expats, vacationers and travelers to listen to radio in their native language while traveling abroad. The idea is that stations broadcast in English to popular holiday destinations such as Pattaya or the French Riviera or places with high expat communities. English language broadcasting also takes the form of military-backed radio such as the American Forces Network. However English-language radio based in foreign countries has to now compete with the introduction of internet radio and satellite technology that has increased listener's access to English-language radio based in \"home\" counties.\n\nThe first English-language radio in a foreign country transmission was thought to be in 1925 when Radio Paris broadcast from the Eiffel Tower, a show about fashion design, sponsored by Selfridges of London.\n\nWith end of World War II American and British forces began occupation of bases within regions of conquered Axis countries such as Germany and Okinawa for the enjoyment and informative power radio bring to both the troops and their families. Today traditions remain as the American Forces Network and the British Forces Broadcasting Service continue to provide English-language entertainment and information to troops stationed abroad in their respective countries or areas.\n\nNon-military English broadcasting gained momentum with the increase in globalization after World War II. As English-speaking business personnel and expat communities grew because of international trade and investment, so did the demand for English language entertainment. As the number of global English speakers has grown, demand from the local native market has grown as well. Stations that actively reach out to the local community such as International Community Radio Taipei have been on the rise.\n\nThe location of most English-language radio stations can be determined by their proximity to large populations of English speakers. Geneva, Switzerland, for example, has many English speakers and expatriates, also the Spanish coastal areas, and thus English radio broadcasts. Radio stations in places such as Baja California and Costa Rica also serve the increasing number of English speakers.\n\n\n\n"}
{"id": "6442856", "url": "https://en.wikipedia.org/wiki?curid=6442856", "title": "G-Zero world", "text": "G-Zero world\n\nThe term G-Zero world refers to an emerging vacuum of power in international politics created by a decline of Western influence and the domestic focus of the governments of developing states. It aims to explain a world in which there is no single country or group of countries that has ability and will, economically and politically, to drive a truly global agenda. \n\nThe term G-Zero was first coined by political scientists Ian Bremmer and David F. Gordon. G-Zero became the main theme of Ian Bremmer's book, \"\" (Portfolio, May 2012). \n\nIt is a reference to a perceived shift away from the preeminence of the Group of Seven industrialized countries and the expanded Group of Twenty, which includes major emerging powers like China, India, Brazil, Turkey and others. It is also a rejection of terms like G2, often used to identify a possible strategic partnership between the U.S. and Chinese governments, or G3, which represents an attempt to align U.S., European and Japanese interests to defend free market democracy from the rise of Chinese-inspired state-dominated capitalism.\n\nThose who argue that the G-Zero has become the current international order warn that the G7 has become obsolete, that the G20 offers too many competing visions of the proper role of government in an economy to produce well-coordinated policies, that China has no interest in the responsibilities that come with a G2, and that America, Europe and Japan are too mired in internal problems to forge a common approach to economic and security policy. \n\nIn an article called “From G8 to G20 to G-Zero: Why no one wants to take charge in the new global order,\" Ian Bremmer writes that making compromises are difficult since each country has their own values and developed countries have voters that want their leader's focus to be domestic community, not the international one. Some of these developed countries include: the United States, Britain, Germany, France, and Japan. As developed countries start to focus on their domestic issues, the lack of global leadership increases which in turn increases the transnational problems. As global leadership decreases, clashes between countries are also increasing such as America and China having different views on “statedriven and free-market varieties of capitalism”. There are also issues arising in East Asia between nations such as China and Japan in the East China Sea. The U.S. has to also focus on changes in their energy sector and whether they should participate in Syria’s civil war.\n\nBremmer explains that governments can adapt to the G-Zero through focusing on regional solutions such as China’s deals with the Association of South-East Asian Nations (A.S.E.A.N.) and the United States’ progress on the Trans-Pacific Partnership. Governments can also form relationships with a diversity of partners. However some countries may still not be able to adapt to the G-0 because of three impacting events in the world: \"China's rise, Middle East turmoil and the redesign of Europe\". Countries affected by these events would be Japan, Israel and Britain. \n\nThe concept of the G-Zero has been criticized by some who argue that it overstates the decline in America’s political and economic power and underestimates the willingness of developing countries to play a larger role on the international stage.\n\n\n"}
{"id": "31877720", "url": "https://en.wikipedia.org/wiki?curid=31877720", "title": "George Wood (Radio Sweden)", "text": "George Wood (Radio Sweden)\n\nGeorge MacClaren Wood III is an American journalist who has worked at Radio Sweden since 1975, He was born in Berkeley, California on August 10, 1949, and grew up in Piedmont, California. He has degrees from the University of California, Santa Barbara and the University of California, Berkeley, and participated in the university's Education Abroad Program to Lund University in Sweden, 1969-1970.\n\nGeorge Wood began as a freelance reporter at Radio Sweden in 1975. Following the retirement of Arne Skoog in 1978 he told over the writing and presenting of the program Sweden Calling DXers and its successor MediaScan, until the latter was taken off the air in 2001. In 1994 MediaScan became the first radio program in Sweden and the second in Europe (the first in English) to have its audio posted on the Internet.\n\nHe was Radio Sweden's Webmaster since Swedish Radio's first website launched in 1995, while also serving as a journalist for the Radio Swedish English Service. His was one of the voices in the satirical sketches in the program the Saturday Show. He retired from Radio Sweden in August, 2014.\n\nAfter retirement George Wood enrolled in Egyptology courses at Uppsala University.\n\nGeorge Wood was News Director of the university radio station KCSB-FM (at the University of California, Santa Barbara) in 1971-1973, and has also worked at KPFA in Berkeley, California, Earth News Service in San Francisco, and briefly as a freelancer for National Public Radio. Since the late 70's he has been the Stockholm stringer for CBS Radio News. He has written articles for a number of publications including \"Satellite Times\", \"The World Radio TV Handbook\", and the \"New Age Journal\".\n\n"}
{"id": "44023814", "url": "https://en.wikipedia.org/wiki?curid=44023814", "title": "German Parliamentary Committee investigation of the NSA spying scandal", "text": "German Parliamentary Committee investigation of the NSA spying scandal\n\nThe German Parliamentary Committee investigation of the NSA spying scandal (official title: \"1. Untersuchungsausschuss „NSA“\") was started on March 20, 2014, by the German Parliament in order to investigate the extent and background of foreign secret services spying in Germany in the light of the Global surveillance disclosures (2013–present).\nThe Committee is also in search of strategies on how to protect telecommunication with technical means.\n\nThe committee is formed by eight members of the German Parliament. The parliamentarian of the Christian Democratic Union (CDU) Clemens Binninger was head of the committee but stepped down after six days. In a statement, Binninger clarified that the other committee members had insisted on inviting Edward Snowden to testify; Binninger objected to this and resigned in protest. Patrick Sensburg (CDU) succeeded him. \n\nOn May 8, 2014, the committee unanimously decided to let US whistleblower Edward Snowden testify as a witness.\n\nOn September 23, 2014, the Green Party and The Left filed a constitutional complaint against the Christian Democratic Union, the Social Democrats and the NSA Parliamentary Committee because of the Christian Democrats' and the Social Democrats' refusal to let the witness Edward Snowden testify in Berlin. The accused proposed a video conference from Moscow which Snowden had refused.\n\nOn September 28, 2014, the Green Party and The Left filed a constitutional complaint against German chancellor Merkel. According to them, she refuses to comply with her duty according to Chapter 44 of the German constitution to ensure a real investigation; especially by refusing to ensure the legal requirements to allow the witness Edward Snowden to testify.\n\nOn July 3, 2014, the former Technical Director of the NSA, William Binney, who had become a whistleblower after the terrorist attacks of September 11, 2001, testified to the committee. He said that the NSA has a totalitarian approach that has previously only been known from dictatorships and that there is no longer such a thing as privacy. Former NSA employee Thomas Andrews Drake described the close cooperation between the NSA and the German foreign intelligence service BND.\n\nThe US journalist Glenn Greenwald was asked to testify in September, 2014. On August 1, 2014, he wrote in a letter that he was willing to support the Parliament's investigation on the espionage in Germany by the NSA. By their refusal to let the crucial witness Edward Snowden testify, German politicians had however shown that it is more important to them not to annoy the US than to really investigate and he was not willing to take part in a \"ritual\" that \"shall seem like an investigation\".\n\nIn Operation Eikonal German BND agents received \"Selector Lists\" from the NSA − search terms for their dragnet surveillance. They contain IP addresses, mobile phone numbers and email accounts with the BND surveillance system containing hundreds of thousands and possibly more than a million such targets. These lists have been subject of controversy as in 2008 it was revealed that they contained some terms targeting the European Aeronautic Defence and Space Company (EADS), the Eurocopter project as well as French administration, which were first noticed by BND employees in 2005. Other selectors were found to target the administration of Austria. After the revelations made by whistleblower Edward Snowden the BND decided to investigate the issue whose October 2013 conclusion was that at least 2,000 of these selectors were aimed at Western European or even German interests which has been a violation of the Memorandum of Agreement that the US and Germany signed in 2002 in the wake of the 9/11 terror attacks. After reports emerged in 2014 that EADS and Eurocopter had been surveillance targets the Left Party and the Greens filed an official request to obtain evidence of the violations.\n\nThe investigative Parliamentary Committee was set up in spring 2014 and reviewed the selectors and discovered 40,000 suspicious search parameters, including espionage targets in Western European governments and numerous companies. The group also confirmed suspicions that the NSA had systematically violated German interests and concluded that the Americans could have perpetrated economic espionage directly under the Germans' noses. The investigative parliamentary committee was not granted access to the NSA's selectors list as an appeal led by opposition politicians failed at Germany's top court - instead the ruling coalition appointed an administrative judge, Kurt Graulich, as a \"person of trust\" who was granted access to the list and briefed the investigative commission on its contents after analyzing the 40,000 parameters. In his almost 300-paged report Graulich concluded that European government agencies were targeted massively and that Americans hence broke contractual agreements. He also found that German targets which received special protection from surveillance of domestic intelligence agencies by Germany's Basic Law (Grundgesetz) − including numerous enterprises based in Germany − were featured in the NSA's wishlist in a surprising plenitude. While the magnitude differs there have also been problematic BND-internal selectors which have been used until end of 2013 - around two thirds of 3300 targets were related to EU and NATO states. Klaus Landefeld, member of the board at the Internet industry association Eco International, has met intelligence officials and legislators to present suggestions for improvement, like streamlining the selector system.\nOn July 4, 2014, it was revealed to the public that BND agent Markus R. had been arrested on July 2, 2014, for apparently having spied. The 31-year-old German is accused of having worked for the CIA. After his arrest, the US ambassador John B. Emerson was summoned for talks at the German Foreign Office.\n\nIt was revealed that the BND-agent had saved 218 secret BND documents on USB sticks since 2012 and sold them to US agents for a sum of 25,000 Euro in Salzburg, Austria. At least three of the documents were about the NSA Parliamentary Committee.\nThe Federal Office for the Protection of the Constitution had mistaken him for a Russian spy and asked US colleagues to help uncover him.\n\nOn July 9, 2014, a second US spy was discovered, who worked for the Secretary of Defense.\n\nIn July 2014 a Parliament technician found out that the mobile phone of Roderich Kiesewetter, representative of the Christian Democratic Union in the committee, was spied on. Kiesewetter said there is evidence that all four Party representatives in the committee have been spied on.\n\nIn the months following May 2015, Peter Pilz, a member of the Austrian parliament for the Green Party, disclosed several documents and transcripts related to operation Eikonal, in which NSA and BND cooperated for tapping transit cables at a facility of Deutsche Telekom in Frankfurt. These documents were highly sensitive and handed over to the committee for investigating the Eikonal operation. Therefore, it seems likely someone from the committee leaked these documents to Pilz. Among them are lists of communication channels from many European countries, including most of Germany's neighbours. Peter Pilz also discovered NSA spying facilities in Austria, and therefore wants a parliamentary committee on the NSA spying in his own country too.\n\nOn December 1, 2016, WikiLeaks released over 2,400 documents which it claims are from the investigation.\n\n"}
{"id": "19574596", "url": "https://en.wikipedia.org/wiki?curid=19574596", "title": "Global Handwashing Day", "text": "Global Handwashing Day\n\nGlobal Handwashing Day (GHD) is a campaign to motivate and mobilize people around the world to improve their handwashing habits. Washing hands at critical points during the day and washing with soap are both important. \n\nGlobal Handwashing Day occurs on 15 October of each year. The global campaign is dedicated to raising awareness of handwashing with soap as a key factor in disease prevention. Respiratory and intestinal diseases can be reduced by 25-50%.\n\nThe Global Handwashing Partnership (GHP) (formerly called \"Public Private Partnership for Handwashing\" (PPPHW)) established Global Handwashing Day in 2008 as a way to promote a global and local vision of handwashing with soap.\n\nSteering Committee members of the GHP include Colgate-Palmolive; FHI 360; The London School of Hygiene and Tropical Medicine; Procter & Gamble; UNICEF; Unilever; University at Buffalo; USAID; the Water and Sanitation Programme at the World Bank; and the Water Supply and Sanitation Collaborative Council.\n\nContinued research on handwashing habits and practices is commissioned in conjunction with GHD. In 2011, Svenska Cellulosa Aktiebolaget (SCA), sponsored a study to assess the handwashing habits of American and Canadian adults, finding that many were not using soap when washing their hands.\n\nThe aims of Global Handwashing Day are to:\n\nEach year, over 200 million people celebrate Global Handwashing Day.\n\n\nGlobal Handwashing Day was initiated by the Global Handwashing Partnership (GHP) in August 2008 at the annual World Water Week in Stockholm, Sweden. This means that the first Global Handwashing Day took place on 15 October 2008. The date was appointed by the UN General Assembly. The year 2008 was also the International Year of Sanitation. The founding bodies in 2008 included: FHI360 (a nonprofit human development organization based in the US), US Centers for Disease Control and Prevention, Procter & Gamble, UNICEF, Unilever, World Bank Water & Sanitation Program and the United States Agency for International Development.\n\n\nTheme for Global Handwashing Day 2018: Clean Hands- a recipe for health\n\nThe campaign was initiated to reduce childhood mortality rates and related respiratory and diarrheal diseases by introducing simple behavioral changes, such as handwashing with soap. This simple action can reduce the mortality rate of respiratory disease by 25%. Death from diarrheal diseases can be reduced by 50%. Across the world, more than 60 percent of health workers do not adhere to proper hand hygiene. According to the US Centers for Disease Control and Prevention, US health care providers, on average, wash their hands less than half of the time they should. On any given day, one in 25 US hospital patients has at least one health care-associated infection.\n\nHandwashing with soap is very effective and the least expensive way to prevent diarrhea and acute respiratory infections. Pneumonia, a major ARI (acute respiratory infection), is the number one cause of mortality among children under five years old, killing an estimated 1.8 million children per year. Diarrhea and pneumonia together account for almost 3.5 million child deaths annually. Handwashing with soap is estimated to reduce cases of diarrhea by 30% and respiratory infections by 21% in children under the age of five.\n\nIt is important to make handwashing into a habit. Good handwashing with soap before eating and after using the toilet into a regular habit can save more lives than any single vaccine or medical intervention, cutting deaths from diarrhea by almost half and deaths from acute respiratory infections by one-quarter.\n\nHandwashing is usually done together with other sanitation interventions as part of water, sanitation and hygiene WASH programmes.\n\nThe Global Handwashing Day helps raise awareness of the importance of washing with soap, but it also makes it fun for children to get involved.\n\nProper hygiene requires that individuals know the importance of good hygiene and develop the habits to carry it out. There are people with plenty of money but nonetheless, they lack the important habits of timely handwashing with soap, and thereby unknowingly endanger themselves and others around them.\n\nPeer influence is significant to seeing increased handwashing among students. In a study conducted in Kenya, researchers found that students were much more likely to wash their hands when another student is present. Peer influence is only successful, however, when students know that handwashing is a desirable action.\n\nThe World Health Organization (WHO) celebrates a World Hand Hygiene Day on 5 May. In 2018 the theme was prevention of sepsis in health care. The theme of the year before was to combat antibiotic resistance (AMR).\n\n\n"}
{"id": "28919960", "url": "https://en.wikipedia.org/wiki?curid=28919960", "title": "Global Strategy for Women's and Children's Health", "text": "Global Strategy for Women's and Children's Health\n\nThe Global Strategy for Women's and Children's Health was a program of the United Nations (UN) directed at improving women's and children's health in the developing world.\n\nThe program was announced by UN Secretary-General Ban Ki-moon in September 2010. At the time of the announcement, the program was valued at $US40 billion over a five-year period, funded by state and private donors, with the UN hoping for more pledges to follow. The objective of the program was to save the lives of 16 million people during the period of the program. As the Millennium Development Goals 4, 5 and 6 were showing the slowest rate of progression, this program was also instituted to gain momentum in achieving them. The implementation of the program was led by the World Health Organization, reporting to the UN.\n\nThe aid-based program was accompanied by pledges from some developing nations (including Tanzania and Rwanda) to increase their own domestic spending on health care. According to the UN, around $8.6 million of the program's funding came from what it described as \"low-income countries\".\n\nInternational aid group Oxfam expressed doubts about the program, including the extent to which its funding was genuinely new.\n\nThe Global Strategy managed to improve the coordination of global efforts towards the improvement of women’s and children’s health as well as enhancing strategies to tackle this. It gave rise to the “Every Woman Every Child” movement, which assisted in the mobilisation of stakeholders. Despite not reaching targets, reductions in both child and maternal mortality were noted; of 49% and 45% respectively from 1990 to 2013. 2.4 million maternal and child deaths were prevented.  Prevention of mother-to-child transmission of HIV, oral rehydration therapy and exclusive breastfeeding coverage showed the most significant improvement, however, progress in vaccination and pneumonia was still lagging.\n\nThe United Nations also reported increased collaboration with the private sector, with an increase in donor funding of US$19.8 billion noted from September 2010 to May 2014.\n\nThe Global Health Strategy for Women, Children and Adolescents 2016-2030 was launched in September 2015, building on experience gained from 2010-2015, with the inclusion of adolescents as an additional target group. It is aligned with the Sustainable Development Goals (SDGs) and has 3 main objectives; namely for women, adolescents and children to \"survive\", \"thrive\" and \"transform\". It is an evidence-based, multi-sectoral approach and emphasises the need to address equity, with interventions applied across the life-course. \n\nAlthough high returns on investment are projected, a monitoring report done in May 2018 shows that expected targets may not be achieved in time.\n\n"}
{"id": "3044408", "url": "https://en.wikipedia.org/wiki?curid=3044408", "title": "Global citizenship", "text": "Global citizenship\n\nGlobal citizenship is the idea that all people have rights and civic responsibilities that come with being a member of the world, with whole-world philosophy and sensibilities, rather than as a citizen of a particular nation or place. The idea is that one’s identity transcends geography or political borders and that responsibilities or rights are derived from membership in a broader class: \"humanity\". This does not mean that such a person denounces or waives their nationality or other, more local identities, but such identities are given \"second place\" to their membership in a global community. Extended, the idea leads to questions about the state of global society in the age of globalization. In general usage, the term may have much the same meaning as \"world citizen\" or cosmopolitan, but it also has additional, specialized meanings in differing contexts. Various organizations, such as the World Service Authority, have advocated global citizenship.\n\nIn education, the term is most often used to describe a worldview or a set of values toward which education is oriented (see, for example, the priorities of the \"Global Education First Initiative\" led by the Secretary-General of the United Nations). The term \"global society\" is sometimes used to indicate a global studies set of learning objectives for students to prepare them for global citizenship (see, for example, the Global Studies Center at the University of Pittsburgh).\n\nWithin the educational system, the concept of global citizenship education (GCED) is beginning to supersede or overarch movements such as multicultural education, peace education, human rights education, Education for Sustainable Development and international education. Additionally, GCED rapidly incorporates references to the aforementioned movements. The concept of global citizenship has been linked with awards offered for helping humanity. Teachers are being given the responsibility of being social change agents. Audrey Osler, director of the \"Centre for Citizenship and Human Rights Education\", the University of Leeds, affirms that \"Education for living together in an interdependent world is not an optional extra, but an essential foundation\".\n\nWith GCED gaining attention, scholars are investigating the field and developing perspectives. The following are a few of the more common perspectives:\n\nGlobal citizenship, in some contexts, may refer to a brand of ethics or political philosophy in which it is proposed that the core social, political, economic and environmental realities of the world today should be addressed at all levels—by individuals, civil society organizations, communities and nation states—through a global lens. It refers to a broad, culturally- and environmentally-inclusive worldview that accepts the fundamental interconnectedness of all things. Political, geographic borders become irrelevant and solutions to today's challenges are seen to be beyond the narrow vision of national interests. Proponents of this philosophy often point to Diogenes of Sinope (c. 412 B.C.) as an example, given his reported declaration that \"I am a citizen of the world (κοσμοπολίτης, \"cosmopolites\")\" in response to a question about his place of origin. A Sanskrit term, \"Vasudhaiva Kutumbakam\", has the meaning of \"the world is one family\". The earliest reference to this phrase is found in the Hitopadesha, a collection of parables. In the Mahopanishad VI.71-73, ślokas describe how one finds the Brahman (the one supreme, universal Spirit that is the origin and support of the phenomenal universe). The statement is not just about peace and harmony among the societies in the world, but also about a truth that somehow the whole world has to live together like a family.\n\nGlobal pollsters and psychologists have studied individual differences in the sense of global citizenship. Beginning in 2005, the World Values Survey, administered across almost 100 countries, included the statement, “I see myself as a world citizen.” For smaller studies, several multi-item scales have been developed, including Sam McFarland and colleagues’ Identification with All Humanity scale (e.g., “How much do you identify with (that is, feel a part of, feel love toward, have concern for) . . . all humans everywhere?”), Anna Malsch and Alan Omoto’s Psychological Sense of Global Community (e.g., “I feel a sense of connection to people all over the world, even if I don’t know them personally”), Gerhard Reese and colleagues’ Global Social Identity scale (e.g. “I feel strongly connected to the world community as a whole.”), and Stephen Reysen and Katzarska-Miller's global citizenship identification scale (e.g., “I strongly identify with global citizens.”). These measures are strongly related to one another, but they are not fully identical.\n\nStudies of the psychological roots of global citizenship have found that persons high in global citizenship are also high on the personality traits of openness to experience and agreeableness from the Big Five personality traits and high in empathy and caring. Oppositely, the authoritarian personality, the social dominance orientation and psychopathy are all associated with less global human identification. Some of these traits are influenced by heredity as well as by early experiences, which, in turn, likely influence individuals' receptiveness to global human identification.\n\nResearch has found that those who are high in global human identification are less prejudiced toward many groups, care more about international human rights, worldwide inequality, global poverty and human suffering. They attend more actively to global concerns, value the lives of all human beings more equally, and give more in time and money to international humanitarian causes. They tend to be more politically liberal on both domestic and international issues. They want their countries to do more to alleviate global suffering.\n\nFollowing a social identity approach, Reysen and Katzarska-Miller tested a model showing the antecedents and outcomes of global citizenship identification (i.e., degree of psychological connection with global citizens). Individuals’ normative environment (the cultural environment in which one is embedded contains people, artifacts, cultural patterns that promote viewing the self as a global citizen) and global awareness (perceiving oneself as aware, knowledgeable, and connected to others in the world) predict global citizenship identification. Global citizenship identification then predicts six broad categories of prosocial behaviors and values, including: intergroup empathy, valuing diversity, social justice, environmental sustainability, intergroup helping, and a felt responsibility to act. Subsequent research has examined variables that influence the model such as: participation in a college course with global components, perception of one’s global knowledge, college professors' attitudes toward global citizenship, belief in an intentional worlds view of culture, participation in a fan group that promotes the identity, use of global citizen related words when describing one's values, possible self as a global citizen, religiosity and religious orientation, threat to one’s nation, interdependent self-construal prime, perception of the university environment, and social media usage.\n\nAt the same time that globalization is reducing the importance of nation-states, the idea of global citizenship may require a redefinition of ties between civic engagement and geography. Face-to-face town hall meetings seem increasingly supplanted by electronic \"town halls\" not limited by space and time. Absentee ballots opened the way for expatriates to vote while living in another country; the Internet may carry this several steps further. Another interpretation given by several scholars of the changing configurations of citizenship due to globalization is the possibility that citizenship becomes a changed institution; even if situated within territorial boundaries that are national, if the meaning of the national itself has changed, then the meaning of being a citizen of that nation changes.\n\nThe lack of a universally recognized world body can put the initiative upon global citizens themselves to create rights and obligations. Rights and obligations as they arose at the formation of nation-states (e.g. the right to vote and obligation to serve in time of war) are being expanded. Thus, new concepts that accord certain \"human rights\" which arose in the 20th century are increasingly being universalized across nations and governments. This is the result of many factors, including the Universal Declaration of Human Rights by the United Nations in 1948, the aftermath of World War II and the Holocaust and growing sentiments towards legitimizing marginalized peoples (e.g., pre-industrialized peoples found in the jungles of Brazil and Borneo). Couple this with growing awareness of our impact on the environment, and there is the rising feeling that citizen rights may extend to include the right to dignity and self-determination. If national citizenship does not foster these new rights, then global citizenship may seem more accessible.\n\nGlobal citizenship advocates may confer specific rights and obligations of human beings trapped in conflicts, those incarcerated as part of ethnic cleansing, and pre-industrialized tribes newly discovered by scientists living in the depths of dense jungle\nOn 10 December 1948, the UN General Assembly Adopted Resolution 217A (III), also known as \"The Universal Declaration of Human Rights.\"\n\nArticle 1 states that \"All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood.\" \n\nArticle 2 states that \"Everyone is entitled to all the rights and freedoms set forth in this Declaration, without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status. Furthermore, no distinction shall be made on the basis of the political, jurisdictional or international status of the country or territory to which a person belongs, whether it be independent, trust, non-self-governing or under any other limitation of sovereignty.\"\n\nArticle 13(2) states that \"Everyone has the right to leave any country, including his own, and to return to his country.\" \n\nAs evidence in today's modern world, events such as the Trial of Saddam Hussein have proven what British jurist A. V. Dicey said in 1885, when he popularized the phrase \"rule of law\" in 1885. Dicey emphasized three aspects of the rule of law :\n\nThe opening of the United States Declaration of Independence, written by Thomas Jefferson in 1776, states as follows:\n\"Global citizenship in the United States\" was a term used by former U.S. President Barack Obama in 2008 in a speech in Berlin.\n\nIn general, a world citizen is a person who places global citizenship above any nationalistic or local identities and relationships. An early expression of this value is found in Diogenes of Sinope (c. 412 B.C.; mentioned above), the founding father of the Cynic movement in Ancient Greece. Of Diogenes it is said: \"Asked where he came from, he answered: 'I am a citizen of the world (kosmopolitês)'\". This was a ground-breaking concept because the broadest basis of social identity in Greece at that time was either the individual city-state or the Greeks (Hellenes) as a group. The Tamil poet Kaniyan Poongundran wrote in \"Purananuru\", \"To us all towns are one, all men our kin.\" In later years, political philosopher Thomas Paine would declare, \"my country is the world, and my religion is to do good.\" Today, the increase in worldwide globalization has led to the formation of a \"world citizen\" social movement under a proposed world government. In a non-political definition, it has been suggested that a world citizen may provide value to society by using knowledge acquired across cultural contexts. Many people also consider themselves world citizens, as they feel at home wherever they may go.\n\nAlbert Einstein described himself as a world citizen and supported the idea throughout his life, famously saying \"Nationalism is an infantile disease. It is the measles of mankind.\" World citizenship has been promoted by distinguished people including Garry Davis, who lived for 60 years as a citizen of no nation, only the world. Davis founded the World Service Authority in Washington, DC, which sells World Passports, a fantasy passport to world citizens. In 1956 Hugh J. Schonfield founded the Commonwealth of World Citizens, later known by its Esperanto name \"Mondcivitana Respubliko\", which also issued a world passport; it declined after the 1980s.\n\nThe Bahá'í faith promotes the concept through its founder's proclamation (in the late 19th century) that \"The Earth is but one country, and mankind its citizens.\" As a term defined by the Bahá'í International Community in a concept paper shared at the 1st session of the United Nations Commission on Sustainable Development, New York, U.S.A. on 14–25 June 1993. \"World citizenship begins with an acceptance of the oneness of the human family and the interconnectedness of the nations of 'the earth, our home.' While it encourages a sane and legitimate patriotism, it also insists upon a wider loyalty, a love of humanity as a whole. It does not, however, imply abandonment of legitimate loyalties, the suppression of cultural diversity, the abolition of national autonomy, nor the imposition of uniformity. Its hallmark is 'unity in diversity.' World citizenship encompasses the principles of social and economic justice, both within and between nations; non-adversarial decision making at all levels of society; equality of the sexes; racial, ethnic, national and religious harmony; and the willingness to sacrifice for the common good. Other facets of world citizenship—including the promotion of human honour and dignity, understanding, amity, co-operation, trustworthiness, compassion and the desire to serve—can be deduced from those already mentioned.\"\n\nPhilosophically, mundialization (French, \"mondialisation\") is seen as a response to globalization’s \"dehumanisation through [despatialised] planetarisation\" (Teilhard de Chardin quoted in Capdepuy 2011). An early use of \"mondialisation\" was to refer to the act of a city or a local authority declaring itself a \"world citizen\" city, by voting a charter stating its awareness of global problems and its sense of shared responsibility. The concept was promoted by the self-declared World Citizen Garry Davis in 1949, as a logical extension of the idea of individuals declaring themselves world citizens, and promoted by Robert Sarrazac, a former leader of the French Resistance who created the Human Front of World Citizens in 1945. The first city to be officially mundialised was the small French city of Cahors (only 20,000 in 2006), the capital city of the Département of Lot in central France, on 20 July 1949. Hundreds of cities mundialised themselves over a few years, most of them in France, and then it spread internationally, including to many German cities and to Hiroshima and Nagasaki. In less than a year, 10 General Councils (the elected councils of the French \"Départements\"), and hundreds of cities in France covering 3.4 million inhabitants voted mundialisation charters. One of the goals was to elect one delegate per million inhabitants to a People's World Constitutional Convention given the already then historical failure of the United Nations in creating a global institution able to negotiate a final world peace. To date, more than 1000 cities and towns have declared themselves World cities, including Beverly Hills, Los Angeles, Minneapolis, St. Louis, Philadelphia, Toronto, Hiroshima, Tokyo, Nivelles, and Königswinter.\n\nAs a social movement, mundialization expresses the solidarity of populations of the globe and aims to establish institutions and supranational laws of a federative structure common to them, while respecting the diversity of cultures and peoples. The movement advocates for a new political organization governing all humanity, involving the transfer of certain parts of national sovereignty to a Federal World Authority, Federal World Government and Federal World Court. Basing its authority on the will of the people, supporters hope it could develop new systems to draw on the highest and best wisdom of all humanity, and solve major planetary problems like hunger, access to water, war, peace-keeping, pollution and energy. The mundialization movement includes the declaration of specified territory - a city, town, or state, for example - as world territory, with responsibilities and rights on a world scale. Currently the nation-state system and the United Nations offer no way for the people of the world to vote for world officials or participate in governing our world. International treaties or agreements lack the force of law. Mundialization seeks to address this lack by presenting a way to build, one city at a time, such a system of true World Law based upon the sovereignty of the whole.\n\nAuthor Shashi Tharoor feels that an Earth Anthem sung by people across the world can inspire planetary consciousness and global citizenship among people.\n\nNot all interpretations of global citizenship are positive. For example, Parekh advocates what he calls globally oriented citizenship, and states, \"If global citizenship means being a citizen of the world, it is neither practicable nor desirable.\" He argues that global citizenship, defined as an actual membership of a type of worldwide government system, is impractical and dislocated from one's immediate community. He also notes that such a world state would inevitably be \"remote, bureaucratic, oppressive, and culturally bland.\" Parekh presents his alternative option with the statement: \"Since the conditions of life of our fellow human beings in distant parts of the world should be a matter of deep moral and political concern to us, our citizenship has an inescapable global dimension, and we should aim to become what I might call a globally oriented citizen.\" Parekh's concept of globally oriented citizenship consists of identifying with and strengthening ties towards one's political regional community (whether in its current state or an improved, revised form), while recognizing and acting upon obligations towards others in the rest of the world.\n\nMichael Byers, a professor in Political Science at the University of British Columbia, questions the assumption that there is one definition of global citizenship, and unpacks aspects of potential definitions. In the introduction to his public lecture, the UBC Internalization website states, \"'Global citizenship' remains undefined. What, if anything, does it really mean? Is global citizenship just the latest buzzword?\" Byers notes the existence of stateless persons, whom he remarks ought to be the primary candidates for global citizenship, yet continue to live without access to basic freedoms and citizenship rights. Byers does not oppose the concept of global citizenship, however he criticizes potential implications of the term depending on one's definition of it, such as ones that provide support for the \"ruthlessly capitalist economic system that now dominates the planet.\" Byers states that global citizenship is a \"powerful term\" because \"people that invoke it do so to provoke and justify action,\" and encourages the attendees of his lecture to re-appropriate it in order for its meaning to have a positive purpose, based on idealistic values.\n\nNeither criticism of global citizenship is anything new. Gouverneur Morris, a delegate to the Constitutional Convention (United States), criticized \"citizens of the world\" while he was on the floor of the convention; August 9, 1787. \"As to those philosophical gentlemen, those Citizens of the World as they call themselves, He owned he did not wish to see any of them in our public Councils. He would not trust them. The men who can shake off their attachments to their own Country can never love any other. These attachments are the wholesome prejudices which uphold all Governments, Admit a Frenchman into your Senate, and he will study to increase the commerce of France: an Englishman, and he will feel an equal biass in favor of that of England.\"\n\n\n\n"}
{"id": "46260828", "url": "https://en.wikipedia.org/wiki?curid=46260828", "title": "Global silver trade from the 16th to 18th centuries", "text": "Global silver trade from the 16th to 18th centuries\n\nThe global silver trade between the Americas and Europe from the sixteenth to nineteenth centuries was a spillover of the Columbian Exchange which had a profound effect on the world economy. In fact, many scholars consider the silver trade to mark the beginning of a genuinely global economy, with one historian noting that silver \"went round the world and made the world go round.\" Although global, much of that silver ended up in the hands of the Chinese, as they accepted it as a form of currency. In addition to the global economic changes the silver trade engendered, it also put into motion a wide array of political transformations in the early modern era. \"New World mines,\" concluded several prominent historians \"supported the Spanish empire,\" acting as a linchpin of the Spanish economy.\n\nSpaniards at the time of the Age of Exploration discovered vast amounts of silver, much of which was from the Potosí silver mines, to fuel their trade economy. Potosí's deposits were rich and Spanish American silver mines were the world's cheapest sources of it. The Spanish acquired the silver, minting it into the peso de ocho (a currency) to then use it as a means of purchase; that currency was so widespread that even the United States accepted it as valid until the Coinage Act of 1857. As the Spanish need for silver increased, new innovations for more efficient extraction of silver were developed, such as the amalgamation method of using mercury to extract silver from ore.\n\nIn the two centuries that followed the discovery of Potosí, the Spanish silver mines in the Americas produced 40,000 tons of silver. Altogether, more than 150,000 tons of silver were shipped from Potosí by the end of the 18th century. From 1500 to 1800, Mexico and Peru produced about 80% of the world's silver with 30% of it eventually ending up in China (largely because of British merchants who used it to purchase exotic Chinese commodities). In the late 16th and early 17th century, Japan was also exporting heavily into China and the foreign trade at large.\n\nAs has been demonstrated, China dominated silver imports. The market value of silver in the Ming territory was double its value elsewhere, which provided great arbitrage profit for the Europeans and Japanese. The abundance of silver in China made it easy for the country to mint it into coinage. That process was so widespread that local Chinese government officials would demand taxes to be paid in silver to the point that silver eventually backed all of China's economy.\n\nThe world's first paper money (\"flying money\") was invented by the Chinese and they needed some commodity to back it. Traditional coins were useful, but the amount of coins needed for large purchases could be bulky and dangerous to transport. That problem was solved when the Chinese created small pieces of paper with pictures of the coin printed on them. By the nature of their geography, China had no real amount of precious metals of their own to back the paper money they invented. Because the Spaniards didn't find gold but did find copious amounts of silver, the Spaniards and the rest of Europe used this silver to purchase the commodities of choice from China, solving both of their problems.\n\nA result of the Spanish colonization of the Americas was the discovery, production, and trade of precious metals. The Spanish, along with other European nations, had a great desire for Chinese goods such as silk and porcelain. The Europeans did not have any goods or commodities which China desired, so they traded silver to make up for their trade deficit. The two most important mining colonies of the Spanish Empire were Peru and Mexico, who were estimated to have provided one-hundred thousand tons of silver from the mid 16th Century to the end of the colonial period. The richest, and most productive mine in the Americas was that of Potosí in what is modern day Bolivia. The richest camp in Mexico was in the city of Zacatecas, however the production of this mine was far less than that of Potosi.\n\nMore simplistic native mining techniques dominated American mining for the early part of the 16th Century. Mining in the Americas became formally industrialized when the process of mercury amalgamation became popularized. Mercury amalgamation was invented by a Spaniard in central Mexico in the 1550s. Historians dispute what individual was the first to invent the process, however most agree that it was a Spaniard. Mercury was the one of the highest costs of production for the Americas, since much of it had to be shipped. The ratio of Mercury to silver produced was about two to one. Furthermore, German miners introduced the stamp mill and lead smelting in the 1530s. Gunpowder was often used to blast of large holes to create the mine shafts, although there were not many deep shafts. Potosí had the most amount of ore, however it was lower quality than that of Mexico.\n\nMining production in the Americas largely depended on native labor in both Mexico and Peru. In Mexico, many of the natives worked as wage laborers by the middle of the 17th Century. However, the labor system known as the repartimiento still existed in some places. Silver production in Mexico was relatively cheap when compared to that of Peru, and the general trend of Mexican labor systems was that towards waged labor. In Peru mines, the mit'a system was a dominant form of native labor subjection, although waged laborers worked on the mines as well. Natives under the mit'a system were paid much less, and this was necessary for the production of silver to continue in Peru where costs were relatively high.\n\nThe ultimate destination for the mass amounts of silver produced in the Americas and Japan was China. Silver from the Americas flowed mostly across the Atlantic and made its way to the far east. A popular route was around the Cape of Good Hope into the east, and sometimes it came over land. Major outposts for the silver trade were located in Southeast Asian countries, such as the Philippines. The city of Manilla served as a primary outpost of the exchange of goods between the Americas, Japan, and China. However, there is a large amount of silver that crossed across the Pacific Ocean directly from the Americas as well. There are not many records of the amount of silver which crossed the Pacific due to it being discouraged by the Spanish monarchy, so estimates highly vary.\n\nSilver also found its way across other parts of the world as well. India and Europe both received a fair amount of silver. This silver was often locally traded for other commodities, such as gold or crops. In India, silver flowed from the south to the north, and gold flowed the opposite way. Often silver and gold were manufactured into jewelry or hoarded as treasure.\n\nChina was the ultimate destination in which silver would flow towards. In exchange, the Chinese traded their popular goods such as silk and porcelain. China had a high demand for silver due to its shift from paper money to coins in the early period of the Ming Dynasty. The Ming paper currency eventually failed due to self-imposed inflation along with an inability to stop the production of counterfeit bills. The Ming attempted to produce copper coins as a new form of currency, but production was inconsistent. Hence silver became of high value because it was a valid currency that could be processed abroad. The bimetallic ratio of silver to gold was about two to one, which meant that European and Japanese merchants made a large amount of profit. In the 1640s, the bimetallic ratios in China converged with the rest of the world, before experiencing another population boom. The new population boom was a product of the introduction of New World crops into China, mainly sweet potatoes, which could be more easily grown. By this time, the silver mines in Japan were largely depleted and the New World became China's primary source for silver.\n\nInitially, Japan served as China's primary source for silver in the 16th Century. In exchange for silver, China would provide Japan with silk and gold. Japan and China did not directly trade with each other, due to political tensions. This meant that European entities and countries, such as the Dutch and Portuguese served as a middle man between the two countries.\n\nIn the famed \"The Wealth of Nations,\" Adam Smith noted the sheer force and great reach of the global silver trade. He was impressed by its market value but more intrigued with the way this single item of commerce brought together new and old worlds i.e. the Americas and China. Although China acted as the cog running the wheel of global trade, Japan's huge contribution of silver exports to China were critical to the world economy and China's liquidity and success with the commodity. Historians posit Europeans would have been left out of world trade, and China may have fallen prey to conquest by settlers of the Americas if not for Japanese silver mining. Silver was paramount to East Asia's introduction into the global trade market. Under the Ming and Qing empires, China hoarded silver to boost its economy and increase its trading power.\n\nMany historians argue that silver was responsible for the birth of global economics and trade. According to this view, global trade commenced in 1571 when Manila was founded and became the first trading post linking America and Asia due to the expansive and profitable silver trade. In fact, research shows the amount of silver traveling from Manila to China was approximately three million pesos or 94,000 kilograms in the early 1600s.\n\nThe rarity of silver production was seen as an opportunity for China to control the currency's value and support its own national currency. Silver was one of the only accepted trade items from Europeans and its value in China was astronomical compared to rest of the world. In fact, its value was twice that of Spain in the 16th and 17th centuries. Between 1600 and 1800 China received 100 tons of silver on average per year. A large populace near the Lower Yangzte averaged a hundreds of taels of silver per household in the late 16th century.\n\nSilver even played a large role when defending Toyotomi Hideyoshi's attemptive take over of Ming ruled Joseon Korea. The Ming Ministiry of War sent approximately 140,000 liang of silver to its soldiers and required provinces to provide silver as tax for the war effort as well. In the sixteenth century, the daimyos of Southwest Japan hoped for unhinged global trade but were stopped due to Ming China trade policies. Still, Japan became a player in the global economy via frequent Ming merchant ships arriving to extract Japan's abundance of silver and exchange goods. Japan increased its wealth through successful trilateral trade with Portugal and China as Japan now had Chinese goods to offer the Portuguese who had silver mines of their own. Founder of the Ming China dynasty, Hongwu, actually sought to eliminate silver from the market due to his fear of inflation which he previously experienced in the Yuan dynasty. His attempt involved imposing harsh limits on silver mining to stop its flow into the market and subsequently replaced it with baochao or paper money. However, the currency never popularized and silver proved its mainstay as a global currency.\n\nDespite some restrictions, silver continued to drive trade through its popularity in Europe. This, combined with a high British demand for Chinese tea, created chronic trade deficits for European governments, which were forced to risk silver deficits to supply merchants in Asia. As supplies of silver decreased in Europe, Europeans had less ability to purchase highly coveted Chinese goods. Merchants were no longer able to sustain the China trade through profits made by selling Chinese goods in the West and were forced to take bullion out of circulation in Europe to buy goods in China.\n\nIn the 19th century, American merchants began to introduce opium to Chinese markets. The demand for opium rose rapidly and was so profitable that Chinese opium dealers began to seek out more suppliers of the drug, thus inaugurating the opium trade; one merchant declared that Opium \"is like gold. It can sell any time.\" From 1804 to 1820, a period when the Qing Dynasty needed to finance the suppression of the White Lotus Rebellion, Chinese merchants were soon exporting silver to pay for opium rather than Europeans paying for Chinese goods with the precious metal.\n\nThe Qing imperial court debated whether and how to end the opium trade, eventually settling on regulations on consumption. That measure, however, resulted in an increase in drug smuggling by Europeans and Chinese traders. In 1810, the Daoguang Emperor issued an edict concerning the matter, declaring, \"Opium has a harm. Opium is a poison, undermining our good customs and morality. Its use is prohibited by law.\" Following a debate at court in 1836 on whether to legalize the drug or crack down on its use, the emperor decided on the latter. An upright official, Commissioner Lin Zexu led the campaign against opium as a kind of \"drug czar.\" The British, offended by the seizure of their property in opium, sent a large naval expedition to China to end the restrictive conditions under which they had long traded with that country. Thus began the first Opium War, in which Britain's industrialized military might was proven in China's rout. The Treaty of Nanking, which ended the war in 1842 largely on British terms, imposed numerous restrictions on Chinese sovereignty and opened five ports to European traders.\n\n"}
{"id": "50835353", "url": "https://en.wikipedia.org/wiki?curid=50835353", "title": "Health systems strengthening", "text": "Health systems strengthening\n\nHealth systems strengthening (also health system strengthening, abbreviated HSS) is a term used in global health that roughly means to improve the health care system of a country. Within this general definition, it can mean increasing funding for health infrastructure, improving health policy, trying to achieve universal healthcare, or any number of other health measures.\n\nThere has been some effort to use a systems thinking approach to health systems strengthening.\n\nVarious health organizations have claimed to use health systems strengthening (while not necessarily agreeing on the definition). Some of these are:\n\n\nBoth the idea of health systems strengthening and the term itself have received attention.\n\nEven advocates of health systems strengthening admit that it can often seem like a \"distant, even abstract aim\".\n\nMarchal et al., writing in 2009, called the term \"vague\" and argued that \"most current HSS strategies are selective (i.e., they target a specific disease), and their effects may undermine progress towards the long-term goal of effective, high-quality, and inclusive health systems.\"\n\nPeter Berman, who was the lead health economist at the World Bank, has pointed out that \"Almost any support to health interventions can be considered HSS\".\n\n"}
{"id": "15729059", "url": "https://en.wikipedia.org/wiki?curid=15729059", "title": "International health", "text": "International health\n\nInternational health, also called geographic medicine, international medicine, or global health, is a field of health care, usually with a public health emphasis, dealing with health across regional or national boundaries. One subset of international medicine, travel medicine, prepares travelers with immunizations, prophylactic medications, preventive techniques such as bednets and residual pesticides, in-transit care, and post-travel care for exotic illnesses. International health, however, more often refers to health personnel or organizations from one area or nation providing direct health care, or health sector development, in another area or nation. It is this sense of the term that is explained here. More recently, public health experts have become interested in global processes that impact on human health. Globalization and health, for example, illustrates the complex and changing sociological environment within which the determinants of health and disease express themselves.\n\nThe World Health Organization (WHO) is the international body primarily responsible for regulating and governing health-related policies and practices across nations. While the WHO uses various policies and treaties to address international health issues, many of their policies have no binding power and thus state compliance is often limited. As a result, a Framework Convention on Global Health (FCGH) has recently been proposed as a global health treaty that would use stronger domestic accountability mechanisms (including incentives & sanctions) in order to close national and global health inequities. However, some scholars have addressed concerns regarding the FCGH, arguing that it would duplicate other global health governance efforts, lack feasibility, and have limited impact in regulating global health.\n\nMuch work in international health is performed by non-governmental organizations, or NGOs. Services provided by international health NGOs include direct health care, community potable water, vitamin supplementation, and mitigation of endemic and epidemic infectious diseases and malnutrition. Examples of NGOs dedicated to international health include:\n\nThese organizations often go in harm's way to provide services to people affected by natural disaster or conflict. For example, Médecins Sans Frontières has lost members in the Darfur area, and Care International's Iraq Director, Margaret Hassan (a long-time Iraq resident with dual Iraqi-British citizenship) was brutally murdered on the Internet by Al Qaeda-affiliated terrorists for the \"crime\" of providing services equitably among Iraqis. International Medical Corps was begun in response to the suffering of the Afghan people after the Soviet invasion of 1979, and is adept at providing services in dangerous places (see Attacks on humanitarian workers).\n\nHealth-related NGOs also provide capacity development in areas of need; that is, helping nations develop sustainable domestic health solutions through training programs. An example of this type of aid is the Center for International Rehabilitation, which has provided rehabilitation training for Iraqi physical therapists, physicians, and rehabilitation clinic managers in Tuzla, Bosnia and Amman, Jordan. These trainees then care for amputees, spinal and head injury patients in their home country.\n\nOne important characteristic of NGO work is that, in the \"pure\" sense, they provide services based solely upon need, without political, ethnic, religious or other considerations. Thus, strictly speaking, religious missionary organizations that perform services as part of a proselytizing or evangelical campaign should be separated from the NGO category and simply be referred to as religious missionary organizations. Some religious relief organizations do provide services more as a duty or \"charity\", however, without requirements for the recipients to attend any preaching, prayer or other religious preconditions.ngo\n\nAs NGO practice evolves parallel with technology, NGOs have developed more scientific and precise methods of assessment, planning and operations in humanitarian assistance and complex emergencies. One example is the Sphere Project's Humanitarian Charter and Minimum Standards in Disaster Response. They have taken other new tools into the planning offices and field: in addition to the obligatory laptop computer, they typically rely heavily upon cellular and satellite communications, the Internet, and geographic information services, or GIS. These technological improvements allow them to better focus efforts in areas of need, respond to evolving crises, and predict future needs. Indeed, in a related effort, the United States Holocaust Museum teamed with Google Earth to establish baseline GIS photos of crisis-torn Darfur, updating them at intervals, and uploading them to the Internet for public access. Since Internet \"surfers\" can browse these images and see where once-present villages are later obliterated, this teamwork gave lie to the Sudanese claim that it was engaging in neither ethnic cleansing nor genocide.\n\nIn another teamwork effort, the Assistant Secretary of Defense (Health Affairs) of the United States Department of Defense, as the DoD's senior medical officer, established the International Health Division in late 2007 to help coordinate military health doctrine and practices in international development. The International Health Division places great emphasis upon working with NGOs to provide sustainable, culturally-appropriate development activities around the world. While critics maintain that DoD does not provide aid equitably and without regard to political influence, the Asian tsunami of December, 2004 (due to the 2004 Indian Ocean earthquake) demonstrated that DoD was capable of working in a supporting role without regard to geopolitical gain. Indeed, the DoD was surprised at the unexpected degree of improvement in American prestige as a result of its role in Southeast Asia and months later, in the Pakistan earthquake. A similar event resulted in rapid mobilization of DoD resources in response to the 2007 Peru earthquake, Bangladeshi Typhoon Sidr and Tropical Storm Nero in the Dominican Republic, all in the last half of 2007, with no reasonable expectation of material gain for America.\n\nIn 2005, then-Secretary of Defense Donald Rumsfeld signed DoD Directive 3000.05, \"Stability, Security, Transition and Reconstruction Operations\". This document requires the DoD to assign Stability, Security, Transition and Reconstruction (SSTR) the same importance in planning and preparation as it gives to warfighting.\n\nThe rationale for SSTR is intuitive: stability promotes rule of law and economic development. These provide the base for essential services such as education, public health and sanitation, law enforcement and fire suppression. Essential services, in turn, lead to increased stability and economic opportunity. Health in the general population, and in particular the labor force, is essential to productivity and consequent stability.\n\nAlthough these relationships are not necessarily linear, and there is no inherent guarantee of equitable distribution of wealth in a developing society, full employment and hope for the future may be powerful disincentives to conflict. In this way, the DoD, through SSTR operations, expects to prevent some potential conflicts and criminal activities.\n\nThe International Health Division, charged with policy implications of DoDD 3000.05, is located within the Office of the ASD(HA), reporting through Force Health Protection & Readiness. International Health develops DoD's policy on medical ethics and the practice of medicine in international health and development settings. International Health also identifies needs in developing nations and looks for non-governmental organizations (NGOs), intergovernmental organizations, and private voluntary organizations (PVOs) such as professional societies, that have the ability and expertise to address these problems. In this way, the NGOs develop helping relationships with the nations or regions they work in, fostering stability and sustainability.\n\nOther DoD international health activities occurring on a regular basis include medical civic action projects (MEDCAPs), in which Army, Navy or Air Force medical assets provide direct care, sanitation, and other public health services to host nation (HN) locals. Such MEDCAPs are generally traced to the Vietnam war, when medical units and medical personnel assigned to combat units would organize field medical care to Vietnamese, Hmong and others. There is a growing realization among the military that MEDCAP care may not be the best model, if the result is merely handing out antibiotics for upper respiratory infections and anti-inflammatories for aches and pains. However, projects such as de-worming, dentistry, prenatal education and care, and veterinary care, when performed in conjunction with HN health authorities and the local health infrastructure, have indisputable and long-lasting benefits to the recipients.\n\nSimilar to MEDCAPs, the military performs Medical Readiness Training Exercises (MEDRETEs), Joint Combined Exchange Training (JCET), and Humanitarian-Civic Action (HCA) exercises, all of which may have direct and indirect services as a feature of the training.\n\nFinally, the military has unparalleled logistical and lift capabilities to respond to humanitarian assistance/disaster response(HADR) needs.\n\nIn conjunction with the Uniformed Services University of the Health Sciences (USUHS), the Center for Disaster and Humanitarian Medicine (CDHAM) develops curriculum, teaches disaster and humanitarian assistance principles to graduate, medical, and post-doctoral students and publishes courses on incident command and other related topics. The handbook on military-NGO relations, \"A Guide to Non-Governmental Organizations for the Military\" is available free on-line.\n\nAmong more recent developments in the area, the formation of the American College of Academic International Medicine (ACAIM) provided a renewed impetus toward the consolidation and formalization of U.S. based coordination of Academic International Medicine (AIM) efforts across the multiple currently existing platforms . Since its inception, ACAIM galvanized the U.S. AIM community to action, highlighting the need for the formation of cross-disciplinary, bi-directional International Medical Programs (IMPs) that foster the sustainable development of AIM efforts while minimizing the deleterious effects of brain drain.\n\nAnother novel and unique aspect of ACAIM's overall mission and postulate is the need for healthcare institutions, both academic and non-academic, to recognize faculty efforts dedicated to International Medical Program development as valid expressions of academic contribution that should be granted credit equivalence with U.S. based medical outreach efforts. Within such proposed framework, faculty members would receive academic RVU based credit for international work, with academic tracks formally recognizing International Medical Program contributions as equivalent to any other academic or educational work.\n\n"}
{"id": "1078772", "url": "https://en.wikipedia.org/wiki?curid=1078772", "title": "Largest naval battle in history", "text": "Largest naval battle in history\n\nThe title of the \"largest naval battle in history\" is disputed between adherents of different criteria which include the numbers of personnel and/or vessels involved in the battle, and the total tonnage of the vessels involved. While battles fought in modern times are comparatively well-documented, the figures from those in pre-Renaissance times are generally believed to be exaggerated by contemporary chroniclers.\n\n\nNotes\n\nBibliography\n"}
{"id": "46383774", "url": "https://en.wikipedia.org/wiki?curid=46383774", "title": "List of Madonna records and achievements", "text": "List of Madonna records and achievements\n\nAmerican singer Madonna, throughout her career, spanning three decades, has obtained a remarkable series of statistical achievements, setting and breaking several world records with her participation in entrepreneurial activities, of acting and her performance in the musical scene for her videos, singles, albums, and tours.\n\nHer first appearance in the \"Guinness Book of World Records\" was in 1986 with her third studio album, \"True Blue\". Since then, she has earned multiple appearances, some 20 at least in February 2012, including her insigne record title as the top-selling female recording artist of all time. Madonna's commerciality has achieved scrutiny studies and analysis from different point of view in the academia world or by marketers, through her marketing strategies, controversies and reinvention, surpassing to others new or contemporary artists. In popular culture, many international artists have been called \"Madonna\", many times, by their impact and success in their respective countries or genres. Also, her presence in popular culture, has been led to create world records about Madonna. Dubbed as the most successful and most influential female artist of all time,\n\nWhen she reached number one with \"Music\" in 2000 at Billboard Hot 100, it made Madonna the second artist to achieve number one hits on the Hot 100 in the 1980s, 1990s and 2000s. Also, when she released \"Who's That Girl\" in 1987 it became Madonna's sixth number-one single in the United States, making her the first artist to accumulate six number-one singles in the 1980s, and the first female performer to get that many number-ones as a solo act. In 2012, with \"Give Me All Your Luvin'\" she became the second female with highest number of \"Billboard\" Hot 100 singles by female artists, only behind Aretha Franklin. The song is her 56th appearance on the chart. In 1991, with \"Rescue Me\" when it debuted at No. 15 on the March 2, 1991 Hot 100 chart, it marked the highest-ever bow for a single by a woman. Further, it was —at the time— one of only four titles to debut in the top 20. Madonna is the third oldest female to place a number one at the Billboard Hot 100. The single \"Music\" reached the number-one spot when Madonna was forty-two years one month old (September 2000). She holds the record with 38 singles within the Top 10, most for any artist.\n\nShe has 46 number-one songs in the chart —the most for any artist. Also, is the only active artist to chart continuously since 1982, spanning four decades. \"Billboard\" said: \"comparing her chart champs by decade, Madonna scored nine Dance/Club Songs No. 1s in the '80s and 13 in the '90s. Since 2000, she has almost doubled her total, adding 18 No. 1s in that span\". In 2012, when she release \"Girl Gone Wild\", became her 42nd No. 1 on the record chart, \"Billboard\" said that she has the quickest span of back-to-back No. 1s. Also, the magazine declared that \"essentially, if Madonna releases a single and it charts on Dance/Club Play Songs, it's a safe bet to assume it'll go to No. 1. Since 2000, she's placed 26 hits on the survey. Of those, all but six have gone all the way to No. 1. Also, Madonna is the only artist in history to achieve seven top-ten hits from one album (\"American Life\") and the only artist ever to achieve seven consecutive number-one hits on this chart twice.\n\n\"Give Me All Your Luvin'\" set a record chart, when it debuted at 24 in the Dance/Club Play Songs chart and rose to 9 the next week, having the fastest rising to the top 10 for a song ever \"Hung Up\" became the most successful dance song of the 2000s in the United States, by topping the Dance/Club Play Songs Decade-end tally and \"Music\" became the second most-successful dance song of decade, reaching number two on the record chart. Furthermore, \"Music\" was also the longest-running number one song on Dance/Club Play Songs in the 2000s, with a longevity of five weeks at number one.\n\nShe is the second female artist with most number ones albums, with 8, behind only Barbra Streisand, who has 10 number one albums. Her other achievements on the record chart, tied with Beyoncé as the female artist with most consecutive number-one albums. Also, in 1984 Madonna was the first female to sell over 5 million albums in the US in a single year with \"Like a Virgin\". Madonna is the artist with most top 10 albums on the Billboard 200, with 21 (20 in 2012, with \"MDNA\") George Strait places second with 17 top 10s, followed by Mariah Carey (16). Also, she is the female artist with most number-two albums on Billboard's Top 200 Albums, with six, tied with The Beatles and behind Frank Sinatra's seven\n\nHer albums \"The Immaculate Collection\", \"Like a Virgin\" and \"True Blue\" are among the top 100 certified albums according to the RIAA, with \"The Immaculate Collection\" and \"Like a Virgin\" becoming in one of the best-selling albums in United States with a diamond status. As of 2015, she is the eighth artist with most number-one albums. However, she has a record for the biggest second week sales drop in history in Nielsen SoundScan era with her twelfth studio album, \"MDNA\".\n\nWhen she released \"Open Your Heart\" in Australia, it reached a peak of number 16, breaking a run of nine consecutive top ten singles for Madonna in that country. She is tied with Australian singer Kylie Minogue, having 10 number one singles.\nShe have debuted her albums at number one for nine occasions, with \"Rebel Heart\" her last album, it became Madonna's 19th week atop the chart, ranking her at number 24 on the list of artists with most accumulated weeks at the top. She has 11 number one albums, tied with U2.\n\nShe has a total of 25 #1 singles in Canada — the most for any artist in spanning four decades: 1980s, 1990s, 2000s and 2010s. Only two of these number one singles belong to Canadian Hot 100 and the rest of Canadian RPM singles chart. Her 2000 single \"Music\" was the last number one hit on the Canadian RPM singles chart. Also, she has sixty-eight Top 40, fifty-nine Top 20, fifty-one Top 10 and thirty-nine Top 5 singles. \"4 Minutes\" debuted at the top of the Canadian Contemporary Hit Radio chart. This marked the first time any song entered at the top of the CHR chart in BDS history. With \"Music and \"American Pie\" was the first time in Canadian chart history that an artist held the top two positions on the year-end musical charts.\n\nShe has to date, two album with diamond status in Canada with \"True Blue\" (in June 1987) and \"Like a Virgin\" (July 1992). Making her one of the few artists that have this certification. Also, she has 21 albums in the Top 5, with only 3 on the Top 20.\n\nMadonna had only three number one singles in France, but spanning three decades: 1980s, 1990s and 2000s. She has twenty-two Top 10 singles on the French Top 100 Singles charts and forty-nine Top 40, during four decades: 1980s, 1990s, 2000s and 2010s.\n\nShe has eight number one albums in France. Also, she has three albums with diamond status in France with \"True Blue\" (1,000,000), \"The Immaculate Collection\" (1,000,000) and \"Confessions on a Dancefloor\" (750,000). Also, she has ten albums number-two and three number-three albums. Generally, her albums always topped the Top 10 places in France.\n\nMadonna had four number one singles in Germany, but has fifty-eight Top 40, thirty-seven Top 20, twenty-five Top 10 and nineteen Top 5 singles.\n\nShe has one album in the top 40 best-selling albums ever in Germany, with \"Ray of Light\" sold 1.5 million units. She has number ones albums during four decades: 1980s, 1990s, 2000s and 2010s\n\nSource: Media Control Charts\n\nShe has a total of twenty-five number ones singles on Italian charts, spanning for three decades: 1980s, 1990s and 2000s. Also she has sixty-eight Top 40, sixty-five Top 20, fifty-six Top 10 and forty-five Top 5 singles.\n\nShe has a total of 15 number-one albums in Italy and 8 albums number two. Most of her albums have entered the top 5, with only two studio albums, topping the two.\n\nIn Japan, she was the only foreign artist with two albums into the best selling of the 1980 decade, with \"Like a Virgin\" (#33) and \"True Blue\" (#36).\n\nShe has a total of twenty-two singles number one and two number-two singles: \"Angel\", \"The Power of Good-Bye\", \"Don't Tell Me\", \"American Life\" and \"Give Me All Your Luvin'\".\n\nShe has ten number one albums in Spain, spanning during four decades: 1980s, 1990s, 2000s and 2010s. Also, she has twenty Top 5 albums and generally, her albums always topped the Top 20 in Spain.\n\nMadonna has 13 number one hits in United Kingdom, a record for a female recording artist, spanning her number one for three decades: 1980s, 1990s and 2000s\n\nIn 1985, Madonna became the first female artist in UK chart history to hold the top-two positions of the chart simultaneously, with \"Into the Groove\" topping number one and \"Holiday\" the second place By the end of 1985, Madonna achieved up another record with the song, becoming the first female artist to have eight UK top-ten singles in one calendar year. In 1987 when she published \"La Isla Bonita\", she became the female artist with the most number-one singles in the British chart history—a record that has since been maintained by Madonna to date Every single reached the UK Top 20 until 2008's \"Miles Away\". Also, Madonna simultaneously topped the albums and singles charts 4 times in her career, which is unmatched by any other female artist. In 2014, Official Charts Company compiled her Top 40 biggest selling singles, with \"Into the Groove\" in the top with 870,000 copies. Furthermore, Madonna had 71st Top 40 U.K. singles, the most for any female artist. Her others milestones including, eleven Top 2 singles, sixty Top 10 and forty four Top 20 singles.\n\nSource: Official Charts Company \n\nShe has 12 number-one albums with 9 studio albums —the most for any solo artist. Also, she has five number-two albums and twenty Top 5 albums, more than any other female artist. In 1986, \"True Blue\" opened at the top of the UK Albums Chart on July 12, 1986, making it the first album by American artist to debut at number one in British chart history. In 2012, with \"MDNA\" she became the first female in have an album in the number one during the 1980, 1990, 2000 and 2010. Also, Madonna and Kylie Minogue are the only artists ever to have a number-one album and a number-one single in three different decades.\n\nAccording to \"New Musical Express\" her albums \"The Immaculate Collection\" and \"Confessions on a Dance Floor\" are one of the 50 fastest selling albums ever in United Kingdom, selling 340,000 and 217,610 respectively. Making in the female artist with most entries. Both Michael Jackson, Madonna had two of the best selling albums of the decade 1980 with \"True Blue\" (#9) and \"Like a Virgin\" (#17). Also during the 2000s, she figured with two albums in the top 100 with \"Music\" and \"Confessions on a Dance Floor\" and she topped the UK chart Christmas with \"The Immaculate Collection\", making the first to the decade 1990s and occupied the record number one during nine weeks.\n\nSource: Official Charts Company \n\nIn popular culture, Madonna has generated records titles by others ways in \"Guinness Book of World Records\". They said: You might not be able to run as fast as Michael Johnson, or sell as many records as Madonna.\n\n\n\nGeneral\n\nSpecific\n\n\n\n"}
{"id": "49470944", "url": "https://en.wikipedia.org/wiki?curid=49470944", "title": "List of countries and dependencies by number of physicians", "text": "List of countries and dependencies by number of physicians\n"}
{"id": "356095", "url": "https://en.wikipedia.org/wiki?curid=356095", "title": "Longest English sentence", "text": "Longest English sentence\n\nThere have been several claims for the longest sentence in the English language, usually with claims that revolve around the longest \"printed\" sentence, because there is no limit on the possible length of a written English sentence. \n\nAt least one linguistics textbook concludes that, in theory, \"there is no longest English sentence.\" A sentence can be made arbitrarily long by successive iterations, such as \n\"Someone thinks that someone thinks that someone thinks that...,\" or by combining shorter clauses in various ways. \n\nFor example, sentences can be extended by recursively embedding clauses one into another, such as \n\nThe ability to embed structures within larger ones is called recursion. This also highlights the difference between linguistic performance and linguistic competence, because the language can support more variation than can reasonably be created or recorded.\n\nOne of the longest sentences in literature is contained in William Faulkner's \"Absalom, Absalom!\" (1936). The sentence is composed of 1,288 words (In the 1951 Random House version).\n\nAnother sentence that is often claimed to be the longest sentence ever written is Molly Bloom's soliloquy in the James Joyce novel \"Ulysses\" (1922), which contains a sentence of 3,687 words. However, this sentence is simply many sentences without punctuation.\n\nJonathan Coe's \"The Rotters' Club\" appears to hold the record at 13,955 words. It was inspired by Bohumil Hrabal's \"Dancing Lessons for the Advanced in Age\": a Czech language novel written in one long sentence.\n\n"}
{"id": "42780", "url": "https://en.wikipedia.org/wiki?curid=42780", "title": "Nordic Council", "text": "Nordic Council\n\nThe Nordic Council is the official body for formal inter-parliamentary co-operation among the Nordic countries. Formed in 1952, it has 87 representatives from Denmark, Finland, Iceland, Norway, and Sweden as well as from the autonomous areas of the Faroe Islands, Greenland, and the Åland Islands. The representatives are members of parliament in their respective countries or areas and are elected by those parliaments. The Council holds ordinary sessions each year in October/November and usually one extra session per year with a specific theme.\n\nIn 1971, the Nordic Council of Ministers, an intergovernmental forum, was established to complement the Council. The official and working languages of both the Nordic Council and the Nordic Council of Ministers are Danish, Norwegian, and Swedish, which comprise the first language of around 80% of the region's population and learned as a foreign language by the remaining 20%.\n\nThe Nordic Council and the Nordic Council of Ministers are involved in various forms of cooperation with neighbouring areas, amongst them being the Baltic Assembly and the Benelux, as well as Russia and Schleswig-Holstein.\n\nDuring World War II, Denmark and Norway were occupied by Germany; Finland was under assault by the Soviet Union; while Sweden, though neutral, still felt the war's effects. Following the war, the Nordic countries pursued the idea of a Scandinavian defence union to ensure their mutual defence. However, Finland, due to its Paasikivi-Kekkonen policy of neutrality and FCMA treaty with the USSR, could not participate.\n\nIt was proposed that the Nordic countries would unify their foreign policy and defence, remain neutral in the event of a conflict and not ally with NATO, which some were planning at the time. The United States, keen on getting access to bases in Scandinavia and believing the Nordic countries incapable of defending themselves, stated it would not ensure military support for Scandinavia if they did not join NATO. As Denmark and Norway sought US aid for their post-war reconstruction, the project collapsed, with Denmark, Norway and Iceland joining NATO.\n\nFurther Nordic co-operation, such as an economic customs union, also failed. This led Danish Prime Minister Hans Hedtoft to propose, in 1951, a consultative inter-parliamentary body. This proposal was agreed by Denmark, Iceland, Norway, and Sweden in 1952. The Council's first session was held in the Danish Parliament on 13 February 1953 and it elected Hans Hedtoft as its president. When Finnish-Soviet relations thawed following the death of Joseph Stalin, Finland joined the council in 1955.\n\nOn 2 July 1954, the Nordic labour market was created and in 1958, building upon a 1952 passport-free travel area, the Nordic Passport Union was created. These two measures helped ensure Nordic citizens' free movement around the area. A Nordic Convention on Social Security was implemented in 1955. There were also plans for a single market but they were abandoned in 1959 shortly before Denmark, Norway, and Sweden joined the European Free Trade Area (EFTA). Finland became an associated member of EFTA in 1961 and Denmark and Norway applied to join the European Economic Community (EEC).\n\nThis move towards the EEC led to desire for a formal Nordic treaty. The Treaty of Helsinki outlined the workings of the Council and came into force on 24 March 1962. Further advancements on Nordic cooperation were made in the following years: a Nordic School of Public Health, a Nordic Cultural Fund, and Nordic House in Reykjavík were created. Danish Prime Minister Hilmar Baunsgaard proposed full economic cooperation (\"Nordek\") in 1968. Nordek was agreed in 1970, but Finland then backtracked, stating that its ties with the Soviet Union meant it could not form close economic ties with potential members of the EEC (Denmark and Norway). Nordek was then abandoned.\n\nAs a consequence, Denmark and Norway applied to join the EEC and the Nordic Council of Ministers was set up in 1971 to ensure continued Nordic cooperation. In 1970 representatives of the Faroe Islands and Åland were allowed to take part in the Nordic Council as part of the Danish and Finnish delegations. Norway turned down EEC membership in 1972 while Denmark acted as a bridge builder between the EEC and the Nordics. Also in 1973, although it did not opt for full membership of the EEC, Finland negotiated a free trade treaty with the EEC that in practice removed customs duties from 1977 on, although there were transition periods up to 1985 for some products. Sweden did not apply due to its non-alliance policy, which was aimed at preserving neutrality. Greenland subsequently left the EEC and has since sought a more active role in circumpolar affairs.\n\nIn the 1970s, the Nordic Council founded the Nordic Industrial Fund, Nordtest and the Nordic Investment Bank. The Council's remit was also expanded to include environmental protection and, in order to clean up the pollution in the Baltic Sea and the North Atlantic, a joint energy network was established. The Nordic Science Policy Council was set up in 1983 and, in 1984, representatives from Greenland were allowed to join the Danish delegation.\n\nFollowing the collapse of the Soviet Union in 1991, the Nordic Council began to cooperate more with the Baltic states and new Baltic Sea organisations. Sweden and Finland joined the European Union (EU), the EEC's successor, in 1995. Norway had also applied, but once again voted against membership. However, Norway and Iceland did join the European Economic Area (EEA) which integrated them economically with the EU. The Nordic Passport Union was also subsumed into the EU's Schengen Area in 1996.\n\nThe Nordic Council became more outward-looking, to the Arctic, Baltic, Europe, and Canada. The Øresund Bridge linking Sweden and Denmark led to a large amount of cross-border travel, which in turn led to further efforts to reduce barriers. However, the initially envisioned tasks and functions of the Nordic Council have become partially dormant due to the significant overlap with the EU and EEA. In 2008 Iceland began EU membership talks, but decided to annul these in 2015.\n\nThe Nordic Council and the Nordic Council of Ministers have a particular focus on strengthening the Nordic language community; the main focus of their work to promote language understanding in the Nordic countries is on children and young people's understanding of written and oral Danish, Norwegian, and Swedish, the three mutually intelligible Scandinavian languages. Representatives of the Council have the ability to issue proposals in their own languages, and official documents are translated to cater to all five of the major Nordic languages. Discussions for bringing Finnish and Icelandic into equal footing with the three other languages has been proposed.\n\nThe Nordic Council consists of 87 representatives, elected from its members' parliaments and reflecting the relative representation of the political parties in those parliaments. It holds its main session in the autumn, while a so-called \"theme session\" is arranged in the spring. Each of the national delegations has its own secretariat in the national parliament. The autonomous territoriesGreenland, the Faroe Islands and Ålandalso have Nordic secretariats.\n\nThe Nordic Council uses the three Continental Scandinavian languages (Danish, Norwegian, and Swedish) as its official working languages, but also publishes material in Finnish, Icelandic, and English for information purposes. The council refers to Danish, Norwegian, and Swedish collectively as Scandinavian and considers them to be different forms of the same language forming a common language community. Since 1987, under the Nordic Language Convention, citizens of the Nordic countries have the opportunity to use their native language when interacting with official bodies in other Nordic countries without being liable to any interpretation or translation costs. The Convention covers visits to hospitals, job centres, the police and social security offices. The languages included are Swedish, Danish, Norwegian, Finnish, and Icelandic.\n\nThe Council does not have any formal power on its own, but each government has to implement any decisions through its national legislature. With Denmark, Norway, and Iceland being members of NATO and Finland and Sweden being neutral, the Nordic Council has not been involved in any military cooperation.\n\nThe original Nordic Council concentrates on inter-parliamentary cooperation. The \"Nordic Council of Ministers\", founded in 1971, is responsible for inter-governmental cooperation. Prime Ministers have ultimate responsibility but this is usually delegated to the Minister for Nordic Cooperation and the Nordic Committee for Co-operation, which co-ordinates the day-to-day work. The autonomous territories have the same representation as states.\n\n\nThe Nordic Council and the Council of Ministers have their headquarters in Copenhagen and various installations in each separate country, as well as many offices in neighbouring countries. The headquarters are located at Ved Stranden No. 18, close to Slotsholmen.\n\nThe Nordic Council has 8 members, 5 sovereign states and 3 self-governing regions.\n\nIn accordance with § 13 of the Rules of Procedure for the Nordic Council the Sámi Parliamentary Council is the only institution with observer status with the Nordic Council. In accordance with § 14, the Nordic Youth Council has the status of \"guest\" on a permanent basis, and the Presidium \"may invite representatives of popularly elected bodies and other persons to a session and grant them speaking rights\" as guests. According to the council, \"within the last couple of years, guests from other international and Nordic organisations have been able to take part in the debates at the Sessions. Visitors from the Baltic States and Northwest Russia are those who mostly take up this opportunity. Guests who have a connection to the theme under discussion are invited to the Theme Session.\"\n\nThe Nordic Council of Ministers has established four \"Offices outside the Nordic Region\", namely in all the Baltic states – Estonia, Latvia and Lithuania – and the German state of Schleswig-Holstein. The offices form part of the secretariat of the Nordic Council of Ministers; according to the Council of Ministers their primary mission is to promote cooperation between the Nordic countries and the Baltic states and to promote the Nordic countries in cooperation with their embassies within the Baltic states.\n\nThe Nordic Council and the Council of Ministers define Estonia, Latvia, Lithuania and Russia as \"Adjacent Areas\" and has formal cooperation with them under the Adjacent Areas policies framework; in recent years the cooperation has focused increasingly on Russia.\n\nThe Nordic Council had historically been a strong supporter of Baltic independence from the Soviet Union. During the move towards independence in the Baltic States in 1991, Denmark and Iceland pressed for the Observer Status in the Nordic Council for the then-nonsovereign Estonia, Latvia and Lithuania. The move in 1991 was opposed by Norway and Finland. The move was heavily opposed by the Soviet Union, accusing the Nordic Council of getting involved in its internal affairs. In the same year, the Nordic Council refused to give observer status for the three, at the time nonsovereign, Baltic states.\n\nWhile the Nordic Council rejected the Baltic states' application for formal observer status, the council nevertheless has extensive cooperation on different levels with all neighbouring countries, including the Baltic states and Germany, especially the state of Schleswig-Holstein. Representatives of Schleswig-Holstein were present as informal guests during a session for the first time in 2016. The state has historical ties to Denmark and cross-border cooperation with Denmark and has a Danish minority population. As parliamentary representatives from Schleswig-Holstein, a member of the South Schleswig Voter Federation and a member of the Social Democrats with ties to the Danish minority were elected. \n\nThe Sámi political structures long desired formal representation in the Nordic Council's structures, and were eventually granted observer status through the Sámi Parliamentary Council. In addition, representatives of the Sámi people are de facto included in activities touching upon their interests. In addition, the Faroe Islands have expressed their wishes for full membership in the Nordic Council instead of the current associate membership.\n\nRecently, three of the members of the Nordic Council (Sweden, Denmark and Finland, all EU-member states), the Baltic Assembly and the Benelux sought intensifying cooperation in the Digital Single Market, as well as discussing social matters, the Economic and Monetary Union of the European Union, the European migrant crisis and defense cooperation. Relations with Russia, Turkey and the United Kingdom was also on the agenda.\n\nSome desire the Nordic Council's promotion of Nordic cooperation to go much further than at present. If the states of Iceland, Sweden, Norway, Denmark and Finland were to merge in such an integration as some desire, it would command a gross domestic product of US$1.60 trillion, making it the twelfth largest economy in the world, larger than that of Australia, Spain, Mexico or South Korea. Gunnar Wetterberg, a Swedish historian and economist, wrote a book entered into the Nordic Council's year book that proposes the creation of a Nordic Federation from the Council in a few decades.\n\n\n"}
{"id": "49686904", "url": "https://en.wikipedia.org/wiki?curid=49686904", "title": "Our World In Data", "text": "Our World In Data\n\nOur World In Data (OWID) is an online publication that presents empirical research and data that show how living conditions around the world are changing. The web publication on global development uses interactive data visualisations (charts and maps) to present the research findings on development that explain the causes and consequences of the observed changes. The aim is to show how the world is changing and why.\n\nThe publication is developed at the University of Oxford and authored by social historian and development economist Max Roser. It covers a wide range of topics across many academic disciplines: Trends in health, food provision, the growth and distribution of incomes, violence, rights, wars, culture, energy use, education, and environmental changes are empirically analysed and visualised in this web publication.\n\nCovering all of these aspects in one resource makes it possible to understand how the observed long-run trends are interlinked. The research on global development is presented to the audience of interested readers, journalists, academics, and policy people. The articles cross-reference each other to make it possible for the reader to learn about the drivers of the observed long-run trends. For each topic the quality of the data is discussed and, by pointing the visitor to the sources, this website works as a database of databases – a meta-database.\n\nOur World In Data is made available as a public good: \nOur World in Data is currently financed entirely through small individual donations from readers of the publication. The website is used widely in the media. Authors like John Green and Steven Berlin Johnson use it for their work. It is used in teaching by economists, historians, and international development experts.\n\nTina Rosenberg emphasised in \"The New York Times\" that Our World In Data presents a “big picture that’s an important counterpoint to the constant barrage of negative world news”. Steven Pinker placed Roser’s Our World In Data on his list of his personal “cultural highlights” and explained in his article on 'the most interesting recent scientific news' why he considers Our World In Data so very important.\n"}
{"id": "23450639", "url": "https://en.wikipedia.org/wiki?curid=23450639", "title": "Outline of the Post-War New World Map", "text": "Outline of the Post-War New World Map\n\nThe Outline of the Post-War New World Map was a map completed before the attack on Pearl Harbor and self-published on February 25, 1942 by Maurice Gomberg of Philadelphia, United States. It shows a proposed political division of the world after World War II in the event of an Allied victory in which the United States of America, the United Kingdom, and the Soviet Union as well as the Republic of China would rule. The map includes a manifesto describing a \"New World Moral Order\", along with quotes from Roosevelt's Four Freedoms speech.\n\nGomberg created the map as a personal project, and little else is known of him. The map has been highlighted by New World Order conspiracy theorists who believe it represents some broader view of the US government, and has also been widely circulated online.\n\nThe map proposes a total of 14 independent sovereign states, 4 of them democracies and 10 of them demilitarized, and 3 \"quarantined\" states (the fate of 2 are to be eventually integrated into sovereign states).\n\nThe United States has 82 states, not including Security Outposts in the Pacific and the Atlantic, gaining all of Canada, Mexico, and Central America, among other places:\n\nStates:\nAlabama - Alberta - Alaska - Arizona - Arkansas - The Bahamas - California (historical Alta (Upper) California) - Colorado - Columbia - Connecticut - Costa Rica - Cuba - Delaware - Florida - Georgia - Greenland - Guatemala (Guatemala and Belize)\n- Haiti (including all of Hispaniola) - Honduras - Idaho - Illinois - Indiana - Iowa - Jamaica - Kansas - Keewatin (pre-1999 Northwest Territories east of the 110° meridian) - Kentucky - Labrador (mainland Newfoundland and Labrador) - Leeward Islands - Louisiana - Lower California (consisting of the Baja California peninsula) - Maine - Mackenzie (pre-1999 Northwest Territories west of the 110° meridian) - Manitoba - Maryland - Martinique - Massachusetts - Mexico (the remainder of Mexico) - Michigan - Minnesota - Mississippi - Missouri - Montana - Nevada - New Brunswick - Newfoundland (Island Newfoundland and Labrador) - New Hampshire - New Jersey - New Mexico - New York - Nicaragua - North Carolina - North Dakota - Nova Scotia - Ohio - Oklahoma - Ontario - Oregon - Panama - Pennsylvania - Prince Edward Island - Puerto Rico - Quebec - Rhode Island - El Salvador - Saskatchewan - South Carolina - South Dakota - Tennessee - Texas - Trinidad - Utah - Vermont - Virginia - Virgin Islands - Washington - West Virginia - Windward Islands - Wisconsin - Wyoming - Yukon\n\nProtectorates:\n- Celebes - Hainan - Halmahera Islands\n- Iceland - Moluccas Islands - Commonwealth of the Philippines - Taiwan\n\nPort \"Peace-security bases\":\nDakar and Freetown on the Atlantic coast of Africa\n\nThe British Commonwealth of Nations is headquartered in the United Kingdom, including England (including Wales) and Scotland, but not Northern Ireland. The Commonwealth includes the Faroe Islands and the former colonies of Madagascar (in early 1942 still a Vichy French colony), Ceylon, the Andaman Islands, Cyprus, Malta, most of Indonesia (in 1942 a Dutch colony occupied by Japan; other parts are given to the US), as well as the then British colonies that are now Singapore and Malaysian Borneo, South Georgia, the Bismarck Archipelago, the Solomon Islands, and the countries of Australia and New Zealand.\n\nPort \"Peace-security bases\":\n\nThe Soviet Union would expand to be far larger than its then-current size, expanding to 24 (later 25) Soviet Socialist Republics (while downgrading preexisting SSR's to Autonomous Soviet Socialist Republics):\n\nSoviet Socialist Republics:\nArmenia - Azerbaijan - Bulgaria - Czech Republic - Estonia - Finland - Georgia - Hungary - Iran - Latvia - Lithuania - Manchuria (Northern Manchuria) - Moldavia (all of Bessarabia) - Mongolia - Poland - Romania - Russia (which includes Kazakhstan and Kirghizia (Kyrgyzstan) - Slovakia - Tajikistan - Turkmenistan - Ukraine - Uzbekistan - White Russia (Byelorussia) - Yugoslavia\n<br>\nAt an unspecified later time, Germany (which includes Austria and former Polish territory formerly part of the Weimar Republic sans East Prussia). Germany is termed \"quarantined Germany\" until full integration\n\nEverything below the Darién Gap, and offshore islands including the Falkland Islands:\n\n- Argentina - Bolivia - Brazil - Chile - Colombia - Ecuador - Guiana - Paraguay - Peru - Uruguay - Venezuela\n\nChina (without Formosa or Hainan) - Inner Mongolia - Indo China (Cambodia, Laos, and Vietnam) - Korea - Malaya - Sinkiang - Thailand - Tibet\n\nBelgium (including Luxembourg) - France (including Monaco and all of Germany west of the Rhine river) - Netherlands - Portugal - San Marino (later included in Italy) - Spain (including Andorra) - Switzerland (including Liechtenstein) - Vatican City (later included in Italy)\n<br>\nAt an unspecified later time, Italy (which is termed \"quarantined Italy\" until full integration)\n\nDenmark (without the Faroe Islands and Greenland) - Norway (including Spitsbergen, without Jan Mayen) - Sweden\n\nBesides the port \"peace-security bases\", areas included are Algeria - Angola - Bechuanaland (Botswana) - Congo (including Burundi) - Dahomey (Benin, including Togo) - Egypt - Equatorial Africa (including Equatorial Guinea, eastern Guinea, and São Tomé and Príncipe) - Eritrea - Ethiopia (including Djibouti) - Gold Coast (Ghana) - Kenya - Liberia - Libya - Morocco - Mozambique (including southern Malawi) - Nigeria - Rhodesia (northern Malawi, Zambia, and Zimbabwe) - Senegal (including the Gambia, western Guinea, and Guinea-Bissau) - Somaliland (Somalia) - South Africa (including Lesotho and Swaziland) - South West Africa (Namibia) - Sudan - Tanganyika (including Rwanda) - Tunisia - Uganda - West Africa (including Sahrawi Arab Democratic Republic/Western Sahara and Sierra Leone, without Benin, Senegal, and Togo)\n\nAden (South Yemen) - Hejaz - Iraq (including Kuwait) - Lebanon - Oman (including Bahrain, Qatar, and United Arab Emirates) - Saudi Arabia - Syria - Yemen (North Yemen)\n\nAfghanistan - Balochistan - Bhutan - Burma - India (including Pakistan without Balochistan) - Nepal\n\nAlbania - Greece\n<br>\nPoint #24 notes the inclusion of Macedonia. that \"Macedonia\" is not clearly defined; the map seems to not include the modern country of that name, but rather labels Macedonia as Greek Macedonia.\n\nConsists of the whole of the island of Ireland\n\nIncludes all of modern Israel, Jordan and Palestine, taking in parts of modern Syria and a slice of northern Saudi Arabia.\n\nAll of Asian Turkey. European Turkey is placed under joint control of the USSR and Turkey - cf. points #27 and #28.\n\nMentioned as \"quarantined Germany\", all of Weimar Republic territory east of the Rhine river but west of the former Polish Corridor, plus Austria, eventually supposed to become a full Soviet Socialist Republic in the Soviet Union\nMentioned as \"quarantined Italy\", all of modern Italy and the Julian March (pre 1941), eventually supposed to become a full state in the United States of Europe\nMentioned as \"quarantined Japan\", all of modern Japan and Iturup, Kunashir, Shikotan, Habomai (but not including Bonin Islands). Later fate presumed to be an independent democracy\n\n\n"}
{"id": "738240", "url": "https://en.wikipedia.org/wiki?curid=738240", "title": "Oxalis corniculata", "text": "Oxalis corniculata\n\nOxalis corniculata, the creeping woodsorrel, also called procumbent yellow sorrel or sleeping beauty, resembles the common yellow woodsorrel, \"Oxalis stricta\". It is a somewhat delicate-appearing, low-growing, herbaceous plant in the family Oxalidaceae. It has a narrow, creeping stem that readily roots at the nodes. The trifoliate leaves are subdivided into three rounded leaflets and resemble a clover in shape. Some varieties have green leaves, while others, like \"Oxalis corniculata\" var. \"atropurpurea\", have purple. The leaves have inconspicuous stipules at the base of each petiole.\n\nThe fruit is a narrow, cylindrical capsule, long, and noteworthy for its explosive discharge of the contained seeds, long.\n\nThis species is cosmopolitan in its distribution, and its place of origin is unknown, but it is considered an Old World plant. It is regarded as a weed in gardens, agricultural fields, and lawns.\n\nThe leaves of woodsorrel are quite edible, with a tangy taste of lemons. A drink can be made by infusing the leaves in hot water for about 10 minutes, sweetening and then chilling. The entire plant is rich in vitamin C. Any woodsorrel is safe in low dosages, but if eaten in large quantities over a length of time can inhibit calcium absorption by the body.\n\n"}
{"id": "24255", "url": "https://en.wikipedia.org/wiki?curid=24255", "title": "Pandemic", "text": "Pandemic\n\nA pandemic (from Greek πᾶν \"pan\" \"all\" and δῆμος \"demos\" \"people\") is an epidemic of infectious disease that has spread across a large region; for instance multiple continents, or even worldwide.\n\nA widespread endemic disease that is stable in terms of how many people are getting sick from it is not a pandemic. Further, flu pandemics generally exclude recurrences of seasonal flu. Throughout history, there have been a number of pandemics, such as smallpox and tuberculosis. One of the most devastating pandemics was the Black Death, which killed over 75 million people in 1350. The most recent pandemics include the HIV pandemic as well as the 1918 and 2009 H1N1 pandemics.\n\nA pandemic is an epidemic occurring on a scale which crosses international boundaries, usually affecting a large number of people. Pandemics can also occur in important agricultural organisms (livestock, crop plants, fish, tree species) or in other organisms.\n\nThe World Health Organization (WHO) has a six-stage classification that describes the process by which a novel influenza virus moves from the first few infections in humans through to a pandemic. This starts with the virus mostly infecting animals, with a few cases where animals infect people, then moves through the stage where the virus begins to spread directly between people, and ends with a pandemic when infections from the new virus have spread worldwide and it will be out of control until we stop it.\n\nA disease or condition is not a pandemic merely because it is widespread or kills many people; it must also be infectious. For instance, cancer is responsible for many deaths but is not considered a pandemic because the disease is not infectious or contagious.\n\nIn a virtual press conference in May 2009 on the influenza pandemic, Dr Keiji Fukuda, Assistant Director-General \"ad interim\" for Health Security and Environment, WHO said \"An easy way to think about pandemic … is to say: a pandemic is a global outbreak. Then you might ask yourself: 'What is a global outbreak'? Global outbreak means that we see both spread of the agent … and then we see disease activities in addition to the spread of the virus.\"\n\nIn planning for a possible influenza pandemic, the WHO published a document on pandemic preparedness guidance in 1999, revised in 2005 and in February 2009, defining phases and appropriate actions for each phase in an aide memoir entitled \"WHO pandemic phase descriptions and main actions by phase\". The 2009 revision, including definitions of a pandemic and the phases leading to its declaration, were finalized in February 2009. The pandemic H1N1 2009 virus was neither on the horizon at that time nor mentioned in the document. All versions of this document refer to influenza. The phases are defined by the spread of the disease; virulence and mortality are not mentioned in the current WHO definition, although these factors have previously been included.\n\nHIV originated in Africa, and spread to the United States via Haiti between 1966 and 1972. AIDS is currently a pandemic, with infection rates as high as 25% in southern and eastern Africa. In 2006, the HIV prevalence rate among pregnant women in South Africa was 29.1%. Effective education about safer sexual practices and bloodborne infection precautions training have helped to slow down infection rates in several African countries sponsoring national education programs. Infection rates are rising again in Asia and the Americas. The AIDS death toll in Africa may reach 90–100 million by 2025.\n\nThere have been a number of significant pandemics recorded in human history, generally zoonoses which came about with domestication of animals, such as influenza and tuberculosis. There have been a number of particularly significant epidemics that deserve mention above the \"mere\" destruction of cities:\n\n\nEncounters between European explorers and populations in the rest of the world often introduced local epidemics of extraordinary virulence. Disease killed part of the native population of the Canary Islands in the 16th century (Guanches). Half the native population of Hispaniola in 1518 was killed by smallpox. Smallpox also ravaged Mexico in the 1520s, killing 150,000 in Tenochtitlán alone, including the emperor, and Peru in the 1530s, aiding the European conquerors. Measles killed a further two million Mexican natives in the 17th century. In 1618–1619, smallpox wiped out 90% of the Massachusetts Bay Native Americans. During the 1770s, smallpox killed at least 30% of the Pacific Northwest Native Americans. Smallpox epidemics in 1780–1782 and 1837–1838 brought devastation and drastic depopulation among the Plains Indians. Some believe that the death of up to 95% of the Native American population of the New World was caused by Old World diseases such as smallpox, measles, and influenza. Over the centuries, the Europeans had developed high degrees of immunity to these diseases, while the indigenous peoples had no such immunity.\n\nSmallpox devastated the native population of Australia, killing around 50% of Indigenous Australians in the early years of British colonisation. It also killed many New Zealand Māori. As late as 1848–49, as many as 40,000 out of 150,000 Hawaiians are estimated to have died of measles, whooping cough and influenza. Introduced diseases, notably smallpox, nearly wiped out the native population of Easter Island. In 1875, measles killed over 40,000 Fijians, approximately one-third of the population. The disease devastated the Andamanese population. Ainu population decreased drastically in the 19th century, due in large part\nto infectious diseases brought by Japanese settlers pouring into Hokkaido.\n\nResearchers concluded that syphilis was carried from the New World to Europe after Columbus' voyages. The findings suggested Europeans could have carried the nonvenereal tropical bacteria home, where the organisms may have mutated into a more deadly form in the different conditions of Europe. The disease was more frequently fatal than it is today. Syphilis was a major killer in Europe during the Renaissance. Between 1602 and 1796, the Dutch East India Company sent almost a million Europeans to work in Asia. Ultimately, only less than one-third made their way back to Europe. The majority died of diseases. Disease killed more British soldiers in India than war.\n\nAs early as 1803, the Spanish Crown organized a mission (the Balmis expedition) to transport the smallpox vaccine to the Spanish colonies, and establish mass vaccination programs there. By 1832, the federal government of the United States established a smallpox vaccination program for Native Americans. From the beginning of the 20th century onwards, the elimination or control of disease in tropical countries became a driving force for all colonial powers. The sleeping sickness epidemic in Africa was arrested due to mobile teams systematically screening millions of people at risk. In the 20th century, the world saw the biggest increase in its population in human history due to lessening of the mortality rate in many countries due to medical advances. The world population has grown from 1.6 billion in 1900 to an estimated 7 billion today.\n\nSince it became widespread in the 19th century, cholera has killed tens of millions of people.\n\n. Influenza A (H3N2) viruses still circulate today.\n\nTyphus is sometimes called \"camp fever\" because of its pattern of flaring up in times of strife. (It is also known as \"gaol fever\" and \"ship fever\", for its habits of spreading wildly in cramped quarters, such as jails and ships.) Emerging during the Crusades, it had its first impact in Europe in 1489, in Spain. During fighting between the Christian Spaniards and the Muslims in Granada, the Spanish lost 3,000 to war casualties, and 20,000 to typhus. In 1528, the French lost 18,000 troops in Italy, and lost supremacy in Italy to the Spanish. In 1542, 30,000 soldiers died of typhus while fighting the Ottomans in the Balkans.\n\nDuring the Thirty Years' War (1618–1648), about 8 million Germans were killed by bubonic plague and typhus. The disease also played a major role in the destruction of Napoleon's \"Grande Armée\" in Russia in 1812. During the retreat from Moscow, more French military personnel died of typhus than were killed by the Russians. Of the 450,000 soldiers who crossed the Neman on 25 June 1812, fewer than 40,000 returned. More military personnel were killed from 1500–1914 by typhus than from military action. In early 1813, Napoleon raised a new army of 500,000 to replace his Russian losses. In the campaign of that year, over 219,000 of Napoleon's soldiers died of typhus. Typhus played a major factor in the Irish Potato Famine. During World War I, typhus epidemics killed over 150,000 in Serbia. There were about 25 million infections and 3 million deaths from epidemic typhus\nin Russia from 1918 to 1922. Typhus also killed numerous prisoners in the Nazi concentration camps and Soviet prisoner of war camps during World War II. More than 3.5 million Soviet POWs died out of the 5.7 million in Nazi custody.\n\nSmallpox was a contagious disease caused by the variola virus. The disease killed an estimated 400,000 Europeans per year during the closing years of the 18th century. During the 20th century, it is estimated that smallpox was responsible for 300–500 million deaths. As recently as the early 1950s, an estimated 50 million cases of smallpox occurred in the world each year. After successful vaccination campaigns throughout the 19th and 20th centuries, the WHO certified the eradication of smallpox in December 1979. To this day, smallpox is the only human infectious disease to have been completely eradicated, and one of two infectious viruses ever to be eradicated.\n\nHistorically, measles was prevalent throughout the world, as it is highly contagious. According to the U.S. National Immunization Program, 90% of people were infected with measles by age 15. Before the vaccine was introduced in 1963, there were an estimated 3–4 million\ncases in the U.S. each year. Measles killed around 200 million people worldwide over the last 150 years. In 2000 alone, measles killed some 777,000 worldwide out of 40 million cases globally.\n\nMeasles is an endemic disease, meaning that it has been continually present in a community, and many people develop resistance. In populations that have not been exposed to measles, exposure to a new disease can be devastating. In 1529, a measles outbreak in Cuba killed two-thirds of the natives who had previously survived smallpox. The disease had ravaged Mexico, Central America, and the Inca civilization.\n\nOne-third of the world's current population has been infected with \"Mycobacterium tuberculosis\", and new infections occur at a rate of one per second. About 5–10% of these latent infections will eventually progress to active disease, which, if left untreated, kills more than half of its victims. Annually, 8 million people become ill with tuberculosis, and 2 million people die from the disease worldwide. In the 19th century, tuberculosis killed an estimated one-quarter of the adult population of Europe; by 1918, one in six deaths in France were still caused by tuberculosis. During the 20th century, tuberculosis killed approximately 100 million people. TB is still one of the most important health problems in the developing world.\n\nLeprosy, also known as Hansen's disease, is caused by a bacillus, \"Mycobacterium leprae\". It is a chronic disease with an incubation period of up to five years. Since 1985, 15 million people worldwide have been cured of leprosy.\n\nHistorically, leprosy has affected people since at least 600 BC. Leprosy outbreaks began to occur in Western Europe around 1000 AD. Numerous \"leprosaria\", or leper hospitals, sprang up in the Middle Ages; Matthew Paris estimated that in the early 13th century, there were 19,000 of them across Europe.\n\nMalaria is widespread in tropical and subtropical regions, including parts of the Americas, Asia, and Africa. Each year, there are approximately 350–500 million cases of malaria. Drug resistance poses a growing problem in the treatment of malaria in the 21st century, since resistance is now common against all classes of antimalarial drugs, except for the artemisinins.\n\nMalaria was once common in most of Europe and North America, where it is now for all purposes non-existent. Malaria may have contributed to the decline of the Roman Empire. The disease became known as \"Roman fever\". \"Plasmodium falciparum\" became a real threat to colonists and indigenous people alike when it was introduced into the Americas along with the slave trade. Malaria devastated the Jamestown colony and regularly ravaged the South and Midwest of the United States. By 1830, it had reached the Pacific Northwest. During the American Civil War, there were over 1.2 million cases of malaria among\nsoldiers of both sides. The southern U.S. continued to be afflicted with millions of cases of malaria into the 1930s.\n\nYellow fever has been a source of several devastating epidemics. Cities as far north as New York, Philadelphia, and Boston were hit with epidemics. In 1793, one of the largest yellow fever epidemics in U.S. history killed as many as\n5,000 people in Philadelphia—roughly 10% of the population. About half of the residents had fled the city, including President George Washington. In colonial times, West Africa became known as \"the white man's grave\" because of malaria and yellow fever.\n\nViral hemorrhagic fevers such as Ebola virus disease, Lassa fever virus, Rift Valley fever, Marburg virus and Bolivian hemorrhagic fever are highly contagious and deadly diseases, with the theoretical potential to become pandemics. Their ability to spread efficiently enough to cause a pandemic is limited, however, as transmission of these viruses requires close contact with the infected vector, and the vector only has a short time before death or serious illness. Furthermore, the short time between a vector becoming infectious and the onset of symptoms allows medical professionals to quickly quarantine vectors, and prevent them from carrying the pathogen elsewhere. Genetic mutations could occur, which could elevate their potential for causing widespread harm; thus close observation by contagious disease specialists is merited.\n\nAntibiotic-resistant microorganisms, sometimes referred to as \"superbugs\", may contribute to the re-emergence of diseases which are currently well controlled. For example, cases of tuberculosis that are resistant to traditionally effective treatments remain a cause of great concern to health professionals. Every year, nearly half a million new cases of multidrug-resistant tuberculosis (MDR-TB) are estimated to occur worldwide. China and India have the highest rate of multidrug-resistant TB. The World Health Organization (WHO) reports that approximately 50 million people worldwide are infected with MDR TB, with 79 percent of those cases resistant to three or more antibiotics. In 2005, 124 cases of MDR TB were reported in the United States. Extensively drug-resistant tuberculosis (XDR TB) was identified in Africa in 2006, and subsequently discovered to exist in 49 countries, including the United States. There are about 40,000 new cases of XDR-TB per year, the WHO estimates.\n\nIn the past 20 years, common bacteria including \"Staphylococcus aureus\", \"Serratia marcescens\" and Enterococcus, have developed resistance to various antibiotics such as vancomycin, as well as whole classes of antibiotics, such as the aminoglycosides and cephalosporins. Antibiotic-resistant organisms have become an important cause of healthcare-associated (nosocomial) infections (HAI). In addition, infections caused by community-acquired strains of methicillin-resistant \"Staphylococcus aureus\" (MRSA) in otherwise healthy individuals have become more frequent in recent years. \n\nIn 2003 the Italian physician Carlo Urbani (1956–2003) was the first to identify severe acute respiratory syndrome (SARS) as a new and dangerously contagious disease, although he became infected and died. It is caused by a coronavirus dubbed SARS-CoV. Rapid action by national and international health authorities such as the World Health Organization helped to slow transmission and eventually broke the chain of transmission, which ended the localized epidemics before they could become a pandemic. However, the disease has not been eradicated. It could re-emerge. This warrants monitoring and reporting of suspicious cases of atypical pneumonia.\n\nWild aquatic birds are the natural hosts for a range of influenza A viruses. Occasionally, viruses are transmitted from these species to other species, and may then cause outbreaks in domestic poultry or, rarely, in humans.\n\nIn February 2004, avian influenza virus was detected in birds in Vietnam, increasing fears of the emergence of new variant strains. It is feared that if the avian influenza virus combines with a human influenza virus (in a bird or a human), the new subtype created could be both highly contagious and highly lethal in humans. Such a subtype could cause a global influenza pandemic, similar to the Spanish Flu, or the lower mortality pandemics such as the Asian Flu and the Hong Kong Flu.\n\nFrom October 2004 to February 2005, some 3,700 test kits of the 1957 Asian Flu virus were accidentally spread around the world from a lab in the US.\n\nIn May 2005, scientists urgently called upon nations to prepare for a global influenza pandemic that could strike as much as 20% of the world's population.\n\nIn October 2005, cases of the avian flu (the deadly strain H5N1) were identified in Turkey. EU Health Commissioner Markos Kyprianou said: \"We have received now confirmation that the virus found in Turkey is an avian flu H5N1 virus. There is a direct relationship with viruses found in Russia, Mongolia and China.\" Cases of bird flu were also identified shortly thereafter in Romania, and then Greece. Possible cases of the virus have also been found in Croatia, Bulgaria and the United Kingdom.\n\nBy November 2007, numerous confirmed cases of the H5N1 strain had been identified across Europe. However, by the end of October, only 59 people had died as a result of H5N1, which was atypical of previous influenza pandemics.\n\nAvian flu cannot yet be categorized as a \"pandemic\", because the virus cannot yet cause sustained and efficient human-to-human transmission. Cases so far are recognized to have been transmitted from bird to human, but as of December 2006, there have been very few (if any) cases of proven human-to-human transmission. Regular influenza viruses establish infection by attaching to receptors in the throat and lungs, but the avian influenza virus can only attach to receptors located deep in the lungs of humans, requiring close, prolonged contact with infected patients, and thus limiting person-to-person transmission.\n\nAn outbreak of Zika virus began in 2015 and strongly intensified throughout the start of 2016, with over 1.5 million cases across more than a dozen countries in the Americas. The World Health Organisation warned that Zika had the potential to become an explosive global pandemic if the outbreak was not controlled.\n\nIn 2016, the Commission on a Global Health Risk Framework for the Future estimated that pandemic disease events would cost the global economy over $6 trillion in the 21st century - over $60 billion per year. The same report also recommended spending $4.5 billion annually on global prevention and response capabilities to reduce the threat posed by pandemic events.\n\nIn 1346, the bodies of Mongol warriors who had died of plague were thrown over the walls of the besieged Crimean city of Kaffa (now Theodosia). After a protracted siege, during which the Mongol army under Jani Beg was suffering the disease, they catapulted the infected corpses over the city walls to infect the inhabitants. It has been speculated that this operation may have been responsible for the arrival of the Black Death in Europe.\n\nThe Native American population was devastated after contact with the Old World by introduction of many fatal diseases. In a well documented case of germ warfare involving British commander Jeffery Amherst and Swiss-British officer Colonel Henry Bouquet, their correspondence included a proposal and agreement to give smallpox-infected blankets to Indians in order to \"Extirpate this Execrable Race\". During the siege of Fort Pitt late in the French and Indian War, as recorded in his journal by sundries trader and militia Captain, William Trent, on June 24, 1763, dignitaries from the Delaware tribe met with Fort Pitt officials, warned them of \"great numbers of Indians\" coming to attack the fort, and pleaded with them to leave the fort while there was still time. The commander of the fort refused to abandon the fort. Instead, the British gave as gifts two blankets, one silk handkerchief and one linen from the smallpox hospital to two Delaware Indian dignitaries. A devastating smallpox epidemic plagued Native American tribes in the Ohio Valley and Great Lakes area through 1763 and 1764, but the effectiveness of individual instances of biological warfare remains unknown. After extensive review of surviving documentary evidence, historian Francis Jennings concluded the attempt at biological warfare was \"unquestionably effective at Fort Pitt\"; Smallpox after Pontiac's Rebellion killed 400,000–500,000 (possibly even up to 1.5 million) Native Americans.\n\nDuring the Sino-Japanese War (1937–1945), Unit 731 of the Imperial Japanese Army conducted human experimentation on thousands, mostly Chinese. In military campaigns, the Japanese army used biological weapons on Chinese soldiers and civilians. Plague fleas, infected clothing, and infected supplies encased in bombs were dropped on various targets. The resulting cholera, anthrax, and plague were estimated to have killed around 400,000 Chinese civilians.\n\nDiseases considered for or known to be used as a weapon include anthrax, ebola, Marburg virus, plague, cholera, typhus, Rocky Mountain spotted fever, tularemia, brucellosis, Q fever, machupo, Coccidioides mycosis, Glanders, Melioidosis, Shigella, Psittacosis, Japanese B encephalitis, Rift Valley fever, yellow fever, and smallpox.\n\nSpores of weaponized anthrax were accidentally released from a military facility near the Soviet closed city of Sverdlovsk in 1979. The Sverdlovsk anthrax leak is sometimes called \"biological Chernobyl\". In January 2009, an Al-Qaeda training camp in Algeria was reportedly wiped out by the plague, killing approximately 40 Islamic extremists. Some experts said that the group was developing biological weapons, however, a couple of days later the Algerian Health Ministry flatly denied this rumour stating \"No case of plague of any type has been recorded in any region of\nAlgeria since 2003\".\n\nPandemics appear in multiple fiction works. A common use is in disaster films, where the protagonists must avoid the effects of the plague, for example zombies.\n\nLiterature\n\nFilm\n\nTelevision\n\nGames\n\nNotes\nFurther reading\n\n"}
{"id": "33863280", "url": "https://en.wikipedia.org/wiki?curid=33863280", "title": "Pathogens and Global Health", "text": "Pathogens and Global Health\n\nPathogens and Global Health is a peer-reviewed medical journal published by Maney Publishing. It covers tropical diseases, including their microbiology, epidemiology and molecular biology, as well as medical entomology, HIV/AIDS, malaria, and tuberculosis. The editor-in-chief is Andrea Crisanti (Imperial College London).\n\nThe journal was established by Sir Ronald Ross in 1906 as \"Annals of Tropical Medicine and Parasitology\" to share the results of the Liverpool School of Tropical Medicine's research and field expeditions. In May 2011, the journal was purchased by Maney Publishing, obtaining its current title in 2012, reflecting a broader focus including the biology, immunology, genetics, treatment, and control of pathogens of medical relevance beyond a regional definition.\n\nThe journal is abstracted and indexed in:\n\nAccording to the \"Journal Citation Reports\", the journal has a 2014 impact factor of 1.656.\n\n"}
{"id": "38530392", "url": "https://en.wikipedia.org/wiki?curid=38530392", "title": "Per Fugelli", "text": "Per Fugelli\n\nPer Fugelli (7 December 1943 – 13 September 2017) was a Norwegian physician and professor of General Practice at the University of Bergen from 1984 to 1992, and social medicine at the University of Oslo from 1992 until his death in 2017.\n\nFugelli was born in Stavanger, Norway, on December 7, 1943. He studied medicine at University of Oslo.\n\nFrom 1971–73 Fugelli was a general practitioner in Værøy and Røst, and from 1977 to 1980 in Porsanger. During this time he earned his PhD and graduated in 1978. In 1984, he became a Professor of General Practice at the University of Bergen, where he stayed until 1992. He became a Professor of social medicine at University of Oslo´s Institute of Health and Society. In 2013, he became Emeritus.\n\nIn 1993 Fugelli wrote: \"The patient Earth is sick. Global environmental disruptions can have serious consequences for human health. It's time for doctors to give a world diagnosis and advise on treatment,\" predating the founding of planetary health. He is the subject of the documentary \"I die\" by filmmaker Erik Poppe.\n\nHe was a frequent contributor to the public debate on health and medical questions. Among his early books are \"Tilbake til huslegen\" from 1975, \"Doktor på Værøy og Røst\" from 1977, and \"Helsetilstand og helsetjeneste på Værøy og Røst\" from 1978.\n\nHe published the essay collections \"Med sordin og kanon\" and \"Helse og rettferdighet\" in 1990, \"0-visjonen\" in 2003, and \"Nokpunktet\" in 2008. He has been editor or co-editor of several works, including \"Huslegen\" from 1985, \"Medisinsk leksikon\" from 1990, \"Medisin og helse\" from 1993, and \"Verdier og penger i helsetjenesten\" from 2009.\n\nFugelli was married, had two children, and three grandchildren by the time he died.\n\nIn 2009, he was diagnosed with colorectal cancer. It metastasized into his lungs and by 2012, the cancer was declared terminal. Nevertheless, Fugelli continued to write and work as long as he was able, with his final published article written six weeks before his death. He died at Jæren on 13 September 2017, aged 73.\n\nFugelli won the 2010 Karl Evang Prize and in 2013, the Freedom of Expression Foundation Prize. \n"}
{"id": "23151656", "url": "https://en.wikipedia.org/wiki?curid=23151656", "title": "Rise Against Hunger", "text": "Rise Against Hunger\n\nRise Against Hunger, formerly Stop Hunger Now, is an international hunger relief non-profit organization that coordinates the packaging and distribution of food and other life-changing aid to people in developing nations. Founded in 1998, Rise Against Hunger mobilizes more than 350,000 volunteers each year to package meals for people in need around the globe. Since 2005, Rise Against Hunger has distributed more than 315,000,000 meals to recipients in 74 countries with a mission to end hunger in our lifetime.\n\nRise Against Hunger is an international hunger relief agency that seeks to end global hunger by engaging local volunteers. The organization was formed in 1998 by Ray Buchanan, a United Methodist Minister, and began its meal packaging program in 2005. The organizational mission is stated as \"Rise Against Hunger is driven by the vision of a world without hunger. Its mission is to end hunger in our lifetime by providing food and life-changing aid to the world’s most vulnerable and creating a global commitment to mobilize the necessary resources.\"\n\nRise Against Hunger aims to end hunger through four pathways: Nourishing Lives, Responding to Emergencies, Empowering Communities and Growing the Movement. From the implementation of sustainable development community projects to the meal packaging program that utilizes local volunteers, Rise Against Hunger strives to make a global impact on hunger by building resilience, self-sufficiency and empowerment among the world’s most vulnerable populations. \n\nRise Against Hunger supports safety net programs that support nourishment and skills trainings that help the world’s most vulnerable navigate the difficult journey out of poverty. Rise Against Hunger partners with schools in order to promote and incentivize increased attendance. Additionally, Rise Against Hunger works to partner with skills trainings and clinics in order to support adults learning new trades and encourage healthy lifestyles. Rise Against Hunger works to nourish lives through a holistic approach in the development of the most vulnerable populations.\n\nRise Against Hunger responds to emergencies. In times of floods, droughts or political unrest, to name a few, Rise Against Hunger aims to provide the immediate critical need, food. Access to food, wages and market systems are often destroyed in times of emergency. Rise Against Hunger works with its in-country partner organizations in order to address the immediate needs in the wake of crisis. Each year Rise Against Hunger reserves 10% of its projected meals to respond to crisis situations. Official Rise Against Hunger responses include the 2016 Hurricane Matthew, Syrian conflict, South Sudanese conflict and 2010 Haiti earthquake.\n\nIn order to create long-term solutions to hunger and poverty, Rise Against Hunger works to empower communities through agricultural and income-generating initiatives. Rise Against Hunger works to increase agriculture production and incomes through programs that promote improved agricultural methods, business skills and market access. Farmers, one of the most food insecure populations in the world, are given access to quality seeds and fertilizers to increase agricultural production and diversify their crops. Rise Against Hunger supports vocational training to help at-risk individuals increase their earning potentials and gain consistent access to food.\n\nPart of Rise Against Hunger’s mission is to create a global commitment to mobilize the necessary resources to end hunger. Rise Against Hunger works with volunteer groups from communities of faith, corporations, schools and civic clubs to package meals while developing a greater awareness of hunger-related issues. Additionally, Rise Against Hunger engages its supporters to participate in advocacy activities to work toward changing laws, policies, systems and attitudes to end hunger by 2030.\n\nThe assembly process combines rice, soy, dehydrated vegetables and a micronutrient flavoring mix formulated by Kraft Heinz Company Foundation that includes 23 essential vitamins and minerals. The cost of each meal varies between 29 and 34 cents. The food has a shelf-life of two years.\nRise Against Hunger provides over 70% of its meals to support transformational development programs such as school lunch programs, vocational training programs, early childhood development programs, orphanages, and medical clinics. Working with these programs helps enhance lives by giving beneficiaries the opportunity to break the cycle of poverty through education, skills development, and healthcare while also receiving much needed nutrition.\n\nRise Against Hunger supports partner organizations in developing countries by providing direct financial assistance to support ongoing programs that provide food, medicines or other basic necessities to impoverished populations. This program enables Rise Against Hunger to respond to crises immediately by working with organizations already on the ground. It also supports local economies in developing areas and promotes self-reliance.\n\n"}
{"id": "19946174", "url": "https://en.wikipedia.org/wiki?curid=19946174", "title": "Schøyen Collection", "text": "Schøyen Collection\n\nThe Schøyen Collection is the largest private manuscript collection in the world, mostly located in Oslo and London. Formed in the 20th century by Martin Schøyen, it comprises manuscripts of global provenance, spanning 5,000 years of history. It contains more than 13,000 manuscript items; the oldest is about 5,300 years old. There are manuscripts from 134 different countries and territories, representing 120 distinct languages.\n\nThe variety of manuscripts—geographic, linguistic, textual and material—even more than its size makes the Schøyen Collection unique. The collection has a website with many items illustrated and described. The provenance of the various cuneiform materials held by the Schøyen Collection remains subject to controversy.\n\nAmong the most notable items of the collection are the following:\n\n"}
{"id": "14253151", "url": "https://en.wikipedia.org/wiki?curid=14253151", "title": "The General Crisis", "text": "The General Crisis\n\nThe General Crisis is the term used by some historians to describe the period of widespread conflict and instability that occurred from the early 17th century to the early 18th century in Europe and in more recent historiography in the world at large. The concept is much debated by historians and there is no consensus.\n\nThe term was coined by Eric Hobsbawm in his pair of 1954 articles entitled \"The Crisis of the Seventeenth Century\" published in \"Past and Present\".         \n\nAs a historiographic concept, the place of the general crisis was cemented by Hugh Trevor-Roper, in a 1959 article entitled \"The General Crisis of the Seventeenth Century\" published in the same journal. Hobsbawm discussed an economic crisis in Europe; Trevor-Roper saw a wider crisis, \"a crisis in the relations between society and the State\". Trevor-Roper argued that the middle years of the 17th century in Western Europe saw a widespread break-down in politics, economics and society caused by a complex series of demographic, religious, economic and political problems. In this \"general crisis\", various events such as the English Civil War, the Fronde in France, the climax of the Thirty Years' War in the Holy Roman Empire and revolts against the Spanish Crown in Portugal, Naples and Catalonia were all manifestations of the same problem. The most important cause of the \"general crisis\", in Trevor-Roper’s opinion, was the conflict between \"Court\" and \"Country\"; that is between the increasingly powerful centralizing, bureaucratic, sovereign princely states represented by the court, and the traditional, regional, land-based aristocracy and gentry representing the country. In addition, the intellectual and religious changes introduced by the Renaissance and the Protestant Reformation were important secondary causes of the \"general crisis\".\n\nThere were various controversies regarding the \"general crisis\" thesis between historians. Some simply denied the existence of any such crisis. For instance, Hobsbawm saw the problems of 17th-century Europe as being social and economic in origin – an emphasis than Trevor-Roper would not concede.        \n\nSubsequent historians interested in the General Crisis include Geoffrey Parker, who has authored a book on the subject.        \n\nMany historians have argued the 17th century was an era of crisis. Many other historians have rejected the idea. Today there are historians who promote the crisis model, arguing it provides an invaluable insight into the warfare, politics, economics, and even art. The Thirty Years War (1618–48) focused attention on the massive horrors that wars could bring to entire populations. The 1640s in particular saw more state breakdowns around the world than any previous or subsequent period. The Polish–Lithuanian Commonwealth, the largest state in Europe, temporarily disappeared. In addition, there were secessions and upheavals in several parts of the Spanish Empire, the world’s first global empire. In Britain the entire Stuart monarchy (Kingdom of England, Kingdom of Scotland, Kingdom of Ireland, and British America) rebelled. Political insurgency and a spate of popular revolts seldom equaled shook the foundations of most states in Europe and Asia. More wars took place around the world in the mid-17th century than in almost any other period of recorded history. The crises spread far beyond Europe—for example Ming China, the most populous state in the world, collapsed.\n\nChina’s Ming dynasty and Japan’s Tokugawa shogunate had radically different economic, social, and political systems. However, they experienced a series of crises during the mid-17th century that were at once interrelated and strikingly similar to those occurring in other parts of the world at the same time. Frederic Wakeman argues that the crisis which destroyed the Ming dynasty was partly a result of the climatic change as well as China’s already significant involvement in the developing world economy. Bureaucratic dishonesty worsened the problem. Moreover, the Qing dynasty’s success in dealing with the crisis made it more difficult for it to consider alternative responses when confronted with severe challenges from the West in the 19th century.\n\nExamples which have been given for general crisis and state breakdown during this period include:\n\nPrecious metals from newly discovered deposits in America, especially silver from Potosí in modern Bolivia and from Mexico, were shipped by Spain to China as well as to Europe. Silver was less prevalent in China than in Europe and consequently more valuable. The continuous flow of silver from the New World caused a continuous flow of wealth from China to Spain. The silver imports also caused general price inflation throughout Europe. Rapid population growth until the mid-decades of the seventeenth century also initially contributed to inflation in some areas.\n\nFor those who extend the General Crisis outside Europe, one symptom is dramatic population decline. For example, with the collapse of the Ming Dynasty the population of China fell by approximately 50 million between 1600 and 1644, a decrease of over 30%. Likewise, Germany's population was reduced by approximately 15% to 30% in the Thirty Years War. The Polish-Lithuanian Commonwealth also lost about a third of its population. Many theories have been proposed as to why population dropped so rapidly during this period. Renowned economist Robert Malthus proposed the theory of population limitation as a result of carrying capacity. In his theory, food supplies simply did not grow as fast as population. As such, the subsistence gap between food and population created a check on the population. In applying this theory to the demographic crisis of this period, much focus has been placed on the growth and expansion of the \"new\" monarchies of late medieval Europe. These newly centralized and bureaucratized monarchies with their greater demands for war placed greater demands on the populaces of their realms. The previously mentioned climatic change also helped to exacerbate these new problems of war.\n\nThe General Crisis overlaps fairly neatly with the Little Ice Age which some authorities locate in the 17th century. Of particular interest is the overlap with the Maunder Minimum. Across the Northern Hemisphere, the mid-17th century experienced almost unprecedented death rates. Geoffrey Parker has suggested that environmental factors may have been in part to blame, especially the global cooling trend of this period.\n\n\n"}
{"id": "3870084", "url": "https://en.wikipedia.org/wiki?curid=3870084", "title": "The Globalization of World Politics", "text": "The Globalization of World Politics\n\nThe Globalization of World Politics: An Introduction to International Relations is a book by John Baylis, Patricia Owens, and Steve Smith.\n\nJohn Baylis, Steve Smith and Patricia Owens: Introduction\nThe historical context\nTheories of world politics\nStructures and processes\nInternational issues\nGlobalization in the future\n"}
{"id": "50166890", "url": "https://en.wikipedia.org/wiki?curid=50166890", "title": "Timeline of global health", "text": "Timeline of global health\n\nThis page is a timeline of global health, including major conferences, interventions, cures, and crises.\n\nDuring this pre-WWII era, there are three big trends that operate separately, but sometimes affect each other in development and outcomes.\n\nFirst, a trend of urbanization (fueled by the Industrial Revolution) as well as greater global trade and migration leads to new challenges, including those in urban sanitation and infectious diseases/pandemics. Six global cholera pandemics happen in this period because of increased commerce and migration.\n\nSecond, there is a lot of development on the underlying theory of disease, advancements in vaccine and antibiotic development, and a variety of experimental large-scale eradication and control programs. One big example: the germ theory of diseases begins to become accepted and popularized starting around 1850. Another big example is the development of the smallpox vaccine by Edward Jenner in 1796. Systematic eradication and control efforts include the Rockefeller Sanitary Commission and efforts to eradicate smallpox. Antitoxins and vaccines for numerous diseases including cholera and tuberculosis are developed during this period, building on a trend of greater understanding of and control over microorganisms.\n\nA third theme during this era is the formation of various preliminary international alliances and conferences, including the International Sanitary Conferences, Pan American Health Organization, Office International d'Hygiène Publique, and the League of Nations Health Committee. This is closely intertwined with the other two trends. For instance, the cholera pandemics mentioned above, as well as the growing scientific understanding of the germ theory of disease, are both key impetuses for the International Sanitary Conferences.\n\nFollowing the end of World War II, the first batch of big organizations, both international and national (with international cooperation), including the United Nations and World Health Organization (WHO), form. Beginning with the United Nations Relief and Rehabilitation Administration for relief of victims of war in 1943, there is a big push to begin creating large scale health initiatives, non-governmental organizations, and worldwide global health programs by the United Nations to improve quality of life around the world. UNICEF, the World Health Organization, as well as the UNRRA are all part of United Nations efforts to benefit global health beginning with developing countries. These various programs aim to aid in economic endeavors by providing loans, direct disease prevention programs, health education, etc.\n\nAfter wrapping up complications caused by the end of the war, there is an international energy put in into eradication, beginning with the complete smallpox eradication in 1979. There is greater dissatisfaction with WHO for its focus on disease/infection control at the expense of trying to improve general living conditions, as well as disappointment at its low budget and staffing. This atmosphere spurs other organizations to provide their own forms of aid. The Alma Ata Declaration and selective primary healthcare are created to express urgent action by all governments and citizens to protect and promote the health of all people equally. More organizations form following these new active attitudes toward global health, including the International Agency for Research on Cancer and the Doctors Without Borders organization. Publications like the WHO Model List of Essential Medicines highlight basic medicines required by most adults and children to survive, and set priorities for healthcare fund allocation in developing countries. Generally, there is more buy-in for the idea that direct, targeted efforts to address healthcare could be worthwhile and benefit many countries.\n\nCertain specific efforts increase in efficiency and productivity, including improvement in maternal and child health and a focus on HIV/AIDS, tuberculosis, and malaria (the 'Big Three') in developing countries. During this time period, the child survival revolution (CSR), which helps reduce child mortality in the developing world, and GOBI-FFF are both advocated by James P. Grant. The World Summit for Children also takes place, becoming one of the largest ever gathering of heads of states and government to commit a set of goals to improve the well-being of children. Finally, HIV/AIDS becomes the focus of many governmental and non-governmental organizations, leading to the formation of the Global Programme on AIDS (GPA) by efforts of the World Health Organization. However, these health organizations also make significant advancements to tuberculosis treatments, including the DOTS strategy and the formation of the Stop TB Partnership.\n\nUN's Millennium Development Goals establishes health care as an important goal (not just combating infectious diseases). Later in 2015, the Sustainable Development Goals build on the MDGs to outline the objectives that will transform our world by ending poverty, helping the environment, and improving health and education. More specific disease-targeting organizations are created primarily to fund healthcare plans in developing countries, including the President's Emergency Plan for AIDS Relief and The Global Fund to Fight AIDS, Tuberculosis and Malaria. These organizations (especially the WHO) adopt new strategies and initiatives, including the 3 by 5 Initiative to widen the access to antiretroviral treatment, the WHO Framework Convention on Tobacco Control, etc. Private large donors such as the Bill & Melinda Gates Foundation begin to play an important role in shaping the funding landscape and direction of efforts in global health.\n\nThe following events are selected for inclusion in the timeline:\n\n\nWe do \"not\" include:\n\n\n\n\n\n"}
{"id": "889672", "url": "https://en.wikipedia.org/wiki?curid=889672", "title": "Tropical disease", "text": "Tropical disease\n\nTropical diseases are diseases that are prevalent in or unique to tropical and subtropical regions. The diseases are less prevalent in temperate climates, due in part to the occurrence of a cold season, which controls the insect population by forcing hibernation. However, many were present in northern Europe and northern America in the 17th and 18th centuries before modern understanding of disease causation. The initial impetus for tropical medicine was to protect the health of colonialists, notably in India under the British Raj. Insects such as mosquitoes and flies are by far the most common disease carrier, or vector. These insects may carry a parasite, bacterium or virus that is infectious to humans and animals. Most often disease is transmitted by an insect \"bite\", which causes transmission of the infectious agent through subcutaneous blood exchange. Vaccines are not available for most of the diseases listed here, and many do not have cures.\n\nHuman exploration of tropical rainforests, deforestation, rising immigration and increased international air travel and other tourism to tropical regions has led to an increased incidence of such diseases.\n\nIn 1975 the Special Programme for Research and Training in Tropical Diseases (TDR) was established to focus on neglected infectious diseases which disproportionately affect poor and marginalized populations in developing regions of Africa, Asia, Central America and South America. It was established at the World Health Organization, which is the executing agency, and is co-sponsored by the United Nations Children's Fund, United Nations Development Programme, the World Bank and the World Health Organization.\n\nTDR's vision is to foster an effective global research effort on infectious diseases of poverty in which disease endemic countries play a pivotal role. It has a dual mission of developing new tools and strategies against these diseases, and to develop the research and leadership capacity in the countries where the diseases occur. The TDR secretariat is based in Geneva, Switzerland, but the work is conducted throughout the world through many partners and funded grants.\n\nSome examples of work include helping to develop new treatments for diseases, such as ivermectin for onchocerciasis (river blindness); showing how packaging can improve use of artemesinin-combination treatment (ACT) for malaria; demonstrating the effectiveness of bednets to prevent mosquito bites and malaria; and documenting how community-based and community-led programmes increases distribution of multiple treatments. TDR history\n\nThe current TDR disease portfolio includes the following entries:\n\n\nAdditional neglected tropical diseases include:\n\nSome tropical diseases are very rare, but may occur in sudden epidemics, such as the Ebola hemorrhagic fever, Lassa fever and the Marburg virus. There are hundreds of different tropical diseases which are less known or rarer, but that, nonetheless, have importance for public health.\n\nThe so-called \"exotic\" diseases in the tropics have long been noted both by travelers, explorers, etc., as well as by physicians. One obvious reason is that the hot climate present during all the year and the larger volume of rains directly affect the formation of breeding grounds, the larger number and variety of natural reservoirs and animal diseases that can be transmitted to humans (zoonosis), the largest number of possible insect vectors of diseases. It is possible also that higher temperatures may favor the replication of pathogenic agents both inside and outside biological organisms. Socio-economic factors may be also in operation, since most of the poorest nations of the world are in the tropics. Tropical countries like Brazil, which have improved their socio-economic situation and invested in hygiene, public health and the combat of transmissible diseases have achieved dramatic results in relation to the elimination or decrease of many endemic tropical diseases in their territory.\n\nClimate change, global warming caused by the greenhouse effect, and the resulting increase in global temperatures, are possibly causing tropical diseases and vectors to spread to higher altitudes in mountainous regions, and to higher latitudes that were previously spared, such as the Southern United States, the Mediterranean area, etc. For example, in the Monteverde cloud forest of Costa Rica, global warming enabled Chytridiomycosis, a tropical disease, to flourish and thus force into decline amphibian populations of the Monteverde Harlequin frog. Here, global warming raised the heights of orographic cloud formation, and thus produced cloud cover that would facilitate optimum growth conditions for the implicated pathogen, B. dendrobatidis.\n\nSome of the strategies for controlling tropical diseases include: \n\n\n\n\n"}
{"id": "6629974", "url": "https://en.wikipedia.org/wiki?curid=6629974", "title": "WHO Collaborating Centres", "text": "WHO Collaborating Centres\n\nWorld Health Organization Collaborating Centres are institutions such as research institutes, parts of universities or academies from \"over 700 institutions in 80 countries\" that work with WHO in disciplines such as occupational health, food safety, and communicable disease prevention. The participating institutions partner with WHO to perform research, provide training, or offer other services in furthering the WHO health agenda. These partners are designated by the WHO director-general as a part of a collaborative network. By using networks of established organizations, WHO is able to strengthen the scientific validity of its work and lower the costs of research.\n\nThe World Health Organization has established networks related to a variety of health topics. For example, WHO has put in place centres focused on organ transplants, hearing loss prevention, hepatitis, leprosy, ethics, and maternal health. To move the work forward, WHO has numerous designated centres in each inhabited continent. The network of centres for reference and research on influenza draws upon resources from Japan, the United States, the United Kingdom, and Australia. The network of WHO collaborating centres in occupational health is chaired by Dr. John Howard, director of the U.S. National Institute for Occupational Safety and Health, and contains more than 60 designated organizations from across the globe.\n"}
{"id": "6872117", "url": "https://en.wikipedia.org/wiki?curid=6872117", "title": "World Englishes", "text": "World Englishes\n\nWorld Englishes is a term for emerging localized or indigenized varieties of English, especially varieties that have developed in territories influenced by the United Kingdom or the United States. The study of World Englishes consists of identifying varieties of English used in diverse sociolinguistic contexts globally and analyzing how sociolinguistic histories, multicultural backgrounds and contexts of function influence the use of English in different regions of the world.\n\nThe issue of World Englishes was first raised in 1978 to examine concepts of regional Englishes globally. Pragmatic factors such as appropriateness, comprehensibility and interpretability justified the use of English as an international and intra-national language. In 1988, at a Teachers of English to Speakers of Other Languages (TESOL) conference in Honolulu, Hawaii, the International Committee of the Study of World Englishes (ICWE) was formed. In 1992, the ICWE formally launched the International Association for World Englishes (IAWE) at a conference of \"World Englishes Today\", at the University of Illinois, USA. There is now an academic journal devoted to the study of this topic, titled \"World Englishes\".\n\nCurrently, there are approximately 75 territories where English is spoken either as a first language (L1) or as an unofficial or institutionalized second language (L2) in fields such as government, law and education. It is difficult to establish the total number of Englishes in the world, as new varieties of English are constantly being developed and discovered.\n\nThe notions of World English and World Englishes are far from similar, although the terms are often mistakenly used interchangeably. \"World English\" refers to the English language as a lingua franca used in business, trade, diplomacy and other spheres of global activity, while \"World Englishes\" refers to the different varieties of English and English-based creoles developed in different regions of the world. Alternatively, the term \"Global Englishes\" has been used by scholars in the field to emphasise the more recent spread of English due to globalization, which has resulted in increased usage of English as a lingua franca.\n\nEnglish is a West Germanic language that originated from the Anglo-Frisian dialects brought by Germanic invaders into Britain. Initially, Old English was a diverse group of dialects, reflecting the varied origins of the Anglo-Saxon kingdoms of England. Eventually, one of these dialects, Late West Saxon, came to dominate.\n\nThe original Old English language was then influenced by two further waves of invasion: the first by speakers of the Scandinavian branch of the Germanic language family, who conquered and colonized parts of Britain in the 8th and 9th centuries; the second by the Normans in the 11th century, who spoke Old Norman and ultimately developed a Norman variety called Anglo-Norman. For two centuries after the Norman Conquest, French became the language of everyday life among the upper classes in England. Although the language of the masses remained English, the bilingual character of England in this period was thus formed.\n\nDuring the Middle English period, France and England experienced a process of separation. This period of conflicting interests and feelings of resentment was later termed the Hundred Years' War. By the beginning of the 14th century, English had regained universal use and become the principal tongue of all England, but not without having undergone significant change.\n\nDuring the Renaissance, patriotic feelings regarding English brought about the recognition of English as the national language of England. The language was advocated as acceptable for learned and literary use. With the Great Vowel Shift, the language in this period matured to a standard and differed significantly from the Middle English period, becoming recognizably \"modern\".\n\nBy the 18th century, three main forces were driving the direction of the English language: (1) to reduce the language to rule and effect a standard of correct usage; (2) to refine the language by removing supposed defects and introducing certain improvements; and (3) to fix English permanently in the desired form. This desire for system and regularity in the language contrasted with the individualism and spirit of independence characterized by the previous age.\n\nBy the 19th century, the expansion of the British Empire, as well as global trade, had led to the spread of English around the world. The rising importance of some of England's larger colonies and former colonies, such as the rapidly developing United States, enhanced the value of the English varieties spoken in these regions, encouraging the belief, among the local populations, that their distinct varieties of English should be granted equal standing with the standard of Great Britain.\n\nThe first diaspora involved relatively large-scale migrations of mother-tongue English speakers from England, Scotland and Ireland predominantly to North America and the Caribbean, Australia, South Africa and New Zealand. Over time, their own English dialects developed into modern American, Canadian, West Indian, South African, Australian, and New Zealand Englishes. In contrast to the English of Great Britain, the varieties spoken in modern North America and Caribbean, South Africa, Australia, and New Zealand have been modified in response to the changed and changing sociolinguistic contexts of the migrants, for example being in contact with indigenous Native American, Khoisan and Bantu, Aboriginal or Maori populations in the colonies.\n\nThe second diaspora was the result of the colonization of Asia and Africa, which led to the development of 'New Englishes', the second-language varieties of English. In colonial Africa, the history of English is distinct between West and East Africa. English in West Africa began with trade. particularly the slave trade. English soon gained official status in what are today Gambia, Sierra Leone, Ghana, Nigeria and Cameroon, and some of the pidgin and creoles which developed from English contact, including Krio (Sierra Leone) and Cameroon Pidgin, have large numbers of speakers now.\n\nAs for East Africa, extensive British settlements were established in what are now Kenya, Uganda, Tanzania, Malawi, Zambia and Zimbabwe, where English became a crucial language of the government, education and the law. From the early 1960s, the six countries achieved independence in succession; but English remained the official language and had large numbers of second language speakers in Uganda, Zambia, Zimbabwe and Malawi (along with Chewa).\n\nEnglish was formally introduced to the sub-continent of South Asia (India, Bangladesh, Pakistan, Sri Lanka, Nepal and Bhutan) during the second half of the eighteenth century. In India, English was given status through the implementation of Macaulay 'Minute' of 1835, which proposed the introduction of an English educational system in India. Over time, the process of 'Indianisation' led to the development of a distinctive national character of English in the Indian sub-continent.\n\nBritish influence in South-East Asia and the South Pacific began in the late eighteenth century, involving primarily the territories now known as Singapore, Malaysia and Hong Kong. Papua New Guinea, also a British protectorate, exemplified the English-based pidgin - Tok Pisin.\n\nThe Americans came late in South-East Asia but their influence spread like wildfire as their reforms on education in the Philippines progressed in their less than half a century colonization of the islands. English has been taught since the American period and is one of the official languages of the Philippines. Ever since English became the official language, a localized variety gradually emerged - Philippine English. Lately, linguist Wilkinson Daniel Wong Gonzales argued that this variety has in itself more varieties, suggesting that we move towards Philippine Englishes paradigm to progress further in Schneider's dynamic model after gathering evidences of such happening.\n\nNowadays, English is also learnt in other countries in neighbouring areas, most notably in Taiwan, Japan and Korea, with the latter two having begun to consider the possibility of making English their official second language.\n\nThe spread of English around the world is often discussed in terms of three distinct groups of users, where English is used respectively as:\n\n\n The most influential model of the spread of English is Braj Kachru's model of World Englishes. In this model the diffusion of English is captured in terms of three Concentric Circles of the language: The Inner Circle, the Outer Circle, and the Expanding Circle.\n\nThe Inner Circle refers to English as it originally took shape and was spread across the world in the first diaspora. In this transplantation of English, speakers from England carried the language to Australia, New Zealand and North America. The Inner Circle thus represents the traditional historical and sociolinguistic bases of English in regions where it is now used as a primary language: the United Kingdom, the United States, Australia, New Zealand, Ireland, anglophone Canada and South Africa, and some of the Caribbean territories. English is the native language or mother tongue of most people in these countries. The total number of English speakers in the inner circle is as high as 380 million, of whom some 120 million are outside the United States.\n\nThe Outer Circle of English was produced by the second diaspora of English, which spread the language through imperial expansion by Great Britain in Asia and Africa. In these regions, English is not the native tongue, but serves as a useful lingua franca between ethnic and language groups. Higher education, the legislature and judiciary, national commerce and so on may all be carried out predominantly in English. This circle includes India, Nigeria, Bangladesh, Pakistan, Malaysia, Tanzania, Kenya, non-Anglophone South Africa, the Philippines (colonized by the US) and others. The total number of English speakers in the outer circle is estimated to range from 150 million to 300 million. Singapore, while in the Outer Circle, may be drifting into the Inner Circle as English becomes more often used as a home language (see Languages of Singapore), much as Ireland did earlier. Countries where most people speak an English-based creole and retain standard English for official purposes, such as Jamaica and Papua New Guinea, are also in the Outer Circle.\n\nFinally, the Expanding Circle encompasses countries where English plays no historical or governmental role, but where it is nevertheless widely used as a medium of international communication. This includes much of the rest of the world's population not categorized above, including territories such as China, Russia, Japan, non-Anglophone Europe (especially the Netherlands and Nordic countries), South Korea, Egypt and Indonesia. The total in this expanding circle is the most difficult to estimate, especially because English may be employed for specific, limited purposes, usually in a business context. The estimates of these users range from 100 million to one billion.\n\nThe inner circle (UK, US etc.) is 'norm-providing'; that means that English language norms are developed in these countries. The outer circle (mainly New Commonwealth countries) is 'norm-developing'. The expanding circle (which includes much of the rest of the world) is 'norm-dependent', because it relies on the standards set by native speakers in the inner circle.\n\nEdgar Werner Schneider tries to avoid a purely geographical and historical approach evident in the 'circles' models and incorporates sociolinguistic concepts pertaining to acts of identity.\nHe outlines five characteristic stages in the spread of English:\n\nPhase 1 - Foundation: This is the initial stage of the introduction of English to a new territory over an extended period of time. Two linguistic processes are operative at this stage: (a) language contact between English and indigenous languages; (b) contact between different dialects of English of the settlers which eventually results in a new stable dialect (see koiné). At this stage, bilingualism is marginal. A few members of the local populace may play an important role as interpreters, translators and guides. Borrowings are limited to lexical items; with local place names and terms for local fauna and flora being adopted by the English.\n\nPhase 2 - Exonormative stabilization: At this stage, the settler communities tend to stabilize politically under British rule. English increases in prominence and though the colloquial English is a colonial koiné, the speakers look to England for their formal norms. Local vocabulary continues to be adopted. Bilingualism increases amongst the indigenous population through education and increased contacts with English settlers. Knowledge of English becomes an asset, and a new indigenous elite develops.\n\nPhase 3 - Nativisation: According to Schneider, this is the stage at which a transition occurs as the English settler population starts to accept a new identity based on present and local realities, rather than sole allegiance to their 'mother country'. By this time, the indigenous strand has also stabilized an L2 system that is a synthesis of substrate effects, interlanguage processes and features adopted from the settlers' koiné English. Neologisms stabilize as English is made to adapt to local sociopolitical and cultural practices.\n\nPhase 4 - Endonormative stabilization: This stage is characterized by the gradual acceptance of local norms, supported by a new locally rooted linguistic self-confidence. By this time political events have made it clear that the settler and indigenous strands are inextricably bound in a sense of nationhood independent of Britain. Acceptance of local English(es) expresses this new identity. National dictionaries are enthusiastically supported, at least for new lexis (and not always for localized grammar). Literary creativity in local English begins to flourish.\n\nPhase 5 - Differentiation: At this stage there is a change in the dynamics of identity as the young nation sees itself as less defined by its differences from the former colonial power as a composite of subgroups defined on regional, social and ethnic lines. Coupled with the simple effects of time in effecting language change (with the aid of social differentiation) the new English koiné starts to show greater differentiation.\n\nThe oldest map of the spread of English is Strevens's world map of English. His world map, even predating that of Kachru's three circles, showed that since American English became a separate variety from British English, all subsequent Englishes have had affinities with either one or the other.\n\nMcArthur's \"wheel model\" has an idealized central variety called \"World Standard English,\" which is best represented by \"written international English.\" The next circle is made of regional standards or standards that are emerging. Finally, the outer layer consists of localized varieties which may have similarities with the regional standards or emerging standards.\n\nAlthough the model is neat, it raises several problems. Firstly, the three different types of English — ENL, ESL and EFL, are conflated in the second circle. Secondly, the multitude of Englishes in Europe are also missing in this layer. Finally, the outside layer includes pidgins, creoles and L2 Englishes. Most scholars would argue that English pidgins and creoles do not belong to one family: rather they have overlapping multiple memberships.\n\nManfred Görlach's and McArthur's models are reasonably similar. Both exclude English varieties in Europe. As Görlach does not include EFLs at all, his model is more consistent, though less comprehensive. Outside the circle are mixed varieties (pidgins, creoles and mixed languages involving English), which are better categorized as having partial membership.\n\nIn Modiano's model of English, the center consists of users of English as an International Language, with a core set of features which are comprehensible to the majority of native and competent non-native speakers of English. The second circle consists of features which may become internationally common or may fall into obscurity. Finally, the outer area consists of five groups (American English, British English, other major varieties, local varieties, foreign varieties) each with features peculiar to their own speech community and which are unlikely to be understood by most members of the other four groups.\n\nThe World Englishes paradigm is not static, and neither are rapidly changing realities of language use worldwide. The use of English in the Outer and Expanding Circle societies (refer to Kachru's Three Circles of English) continues its rapid spread, while at the same time new patterns of language contact and variety differentiation emerge. The different varieties range from English in the Inner circle societies such as the United States, Canada, South Africa, Australia and New Zealand, to the Outer circle post-colonial societies of Asia and Africa.\nThe World Englishes initiative, in recognizing and describing the New Englishes of the Caribbean, Africa and Asia, has been partly motivated by a consideration of the local linguistic factors and partly by a consideration of the wider cultural and political contexts of language acquisition and use. This, in turn, has involved the creative rewriting of discourses towards a recognition of pluralism and multiple possibilities for scholarship. The notion of varieties in this context is similarly dynamic, as new contexts, new realities, new discourses, and new varieties continue to emerge.\n\nThe terms \"language\" and \"dialect\" are not easily defined concepts. It is often suggested that languages are autonomous, while dialects are heteronomous. It is also said that dialects, in contrast with languages, are mutually intelligible, though this is not always the case. Dialects are characteristically spoken, do not have a codified form and are used only in certain domains.\nIn order to avoid the difficult dialect-language distinction, linguists tend to prefer a more neutral term, \"variety\", which covers both concepts and is not clouded by popular usage. This term is generally used when discussing World Englishes.\n\nTwo scenarios have been advanced about English's future status as the major world language: it will ultimately fragment into a large number of mutually unintelligible varieties (in effect, languages), or it will converge so that differences across groups of speakers are largely eliminated.\n\nIf English is, numerically speaking, the language of 'others', then the center of gravity of the language is almost certain to shift in the direction of the 'others'. In the words of Widdowson, there is likely to be a paradigm shift from one of language distribution to one of language spread:\nIn this new paradigm, English spreads and adapts according to the linguistic and cultural preferences of its users in the Outer and Expanding circles (refer to Kachru's Three Circles of English). However, if English is genuinely to become the language of 'others', then the 'others' have to be accorded – or perhaps more likely, accord themselves – at least the same English language rights as those claimed by mother-tongue speakers.\n\nThe other potential shift in the linguistic center of gravity is that English could lose its international role altogether, or come to share it with a number of equals. Although this would not happen mainly as a result of native-speaker resistance to the spread of non-native speaker Englishes and the consequent abandoning of English by large numbers of non-native speakers, the latter could play a part.\n\nAs evidence that English may eventually give way to another language (or languages) as the world's lingua franca, David Crystal cites Internet data:\n\nOn the other hand, there are at least 1500 languages present on the internet now and that figure is likely to increase. Nevertheless, Crystal predicts that English will retain its dominant presence.\n\n"}
{"id": "33153769", "url": "https://en.wikipedia.org/wiki?curid=33153769", "title": "World History Association", "text": "World History Association\n\nThe World History Association (WHA) is an academic association that promotes the study of world history through the encouragement of research, teaching, and publication. It was founded in 1982.\n\nThe WHA provides many opportunities for connecting world historians with one another. It publishes the \"Journal of World History\" and \"World History Bulletin\", and has awarded World History Association Book Prize since 1999.\n\n\n"}
{"id": "4764461", "url": "https://en.wikipedia.org/wiki?curid=4764461", "title": "World War I", "text": "World War I\n\nWorld War I (often abbreviated as WWI or WW1), also known as the First World War or the Great War, was a global war originating in Europe that lasted from 28 July 1914 to 11 November 1918. Contemporaneously described as the \"war to end all wars\", it led to the mobilisation of more than 70 million military personnel, including 60 million Europeans, making it one of the largest wars in history. An estimated nine million combatants and seven million civilians died as a direct result of the war, and it also contributed to later genocides and the 1918 influenza pandemic, which caused between 50 and 100 million deaths worldwide. Military losses were exacerbated by new technological and industrial developments and the tactical stalemate caused by gruelling trench warfare. It was one of the deadliest conflicts in history and precipitated major political changes, including the Revolutions of 1917–1923, in many of the nations involved. Unresolved rivalries at the end of the conflict contributed to the start of World War II about twenty years later.\n\nOn 28 June 1914, Gavrilo Princip, a Bosnian Serb Yugoslav nationalist, assassinated the Austro-Hungarian heir Archduke Franz Ferdinand in Sarajevo, leading to the July Crisis. In response, on 23 July Austria-Hungary issued an ultimatum to Serbia. Serbia's reply failed to satisfy the Austrians, and the two moved to a war footing.\n\nA network of interlocking alliances enlarged the crisis from a bilateral issue in the Balkans to one involving most of Europe. By 1914, the great powers of Europe were divided into two coalitions: the Triple Entente—consisting of France, Russia and Britain—and the Triple Alliance of Germany, Austria-Hungary and Italy (the Triple Alliance was primarily defensive in nature, allowing Italy to stay out of the war in 1914). Russia felt it necessary to back Serbia, on 25 July issuing orders for the 'period preparatory to war', and after Austria-Hungary shelled the Serbian capital of Belgrade on the 28th, partial mobilisation was approved of the military districts nearest to Austria. General Russian mobilisation was announced on the evening of 30 July; on the 31st, Austria-Hungary and Germany did the same, while Germany demanded Russia demobilise within 12 hours. When Russia failed to comply, Germany declared war on 1 August in support of Austria-Hungary, with Austria-Hungary following suit on 6th; France ordered full mobilisation in support of Russia on 2 August.\n\nGerman strategy for a war on two fronts against France and Russia was to concentrate the bulk of its army in the West to defeat France within four weeks, then shift forces to the East before Russia could fully mobilise; this was later known as the Schlieffen Plan. On 2 August, Germany demanded free passage through Belgium, an essential element in achieving a quick victory over France. When this was refused, German forces invaded Belgium early on the morning of 3 August and declared war with France the same day; the Belgian government invoked the 1839 Treaty of London and in compliance with its obligations under this, Britain declared war on Germany on 4 August. On 12 August, Britain and France also declared war on Austria-Hungary; on the 23rd, Japan sided with the Entente, seizing the opportunity to expand its sphere of influence by capturing German possessions in China and the Pacific. The war was fought in and drew upon each powers' colonial empires as well, spreading the conflict across the globe. The Entente and its allies would eventually become known as the Allied Powers, while the grouping of Austria-Hungary and Germany would become known as the Central Powers.\n\nThe German advance into France was halted at the Battle of the Marne and by the end of 1914, the Western Front settled into a battle of attrition, marked by a long series of trench lines that changed little until 1917. The Eastern Front was marked by much greater exchanges of territory, but though Serbia was defeated in 1915, and Romania joined the Allied Powers in 1916 only to be defeated in 1917, none of the great powers were knocked out of the war until 1918. In November 1914, the Ottoman Empire joined the Central Powers, opening fronts in the Caucasus, Mesopotamia and the Sinai Peninsula. In 1915, Italy joined the Allied Powers and Bulgaria joined the Central Powers. After the sinking of seven US merchant ships by German submarines, and the revelation that the Germans were trying to incite Mexico to make war on the United States, the US declared war on Germany on 6 April 1917.\n\nThe 1917 February Revolution in Russia replaced the Tsarist autocracy with the Provisional Government, but continuing discontent at the cost of the war led to the October Revolution, the creation of the Soviet Socialist Republic, and the signing of the Treaty of Brest-Litovsk by the new government, ending Russia's involvement in the war. This allowed the transfer of large numbers of German troops from the East to the Western Front, resulting in the German March 1918 Offensive. The offensive was initially successful, but the Allied Powers rallied and drove the Germans back in the Hundred Days Offensive. Bulgaria was the first Central Power to sign an armistice—the Armistice of Salonica on 29 September 1918. On 30 October, the Ottoman Empire capitulated, signing the Armistice of Mudros. On 4 November, the Austro-Hungarian empire agreed to the Armistice of Villa Giusti. With its allies defeated, revolution at home, and the military no longer willing to fight, Kaiser Wilhelm abdicated on 9 November and Germany also signed an armistice on 11 November 1918.\n\nWorld War I was a significant turning point in the political, cultural, economic, and social climate of the world. As a result of the war, the Russian Empire, the German Empire, Austria-Hungary and the Ottoman Empire ceased to exist. Revolutions and uprisings in the aftermath of the war became widespread, being mainly socialist or anti-colonial in nature. The Big Four (Britain, France, the United States and Italy) imposed their terms in a series of treaties agreed at the 1919 Paris Peace Conference. The formation of the League of Nations was intended to prevent another world war, but for various reasons failed to do so. The rise of the Nazi Party and their central role in World War II led to a focus on how the Treaty of Versailles affected Germany, but the peace treaties in addition to various secret agreements during the war also transformed borders throughout Europe, Asia and the Middle East, with repercussions that still echo to this day.\n\nThe term \"First World War\" was first used in September 1914 by German biologist and philosopher Ernst Haeckel, who claimed that \"there is no doubt that the course and character of the feared 'European War' ... will become the first world war in the full sense of the word,\" citing a wire service report in \"The Indianapolis Star\" on 20 September 1914.\n\nPrior to World War II, the events of 1914–1918 were generally known as the Great War or simply the World War. Contemporary Europeans also referred to it as \"the war to end war\" or \"the war to end all wars\" due to their perception of its then-unparalleled scale and devastation. After World War II began in 1939, the terms became more standard, with British Empire historians, including Canadians, favouring \"The First World War\" and Americans \"World War I\".\n\nIn October 1914, the Canadian magazine \"Maclean's\" wrote, \"Some wars name themselves. This is the Great War.\" However, while certainly accurate in Canada, this was not so even in Britain; historian John Holland Rose's 1911 account of the 1793–1815 wars against France was titled \"William Pitt and the Great War\". This was validated by Gareth Glover's 2015 book, \"Waterloo in 100 Objects\", in which he states: \"This opening statement will cause some bewilderment to many who have grown up with the appellation of the Great War firmly applied to the 1914–18 First World War. But to anyone living before 1918, the title of the Great War was applied to the Revolutionary and Napoleonic wars in which Britain fought France almost continuously for twenty-two years from 1793 to 1815.\"\n\nIn Germany, \"The Great War\" was historically used for the 1618–1648 Thirty Years' War, also known as the \"Great German War\" or \"Great Schism\". One of the longest and most destructive conflicts in human history, it resulted in eight million fatalities from military action, violence, famine and plague, the vast majority of them in the German states of the Holy Roman Empire. In terms of proportional German casualties and destruction, it was only surpassed by the period from January to May 1945; its enduring visibility is partly the result of 19th-century Pan-Germanism, as an example of the dangers of a divided Germany and a driver in the 1871 creation of the or German Empire. Regardless of terminology, the Thirty Years' War remains the single greatest war trauma in German memory, as demonstrated in debates over naming conventions during the centenary of 1914–1918.\n\nFor much of the 19th century, the major European powers had tried to maintain a tenuous balance of power among themselves, resulting in a complex network of political and military alliances. The biggest challenges to this were Britain's withdrawal into so-called splendid isolation, the decline of the Ottoman Empire and the post-1848 rise of Prussia under Otto von Bismarck. Victory in the 1866 Austro-Prussian War established Prussian hegemony in Germany, while victory over France in the 1870–1871 Franco-Prussian War unified the German states into a German Reich under Prussian leadership.\n\nIn 1873, to isolate France and avoid a war on two fronts, Bismarck negotiated the League of the Three Emperors (German: \"Dreikaiserbund\") between Austria-Hungary, Russia and Germany. Concerned by Russia's victory in the 1877–1878 Russo-Turkish War and their influence in the Balkans, the League was dissolved in 1878, with Germany and Austria-Hungary subsequently forming the 1879 Dual Alliance; this became the Triple Alliance when Italy joined in 1882. \n\nThe practical details of these alliances were limited, since their primary purpose was to ensure cooperation between the three Imperial Powers and isolate France. Attempts by Britain in 1880 to resolve colonial tensions with Russia and diplomatic moves by France led to Bismarck reforming the League in 1881. When the League finally lapsed in 1887, it was replaced by the Reinsurance Treaty, a secret agreement between Germany and Russia to remain neutral if either were attacked by France or Austria-Hungary.\n\nIn 1890, the new German Emperor, Kaiser Wilhelm II, forced Bismarck to retire and was persuaded not to renew the Reinsurance Treaty by the new Chancellor, Leo von Caprivi. This allowed France to counteract the Triple Alliance with the Franco-Russian Alliance of 1894 and the 1904 Entente Cordiale with Britain, while in 1907 Britain and Russia signed the Anglo-Russian Convention. The agreements did not constitute formal alliances, but by settling long-standing colonial disputes, they made British entry into any future conflict involving France or Russia a possibility; these interlocking bilateral agreements became known as the Triple Entente.\n\nVictory in the 1871 Franco-Prussian War and the creation of the German Reich led to a massive increase in Germany's economic and industrial strength. Admiral Alfred von Tirpitz and Wilhelm II, who became Emperor in 1890, sought to use that to create a \"Kaiserliche Marine\" or Imperial German Navy to compete with Britain's Royal Navy for world naval supremacy. Their rationale was based on the ideas of US naval strategist Alfred Mahan, who argued that whoever ruled the sea also ruled the world; Tirpitz had Mahan's books translated into German, while Wilhelm made them required reading for his officers. However, Wilhelm annoyed his ministers by publicly declaring one motive to be his childhood admiration of the Royal Navy, which he had visited \"with kind aunts and friendly admirals.\"\n\nThe result was the Anglo-German naval arms race. With the launch of in 1906, the Royal Navy increased its advantage over its German rival and continued to do so. By 1912, the German economy could no longer support both naval expansion and the largest permanent army in Europe, with Chancellor Theobald von Bethmann-Hollweg acknowledging defeat. In many ways, it was a strategic disaster for Germany, diverting huge resources to create a navy large enough to antagonise Britain but not defeat it.\n\nEnding the naval arms race reduced tensions between Britain and Germany but did not lead to reductions elsewhere; in 1913, Germany approved an increase in its standing army by 170,000 men, Russia committed to another 500,000 men over the next three years, while France extended compulsory military service from two to three years. Between 1870 and 1914, total military spending by Austria, Germany, Italy, and Russia increased from £94 million to £394 million (equivalent to £ billion in ). The largest proportional increases occurred in Germany (+73%) and Russia (+39%).\n\nIn October 1908, Austria-Hungary precipitated the Bosnian crisis of 1908–1909 by officially annexing the former Ottoman territory of Bosnia and Herzegovina, which it had occupied since 1878. This angered the Kingdom of Serbia and its patron, the Pan-Slavic and Orthodox Russian Empire. Russian political manoeuvring in the region destabilised peace accords that were already fracturing in the Balkans, which came to be known as the \"powder keg of Europe\".\n\nIn 1912 and 1913, the First Balkan War was fought between the Balkan League and the fracturing Ottoman Empire. The resulting Treaty of London further shrank the Ottoman Empire, creating an independent Albanian state while enlarging the territorial holdings of Bulgaria, Serbia, Montenegro, and Greece. When Bulgaria attacked Serbia and Greece on 16 June 1913, it sparked the 33-day Second Balkan War, by the end of which it lost most of Macedonia to Serbia and Greece, and Southern Dobruja to Romania, further destabilising the region. The Great Powers were able to keep these Balkan conflicts contained, but the next one would spread throughout Europe and beyond.\n\nOn 28 June 1914, Archduke Franz Ferdinand, heir presumptive to the Austro-Hungarian Empire, visited the Bosnian capital, Sarajevo. A group of six assassins (Cvjetko Popović, Gavrilo Princip, Muhamed Mehmedbašić, Nedeljko Čabrinović, Trifko Grabež, and Vaso Čubrilović) from the Yugoslavist group Mlada Bosna, supplied with arms by the Serbian Black Hand, gathered on the street where the Archduke's motorcade was to pass, with the intention of assassinating him. The political objective of the assassination was to break off Austria-Hungary's South Slav provinces, which Austria-Hungary had annexated from the Ottoman Empire, so they could be combined into a Yugoslavia.\n\nČabrinović threw a grenade at the car, but missed. Some nearby were injured by the blast, but Ferdinand's convoy carried on. The other assassins failed to act as the cars drove past them.\n\nAbout an hour later, when Ferdinand was returning from a visit at the Sarajevo Hospital with those wounded in the assassination attempt, the convoy took a wrong turn into a street where, by coincidence, Princip stood. With a pistol, Princip shot and killed Ferdinand and his wife Sophie. Although they were reportedly not personally close, the Emperor Franz Joseph was profoundly shocked and upset. The reaction among the people in Austria, however, was mild, almost indifferent. As historian Zbyněk Zeman later wrote, \"the event almost failed to make any impression whatsoever. On Sunday and Monday (28 and 29 June), the crowds in Vienna listened to music and drank wine, as if nothing had happened.\" Nevertheless, the political impact of the murder of the heir to the throne was significant, and was described by historian Christopher Clark on the BBC Radio 4 series \"Month of Madness\" as a \"9/11 effect, a terrorist event charged with historic meaning, transforming the political chemistry in Vienna.\"\n\nThe Austro-Hungarian authorities encouraged the subsequent anti-Serb riots in Sarajevo, in which Bosnian Croats and Bosniaks killed two Bosnian Serbs and damaged numerous Serb-owned buildings. Violent actions against ethnic Serbs were also organised outside Sarajevo, in other cities in Austro-Hungarian-controlled Bosnia and Herzegovina, Croatia and Slovenia. Austro-Hungarian authorities in Bosnia and Herzegovina imprisoned and extradited approximately 5,500 prominent Serbs, 700 to 2,200 of whom died in prison. A further 460 Serbs were sentenced to death. A predominantly Bosniak special militia known as the \"Schutzkorps\" was established and carried out the persecution of Serbs.\n\nThe assassination led to a month of diplomatic manoeuvring between Austria-Hungary, Germany, Russia, France and Britain, called the July Crisis. Austria-Hungary correctly believed that Serbian officials (especially the officers of the Black Hand) were involved in the plot to murder the Archduke, and wanted to finally end Serbian interference in Bosnia. On 23 July, Austria-Hungary delivered to Serbia the July Ultimatum, a series of ten demands that were made intentionally unacceptable, in an effort to provoke a war with Serbia. Serbia decreed general mobilisation on the 25th. Serbia accepted all of the terms of the ultimatum except for article six, which demanded that Austrian delegates be allowed in Serbia for the purpose of participation in the investigation into the assassination. Following this, Austria broke off diplomatic relations with Serbia and, the next day, ordered a partial mobilisation. Finally, on 28 July 1914, a month after the assassination, Austria-Hungary declared war on Serbia.\nOn 29 July, Russia, in support of Serbia, declared partial mobilisation against Austria-Hungary. On the 30th, Russia ordered general mobilisation. German Chancellor Bethmann-Hollweg waited until the 31st for an appropriate response, when Germany declared \"Erklärung des Kriegszustandes\", or \"State of danger of war\". Kaiser Wilhelm II asked his cousin, Tsar Nicolas II, to suspend the Russian general mobilisation. When he refused, Germany issued an ultimatum demanding its mobilisation be stopped, and a commitment not to support Serbia. Another was sent to France, asking her not to support Russia if it were to come to the defence of Serbia. On 1 August, after the Russian response, Germany mobilised and declared war on Russia. This also led to the general mobilisation in Austria-Hungary on 4 August.\n\nThe German government issued demands to France that it remain neutral as they had to decide which deployment plan to implement, it being difficult if not impossible to change the deployment whilst it was underway. The modified German Schlieffen Plan, \"Aufmarsch II West\", would deploy 80% of the army in the west, and \"Aufmarsch I Ost\" and \"Aufmarsch II Ost\" would deploy 60% in the west and 40% in the east as this was the maximum that the East Prussian railway infrastructure could carry. The French did not respond, but sent a mixed message by ordering their troops to withdraw from the border to avoid any incidents, and at the same time ordered the mobilisation of their reserves. Germany responded by mobilising its own reserves and implementing \"Aufmarsch II West\".\n\nOn 1 August, Wilhelm ordered General Helmuth von Moltke the Younger to \"march the whole of the ... army to the East\" after being wrongly informed the British would remain neutral if France was not attacked. Moltke told the Kaiser that attempting to redeploy a million men was unthinkable, and that making it possible for the French to attack the Germans \"in the rear\" would prove disastrous. Yet Wilhelm insisted that the German army should not march into Luxembourg until he received a telegram sent by his cousin George V, who made it clear that there had been a misunderstanding. Eventually the Kaiser told Moltke, \"Now you can do what you want.\"\n\nOn 2 August, Germany occupied Luxembourg, and on 3 August declared war on France; on the same day, they sent the Belgian government an ultimatum demanding unimpeded right of way through any part of Belgium, which was refused. Early on the morning of 4 August, the Germans invaded; King Albert ordered his military to resist and called for assistance under the 1839 Treaty of London. Britain demanded Germany comply with the Treaty and respect Belgian neutrality; it declared war on Germany at 19:00 UTC on 4 August 1914 (effective from 23:00), following an \"unsatisfactory reply\".\n\nThe strategy of the Central Powers suffered from miscommunication. Germany had promised to support Austria-Hungary's invasion of Serbia, but interpretations of what this meant differed. Previously tested deployment plans had been replaced early in 1914, but those had never been tested in exercises. Austro-Hungarian leaders believed Germany would cover its northern flank against Russia. Germany, however, envisioned Austria-Hungary directing most of its troops against Russia, while Germany dealt with France. This confusion forced the Austro-Hungarian Army to divide its forces between the Russian and Serbian fronts.\n\nAustria invaded and fought the Serbian army at the Battle of Cer and Battle of Kolubara beginning on 12 August. Over the next two weeks, Austrian attacks were thrown back with heavy losses, which marked the first major Allied victories of the war and dashed Austro-Hungarian hopes of a swift victory. As a result, Austria had to keep sizeable forces on the Serbian front, weakening its efforts against Russia. Serbia's defeat of the Austro-Hungarian invasion of 1914 has been called one of the major upset victories of the twentieth century.\n\nWhen the war began, the German Order of Battle placed 80% of the army in the West, with the remainder acting as a screening force in the East. The plan was to quickly knock France out of the war, then redeploy to the East and do the same to Russia.\n\nThe German offensive in the West was officially titled \"Aufmarsch I West,\" but is better known as the Schlieffen Plan, after its original creator. Schlieffen deliberately kept the German left (i.e. its positions in Alsace-Lorraine) weak to lure the French into attacking there, while the majority were allocated to the German right, so as to sweep through Belgium, encircle Paris and trap the French armies against the Swiss border (the French charged into Alsace-Lorraine on the outbreak of war as envisaged by their Plan XVII, thus actually aiding this strategy). However, Schlieffen's successor Moltke grew concerned that the French might push too hard on his left flank. As such, as the German Army increased in size in the years leading up to the war, he changed the allocation of forces between the German right and left wings from 85:15 to 70:30. Ultimately, Moltke's changes meant insufficient forces to achieve decisive success and thus unrealistic goals and timings.\n\nThe initial German advance in the West was very successful: by the end of August the Allied left, which included the British Expeditionary Force (BEF), was in full retreat; French casualties in the first month exceeded 260,000, including 27,000 killed on 22 August during the Battle of the Frontiers. German planning provided broad strategic instructions, while allowing army commanders considerable freedom in carrying them out at the front; this worked well in 1866 and 1870 but in 1914, von Kluck used this freedom to disobey orders, opening a gap between the German armies as they closed on Paris. The French and British exploited this gap to halt the German advance east of Paris at the First Battle of the Marne from 5 to 12 September and push the German forces back some .\n\nIn 1911, the Russian Stavka had agreed with the French to attack Germany within 15 days of mobilisation; this was unrealistic and the two Russian armies that entered East Prussia on 17 August did so without many of their support elements. The Russian Second Army was effectively destroyed at the Battle of Tannenberg on 26–30 August but the Russian advance caused the Germans to re-route their 8th Field Army from France to East Prussia, a factor in Allied victory on the Marne.\n\nBy the end of 1914, German troops held strong defensive positions inside France, controlled the bulk of France's domestic coalfields and had inflicted 230,000 more casualties than it lost itself. However, communications problems and questionable command decisions cost Germany the chance of a decisive outcome while it had failed to achieve the primary objective of avoiding a long, two-front war. This amounted to a strategic defeat; shortly after the Marne, Crown Prince Wilhelm told an American reporter; \"We have lost the war. It will go on for a long time but lost it is already.\"\n\nNew Zealand occupied German Samoa (later Western Samoa) on 30 August 1914. On 11 September, the Australian Naval and Military Expeditionary Force landed on the island of Neu Pommern (later New Britain), which formed part of German New Guinea. On 28 October, the German cruiser sank the Russian cruiser Zhemchug in the Battle of Penang. Japan seized Germany's Micronesian colonies and, after the Siege of Tsingtao, the German coaling port of Qingdao on the Chinese Shandong peninsula. As Vienna refused to withdraw the Austro-Hungarian cruiser from Tsingtao, Japan declared war not only on Germany, but also on Austria-Hungary; the ship participated in the defence of Tsingtao where it was sunk in November 1914. Within a few months, the Allied forces had seized all the German territories in the Pacific; only isolated commerce raiders and a few holdouts in New Guinea remained.\n\nSome of the first clashes of the war involved British, French, and German colonial forces in Africa. On 6–7 August, French and British troops invaded the German protectorate of Togoland and Kamerun. On 10 August, German forces in South-West Africa attacked South Africa; sporadic and fierce fighting continued for the rest of the war. The German colonial forces in German East Africa, led by Colonel Paul von Lettow-Vorbeck, fought a guerrilla warfare campaign during World War I and only surrendered two weeks after the armistice took effect in Europe.\n\nGermany attempted to use Indian nationalism and pan-Islamism to its advantage, instigating uprisings in India, and sending a mission that urged Afghanistan to join the war on the side of Central Powers. However, contrary to British fears of a revolt in India, the outbreak of the war saw an unprecedented outpouring of loyalty and goodwill towards Britain. Indian political leaders from the Indian National Congress and other groups were eager to support the British war effort, since they believed that strong support for the war effort would further the cause of Indian Home Rule. The Indian Army in fact outnumbered the British Army at the beginning of the war; about 1.3 million Indian soldiers and labourers served in Europe, Africa, and the Middle East, while the central government and the princely states sent large supplies of food, money, and ammunition. In all, 140,000 men served on the Western Front and nearly 700,000 in the Middle East. Casualties of Indian soldiers totalled 47,746 killed and 65,126 wounded during World War I.\nThe suffering engendered by the war, as well as the failure of the British government to grant self-government to India after the end of hostilities, bred disillusionment and fuelled the campaign for full independence that would be led by Mohandas K. Gandhi and others.\n\nMilitary tactics developed before World War I failed to keep pace with advances in technology and had become obsolete. These advances had allowed the creation of strong defensive systems, which out-of-date military tactics could not break through for most of the war. Barbed wire was a significant hindrance to massed infantry advances, while artillery, vastly more lethal than in the 1870s, coupled with machine guns, made crossing open ground extremely difficult. Commanders on both sides failed to develop tactics for breaching entrenched positions without heavy casualties. In time, however, technology began to produce new offensive weapons, such as gas warfare and the tank.\n\nAfter the First Battle of the Marne (5–12 September 1914), Allied and German forces unsuccessfully tried to outflank each other, a series of manoeuvres later known as the \"Race to the Sea\". By the end of 1914, the opposing forces were left confronting each other along an uninterrupted line of entrenched positions from Lorraine to Belgium's coast. Since the Germans were able to choose where to stand, they normally had the advantage of the high ground; in addition, their trenches tended to be better built, since Anglo-French trenches were initially intended as \"temporary,\" preparatory to breaking the German defences.\n\nBoth sides tried to break the stalemate using scientific and technological advances. On 22 April 1915, at the Second Battle of Ypres, the Germans (violating the Hague Convention) used chlorine gas for the first time on the Western Front. Several types of gas soon became widely used by both sides, and though it never proved a decisive, battle-winning weapon, poison gas became one of the most-feared and best-remembered horrors of the war. Tanks were developed by Britain and France and were first used in combat by the British during the Battle of Flers–Courcelette (part of the Battle of the Somme) on 15 September 1916, with only partial success. However, their effectiveness would grow as the war progressed; the Allies built tanks in large numbers, whilst the Germans employed only a few of their own design, supplemented by captured Allied tanks.\n\nNeither side proved able to deliver a decisive blow for the next two years. Throughout 1915–17, the British Empire and France suffered more casualties than Germany, because of both the strategic and tactical stances chosen by the sides. Strategically, while the Germans only mounted one major offensive, the Allies made several attempts to break through the German lines.\n\nIn February 1916 the Germans attacked French defensive positions at the Battle of Verdun, lasting until December 1916. The Germans made initial gains, before French counter-attacks returned matters to near their starting point. Casualties were greater for the French, but the Germans bled heavily as well, with anywhere from 700,000 to 975,000 casualties suffered between the two combatants. Verdun became a symbol of French determination and self-sacrifice.\n\nThe Battle of the Somme was an Anglo-French offensive of July to November 1916. The opening day of the offensive (1 July 1916) was the bloodiest day in the history of the British Army, suffering 57,470 casualties, including 19,240 dead. The entire Somme offensive cost the British Army some 420,000 casualties. The French suffered another estimated 200,000 casualties and the Germans an estimated 500,000. Gun fire wasn't the only factor taking lives; the diseases that emerged in the trenches were a major killer on both sides. The living conditions made it so that countless diseases and infections occurred, such as trench foot, shell shock, blindness/burns from mustard gas, lice, trench fever, cooties (body lice) and the ‘Spanish Flu’.\n\nTo maintain morale, wartime censors minimised early reports of widespread influenza illness and mortality in Germany, the United Kingdom, France, and the United States. Papers were free to report the epidemic's effects in neutral Spain (such as the grave illness of King Alfonso XIII). This created a false impression of Spain as especially hard hit, thereby giving rise to the pandemic's nickname, \"Spanish Flu\".\n\nProtracted action at Verdun throughout 1916, combined with the bloodletting at the Somme, brought the exhausted French army to the brink of collapse. Futile attempts using frontal assault came at a high price for both the British and the French and led to the widespread French Army Mutinies, after the failure of the costly Nivelle Offensive of April–May 1917. The concurrent British Battle of Arras was more limited in scope, and more successful, although ultimately of little strategic value. A smaller part of the Arras offensive, the capture of Vimy Ridge by the Canadian Corps, became highly significant to that country: the idea that Canada's national identity was born out of the battle is an opinion widely held in military and general histories of Canada.\n\nThe last large-scale offensive of this period was a British attack (with French support) at Passchendaele (July–November 1917). This offensive opened with great promise for the Allies, before bogging down in the October mud. Casualties, though disputed, were roughly equal, at some 200,000–400,000 per side.\n\nThe years of trench warfare on the Western front achieved no major exchanges of territory and, as a result, are often thought of as static and unchanging. However, throughout this period, British, French, and German tactics constantly evolved to meet new battlefield challenges.\n\nAt the start of the war, the German Empire had cruisers scattered across the globe, some of which were subsequently used to attack Allied merchant shipping. The British Royal Navy systematically hunted them down, though not without some embarrassment from its inability to protect Allied shipping. Before the beginning of the war, it was widely understood that Britain held the position of strongest, most influential navy in the world. The publishing of the book \"The Influence of Sea Power upon History\" by Alfred Thayer Mahan in 1890 was intended to encourage the United States to increase their naval power. Instead, this book made it to Germany and inspired its readers to try to over-power the British Royal Navy. For example, the German detached light cruiser , part of the East Asia Squadron stationed at Qingdao, seized or destroyed 15 merchantmen, as well as sinking a Russian cruiser and a French destroyer. However, most of the German East-Asia squadron—consisting of the armoured cruisers and , light cruisers and and two transport ships—did not have orders to raid shipping and was instead underway to Germany when it met British warships. The German flotilla and sank two armoured cruisers at the Battle of Coronel, but was virtually destroyed at the Battle of the Falkland Islands in December 1914, with only \"Dresden\" and a few auxiliaries escaping, but after the Battle of Más a Tierra these too had been destroyed or interned.\n\nSoon after the outbreak of hostilities, Britain began a naval blockade of Germany. The strategy proved effective, cutting off vital military and civilian supplies, although this blockade violated accepted international law codified by several international agreements of the past two centuries. Britain mined international waters to prevent any ships from entering entire sections of ocean, causing danger to even neutral ships. Since there was limited response to this tactic of the British, Germany expected a similar response to its unrestricted submarine warfare.\n\nThe Battle of Jutland (German: \"Skagerrakschlacht\", or \"Battle of the Skagerrak\") in May/June 1916 developed into the largest naval battle of the war. It was the only full-scale clash of battleships during the war, and one of the largest in history. The Kaiserliche Marine's High Seas Fleet, commanded by Vice Admiral Reinhard Scheer, fought the Royal Navy's Grand Fleet, led by Admiral Sir John Jellicoe. The engagement was a stand off, as the Germans were outmanoeuvred by the larger British fleet, but managed to escape and inflicted more damage to the British fleet than they received. Strategically, however, the British asserted their control of the sea, and the bulk of the German surface fleet remained confined to port for the duration of the war.\n\nGerman U-boats attempted to cut the supply lines between North America and Britain. The nature of submarine warfare meant that attacks often came without warning, giving the crews of the merchant ships little hope of survival. The United States launched a protest, and Germany changed its rules of engagement. After the sinking of the passenger ship RMS \"Lusitania\" in 1915, Germany promised not to target passenger liners, while Britain armed its merchant ships, placing them beyond the protection of the \"cruiser rules\", which demanded warning and movement of crews to \"a place of safety\" (a standard that lifeboats did not meet). Finally, in early 1917, Germany adopted a policy of unrestricted submarine warfare, realising that the Americans would eventually enter the war. Germany sought to strangle Allied sea lanes before the United States could transport a large army overseas, but after initial successes eventually failed to do so.\n\nThe U-boat threat lessened in 1917, when merchant ships began travelling in convoys, escorted by destroyers. This tactic made it difficult for U-boats to find targets, which significantly lessened losses; after the hydrophone and depth charges were introduced, accompanying destroyers could attack a submerged submarine with some hope of success. Convoys slowed the flow of supplies, since ships had to wait as convoys were assembled. The solution to the delays was an extensive program of building new freighters. Troopships were too fast for the submarines and did not travel the North Atlantic in convoys. The U-boats had sunk more than 5,000 Allied ships, at a cost of 199 submarines.\n\nWorld War I also saw the first use of aircraft carriers in combat, with launching Sopwith Camels in a successful raid against the Zeppelin hangars at Tondern in July 1918, as well as blimps for antisubmarine patrol.\n\nFaced with Russia in the east, Austria-Hungary could spare only one-third of its army to attack Serbia. After suffering heavy losses, the Austrians briefly occupied the Serbian capital, Belgrade. A Serbian counter-attack in the Battle of Kolubara succeeded in driving them from the country by the end of 1914. For the first ten months of 1915, Austria-Hungary used most of its military reserves to fight Italy. German and Austro-Hungarian diplomats, however, scored a coup by persuading Bulgaria to join the attack on Serbia. The Austro-Hungarian provinces of Slovenia, Croatia and Bosnia provided troops for Austria-Hungary in the fight with Serbia, Russia and Italy. Montenegro allied itself with Serbia.\n\nBulgaria declared war on Serbia on 12 October 1915 and joined in the attack by the Austro-Hungarian army under Mackensen's army of 250,000 that was already underway. Serbia was conquered in a little more than a month, as the Central Powers, now including Bulgaria, sent in 600,000 troops total. The Serbian army, fighting on two fronts and facing certain defeat, retreated into northern Albania. The Serbs suffered defeat in the Battle of Kosovo. Montenegro covered the Serbian retreat towards the Adriatic coast in the Battle of Mojkovac in 6–7 January 1916, but ultimately the Austrians also conquered Montenegro. The surviving Serbian soldiers were evacuated by ship to Greece. After conquest, Serbia was divided between Austro-Hungary and Bulgaria.\n\nIn late 1915, a Franco-British force landed at Salonica in Greece to offer assistance and to pressure its government to declare war against the Central Powers. However, the pro-German King Constantine I dismissed the pro-Allied government of Eleftherios Venizelos before the Allied expeditionary force arrived. The friction between the King of Greece and the Allies continued to accumulate with the National Schism, which effectively divided Greece between regions still loyal to the king and the new provisional government of Venizelos in Salonica. After intense negotiations and an armed confrontation in Athens between Allied and royalist forces (an incident known as Noemvriana), the King of Greece resigned and his second son Alexander took his place; Greece officially joined the war on the side of the Allies in June 1917.\n\nThe Macedonian Front was initially mostly static. French and Serbian forces retook limited areas of Macedonia by recapturing Bitola on 19 November 1916 following the costly Monastir Offensive, which brought stabilisation of the front.\n\nSerbian and French troops finally made a breakthrough in September 1918 in the Vardar Offensive, after most of the German and Austro-Hungarian troops had been withdrawn. The Bulgarians were defeated at the Battle of Dobro Pole, and by 25 September British and French troops had crossed the border into Bulgaria proper as the Bulgarian army collapsed. Bulgaria capitulated four days later, on 29 September 1918. The German high command responded by despatching troops to hold the line, but these forces were far too weak to reestablish a front.\n\nThe disappearance of the Macedonian Front meant that the road to Budapest and Vienna was now opened to Allied forces. Hindenburg and Ludendorff concluded that the strategic and operational balance had now shifted decidedly against the Central Powers and, a day after the Bulgarian collapse, insisted on an immediate peace settlement.\n\nThe Ottomans threatened Russia's Caucasian territories and Britain's communications with India via the Suez Canal. As the conflict progressed, the Ottoman Empire took advantage of the European powers' preoccupation with the war and conducted large-scale ethnic cleansing of the indigenous Armenian, Greek, and Assyrian Christian populations, known as the Armenian Genocide, Greek Genocide, and Assyrian Genocide.\n\nThe British and French opened overseas fronts with the Gallipoli (1915) and Mesopotamian campaigns (1914). In Gallipoli, the Ottoman Empire successfully repelled the British, French, and Australian and New Zealand Army Corps (ANZACs). In Mesopotamia, by contrast, after the defeat of the British defenders in the Siege of Kut by the Ottomans (1915–16), British Imperial forces reorganised and captured Baghdad in March 1917. The British were aided in Mesopotamia by local Arab and Assyrian tribesmen, while the Ottomans employed local Kurdish and Turcoman tribes.\n\nFurther to the west, the Suez Canal was defended from Ottoman attacks in 1915 and 1916; in August, a German and Ottoman force was defeated at the Battle of Romani by the ANZAC Mounted Division and the 52nd (Lowland) Infantry Division. Following this victory, an Egyptian Expeditionary Force advanced across the Sinai Peninsula, pushing Ottoman forces back in the Battle of Magdhaba in December and the Battle of Rafa on the border between the Egyptian Sinai and Ottoman Palestine in January 1917.\n\nRussian armies generally had success in the Caucasus. Enver Pasha, supreme commander of the Ottoman armed forces, was ambitious and dreamed of re-conquering central Asia and areas that had been lost to Russia previously. He was, however, a poor commander. He launched an offensive against the Russians in the Caucasus in December 1914 with 100,000 troops, insisting on a frontal attack against mountainous Russian positions in winter. He lost 86% of his force at the Battle of Sarikamish.\n\nThe Ottoman Empire, with German support, invaded Persia (modern Iran) in December 1914 in an effort to cut off British and Russian access to petroleum reservoirs around Baku near the Caspian Sea. Persia, ostensibly neutral, had long been under the spheres of British and Russian influence. The Ottomans and Germans were aided by Kurdish and Azeri forces, together with a large number of major Iranian tribes, such as the Qashqai, Tangistanis, Luristanis, and Khamseh, while the Russians and British had the support of Armenian and Assyrian forces. The Persian Campaign was to last until 1918 and end in failure for the Ottomans and their allies. However, the Russian withdrawal from the war in 1917 led to Armenian and Assyrian forces, who had hitherto inflicted a series of defeats upon the forces of the Ottomans and their allies, being cut off from supply lines, outnumbered, outgunned and isolated, forcing them to fight and flee towards British lines in northern Mesopotamia.\n\nGeneral Yudenich, the Russian commander from 1915 to 1916, drove the Turks out of most of the southern Caucasus with a string of victories. In 1917, Russian Grand Duke Nicholas assumed command of the Caucasus front. Nicholas planned a railway from Russian Georgia to the conquered territories, so that fresh supplies could be brought up for a new offensive in 1917. However, in March 1917 (February in the pre-revolutionary Russian calendar), the Czar abdicated in the course of the February Revolution, and the Russian Caucasus Army began to fall apart.\n\nThe Arab Revolt, instigated by the Arab bureau of the British Foreign Office, started June 1916 with the Battle of Mecca, led by Sherif Hussein of Mecca, and ended with the Ottoman surrender of Damascus. Fakhri Pasha, the Ottoman commander of Medina, resisted for more than two and half years during the Siege of Medina before surrendering in January 1919.\n\nThe Senussi tribe, along the border of Italian Libya and British Egypt, incited and armed by the Turks, waged a small-scale guerrilla war against Allied troops. The British were forced to dispatch 12,000 troops to oppose them in the Senussi Campaign. Their rebellion was finally crushed in mid-1916.\n\nTotal Allied casualties on the Ottoman fronts amounted 650,000 men. Total Ottoman casualties were 725,000 (325,000 dead and 400,000 wounded).\n\nItaly had been allied with the German and Austro-Hungarian Empires since 1882 as part of the Triple Alliance. However, the nation had its own designs on Austrian territory in Trentino, the Austrian Littoral, Fiume (Rijeka) and Dalmatia. Rome had a secret 1902 pact with France, effectively nullifying its part in the Triple Alliance; Italy secretly agreed with France to remain neutral if the latter was attacked by Germany. At the start of hostilities, Italy refused to commit troops, arguing that the Triple Alliance was defensive and that Austria-Hungary was an aggressor. The Austro-Hungarian government began negotiations to secure Italian neutrality, offering the French colony of Tunisia in return. The Allies made a counter-offer in which Italy would receive the Southern Tyrol, Austrian Littoral and territory on the Dalmatian coast after the defeat of Austria-Hungary. This was formalised by the Treaty of London. Further encouraged by the Allied invasion of Turkey in April 1915, Italy joined the Triple Entente and declared war on Austria-Hungary on 23 May. Fifteen months later, Italy declared war on Germany.\n\nThe Italians had numerical superiority, but this advantage was lost, not only because of the difficult terrain in which the fighting took place, but also because of the strategies and tactics employed. Field Marshal Luigi Cadorna, a staunch proponent of the frontal assault, had dreams of breaking into the Slovenian plateau, taking Ljubljana and threatening Vienna.\n\nOn the Trentino front, the Austro-Hungarians took advantage of the mountainous terrain, which favoured the defender. After an initial strategic retreat, the front remained largely unchanged, while Austrian Kaiserschützen and Standschützen engaged Italian Alpini in bitter hand-to-hand combat throughout the summer. The Austro-Hungarians counterattacked in the Altopiano of Asiago, towards Verona and Padua, in the spring of 1916 (\"Strafexpedition\"), but made little progress.\n\nBeginning in 1915, the Italians under Cadorna mounted eleven offensives on the Isonzo front along the Isonzo (Soča) River, northeast of Trieste. Of this eleven offensives, five were won by Italy, three remained inconclusive, and other three were repelled by the Austro-Hungarians, who held the higher ground. In the summer of 1916, after the Battle of Doberdò, the Italians captured the town of Gorizia. After this minor victory, the front remained static for over a year, despite several Italian offensives, centred on the Banjšice and Karst Plateau east of Gorizia.\n\nThe Central Powers launched a crushing offensive on 26 October 1917, spearheaded by the Germans, and achieved a victory at Caporetto (Kobarid). The Italian Army was routed and retreated more than to reorganise, stabilising the front at the Piave River. Since the Italian Army had suffered heavy losses in the Battle of Caporetto, the Italian Government ordered conscription of the so-called \"99 Boys\" (\"Ragazzi del '99\"): all males born in 1899 and prior, who were 18 years old or older. In 1918, the Austro-Hungarians failed to break through in a series of battles on the Piave and were finally decisively defeated in the Battle of Vittorio Veneto in October. On 1 November, the Italian Navy destroyed much of the Austro-Hungarian fleet stationed in Pula, preventing it from being handed over to the new State of Slovenes, Croats and Serbs. On 3 November, the Italians invaded Trieste from the sea. On the same day, the Armistice of Villa Giusti was signed. By mid-November 1918, the Italian military occupied the entire former Austrian Littoral and had seized control of the portion of Dalmatia that had been guaranteed to Italy by the London Pact. By the end of hostilities in November 1918, Admiral Enrico Millo declared himself Italy's Governor of Dalmatia. Austria-Hungary surrendered on 11 November 1918.\n\nRomania had been allied with the Central Powers since 1882. When the war began, however, it declared its neutrality, arguing that because Austria-Hungary had itself declared war on Serbia, Romania was under no obligation to join the war. On August 4, 1916, Romania and the Entente signed the Political Treaty and Military Convention, that established the coordinates of Romania’s participation in the war. In return, it received the Allies' formal sanction for the annexation of the Romanian-inhabited regions of Austria-Hungary. The action had large popular support On 27 August 1916, the Romanian Army launched an attack against Austria-Hungary, with limited Russian support. The Romanian offensive was initially successful, against the Austro-Hungarian troops in Transylvania, but a counterattack by the forces of the Central Powers drove them back. As a result of the Battle of Bucharest, the Central Powers occupied Bucharest on 6 December 1916. Fighting in Moldova continued in 1917, resulting in some battles won by Romanians at Mărăşesti, Mărăşti and Oituz and a costly stalemate for the Central Powers. Russian withdrawal from the war in late 1917 as a result of the October Revolution meant that Romania was forced to sign an armistice with the Central Powers on 9 December 1917.\n\nIn January 1918, Romanian forces established control over Bessarabia as the Russian Army abandoned the province. Although a treaty was signed by the Romanian and Bolshevik Russian governments following talks between 5 and 9 March 1918 on the withdrawal of Romanian forces from Bessarabia within two months, on 27 March 1918 Romania formally attached Bessarabia, inhabited by a Romanian majority, to its territory, based on a resolution passed by the local assembly of that territory on its unification with Romania.\n\nRomania officially made peace with the Central Powers by signing the Treaty of Bucharest on 7 May 1918. Under the treaty, Romania was obliged to end the war with the Central Powers and make small territorial concessions to Austria-Hungary, ceding control of some passes in the Carpathian Mountains, and to grant oil concessions to Germany. In exchange, the Central Powers recognised the sovereignty of Romania over Bessarabia. The treaty was renounced in October 1918 by the Alexandru Marghiloman government, and Romania nominally re-entered the war on 10 November 1918. The next day, the Treaty of Bucharest was nullified by the terms of the Armistice of Compiègne. Total Romanian deaths from 1914 to 1918, military and civilian, within contemporary borders, were estimated at 748,000.\n\nRussian plans for the start of the war called for simultaneous invasions of Austrian Galicia and East Prussia. Although Russia's initial advance into Galicia was largely successful, it was driven back from East Prussia by Hindenburg and Ludendorff at the battles of Tannenberg and the Masurian Lakes in August and September 1914. Russia's less developed industrial base and ineffective military leadership were instrumental in the events that unfolded. By the spring of 1915, the Russians had retreated to Galicia, and, in May, the Central Powers achieved a remarkable breakthrough on Poland's southern frontiers with their Gorlice–Tarnów Offensive. On 5 August, they captured Warsaw and forced the Russians to withdraw from Poland.\n\nDespite Russia's success in the June 1916 Brusilov Offensive against the Austrians in eastern Galicia, the offensive was undermined by the reluctance of other Russian generals to commit their forces to support the victory. Allied and Russian forces were revived only temporarily by Romania's entry into the war on 27 August. German forces came to the aid of embattled Austro-Hungarian units in Transylvania while a German-Bulgarian force attacked from the south; Bucharest was taken by the Central Powers on 6 December and Romania knocked out of the war. Meanwhile, unrest grew in Russia as the Tsar remained at the front. The increasingly incompetent rule of Empress Alexandra drew protests and resulted in the murder of her favourite, Rasputin, at the end of 1916.\n\nIn March 1917, demonstrations in Petrograd culminated in the abdication of Tsar Nicholas II and the appointment of a weak Provisional Government, which shared power with the Petrograd Soviet socialists. This arrangement led to confusion and chaos both at the front and at home. The army became increasingly ineffective.\n\nFollowing the Tsar's abdication, Vladimir Lenin—with the help of the German government—was ushered by train from Switzerland into Russia 16 April 1917. Discontent and the weaknesses of the Provisional Government led to a rise in the popularity of the Bolshevik Party, led by Lenin, which demanded an immediate end to the war. The Revolution of November was followed in December by an armistice and negotiations with Germany. At first, the Bolsheviks refused the German terms, but when German troops began marching across Ukraine unopposed, the new government acceded to the Treaty of Brest-Litovsk on 3 March 1918. The treaty ceded vast territories, including Finland, the Baltic provinces, parts of Poland and Ukraine to the Central Powers. Despite this enormous German success, the manpower required by the Germans to occupy the captured territory may have contributed to the failure of the Spring Offensive, and secured relatively little food or other materiel for the Central Powers war effort.\n\nWith the adoption of the Treaty of Brest-Litovsk, the Entente no longer existed. The Allied powers led a small-scale invasion of Russia, partly to stop Germany from exploiting Russian resources, and to a lesser extent, to support the \"Whites\" (as opposed to the \"Reds\") in the Russian Civil War. Allied troops landed in Arkhangelsk and in Vladivostok as part of the North Russia Intervention.\n\nThe Czechoslovak Legion fought with the Entente; its goal was to win support for the independence of Czechoslovakia. The Legion in Russia was established in September 1914, in December 1917 in France (including volunteers from America) and in April 1918 in Italy. Czechoslovak Legion troops defeated the Austro-Hungarian army at the Ukrainian village of Zborov, in July 1917. After this success, the number of Czechoslovak legionaries increased, as well as Czechoslovak military power. In the Battle of Bakhmach, the Legion defeated the Germans and forced them to make a truce.\n\nIn Russia, they were heavily involved in the Russian Civil War, siding with the Whites against the Bolsheviks, at times controlling most of the Trans-Siberian railway and conquering all the major cities of Siberia. The presence of the Czechoslovak Legion near Yekaterinburg appears to have been one of the motivations for the Bolshevik execution of the Tsar and his family in July 1918. Legionaries arrived less than a week afterwards and captured the city. Because Russia's European ports were not safe, the corps was evacuated by a long detour via the port of Vladivostok. The last transport was the American ship Heffron in September 1920.\n\nOn 12 December 1916, after ten brutal months of the Battle of Verdun and a successful offensive against Romania, Germany attempted to negotiate a peace with the Allies. However, this attempt was rejected out of hand as a \"duplicitous war ruse\".\n\nSoon after, the US President, Woodrow Wilson, attempted to intervene as a peacemaker, asking in a note for both sides to state their demands. Lloyd George's War Cabinet considered the German offer to be a ploy to create divisions amongst the Allies. After initial outrage and much deliberation, they took Wilson's note as a separate effort, signalling that the United States was on the verge of entering the war against Germany following the \"submarine outrages\". While the Allies debated a response to Wilson's offer, the Germans chose to rebuff it in favour of \"a direct exchange of views\". Learning of the German response, the Allied governments were free to make clear demands in their response of 14 January. They sought restoration of damages, the evacuation of occupied territories, reparations for France, Russia and Romania, and a recognition of the principle of nationalities. This included the liberation of Italians, Slavs, Romanians, Czecho-Slovaks, and the creation of a \"free and united Poland\". On the question of security, the Allies sought guarantees that would prevent or limit future wars, complete with sanctions, as a condition of any peace settlement. The negotiations failed and the Entente powers rejected the German offer on the grounds that Germany had not put forward any specific proposals.\n\nEvents of 1917 proved decisive in ending the war, although their effects were not fully felt until 1918.\n\nThe British naval blockade began to have a serious impact on Germany. In response, in February 1917, the German General Staff convinced Chancellor Theobald von Bethmann-Hollweg to declare unrestricted submarine warfare, with the goal of starving Britain out of the war. German planners estimated that unrestricted submarine warfare would cost Britain a monthly shipping loss of 600,000 tons. The General Staff acknowledged that the policy would almost certainly bring the United States into the conflict, but calculated that British shipping losses would be so high that they would be forced to sue for peace after 5 to 6 months, before American intervention could make an impact. Tonnage sunk rose above 500,000 tons per month from February to July. It peaked at 860,000 tons in April. After July, the newly re-introduced convoy system became effective in reducing the U-boat threat. Britain was safe from starvation, while German industrial output fell, and the United States joined the war far earlier than Germany had anticipated.\n\nOn 3 May 1917, during the Nivelle Offensive, the French 2nd Colonial Division, veterans of the Battle of Verdun, refused orders, arriving drunk and without their weapons. Their officers lacked the means to punish an entire division, and harsh measures were not immediately implemented. The French Army Mutinies eventually spread to a further 54 French divisions, and 20,000 men deserted. However, appeals to patriotism and duty, as well as mass arrests and trials, encouraged the soldiers to return to defend their trenches, although the French soldiers refused to participate in further offensive action. Robert Nivelle was removed from command by 15 May, replaced by General Philippe Pétain, who suspended bloody large-scale attacks.\n\nThe victory of the Central Powers at the Battle of Caporetto led the Allies to convene the Rapallo Conference at which they formed the Supreme War Council to co-ordinate planning. Previously, British and French armies had operated under separate commands.\n\nIn December, the Central Powers signed an armistice with Russia, thus freeing large numbers of German troops for use in the west. With German reinforcements and new American troops pouring in, the outcome was to be decided on the Western Front. The Central Powers knew that they could not win a protracted war, but they held high hopes for success based on a final quick offensive. Furthermore, both sides became increasingly fearful of social unrest and revolution in Europe. Thus, both sides urgently sought a decisive victory.\n\nIn 1917, Emperor Charles I of Austria secretly attempted separate peace negotiations with Clemenceau, through his wife's brother Sixtus in Belgium as an intermediary, without the knowledge of Germany. Italy opposed the proposals. When the negotiations failed, his attempt was revealed to Germany, resulting in a diplomatic catastrophe.\n\nIn March and April 1917, at the First and Second Battles of Gaza, German and Ottoman forces stopped the advance of the Egyptian Expeditionary Force, which had begun in August 1916 at the Battle of Romani.\nAt the end of October, the Sinai and Palestine Campaign resumed, when General Edmund Allenby's XXth Corps, XXI Corps and Desert Mounted Corps won the Battle of Beersheba. Two Ottoman armies were defeated a few weeks later at the Battle of Mughar Ridge and, early in December, Jerusalem was captured following another Ottoman defeat at the Battle of Jerusalem. About this time, Friedrich Freiherr Kress von Kressenstein was relieved of his duties as the Eighth Army's commander, replaced by Djevad Pasha, and a few months later the commander of the Ottoman Army in Palestine, Erich von Falkenhayn, was replaced by Otto Liman von Sanders.\n\nIn early 1918, the front line was extended and the Jordan Valley was occupied, following the First Transjordan and the Second Transjordan attacks by British Empire forces in March and April 1918. In March, most of the Egyptian Expeditionary Force's British infantry and Yeomanry cavalry were sent to the Western Front as a consequence of the Spring Offensive. They were replaced by Indian Army units. During several months of reorganisation and training of the summer, a number of attacks were carried out on sections of the Ottoman front line. These pushed the front line north to more advantageous positions for the Entente in preparation for an attack and to acclimatise the newly arrived Indian Army infantry. It was not until the middle of September that the integrated force was ready for large-scale operations.\n\nThe reorganised Egyptian Expeditionary Force, with an additional mounted division, broke Ottoman forces at the Battle of Megiddo in September 1918. In two days the British and Indian infantry, supported by a creeping barrage, broke the Ottoman front line and captured the headquarters of the Eighth Army (Ottoman Empire) at Tulkarm, the continuous trench lines at Tabsor, Arara, and the Seventh Army (Ottoman Empire) headquarters at Nablus. The Desert Mounted Corps rode through the break in the front line created by the infantry. During virtually continuous operations by Australian Light Horse, British mounted Yeomanry, Indian Lancers, and New Zealand Mounted Rifle brigades in the Jezreel Valley, they captured Nazareth, Afulah and Beisan, Jenin, along with Haifa on the Mediterranean coast and Daraa east of the Jordan River on the Hejaz railway. Samakh and Tiberias on the Sea of Galilee were captured on the way northwards to Damascus. Meanwhile, Chaytor's Force of Australian light horse, New Zealand mounted rifles, Indian, British West Indies and Jewish infantry captured the crossings of the Jordan River, Es Salt, Amman and at Ziza most of the Fourth Army (Ottoman Empire). The Armistice of Mudros, signed at the end of October, ended hostilities with the Ottoman Empire when fighting was continuing north of Aleppo.\n\nOn or shortly before 15 August 1917 Pope Benedict XV made a peace proposal suggesting:\n\nAt the outbreak of the war, the United States pursued a policy of non-intervention, avoiding conflict while trying to broker a peace. When the German U-boat \"U-20\" sank the British liner RMS \"Lusitania\" on 7 May 1915 with 128 Americans among the dead, President Woodrow Wilson insisted that America is \"too proud to fight\" but demanded an end to attacks on passenger ships. Germany complied. Wilson unsuccessfully tried to mediate a settlement. However, he also repeatedly warned that the United States would not tolerate unrestricted submarine warfare, in violation of international law. Former president Theodore Roosevelt denounced German acts as \"piracy\". Wilson was narrowly re-elected in 1916 after campaigning with the slogan \"he kept us out of war\".\n\nIn January 1917, Germany decided to resume unrestricted submarine warfare, realising it would mean American entry. The German Foreign Minister, in the Zimmermann Telegram, invited Mexico to join the war as Germany's ally against the United States. In return, the Germans would finance Mexico's war and help it recover the territories of Texas, New Mexico, and Arizona. The United Kingdom intercepted the message and presented it to the US embassy in the UK. From there it made its way to President Wilson who released the Zimmermann note to the public, and Americans saw it as \"casus belli\". Wilson called on anti-war elements to end all wars, by winning this one and eliminating militarism from the globe. He argued that the war was so important that the US had to have a voice in the peace conference. After the sinking of seven US merchant ships by submarines and the publication of the Zimmermann telegram, Wilson called for war on Germany on 2 April 1917, which the US Congress declared 4 days later.\n\nThe United States was never formally a member of the Allies but became a self-styled \"Associated Power\". The United States had a small army, but, after the passage of the Selective Service Act, it drafted 2.8 million men, and, by summer 1918, was sending 10,000 fresh soldiers to France every day. In 1917, the US Congress granted US citizenship to Puerto Ricans to allow them to be drafted to participate in World War I, as part of the Jones–Shafroth Act. German General Staff assumptions that it would be able to defeat the British and French forces before American troops reinforced them were proven incorrect.\n\nThe United States Navy sent a battleship group to Scapa Flow to join with the British Grand Fleet, destroyers to Queenstown, Ireland, and submarines to help guard convoys. Several regiments of US Marines were also dispatched to France. The British and French wanted American units used to reinforce their troops already on the battle lines and not waste scarce shipping on bringing over supplies. General John J. Pershing, American Expeditionary Forces (AEF) commander, refused to break up American units to be used as filler material. As an exception, he did allow African-American combat regiments to be used in French divisions. The Harlem Hellfighters fought as part of the French 16th Division, and earned a unit Croix de Guerre for their actions at Château-Thierry, Belleau Wood, and Sechault. AEF doctrine called for the use of frontal assaults, which had long since been discarded by British Empire and French commanders due to the large loss of life that resulted.\n\nLudendorff drew up plans (codenamed Operation Michael) for the 1918 offensive on the Western Front. The Spring Offensive sought to divide the British and French forces with a series of feints and advances. The German leadership hoped to end the war before significant US forces arrived. The operation commenced on 21 March 1918 with an attack on British forces near Saint-Quentin. German forces achieved an unprecedented advance of .\n\nBritish and French trenches were penetrated using novel infiltration tactics, also named \"Hutier\" tactics after General Oskar von Hutier, by specially trained units called stormtroopers. Previously, attacks had been characterised by long artillery bombardments and massed assaults. In the Spring Offensive of 1918, however, Ludendorff used artillery only briefly and infiltrated small groups of infantry at weak points. They attacked command and logistics areas and bypassed points of serious resistance. More heavily armed infantry then destroyed these isolated positions. This German success relied greatly on the element of surprise.\n\nThe front moved to within of Paris. Three heavy Krupp railway guns fired 183 shells on the capital, causing many Parisians to flee. The initial offensive was so successful that Kaiser Wilhelm II declared 24 March a national holiday. Many Germans thought victory was near. After heavy fighting, however, the offensive was halted. Lacking tanks or motorised artillery, the Germans were unable to consolidate their gains. The problems of re-supply were also exacerbated by increasing distances that now stretched over terrain that was shell-torn and often impassable to traffic.\n\nGeneral Foch pressed to use the arriving American troops as individual replacements, whereas Pershing sought to field American units as an independent force. These units were assigned to the depleted French and British Empire commands on 28 March. A Supreme War Council of Allied forces was created at the Doullens Conference on 5 November 1917. General Foch was appointed as supreme commander of the Allied forces. Haig, Petain, and Pershing retained tactical control of their respective armies; Foch assumed a co-ordinating rather than a directing role, and the British, French, and US commands operated largely independently.\n\nFollowing Operation Michael, Germany launched Operation Georgette against the northern English Channel ports. The Allies halted the drive after limited territorial gains by Germany. The German Army to the south then conducted Operations Blücher and Yorck, pushing broadly towards Paris. Germany launched Operation Marne (Second Battle of the Marne) on 15 July, in an attempt to encircle Reims. The resulting counter-attack, which started the Hundred Days Offensive, marked the first successful Allied offensive of the war. By 20 July, the Germans had retreated across the Marne to their starting lines, having achieved little, and the German Army never regained the initiative. German casualties between March and April 1918 were 270,000, including many highly trained storm troopers.\n\nMeanwhile, Germany was falling apart at home. Anti-war marches became frequent and morale in the army fell. Industrial output was half the 1913 levels.\n\nIn the late spring of 1918, three new states were formed in the South Caucasus: the First Republic of Armenia, the Azerbaijan Democratic Republic, and the Democratic Republic of Georgia, which declared their independence from the Russian Empire. Two other minor entities were established, the Centrocaspian Dictatorship and South West Caucasian Republic (the former was liquidated by Azerbaijan in the autumn of 1918 and the latter by a joint Armenian-British task force in early 1919). With the withdrawal of the Russian armies from the Caucasus front in the winter of 1917–18, the three major republics braced for an imminent Ottoman advance, which commenced in the early months of 1918. Solidarity was briefly maintained when the Transcaucasian Federative Republic was created in the spring of 1918, but this collapsed in May, when the Georgians asked for and received protection from Germany and the Azerbaijanis concluded a treaty with the Ottoman Empire that was more akin to a military alliance. Armenia was left to fend for itself and struggled for five months against the threat of a full-fledged occupation by the Ottoman Turks before defeating them at the Battle of Sardarabad.\n\nThe Allied counteroffensive, known as the Hundred Days Offensive, began on 8 August 1918, with the Battle of Amiens. The battle involved over 400 tanks and 120,000 British, Dominion, and French troops, and by the end of its first day a gap long had been created in the German lines. The defenders displayed a marked collapse in morale, causing Ludendorff to refer to this day as the \"Black Day of the German army\". After an advance as far as , German resistance stiffened, and the battle was concluded on 12 August.\n\nRather than continuing the Amiens battle past the point of initial success, as had been done so many times in the past, the Allies shifted attention elsewhere. Allied leaders had now realised that to continue an attack after resistance had hardened was a waste of lives, and it was better to turn a line than to try to roll over it. They began to undertake attacks in quick order to take advantage of successful advances on the flanks, then broke them off when each attack lost its initial impetus.\n\nThe day after the Offensive began, Ludendorff said: \"We cannot win the war any more, but we must not lose it either.\" On 11 August he offered his resignation to the Kaiser, who refused it, replying, \"I see that we must strike a balance. We have nearly reached the limit of our powers of resistance. The war must be ended.\" On 13 August, at Spa, Hindenburg, Ludendorff, the Chancellor, and Foreign Minister Hintz agreed that the war could not be ended militarily and, on the following day, the German Crown Council decided that victory in the field was now most improbable. Austria and Hungary warned that they could only continue the war until December, and Ludendorff recommended immediate peace negotiations. Prince Rupprecht warned Prince Max of Baden: \"Our military situation has deteriorated so rapidly that I no longer believe we can hold out over the winter; it is even possible that a catastrophe will come earlier.\"\n\nBritish and Dominion forces launched the next phase of the campaign with the Battle of Albert on 21 August. The assault was widened by French and then further British forces in the following days. During the last week of August the Allied pressure along a front against the enemy was heavy and unrelenting. From German accounts, \"Each day was spent in bloody fighting against an ever and again on-storming enemy, and nights passed without sleep in retirements to new lines.\"\n\nFaced with these advances, on 2 September the German Supreme Army Command issued orders to withdraw in the south to the Hindenburg Line. This ceded without a fight the salient seized the previous April. According to Ludendorff, \"We had to admit the necessity ... to withdraw the entire front from the Scarpe to the Vesle. In nearly four weeks of fighting beginning on 8 August, over 100,000 German prisoners were taken. The German High Command realised that the war was lost and made attempts to reach a satisfactory end. On 10 September Hindenburg urged peace moves to Emperor Charles of Austria, and Germany appealed to the Netherlands for mediation. On 14 September Austria sent a note to all belligerents and neutrals suggesting a meeting for peace talks on neutral soil, and on 15 September Germany made a peace offer to Belgium. Both peace offers were rejected.\n\nIn September the Allies advanced to the Hindenburg Line in the north and centre. The Germans continued to fight strong rear-guard actions and launched numerous counterattacks, but positions and outposts of the Line continued to fall, with the BEF alone taking 30,441 prisoners in the last week of September. On 24 September an assault by both the British and French came within of St. Quentin. The Germans had now retreated to positions along or behind the Hindenburg Line. That same day, Supreme Army Command informed the leaders in Berlin that armistice talks were inevitable.\n\nThe final assault on the Hindenburg Line began with the Meuse-Argonne Offensive, launched by French and American troops on 26 September. The following week, co-operating French and American units broke through in Champagne at the Battle of Blanc Mont Ridge, forcing the Germans off the commanding heights, and closing towards the Belgian frontier. On 8 October the line was pierced again by British and Dominion troops at the Battle of Cambrai. The German army had to shorten its front and use the Dutch frontier as an anchor to fight rear-guard actions as it fell back towards Germany.\n\nWhen Bulgaria signed a separate armistice on 29 September, Ludendorff, having been under great stress for months, suffered something similar to a breakdown. It was evident that Germany could no longer mount a successful defence.The collapse of the Balkans meant that Germany was about to lose its main supplies of oil and food. Its reserves had been used up, even as US troops kept arriving at the rate of 10,000 per day. The Americans supplied more than 80% of Allied oil during the war, and there was no shortage.\n\nNews of Germany's impending military defeat spread throughout the German armed forces. The threat of mutiny was rife. Admiral Reinhard Scheer and Ludendorff decided to launch a last attempt to restore the \"valour\" of the German Navy.\n\nIn northern Germany, the German Revolution of 1918–1919 began at the end of October 1918. Units of the German Navy refused to set sail for a last, large-scale operation in a war they believed to be as good as lost, initiating the uprising. The sailors' revolt, which then ensued in the naval ports of Wilhelmshaven and Kiel, spread across the whole country within days and led to the proclamation of a republic on 9 November 1918, shortly thereafter to the abdication of Kaiser Wilhelm II, and to German surrender.\n\nWith the military faltering and with widespread loss of confidence in the Kaiser leading to his abdication and fleeing of the country, Germany moved towards surrender. Prince Maximilian of Baden took charge of a new government on 3 October as Chancellor of Germany to negotiate with the Allies. Negotiations with President Wilson began immediately, in the hope that he would offer better terms than the British and French. Wilson demanded a constitutional monarchy and parliamentary control over the German military. There was no resistance when the Social Democrat Philipp Scheidemann on 9 November declared Germany to be a republic. The Kaiser, kings and other hereditary rulers all were removed from power and Wilhelm fled to exile in the Netherlands. Imperial Germany was dead; a new Germany had been born as the Weimar Republic.\n\nThe collapse of the Central Powers came swiftly. Bulgaria was the first to sign an armistice, the Armistice of Salonica on 29 September 1918. On 30 October, the Ottoman Empire capitulated, signing the Armistice of Mudros.\n\nOn 24 October, the Italians began a push that rapidly recovered territory lost after the Battle of Caporetto. This culminated in the Battle of Vittorio Veneto, which marked the end of the Austro-Hungarian Army as an effective fighting force. The offensive also triggered the disintegration of the Austro-Hungarian Empire. During the last week of October, declarations of independence were made in Budapest, Prague, and Zagreb. On 29 October, the imperial authorities asked Italy for an armistice, but the Italians continued advancing, reaching Trento, Udine, and Trieste. On 3 November, Austria-Hungary sent a flag of truce to ask for an armistice (Armistice of Villa Giusti). The terms, arranged by telegraph with the Allied Authorities in Paris, were communicated to the Austrian commander and accepted. The Armistice with Austria was signed in the Villa Giusti, near Padua, on 3 November. Austria and Hungary signed separate armistices following the overthrow of the Habsburg Monarchy. In the following days the Italian Army occupied Innsbruck and all Tyrol with 20 to 22,000 soldiers.\n\nOn 11 November, at 5:00 am, an armistice with Germany was signed in a railroad carriage at Compiègne. At 11 am on 11 November 1918—\"the eleventh hour of the eleventh day of the eleventh month\"—a ceasefire came into effect. During the six hours between the signing of the armistice and its taking effect, opposing armies on the Western Front began to withdraw from their positions, but fighting continued along many areas of the front, as commanders wanted to capture territory before the war ended. The occupation of the Rhineland took place following the Armistice. The occupying armies consisted of American, Belgian, British and French forces.\n\nIn November 1918, the Allies had ample supplies of men and materiel to invade Germany. Yet at the time of the armistice, no Allied force had crossed the German frontier, the Western Front was still some from Berlin, and the Kaiser's armies had retreated from the battlefield in good order. These factors enabled Hindenburg and other senior German leaders to spread the story that their armies had not really been defeated. This resulted in the stab-in-the-back legend, which attributed Germany's defeat not to its inability to continue fighting (even though up to a million soldiers were suffering from the 1918 flu pandemic and unfit to fight), but to the public's failure to respond to its \"patriotic calling\" and the supposed intentional sabotage of the war effort, particularly by Jews, Socialists, and Bolsheviks.\n\nThe Allies had much more potential wealth they could spend on the war. One estimate (using 1913 US dollars) is that the Allies spent $58 billion on the war and the Central Powers only $25 billion. Among the Allies, the UK spent $21 billion and the US $17 billion; among the Central Powers Germany spent $20 billion.\n\nIn the aftermath of the war, four empires disappeared: the German, Austro-Hungarian, Ottoman, and Russian. Numerous nations regained their former independence, and new ones were created. Four dynasties, together with their ancillary aristocracies, fell as a result of the war: the Romanovs, the Hohenzollerns, the Habsburgs, and the Ottomans. Belgium and Serbia were badly damaged, as was France, with 1.4 million soldiers dead, not counting other casualties. Germany and Russia were similarly affected.\n\nA formal state of war between the two sides persisted for another seven months, until the signing of the Treaty of Versailles with Germany on 28 June 1919. The United States Senate did not ratify the treaty despite public support for it, and did not formally end its involvement in the war until the Knox–Porter Resolution was signed on 2 July 1921 by President Warren G. Harding. For the United Kingdom and the British Empire, the state of war ceased under the provisions of the \"Termination of the Present War (Definition) Act 1918\" with respect to:\n\nAfter the Treaty of Versailles, treaties with Austria, Hungary, Bulgaria, and the Ottoman Empire were signed. However, the negotiation of the treaty with the Ottoman Empire was followed by strife, and a final peace treaty between the Allied Powers and the country that would shortly become the Republic of Turkey was not signed until 24 July 1923, at Lausanne.\n\nSome war memorials date the end of the war as being when the Versailles Treaty was signed in 1919, which was when many of the troops serving abroad finally returned home; by contrast, most commemorations of the war's end concentrate on the armistice of 11 November 1918. Legally, the formal peace treaties were not complete until the last, the Treaty of Lausanne, was signed. Under its terms, the Allied forces left Constantinople on 23 August 1923.\n\nAfter the war, the Paris Peace Conference imposed a series of peace treaties on the Central Powers officially ending the war. The 1919 Treaty of Versailles dealt with Germany and, building on Wilson's 14th point, brought into being the League of Nations on 28 June 1919.\n\nThe Central Powers had to acknowledge responsibility for \"all the loss and damage to which the Allied and Associated Governments and their nationals have been subjected as a consequence of the war imposed upon them by\" their aggression. In the Treaty of Versailles, this statement was Article 231. This article became known as the War Guilt clause as the majority of Germans felt humiliated and resentful. Overall the Germans felt they had been unjustly dealt with by what they called the \"diktat of Versailles\". German historian Hagen Schulze said the Treaty placed Germany \"under legal sanctions, deprived of military power, economically ruined, and politically humiliated.\" Belgian historian Laurence Van Ypersele emphasises the central role played by memory of the war and the Versailles Treaty in German politics in the 1920s and 1930s:\nActive denial of war guilt in Germany and German resentment at both reparations and continued Allied occupation of the Rhineland made widespread revision of the meaning and memory of the war problematic. The legend of the \"stab in the back\" and the wish to revise the \"Versailles diktat\", and the belief in an international threat aimed at the elimination of the German nation persisted at the heart of German politics. Even a man of peace such as <nowiki>[</nowiki>Gustav<nowiki>]</nowiki> Stresemann publicly rejected German guilt. As for the Nazis, they waved the banners of domestic treason and international conspiracy in an attempt to galvanise the German nation into a spirit of revenge. Like a Fascist Italy, Nazi Germany sought to redirect the memory of the war to the benefit of its own policies.\n\nMeanwhile, new nations liberated from German rule viewed the treaty as recognition of wrongs committed against small nations by much larger aggressive neighbours. The Peace Conference required all the defeated powers to pay reparations for all the damage done to civilians. However, owing to economic difficulties and Germany being the only defeated power with an intact economy, the burden fell largely on Germany.\n\nAustria-Hungary was partitioned into several successor states, including Austria, Hungary, Czechoslovakia, and Yugoslavia, largely but not entirely along ethnic lines. Transylvania was shifted from Hungary to Greater Romania. The details were contained in the Treaty of Saint-Germain and the Treaty of Trianon. As a result of the Treaty of Trianon, 3.3 million Hungarians came under foreign rule. Although the Hungarians made up 54% of the population of the pre-war Kingdom of Hungary, only 32% of its territory was left to Hungary. Between 1920 and 1924, 354,000 Hungarians fled former Hungarian territories attached to Romania, Czechoslovakia, and Yugoslavia.\n\nThe Russian Empire, which had withdrawn from the war in 1917 after the October Revolution, lost much of its western frontier as the newly independent nations of Estonia, Finland, Latvia, Lithuania, and Poland were carved from it. Romania took control of Bessarabia in April 1918.\n\nThe Ottoman Empire disintegrated, with much of its Levant territory awarded to various Allied powers as protectorates. The Turkish core in Anatolia was reorganised as the Republic of Turkey. The Ottoman Empire was to be partitioned by the Treaty of Sèvres of 1920. This treaty was never ratified by the Sultan and was rejected by the Turkish National Movement, leading to the victorious Turkish War of Independence and the much less stringent 1923 Treaty of Lausanne.\n\nEven though a lot of countries had already made a peace treaty, there was one exception, Andorra. Andorra declared war on Germany in August 1914, but, because it had a very small population, Andorra had never sent any soldiers to the battlefield. Because of that, Andorra wasn't allowed to go to the Treaty of Versailles, so the country hadn't made a peace treaty with Germany until 1958.\nWhen Andorra made the declaration of war, it had an army of 600 part-time militarymen, commanded by two officials.\n\nAfter 123 years, Poland re-emerged as an independent country. The Kingdom of Serbia and its dynasty, as a \"minor Entente nation\" and the country with the most casualties per capita, became the backbone of a new multinational state, the Kingdom of Serbs, Croats and Slovenes, later renamed Yugoslavia. Czechoslovakia, combining the Kingdom of Bohemia with parts of the Kingdom of Hungary, became a new nation. Russia became the Soviet Union and lost Finland, Estonia, Lithuania, and Latvia, which became independent countries. The Ottoman Empire was soon replaced by Turkey and several other countries in the Middle East.\n\nIn the British Empire, the war unleashed new forms of nationalism. In Australia and New Zealand the Battle of Gallipoli became known as those nations' \"Baptism of Fire\". It was the first major war in which the newly established countries fought, and it was one of the first times that Australian troops fought as Australians, not just subjects of the British Crown. Anzac Day, commemorating the Australian and New Zealand Army Corps, celebrates this defining moment.\n\nAfter the Battle of Vimy Ridge, where the Canadian divisions fought together for the first time as a single corps, Canadians began to refer to their country as a nation \"forged from fire\". Having succeeded on the same battleground where the \"mother countries\" had previously faltered, they were for the first time respected internationally for their own accomplishments. Canada entered the war as a Dominion of the British Empire and remained so, although it emerged with a greater measure of independence. When Britain declared war in 1914, the dominions were automatically at war; at the conclusion, Canada, Australia, New Zealand, and South Africa were individual signatories of the Treaty of Versailles.\n\nLobbying by Chaim Weizmann and fear that American Jews would encourage the United States to support Germany culminated in the British government's Balfour Declaration of 1917, endorsing creation of a Jewish homeland in Palestine. A total of more than 1,172,000 Jewish soldiers served in the Allied and Central Power forces in World War I, including 275,000 in Austria-Hungary and 450,000 in Tsarist Russia.\n\nThe establishment of the modern state of Israel and the roots of the continuing Israeli–Palestinian conflict are partially found in the unstable power dynamics of the Middle East that resulted from World War I. Before the end of the war, the Ottoman Empire had maintained a modest level of peace and stability throughout the Middle East. With the fall of the Ottoman government, power vacuums developed and conflicting claims to land and nationhood began to emerge. The political boundaries drawn by the victors of World War I were quickly imposed, sometimes after only cursory consultation with the local population. These continue to be problematic in the 21st-century struggles for national identity. While the dissolution of the Ottoman Empire at the end of World War I was pivotal in contributing to the modern political situation of the Middle East, including the Arab-Israeli conflict, the end of Ottoman rule also spawned lesser known disputes over water and other natural resources.\n\nThe war had profound consequences on the health of soldiers. Of the 60 million European military personnel who were mobilised from 1914 to 1918, 8 million were killed, 7 million were permanently disabled, and 15 million were seriously injured. Germany lost 15.1% of its active male population, Austria-Hungary lost 17.1%, and France lost 10.5%. In Germany, civilian deaths were 474,000 higher than in peacetime, due in large part to food shortages and malnutrition that weakened resistance to disease. By the end of the war, starvation caused by famine had killed approximately 100,000 people in Lebanon. Between 5 and 10 million people died in the Russian famine of 1921. By 1922, there were between 4.5 million and 7 million homeless children in Russia as a result of nearly a decade of devastation from World War I, the Russian Civil War, and the subsequent famine of 1920–1922. Numerous anti-Soviet Russians fled the country after the Revolution; by the 1930s, the northern Chinese city of Harbin had 100,000 Russians. Thousands more emigrated to France, England, and the United States.\n\nThe Australian prime minister, Billy Hughes, wrote to the British prime minister, Lloyd George, \"You have assured us that you cannot get better terms. I much regret it, and hope even now that some way may be found of securing agreement for demanding reparation commensurate with the tremendous sacrifices made by the British Empire and her Allies.\" Australia received £5,571,720 war reparations, but the direct cost of the war to Australia had been £376,993,052, and, by the mid-1930s, repatriation pensions, war gratuities, interest and sinking fund charges were £831,280,947. Of about 416,000 Australians who served, about 60,000 were killed and another 152,000 were wounded.\n\nDiseases flourished in the chaotic wartime conditions. In 1914 alone, louse-borne epidemic typhus killed 200,000 in Serbia. From 1918 to 1922, Russia had about 25 million infections and 3 million deaths from epidemic typhus. In 1923, 13 million Russians contracted malaria, a sharp increase from the pre-war years. In addition, a major influenza epidemic spread around the world. Overall, the 1918 flu pandemic killed at least 50 million people.\n\nThe social disruption and widespread violence of the Russian Revolution of 1917 and the ensuing Russian Civil War sparked more than 2,000 pogroms in the former Russian Empire, mostly in Ukraine. An estimated 60,000–200,000 civilian Jews were killed in the atrocities.\n\nIn the aftermath of World War I, Greece fought against Turkish nationalists led by Mustafa Kemal, a war that eventually resulted in a massive population exchange between the two countries under the Treaty of Lausanne. According to various sources, several hundred thousand Greeks died during this period, which was tied in with the Greek Genocide.\n\nWorld War I began as a clash of 20th-century technology and 19th-century tactics, with the inevitably large ensuing casualties. By the end of 1917, however, the major armies, now numbering millions of men, had modernised and were making use of telephone, wireless communication, armoured cars, tanks, and aircraft. Infantry formations were reorganised, so that 100-man companies were no longer the main unit of manoeuvre; instead, squads of 10 or so men, under the command of a junior NCO, were favoured.\n\nArtillery also underwent a revolution. In 1914, cannons were positioned in the front line and fired directly at their targets. By 1917, indirect fire with guns (as well as mortars and even machine guns) was commonplace, using new techniques for spotting and ranging, notably aircraft and the often overlooked field telephone. Counter-battery missions became commonplace, also, and sound detection was used to locate enemy batteries.\n\nGermany was far ahead of the Allies in using heavy indirect fire. The German Army employed and howitzers in 1914, when typical French and British guns were only and . The British had a 6-inch (152 mm) howitzer, but it was so heavy it had to be hauled to the field in pieces and assembled. The Germans also fielded Austrian and guns and, even at the beginning of the war, had inventories of various calibres of \"Minenwerfer\", which were ideally suited for trench warfare.\n\nOn 27 June 1917 the Germans used the biggest gun in the world, Batterie Pommern, nicknamed \"Lange Max\". This gun from Krupp was able to shoot 750 kg shells from Koekelare to Dunkirk, a distance of about .\n\nMuch of the combat involved trench warfare, in which hundreds often died for each metre gained. Many of the deadliest battles in history occurred during World War I. Such battles include Ypres, the Marne, Cambrai, the Somme, Verdun, and Gallipoli. The Germans employed the Haber process of nitrogen fixation to provide their forces with a constant supply of gunpowder despite the British naval blockade. Artillery was responsible for the largest number of casualties and consumed vast quantities of explosives. The large number of head wounds caused by exploding shells and fragmentation forced the combatant nations to develop the modern steel helmet, led by the French, who introduced the Adrian helmet in 1915. It was quickly followed by the Brodie helmet, worn by British Imperial and US troops, and in 1916 by the distinctive German \"Stahlhelm\", a design, with improvements, still in use today.\n\nThe widespread use of chemical warfare was a distinguishing feature of the conflict. Gases used included chlorine, mustard gas and phosgene. Relatively few war casualties were caused by gas, as effective countermeasures to gas attacks were quickly created, such as gas masks. The use of chemical warfare and small-scale strategic bombing were both outlawed by the Hague Conventions of 1899 and 1907, and both proved to be of limited effectiveness, though they captured the public imagination.\n\nThe most powerful land-based weapons were railway guns, weighing dozens of tons apiece. The German version were nicknamed Big Berthas, even though the namesake was not a railway gun. Germany developed the Paris Gun, able to bombard Paris from over , though shells were relatively light at 94 kilograms (210 lb).\n\nTrenches, machine guns, air reconnaissance, barbed wire, and modern artillery with fragmentation shells helped bring the battle lines of World War I to a stalemate. The British and the French sought a solution with the creation of the tank and mechanised warfare. The British first tanks were used during the Battle of the Somme on 15 September 1916. Mechanical reliability was an issue, but the experiment proved its worth. Within a year, the British were fielding tanks by the hundreds, and they showed their potential during the Battle of Cambrai in November 1917, by breaking the Hindenburg Line, while combined arms teams captured 8,000 enemy soldiers and 100 guns. Meanwhile, the French introduced the first tanks with a rotating turret, the Renault FT, which became a decisive tool of the victory. The conflict also saw the introduction of light automatic weapons and submachine guns, such as the Lewis Gun, the Browning automatic rifle, and the Bergmann MP18.\n\nAnother new weapon, the flamethrower, was first used by the German army and later adopted by other forces. Although not of high tactical value, the flamethrower was a powerful, demoralising weapon that caused terror on the battlefield.\n\nTrench railways evolved to supply the enormous quantities of food, water, and ammunition required to support large numbers of soldiers in areas where conventional transportation systems had been destroyed. Internal combustion engines and improved traction systems for automobiles and trucks/lorries eventually rendered trench railways obsolete.\n\nOn the Western Front neither side made impressive gains in the first three years of the war with attacks at Verdun, the Somme, Passchendaele, and Cambrai the exception was Nivelle's Offensive in which the German defence gave ground while mauling the attackers so badly that there were mutinies in the French Army. In 1918 the Germans smashed through the defence lines in three great attacks: Michael, on the Lys, and on the Aisne, which displayed the power of their new tactics. The Allies struck back at Soissons, which showed the Germans that they must return to the defensive, and at Amiens; tanks played a prominent role in both of these assaults, as they had the year before at Cambrai.\n\nThe areas in the East were larger. The Germans did well at the First Masurian Lakes driving the invaders from East Prussia, and at Riga, which led the Russians to sue for peace. The Austro-Hungarians and Germans joined for a great success at Gorlice–Tarnów, which drove the Russians out of Poland. In a series of attacks along with the Bulgarians they occupied Serbia, Albania, Montenegro and most of Romania. The Allies successes came later in Palestine, the beginning of the end for the Ottomans, in Macedonia, which drove the Bulgarians out of the war, and at Vittorio Veneto, the final blow for the Austro-Hungarians. The area occupied in East by the Central powers on 11 November 1918 was .\n\nGermany deployed U-boats (submarines) after the war began. Alternating between restricted and unrestricted submarine warfare in the Atlantic, the Kaiserliche Marine employed them to deprive the British Isles of vital supplies. The deaths of British merchant sailors and the seeming invulnerability of U-boats led to the development of depth charges (1916), hydrophones (passive sonar, 1917), blimps, hunter-killer submarines (HMS \"R-1\", 1917), forward-throwing anti-submarine weapons, and dipping hydrophones (the latter two both abandoned in 1918). To extend their operations, the Germans proposed supply submarines (1916). Most of these would be forgotten in the interwar period until World War II revived the need.\n\nFixed-wing aircraft were first used militarily by the Italians in Libya on 23 October 1911 during the Italo-Turkish War for reconnaissance, soon followed by the dropping of grenades and aerial photography the next year. By 1914, their military utility was obvious. They were initially used for reconnaissance and ground attack. To shoot down enemy planes, anti-aircraft guns and fighter aircraft were developed. Strategic bombers were created, principally by the Germans and British, though the former used Zeppelins as well. Towards the end of the conflict, aircraft carriers were used for the first time, with launching Sopwith Camels in a raid to destroy the Zeppelin hangars at Tondern in 1918.\n\nManned observation balloons, floating high above the trenches, were used as stationary reconnaissance platforms, reporting enemy movements and directing artillery. Balloons commonly had a crew of two, equipped with parachutes, so that if there was an enemy air attack the crew could parachute to safety. At the time, parachutes were too heavy to be used by pilots of aircraft (with their marginal power output), and smaller versions were not developed until the end of the war; they were also opposed by the British leadership, who feared they might promote cowardice.\n\nRecognised for their value as observation platforms, balloons were important targets for enemy aircraft. To defend them against air attack, they were heavily protected by antiaircraft guns and patrolled by friendly aircraft; to attack them, unusual weapons such as air-to-air rockets were tried. Thus, the reconnaissance value of blimps and balloons contributed to the development of air-to-air combat between all types of aircraft, and to the trench stalemate, because it was impossible to move large numbers of troops undetected. The Germans conducted air raids on England during 1915 and 1916 with airships, hoping to damage British morale and cause aircraft to be diverted from the front lines, and indeed the resulting panic led to the diversion of several squadrons of fighters from France.\n\nOn 19 August 1915, the German submarine U-27 was sunk by the British Q-ship . All German survivors were summarily executed by \"Baralong\"s crew on the orders of Lieutenant Godfrey Herbert, the captain of the ship. The shooting was reported to the media by American citizens who were on board the \"Nicosia\", a British freighter loaded with war supplies, which was stopped by U-27 just minutes before the incident.\n\nOn 24 September, \"Baralong\" destroyed U-41, which was in the process of sinking the cargo ship \"Urbino\". According to Karl Goetz, the submarine's commander, \"Baralong\" continued to fly the US flag after firing on U-41 and then rammed the lifeboat—carrying the German survivors—sinking it.\n\nThe Canadian hospital ship was torpedoed by the German submarine SM U-86 on 27 June 1918 in violation of international law. Only 24 of the 258 medical personnel, patients, and crew survived. Survivors reported that the U-boat surfaced and ran down the lifeboats, machine-gunning survivors in the water. The U-boat captain, Helmut Patzig, was charged with war crimes in Germany following the war, but escaped prosecution by going to the Free City of Danzig, beyond the jurisdiction of German courts.\n\nAfter the war, the German government claimed that approximately 763,000 German civilians died from starvation and disease during the war because of the Allied blockade. Germany protested that the Allies had used starvation as a weapon of war. According to the British judge and legal philosopher Patrick Devlin, \"The War Orders given by the Admiralty on 26 August [1914] were clear enough. All food consigned to Germany through neutral ports was to be captured and all food consigned to Rotterdam was to be presumed consigned to Germany. ... The British were determined on the starvation policy, whether or not it was lawful.\"\n\nThe first successful use of poison gas as a weapon of warfare occurred during the Second Battle of Ypres (22 April – 25 May 1915). Gas was soon used by all major belligerents throughout the war. It is estimated that the use of chemical weapons employed by both sides throughout the war had inflicted 1.3 million casualties. For example, the British had over 180,000 chemical weapons casualties during the war, and up to one-third of American casualties were caused by them. The Russian Army reportedly suffered roughly 500,000 chemical weapon casualties in World War I. The use of chemical weapons in warfare was in direct violation of the 1899 Hague Declaration Concerning Asphyxiating Gases and the 1907 Hague Convention on Land Warfare, which prohibited their use.\n\nThe effect of poison gas was not limited to combatants. Civilians were at risk from the gases as winds blew the poison gases through their towns, and they rarely received warnings or alerts of potential danger. In addition to absent warning systems, civilians often did not have access to effective gas masks. An estimated 100,000–260,000 civilian casualties were caused by chemical weapons during the conflict and tens of thousands more (along with military personnel) died from scarring of the lungs, skin damage, and cerebral damage in the years after the conflict ended. Many commanders on both sides knew such weapons would cause major harm to civilians but nonetheless continued to use them. British Field Marshal Sir Douglas Haig wrote in his diary, \"My officers and I were aware that such weapons would cause harm to women and children living in nearby towns, as strong winds were common in the battlefront. However, because the weapon was to be directed against the enemy, none of us were overly concerned at all.\"\n\nThe ethnic cleansing of the Ottoman Empire's Armenian population, including mass deportations and executions, during the final years of the Ottoman Empire is considered genocide. The Ottomans carried out organised and systematic massacres of the Armenian population at the beginning of the war and portrayed deliberately provoked acts of Armenian resistance as rebellions to justify further extermination. In early 1915, a number of Armenians volunteered to join the Russian forces and the Ottoman government used this as a pretext to issue the Tehcir Law (Law on Deportation), which authorised the deportation of Armenians from the Empire's eastern provinces to Syria between 1915 and 1918. The Armenians were intentionally marched to death and a number were attacked by Ottoman brigands. While an exact number of deaths is unknown, the International Association of Genocide Scholars estimates 1.5 million. The government of Turkey has consistently denied the genocide, arguing that those who died were victims of inter-ethnic fighting, famine, or disease during World War I; these claims are rejected by most historians.\n\nOther ethnic groups were similarly attacked by the Ottoman Empire during this period, including Assyrians and Greeks, and some scholars consider those events to be part of the same policy of extermination. At least 250,000 Assyrian Christians, about half of the population, and 350,000–750,000 Anatolian and Pontic Greeks were killed between 1915 and 1922.\n\nMany pogroms accompanied the Russian Revolution of 1917 and the ensuing Russian Civil War. 60,000–200,000 civilian Jews were killed in the atrocities throughout the former Russian Empire (mostly within the Pale of Settlement in present-day Ukraine).\n\nThe German invaders treated any resistance—such as sabotaging rail lines—as illegal and immoral, and shot the offenders and burned buildings in retaliation. In addition, they tended to suspect that most civilians were potential \"francs-tireurs\" (guerrillas) and, accordingly, took and sometimes killed hostages from among the civilian population. The German army executed over 6,500 French and Belgian civilians between August and November 1914, usually in near-random large-scale shootings of civilians ordered by junior German officers. The German Army destroyed 15,000–20,000 buildings—most famously the university library at Louvain—and generated a wave of refugees of over a million people. Over half the German regiments in Belgium were involved in major incidents. Thousands of workers were shipped to Germany to work in factories. British propaganda dramatising the Rape of Belgium attracted much attention in the United States, while Berlin said it was both lawful and necessary because of the threat of franc-tireurs like those in France in 1870. The British and French magnified the reports and disseminated them at home and in the United States, where they played a major role in dissolving support for Germany.\n\nThe British soldiers of the war were initially volunteers but increasingly were conscripted into service. Surviving veterans, returning home, often found they could discuss their experiences only amongst themselves. Grouping together, they formed \"veterans' associations\" or \"Legions\". A small number of personal accounts of American veterans have been collected by the Library of Congress Veterans History Project.\n\nAbout eight million men surrendered and were held in POW camps during the war. All nations pledged to follow the Hague Conventions on fair treatment of prisoners of war, and the survival rate for POWs was generally much higher than that of combatants at the front. Individual surrenders were uncommon; large units usually surrendered \"en masse\". At the siege of Maubeuge about 40,000 French soldiers surrendered, at the battle of Galicia Russians took about 100,000 to 120,000 Austrian captives, at the Brusilov Offensive about 325,000 to 417,000 Germans and Austrians surrendered to Russians, and at the Battle of Tannenberg 92,000 Russians surrendered. When the besieged garrison of Kaunas surrendered in 1915, some 20,000 Russians became prisoners, at the battle near Przasnysz (February–March 1915) 14,000 Germans surrendered to Russians, and at the First Battle of the Marne about 12,000 Germans surrendered to the Allies. 25–31% of Russian losses (as a proportion of those captured, wounded, or killed) were to prisoner status; for Austria-Hungary 32%, for Italy 26%, for France 12%, for Germany 9%; for Britain 7%. Prisoners from the Allied armies totalled about 1.4 million (not including Russia, which lost 2.5–3.5 million men as prisoners). From the Central Powers about 3.3 million men became prisoners; most of them surrendered to Russians. Germany held 2.5 million prisoners; Russia held 2.2–2.9 million; while Britain and France held about 720,000. Most were captured just before the Armistice. The United States held 48,000. The most dangerous moment was the act of surrender, when helpless soldiers were sometimes gunned down. Once prisoners reached a camp, conditions were, in general, satisfactory (and much better than in World War II), thanks in part to the efforts of the International Red Cross and inspections by neutral nations. However, conditions were terrible in Russia: starvation was common for prisoners and civilians alike; about 15–20% of the prisoners in Russia died, and in Central Powers imprisonment 8% of Russians. In Germany, food was scarce, but only 5% died.\nThe Ottoman Empire often treated POWs poorly. Some 11,800 British Empire soldiers, most of them Indians, became prisoners after the Siege of Kut in Mesopotamia in April 1916; 4,250 died in captivity. Although many were in a poor condition when captured, Ottoman officers forced them to march to Anatolia. A survivor said: \"We were driven along like beasts; to drop out was to die.\" The survivors were then forced to build a railway through the Taurus Mountains.\n\nIn Russia, when the prisoners from the Czech Legion of the Austro-Hungarian army were released in 1917, they re-armed themselves and briefly became a military and diplomatic force during the Russian Civil War.\n\nWhile the Allied prisoners of the Central Powers were quickly sent home at the end of active hostilities, the same treatment was not granted to Central Power prisoners of the Allies and Russia, many of whom served as forced labour, e.g., in France until 1920. They were released only after many approaches by the Red Cross to the Allied Supreme Council. German prisoners were still being held in Russia as late as 1924.\n\nMilitary and civilian observers from every major power closely followed the course of the war. Many were able to report on events from a perspective somewhat akin to modern \"embedded\" positions within the opposing land and naval forces.\n\nIn the Balkans, Yugoslav nationalists such as the leader, Ante Trumbić, strongly supported the war, desiring the freedom of Yugoslavs from Austria-Hungary and other foreign powers and the creation of an independent Yugoslavia. The Yugoslav Committee, led by Trumbić, was formed in Paris on 30 April 1915 but shortly moved its office to London. In April 1918, the Rome Congress of Oppressed Nationalities met, including Czechoslovak, Italian, Polish, Transylvanian, and Yugoslav representatives who urged the Allies to support national self-determination for the peoples residing within Austria-Hungary.\n\nIn the Middle East, Arab nationalism soared in Ottoman territories in response to the rise of Turkish nationalism during the war, with Arab nationalist leaders advocating the creation of a pan-Arab state. In 1916, the Arab Revolt began in Ottoman-controlled territories of the Middle East in an effort to achieve independence.\n\nIn East Africa, Iyasu V of Ethiopia was supporting the Dervish state who were at war with the British in the Somaliland Campaign. Von Syburg, the German envoy in Addis Ababa, said, \"now the time has come for Ethiopia to regain the coast of the Red Sea driving the Italians home, to restore the Empire to its ancient size.\" The Ethiopian Empire was on the verge of entering World War I on the side of the Central Powers before Iyasu's overthrow due to Allied pressure on the Ethiopian aristocracy.\n\nA number of socialist parties initially supported the war when it began in August 1914. But European socialists split on national lines, with the concept of class conflict held by radical socialists such as Marxists and syndicalists being overborne by their patriotic support for the war. Once the war began, Austrian, British, French, German, and Russian socialists followed the rising nationalist current by supporting their countries' intervention in the war.\n\nItalian nationalism was stirred by the outbreak of the war and was initially strongly supported by a variety of political factions. One of the most prominent and popular Italian nationalist supporters of the war was Gabriele d'Annunzio, who promoted Italian irredentism and helped sway the Italian public to support intervention in the war. The Italian Liberal Party, under the leadership of Paolo Boselli, promoted intervention in the war on the side of the Allies and used the Dante Alighieri Society to promote Italian nationalism. Italian socialists were divided on whether to support the war or oppose it; some were militant supporters of the war, including Benito Mussolini and Leonida Bissolati. However, the Italian Socialist Party decided to oppose the war after anti-militarist protestors were killed, resulting in a general strike called Red Week. The Italian Socialist Party purged itself of pro-war nationalist members, including Mussolini. Mussolini, a syndicalist who supported the war on grounds of irredentist claims on Italian-populated regions of Austria-Hungary, formed the pro-interventionist \"Il Popolo d'Italia\" and the \"Fasci Rivoluzionario d'Azione Internazionalista\" (\"Revolutionary Fasci for International Action\") in October 1914 that later developed into the \"Fasci di Combattimento\" in 1919, the origin of fascism. Mussolini's nationalism enabled him to raise funds from Ansaldo (an armaments firm) and other companies to create \"Il Popolo d'Italia\" to convince socialists and revolutionaries to support the war.\n\nOnce war was declared, many socialists and trade unions backed their governments. Among the exceptions were the Bolsheviks, the Socialist Party of America, the Italian Socialist Party, and people like Karl Liebknecht, Rosa Luxemburg, and their followers in Germany.\n\nBenedict XV, elected to the papacy less than three months into World War I, made the war and its consequences the main focus of his early pontificate. In stark contrast to his predecessor, five days after his election he spoke of his determination to do what he could to bring peace. His first encyclical, \"Ad beatissimi Apostolorum\", given 1 November 1914, was concerned with this subject. Benedict XV found his abilities and unique position as a religious emissary of peace ignored by the belligerent powers. The 1915 Treaty of London between Italy and the Triple Entente included secret provisions whereby the Allies agreed with Italy to ignore papal peace moves towards the Central Powers. Consequently, the publication of Benedict's proposed of August 1917 was roundly ignored by all parties except Austria-Hungary.\n\nIn Britain in 1914, the Public Schools Officers' Training Corps annual camp was held at Tidworth Pennings, near Salisbury Plain. Head of the British Army, Lord Kitchener, was to review the cadets, but the imminence of the war prevented him. General Horace Smith-Dorrien was sent instead. He surprised the two-or-three thousand cadets by declaring (in the words of Donald Christopher Smith, a Bermudian cadet who was present),\nthat war should be avoided at almost any cost, that war would solve nothing, that the whole of Europe and more besides would be reduced to ruin, and that the loss of life would be so large that whole populations would be decimated. In our ignorance I, and many of us, felt almost ashamed of a British General who uttered such depressing and unpatriotic sentiments, but during the next four years, those of us who survived the holocaust—probably not more than one-quarter of us—learned how right the General's prognosis was and how courageous he had been to utter it.\nVoicing these sentiments did not hinder Smith-Dorrien's career, or prevent him from doing his duty in World War I to the best of his abilities.\n\nMany countries jailed those who spoke out against the conflict. These included Eugene Debs in the United States and Bertrand Russell in Britain. In the US, the Espionage Act of 1917 and Sedition Act of 1918 made it a federal crime to oppose military recruitment or make any statements deemed \"disloyal\". Publications at all critical of the government were removed from circulation by postal censors, and many served long prison sentences for statements of fact deemed unpatriotic.\n\nA number of nationalists opposed intervention, particularly within states that the nationalists were hostile to. Although the vast majority of Irish people consented to participate in the war in 1914 and 1915, a minority of advanced Irish nationalists staunchly opposed taking part. The war began amid the Home Rule crisis in Ireland that had resurfaced in 1912, and by July 1914 there was a serious possibility of an outbreak of civil war in Ireland. Irish nationalists and Marxists attempted to pursue Irish independence, culminating in the Easter Rising of 1916, with Germany sending 20,000 rifles to Ireland to stir unrest in Britain. The UK government placed Ireland under martial law in response to the Easter Rising, though once the immediate threat of revolution had dissipated, the authorities did try to make concessions to nationalist feeling. However, opposition to involvement in the war increased in Ireland, resulting in the Conscription Crisis of 1918.\n\nOther opposition came from conscientious objectors—some socialist, some religious—who refused to fight. In Britain, 16,000 people asked for conscientious objector status. Some of them, most notably prominent peace activist Stephen Henry Hobhouse, refused both military and alternative service. Many suffered years of prison, including solitary confinement and bread and water diets. Even after the war, in Britain many job advertisements were marked \"No conscientious objectors need apply\".\n\nThe Central Asian Revolt started in the summer of 1916, when the Russian Empire government ended its exemption of Muslims from military service.\n\nIn 1917, a series of French Army Mutinies led to dozens of soldiers being executed and many more imprisoned.\n\nIn Milan, in May 1917, Bolshevik revolutionaries organised and engaged in rioting calling for an end to the war, and managed to close down factories and stop public transportation. The Italian army was forced to enter Milan with tanks and machine guns to face Bolsheviks and anarchists, who fought violently until 23 May when the army gained control of the city. Almost 50 people (including three Italian soldiers) were killed and over 800 people arrested.\n\nIn September 1917, Russian soldiers in France began questioning why they were fighting for the French at all and mutinied. In Russia, opposition to the war led to soldiers also establishing their own revolutionary committees, which helped foment the October Revolution of 1917, with the call going up for \"bread, land, and peace\". The Bolsheviks agreed to a peace treaty with Germany, the peace of Brest-Litovsk, despite its harsh conditions. The German Revolution of 1918-1919 led to the abdication of the Kaiser and German surrender.\n\nConscription was common in most European countries. However, it was controversial in English-speaking countries. It was especially unpopular among minority ethnic groups—especially the Irish Catholics in Ireland and Australia, and the French Catholics in Canada.\n\nIn Canada the issue produced a major political crisis that permanently alienated the Francophones. It opened a political gap between French Canadians, who believed their true loyalty was to Canada and not to the British Empire, and members of the Anglophone majority, who saw the war as a duty to their British heritage.\n\nIn Australia, a sustained pro-conscription campaign by Billy Hughes, the Prime Minister, caused a split in the Australian Labor Party, so Hughes formed the Nationalist Party of Australia in 1917 to pursue the matter. Farmers, the labour movement, the Catholic Church, and the Irish Catholics successfully opposed Hughes' push, which was rejected in two plebiscites.\n\nIn Britain, conscription resulted in the calling up of nearly every physically fit man in Britain—six of ten million eligible. Of these, about 750,000 lost their lives. Most deaths were those of young unmarried men; however, 160,000 wives lost husbands and 300,000 children lost fathers. Conscription during the First World War began when the British government passed the Military Service Act in 1916. The act specified that single men aged 18 to 40 years old were liable to be called up for military service unless they were widowed with children or ministers of a religion. There was a system of Military Service Tribunals to adjudicate upon claims for exemption upon the grounds of performing civilian work of national importance, domestic hardship, health, and conscientious objection. The law went through several changes before the war ended. Married men were exempt in the original Act, although this was changed in June 1916. The age limit was also eventually raised to 51 years old. Recognition of work of national importance also diminished, and in the last year of the war there was some support for the conscription of clergy. Conscription lasted until mid-1919. Due to the political situation in Ireland, conscription was never applied there; only in England, Scotland and Wales.\n\nIn the United States, conscription began in 1917 and was generally well received, with a few pockets of opposition in isolated rural areas. The administration decided to rely primarily on conscription, rather than voluntary enlistment, to raise military manpower for when only 73,000 volunteers enlisted out of the initial 1 million target in the first six weeks of the war. In 1917 10 million men were registered. This was deemed to be inadequate, so age ranges were increased and exemptions reduced, and so by the end of 1918 this increased to 24 million men that were registered with nearly 3 million inducted into the military services. The draft was universal and included blacks on the same terms as whites, although they served in different units. In all 367,710 black Americans were drafted (13% of the total), compared to 2,442,586 white (87%).\n\nForms of resistance ranged from peaceful protest to violent demonstrations and from humble letter-writing campaigns asking for mercy to radical newspapers demanding reform. The most common tactics were dodging and desertion, and many communities sheltered and defended their draft dodgers as political heroes. Many socialists were jailed for \"obstructing the recruitment or enlistment service\". The most famous was Eugene Debs, head of the Socialist Party of America, who ran for president in 1920 from his prison cell. In 1917 a number of radicals and anarchists challenged the new draft law in federal court, arguing that it was a direct violation of the Thirteenth Amendment's prohibition against slavery and involuntary servitude. The Supreme Court unanimously upheld the constitutionality of the draft act in the Selective Draft Law Cases on 7 January 1918.\n\nLike all of the armies of mainland Europe, Austria-Hungary relied on conscription to fill its ranks. Officer recruitment, however, was voluntary. The effect of this at the start of the war was that well over a quarter of the rank and file were Slavs, while more than 75% of the officers were ethnic Germans. This was much resented. The army has been described as being \"run on colonial lines\" and the Slav soldiers as \"disaffected\". Thus conscription contributed greatly to Austria's disastrous performance on the battlefield.\n\nThe non-military diplomatic and propaganda interactions among the nations were designed to build support for the cause, or to undermine support for the enemy. For the most part, wartime diplomacy focused on five issues: propaganda campaigns; defining and redefining the war goals, which became harsher as the war went on; luring neutral nations (Italy, Ottoman Empire, Bulgaria, Romania) into the coalition by offering slices of enemy territory; and encouragement by the Allies of nationalistic minority movements inside the Central Powers, especially among Czechs, Poles, and Arabs. In addition, there were multiple peace proposals coming from neutrals, or one side or the other; none of them progressed very far.\n\nThe first tentative efforts to comprehend the meaning and consequences of modern warfare began during the initial phases of the war, and this process continued throughout and after the end of hostilities, and is still underway, more than a century later.\n\nHistorian Heather Jones argues that the historiography has been reinvigorated by the cultural turn in recent years. Scholars have raised entirely new questions regarding military occupation, radicalisation of politics, race, and the male body. Furthermore, new research has revised our understanding of five major topics that historians have long debated: Why the war began, why the Allies won, whether generals were responsible for high casualty rates, how the soldiers endured the horrors of trench warfare, and to what extent the civilian homefront accepted and endorsed the war effort.\n\nMemorials were erected in thousands of villages and towns. Close to battlefields, those buried in improvised burial grounds were gradually moved to formal graveyards under the care of organisations such as the Commonwealth War Graves Commission, the American Battle Monuments Commission, the German War Graves Commission, and Le Souvenir français. Many of these graveyards also have central monuments to the missing or unidentified dead, such as the Menin Gate memorial and the Thiepval Memorial to the Missing of the Somme.\n\nIn 1915 John McCrae, a Canadian army doctor, wrote the poem \"In Flanders Fields\" as a salute to those who perished in the Great War. Published in \"Punch\" on 8 December 1915, it is still recited today, especially on Remembrance Day and Memorial Day.\n\nNational World War I Museum and Memorial in Kansas City, Missouri, is a memorial dedicated to all Americans who served in World War I. The Liberty Memorial was dedicated on 1 November 1921, when the supreme Allied commanders spoke to a crowd of more than 100,000 people.\n\nThe UK Government has budgeted substantial resources to the commemoration of the war during the period 2014 to 2018. The lead body is the Imperial War Museum. On 3 August 2014, French President Francois Hollande and German President Joachim Gauck together marked the centenary of Germany's declaration of war on France by laying the first stone of a memorial in Vieil Armand, known in German as Hartmannswillerkopf, for French and German soldiers killed in the war.\n\nWorld War I had a lasting impact on social memory. It was seen by many in Britain as signalling the end of an era of stability stretching back to the Victorian period, and across Europe many regarded it as a watershed. Historian Samuel Hynes explained:\n\nThis has become the most common perception of World War I, perpetuated by the art, cinema, poems, and stories published subsequently. Films such as \"All Quiet on the Western Front\", \"Paths of Glory\" and \"King & Country\" have perpetuated the idea, while war-time films including \"Camrades\", \"Poppies of Flanders\", and \"Shoulder Arms\" indicate that the most contemporary views of the war were overall far more positive. Likewise, the art of Paul Nash, John Nash, Christopher Nevinson, and Henry Tonks in Britain painted a negative view of the conflict in keeping with the growing perception, while popular war-time artists such as Muirhead Bone painted more serene and pleasant interpretations subsequently rejected as inaccurate. Several historians like John Terraine, Niall Ferguson and Gary Sheffield have challenged these interpretations as partial and polemical views:\n\nThese beliefs did not become widely shared because they offered the only accurate interpretation of wartime events. In every respect, the war was much more complicated than they suggest. In recent years, historians have argued persuasively against almost every popular cliché of World War I. It has been pointed out that, although the losses were devastating, their greatest impact was socially and geographically limited. The many emotions other than horror experienced by soldiers in and out of the front line, including comradeship, boredom, and even enjoyment, have been recognised. The war is not now seen as a 'fight about nothing', but as a war of ideals, a struggle between aggressive militarism and more or less liberal democracy. It has been acknowledged that British generals were often capable men facing difficult challenges, and that it was under their command that the British army played a major part in the defeat of the Germans in 1918: a great forgotten victory.\n\nThough these views have been discounted as \"myths\", they are common. They have dynamically changed according to contemporary influences, reflecting in the 1950s perceptions of the war as \"aimless\" following the contrasting Second World War and emphasising conflict within the ranks during times of class conflict in the 1960s. The majority of additions to the contrary are often rejected.\n\nThe social trauma caused by unprecedented rates of casualties manifested itself in different ways, which have been the subject of subsequent historical debate.\n\nThe optimism of \"la belle époque\" was destroyed, and those who had fought in the war were referred to as the Lost Generation. For years afterwards, people mourned the dead, the missing, and the many disabled. Many soldiers returned with severe trauma, suffering from shell shock (also called neurasthenia, a condition related to posttraumatic stress disorder). Many more returned home with few after-effects; however, their silence about the war contributed to the conflict's growing mythological status. Though many participants did not share in the experiences of combat or spend any significant time at the front, or had positive memories of their service, the images of suffering and trauma became the widely shared perception. Such historians as Dan Todman, Paul Fussell, and Samuel Heyns have all published works since the 1990s arguing that these common perceptions of the war are factually incorrect.\n\nThe rise of Nazism and Fascism included a revival of the nationalist spirit and a rejection of many post-war changes. Similarly, the popularity of the stab-in-the-back legend (German: \"Dolchstoßlegende\") was a testament to the psychological state of defeated Germany and was a rejection of responsibility for the conflict. This conspiracy theory of betrayal became common, and the German populace came to see themselves as victims. The widespread acceptance of the \"stab-in-the-back\" theory delegitimised the Weimar government and destabilised the system, opening it to extremes of right and left.\n\nCommunist and fascist movements around Europe drew strength from this theory and enjoyed a new level of popularity. These feelings were most pronounced in areas directly or harshly affected by the war. Adolf Hitler was able to gain popularity by using German discontent with the still controversial Treaty of Versailles. World War II was in part a continuation of the power struggle never fully resolved by World War I. Furthermore, it was common for Germans in the 1930s to justify acts of aggression due to perceived injustices imposed by the victors of World War I. American historian William Rubinstein wrote that:\n\nThe 'Age of Totalitarianism' included nearly all of the infamous examples of genocide in modern history, headed by the Jewish Holocaust, but also comprising the mass murders and purges of the Communist world, other mass killings carried out by Nazi Germany and its allies, and also the Armenian Genocide of 1915. All these slaughters, it is argued here, had a common origin, the collapse of the elite structure and normal modes of government of much of central, eastern and southern Europe as a result of World War I, without which surely neither Communism nor Fascism would have existed except in the minds of unknown agitators and crackpots.\n\nOne of the most dramatic effects of the war was the expansion of governmental powers and responsibilities in Britain, France, the United States, and the Dominions of the British Empire. To harness all the power of their societies, governments created new ministries and powers. New taxes were levied and laws enacted, all designed to bolster the war effort; many have lasted to this day. Similarly, the war strained the abilities of some formerly large and bureaucratised governments, such as in Austria-Hungary and Germany.\n\nGross domestic product (GDP) increased for three Allies (Britain, Italy, and the United States), but decreased in France and Russia, in neutral Netherlands, and in the three main Central Powers. The shrinkage in GDP in Austria, Russia, France, and the Ottoman Empire ranged between 30% and 40%. In Austria, for example, most pigs were slaughtered, so at war's end there was no meat.\n\nIn all nations, the government's share of GDP increased, surpassing 50% in both Germany and France and nearly reaching that level in Britain. To pay for purchases in the United States, Britain cashed in its extensive investments in American railroads and then began borrowing heavily from Wall Street. President Wilson was on the verge of cutting off the loans in late 1916, but allowed a great increase in US government lending to the Allies. After 1919, the US demanded repayment of these loans. The repayments were, in part, funded by German reparations that, in turn, were supported by American loans to Germany. This circular system collapsed in 1931 and some loans were never repaid. Britain still owed the United States $4.4 billion of World War I debt in 1934, the last instalment was finally paid in 2015.\n\nMacro- and micro-economic consequences devolved from the war. Families were altered by the departure of many men. With the death or absence of the primary wage earner, women were forced into the workforce in unprecedented numbers. At the same time, industry needed to replace the lost labourers sent to war. This aided the struggle for voting rights for women.\n\nWorld War I further compounded the gender imbalance, adding to the phenomenon of surplus women. The deaths of nearly one million men during the war in Britain increased the gender gap by almost a million: from 670,000 to 1,700,000. The number of unmarried women seeking economic means grew dramatically. In addition, demobilisation and economic decline following the war caused high unemployment. The war increased female employment; however, the return of demobilised men displaced many from the workforce, as did the closure of many of the wartime factories.\n\nIn Britain, rationing was finally imposed in early 1918, limited to meat, sugar, and fats (butter and margarine), but not bread. The new system worked smoothly. From 1914 to 1918, trade union membership doubled, from a little over four million to a little over eight million.\n\nBritain turned to her colonies for help in obtaining essential war materials whose supply from traditional sources had become difficult. Geologists such as Albert Ernest Kitson were called on to find new resources of precious minerals in the African colonies. Kitson discovered important new deposits of manganese, used in munitions production, in the Gold Coast.\n\nArticle 231 of the Treaty of Versailles (the so-called \"war guilt\" clause) stated Germany accepted responsibility for \"all the loss and damage to which the Allied and Associated Governments and their nationals have been subjected as a consequence of the war imposed upon them by the aggression of Germany and her allies.\" It was worded as such to lay a legal basis for reparations, and a similar clause was inserted in the treaties with Austria and Hungary. However neither of them interpreted it as an admission of war guilt.\" In 1921, the total reparation sum was placed at 132 billion gold marks. However, \"Allied experts knew that Germany could not pay\" this sum. The total sum was divided into three categories, with the third being \"deliberately designed to be chimerical\" and its \"primary function was to mislead public opinion ... into believing the \"total sum was being maintained.\" Thus, 50 billion gold marks (12.5 billion dollars) \"represented the actual Allied assessment of German capacity to pay\" and \"therefore ... represented the total German reparations\" figure that had to be paid.\n\nThis figure could be paid in cash or in kind (coal, timber, chemical dyes, etc.). In addition, some of the territory lost—via the treaty of Versailles—was credited towards the reparation figure as were other acts such as helping to restore the Library of Louvain. By 1929, the Great Depression arrived, causing political chaos throughout the world. In 1932 the payment of reparations was suspended by the international community, by which point Germany had only paid the equivalent of 20.598 billion gold marks in reparations. With the rise of Adolf Hitler, all bonds and loans that had been issued and taken out during the 1920s and early 1930s were cancelled. David Andelman notes \"refusing to pay doesn't make an agreement null and void. The bonds, the agreement, still exist.\" Thus, following the Second World War, at the London Conference in 1953, Germany agreed to resume payment on the money borrowed. On 3 October 2010, Germany made the final payment on these bonds.\n\nThe war contributed to the evolution of the wristwatch from women's jewellery to a practical everyday item, replacing the pocketwatch, which requires a free hand to operate. Military funding of advancements in radio contributed to the postwar popularity of the medium.\n\n\n\n\n\n"}
{"id": "39038931", "url": "https://en.wikipedia.org/wiki?curid=39038931", "title": "World polity theory", "text": "World polity theory\n\nWorld polity theory (also referred to as world society theory, global Neo-institutionalism, and the \"Stanford school\" of global analysis) was developed mainly as an analytical frame for interpreting global relations, structures, and practices. It was developed partly in response to the application of world systems theory. The theory views the world system as a social system with a cultural framework called world polity, which encompasses and influences the actors, such as nations, international organizations, and individuals under it. In other words, according to John Boli and George M. Thomas, \"the world polity is constituted by distinct culture – a set of fundamental principles and models, mainly ontological and cognitive in character, defining the nature and purposes of social actors and action.\" The World polity theory views the primary component of the world society as \"world polity\", which provides a set of cultural norms or directions in which the actors of the world society follow in dealing with problems and general procedures. In contrast to other theories such as neo-realism or liberalism, the theory considers other actors such as the states and institutions to be under the influence of global norms. Although it closely resembles constructivism, world polity theory is to be distinguished from it because \"world-polity theorists have been far more resolute in taking the “cultural plunge” than their constructivism counterparts\". In other words, world polity theory puts more of an emphasis on homogenization than the other. Through globalization, world polity and culture trigger the formation of enactable cultures and organizations while in return cultures and organizations elaborate the world society further.\n\nBeginning in the 1970s with its initiation by John W. Meyer of Stanford University, world polity analysis initially revolved around examining inter-state relations. Simultaneously in the 1970s and also in the 1980s, a significant amount of work was done on international education environment. However, in the 1980s and 1990s due to the noticeable influence of globalization on world culture, the direction of the study shifted towards analyzing the transnational social movement that may amount to a global polity while at the same time attempting to better understand how global polity ideas are implemented through global actors.\n\nThrough a series of empirical studies, Meyer and others observed that new states organize themselves in a significantly similar manner despite their differing needs and background to give strength to their explanation that there is a set norm of forming a new state under the bigger umbrella of world polity.\n\nOther instances suggest a definite presence of world polity:\n\nCritics point to the fact that world polity theory assumes a rather flawless and smooth transfer of norms of world polity to the global actors, which might not always be really plausible. Also, its tendency to focus on the homogenizing effect brings criticisms. World culture theory differs in this aspect from world polity theory because it recognizes that actors find their own identities in relation to the greater global cultural norm instead of simply following what is suggested by the world polity.\n\nAlso, an instance of \"glocalization\" cannot fully be explained by world polity theory. It is a phenomenon by which local values and global cultures converge to create something new.\n\n\n"}
{"id": "19017269", "url": "https://en.wikipedia.org/wiki?curid=19017269", "title": "World population", "text": "World population\n\nIn demographics, the world population is the total number of humans currently living, and was estimated to have reached 7.7 billion people as of November 2018. It took over 200,000 years of human history for the world's population to reach 1 billion; and only 200 years more to reach 7 billion. \n\nWorld population has experienced continuous growth since the end of the Great Famine of 1315–17 and the Black Death in 1350, when it was near 370 million. \nThe highest population growth rates – global population increases above 1.8% per year – occurred between 1955 and 1975, peaking to 2.06% between 1965 and 1970. The growth rate has declined to 1.18% between 2010 and 2015 and is projected to decline further in the course of the 21st century.\n\nTotal annual births were highest in the late 1980s at about 139 million, and as of 2011 were expected to remain essentially constant at a level of 135 million, while deaths numbered 56 million per year and were expected to increase to 80 million per year by 2040. \nThe median age of the world's population was estimated to be 30.4 years in 2018.\n\nSix of the Earth's seven continents are permanently inhabited on a large scale. Asia is the most populous continent, with its 4.54 billion inhabitants accounting for 60% of the world population. The world's two most populated countries, China and India, together constitute about 36% of the world's population. Africa is the second most populated continent, with around 1.28 billion people, or 16% of the world's population. Europe's 742 million people make up 10% of the world's population as of 2018, while the Latin American and Caribbean regions are home to around 651 million (9%). Northern America, primarily consisting of the United States and Canada, has a population of around 363 million (5%), and Oceania, the least populated region, has about 41 million inhabitants (0.5%). Though it is not permanently inhabited by any fixed population, Antarctica has a small, fluctuating international population based mainly in polar science stations. This population tends to rise in the summer months and decrease significantly in winter, as visiting researchers return to their home countries.\n\nEstimates of world population by their nature are an aspect of modernity, possible only since the Age of Discovery. Early estimates for the population of the world date to the 17th century: William Petty in 1682 estimated world population at 320 million (modern estimates ranging close to twice this number); by the late 18th century, estimates ranged close to one billion (consistent with modern estimates). More refined estimates, broken down by continents, were published in the first half of the 19th century, at 600 to 1000 million in the early 1800s and at 800 to 1000 million in the 1840s.\n\nIt is difficult for estimates to be better than rough approximations, as even modern population estimates are fraught with uncertainties on the order of 3% to 5%.\n\nEstimates of the population of the world at the time agriculture emerged in around 10,000 BC have ranged between 1 million and 15 million. Even earlier, genetic evidence suggests humans may have gone through a population bottleneck of between 1,000 and 10,000 people about 70,000 BC, according to the Toba catastrophe theory. By contrast, it is estimated that around 50–60 million people lived in the combined eastern and western Roman Empire in the 4th century AD.\n\nThe Plague of Justinian, which first emerged during the reign of the Roman emperor Justinian, caused Europe's population to drop by around 50% between the 6th and 8th centuries AD. The population of Europe was more than 70 million in 1340. The Black Death pandemic of the 14th century may have reduced the world's population from an estimated 450 million in 1340 to between 350 and 375 million in 1400; it took 200 years for population figures to recover. The population of China decreased from 123 million in 1200 to 65 million in 1393, presumably due to a combination of Mongol invasions, famine, and plague.\n\nStarting in AD 2, the Han Dynasty of ancient China kept consistent family registers in order to properly assess the poll taxes and labor service duties of each household. In that year, the population of Western Han was recorded as 57,671,400 individuals in 12,366,470 households, decreasing to 47,566,772 individuals in 9,348,227 households by AD 146, towards the End of the Han Dynasty. At the founding of the Ming Dynasty in 1368, China's population was reported to be close to 60 million; toward the end of the dynasty in 1644, it may have approached 150 million. England's population reached an estimated 5.6 million in 1650, up from an estimated 2.6 million in 1500. New crops that were brought to Asia and Europe from the Americas by Portuguese and Spanish colonists in the 16th century are believed to have contributed to population growth. Since their introduction to Africa by Portuguese traders in the 16th century, maize and cassava have similarly replaced traditional African crops as the most important staple food crops grown on the continent.\n\nThe pre-Columbian North American population probably numbered somewhere between 2 million and 18 million. Encounters between European explorers and populations in the rest of the world often introduced local epidemics of extraordinary virulence. According to the most extreme scholarly claims, as many as 90% of the Native American population of the New World died due to Old World diseases such as smallpox, measles and influenza. Over the centuries, the Europeans had developed high degrees of immunity to these diseases, while the indigenous peoples had no such immunity.\n\nDuring the European Agricultural and Industrial Revolutions, the life expectancy of children increased dramatically. The percentage of the children born in London who died before the age of five decreased from 74.5% in 1730–1749 to 31.8% in 1810–1829. Between 1700 and 1900, Europe’s population increased from about 100 million to over 400 million. Altogether, the areas populated by people of European descent comprised 36% of the world's population in 1900.\n\nPopulation growth in the West became more rapid after the introduction of vaccination and other improvements in medicine and sanitation. Improved material conditions led to the population of Britain increasing from 10 million to 40 million in the 19th century. The population of the United Kingdom reached 60 million in 2006. The United States saw its population grow from around 5.3 million in 1800 to 106 million in 1920, exceeding 307 million in 2010.\n\nThe first half of the 20th century in Imperial Russia and the Soviet Union was marked by a succession of major wars, famines and other disasters which caused large-scale population losses (approximately 60 million excess deaths). After the collapse of the Soviet Union, Russia's population declined significantly – from 150 million in 1991 to 143 million in 2012 – but by 2013 this decline appeared to have halted.\n\nMany countries in the developing world have experienced extremely rapid population growth since the early 20th century, due to economic development and improvements in public health. China's population rose from approximately 430 million in 1850 to 580 million in 1953, and now stands at over 1.3 billion. The population of the Indian subcontinent, which was about 125 million in 1750, increased to 389 million in 1941; today, India, Pakistan and Bangladesh are collectively home to about billion people. Java had about 5 million inhabitants in 1815; its present-day successor, Indonesia, now has a population of over 140 million. In just one hundred years, the population of Brazil decupled (x10), from about 17 million in 1900, or about 1% of the world population in that year, to about 176 million in 2000, or almost 3% of the global population in the very early 21st century. Mexico's population grew from 13.6 million in 1900 to about 112 million in 2010. Between the 1920s and 2000s, Kenya's population grew from 2.9 million to 37 million.\n\nIt is estimated that the world population reached one billion for the first time in 1804. It was another 123 years before it reached two billion in 1927, but it took only 33 years to reach three billion in 1960. Thereafter, the global population reached four billion in 1974, five billion in 1987, six billion in 1999 and, according to the United States Census Bureau, seven billion in March 2012. The United Nations, however, estimated that the world population reached seven billion in October 2011.\n\nAccording to current projections, the global population will reach eight billion by 2024, and is likely to reach around nine billion by 2042. Alternative scenarios for 2050 range from a low of 7.4 billion to a high of more than 10.6 billion. Projected figures vary depending on underlying statistical assumptions and the variables used in projection calculations, especially the fertility variable. Long-range predictions to 2150 range from a population decline to 3.2 billion in the \"low scenario\", to \"high scenarios\" of 24.8 billion. One extreme scenario predicted a massive increase to 256 billion by 2150, assuming the global fertility rate remained at its 1995 level of 3.04 children per woman; however, by 2010 the global fertility rate had declined to 2.52.\n\nThere is no estimation for the exact day or month the world's population surpassed one or two billion. The points at which it reached three and four billion were not officially noted, but the International Database of the United States Census Bureau placed them in July 1959 and April 1974 respectively. The United Nations did determine, and commemorate, the \"Day of 5 Billion\" on July 11, 1987, and the \"Day of 6 Billion\" on October 12, 1999. The Population Division of the United Nations declared the \"Day of 7 Billion\" to be October 31, 2011.\n\nAs of 2012, the global sex ratio is approximately 1.01 males to 1 female. The greater number of men is possibly due to the significant sex imbalances evident in the Indian and Chinese populations. Approximately 26.3% of the global population is aged under 15, while 65.9% is aged 15–64 and 7.9% is aged 65 or over. The median age of the world's population was estimated to be 29.7 years in 2014, and is expected to rise to 37.9 years by 2050.\n\nAccording to the World Health Organization, the global average life expectancy is 71.4 years as of 2015, with women living an average of 74 years and men approximately 69 years. In 2010, the global fertility rate was estimated at 2.52 children per woman. In June 2012, British researchers calculated the total weight of Earth's human population as approximately 287 million tonnes, with the average person weighing around .\n\nThe CIA estimated nominal 2013 gross world product at US$74.31 trillion, giving an annual global per capita figure of around US$10,500. Around 1.29 billion people (18.4% of the world population) live in extreme poverty, subsisting on less than US$1.25 per day; approximately 870 million people (12.25%) are undernourished. 83% of the world's over-15s are considered literate. In June 2014, there were around 3.03 billion global Internet users, constituting 42.3% of the world population.\n\nThe Han Chinese are the world's largest single ethnic group, constituting over 19% of the global population in 2011. The world's most-spoken first languages are Mandarin Chinese (spoken by 12.44% of the world's population), Spanish (4.85%), English (4.83%), Arabic (3.25%) and Hindustani (2.68%). The world's largest religion is Christianity, whose adherents account for 31% of the global population; Islam is the second-largest religion, accounting for 24.1%, and Hinduism the third, accounting for 13.78%. In 2005, around 16% of the global population were reported to be non-religious.\n\nApproximately 4.38 billion people live in these ten countries, representing around 57% of the world's population as of July 2018.\n\nThe tables below list the world's most densely populated countries, both in absolute terms and in comparison to their total populations.\n\nPopulation size fluctuates at differing rates in differing regions. Nonetheless, population growth is the long-standing trend on all inhabited continents, as well as in most individual states. During the 20th century, the global population saw its greatest increase in known history, rising from about 1.6 billion in 1900 to over 6 billion in 2000. A number of factors contributed to this increase, including the lessening of the mortality rate in many countries by improved sanitation and medical advances, and a massive increase in agricultural productivity attributed to the Green Revolution.\n\nIn 2000, the United Nations estimated that the world's population was growing at an annual rate of 1.14% (equivalent to around 75 million people), down from a peak of 88 million per year in 1989. By 2000, there were approximately ten times as many people on Earth as there had been in 1700. Globally, the population growth rate has been steadily declining from its peak of 2.19% in 1963, but growth remains high in Latin America, the Middle East, and Sub-Saharan Africa.\n\nDuring the 2010s, Japan and some countries in Europe began to encounter negative population growth (i.e. a net decrease in population over time), due to sub-replacement fertility rates.\n\nIn 2006, the United Nations stated that the rate of population growth was visibly diminishing due to the ongoing global demographic transition. If this trend continues, the rate of growth may diminish to zero by 2050, concurrent with a world population plateau of 9.2 billion. However, this is only one of many estimates published by the UN; in 2009, UN population projections for 2050 ranged between around 8 billion and 10.5 billion. An alternative scenario is given by the statistician Jorgen Randers, who argues that traditional projections insufficiently take into account the downward impact of global urbanization on fertility. Randers' \"most likely scenario\" reveals a peak in the world population in the early 2040s at about 8.1 billion people, followed by decline. Adrian Raftery, a University of Washington professor of statistics and of sociology, states that \"there’s a 70 percent probability the world population will not stabilize this century. Population, which had sort of fallen off the world’s agenda, remains a very important issue.\"\n\nThe table below shows historical and predicted regional population figures in millions. The availability of historical population figures varies by region.\n\nThe following table gives estimates, in millions, of population in the past. The data for 1750 to 1900 are from the UN report \"The World at Six Billion\" whereas the data from 1950 to 2015 are from a UN data sheet.\n\nUsing the above figures, the change in population from 2010 to 2015 was:\n\n\nLong-term global population growth is difficult to predict. The United Nations and the US Census Bureau both give different estimates – according to the UN, the world population reached seven billion in late 2011, while the USCB asserted that this occurred in March 2012. The UN has issued multiple projections of future world population, based on different assumptions. From 2000 to 2005, the UN consistently revised these projections downward, until the 2006 revision, issued on March 14, 2007, revised the 2050 mid-range estimate upwards by 273 million.\n\nAverage global birth rates are declining fast, but vary greatly between developed countries (where birth rates are often at or below replacement levels) and developing countries (where birth rates typically remain high). Different ethnicities also display varying birth rates. Death rates can change rapidly due to disease epidemics, wars and other mass catastrophes, or advances in medicine.\n\n2012 United projections show a continued increase in population in the near future with a steady decline in population growth rate; the global population is expected to reach between 8.3 and 10.9 billion by 2050. 2003 UN Population Division population projections for the year 2150 range between 3.2 and 24.8 billion. One of many independent mathematical models supports the lower estimate, while a 2014 estimate forecasts between 9.3 and 12.6 billion in 2100, and continued growth thereafter. Some analysts have questioned the sustainability of further world population growth, highlighting the growing pressures on the environment, global food supplies, and energy resources.\n\nIn 1975, Sebastian von Hoerner proposed a formula for population growth which represented hyperbolic growth with an infinite population in 2025. The hyperbolic growth of the world population observed until the 1970s was later correlated to a non-linear second order positive feedback between demographic growth and technological development. This feedback can be described as follows: technological advance → increase in the carrying capacity of land for people → demographic growth → more people → more potential inventors → acceleration of technological advance → accelerating growth of the carrying capacity → faster population growth → accelerating growth of the number of potential inventors → faster technological advance → hence, the faster growth of the Earth's carrying capacity for people, and so on. The transition from hyperbolic growth to slower rates of growth is related to the demographic transition.\n\nAccording to the Russian demographer Sergey Kapitsa, the world population grew between 67,000 BC and 1965 according to the following formula:\nwhere\n\nAccording to linear interpolation and extrapolation of UNDESA population estimates, the world population has doubled, or will double, in the years listed in the tables below (with two different starting points). During the 2nd millennium, each doubling took roughly half as long as the previous doubling, fitting the hyperbolic growth model mentioned above. However, after 2024, it is unlikely that there will be another doubling of the global population in the 21st century.\n\nIn his 1798 work \"An Essay on the Principle of Population\", the British scholar Thomas Malthus incorrectly predicted that continued population growth would exhaust the global food supply by the mid-19th century. Malthus wrote the essay to refute what he considered the unattainable utopian ideas of William Godwin and Marquis de Condorcet, as presented in \"Political Justice\" and \"The Future Progress of the Human Mind\". In 1968, Paul R. Ehrlich reprised Malthus' argument in \"The Population Bomb\", predicting that mass global famine would occur in the 1970s and 1980s.\n\nThe predictions of Ehrlich and other neo-Malthusians were vigorously challenged by a number of economists, notably Julian Lincoln Simon, and advances in agriculture, collectively known as the Green Revolution, forestalled any potential global famine in the late 20th century. Between 1950 and 1984, as the Green Revolution transformed agriculture around the world, grain production increased by over 250%. The world population has grown by over four billion since the beginning of the Green Revolution, but food production has so far kept pace with population growth. Most scholars believe that, without the Revolution, there would be greater levels of famine and malnutrition than the UN presently documents. However, neo-Malthusians point out that fossil fuels provided the energy for the Green Revolution, in the form of natural gas-derived fertilizers, oil-derived pesticides, and hydrocarbon-fueled irrigation, and that many crops have become so genetically uniform that a crop failure in any one country could potentially have global repercussions.\n\nIn 2004, a meta-analysis of 70 quantitative studies estimating a sustainable limit to the world population generated a meta-estimate of 7.7 billion people.\n\nIn May 2008, the price of grain was pushed up severely by the increased cultivation of biofuels, the increase of world oil prices to over $140 per barrel ($880/m), global population growth, the effects of climate change, the loss of agricultural land to residential and industrial development, and growing consumer demand in the population centres of China and India. Food riots subsequently occurred in some countries. However, oil prices then fell sharply. Resource demands are expected to ease as population growth declines, but it is unclear whether mass food wastage and rising living standards in developing countries will once again create resource shortages.\n\nDavid Pimentel, professor of ecology and agriculture at Cornell University, estimates that the sustainable agricultural carrying capacity for the United States is about 200 million people; its population as of 2015 is over 300 million. In 2009, the UK government's chief scientific advisor, Professor John Beddington, warned that growing populations, falling energy reserves and food shortages would create a \"perfect storm\" of shortages of food, water, and energy by 2030. According to a 2009 report by the United Nations Food and Agriculture Organization (FAO), the world will have to produce 70% more food by 2050 to feed a projected extra 2.3 billion people.\n\nThe observed figures for 2007 showed an actual increase in absolute numbers of undernourished people in the world, with 923 million undernourished in 2007, versus 832 million in 1995. The 2009 FAO estimates showed an even more dramatic increase, to 1.02 billion.\n\nA number of scientists have argued that the current global population expansion and accompanying increase in resource consumption threatens the world's ecosystem.\nThe InterAcademy Panel Statement on Population Growth, which was ratified by 58 member national academies in 1994, states that \"unprecedented\" population growth aggravates many environmental problems, including rising levels of atmospheric carbon dioxide, global warming, and pollution. Indeed, some analysts claim that overpopulation's most serious impact is its effect on the environment.\nThe situation has continued to worsen, as at the time of the 1994 IAP statement, the world population stood at 5.5 billion and lower-bound scenarios predicted a peak of 7.8 billion by 2050, a number that current estimates state will be reached in the late 2020s.\n\nScientists contend that human overpopulation, continued human population growth and overconsumption, particularly by the wealthy, are the primary drivers of mass species extinction. By 2050 population growth, along with profligate consumption, could result in oceans containing more plastic than fish by weight. In November 2017, a statement by 15,364 scientists from 184 countries asserted that rapid human population growth is the \"primary driver behind many ecological and even societal threats.\"\n\nA July 2017 study published in \"Environmental Research Letters\" argued that the most significant way individuals could mitigate their own carbon footprint is to have fewer children, followed by living without a vehicle, forgoing air travel and adopting a plant-based diet.\n\nHuman population control is the practice of intervening to alter the rate of population growth. Historically, human population control has been implemented by limiting a region's birth rate, by voluntary contraception or by government mandate. It has been undertaken as a response to factors including high or increasing levels of poverty, environmental concerns, and religious reasons. The use of abortion in some population control strategies has caused controversy, with religious organizations such as the Roman Catholic Church explicitly opposing any intervention in the human reproductive process.\n\nThe University of Nebraska publication \"Green Illusions\" argues that population control to alleviate environmental pressures need not be coercive. It states that \"Women who are educated, economically engaged, and in control of their own bodies can enjoy the freedom of bearing children at their own pace, which happens to be a rate that is appropriate for the aggregate ecological endowment of our planet.\" The book \"Fatal Misconception\" by Matthew Connelly similarly points to the importance of supporting the rights of women in bringing population levels down over time.\n\nFurther reading\n\nOrganizations\n\nStatistics and maps\n\nPopulation clocks\n"}
{"id": "33666830", "url": "https://en.wikipedia.org/wiki?curid=33666830", "title": "World population milestones", "text": "World population milestones\n\nWorld population milestones were unnoticed until the 20th century, since there were no reliable data on global population dynamics.\n\nIt is estimated that the population of the world reached one billion for the first time in 1804. It would be another 123 years before it reached two billion in 1927, but it took only 33 years to rise by another billion people, reaching three billion in 1960. Thereafter, the global population reached four billion in 1974, five billion in 1987, six billion in 1999 and, by some estimates, seven billion in October 2011 with other estimates being in March 2012. It is projected to reach eight billion by 2024–2030. According to current projections, the world's population is likely to reach around nine billion by 2035–2050, with alternative scenarios ranging from a low of 7.4 billion to a high of more than 10.6 billion. Projected figures vary depending on underlying statistical assumptions and which variables are manipulated in projection calculations, especially the fertility variable. Long-range predictions to 2150 range from a population decline to 3.2 billion in the\n'low scenario', to 'high scenarios' of 24.8 billion. One scenario predicted a massive increase to 256 billion by 2150, assuming fertility remains at 1995 levels.\n\nThere is no estimation for the exact day or month the world's population surpassed each of the one and two billion marks. The days of three and four billion were not officially noted, but the International Database of the United States Census Bureau places them in July 1959 and April 1974.\n\nThe Day of Five Billion, 11 July 1987, was designated by the United Nations Population Fund as the approximate day on which world population reached five billion. Matej Gašpar from Zagreb, Croatia (then SR Croatia, SFR Yugoslavia), was chosen as the symbolic 5-billionth person concurrently alive on Earth. The honor went to Zagreb because the 1987 Summer Universiade was taking place in the city at the time.\n\nThe United Nations Population Fund designated 12 October 1999 as the approximate day on which the world population reached six billion. It was officially designated The Day of Six Billion. Demographers do not universally accept this date as being exact. In fact there has been subsequent research which places the day of six billion nearer to 18 June or 19 June 1999. The International Programs division of the United States Census Bureau estimated that the world population reached six billion on 21 April 1999. United Nations Population Fund spokesman Omar Gharzeddine disputed the date of the Day of Six Billion by stating, \"The U.N. marked the '6 billionth' [person] in 1999, and then a couple of years later the Population Division itself reassessed its calculations and said, actually, no, it was in 1998.\"\n\nOn the Day of Six Billion, UN Secretary-General Kofi Annan was in Sarajevo, Bosnia and Herzegovina to monitor the Dayton Agreement. At midnight he went to Koševo Hospital, where Adnan Mević, born at 12.01 am, was named the symbolic 6 billionth concurrently alive person on Earth. He is the first son of Fatima Mević and Jasminko Mević and weighed 3.5 kg.\n\nThe \"Day of Seven Billion\" was targeted by the United States Census Bureau to be in March 2012, while the Population Division of the United Nations suggested 31 October 2011, and the latter date was officially designated by the United Nations Population Fund (UNFPA) as the approximate day on which the world's population reached seven billion people. United Nations Secretary General Ban Ki-moon spoke at the United Nations building in New York City on this milestone in the size of world population, and promoted the website 7 Billion Actions. Ban Ki-moon did not choose a symbolic seven billionth baby, but several groups proposed candidates: Nargis Kumar of Uttar Pradesh, India, Danica May Camacho of Manila, Philippines and Wattalage Muthumai of Colombo, Sri Lanka.\n\nNational or subnational governments have sometimes made similar designations based on the date estimated by a demographic agency. Some national milestones relate to citizens rather than residents. Commentators in countries with high immigration have pointed out that a population milestone may be reached by an immigrant rather than natural increase. \n\n"}
{"id": "28682776", "url": "https://en.wikipedia.org/wiki?curid=28682776", "title": "Zero world government", "text": "Zero world government\n\nZero world government refers to a hypothetical future in which national governments cease to exist or to matter, as a result of globalization and a worldwide rejection of politics, as known today. The term contrasts with that of one world government in the sense that rather than there being a world-state, there are no political states in the world.\n\n"}
