{"id": "11073185", "url": "https://en.wikipedia.org/wiki?curid=11073185", "title": "Additional funds needed", "text": "Additional funds needed\n\nAdditional funds needed (AFN) is a financial concept used when a business looks to expand its operations. Since a business that seeks to increase its sales level will require more assets to meet that goal, some provision must be made to accommodate the change in assets. To phrase it another way, the business must have some plan to actually finance the new assets that will be needed to increase sales.\n\nAFN is a way of calculating how much new funding will be required, so that the firm can realistically look at whether or not they will be able to generate the additional funding and therefore be able to achieve the higher sales level. Determining the amount of external funding needed is a key part of calculating AFN. \n\nA simplified version of the AFN equation is as follows: \n\ncodice_1\n\nWhen calculating AFN, consideration must be given to whether the company is already operating at full capacity; if not, they can expand sales some without having to invest in new equipment.\n\nIf a negative value is found for AFN, that means that the action would generate extra income that could be invested elsewhere. \n\nThe AFN equation is as follows: \n\nAFN = (A*/S)ΔS – (L*/S)ΔS – MS(RR)\n\nWhere:\n\nA* = Assets tied directly to sales and will increase\n\nL* = Spontaneous liabilities that will be affected by sales. (NOTE: Not all liabilities will be affected by sales such as long-term debt)\n\nS = Sales during the last year\n\nS = Total sales projected for next year (the new level of sales).\n\nΔS = The increase in sales between S and S\n\nM = Profit margin, or the profit per unit of sales\n\nMS = Projected Net Income\n\nRR = The retention ratio from Net Income and is also calculated as (1 – payout ratio)\n\nThe relevant ratios within the formula are:\n\n(A*/S): Called the capital intensity ratio\n\n(L*/S): Called the spontaneous liabilities ratio\n"}
{"id": "21972756", "url": "https://en.wikipedia.org/wiki?curid=21972756", "title": "American Defense Systems", "text": "American Defense Systems\n\nAmerican Defense Systems, Inc. (\"ADSI\") is a company that designs armor for military and commercial uses.\n\nIncorporated on December 6, 2002, the company is based in Hicksville, New York. It trades on the American Stock Exchange (AMEX) under the symbol EAG.A. The company has wholly owned subsidiaries:\n\nADSI provides physical security for the New York Stock Exchange.\n\nSince 2008, the director of American Defense Systems is Pasquale J. D'Amuro.\n"}
{"id": "8389168", "url": "https://en.wikipedia.org/wiki?curid=8389168", "title": "Averch–Johnson effect", "text": "Averch–Johnson effect\n\nThe Averch–Johnson effect is the tendency of regulated companies to engage in excessive amounts of capital accumulation in order to expand the volume of their profits. If companies' profits to capital ratio is regulated at a certain percentage then there is a strong incentive for companies to over-invest in order to increase profits overall. This investment goes beyond any optimal efficiency point for capital that the company may have calculated as higher profit is almost always desired over and above efficiency. \n\nExcessive capital accumulation under rate of return regulation is informally known as 'gold plating'.\n\n\nBody of Knowledge on Infrastructure Regulation: Incentive Features and Other Properties\n"}
{"id": "4822", "url": "https://en.wikipedia.org/wiki?curid=4822", "title": "Board of directors", "text": "Board of directors\n\nA board of directors is a recognized group of people who jointly oversee the activities of an organization, which can be either a for-profit business, nonprofit organization, or a government agency. Such a board's powers, duties, and responsibilities are determined by government regulations (including the jurisdiction's corporations law) and the organization's own constitution and bylaws. These authorities may specify the number of members of the board, how they are to be chosen, and how often they are to meet.\n\nIn an organization with voting members, the board is accountable to, and might be subordinate to, the organization's full membership, which usually vote for the members of the board. In a stock corporation, non-executive directors are voted for by the shareholders and the board is the highest authority in the management of the corporation. The board of directors appoints the chief executive officer of the corporation and sets out the overall strategic direction. In corporations with dispersed ownership, the identification and nomination of directors (that shareholders vote for or against) are often done by the board itself, leading to a high degree of self-perpetuation. In a non-stock corporation with no general voting membership, the board is the supreme governing body of the institution; its members are sometimes chosen by the board itself.\n\nOther names include board of directors and advisors, board of governors, board of managers, board of regents, board of trustees, or board of visitors. It may also be called \"the executive board\" and is often simply referred to as \"the board\".\n\nTypical duties of boards of directors include:\n\nThe legal responsibilities of boards and board members vary with the nature of the organization, and between jurisdictions. For companies with publicly trading stock, these responsibilities are typically much more rigorous and complex than for those of other types.\n\nTypically, the board chooses one of its members to be the \"chairman\" (often now called the \"chair\" or \"chairperson\"), who holds whatever title is specified in the by-laws or articles of association. However, in membership organizations, the members elect the president of the organization and the president becomes the board chair, unless the by-laws say otherwise.\n\nThe directors of an organization are the persons who are members of its board. Several specific terms categorize directors by the presence or absence of their other relationships to the organization.\n\nAn inside director is a director who is also an employee, officer, chief executive, major shareholder, or someone similarly connected to the organization. Inside directors represent the interests of the entity's stakeholders, and often have special knowledge of its inner workings, its financial or market position, and so on.\n\nTypical inside directors are:\n\nAn inside director who is employed as a manager or executive of the organization is sometimes referred to as an executive director (not to be confused with the title executive director sometimes used for the CEO position in some organizations). Executive directors often have a specified area of responsibility in the organization, such as finance, marketing, human resources, or production.\n\nAn outside director is a member of the board who is not otherwise employed by or engaged with the organization, and does not represent any of its stakeholders. A typical example is a director who is president of a firm in a different industry. Outside directors are not employees of the company or affiliated with it in any other way.\n\nOutside directors bring outside experience and perspectives to the board. For example, for a company that only serves a domestic market, the presence of CEOs from global multinational corporations as outside directors can help to provide insights on export and import opportunities and international trade options. One of the arguments for having outside directors is that they can keep a watchful eye on the inside directors and on the way the organization is run. Outside directors are unlikely to tolerate \"insider dealing\" between insider directors, as outside directors do not benefit from the company or organization. Outside directors are often useful in handling disputes between inside directors, or between shareholders and the board. They are thought to be advantageous because they can be objective and present little risk of conflict of interest. On the other hand, they might lack familiarity with the specific issues connected to the organization's governance and they might not know about the industry or sector in which the organization is operating.\n\n\nIndividual directors often serve on more than one board. This practice results in an interlocking directorate, where a relatively small number of individuals have significant influence over a large number of important entities. This situation can have important corporate, social, economic, and legal consequences, and has been the subject of significant research.\n\nThe process for running a board, sometimes called the board process, includes the selection of board members, the setting of clear board objectives, the dissemination of documents or board package to the board members, the collaborative creation of an agenda for the meeting, the creation and follow-up of assigned action items, and the assessment of the board process through standardized assessments of board members, owners, and CEOs. The science of this process has been slow to develop due to the secretive nature of the way most companies run their boards, however some standardization is beginning to develop. Some who are pushing for this standardization in the USA are the National Association of Corporate Directors, McKinsey Consulting and The Board Group.\n\nA board of directors conducts its meetings according to the rules and procedures contained in its governing documents. These procedures may allow the board to conduct its business by conference call or other electronic means. They may also specify how a quorum is to be determined.\n\nMost organizations have adopted \"Robert's Rules of Order\" as its guide to supplement its own rules. In this book, the rules for conducting board meetings may be less formal if there is no more than about a dozen board members present. An example of the informality is that motions are not required if it's clear what is being discussed.\n\nHistorically, nonprofit boards have not uncommonly had large boards with up to twenty-four members, but a modern trend is to have smaller boards as small as six or seven people. Studies suggest that after seven people, each additional person reduces the effectiveness of group decision-making.\n\nThe role and responsibilities of a board of directors vary depending on the nature and type of business entity and the laws applying to the entity (see types of business entity). For example, the nature of the business entity may be one that is traded on a public market (public company), not traded on a public market (a private, limited or closely held company), owned by family members (a family business), or exempt from income taxes (a non-profit, not for profit, or tax-exempt entity). There are numerous types of business entities available throughout the world such as a corporation, limited liability company, cooperative, business trust, partnership, private limited company, and public limited company.\n\nMuch of what has been written about boards of directors relates to boards of directors of business entities actively traded on public markets. More recently, however, material is becoming available for boards of private and closely held businesses including family businesses.\n\nA board-only organization is one whose board is self-appointed, rather than being accountable to a base of members through elections; or in which the powers of the membership are extremely limited.\n\nIn membership organizations, such as a society made up of members of a certain profession or one advocating a certain cause, a board of directors may have the responsibility of running the organization in between meetings of the membership, especially if the membership meets infrequently, such as only at an annual general meeting. The amount of powers and authority delegated to the board depend on the bylaws and rules of the particular organization. Some organizations place matters exclusively in the board's control while in others, the general membership retains full power and the board can only make recommendations.\n\nThe setup of a board of directors vary widely across organizations and may include provisions that are applicable to corporations, in which the \"shareholders\" are the members of the organization. A difference may be that the membership elects the officers of the organization, such as the president and the secretary, and the officers become members of the board in addition to the directors and retain those duties on the board. The directors may also be classified as officers in this situation. There may also be ex-officio members of the board, or persons who are members due to another position that they hold. These ex-officio members have all the same rights as the other board members.\n\nMembers of the board may be removed before their term is complete. Details on how they can be removed are usually provided in the bylaws. If the bylaws do not contain such details, the section on disciplinary procedures in \"Robert's Rules of Order\" may be used.\n\nIn a publicly held company, directors are elected to represent and are legally obligated as fiduciaries to represent owners of the company—the shareholders/stockholders. In this capacity they establish policies and make decisions on issues such as whether there is dividend and how much it is, stock options distributed to employees, and the hiring/firing and compensation of upper management.\n\nTheoretically, the control of a company is divided between two bodies: the board of directors, and the shareholders in general meeting. In practice, the amount of power exercised by the board varies with the type of company. In small private companies, the directors and the shareholders are normally the same people, and thus there is no real division of power. In large public companies, the board tends to exercise more of a supervisory role, and individual responsibility and management tends to be delegated downward to individual professional executives (such as a finance director or a marketing director) who deal with particular areas of the company's affairs.\n\nAnother feature of boards of directors in large public companies is that the board tends to have more \"de facto\" power. Many shareholders grant proxies to the directors to vote their shares at general meetings and accept all recommendations of the board rather than try to get involved in management, since each shareholder's power, as well as interest and information is so small. Larger institutional investors also grant the board proxies. The large number of shareholders also makes it hard for them to organize. However, there have been moves recently to try to increase shareholder activism among both institutional investors and individuals with small shareholdings.\n\nA contrasting view is that in large public companies it is upper management and not boards that wield practical power, because boards delegate nearly all of their power to the top executive employees, adopting their recommendations almost without fail. As a practical matter, executives even choose the directors, with shareholders normally following management recommendations and voting for them.\n\nIn most cases, serving on a board is not a career unto itself. For major corporations, the board members are usually professionals or leaders in their field. In the case of outside directors, they are often senior leaders of other organizations. Nevertheless, board members often receive remunerations amounting to hundreds of thousands of dollars per year since they often sit on the boards of several companies. Inside directors are usually not paid for sitting on a board, but the duty is instead considered part of their larger job description. Outside directors are usually paid for their services. These remunerations vary between corporations, but usually consist of a yearly or monthly salary, additional compensation for each meeting attended, stock options, and various other benefits. such as travel, hotel and meal expenses for the board meetings. Tiffany & Co., for example, pays directors an annual retainer of $46,500, an additional annual retainer of $2,500 if the director is also a chairperson of a committee, a per-meeting-attended fee of $2,000 for meetings attended in person, a $500 fee for each meeting attended via telephone, in addition to stock options and retirement benefits.\n\nIn some European and Asian countries, there are two separate boards, an executive board for day-to-day business and a supervisory board (elected by the shareholders and employees) for supervising the executive board. In these countries, the CEO (chief executive or managing director) presides over the executive board and the chairman presides over the supervisory board, and these two roles will always be held by different people. This ensures a distinction between management by the executive board and governance by the supervisory board and allows for clear lines of authority. The aim is to prevent a conflict of interest and too much power being concentrated in the hands of one person. There is a strong parallel here with the structure of government, which tends to separate the political cabinet from the management civil service. In the United States, the board of directors (elected by the shareholders) is often equivalent to the supervisory board, while the executive board may often be known as the executive committee (operating committee or executive council), composed of the CEO and their direct reports (other C-level officers, division/subsidiary heads).\n\nThe development of a separate board of directors to manage/govern/oversee a company has occurred incrementally and indefinitely over legal history. Until the end of the 19th century, it seems to have been generally assumed that the general meeting (of all shareholders) was the supreme organ of a company, and that the board of directors merely acted as an agent of the company subject to the control of the shareholders in general meeting.\n\nHowever, by 1906, the English Court of Appeal had made it clear in the decision of \"Automatic Self-Cleansing Filter Syndicate Co Ltd v Cuninghame\" [1906] 2 Ch 34 that the division of powers between the board and the shareholders in general meaning depended on the construction of the articles of association and that, where the powers of management were vested in the board, the general meeting could not interfere with their lawful exercise. The articles were held to constitute a contract by which the members had agreed that \"the directors and the directors alone shall manage.\"\n\nThe new approach did not secure immediate approval, but it was endorsed by the House of Lords in \"Quin & Axtens v Salmon\" [1909] AC 442 and has since received general acceptance. Under English law, successive versions of Table A have reinforced the norm that, unless the directors are acting contrary to the law or the provisions of the Articles, the powers of conducting the management and affairs of the company are vested in them.\n\nThe modern doctrine was expressed in \"John Shaw & Sons (Salford) Ltd v Shaw\" [1935] 2 KB 113 by Greer LJ as follows:\n\nA company is an entity distinct alike from its shareholders and its directors. Some of its powers may, according to its articles, be exercised by directors, certain other powers may be reserved for the shareholders in general meeting. If powers of management are vested in the directors, they and they alone can exercise these powers. The only way in which the general body of shareholders can control the exercise of powers by the articles in the directors is by altering the articles, or, if opportunity arises under the articles, by refusing to re-elect the directors of whose actions they disapprove. They cannot themselves usurp the powers which by the articles are vested in the directors any more than the directors can usurp the powers vested by the articles in the general body of shareholders.\nIt has been remarked that this development in the law was somewhat surprising at the time, as the relevant provisions in Table A (as it was then) seemed to contradict this approach rather than to endorse it.\n\nIn most legal systems, the appointment and removal of directors is voted upon by the shareholders in general meeting or through a proxy statement. For publicly traded companies in the U.S., the directors which are available to vote on are largely selected by either the board as a whole or a nominating committee. Although in 2002 the New York Stock Exchange and the NASDAQ required that nominating committees consist of independent directors as a condition of listing, nomination committees have historically received input from management in their selections even when the CEO does not have a position on the board. Shareholder nominations can only occur at the general meeting itself or through the prohibitively expensive process of mailing out ballots separately; in May 2009 the SEC proposed a new rule allowing shareholders meeting certain criteria to add nominees to the proxy statement. In practice for publicly traded companies, the managers (inside directors) who are purportedly accountable to the board of directors have historically played a major role in selecting and nominating the directors who are voted on by the shareholders, in which case more \"gray outsider directors\" (independent directors with conflicts of interest) are nominated and elected.\n\nDirectors may also leave office by resignation or death. In some legal systems, directors may also be removed by a resolution of the remaining directors (in some countries they may only do so \"with cause\"; in others the power is unrestricted).\n\nSome jurisdictions also permit the board of directors to appoint directors, either to fill a vacancy which arises on resignation or death, or as an addition to the existing directors.\n\nIn practice, it can be quite difficult to remove a director by a resolution in general meeting. In many legal systems, the director has a right to receive special notice of any resolution to remove him or her; the company must often supply a copy of the proposal to the director, who is usually entitled to be heard by the meeting. The director may require the company to circulate any representations that he wishes to make. Furthermore, the director's contract of service will usually entitle him to compensation if he is removed, and may often include a generous \"golden parachute\" which also acts as a deterrent to removal.\n\nA recent study examines how corporate shareholders voted in director elections in the United States. It found that directors received fewer votes from shareholders when their companies performed poorly, had excess CEO compensation, or had poor shareholder protection. Also, directors received fewer votes when they did not regularly attend board meetings or received negative recommendations from a proxy advisory firm. The study also shows that companies often improve their corporate governance by removing poison pills or classified boards and by reducing excessive CEO pay after their directors receive low shareholder support.\n\nBoard accountability to shareholders is a recurring issue. In 2010, the \"New York Times\" noted that several directors who had overseen companies which had failed in the financial crisis of 2007–2010 had found new positions as directors. The SEC sometimes imposes a ban (a \"D&O bar\") on serving on a board as part of its fraud cases, and one of these was upheld in 2013.\n\nThe exercise by the board of directors of its powers usually occurs in board meetings. Most legal systems require sufficient notice to be given to all directors of these meetings, and that a quorum must be present before any business may be conducted. Usually, a meeting which is held without notice having been given is still valid if all of the directors attend, but it has been held that a failure to give notice may negate resolutions passed at a meeting, because the persuasive oratory of a minority of directors might have persuaded the majority to change their minds and vote otherwise.\n\nIn most common law countries, the powers of the board are vested in the board as a whole, and not in the individual directors. However, in instances an individual director may still bind the company by his acts by virtue of his ostensible authority (see also: the rule in \"Turquand's Case\").\n\nBecause directors exercise control and management over the organization, but organizations are (in theory) run for the benefit of the shareholders, the law imposes strict duties on directors in relation to the exercise of their duties. The duties imposed on directors are fiduciary duties, similar to those that the law imposes on those in similar positions of trust: agents and trustees.\n\nThe duties apply to each director separately, while the powers apply to the board jointly. Also, the duties are owed to the company itself, and not to any other entity. This does not mean that directors can never stand in a fiduciary relationship to the individual shareholders; they may well have such a duty in certain circumstances.\n\nDirectors must exercise their powers for a proper purpose. While in many instances an improper purpose is readily evident, such as a director looking to feather his or her own nest or divert an investment opportunity to a relative, such breaches usually involve a breach of the director's duty to act in good faith. Greater difficulties arise where the director, while acting in good faith, is serving a purpose that is not regarded by the law as proper.\n\nThe seminal authority in relation to what amounts to a proper purpose is the Supreme Court decision in Eclairs Group Ltd v JKX Oil & Gas plc (2015). The case concerned the powers of directors under the articles of association of the company to disenfranchise voting rights attached to shares for failure to properly comply with notice served on the shareholders. Prior to that case the leading authority was \"Howard Smith Ltd v Ampol Ltd\" [1974] AC 821. The case concerned the power of the directors to issue new shares. It was alleged that the directors had issued a large number of new shares purely to deprive a particular shareholder of his voting majority. An argument that the power to issue shares could only be properly exercised to raise new capital was rejected as too narrow, and it was held that it would be a proper exercise of the director's powers to issue shares to a larger company to ensure the financial stability of the company, or as part of an agreement to exploit mineral rights owned by the company. If so, the mere fact that an incidental result (even if it was a desired consequence) was that a shareholder lost his majority, or a takeover bid was defeated, this would not itself make the share issue improper. But if the sole purpose was to destroy a voting majority, or block a takeover bid, that would be an improper purpose.\n\nNot all jurisdictions recognised the \"proper purpose\" duty as separate from the \"good faith\" duty however.\n\nDirectors cannot, without the consent of the company, fetter their discretion in relation to the exercise of their powers, and cannot bind themselves to vote in a particular way at future board meetings. This is so even if there is no improper motive or purpose, and no personal advantage to the director.\n\nThis does not mean, however, that the board cannot agree to the company entering into a contract which binds the company to a certain course, even if certain actions in that course will require further board approval. The company remains bound, but the directors retain the discretion to vote against taking the future actions (although that may involve a breach by the company of the contract that the board previously approved).\n\nAs fiduciaries, the directors may not put themselves in a position where their interests and duties conflict with the duties that they owe to the company. The law takes the view that good faith must not only be done, but must be manifestly seen to be done, and zealously patrols the conduct of directors in this regard; and will not allow directors to escape liability by asserting that his decision was in fact well founded. Traditionally, the law has divided conflicts of duty and interest into three sub-categories.\n\nBy definition, where a director enters into a transaction with a company, there is a conflict between the director's interest (to do well for himself out of the transaction) and his duty to the company (to ensure that the company gets as much as it can out of the transaction). This rule is so strictly enforced that, even where the conflict of interest or conflict of duty is purely hypothetical, the directors can be forced to disgorge all personal gains arising from it. In \"Aberdeen Ry v Blaikie\" (1854) 1 Macq HL 461 Lord Cranworth stated in his judgment that:\n\nHowever, in many jurisdictions the members of the company are permitted to ratify transactions which would otherwise fall foul of this principle. It is also largely accepted in most jurisdictions that this principle can be overridden in the company's constitution.\n\nIn many countries, there is also a statutory duty to declare interests in relation to any transactions, and the director can be fined for failing to make disclosure.\n\nDirectors must not, without the informed consent of the company, use for their own profit the company's assets, opportunities, or information. This prohibition is much less flexible than the prohibition against the transactions with the company, and attempts to circumvent it using provisions in the articles have met with limited success.\n\nIn \"Regal (Hastings) Ltd v Gulliver\" [1942] All ER 378 the House of Lords, in upholding what was regarded as a wholly unmeritorious claim by the shareholders, held that:\n\nAnd accordingly, the directors were required to disgorge the profits that they made, and the shareholders received their windfall.\n\nThe decision has been followed in several subsequent cases, and is now regarded as settled law.\n\nDirectors cannot compete directly with the company without a conflict of interest arising. Similarly, they should not act as directors of competing companies, as their duties to each company would then conflict with each other.\n\nTraditionally, the level of care and skill which has to be demonstrated by a director has been framed largely with reference to the non-executive director. In \"Re City Equitable Fire Insurance Co\" [1925] Ch 407, it was expressed in purely subjective terms, where the court held that:\n\nHowever, this decision was based firmly in the older notions (see above) that prevailed at the time as to the mode of corporate decision making, and effective control residing in the shareholders; if they elected and put up with an incompetent decision maker, they should not have recourse to complain.\n\nHowever, a more modern approach has since developed, and in \"Dorchester Finance Co Ltd v Stebbing\" [1989] BCLC 498 the court held that the rule in \"Equitable Fire\" related only to skill, and not to diligence. With respect to diligence, what was required was:\n\nThis was a dual subjective and objective test, and one deliberately pitched at a higher level.\n\nMore recently, it has been suggested that both the tests of skill and diligence should be assessed objectively and subjectively; in the United Kingdom, the statutory provisions relating to directors' duties in the new Companies Act 2006 have been codified on this basis.\n\nIn most jurisdictions, the law provides for a variety of remedies in the event of a breach by the directors of their duties:\n\nHistorically, directors' duties have been owed almost exclusively to the company and its members, and the board was expected to exercise its powers for the financial benefit of the company. However, more recently there have been attempts to \"soften\" the position, and provide for more scope for directors to act as good corporate citizens. For example, in the United Kingdom, the Companies Act 2006 requires directors of companies \"to promote the success of the company for the benefit of its members as a whole\" and sets out the following six factors regarding a director's duty to promote success:\n\nThis represents a considerable departure from the traditional notion that directors' duties are owed only to the company. Previously in the United Kingdom, under the Companies Act 1985, protections for non-member stakeholders were considerably more limited (see, for example, s.309 which permitted directors to take into account the interests of employees but which could only be enforced by the shareholders and not by the employees themselves). The changes have therefore been the subject of some criticism.\n\nMost companies have weak mechanisms for bringing the voice of society into the board room. They rely on personalities who weren't appointed for their understanding of societal issues. Often they give limited focus (both through time and financial resource) to issues of corporate responsibility and sustainability. A Social Board has society designed into its structure. It elevates the voice of society through specialist appointments to the board and mechanisms that empower innovation from within the organisation. Social Boards align themselves with themes that are important to society.These may include measuring worker pay ratios, linking personal social and environmental objectives to remuneration, integrated reporting, fair tax and B-Corp Certification. \n\nSocial Boards recognise that they are part of society and that they require more than a licence to operate to succeed.They balance short-term shareholder pressure against long-term value creation, managing the business for a plurality of stakeholders including employees, shareholders, supply chains and civil society.\n\nThe Sarbanes–Oxley Act of 2002 has introduced new standards of accountability on boards of U.S. companies or companies listed on U.S. stock exchanges. Under the Act, directors risk large fines and prison sentences in the case of accounting crimes. Internal control is now the direct responsibility of directors. The vast majority of companies covered by the Act have hired internal auditors to ensure that the company adheres to required standards of internal control. The internal auditors are required by law to report directly to an audit board, consisting of directors more than half of whom are outside directors, one of whom is a \"financial expert.\"\n\nThe law requires companies listed on the major stock exchanges (NYSE, NASDAQ) to have a majority of independent directors—directors who are not otherwise employed by the firm or in a business relationship with it.\n\nAccording to the Corporate Library's study, the average size of publicly traded company's board is 9.2 members, and most boards range from 3 to 31 members. According to Investopedia, some analysts think the ideal size is seven. State law may specify a minimum number of directors, maximum number of directors, and qualifications for directors (e.g. whether board members must be individuals or may be business entities).\n\nWhile a board may have several committees, two—the compensation committee and audit committee—are critical and must be made up of at least three independent directors and no inside directors. Other common committees in boards are nominating and governance.\n\nDirectors of Fortune 500 companies received median pay of $234,000 in 2011. Directorship is a part-time job. A recent National Association of Corporate Directors study found directors averaging just 4.3 hours a week on board work. Surveys indicate that about 20% of nonprofit foundations pay their board members, and 2% of American nonprofit organizations do. 80% of nonprofit organizations require board members to personally contribute to the organization, as BoardSource recommends. This percentage has increased in recent years.\n\nAccording to John Gillespie, a former investment banker and co-author of a book critical of boards, \"Far too much of their time has been for check-the-box and cover-your-behind activities rather than real monitoring of executives and providing strategic advice on behalf of shareholders\". At the same time, scholars have found that individual directors have a large effect on major corporate initiatives such as mergers and acquisitions and cross-border investments.\n\nThe issue of gender representation on corporate boards of directors has been the subject of much criticism in recent years. Governments and corporations have responded with measures such as legislation mandating gender quotas and comply or explain systems to address the disproportionality of gender representation on corporate boards. A study of the French corporate elite has found that certain social classes are also disproportionately represented on boards, with those from the upper and, especially, upper-middle classes tending to dominate.\n\n\n"}
{"id": "11957991", "url": "https://en.wikipedia.org/wiki?curid=11957991", "title": "British business group", "text": "British business group\n\nA British Business Group (BBG) is an association or club of expatriate British business people. The aims of the group are typically to encourage trade with the host country and to provide a social environment for business networking. Typically a BBG will organize trade missions, lectures and social functions. Many BBGs fulfill a charitable role, although that is not a primary function.\n\nBBGs are often closely associated with the local British consulate or embassy, and with related organizations, such as the Middle East Association or the UKTI.\n\n"}
{"id": "49516943", "url": "https://en.wikipedia.org/wiki?curid=49516943", "title": "Business Technology Management", "text": "Business Technology Management\n\nBusiness Technology Management (BTM) is an emerging trans-disciplinary research area and professional discipline in Business Administration.\n\nBuilding upon other business disciplines, such as Management Information Systems (MIS) and Technology and Innovation Management (TIM), it seeks to provide an integrated framework for the strategic use of technology and the digital transformation of organizations.\n\nBTM is evolving similarly to other research areas in business, e.g., professional disciplines of Change Management (CM) and Management Consulting, developed from foundations in Organizational Behavior (OB), Strategic Management (SM), and Operations Management (OM).\n\nA new BTM program accreditation standard has been developed by ITAC Talent, a division of the IT Association of Canada. It was mandated by the Government of Canada to develop and update the educational standards of BTM programs in the country.\n"}
{"id": "20732298", "url": "https://en.wikipedia.org/wiki?curid=20732298", "title": "Business rule mining", "text": "Business rule mining\n\nBusiness rule mining is the process of extracting essential intellectual business logic in the form of Business Rules from packaged or Legacy software applications, recasting them in natural or formal language, and storing them in a source rule repository for further analysis or forward engineering. The goal is to capture these legacy business rules in a way that the business can validate, control and change them over time. \n\nBusiness rule mining supports a Business rules approach, which is defined as a formal way of managing and automating an organization's business rules so that the business behaves and evolves as its leaders intend. \n\nIt is also commonly conducted as part of an application modernization project evolving legacy software applications to service oriented architecture (SOA) solutions, transitioning to packaged software, redeveloping new in-house applications, or to facilitate knowledge retention and communication between business and IT professionals in a maintenance environment.\n\nAlternative approaches to rule mining are manual and automated. \n\nA manual approach involves the hand-writing of rules on the basis of subject matter expert interviews and the inspection of source code, job flows, data structures and observed behavior. \n\nManually extracting rules is complicated by the difficulty of locating and understanding highly interdependent logic that has been interwoven into millions of lines of software code. \n\nAn automated approach utilizes repository-based software to locate logical connections inherent within applications and extract them into a predetermined business rules format.\n\nWith automation, an effective approach is to apply semantic structures to existing applications. By overlaying business contexts onto legacy applications, rules miners can focus effort on discovering rules from systems that are valuable to the business. Effort is redirected away from mining commoditized or irrelevant applications. \n\nFurther, best practices coupled with various tool-assisted techniques of capturing programs’ semantics speeds the transformation of technical rules to true business rules. Adding business semantics to the analysis process allows users to abstract technical concepts and descriptors that are normal in an application to a business level that is consumable by a rules analyst. \n\nSystem integrators, software vendors, rules mining practitioners, and in-house development teams have developed technologies, proprietary methodologies and industry-specific templates for application modernization and business rule mining.\n\n\n\n"}
{"id": "10425639", "url": "https://en.wikipedia.org/wiki?curid=10425639", "title": "CMD Group", "text": "CMD Group\n\nCMD Group, formerly Reed Construction Data and Construction Market Data, is a provider of business information for the North American construction industry. CMD is owned by Warburg Pincus (51%) and Reed Business Information (49%). Its historical roots lie in Construction Market Data, founded in 1982 to publish construction leads and market data. In 2000, London-based Reed Elsevier purchased this original CMD Group, transitioning the company to Reed Construction Data.\n\nIn October 2014 private equity firm Warburg Pincus in New York purchased a majority stake in the company, and Reed Construction Data changed its name to CMD. The Norcross, Ga.-based provider of North American construction data said the new name is a nod to the company’s original name: Construction Market Data. The new brand includes an updated logo and website.\n\nThe company tracks data on hundreds of thousands of projects per year, providing coverage of construction projects in both the United States and Canada. The company provides monthly analysis and data for all aspects of the construction industry. CMD also provides a detailed view of construction activity, including historical data, current-year projections and a five-year forecast. Their research helps customers forecast to find those market segments experiencing the greatest growth and plan tactical marketing strategies.\n\nIn October 2009, Reed Construction Data (which is now Construction Market Data a division of ConstructCONNECT) filed suit in federal court against McGraw-Hill Construction, charging that the company's Dodge Report had unlawfully accessed confidential and trade secret information from Reed since 2002 by using a series of fake companies to pose as Reed customers.\nThe lawsuit, filed in the U.S. District Court for the Southern District of New York, seeks an unspecified amount in lost profits and punitive damages, trial by jury, and injunctive relief as a result of Dodge’s misuse of proprietary construction project information, and that Dodge allegedly manipulated the information to create misleading comparisons between Dodge’s and Reed’s products and services in an effort to mislead the marketplace.\n\nIn 2016, CMD Group became a part of ConstructConnect as part of a merger with iSqFt, BidClerk, Construction Data.\n\n"}
{"id": "44478333", "url": "https://en.wikipedia.org/wiki?curid=44478333", "title": "Cash break even ratio", "text": "Cash break even ratio\n\nThe cash break even ratio is used in evaluating the financial performance of an income property to determine what rate of occupancy is required to meet both operating expense and mortgage payments (debt service).\n\nCash Break Even Ratio = (Operating Expenses + Mortgage Payment - Reserves for Replacement) / Potential Gross Income\n\nIt allows both lenders and investors to assess a particular income properties ability to meet its operating expenses and provide a measurable level of profit. The ratio does not include reserves for replacement, because it is not an actual cash expense. Additionally, it includes mortgage payment (debt service) which applies to most income properties that use leverage to enhance return on investment and equity dividend rate (cash on cash return).\n"}
{"id": "58721", "url": "https://en.wikipedia.org/wiki?curid=58721", "title": "Chemical industry", "text": "Chemical industry\n\nThe chemical industry comprises the companies that produce industrial chemicals. Central to the modern world economy, it converts raw materials (oil, natural gas, air, water, metals, and minerals) into more than 70,000 different products.\n\nThe plastics industry contains some overlap, as most chemical companies produce plastic as well as other chemicals.\n\nAlthough chemicals were made and used throughout history, the birth of the heavy chemical industry (production of chemicals in large quantities for a variety of uses) coincided with the beginnings of the Industrial Revolution in general.\n\nOne of the first chemicals to be produced in large amounts through industrial processes was sulphuric acid. In 1736, the pharmacist Joshua Ward developed a process for its production that involved heating saltpeter, allowing the sulfur to oxidize and combine with water. It was the first practical production of sulphuric acid on a large scale. John Roebuck and Samuel Garbett were the first to establish a large-scale factory in Prestonpans, Scotland, in 1749, which used leaden condensing chambers for the manufacture of sulfuric acid.\nIn the early 18th century, cloth was bleached by treating it with stale urine or sour milk and exposing it to sunlight for long periods of time, which created a severe bottleneck in production. Sulfuric acid began to be used as a more efficient agent as well as lime by the middle of the century, but it was the discovery of bleaching powder by Charles Tennant that spurred the creation of the first great chemical industrial enterprise. His powder was made by reacting chlorine with dry slaked lime and proved to be a cheap and successful product. He opened a factory in St Rollox, north of Glasgow, and production went from just 52 tons in 1799 to almost 10,000 tons just five years later.\n\nSoda ash was used since ancient times in the production of glass, textile, soap, and paper, and the source of the potash had traditionally been wood ashes in Western Europe. By the 18th century, this source was becoming uneconomical due to deforestation, and the French Academy of Sciences offered a prize of 2400 livres for a method to produce alkali from sea salt (sodium chloride). The Leblanc process was patented in 1791 by Nicolas Leblanc who then built a Leblanc plant at Saint-Denis. He was denied his prize money because of the French Revolution.\n\nHowever, it was in Britain that the Leblanc process really took off. William Losh built the first soda works in Britain at the Losh, Wilson and Bell works on the River Tyne in 1816, but it remained on a small scale due to large tariffs on salt production until 1824. When these tariffs were repealed, the British soda industry was able to rapidly expand. James Muspratt's chemical works in Liverpool and Charles Tennant's complex near Glasgow became the largest chemical production centres anywhere. By the 1870s, the British soda output of 200,000 tons annually exceeded that of all other nations in the world combined.\nThese huge factories began to produce a greater diversity of chemicals as the Industrial Revolution matured. Originally, large quantities of alkaline waste were vented into the environment from the production of soda, provoking one of the first pieces of environmental legislation to be passed in 1863. This provided for close inspection of the factories and imposed heavy fines on those exceeding the limits on pollution. Methods were soon devised to make useful byproducts from the alkali.\n\nThe Solvay process was developed by the Belgian industrial chemist Ernest Solvay in 1861. In 1864, Solvay and his brother Alfred constructed a plant in the Belgian town of Charleroi and in 1874, they expanded into a larger plant in Nancy, France. The new process proved more economical and less polluting than the Leblanc method, and its use spread. In the same year, Ludwig Mond visited Solvay to acquire the rights to use his process, and he and John Brunner formed the firm of Brunner, Mond & Co., and built a Solvay plant at Winnington, England. Mond was instrumental in making the Solvay process a commercial success; he made several refinements between 1873 and 1880 that removed byproducts that could slow or halt the mass production of sodium carbonate through use of the process.\n\nThe late 19th century saw an explosion in both the quantity of production and the variety of chemicals that were manufactured. Large chemical industries also took shape in Germany and later in the United States.\nProduction of artificial manufactured fertilizer for agriculture was pioneered by Sir John Lawes at his purpose-built Rothamsted Research facility. In the 1840s he established large works near London for the manufacture of superphosphate of lime. Processes for the vulcanization of rubber were patented by Charles Goodyear in the United States and Thomas Hancock in England in the 1840s. The first synthetic dye was discovered by William Henry Perkin in London. He partly transformed aniline into a crude mixture which, when extracted with alcohol, produced a substance with an intense purple colour. He also developed the first synthetic perfumes. However, it was German industry that quickly began to dominate the field of synthetic dyes. The three major firms BASF, Bayer and Hoechst produced several hundred different dyes, and by 1913, the German industry produced almost 90 percent of the world supply of dyestuffs and sold about 80 percent of their production abroad. In the United States, Herbert Henry Dow's use of electrochemistry to produce chemicals from brine was a commercial success that helped to promote the country's chemical industry.\n\nThe petrochemical industry can be traced back to the oil works of James Young in Scotland and Abraham Pineo Gesner in Canada. The first plastic was invented by Alexander Parkes, an English metallurgist. In 1856, he patented Parkesine, a celluloid based on nitrocellulose treated with a variety of solvents. This material, exhibited at the 1862 London International Exhibition, anticipated many of the modern aesthetic and utility uses of plastics. The industrial production of soap from vegetable oils was started by William Lever and his brother James in 1885 in Lancashire based on a modern chemical process invented by William Hough Watson that used glycerin and vegetable oils.\n\nBy the 1920s, chemical firms consolidated into large conglomerates; IG Farben in Germany, Rhône-Poulenc in France and Imperial Chemical Industries in Britain. Dupont became a major chemicals firm in the early 20th century in America.\n\nCurrently chemical production is a high-tech industry, where the competitiveness is more based on capacity in investment on research and development than the labour cost.\n\n\"Polymers and plastics, especially polyethylene, polypropylene, polyvinyl chloride, polyethylene terephthalate, polystyrene and polycarbonate comprise about 80% of the industry’s output worldwide\". These materials are often converted to fluoropolymer tubing products and used by the industry to transport highly corrosive materials. Chemicals are used in a lot of different consumer goods, but they are also used in a lot of different other sectors; including agriculture manufacturing, construction, and service industries. Major industrial customers include rubber and plastic products, textiles, apparel, petroleum refining, pulp and paper, and primary metals. Chemicals are nearly a $3 trillion global enterprise, and the EU and U.S. chemical companies are the world's largest producers.\n\nSales of the chemical business can be divided into a few broad categories, including basic chemicals (about 35 to 37 percent of the dollar output), life sciences (30 percent), specialty chemicals (20 to 25 percent) and consumer products (about 10 percent).\n\nPolymers, the largest revenue segment at about 33 percent of the basic chemicals dollar value, includes all categories of plastics and man-made fibers. The major markets for plastics are packaging, followed by home construction, containers, appliances, pipe, transportation, toys, and games. \nThe principal raw materials for polymers are bulk petrochemicals.\n\nChemicals in the bulk petrochemicals and intermediates are primarily made from liquefied petroleum gas (LPG), natural gas, and crude oil. Their sales volume is close to 30 percent of overall basic chemicals. \nTypical large-volume products include ethylene, propylene, benzene, toluene, xylenes, methanol, vinyl chloride monomer (VCM), styrene, butadiene, and ethylene oxide. These basic or commodity chemicals are the starting materials used to manufacture many polymers and other more complex organic chemicals particularly those that are made for use in the specialty chemicals category (see below).\n\nOther derivatives and basic industrials include synthetic rubber, surfactants, dyes and pigments, turpentine, resins, carbon black, explosives, and rubber products and contribute about 20 percent of the basic chemicals' external sales.\n\nInorganic chemicals (about 12 percent of the revenue output) make up the oldest of the chemical categories. Products include salt, chlorine, caustic soda, soda ash, acids (such as nitric acid, phosphoric acid, and sulfuric acid), titanium dioxide, and hydrogen peroxide.\n\nFertilizers are the smallest category (about 6 percent) and include phosphates, ammonia, and potash chemicals.\n\nLife sciences (about 30 percent of the dollar output of the chemistry business) include differentiated chemical and biological substances, pharmaceuticals, diagnostics, animal health products, vitamins, and pesticides. While much smaller in volume than other chemical sectors, their products tend to have very high prices—over ten dollars per pound—growth rates of 1.5 to 6 times GDP, and research and development spending at 15 to 25 percent of sales. Life science products are usually produced with very high specifications and are closely scrutinized by government agencies such as the Food and Drug Administration. Pesticides, also called \"crop protection chemicals\", are about 10 percent of this category and include herbicides, insecticides, and fungicides.\n\nSpecialty chemicals are a category of relatively high valued, rapidly growing chemicals with diverse end product markets. Typical growth rates are one to three times GDP with prices over a dollar per pound. They are generally characterized by their innovative aspects. Products are sold for what they can do rather than for what chemicals they contain. Products include electronic chemicals, industrial gases, adhesives and sealants as well as coatings, industrial and institutional cleaning chemicals, and catalysts. In 2012, excluding fine chemicals, the $546 billion global speciality chemical market was 33% Paints, Coating and Surface Treatments, 27% Advanced Polymer, 14% Adhesives and Sealants, 13% additives and 13% pigments and inks.\n\nSpeciality chemicals are sold as effect or performance chemicals. Sometimes they are mixtures of formulations, unlike \"fine chemicals,\" which are almost always single-molecule products.\n\nConsumer products include direct product sale of chemicals such as soaps, detergents, and cosmetics. Typical growth rates are 0.8 to 1.0 times GDP.\n\nConsumers rarely if ever come into contact with basic chemicals but polymers and speciality chemicals are the materials that they will encounter everywhere in their everyday lives, such as in plastics, cleaning materials, cosmetics, paints & coatings, electronic gadgets, automobiles and the materials used to construct their homes. These speciality products are marketed by chemical companies to the downstream manufacturing industries as pesticides, speciality polymers, electronic chemicals, surfactants, construction chemicals, Industrial Cleaners, flavours and fragrances, speciality coatings, printing inks, water-soluble polymers, food additives, paper chemicals, oil field chemicals, plastic adhesives, adhesives and sealants, cosmetic chemicals, water management chemicals, catalysts, textile chemicals. Chemical companies rarely supply these products directly to the consumer.\n\nEvery year, the American Chemistry Council tabulates the U.S. production volume of the top 100 chemicals.In 2000, the aggregate production volume of the top 100 chemicals totalled 502 million tons, up from 397 million tons in 1990. \nInorganic chemicals tend to be the largest volume, though much smaller in dollar revenue terms due to their low prices. The top 11 of the 100 chemicals in 2000 were sulfuric acid (44 million tons), nitrogen (34), ethylene (28), oxygen (27), lime (22), ammonia (17), propylene (16), polyethylene (15), chlorine (13), phosphoric acid (13) and diammonium phosphates (12).\n\nThe largest chemical producers today are global companies with international operations and plants in numerous countries. A list of the top 25 chemical companies by chemical sales in 2015 appears below. (Note: Chemical sales represent only a portion of total sales for some companies.)\n\nTop chemical companies by chemical sales in 2015.\n\nFrom the perspective of chemical engineers, the chemical industry involves the use of chemical processes such as chemical reactions and refining methods to produce a wide variety of solid, liquid, and gaseous materials. Most of these products serve to manufacture other items, although a smaller number go directly to consumers. Solvents, pesticides, lye, washing soda, and portland cement provide a few examples of product used by consumers.\n\nThe industry includes manufacturers of inorganic- and organic-industrial chemicals, ceramic products, petrochemicals, agrochemicals, polymers and rubber (elastomers), oleochemicals (oils, fats, and waxes), explosives, fragrances and flavors. Examples of these products are shown in the Table below.\nAlthough the pharmaceutical industry is often considered a chemical industry , it has many different characteristics that puts it in a separate category. Other closely related industries include petroleum, glass, paint, ink, sealant, adhesive, and food processing manufacturers.\n\nChemical processes such as chemical reactions operate in chemical plants to form new substances in various types of reaction vessels. In many cases the reactions take place in special corrosion-resistant equipment at elevated temperatures and pressures with the use of catalysts. The products of these reactions are separated using a variety of techniques including distillation especially fractional distillation, precipitation, crystallization, adsorption, filtration, sublimation, and drying.\n\nThe processes and product or products are usually tested during and after manufacture by dedicated instruments and on-site quality control laboratories to ensure safe operation and to assure that the product will meet required specifications. More organizations within the industry are implementing chemical compliance software to maintain quality products and manufacturing standards. The products are packaged and delivered by many methods, including pipelines, tank-cars, and tank-trucks (for both solids and liquids), cylinders, drums, bottles, and boxes. Chemical companies often have a research-and-development laboratory for developing and testing products and processes. These facilities may include pilot plants, and such research facilities may be located at a site separate from the production plant(s).\n\nThe scale of chemical manufacturing tends to be organized from largest in volume (petrochemicals and commodity chemicals), to specialty chemicals, and the smallest, fine chemicals.\n\nThe petrochemical and commodity chemical manufacturing units are on the whole single product continuous processing plants. Not all petrochemical or commodity chemical materials are made in one single location, but groups of related materials often are to induce industrial symbiosis as well as material, energy and utility efficiency and other economies of scale.\n\nThose chemicals made on the largest of scales are made in a few manufacturing locations around the world, for example in Texas and Louisiana along the Gulf Coast of the United States, on Teesside in the Northeast of England in the United Kingdom, and in Rotterdam in the Netherlands. The large scale manufacturing locations often have clusters of manufacturing units that share utilities and large scale infrastructure such as power stations, port facilities, road and rail terminals. To demonstrate the clustering and integration mentioned above, some 50% of the United Kingdom's petrochemical and commodity chemicals are produced by the Northeast of England Process Industry Cluster on Teesside.\nSpecialty chemical and fine chemical manufacturing are mostly made in discrete batch processes. These manufacturers are often found in similar locations but in many cases they are to be found in multi sector business parks.\n\nIn the U.S. there are 170 major chemical companies.They operate internationally with more than 2,800 facilities outside the U.S. and 1,700 foreign subsidiaries or affiliates operating. The U.S. chemical output is $750 billion a year. The U.S. industry records large trade surpluses and employs more than a million people in the United States alone. The chemical industry is also the second largest consumer of energy in manufacturing and spends over $5 billion annually on pollution abatement.\n\nIn Europe the chemical, plastics and rubber sectors are among the largest industrial sectors. Together they generate about 3.2 million jobs in more than 60,000 companies. Since 2000 the chemical sector alone has represented 2/3 of the entire manufacturing trade surplus of the EU.\n\nin 2012 The chemical sector accounted for 12% of the EU manufacturing industry's added value. Europe remains world’s biggest chemical trading region with 43% of the world’s exports and 37%of the world’s imports, although the latest data shows that Asia is catching up with 34% of the exports and 37% of imports. Even so, Europe still has a trading surplus with all regions of the world except Japan and China where in 2011 there was a chemical trade balance. Europe’s trade surplus with the rest of the world today amounts to 41.7 billion Euros.\n\nOver the 20 years between 1991 and 2011 the European Chemical industry saw its sales increase 295 billion Euros to 539 billion Euros a picture of constant growth. Despite this the European industry’s share of the world chemical market has fallen from 36% to 20%. This has resulted from the huge increase production and sales in the emerging markets like India and China. The data suggest that 95% of this impact is from China alone. In 2012 the data from the European Chemical Industry Council (CEFIC)shows that 5 European countries account for 71% of the EU's chemicals sales. These are Germany, France, United Kingdom, Italy and the Netherlands.\n\nThe chemical industry has shown rapid growth for more than fifty years. The fastest-growing areas have involved the manufacture of synthetic organic polymers used as plastics, fibres and elastomers. Historically and presently the chemical industry has been concentrated in three areas of the world, Western Europe, North America and Japan (the Triad). The European Community remains the largest producer area followed by the US and Japan.\n\nThe traditional dominance of chemical production by the Triad countries is being challenged by changes in feedstock availability and price, labour cost, energy cost, differential rates of economic growth and environmental pressures. Instrumental in the changing structure of the global chemical industry has been the growth in China, India, Korea, the Middle East, South East Asia, Nigeria, and Brazil.\n\nJust as companies emerge as the main producers of the chemical industry, we can also look on a more global scale to how industrialized countries rank, with regards to the billions of dollars worth of production a country or region could export. Though the business of chemistry is worldwide in scope, the bulk of the world’s $3.7 trillion chemical output is accounted for by only a handful of industrialized nations. The United States alone produced $689 billion, 18.6 percent of the total world chemical output in 2008.\n\n\n"}
{"id": "39105755", "url": "https://en.wikipedia.org/wiki?curid=39105755", "title": "Chemonics", "text": "Chemonics\n\nChemonics International is a private international development company that works for bilateral and multilateral donors and the private sector to manage projects in developing countries. The organization bids primarily on contracts from the U.S. Agency for International Development (USAID) and manages projects that cover a variety of technical sectors. These sectors include agriculture and food security, corporate partnerships, democracy and governance, economic growth, education and youth, environment and natural resources, gender equality, social inclusion, health, peace and stability, supply chain solutions, and water. In addition to its headquarters in Washington, D.C., the company also has project offices in different countries, covering Asia, Africa, Eurasia, Europe, Latin America, and the Middle East.\n\nChemonics was founded in 1975 by Thurston F. (Tony) Teele.\n\nChemonics has been subject to criticism from the US Agency for International Development (USAID) Office of Inspector General (OIG) for their work on several multimillion-dollar aid contracts.\n\nIn 2012 Chemonics came under scrutiny by the OIG for their work in Haiti after the 2010 earthquake. Chemonics was the largest single recipient of post-earthquake funds from USAID, receiving over $196 million in contracts many of which were \"no-bid.\"\n\nAudits specifically cited Chemonics lack of a comprehensive monitoring and evaluation plan and that \"some of the performance indicators Chemonics developed were not well-defined.\" Chemonics also spent more than 75 percent of program budgets on material and equipment when an expenditure of only 30 percent was planned.\n\nAn Inspector General's report also found that local communities were not sufficiently involved with Chemonics' work and stated \"Chemonics used contractors from Port-au-Prince to implement a number of activities in Cap-Haitien and Saint-Marc; these contractors brought their own people to do the jobs instead of hiring locals.\" When locals were required by USAID, Chemonics' policies \"limited the transparency of the selection process and increase the risk of corruption or favoritism by granting decision-making authority to a few individuals.\"\n\nIn November 2006, USAID Afghanistan awarded a $62 million contract to Chemonics, with an expected end date of March 2010. A 2008 audit of the contract by OIG found that Chemonics' \"results fell considerably short of intended results\" and \"buildings constructed by Chemonics’ subcontractors were not acceptable because of significant construction defects.\"\n\nIn 2016, A Department of Labor investigation into Chemonics’ hiring practices found that the group discriminated against applicants based on race while trying to fill entry-level positions. According to the Guardian, none of the 124 Black Americans who applied for the jobs in Chemonics International’s regional business units were hired. Chemonics agreed to pay $482,243 to job applicants who were subjected to racial discrimination in the company’s hiring process, the Guardian reported.\n"}
{"id": "8774909", "url": "https://en.wikipedia.org/wiki?curid=8774909", "title": "Chicago Innovation Awards", "text": "Chicago Innovation Awards\n\nThe Chicago Innovation Awards was created by the Chicago Sun-Times and Kuczmarski & Associates in 2002. Each year the Awards recognize 10 Chicago area businesses, nonprofits, and government organizations that develop the year's most innovative new products and services.\n\nThe 2014 Chicago Innovations Awards reception was held at the Harris Theater. There was a total of 550 nominations by a team of judges. Winners were Auctions By Cellular, Dough, Deuxis, among others.\n\nThe 2013 Chicago Innovation Awards reception was held at the Harris Theater. The Social Innovator Award was given to the Chicago Public Library for their product, \"Maker Lab\" and the People's Choice Award was given to tastytrade. The Collaboration Awards was given to Ingenuity Incorporated for their product, \"Ingenuity\".\n\nRecipients:\n\nThe 2012 Chicago Innovation Awards reception was held at the Harris Theater. The People's Choice Award was given to New Futuro for their eponymous product.\n\nRecipients:\n\nThe 2011 Chicago Innovation Awards reception was held at the Harris Theater.\n\nRecipients:\n\nThe 2010 Chicago Innovation Awards reception was held at the Goodman Theater. A Visionary Award was given to Rocky Wirtz, president of the Wirtz Corp. and owner/chairman of The Chicago Blackhawks, winner of the Stanley Cup in 2010.\n\nRecipients:\n\nThe 2009 Chicago Innovation Awards reception was held at the Goodman Theater.\n\nRecipients:\n\nThe 2008 Chicago Innovation Awards reception was held at the Goodman Theater.\n\nRecipients:\n\nThe 2007 Chicago Innovation Awards reception was held at the Goodman Theater. A Visionary Pioneer Award was given to Joe Mansueto, the CEO of Morningstar.\n\nRecipients:\n\nThe 2006 Chicago Innovation Awards reception was held on October 30, 2006 at the Goodman Theater. A Visionary Pioneer Award was given to Gerald Putnam, the founder of Archipelago, an electronic stock exchange that was recently bought out by The New York Stock Exchange. The event was hosted by Thomas Kuczmarski, President and Senior Partner of Kuczmarski & Associates and Dan Miller, Business Editor of the Chicago Sun-Times.\n\nRecipients:\n\nIn 2005, the Chicago Innovation Awards reception was held on October 18 at the Goodman Theater. Casey Cowell, founder of U.S. Robotics was the keynote speaker and the winner of the 2005 Visionary Pioneer Award.\n\nRecipients:\n\nRecipients:\n\nRecipients:\n\nRecipients:\n\n"}
{"id": "26350643", "url": "https://en.wikipedia.org/wiki?curid=26350643", "title": "Chief content officer", "text": "Chief content officer\n\nA chief content officer (CCO) is a corporate executive responsible for the digital media creation and multi-channel publication of the organization's content (text, video, audio, animation, etc.).\n\nThe CCO is usually an executive role or senior vice president position, typically reporting to the chief executive officer or the president of the organization.\n\nIn a broadcasting organisation, the CCO is generally the highest ranking creative member of the organization. However, the chief content officer position is also common in many other industries, ranging from insurance to video production based on a LinkedIn study.\n\nLike all other chief officers, the chief content officer is responsible for supervision, coordination, planning and operation in his or her own field of responsibility. The CCO may also lead a company's branding and marketing efforts (as it relates to content), if these areas are not overseen by a chief marketing officer. In certain businesses which are involved in media creation such as Netflix, a CCO is responsible for developing original programming.\n"}
{"id": "54637277", "url": "https://en.wikipedia.org/wiki?curid=54637277", "title": "China Hospitality Technology Alliance", "text": "China Hospitality Technology Alliance\n\nChina Hospitality Technology Alliance (CHTA) is the largest Chinese non-profit organization for the technological product and technology development of the domestic hotel and the education and training of IT practitioners in the hotel industry.\n"}
{"id": "49840402", "url": "https://en.wikipedia.org/wiki?curid=49840402", "title": "Community contribution company", "text": "Community contribution company\n\nThe community contribution company is of corporate structure set up in 2012 in British Columbia, Canada. It is intermediate between a commercial, for-profit, model, and the charitable, non-profit organisation. Traditionally, non-profit organizations either depend a combination of government funding, philanthropy, and earned income. This corporate model was set up to help build earned income to secure long-term growth.\n\n\n"}
{"id": "49791445", "url": "https://en.wikipedia.org/wiki?curid=49791445", "title": "Contract management software", "text": "Contract management software\n\nContract management software is the range of computer programmes, libraries and data used to support contract management, contract lifecycle management, and contractor management on projects. It may be used with project management software.\n\nMost sophisticated projects involving contractors now use contract management software instead of relying on the manual management of paper contracts. It has become an essential tool for keeping track of multiple activities with cost implications, and can be especially helpful for automating administration, ensuring compliance, monitoring risk, running reports and triggering alerts. In addition to these types of features, contract management software systems provide a centralized repository for employees to quickly access all contracts worldwide in one place. Having contracts stored in multiple locations can delay and interrupt the contracting process.\n\nContract management software is produced by many companies, working on a range of scales and offering varying degrees of customizability. Basic functions should include the ability to store contract documents, track changes to contract documents, search documents for a particular criterion, send key date alerts and to report required aspects of the contract. Other functions include managing a new contract request, capturing related data, following a document through a review and approval process, and collecting digital signatures.\n\nContract management software may also be an aid to project portfolio management and spend analysis, and may also monitor KPIs. Leading contract management software provides contract visibility, monitoring, and compliance to automate and streamline the contract lifecycle process.\n\nA centralized repository provides a critical advantage allowing for all contract documents to be stored and within one location. Having contracts stored in multiple locations can delay and interrupt the contracting process.\n\nVery large enterprises, such as capital expenditure (capex) projects, involve multiple parties and high risk and uncertainty. They are unlike traditional operating contracts in that they are subject to shared deadlines in unique situations. As the complexity of these unique projects increases, the relationships between parties become more important. This requires contract management software, or contract risk management software (CRMS), to become more dynamic and responsive.\n\nThe terms of these capex contracts necessarily involve assumptions at the start of the process, and are likely to change over the lifetime of the project lifecycle. For this reason, CRMS must be capable of recording one single instance of agreed changes to contract terms, and incorporating these changes in an auditable and legally robust way. With multiple decision makers involved, CRMS should also make accountability more transparent and enable faster decisions about variation proposals.\n\nwww.comforce.co - comforce® Contract Lifecycle Management System (Software de Administración y Gestión de Contratos y Proveedores\n"}
{"id": "32958985", "url": "https://en.wikipedia.org/wiki?curid=32958985", "title": "DaySmart Software", "text": "DaySmart Software\n\nDaySmart Software, Inc., incorporated in 1999, is located in Ann Arbor, Michigan and designs, engineers and sells business management software for hair salons, day spas, pet groomers, tattoo parlors and many other personal service industries.\n\nDaySmart Software, Inc. was founded by Chris and Mark Jackson in March 1999 under the name CMJ Designs, Inc. On January 1, 2011 the name of the company changed from CMJ Designs, Inc. to DaySmart Software, Inc.\n\nDaySmart Software's first software product was designed for salons and spas. Initially branded Salon 2000, the software was rebranded in Aug. 2001 as Salon Iris and remains DaySmart Software's flagship product. The company has also expanded to pet grooming software, spa software, tattoo parlor software and affiliated web services.\n\nDaySmart also offers mobile applications available from the iTunes and Google Play stores.\n\n\"Inc. Magazine\" has included DaySmart Software on their list of the 5000 fastest growing private companies in the United States seven consecutive times.\n\nDaySmart Software was named one of the Michigan 50 Companies to Watch for in 2012 by the Edward Lowe Foundation.\n"}
{"id": "716853", "url": "https://en.wikipedia.org/wiki?curid=716853", "title": "Delivery (commerce)", "text": "Delivery (commerce)\n\nDelivery is the process of transporting goods from a source location to a predefined destination. There are different delivery types. Cargo (physical goods) are primarily delivered via roads and railroads on land, shipping lanes on the sea and airline networks in the air. Certain specialized goods may be delivered via other networks, such as pipelines for liquid goods, power grids for electrical power and computer networks such as the Internet or broadcast networks for electronic information.\n\nThe general process of delivering goods is known as distribution. The study of effective processes for delivery and disposition of goods and personnel is called logistics. Firms that specialize in delivering commercial goods from point of production or storage to point of sale are generally known as distributors, while those that specialize in the delivery of goods to the consumer are known as delivery services. Postal, courier, and relocation services also deliver goods for commercial and private interests.\n\nMost consumer goods are delivered from a point of production (factory or farm) through one or more points of storage (warehouses) to a point of sale (retail store), where the consumer buys the good and is responsible for its transportation to point of consumption. There are many variations on this model for specific types of goods and modes of sale. Products sold via catalogue or the Internet may be delivered directly from the manufacturer or warehouse to the consumer's home, or to an automated delivery booth. Small manufacturers may deliver their products directly to retail stores without warehousing.\n\nSome manufacturers maintain factory outlets which serve as both warehouse and retail store, selling products directly to consumers at wholesale prices (although many retail stores falsely advertise as factory outlets). Building, construction, landscaping and like materials are generally delivered to the consumer by a contractor as part of another service. Some highly perishable or hazardous goods, such as radioisotopes used in medical imaging, are delivered directly from manufacturer to consumer.\n\nHome delivery is often available for fast food and other convenience products, e.g. pizza delivery. Sometimes home delivery of supermarket goods is possible. A milk float is a small battery electric vehicle (BEV), specifically designed for the delivery of fresh milk. A new form of delivery is emerging on the horizon of the internet age: Delivery by the crowd e.g. crowd delivery. In this concept an individual not necessarily contracted by the vendor performs the delivery of goods to the destination. Sometimes, private courier companies will also deliver consumer goods on a regular basis for companies like E-commerce businesses.\n\nThe consumer demand for Supermarkets to deliver to their door created the need for a mixed temperature controlled vehicle on 3.5T chassis. These vehicle bodies were initially built with the traditional GRP sandwich panels but as more damage resistant lightweight materials with better insulation properties have become available companies have been developing Advanced Home Delivery Vehicles. The 2012 Commercial Vehicle Show in the UK saw the new JDC PolyBilt design, one of the latest of these \"Plastic\" bodies that can also be recycled at the end of its service life unlike the traditional GRP which ends up as landfill.\n\nVehicles are often specialized to deliver different types of goods. On land, semi-trailers are outfitted with various trailers such as box trailers, flatbeds, car carriers, tanks and other specialized trailers, while railroad trains include similarly specialized cars. Armored cars, dump trucks and concrete mixers are examples of vehicles specialized for delivery of specific types of goods. On the sea, merchant ships come in various forms, such as cargo ships, oil tankers and fishing boats. Freight aircraft are used to deliver cargo.\n\nOften, passenger vehicles are used for delivery of goods. These include buses, vans, pick-ups, cars (e.g., for mail or pizza delivery), motorcycles and bicycles (e.g., for newspaper delivery). A significant amount of freight is carried in the cargo holds of passenger ships and aircraft. Everyday travelers, known as a casual courier, can also be used to deliver goods.\n\nDelivery to remote, primitive or inhospitable areas may be accomplished using small aircraft, snowmobiles, horse-drawn vehicles, dog sleds, pack animals, on foot, or by a variety of other transport methods.\n\nSome products are delivered to consumers on a periodic schedule. Historically, home delivery of many goods was much more common in urban centres of the developed world. At the beginning of the 20th century, perishable farm items such as milk, eggs and ice, were delivered weekly or even daily to customers by local farms. Milkmen delivered milk and other farm produce. With the advent of home refrigeration and better distribution methods, these products are today largely delivered through the same retail distribution systems as other food products. Icemen delivered ice for iceboxes until the popularization of home refrigerator rendered them obsolete in most places. Similarly, laundry was once picked up and washed at a commercial laundry before being delivered to middle-class homes until the appearance of the washing machine and dryer (the lower classes washed their own and the upper classes had live-in servants). Likewise deliveries of coal and wood for home heating were more common until they were replaced in many areas by natural gas, oil, or electric heating. Some products, most notably home heating oil, are still delivered periodically. Human blood may be delivered to hospitals on a periodic schedule.\n\nMilk delivery continued until the mid-twentieth century across North America. For example, the last milk delivery by horse-and-wagon in Edmonton was in 1961. Milkman jokes continue in circulation long after. Related lines of Jeannie C. Riley's 1968 hit song \"Harper Valley PTA\" say:\n\"There's old Bobby Taylor sitting there, and seven times he's asked me for a date,And Mrs. Taylor sure seems to use a lot of ice whenever he's away.\"\n"}
{"id": "29775597", "url": "https://en.wikipedia.org/wiki?curid=29775597", "title": "Economic History Association", "text": "Economic History Association\n\nThe Economic History Association (EHA) was founded in 1940 to \"encourage and promote teaching, research, and publication on every phase of economic history and to help preserve and administer materials for research in economic history\". It publishes \"The Journal of Economic History\" with the Cambridge University Press, holds an annual meeting that usually takes place in September, and awards prizes and grants. It is also the home to the \"EH.Net Encyclopedia of Economic and Business History\".\n\nThere are more than 1,000 EHA members worldwide, and composed of faculty and graduate students from universities around the world, as well as economists in the private sector and in government.\n\nMichael Haupert of the University of Wisconsin-La Crosse is the Executive Director, and Cormac Ó Gráda is the President. Previous EHA Presidents include Oxford's Robert C. Allen, Vanderbilt's Jeremy Atack, UC Berkeley's Barry Eichengreen, Yale's Naomi Lamoreaux, as well as Economics Nobel Laureates Robert Fogel and Douglass North.\n\nThe Economic History Association supports research through Arthur H. Cole grants-in-aid and awards prizes for publications, dissertations, and teaching, as well as fellowships and grants for students of economic history.\n\nIt awards several prizes for publications:\n\nThe society also provides grants to support the early stages of dissertation work in economic history and fellowships to support students finishing their dissertations on the topic. Two Kenneth Sokoloff fellowships are awarded by the EHA each year to students finishing their dissertations in economic history.\n\nFor many years EHA has partnered with the American Economic Association to arrange sessions at the annual ASSA conference.\n\nThe 2018 annual EHA meeting will take place in Montreal, Canada, in September 2018; its theme is \"‘From Plague, Famine, and War, Save us, O Lord’ Shocks and Disasters in Economic History\".\n"}
{"id": "11574888", "url": "https://en.wikipedia.org/wiki?curid=11574888", "title": "Enterprise service layer", "text": "Enterprise service layer\n\nIn a service-oriented architecture business software implementation, the enterprise service layer (ESL) is the highest level of abstraction.\n\nAny application programming interface (API) defined at the ESL can cross domain boundaries; it calls directly the fomain dervice layer, which in turn interacts with the application service layer or the RDBMS Service Layer. Therefore, any API which must access multiple domains to execute correctly must exist at the enterprise level.\n\nSince the ESL is the API of the entire enterprise, all the components in the enterprise can call it directly, and it can sometimes be accessed from outside the service-providing entity.\n\nESL exposes a number of API considerably lower than the ASL because it works at a higher level of abstraction than the ASL.\n"}
{"id": "34561138", "url": "https://en.wikipedia.org/wiki?curid=34561138", "title": "Environmental profit and loss account", "text": "Environmental profit and loss account\n\nAn environmental profit and loss account (E P&L) is a company's monetary valuation and analysis of its environmental impacts including its business operations and its supply chain from cradle-to-gate.\nAn E P&L internalizes externalities and monetizes the cost of business to nature by accounting for the ecosystem services a business depends on to operate in addition to the cost of direct and indirect negative impacts on the environment. The primary purpose of an E P&L is to allow managers and stakeholders to see the magnitude of these impacts and where in the supply chain they occur.\n\nThe E P&L analysis provides a metric to measure and monitor the footprint of the company's operations and suppliers all the way to the initial raw materials. It is a tool to build awareness of the importance of nature to the sustainability of businesses; enhance visibility across a company's supply chain and deepen understanding to focus sustainability efforts and implement better-informed operational decisions; improve specificity for risk management regarding environmental dependencies and impacts; and support a more holistic view of a company's performance, while bringing clarity and transparency to stakeholders at all levels and identifying new opportunities to enhance the sustainability of a company's products.\n\nConceived by PUMA Chairman, Jochen Zeitz, and launched by Sportlifestyle company PUMA and its parent company's sustainability initiative (PPR HOME), the first-ever E P&L was conducted on 2010 data and released in two phases. In May 2011 the valuation of PUMA's 2010 Greenhouse Gas Emissions (GHG) and water usage was announced, followed in November 2011, by PUMA's overall E P&L, which also included valuation results for other forms of air pollution, land conversion and waste.\n\nSimultaneously, the PPR Group announced in November 2011 that a Group E P&L would be implemented across its Luxury and Sport & Lifestyle brands by 2015.\n\nThe E P&L and the associated methodology were developed with the support of PricewaterhouseCoopers LLP and Trucost PLC. The E P&L used existing input-output models and developed new valuation methodologies, building on a large volume of work in the fields of environmental and natural resource economics such as TEEB, the UN study on The Economics of Ecosystems and Biodiversity. \n\nKering, the parent company for Puma, has released its Environmental Profit and Loss Accounting methodology in an open source mode. Novo Nordisk is another company that has released its environmental profit and loss account and methodology report. The 2017 annual report of Philips mentioned that the company had an environmental impact of Euro 7.2 billion for that year. This assessment was made through an Environmental Profit and Loss Accounting process. The company mentioned that this monetary value has not considered various practices that has environmental impacts.\n\nThe UK government used the PUMA E P&L as a case study for sustainable business in the Department for Environment, Food and Rural Affair (DEFRA) Natural Environment White Paper in June 2011. In July 2011, Pavan Sukhdev who was the Study Leader of TEEB and the Special Advisor and Head of UNEP's Green Economy Initiative, referred to the PUMA E P&L in his TED presentation.\nSustainability authority, John Elkington includes the PUMA E P&L in his \"The Future Quotient: 50 Stars in Seriously Long-Term Innovation\". In the October issue of \"The Harvard Business Review\" the PUMA E P&L is included in \"The Sustainable Economy\" by Yvon Chouinard, Jib Ellison, and Rick Ridgeway.\nIn the Winter 2012 issue, the \"Stanford Social Innovation Review\" published \"Connecting Heart to Head\" by Ram Nidumolu, Kevin Kramer, & Jochen Zeitz. The PUMA E P&L is included as a business case study. In December 2011, Jochen Zeitz spoke at His Royal Highness The Prince of Wales' Accounting For Sustainability Forum about the PUMA E P &L.\n\nPuma's EP&L accounting process has influenced other companies attempting natural capital accounting . A smartphone app has been made available, free of cost, to help students of design and fashion, to understand the environmental impacts.\n\nAn assessment report indicated that preparing an EP&L report can be expensive, while benefits being derived from the process is substantial. EP&L Accounting has also been considered as a first step in the process of ensuring that prices reflect the use of environmental goods and services.\n\n"}
{"id": "31075117", "url": "https://en.wikipedia.org/wiki?curid=31075117", "title": "Ethnic Business Awards", "text": "Ethnic Business Awards\n\nEthnic Business Awards is a business award held in Australia to recognize the achievement of migrant business owners. Held annually since 1988, they are Australia’s longest running business award on television. \n\nFounded in 1988 by Joseph Assaf AM, a Lebanese born Australian who specializes in multicultural marketing and businesses, the awards' goal was to \"recognise and reward the contributions of migrants to the Australian economy\". The Awards have drawn significant attention.\n\nIn 2010, a new category, Indigenous in Business was created, offering recognition for \"the descendants of those first Australians – the traditional owners of the land\".\n\n"}
{"id": "447502", "url": "https://en.wikipedia.org/wiki?curid=447502", "title": "Financial district", "text": "Financial district\n\nA financial district is the central area in some large cities where banks, insurance companies and other large corporations have head offices. Financial districts are often home to skyscrapers.\n\nNotable financial districts of the world include:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "2544706", "url": "https://en.wikipedia.org/wiki?curid=2544706", "title": "Fortune European Businessman of the Year", "text": "Fortune European Businessman of the Year\n\nFortune magazine gives an annual award for the person it considers to be the European Businessman of the Year. Fortune is based in the United States, but it has a European edition which features this award prominently. Currently the award is announced in January for the preceding calendar year. Other organisations also issue similar awards.\n"}
{"id": "39934465", "url": "https://en.wikipedia.org/wiki?curid=39934465", "title": "Funnel analysis", "text": "Funnel analysis\n\nFunnel analysis involves using a series of events that lead towards a defined goal, like from user engagement in a mobile app to a sale in an eCommerce platform or advertisement to purchase in online advertising. The funnel analyses \"are an effective way to calculate conversion rates on specific user behaviors\".\nThis can be in the form of a sale, registration, or other intended action from an audience. The origin of the term funnel analysis comes from the nature of a funnel where individuals will enter the funnel, yet only a small number of them will perform the intended goals.\n\nFor more emphasis, it makes sense why a funnel in analytics is called a funnel. An actual funnel, like the ones from a kitchen or garage, gets narrower along its length, allowing less volume to pass through it. An analytics funnel represents a very similar idea, just in regards to users on an eCommerce platform, application or online game.\n\nAn example of how a company would use funnel analytics is by focusing on drawing actionable insights from funnels. Funnel analysis can be used to determine conversion and user fallout rates in a given funnel. An analysis to determine the steps that lead to a desired goal in order to improve future interactions in the same funnel can be done for further success. To illustrate further, looking at how many users actually make it to the end of the funnel, for example to make a purchase or register, compared with how many do not.\n\nBy continuously monitoring and analyzing funnels, it is possible to assess if changes to an application or platform are having a positive effect on conversion. For instance, one might find that only 10% of users who come to a platform and enter the registration funnel actually reach the goal of completing registration. Using the funnel analytics process, it is then possible to tweak settings or features within the funnel in order to see what makes that number improve. Or when creating a marketing campaign, there is a chance to analyze how well the campaign is working by monitoring a funnel that brings users from the initial event all the way to purchasing a product.\n\nFunnel analysis helps determine the point in which users are dropping off. The next step is to understand why they’re dropping off, in order to reduce drop off rates and in turn increase overall conversion.\n\n\n\n"}
{"id": "14850094", "url": "https://en.wikipedia.org/wiki?curid=14850094", "title": "Goal", "text": "Goal\n\nA goal is an idea of the future or desired result that a person or a group of people envisions, plans and commits to achieve. People endeavor to reach goals within a finite time by setting deadlines.\n\nA goal is roughly similar to a purpose or aim, the anticipated result which guides reaction, or an end, which is an object, either a physical object or an abstract object, that has intrinsic value.\n\nGoal-setting theory was formulated based on empirical research and has been called one of the most important theories in organizational psychology. Edwin A. Locke and Gary P. Latham, the fathers of goal-setting theory, provided a comprehensive review of the core findings of the theory in 2002. In summary, Locke and Latham found that specific, difficult goals lead to higher performance than either easy goals or instructions to \"do your best\", as long as feedback about progress is provided, the person is committed to the goal, and the person has the ability and knowledge to perform the task.\n\nAccording to Locke and Latham, goals affect performance in the following ways:\n\nA positive relationship between goals and performance depends on several factors. First, the goal must be considered important and the individual must be committed. Participative goal setting can help increase performance, but participation itself does not directly improve performance. Self-efficacy also enhances goal commitment. For goals to be effective, people need feedback that details their progress in relation to their goal.\n\nSome coaches recommend establishing specific, measurable, achievable, relevant, and time-bounded (SMART) objectives, but not all researchers agree that these SMART criteria are necessary. The SMART framework does not include goal difficulty as a criterion; in the goal-setting theory of Locke and Latham, it is recommended to choose goals within the 90th percentile of difficulty, based on the average prior performance of those that have performed the task.\n\nGoals can be long-term, intermediate, or short-term. The primary difference is the time required to achieve them.\n\nShort-term goals expect accomplishment in a short period of time, such as trying to get a bill paid in the next few days. The definition of a short-term goal need not relate to any specific length of time. In other words, one may achieve (or fail to achieve) a short-term goal in a day, week, month, year, etc. The time-frame for a short-term goal relates to its context in the overall time line that it is being applied to. For instance, one could measure a short-term goal for a month-long project in days; whereas one might measure a short-term goal for someone's lifetime in months or in years. Planners usually define short-term goals in relation to long-term goals.\n\nIndividuals can set personal goals. A student may set a goal of a high mark in an exam. An athlete might run five miles a day. A traveler might try to reach a destination-city within three hours. Financial goals are a common example, to save for retirement or to save for a purchase.\n\nManaging goals can give returns in all areas of personal life. Knowing precisely what one wants to achieve makes clear what to concentrate and improve on, and often subconsciously prioritizes that goal. However, successful goal adjustment (goal disengagement and goal re-engagement capacities) is also a part of leading a healthy life.\n\nGoal setting and planning (\"goal work\") promotes long-term vision, intermediate mission and short-term motivation. It focuses intention, desire, acquisition of knowledge, and helps to organize resources.\n\nEfficient goal work includes recognizing and resolving all guilt, inner conflict or limiting belief that might cause one to sabotage one's efforts. By setting clearly defined goals, one can subsequently measure and take pride in the accomplishment of those goals. One can see progress in what might have seemed a long, perhaps difficult, grind.\n\nAchieving complex and difficult goals requires focus, long-term diligence and effort (see Goal pursuit). Success in any field requires forgoing excuses and justifications for poor performance or lack of adequate planning; in short, success requires emotional maturity. The measure of belief that people have in their ability to achieve a personal goal also affects that achievement.\n\nLong-term achievements rely on short-term achievements. Emotional control over the small moments of the single day makes a big difference in the long term.\n\nThere has been a lot of research conducted looking at the link between achieving desired goals, changes to self-efficacy and integrity and ultimately changes to subjective well-being. Goal efficacy refers to how likely an individual is to succeed in achieving their goal. Goal integrity refers to how consistent one's goals are with core aspects of the self. Research has shown that a focus on goal efficacy is associated with well-being factor happiness (subjective well-being) and goal integrity is associated with the well-being factor meaning (psychology). Multiple studies have shown the link between achieving long-term goals and changes in subjective well-being; most research shows that achieving goals that hold personal meaning to an individual increases feelings of subjective well-being.\n\nThe self-concordance model is a model that looks at the sequence of steps that occur from the commencement of a goal to attaining that goal. It looks at the likelihood and impact of goal achievement based on the type of goal and meaning of the goal to the individual. Different types of goals impact both goal achievement and the sense of subjective well-being brought about by achieving the goal. The model breaks down factors that promote, first, striving to achieve a goal, then achieving a goal, and then the factors that connect goal achievement to changes in subjective well-being.\n\nGoals that are pursued to fulfill intrinsic values or to support an individual's self-concept are called self-concordant goals. Self-concordant goals fulfill basic needs and align with what psychoanalyst Donald Winnicott called an individual's \"True Self\". Because these goals have personal meaning to an individual and reflect an individual's self-identity, self-concordant goals are more likely to receive sustained effort over time. In contrast, goals that do not reflect an individual's internal drive and are pursued due to external factors (e.g. social pressures) emerge from a non-integrated region of a person and are therefore more likely to be abandoned when obstacles occur.\n\nThose who attain self-concordant goals reap greater well-being benefits from their attainment. Attainment-to-well-being effects are mediated by need satisfaction, i.e., daily activity-based experiences of autonomy, competence, and relatedness that accumulate during the period of striving. The model is shown to provide a satisfactory fit to 3 longitudinal data sets and to be independent of the effects of self-efficacy, implementation intentions, avoidance framing, and life skills.\n\nFurthermore, self-determination theory and research surrounding this theory shows that if an individual effectively achieves a goal, but that goal is not self-endorsed or self-concordant, well-being levels do not change despite goal attainment.\n\nIn organizations, goal management consists of the process of recognizing or inferring goals of individual team-members, abandoning goals that are no longer relevant, identifying and resolving conflicts among goals, and prioritizing goals consistently for optimal team-collaboration and effective operations.\n\nFor any successful commercial system, it means deriving profits by making the best quality of goods or the best quality of services available to end-users (customers) at the best possible cost. Goal management includes:\n\nJens Rasmussen (human factors expert) and Morten Lind distinguish three fundamental categories of goals related to technological system management:\n\nOrganizational goal-management aims for individual employee goals and objectives to align with the vision and strategic goals of the entire organization. Goal-management provides organizations with a mechanism to effectively communicate corporate goals and strategic objectives to each person across the entire organization. The key consists of having it all emanate from a pivotal source and providing each person with a clear, consistent organizational-goal message so that every employee understands how their efforts contribute to an enterprise's success.\n\nAn example of goal types in business management:\n\nGoal displacement occurs when the original goals of an entity or organization are replaced over time by different goals. In some instances, this creates problems, because the new goals may exceed the capacity of the mechanisms put in place to meet the original goals. New goals adopted by an organization may also increasingly become focused on internal concerns, such as establishing and enforcing structures for reducing common employee disputes. In some cases, the original goals of the organization become displaced in part by repeating behaviors that become traditional within the organization. For example, a company that manufactures widgets may decide to do seek good publicity by putting on a fundraising drive for a popular charity, or having a tent at a local county fair. If the fundraising drive or county fair tent is successful, the company may choose to make this an annual tradition, and may eventually involve more and more employees and resources in the new goal of raising the most charitable funds, or having the best county fair tent. In some cases, goals are displaced because the initial problem is resolved or the initial goal becomes impossible to pursue. A famous example is the March of Dimes, which began as an organization to fund the fight against polio, but once that disease was effectively brought under control by the polio vaccine, transitioned to being an organization for combating birth defects.\n\n"}
{"id": "24309649", "url": "https://en.wikipedia.org/wiki?curid=24309649", "title": "Gōshi gaisha", "text": "Gōshi gaisha\n\nGo-shi Gaisha is a Japanese concept of an \"unlimited liability\" incorporation, but its structure is similar to the limited partnership. Unlike the other business types (Gōdō gaisha and Kabushiki gaisha) there is no limit on what a general partner (\"mugen sekinin shain\") of the company is legally responsible for.\n\nIn a Go-shi Gaisha, partners are divided into two categories: 1) a general partner who has unlimited liability similar to a partner in a general partnership and 2) a limited partner who has limited liability only up to the amount he has invested in the partnership (limited partner). All partners are still directly liable to creditors of the partnership, and thus partners can still be sued individually (direct liability).\n"}
{"id": "6688743", "url": "https://en.wikipedia.org/wiki?curid=6688743", "title": "HeadBlade", "text": "HeadBlade\n\nHeadBlade is a head shaving razor brand produced by The HeadBlade Company. Founded by Todd Greene, a 1989 graduate of Bowdoin College, HeadBlade is headquartered in Gardena, California.\n\nHeadBlade’s first commercial product was the HeadBlade Classic, introduced in 1999. The unorthodox design of the Classic was made as a response to the difficulties of head shaving with a regular razor.\n\nThe HeadBlade Classic went on to win the IDSA Silver Award for Design Excellence, as well as a spot in Time Magazine’s “Ten Best Designs of 2000.” In 2005, the Classic was also added to the Permanent Collection at the Museum of Modern Art.\n\nAs the company began to grow, HeadBlade expanded into a variety of hair care products, including HeadSlick, a specially designed shaving cream, HeadShed Scrub, an exfoliating solution and HeadLube, a scalp moisturizing lotion. Greene also continued improving on the design of his original product.\n\nIn 2006, seven years after first introducing the Classic, HeadBlade released the HeadBlade Sport. The Sport kept the same general shape and function as the classic, but added an improved rubber grip to the finger ring and upper pad. Inspired by sport car design, it also added hardened rubber wheels and an improved axel to increase the mobility of the razor. \n\nIn 2012, HeadBlade came out with the HeadBlade ATX. With a design inspired by an all terrain vehicle, the ATX changed the position of the blade to the back of the razor, encouraging action by “pulling” the blade along the head rather than “pushing” it. This was done in order to reduce the learning curve for people who were accustomed to regular razors.\n\nThe latest HeadBlade model is the HeadBlade MOTO, which was released in late 2016. The MOTO was awarded a Red Dot Design Award in 2017 for it’s industrial design and it’s ease of use. \n\n\"GQ\" magazine named Todd Greene to the 2010 Bald 100.\n\n"}
{"id": "2849675", "url": "https://en.wikipedia.org/wiki?curid=2849675", "title": "Japanese management culture", "text": "Japanese management culture\n\nJapanese management culture refers to working philosophies or methods in Japan. It included concepts and philosophies such as Just in Time, Kaizen and Total Quality Management.\nThe Japanese term \"hourensou\" (also rendered as “Ho-Ren-So”) refers to frequent reporting, touching base and discussing -- important attributes that are said to characterize collaboration and information flow within effective Japanese corporate culture. Hou’ stands for ‘Houkoku’, the Japanese word for ‘reporting’. ‘Ren’ comes from ‘Renraku’, the word for ‘informing’. ‘Sou’ is derived from ‘Soudan’, the word for ‘consulting’. refers to \"getting your hands dirty\", to identify or solve immediate problems and leaders are not exempt from this. Aspects of these principles are often mistaken by western managers \"micromanagement.\" In contrast, these principles are used as tools to shepherd processes.\n\nMohammed Ala and William Cordeiro (1999) described the Japanese decision-making process of “ringiseido.” “Ringiseido” provides the opportunity for equal ranking managers or employees of a group within a company to partake in an individual’s idea. The process adheres to the Japanese cultural desire of harmony among people. The physical action of “ringiseido” is referred to as the “ringi decision-making process.” It fosters an environment of support and agreement for a decision once a higher ranking manager has reviewed and accepted the recommended decision.\n\nThe term of “ringi” has two meanings. The first meaning being of “rin,\" ‘submitting a proposal to one’s supervisors and receiving their approval,’ and \"gi\" meaning ‘deliberations and decisions.’ Corporate policy is not clearly defined by the executive leadership of a Japanese company. Rather, the managers at all levels below executives must raise decisions to the next level except for routine decisions. The process of “ringi decision-making” is conducted through a document called a “ringisho.”\n\nThe “ringisho” is created and circulated by the individual who created the idea. As the “ringisho” reaches a peer for review, the peer places his or her “personal seal (hanko) right side up” to agree, “upside down” to disagree, and sideways to indicate being undecided. Once all peers have reviewed the “ringisho” the peers’ manager reviews the “ringisho” and places his or her hanko on it. The upper level manager’s decision is final and the “ringisho” is sent back to the originator who either initiates the idea or re-evaluates, based on the “hanko” of the upper level manager.\n\nTony Kippenberger (2002) elaborates on the leadership values that are deeply rooted in the Japanese business culture. These values were created by Konosuke Matsushita, the prominent deceased entrepreneur of Matsushita’s Electric Company, who cared deeply for the employees of his company as if they were family. Matsushita firmly believed that a business as large as his was responsible to help all of society prosper, and not simply for those that owned and ran the company to prosper. \n\nIn 1933 Matsushita, during the great depression, created seven “guiding principles\":\n\nThe “guiding principles” were “remarkable for their time.” The seven principles are used by Matsushita’s company today and serve as principles for other Japanese companies. Because the “guiding principles” are such powerful statements and an extension of the Japanese cultural into business, the principles have been renamed the “Seven Spirits of Matsushita\" to honor Matsushita.\n\nIn smaller companies, an entirely different corporate culture developed. Similar to the \"Meister\" system of Germany, new recruits are placed under skilled senior specialists and spend years learning every technique that they have. They are trained to develop deeper understanding of specific areas of skills instead of the broader and less deep training that those in a larger corporation receive. They learn to produce work of high quality using few simple tools and few or no advanced industrial tools.\n\nAs the modern cultures of the world continue to advance, cultural concepts either lose presence or evolve with the modern concepts. Japan is experiencing such an evolution in regard to women in the workplace and in management roles. While a main reason for this evolution is the adoption of western influence on Japanese society, Japan is being forced to support this evolution because it is grappling with a declining population and lower birth rate which will lead to a smaller workforce. \n\nAccording to “Cloud, or Silver Linings?” published in the \"Economist\" (2007), it was reported that in 2006 Japan’s birth rate was 1.32 and has been below 2.1 since the 1970s. A birthrate of 2.1 is necessary to successfully maintain current population numbers. The article described that the OECD has proven there is a “positive correlation between fertility and female employment.” Thus, if an effort is made to support females work ambitions and family desires, then women will be more willing and likely to want to have children and families and not have to sacrifice their career in the process. Japanese officials are not taking this information lightly. During his last year in office, Prime Minister Junichiro Koizumi (2002-2007) began legislation to foster “financial support for families with young children and an expansion of child-care facilities (p.27).\n\n\n\n"}
{"id": "6731231", "url": "https://en.wikipedia.org/wiki?curid=6731231", "title": "Lex mercatoria", "text": "Lex mercatoria\n\nLex mercatoria (from the Latin for \"merchant law\"), often referred to as \"the Law Merchant\" in English, is the body of commercial law used by merchants throughout Europe during the medieval period. It evolved similar to English common law as a system of custom and best practice, which was enforced through a system of merchant courts along the main trade routes. It functioned as the international law of commerce. It emphasised contractual freedom and alienability of property, while shunning legal technicalities and deciding cases \"ex aequo et bono\". A distinct feature was the reliance by merchants on a legal system developed and administered by them. States or local authorities seldom interfered, and did not interfere a lot in internal domestic trade. Under \"lex mercatoria\" trade flourished and states took in large amounts of taxation.\n\nIn the last years new theories had changed the understanding of this medieval treatise considering it as proposal for legal reform or a document used for instructional purposes. These theories consider that the treatise cannot be described as a body of laws applicable in its time, but the desire of a legal scholar to improve and facilitate the litigation between merchants. The text is composed by 21 sections and an annex. The sections described procedural matters such as the presence of witnesses and the relation between this body of law and common law. It has been considered as a false statement to define this as a system exclusively based in custom, when there are structures and elements from the existent legal system, such as Ordinances and even concepts proper of the Romano-canonical procedure.\n\nThe \"lex mercatoria\" was originally a body of rules and principles laid down by merchants to regulate their dealings. It consisted of rules and customs common to merchants and traders in Europe, with some local variation. It originated from the need for quick and effective jurisdiction, administered by specialised courts. The guiding spirit of the merchant law was that it ought to derive from commercial practice, respond to the needs of the merchants, and be comprehensible and acceptable to the merchants who submitted to it. International commercial law today owes some of its fundamental principles to the \"lex mercatoria\". This includes choice of arbitration institutions, procedures, applicable law and arbitrators, and the goal to reflect customs, usage and good practice among the parties.\n\nGoods and services flowed freely during the medieval merchant law, thus generating more wealth for all involved. It is debated whether the law was uniform in nature, was spontaneous as a method of dispute resolution, or applied equally to everyone who subordinated to it. The \"lex mercatoria\" was also a means for local communities to protect their own markets. Local kings or lords extracted taxes and set trade restrictions. In 1303 Edward I issued the Carta Mercatoria, a charter to foreign merchants in England, which guaranteed them freedom to trade, with certain protections and exemption under the law. Although the charter was revoked by Edward II, due to complaints by English merchants, foreign merchants retained most of their rights in practice, but these would vary widely with the march of time, events and changes to state policy.\n\nThe \"lex mercatoria\" was the product of customs and practices among traders, and could be enforced through the local courts. However, the merchants needed to solve their disputes rapidly, sometimes on the hour, with the least costs and by the most efficient means. Public courts did not provide this. A trial before the courts would delay their business, and that meant losing money. The \"lex mercatoria\" provided quick and effective justice. This was possible through informal proceedings, with liberal procedural rules. The \"lex mercatoria\" rendered proportionate judgements over the merchants’ disputes, in light of \"fair price\", good commerce, and equity.\n\nJudges were chosen according to their commercial background and practical knowledge. Their reputation rested upon their perceived expertise in merchant trade and their fair-mindedness. Gradually, a professional judiciary developed through the merchant judges. Their skills and reputation would however still rely upon practical knowledge of merchant practice. These characteristics serve as important measures in the appointment of international commercial arbitrators today.\n\nThe \"lex mercatoria\" owed its origin to the fact that the civil law was not sufficiently responsive to the growing demands of commerce, as well as to the fact that trade in pre-medieval times was practically in the hands of those who might be termed cosmopolitan merchants, who wanted a prompt and effective jurisdiction. It was administered for the most part in special courts, such as those of the guilds in Italy, or the fair courts of Germany and France, or as in England, in courts of the Staple or Piepowder.\n\nThe \"lex mercatoria\" was composed of such usages and customs as were common to merchants and traders in all parts of Europe, varied slightly in different localities by special peculiarities. Less procedural formality meant speedier dispensation of justice, particularly when it came to documentation and proof. Out of practical need, the medieval \"lex mercatoria\" originated the “writing obligatory”. By this, creditors could freely transfer the debts owed to them. The “writing obligatory” displaced the need for more complex forms of proof, as it was valid as a proof of debt, without further proof of; transfer of the debt; powers of attorney; or a formal bargain for sale. The \"lex mercatoria\" also strengthened the concept of party autonomy: whatever the rules of the \"lex mercatoria\" were, the parties were always free to choose whether to take a case to court, what evidence to submit and which law to apply.\n\nMerchant law declined as a cosmopolitan and international system of merchant justice towards the end of medieval times. This was to a large extent due to the adoption of national commercial law codes. It was also connected with an increasing modification of local customs to protect the interests of local merchants. The result of the replacement of \"lex mercatoria\" codes with national governed codes was the loss of autonomy of merchant tribunals to state courts. The main reason for this development was the protection of state interests.\n\nThe nationalisation of the \"lex mercatoria\" did not neglect the practises of merchants or their trans-border trade. Some institutions continued to function, and state judges also were appointed for their merchant expertise, just as modern commercial arbitrators. The laws of the merchants were not eradicated, but simply codified. National codes built on the principles laid down by trade commercial practise and to a large extent they embodied \"lex mercatoria\" substantial rules. This was for example the case in France. The Code Commercial was issued in 1807, where \"lex mercatoria\" rules were preserved to govern formation, performance and termination of contracts. In effect, the nation states reconstituted the \"lex mercatoria\" in their image.\n\nEnglish courts applied merchant customs only if they were \"certain\" in nature, \"consistent with law\" and \"in existence since time immemorial.\" English judges also required that merchant customs were proven before the court. But even as early as 1608, Chief Justice Edward Coke described \"lex mercatoria\" as \"a part of the common law,\" and William Blackstone would later concur. The tradition continued especially under Lord Mansfield, who is said to be the father of English commercial law. Precepts of the \"lex mercatoria\" were also kept alive through equity and the admiralty courts in maritime affairs. In the US, traditions of the \"lex mercatoria\" prevailed in the general principles and doctrines of commercial jurisprudence.\n\nThe history of the \"lex mercatoria\" in England is divided into three stages: the first prior to the time of Coke, when it was a special kind of law – as distinct from the common law – administered in special courts for a special class of the community (i.e. the mercantile); the second stage was one of transition, the \"lex mercatoria\" being administered in the common law courts, but as a body of customs, to be proved as a fact in each individual case of doubt; the third stage, which has continued to the present day, dates from the presidency over the king's bench of Lord Mansfield (q.v.), under whom it was moulded into the mercantile law of to-day. To the \"lex mercatoria\" modern English law owes the fundamental principles in the law of partnership, negotiable instruments and trade marks.\nSir John Holt (Chief Justice 1689 to 1710) and Lord Mansfield (Chief Justice, 1756 to 1788) were the leading proponents of incorporating the \"lex mercatoria\" into the common law. Holt did not complete the task, possibly out of his own conservatism (see \"Clerke v Martin\") and it was Lord Mansfield that became known as the 'founder of the commercial law of this country\" (Great Britain). Whilst sitting in Guildhall, Lord Mansfield created,\na body of substantive commercial law, logical, just, modern in character and at the same time in harmony with the principles of the common law. It was due to Lord Mansfield's genius that the harmonisation of commercial custom and the common law was carried out with an almost complete understanding of the requirements of the commercial community, and the fundamental principles of the old law and that that marriage of idea proved acceptable to both merchants and lawyers.\n\n\n\"Lex mercatoria\" precepts have been reaffirmed in new international mercantile law. National trade barriers are torn down in order to induce commerce. The new commercial law is grounded on commercial practice directed at market efficiency and privacy. Dispute resolution has also evolved, and functional methods like international commercial arbitration is now available. These developments have also attracted the interest of empirical sociology of law The principles of the medieval \"lex mercatoria\" – efficiency, party autonomy, and choice of arbitrator – are applied, and arbitrators often render judgements based on customs. The new merchant law encompasses a huge body of international commercial law.\n\nIn summary, nation states somewhat fragmented the medieval \"lex mercatoria\" but it is far from destroyed. Local interests triumphed in the medieval ages, just as national interests do today. A modern variant of the \"lex mercatoria\" is the evolving law and dispute resolution in cyberspace. Internet traders are the fastest growing body of merchants in history. Parties can solve domain-name disputes online expeditiously and quickly. In a virtual court documents are filed and examined online, arguments are made online and decisions are published online – seldom challenged before traditional courts of law. ICANN's UDRP (and its proposals for Rapid Suspension) and Nominet's DRS are examples of this. The medieval, the modern and cyberspace merchant laws face comparable issues of enforceability. They solve the problems somewhat differently, but the reaction of the market is the main incentive to comply with a ruling.\n\nFurther, \"lex mercatoria\" is sometimes used in international disputes between commercial entities. Most often those disputes are decided by arbitrators which sometimes are allowed (explicitly of implied) to apply \"lex mercatoria\" principles. Therefore, some legal practitioners assume that there is a whole set of legal principles named \"lex mercatoria\" in international or transnational commercial law. The most recent and constantly updated set of rules are the \"TransLex Principles\" collected and formulated by Klaus Peter Berger (University of Cologne) and his Center for Transnational Law.\n\nWhat remains of \"lex mercatoria\" precepts today is a qualified faith in self-regulation by merchants, and a reluctance to surrender the efficiencies of merchant practice to state confinement.\n\n\n\n"}
{"id": "25541790", "url": "https://en.wikipedia.org/wiki?curid=25541790", "title": "List of food cooperatives", "text": "List of food cooperatives\n\nThe following is a list of food cooperative grocery stores and buyers groups, current and defunct. Many of the second-wave food cooperatives formed in the 1960s and 1970s started as buying clubs.\n\nThis list is not exhaustive, and is limited to notable food cooperatives.\n\n\n\n\n\n\n"}
{"id": "13452317", "url": "https://en.wikipedia.org/wiki?curid=13452317", "title": "Madoka (business process automation)", "text": "Madoka (business process automation)\n\nMadoka is a software system for supporting the automation of business processes. Initially a stock management system it progressed into an e-commerce system and then into a system for supporting the dynamic processing of various ordering tasks that can be automated.\n\n"}
{"id": "45316622", "url": "https://en.wikipedia.org/wiki?curid=45316622", "title": "Matt Zemlin", "text": "Matt Zemlin\n\nMatthias \"Matt\" Zemlin (born December 11, 1980) is a German manager and sales expert, former film distributor, producer, director and actor.\n\nDuring the last years Matthias Zemlin was sales director at Mediflow where he was involved in the significant increase of Mediflow’s brand awareness and successfully managed the retail and medical supply sales in Germany and Austria.\n\nBefore, in 2012 and 2013, Zemlin was known as one of the key players in senior sales management within in the entertainment and games industry in Germany as well as in Mumbai, because of his distribution of several Bollywood Blockbusters. Notable director and producer credits included the European production Dirty Money (2013) and Bollywood productions such as \"Wanted (2009 film),\" \"Aakrosh (2010 film), Dabangg\" (2010) and Rockstar (2011) that have been released internationally Zemlin repeatedly appeared in German TV shows like Einsatz in Hamburg and had film roles in international productions such as Brain Dead (2007), \nThe Sky Has Fallen (2009), \"Henri 4\" (2010),\nKing of the Underground (2011) and Closer Than Love (2013).\n\n"}
{"id": "15758990", "url": "https://en.wikipedia.org/wiki?curid=15758990", "title": "Open door policy (business)", "text": "Open door policy (business)\n\nAn open door policy (as related to the business and corporate fields) is a communication policy in which a manager, CEO, MD, president or supervisor leaves their office door \"open\" in order to encourage openness and transparency with the employees of that company. As the term implies, employees are encouraged to stop by whenever they feel the need to meet and ask questions, discuss suggestions, and address problems or concerns with management. An open door policy is typically intended to foster an environment of collaboration, high performance, and mutual respect between upper management and employees. \n\nOpen door policies exist to encourage employees to offer suggestions and ideas, provide or solicit feedback, seek personal or professional counsel, or address concerns within the company. The policy establishes an environment of trust and mutual respect between the employer and employee. The practice is viewed as a morale booster by letting employees feel as if they are able to openly speak with their employer about issues face-to-face, rather than through e-mail or voicemail. In essence, an open door policy serves to empower employees, knowing that their voice is heard and issues are quickly addressed and resolved. Trust in the company tends to improve and grow, when employees understand that they are welcome to confide in senior management, when immediate supervisors are unavailable.\n\nWhile open door policies intend to encourage and instill a sense of transparency and openness, some employees hesitate to speak their mind or be honest, for fear of intimidation, criticism, and censure. Management personnel may tend to communicate the willingness to hear suggestions, while belittling the suggestions when unaccompanied by solutions. \n\nOpen door policies have also been seen as a way for companies to discourage the formation of labor unions. Formal, written policies may encourage openness, however, the response received in attempts to engage are often seen as threats to the authority or management style of the individual working in a supervisory or management capacity. The policy, in essence, allows employees to forgo meeting with their immediate supervisors, choosing rather to engage in communication with their senior managers to discuss their employment or personal issues. \n\nA process of open communication and transparency allows employees to bypass their supervisors to engage with senior management. This may inadvertently lead to tension and strife between employees and middle management. Supervisors may either see this as an implication that they are the primary issue of concern, or they may feel threatened, suspecting the employee of undermining him in an attempt to cause problems between him and senior management.\n\nIn other examples, commonly in college dorms, an open door policy means everyone's door must remain open. The idea remains the same, that having the door(s) open will make for a more comfortable and social school or work environment. \n\nGovernment officials at the local, state, and federal level often implement an open door policy for the purpose of meeting with constituents. In Salt Lake City, mayor Ralph Becker maintains an open door policy every Wednesday to meet with residents one-on-one to discuss issues, concerns, and suggestions involving the city. The Democratic Caucus of Orange County, New York has maintained an open door policy for over ten years, where all individuals, regardless of political affiliation are welcome to attend the meeting. In 2011, in an effort to introduce a more open and transparent government, Governor Andrew Cuomo of New York extended an open door policy to members of the public. A lottery was introduced that allowed for 300 New Yorkers to visit Gracie Mansion following the inaugural festivities. The following week, for the first time in the history of the State of New York, a lottery was held to open the State of the State Address to additional members of the public.\n\n"}
{"id": "14190268", "url": "https://en.wikipedia.org/wiki?curid=14190268", "title": "Operational system", "text": "Operational system\n\nAn operational system is a term used in data warehousing to refer to a system that is used to process the day-to-day transactions of an organization. These systems are designed in a manner that processing of day-to-day transactions is performed efficiently and the integrity of the transactional data is preserved.\nSometimes operational systems are referred to as operational databases, transaction processing systems, or online transaction processing systems (OLTP). However, the use of the last two terms as synonyms may be confusing, because operational systems can be batch processing systems as well.\n\nAny enterprise must necessarily maintain a lot of data about its operation. \n\n"}
{"id": "1377904", "url": "https://en.wikipedia.org/wiki?curid=1377904", "title": "PEST analysis", "text": "PEST analysis\n\nPEST analysis (political, economic, socio-cultural and technological) describes a framework of macro-environmental factors used in the environmental scanning component of strategic management. It is part of an external analysis when conducting a strategic analysis or doing market research, and gives an overview of the different macro-environmental factors to be taken into consideration. It is a strategic tool for understanding market growth or decline, business position, potential and direction for operations. \n\nVariants that build on the PEST framework include:\n\nThere is also STEER, which considers sociocultural, technological, economic, ecological, and regulatory factors, but does not specifically include political factors.\n\nThe basic PEST analysis includes four factors:\n\nExpanding the analysis to PESTLE or PESTEL adds:\n\n\nOther factors for the various offshoots include:\n\n\nMore factors discussed in the SPELIT Power Matrix include:\n\n\nThe model's factors will vary in importance to a given company based on its industry and the goods it produces. For example, consumer and B2B companies tend to be more affected by the social factors, while a global defense contractor would tend to be more affected by political factors. Additionally, factors that are more likely to change in the future or more relevant to a given company will carry greater importance. For example, a company which has borrowed heavily will need to focus more on the economic factors (especially interest rates).\n\nFurthermore, conglomerate companies who produce a wide range of products (such as Sony, Disney, or BP) may find it more useful to analyze one department of its company at a time with the PESTEL model, thus focusing on the specific factors relevant to that one department. A company may also wish to divide factors into geographical relevance, such as local, national, and global.\n\nThe PEST factors, combined with external micro-environmental factors and internal drivers, can be classified as opportunities and threats in a SWOT analysis. A graphical method for PEST analysis called \"PESTLEWeb\" was developed at Henley Business School in the UK; research showed that PESTLEWeb diagrams are considered by users to be more logical, rational, and convincing than traditional PEST analysis.\n\n\n"}
{"id": "2538775", "url": "https://en.wikipedia.org/wiki?curid=2538775", "title": "Predictive modelling", "text": "Predictive modelling\n\nPredictive modelling uses statistics to predict outcomes. Most often the event one wants to predict is in the future, but predictive modelling can be applied to any type of unknown event, regardless of when it occurred. For example, predictive models are often used to detect crimes and identify suspects, after the crime has taken place.\n\nIn many cases the model is chosen on the basis of detection theory to try to guess the probability of an outcome given a set amount of input data, for example given an email determining how likely that it is spam.\n\nModels can use one or more classifiers in trying to determine the probability of a set of data belonging to another set, say spam or 'ham'.\n\nDepending on definitional boundaries, predictive modelling is synonymous with, or largely overlapping with, the field of machine learning, as it is more commonly referred to in academic or research and development contexts. When deployed commercially, predictive modelling is often referred to as predictive analytics.\n\nPredictive modelling is often contrasted with causal modelling/analysis. In the former, one may be entirely satisfied to make use of indicators of, or proxies for, the outcome of interest. In the latter, one seeks to determine true cause-and-effect relationships. This distinction has given rise to a burgeoning literature in the fields of research methods and statistics and to the common statement that \"correlation is not the same as causation.\"\n\nNearly any regression model can be used for prediction purposes. Broadly speaking, there are two classes of predictive models: parametric and non-parametric. A third class, semi-parametric models, includes features of both. Parametric models make \"specific assumptions with regard to one or more of the population parameters that characterize the underlying distribution(s)\", while non-parametric regressions make fewer assumptions than their parametric counterparts.\n\nThe majority classifier takes non-anomalous data and incorporates it within its calculations. This ensures that the results produced by the predictive modelling system are as valid as possible.\n\nOrdinary least squares is a method that minimizes the sum of squared distances between observed and predicted values.\n\nThe generalized linear model (GLM) is a flexible family of models that are unified under a single method. Logistic regression is a notable special case of GLM. Other types of GLM include Poisson regression, gamma regression, and multinomial regression.\n\nLogistic regression is a technique in which unknown values of a discrete variable are predicted based on known values of one or more continuous and/or discrete variables. Logistic regression differs from ordinary least squares (OLS) regression in that the dependent variable is binary in nature. This procedure has many applications. In biostatistics, the researcher may be interested in trying to model the probability of a patient being diagnosed with a certain type of cancer based on knowing, say, the incidence of that cancer in his or her family. In business, the marketer may be interested in modelling the probability of an individual purchasing a product based on the price of that product. Both of these are examples of a simple, binary logistic regression model. The model is \"simple\" in that each has only one independent, or predictor, variable, and it is \"binary\" in that the dependent variable can take on only one of two values: cancer or no cancer, and purchase or does not purchase.\n\nGeneralized additive model is a smoothing method for multiple predictors that allows for non-parametric predictions.\n\nRobust regression includes a number of modelling approaches to handle high leverage observations or violation of assumptions. Models can be both parametric (e.g. regression with Huber, White, Sandwich variance estimators) and non-parametric(e.g. quantile regression).\n\nSemiparametric regression includes the proportional odds model and the Cox proportional hazards model where the response is a rank.\n\nPredictive models can either be used directly to estimate a response (output) given a defined set of characteristics (input), or indirectly to drive the choice of decision rules.\n\nDepending on the methodology employed for the prediction, it is often possible to derive a formula that may be used in a spreadsheet software. This has some advantages for end users or decision makers, the main one being familiarity with the software itself, hence a lower barrier to adoption.\nNomograms are useful graphical representation of a predictive model. As in spreadsheet software, their use depends on the methodology chosen. The advantage of nomograms is the immediacy of computing predictions without the aid of a computer.\n\nPoint estimates tables are one of the simplest form to represent a predictive tool. Here combination of characteristics of interests can either be represented via a table or a graph and the associated prediction read off the y-axis or the table itself.\nTree-based methods (e.g. CART, survival trees) provide one of the most graphically intuitive ways to present predictions. However, their usage is limited to those methods that use this type of modelling approach which can have several drawbacks. Trees can also be employed to represent decision rules graphically.\n\nScore charts are graphical tabular or graphical tools to represent either predictions or decision rules.\n\nA new class of modern tools are represented by web-based applications. For example, Shiny is a web-based tool developed by Rstudio, an R IDE. With a Shiny app, a modeller has the advantage to represent any which way he or she chooses to represent the predictive model while allowing the user some control. A user can choose a combination of characteristics of interest via sliders or input boxes and results can be generated, from graphs to confidence intervals to tables and various statistics of interests. However, these tools often require a server installation of Rstudio.\n\nUplift modelling is a technique for modelling the \"change in probability\" caused by an action. Typically this is a marketing action such as an offer to buy a product, to use a product more or to re-sign a contract. For example, in a\nretention campaign you wish to predict the change in probability that a customer will remain a customer if they are contacted. A model of the change in probability allows the retention campaign to be targeted at those customers on whom the change in probability will be beneficial. This allows the retention programme to avoid triggering unnecessary churn or customer attrition without wasting money contacting people who would act anyway.\n\nPredictive modelling in archaeology gets its foundations from Gordon Willey's mid-fifties work in the Virú Valley of Peru. Complete, intensive surveys were performed then covariability between cultural remains and natural features such as slope, and vegetation were determined. Development of quantitative methods and a greater availability of applicable data led to growth of the discipline in the 1960s and by the late 1980s, substantial progress had been made by major land managers worldwide.\n\nGenerally, predictive modelling in archaeology is establishing statistically valid causal or covariable relationships between natural proxies such as soil types, elevation, slope, vegetation, proximity to water, geology, geomorphology, etc., and the presence of archaeological features. Through analysis of these quantifiable attributes from land that has undergone archaeological survey, sometimes the \"archaeological sensitivity\" of unsurveyed areas can be anticipated based on the natural proxies in those areas. Large land managers in the United States, such as the Bureau of Land Management (BLM), the Department of Defense (DOD), and numerous highway and parks agencies, have successfully employed this strategy. By using predictive modelling in their cultural resource management plans, they are capable of making more informed decisions when planning for activities that have the potential to require ground disturbance and subsequently affect archaeological sites.\n\nPredictive modelling is used extensively in analytical customer relationship management and data mining to produce customer-level models that describe the likelihood that a customer will take a particular action. The actions are usually sales, marketing and customer retention related.\n\nFor example, a large consumer organization such as a mobile telecommunications operator will have a set of predictive models for product cross-sell, product deep-sell (or upselling) and churn. It is also now more common for such an organization to have a model of savability using an uplift model. This predicts the likelihood that a customer can be saved at the end of a contract period (the change in churn probability) as opposed to the standard churn prediction model.\n\nPredictive modelling is utilised in vehicle insurance to assign risk of incidents to policy holders from information obtained from policy holders. This is extensively employed in usage-based insurance solutions where predictive models utilise telemetry-based data to build a model of predictive risk for claim likelihood. Black-box auto insurance predictive models utilise GPS or accelerometer sensor input only. Some models include a wide range of predictive input beyond basic telemetry including advanced driving behaviour, independent crash records, road history, and user profiles to provide improved risk models.\n\nIn 2009 Parkland Health & Hospital System began analyzing electronic medical records in order to use predictive modeling to help identify patients at high risk of readmission. Initially the hospital focused on patients with congestive heart failure, but the program has expanded to include patients with diabetes, acute myocardial infarction, and pneumonia.\n\nIn 2018, Banerjee et. al. proposed a deep learning model - Probabilistic Prognostic Estimates of Survival in Metastatic Cancer Patients (PPES-Met) for estimating short-term life expectancy (>3 months) of the patients by analyzing free-text clinical notes in the electronic medical record, while maintaining the temporal visit sequence.The model was trained on a large dataset (10,293 patients) and validated on a separated dataset (1818 patients). It achieved an area under the ROC curve (AUC) of 0.89. To provide explain-ability, they developed an interactive graphical tool that may improve physician understanding of the basis for the model’s predictions. The high accuracy and explain-ability of the PPES-Met model may enable the model to be used as a decision support tool to personalize metastatic cancer treatment and provide valuable assistance to the physicians.\n\nPredictive modeling in trading is a modeling process wherein we predict the probability of an outcome using a set of predictor variables. Predictive models can be built for different assets like stocks, futures, currencies, commodities etc. Predictive modeling is still extensively used by trading firms to devise strategies and trade. It utilizes mathematically advanced software to evaluate indicators on price, volume, open interest and other historical data, to discover repeatable patterns.\n\nAlthough not widely discussed by the mainstream predictive modeling community, predictive modeling is a methodology that has been widely used in the financial industry in the past and some of the major failures contributed to the financial crisis of 2008. These failures exemplify the danger of relying exclusively on models that are essentially backward looking in nature. The following examples are by no mean a complete list:\n\n1) Bond rating. S&P, Moody's and Fitch quantify the probability of default of bonds with discrete variables called rating. The rating can take on discrete values from AAA down to D. The rating is a predictor of the risk of default based on a variety of variables associated with the borrower and historical macroeconomic data. The rating agencies failed with their ratings on the US$600 billion mortgage backed Collateralized Debt Obligation (CDO) market. Almost the entire AAA sector (and the super-AAA sector, a new rating the rating agencies provided to represent super safe investment) of the CDO market defaulted or severely downgraded during 2008, many of which obtained their ratings less than just a year previously.\n\n2) So far, no statistical models that attempt to predict equity market prices based on historical data are considered to consistently make correct predictions over the long term. One particularly memorable failure is that of Long Term Capital Management, a fund that hired highly qualified analysts, including a Nobel Memorial Prize in Economic Sciences winner, to develop a sophisticated statistical model that predicted the price spreads between different securities. The models produced impressive profits until a major debacle that caused the then Federal Reserve chairman Alan Greenspan to step in to broker a rescue plan by the Wall Street broker dealers in order to prevent a meltdown of the bond market.\n\n1) History cannot always accurately predict the future: Using relations derived from historical data to predict the future implicitly assumes there are certain lasting conditions or constants in a complex system. This almost always leads to some imprecision when the system involves people.\n\n2) The issue of unknown unknowns: In all data collection, the collector first defines the set of variables for which data is collected. However, no matter how extensive the collector considers his/her selection of the variables, there is always the possibility of new variables that have not been considered or even defined, yet are critical to the outcome.\n\n3) Self-defeat of an algorithm: After an algorithm becomes an accepted standard of measurement, it can be taken advantage of by people who understand the algorithm and have the incentive to fool or manipulate the outcome. This is what happened to the CDO rating described above. The CDO dealers actively fulfilled the rating agencies' input to reach an AAA or super-AAA on the CDO they were issuing, by cleverly manipulating variables that were \"unknown\" to the rating agencies' \"sophisticated\" models.\n\n"}
{"id": "36721370", "url": "https://en.wikipedia.org/wiki?curid=36721370", "title": "Product defect", "text": "Product defect\n\nA product defect is any characteristic of a product which hinders its usability for the purpose for which it was designed and manufactured. \n\nProduct defects arise most prominently in legal contexts, where the term is applied to \"anything that renders the product not reasonably safe\". The field of law that addresses injuries caused by defective products is called products liability.\n\nA wide range of circumstances can render a product defective. The product may have a design defect, resulting from the product having been poorly designed or tested, so that the design itself yields a product that can not perform its desired function. Even if the design is correct, the product may have a manufacturing defect if it was incorrectly manufactured, for example if the wrong materials are used. A product may also be considered legally defective if it lacks appropriate instructions for its use, or appropriate warnings of dangers accompanying normal use or misuse of the product.\n\nA product that is defective in some way that does not render it dangerous might still be sold, with a discounted price reflecting the defect. For example, where a clothing manufacturer discovers that a line of shirts have been made with slightly uneven sleeves, the manufacturer may choose to sell these shirts at a discount, often through at outlet store and with the label cut off to indicate that the quality is not intended to reflect on the brand.\n"}
{"id": "51783746", "url": "https://en.wikipedia.org/wiki?curid=51783746", "title": "Recruitee", "text": "Recruitee\n\nRecruitee is Software as a service (Saas) that functions as an applicant tracking system (ATS). It includes a careers site editor for employer branding, a plugin for sourcing (personnel), job board integration, email and calendar synchronization. Within 4 months after its public launch in August 2015, Recruitee attracted over 1000 small and medium-sized enterprises (SMEs) and recruiting agencies worldwide.\n\nIn 2011, Perry Oostdam met Pawel Smoczyk on Founder2be, a social network that helps aspiring entrepreneurs find their co-founder. Working remotely from the Netherlands and Poland, they put together their first product - a mobile activation game called GeoRun.\n\nIn 2014, Oostdam and Smoczyk pivoted the business and built Recruitee out of their own frustration with the hassles of hiring. They believe hiring should be a team effort, not only for founders and HR alone.\n\nAfter its launch, Recruitee quickly became popular and got an undisclosed amount of seed funding in September 1, 2015. Its board members include Dutch entrepreneurs Robert Pijselman and Luc Brandts.\n\nIn November 2015, Recruitee announced a partnership with Rockstart, an accelerator in Amsterdam. Recruitee set up a Talent Pool that let applicants apply to job openings from all startups that are and were affiliated with Rockstart.\n\nRecruitee's current clients include Vice (magazine), Usabilla, and Vlisco.\n\nUsers can customize the hiring pipeline for each job opening. Users can drag and drop candidates' profiles to different stages as they move along the hiring process. Users can post job openings to free and paid job boards from Recruitee.\n\nUsers can bulk upload résumés, synchronize emails and calendars to Recruitee and Users can send bulk emails to candidates.\n\nUsers can import potential candidates from websites by using Recruitee's sourcing extension for Google Chrome and Firefox.\n\nUsers can make careers sites to showcase their employer branding like company, team, and culture.\n\n"}
{"id": "26002528", "url": "https://en.wikipedia.org/wiki?curid=26002528", "title": "Rules of the garage", "text": "Rules of the garage\n\nThe rules of the garage are a set of eleven rules that attempt to encapsulate the work ethos that Bill Hewlett and David Packard when they founded Hewlett-Packard. Since Hewlett-Packard was one of the earliest success stories of the information technology sector, it also used to more broadly describe the work ethos of Silicon Valley.\n\nThe Rules were first articulated in 1999 by then HP CEO Carly Fiorina - during her tenure as then HP CEO - and they were later used in a Hewlett-Packard ad campaign. The name was a reference to David Packard's garage in Palo Alto, in which Packard and Bill Hewlett first founded the company after graduating from nearby Stanford University in 1935.\n\nThe eleven rules are:\n\nSee also Wikipedia discussion of HP culture\n"}
{"id": "49181275", "url": "https://en.wikipedia.org/wiki?curid=49181275", "title": "SKS process", "text": "SKS process\n\nThe SKS process is a framework of Stop/Keep-doing/Start that is used to collect or categorize feedback.\n\nYou can ask customers or colleagues:\n\nThis approach is also used in agile development, where it is known as Start/Stop/Continue.\n"}
{"id": "21022706", "url": "https://en.wikipedia.org/wiki?curid=21022706", "title": "Stock market education", "text": "Stock market education\n\nTo become a professional securities broker in the United States, an individual must take and pass the General Securities Representative Exam (Series 7) and in most states, the Uniform Securities Agent State Law Examination (Series 63). To take the test, you must be sponsored by \"a member firm, a self-regulatory organization (SRO), or an exchange.\" This requirement, as well as the administration of the test, is under the jurisdiction of FINRA, the Financial Industry Regulatory Authority.\n\nFor individuals who are interested only in managing their own investments, several options exist to obtain a stock market education:\n\n\nMany colleges and universities offer courses of study in business, economics, and finance. However, the coursework is aimed at preparing the student for the professional world. They are not designed or intended to teach a student how to trade in the stock market, although the introductory/basic courses would provide a good basic foundation of knowledge. Those intending to follow the professional stockbroker career path usually begin their education by obtaining a degree in business, economics, or finance.\n\nSome of the core subjects covered by an undergraduate education during the course of a financial/business college education are:\n\nNon-traditional classroom settings are offered by:\n\n\nFor-profit financial education companies exist that offer programs of study (also referred to as \"systems\" or \"courses\" – the terminology varies) on stock market education. Unlike colleges that prepare students for working in the financial arena, these companies educate students with a more narrow focus – how to trade derivatives for the purpose of personal investing. Examples of such companies are thinkorswim (formerly Investools), Invested Central, Trading Advantage, Global Finance School, and Rich Dad's Education (based on the \"Rich Dad, Poor Dad\" book by Robert Kiyosaki). These types of companies offer both classroom settings for learning and distance education programs.\n\nAnother aspect that differentiates for-profit stock market education companies from traditional colleges is the commercialization factor. For-profit stock market education companies frequently develop other products – such as software and newsletters – that they market to their students. Colleges and universities, frequently founded for the purpose of providing education and established as non-profit organizations, do not follow this business model.\n\nAlso referred to as \"personal coaches,\" mentors work one-on-one with a student, In this situation, the student receives more personal attention from the instructor than from a classroom or distance learning education. Some mentors offer their services for a fee.\n\nThe following resources exist in libraries and on the Internet for an individual to learn about investing in the stock market:\n\n\nWhether an individual chooses a traditional or non-traditional education to learn how the stock market works, the following basic subjects are covered:\n\n\nMore advanced topics would include:\n\n"}
{"id": "10556434", "url": "https://en.wikipedia.org/wiki?curid=10556434", "title": "Tax assessment", "text": "Tax assessment\n\nTax assessment, or assessment, is the job of determining the value, and sometimes determining the use, of property, usually to calculate a property tax. This is usually done by an office called the assessor or tax assessor.\n\nIn local government in the United States, an assessor, also called a tax assessor, is an appointed or elected official charged with determining the value of each taxable property in a county, municipality, or township; this information is then used by the local governments to determine the necessary rates of taxation to support the community's annual public budgets. In Florida, this official is known as the property appraiser. In Vermont, this office is known as a lister.\n\n"}
{"id": "16773166", "url": "https://en.wikipedia.org/wiki?curid=16773166", "title": "Tulane Corporate Law Institute", "text": "Tulane Corporate Law Institute\n\nThe Tulane Corporate Law Institute is an annual two-day M&A and corporate law conference that takes place in downtown New Orleans every spring. It attracts the most high-profile lawyers and bankers from around the United States, as well as judges, journalists, and others who follow the dealmaking world. The event typically takes place on a Thursday and Friday in late March or early April, at a prominent Canal Street hotel. \n\nIn the late 1980s, Delaware Supreme Court Justice Andrew G.T. Moore (author of \"Smith v. Van Gorkom\" and \"Revlon v. MacAndrews\") and a group of New Orleans corporate practitioners were among those who undertook an aggressive goal: to establish a new annual platform for a gathering of the nation's\nleading corporate jurists and practitioners. More than 20 years later, the Tulane Corporate Law Institute remains a critical meeting place for national leaders in the fields of law and business. \n\nThe second day of the 22nd annual meeting (on April 16, 2010), coincided with the unexpected release of an SEC fraud complaint against Goldman Sachs. The release temporarily disrupted the day's meeting agenda as the story made national headlines and SEC officials were sought for comment in The Roosevelt Hotel. The news caused an immediate thirteen percent drop in Goldman's stock price, and a 1.3% decline in the market as a whole. \n\n\n\nThe Tulane Law School's Career Development Office typically organizes informational interviews among leading practitioners and select groups of Tulane law and JD/MBA students. In the past, students have met directly with a variety of business and governmental leaders, including partners of big New York City and Los Angeles law firms, in-house attorneys at major investment banks and hedge funds throughout the country, and the commissioner of the SEC.\n\n"}
{"id": "41772890", "url": "https://en.wikipedia.org/wiki?curid=41772890", "title": "Veritrade", "text": "Veritrade\n\nVeritrade is a privately owned commercial intelligence company founded in 1999, dedicated to providing information about International trade from multiple countries, in the form of digital publications.\n\nThrough the use of its database, Veritrade incorporates different products for varied sectors and industries in Peru and worldwide.\n\nVeritrade has developed several products that allow reading and analyzing data on foreign trade for each country, with different specifications catering to different types of industries, businesses and individual clients: Veritrade Business, Veritrade Analytic, Veritrade Motors and Verinews.\n\nThese products are based on the use of information technology and help clients to analize production, costs, etc.\n\nVeritrade collaborates with different online and printed media outlets providing foreign trade data and analysis. The most notable examples are articles in newspapers El Comercio, Perú21 and Gestión.\n\nIn May 2014, Veritrade provided foreign trade information relevant to an ongoing murder investigation, featured in a local news coverage.\n"}
{"id": "58971694", "url": "https://en.wikipedia.org/wiki?curid=58971694", "title": "Wells Print Shop", "text": "Wells Print Shop\n\nThe Wells Print Shop was located at 27 Cuna Street in St. Augustine, Florida. It operated as part of the Historic St. Augustine Preservation Board's 18th century museum village, San Agustín Antiguo, demonstrating the colonial printmaking process.<mapframe latitude=\"29.8949\" longitude=\"-81.3152\" zoom=\"15\" width=\"250\" height=\"200\" align=\"right\">\n</mapframe>\n\nWilliam Charles Wells was born in 1757 in Charleston, South Carolina, the son of a Tory printer, publisher, and bookseller. He was formally trained as a doctor, receiving a degree in medicine from the University of Edinburgh in 1780. When the British left Charleston in 1782, William and his brother John moved to St. Augustine where they established a print shop. In St. Augustine the Wells brothers are most well known for publishing the \"East Florida Gazette\", the first newspaper in Florida. After the 1783 Treaty of Paris returned Florida to the Spanish, William Wells went to England and practiced medicine for the rest of his life. He died in London in 1817.\n\nThe Wells brothers' publication began on February 1, 1783 and lasted a little over one year, with the last issue published on March 22, 1784. London's Public Record Office only contains three issues of the newspaper, those from March 1, May 3, and May 17, 1783. The St. Augustine Historical Society resurrected the name \"East Florida Gazette\" with its newsletter, which is indexed on the Historical Society Research Library's online catalog.\n\nThe Historic St. Augustine Preservation Board reconstructed the Wells Print Shop in 1968 on Cuna Street. The original Wells printing press owned by William and John was located on Treasury Lane. The all-wooden shop was constructed using board-and-batten building method, which the British settlers in St. Augustine preferred for its quick construction and ease of repair. The building is 220 square feet. \n\nInside the print shop was a replica of the type of printing press used towards the end of the 18th century. The press was operated daily to demonstrate the printing process to visitors, but the Preservation Board also used it to make reproductions of historic St. Augustine maps and replicas of the \"East Florida Gazette,\" which were sold as souvenirs. \n\nToday the site once occupied by the Wells Print Shop operates as a jewelry store.\n \n"}
{"id": "2683953", "url": "https://en.wikipedia.org/wiki?curid=2683953", "title": "Work card", "text": "Work card\n\nA work card is like an Identity Card which verifies that a person has been given work, or is eligible to perform work in a given profession or jurisdiction. The work card is not a work visa, although it may be used in conjunction with a work visa, permanent resident card or other documentation.\n\nWork cards are often used in countries with high unemployment to certify that the individual meets certain legal requirements (such as head of household, or with dependent children) making him or her eligible for work.\n\nWork cards are also used in certain industries like construction (where specialized training and safety skills are required) or gambling (where background and credit checks are required to reduce the incidence of crime).\n\nWork cards are used in some employment situations, such as prostitution, so that government officials may track the number of workers in a given industry. Frequent renewal of work cards may also be required to ensure that workers undergo regular health check-ups, or to gather information on working conditions or the incident of crime (such as assault against the prostitute, or a prostitute's criminal background).\n\nWork cards are increasingly used in the European Union (EU) to verify an individual's citizenship in a member-nation, and the kind of work which that individual may engage in. For example, citizens of states with provisional membership in the EU must obtain both an EU work card and a work card from nation in which they wish to work.\n\nIn cases where a union has won the closed shop, a work card may be issued by a trade union. The work card will permit the non-union worker to work in the industry or for the employer with union permission.\n\n\n"}
