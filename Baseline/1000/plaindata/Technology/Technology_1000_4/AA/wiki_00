{"id": "30891062", "url": "https://en.wikipedia.org/wiki?curid=30891062", "title": "Adaptxt", "text": "Adaptxt\n\nAdaptxt is a predictive text application for mobile phones, developed by KeyPoint Technologies, a UK-based software company. The application is designed to improve text entry on mobile devices by making it faster and error-free. It achieves this by predicting the next word as well as the word being typed, continuously adapting to the user's writing-style and vocabulary.\n\nLaunched in 2006, Adaptxt supported Windows Mobile smartphones only. Adaptxt provides features such as context-based next-word suggestions, word completion, personal dictionary, dynamic language detection, conversion from SMS language to standard English and vice versa, multilingual text entry and a feature that learns new words and context while typing.\n\nThe application stores the new words in the user’s personal dictionary, where they can be edited. KeyPoint also claims that Adaptxt users can type in any of the installed languages without changing their keyboard language or dictionary, thanks to an engine capable of recognizing the language in use. This feature is supposed to be an added value for users who are bi-lingual or occasionally type in a foreign language.\n\nA version for Symbian S60 smartphones was released in 2008, with improved support for third-party applications.\n\nIn April 2009, KeyPoint introduced a feature to scan personal data, including calendar entries, phonebook contacts, SMS and email inbox and sent items. The “Scan Facebook” feature learns words from the user’s Facebook profile. The new words learnt are added to the personal dictionary and offered as suggestions during text entry.\n\nLater that year, KeyPoint also launched a new version of Adaptxt with error correction. This feature provides alternative suggestions for incorrect spellings. Automated correction of spelling mistakes were also made available, with an option to revert to the exact word entered by the user in case of unwanted corrections. All these features can now be found in the Symbian version of the product and most of them can also be found in the Windows Mobile version.\n\nKeyPoint was also the first software company to introduce professional add-on dictionaries that provide industry-specific word and phrase suggestions related to a particular profession, such as medicine, law, IT and telecommunications, business and finance. Users can download additional language and professional dictionaries from the product website directly to their devices.\n\nIn May 2011, KeyPoint made Adaptxt open source through the project \"OpenAdaptxt\".\n\nAn Android-compatible version of the application has been launched in November 2011.\n\nAdaptxt supports both touch-screen and hard-keyboard devices with 12-key, 20-key or QWERTY layouts. On 12-key phones, Adaptxt offers both Multi-tap and Predictive entry modes.\n\nMore than 50 languages and respective keyboard layouts are supported by Adaptxt, including: English US, English UK, European French, Canadian French, German, Italian, European Spanish, Latin-American Spanish, European Portuguese, Brazilian Portuguese, Danish, Swedish, Finnish, Norwegian, Icelandic, Estonian, Latvian, Lithuanian, Polish, Czech, Slovak, Hungarian, Slovenian, Serbian, Croatian, Greek, Turkish, Bulgarian, Romanian, Russian, Belarusian, Ukrainian, Galician, Basque, Catalan, Filipino, Indonesian, Malay, Vietnamese, Hausa, Hinglish, Arabic, Persian, Urdu, Hebrew, Hindi, Marathi, Arabic, Tamil, Telugu, Malayalam, Scottish Gaelic, Manx Gaelic and Irish.\n"}
{"id": "21642043", "url": "https://en.wikipedia.org/wiki?curid=21642043", "title": "Audience (company)", "text": "Audience (company)\n\nAudience was an American mobile voice and audio-processing company based in Mountain View, California, and was one of the 34 founding members of The Open Handset Alliance. They specialized in improving voice clarity and noise suppression for a broad range of consumer products, including cellular phones, mobile devices and PCs. They were bought by Knowles for $85 Million in 3Q15 who changed their name to Knowles Intelligent Audio.\n\nAudience was the first company to have reverse-engineered the human hearing system and model its processes onto a chip, enabling computers and mobile devices to use the same kind of “auditory intelligence” that humans employ. By using this technology in conjunction with two or more microphones, background noise is suppressed, improving the quality of the remaining voice and reducing distraction for the listener. This technology mimics the “cocktail party effect”.\n\nIn 2010, Audience partnered with HTC to integrate their noise suppression technology into the Google Nexus One smartphone. The next year AT&T introduced eight different handsets powered by Audience's earSmart technology including the Samsung Galaxy S III Skyrocket and the HTC Vivid.\n\nIn 2013, Audience unveiled its eS515, a combination voice processor and audio codec. This single slot solution enables device manufacturers to streamline their designs, negating the need for a separate voice processor and codec.\n\nThe company’s core technology reduces background noise and improves voice clarity on smartphones, computers and tablets. The company’s technology has shipped in more than 140 devices including the Nexus One, Samsung Galaxy S, Galaxy S 4, Galaxy Note, the iPhone4 and 4S, and the LG G2. Audience also works with other mobile phone manufacturers such as Huawei, Google, HTC, Sharp, Pantech, ZTE and others. In 2010, the company announced a collaboration with AT&T to deliver its advanced voice capabilities to AT&T devices and is engaged with multiple operators around the world. Most recently the company announced its first design implementation in the PC space with the Dell Vostro 5460.\n\nThey had two lines of processors, Advanced Voice and Smart Sound, both branded as \"earSmart.\" Advanced Voice processors come in a variety of models, the eS110 (supports 1 microphone), eS305 and eS310 (supports 2 microphones) and the company’s latest generation eS325 (supports 3 microphones), which was announced at Mobile World Congress 2013.\n\nSmart Sound processors combined the Advanced Voice processor feature set (HD call quality, wideband noise suppression, bandwidth expansion, acoustic echo cancelation, and improved performance for Automatic Speech Recognition) with a stereo audio codec. The company introduced its Smart Sound processor category at Consumer Electronics Show 2013 with the launch of the eS515.\n\nThe company’s technology was built around the foundation of Computational Auditory Scene Analysis (CASA) -- a field of study that builds on the concept of Auditory Scene Analysis (ASA), a term first coined by psychologist Albert Bregman. ASA enables humans to accurately group sounds—even when composed of multiple frequencies, as in music, or when heard simultaneously –- and avoid blending \"sources.\" As a result, ASA allows the listener to correctly distinguish and identify a sound of interest, like a voice, from other noise sources.\n\nCASA attempts to recreate sound source separation in the same manner as human hearing, but in machines. Using the principles of CASA, Audience’s earSmart processors act like a human cochlea and group different sounds, based on a diverse list of cues such as pitch, onset/offset time, spatial location and harmonicity. These simultaneous sounds are evaluated and grouped by source. In doing this, the microphones of a mobile device, together with Audience's proprietary \"Fast Cochlea Transform\" technology, can identify and group sounds which are classified as noise, remove or at least reduce them, and leave the remaining clear voice signal intact.\n\nBeyond voice and video calls, this technology has been proven to improve the reliability and task completion rate of ASR (automatic speech recognition) in noisy environments as well as improve the quality and usability of media capture functions. Outside of the smartphone, tablet and mobile PC space, Audience is said to be targeting the Smart TV and Automotive markets where voice is becoming more commonplace as a form of user interface.\n\nAudience was the Silver Winner in the 2008 Wall Street Journal Technology Innovation Awards and the Winner of the Semiconductor category. The company was included in Gartner’s “Cool Vendors in Semiconductors, 2008” and selected as the Most Innovative True Mobile Start-Up for the “2008 GSMA Mobile Innovation Global Awards.”\n\n\n"}
{"id": "16039139", "url": "https://en.wikipedia.org/wiki?curid=16039139", "title": "Automatic-tracking satellite dish", "text": "Automatic-tracking satellite dish\n\nAutomatic Tracking Satellite Dishes are satellite dishes used while a vehicle is in motion. Automatic tracking satellite dishes utilize gyroscopes, GPS position sensors, and uses unique satellite identification data and an integrated DVB decoder to aid in identification of the satellite that it is pointing at.\n\nThe dishes consist usually of stepper motors to drive and aim the dish, gyroscopes to detect changes in position while the vehicle is in motion, a parabolic reflector, low-noise block converter, and control unit.\n\n"}
{"id": "10927936", "url": "https://en.wikipedia.org/wiki?curid=10927936", "title": "BioValley (Europe)", "text": "BioValley (Europe)\n\nBioValley is the leading life science cluster in Europe, founded 1996. It connects academia and companies of three nations in the Upper Rhine Valley, namely France, Germany and Switzerland. The main objective is the greater research cooperation between companies and academia involved in the life science sectors, including pharmacology, biotechnology, nanotechnology, medical technology, chemistry and agricultural biotechnology.\n\n\n\n"}
{"id": "27792533", "url": "https://en.wikipedia.org/wiki?curid=27792533", "title": "Bowler Communications System", "text": "Bowler Communications System\n\nThe Bowler Communications System is an open protocol developed by Neuron Robotics for simplified communications between components in cyber-physical systems.\n\n"}
{"id": "56345589", "url": "https://en.wikipedia.org/wiki?curid=56345589", "title": "Brigade Media", "text": "Brigade Media\n\nBrigade Media, also known as Brigade, is a civic technology platform that was formed on June 4, 2014, and founded by James Windon, Jason Putorti, John Thrall, Matt Mahan, and Miche Capone. The platform is intended to serve as a way for users to connect with others who share the same or similar views and voice their opinions, create debates, or organize petitions. This process is intended to make the users' concerns more visible to and influential towards United States' policymakers.\n\nJames Wendon is the President of the Brigade platform. He previously acted as the Vice President of Causes and earlier worked with the World Trade Organization in Switzerland. Matt Mahan is the CEO of Brigade and previously served as the CEO of Causes. John Thrall works in Engineering, Jason Putorti works in Design, and Miche Capone specializes in Production. Sean Parker is the Chairman of the startup. He sits on the board of Spotify and was the founding president of Facebook.\n\nOn June 4th, 2014, Brigade Beta became available to download on iOS or Google Play, in its private beta version. In this beginning stage, the app asked users to agree or disagree on a position. Brigade then split up its users into those who agreed on the issue and those who disagreed on the issue. Participants were also allowed to write their own opinions on positions and ask those in their respective group if they were \"for\" or \"against\" the opinion stated.\n\nA few weeks before the November 2016 elections, Brigade created a ballot guide for its users. It ran these voter guides in San Francisco and Manchester, New Hampshire. As the user entered the application, he or she was prompted with questions regarding government and social issues. One could agree, disagree, or click unsure as their answer choices. After completing the questionnaire, the guide gave recommendations on who to vote for and which propositions to pass or not pass. Furthermore, the app also determined these choices based on those a user socializes with on Brigade. Brigade users could then pledge their votes to the candidates and propositions listed on the ballot. With these pledges, the app could track which candidates had more pledged votes in real time. Users were further able to recruit pledges from other users for their favorite candidates or propositions.\n\nBrigade implemented a voter verification service as well. With voter verification, a user can determine how similar or different a political representative's viewpoints are from their own. This data was received from Google's Civic API with geographic information on 520,000 American elected officials.\n\nBrigade Media has acquired Causes,Votizen, and Voter. At the time of its acquisition, Causes was the largest online platform where candidates could campaign. At the time of its acquisition, Votizen functioned as a tool for voters to learn more about their leaders. At the time of its acquisition, Voter aimed to put voters and politicians together via shared viewpoints. These three companies helped Brigade gain social media presence and find intelligent workers in the field.\n\nAs technology has advanced, it was assumed that the average individual would have further access to voting, and therefore, voting numbers would increase. Instead, voter turnout at the elections remains low, with numbers at the presidential elections between 50% and 60% of the US population in the last 50 years. At the midterm election of 2014, only 36.4% of people voted, the lowest percentage since 1942. It is hoped that civic technology will incentivize and educate its users to vote. Brigade's voter ballot was an attempt as a civic technology platform to increase voter participation as well as educate its users about candidates and propositions.\n\nOne mission of Brigade Media is to act as a foreground for its users to connect and organize so that they can voice their opinions on our nation's issues. Another more general goal is to increase voter participation.\n\nBrigade interacts with American voters by linking its users to the same held concerns. The opinions of elected officials on those concerns will be provided and metrics about the candidate most similar in concerns and degree of concern will be available. This data should be useful for both candidates and voters, in that voters can voice their grievances and candidates must respond accordingly.\n\nIn 2014, Brigade Media received about $9.5 million in seed money from Sean Parker, Marc Benioff, and Ron Conway.\n\nBarbara Simons, a computer scientist from IBM, asserts that all current forms of digital voting devices are hackable, and that the best unhackable option is paper.\nFurthermore, a Canadian study revealed that online voting platforms may not improve voter participation. The study found that those who did not already vote on paper ballots did not vote with digital devices. Instead, non-paper voting forms are simply more convenient for those who would have already decided to vote. With this data brought to light, the Independent Panel On Internet Voting did not recommend internet voting to the Legislative Assembly of British Columbia in 2012.\n\nBrigade's Executive Chairman, Sean Parker, was the president of Facebook in mid-2004. Recently, Facebook sold information on over 50 million Facebook users to Cambridge Analytica. Sean Parker's previous relationship with Facebook could provide controversy in his work with Brigade Media and his other projects.\n\nAt the company's formation, Brigade Media also faced a racial controversy. When Brigade was only a few weeks old, the entire leadership division of the start-up was white males. The company addressed the issues by filling in 12 additional positions and noting that women were also present in the organization.\n\nWhen the ballot guide was introduced, about 67% of its users were millennials. This is an accomplishment because millennial participation in the 2014 midterm elections had declined. At the time of the ballot guide, the start-up had 100,000 pledged candidates and 400,000 friends of candidates also pledged. \n\nThe platforms data also saw Donald Trump winning swing states before the polls in the 2016 United States Presidential Election. At this time, Brigade had 200,000 verified users. Within the vote pledges, 94.5% of Republicans pledged to vote for Republican nominee Trump, with 2.2% pledging with Democratic nominee Hillary Clinton. However, on the Democratic pledge side, only 55% pledged for Clinton while 40% of Democrats pledged for Trump.\n"}
{"id": "36541240", "url": "https://en.wikipedia.org/wiki?curid=36541240", "title": "Ceramic mixing technology", "text": "Ceramic mixing technology\n\nCeramic mixing technology is used to mix and blend ceramics to create end products such as: ceramic powder blends, injection molding feedstock, electronics, decorative finishes, refractory linings, batteries and fuel cells, thermally conductive pastes, investment casting slurries, dental ceramics and advanced composites.\n\nA wide range of equipment is available for these requirements.\n\n"}
{"id": "4564673", "url": "https://en.wikipedia.org/wiki?curid=4564673", "title": "Colloid mill", "text": "Colloid mill\n\nA colloid mill is a machine that is used to reduce the particle size of a solid in suspension in a liquid, or to reduce the droplet size of a liquid suspended in another liquid. Colloid mills work on the rotor-stator principle: a rotor turns at high speeds (2000 - 18000 RPM). The resulting high levels of hydraulic shear applied to the process liquid disrupt structures in the fluid. Colloid mills are frequently used to increase the stability of suspensions and emulsions, but can also be used to reduce the particle size of solids in suspensions. Higher shear rates lead to smaller droplets, down to approximately 1 µm which are more resistant to emulsion separation.\n\nColloid mills are used in the following industries:\n\n"}
{"id": "18704670", "url": "https://en.wikipedia.org/wiki?curid=18704670", "title": "Comparison of domestic robots", "text": "Comparison of domestic robots\n\nDomestic robots can vary widely in their capabilities and tasks. Sensors include: cliff or stair sensors, motion sensors, ultrasonic object sensors, dirt sensors, IR sensors, and more. Intelligence varies also. Some have none while others can map out their environment and maneuver using complex algorithms.\n"}
{"id": "38823520", "url": "https://en.wikipedia.org/wiki?curid=38823520", "title": "Comparison of hub gears", "text": "Comparison of hub gears\n\nThis page is a list of internal hub gears for bicycles.\n\n"}
{"id": "27125801", "url": "https://en.wikipedia.org/wiki?curid=27125801", "title": "Comparison of train and tram tracks", "text": "Comparison of train and tram tracks\n\nA railway or railroad is a track where the vehicle travels over two parallel steel bars, called rails. The rails support and guide the wheels of the vehicles, which are traditionally either trains or trams. Modern light rail is a relatively new innovation which combines aspects of those two modes of transport. However fundamental differences in the track and wheel design are important, especially where trams or light railways and trains have to share a section of track, as sometimes happens in congested areas.\n\nBoth trams and trains have flanged iron wheels with a horizontal section transferring the vehicle weight to the rail and a vertical flange \"inboard\" to guide the vehicle along the rail using its inside edge.\n\nRail vehicle wheels are usually mounted on a solid axle, so they turn at the same speed. When a vehicle turns the outer wheel has to travel further than the inner wheel. On a road vehicle, this is usually achieved by allowing the wheels to move independently, and fixing the front wheels in an arrangement known as Ackermann steering geometry.\n\nTrains and trams can turn corners without wheel-slip because the outer horizontal part of the wheels has a slightly tapered rim. The guide flange (ridge) is on the inside to prevent the vehicle from slipping sideways off the rails. The horizontal (cone-shaped) rim makes contact with the slightly convex top of a steel rail in different (horizontal) places so that the outer wheel has a larger effective diameter than the inner wheel.\n\nWith both tram and train wheels, this happens naturally because the tires are cone shaped sloping surfaces: the inside diameter is a few millimeters larger than the outside. As the track starts to curve, the train tries to run straight. The wheel flange presses against the side of the curved rail so the \"contact point\" between rail and wheel moves a few millimeters outwards, making the effective diameter of the outer wheel temporarily larger, and equally opposite: the effective diameter of the inner wheel effectively becomes temporarily smaller. This technique works well on large-radius curves which are canted, but not as well on tight curves and railway switches (also known as \"points\"). This is because the geometry or cant of the track is more difficult to optimize for every possible combination of vehicle and direction of travel.\n\nCity trams often use tight curves - sometimes with a radius of much less than about , and canting may be impossible because the surface is shared with road vehicles or pedestrian zones or sidewalks, so the track often has to be flush with the road surface or pavement. In sharp curves, the rail grooves are sometimes made very shallow, which causes the outer wheel to temporarily ride up onto the edge of its flange. This increases the wheel diameter and the curve can be taken more easily. In extreme cases, the rail has a groove so that the rim of the flange can take most of the weight, the \"out-board\" tire (on the outer radius of the outer rail) acting as no more than a vertical plate. \n\nIn contrast, a train wheel is almost never designed to transfer weight through the flange rim, and some train wheels may be damaged if this should happen even once. \n\nThe point where two straight but intersecting railroads cross is called a frog. A groove through each rail allows the wheel flanges to pass through the intersecting rails. Without countermeasures each wheel would dip into the groove and strike the frog point gap causing unacceptable wear. The point where two tracks join and the vehicle can take one of two directions is called a railway switch. This works on the same principle, except that the inner rail is almost continuous and the outer rail has a gap for the flange to pass through.\n\nWith a train this problem is solved by using a wide tire. Train rails usually cross at a shallow angle. In the middle of the interchange there is a supporting frog. The tire is guided on each side by guide rails and some portion of the tire always maintains rail contact. This method is not feasible with trams and light railways.\n\nTram tires are generally narrower than train tires. Trams use bigger crossing angles and tighter curve radii are more likely than for train tracks. To cope with this difficulty the wheels of trams temporarily transfer the weight of the tram onto the flange to reduce wear on both the frog point and the horizontal surface of the tram wheels. Train wheels are not designed to bear such weight on their flanges.\n\nA tram wheel which runs on the flange rather than on the horizontal tyre has a larger effective diameter, so the distance travelled per revolution is greater. On the outside track of the curve this is an advantage. It may be necessary to compensate the inner wheel or allow for some slippage. Modern trams and trams tend to have thicker and wider tires which allow for a greater (horizontal) conical section and so greater effective diameter variation and turning ability.\n\nAt the junctions of train tracks, the gap in the frog or switch rail is wide. So trams can be accommodated.\n\nThe main problem with a train on tram rails is the relatively narrow width of frog and switch gaps and channels of the groove rails designed to accommodate the narrow flanges of tram wheels . The wider flanges of train wheels increase the risk of derailment at these points. On routes where train carriages are driven on tram tracks (as in the past in parts of The Hague), wider grooves are required as a compromise that is practical as wide grooved girder rail is available. A larger structure gauge would also be required This was also done in Los Angeles and in Vancouver as well as elsewhere in North America. The usually or normally limited structure gauge, and tight curves, on tram tracks will also prevent trains from using tram tracks.\n\nIn North America the groove would have to be a minimum of wide and by extension, the maximum distance between the inside faces of the guard flanges of the grooved rails can be no more than , see below. \n\nQuote: \n1. Lateral tolerance between wheels and rails \nTwo types of flanges are permitted on railroad wheels - narrow and wide. The maximum\nlateral movement T1 possible for a new wheel set centered on in-gage track is a function of\nthe flange type and is determined by the following formula: \nCAUTION: Use only English Units in Formulas in this Recommended Practice \n\nWhere: gt = standard track gage at a point “5/8” () below top of rail = 56.5\" ()\ngw = minimum gage of wheel set between backs of flanges = 53” ()\nfn = minimum thickness of new wheel flange = 1.15625” () for narrow flange or = 1.375\" () for wide flange\nQuoted from \n\nRural and suburban lines can be made compatible for use by several types of vehicles. For example, the narrow gauge railway used by Charleroi Metro in Belgium is ridden by trams, but the tracks are built to train track standards. Trams nonetheless run smoothly on the old NMVB tram net in Anderlues, where shallow groove rails are used. Between The Hague and Rotterdam, an old railway line was converted for RandstadRail into a route able to carry both the Rotterdam Metro, which uses vehicles built to train standards as well as The Hague trams which uses vehicles built to tram standards. The Electroliners which ran out of Chicago on the Chicago North Shore and Milwaukee Railroad, and afterwards on the Norristown High Speed Line, were another example.\n\n"}
{"id": "39204539", "url": "https://en.wikipedia.org/wiki?curid=39204539", "title": "Digital Humanitarian Network", "text": "Digital Humanitarian Network\n\nThe Digital Humanitarian Network is a network-of-networks, enabling a consortium of Volunteer and Technical Communities (V&TCs) to interface with humanitarian organizations that seek their services. As a community-based network, the DHN has a growing list of member-groups and organizations.\n\nThe Digital Humanitarian Network’s (DHNetwork) website was launched on April 9, 2012 by its co-founders:\n\n\nThe purpose is to support humanitarian organizations in their disaster response efforts around the world. The network consists of member V&TCs (entities that manage networks of technically trained volunteers around the globe, who can be activated to backstop disaster response operations and produce information with limited turn over time). These groups have a wide range of skills from GIS mapping, crowdsourcing, and data analysis and collection, to volunteer management and process design. The DHNetwork puts groups that have existed for years under one umbrella and provides a single outlet for traditional responders to access the organizations.\n\nIn recent crises, like the 2010 Haiti earthquake, members of online technology communities have cooperated to gather, process and share crucial information resources to help aid agencies on the ground, without contributing to 'data noise', by focusing on the information needs of aid agencies and other responders. This collective action was recognised and legitimized after the Haiti earthquake when volunteer communities established a 'network of networks' with the aim of concentrating the abilities online responders on the most urgent information needs during each new emergency.\n\nThe DHNetwork, has been created precisely in order to coordinate their action with, at its heart, a coordinator's group. The network brings together many of the major V&TCs thereby increasing their visibility both amongst themselves and amongst the traditional humanitarian community, and has defined a clear activation process between the VT&Cs and coordinators, so that traditional organizations are able to submit one request and rely on the DHNetwork to build a solution team with the relevant V&TC members. DHNetwork also makes it simpler for organizations to define collaborative projects with the V&TCs. As Jacobo Quintanilla underlines it: \"humanitarian actors too, are finally adopting some of these tools (i.e. crowdsourcing and mapping tools) more systematically within their work, relying on input from affected populations\", citing initiatives such as the DHNetwork as an example \"to create important inroads in the way aid organisations leverage technology and the power of VT&Cs\".\n\nThe DHNetwork is composed of several members who form Solution Teams when the network is activated. DHNetwork Coordinators review activation requests and rapidly liaise with the different volunteer & technical teams who are members of Digital Humanitarians to build a Solution Team best able to act on a request. The Coordinators aim to provide a response to every request within 24 hours.\n\nThe Current Coordinators of the DHNetwork are:\nHeather Milton, \nEvert Bopp, \nOludontun Babayemi, \nHilary Nicole Zainab Ervin, \n\nPast Coordinators of the DHNetwork are:\n\n2014\nJustine Mackinnon, \nHelen Campbell, \n\n2013\n\nIn the past year, the DHNetwork has been activated five times by OCHA South Sudan, ACAPS, OCHA Philippines, Samoa government and UNHCR (Syria). In each case, the requesting entity sent a central request to the DHNetwork. These efforts resulted in such things as rapid data collection, social media filters to augment traditional assessments, and a translation of the UNHCR Syria portal into Arabic allowing regional civilians to access normally inaccessible information.\n\n1) OCHA South Sudan. Searching the internet for 3 days looking for reports, articles, and data, the team collected 15,271 unique pieces of information.\n\n2) ACAPS. The team surveyed the internet for Democratic Republic of Congo-related assessments, population statistics, historical IDP numbers, humanitarian events, and indicator values. The group also created several maps.\n\n3) OCHA Philippines. The United Nations Office for the Coordination of Humanitarian Affairs (OCHA) activated the DHNetwork on December 5, 2012, to track the real-time effects of Typhoon Pablo in the Philippines and collect all relevant tweets about the typhoon; identify pictures and videos of damage/flooding shared in those tweets; geolocate, time stamp, and develop real-time maps of displaced people, fatalities, crop damage, broken bridges. The team searched through over 20,000 social media messages within 24 hours of the crisis for photos and videos. Results were compiled and organized in a structured database. The Solution team used a variety of methods ranging from automated algorithms to micro-tasking. They used Geofeedia to identify all relevant pictures/videos that were already geo-tagged by users, PyBossa and a free and open-source microtasking platform. UN OCHA published a map that is entirely sourced from social media analysis.\n\n4) UNHCR (Syria). Translation of UNHCR’s English portal to Arabic, which allows responders, refugees (2 million), internally displaced populations, the global public, and professionals easier access to information.\n\n"}
{"id": "18672045", "url": "https://en.wikipedia.org/wiki?curid=18672045", "title": "Digital component video", "text": "Digital component video\n\nDigital component video is defined by ITU-R BT.601 (formerly CCIR 601) standard and uses the Y'CbCr colorspace. Like Analog Component Video it gets its name from the fact that the video signal has been split into two or more components, that are then carried on multiple conductors between devices. Digital component video is slowly becoming popular in both computer and home-theatre applications. Component video is capable of carrying signals such as 480i, 480p, 576i, 576p, 720p, 1080i and 1080p, although many TVs do not support 1080p through component video.\n\n"}
{"id": "42249611", "url": "https://en.wikipedia.org/wiki?curid=42249611", "title": "Digital electronic computer", "text": "Digital electronic computer\n\nIn computer science, a digital electronic computer is a computer machine which is both an electronic computer and a digital computer. Examples of a digital electronic computers include the IBM PC, the Apple Macintosh as well as modern smartphones. When computers that were both digital and electronic appeared, they displaced almost all other kinds of computers, but computation has historically been performed in various non-digital and non-electronic ways: the Lehmer sieve is an example of a digital non-electronic computer, while analog computers are examples of non-digital computers which can be electronic (with analog electronics), and mechanical computers are examples of non-electronic computers (which may be digital or not). An example of a computer which is both non-digital and non-electronic is the ancient Antikythera mechanism found in Greece. All kinds of computers, whether they are digital or analog, and electronic or non-electronic, can be Turing complete if they have sufficient memory. A digital electronic computer is not necessarily a programmable computer, a stored program computer, or a general purpose computer, since in essence a digital electronic computer can be built for one specific application and be non-reprogrammable. As of 2014, most personal computers and smartphones in people's homes that use multicore central processing units (such as AMD FX, Intel Core i7, or the multicore varieties of ARM-based chips) are also parallel computers using the MIMD (multiple instructions - multiple data) paradigm, a technology previously only used in digital electronic supercomputers. As of 2014, most digital electronic supercomputers are also cluster computers, a technology that can be used at home in the form of small Beowulf clusters. Parallel computation is also possible with non-digital or non-electronic computers. An example of a parallel computation system using the abacus would be a group of human computers using a number of abacus machines for computation and communicating using natural language.\n\nA digital computer can perform its operations in the decimal system, in binary, in ternary or in other numeral systems. As of 2014, all digital electronic computers commonly used, whether personal computers or supercomputers, are working in the binary number system and also use binary logic. A few ternary computers using ternary logic were built mainly in the Soviet Union as research projects.\n\nA digital electronic computer is not necessarily a transistorized computer: before the advent of the transistor, computers used vacuum tubes. The transistor enabled electronic computers to become much more powerful, and recent and future developments in digital electronics may enable humanity to build even more powerful electronic computers. One such possible development is the memristor.\n\nPeople living in the beginning of the 21st century use digital electronic computers for storing data, such as photos, music, documents, and for performing complex mathematical computations or for communication, commonly over a worldwide computer network called the internet which connects many of the world's computers. All these activities made possible by digital electronic computers could, in essence, be performed with non-digital or non-electronic computers if they were sufficiently powerful, but it was only the combination of electronics technology with digital computation in binary that enabled humanity to reach the computation power necessary for today's computing. Advances in quantum computing, DNA computing, optical computing or other technologies could lead to the development of more powerful computers in the future.\n\nDigital computers are inherently best described by discrete mathematics, while analog computers are most commonly associated with continuous mathematics.\n\nThe philosophy of digital physics views the universe as being digital. Konrad Zuse wrote a book known as \"Rechnender Raum\" in which he described the whole universe as one all-encompassing computer.\n\n"}
{"id": "851532", "url": "https://en.wikipedia.org/wiki?curid=851532", "title": "Electro stimulation", "text": "Electro stimulation\n\nElectro-stimulation is stimulation using electricity. \n\nIt can be used in the context of:\n"}
{"id": "38500724", "url": "https://en.wikipedia.org/wiki?curid=38500724", "title": "Electronic media and sleep", "text": "Electronic media and sleep\n\nThe use of computers (including devices such as smartphones, tablet computers and laptops) by children and adolescents before bed has been associated with a reduction in the hours of sleep experienced by frequent users, along with a decreased quality of sleep, in most cases. The results of computer use at night have been linked with tiredness.\n\nA 2010 review concluded that \"the use of electronic media by children and adolescents does have a negative impact on their sleep, although the precise effects and mechanisms remain unclear\", with the most consistent results associating excessive media use with shorter sleep duration and delayed bed times. A 2016 meta-analysis found that \"Bedtime access and use of media devices was significantly associated with inadequate sleep quantity; poor sleep quality; and excessive daytime sleepiness\".\n\nThe American Academy of Pediatrics recommends screen time for children be limited for multiple reasons, among them that \"Too much screen time can also harm the amount and quality of sleep\".\n\nMany apps promise to improve sleep by filtering out blue light produced by media devices; there have been no large studies to assess whether such apps work. Some users express dissatisfaction with the resultant orange tint of screens. Some people use blue-blocking glasses, for the purpose of attempting to block out blue light both from electronic media and from other artificial light sources.\n\n"}
{"id": "9251", "url": "https://en.wikipedia.org/wiki?curid=9251", "title": "Engineering", "text": "Engineering\n\nEngineering is the creative application of science, mathematical methods, and empirical evidence to the innovation, design, construction, operation and maintenance of structures, machines, materials, devices, systems, processes, and organizations for the benefit of humankind. The discipline of engineering encompasses a broad range of more specialized fields of engineering, each with a more specific emphasis on particular areas of applied mathematics, applied science, and types of application. See glossary of engineering.\n\nThe term \"engineering\" is derived from the Latin \"ingenium\", meaning \"cleverness\" and \"ingeniare\", meaning \"to contrive, devise\".\n\nThe American Engineers' Council for Professional Development (ECPD, the predecessor of ABET) has defined \"engineering\" as:\nThe creative application of scientific principles to design or develop structures, machines, apparatus, or manufacturing processes, or works utilizing them singly or in combination; or to construct or operate the same with full cognizance of their design; or to forecast their behavior under specific operating conditions; all as respects an intended function, economics of operation and safety to life and property.\n\nEngineering has existed since ancient times, when humans devised inventions such as the wedge, lever, wheel and pulley.\n\nThe term \"engineering\" is derived from the word \"engineer\", which itself dates back to 1390 when an \"engine'er\" (literally, one who operates an \"engine\") referred to \"a constructor of military engines.\" In this context, now obsolete, an \"engine\" referred to a military machine, \"i.e.\", a mechanical contraption used in war (for example, a catapult). Notable examples of the obsolete usage which have survived to the present day are military engineering corps, \"e.g.\", the U.S. Army Corps of Engineers.\n\nThe word \"engine\" itself is of even older origin, ultimately deriving from the Latin \"ingenium\" (c. 1250), meaning \"innate quality, especially mental power, hence a clever invention.\"\n\nLater, as the design of civilian structures, such as bridges and buildings, matured as a technical discipline, the term civil engineering entered the lexicon as a way to distinguish between those specializing in the construction of such non-military projects and those involved in the discipline of military engineering.\n\nThe pyramids in Egypt, the Acropolis and the Parthenon in Greece, the Roman aqueducts, Via Appia and the Colosseum, Teotihuacán, the Great Wall of China, the Brihadeeswarar Temple of Thanjavur, among many others, stand as a testament to the ingenuity and skill of ancient civil and military engineers. Other monuments, no longer standing, such as the Hanging Gardens of Babylon, and the Pharos of Alexandria were important engineering achievements of their time and were considered among the Seven Wonders of the Ancient World.\n\nThe earliest civil engineer known by name is Imhotep. As one of the officials of the Pharaoh, Djosèr, he probably designed and supervised the construction of the Pyramid of Djoser (the Step Pyramid) at Saqqara in Egypt around 2630–2611 BC.\nAncient Greece developed machines in both civilian and military domains. The Antikythera mechanism, the first known mechanical computer, and the mechanical inventions of Archimedes are examples of early mechanical engineering. Some of Archimedes' inventions as well as the Antikythera mechanism required sophisticated knowledge of differential gearing or epicyclic gearing, two key principles in machine theory that helped design the gear trains of the Industrial Revolution, and are still widely used today in diverse fields such as robotics and automotive engineering.\n\nAncient Chinese, Greek, Roman and Hungarian armies employed military machines and inventions such as artillery which was developed by the Greeks around the 4th century BC, the trireme, the ballista and the catapult. In the Middle Ages, the trebuchet was developed.\n\nBefore the development of modern engineering, mathematics was used by artisans and craftsmen, such as millwrights, clock makers, instrument makers and surveyors. Aside from these professions, universities were not believed to have had much practical significance to technology.\n\nA standard reference for the state of mechanical arts during the Renaissance is given in the mining engineering treatise \"De re metallica\" (1556), which also contains sections on geology, mining and chemistry. \"De re metallica\" was the standard chemistry reference for the next 180 years.\n\nThe science of classical mechanics, sometimes called Newtonian mechanics, formed the scientific basis of much of modern engineering. With the rise of engineering as a profession in the 18th century, the term became more narrowly applied to fields in which mathematics and science were applied to these ends. Similarly, in addition to military and civil engineering, the fields then known as the mechanic arts became incorporated into engineering.\n\nCanal building was an important engineering work during the early phases of the Industrial Revolution.\n\nJohn Smeaton was the first self-proclaimed civil engineer and is often regarded as the \"father\" of civil engineering. He was an English civil engineer responsible for the design of bridges, canals, harbours, and lighthouses. He was also a capable mechanical engineer and an eminent physicist. Using a model water wheel, Smeaton conducted experiments for seven years, determining ways to increase efficiency. Smeaton introduced iron axles and gears to water wheels. Smeaton also made mechanical improvements to the Newcomn steam engine. Smeaton designed the third Eddystone Lighthouse (1755–59) where he pioneered the use of 'hydraulic lime' (a form of mortar which will set under water) and developed a technique involving dovetailed blocks of granite in the building of the lighthouse. He is important in the history, rediscovery of, and development of modern cement, because he identified the compositional requirements needed to obtain \"hydraulicity\" in lime; work which led ultimately to the invention of Portland cement.\n\nApplied science lead to the development of the steam engine. The sequence of events began with the invention the barometer and the measurement of atmospheric pressure by Evangelista Torricelli in 1643, demonstration of the force of atmospheric pressure by Otto von Guericke using the Magdeburg hemispheres in 1656, laboratory experiments by Denis Papin, who built experimental model steam engines and demonstrated the use of a piston, which he published in 1707. Edward Somerset, 2nd Marquess of Worcester published a book of 100 inventions containing a method for raising waters similar to a coffee percolator. Samuel Morland, a mathematician and inventor who worked on pumps, left notes at the Vauxhall Ordinance Office on a steam pump design that Thomas Savery read. In 1698 Savery built a steam pump called “The Miner’s Friend.” It employed both vacuum and pressure. Iron merchant Thomas Newcomen, who built the first commercial piston steam engine in 1712, was not known to have any scientific training.\n\nThe application of steam powered cast iron blowing cylinders for providing pressurized air for blast furnaces lead to a large increase in iron production in the late 18th century. The higher furnace temperatures made possible with steam powered blast allowed for the use of more lime in blast furnaces, which enabled the transition from charcoal to coke. These innovations lowered the cost of iron, making horse railways and iron bridges practical. The puddling process, patented by Henry Cort in 1784 produced large scale quantities of wrought iron. Hot blast, patented by James Beaumont Neilson in 1828, greatly lowered the amount of fuel needed to smelt iron. With the development of the high pressure steam engine, the power to weight ratio of steam engines made practical steamboats and locomotives possible. New steel making processes, such as the Bessemer process and the open hearth furnace, ushered in an area of heavy engineering in the late 19th century.\n\nOne of the most famous engineers of the mid 19th century was Isambard Kingdom Brunel, who built railroads, dockyards and steamships.\n\nThe Industrial Revolution created a demand for machinery with metal parts, which led to the development of several machine tools. Boring cast iron cylinders with precision was not possible until John Wilkinson invented his boring machine, which is considered the first machine tool. Other machine tools included the screw cutting lathe, milling machine, turret lathe and the metal planer. Precision machining techniques were developed in the first half of the 19th century. These included the use of gigs to guide the machining tool over the work and fixtures to hold the work in the proper position. Machine tools and machining techniques capable of producing interchangeable parts lead to large scale factory production by the late 19th century.\n\nThe United States census of 1850 listed the occupation of \"engineer\" for the first time with a count of 2,000. There were fewer than 50 engineering graduates in the U.S. before 1865. In 1870 there were a dozen U.S. mechanical engineering graduates, with that number increasing to 43 per year in 1875. In 1890, there were 6,000 engineers in civil, mining, mechanical and electrical.\n\nThere was no chair of applied mechanism and applied mechanics at Cambridge until 1875, and no chair of engineering at Oxford until 1907. Germany established technical universities earlier.\n\nThe foundations of electrical engineering in the 1800s included the experiments of Alessandro Volta, Michael Faraday, Georg Ohm and others and the invention of the electric telegraph in 1816 and the electric motor in 1872. The theoretical work of James Maxwell (see: Maxwell's equations) and Heinrich Hertz in the late 19th century gave rise to the field of electronics. The later inventions of the vacuum tube and the transistor further accelerated the development of electronics to such an extent that electrical and electronics engineers currently outnumber their colleagues of any other engineering specialty.\nChemical engineering developed in the late nineteenth century. Industrial scale manufacturing demanded new materials and new processes and by 1880 the need for large scale production of chemicals was such that a new industry was created, dedicated to the development and large scale manufacturing of chemicals in new industrial plants. The role of the chemical engineer was the design of these chemical plants and processes.\n\nAeronautical engineering deals with aircraft design process design while aerospace engineering is a more modern term that expands the reach of the discipline by including spacecraft design. Its origins can be traced back to the aviation pioneers around the start of the 20th century although the work of Sir George Cayley has recently been dated as being from the last decade of the 18th century. Early knowledge of aeronautical engineering was largely empirical with some concepts and skills imported from other branches of engineering.\n\nThe first PhD in engineering (technically, \"applied science and engineering\") awarded in the United States went to Josiah Willard Gibbs at Yale University in 1863; it was also the second PhD awarded in science in the U.S.\n\nOnly a decade after the successful flights by the Wright brothers, there was extensive development of aeronautical engineering through development of military aircraft that were used in World War I. Meanwhile, research to provide fundamental background science continued by combining theoretical physics with experiments.\n\nEngineering is a broad discipline which is often broken down into several sub-disciplines. Although an engineer will usually be trained in a specific discipline, he or she may become multi-disciplined through experience. Engineering is often characterized as having four main branches: chemical engineering, civil engineering, electrical engineering, and mechanical engineering.\n\nChemical engineering is the application of physics, chemistry, biology, and engineering principles in order to carry out chemical processes on a commercial scale, such as the manufacture of commodity chemicals, specialty chemicals, petroleum refining, microfabrication, fermentation, and biomolecule production.\n\nCivil engineering is the design and construction of public and private works, such as infrastructure (airports, roads, railways, water supply, and treatment etc.), bridges, tunnels, dams, and buildings. Civil engineering is traditionally broken into a number of sub-disciplines, including structural engineering, environmental engineering, and surveying. It is traditionally considered to be separate from military engineering.\n\nElectrical engineering is the design, study, and manufacture of various electrical and electronic systems, such as Broadcast engineering, electrical circuits, generators, motors, electromagnetic/electromechanical devices, electronic devices, electronic circuits, optical fibers, optoelectronic devices, computer systems, telecommunications, instrumentation, controls, and electronics.\n\nMechanical engineering is the design and manufacture of physical or mechanical systems, such as power and energy systems, aerospace/aircraft products, weapon systems, transportation products, engines, compressors, powertrains, kinematic chains, vacuum technology, vibration isolation equipment, manufacturing, and mechatronics.\n\nBeyond these \"Big 4\", a number of other branches are recognized, though many can be thought of as sub-disciplines of the four major branches, or as cross-curricular disciplines among multiple. Historically, naval engineering and mining engineering were major branches. Other engineering fields are manufacturing engineering, acoustical engineering, corrosion engineering, instrumentation and control, aerospace, automotive, computer, electronic, information engineering, petroleum, environmental, systems, audio, software, architectural, agricultural, biosystems, biomedical, geological, textile, industrial, materials, and nuclear engineering. These and other branches of engineering are represented in the 36 licensed member institutions of the UK Engineering Council.\n\nNew specialties sometimes combine with the traditional fields and form new branches – for example, Earth systems engineering and management involves a wide range of subject areas including engineering studies, environmental science, engineering ethics and philosophy of engineering.\n\nOne who practices engineering is called an engineer, and those licensed to do so may have more formal designations such as Professional Engineer, Chartered Engineer, Incorporated Engineer, Ingenieur, European Engineer, or Designated Engineering Representative.\n\nIn the engineering design process, engineers apply mathematics and sciences such as physics to find novel solutions to problems or to improve existing solutions. More than ever, engineers are now required to have a proficient knowledge of relevant sciences for their design projects. As a result, many engineers continue to learn new material throughout their career.\n\nIf multiple solutions exist, engineers weigh each design choice based on their merit and choose the solution that best matches the requirements. The crucial and unique task of the engineer is to identify, understand, and interpret the constraints on a design in order to yield a successful result. It is generally insufficient to build a technically successful product, rather, it must also meet further requirements.\n\nConstraints may include available resources, physical, imaginative or technical limitations, flexibility for future modifications and additions, and other factors, such as requirements for cost, safety, marketability, productivity, and serviceability. By understanding the constraints, engineers derive specifications for the limits within which a viable object or system may be produced and operated.\n\nA general methodology and epistemology of engineering can be inferred from the historical case studies and comments provided by Walter Vincenti. Though Vincenti's case studies are from the domain of aeronautical engineering, his conclusions can be transferred into many other branches of engineering, too.\n\nAccording to Billy Vaughn Koen, the \"\"engineering method\" is the use of heuristics to cause the best change in a poorly understood situation within the available resources.\" Koen argues that the definition of what makes one an engineer should not be based on what he produces, but rather how he goes about it.\n\nEngineers use their knowledge of science, mathematics, logic, economics, and appropriate experience or tacit knowledge to find suitable solutions to a problem. Creating an appropriate mathematical model of a problem often allows them to analyze it (sometimes definitively), and to test potential solutions.\n\nUsually, multiple reasonable solutions exist, so engineers must evaluate the different design choices on their merits and choose the solution that best meets their requirements. Genrich Altshuller, after gathering statistics on a large number of patents, suggested that compromises are at the heart of \"low-level\" engineering designs, while at a higher level the best design is one which eliminates the core contradiction causing the problem.\n\nEngineers typically attempt to predict how well their designs will perform to their specifications prior to full-scale production. They use, among other things: prototypes, scale models, simulations, destructive tests, nondestructive tests, and stress tests. Testing ensures that products will perform as expected.\n\nEngineers take on the responsibility of producing designs that will perform as well as expected and will not cause unintended harm to the public at large. Engineers typically include a factor of safety in their designs to reduce the risk of unexpected failure. However, the greater the safety factor, the less efficient the design may be.\n\nThe study of failed products is known as forensic engineering and can help the product designer in evaluating his or her design in the light of real conditions. The discipline is of greatest value after disasters, such as bridge collapses, when careful analysis is needed to establish the cause or causes of the failure.\n\nAs with all modern scientific and technological endeavors, computers and software play an increasingly important role. As well as the typical business application software there are a number of computer aided applications (computer-aided technologies) specifically for engineering. Computers can be used to generate models of fundamental physical processes, which can be solved using numerical methods.\n\nOne of the most widely used design tools in the profession is computer-aided design (CAD) software like CATIA, Autodesk Inventor, DSS SolidWorks or Pro Engineer which enables engineers to create 3D models, 2D drawings, and schematics of their designs. CAD together with digital mockup (DMU) and CAE software such as finite element method analysis or analytic element method allows engineers to create models of designs that can be analyzed without having to make expensive and time-consuming physical prototypes.\n\nThese allow products and components to be checked for flaws; assess fit and assembly; study ergonomics; and to analyze static and dynamic characteristics of systems such as stresses, temperatures, electromagnetic emissions, electrical currents and voltages, digital logic levels, fluid flows, and kinematics. Access and distribution of all this information is generally organized with the use of product data management software.\n\nThere are also many tools to support specific engineering tasks such as computer-aided manufacturing (CAM) software to generate CNC machining instructions; manufacturing process management software for production engineering; EDA for printed circuit board (PCB) and circuit schematics for electronic engineers; MRO applications for maintenance management; and Architecture, engineering and construction (AEC) software for civil engineering.\n\nIn recent years the use of computer software to aid the development of goods has collectively come to be known as product lifecycle management (PLM).\n\nThe engineering profession engages in a wide range of activities, from large collaboration at the societal level, and also smaller individual projects. Almost all engineering projects are obligated to some sort of financing agency: a company, a set of investors, or a government. The few types of engineering that are minimally constrained by such issues are \"pro bono\" engineering and open-design engineering.\n\nBy its very nature engineering has interconnections with society, culture and human behavior. Every product or construction used by modern society is influenced by engineering. The results of engineering activity influence changes to the environment, society and economies, and its application brings with it a responsibility and public safety.\n\nEngineering projects can be subject to controversy. Examples from different engineering disciplines include the development of nuclear weapons, the Three Gorges Dam, the design and use of sport utility vehicles and the extraction of oil. In response, some western engineering companies have enacted serious corporate and social responsibility policies.\n\nEngineering is a key driver of innovation and human development. Sub-Saharan Africa, in particular, has a very small engineering capacity which results in many African nations being unable to develop crucial infrastructure without outside aid. The attainment of many of the Millennium Development Goals requires the achievement of sufficient engineering capacity to develop infrastructure and sustainable technological development.\n\nAll overseas development and relief NGOs make considerable use of engineers to apply solutions in disaster and development scenarios. A number of charitable organizations aim to use engineering directly for the good of mankind:\n\nEngineering companies in many established economies are facing significant challenges with regard to the number of professional engineers being trained, compared with the number retiring. This problem is very prominent in the UK where engineering has a poor image and low status. There are many negative economic and political issues that this can cause, as well as ethical issues. It is widely agreed that the engineering profession faces an \"image crisis\", rather than it being fundamentally an unattractive career. Much work is needed to avoid huge problems in the UK and other western economies.\n\nMany engineering societies have established codes of practice and codes of ethics to guide members and inform the public at large. The National Society of Professional Engineers code of ethics states:\nIn Canada, many engineers wear the Iron Ring as a symbol and reminder of the obligations and ethics associated with their profession.\n\nThere exists an overlap between the sciences and engineering practice; in engineering, one applies science. Both areas of endeavor rely on accurate observation of materials and phenomena. Both use mathematics and classification criteria to analyze and communicate observations.\n\nScientists may also have to complete engineering tasks, such as designing experimental apparatus or building prototypes. Conversely, in the process of developing technology engineers sometimes find themselves exploring new phenomena, thus becoming, for the moment, scientists or more precisely \"engineering scientists\".\n\nIn the book \"What Engineers Know and How They Know It\", Walter Vincenti asserts that engineering research has a character different from that of scientific research. First, it often deals with areas in which the basic physics or chemistry are well understood, but the problems themselves are too complex to solve in an exact manner.\n\nThere is a \"real and important\" difference between engineering and physics as similar to any science field has to do with technology. Physics is an exploratory science that seeks knowledge of principles while engineering uses knowledge for practical applications of principles. The former equates an understanding into a mathematical principle while the latter measures variables involved and creates technology. For technology, physics is an auxiliary and in a way technology is considered as applied physics. Though physics and engineering are interrelated, it does not mean that a physicist is trained to do an engineer's job. A physicist would typically require additional and relevant training. Physicists and engineers engage in different lines of work. But PhD physicists who specialize in sectors of technology and applied science are titled as Technology officer, R&D Engineers and System Engineers.\n\nAn example of this is the use of numerical approximations to the Navier–Stokes equations to describe aerodynamic flow over an aircraft, or the use of Miner's rule to calculate fatigue damage. Second, engineering research employs many semi-empirical methods that are foreign to pure scientific research, one example being the method of parameter variation.\n\nAs stated by Fung \"et al.\" in the revision to the classic engineering text \"Foundations of Solid Mechanics\":\n\nEngineering is quite different from science. Scientists try to understand nature. Engineers try to make things that do not exist in nature. Engineers stress innovation and invention. To embody an invention the engineer must put his idea in concrete terms, and design something that people can use. That something can be a complex system, device, a gadget, a material, a method, a computing program, an innovative experiment, a new solution to a problem, or an improvement on what already exists. Since a design has to be realistic and functional, it must have its geometry, dimensions, and characteristics data defined. In the past engineers working on new designs found that they did not have all the required information to make design decisions. Most often, they were limited by insufficient scientific knowledge. Thus they studied mathematics, physics, chemistry, biology and mechanics. Often they had to add to the sciences relevant to their profession. Thus engineering sciences were born.\n\nAlthough engineering solutions make use of scientific principles, engineers must also take into account safety, efficiency, economy, reliability, and constructability or ease of fabrication as well as the environment, ethical and legal considerations such as patent infringement or liability in the case of failure of the solution.\n\nThe study of the human body, albeit from different directions and for different purposes, is an important common link between medicine and some engineering disciplines. Medicine aims to sustain, repair, enhance and even replace functions of the human body, if necessary, through the use of technology.\nModern medicine can replace several of the body's functions through the use of artificial organs and can significantly alter the function of the human body through artificial devices such as, for example, brain implants and pacemakers. The fields of bionics and medical bionics are dedicated to the study of synthetic implants pertaining to natural systems.\n\nConversely, some engineering disciplines view the human body as a biological machine worth studying and are dedicated to emulating many of its functions by replacing biology with technology. This has led to fields such as artificial intelligence, neural networks, fuzzy logic, and robotics. There are also substantial interdisciplinary interactions between engineering and medicine.\n\nBoth fields provide solutions to real world problems. This often requires moving forward before phenomena are completely understood in a more rigorous scientific sense and therefore experimentation and empirical knowledge is an integral part of both.\n\nMedicine, in part, studies the function of the human body. The human body, as a biological machine, has many functions that can be modeled using engineering methods.\n\nThe heart for example functions much like a pump, the skeleton is like a linked structure with levers, the brain produces electrical signals etc. These similarities as well as the increasing importance and application of engineering principles in medicine, led to the development of the field of biomedical engineering that uses concepts developed in both disciplines.\n\nNewly emerging branches of science, such as systems biology, are adapting analytical tools traditionally used for engineering, such as systems modeling and computational analysis, to the description of biological systems.\n\nThere are connections between engineering and art, for example, architecture, landscape architecture and industrial design (even to the extent that these disciplines may sometimes be included in a university's Faculty of Engineering).\n\nThe Art Institute of Chicago, for instance, held an exhibition about the art of NASA's aerospace design. Robert Maillart's bridge design is perceived by some to have been deliberately artistic. At the University of South Florida, an engineering professor, through a grant with the National Science Foundation, has developed a course that connects art and engineering.\n\nAmong famous historical figures, Leonardo da Vinci is a well-known Renaissance artist and engineer, and a prime example of the nexus between art and engineering.\n\nBusiness Engineering deals with the relationship between professional engineering, IT systems, business administration and change management. Engineering management or \"Management engineering\" is a specialized field of management concerned with engineering practice or the engineering industry sector. The demand for management-focused engineers (or from the opposite perspective, managers with an understanding of engineering), has resulted in the development of specialized engineering management degrees that develop the knowledge and skills needed for these roles. During an engineering management course, students will develop industrial engineering skills, knowledge, and expertise, alongside knowledge of business administration, management techniques, and strategic thinking. Engineers specializing in change management must have in-depth knowledge of the application of industrial and organizational psychology principles and methods. Professional engineers often train as certified management consultants in the very specialized field of management consulting applied to engineering practice or the engineering sector. This work often deals with large scale complex business transformation or Business process management initiatives in aerospace and defence, automotive, oil and gas, machinery, pharmaceutical, food and beverage, electrical & electronics, power distribution & generation, utilities and transportation systems. This combination of technical engineering practice, management consulting practice, industry sector knowledge, and change management expertise enables professional engineers who are also qualified as management consultants to lead major business transformation initiatives. These initiatives are typically sponsored by C-level executives.\n\nIn political science, the term \"engineering\" has been borrowed for the study of the subjects of social engineering and political engineering, which deal with forming political and social structures using engineering methodology coupled with political science principles. Financial engineering has similarly borrowed the term.\n\n\n\n\n\n\n\n"}
{"id": "2654494", "url": "https://en.wikipedia.org/wiki?curid=2654494", "title": "Engineering design management", "text": "Engineering design management\n\nEngineering design management is a knowledge area within engineering management. It represents the adaptation and application of customary management practices, with the intention of achieving a productive engineering design process. Engineering design management is primarily applied in the context of engineering design teams, whereby the activities, outputs and influences of design teams are planned, guided, monitored and controlled.\n"}
{"id": "16997450", "url": "https://en.wikipedia.org/wiki?curid=16997450", "title": "Exhaust gas temperature gauge", "text": "Exhaust gas temperature gauge\n\nAn exhaust gas temperature gauge (EGT gauge) is a meter used to monitor the exhaust gas temperature of an internal combustion engine in conjunction with a thermocouple-type pyrometer. EGT gauges are found in certain cars and aeroplanes. By monitoring EGT, the driver or pilot can get an idea of the vehicle's air-fuel ratio.\n\nAt a stoichiometric air-fuel ratio, the exhaust gas temperature is different from that in a lean or rich air-fuel ratio. At rich air-fuel ratio, the exhaust gas temperature either increases or decreases depending on the fuel. High temperatures (typically above ) can be an indicator of dangerous conditions that can lead to catastrophic engine failure.\n\n\nUsing an EGT meter alone is considered an older technique for getting the most out of petrol and diesel engines, as a gauge-type wideband digital oxygen sensor can be purchased for about the same price, or for a little more. However, some advanced racers will use EGT gauges in combination with a wideband oxygen sensor to 'lean' the fuel ratio a bit to safely raise the temperature for more power.\n\nThough by tuning primarily by EGT and air fuel ratio values, EGT is still to this day a used data output for engine tuning. When fine tuning an engine, if possible with the ECU manipulation with the cylinder's timing can be made. By adjusting the timing, the resultant cylinder temperature can be used to improve cylinder efficiency. Though this is still widely done, EGT values should be used as a safe guard sensor measure and as a tuning guide. [1]\n\nwww.fku.com\n\nBenefits of individual cylinder tuning\nSensors\n"}
{"id": "1021118", "url": "https://en.wikipedia.org/wiki?curid=1021118", "title": "Fast fracture", "text": "Fast fracture\n\nIn structural engineering and material science, fast fracture is a term given to a phenomenon in which a flaw (such as a crack) in a material expands quickly, and leads to catastrophic failure of the material. Stress acting on a material when fast fracture occurs is less than the material's yield stress. A very representative example of this is what happens when poking a blown up balloon with a needle, that is, fast fracture of the balloon's material.\n\n"}
{"id": "52972673", "url": "https://en.wikipedia.org/wiki?curid=52972673", "title": "Feel Train", "text": "Feel Train\n\nFeel Train is a technology collaborative co-founded by Courtney Stanton and Darius Kazemi and based in Portland, Oregon.\n\nFeel Train is a worker-owned cooperative. Stanton and Kazemi are its first two worker-owners, and the organization is chartered to allow a maximum of eight employees, each with equal salary, equal share in the company and equal firing power over others, including the founders. \n\nFeel Train projects have included the Stay Woke Bot, a Twitter bot developed in collaboration with activists DeRay Mckesson and Samuel Sinyangwe, and Shortcut, an app developed with radio program \"This American Life\" to facilitate sharing audio clips across social media, similar to the way gifs allow video clips to be shared. Feel Train is also developing a Twitter bot based on the Obama Social Media Archive called Relive 44, which beginning in May 2017 will repost, eight years later, every tweet from President Barack Obama (whose first tweet came in May 2009.)\n\nFeel Train website\n"}
{"id": "871236", "url": "https://en.wikipedia.org/wiki?curid=871236", "title": "Hanshin Industrial Region", "text": "Hanshin Industrial Region\n\nThe is one of the largest industrial regions in Japan. Its name comes from the \"on\"-reading of the kanji used to abbreviate the names of Osaka (大阪) and Kobe (神戸), the two largest cities in the megalopolis. The GDP of this area (Osaka and Kobe) is $341 billion, one of the world's most productive regions.\n2014 Osaka and Kyoto's GDP per capita (PPP) was US$35,902.\n\nFacilities:\n\nLaboratories, research institutes:\n\nFacilities:\n\n\n\n\nLaboratories, research institutes:\n\nFacilities: and research institutes:\n\nFacilities:\n\nLaboratories, research institutes:\n\nFacilities:\n\n\n\n\nLaboratories, research institutes:\n\nFacilities:\n\nLaboratories, research institutes:\n\nFacilities:\n\nLaboratories, research institutes:\n\n\n"}
{"id": "1688179", "url": "https://en.wikipedia.org/wiki?curid=1688179", "title": "History of materials science", "text": "History of materials science\n\nMaterials science has shaped the development of civilizations since the dawn of mankind. Better materials for tools and weapons has allowed mankind to spread and conquer, and advancements in material processing like steel and aluminum production continue to impact society today. Historians have regarded materials as such an important aspect of civilizations such that entire periods of time have defined by the predominant material used (Stone Age, Bronze Age, Iron Age, etc.). For most of recorded history, control of materials had been through alchemy or empirical means at best. The study and development of chemistry and physics assisted the study of materials, and eventually the interdisciplinary study of materials science emerged from the fusion of these studies. The history of materials science is the study of how different materials were used and developed through the history of Earth and how those materials affected the culture of the peoples of the Earth.\n\nIn many cases different cultures leave their materials as the only records which anthropologists can use to define the existence of such cultures. The progressive use of more sophisticated materials allows archeologists to characterize and distinguish between peoples. This is partially due to the major material of use in a culture and to its associated benefits and drawbacks. Stone-Age cultures were limited by which rocks they could find locally and by which they could acquire by trading. The use of flint around 300,000 BCE is sometimes considered the beginning of the use of ceramics. The use of polished stone axes marks a significant advance because a much wider variety of rocks could serve as tools.\n\nThe innovation of smelting and casting metals in the Bronze Age started to change the way that cultures developed and interacted with each other. Starting around 5500 BCE, early smiths began to re-shape native metals of copper and gold - without the use of fire - for tools and weapons. The heating of copper and its shaping with hammers began around 5000 BCE. Melting and casting started around 4000 BCE. Metallurgy had its dawn with the reduction of copper from its ore around 3500 BCE. The first alloy, bronze came into use around 3000 BCE. Iron-working came into prominence from about 1200 BCE.\n\nIn the 10th century BCE glass production began in ancient Near East. In the 3rd century BCE people in ancient India developed wootz steel, the first crucible steel. In the 1st century BCE glassblowing techniques flourished in Phoenicia. In the 2nd century CE steel-making became widespread in Han Dynasty China. The 4th century CE saw the production of the Iron pillar of Delhi, the oldest surviving example of corrosion-resistant steel.\n\nWood, bone, stone, and earth are some of the materials which formed the structures of the Roman Empire. Certain structures were made possible by the character of the land upon which these structures are built; a volcanic peninsula with stone aggregates and conglomerates containing crystalline material will produce material which weathers differently from soft, sedimentary rock and silt. That is one of the reasons that the concrete Pantheon of Rome could last for 1850 years, and why the thatched farmhouses of Holland sketched by Rembrandt have long since decayed.\n\nAfter the thighbone daggers of the early hunter-gatherers were superseded by wood and stone axes, and then by copper, bronze and iron implements of the Roman civilization, more precious materials could then be sought, and gathered together. Thus the medieval goldsmith Benvenuto Cellini could seek and defend the gold which he had to turn into objects of desire for dukes and popes. \"The Autobiography of Benvenuto Cellini\" contains one of the first descriptions of a metallurgical process.\n\nThe use of materials begins in the stone age. Typically materials such as bone, fibers, feathers, shells, animal skin, and clay were used for weapons, tools, jewelry, and shelter. The earliest tools were in the paleolithic age, called Oldowan. These were tools created from chipped rocks that would be used for scavenging purpose. As history carried on into the Mesolithic age, tools became more complex and symmetrical in design with sharper edges. Moving into the Neolithic age, agriculture began to develop as new was to form tools for farming were discovered. Nearing the end of the stone age, humans began using copper, gold, and silver as a material. Due to these metals softness, the general use was for ceremonial purposes and to create ornaments or decorations and did not replace other materials for use in tools. The simplicity of the tools used reflected on the simple understanding of the human species of the time.\n\nThe use of copper had become very apparent to civilizations, such as its properties of elasticity and plasticity that allow it to be hammered into useful shapes, along with its ability to be melted and pored into intricate shapes. Although the advantages of copper were many, the materials was to soft to find large scale usefulness. Through experimentation or by chance, additions to copper lead to increased hardness of a new metal alloy, called bronze. Bronze was originally composed of copper and arsenic, forming arsenic bronze.\n\nProto-porcelain material has been discovered dating back to the Neolthic period, with shards of material found in archaeological sites from the Eastern Han period in China. These wares are estimated to have been fired from 1260 to 1300 °C. In the 8th century, porcelain was invented in Tang Dynasty China. Porcelain in china resulted in a methodical development of widely used kilns that increased the quality and quantity that procelain could be produced. Tin-glazing of ceramics is invented by Arabic chemists and potters in Basra, Iraq.\n\nIn the 9th century, stonepaste ceramics were invented in Iraq, and lustreware appeared in Mesopotamia.\n\nIn the 11th century, Damascus steel is developed in the Middle East. In the 15th century, Johann Gutenberg develops type metal alloy and Angelo Barovier invents cristallo, a clear soda-based glass.\n\nIn the 16th century, Vannoccio Biringuccio publishes his Pirotechnia, the first systematic book on metallurgy, Georg Agricola writes De Re Metallica, an influential book on metallurgy and mining, and glass lens are developed in the Netherlands and used for the first time in microscopes and telescopes.\n\nIn the 17th century, Galileo's \"Two New Sciences\" (strength of materials and kinematics) includes the first quantitative statements in the science of materials. In the 18th century, William Champion patents a process for the production of metallic zinc by distillation from calamine and charcoal, Bryan Higgins was issued a patent for hydraulic cement (stucco) for use as an exterior plaster, and Alessandro Volta makes a copper/zinc acid battery.\n\nIn the 19th century, Thomas Johann Seebeck invents the thermocouple, Joseph Aspin invents Portland cement, Charles Goodyear invents vulcanized rubber, Louis Daguerre and William Fox Talbot invent silver-based photographic processes, James Clerk Maxwell demonstrates color photography, and Charles Fritts makes the first solar cells using selenium waffles.\n\nBefore the early 1800s, aluminum had not been produced as an isolated metal. It wasn't until 1825 that Hans Christian Ørsted discovered how to create elemental aluminum via the reduction of aluminum chloride. Since aluminum is a light element with good mechanical properties, it was widely sought to replace heavier less functional metals like silver and gold. Napoleon III used aluminum plates and utensils for his honored guests, while the rest were given silver. However, this process was still expensive and was still not able to produce the metal in large quantities. In 1886, American Charles Martin Hall and Frenchman Paul Héroult invented a process completely independent of each other to produce aluminum from aluminum oxide via electrolysis. This process would allow aluminum to be manufactured cheaper than ever before, and laid the groundwork for turning the element from a precious metal into an easily obtainable commodity. Around the same time in 1888, Carl Josef Bayer was working in St Petersburg, Russia to develop a method to make pure alumina for the textile industry. This process involved dissolving the aluminum oxide out of the bauxite mineral to produce gibbsite, which can then be purified back into raw alumina. The Bayer process and the Hall-Héroult process are still used today to produce a majority of the world's alumina and aluminum.\n\nMost fields of studies have a founding father, such as Newton in physics and Lavoisier in chemistry. Materials science on the other hand has no central figure that set in motion materials studies. In the 1940s, wartime collaborations of multiple fields of study to produce technological advances became a structure to the future field of study that would become known as material science and engineering. During the Cold War in the 1950s, US President Science Advisory Committee (PSAC) made materials a priority when it realized that materials were the limiting factor for advances in space and military technology. The Department of defense signed a contract with 5 universities (Harvard, MIT, Brown, Stanford, and Chicago) providing over $13 million for material research. Several institutions departments changed titles from \"metallurgy\" to \"metallurgy and materials science\" in 1960's.\n\nIn the early part of the 20th century, most engineering schools had a department of metallurgy and perhaps of ceramics as well. Much effort was expended on consideration of the austenite-martensite-cementite phases found in the iron-carbon phase diagram that underlies steel production. The fundamental understanding of other materials was not sufficiently advanced for them to be considered as academic subjects. In the post-WWII era, the systematic study of polymers advanced particularly rapidly. Rather than create new polymer science departments in engineering schools, administrators and scientists began to conceive of materials science as a new interdisciplinary field in its own right, one that considered all substances of engineering importance from a unified point of view. Northwestern University instituted the first materials science department in 1955.\n\nDr. Richard E. Tressler was an international leader in the development of high temperature materials. He pioneered high temperature fiber testing and use, advanced instrumentation and test methodologies for thermostructural materials, and design and performance verification of ceramics and composites in high temperature aerospace, industrial and energy applications. He was founding director of the Center for Advanced Materials (CAM) which supported many faculty and students from the College of Earth and Mineral Science, the Eberly College of Science, the College of Engineering, the Materials Research Laboratory and the Applied Research Laboratories at Penn State on high temperature materials. His vision for interdisciplinary research played a key role in the creation of the Materials Research Institute. Tressler's contribution to materials science is celebrated with a Penn State lecture named in his honor.\n\nThe Materials Research Society (MRS) has been instrumental in creating an identity and cohesion for this young field. MRS was the brainchild of researchers at Penn State University and grew out of discussions initiated by Prof. Rustum Roy in 1970. The first meeting of MRS was held in 1973. As of 2006, MRS has grown into an international society that sponsors a large number of annual meetings and has over 13,000 members. MRS sponsors meetings that are subdivided into symposia on a large variety of topics as opposed to the more focused meetings typically sponsored by organizations like the American Physical Society or the IEEE. The fundamentally interdisciplinary nature of MRS meetings has had a strong influence on the direction of science, particularly in the popularity of the study of soft materials, which are in the nexus of biology, chemistry, physics and mechanical and electrical engineering.\nBecause of the existence of integrative textbooks, materials research societies and university chairs in all parts of the world, BA, MA and PhD programs and other indicators of discipline formation, it is fair to call materials science (and engineering) a discipline.\n\nIn 1958, President Dwight D. Eisenhower created the Advanced Research Project Agency (ARPA), referred to as the Defense Advanced Research Project Agency (DARPA) since 1996. In 1960, ARPA encouraged the establishment of interdisciplinary laboratories (IDL's) on university campuses, which would be dedicated to the research of materials, as well as to the education of students on how to conduct materials science research. ARPA offered 4-year IDL contracts to universities, originally to Cornell University, University of Pennsylvania, and Northwestern University, eventually granting 9 more contracts. Although ARPA is no longer in control of the IDL program (the National Science Foundation took over the program in 1972), the original establishment of IDL's marked a significant milestone in the United States' research and development of materials science.\n\n\n\n"}
{"id": "32303617", "url": "https://en.wikipedia.org/wiki?curid=32303617", "title": "IControlPad", "text": "IControlPad\n\nThe iControlPad is a wireless game controller compatible with a variety of smartphones, tablets, and personal computers. It is designed for use as either a standalone gamepad or attached to appropriately sized devices, such as the iPhone, using a clamp system. Due to this, the iControlPad is able to add traditional physical gaming controls to devices which otherwise rely on inputs such as touchscreens and accelerometers.\n\nThe iControlPad's input controls include an eight-directional D-pad, dual analog nubs, six digital face buttons, and two digital trigger buttons on the gamepad's reverse. The sides of the iControlPad are detachable, with two different attachment types: rubber grips, for using the controller as a standard wireless gamepad; or plastic clamps, for connecting with a suitable handheld, such as a smartphone or iPod Touch. A mini USB port on the bottom of the iControlPad can be used to charge the internal 1500mAh battery, update the device's firmware, and charge attached devices using a USB On-The-Go connection and an appropriate adapter.\n\nThe iControlPad, a Bluetooth device, can be run in a wide variety of modes, including as a HID keyboard, mouse, joystick, and gamepad, among others, allowing compatibility with equipment which is limited to only certain types of input. One of the iControlPad's modes mimics the protocol used by the iCade, an arcade cabinet released for the Apple iPad, facilitating compatibility between apps designed for the iCade and the iControlPad hardware.\n\nDue to the iControlPad's ability to operate as a Bluetooth keyboard—by mapping the D-pad and buttons to standard keyboard keys—it is able to communicate with devices such as those running Apple's iOS, including the iPhone and iPad, which do not support Bluetooth gamepads. Since iOS natively supports keyboards, apps can be developed with iControlPad compatibility using either its own protocol or that of the iCade. Thus, the iControlPad is able to control video games and video game console emulators across multiple platforms.\n\nDevelopment of the iControlPad began in 2007, with testing using a hacked SNES gamepad to connect to an iPhone over the dock connection. Once the serial connection was working, the first prototype iControlPad was produced, using a design styled after the Sony PSP. This earliest concept was a one-piece case enveloping the iPhone, with a D-pad on the left side, and four face buttons on the right in a landscape orientation, and was first revealed in 2008.\n\nBy November 2009, a completely redesigned iControlPad prototype was under development. This much larger version moved the controls below the screen and added two analog nubs and two trigger buttons to the controller. This design, which featured clamps to attach it to the iPhone, was much closer to the version that was ultimately released, and would soon go into production.\n\nHowever, one large change was made very late in development. The team had secretly added Bluetooth support to the iControlPad, in order to increase compatibility beyond the iPhone and its proprietary connection. This proved fortunate when Apple began exercising its rights over the dock connector, suing an unlicensed accessory maker. Thus, the iControlPad team were forced to adapt to use the Bluetooth connection for the iPhone, and it was this version which finally became available for order in February 2011.\n\n\n\n\nReception for the iControlPad has been mostly positive. Register Hardware noted that while \"patience and geekery\" were required to get the controller working, the iControlPad \"almost perfectly solves the touchscreen game control conundrum\". Gadgetoid homed in on the device's usefulness for classic gaming, remarking that it was \"awesome [...] for emulation on the go\". TouchArcade's reviewer said while playing games with the iControlPad that \"the experience feels great\", but that \"[he couldn't] recommend that the typical gamer run out right now and grab one,\" due to its limited support on the iTunes App Store.\n\nEarly reviews were mixed on the quality of the controls, with DroidGamers describing them as \"very loose\", while, conversely, Register Hardware said \"the analogue nubs and face buttons work extremely well\". The controller's responsiveness was later improved by replacing the original rubber keymat with a larger one. In their review, Gadgetoid lauded the inputs as having \"a great tactile feel and a liberal amount of travel with a good response.\"\n\nA successor, the iControlPad 2, was successfully funded via Kickstarter in October 2012. As of November 2013, it has been cancelled, with little to no refunds.\n\n"}
{"id": "4724116", "url": "https://en.wikipedia.org/wiki?curid=4724116", "title": "ISO 15926", "text": "ISO 15926\n\nThe ISO 15926 is a standard for data integration, sharing, exchange, and hand-over between computer systems.\n\nThe title, \"Industrial automation systems and integration—Integration of life-cycle data for process plants including oil and gas production facilities\", is regarded too narrow by the present ISO 15926 developers. Having developed a generic data model and Reference Data Library for process plants, it turned out that this subject is already so wide, that actually any state information may be modelled with it.\n\nIn 1991 a European Union ESPRIT-, named ProcessBase, started. The focus of this research project was to develop a data model for lifecycle information of a facility that would suit the requirements of the process industries. At the time that the project duration had elapsed, a consortium of companies involved in the process industries had been established: EPISTLE (European Process Industries STEP Technical Liaison Executive). Initially individual companies were members, but later this changed into a situation where three national consortia were the only members: PISTEP (UK), POSC/Caesar (Norway), and USPI-NL (Netherlands). (later PISTEP merged into POSC/Caesar, and USPI-NL was renamed to USPI).\n\nEPISTLE took over the work of the ProcessBase project. Initially this work involved a standard called ISO 10303-221 (referred to as \"STEP AP221\"). In that AP221 we saw, for the first time, an Annex M with a list of standard instances of the AP221 data model, including types of objects. These standard instances would be for reference and would act as a knowledge base with knowledge about the types of objects.\nIn the early nineties EPISTLE started an activity to extend Annex M to become a library of such object classes and their relationships: STEPlib. In the STEPlib activities a group of approx. 100 domain experts from all three member consortia, spread over the various expertises (e.g. Electrical, Piping, Rotating equipment, etc.), worked together to define the \"core classes\".\n\nThe development of STEPlib was extended with many additional classes and relationships between classes and published as Open Source data. Furthermore, the concepts and relation types from the AP221 and ISO 15926-2 data models were also added to the STEPlib dictionary. This resulted in the development of Gellish English, whereas STEPlib became the Gellish English dictionary. Gellish English is a structured subset of natural English and is a modeling language suitable for knowledge modeling, product modeling and data exchange. It differs from conventional modeling languages (meta languages) as used in information technology as it not only defines generic concepts, but also includes an English dictionary. The semantic expression capability of Gellish English was significantly increased by extending the number of relation types that can be used to express knowledge and information.\n\nFor modelling-technical reasons POSC/Caesar proposed another standard than ISO 10303, called ISO 15926. EPISTLE (and ISO) supported that proposal, and continued the modelling work, thereby writing Part 2 of ISO 15926. This Part 2 has official ISO IS (International Standard) status since 2003.\n\nPOSC/Caesar started to put together their own RDL (Reference Data Library). They added many specialized classes, for example for ANSI (American National Standards Institute) pipe and pipe fittings. Meanwhile, STEPlib continued its existence, mainly driven by some members of USPI. Since it was clear that it was not in the interest of the industry to have two libraries for, in essence, the same set of classes, the Management Board of EPISTLE decided that the core classes of the two libraries shall be merged into Part 4 of ISO 15926. This merging process has been finished. Part 4 should act as reference data for part 2 of ISO 15926 as well as for ISO 10303-221 and replaced its Annex M. On June 5, 2007 ISO 15926-4 was signed off as a TS (Technical Specification).\n\nIn 1999 the work on an earlier version of Part 7 started. Initially this was based on XML Schema (the only useful W3C Recommendation available then), but when Web Ontology Language (OWL) became available it was clear that provided a far more suitable environment for Part 7. Part 7 passed the first ISO ballot by the end of 2005, and an implementation project started. A formal ballot for TS (Technical Specification) was planned for December 2007. However, it was decided then to split Part 7 into more than one part, because the scope was too wide.\n\nISO 15926 has eleven parts (as of June 2009):\n\n\nThe model and the library are suitable for representing lifecycle information about technical installations and their components.\n\nThey can also be used for defining the terms used in product catalogs in e-commerce. Another, more limited, use of the standard is as a reference classification for harmonization purposes between shared databases and product catalogues that are not based on ISO 15926.\n\nThe purpose of ISO 15926 is to provide a Lingua Franca for computer systems, thereby integrating the information produced by them. Although set up for the process industries with large projects involving many parties, and involving plant operations and maintenance lasting decades, the technology can be used by anyone willing to set up a proper vocabulary of reference data in line with Part 4.\n\nIn Part 7 the concept of Templates is introduced. These are semantic constructs, using Part 2 entities, that represent a small piece of information. These constructs then are mapped to more efficient classes of n-ary relations that interlink the Nodes that are involved in the represented information.\n\nIn Part 8 the data model of Part 2 is mapped to OWL, and so are, in concept, the Reference Data of Part 4 and the templates of Part 7. For validation and reasoning purposes all are represented in First-Order Logic as well.\n\nIn Part 9 these Node and Template instances are stored in Façades. A Façade is an RDF quad store, set up to a standard schema and an API. Any Façade only stores the data for which the Façade owner is responsible.\n\nEach participating computer system maps its data from its internal format to such ISO-standard Node and Template instances. These are stored in a System Façade, each system its own Façade.\n\nData can be \"handed over\" from one Façade to another in cases where data custodianship is handed over (e.g. from a contractor to a plant owner, or from a manufacturer to the owners of the manufactured goods). Hand-over can be for a part of all data, whilst maintaining full referential integrity.\n\nFaçades can be set up for the consolidation of data by handing over data produced by various participating computer systems and stored in their System Façades. Examples are: a Façade for a project discipline, a project, a plant).\n\nDocuments are user-definable. They are defined in XML Schema and they are, in essence, only a structure containing cells that make reference to instances of Templates. This represents a view on all lifecycle data: since the data model is a 4D (space-time) model, it is possible to present the data that was valid at any given point in time, thus providing a true historical record. It is expected that this will be used for Knowledge Mining.\n\nData can be queried by means of SPARQL. In any implementation a restricted number of Façades can be involved, with different access rights. This is done by means of creating a CPF Server (= Confederation of Participating Façades). An Ontology Browser allows for access to one or more Façades in a given CPF, depending on the access rights.\n\nThere are a number of projects working on the extension of the ISO 15926 standard in different application areas.\n\nWithin the application of Capital Intensive projects, some cooperating implementation projects are running:\n\n\nFinalised projects include:\n\n\nThe Norwegian Oil Industry Association (OLF) has decided to use ISO 15926 (also known as the Oil and Gas Ontology) as the instrument for integrating data across disciplines and business domains for the Upstream Oil and Gas industry. It is seen as one of the enablers of what has been called the next (or second) generation of Integrated operations, where a better integration across companies is the goal.\n\nThe following projects are currently running (May 2009):\n\n\nFinalised projects include:\n\n\nOne of the main requirements was (and still is) that the scope of the data model covers the entire lifecycle of a facility (e.g. oil refinery) and its components (e.g. pipes, pumps and their parts, etc.). Since such a facility over such a long time entails many different types of activities on a myriad of different objects it became clear that a generic and data-driven data model would be required.\n\nA simple example will illustrate this. There are thousands of different types of physical objects in a facility (pumps, compressors, pipes, instruments, fluids, etc). Each of these has many properties. If all combinations would be modelled in a \"hard-coded\" fashion, the number of combinations would be staggering, and unmanageable.\n\nThe solution is a \"template\" that represents the semantics of: \"This object has a property of X yyyy\" (where yyyy is the unit of measure). Any instance of that template refers to the applicable reference data:\n\nWithout being able to make reference to those classes, via the Internet, it will be impossible to express this information.\n\n"}
{"id": "203614", "url": "https://en.wikipedia.org/wiki?curid=203614", "title": "Information mapping", "text": "Information mapping\n\nInformation mapping is a research-based method for writing clear and user focused information, based on the audience's needs and the purpose of the information. The method is applied primarily to designing and developing business and technical communications. It is used as a content standard within organizations throughout the world.\n\nThe information mapping method is a research-based methodology used to analyze, organize and present information based on an audience's needs and the purpose of the information. The method applies to all subject matter and media technology. Information mapping has close ties to information visualization, information architecture, graphic design, information design, data analysis, experience design, graphic user interface design, and knowledge management systems.\n\nInformation mapping provides a number of tools for analyzing, organizing and presenting information.\n\nSome of Robert E. Horn's best-known work was his development of the theory of information types. Horn identified six types of information that account for nearly all the content of business and technical communications. The types categorize elements according to their purpose for the audience:\nThe information mapping method proposes six principles for organizing information so that it is easy to access, understand, and remember:\nDocuments written according to information mapping have a modular structure. They consist of clearly outlined information units (\"maps\" and \"blocks\") that take into account how much information a reader is able to assimilate.\n\nThere is an essential difference between an information unit and the traditional text paragraph. A \"block\" is limited to a single topic and consists of a single type of information. Blocks are grouped into \"maps\", and each map consists only of relevant blocks. The hierarchical approach to structuring information greatly facilitates electronic control of content via content management systems and knowledge management systems.\n\nThe information mapping method offers advantages to writers and readers, as well as to an entire organization.\n\nInformation mapping offers these advantages for writers:\n\nInformation mapping offers these advantages for readers:\n\nAlso an entire organization can benefit from using a content standard like information mapping if the method is used with the following objectives in mind:\n\nInformation mapping was developed in the late 20th century by Robert E. Horn, a researcher in the cognitive and behavioral sciences. Horn was interested in visual presentation of information to improve accessibility, comprehension and performance. Horn's development of the information mapping method has won him recognition from the International Society for Performance Improvement and the Association for Computing Machinery.\n\nMany independent studies have confirmed that applying the information mapping method to business and technical communications results in quicker, easier access to information, improved comprehension and enhanced performance. It also facilitates repurposing for publication in different formats.\n\nDoubts have been raised over the strength of the research Horn uses to justify some of his principles. For instance, his chunking principle requires lists, paragraphs, sub-sections and sections in a document to contain no more than 7±2 chunks of information. Horn does not state where he got this principle, but an Information Mapping website stated that the principle is \"based on George A. Miller's 1956 research\". Miller did write a paper in 1956 called \"The Magical Number Seven, Plus or Minus Two: Some Limits on our Capacity for Processing Information\", but its relevance to writing is tenuous. Miller himself said that his research had nothing to do with writing. Insisting that lists, paragraphs, sub-sections and sections throughout a document contain no more than 7±2 chunks of information paradoxically assumes that the size of what is not read in a document can influence a reader's ability to comprehend what they do read.\n\n\n"}
{"id": "49366750", "url": "https://en.wikipedia.org/wiki?curid=49366750", "title": "International Society for Technology in Education", "text": "International Society for Technology in Education\n\nThe International Society for Technology in Education (ISTE) is a nonprofit organization that serves educators interested in the use of technology in education. ISTE serves more than 100,000 education stakeholders throughout the world through individual and organizational membership and support services. ISTE provides educational technology resources to support professional learning for educators and education leaders, including the \"ISTE Conference & Expo\"—a worldwide comprehensive ed tech event, and the widely adopted \"ISTE Standards for learning, teaching and leading with technology\". ISTE also provides a suite of professional learning resources to members, including webinars, online courses, consulting services, books, and peer-reviewed journals and publications.\n\nISTE is probably best known for its annual conference (called the ISTE Conference & Expo). The annual conference serves as a forum for exploring and exchanging ideas about education technology with educators from around the world. The event attracts more than 24,000 educators and education leaders, and includes keynote speakers, hundreds of sessions, and a massive expo where vendors can show off the latest ed tech products and services. Recent conferences have been held in Chicago, IL (2018), San Antonio, TX (2017), Denver, CO (2016) Philadelphia, PA (2015) and Atlanta, GA (2014).\n\nThe 2019 conference will be held in Philadelphia, Pennsylvania, June 23–26, 2019. See ISTE Conference 2019 for more information.\n\nThe ISTE Standards (formerly \"National Educational Technology Standards\", NETS) are a framework for implementing digital strategies in education to positively impact learning, teaching and leading. Along with the standards themselves, ISTE offers information and resources to support understanding and implementation of the standards at a variety of levels. See ISTE Standards.\n\nISTE actively advocates for education technology at the local and national levels to advance the global transformation of education through the application of technology to education. We work with educators and policy makers at all levels to try to ensure that all learners have equal access to tools, connectivity and skills needed for success in using technology. See ISTE Advocacy.\n\nISTE membership is extended to individuals, affiliates (organizations, like school districts and state technology organizations), and corporate members interested in the use and application of technology in Education.\n\nIn addition to an individual membership of over 20,000, ISTE has several corporate members, including:\n\nAdobe, Apple, Best Buy, BrainPOP, Canon U.S.A., CDW-G, Cisco Systems, Dell, Google, LEGO Education, Microsoft, Pearson, PowerSchool, SMART Technologies, Summit Learning, the Verizon Foundation, and more\n\nThe International Council for Computers in Education (ICCE) was founded in 1979, with David Moursund as executive officer and editor-in-chief of the organization's organ \"The Computing Teacher\". In 1989 ICCE changed its name to the present name, International Society for Technology in Education (ISTE). Shortly after, in 1990, The \"Computing Teacher\" was retitled \"Learning and Leading with Technology\".\n\n"}
{"id": "7983699", "url": "https://en.wikipedia.org/wiki?curid=7983699", "title": "Knowledge divide", "text": "Knowledge divide\n\nThe knowledge divide is the gap in standards of living between those who can find, create, manage, process, and disseminate information or knowledge, and those who are impaired in this process. According to a 2005 UNESCO World Report, the rise in the 21st century of a global information society has resulted in the emergence of knowledge as a valuable resource, increasingly determining who has access to power and profit. The rapid dissemination of information on a potentially global scale as a result of new information media and the globally uneven ability to assimilate knowledge and information has resulted in potentially expanding gaps in knowledge between individuals and nations.\n\nIn the 21st century, the emergence of the knowledge society becomes pervasive. The transformations of world's economy and of each society have a fast pace. Together with information and communication technologies (ICT) these new paradigms have the power to reshape the global economy. In order to keep pace with innovations, to come up with new ideas, people need to produce and manage knowledge. This is why knowledge has become essential for all societies.\n\nAccording to UNESCO and the World Bank, knowledge gaps between nations may occur due to the varying degrees by which individual nations incorporate the following elements:\n\n\nThe information and ICT systems that support knowledge are very important. This is why digitization is viewed closely related to knowledge. Scientists generally agree that there is a digital divide, recently different reports also showed the existence of knowledge divide.\n\nThe creation and effective use of knowledge are increasingly related to the development of an ICT infrastructure. Without ICT, it is impossible to have an infrastructure able to process the huge flow of information required in an advanced economy. In particular, without adequate technical support, it is difficult to develop and use e-learning and electronic documents to overcome time and space constraints.\n\nThe digital divide is, however, but one important part of the larger knowledge divide. As UNESCO states, \"closing the digital divide will not suffice to close the knowledge divide, for access to useful, relevant knowledge is more than simply a matter of infrastructure—it depends on training, cognitive skills and regulatory frameworks geared towards access to contents.\"\n\nIn the book Digital Dead End, Virginia Eubanks criticizes the way that the digital divide is generally thought of as a division between haves and have-nots, where the solution is distribution. This over simplistic depiction obscures the fact that often social and structural inequality is at the root of the divide. According to a study done by Eubanks with women of the YWCA, the women of the community \"insisted that have-nots possess many different kinds of crucial information and skills.\" In other words, it is not simply knowledge of the technology itself that is the issue but the structural system based on perpetuating the status quo in which the haves \"hoard\" knowledge.\n\nFirst, it was noticed that a great difference exists between the North and the South (rich countries vs. poor countries). The development of knowledge depends on spreading Internet and computer technology and also on the development of education in these countries. If a country has attained a higher literacy level then this will result in having higher level of knowledge.\nIndeed, UNESCO's report details many social issues in knowledge divide related to globalization. There was noticed a knowledge divide with respect to\n\n\n\n"}
{"id": "45358106", "url": "https://en.wikipedia.org/wiki?curid=45358106", "title": "LTE in unlicensed spectrum", "text": "LTE in unlicensed spectrum\n\nLTE in unlicensed spectrum (LTE-Unlicensed): The commercial success of the Long Term Evolution (LTE) and the resulting growth in mobile data demand have urged cellular network operators to strive for new innovations. LTE in unlicensed spectrum has been proposed to allow cellular network operators to offload some of their data traffic by accessing the unlicensed 5 GHz frequency band. LTE-Unlicensed is a proposal, originally developed by Qualcomm, for the use of the 4G LTE radio communications technology in unlicensed spectrum, such as the 5 GHz band used by 802.11a and 802.11ac compliant Wi-Fi equipment. It would serve as an alternative to carrier-owned Wi-Fi hotspots. Currently, there are number of variants of LTE operation in the unlicensed band, namely LTE-U, Licensed Spectrum Access (LAA), and MulteFire. \n\nCurrently, only T-Mobile supports it in selected areas in the US, and AIS supports for some areas in Bangkok, and the only devices supporting it are smartphones that using Qualcomm Snapdragon 820, 821, 835 and 845 processor with X12 LTE modem, Exynos 9 Series 8895/9810 processor. or using Skyworks model SKY662xx-xx/SKY663xx-xx/SKY781xx-xx modem.\n\nThe first version of LTE-Unlicensed is called LTE-U and is developed by the LTE-U Forum to work with the existing 3GPP Releases 10/11/12. LTE-U was designed for quick launch in countries, such as the United States and China, that do not mandate implementing the listen-before-talk (LBT) technique. LTE-U would allow cellphone carriers to boost coverage in their cellular networks, by using the unlicensed 5 GHz band already populated by Wi-Fi devices. \n\nLTE-U is intended to let cell networks boost data speeds over short distances, without requiring the user to use a separate Wi-Fi network as they normally would. It differs from Wi-Fi calling; there remains a control channel using LTE, but all data (not just phone calls) flows over the unlicensed 5 GHz band, instead of the carrier's frequencies.\n\nIn 2014, the LTE-U Forum was created by Verizon, in conjunction with Alcatel-Lucent, Ericsson, Qualcomm, and Samsung as members. The forum collaborates and creates technical specifications for base stations and consumer devices passing LTE-U on the unlicensed 5 GHz band, as well as coexistence specs to handle traffic contention with existing Wi-Fi devices.\n\nT-Mobile and Verizon Wireless have indicated early interest in deploying such a system as soon as 2016. While cell providers ordinarily rely on the radio spectrum to which they have exclusive licenses, LTE-U would share space with Wi-Fi equipment already inhabiting that band – smartphones, laptops and tablets connecting to home broadband networks, free hotspots provided by businesses, and so on.\n\nAs of late 2018, all trial and commercial deployments of pre-standards LTE Forum LTE-U technology have been shut down or upgraded to the 3GPP Standard release 13 LTE-LAA.\n\nThe second variant of LTE-Unlicensed is Licensed Assisted Access (LAA) and has been standardized by the 3GPP in Rel-13. LAA adheres to the requirements of the LBT protocol, which is mandated in Europe and Japan. It promises to provide a unified global framework that complies with the regulatory requirements in the different regions of the world. \n\nEricsson uses the term License Assisted Access (LAA) to describe similar technology. LAA is the 3rd Generation Partnership Project's (3GPP) effort to standardize operation of LTE in the Wi-Fi bands. It uses a contention protocol known as listen-before-talk (LBT), mandated in some European countries, to coexist with other Wi-Fi devices on the same band.\n\nMulteFire is another variant of LTE in unlicensed bands and has been proposed as a standalone version of LTE for small cells. This variant will use only the unlicensed spectrum as the primary and only carrier, and it will provide an opportunity for neutral hosts to deploy LTE in the future. The idea of standalone operation of LTE in unlicensed bands was originally proposed by a small minority of vendors in 3GPP but rejected by the network operators who wanted the technology to be reliant on their licensed spectrum holdings. This technology is now developed by the MuLTEfire Alliance. \n\nThe proposed use of LTE-U by mobile phone network operators is the subject of controversy in the telecommunications industry. In June 2015, Google sent the Federal Communications Commission of the United States a 25-page protest, making an argument against LTE-U in highly technical detail. Since Google's study did not use actual LTE-U equipment in the tests, some industry experts have called its conclusions into question, with one commenter calling the study \"utterly artificial and speculative\" and \"embarrassing\".\n\nIn August 2015, the Wi-Fi Alliance and National Cable & Telecommunications Association (NCTA) also voiced opposition to LTE-U approval before more testing can be done, citing concerns that it would severely degrade performance of other Wi-Fi devices. Also in August 2015, Qualcomm responded to the allegations made in Google's whitepaper in a detailed filing with the FCC. Qualcomm stated that it conducted tests that were \"specifically designed to replicate (to the fullest extent possible) the test scenarios cited in Google’s FCC filing, in particular\", and that they \"collectively showed that LTE-U coexists very well with Wi-Fi when LTE-U is operating either above or below Wi-Fi’s Energy Detect ('ED') level.\" Qualcomm explained that the divergence in results was caused by the fact that \"the testing the opposing parties conducted for LTE-U/Wi-Fi coexistence below the ED level utilized extremely pessimistic and impractical technical assumptions\", whereas Qualcomm's tests were conducted \"using a far more realistic setup\", including actual LTE-U equipment (versus signal generators in Google's study).\n\nIn May 2016, the New York City Mayor's Office sent a letter to the FCC, 3GPP, Wi-Fi Alliance, and IEEE, expressing concern over LTE-U interference with Wi-Fi, given the City's broad investment in the technology. These concerns were discussed at a public event.\n\nIn June 2016 the Wi-Fi Alliance announced its co-existence test plan would be ready in August. In FCC filings, Qualcomm, Verizon and T-Mobile said they plan to use this plan, some with the aim of full implementation before the end of 2016. However, in August 2016, Qualcomm demurred. “The latest version of the test plan released by the Wi-Fi Alliance lacks technical merit, is fundamentally biased against LTE-U, and rejects virtually all the input that Qualcomm provided for the last year, even on points that were not controversial,” said Dean Brenner, senior vice president of government affairs. Qualcomm asserts that the plan biased in favor of Wi-Fi, and also that the testing regimen is extended to cover not just LTE-U, but also LAA, despite it already being a 3GPP standard. Verizon also opposed the test plan, saying it was \"fundamentally unfair and biased\".\n\nIn November 2016 Verizon, separate to the Wi-Fi Alliance coexistence plan, filed a Special Temporary Authority (STA) application with the FCC to test 40 small cells in the 5Ghz band. According to a separate filing, Verizon will conduct the tests in Oklahoma City, Raleigh and Cary, North Carolina, and Irving, Texas.\n\nIn February 2017, the FCC approved the use of LTE-U on base stations manufactured by Ericsson and Nokia.\n\nAs of June 26, 2017, T-Mobile declared that they have successfully launched LTE-U in Bellevue, Washington; Brooklyn, New York; Dearborn, Michigan; Las Vegas, Nevada; Richardson, Texas; and Simi Valley, California. More are rolling out this year.\n\n"}
{"id": "52308828", "url": "https://en.wikipedia.org/wiki?curid=52308828", "title": "List of Fitbit products", "text": "List of Fitbit products\n\n\"This page contains a list of products Fitbit has released.\"\n\nAnnounced on September 17, 2012, the Fitbit Zip is about the size of a United States quarter and tracks steps taken, distance traveled and calories burned. It is able to sync its data wirelessly to supported mobile devices.\n\nReleased in 2017. It is waterproof and can track swimming. The tracker can be worn in a wristband or pendant, or carried in a pocket. The LED lights function similar to the original Flex, with the number of illuminated dots indicating progress toward the set goal. It features \"reminder to move\" alerts and vibrations when a call or text is received.\n\nThe Fitbit Alta was released in February 2016. The wristband offers a full OLED screen that can be tapped for reminders, a clock and smartphone notifications. While not a touch screen, it is interacted with by tapping the band, similar to previous models. The Alta is also able to recognize the type of activity in progress: running, football or walking. \n\nThe Fitbit Alta HR was released in March 2017. It has an added heart rate monitor. It includes the new Sleep Stages feature, which intends to show the stages of sleep, rather than just time asleep as in previous versions. \n\nReleased in 2018, the Fitbit Ace is a variant of the Alta for children 8+ years of age.\n\nThe Fitbit Charge 3 was released in October 2018. It has a heart rate sensor as well as an oxygen saturation (SPO2) sensor. Sleep tracking has been improved from the Charge 2.\nIn November 2018, a special edition of the Fitbit Charge 3 was released featuring \"Fitbit Pay\" as a special feature.\n\nThe Fitbit Ionic was released in late September 2017. Designed to compete with the Apple Watch Series 3, it is the successor to both the Blaze and the Surge. Like the Surge, the Ionic uses built-in GPS, using GLONASS to tap into global satellites and provide better accuracy when recording exercises, with the antenna being integrated into the watch case for a stronger connection. The Ionic also features SmartTrack, which auto-recognizes user activity and records it in the Fitbit app. The Ionic has interchangeable bands, including classic Fitbit bands, leather bands, and perforated bands for a more sport-like appearance, and the release mechanism has been modified to make swapping out bands easier. It is also water-resistant, making it safe to wear when swimming. Many of the Blaze's clock faces return, as do several new clock faces. New to the Ionic is the ability to load apps onto the watch itself such as AccuWeather and Starbucks, as well as an NFC chip that allows the Ionic to be used for credit card purchases at places that allow contactless payment. As a result, the tactile buttons on the Ionic have some new functions. When not in workout mode, the right side buttons now function as shortcuts for the leftmost two apps loaded onto the watch, while a long press on the left side button brings up Fitbit Pay as well as music and quick settings. The Ionic is shipped in three color combinations of the wristband and watch case: Charcoal & Smoke Gray, Slate Blue & Burnt Orange, and Blue Gray & Silver Gray.\n\nIn 2018, the Ionic was updated to Fitbit OS 2.0 alongside the release of the Versa. The most notable change from OS 1.0 is the addition of a new app called Fitbit Today, a much more intuitive and informative dashboard displaying the user's health and fitness data. It is accessible by swiping up from the clock face, while the notification tray is now accessed by swiping down from the clock face. In addition, a long press on the back button now opens up the music controls, payments, and the shortcuts screen, instead of just Fitbit Pay. In July 2018, Fitbit announced the 15+ Best Fitbit OS Apps for Travel, that can be downloaded in Ionic and some are also available in Versa.\n\nReleased in April 2018, it has a square design with round edges, similar to the Apple Watch and Pebble watches. It retains most of the Ionic's features and interface. It is capable of tracking women's menstrual cycles. It does not have built-in GPS like the Ionic, instead using connected GPS like the Blaze. \n\nThere are two variants of the Versa; the standard edition and the Special Edition. The standard Versa comes in three colors: Black, Rose Gold, and Silver. The Special Edition comes in two colors: Rose Gold with a Lavender band, and Graphite with a Charcoal band. They also include woven wristbands.\n\nThe Aria 2 was announced in August 2017 concurrently with the Ionic. The Aria 2 has been re-engineered for greater accuracy and easier Bluetooth setup. The Aria 2 also has personalized face icons and greetings, compatibility with more Wi-Fi networks, and has an increased weight tolerance of up to 400 pounds.\n\nSweatproof wireless earphones by Fitbit. Has noise isolation.\n\nThe Fitbit Tracker was a small black and teal device that could be clipped discreetly onto clothing and worn 24/7. It uses a three-dimensional accelerometer to sense user movement. The Tracker measures steps taken and combines it with user data to calculate distance walked, calories burned, floors climbed and activity duration and intensity. It uses an OLED display to display this and other information such as the battery level. It also measures sleep quality by tracking periods of restlessness, how long it takes the wearer to fall asleep and how long they are actually asleep.\n\nA wireless base station is included to receive data from the Tracker and to charge its battery. When connected to a computer, the base station will upload data to the Fitbit website, where a number of features are available: seeing an overview of physical activity, setting and tracking goals, keeping food and activity logs and interacting with friends. Use of the website is free.\n\nThe Fitbit Classic tracked only steps taken, distance traveled, calories burned, activity intensity and sleep.\n\nAt the TechCrunch50 during the \"Mobile\" session on September 9, 2008, Fitbit received positive reactions during its panel from experts like Rafe Needleman, Tim O'Reilly, and Evan Williams who cited its wearability, price, and lack of subscription fees.\n\nThe Fitbit Ultra was announced on October 3, 2011. The new features included:\n\n\nThe Fitbit Ultra is powered by a small lithium polymer battery.\n\nThe Fitbit Ultra suffered from a small design flaw: the unit had a permanently curved shape in order to clip directly onto any piece of clothing. The plastic used in the unit was not appropriate for the strain experienced at the looped end, and with time would become brittle, and crack. While most users experienced only minor cracking with no effects to the device's function, in a few cases the cracking led to total failure. Fitbit offered replacement or repair of affected units that were under warranty.\n\nAnnounced on September 17, 2012, the Fitbit One is an update to the Fitbit Ultra that uses a more vivid digital display, has a separate clip and a separate charging cable and wireless sync dongle. The Fitbit One and the Fitbit Zip were the first wireless activity trackers to sync using Bluetooth 4.0 or Bluetooth SMART technology. The wireless syncing is currently available on iOS and Android devices such as the iPhone 4S and higher, iPad 3rd generation, iPod touch 5th generation, Samsung Galaxy Note II and higher, Samsung Galaxy S III and higher, LG G2, HTC One, Moto X, and Nexus 4 or higher. Fitbit One can record several daily activities, including but not limited to, number of steps taken, distance traveled on foot, number of floors climbed, calories burned, vigorously active minutes, and sleep efficiency.\n\nIn May 2013, Fitbit released the Fitbit Flex, the first Fitbit tracker worn on the wrist. It tracks movement 24 hours a day, including sleep patterns. It has a simple display of 5 LED lights that indicate the progress toward the goal number of steps walked in a day and vibrates to indicate when the goal has been reached. The sync functions are similar to the Fitbit One and Zip. The Flex is the most water-resistant tracker, though cannot be worn while swimming. It includes a specialized USB charger; the battery lasts 5–7 days, and it takes 1–2 hours to charge.\n\nThe Fitbit Force was announced on October 10, 2013. It has an OLED display that shows time and daily activity. The Force tracks a number of statistics in real-time, including steps taken, distance traveled, calories burned, stairs climbed and active minutes throughout the day. At night, the Force tracks sleep and can wake a user silently with a vibrating alarm.\n\nOn January 13, 2014 it was reported that an unconfirmed number of Fitbit customers had complained about skin irritation after wearing the Force for extended periods of time. Fitbit stated on its website that the company consulted with medical professionals whose assessments are that these irritations are most likely allergic reactions to nickel, a component of the surgical-grade steel or the adhesives used to assemble the Fitbit Force. Fitbit, working with the Consumer Protection Safety Commission, recalled the Fitbit Force on February 20, 2014. On March 12, 2014 the Consumer Product Safety Commission (CPSC) made the recall official. At that time it was revealed that The Fitbit Force had caused about 9,900 injuries. It is no longer for sale on Fitbit's website.\n\nAnnounced in October 2014, the Fitbit Charge is intended as a replacement for the recalled Fitbit Force. It was released in November 2014 for US$130 retail. The Charge's wrist band is textured and has a screen that can display caller ID information from a connected smartphone through the Fitbit app. The Charge automatically tracks users' steps, sleep, flights of stairs (using an altimeter) and an approximation of distance traveled. It tracks steps using a 3 axis accelerometer by tracking forward movement along with upward movements.\n\nAnnounced in October 2014 and released in early January 2015, the Charge HR is similar to the Charge, with an additional heart-rate monitor. With this addition, the 7-day battery life is reduced to 5 days. The Charge HR has the same textured band as the Charge and comes in black, plum, blue, tangerine, pink, and teal colors. The Charge HR band clasp resembles that of a traditional watch instead of the snap-on band of the original Charge, as the band needs to fit tightly for the heart rate feature.\n\nThe Fitbit Charge 2 featured a new multi-sport mode allowing users to start workouts from their Fitbit. Compared to its predecessor it had a larger screen.\n\nAnnounced in October 2014, the Surge was a smartwatch and an activity tracker. It features a heart-rate monitor and the ability to track pace, distance, and elevation using the GPS on the device. The Surge also can send alerts of text and incoming calls from a connected smartphone.\n\nThe Surge was discontinued in late 2017.\n\nReleased in January 2016 the Fitbit Blaze is a smartwatch made to compete with the Apple Watch, Pebble, and Android Wear. The Blaze comes with a colored touchscreen, and exchangeable strap and frame. It can auto-tracking exercises and has a heart-rate monitor. Blaze has connected GPS, meaning it tracks location using the connected smartphone's GPS. It can display notifications, including incoming calls, texts and calendar appointments. The Blaze introduces the Sleep Stages feature.\n\nThe Fitbit Blaze also integrates with Fitstar, Fitbit's website for customized workouts. These workouts can be displayed on the Blaze's screen.\n\nThe Blaze was discontinued in early 2018.\n\nIn April 2012, Fitbit released a weighing scale called the Fitbit Aria. It recognizes users and measures weight, body mass index (BMI) and percentage of body fat of the user. It can keep track of eight individual users and updates information to fitbit.com automatically via Wi-Fi network. The information is also updated to smartphone apps.\n\n"}
{"id": "38060737", "url": "https://en.wikipedia.org/wiki?curid=38060737", "title": "List of highest airports", "text": "List of highest airports\n\nThis is a list of the world's highest civilian airports, situated at a minimum elevation of above mean sea level.\n"}
{"id": "8441254", "url": "https://en.wikipedia.org/wiki?curid=8441254", "title": "Missile Row", "text": "Missile Row\n\nMissile Row was a nickname given in the 1960s to the US Air Force and NASA launch complexes at Cape Canaveral Air Force Station (CCAFS). Operated by the 45th Space Wing of the U.S. Air Force since 1949, it was the site of all pre-Apollo 8 manned launches, as well as many other early Department of Defense (DoD) and NASA launches. For the DoD, it plays a secondary role to Vandenberg AFB in California, but is the launch site for many NASA unmanned space probes, as those spacecraft are typically launched on Air Force launchers. Active launch vehicles are in bold.\n\nMuch of the support activity for CCAFS occurs at Patrick Air Force Base to the south, its reporting base.\n\nSome of the launch complexes have been recommissioned for modern space vehicle launches.\n"}
{"id": "21815281", "url": "https://en.wikipedia.org/wiki?curid=21815281", "title": "Mobile community", "text": "Mobile community\n\nA mobile community is a group of people generally united by shared interests or goals who interact: \n\n\n"}
{"id": "25208936", "url": "https://en.wikipedia.org/wiki?curid=25208936", "title": "Mobile technology", "text": "Mobile technology\n\nMobile technology is the technology used for cellular communication. Mobile code-division multiple access (CDMA) technology has evolved rapidly over the past few years. Since the start of this millennium, a standard mobile device has gone from being no more than a simple two-way pager to being a mobile phone, GPS navigation device, an embedded web browser and instant messaging client, and a handheld gaming console. Many experts believe that the future of computer technology rests in mobile computing with wireless networking. Mobile computing by way of tablet computers are becoming more popular. Tablets are available on the 3G and 4G networks.\n\nIn the early 1980s, 1G was introduced as voice-only communication via \"brick phones\". Later in 1991, the development of 2G introduced Short Message Service (SMS) and Multimedia Messaging Service (MMS) capabilities, allowing picture messages to be sent and received between phones. In 1998, 3G was introduced to provide faster data-transmission speeds to support video calling and internet access. 4G was released in 2008 to support more demanding services such as gaming services, HD mobile TV, video conferencing, and 3D TV. 5G technology has been planned for the upcoming future.\n\n4G is the current mainstream cellular service offered to cell phone users, performance roughly 10 times faster than 3G service. One of the most important features in the 4G mobile networks is the domination of high-speed packet transmissions or burst traffic in the channels. The same codes used in the 2G-3G networks are applied to 4G mobile or wireless networks, the detection of very short bursts will be a serious problem due to their very poor partial correlation properties. Recent study has indicated that traditional multilayer network architecture based on the Open Systems Interconnection (OSI) model may not be well suited for 4G mobile network, where transactions of short packets will be the major part of the traffic in the channels. As the packets from different mobiles carry completely different channel characteristics, the receiver should execute all necessary algorithms, such as channel estimation, interactions with all upper layers and so on, within a very short period of time.\n\nMany types of mobile operating systems (OS) are available for smartphones, including Android, BlackBerry OS, webOS, iOS, Symbian, Windows Mobile Professional (touch screen), Windows Mobile Standard (non-touch screen), and Bada. The most popular are the Apple iPhone, and the newest: Android. Android, a mobile OS developed by Google, is the first completely open-source mobile OS, meaning that it is free to any cell phone mobile network.\n\nSince 2008 customizable OSs allow the user to download apps like games, GPS, utilities, and other tools. Users can also create their own apps and publish them, e.g. to Apple's App Store. The Palm Pre using webOS has functionality over the Internet and can support Internet-based programming languages such as Cascading Style Sheets (CSS), HTML, and JavaScript. The Research In Motion (RIM) BlackBerry is a smartphone with a multimedia player and third-party software installation. The Windows Mobile Professional Smartphones (Pocket PC or Windows Mobile PDA) are like personal digital assistants (PDA) and have touchscreen abilities. The Windows Mobile Standard does not have a touch screen but uses a trackball, touchpad, or rockers.\n\nThere will be a hit to file sharing, the normal web surfer would want to look at a new web page every minute or so at 100 kbs a page loads quickly. Because of the changes to the security of wireless networks users will be unable to do huge file transfers because service providers want to reduce channel use. AT&T claimed that they would ban any of their users that they caught using peer-to-peer (P2P) file sharing applications on their 3G network. It then became apparent that it would keep any of their users from using their iTunes programs. The users would then be forced to find a Wi-Fi hotspot to be able to download files. The limits of wireless networking will not be cured by 4G, as there are too many fundamental differences between wireless networking and other means of Internet access. If wireless vendors do not realize these differences and bandwidth limits, future wireless customers will find themselves disappointed and the market may suffer setbacks.\n\nIncreasing mobile technology use has changed how the modern family interacts with one another through technology. With the rise of mobile devices, families are becoming increasingly \"on-the-move\", and spend less time in physical contact with one another. However, this trend does not mean that families are no longer interacting with each other, but rather have evolved into a more digitized variant. A study has shown that the modern family actually learns better with usage of mobile media, and children are more willing to cooperate with their parents via a digital medium than a more direct approach. For example, family members can share information from articles or online videos via mobile devices and thus stay connected with one another during a busy day.\n\nThis trend is not without controversy, however. Many parents of elementary school-age children express concern and sometimes disapproval of heavy mobile technology use. Parents may feel that excessive usage of such technologies distracts children from \"un-plugged\" bonding experiences, and many express safety concerns about children using mobile media. While parents may have many concerns are, they are not necessarily anti-technology. In fact, many parents express approval of mobile technology usage if their children can learn something from the session. for example, through art or music tutorials on YouTube.\n\nThe next generation of smartphones will be context-aware, taking advantage of the growing availability of embedded physical sensors and data exchange abilities. One of the main features applying to this is that phones will start keeping track of users' personal data, and adapt to anticipate the information will need. All-new applications will come out with the new phones, one of which is an X-ray device that reveals information about any location at which the phone is pointed. Companies are developing software to take advantage of more accurate location-sensing data. This has been described as making the phone a virtual mouse able to click the real world. An example would be pointing the phone's camera at a building while having the live feed open, and the phone will show text with the image of the building, and save its location for use in the future.\n\nOmnitouch is a device via which apps can be viewed and used on a hand, arm, wall, desk, or any other everyday surface. The device uses a sensor touch interface, which enables the user to access all the functions through the use of the touch of a finger. It was developed at Carnegie Mellon University. This device uses a projector and camera worn on the user's shoulder, with no controls other than the user's fingers.\n"}
{"id": "30551191", "url": "https://en.wikipedia.org/wiki?curid=30551191", "title": "NCL Eclipse", "text": "NCL Eclipse\n\nNCL Eclipse is a plugin for Eclipse IDE aiming at supporting the development of Nested Context Language applications. NCL is the declarative standard language for ISDB-Tb (International System for Digital Broadcast Terrestrial Brazilian) and also is ITU-T standard for IPTV systems. NCL Eclipse was first developed by Laws Lab and it is currently jointly maintained by Laws and TeleMídia Labs.\n\n\"NCL Eclipse\" is free software, available at Brazilian Public Software Portal under GNU GPLv2 license.\n\nAs an Eclipse IDE plug-in NCL Eclipse can be easily integrated with others plug-ins---for instance, those supporting other ISDB-Tb and ITU-T standard languages (such as Lua and Java).\n\nThe first stable version of NCL Eclipse was named \"NCL Eclipse 1.0\". This version has included support to syntax highlighting, folding (which allows the author to hide parts of source code according with his needs), wizards to create simple documents, auto-formatting, document, marking error validation, contextual content suggestion and an outline view (which shows the document content as a tree). To provide the marking error validation, all NCL Eclipse versions uses the NCL Validator (validation framework of NCL documents). This first version was very well accepted by the community of NCL developers, which gave several feedbacks. The NCL Eclipse evolution is strongly based on these feedbacks.\n\nThe NCL Eclipse 1.1, 1.2, and 1.3 have focused mainly on fixing bugs from the previous version. The next big changes came with 1.4 version of NCL Eclipse. That version brings program visualization, media previews and hypertext navigation. Additionally, a new plug-in aimed to integrate NCL Eclipse with NCL Club was included in the same package. As pointed out before, the integration with NCL Club allows for beginners to start learning NCL based on real-world examples. The internationalization support for English, Spanish and Portuguese was also included in this version.\n\nThe latest stable, and current version, is \"NCL Eclipse 1.5\". This version contains some improvements in source code. As new feature, this version came with support to semi-automatic error correction and option to run the NCL document, provided by a virtual machine running the Ginga-NCL emulator.\n\n"}
{"id": "639115", "url": "https://en.wikipedia.org/wiki?curid=639115", "title": "Neolithic Revolution", "text": "Neolithic Revolution\n\nThe Neolithic Revolution, Neolithic Demographic Transition, Agricultural Revolution, or First Agricultural Revolution was the wide-scale transition of many human cultures during the Neolithic period from a lifestyle of hunting and gathering to one of agriculture and settlement, making an increasingly larger population possible. These settled communities permitted humans to observe and experiment with plants to learn how they grew and developed. This new knowledge led to the domestication of plants.\n\nArchaeological data indicates that the domestication of various types of plants and animals happened in separate locations worldwide, starting in the geological epoch of the Holocene around 12,500 years ago. It was the world's first historically verifiable revolution in agriculture. The Neolithic Revolution greatly narrowed the diversity of foods available, resulting in a downturn in human nutrition.\n\nThe Neolithic Revolution involved far more than the adoption of a limited set of food-producing techniques. During the next millennia it would transform the small and mobile groups of hunter-gatherers that had hitherto dominated human pre-history into sedentary (non-nomadic) societies based in built-up villages and towns. These societies radically modified their natural environment by means of specialized food-crop cultivation, with activities such as irrigation and deforestation which allowed the production of surplus food. Other developments found very widely are the domestication of animals, pottery, polished stone tools, and rectangular houses.\n\nThese developments, sometimes called the Neolithic package, provided the basis for centralized administrations and political structures, hierarchical ideologies, depersonalized systems of knowledge (e.g. writing), densely populated settlements, specialization and division of labour, more trade, the development of non-portable art and architecture, and property ownership. The earliest known civilization developed in Sumer in southern Mesopotamia (); its emergence also heralded the beginning of the Bronze Age.\n\nThe relationship of the above-mentioned Neolithic characteristics to the onset of agriculture, their sequence of emergence, and empirical relation to each other at various Neolithic sites remains the subject of academic debate, and varies from place to place, rather than being the outcome of universal laws of social evolution. The Levant saw the earliest developments of the Neolithic Revolution from around 10,000 BCE, followed by sites in the wider Fertile Crescent.\n\nThe term \"Neolithic Revolution\" was coined in 1923 by V. Gordon Childe to describe the first in a series of agricultural revolutions in Middle Eastern history. The period is described as a \"revolution\" to denote its importance, and the great significance and degree of change affecting the communities in which new agricultural practices were gradually adopted and refined.\n\nThe beginning of this process in different regions has been dated from 10,000 to 8,000 BC in the Fertile Crescent and perhaps 8000 BC in the Kuk Early Agricultural Site of Melanesia. This transition everywhere seems associated with a change from a largely nomadic hunter-gatherer way of life to a more settled, agrarian-based one, with the inception of the domestication of various plant and animal species—depending on the species locally available, and probably also influenced by local culture. Recent archaeological research suggests that in some regions such as the Southeast Asian peninsula, the transition from hunter-gatherer to agriculturalist was not linear, but region-specific.\n\nThere are several competing (but not mutually exclusive) theories as to the factors that drove populations to take up agriculture. The most prominent of these are:\n\nOnce agriculture started gaining momentum, around 9000 BC, human activity resulted in the selective breeding of cereal grasses (beginning with emmer, einkorn and barley), and not simply of those that would favour greater caloric returns through larger seeds. Plants with traits such as small seeds or bitter taste would have been seen as undesirable. Plants that rapidly shed their seeds on maturity tended not to be gathered at harvest, therefore not stored and not seeded the following season; years of harvesting selected for strains that retained their edible seeds longer.\n\nSeveral plant species, the \"pioneer crops\" or Neolithic founder crops, were identified by Daniel Zohary, who highlighted the importance of the three cereals, and suggested that domestication of flax, peas, chickpeas, bitter vetch and lentils came a little later. Based on analysis of the genes of domesticated plants, he preferred theories of a single, or at most a very small number of domestication events for each taxon that spread in an arc from the Levantine corridor around the Fertile Crescent and later into Europe. Gordon Hillman and Stuart Davies carried out experiments with wild wheat varieties to show that the process of domestication would have occurred over a relatively short period of between 20 and 200 years. Some of these pioneering attempts failed at first and crops were abandoned, sometimes to be taken up again and successfully domesticated thousands of years later: rye, tried and abandoned in Neolithic Anatolia, made its way to Europe as weed seeds and was successfully domesticated in Europe, thousands of years after the earliest agriculture. Wild lentils presented a different problem: most of the wild seeds do not germinate in the first year; the first evidence of lentil domestication, breaking dormancy in their first year, was found in the early Neolithic at Jerf el Ahmar (in modern Syria), and quickly spread south to the Netiv HaGdud site in the Jordan Valley. This process of domestication allowed the founder crops to adapt and eventually become larger, more easily harvested, more dependable in storage and more useful to the human population.\n\nSelectively propagated figs, wild barley and wild oats were cultivated at the early Neolithic site of Gilgal I, where in 2006 archaeologists found caches of seeds of each in quantities too large to be accounted for even by intensive gathering, at strata datable to c. 11,000 years ago. Some of the plants tried and then abandoned during the Neolithic period in the Ancient Near East, at sites like Gilgal, were later successfully domesticated in other parts of the world.\n\nOnce early farmers perfected their agricultural techniques like irrigation, their crops would yield surpluses that needed storage. Most hunter gatherers could not easily store food for long due to their migratory lifestyle, whereas those with a sedentary dwelling could store their surplus grain. Eventually granaries were developed that allowed villages to store their seeds longer. So with more food, the population expanded and communities developed specialized workers and more advanced tools.\n\nThe process was not as linear as was once thought, but a more complicated effort, which was undertaken by different human populations in different regions in many different ways.\n\nEarly agriculture is believed to have originated and become widespread in Southwest Asia around 10,000–9,000 BP, though earlier individual sites have been identified. The Fertile Crescent region of Southwest Asia is the centre of domestication for three cereals (einkorn wheat, emmer wheat and barley), four legumes (lentil, pea, bitter vetch and chickpea), and flax. Domestication was a slow process involving multiple sites for each crop.\n\nFinds of large quantities of seeds and a grinding stone at the paleolithic site of Ohalo II in the vicinity of the Sea of Galilee, dated to around 19,400 BP, has shown some of the earliest evidence for advanced planning of plant food consumption and suggests that humans at Ohalo II processed the grain before consumption. Tell Aswad is the oldest site of agriculture, with domesticated emmer wheat dated to 10,800 BP. Soon after came hulled, two-row barley found domesticated earliest at Jericho in the Jordan valley and Iraq ed-Dubb in Jordan. Other sites in the Levantine corridor that show the first evidence of agriculture include Wadi Faynan 16 and Netiv Hagdud. Jacques Cauvin noted that the settlers of Aswad did not domesticate on site, but \"arrived, perhaps from the neighbouring Anti-Lebanon, already equipped with the seed for planting\". In the Eastern Fertile Crescent, evidence of cultivation of wild plants has been found in Choga Gholan in Iran dated to 12,000 BP, suggesting there were multiple regions in the Fertile Crescent where domestication evolved roughly contemporaneously. The Heavy Neolithic Qaraoun culture has been identified at around fifty sites in Lebanon around the source springs of the River Jordan, but never reliably dated.\n\nNorthern China appears to have been the domestication center for foxtail millet (\"Setaria italica\") and broomcorn millet (\"Panicum miliaceum\") with evidence of domestication of these species approximately 8,000 years ago.<ref name=\"doi10.1093/aob/mcm048\"></ref> These species were subsequently widely cultivated in the Yellow River basin (7,500 years ago). Rice was domesticated in southern China later on. Soybean was domesticated in northern China 4,500 years ago. Orange and peach also originated in China. They were cultivated around 2500 BC.\nOn the African continent, three areas have been identified as independently developing agriculture: the Ethiopian highlands, the Sahel and West Africa. By contrast, Agriculture in the Nile River Valley is thought to have developed from the original Neolithic Revolution in the Fertile Crescent. \nMany grinding stones are found with the early Egyptian Sebilian and Mechian cultures and evidence has been found of a neolithic domesticated crop-based economy dating around 7,000 BP.\nUnlike the Middle East, this evidence appears as a \"false dawn\" to agriculture, as the sites were later abandoned, and permanent farming then was delayed until 6,500 BP with the Tasian and Badarian cultures and the arrival of crops and animals from the Near East.\n\nBananas and plantains, which were first domesticated in Southeast Asia, most likely Papua New Guinea, were re-domesticated in Africa possibly as early as 5,000 years ago. Asian yams and taro were also cultivated in Africa.\n\nThe most famous crop domesticated in the Ethiopian highlands is coffee. In addition, khat, ensete, noog, teff and finger millet were also domesticated in the Ethiopian highlands. Crops domesticated in the Sahel region include sorghum and pearl millet. The kola nut was first domesticated in West Africa. Other crops domesticated in West Africa include African rice, yams and the oil palm.\n\nAgriculture spread to Central and Southern Africa in the Bantu expansion during the 1st millennium BC to 1st millennium AD.\n\nMaize (corn), beans and squash were among the earliest crops domesticated in Mesoamerica, with maize beginning about 4000 BC, squash as early as 6000 BC, and beans by no later than 4000 BC. Potatoes and manioc were domesticated in South America. In what is now the eastern United States, Native Americans domesticated sunflower, sumpweed and goosefoot around 2500 BC. Sedentary village life based on farming did not develop until the second millennium BC, referred to as the formative period.\n\nEvidence of drainage ditches at Kuk Swamp on the borders of the Western and Southern Highlands of Papua New Guinea shows evidence of the cultivation of taro and a variety of other crops, dating back to 11,000 BP. Two potentially significant economic species, taro (\"Colocasia esculenta\") and yam (\"Dioscorea\" sp.), have been identified dating at least to 10,200 calibrated years before present (cal BP). Further evidence of bananas and sugarcane dates to 6,950 to 6,440 BP. This was at the altitudinal limits of these crops, and it has been suggested that cultivation in more favourable ranges in the lowlands may have been even earlier. CSIRO has found evidence that taro was introduced into the Solomon Islands for human use, from 28,000 years ago, making taro cultivation the earliest crop in the world. It seems to have resulted in the spread of the Trans–New Guinea languages from New Guinea east into the Solomon Islands and west into Timor and adjacent areas of Indonesia. This seems to confirm the theories of Carl Sauer who, in \"Agricultural Origins and Dispersals\", suggested as early as 1952 that this region was a centre of early agriculture.\n\nWhen hunter-gathering began to be replaced by sedentary food production it became more profitable to keep animals close at hand. Therefore, it became necessary to bring animals permanently to their settlements, although in many cases there was a distinction between relatively sedentary farmers and nomadic herders. The animals' size, temperament, diet, mating patterns, and life span were factors in the desire and success in domesticating animals. Animals that provided milk, such as cows and goats, offered a source of protein that was renewable and therefore quite valuable. The animal’s ability as a worker (for example ploughing or towing), as well as a food source, also had to be taken into account. Besides being a direct source of food, certain animals could provide leather, wool, hides, and fertilizer. Some of the earliest domesticated animals included dogs (East Asia, about 15,000 years ago), sheep, goats, cows, and pigs.\n\nThe Middle East served as the source for many animals that could be domesticated, such as sheep, goats and pigs. This area was also the first region to domesticate the dromedary. Henri Fleisch discovered and termed the Shepherd Neolithic flint industry from the Bekaa Valley in Lebanon and suggested that it could have been used by the earliest nomadic shepherds. He dated this industry to the Epipaleolithic or Pre-Pottery Neolithic as it is evidently not Paleolithic, Mesolithic or even Pottery Neolithic. The presence of these animals gave the region a large advantage in cultural and economic development. As the climate in the Middle East changed and became drier, many of the farmers were forced to leave, taking their domesticated animals with them. It was this massive emigration from the Middle East that would later help distribute these animals to the rest of Afroeurasia. This emigration was mainly on an east-west axis of similar climates, as crops usually have a narrow optimal climatic range outside of which they cannot grow for reasons of light or rain changes. For instance, wheat does not normally grow in tropical climates, just like tropical crops such as bananas do not grow in colder climates. Some authors, like Jared Diamond, have postulated that this East-West axis is the main reason why plant and animal domestication spread so quickly from the Fertile Crescent to the rest of Eurasia and North Africa, while it did not reach through the North-South axis of Africa to reach the Mediterranean climates of South Africa, where temperate crops were successfully imported by ships in the last 500 years. Similarly, the African Zebu of central Africa and the domesticated bovines of the fertile-crescent — separated by the dry sahara desert — were not introduced into each other's region.\n\nDespite the significant technological advance, the Neolithic revolution did not lead immediately to a rapid growth of population. Its benefits appear to have been offset by various adverse effects,\nmostly diseases and warfare.\n\nThe introduction of agriculture has not necessarily led to unequivocal progress. The nutritional standards of the growing Neolithic populations were inferior to that of hunter-gatherers. Several ethnological and archaeological studies conclude that the transition to cereal-based diets caused a reduction in life expectancy and stature, an increase in infant mortality and infectious diseases, the development of chronic, inflammatory or degenerative diseases (such as obesity, type 2 diabetes and cardiovascular diseases) and multiple nutritional deficiencies, including vitamin deficiencies, iron deficiency anemia and mineral disorders affecting bones (such as osteoporosis and rickets) and teeth. Average height went down from 5'10\" (178 cm) for men and 5'6\" (168 cm) for women to 5'5\" (165 cm) and 5'1\" (155 cm), respectively, and it took until the twentieth century for average human height to come back to the pre-Neolithic Revolution levels.\n\nThe traditional view is that agricultural food production supported a denser population, which in turn supported larger sedentary communities, the accumulation of goods and tools, and specialization in diverse forms of new labor. The development of larger societies led to the development of different means of decision making and to governmental organization. Food surpluses made possible the development of a social elite who were not otherwise engaged in agriculture, industry or commerce, but dominated their communities by other means and monopolized decision-making. Jared Diamond (in The World Until Yesterday) identifies the availability of milk and cereal grains as permitting mothers to raise both an older (e.g. 3 or 4 year old) and a younger child concurrently. The result is that a population can increase more rapidly. Diamond, in agreement with feminist scholars such as V. Spike Peterson, points out that agriculture brought about deep social divisions and encouraged gender inequality. \n\nAndrew Sherratt has argued that following upon the Neolithic Revolution was a second phase of discovery that he refers to as the secondary products revolution. Animals, it appears, were first domesticated purely as a source of meat. The Secondary Products Revolution occurred when it was recognised that animals also provided a number of other useful products. These included:\n\nSherratt argued that this phase in agricultural development enabled humans to make use of the energy possibilities of their animals in new ways, and permitted permanent intensive subsistence farming and crop production, and the opening up of heavier soils for farming. It also made possible nomadic pastoralism in semi arid areas, along the margins of deserts, and eventually led to the domestication of both the dromedary and Bactrian camel. Overgrazing of these areas, particularly by herds of goats, greatly extended the areal extent of deserts.\n\nLiving in one spot would have more easily permitted the accrual of personal possessions and an attachment to certain areas of land. From such a position, it is argued, prehistoric people were able to stockpile food to survive lean times and trade unwanted surpluses with others. Once trade and a secure food supply were established, populations could grow, and society would have diversified into food producers and artisans, who could afford to develop their trade by virtue of the free time they enjoyed because of a surplus of food. The artisans, in turn, were able to develop technology such as metal weapons. Such relative complexity would have required some form of social organisation to work efficiently, so it is likely that populations that had such organisation, perhaps such as that provided by religion, were better prepared and more successful. In addition, the denser populations could form and support legions of professional soldiers. Also, during this time property ownership became increasingly important to all people. Ultimately, Childe argued that this growing social complexity, all rooted in the original decision to settle, led to a second Urban Revolution in which the first cities were built.\n\nThroughout the development of sedentary societies, disease spread more rapidly than it had during the time in which hunter-gatherer societies existed. Inadequate sanitary practices and the domestication of animals may explain the rise in deaths and sickness following the Neolithic Revolution, as diseases jumped from the animal to the human population. Some examples of infectious diseases spread from animals to humans are influenza, smallpox, and measles. In concordance with a process of natural selection, the humans who first domesticated the big mammals quickly built up immunities to the diseases as within each generation the individuals with better immunities had better chances of survival. In their approximately 10,000 years of shared proximity with animals, such as cows, Eurasians and Africans became more resistant to those diseases compared with the indigenous populations encountered outside Eurasia and Africa. For instance, the population of most Caribbean and several Pacific Islands have been completely wiped out by diseases. 90% or more of many populations of the Americas were wiped out by European and African diseases before recorded contact with European explorers or colonists. Some cultures like the Inca Empire did have a large domestic mammal, the llama, but llama milk was not drunk, nor did llamas live in a closed space with humans, so the risk of contagion was limited. According to bioarchaeological research, the effects of agriculture on physical and dental health in Southeast Asian rice farming societies from 4000 to 1500 B.P. was not detrimental to the same extent as in other world regions.\n\nIn his book \"Guns, Germs, and Steel\", Jared Diamond argues that Europeans and East Asians benefited from an advantageous geographical location that afforded them a head start in the Neolithic Revolution. Both shared the temperate climate ideal for the first agricultural settings, both were near a number of easily domesticable plant and animal species, and both were safer from attacks of other people than civilizations in the middle part of the Eurasian continent. Being among the first to adopt agriculture and sedentary lifestyles, and neighboring other early agricultural societies with whom they could compete and trade, both Europeans and East Asians were also among the first to benefit from technologies such as firearms and steel swords.\nThe dispersal of Neolithic culture from the Middle East has recently been associated with the distribution of human genetic markers. In Europe, the spread of the Neolithic culture has been associated with distribution of the E1b1b lineages and Haplogroup J that are thought to have arrived in Europe from North Africa and the Near East respectively. In Africa, the spread of farming, and notably the Bantu expansion, is associated with the dispersal of Y-chromosome haplogroup E1b1a from West Africa.\n\n\n\n"}
{"id": "22053", "url": "https://en.wikipedia.org/wiki?curid=22053", "title": "Network effect", "text": "Network effect\n\nA network effect (also called network externality or demand-side economies of scale) is the positive effect described in economics and business that an additional user of a good or service has on the value of that product to others. When a network effect is present, the value of a product or service increases according to the number of others using it.\n\nThe classic example is the telephone, where a greater number of users increases the value to each. A positive externality is created when a telephone is purchased without its owner intending to create value for other users, but does so regardless. Online social networks work similarly, with sites like Twitter and Facebook increasing in value to each member as more users join.\n\nThe network effect can create a bandwagon effect as the network becomes more valuable and more people join, resulting in a positive feedback loop.\n\nThe expression \"network effect\" is applied to positive network externalities as in the case of the telephone. Negative network externalities can also occur, where more users make a product less valuable, but they are more commonly referred to as \"congestion\" (as in traffic congestion or network congestion).\n\nNetwork effects were a central theme in the arguments of Theodore Vail, the first post-patent president of Bell Telephone, in gaining a monopoly on US telephone services. In 1908, when he presented the concept in Bell's annual report, there were over 4,000 local and regional telephone exchanges, most of which were eventually merged into the Bell System.\n\nNetwork effects were popularized by Robert Metcalfe, stated as Metcalfe's law. Metcalfe was one of the co-inventors of Ethernet and a co-founder of the company 3Com. In selling the product, Metcalfe argued that customers needed Ethernet cards to grow above a certain critical mass if they were to reap the benefits of their network.\n\nAccording to Metcalfe, the rationale behind the sale of networking cards was that the cost of the network was directly proportional to the number of cards installed, but the value of the network was proportional to the square of the number of users. This was expressed algebraically as having a cost of N, and a value of N². While the actual numbers behind this proposition were never firm, the concept allowed customers to share access to expensive resources like disk drives and printers, send e-mail, and eventually access the Internet.\n\nThe economic theory of the network effect was advanced significantly between 1985 and 1995 by researchers Michael L. Katz, Carl Shapiro, Joseph Farrell and Garth Saloner. Author, high-tech entrepreneur Rod Beckstrom presented a mathematical model for describing networks that are in a state of positive network effect at BlackHat and Defcon in 2009 and also presented the \"inverse network effect\" with an economic model for defining it as well.\n\nNetwork effects become significant after a certain subscription percentage has been achieved, called critical mass. At the critical mass point, the value obtained from the good or service is greater than or equal to the price paid for the good or service. As the value of the good is determined by the user base, this implies that after a certain number of people have subscribed to the service or purchased the good, additional people will subscribe to the service or purchase the good due to the value exceeding the price.\n\nA key business concern must then be how to attract users prior to reaching critical mass. One way is to rely on extrinsic motivation, such as a payment, a fee waiver, or a request for friends to sign up. A more natural strategy is to build a system that has enough value \"without\" network effects, at least to early adopters. Then, as the number of users increases, the system becomes even more valuable and is able to attract a wider user base.\n\nBeyond critical mass, the increasing number of subscribers generally cannot continue indefinitely. After a certain point, most networks become either congested or saturated, stopping future uptake. Congestion occurs due to overuse. The applicable analogy is that of a telephone network. While the number of users is below the congestion point, each additional user adds additional value to every other customer. However, at some point the addition of an extra user exceeds the capacity of the existing system. After this point, each additional user decreases the value obtained by every other user. In practical terms, each additional user increases the total system load, leading to busy signals, the inability to get a dial tone, and poor customer support. Assuming the congestion point is below the potential market size, the next critical point is where the value obtained again equals the price paid. The network will cease to grow at this point if system capacity is not improved. Peer-to-peer (P2P) systems are networks designed to distribute load among their user pool. This theoretically allows P2P networks to scale indefinitely. The P2P based telephony service Skype benefits from this effect and its growth is limited primarily by market saturation.\n\nNetwork effects are commonly mistaken for economies of scale, which result from business size rather than interoperability. To help clarify the distinction, people speak of demand side vs. supply side economies of scale. Classical economies of scale are on the production side, while network effects arise on the demand side. Network effects are also mistaken for economies of scope. Because of the positive feedback often associated with the network effect, system dynamics can be used as a modelling method to describe the phenomena. Word of mouth and the Bass diffusion model are also potentially applicable.\n\nNetwork effect is a benefit to society as a whole because it positively relates to and affects the Intellectual Commons, Property Rights, and Cultural Commons of the world. One form of network externality is social media, which is a peer-to-peer network run by a privately held for profit business. Although the creation of a large network creates a barrier to entry according to Porters five forces and may prevent a few from creating a new form of P2P networking, it largely benefits society as whole and provides a new form of a common-pool resource so largely scalable that the entire world has the ability to use it. Although the barrier to entry may be high, there is no true form of monopoly in the P2P social sharing market. For example, Facebook holds a large stake in the P2P social sharing market, but it is not mutually exclusive, meaning users can have an account on Facebook and also have an account on Twitter. Furthermore, there becomes no true critical mass in this space due to the ability for technology and innovation to constantly adapt to different environments, market for underdeveloped countries to integrate with social sharing is unlimited.\n\nNetwork effect relates to the intellectual commons in a positive way. Through P2P networks users are able to share their intellectual property in a way that can benefit society as a whole.The sharing of intellectual property ultimately relates to economic growth due to the ability for creators to share information and still possibly benefit financially from it. Through P2P networks people are able to share types of education like scholarly articles, becoming a new form of public commons. Network externality like Ted.com is an example of how intellectual commons with the use of network externality benefits society as a whole. Those who present intellectual property at Ted conferences are sharing their education on a public forum that benefits whoever will listen. Therefore, the larger Ted.com network becomes positively correlates to those who benefit from its common-pool resources.\n\nP2P networks positively affect property rights. In reference to property rights, it enables those who create the intellectual property: The right to use the good, The right to earn income from the good, The right to transfer the good to others, The right to enforcement of property rights. Through P2P networks those who provide intellectual property not only have these rights, but they also possess the right to claim their information on a public forum. Due to these rights sharing benefits the intellectual property holders and promotes P2P sharing in a positive way. Those who consume the intellectual property also benefit positively from the sharing of it because they are able to use the information freely with respect to the person who created it. An example of this system in effect is a company called Music Vault. Music Vault operates on the P2P network Facebook, enabling users who create music to openly and freely collaborate with other artists content. This is a form of remixing that benefits both parties. This is an example of how a P2P network positively affects the sharing of property rights. In Joseph E. Stiglitz essay \"Prizes, Not Patents\", he suggests that the creation of intellectual property should be rewarded with by social gratification and rewards instead of patents preventing others from duplicating the creation and sharing it as a common-pool resource. This can be related to P2P networking because it creates a greater incentive for those who create intellectual property to share it is a common-pool resource. As a P2P sharing network becomes larger the gratification of being rewarded on a global public forum would compete with a patent. It is through large P2P networks and network externality that humans can create a reward system large enough to deter seekers of patents to be rewarded in different ways.\n\nNetwork Externality positively affects the cultural commons in many ways. The reward for being part of a group, society, and even the world through a P2P network is one of the greatest benefits that a modern common-pool resource can provide.The ability to connect and create with people from different cultures, ethnicities, and beliefs is something thought to be impossible 100 years ago. Without network externality this form of communication would have been impossible. Through P2P sharing the world as a culture are able to learn and teach each other through public forums. In Sugata Mitra’s Ted talk, “The child-driven education” he placed a computer in a third world town and left it there to see what would happen. To his amazement children were able to quickly figure out how to use the computer and educate themselves on its inner workings. This example is a benefit to society for several reasons. The first is the relationship between Sugata Mitra and the P2P network which led him to place the computer in a third world town, along with the ability to present his findings on a public forum. Secondly, it is those who consumed his ted talk and benefited from the knowledge that those in third world countries just need a chance to learn and they will take it. This experiment as a whole brings the culture of the world together and connects us with those we thought impossible due to the P2P network and network externality that led individuals to the Ted talk.\n\nIf some existing technology or company whose benefits are largely based on network effects starts to lose market share against a challenger such as a disruptive technology or open standards based competition, the benefits of network effects will reduce for the incumbent, and increase for the challenger. In this model, a tipping point is eventually reached at which the network effects of the challenger dominate those of the former incumbent, and the incumbent is forced into an accelerating decline, whilst the challenger takes over the incumbent's former position.\n\nNot surprisingly network economics became a hot topic after the diffusion of the Internet across academia. Most people know only of Metcalfe's law as part of network effects. Network effects are notorious for causing lock-in with the most-cited examples being Microsoft products and the QWERTY keyboard.\n\nVendor lock-in can be mitigated by opening the standards upon which users depend, allowing competition between implementations. This does not, however, mitigate industry-wide lock-in to the standard itself. Indeed, as there are now multiple vendors driving down the price and increasing the quality, more users are likely to adopt the standard thereby creating greater industry-wide lock-in to the standard.\n\nBroadly, there are two kinds of networks effects:\n\n\nAdditionally, there are two sources of economic value that are relevant when analyzing products that display network effects:\n\nNegative network externalities, in the mathematical sense, are those that have a negative effect compared to normal (positive) network effects. Just as positive network externalities (network effects) cause positive feedback loops and exponential growth, negative network externalities create negative feedback and exponential decay. In nature, negative network externalities are the forces that pull towards equilibrium, are responsible for stability, and are the physical limitations preventing states from reaching infinity.\n\n\nInteroperability has the effect of making the network bigger and thus increases the external value of the network to consumers. Interoperability achieves this primarily by increasing potential connections and secondarily by attracting new participants to the network. Other benefits of interoperability include reduced uncertainty, reduced lock-in, commoditization and competition based on price.\n\nInteroperability can be achieved through standardization or other cooperation. Companies involved in fostering interoperability face a tension between cooperating with their competitors to grow the potential market for products and competing for market share.\n\nIn communication and information technologies, open standards and interfaces are often developed through the participation of multiple companies and are usually perceived to provide mutual benefit. But, in cases in which the relevant communication protocols or interfaces are closed standards the network effect can give the company controlling those standards monopoly power. The Microsoft corporation is widely seen by computer professionals as maintaining its monopoly through these means. One observed method Microsoft uses to put the network effect to its advantage is called Embrace, extend and extinguish.\n\nMirabilis is an Israeli start-up which pioneered instant messaging (IM) and was bought by America Online. By giving away their ICQ product for free and preventing interoperability between their client software and other products, they were able to temporarily dominate the market for instant messaging. Because of the network effect, new IM users gained much more value by choosing to use the Mirabilis system (and join its large network of users) than they would using a competing system. As was typical for that era, the company never made any attempt to generate profits from their dominant position before selling the company.\n\nStock exchanges and derivatives exchanges feature a network effect. Market liquidity is a major determinant of transaction cost in the sale or purchase of a security, as a bid–ask spread exists between the price at which a purchase can be done versus the price at which the sale of the same security can be done. As the number of buyers and sellers on an exchange increases, liquidity increases, and transaction costs decrease. This then attracts a larger number of buyers and sellers to the exchange.\n\nThe network advantage of financial exchanges is apparent in the difficulty that startup exchanges have in dislodging a dominant exchange. For example, the Chicago Board of Trade has retained overwhelming dominance of trading in US Treasury bond futures despite the startup of Eurex US trading of identical futures contracts. Similarly, the Chicago Mercantile Exchange has maintained a dominance in trading of Eurobond interest rate futures despite a challenge from Euronext.Liffe.\n\nThere are very strong network effects operating in the market for widely used computer software.\n\nFor many people choosing an office suite, prime considerations include how much value having learned that office suite will prove to potential employers, and how well the software interoperates with other users. That is, since learning to use an office suite takes many hours, users want to invest that time learning the office suite that will make them most attractive to potential employers and clients, and they also want to be able to share documents. Similarly, finding already-trained employees is a big concern for employers when deciding which office suite to purchase or standardize on.\n\nIn 2007 Apple released the iPhone followed by the app store. Most iPhone apps rely heavily on the existence of strong network effects. This enables the software to grow in popularity very quickly and spread to a large userbase with very limited marketing needed. The Freemium business model has evolved to take advantage of these network effects by releasing a free version that will not limit the adoption or any users and then charge for \"premium\" features as the primary source of revenue.\n\nMany web sites benefit from a network effect. One example is web marketplaces and exchanges. For example, eBay would not be a particularly useful site if auctions were not competitive. However, as the number of users grows on eBay, auctions grow more competitive, pushing up the prices of bids on items. This makes it more worthwhile to sell on eBay and brings more sellers onto eBay, which drives prices down again as this increases supply, while bringing more people onto eBay because there are more things being sold that people want. Essentially, as the number of users of eBay grows, prices fall and supply increases, and more and more people find the site to be useful.\n\nNetwork effects were used as justification for some of the dot-com business models in the late 1990s. These firms operated under the belief that when a new market comes into being which contains strong network effects, firms should care more about growing their market share than about becoming profitable. This was believed because market share will determine which firm can set technical and marketing standards and thus determine the basis of future competition.\n\nSocial networking websites are good examples. The more people register onto a social networking website, the more useful the website is to its registrants.\n\nAlexa Internet uses a technology that tracks users' surfing patterns; thus Alexa's Related Sites results improve as more users use the technology. Alexa's network relies heavily on a small number of browser software relationships, which makes the network more vulnerable to competition.\n\nGoogle has also attempted to create a network effect in its advertising business with its Google AdSense service. Google AdSense places ads on many small sites, such as blogs, using Google technology to determine which ads are relevant to which blogs. Thus, the service appears to aim to serve as an exchange (or ad network) for matching many advertisers with many small sites (such as blogs). In general, the more blogs Google AdSense can reach, the more advertisers it will attract, making it the most attractive option for more blogs, and so on, making the network more valuable for all participants.\n\nBy contrast, the value of a news site is primarily proportional to the quality of the articles, not to the number of other people using the site. Similarly, the first generation of search sites experienced little network effect, as the value of the site was based on the value of the search results. This allowed Google to win users away from Yahoo! without much trouble, once users believed that Google's search results were superior. Some commentators mistook the value of the Yahoo! brand (which does increase as more people know of it) for a network effect protecting its advertising business.\n\nThere are strong network effects in the initial choice of rail gauge, and in gauge conversion decisions. Even when placing isolated rails not connected to any other lines, track layers usually choose a standard rail gauge so they can use off-the-shelf rolling stock. Although a few manufacturers make rolling stock that can adjust to different rail gauges, most manufacturers make rolling stock that only works with one of the standard rail gauges.\n\n"}
{"id": "55567666", "url": "https://en.wikipedia.org/wiki?curid=55567666", "title": "New Lab", "text": "New Lab\n\nNew Lab opened in June, 2016, as a multi-disciplinary technology center. Housed in Building 128 of the Brooklyn Navy Yard, the $35 million project serves as a hardware-focused shared workspace, research lab, and hatchery for socially-oriented tech manufacturing.\n\nUsing the MIT Media Lab as a model, the impetus for the independent organization was to provide space and services to new manufacturing enterprises. Current members work in fields such as robotics, connected devices, energy, nanotechnology, life sciences, and urban tech.\n\nMedia coverage of New Lab has focused on the company's role in revitalizing the Brooklyn Navy Yard, its public-private partnership lease structure, and Urban Tech initiative with the New York CIty Economic Development Corporation.\n\nDavid Belt and partner Scott Cohen formed the concept for New Lab in 2011 after prospecting the decaying Building 128 with Navy Yard president David Ehrenberg. The partners found the maritime manufacturing history of the structure, specifically the manufacturing innovations that took place there, synchronous with their aim to provide a platform for emerging hardware technologies in New York City. The city was abundant in resources and opportunities for entrepreneurs working in software, Belt said in a recent interview, but space, tools and resources for those working in the new manufacturing hardware community were lacking.\n\nBelt leveraged his development firm, Macro Sea, a company that specializes \"in bringing historic properties back into cultural relevance,\" to obtain funding, architectural expertise, and begin constructing a lease with the city of New York. The Navy Yard was in the initial stages of its current revitalization at the time and, because the city owned the property, special arrangements were needed to develop there.\n\nCohen began scouting the companies who would comprise their core members and helped work to capitalize them. To date, venture capitalists have invested approximately $250 million in New Lab and its members.\n\nThe land predating New Lab has a rich historical cultural lineage and narrative of experimental and innovative breakthroughs. That past was a major factor in the decision to develop New Lab in the Navy Yard. Before colonial settlement, the area that would become the Navy Yard served as a clamming site for the Lenape Native Americans. It was then settled by the Dutch and sold to a developer, thus beginning its employment as a center for manufacturing. Among the technological advancements that took place at the Navy Yard are: the first use of the steam-powered pile driver; construction of the first undersea telegraph cable; development of a commercialized form of anesthetic ether by E.R. Squibb; and a broadcast of the first woman to sing over the radio, opera singer Eugenia Farrar performed \"I Love You Truly.\"\n\nConstruction of navy ships like the Fulton II, a first-of-its-kind steam-powered warship, and fabrication of the USS Arizona, state-of-the-art among its peers, induced many influential manufacturing process refinements and advancements.\n\nIn interviews, Belt and Cohen both cite this maritime and technological history as inspiration for New Lab, both in guiding the renovation of the facility and in shaping its mission.\n\nAccording to a Brooklyn Navy Yard Development Corporation document,128 was raised in 1899 as a \"steel structure... used to assemble large boiler engines and fabricated sections of naval vessels.\" It served as the primary machine shop for every major ship launched during World Wars One and Two. Designed to accommodate the significant height of a warship, the sequence of its hulking steel girders resembles an airport hangar. 128 has been slated for, but avoided, plans for non-naval readaptation. The City of New York sought to adapt it for reuse as a \"food complex at one point,\" but the effort was not sustained.\n\nMarvel Architects, New Lab's architect of record, along with DBI, Belt's project management firm, worked together to craft and execute the renovation. Press regarding New Lab often states that the company occupies Building 128 of the Navy Yard, but this is slightly misleading in that 128 is a complex of warehouses and New Lab occupies the southernmost portion.\n\nRecladding the building's armature and repurposing of the 51,000 ft machine shop into an 84,000 ft multidisciplinary design, prototyping, and advanced manufacturing space took approximately 5 years and continued until the company's full opening in September 2016. The undertaking utilized approximately 9,000 lbs of steel in total according to the developer.\n\nA guiding principle of the redesign was to harmonize of the needs of the forthcoming lab environment with the original structural features. Modern workplace design elements were fused with the 19th century industrial characteristics of the building's centerline.\n\nNew Lab's open floor design was intended, spatially, to reinforce its mission, the layout meant to encourage member companies to collaborate and cross-pollinate ideas. Communal meeting rooms, office pods, and interior plazas on both floors emphasize the developer’s intention to create a collaborative design and fabrication center.\n\nUpon completion, the rebuild subdivided Building 128's usable space into: Private studios = 31,664 ft; Open private studios = 6,226 ft; Fabrication lab = 6,834 ft; Cafe kitchen = 600 ft; Conference rooms = 2,014 ft; Coworking desks = 144; Flex space = 66 desks.\n\nThere is an additional 6,174 ft of event space which hosts talks, hackathons, and new manufacturing events such as the recent Urban Tech Hub launch.\n\nAdditive Manufacturing (3D printing) technology is a component of the design process for many New Lab residents. Prototyping shops are a distinguishing feature of the hardware-centric facility. New Lab leverages partnerships with firms like AutoDesk, Stratasys, BigRep, Haas, Ultimaker, and others to provide and maintain equipment and filament for printing. The organization has amassed several million dollars of digital fabrication and manufacturing machine assets such as 3D Printers, electronic workbenches, fabrication tools, and CNC equipment since its opening.\nAs of September 2017 eighty companies and 400 people worked at New Lab. By 2018, the number of companies had increased to over 100. Members are typically growth-stage companies with anywhere between 3-20 employees.\n\n\n"}
{"id": "46972538", "url": "https://en.wikipedia.org/wiki?curid=46972538", "title": "Online shaming", "text": "Online shaming\n\nOnline shaming is a form of Internet vigilantism in which targets are publicly humiliated using technology like social and new media. Proponents of shaming see it as a form of online participation that allows hacktivists and cyber-dissidents to right injustices. Critics see it as a tool that encourages online mobs to destroy the reputation and careers of people or organizations who made perceived slights.\n\nOnline shaming frequently involves the publication of private information on the Internet (called doxing), which can frequently lead to hate messages and death threats being used to intimidate that person. The ethics of public humiliation has been a source of debate over privacy and ethics.\n\nThe social networking tools of the Internet have been used as a tool to easily and widely publicize instances of perceived anti-social behavior.\n\nDavid Furlow, chairman of the Media, Privacy and Defamation Committee of the American Bar Association, has identified the potential privacy concerns raised by websites facilitating the distribution of information that is not part of the public record (documents filed with a government agency), and has said that such websites \"just [give] a forum to people whose statements may not reflect truth.\"\n\nAfter some controversial incidents of public shaming, the popular link-sharing and discussion website Reddit introduced a strict rule against the publication of non-public personally-identifying information via the site (colloquially known on Reddit and elsewhere as \"doxing\"). Those who break the rule are subject to a site-wide ban, and their posts and even entire communities may be removed for breaking the rule.\n\nIn 2015, online shaming was the subject of the book \"So You've Been Publicly Shamed\" by Jon Ronson. Ronson documented how people had become agoraphobic due to humiliation online for misinterpreted jokes, and says people should think twice before gleefully condemning someone for doing almost nothing wrong.\n\nDoxing involves researching and broadcasting personally identifiable information about an individual, often with the intention of harming that person. This can often lead to extortion, coercion, harassment and other forms of abuse. On February 1, 2017, Reddit, a social news website, has banned two alt-right communities, r/altright and r/alternativeright for doxing and violating Reddit community guidelines.\n\nNonconsensual pornography is a form of sexually explicit recording publicized on the Internet in order to humiliate a person, frequently distributed by computer hackers or ex-partners (called revenge porn). Images and video of sexual acts are often combined with doxing of a person's private details, such as their home addresses and workplaces. Victims' lives can be ruined as a result, the victims exposed to cyber-stalking and physical attack as well as facing difficulties in their workplace should their images become known as a result of routine checks by employers. Some have lost their jobs, while others have been unable to find work at all.\n\nProducts frequently attract negative reviews on Goodreads, Amazon and other online commerce websites.\n\nIn many cases, users of Yelp write reviews in order to lash out at corporate interests or businesses they dislike. During the Chick-fil-A same-sex marriage controversy, activists encouraged a consumer boycott of Chick-fil-A and left negative reviews of the site's locations on restaurant rating websites after the founder declared that corporate profits would be donated to political causes opposing same-sex marriage in the United States. In 2015 an Indiana pizzeria was swarmed with negative Yelp reviews after the owner said it wouldn't cater gay weddings. Similar reactions have frequently followed bakers refusing to make cakes for gay weddings. After Cecil the lion was shot by an American recreational big-game hunter, his business was flooded with negative reviews.\n\nVarious governments have used \"name and shame\" policies to punish tax evasion, environmental violations and minor crimes like littering.\n\nIn July 2015, a group hacked the user data of Ashley Madison, a commercial dating website marketed as helping people have extramarital affairs. In August 2015, over 30 million user account details, including names and email addresses were released publicly.\n\nA variety of security researchers and Internet privacy activists debated the ethics of the release.\n\nClinical psychologists argued that dealing with an affair in a particularly public way increases the hurt for spouses and children. Carolyn Gregoire argued \"[s]ocial media has created an aggressive culture of public shaming in which individuals take it upon themselves to inflict psychological damage\" and more often than not, \"the punishment goes beyond the scope of the crime.\" Charles J. Orlando, who had joined the site to conduct research concerning women who cheat, said he felt users of the site were anxious the release of sexually explicit messages would humiliate their spouses and children. He wrote it is alarming \"the mob that is the Internet is more than willing to serve as judge, jury, and executioner\" and members of the site \"don’t deserve a flogging in the virtual town square with millions of onlookers.\"\n\nIn December 2013, Justine Sacco, a woman with 170 Twitter followers, tweeted acerbic jokes during a plane trip from New York to Cape Town, such as \"Weird German dude get some deodorant\" and, in Heathrow; \"Going to Africa. Hope I don't get AIDS. Just Kidding. I'm white!\" Sacco, a South African herself, intended the tweet to mock American ignorance of South Africa, and in a later interview expressed that her intention was to \"mimic—and mock what an actual racist, ignorant person would say.\" Sacco slept during her 11-hour plane trip, and woke up to find out that she had lost her job and was the number one Twitter topic worldwide, with celebrities and new media bloggers all over the globe denouncing her and encouraging all their followers to do the same. Sacco's employer, New York internet firm IAC, declared that she had lost her job as Director of Corporate Communications. People began tweeting \"Has Justine landed yet?\", expressing schadenfreude at the loss of her career. Sam Biddle, the Gawker Media blogger who promoted the #HasJustineLandedYet hashtag, later apologised for his role, admitting that he did so for Internet traffic to his blog, and noting that \"it's easy and thrilling to hate a stranger online.”\n\nAccording to Ronson, the public does not understand that a vigilante campaign of public shaming, undertaken with the ostensible intention of defending the underdog, may create a mob mentality capable of destroying the lives and careers of the public figures singled out for shaming. Ronson argued that in the early days of Twitter, people used the platform to share intimate details of their lives, and not as a vehicle of shaming. Brooke Gladstone argued that the Sacco affair may deter people from expressing themselves online due to a fear of being misinterpreted. Kelly McBride argues that journalists play a key role in expanding the shame and humiliation of targets of the campaigns by relaying claims to a larger audience, while justifying their actions as simply documenting an event in an impartial manner. She writes: \"Because of the mob mentality that accompanies public shaming events, often there is very little information about the target, sometimes only a single tweet. Yet there is a presumption of guilt and swift move toward justice, with no process for ascertaining facts.\" McBride further notes \"If newspapers ran front-page photos of adulterers in the Middle East being stripped naked and whipped in order to further their shame, we would criticize them as part of a backward system of justice.\" Ben Adler compared the Sacco incident to a number of Twitter hoaxes, and argued that the media needs to be more careful to fact-check articles and evaluate context.\n\nIn March 2013, at a PyCon technology conference, a female participant named Adria Richards took offense at a private discussion between two male attendees seated nearby using the words \"dongle\" and \"forking\" in reference to the male presenter, which she perceived as a sexual joke. Richards photographed the attendees with their faces visible, then published the photograph on Twitter including a shaming statement in her tweet. The following day, the employer of one of the photographed individuals, a software developer, terminated his employment because of the joke.\n\nIn response to Richards' public shaming of the developers, Internet users who were uninvolved launched a DDoS Attack on her employer, SendGrid, and according to an article by Jon Ronson in \"The New York Times Magazine\" \"told the employer the attacks would stop if Richards was fired\". SendGrid subsequently terminated her employment later the same day citing Richards' dividing the very community she was hired to unite, and the male anatomy joke she had posted a few days earlier on the employer website. Following the incident, PyCon updated its attendee rules stating, \"Public shaming can be counter-productive to building a strong community. PyCon does not condone nor participate in such actions out of respect.\"\n\nIn a 2014 interview, Richards—still unemployed—speculated whether the developer was responsible for instigating the Internet backlash against her. The developer, who was offered a new job \"right away\", said he had not engaged with those who sent him messages of support, and had posted a short statement on Hacker News the same night after he was fired saying in part that Richards had \"every right to report me to staff, and I defend her position\".\n\nIn November 2012, an Australian man filmed several passengers on a Melbourne bus verbally abusing and threatening a woman who had begun singing a song in French. A video alerting viewers of their racist and sexist comments was uploaded to YouTube and quickly attracted national and international media attention. The two male perpetrators who were most prominent in the video were later jailed, with Magistrate Jennifer Goldsbrough describing their threats as \"offensive to the entire population\".\n\nStarting as a turn of phrase, manspreading is a critique of men who take up more than one seat with their legs widely spread. In New York, actor Tom Hanks was photographed on the subway, taking up two seats, and then criticized for it. He responded on a talk show, \"Hey Internet, you idiot! The train was half empty! It was scattered—there was plenty of room!\" The controversy surrounding manspreading have been described by libertarian feminist Cathy Young as \"pseudo feminism—preoccupied with male misbehavior, no matter how trivial\". The practice of posting pictures of manspreading taken on subways, buses, and other modes of transportation online has been described as a form of public shaming. The criticism and campaigns against manspreading have been counter-criticized for not addressing similar behavior by women, such as taking up adjacent seats with bags, or \"she-bagging\". Twitter campaigns with the hashtag #manspreading have also been accompanied by hashtags like #she-bagging.\n\nThe feminist philosophy journal became involved in a dispute in April 2017 that led to the online shaming of one of its authors. The journal published an article about transracialism by Rebecca Tuvel, an assistant professor of philosophy, comparing the situation of Caitlyn Jenner, a trans woman, to that of Rachel Dolezal, a white woman who identifies as black. The article was criticized on Facebook and Twitter as a source of \"epistemic violence\", and the author became the subject of personal attacks. Academics associated with \"Hypatia\" joined in the criticism. A member of the journal's editorial board became the point of contact for an open letter demanding that the article be retracted, and the journal's board of associate editors issued an unauthorized apology, saying the article should never have been published. Rogers Brubaker described the episode in the \"New York Times\" as an example of \"internet shaming\".\n\nIn February 2009, an incident occurred involving the posting on YouTube of a video clip in which a domestic cat, named Dusty, was beaten and tortured by a 14-year-old boy calling himself \"Timmy\". After about 30,000 viewings, this clip and the account were removed by YouTube as a violation of their terms of service. Members of the 4chan imageboard investigated the incident, and by extrapolating from the poster's YouTube user name and the background in the video, they identified the abuser. As a result of these complaints, the Comanche County Sheriff's Department investigated the incident, and two suspects were arrested. Dusty survived the abuse, and was placed in the care of a local veterinarian. Both the assailant and the cameraman were charged with animal cruelty; as both were juveniles, possible punishments included \"psychological counseling, court monitoring until they turn 18, community service to provide restitution for treatment of animals, and/or placement in court custody.\"\n\nIn 2006, Wang-Jue (), a Chinese nurse appearing in an Internet crush video stomping a helpless kitten with her stilettos, gave herself up to authorities after bloggers and some print media started a campaign to trace back the recording. In the beginning, she was labeled as the kitten killer of Hangzhou, because it was believed she was from there; but some internauts recognized an island in northern Heilongjiang province. Upon discovery of her identity, Wang Jue received death threats from many angry animal lovers.\n\nWang posted an apology on the Luobei city government official website. She said she was recently divorced and did not know what to do with her life. She and the cameraman, a provincial TV employee, lost their jobs when internauts discovered their identities.\n\nIn August 2010, a passer-by in Coventry, England, later identified as Mary Bale by 4chan's members, was caught on a private security camera stroking a cat, named Lola, then looking around and dumping her in a wheelie bin, where she was found by her owners 15 hours later. The owners posted the video on the Internet in a bid to identify the woman, who was later interviewed by the RSPCA about her conduct. Outrage was sparked among animal lovers, and a Facebook group called \"Death to Mary Bale\" was created, and later removed. Police said they were speaking to the 45-year-old about her personal safety.\n\nThe woman, who at first downplayed her actions (\"I thought it would be funny\", \"it's just a cat\" and \"didn't see what all the buzz was about\") eventually apologised \"profusely for the upset and distress\".\n\nBale was convicted under the Animal Welfare Act of 2006 with causing unnecessary suffering to a cat. An additional charge of failing to provide the cat with a suitable environment was dropped. She was fined £250 and ordered to pay costs, totaling £1,436.04.\n\nIn 2010, a case was publicized involving a young female from Sichuan, using the alias Huang siu siu (黄小小), torturing and crushing rabbits. The group that financially sponsored the making of these videos, later revealed to be called \"Crushfetish\", paid young girls to crush fish, insects, rabbits and other small animals. The girl was paid 100 yuan for each attempt, and she had been participating since 2007. Police said the group makes videos to sell overseas, and the company has allegedly made 279 animal abuse videos with a subscription fee. Because of the concurrent hosting of the 2010 Asian Games, the animal videos were limited to being hosted online for a few hours a day.\n\nIn October 2013, a delicately balanced hoodoo in Goblin Valley State Park was intentionally knocked over by Boy Scout leaders who had been camping in the area. David Benjamin Hall captured video and shouted encouragement while Glenn Tuck Taylor toppled the formation. They posted the video to Facebook, whereupon it was viewed by thousands and the two men began receiving death threats. Their claim that the hoodoo appeared unstable, and that they vandalised it out of concern for passersby, was rejected by Fred Hayes, director of the Utah Division of State Parks and Recreation. Hall and Taylor were charged with third-degree felonies and were expelled from Boy Scouts.\n\nOn August 26, 2012, Yang Dacai, chief of the Shanxi provincial work safety administration, was caught grinning widely amid the wreckage of a long-distance bus that killed 36 passengers when it collided with a tanker loaded with highly flammable methanol on a Chinese highway in Shanxi Province. Pictures of the accident began to circulate on Sina Weibo, the most popular micro-blogging site in China which led to a meme dubbing him as the \"Smiling Brother\". Searches on the human flesh search engine followed leading to pictures surfacing on Weibo, showing Yang wearing luxury watches such as a $10,000 Rolex initiating another meme calling him \"Watch Brother\". On September 21, Yang was relieved of his position and accused of serious discipline violations. He was subsequently jailed for 14 years after being found guilty of taking bribes.\n\nIn 2005 in South Korea, bloggers targeted a woman who refused to clean up when her dog defecated on the floor of a Seoul subway car, labeling her \"Dog Poop Girl\" (rough translation of into English). Another commuter had taken a photograph of the woman and her dog, and posted it on a popular South Korean website. Within days, she had been identified by Internet vigilantes, and much of her personal information was leaked onto the Internet in an attempt to punish her for the offense. The story received mainstream attention when it was widely reported in South Korean media. The public humiliation led the woman to drop out of her university, according to reports.\n\nThe reaction by the South Korean public to the incident prompted several newspapers in South Korea to run editorials voicing concern over Internet vigilantism. One paper quoted Daniel Solove as saying that the woman was the victim of a \"cyber-posse, tracking down norm violators and branding them with digital Scarlet Letters.\" Another called it an \"Internet witch-hunt,\" and went on to say that \"the Internet is turning the whole society into a kangaroo court.\"\n\nOther notable instances also include the case of Evan Guttman and his friend's stolen Sidekick II smartphone, and the case of Jesse McPherson and his stolen Xbox 360, PowerBook, and TV.\n\nIn 2008, a 5-year-old girl asked to use the bathroom at the Rocky Mountain Chocolate Factory at Bella Terra/Huntington Beach, but was disallowed from using it because the Factory's restrooms were for employees only. The girl's mother describes the incident this way: \"I explained she had diarrhea and couldn't hold it and told [the store owners] she was about to go on the floor. They refused again and never offered me any alternatives. I begged them to have a heart and that she was 5 but by that time she had lost it all over herself and me.\" The story then spread to sites like digg.com where contact information for the owner of the store was released in message boards.\n\nIn 2008, a girl called Zhang Ya () from Liaoning province, Northeast China, posted a 4-minute video of herself complaining about the amount of attention the Sichuan earthquake victims were receiving on television. An intense response from Internet vigilantes resulted in the girl's personal details (even including her blood type) being made available online, as well as dozens of abusive video responses on Chinese websites and blogs. The girl was taken into police custody for three days as protection from vigilante death threats.\n\nStephen Fowler, a British expatriate and venture capitalist businessman, gained notoriety after his performance on ABC's \"Wife Swap\" (originally aired Friday January 30, 2009) when his wife exchanged positions in his family with a woman from Missouri for a two-week period. In response to her rule changes (standard procedure for the second week in the show) he insulted his guest and, in doing so, groups including the lower classes, soldiers, and the overweight. Several websites were made in protest against his behaviour. After the show, and after watching the \"Wife Swap\" video, his wife, a professional life coach, reported that she had encouraged him to attend professional behaviour counselling. Businesses with only tangential connection to Fowler publicly disclaimed any association with him due to the negative publicity. He resigned positions on the boards of two environmental charities to avoid attracting negative press.\n\nIn 2008, video of Patrick Pogan, a rookie police officer, body-slamming Christopher Long, a cyclist, surfaced on the Internet. The altercation happened when members of Critical Mass conducted a bicycling advocacy event at Times Square. The officer claimed the cyclist had veered into him, and so the biker was charged with assault, disorderly conduct and resisting arrest.\n\nThe charges against the cyclist were later dropped and Pogan was convicted of lying about the confrontation with the cyclist.\n\nIn 2009, a Facebook group was started, accusing a single mother for the death of a 13-month-old child in her foster care. It was the mother's then common-law husband who pleaded guilty to manslaughter and the mother was not formally accused of any wrongdoing. However, the members of the group, such as the boy's biological mother, accuse her of knowing what was going on and doing nothing to stop it.\n\nThe food magazine \"Cooks Source\" printed an article by Monica Gaudio without her permission in their October 2010 issue. Learning of the copyright violation, Gaudio emailed Judith Griggs, managing editor of \"Cooks Source Magazine\", requesting that the magazine both apologize and also donate $130 to the Columbia School of Journalism as payment for using her work. Instead she received a very unapologetic letter stating that she (Griggs) herself should be thanked for making the piece better and that Gaudio should be glad that she didn't give someone else credit for writing the article. During the ensuing public outcry, online vigilantes took it upon themselves to avenge Gaudio. The \"Cooks Source\" Facebook page was flooded with thousands of contemptuous comments, forcing the magazine's staff to create new pages in an attempt to escape the protest and accuse 'hackers' of taking control of the original page. The magazine's website was stripped of all content by the staff and shut down a week later.\n\nIn June 2012, An elderly bus monitor, Karen Klein, was taunted, picked on, and threatened by four seventh-graders. The act was caught on video and uploaded to the Internet which in turn caused an act of kindness from complete strangers. $703,833 was raised for Klein in donations from concerned strangers who were outraged after viewing a video that captured her torment.\n\nIn 2015 a junior barrister Charlotte Proudman working in the UK tweeted a screenshot of her LinkedIn exchange with Alexander Carter-Silk, a senior City solicitor, rebuking him for complimenting her on her profile photograph. The social media backlash included Proudman finding herself condemned as a \"feminazi\".\n\n\n"}
{"id": "27352320", "url": "https://en.wikipedia.org/wiki?curid=27352320", "title": "Open-source appropriate technology", "text": "Open-source appropriate technology\n\nOpen-source appropriate technology (OSAT) is appropriate technology developed through the principles of the open-design movement. OSAT refers to, on the one hand, technology designed with special consideration to the environmental, ethical, cultural, social, political, and economic aspects of the community it is intended for. On the other hand, OSAT is developed in the open and licensed in such a way as to allow their designs to be used, modified and distributed freely.\n\nOpen source is a development method for appropriate technology that harnesses the power of distributed peer review and transparency of process. is an example of open-source appropriate technology. There anyone can both learn how to make and use AT free of concerns about patents. At the same time anyone can also add to the collective open-source knowledge base by contributing ideas, observations, experimental data, deployment logs, etc. It has been claimed that the potential for open-source-appropriate technology to drive applied sustainability is enormous. The built in continuous peer-review can result in better quality, higher reliability, and more flexibility than conventional design/patenting of technologies. The free nature of the knowledge also obviously provides lower costs, particularly for those technologies that do not benefit to a large degree from scale of manufacture. Finally, OSAT also enables the end to predatory intellectual property lock-in. This is particularly important in the context of technology focused on relieving suffering and saving lives in the developing world.\n\nThe \"open-source\" model can act as a driver of sustainable development. Reasons include:\n\n\nFor solutions, many researchers, companies, and academics do work on products meant to assist sustainable development. Vinay Gupta has suggested that those developers agree to three principles:\n\n\nThe ethics of information sharing in this context has been explored in depth.\n\n\n\n\nAppropriate technology is designed to promote decentralized, labor-intensive, energy-efficient and environmentally sound businesses. Carroll Pursell says that the movement declined from 1965 to 1985, due to an inability to counter advocates of agribusiness, large private utilities, and multinational construction companies. Recently (2011), several barriers to OSAT deployment have been identified:\n\n"}
{"id": "56819159", "url": "https://en.wikipedia.org/wiki?curid=56819159", "title": "Posthumanization", "text": "Posthumanization\n\nPosthumanization comprises \"those processes by which a society comes to include members other than 'natural' biological human beings who, in one way or another, contribute to the structures, dynamics, or meaning of the society.\" Posthumanization is one of the key phenomena studied by those academic disciplines and methodologies that identify themselves as \"posthumanist\", including critical, cultural, and philosophical posthumanism. Its processes can be divided into forms of \"non-technological\" and \"technological\" posthumanization.\n\nWhile posthumanization has links with the scholarly methodologies of posthumanism, it is a distinct phenomenon. The rise of explicit posthumanism as a scholarly approach is relatively recent, occurring since the late 1970s; however, some of the processes of posthumanization that it studies are ancient. For example, the dynamics of \"non-technological\" posthumanization have existed historically in all societies in which animals were incorporated into families as household pets or in which ghosts, monsters, angels, or semidivine heroes were considered to play some role in the world.\n\nSuch non-technological posthumanization has been manifested not only in mythological and literary works but also in the construction of temples, cemeteries, zoos, or other physical structures that were considered to be inhabited or used by quasi- or para-human beings who were not natural, living, biological human beings but who nevertheless played some role within a given society, to the extent that, according to philosopher Francesca Ferrando: \"the notion of spirituality dramatically broadens our understanding of the posthuman, allowing us to investigate not only technical technologies (robotics, cybernetics, biotechnology, nanotechnology, among others), but also, technologies of existence.\" \n\nSome forms of technological posthumanization involve efforts to directly alter the social, psychological, or physical structures and behaviors of the human being through the development and application of technologies relating to genetic engineering or neurocybernetic augmentation; such forms of posthumanization are studied, e.g., by cyborg theory. Other forms of technological posthumanization indirectly \"posthumanize\" human society through the deployment of social robots or attempts to develop artificial general intelligences, sentient networks, or other entities that can collaborate and interact with human beings as members of posthumanized societies.\n\nThe dynamics of technological posthumanization have long been an important element of science fiction; genres such as cyberpunk take them as a central focus. In recent decades, technological posthumanization has also become the subject of increasing attention by scholars and policymakers. The expanding and accelerating forces of technological posthumanization have generated diverse and conflicting responses, with some researchers viewing the processes of posthumanization as opening the door to a more meaningful and advanced transhumanist future for humanity, while other bioconservative critiques warn that such processes may lead to a fragmentation of human society, loss of meaning, and subjugation to the forces of technology.\n\nProcesses of technological and non-technological posthumanization both tend to result in a partial \"de-anthropocentrization\" of human society, as its circle of membership is expanded to include other types of entities and the position of human beings is decentered. A common theme of posthumanist study is the way in which processes of posthumanization challenge or blur simple binaries, such as those of \"human versus non-human\", \"natural versus artificial\", \"alive versus non-alive\", and \"biological versus mechanical\".\n\n"}
{"id": "9031121", "url": "https://en.wikipedia.org/wiki?curid=9031121", "title": "Real-time transcription", "text": "Real-time transcription\n\nReal-time transcription is the general term for transcription by court reporters using real-time text technologies to deliver computer text screens within a few seconds of the words being spoken. Specialist software allows participants in court hearings or depositions to make notes in the text and highlight portions for future reference.\n\nTypically, real-time writers can produce text using machines at the rate of at least 200 words per minute. Stenographers can typically type up to 300 words per minute for short periods of time, but most cannot sustain such a speed.\n\nReal-time transcription is also used in the broadcasting environment where it is more commonly termed \"captioning.\"\n\nReal-time reporting is used in a variety of industries, including entertainment, television, the Internet, and law.\n\nSpecific careers include the following:\n\n"}
{"id": "375140", "url": "https://en.wikipedia.org/wiki?curid=375140", "title": "Room-temperature superconductor", "text": "Room-temperature superconductor\n\nA room-temperature superconductor is a hypothetical material that would be capable of exhibiting superconductivity at operating temperatures above 0 °C (273.15 K). While this is not strictly \"room temperature\", which would be approximately 20–25 °C, it is the temperature at which ice forms and can be reached and easily maintained in an everyday environment. The highest temperature known superconducting material is highly pressurized hydrogen sulfide, the transition temperature of which is , the highest accepted superconducting critical temperature as of 2015. By substituting a small part of sulfur with phosphorus and using even higher pressures, it has been predicted that it may be possible to raise the critical temperature to above 0 °C and achieve room-temperature superconductivity. Previously the record was held by the cuprates, which have demonstrated superconductivity at atmospheric pressure at temperatures as high as , and under high pressure.\n\nAlthough some researchers doubt whether room-temperature superconductivity is actually achievable, superconductivity has repeatedly been discovered at temperatures that were previously unexpected or held to be impossible.\n\nClaims of \"near-room temperature\" transient effects date from the early 1950s and some suggest that in fact the breakthrough might have been made more than once but could not be made stable enough and/or reproducible as the relationship between isotope number and T was not known at the time.\n\nFinding a room temperature superconductor \"would have enormous technological importance and, for example, help to solve the world’s energy problems, provide for faster computers, allow for novel memory-storage devices, and enable ultra-sensitive sensors, among many other possibilities.\"\n\nSince the discovery of high-temperature superconductors, several materials have been reported to be room-temperature superconductors, although none of these reports has been confirmed.\n\nIn 2000, while extracting electrons from diamond during ion implantation work, Johan Prins claimed to have observed a phenomenon that he explained as room-temperature superconductivity within a phase formed on the surface of oxygen-doped type IIa diamonds in a vacuum.\n\nIn 2003, a group of researchers published results on high-temperature superconductivity in palladium hydride (PdH: x>1) and an explanation in 2004.\nIn 2007 the same group published results suggesting a superconducting transition temperature of 260 K. The superconducting critical temperature increases as the density of hydrogen inside the palladium lattice increases. This work has not been corroborated by other groups.\n\nIn 2012, an \"Advanced Materials\" article claimed superconducting behavior of graphite powder after treatment with pure water at temperatures as high as 300 K and above.[Unreliable source] So far, the authors have not been able to demonstrate the occurrence of a clear Meissner phase and the vanishing of the material's resistance.\n\nIn 2014, an article published in \"Nature\" suggested that some materials, notably YBCO (yttrium barium copper oxide), could be made to superconduct at room temperature using infrared laser pulses.\n\nIn 2015, an article published in \"Nature\" by researchers of the Max Planck Institute suggested that under certain conditions such as extreme pressure HS transitioned to a superconductive form HS at around 1.5 million times atmospheric pressure in a diamond anvil cell. The critical temperature is 203 K which would be the highest T ever recorded and their research suggests that other hydrogen compounds could superconduct at up to 260 K which would match up with the original research of Ashcroft.\n\nIn 2018, Dev Kumar Thapa and Anshu Pandey from the Solid State and Structural Chemistry Unit of the Indian Institute of Science in Bangalore claimed the observation of superconductivity at ambient pressure and room temperature in films and pellets of a nanostructured material that is composed of silver particles embedded in a gold matrix.Due to similar noise patterns of supposedly independent plots and the not peer-reviewed nature of this publication, the results were called into question.\n\nIn 2018, researchers noted a possible superconducting phase at 260K in lanthanum decahydride at elevated (200GPa) pressure.\n\nOther research also suggests a link between the palladium hydride containing small impurities of sulfur as a plausible explanation for the anomalous resistance drops noticed by other researchers, and hydrogen absorption by cuprates has been suggested in light of the recent results in HS as a plausible explanation for transient resistance drops or \"USO\" noticed\nin the 1990s during research after the discovery of YBCO.\n\nTheoretical work by Neil Ashcroft predicted that solid metallic hydrogen at extremely high pressure (~500 GPa) should become superconducting at approximately room-temperature because of its extremely high speed of sound and expected strong coupling between the conduction electrons and the lattice vibrations (phonons). This prediction is yet to be experimentally verified, as yet the pressure to achieve metallic hydrogen is not known but may be of the order of 500 GPa.\n\nA team at Harvard has claimed to make metallic hydrogen and reports a pressure of 495 GPa. Though the exact critical temperature has not yet been determined, weak signs of a Meissner effect at 250K may have appeared in magnetometer tests.\n\nIn 1964, William A. Little proposed the possibility of high temperature superconductivity in organic polymers. This proposal is based on the exciton-mediated electron pairing, as opposed to phonon-mediated pairing in BCS theory.\n"}
{"id": "27367532", "url": "https://en.wikipedia.org/wiki?curid=27367532", "title": "SEVEN Networks", "text": "SEVEN Networks\n\nSEVEN Networks, Inc. is a privately funded American corporation founded in 2000. It had about 265 employees in 2010. As of 2017, the company has research and development centers in Texas and Finland.\n\nSEVEN mobile messaging products are turnkey multi-device, multi-service computer software for operators and device manufacturers. The company claims its products have a desktop-like experience for core messaging applications like email, instant messagings and social networking.\n\nThe company was formerly known as Leap Corporation and changed its name to SEVEN Networks, Inc. in December 2000. \nIn 2004 the company was selected for FierceWireless' list of 15 promising and innovative wireless startups of the year. \nBy 2005, CEO Bill Nguyen had left to start another company.\nIn 2006, the company announced Sprint as a customer.\n\nSince then, the company expanded its products to support email services, added mobile instant messaging applications, analytics and social networking.\nIn 2010, the company announced it was selected by Samsung Electronics to provide push technology for Samsung Social Hub, a social networking and integrated messaging service available on several of the company’s handsets. In January 2010, the company claimed in a press release to have more than eight million accounts actively synchronized on mobile devices using its software. In early 2011, the company announced Verizon Wireless as a customer and also announced Open Channel.\n\nIn 2012, the company announced a combined email, instant messaging and social media product, Ping.\n\nThe Open Channel software product line focuses on mobile traffic management and optimization. There are Open Channel products for wireless signaling optimization, carrier network policy enforcement, and mobile data offloading.\nOpen Channel was launched in February 2011 to help carriers manage the impact of push technology for message notifications on their networks. It works by monitoring all requests for data from smartphone applications, such as Facebook, email, Twitter, which make up to hundreds of requests per hour, with only a small fraction of them actually returning data.\n\nThe platform acts as a buffer in the network, determining when content for a particular app is available and then allowing the phone to get that content. Early tests estimated mobile devices might reduce their time on a network by up to 40 percent and mobile traffic by up to 70 percent while boosting battery life by up to 25 percent.\n\nOpen Channel is transparent to connected applications and requires no changes or special integration by mobile developers. Additionally, it does not require changes to the network and can work in conjunction with new standards for fast network dormancy, smart signaling and other network optimizations. In February 2011, Open Channel received the GSMA Global Mobile Award for Best Mobile Technology Breakthrough in 2011.\n\nIn February 2013, Open Channel added offerings for policy enforcement and offloading. Also in early 2013, Toronto-based wireless operator Public Mobile selected Open Channel to manage network signaling and help reduce service costs stemming from non-optimized mobile applications and unnecessary data traffic that was creating excess network congestion.\n\nIn September 2015, Open Channel was made available directly to consumers.\n\nThe System SEVEN software allows consumers and enterprises to access information, such as business and personal email, calendar, corporate directories, personal contacts, and documents, as well as allows users to deliver mobile data, applications, and services to a portfolio of devices. SEVEN's push notification platform, System SEVEN, is deployed as a SaaS (software-as a service) solution. SEVEN Mobile Email and SEVEN Mobile IM are SEVEN's own applications built on top of its push platform and its Ping Services allow operators and device manufacturers to use the SEVEN push notification technology for messaging services and mobile applications. They provide mobile operators and device manufacturers with a solution for integrated messaging services.\n\nSystem SEVEN mobile email is a server-assisted solution, where access to user's email account appears to originate from IP addresses hosted by SEVEN (208.87.200.0 - 208.87.207.255) or its customers. Although done with user's permission, email service providers may flag these as potential hacking attempts and have raised security concerns, most recently with Microsoft Outlook for Android and iOS\n\nThe firm works with mobile platform providers, device manufacturers, email messaging solutions and providers of services in the cloud, and infrastructure partners, to sell mobile messaging services.\nIts systems use commonly deployed mobile platforms including Android, bada, BREW, J2ME, Symbian and Windows Mobile. They work on products from device manufacturers, including: HTC, INQ, LG, Motorola, Nokia, Sanyo, Samsung, and Sony Ericsson; and are embedded on more than 550 device types. The firm has partnered with many of the top Internet Service Providers including Google, Microsoft (Exchange and Windows Live) and Yahoo!, and infrastructure providers such as Equinix, Savvis and Oracle.\n\n\n"}
{"id": "359626", "url": "https://en.wikipedia.org/wiki?curid=359626", "title": "Second Industrial Revolution", "text": "Second Industrial Revolution\n\nThe Second Industrial Revolution, also known as the Technological Revolution, was a phase of rapid industrialization in the final third of the 19th century and the beginning of the 20th. The First Industrial Revolution, which ended in the early to mid 1800s, was punctuated by a slowdown in macroinventions before the Second Industrial Revolution in 1870. Though a number of its characteristic events can be traced to earlier innovations in manufacturing, such as the establishment of a machine tool industry, the development of methods for manufacturing interchangeable parts and the invention of the Bessemer Process to produce steel, the Second Industrial Revolution is generally dated between 1870 and 1914 (the start of World War I).\n\nAdvancements in manufacturing and production technology enabled the widespread adoption of preexisting technological systems such as telegraph and railroad networks, gas and water supply, and sewage systems, which had earlier been concentrated to a few select cities. The enormous expansion of rail and telegraph lines after 1870 allowed unprecedented movement of people and ideas, which culminated in a new wave of globalization. In the same time period, new technological systems were introduced, most significantly electrical power and telephones. The Second Industrial Revolution continued into the 20th century with early factory electrification and the production line, and ended at the start of World War I.\n\nThe Second Industrial Revolution was a period of rapid industrial development, primarily in Britain, Germany and the United States, but also in France, the Low Countries, Italy and Japan. It followed on from the First Industrial Revolution that began in Britain in the late 18th century that then spread throughout Western Europe and North America. It was characterized by the build out of railroads, large-scale iron and steel production, widespread use of machinery in manufacturing, greatly increased use of steam power, widespread use of the telegraph, use of petroleum and the beginning of electrification. It also was the period during which modern organizational methods for operating large scale businesses over vast areas came into use.\n\nThe concept was introduced by Patrick Geddes, \"Cities in Evolution\" (1910), but David Landes' use of the term in a 1966 essay and in \"The Unbound Prometheus\" (1972) standardized scholarly definitions of the term, which was most intensely promoted by Alfred Chandler (1918–2007). However, some continue to express reservations about its use.\n\nLandes (2003) stresses the importance of new technologies, especially, the internal combustion engine and petroleum, new materials and substances, including alloys and chemicals, electricity and communication technologies (such as the telegraph, telephone and radio).\n\nVaclav Smil called the period 1867–1914 \"The Age of Synergy\" during which most of the great innovations were developed since the inventions and innovations were engineering and science-based.\n\nA synergy between iron and steel, railroads and coal developed at the beginning of the Second Industrial Revolution. Railroads allowed cheap transportation of materials and products, which in turn led to cheap rails to build more roads. Railroads also benefited from cheap coal for their steam locomotives. This synergy led to the laying of 75,000 miles of track in the U.S. in the 1880s, the largest amount anywhere in world history.\n\nThe hot blast technique, in which the hot flue gas from a blast furnace is used to preheat combustion air blown into a blast furnace, was invented and patented by James Beaumont Neilson in 1828 at Wilsontown Ironworks in Scotland. Hot blast was the single most important advance in fuel efficiency of the blast furnace as it greatly reduced the fuel consumption for making pig iron, and was one of the most important technologies developed during the Industrial Revolution. Falling costs for producing wrought iron coincided with the emergence of the railway in the 1830s.\n\nThe early technique of hot blast used iron for the regenerative heating medium. Iron caused problems with expansion and contraction, which stressed the iron and caused failure. Edward Alfred Cowper developed the Cowper stove in 1857. This stove used firebrick as a storage medium, solving the expansion and cracking problem. The Cowper stove was also capable of producing high heat, which resulted in very high throughput of blast furnaces. The Cowper stove is still used in today's blast furnaces.\n\nWith the greatly reduced cost of producing pig iron with coke using hot blast, demand grew dramatically and so did the size of blast furnaces.\n\nThe Bessemer process, invented by Sir Henry Bessemer, allowed the mass-production of steel, increasing the scale and speed of production of this vital material, and decreasing the labor requirements. The key principle was the removal of excess carbon and other impurities from pig iron by oxidation with air blown through the molten iron. The oxidation also raises the temperature of the iron mass and keeps it molten.\n\nThe \"acid\" Bessemer process had a serious limitation in that it required relatively scarce hematite ore which is low in phosphorus. Sidney Gilchrist Thomas developed a more sophisticated process to eliminate the phosphorus from iron. Collaborating with his cousin, Percy Gilchrist a chemist at the Blaenavon Ironworks, Wales, he patented his process in 1878; Bolckow Vaughan & Co. in Yorkshire was the first company to use his patented process. His process was especially valuable on the continent of Europe, where the proportion of phosphoric iron was much greater than in England, and both in Belgium and in Germany the name of the inventor became more widely known than in his own country. In America, although non-phosphoric iron largely predominated, an immense interest was taken in the invention.\n\nThe next great advance in steel making was the Siemens-Martin process. Sir Charles William Siemens developed his regenerative furnace in the 1850s, for which he claimed in 1857 to able to recover enough heat to save 70–80% of the fuel. The furnace operated at a high temperature by using regenerative preheating of fuel and air for combustion. Through this method, an open-hearth furnace can reach temperatures high enough to melt steel, but Siemens did not initially use it in that manner.\n\nFrench engineer Pierre-Émile Martin was the first to take out a license for the Siemens furnace and apply it to the production of steel in 1865. The Siemens-Martin process complemented rather than replaced the Bessemer process. Its main advantages were that it did not expose the steel to excessive nitrogen (which would cause the steel to become brittle), it was easier to control, and that it permitted the melting and refining of large amounts of scrap steel, lowering steel production costs and recycling an otherwise troublesome waste material. It became the leading steel making process by the early 20th century.\n\nThe availability of cheap steel allowed building larger bridges, railroads, skyscrapers, and ships. Other important steel products—also made using the open hearth process—were steel cable, steel rod and sheet steel which enabled large, high-pressure boilers and high-tensile strength steel for machinery which enabled much more powerful engines, gears and axles than were previously possible. With large amounts of steel it became possible to build much more powerful guns and carriages, tanks, armored fighting vehicles and naval ships.\n\nThe increase in steel production from the 1860s meant that railroads could finally be made from steel at a competitive cost. Being a much more durable material, steel steadily replaced iron as the standard for railway rail, and due to its greater strength, longer lengths of rails could now be rolled. Wrought iron was soft and contained flaws caused by included dross. Iron rails could also not support heavy locomotives and was damaged by hammer blow. The first to make durable rails of steel rather than wrought iron was Robert Forester Mushet at the Darkhill Ironworks, Gloucestershire in 1857.\n\nThe first of his steel rails was sent to Derby Midland railway station. They were laid at part of the station approach where the iron rails had to be renewed at least every six months, and occasionally every three. Six years later, in 1863, the rail seemed as perfect as ever, although some 700 trains had passed over it daily. This provided the basis for the accelerated construction of rail transportation throughout the world in the late nineteenth century. Steel rails lasted over ten times longer than did iron, and with the falling cost of steel, heavier weight rails were used. This allowed the use of more powerful locomotives, which could pull longer trains, and longer rail cars, all of which greatly increased the productivity of railroads. Rail became the dominant form of transport infrastructure throughout the industrialized world, producing a steady decrease in the cost of shipping seen for the rest of the century.\n\nThe theoretical and practical basis for the harnessing of electric power was laid by the scientist and experimentalist Michael Faraday. Through his research on the magnetic field around a conductor carrying a direct current, Faraday established the basis for the concept of the electromagnetic field in physics. His inventions of electromagnetic rotary devices were the foundation of the practical use of electricity in technology.\n\nIn 1881, Sir Joseph Swan, inventor of the first feasible incandescent light bulb, supplied about 1,200 Swan incandescent lamps to the Savoy Theatre in the City of Westminster, London, which was the first theatre, and the first public building in the world, to be lit entirely by electricity. Swan's lightbulb had already been used in 1879 to light Mosley Street, in Newcastle upon Tyne, the first electrical street lighting installation in the world. This set the stage for the electrification of industry and the home. The first large scale central distribution supply plant was opened at Holborn Viaduct in London in 1882 and later at Pearl Street Station in New York City.\n\nThe first modern power station in the world was built by the English electrical engineer Sebastian de Ferranti at Deptford. Built on an unprecedented scale and pioneering the use of high voltage (10,000V) alternating current, it generated 800 kilowatts and supplied central London. On its completion in 1891 it supplied high-voltage AC power that was then \"stepped down\" with transformers for consumer use on each street. Electrification allowed the final major developments in manufacturing methods of the Second Industrial Revolution, namely the assembly line and mass production.\n\nElectrification was called \"the most important engineering achievement of the 20th century\" by the National Academy of Engineering. Electric lighting in factories greatly improved working conditions, eliminating the heat and pollution caused by gas lighting, and reducing the fire hazard to the extent that the cost of electricity for lighting was often offset by the reduction in fire insurance premiums. Frank J. Sprague developed the first successful DC motor in 1886. By 1889 110 electric street railways were either using his equipment or in planning. The electric street railway became a major infrastructure before 1920. The AC (Induction motor) was developed in the 1890s and soon began to be used in the electrification of industry. Household electrification did not become common until the 1920s, and then only in cities. Fluorescent lighting was commercially introduced at the 1939 World's Fair.\n\nElectrification also allowed the inexpensive production of electro-chemicals, such as aluminium, chlorine, sodium hydroxide, and magnesium.\n\nThe use of machine tools began with the onset of the First Industrial Revolution. The increase in mechanization required more metal parts, which were usually made of cast iron or wrought iron—and hand working lacked precision and was a slow and expensive process. One of the first machine tools was John Wilkinson's boring machine, that bored a precise hole in James Watt's first steam engine in 1774. Advances in the accuracy of machine tools can be traced to Henry Maudslay and refined by Joseph Whitworth. Standardization of screw threads began with Henry Maudslay around 1800, when the modern screw-cutting lathe made interchangeable V-thread machine screws a practical commodity.\n\nIn 1841, Joseph Whitworth created a design that, through its adoption by many British railroad companies, became the world's first national machine tool standard called British Standard Whitworth. During the 1840s through 1860s, this standard was often used in the United States and Canada as well, in addition to myriad intra- and inter-company standards.\n\nThe importance of machine tools to mass production is shown by the fact that production of the Ford Model T used 32,000 machine tools, most of which were powered by electricity. Henry Ford is quoted as saying that mass production would not have been possible without electricity because it allowed placement of machine tools and other equipment in the order of the work flow.\n\nThe first paper making machine was the Fourdrinier machine, built by Sealy and Henry Fourdrinier, stationers in London. In 1800, Matthias Koops, working in London, investigated the idea of using wood to make paper, and began his printing business a year later. However, his enterprise was unsuccessful due to the prohibitive cost at the time.\n\nIt was in the 1840s, that Charles Fenerty in Nova Scotia and Friedrich Gottlob Keller in Saxony both invented a successful machine which extracted the fibres from wood (as with rags) and from it, made paper. This started a new era for paper making, and, together with the invention of the fountain pen and the mass-produced pencil of the same period, and in conjunction with the advent of the steam driven rotary printing press, wood based paper caused a major transformation of the 19th century economy and society in industrialized countries. With the introduction of cheaper paper, schoolbooks, fiction, non-fiction, and newspapers became gradually available by 1900. Cheap wood based paper also allowed keeping personal diaries or writing letters and so, by 1850, the clerk, or writer, ceased to be a high-status job. By the 1880s chemical processes for paper manufacture were in use, becoming dominant by 1900.\n\nThe petroleum industry, both production and refining, began in 1848 with the first oil works in Scotland. The chemist James Young set up a small business refining the crude oil in 1848. Young found that by slow distillation he could obtain a number of useful liquids from it, one of which he named \"paraffine oil\" because at low temperatures it congealed into a substance resembling paraffin wax. In 1850 Young built the first truly commercial oil-works and oil refinery in the world at Bathgate, using oil extracted from locally mined torbanite, shale, and bituminous coal to manufacture naphtha and lubricating oils; paraffin for fuel use and solid paraffin were not sold till 1856.\n\nCable tool drilling was developed in ancient China and was used for drilling brine wells. The salt domes also held natural gas, which some wells produced and which was used for evaporation of the brine. Chinese well drilling technology was introduced to Europe in 1828.\n\nAlthough there were many efforts in the mid-19th century to drill for oil Edwin Drake's 1859 well near Titusville, Pennsylvania, is considered the first \"modern oil well\". Drake's well touched off a major boom in oil production in the United States. Drake learned of cable tool drilling from Chinese laborers in the U. S. The first primary product was kerosene for lamps and heaters. Similar developments around Baku fed the European market.\n\nKerosene lighting was much more efficient and less expensive than vegetable oils, tallow and whale oil. Although town gas lighting was available in some cities, kerosene produced a brighter light until the invention of the gas mantle. Both were replaced by electricity for street lighting following the 1890s and for households during the 1920s. Gasoline was an unwanted byproduct of oil refining until automobiles were mass-produced after 1914, and gasoline shortages appeared during World War I. The invention of the Burton process for thermal cracking doubled the yield of gasoline, which helped alleviate the shortages.\n\nSynthetic dye was discovered by English chemist William Henry Perkin in 1856. At the time, chemistry was still in a quite primitive state; it was still a difficult proposition to determine the arrangement of the elements in compounds and chemical industry was still in its infancy. Perkin's accidental discovery was that aniline could be partly transformed into a crude mixture which when extracted with alcohol produced a substance with an intense purple colour. He scaled up production of the new \"mauveine\", and commercialized it as the world's first synthetic dye.\n\nAfter the discovery of mauveine, many new aniline dyes appeared (some discovered by Perkin himself), and factories producing them were constructed across Europe.\nTowards the end of the century, Perkin and other British companies found their research and development efforts increasingly eclipsed by the German chemical industry which became world dominant by 1914.\n\nThis era saw the birth of the modern ship as disparate technological advances came together.\n\nThe screw propeller was introduced in 1835 by Francis Pettit Smith who discovered a new way of building propellers by accident. Up to that time, propellers were literally screws, of considerable length. But during the testing of a boat propelled by one, the screw snapped off, leaving a fragment shaped much like a modern boat propeller. The boat moved faster with the broken propeller. The superiority of screw against paddles was taken up by navies. Trials with Smith's SS \"Archimedes\", the first steam driven screw, led to the famous tug-of-war competition in 1845 between the screw-driven and the paddle steamer ; the former pulling the latter backward at 2.5 knots (4.6 km/h).\n\nThe first seagoing iron steamboat was built by Horseley Ironworks and named the \"Aaron Manby\". It also used an innovative oscillating engine for power. The boat was built at Tipton using temporary bolts, disassembled for transportation to London, and reassembled on the Thames in 1822, this time using permanent rivets.\n\nOther technological developments followed, including the invention of the surface condenser, which allowed boilers to run on purified water rather than salt water, eliminating the need to stop to clean them on long sea journeys. The \"Great Western\"\n, built by engineer Isambard Kingdom Brunel, was the longest ship in the world at with a keel and was the first to prove that transatlantic steamship services were viable. The ship was constructed mainly from wood, but Brunel added bolts and iron diagonal reinforcements to maintain the keel's strength. In addition to its steam-powered paddle wheels, the ship carried four masts for sails.\n\nBrunel followed this up with the \"Great Britain\", launched in 1843 and considered the first modern ship built of metal rather than wood, powered by an engine rather than wind or oars, and driven by propeller rather than paddle wheel. Brunel's vision and engineering innovations made the building of large-scale, propeller-driven, all-metal steamships a practical reality, but the prevailing economic and industrial conditions meant that it would be several decades before transoceanic steamship travel emerged as a viable industry.\n\nHighly efficient multiple expansion steam engines began being used on ships, allowing them to carry less coal than freight. The oscillating engine was first built by Aaron Manby and Joseph Maudslay in the 1820s as a type of direct-acting engine that was designed to achieve further reductions in engine size and weight. Oscillating engines had the piston rods connected directly to the crankshaft, dispensing with the need for connecting rods. In order to achieve this aim, the engine cylinders were not immobile as in most engines, but secured in the middle by trunnions which allowed the cylinders themselves to pivot back and forth as the crankshaft rotated, hence the term \"oscillating\".\n\nIt was John Penn, engineer for the Royal Navy who perfected the oscillating engine. One of his earliest engines was the grasshopper beam engine. In 1844 he replaced the engines of the Admiralty yacht, with oscillating engines of double the power, without increasing either the weight or space occupied, an achievement which broke the naval supply dominance of Boulton & Watt and Maudslay, Son & Field. Penn also introduced the trunk engine for driving screw propellers in vessels of war. (1846) and (1848) were the first ships to be fitted with such engines and such was their efficacy that by the time of Penn's death in 1878, the engines had been fitted in 230 ships and were the first mass-produced, high-pressure and high-revolution marine engines.\n\nThe revolution in naval design led to the first modern battleships in the 1870s, evolved from the ironclad design of the 1860s. The \"Devastation\"-class turret ships were built for the British Royal Navy as the first class of ocean-going capital ship that did not carry sails, and the first whose entire main armament was mounted on top of the hull rather than inside it.\n\nThe vulcanization of rubber, by American Charles Goodyear and Englishman Thomas Hancock in the 1840s paved the way for a growing rubber industry, especially the manufacture of rubber tyres\n\nJohn Boyd Dunlop developed the first practical pneumatic tyre in 1887 in South Belfast. Willie Hume demonstrated the supremacy of Dunlop's newly invented pneumatic tyres in 1889, winning the tyre's first ever races in Ireland and then England.\n\nThe modern bicycle was designed by the English engineer Harry John Lawson in 1876, although it was John Kemp Starley who produced the first commercially successful safety bicycle a few years later. Its popularity soon grew, causing the bike boom of the 1890s.\n\nRoad networks improved greatly in the period, using the Macadam method pioneered by Scottish engineer John Loudon McAdam, and hard surfaced roads were built around the time of the bicycle craze of the 1890s. Modern tarmac was patented by British civil engineer Edgar Purnell Hooley in 1901.\n\nGerman inventor Karl Benz patented the world's first automobile in 1886. It featured wire wheels (unlike carriages' wooden ones) with a four-stroke engine of his own design between the rear wheels, with a very advanced coil ignition and evaporative cooling rather than a radiator. Power was transmitted by means of two roller chains to the rear axle. It was the first automobile entirely designed as such to generate its own power, not simply a motorized-stage coach or horse carriage.\n\nBenz began to sell the vehicle (advertising it as the Benz Patent Motorwagen) in the late summer of 1888, making it the first commercially available automobile in history.\n\nHenry Ford built his first car in 1896 and worked as a pioneer in the industry, with others who would eventually form their own companies, until the founding of Ford Motor Company in 1903. Ford and others at the company struggled with ways to scale up production in keeping with Henry Ford's vision of a car designed and manufactured on a scale so as to be affordable by the average worker. The solution that Ford Motor developed was a completely redesigned factory with machine tools and special purpose machines that were systematically positioned in the work sequence. All unnecessary human motions were eliminated by placing all work and tools within easy reach, and where practical on conveyors, forming the assembly line, the complete process being called mass production. This was the first time in history when a large, complex product consisting of 5000 parts had been produced on a scale of hundreds of thousands per year. The savings from mass production methods allowed the price of the Model T to decline from $780 in 1910 to $360 in 1916. In 1924 2 million T-Fords were produced and retailed $290 each.\n\nApplied science opened many opportunities. By the middle of the 19th century there was a scientific understanding of chemistry and a fundamental understanding of thermodynamics and by the last quarter of the century both of these sciences were near their present-day basic form. Thermodynamic principles were used in the development of physical chemistry. Understanding chemistry greatly aided the development of basic inorganic chemical manufacturing and the aniline dye industries.\n\nThe science of metallurgy was advanced through the work of Henry Clifton Sorby and others. Sorby pioneered the study of iron and steel under microscope, which paved the way for a scientific understanding of metal and the mass-production of steel. In 1863 he used etching with acid to study the microscopic structure of metals and was the first to understand that a small but precise quantity of carbon gave steel its strength. This paved the way for Henry Bessemer and Robert Forester Mushet to develop the method for mass-producing steel.\n\nOther processes were developed for purifying various elements such as chromium, molybdenum, titanium, vanadium and nickel which could be used for making alloys with special properties, especially with steel. Vanadium steel, for example, is strong and fatigue resistant, and was used in half the automotive steel. Alloy steels were used for ball bearings which were used in large scale bicycle production in the 1880s. Ball and roller bearings also began being used in machinery. Other important alloys are used in high temperatures, such as steam turbine blades, and stainless steels for corrosion resistance.\n\nThe work of Justus von Liebig and August Wilhelm von Hofmann laid the groundwork for modern industrial chemistry. Liebig is considered the \"father of the fertilizer industry\" for his discovery of nitrogen as an essential plant nutrient and went on to establish Liebig's Extract of Meat Company which produced the Oxo meat extract. Hofmann headed a school of practical chemistry in London, under the style of the Royal College of Chemistry, introduced modern conventions for molecular modeling and taught Perkin who discovered the first synthetic dye.\n\nThe science of thermodynamics was developed into its modern form by Sadi Carnot, William Rankine, Rudolf Clausius, William Thomson, James Clerk Maxwell, Ludwig Boltzmann and J. Willard Gibbs. These scientific principles were applied to a variety of industrial concerns, including improving the efficiency of boilers and steam turbines. The work of Michael Faraday and others was pivotal in laying the foundations of the modern scientific understanding of electricity.\n\nScottish scientist James Clerk Maxwell was particularly influential—his discoveries ushered in the era of modern physics. His most prominent achievement was to formulate a set of equations that described electricity, magnetism, and optics as manifestations of the same phenomenon, namely the electromagnetic field. The unification of light and electrical phenomena led to the prediction of the existence of radio waves and was the basis for the future development of radio technology by Hughes, Marconi and others.\n\nMaxwell himself developed the first durable colour photograph in 1861 and published the first scientific treatment of control theory. Control theory is the basis for process control, which is widely used in automation, particularly for process industries, and for controlling ships and airplanes. Control theory was developed to analyze the functioning of centrifugal governors on steam engines. These governors came into use in the late 18th century on wind and water mills to correctly position the gap between mill stones, and were adapted to steam engines by James Watt. Improved versions were used to stabilize automatic tracking mechanisms of telescopes and to control speed of ship propellers and rudders. However, those governors were sluggish and oscillated about the set point. James Clerk Maxwell wrote a paper mathematically analyzing the actions of governors, which marked the beginning of the formal development of control theory. The science was continually improved and evolved into an engineering discipline.\n\nJustus von Liebig was the first to understand the importance of ammonia as fertilizer, and promoted the importance of inorganic minerals to plant nutrition. In England, he attempted to implement his theories commercially through a fertilizer created by treating phosphate of lime in bone meal with sulfuric acid. Another pioneer was John Bennet Lawes who began to experiment on the effects of various manures on plants growing in pots in 1837, leading to a manure formed by treating phosphates with sulphuric acid; this was to be the first product of the nascent artificial manure industry.\n\nThe discovery of coprolites in commercial quantities in East Anglia, led Fisons and Edward Packard to develop one of the first large-scale commercial fertilizer plants at Bramford, and Snape in the 1850s. By the 1870s superphosphates produced in those factories, were being shipped around the world from the port at Ipswich.\n\nThe Birkeland–Eyde process was developed by Norwegian industrialist and scientist Kristian Birkeland along with his business partner Sam Eyde in 1903, but was soon replaced by the much more efficient Haber process,\ndeveloped by the Nobel prize-winning chemists Carl Bosch of IG Farben and Fritz Haber in Germany. The process utilized molecular nitrogen (N) and methane (CH) gas in an economically sustainable synthesis of ammonia (NH). The ammonia produced in the Haber process is the main raw material for production of nitric acid.\n\nThe steam turbine was developed by Sir Charles Parsons in 1884. His first model was connected to a dynamo that generated 7.5 kW (10 hp) of electricity. The invention of Parson's steam turbine made cheap and plentiful electricity possible and revolutionized marine transport and naval warfare. By the time of Parson's death, his turbine had been adopted for all major world power stations. Unlike earlier steam engines, the turbine produced rotary power rather than reciprocating power which required a crank and heavy flywheel. The large number of stages of the turbine allowed for high efficiency and reduced size by 90%. The turbine's first application was in shipping followed by electric generation in 1903.\n\nThe first widely used internal combustion engine was the Otto type of 1876. From the 1880s until electrification it was successful in small shops because small steam engines were inefficient and required too much operator attention. The Otto engine soon began being used to power automobiles, and remains as today's common gasoline engine.\n\nThe diesel engine was independently designed by Rudolf Diesel and Herbert Akroyd Stuart in the 1890s using thermodynamic principles with the specific intention of being highly efficient. It took several years to perfect and become popular, but found application in shipping before powering locomotives. It remains the world's most efficient prime mover.\n\nThe first commercial telegraph system was installed by Sir William Fothergill Cooke and Charles Wheatstone in May 1837 between Euston railway station and Camden Town in London.\n\nThe rapid expansion of telegraph networks took place throughout the century, with the first undersea cable being built by John Watkins Brett between France and England.\nThe Atlantic Telegraph Company was formed in London in 1856 to undertake to construct a commercial telegraph cable across the Atlantic Ocean. This was successfully completed on 18 July 1866 by the ship SS \"Great Eastern\", captained by Sir James Anderson after many mishaps along the away. From the 1850s until 1911, British submarine cable systems dominated the world system. This was set out as a formal strategic goal, which became known as the All Red Line.\n\nThe telephone was patented in 1876 by Alexander Graham Bell, and like the early telegraph, it was used mainly to speed business transactions.\n\nAs mentioned above, one of the most important scientific advancements in all of history was the unification of light, electricity and magnetism through Maxwell's electromagnetic theory. A scientific understanding of electricity was necessary for the development of efficient electric generators, motors and transformers. David Edward Hughes and Heinrich Hertz both demonstrated and confirmed the phenomenon of electromagnetic waves that had been predicted by Maxwell.\n\nIt was Italian inventor Guglielmo Marconi who successfully commercialized radio at the turn of the century. He founded The Wireless Telegraph & Signal Company in Britain in 1897 and in the same year transmitted Morse code across Salisbury Plain, sent the first ever wireless communication over open sea and made the first transatlantic transmission in 1901 from Poldhu, Cornwall to Signal Hill, Newfoundland. Marconi built high-powered stations on both sides of the Atlantic and began a commercial service to transmit nightly news summaries to subscribing ships in 1904.\n\nThe key development of the vacuum tube by Sir John Ambrose Fleming in 1904 underpinned the development of modern electronics and radio broadcasting. Lee De Forest's subsequent invention of the triode allowed the amplification of electronic signals, which paved the way for radio broadcasting in the 1920s.\n\nRailroads are credited with creating the modern business enterprise by scholars such as Alfred Chandler. Previously, the management of most businesses had consisted of individual owners or groups of partners, some of whom often had little daily hands-on operations involvement. Centralized expertise in the home office was not enough. A railroad required expertise available across the whole length of its trackage, to deal with daily crises, breakdowns and bad weather. A collision in Massachusetts in 1841 led to a call for safety reform. This led to the reorganization of railroads into different departments with clear lines of management authority. When the telegraph became available, companies built telegraph lines along the railroads to keep track of trains.\n\nRailroads involved complex operations and employed extremely large amounts of capital and ran a more complicated business compared to anything previous. Consequently, they needed better ways to track costs. For example, to calculate rates they needed to know the cost of a ton-mile of freight. They also needed to keep track of cars, which could go missing for months at a time. This led to what was called \"railroad accounting\", which was later adopted by steel and other industries, and eventually became modern accounting.\nLater in the Second Industrial Revolution, Frederick Winslow Taylor and others in America developed the concept of scientific management or Taylorism. Scientific management initially concentrated on reducing the steps taken in performing work (such as bricklaying or shoveling) by using analysis such as time-and-motion studies, but the concepts evolved into fields such as industrial engineering, manufacturing engineering, and business management that helped to completely restructure the operations of factories, and later entire segments of the economy.\n\nTaylor's core principles included:\n\n\nThe period from 1870 to 1890 saw the greatest increase in economic growth in such a short period as ever in previous history. Living standards improved significantly in the newly industrialized countries as the prices of goods fell dramatically due to the increases in productivity. This caused unemployment and great upheavals in commerce and industry, with many laborers being displaced by machines and many factories, ships and other forms of fixed capital becoming obsolete in a very short time span.\n\n\"The economic changes that have occurred during the last quarter of a century -or during the present generation of living men- have unquestionably been more important and more varied than during any period of the world's history\".\nCrop failures no longer resulted in starvation in areas connected to large markets through transport infrastructure.\n\nMassive improvements in public health and sanitation resulted from public health initiatives, such as the construction of the London sewerage system in the 1860s and the passage of laws that regulated filtered water supplies—(the Metropolis Water Act introduced regulation of the water supply companies in London, including minimum standards of water quality for the first time in 1852). This greatly reduced the infection and death rates from many diseases.\n\nBy 1870 the work done by steam engines exceeded that done by animal and human power. Horses and mules remained important in agriculture until the development of the internal combustion tractor near the end of the Second Industrial Revolution.\n\nImprovements in steam efficiency, like triple-expansion steam engines, allowed ships to carry much more freight than coal, resulting in greatly increased volumes of international trade. Higher steam engine efficiency caused the number of steam engines to increase several fold, leading to an increase in coal usage, the phenomenon being called the Jevons paradox.\n\nBy 1890 there was an international telegraph network allowing orders to be placed by merchants in England or the US to suppliers in India and China for goods to be transported in efficient new steamships. This, plus the opening of the Suez Canal, led to the decline of the great warehousing districts in London and elsewhere, and the elimination of many middlemen.\n\nThe tremendous growth in productivity, transportation networks, industrial production and agricultural output lowered the prices of almost all goods. This led to many business failures and periods that were called \"depressions\" that occurred as the world economy actually grew. See also: Long depression\n\nThe factory system centralized production in separate buildings funded and directed by specialists (as opposed to work at home). The division of labor made both unskilled and skilled labor more productive, and led to a rapid growth of population in industrial centers. The shift away from agriculture toward industry had occurred in Britain by the 1730s, when the percentage of the working population engaged in agriculture fell below 50%, a development that would only happen elsewhere (the Low Countries) in the 1830s and '40s. By 1890, the figure had fallen to under 10% percent and the vast majority of the British population was urbanized. This milestone was reached by the Low Countries and the US in the 1950s.\n\nLike the first industrial revolution, the second supported population growth and saw most governments protect their national economies with tariffs. Britain retained its belief in free trade throughout this period. The wide-ranging social impact of both revolutions included the remaking of the working class as new technologies appeared. The changes resulted in the creation of a larger, increasingly professional, middle class, the decline of child labor and the dramatic growth of a consumer-based, material culture.\n\nBy 1900, the leaders in industrial production was Britain with 24% of the world total, followed by the US (19%), Germany (13%), Russia (9%) and France (7%). Europe together accounted for 62%.\n\nThe great inventions and innovations of the Second Industrial Revolution are part of our modern life. They continued to be drivers of the economy until after WWII. Only a few major innovations occurred in the post-war era, some of which are: computers, semiconductors, the fiber optic network and the Internet, cellular telephones, combustion turbines (jet engines) and the Green Revolution. Although commercial aviation existed before WWII, it became a major industry after the war.\n\nNew products and services were introduced which greatly increased international trade. Improvements in steam engine design and the wide availability of cheap steel meant that slow, sailing ships were replaced with faster steamship, which could handle more trade with smaller crews. The chemical industries also moved to the forefront. Britain invested less in technological research than the U.S. and Germany, which caught up.\n\nThe development of more intricate and efficient machines along with mass production techniques (after 1910) greatly expanded output and lowered production costs. As a result, production often exceeded domestic demand. Among the new conditions, more markedly evident in Britain, the forerunner of Europe's industrial states, were the long-term effects of the severe Long Depression of 1873–1896, which had followed fifteen years of great economic instability. Businesses in practically every industry suffered from lengthy periods of low — and falling — profit rates and price deflation after 1873.\n\nThe U.S. had its highest economic growth rate in the last two decades of the Second Industrial Revolution; however, population growth slowed while productivity growth peaked around the mid 20th century. The Gilded Age in America was based on heavy industry such as factories, railroads and coal mining. The iconic event was the opening of the First Transcontinental Railroad in 1869, providing six-day service between the East Coast and San Francisco.\n\nDuring the Gilded Age, American railroad mileage tripled between 1860 and 1880, and tripled again by 1920, opening new areas to commercial farming, creating a truly national marketplace and inspiring a boom in coal mining and steel production. The voracious appetite for capital of the great trunk railroads facilitated the consolidation of the nation's financial market in Wall Street. By 1900, the process of economic concentration had extended into most branches of industry—a few large corporations, some organized as \"trusts\" (e.g. Standard Oil), dominated in steel, oil, sugar, meatpacking, and the manufacture of agriculture machinery. Other major components of this infrastructure were the new methods for manufacturing steel, especially the Bessemer process. The first billion-dollar corporation was United States Steel, formed by financier J. P. Morgan in 1901, who purchased and consolidated steel firms built by Andrew Carnegie and others.\n\nIncreased mechanization of industry and improvements to worker efficiency, increased the productivity of factories while undercutting the need for skilled labor. Mechanical innovations such as batch and continuous processing began to become much more prominent in factories. This mechanization made some factories an assemblage of unskilled laborers performing simple and repetitive tasks under the direction of skilled foremen and engineers. In some cases, the advancement of such mechanization substituted for low-skilled workers altogether. Both the number of unskilled and skilled workers increased, as their wage rates grew Engineering colleges were established to feed the enormous demand for expertise. Together with rapid growth of small business, a new middle class was rapidly growing, especially in northern cities.\n\nIn the early 1900s there was a disparity between the levels of employment seen in the northern and southern United States. On average, states in the North had both a higher population, and a higher rate of employment than states in the South. The higher rate of employment is easily seen by considering the 1909 rates of employment compared to the populations of each state in the 1910 census. This difference was most notable in the states with the largest populations, such as New York and Pennsylvania. Each of these states had roughly 5 percent more of the total US workforce than would be expected given their populations. Conversely, the states in the South with the best actual rates of employment, North Carolina and Georgia, had roughly 2 percent less of the workforce than one would expect from their population. When the averages of all southern states and all northern states are taken, the trend holds with the North over-performing by about 2 percent, and the South under-performing by about 1 percent.\n\nThe German Empire came to rival Britain as Europe's primary industrial nation during this period. Since Germany industrialized later, it was able to model its factories after those of Britain, thus making more efficient use of its capital and avoiding legacy methods in its leap to the envelope of technology. Germany invested more heavily than the British in research, especially in chemistry, motors and electricity. The German concern system (known as \"Konzerne\"), being significantly concentrated, was able to make more efficient use of capital. Germany was not weighted down with an expensive worldwide empire that needed defense. Following Germany's annexation of Alsace-Lorraine in 1871, it absorbed parts of what had been France's industrial base.\n\nBy 1900 the German chemical industry dominated the world market for synthetic dyes. The three major firms BASF, Bayer and Hoechst produced several hundred different dyes, along with the five smaller firms. In 1913 these eight firms produced almost 90 percent of the world supply of dyestuffs, and sold about 80 percent of their production abroad. The three major firms had also integrated upstream into the production of essential raw materials and they began to expand into other areas of chemistry such as pharmaceuticals, photographic film, agricultural chemicals and electrochemical. Top-level decision-making was in the hands of professional salaried managers, leading Chandler to call the German dye companies \"the world's first truly managerial industrial enterprises\". There were many spin offs from research—such as the pharmaceutical industry, which emerged from chemical research.\n\nBelgium during the Belle Époque showed the value of the railways for speeding the Second Industrial Revolution. After 1830, when it broke away from the Netherlands and became a new nation, it decided to stimulate industry. It planned and funded a simple cruciform system that connected major cities, ports and mining areas, and linked to neighboring countries. Belgium thus became the railway center of the region. The system was soundly built along British lines, so that profits were low but the infrastructure necessary for rapid industrial growth was put in place.\n\nThere have been other times that have been called \"second industrial revolution\". Industrial revolutions may be renumbered by taking earlier developments, such as the rise of medieval technology in the 12th century, or of ancient Chinese technology during the Tang Dynasty, or of ancient Roman technology, as first. \"Second industrial revolution\" has been used in the popular press and by technologists or industrialists to refer to the changes following the spread of new technology after World War I.\n\nExcitement and debate over the dangers and benefits of the Atomic Age were more intense and lasting than those over the Space age but both were predicted to lead to another industrial revolution. At the start of the 21st century the term \"second industrial revolution\" has been used to describe the anticipated effects of hypothetical molecular nanotechnology systems upon society. In this more recent scenario, they would render the majority of today's modern manufacturing processes obsolete, transforming all facets of the modern economy.\n\n"}
{"id": "15682002", "url": "https://en.wikipedia.org/wiki?curid=15682002", "title": "Seven stages of action", "text": "Seven stages of action\n\nSeven stages of action is a term coined by the usability consultant Donald Norman. \nHe explains this phrase in chapter two of his book \"The Design of Everyday Things\", in the context of explaining the psychology of a person behind the task performed by him or her.\n\nThe history behind the action cycle starts from a conference in Italy attended by Donald Norman.\nThis excerpt has been taken from the book \"The Design of Everyday Things\":\n\nI am in Italy at a conference. I watch the next speaker attempt to thread a film onto a projector that he never used before. He puts the reel into place, then takes it off and reverses it. Another person comes to help. Jointly they thread the film through the projector and hold the free end, discussing how to put it on the takeup reel. Two more people come over to help and then another. The voices grow louder, in three languages: Italian, German and English. One person investigates the controls, manipulating each and announcing the result. Confusion mounts. I can no longer observe all that is happening. The conference organizer comes over. After a few moments he turns and faces the audience, who had been waiting patiently in the auditorium. \"Ahem,\" he says, \"is anybody expert in projectors?\" Finally, fourteen minutes after the speaker had started to thread the film (and eight minutes after the scheduled start of the session) a blue-coated technician appears. He scowls, then promptly takes the entire film off the projector, rethreads it, and gets it working.\nNorman pondered on the reasons that made something like threading of a projector difficult to do. To examine this, he wanted to know what happened when something implied nothing. In order to do that, he examined the structure of an action. So to get something done, a notion of what is wanted – the goal that is to be achieved, needs to be started. Then, something is done to the world i.e. take action to move oneself or manipulate someone or something. Finally, the checking is required if the goal was made. This led to formulation of Stages of Execution and Evaluation.\n\n\"Execution\" formally means to perform or do something. Norman explains that a person sitting on an armchair while reading a book at dusk, might need more light when it becomes dimmer and dimmer. To do that, he needs to switch on the button of a lamp i.e. get more light (the goal). To do this, one must need to specify on how to move one's body, how to stretch to reach the light switch and how to extend one's finger to push the button. The goal has to be translated into an intention, which in turn has to be made into an action sequence.\n\nThus, formulation of stages of execution:\n\n\"Evaluation\" formally means to examine and calculate. Norman explains that after turning on the light, we evaluate if it is actually turned on. A careful judgement is then passed on how the light has affected our world i.e. the room in which the person is sitting on the armchair while reading a book.\n\nThe formulation of the stages of evaluation can be described as:\n\nSeven Stages of Action constitute four stages of execution, three stages of evaluation and our goals.\n\n1. Forming the goal\n\n2. Forming the intention\n\n3. Specifying an action\n\n4. Executing the action\n\n5. Perceiving the state of the world\n\n6. Interpreting the state of the world\n\n7. Evaluating the outcome \n\nThe difference between the intentions and the allowable actions is the \"Gulf of execution\".\n\n\"Consider the movie projector example: one problem resulted from the Gulf of Execution. The person wanted to set up the projector. Ideally, this would be a simple thing to do. But no, a long, complex sequence was required. It wasn't all clear what actions had to be done to accomplish the intentions of setting up the projector and showing the film.\"\nThe \"Gulf of evaluation\" reflects the amount of effort that the person must exert to interpret the physical state of the system and to determine how well the expectations and intentions have been met.\n\n\"In the movie projector example there was also a problem with the Gulf of Evaluation. Even when the film was in the projector, it was difficult to tell if it had been threaded correctly.\"\nThe seven-stage structure is referenced as design aid to act as a basic checklist for designers' questions to ensure that the Gulfs of Execution and Evaluation are bridged.\n\nThe Seven Stages of Action can be broken down into 4 main principles of good design:\n\n\n"}
{"id": "3199082", "url": "https://en.wikipedia.org/wiki?curid=3199082", "title": "ShapeWriter", "text": "ShapeWriter\n\nShapeWriter (previously known as Shorthand-Aided Rapid Keyboarding (SHARK)) was a keyboard text input method for tablet, handheld PCs, and mobile phones invented by Shumin Zhai and Per Ola Kristensson at IBM Almaden Research Center and the Department of Computer and Information Science at Linköping University.\n\nUsing ShapeWriter text entry software, a user draws words on a graphical keyboard using a pen. Instead of tapping the keys, the user draws a pen gesture that connects all the letters in the desired word. After some usage the user learns the movement pattern for the commonly used words and can write them faster than is possible on a traditional virtual keyboard.\n\nThe first system described by Shumin Zhai and Per Ola Kristensson (2003) was only a prototype system that could recognize about 100 pen gestures for the top 100 words used in the English language. It used a handwriting recognition algorithm that relied on dynamic programming to recognize the word patterns drawn from a lexicon. The next version described by Per Ola Kristensson and Shumin Zhai (2004) has a fundamentally different recognition engine that can recognize 50,000 - 60,000 words with low latency. This system introduced the notion that every word in a large lexicon should be possible to write by tracing the letters. It is this system that was the basis for the software release on IBM alphaWorks that is generally associated with the term \"ShapeWriter\".\n\nShapeWriter was acquired by Nuance Communications, and taken off the market in 2010., its technology presumably incorporated as part of Nuance's FlexT9 app in 2011.\n\nShapeWriter was made available for the iPhone approximately in 2008 and was revised several times (including ShapeWriter Lite and ShapeWriter Pro or Plus) before being pulled due to its sale to Nuance Communications (see following entry).\n\nThose who purchased the iPhone version continued to use it and it also functioned on iPads v. 1 and 2 until 2013.\n\nAs of 2013 it no longer functions on iOS devices and is no longer available in Apple's App Store.\n\nShapeWriter software was made available as a free application for Android (operating system) smartphones through the Android Market. As a touchscreen keyboard replacement, it had over 50,000 users on Android worldwide. It was available only for Android OS versions 1.6 or higher. ShapeWriter for Android was available in 7 European languages including English, Spanish, and German. There was also a Beta release for Android 1.5 phones including the HTC Hero and Droid Eris.\n\nShapeWriter, Inc. was purchased by Nuance Communications and the ShapeWriter software was removed from the Android Market indefinitely on June 20, 2010.\n\n"}
{"id": "16017237", "url": "https://en.wikipedia.org/wiki?curid=16017237", "title": "Style guide", "text": "Style guide\n\nA style guide (or manual of style) is a set of standards for the writing and design of documents, either for general use or for a specific publication, organization, or field. (It is often called a style sheet, though that term has other meanings.)\n\nA style guide establishes and enforces style to improve communication. To do that, it ensures consistency within a document and across multiple documents and enforces best practice in usage and in language composition, visual composition, orthography and typography. For academic and technical documents, a guide may also enforce the best practice in ethics (such as authorship, research ethics, and disclosure), pedagogy (such as exposition and clarity), and compliance (technical and regulatory).\n\nStyle guides are common for general and specialized use, for the general reading and writing audience, and for students and scholars of various academic disciplines, medicine, journalism, the law, government, business, and specific industries. House style refers to the internal style manual of a particular publisher or organization.\n\nStyle guides vary widely in scope and size.\n\nThis variety in scope and length is enabled by the cascading of one style over another, in a way analogous to how styles cascade in web development and in desktop publishing (e.g., how inline styles in HTML cascade over CSS styles).\n\nA short style guide is often called a \"style sheet\". A comprehensive guide tends to be long and is often called a \"style manual\" or \"manual of style\" (\"MOS\" or \"MoS\"). In many cases, a project such as one book, journal, or monograph series typically has a short style sheet that cascades over the somewhat larger style guide of an organization such as a publishing company, whose content is usually called \"house style\". Most house styles, in turn, cascade over an \"industry-wide or profession-wide style manual\" that is even more comprehensive. Some examples of these industry style guides include the following: \n\nFinally, these reference works cascade over the orthographic norms of the language in use (for example, English orthography for English-language publications). This, of course, may be subject to national variety such as the different varieties of American English and British English.\n\nSome style guides focus on specific topic areas such as graphic design, including typography. Website style guides cover a publication's visual and technical aspects along with text.\n\nStyle guides that cover usage may suggest ways of describing people that avoid racism, sexism, and homophobia. Guides in specific scientific and technical fields cover nomenclature, which specifies names or classifying labels that are preferred because they are clear, standardized, and ontologically sound (e.g., taxonomy, chemical nomenclature, and gene nomenclature).\n\nMost style guides are revised periodically to accommodate changes in conventions and usage. The frequency of updating and the revision control are determined by the subject matter. For style manuals in reference work format, new editions typically appear every 1 to 20 years. For example, the AP Stylebook is revised annually, and the Chicago, APA, and ASA manuals are in their 17th, 6th, and 4th editions, respectively. Many house styles and individual project styles change more frequently, especially for new projects.\n\nSeveral basic style guides for technical and scientific communication have been defined by international standards organizations. One example is ISO 215 \"Documentation — Presentation of contributions to periodicals and other serials\".\n\nThe European Union publishes an \"Interinstitutional style guide\"—encompassing 24 languages across the European Union. This manual is \"obligatory\" for all those employed by the institutions of the EU who are involved in preparing EU documents and works. The Directorate-General for Translation of the European Commission publishes its own \"English Style Guide\", intended primarily for English-language authors and translators, but aiming to serve a wider readership as well.\n\n\nGeneral\n\nJournalism\n\nLaw\n\n\n\nIn the United States, most public-facing corporate communication and journalism writing is written with styles following \"The Associated Press Stylebook\". Book publishers and authors of journals requiring reference sections generally choose the Chicago Manual of Style, while scholarly writing often follows the \"MLA Style Manual and Guide to Scholarly Publishing\". One of the most popular grammar guides used in third-person writing is \"The Elements of Style\". The Associated Press Stylebook is written to be used together with The Elements of Style to provide a very complete grammar and English style reference with no conflicts.\n\n\n\n\n\n\n\nDespite the near uniform use of the Bluebook, nearly every state has appellate court rules that specify citation methods and writing styles specific to that state - and the Supreme Court of the United States has its own citation method. However, in most cases these are derived from the Bluebook.\n\nThere are also several other citation manuals available to legal writers in wide usage in the United States. Virtually all large law firms maintain their own citation manual and several major publishers of legal texts (West, Lexis-Nexis, Hein, \"et al.\") maintain their own systems.\n\n\n\n\n\nGuidelines for citing web content also appear in comprehensive style guides such as Oxford/Hart, Chicago and MLA.\n\n"}
{"id": "20418621", "url": "https://en.wikipedia.org/wiki?curid=20418621", "title": "Vacuum airship", "text": "Vacuum airship\n\nA vacuum airship, also known as a vacuum balloon, is a hypothetical airship that is evacuated rather than filled with a lighter-than-air gas such as hydrogen or helium. First proposed by Italian Jesuit priest Francesco Lana de Terzi in 1670, the vacuum balloon would be the ultimate expression of displacement lift power.\n\nFrom 1886 to 1900 Arthur De Bausset attempted in vain to raise funds to construct his \"vacuum-tube\" airship design, but despite early support in the United States Congress, the general public was skeptical. Illinois historian Howard Scamehorn reported that Octave Chanute and Albert Francis Zahm \"publicly denounced and mathematically proved the fallacy of the vacuum principle\", however the author does not give his source. De Bausset published a book on his design and offered $150,000 stock in the Transcontinental Aerial Navigation Company of Chicago. His patent application was eventually denied on the basis that it was \"wholly theoretical, everything being based upon calculation and nothing upon trial or demonstration.\"\n\nIn 1921, Lavanda Armstrong discloses a composite wall structure with a vacuum chamber \"surrounded by a second envelop constructed so as to hold air under pressure, the walls of the envelope being spaced from one another and tied together\", including a honeycomb-like cellular structure, however leaving some uncertainty how to achieve adequate buoyancy given \"walls may be made as thick and strong as desired\".\n\nIn 1983, David Noel discussed the use of geodesic sphere covered with plastic film and \"a double balloon containing pressurized air between the\nskins, and a vacuum in the centre\".\n\nIn 1982–1985 Emmanuel Bliamptis elaborated on energy sources and use of \"inflatable strut rings\".\n\nIn 2004–2007 Akhmeteli and Gavrilin address choice of materials (\"beryllium, boron carbide ceramic, and diamond-like carbon\" or aluminum) in honeycomb double layer craft to address buckling issues.\n\nAn airship operates on the principle of buoyancy, according to Archimedes' principle. In an airship, air is the fluid in contrast to a traditional ship where water is the fluid.\n\nThe density of air at standard temperature and pressure is 1.28 g/l, so 1 liter of displaced air has sufficient buoyant force to lift 1.28 g. Airships use a bag to displace a large volume of air; the bag is usually filled with a lightweight gas such as helium or hydrogen. The total lift generated by an airship is equal to the weight of the air it displaces, minus the weight of the materials used in its construction including the gas used to fill the bag.\n\nVacuum airships would replace the helium gas with a near-vacuum environment, having no mass, density would be near to 0.00 g/l, which would theoretically be able to provide the full lift potential of displaced air, so every liter of vacuum could lift 1.28 g. Using the molar volume, the mass of 1 liter of helium (at 1 atmospheres of pressure) is found to be 0.178 g. If helium is used instead of vacuum, the lifting power of every liter is reduced by 0.178 g, so the effective lift is reduced by 14%. A 1-liter volume of hydrogen has a mass of 0.090 g.\n\nThe main problem with the concept of vacuum airships is that, with a near-vacuum inside the airbag, the exterior atmospheric pressure is not balanced by any internal pressure. This enormous imbalance of forces would cause the airbag to collapse unless it were extremely strong (in an ordinary airship, the force is balanced by helium, making this unnecessary). Thus the difficulty is in constructing an airbag with the additional strength to resist this extreme net force, without weighing the structure down so much that the greater lifting power of vacuum is negated.\n\nFrom the analysis by Akhmeteli and Gavrilin:\n\nThe total force on a hemi-spherical shell of radius formula_1 by an external pressure formula_2 is formula_3. Since the force on each hemisphere has to balance along the equator the compressive stress will be, assuming formula_4 \nwhere formula_6 is the shell thickness.\n\nNeutral buoyancy occurs when the shell has the same mass as the displaced air, which occurs when formula_7, where formula_8 is the air density and formula_9 is the shell density, assumed to be homogeneous. Combining with the stress equation gives \nFor aluminum and terrestrial conditions Akhmeteli and Gavrilin estimate the stress as formula_11 Pa, of the same order of magnitude as the compressive strength of aluminum alloys.\n\nAkhmeteli and Gavrilin note, however, that the compressive strength calculation disregards buckling, and using R. Zoelli's formula for the critical buckling pressure of a sphere\nwhere formula_13 is the modulus of elasticity and formula_14 is the Poisson ratio of the shell. Substituting the earlier expression gives a necessary condition for a feasible vacuum balloon shell:\nThe requirement is about formula_16.\n\nAkhmeteli and Gavrilin assert that this cannot even be achieved using diamond (formula_17), and \npropose that dropping the assumption that the shell is a homogeneous material may allow lighter and stiffer structures (e.g. a honeycomb structure).\n\nA vacuum airship should at least float (Archimedes law) and resist external pressure (strength law, depending on design, like the above R. Zoelli's formula for sphere). These two conditions may be rewritten as an inequality where a complex of several physical constants related to the material of the airship is to be lesser than a complex of atmospheric parameters. Thus, for a sphere (hollow sphere and, to a lesser extent, cylinder are practically the only designs for which a strength law is known) it is formula_18, where formula_19 is pressure within the sphere, while formula_20 («Lana coefficient») and formula_21 («Lana atmospheric ratio») are:\n\nwhere formula_28 formula_29 and formula_30 formula_31 are pressure and density of standard Earth atmosphere at sea level, formula_32 and formula_33 are molar mass (kg/kmol) and temperature (K) of atmosphere at floating area.\nOf all known planets and moons of the Sun system only the Venusian atmosphere has formula_21 big enough to surpass formula_20 for such materials as some composites (below altitude of ca. 15 km) and graphene (below altitude of ca. 40 km). Both materials may survive in the Venusian atmosphere. The equation for formula_21 shows that exoplanets with dense, cold and high-molecular (formula_37, formula_38, formula_39 type) atmospheres may be suitable for vacuum airships, but it is a rare type of atmosphere.\n\nIn the Edgar Rice Burroughs novel \"Tarzan at the Earth's Core\" Tarzan travels to Pellucidar in a vacuum airship constructed of the fictional material Harbenite.\n\nIn \"Passarola Rising\", novelist Azhar Abidi imagines what might have happened had Bartolomeu de Gusmão built and flown a vacuum airship.\n\nSpherical vacuum body airships using the Magnus effect and made of carbyne or similar superhard carbon are glimpsed in Neal Stephenson's novel \"The Diamond Age\".\n\nIn \"Maelstrom\" and \"Behemoth:B-Max\", author Peter Watts describes various flying devices, such as \"botflies\" and \"lifters\" that use \"vacuum bladders\" to keep them airborne.\n\nIn \"Feersum Endjinn\" by Iain M. Banks, a vacuum balloon is used by the narrative character Bascule in his quest to rescue Ergates. Vacuum dirigibles (airships) are also mentioned as a notable engineering feature of the space-faring utopian civilisation The Culture in Banks' novel \"Look to Windward\", and the vast vacuum dirigible Equatorial 353 is a pivotal location in the final Culture novel, \"The Hydrogen Sonata\".\n\n"}
{"id": "57534427", "url": "https://en.wikipedia.org/wiki?curid=57534427", "title": "XP-PEN", "text": "XP-PEN\n\nXP-Pen is founded in Japan in 2005, it specializes in graphics tablets, pen display monitors, light pads, stylus pens and digital graphical products. In 2008 they established an office in Taiwan. In 2013, XP-Pen Technology Co. was founded in the United States. In 2015 they opened their office in Shenzhen, China. \n\nIn December 2017, they were invited to DreamWorks campus in Glendale California. in October 2017, they exhibited in Stan Lee Comic Con during the Halloween weekend. In July 2017, they took part in Los Angeles' 25th Anime Expo.\n\nArtist series display\nXP-Pen supplies drivers for Windows 7, 8, 10 and Mac 10.8 and above.\n"}
