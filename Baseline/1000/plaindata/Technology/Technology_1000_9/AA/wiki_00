{"id": "12576767", "url": "https://en.wikipedia.org/wiki?curid=12576767", "title": "Advanced Technology Development Center", "text": "Advanced Technology Development Center\n\nThe Advanced Technology Development Center (ATDC) is a science and business incubator in Georgia. It is part of the Enterprise Innovation Institute (EI2) at the Georgia Institute of Technology, and is headquartered in Technology Square. ATDC was formed in 1980 to stimulate growth in Georgia's technology business base, and admitted its first member company in 1981. It now has locations in Atlanta and Savannah. In 2011, ATDC expanded its mission by merging with Georgia Tech’s VentureLab and with the Georgia SBIR Assistance Program. ATDC has opened its membership to all technology entrepreneurs in Georgia, from those at the earliest conception stage to the well-established, venture-fundable companies.\n\nMore than 120 companies started there, including firms such as MindSpring (now part of EarthLink) and TransNexus. Sponsored companies have created almost 51,000 man-years of employment, generated over $12.7 billion revenue, generated over $100 million in profit to Georgia, and raised over $1 billion in venture capital since 1999. ATDC has been recognized by Inc. Magazine and Business Week as one of the nation's top incubators, and won several other awards.\n"}
{"id": "7127409", "url": "https://en.wikipedia.org/wiki?curid=7127409", "title": "BC Research", "text": "BC Research\n\nBC Research Inc. was based at a scientific research and development company located at the BC Research and Innovation Complex at the south end of the University of British Columbia campus. The facility closed in November 2007. The company specialized in consulting and applied research and development in the area of plant biotechnology and environment, health and safety, process and analysis, transportation and ship dynamics.\n\nThe company can be traced back to 1944 as it developed from the non-profit BC Research Council to a private company in 1993, founded by Dr. Hugh Wynne-Edwards, Ph.D, DSc., FRSC, a member of the Order of Canada, who served as the founding Chief Executive Officer and developed the facility into one of Canada's most recognized incubators in the fields of biotechnology, drug discovery and alternative fuel technologies. In 2000, BC Research was purchased by Immune Network Ltd and was sold to Cromedica (now PRA International) in July 2001 for a consideration of $8.3 million according to 2001 audited financials published on SEDAR. Its plant biotechnology team was mostly spun off in Silvagen Inc. which specialized in clonal reforestation and which became a part of CellFor. In 1999 Azure Dynamics, a hybrid commercial vehicle systems developer, was formed with some of the transportation team and left the facility in 2004 having gone public in 2001 as Azure Dynamics Corporation. Technologies, Inc., specializing in microwave-assisted natural product extraction, purification and isolation, was also spun off in 2001 as a joint venture with Environment Canada. The remaining laboratory and consulting business functions continued under the name Vizon SciTec until August 2006 when CANTEST Ltd. announced its acquisition from BC Research Inc. which continues as a privately held technology holding company. \n\nIn May 2007, the former Industrial Process Division of BC Research was acquired by Kemetco Research Inc. Kemetco provides contract research, process development and laboratory testing services to industry, primarily in mining, metallurgy and chemical processing. Since inception, Kemetco has grown to be one of the largest privately held contract R&D firms in Canada that services Environmental, Chemical and Mining companies. Kemetco operates in an state-of-the-art R&D facility in Richmond, British Columbia. \nFinally in 2010, BC Research Inc., BCRI, opened again for business in its new research facilities in Burnaby, B.C. Their board of directors is composed of Kemetco and NORAM Engineering and Constructors Ltd business and technology leaders. The Company continues to provide specialized consulting and applied research and development in an expanding number of different technologies and industries, including fluidized beds, storage of energy in batteries, fuel cells, electrochemical cells, corrosion testing and analysis, hydrogen, sulfur, chlorine, nitration, water treatment, and pulp and paper chemistry.\nAs of Q4 2016 BCRI is opening a newly constructed facility on Mitchell Island in Vancouver B.C. to expand their capabilities.\n\n"}
{"id": "59161710", "url": "https://en.wikipedia.org/wiki?curid=59161710", "title": "BIM Collaboration Format", "text": "BIM Collaboration Format\n\nThe BIM Collaboration Format (BCF) is a structured file format which allows issue tracking with a building information model. BCF is designed primarily for attaching information to collisions and errors connected with specific objects in a model, but can be used for general issue tracking in building construction projects. This allows developers of BIM-supporting software to design interfaces for collaboration between users who access the same model, especially with different software.\n\nThe format was developed by Tekla and Solibri and later adopted as a standard by buildingSMART. Notable software with native support for BCF are Solibri, Tekla with plugins which provide usability for other software.\n\n\n"}
{"id": "29138975", "url": "https://en.wikipedia.org/wiki?curid=29138975", "title": "Backshop", "text": "Backshop\n\nA backshop or back-shop is a specialized store or workshop found in service industries, such as locomotive and aircraft repair. Most repairs are carried out in small workshops, except where an industrial service is needed.\n\nIn the military, backshops repair parts known as shop-replaceable units (SRUs). These are commonly stocked subassemblies of a larger system, such as circuit cards components of a line-replaceable unit (LRU), designed to be repaired at the field level. Repair at this level is known as field-level maintenance or intermediate-level (I-level) maintenance. \nCalibration and repair of United States Air Force test equipment is conducted at shops known as precision measurement equipment laboratories.\n\n"}
{"id": "30819581", "url": "https://en.wikipedia.org/wiki?curid=30819581", "title": "Comparison of Nikon DSLR cameras", "text": "Comparison of Nikon DSLR cameras\n\nThe following table compares general and technical features of Nikon DSLR cameras.\n\nKey:\n\n"}
{"id": "14192567", "url": "https://en.wikipedia.org/wiki?curid=14192567", "title": "Comparison of orbital launch systems", "text": "Comparison of orbital launch systems\n\nThis is a comparison of orbital launch systems. The following exposes the full list of conventional orbital launch systems. For the short simple list of conventional launcher families, see: Comparison of orbital launchers families. For the list of predominantly solid-fuelled orbital launch systems, see: Comparison of solid-fuelled orbital launch systems.\n\nSpacecraft propulsion is any method used to accelerate spacecraft and artificial satellites. A conventional solid rocket or a conventional solid-fuel rocket is a rocket with a motor that uses solid propellants (fuel/oxidizer). Orbital launch systems are rockets and other systems capable of placing payloads into or beyond Earth orbit. All current spacecraft use conventional chemical rockets (bipropellant or solid-fuel) for launch, though some have used air-breathing engines on their first stage.\n\nThe following chart shows the number of launch systems developed in each country, and broken down by operational status. Rocket variants are not distinguished; i.e., the Atlas V series is only counted once for all its configurations 401–431, 501–551, 552, and N22.\n"}
{"id": "10551079", "url": "https://en.wikipedia.org/wiki?curid=10551079", "title": "Comparison of recording mediums", "text": "Comparison of recording mediums\n\nThis article details a comparison of audio recording mediums.\n\nThe typical duration of a vinyl album is about 15 to 25 minutes per side. Classical music and spoken word recordings can extend to over 30 minutes on a side. If a side exceeds the average time, the maximum groove amplitude is reduced to make room for the additional program material. This can cause hiss in the sound from lower quality amplifiers when the volume is turned up to compensate for the lower recorded level. An extreme example, Todd Rundgren's \"Initiation\" LP, with 36 minutes of music on one side, has a \"technical note\" at the bottom of the inner sleeve: \"if the sound does not seem loud enough on your system, try re-recording the music onto tape.\" The total of around 40–45 minutes often influences the arrangement of tracks, with the preferred positions being the opening and closing tracks of each side.\n\nAlthough the term EP is commonly used to describe a 7\" single with more than two tracks, technically they are not different from a normal 7\" single. The EP uses reduced dynamic range and a smaller run-off groove area to extend the playing time. However, there are examples of singles, such as The Beatles' \"Hey Jude\" or Queen's \"Bohemian Rhapsody\", which are six minutes long or more. (in 1989, RCA released 'Dreamtime' by the band Love and Rockets, which clocks at 8:40). These longer recordings would require the same technical approach as an EP. The term EP has also been used for 10\" 45 rpm records, typically containing a reduced number of tracks.\n\nVinyl albums have a large 12\" (30 cm) album cover, which also allows cover designers scope for imaginative designs, often including fold-outs and leaflets.\n\n\n\n"}
{"id": "3568143", "url": "https://en.wikipedia.org/wiki?curid=3568143", "title": "DARPA XG", "text": "DARPA XG\n\nThe neXt Generation program or XG is a technology development project sponsored by DARPA's Strategic Technology Office, with the goals to \"develop both the enabling technologies and system concepts to dynamically redistribute allocated spectrum along with novel waveforms in order to provide dramatic improvements in assured military communications in support of a full range of worldwide deployments.\"\n\nIn the Wireless World Research Forum of 27 October 2003, Preston Marshall, program manager of DARPA XG Program, said \"The primary product of the XG program is not a new radio, but a set of advanced technologies for dynamic spectrum\naccess.\"\n\n\n"}
{"id": "38183293", "url": "https://en.wikipedia.org/wiki?curid=38183293", "title": "DaVinci (software)", "text": "DaVinci (software)\n\nDaVinci is a development tool used to create HTML5 mobile applications and media content. It includes a jQuery framework, which is a JavaScript library, and can be used by developers and designers, to create web applications used on mobile devices, that have a user experience similar to native applications. Business applications, games, and rich media content, such as HTML5 multi-media magazines, advertisements, and animation, may be produced with the tool. DaVinci is based on standard web technology, including HTML5, CSS3, and JavaScript.\n\nDaVinci is composed of DaVinci Studio and DaVinci Animator, which handle application programming and UI design, respectively. The tool has a WYSIWYG (What You See Is What You Get) authoring environment in which users may drag and drop components to build applications and design web content.\n\nOpen source libraries, such as KnockOut, jsView/jsRender, Impress.js, and turn.js are included in the tool. Other open source frameworks may also be integrated.\n\nThe Model View Controller (MVC) and Data Binding in JavaScript may be handled through DaVinci’s Data-Set Editor. Here, view components and model data may be visually bound, which allows users to create web applications with server integrated UI components without coding.\n\nDaVinci also includes a N-Screen editor, which automatically applies designs and functions to the screen size of various devices, such as smartphones, tablet PCs, and smartTV.\n\nDaVinci has worked closely with the jQuery Foundation in presenting the very first jQuery conference in an Asian district on November 12, 2012 in Seoul, South Korea. DaVinci had been used as a tool to demonstrate application development techniques at the conference.\n\n\n"}
{"id": "3990817", "url": "https://en.wikipedia.org/wiki?curid=3990817", "title": "Differential technological development", "text": "Differential technological development\n\nDifferential technological development is a strategy proposed by transhumanist philosopher Nick Bostrom in which societies would seek to influence the sequence in which emerging technologies developed. On this approach, societies would strive to retard the development of harmful technologies and their applications, while accelerating the development of beneficial technologies, especially those that offer protection against the harmful ones.\n\nPaul Christiano believes that while accelerating technological progress appears to be one of the best ways to improve human welfare in the next few decades, a faster rate of growth cannot be equally important for the far future because growth must eventually saturate due to physical limits. Hence, from the perspective of the far future, differential technological development appears more crucial.\n\nInspired by Bostrom's proposal, Luke Muehlhauser and Anna Salamon suggested a more general project of \"differential intellectual progress\", in which society advances its wisdom, philosophical sophistication, and understanding of risks faster than its technological power. Brian Tomasik has expanded on this notion.\n\n"}
{"id": "242495", "url": "https://en.wikipedia.org/wiki?curid=242495", "title": "Diffusion (business)", "text": "Diffusion (business)\n\nDiffusion is the process by which a new idea or new product is accepted by the market. The rate of diffusion is the speed with which the new idea spreads from one consumer to the next. Adoption (the reciprocal process as viewed from a consumer perspective rather than distributor) is similar to diffusion except that it deals with the psychological processes an individual goes through, rather than an aggregate market process. In economics it is more often named \"technological change\".\n\nThere are several theories that purport to explain the mechanics of diffusion:\n\nAccording to Everett M. Rogers, the rate of diffusion is influenced by:\n\nThere are several types of diffusion rate models:\n\n\n"}
{"id": "11060935", "url": "https://en.wikipedia.org/wiki?curid=11060935", "title": "Doom9", "text": "Doom9\n\nDoom9 is a website featuring information on digital audio and video manipulation (mostly video) and digital copyrights. It is also the forum username of the author of the page, an Austrian who was a college student at the time of the creation of the site. The site's tagline is \"The Definitive DVD Backup Resource\".\n\nStarted in March 2000, the site has expanded to contain a wide range of information on the subject of digital video encoding and DVD backup (or ripping). The most popular sections of the site were the guides to DVD ripping and the annual codec comparisons, where popular digital video codecs were compared on the basis of quality, speed, and compression. The forum is frequented by many developers of the tools and codecs featured on the site, such as FairUse4WM. The site has been criticized, as the techniques described by it can be used for copyright infringement, but it maintains that its guides should only be used for fair use. In some cases, users suspected of illegally copying media are refused help on the forums.\n\nThe VirtualDubMod project began after many modifications to VirtualDub were posted on the Doom9 forums.\n\nDoom9 gained notoriety as a result of its involvement in the AACS encryption key controversy. The utility BackupHDDVD was first posted by a Doom9 poster using the alias \"muslix64\". The earliest information on how to find title and volume keys was also first revealed on Doom9 forums, by other users. The key that set off the controversy was also first posted by a user using the name \"arnezami\".\n\nDoom9 is also known for being the main discussion forum for many major video encoding tools, such as x264, AviSynth and MeGUI.\n\nDue to the concentration of forum members who have technical backgrounds, there have been various software projects developed and maintained by forum members. These include:\n\nDoom9 members have also contributed significantly to various software projects, including:\n\n\n"}
{"id": "22415560", "url": "https://en.wikipedia.org/wiki?curid=22415560", "title": "Engineering, procurement, and construction", "text": "Engineering, procurement, and construction\n\nEngineering, Procurement and Construction (EPC) is a particular form of contracting arrangement used in some industries where the EPC contractor is made responsible for all the activities from design, procurement, construction, commissioning and handover of the project to the end-user or owner. This form of contract is covered by the FIDIC Silver Book containing the title words \"EPC/Turnkey\". Other abbreviations used for this type of contract are \"LSTK\" for \"Lump Sum Turn Key\", EPIC for Engineering, Procurement, Installation & Commissioning and sometimes also EPCC which is short for Engineering, Procurement, Construction and Commissioning. Use of EPC is common e.g. by FIDIC and most Persian Gulf countries. Use of LSTK is common in Kingdom of Saudi Arabia. Use of EPCC is common in Qatar and some other countries e.g. by Qatar Petroleum. Therefore, an EPC, LSTK or EPCC are all same types of contracts a typical well-known example of which is the Silver Book of FIDIC. \nEngineering, Procurement and Construction Management (EPCM) is a special form of contracting arrangement. In an EPCM arrangement, the client selects a contractor who provides management services for the whole project on behalf of the client. The EPCM contractor coordinates all design, procurement and construction work and ensures that the whole project is completed as required and in time. The EPCM contractor may or may not undertake actual site work. \n\nThe acronym EPCM is also encountered frequently on international projects, but this is very different from EPC. EPCM is a services-only contract, under which the contractor performs engineering, procurement and construction management services.\n\n\n"}
{"id": "3720589", "url": "https://en.wikipedia.org/wiki?curid=3720589", "title": "Entertainment technology", "text": "Entertainment technology\n\nEntertainment technology is the discipline of using manufactured or created components to enhance or make possible any sort of entertainment experience. Because entertainment categories are so broad, and because entertainment models the world in many ways, the types of implemented technology are derived from a variety of sources. Thus, in theatre, for example, entertainment technology practitioners must be able to design and construct scenery, install electrical systems, build clothing, use motors if there is scenery automation, provide plumbing (if functioning kitchen fixtures are required, or if \"singing in the rain\"), etc. In this way, the entertainment technology field intersects with most other types of technology.\n\nTraditionally, entertainment technology is derived from theatrical stagecraft, and stagecraft is an important subset of the discipline. However, the rise of new types and venues for entertainment, as well as rapidly advancing technological development, has increased the range and scope of its practice.\n\nEntertainment technology includes:\n\n\nIn animation and game design, the phrase \"entertainment technology\" refers to a very real world of entertainment experiences made possible by the advent of primarily computer-mediated digital technologies.\n\nEntertainment Technology can be traced back to the “Pre-digital Age.” The invention of the first phonograph machine, which is used to record and playback sound, dates back to 1877 by inventor Thomas Edison. There has been a significant progression from that antiquated modality of entertainment. From silent films (which also gave way to the art of creative storytelling using moving pictures) to the digital age, in which we now see growth on a global scale and, relative to earlier inventions, an extremely fast pace. By comparison, from the invention of the phonograph machine in 1877 to the invention of the first motion picture camera by Louis Lumiere in 1895 shows a gap of 18 years between significant entertainment technology inventions. Whereas compact discs were introduced in the 1980’s and within the next 10 years, satellite television was introduced. More recent developments in entertainment technology are sometimes considered to be a “race” in terms of which company will develop and distribute their product first. Knowing what we have available to us and where it all began can be used as a footnote in our ever-increasing development of entertainment and other technological advances.\n\nSociety has completely been changed and advanced in many different ways by all the advancements in entertainment technology. Ranging from how companies get their product name out and get customers to buy into that product, to how people come into contact with one another and how we converse. Media and entertainment have become such a huge part of everyone’s life. We are all invested in some kind of media whether it is a tv show or a vlog and the producer of those are all very aware of the consumption of their product and will try to advertise it in as many ways as possible. They will reach out and promote their form of entertainment by having it on multiple platforms. Media companies will share their product on many different popular websites and forms of social media and ask its consumers to share it as well, generating more views and continuously advancing their products notoriety. Millions of dollars have been spent on Artificial Intelligence. Companies use AI because it is so detailed and precise with all of its obtained knowledge, they will use it to help market their brand because AI knows exactly what people like and what they want to see and will put together the final product that will succeed the most. Entertainment websites and websites that sell goods maintain and expand their viewers and customers by advertising something new you haven’t seen before when you are done with what you originally visited the website for. A big reason why a company became so successful and became so popular is that they bundled everything people want into a smaller collection, instead of having a much larger bundle that only included a couple items a consumer wants. Virtual reality is giving us a new way to experience the world. You can travel to see your favorite live event anywhere in the world without even having to leave your house.\n\nA three dimensional, computer generated simulation of a real seeming environment brought on by the use of special electronic equipment. This technology is used to replace the user’s entire real world environment with a computer generated (or simulated) one.\n\nAn interactive technology that intertwines computer generated images with real world objects. These artificial images can align with or block the real world environment. This technology is used to alter the user’s perception of the real world which should not to be confused with virtual reality in which the user’s whole perception is changed.\n\nA rich visual and audio experience that provides a greater contrast than standard dynamic range. This technology is most associated with display devices, sound recording, 3D rendering, and photography. Technology like this provides a more lifelike image in the visual aspect.\n\nA device (usually a camera) that captures information about the light field that is emerging from a real life scene which is; the direction of the light rays in space and the intensity of the light in the actual environment/scene. This technology will someday surpass Virtual Reality.\n\nVideo streaming is becoming a huge part of society in this day and age and it’s only beginning to expand. Video streaming brought in a revenue of $30.29 billion in 2016 and based on projections conducted by Research and Markets, will reach an astonishing $70.05 billion in the year 2021. This projected drastic increase has caused there to be more competition in streaming, which has led to rapid growth, development, and a large increase in the amount of users. Technology is a data based driven field, and with this rapid growth the future is bright for this field. Technology has been enhancing discoveries for as long as it’s been invented. It holds the digital power to entertain, inform, and persuade. Technology will continue to provide all of these sentiments and will continue to do so for as long as developments keep forthcoming. Rapid growth and development does not only affect the consumers, but the producers. Large technology companies will have improve content quality of all while extracting maximum value of the product. Challenges for development in the media industry are how to maximize content, brands, and advertising. While also created tailoring consumers needs to enhance their experience. Consumers drive this field, companies are constantly running data about consumers preferences, relationships, habits, and locations. Technology is a growing field and with companies beginning to care more about the consumers, and with rapid growing development in this field, expect technology to take bigger steps forward in years to come.  \n\nSchools that offer programs or degrees in entertainment technology include:\n\n\nCurrently, the only university offering a degree specifically in Entertainment Engineering and Design (EED) is the University of Nevada, Las Vegas (UNLV). Because UNLV's program is in its infancy, current entertainment technologists come from a wide variety of educational backgrounds, the most prevalent of which are theater and mechanical technology. Several other institutions of higher education offer similar programs for entertainment-related ventures.\n\nA bachelor's degree in these areas will typically have a difference of only a few specialized classes.\n\nTraditionally, people interested in careers in this field either presented themselves as apprentices within craft unions, or attended college programs in theatre technology. Although both are appropriate in limited ways, the growing world of entertainment technology encompasses many different types of performance and display environments than the theatre. To this end, newer opportunities have arisen that provide a wider educational base than these more traditional environments. An article \"Rethinking Entertainment Technology Education\" by John Huntington describes new teaching philosophies that resonate with the need for a richer and more flexible educational environment:\n\n"}
{"id": "43751582", "url": "https://en.wikipedia.org/wiki?curid=43751582", "title": "Equivalent input", "text": "Equivalent input\n\nEquivalent input (also input-referred or input-related), is a method of referring to the signal or noise level at the output of a system as if it were an input to the same system. This is accomplished by removing all signal changes (e.g. amplifier gain, transducer sensitivity, etc.) to get the units to match the input.\n\nA microphone converts acoustical energy to electrical energy. Microphones have some level of electrical noise at their output. This noise may have contributions from random diaphragm movement, thermal noise, or a dozen other sources, but those can all be thought of as an imaginary acoustic noise source injecting sound into the (now noiseless) microphone. The units on this noise are no longer volts, but units of sound pressure (pascals or dBSPL), which can be directly compared to the desired sound pressure inputs.\n\nA device which uses a microphone may be susceptible to electromagnetic interference which causes sonic artifacts. The problem is not in the microphone, but the interference level can be \"related\" back to the input to compare to the level of typical inputs to see how audible the artifact is.\n"}
{"id": "43730085", "url": "https://en.wikipedia.org/wiki?curid=43730085", "title": "European Association for Technical Communication", "text": "European Association for Technical Communication\n\nThe European Association for Technical Communication (tekom Europe e.V.) is the largest professional association for technical communication worldwide. The association connects more than 8,500 professionals like technical communicators, technical writers, and others from related fields. The working language is English.\n\ntekom Europe was founded in November 2013 in Wiesbaden, Germany, by representatives of tekom Deutschland, of the former tekom country groups and of the Italian association COM&TEC. and registered as a lobby organization in the European Transparency Register.\n\nThe main task of the association is to organize creators of user information in their countries and represent their interests on European level. tekom Europe supports important EU policies such as improving the training of young people, the employability and mobility of workers as well as the competitiveness of the European economy in general. One of the European initiatives which tekom Europe is involved in is ESCO (European Skills/Competences, qualifications and Occupations).\n\nThe association currently consists of members from nine countries: \n\nCandidate Countries (where a country organization will be founded soon): \n\ntekom Europe’s mission is…<br>\n… promote and further develop technical communication in Europe\n\n… set European standards for the quality of technical communication\n\n… increase the importance given to technical communication throughout Europe, both in commerce and among the general public\n\n… strengthen and harmonize the occupational profile of the technical writer\n\n… promote cooperation among universities and educational institutions at a European level\n\n… participate in developing international standards for user manuals and operating instructions\n\n\nChairperson: Isabelle Fleury\n\nDeputy Chairperson: Tiziana Sicila\n\nSecretary: Holger Thater\n\nTreasurer: Martin Rieder\n"}
{"id": "25527138", "url": "https://en.wikipedia.org/wiki?curid=25527138", "title": "Federal Ministry of Science and Technology", "text": "Federal Ministry of Science and Technology\n\nThe Federal Ministry of Science & Technology is a Nigerian ministry whose mission is to facilitate the development and deployment of science and technology apparatus to enhance the pace of socio-economic development of the country through appropriate technological inputs into productive activities in the nation.\nIt is headed by a Minister appointed by the President, assisted by a Permanent Secretary, who is a career civil servant.\nPresident Muhammadu Buhari, GCFR on November 11, 2015 swore in Dr. Christopher Ogbonnaya Onu as the Minister of Science and Technology with Dr.(Mrs) Amina Muhammed Bello Shamaki as the permanent secretary in the ministry.\nThe ministry engages in the following activities:\n\nThe Computers for All Nigerians Initiative (CANi) program is focused on enhancing Nigeria's economic and social foundation by supplying access to personal computers (PCs) and internet to its citizens. It is a joint effort between the Federal Ministry of Science and Technology (FMST) and the National Information Technology and Development Agency (NITDA) with local banks and PC producers, as well as private technology companies like Intel and Microsoft.\n\n\nThe Ministry is responsible for a number of parastatals, or government-owned agencies:\n\n\n"}
{"id": "15385424", "url": "https://en.wikipedia.org/wiki?curid=15385424", "title": "Gate (cytometry)", "text": "Gate (cytometry)\n\nA gate in cytometry is a set of value limits (boundaries) that serve to isolate a specific group of cytometric events from a large set. Gates can be defined by discrimination analysis, or can simply be drawn around a given set of data points on a printout and then converted to a computer-useful form. Gates can be implemented with a physical blinder. Gates may be used either to selectively gather data or to segregate data for analysis.\n\nGates are divided mathematically into inclusive gates and exclusive gates. Inclusive gates select data that falls within the limits set, while exclusive gates select data that falls outside the limits.\n\nA live gate is a term used for a process that prevents the acquisition by the computer of non-selected data from the flow cytometer.\n\n"}
{"id": "27313582", "url": "https://en.wikipedia.org/wiki?curid=27313582", "title": "Handover", "text": "Handover\n\nIn cellular telecommunications, the terms handover or handoff refer to the process of transferring an ongoing call or data session from one channel connected to the core network to another channel. In satellite communications it is the process of transferring satellite control responsibility from one earth station to another without loss or interruption of service.\n\nAmerican English uses the term \"handoff\", and this is most commonly used within some American organizations such as 3GPP2 and in American originated technologies such as CDMA2000. In British English the term \"handover\" is more common, and is used within international and European organisations such as ITU-T, IETF, ETSI and 3GPP, and standardised within European originated standards such as GSM and UMTS. The term handover is more common than handoff in academic research publications and literature, while handoff is slightly more common within the IEEE and ANSI organisations.\n\nIn telecommunications there may be different reasons why a handover might be conducted:\n\nThe most basic form of handover is when a phone call in progress is redirected from its current cell (called \"source\") to a new cell (called \"target\"). In terrestrial networks the source and the target cells may be served from two different cell sites or from one and the same cell site (in the latter case the two cells are usually referred to as two \"sectors\" on that cell site). Such a handover, in which the source and the target are different cells (even if they are on the same cell site) is called \"inter-cell\" handover. The purpose of inter-cell handover is to maintain the call as the subscriber is moving out of the area covered by the source cell and entering the area of the target cell.\n\nA special case is possible, in which the source and the target are one and the same cell and only the used channel is changed during the handover. Such a handover, in which the cell is not changed, is called \"intra-cell\" handover. The purpose of intra-cell handover is to change one channel, which may be interfered or fading with a new clearer or less fading channel.\n\nIn addition to the above classification of \"inter-cell\" and \"intra-cell\" classification of handovers, they also can be divided into hard and soft handovers:\nHandover can also be classified on the basis of handover techniques used. Broadly they can be classified into three types:\n\nAn advantage of the hard handover is that at any moment in time one call uses only one channel. The hard handover event is indeed very short and usually is not perceptible by the user. In the old analog systems it could be heard as a click or a very short beep; in digital systems it is unnoticeable. Another advantage of the hard handover is that the phone's hardware does not need to be capable of receiving two or more channels in parallel, which makes it cheaper and simpler. A disadvantage is that if a handover fails the call may be temporarily disrupted or even terminated abnormally. Technologies which use hard handovers, usually have procedures which can re-establish the connection to the source cell if the connection to the target cell cannot be made. However re-establishing this connection may not always be possible (in which case the call will be terminated) and even when possible the procedure may cause a temporary interruption to the call.\n\nOne advantage of the soft handovers is that the connection to the source cell is broken only when a reliable connection to the target cell has been established and therefore the chances that the call will be terminated abnormally due to failed handovers are lower. However, by far a bigger advantage comes from the mere fact that simultaneously channels in multiple cells are maintained and the call could only fail if all of the channels are interfered or fade at the same time. Fading and interference in different channels are unrelated and therefore the probability of them taking place at the same moment in all channels is very low. Thus the reliability of the connection becomes higher when the call is in a soft handover. Because in a cellular network the majority of the handovers occur in places of poor coverage, where calls would frequently become unreliable when their channel is interfered or fading, soft handovers bring a significant improvement to the reliability of the calls in these places by making the interference or the fading in a single channel not critical. This advantage comes at the cost of more complex hardware in the phone, which must be capable of processing several channels in parallel. Another price to pay for soft handovers is use of several channels in the network to support just a single call. This reduces the number of remaining free channels and thus reduces the capacity of the network. By adjusting the duration of soft handovers and the size of the areas in which they occur, the network engineers can balance the benefit of extra call reliability against the price of reduced capacity.\n\nWhile theoretically speaking soft handovers are possible in any technology, analog or digital, the cost of implementing them for analog technologies is prohibitively high and none of the technologies that were commercially successful in the past (e.g. AMPS, TACS, NMT, etc.) had this feature. Of the digital technologies, those based on FDMA also face a higher cost for the phones (due to the need to have multiple parallel radio-frequency modules) and those based on TDMA or a combination of TDMA/FDMA, in principle, allow not so expensive implementation of soft handovers. However, none of the 2G (second-generation) technologies have this feature (e.g. GSM, D-AMPS/IS-136, etc.). On the other hand, all CDMA based technologies, 2G and 3G (third-generation), have soft handovers. On one hand, this is facilitated by the possibility to design not so expensive phone hardware supporting soft handovers for CDMA and on the other hand, this is necessitated by the fact that without soft handovers CDMA networks may suffer from substantial interference arising due to the so-called \"near-far\" effect..\n\nIn all current commercial technologies based on FDMA or on a combination of TDMA/FDMA (e.g. GSM, AMPS, IS-136/DAMPS, etc.) changing the channel during a hard handover is realised by changing the pair of used transmit/receive frequencies.\n\nFor the practical realisation of handovers in a cellular network each cell is assigned a list of potential target cells, which can be used for handing over calls from this source cell to them. These potential target cells are called \"neighbors\" and the list is called \"neighbor list\". Creating such a list for a given cell is not trivial and specialized computer tools are used. They implement different algorithms and may use for input data from field measurements or computer predictions of radio wave propagation in the areas covered by the cells.\n\nDuring a call one or more parameters of the signal in the channel in the source cell are monitored and assessed in order to decide when a handover may be necessary. The downlink (forward link) and/or uplink (reverse link) directions may be monitored. The handover may be requested by the phone or by the base station (BTS) of its source cell and, in some systems, by a BTS of a neighboring cell. The phone and the BTSes of the neighboring cells monitor each other's signals and the best target candidates are selected among the neighboring cells. In some systems, mainly based on CDMA, a target candidate may be selected among the cells which are not in the neighbor list. This is done in an effort to reduce the probability of interference due to the aforementioned near-far effect.\n\nIn analog systems the parameters used as criteria for requesting a hard handover are usually the \"received signal power\" and the \"received signal-to-noise ratio\" (the latter may be estimated in an analog system by inserting additional tones, with frequencies just outside the captured voice-frequency band at the transmitter and assessing the form of these tones at the receiver). In non-CDMA 2G digital systems the criteria for requesting hard handover may be based on estimates of the received signal power, bit error rate (BER) and block error/erasure rate (BLER), received quality of speech (RxQual), distance between the phone and the BTS (estimated from the radio signal propagation delay) and others. In CDMA systems, 2G and 3G, the most common criterion for requesting a handover is Ec/Io ratio measured in the pilot channel (CPICH) and/or RSCP.\n\nIn CDMA systems, when the phone in soft or softer handover is connected to several cells simultaneously, it processes the received in parallel signals using a rake receiver. Each signal is processed by a module called \"rake finger\". A usual design of a rake receiver in mobile phones includes three or more rake fingers used in soft handover state for processing signals from as many cells and one additional finger used to search for signals from other cells. The set of cells, whose signals are used during a soft handover, is referred to as the \"active set\". If the search finger finds a sufficiently-strong signal (in terms of high Ec/Io or RSCP) from a new cell this cell is added to the active set. The cells in the neighbour list (called in CDMA \"neighbouring set\") are checked more frequently than the rest and thus a handover with a neighbouring cell is more likely, however a handover with others cells outside the neighbor list is also allowed (unlike in GSM, IS-136/DAMPS, AMPS, NMT, etc.).\n\nThere are occurrences where a handoff is unsuccessful. Much research has been dedicated to this problem. The source of the problem was discovered in the late 1980s. Because frequencies cannot be reused in adjacent cells, when a user moves from one cell to another, a new frequency must be allocated for the call. If a user moves into a cell when all available channels are in use, the user’s call must be terminated. Also, there is the problem of signal interference where adjacent cells overpower each other resulting in receiver desensitization.\n\nThere are also inter-technology handovers where a call's connection is transferred from one access technology to another, e.g. a call being transferred from GSM to UMTS or from CDMA IS-95 to cdma2000.\n\nThe 3GPP UMA/GAN standard enables GSM/UMTS handoff to Wi-Fi and vice versa.\n\nDifferent systems have different methods for handling and managing handoff request. Some systems handle handoff in same way as they handle new originating call. In such system the probability that the handoff will not be served is equal to blocking probability of new originating call. But if the call is terminated abruptly in the middle of conversation then it is more annoying than the new originating call being blocked. So in order to avoid this abrupt termination of ongoing call handoff request should be given priority to new call this is called as handoff prioritization.\n\nThere are two techniques for this:\n\n\n\n\n"}
{"id": "803641", "url": "https://en.wikipedia.org/wiki?curid=803641", "title": "History and Technology", "text": "History and Technology\n\nHistory and Technology is a quarterly peer reviewed academic journal devoted to publishing papers on all aspects of the history of technology. It was established in 1983. One of the founding editors was Pietro Redondi. The subjects range from ancient and classical times to the present day. The current publisher is Taylor & Francis.\n"}
{"id": "14449116", "url": "https://en.wikipedia.org/wiki?curid=14449116", "title": "History of timekeeping devices", "text": "History of timekeeping devices\n\nFor thousands of years, devices have been used to measure and keep track of time. The current sexagesimal system of time measurement dates to approximately 2000  from the Sumerians.\n\nThe Egyptians divided the day into two 12-hour periods, and used large obelisks to track the movement of the sun. They also developed water clocks, which were probably first used in the Precinct of Amun-Re, and later outside Egypt as well; they were employed frequently by the Ancient Greeks, who called them \"clepsydrae\". The Zhou dynasty is believed to have used the outflow water clock around the same time, devices which were introduced from Mesopotamia as early as 2000.\n\nOther ancient timekeeping devices include the candle clock, used in ancient China, ancient Japan, England and Mesopotamia; the timestick, widely used in India and Tibet, as well as some parts of Europe; and the hourglass, which functioned similarly to a water clock. The sundial, another early clock, relies on shadows to provide a good estimate of the hour on a sunny day. It is not so useful in cloudy weather or at night and requires recalibration as the seasons change (if the gnomon was not aligned with the Earth's axis).\n\nThe earliest known clock with a water-powered escapement mechanism, which transferred rotational energy into intermittent motions, dates back to 3rd century in ancient Greece; Chinese engineers later invented clocks incorporating mercury-powered escapement mechanisms in the 10th century, followed by Iranian engineers inventing water clocks driven by gears and weights in the 11th century.\n\nThe first mechanical clocks, employing the verge escapement mechanism with a foliot or balance wheel timekeeper, were invented in Europe at around the start of the 14th century, and became the standard timekeeping device until the pendulum clock was invented in 1656. The invention of the mainspring in the early 15th century allowed portable clocks to be built, evolving into the first pocketwatches by the 17th century, but these were not very accurate until the balance spring was added to the balance wheel in the mid 17th century.\n\nThe pendulum clock remained the most accurate timekeeper until the 1930s, when quartz oscillators were invented, followed by atomic clocks after World War 2. Although initially limited to laboratories, the development of microelectronics in the 1960s made quartz clocks both compact and cheap to produce, and by the 1980s they became the world's dominant timekeeping technology in both clocks and wristwatches.\n\nAtomic clocks are far more accurate than any previous timekeeping device, and are used to calibrate other clocks and to calculate the International Atomic Time; a standardized civil system, Coordinated Universal Time, is based on atomic time.\n\nMany ancient civilizations observed astronomical bodies, often the Sun and Moon, to determine times, dates, and seasons. The first calendars may have been created during the last glacial period, by hunter-gatherers who employed tools such as sticks and bones to track the phases of the moon or the seasons. Stone circles, such as England's Stonehenge, were built in various parts of the world, especially in Prehistoric Europe, and are thought to have been used to time and predict seasonal and annual events such as equinoxes or solstices. As those megalithic civilizations left no recorded history, little is known of their calendars or timekeeping methods. Methods of sexagesimal timekeeping, now common in both Western and Eastern societies, are first attested nearly 4,000 years ago in Mesopotamia and Egypt. Mesoamericans similarly modified their usual vigesimal counting system when dealing with calendars to produce a 360-day year.\n\nThe oldest known sundial is from Egypt; it dates back to around 1500 (19th Dynasty), and was discovered in the Valley of the Kings in 2013. Sundials have their origin in shadow clocks, which were the first devices used for measuring the parts of a day. Ancient Egyptian obelisks, constructed about 3500, are also among the earliest shadow clocks.\nEgyptian shadow clocks divided daytime into 12 parts with each part further divided into more precise parts. One type of shadow clock consisted of a long stem with five variable marks and an elevated crossbar which cast a shadow over those marks. It was positioned eastward in the morning, and was turned west at noon. Obelisks functioned in much the same manner: the shadow cast on the markers around it allowed the Egyptians to calculate the time. The obelisk also indicated whether it was morning or afternoon, as well as the summer and winter solstices. A third shadow clock, developed c. 1500, was similar in shape to a bent T-square. It measured the passage of time by the shadow cast by its crossbar on a non-linear rule. The \"T\" was oriented eastward in the mornings, and turned around at noon, so that it could cast its shadow in the opposite direction.\n\nAlthough accurate, shadow clocks relied on the sun, and so were useless at night and in cloudy weather. The Egyptians therefore developed a number of alternative timekeeping instruments, including water clocks, and a system for tracking star movements. The oldest description of a water clock is from the tomb inscription of the 16th-century Egyptian court official Amenemhet, identifying him as its inventor. There were several types of water clocks, some more elaborate than others. One type consisted of a bowl with small holes in its bottom, which was floated on water and allowed to fill at a near-constant rate; markings on the side of the bowl indicated elapsed time, as the surface of the water reached them. The oldest-known waterclock was found in the tomb of pharaoh Amenhotep I (1525–1504), suggesting that they were first used in ancient Egypt. Another Egyptian method of determining the time during the night was using plumb-lines called merkhets. In use since at least 600, two of these instruments were aligned with Polaris, the north pole star, to create a north–south meridian. The time was accurately measured by observing certain stars as they crossed the line created with the \"merkhets\".\n\nWater clocks, or clepsydrae, were commonly used in Ancient Greece following their introduction by Plato, who also invented a water-based alarm clock. One account of Plato's alarm clock describes it as depending on the nightly overflow of a vessel containing lead balls, which floated in a columnar vat. The vat held a steadily increasing amount of water, supplied by a cistern. By morning, the vessel would have floated high enough to tip over, causing the lead balls to cascade onto a copper platter. The resultant clangor would then awaken Plato's students at the Academy. Another possibility is that it comprised two jars, connected by a siphon. Water emptied until it reached the siphon, which transported the water to the other jar. There, the rising water would force air through a whistle, sounding an alarm. The Greeks and Chaldeans regularly maintained timekeeping records as an essential part of their astronomical observations.\n\nGreek astronomer, Andronicus of Cyrrhus, supervised the construction of the Tower of the Winds in Athens in the 1st century.\n\nIn Greek tradition, clepsydrae were used in court; later, the Romans adopted this practice, as well. There are several mentions of this in historical records and literature of the era; for example, in \"Theaetetus\", Plato says that \"Those men, on the other hand, always speak in haste, for the flowing water urges them on\". Another mention occurs in Lucius Apuleius' \"The Golden Ass\": \"The Clerk of the Court began bawling again, this time summoning the chief witness for the prosecution to appear. Up stepped an old man, whom I did not know. He was invited to speak for as long as there was water in the clock; this was a hollow globe into which water was poured through a funnel in the neck, and from which it gradually escaped through fine perforations at the base\". The clock in Apuleius's account was one of several types of water clock used. Another consisted of a bowl with a hole in its centre, which was floated on water. Time was kept by observing how long the bowl took to fill with water.\n\nAlthough clepsydrae were more useful than sundials—they could be used indoors, during the night, and also when the sky was cloudy—they were not as accurate; the Greeks, therefore, sought a way to improve their water clocks. Although still not as accurate as sundials, Greek water clocks became more accurate around 325, and they were adapted to have a face with an hour hand, making the reading of the clock more precise and convenient. One of the more common problems in most types of clepsydrae was caused by water pressure: when the container holding the water was full, the increased pressure caused the water to flow more rapidly. This problem was addressed by Greek and Roman horologists beginning in 100, and improvements continued to be made in the following centuries. To counteract the increased water flow, the clock's water containers—usually bowls or jugs—were given a conical shape; positioned with the wide end up, a greater amount of water had to flow out in order to drop the same distance as when the water was lower in the cone. Along with this improvement, clocks were constructed more elegantly in this period, with hours marked by gongs, doors opening to miniature figurines, bells, or moving mechanisms. There were some remaining problems, however, which were never solved, such as the effect of temperature. Water flows more slowly when cold, or may even freeze.\n\nBetween 270 and 500, Hellenistic (Ctesibius, Hero of Alexandria, Archimedes) and Roman horologists and astronomers began developing more elaborate mechanized water clocks. The added complexity was aimed at regulating the flow and at providing fancier displays of the passage of time. For example, some water clocks rang bells and gongs, while others opened doors and windows to show figurines of people, or moved pointers, and dials. Some even displayed astrological models of the universe.\n\nAlthough the Greeks and Romans did much to advance water clock technology, they still continued to use shadow clocks. The mathematician and astronomer Theodosius of Bithynia, for example, is said to have invented a universal sundial that was accurate anywhere on Earth, though little is known about it. Others wrote of the sundial in the mathematics and literature of the period. Marcus Vitruvius Pollio, the Roman author of \"De Architectura\", wrote on the mathematics of gnomons, or sundial blades. During the reign of Emperor Augustus, the Romans constructed the largest sundial ever built, the Solarium Augusti. Its gnomon was an obelisk from Heliopolis. Similarly, the obelisk from Campus Martius was used as the gnomon for Augustus's zodiacal sundial. Pliny the Elder records that the first sundial in Rome arrived in 264, looted from Catania, Sicily; according to him, it gave the incorrect time until the markings and angle appropriate for Rome's latitude were used—a century later.\n\nAccording to Callisthenes, the Persians were using water clocks in 328 to ensure a just and exact distribution of water from qanats to their shareholders for agricultural irrigation. The use of water clocks in Iran, especially in Zeebad, dates back to 500. Later they were also used to determine the exact holy days of pre-Islamic religions, such as the \"Nowruz\", \"Chelah\", or \"Yaldā\" – the shortest, longest, and equal-length days and nights of the years. The water clocks used in Iran were one of the most practical ancient tools for timing the yearly calendar.\n\nWater clocks, or \"Fenjaan\", in Persia reached a level of accuracy comparable to today's standards of timekeeping. The fenjaan was the most accurate and commonly used timekeeping device for calculating the amount or the time that a farmer must take water from a qanat or well for irrigation of the farms, until it was replaced by more accurate current clock. Persian water clocks were a practical and useful tool for the qanat's shareholders to calculate the length of time they could divert water to their farm. The qanat was the only water source for agriculture and irrigation so a just and fair water distribution was very important. Therefore, a very fair and clever old person was elected to be the manager of the water clock, and at least two full-time managers were needed to control and observe the number of fenjaans and announce the exact time during the days and nights.\n\nThe fenjaan was a big pot full of water and a bowl with small hole in the center. When the bowl become full of water, it would sink into the pot, and the manager would empty the bowl and again put it on the top of the water in the pot. He would record the number of times the bowl sank by putting small stones into a jar.\n\nThe place where the clock was situated, and its managers, were collectively known as \"khaneh fenjaan\". Usually this would be the top floor of a public-house, with west- and east-facing windows to show the time of sunset and sunrise. There was also another time-keeping tool named a \"staryab\" or astrolabe, but it was mostly used for superstitious beliefs and was not practical for use as a farmers' calendar. The Zeebad Gonabad water clock was in use until 1965 when it was substituted by modern clocks.\n\nJoseph Needham speculated that the introduction of the outflow clepsydra to China, perhaps from Mesopotamia, occurred as far back as the 2nd millennium, during the Shang Dynasty, and at the latest by the 1st millennium. By the beginning of the Han Dynasty, in 202, the outflow clepsydra was gradually replaced by the inflow clepsydra, which featured an indicator rod on a float. To compensate for the falling pressure head in the reservoir, which slowed timekeeping as the vessel filled, Zhang Heng added an extra tank between the reservoir and the inflow vessel. Around 550 AD, Yin Gui was the first in China to write of the overflow or constant-level tank added to the series, which was later described in detail by the inventor Shen Kuo. Around 610, this design was trumped by two Sui Dynasty inventors, Geng Xun and Yuwen Kai, who were the first to create the balance clepsydra, with standard positions for the steelyard balance. Joseph Needham states that:\nThe term 'clock' encompasses a wide spectrum of devices, ranging from wristwatches to the Clock of the Long Now. The English word \"clock\" is said to derive from the Middle English \"clokke\", Old North French \"cloque\", or Middle Dutch \"clocke\", all of which mean \"bell\", and are derived from the Medieval Latin \"clocca\", also meaning bell. Indeed, bells were used to mark the passage of time; they marked the passage of the hours at sea and in abbeys.\n\nThroughout history, clocks have had a variety of power sources, including gravity, springs, and electricity. Mechanical clocks became widespread in the 14th century, when they were used in medieval monasteries to keep the regulated schedule of prayers. The clock continued to be improved, with the first pendulum clock being designed and built in the 17th century.\n\nThe earliest mention of candle clocks comes from a Chinese poem, written in 520 by You Jianfu. According to the poem, the graduated candle was a means of determining time at night. Similar candles were used in Japan until the early 10th century.\n\nThe candle clock most commonly mentioned and written of is attributed to King Alfred the Great. It consisted of six candles made from 72 pennyweights of wax, each high, and of uniform thickness, marked every inch (2.54 cm). As these candles burned for about four hours, each mark represented 20 minutes. Once lit, the candles were placed in wooden framed glass boxes, to prevent the flame from extinguishing.\n\nThe most sophisticated candle clocks of their time were those of Al-Jazari in 1206. One of his candle clocks included a dial to display the time and, for the first time, employed a bayonet fitting, a fastening mechanism still used in modern times. Donald Routledge Hill described Al-Jazari's candle clocks as follows:\n\nA variation on this theme were oil-lamp clocks. These early timekeeping devices consisted of a graduated glass reservoir to hold oil — usually whale oil, which burned cleanly and evenly — supplying the fuel for a built-in lamp. As the level in the reservoir dropped, it provided a rough measure of the passage of time.\n\nIn addition to water, mechanical, and candle clocks, incense clocks were used in the Far East, and were fashioned in several different forms. Incense clocks were first used in China around the 6th century; in Japan, one still exists in the Shōsōin, although its characters are not Chinese, but Devanagari. Due to their frequent use of Devanagari characters, suggestive of their use in Buddhist ceremonies, Edward H. Schafer speculated that incense clocks were invented in India. Although similar to the candle clock, incense clocks burned evenly and without a flame; therefore, they were more accurate and safer for indoor use.\n\nSeveral types of incense clock have been found, the most common forms include the incense stick and incense seal. An incense stick clock was an incense stick with calibrations; most were elaborate, sometimes having threads, with weights attached, at even intervals. The weights would drop onto a platter or gong below, signifying that a certain amount of time had elapsed. Some incense clocks were held in elegant trays; open-bottomed trays were also used, to allow the weights to be used together with the decorative tray. Sticks of incense with different scents were also used, so that the hours were marked by a change in fragrance. The incense sticks could be straight or spiraled; the spiraled ones were longer, and were therefore intended for long periods of use, and often hung from the roofs of homes and temples. In Japan, a geisha was paid for the number of \"senkodokei\" (incense sticks) that had been consumed while she was present, a practice which continued until 1924.\n\nIncense seal clocks were used for similar occasions and events as the stick clock; while religious purposes were of primary importance, these clocks were also popular at social gatherings, and were used by Chinese scholars and intellectuals. The seal was a wooden or stone disk with one or more grooves etched in it into which incense was placed. These clocks were common in China, but were produced in fewer numbers in Japan. To signal the passage of a specific amount of time, small pieces of fragrant woods, resins, or different scented incenses could be placed on the incense powder trails. Different powdered incense clocks used different formulations of incense, depending on how the clock was laid out. The length of the trail of incense, directly related to the size of the seal, was the primary factor in determining how long the clock would last; all burned for long periods of time, ranging between 12 hours and a month.\n\nWhile early incense seals were made of wood or stone, the Chinese gradually introduced disks made of metal, most likely beginning during the Song dynasty. This allowed craftsmen to more easily create both large and small seals, as well as design and decorate them more aesthetically. Another advantage was the ability to vary the paths of the grooves, to allow for the changing length of the days in the year. As smaller seals became more readily available, the clocks grew in popularity among the Chinese, and were often given as gifts. Incense seal clocks are often sought by modern-day clock collectors; however, few remain that have not already been purchased or been placed on display at museums or temples.\n\nSundials had been used for timekeeping since Ancient Egypt. Ancient dials were nodus-based with straight hour-lines that indicated unequal hours—also called temporary hours—that varied with the seasons. Every day was divided into 12 equal segments regardless of the time of year; thus, hours were shorter in winter and longer in summer. The sundial was further developed by Muslim astronomers. The idea of using hours of equal length throughout the year was the innovation of Abu'l-Hasan Ibn al-Shatir in 1371, based on earlier developments in trigonometry by Muhammad ibn Jābir al-Harrānī al-Battānī (Albategni). Ibn al-Shatir was aware that \"using a gnomon that is parallel to the Earth's axis will produce sundials whose hour lines indicate equal hours on any day of the year\". His sundial is the oldest polar-axis sundial still in existence. The concept appeared in Western sundials starting in 1446.\n\nFollowing the acceptance of heliocentrism and equal hours, as well as advances in trigonometry, sundials appeared in their present form during the Renaissance, when they were built in large numbers. In 1524, the French astronomer Oronce Finé constructed an ivory sundial, which still exists; later, in 1570, the Italian astronomer Giovanni Padovani published a treatise including instructions for the manufacture and laying out of mural (vertical) and horizontal sundials. Similarly, Giuseppe Biancani's \"Constructio instrumenti ad horologia solaria\" (c. 1620) discusses how to construct sundials.\n\nSince the hourglass was one of the few reliable methods of measuring time at sea, it is speculated that it was used on board ships as far back as the 11th century, when it would have complemented the magnetic compass as an aid to navigation. However, the earliest unambiguous evidence of their use appears in the painting \"Allegory of Good Government\", by Ambrogio Lorenzetti, from 1338. From the 15th century onwards, hourglasses were used in a wide range of applications at sea, in churches, in industry, and in cooking; they were the first dependable, reusable, reasonably accurate, and easily constructed time-measurement devices. The hourglass also took on symbolic meanings, such as that of death, temperance, opportunity, and Father Time, usually represented as a bearded, old man. Though also used in China, the hourglass's history there is unknown. The Portuguese navigator Ferdinand Magellan used 18 hourglasses on each ship during his circumnavigation of the globe in 1522.\n\nThe earliest instance of a liquid-driven escapement was described by the Greek engineer Philo of Byzantium (fl. 3rd century) in his technical treatise \"Pneumatics\" (chapter 31) where he likens the escapement mechanism of a washstand automaton with those as employed in (water) clocks. Another early clock to use escapements was built during the 7th century in Chang'an, by Tantric monk and mathematician, Yi Xing, and government official Liang Lingzan. An astronomical instrument that served as a clock, it was discussed in a contemporary text as follows:\n[It] was made in the image of the round heavens and on it were shown the lunar mansions in their order, the equator and the degrees of the heavenly circumference. Water, flowing into scoops, turned a wheel automatically, rotating it one complete revolution in one day and night. Besides this, there were two rings fitted around the celestial sphere outside, having the sun and moon threaded on them, and these were made to move in circling orbit ... And they made a wooden casing the surface of which represented the horizon, since the instrument was half sunk in it. It permitted the exact determinations of the time of dawns and dusks, full and new moons, tarrying and hurrying. Moreover, there were two wooden jacks standing on the horizon surface, having one a bell and the other a drum in front of it, the bell being struck automatically to indicate the hours, and the drum being beaten automatically to indicate the quarters. All these motions were brought about by machinery within the casing, each depending on wheels and shafts, hooks, pins and interlocking rods, stopping devices and locks checking mutually.\n\nSince Yi Xing's clock was a water clock, it was affected by temperature variations. That problem was solved in 976 by Zhang Sixun by replacing the water with mercury, which remains liquid down to . Zhang implemented the changes into his clock tower, which was about tall, with escapements to keep the clock turning and bells to signal every quarter-hour. Another noteworthy clock, the elaborate Cosmic Engine, was built by Su Song, in 1088. It was about the size of Zhang's tower, but had an automatically rotating armillary sphere—also called a celestial globe—from which the positions of the stars could be observed. It also featured five panels with mannequins ringing gongs or bells, and tablets showing the time of day, or other special times. Furthermore, it featured the first known endless power-transmitting chain drive in horology. Originally built in the capital of Kaifeng, it was dismantled by the Jin army and sent to the capital of Yanjing (now Beijing), where they were unable to put it back together. As a result, Su Song's son Su Xie was ordered to build a replica.\nThe clock towers built by Zhang Sixun and Su Song, in the 10th and 11th centuries, respectively, also incorporated a striking clock mechanism, the use of clock jacks to sound the hours. A striking clock outside of China was the Jayrun Water Clock, at the Umayyad Mosque in Damascus, Syria, which struck once every hour. It was constructed by Muhammad al-Sa'ati in the 12th century, and later described by his son Ridwan ibn al-Sa'ati, in his \"On the Construction of Clocks and their Use\" (1203), when repairing the clock. In 1235, an early monumental water-powered alarm clock that \"announced the appointed hours of prayer and the time both by day and by night\" was completed in the entrance hall of the Mustansiriya Madrasah in Baghdad.\n\nThe first geared clock was invented in the 11th century by the Arab engineer Ibn Khalaf al-Muradi in Islamic Iberia; it was a water clock that employed a complex gear train mechanism, including both segmental and epicyclic gearing, capable of transmitting high torque. The clock was unrivalled in its use of sophisticated complex gearing, until the mechanical clocks of the mid-14th century. Al-Muradi's clock also employed the use of mercury in its hydraulic linkages, which could function mechanical automata. Al-Muradi's work was known to scholars working under Alfonso X of Castile, hence the mechanism may have played a role in the development of the European mechanical clocks. Other monumental water clocks constructed by medieval Muslim engineers also employed complex gear trains and arrays of automata. Like the earlier Greeks and Chinese, Arab engineers at the time also developed a liquid-driven escapement mechanism which they employed in some of their water clocks. Heavy floats were used as weights and a constant-head system was used as an escapement mechanism, which was present in the hydraulic controls they used to make heavy floats descend at a slow and steady rate.\n\nA mercury clock, described in the \"Libros del saber de Astronomia\", a Spanish work from 1277 consisting of translations and paraphrases of Arabic works, is sometimes quoted as evidence for Muslim knowledge of a mechanical clock. However, the device was actually a compartmented cylindrical water clock, which the Jewish author of the relevant section, Rabbi Isaac, constructed using principles described by a philosopher named \"Iran\", identified with Heron of Alexandria (fl. 1st century AD), on how heavy objects may be lifted.\n\nClock towers in Western Europe in the Middle Ages were also sometimes striking clocks. The most famous original still standing is possibly St Mark's Clock on the top of St Mark's Clocktower in St Mark's Square in Venice, assembled in 1493 by the clockmaker Gian Carlo Rainieri from Reggio Emilia. In 1497, Simone Campanato moulded the great bell on which every definite time-lapse is beaten by two mechanical bronze statues (h. 2,60 m.) called \"Due Mori\" (\"Two Moors\"), handling a hammer. Possibly earlier (1490) is the Prague Astronomical Clock by clockmaster Jan Růže (also called Hanuš) – according to another source this device was assembled as early as 1410 by clockmaker Mikuláš of Kadaň and mathematician Jan Šindel. The allegorical parade of animated sculptures rings on the hour every day.\n\nDuring the 11th century in the Song Dynasty, the Chinese astronomer, horologist and mechanical engineer Su Song created a water-driven astronomical clock for his clock tower of Kaifeng City. It incorporated an escapement mechanism as well as the earliest known endless power-transmitting chain drive, which drove the armillary sphere.\n\nContemporary Muslim astronomers also constructed a variety of highly accurate astronomical clocks for use in their mosques and observatories, such as the water-powered astronomical clock by Al-Jazari in 1206, and the astrolabic clock by Ibn al-Shatir in the early 14th century. The most sophisticated timekeeping astrolabes were the geared astrolabe mechanisms designed by Abū Rayhān Bīrūnī in the 11th century and by Muhammad ibn Abi Bakr in the 13th century. These devices functioned as timekeeping devices and also as calendars.\nA sophisticated water-powered astronomical clock was built by Al-Jazari in 1206. This castle clock was a complex device that was about high, and had multiple functions alongside timekeeping. It included a display of the zodiac and the solar and lunar paths, and a pointer in the shape of the crescent moon which travelled across the top of a gateway, moved by a hidden cart and causing doors to open, each revealing a mannequin, every hour. It was possible to reset the length of day and night in order to account for the changing lengths of day and night throughout the year. This clock also featured a number of automata including falcons and musicians who automatically played music when moved by levers operated by a hidden camshaft attached to a water wheel.\n\nThe earliest medieval European clockmakers were Catholic monks. Medieval religious institutions required clocks because they regulated daily prayer- and work-schedules strictly, using various types of time-telling and recording devices, such as water clocks, sundials and marked candles, probably in combination. When mechanical clocks came into use, they were often wound at least twice a day to ensure accuracy. Monasteries broadcast important times and durations with bells, rung either by hand or by a mechanical device, such as by a falling weight or by rotating beater.\n\nAlthough the mortuary inscription of Pacificus, archdeacon of Verona, records that he constructed a night clock (\"horologium nocturnum\") as early as 850, his clock has been identified as being an observation tube used to locate stars with an accompanying book of astronomical observations, rather than a mechanical or water clock, an interpretation supported by illustrations from medieval manuscripts.\n\nThe religious necessities and technical skill of the medieval monks were crucial factors in the development of clocks, as the historian Thomas Woods writes:\nThe appearance of clocks in writings of the 11th century implies that they were well known in Europe in that period. In the early 14th-century, the Florentine poet Dante Alighieri referred to a clock in his \"Paradiso\"; the first known literary reference to a clock that struck the hours. Giovanni da Dondi, Professor of Astronomy at Padua, presented the earliest detailed description of clockwork in his 1364 treatise \"Il Tractatus Astrarii\". This has inspired several modern replicas, including some in London's Science Museum and the Smithsonian Institution. Other notable examples from this period were built in Milan (1335), Strasbourg (1354), Lund (1380), Rouen (1389), and Prague (1462).\n\nSalisbury cathedral clock, dating from about 1386, is one of the oldest working clocks in the world, and may be the oldest. It still has most of its original parts, although its original verge and foliot timekeeping mechanism is lost, having been converted to a pendulum, which was replaced by a replica verge in 1956. It has no dial, as its purpose was to strike a bell at precise times. The wheels and gears are mounted in an open, box-like iron frame, measuring about square. The framework is held together with metal dowels and pegs. Two large stones, hanging from pulleys, supply the power. As the weights fall, ropes unwind from the wooden barrels. One barrel drives the main wheel, which is regulated by the escapement, and the other drives the striking mechanism and the air brake.\n\nNote also Peter Lightfoot's Wells Cathedral clock, constructed c. 1390. The dial represents a geocentric view of the universe, with the Sun and Moon revolving around a central fixed Earth. It is unique in having its original medieval face, showing a philosophical model of the pre-Copernican universe. Above the clock is a set of figures, which hit the bells, and a set of jousting knights who revolve around a track every 15 minutes. The clock was converted to pendulum-and-anchor escapement in the 17th century, and was installed in London's Science Museum in 1884, where it continues to operate. Similar astronomical clocks, or \"horologes\", survive at Exeter, Ottery St Mary, and Wimborne Minster.\nOne clock that has not survived is that of the Abbey of St Albans, built by the 14th-century abbot Richard of Wallingford. It may have been destroyed during Henry VIII's Dissolution of the Monasteries, but the abbot's notes on its design have allowed a full-scale reconstruction. As well as keeping time, the astronomical clock could accurately predict lunar eclipses, and may have shown the Sun, Moon (age, phase, and node), stars and planets, as well as a wheel of fortune, and an indicator of the state of the tide at London Bridge. According to Thomas Woods, \"a clock that equaled it in technological sophistication did not appear for at least two centuries\". Giovanni de Dondi was another early mechanical clockmaker whose clock did not survive, but his work has been replicated based on the designs. De Dondi's clock was a seven-faced construction with 107 moving parts, showing the positions of the Sun, Moon, and five planets, as well as religious feast days. Around this period, mechanical clocks were introduced into abbeys and monasteries to mark important events and times, gradually replacing water clocks which had served the same purpose.\n\nDuring the Middle Ages, clocks primarily served religious purposes; the first employed for secular timekeeping emerged around the 15th century. In Dublin, the official measurement of time became a local custom, and by 1466 a public clock stood on top of the Tholsel (the city court and council chamber). It was the first of its kind to be clearly recorded in Ireland, and would only have had an hour hand. The increasing lavishness of castles led to the introduction of turret clocks. A 1435 example survives from Leeds castle; its face is decorated with the images of the Crucifixion of Jesus, Mary and St George.\n\nEarly clock dials showed hours: the display of minutes and seconds evolved later. A clock with a minutes dial is mentioned in a 1475 manuscript, and clocks indicating minutes and seconds existed in Germany in the 15th century. Timepieces which indicated minutes and seconds were occasionally made from this time on, but this was not common until the increase in accuracy made possible by the pendulum clock and, in watches, by the spiral balance spring. The 16th-century astronomer Tycho Brahe used clocks with minutes and seconds to observe stellar positions.\n\nThe Ottoman engineer Taqi al-Din described a weight-driven clock with a verge-and-foliot escapement, a striking train of gears, an alarm, and a representation of the moon's phases in his book \"The Brightest Stars for the Construction of Mechanical Clocks\" (\"Al-Kawākib al-durriyya fī wadh' al-bankāmat al-dawriyya\"), written around 1556.\n\nThe concept of the wristwatch goes back to the production of the very earliest watches in the 16th century. Elizabeth I of England received a wristwatch from Robert Dudley in 1571, described as an arm watch. From the beginning, wrist watches were almost exclusively worn by women, while men used pocket-watches up until the early 20th century. This was not just a matter of fashion or prejudice; watches of the time were notoriously prone to fouling from exposure to the elements, and could only reliably be kept safe from harm if carried securely in the pocket. When the waistcoat was introduced as a manly fashion at the court of Charles II in the 17th century, the pocket watch was tucked into its pocket. Prince Albert, the consort to Queen Victoria, introduced the 'Albert chain' accessory, designed to secure the pocket watch to the man's outergarment by way of a clip. By the mid nineteenth century, most watchmakers produced a range of wristwatches, often marketed as bracelets, for women.\n\nWristwatches were first worn by military men towards the end of the nineteenth century, when the importance of synchronizing manoeuvres during war without potentially revealing the plan to the enemy through signalling was increasingly recognized. It was clear that using pocket watches while in the heat of battle or while mounted on a horse was impractical, so officers began to strap the watches to their wrist. The Garstin Company of London patented a 'Watch Wristlet' design in 1893, although they were probably producing similar designs from the 1880s. Clearly, a market for men's wristwatches was coming into being at the time. Officers in the British Army began using wristwatches during colonial military campaigns in the 1880s, such as during the Anglo-Burma War of 1885.\n\nDuring the Boer War, the importance of coordinating troop movements and synchronizing attacks against the highly mobile Boer insurgents was paramount, and the use of wristwatches subsequently became widespread among the officer class. The company Mappin & Webb began production of their successful 'campaign watch' for soldiers during the campaign at the Sudan in 1898 and ramped up production for the Boer War a few years later.\nThese early models were essentially standard pocket-watches fitted to a leather strap, but by the early 20th century, manufacturers began producing purpose-built wristwatches. The Swiss company, Dimier Frères & Cie patented a wristwatch design with the now standard wire lugs in 1903. In 1904, Alberto Santos-Dumont, an early aviator, asked his friend, a French watchmaker called Louis Cartier, to design a watch that could be useful during his flights.\n\nThe impact of the First World War dramatically shifted public perceptions on the propriety of the man's wristwatch, and opened up a mass market in the post-war era. The creeping barrage artillery tactic, developed during the War, required precise synchronization between the artillery gunners and the infantry advancing behind the barrage. Service watches produced during the War were specially designed for the rigours of trench warfare, with luminous dials and unbreakable glass. Wristwatches were also found to be needed in the air as much as on the ground: military pilots found them more convenient than pocket watches for the same reasons as Santos-Dumont had. The British War Department began issuing wristwatches to combatants from 1917.\nThe company H. Williamson Ltd., based in Coventry, was one of the first to capitalize on this opportunity. During the company's 1916 AGM it was noted that \"...the public is buying the practical things of life. Nobody can truthfully contend that the watch is a luxury. It is said that one soldier in every four wears a wristlet watch, and the other three mean to get one as soon as they can.\" By the end of the War, almost all enlisted men wore a wristwatch, and after they were demobilized, the fashion soon caught on – the British \"Horological Journal\" wrote in 1917 that \"...the wristlet watch was little used by the sterner sex before the war, but now is seen on the wrist of nearly every man in uniform and of many men in civilian attire.\" Within a decade, sales of wristwatches had outstripped those of pocket watches.\n\nIn the late 17th and 18th Centuries, equation clocks were made, which allowed the user to see or calculate apparent solar time, as would be shown by a sundial. Before the invention of the pendulum clock, sundials were the only accurate timepieces. When good clocks became available, they appeared inaccurate to people who were used to trusting sundials. The annual variation of the equation of time made a clock up to about 15 minutes fast or slow, relative to a sundial, depending on the time of year. Equation clocks satisfied the demand for clocks that always agreed with sundials. Several types of equation clock mechanism were devised. which can be seen in surviving examples, mostly in museums.\n\nInnovations to the mechanical clock continued, with miniaturization leading to domestic clocks in the 15th century, and personal watches in the 16th. In the 1580s, the Italian polymath Galileo Galilei investigated the regular swing of the pendulum, and discovered that it could be used to regulate a clock. Although Galileo studied the pendulum as early as 1582, he never actually constructed a clock based on that design. The first pendulum clock was designed and built by Dutch scientist Christiaan Huygens, in 1656. Early versions erred by less than one minute per day, and later ones only by 10 seconds, very accurate for their time.\n\nIn England, the manufacturing of pendulum clocks was soon taken up. The longcase clock (also known as the grandfather clock) was first created to house the pendulum and works by the English clockmaker William Clement in 1670 or 1671; this became feasible after Clement invented the anchor escapement mechanism in about 1670. Before then, pendulum clocks used the older verge escapement mechanism, which required very wide pendulum swings of about 100°. To avoid the need for a very large case, most clocks using the verge escapement had a short pendulum. The anchor mechanism, however, reduced the pendulum's necessary swing to between 4° to 6°, allowing clockmakers to use longer pendulums with consequently slower beats. These required less power to move, caused less friction and wear, and were more accurate than their shorter predecessors. Most longcase clocks use a pendulum about a metre (39 inches) long to the center of the bob, with each swing taking one second. This requirement for height, along with the need for a long drop space for the weights that power the clock, gave rise to the tall, narrow case.\n\nClement also introduced the pendulum suspension spring in 1671. The concentric minute hand was added to the clock by Daniel Quare, a London clock-maker, and the Second Hand was introduced.\n\nThe Jesuits were another major contributor to the development of pendulum clocks in the 17th and 18th centuries, having had an \"unusually keen appreciation of the importance of precision\". In measuring an accurate one-second pendulum, for example, the Italian astronomer Father Giovanni Battista Riccioli persuaded nine fellow Jesuits \"to count nearly 87,000 oscillations in a single day\". They served a crucial role in spreading and testing the scientific ideas of the period, and collaborated with contemporary scientists, such as Huygens.\n\nThe invention of the mainspring in the early 15th century allowed portable clocks to be built, evolving into the first pocketwatches by the 17th century, but these were not very accurate until the balance spring was added to the balance wheel in the mid 17th century. Some dispute remains as to whether British scientist Robert Hooke (his was a straight spring) or Dutch scientist Christiaan Huygens was the actual inventor of the balance spring. Huygens was clearly the first to use a spiral balance spring, the form used in virtually all watches to the present day. The addition of the balance spring made the balance wheel a harmonic oscillator like the pendulum in a pendulum clock, which oscillated at a fixed resonant frequency and resisted oscillating at other rates. This innovation increased watches' accuracy enormously, reducing error from perhaps several hours per day to perhaps 10 minutes per day, resulting in the addition of the minute hand to the watch face around 1680 in Britain and 1700 in France.\n\nLike the invention of pendulum clock, Huygens' spiral hairspring (balance spring) system of portable timekeepers, helped lay the foundations for the modern watchmaking industry. The application of the spiral balance spring for watches ushered in a new era of accuracy for portable timekeepers, similar to that which the pendulum had introduced for clocks. From its invention in 1675 by Christiaan Huygens, the spiral hairspring (balance spring) system for portable timekeepers, still used in mechanical watchmaking industry today.\n\nIn 1675, Huygens and Robert Hooke invented the spiral balance, or the hairspring, designed to control the oscillating speed of the balance wheel. This crucial advance finally made accurate pocket watches possible. This resulted in a great advance in accuracy of pocket watches, from perhaps several hours per day to 10 minutes per day, similar to the effect of the pendulum upon mechanical clocks. The great English clockmaker, Thomas Tompion, was one of the first to use this mechanism successfully in his pocket watches, and he adopted the minute hand which, after a variety of designs were trialled, eventually stabilised into the modern-day configuration.\n\nThe Rev. Edward Barlow invented the rack and snail striking mechanism for striking clocks, which was a great improvement over the previous mechanism. The repeating clock, that chimes the number of hours (or even minutes) was invented by either Quare or Barlow in 1676. George Graham invented the deadbeat escapement for clocks in 1720.\n\nMarine chronometers are clocks used at sea as time standards, to determine longitude by celestial navigation.\nA major stimulus to improving the accuracy and reliability of clocks was the importance of precise time-keeping for navigation. The position of a ship at sea could be determined with reasonable accuracy if a navigator could refer to a clock that lost or gained less than about 10 seconds per day. The marine chronometer would have to keep the time of a fixed location—usually Greenwich Mean Time—allowing seafarers to determine longitude by comparing the local high noon to the clock. This clock could not contain a pendulum, which would be virtually useless on a rocking ship.\nAfter the Scilly naval disaster of 1707 where four ships ran aground due to navigational mistakes, the British government offered a large prize of £20,000, equivalent to millions of pounds today, for anyone who could determine longitude accurately. The reward was eventually claimed in 1761 by Yorkshire carpenter John Harrison, who dedicated his life to improving the accuracy of his clocks.\n\nIn 1735 Harrison built his first chronometer, which he steadily improved on over the next thirty years before submitting it for examination. The clock had many innovations, including the use of bearings to reduce friction, weighted balances to compensate for the ship's pitch and roll in the sea and the use of two different metals to reduce the problem of expansion from heat.\n\nThe chronometer was trialled in 1761 by Harrison's son and by the end of 10 weeks the clock was in error by less than 5 seconds.\n\nIn 1815, Sir Francis Ronalds (1788-1873) of London published the forerunner of the electric clock, the electrostatic clock. It was powered with dry piles, a high voltage battery with extremely long life but the disadvantage of its electrical properties varying with the weather. He trialled various means of regulating the electricity and these models proved to be reliable across a range of meteorological conditions.\n\nAlexander Bain, a Scottish clock and instrument maker, was the first to invent and patent the electric clock in 1840. On January 11, 1841, Alexander Bain along with John Barwise, a chronometer maker, took out another important patent describing a clock in which an electromagnetic pendulum and an electric current is employed to keep the clock going instead of springs or weights. Later patents expanded on his original ideas.\n\nThe piezoelectric properties of crystalline quartz were discovered by Jacques and Pierre Curie in 1880. The first quartz crystal oscillator was built by Walter G. Cady in 1921, and in 1927 the first quartz clock was built by Warren Marrison and J. W. Horton at Bell Telephone Laboratories in Canada. The following decades saw the development of quartz clocks as precision time measurement devices in laboratory settings—the bulky and delicate counting electronics, built with vacuum tubes, limited their practical use elsewhere. In 1932, a quartz clock able to measure small weekly variations in the rotation rate of the Earth was developed. The National Bureau of Standards (now NIST) based the time standard of the United States on quartz clocks from late 1929 until the 1960s, when it changed to atomic clocks. In 1969, Seiko produced the world's first quartz wristwatch, the Astron. Their inherent accuracy and low cost of production has resulted in the subsequent proliferation of quartz clocks and watches.\n\nAtomic clocks are the most accurate timekeeping devices in practical use today. Accurate to within a few seconds over many thousands of years, they are used to calibrate other clocks and timekeeping instruments.\n\nThe idea of using atomic transitions to measure time was first suggested by Lord Kelvin in 1879, although it was only in the 1930s with the development of Magnetic resonance that there was a practical method for doing this. A prototype ammonia maser device was built in 1949 at the U.S. National Bureau of Standards (NBS, now NIST). Although it was less accurate than existing quartz clocks, it served to demonstrate the concept.\nThe first accurate atomic clock, a caesium standard based on a certain transition of the caesium-133 atom, was built by Louis Essen in 1955 at the National Physical Laboratory in the UK. Calibration of the caesium standard atomic clock was carried out by the use of the astronomical time scale \"ephemeris time\" (ET).\n\nThe International System of Units standardized its unit of time, the second, on the properties of cesium in 1967. SI defines the second as 9,192,631,770 cycles of the radiation which corresponds to the transition between two electron spin energy levels of the ground state of the Cs atom. The cesium atomic clock, maintained by the National Institute of Standards and Technology, is accurate to 30 billionths of a second per year. Atomic clocks have employed other elements, such as hydrogen and rubidium vapor, offering greater stability—in the case of hydrogen clocks—and smaller size, lower power consumption, and thus lower cost (in the case of rubidium clocks).\n\nThe first professional clockmakers came from the guilds of locksmiths and jewellers. Clockmaking developed from a specialized craft into a mass production industry over many years.\n\nParis and Blois were the early centres of clockmaking in France. French clockmakers such as Julien Le Roy, clockmaker of Versailles, were leaders in case design and ornamental clocks. Le Roy belonged to the fifth generation of a family of clockmakers, and was described by his contemporaries as \"the most skillful clockmaker in France, possibly in Europe\". He invented a special repeating mechanism which improved the precision of clocks and watches, a face that could be opened to view the inside clockwork, and made or supervised over 3,500 watches. The competition and scientific rivalry resulting from his discoveries further encouraged researchers to seek new methods of measuring time more accurately.\n\nBetween 1794 and 1795, in the aftermath of the French Revolution, the French government briefly mandated decimal clocks, with a day divided into 10 hours of 100 minutes each. The astronomer and mathematician Pierre-Simon Laplace, among other individuals, modified the dial of his pocket watch to decimal time. A clock in the Palais des Tuileries kept decimal time as late as 1801, but the cost of replacing all the nation's clocks prevented decimal clocks from becoming widespread. Because decimalized clocks only helped astronomers rather than ordinary citizens, it was one of the most unpopular changes associated with the metric system, and it was abandoned.\n\nIn Germany, Nuremberg and Augsburg were the early clockmaking centers, and the Black Forest came to specialize in wooden cuckoo clocks.\nThe English became the predominant clockmakers of the 17th and 18th centuries. The main centres of the British industry were in the City of London, the West End of London, Soho where many skilled French Huguenots settled and later in Clerkenwell. The Worshipful Company of Clockmakers was established in 1631 as one of the Livery Companies of the City of London.\n\nThomas Tompion was the first English clockmaker with an international reputation and many of his pupils went on to become great horologists in their own right, such as George Graham who invented the deadbeat escapement, orrery and mercury pendulum, and his pupil Thomas Mudge who created the first lever escapement. Famous clockmakers of this period included Joseph Windmills, Simon de Charmes who established the De Charmes clockmaker firm and Christopher Pinchbeck who invented the alloy pinchbeck.\n\nLater famous horologists included John Arnold who made the first practical and accurate modern watch by refining Harrison's chronometer, Thomas Earnshaw who was the first to make these available to the public, Daniel Quare, who invented a repeating watch movement, a portable barometer and introduced the concentric minute hand.\n\nQuality control and standards were imposed on clockmakers by the Worshipful Company of Clockmakers, a guild which licensed clockmakers for doing business. By the rise of consumerism in the late 18th century, clocks, especially pocket watches, became regarded as fashion accessories and were made in increasingly decorative styles. By 1796, the industry reached a high point with almost 200,000 clocks being produced annually in London, however by the mid-19th century the industry had gone into steep decline from Swiss competition.\n\nSwitzerland established itself as a clockmaking center following the influx of Huguenot craftsmen, and in the 19th century, the Swiss industry \"gained worldwide supremacy in high-quality machine-made watches\". The leading firm of the day was Patek Philippe, founded by Antoni Patek of Warsaw and Adrien Philippe of Bern.\n\n\n\n\n"}
{"id": "25012873", "url": "https://en.wikipedia.org/wiki?curid=25012873", "title": "History of virtual learning environments", "text": "History of virtual learning environments\n\nA virtual learning environment (VLE) is a system that creates an environment designed to facilitate teachers' management of educational courses for their students, especially a system using computer hardware and software, which involves distance learning. In North America, a virtual learning environment is often referred to as a \"learning management system\" (LMS).\n\nThe terminology for systems which integrate and manage computer-based learning has changed over the years. Terms which are useful in understanding and searching for earlier materials include:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDevelops the \"Interactive Learning Network\" ILN 1.5, and installs it at several academic institutions including Cornell University, Yale Medical School and University of Pittsburgh. The ILN was the first e-learning system of its kind to leverage an install on top of a relational database MySqL.\n\n\n\n\nLater that year in October 2000, deploy the ArsDigita Community Education System (ACES) at MIT Sloan School. The system is called Sloanspace. The ArsDigita Community System as well as ACES in the next few years grow to OpenACS and .LRN\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "18558517", "url": "https://en.wikipedia.org/wiki?curid=18558517", "title": "IPv6 deployment", "text": "IPv6 deployment\n\nDeployment of Internet Protocol Version 6 (IPv6), the next generation of the Internet Protocol, has been in progress since the mid-2000s.\n\nIPv6 was designed as a replacement for IPv4 which has been in use since 1982, and is in the final stages of exhausting its unallocated address space, but still carries most Internet traffic. Google's statistics show IPv6 availability of its users up to 25% depending on the day of the week (more use on weekends), with use over 20% any day of the week . Adoption is uneven across countries and Internet service providers.\nIn November 2016, 1491 (98.2%) of the 1519 top-level domains (TLDs) in the Internet supported IPv6 to access their domain name servers, and 1485 (97.8%) zones contained IPv6 glue records, and approximately 9.0 million domains (4.6%) had IPv6 address records in their zones. Of all networks in the global BGP routing table, 29.2% had IPv6 protocol support.\n\nBy 2011, all major operating systems in use on personal computers and server systems had production-quality IPv6 implementations. Cellular telephone systems present a large deployment field for Internet Protocol devices as mobile telephone service is making the transition from 3G to \"next-generation\" 4G technologies, in which voice is provisioned as a voice over IP (VoIP) service. This mandates the use of IPv6 for such networks. In 2009, the US cellular operator Verizon released technical specifications for devices to operate on its \"next-generation\" networks. The specification mandates IPv6 operation according to the \"3GPP Release 8 Specifications (March 2009)\", and deprecates IPv4 as an optional capability.\n\nGoogle publishes statistics on IPv6 adoption among Google users. A graph of IPv6 adoption since 2008 and a map of IPv6 deployment by country are available.\n\nAkamai publishes by-country and by-network statistics on IPv6 adoption for traffic it sees on its global Content Distribution Network (CDN). This set of data also shows graphs for each country and network over time.\n\nA global view into the history of the growing IPv6 routing tables can be obtained with the SixXS Ghost Route Hunter. This tool provided a list of all allocated IPv6 prefixes until 2014 and marks with colors the ones that were actually being announced into the Internet BGP tables. When a prefix was announced, it means that the ISP at least can receive IPv6 packets for their prefix.\n\nThe integration of IPv6 on existing network infrastructure may be monitored from other sources, for example:\n\nA few organizations are involved with international IPv6 test and evaluation, ranging from the United States Department of Defense to the University of New Hampshire.\n\n\nBy 2011, all major operating systems in use on personal computers and server systems had production-quality IPv6 implementations. Microsoft Windows has supported IPv6 since Windows 2000, and in production-ready state beginning with Windows XP. Windows Vista and later have improved IPv6 support. macOS since Panther (10.3), Linux 2.6, FreeBSD, and Solaris also have mature production implementations. Some implementations of the BitTorrent peer-to-peer file transfer protocol make use of IPv6 to avoid NAT issues common for IPv4 private networks.\n\nIn the early 2000s, governments increasingly required support for IPv6 in new equipment. The US government, for example, specified in 2005 that the network backbones of all federal agencies had to be upgraded to IPv6 by June 30, 2008; this was completed before the deadline. In addition, the US government in 2010 required federal agencies to provide native dual-stacked IPv4/IPv6 access to external/public services by 2012, and internal clients were to utilize IPv6 by 2014. Progress on the US government's external facing IPv6 services is tracked by NIST. The government of the People's Republic of China implemented a five-year plan for deployment of IPv6 called the \"China Next Generation Internet\" (see below).\n\nOn March 07, 2013, the Internet Engineering Task Force, created a working group for IPv4 sunset. However in May 2018 this working group was closed.\n\nAnwarNet (www.anwarnet.dz); AfriNIC has allocated range of IPv6 address space to AnwarNet. AnwarNet started IPV6 services in 2011.\n\n\n\n\nAs of 2017, Brazil has 20% IPv6 adoption, IPv6 being adopted by most universities, companies and made available for home users by larger ISPs.\n\nHas constructed a research center to study the possibilities of adopting IPv6 in the country. The center will operate alongside another facility, which is equipped with an IBM Blue Gene/P supercomputer.\n\nSince 2015 the ISP Blizoo enabled IPv6 for many home customers.\n\nAt the end of 2016, the ISP ComNet Bulgaria Holding Ltd. has provided complete IPv6 support for all customers and households within company network in Bulgaria.\n\nIPv6 deployment is slow but ongoing, with major Canadian ISPs (notably Bell Canada, Vidéotron, and Cogeco) lacking in support for its residential customers, and the majority of their business customers (including server packages). Canadian IPv6 usage jumped from 0.5% in July 2015 to 7% in Dec 2015 due to IPv6 deployment at Rogers and Telus.\n\nAccording to Google's statistics, Canada has reached an IPv6 adoption rate of 16% by December 2016.\n\n\nThe China Next Generation Internet (CNGI, 中国下一代互联网) project is a five-year plan initiated by the Chinese government with the purpose of gaining a significant position in the development of the Internet through the early adoption of IPv6. China showcased CNGI's IPv6 infrastructure during the 2008 Summer Olympic Games, being the first time a major world event has had a presence on the IPv6 Internet. At the time of the event, it was believed that the Olympics provided the largest showcase of IPv6 technology since the inception of IPv6. The deployment of IPv6 was widespread in all related applications, from data networking and camera transmissions for sporting events, to civil applications, such as security cameras and taxis. The events were streamed live over the Internet and networked cars were able to monitor traffic conditions readily, all network operations of the Games being conducted using IPv6.\n\nAlso, the CERNET (China Education and Research NETwork, 中国教育和科研计算机网, 教育网) set up native IPv6 (CERNET2), and since then many academic institutions in China joined CERNET2 for IPv6 connectivity. CERNET-2 is probably the widest deployment of IPv6 in China. It is managed and operated jointly by 25 universities. Students in Shanghai Jiao Tong University and Beijing University of Posts and Telecommunications, for example, get native IPv6.\n\nIn November 2017, the Communist party decreed a plan to get all its Internet users on IPv6 by 2025 with a quarter of them by the end of 2018.\n\nAs of December 2016, the country has only 2% IPv6 traffic (according to both Google and Apnic stats).\n\nA web page (in Danish) follows national IPv6 deployment.\n\nThe ISP Fullrate has begun offering IPv6 to its customers, on the condition that their router (provided by the ISP itself) is compatible. If the router is of a different version, the customer has to request a new router.\n\nEstonian Telekom is providing native IPv6 access on residential and business broadband connections since September 2014. According to Google's statistics, Estonia has reached an IPv6 adoption rate of 18% by end of June 2017.\n\nFICORA (Finnish Communications Regulatory Authority), the NIC for the .fi top level domain, has added IPv6 address to DNS servers, and allows entering IPv6 address when registering domains. The registration service domain.fi for new domains is also available over IPv6.\n\nA small Finnish ISP has offered IPv6 access since 2007.\n\nFICORA held national IPv6 day on June 9, 2015. At that time Elisa and DNA Oyj started providing IPv6 on mobile subscriptions, and Telia Company and DNA Oyj started providing IPv6 on fixed-line connections.\n\nAccording to Google's statistics, Finland has reached an IPv6 adoption rate of 15% by May 2017.\n\n\nAs of May 2017, France has 16% IPv6 traffic (according to Google and 20% Apnic stats).\n\nAccording to Google's statistics, Germany has reached an IPv6 adoption rate of 30% by end of May 2017.\n\n\nIn Hungary was the first ISP starting deploying IPv6 on its network in 2008 August. The service was commercially available since 2009 May.\n\nMagyar Telekom was running tests on its production environments since the beginning of 2009. Free customer trials started on November 2, 2009, for those on ADSL or Fiber Optic. Customers are given a /128 via DHCP-ND unless they register their DUID in which case they receive a /56 using a static configuration results in a single /64.\n\nAccording to information on telecompaper.com, UPC Hungary will start deploying IPv6 in mid-2013, finishing it in 2013.\n\nIn 2015, December RCS&RDS (Digi) has enabled native dual stack IPv6(customers receive dynamic /64 prefixes) for its FTTB/H customers. In November the same year UPC Hungary introduced DS Lite(with private IPv4 addresses) which can be enabled on a customer-to-customer basis if the customer asks for it.\n\nMagyar Telekom deployed dual stack IPv6 (using dynamic /56 prefixes on DSL and GPON and static /56 prefixes on DOCSIS) for all of its wired (and for all of its compatible mobile) customers in October 2016.\n\nAccording to the statistics of APNIC, IPv6 use in Hungary as of 2017 June has reached around 11%.\n\nAccording to Google's IPv6 statistics the adoption rate at 2017 June was 11%.\n\nAccording to Google's statistics, India has reached an IPv6 adoption rate of around 32% at the end of May 2018.\nAPNIC places India at more than 50% preferring IPv6.\n\n\n\nGrowth of IPv6 in Ireland as seen by Google.\n\n\nAccording to Google's statistics, Japan has reached an IPv6 adoption rate of 17% by May 2017.\n\n\nThe LITNET academic & research network has supported IPv6 since 2001. Most commercial ISPs have not publicly deployed IPv6 yet.\n\nAccording to Google's statistics, Luxembourg has reached an IPv6 adoption rate of 24% by May 2017.\n\n\n, surveys conducted by the New Zealand IPv6 Task Force indicated that awareness of IPv6 had reached a near-universal level among New Zealand's large public- and private-sector organisations, with adoption mostly occurring as part of normal network refresh cycles. Most of New Zealand's ISP and carrier community have a test environment for IPv6 and many have started bringing IPv6 products and services on-stream. An increasing number of New Zealand government websites are available over IPv6, including those of the Ministry of Defence (New Zealand), Ministry for Primary Industries (New Zealand) and the Department of Internal Affairs.\n\n\nThe government is in process of upgrading its facilities. Globe Telecom has already set in motion the transition of its core IP network to IPv6, noting that it is now fully prepared even as the Internet runs out of IPv4 addresses. Globe claims it is the first local telecommunication company to test IPv6 with Department of Science and Technology (Philippines). In some cases, like test networks or users, IPv6 or both maybe present.\n\n\n\n\nThe Sudanese IPv6 task Force SDv6TF was formed in 2010 to fellow the implementation of IPv6 migration plan (2011–2015).\n\nBy November 2012, all telecom operators are becoming IPv6 enabled, this was tested for the first time at the AFRINIC-17 meeting held in Khartoum.\n\nSudREN (Sudanese Research and Education Network) is the first ISP to provide native IPv6 connectivity of the member institution. By August 2014, SudREN.edu.sd is fully IPv6 Enabled.\nTwo certification received from IPv6 Forum, for WWW and ISP Enabled Logos.\n\n\nOperators offering native IPv6 access for business clients and collocation customers include Tele2 and Phonera.\n\n\nStarted deploying IPv6 in 2010. In 2011, ATI (Tunisian Internet Agency) obtained a new IPv6 bloc from Afrinic (2c0f:fab0::/28).\nIn 2013–2015, Gnet (Global Net), and CIMSP (Computing Departement of Health Ministry) received IPv6 prefixes from Afrinic.\nDeployment of an IPv6 tunnel between ATI and HE (Hurricane Electric).\nIn 2016, CCK (Centre de Calcul El Khawarizmi) obtains its own IPv6 (/32) bloc from Afrinic. In 2016, ISET Charguia (Higher Institute of Technologies in Tunisia) deployed its IPv6 network as end user.\n\n\nIn the United States the majority of smartphones use IPv6, but only a small percent of computers and tablets use IPv6.\n\nThe Internet Society promoted June 8, 2011, as \"World IPv6 Day\". The event was described as a \"test drive\" for full IPv6 rollouts.\n\nThe Internet Society declared June 6, 2012, to be the date for \"World IPv6 Launch\", with participating major websites enabling IPv6 permanently, participating ISPs offering IPv6 connectivity, and participating router manufacturers offering devices enabled for IPv6 by default.\n\n\n"}
{"id": "32261703", "url": "https://en.wikipedia.org/wiki?curid=32261703", "title": "Ip.access", "text": "Ip.access\n\nip.access Limited is a multinational corporation that designs, manufactures, and markets small cells (picocell and femtocell) technologies and infrastructure equipment for GSM, GPRS, EDGE, 3G and LTE. The firm has headquarters in Cambourne, England, the company also maintains operations and offices in Bellevue, United States, and Gurgaon and Pune, India.\n\nip.access combines IP and cellular technologies together to provide 2G, 3G and LTE coverage and for mobile networks .Using satellite backhaul, its products provide coverage to commercial passenger aircraft, ships, and users in remote rural areas.\n\nThe firm is a member of 3GPP, the Cambridge Network, European Telecommunications Standards Institute (ETSI), Small Cell Forum, and an associate member of the Network Vendors Interoperability Testing (NVIOT) Forum.\n\nip.access was founded in December 1999 as a wholly owned subsidiary of TTP Group PLC aimed at developing technologies that would allow multiple radio access technologies to communicate over the Internet. To accommodate its growing staff, in 2006 ip.access relocated to new offices in Cambourne Business Park, Cambridge, where it remains.\n\nIn October 2000, TTP Group spun off its communications division (TTP Communications, or TTPCom) in an initial public offering on the London Stock Exchange, and ip.access joined the spin-off as a wholly owned subsidiary of the TTPCom group.\n\nIn March 2006, the company secured an £8.5 million round of funding from Intel Capital, Scottish Equity Partners, and Rothschild & Cie Banque. As part of its June 2006 acquisition of TTP Communications, Motorola also gained a stake in ip.access. In 2007, after signing an OEM agreement with ip.access, ADC (now part of Tyco Electronics) made a minority interest investment in the company. Followed by, both Cisco Systems and Qualcomm making strategic financial investments in the company in 2008.\n\nIn July 2007, the firm became a founding member of the Femto Forum, renamed Small Cell Forum in February 2012. ip.access was named in The Sunday Times Fast Tech Track 100 in both 2007 and 2008. The company was also cited as the number one picocell vendor by global market intelligence company, ABI Research in 2008.\n\nIn 2009, ip.access was named in the Deloitte Technology Fast 500 EMEA. In April 2009, the company announced its Oyster 3G product would support femtocell standards published by 3GPP and the Broadband Forum. In March 2010, the company took part in the first Plugfest, organized by ETSI as part of its Plugtests program, held to demonstrate the effectiveness of the 3GPP femtocell standards in supporting interoperability between femtocell access points and network equipment from different vendors.\n\nIn June 2011, the market research and analysis firm Infonetics named ip.access along with its partner Cisco Systems, as the leading supplier of 3G femtocells. In August 2011, ip.access announced it had made more than 500,000 installations of its 3G technologies. In February 2013, ip.access announced it had become the first 3G small cell provider to ship one million residential units. In the same month, ip.access and iDirect completed successful interopability test of 3G small cells over IP Satellite.\n\nIn February 2014, ip.access launched a new range of small cells called presenceCell, which unlike traditional small cells, do not rely on providing indoor coverage and capacity to deliver a return on investment. Rather, the ultra-compact base stations are designed to capture anonymous user location and phone identity information from smartphones, which can be analysed and packaged as a service for a variety of businesses.\n\nThe telecommunications firms AT&T uses Oyster 3G as the core femtocell technology for its 3G MicroCell product. Cisco Systems, has jointly developed a femtocell solution with ip.access in compliance with the Broadband Forum's TR-069 technical specification.\n\nIn 2002, ip.access introduced the world’s first IP basestation controller for indoor GSM networks. nanoGSM uses 2G picocells that leverage the standard GSM air interface, full IP-based BSC, and an OMC-R management system that delivers voice, messaging and data to both 2G and 3G handsets at an indoor range of up to 200m.\n\nnano3G is an end-to-end Femtocell system with access points for Enterprise, E-class [E8, E16 and E24] and Small Medium Business, S-class [S8], access controller and element management system, providing carrier-class coverage to commercial and consumer users.\n\nLaunched at the 2007 3GSM World Congress in Barcelona, Spain, the Oyster 3G is ip.access' core 3G femtocell technology used by system integrators and OEM customers to integrate WCDMA femtocells into home gateways, set-top boxes, and other devices. ip.access' Oyster 3G is the core technology of AT&T's 3G MicroCell\n\nnanoLTE [E-40, E-100] is an Enterprise grade platform that brings LTE capacity both in-doors and in public spaces, while also offering the option of providing extra 3G infill and Circuit Switch Fall Back (CSFB) capacity.\n\nLaunched in 2014, the presenceCell is a new range of small cell, designed to capture precise user location data via their smart phone, which can be analysed and packaged as a service for a variety of businesses.\nIn addition to the presenceCell, ip.access also provides the back-end processing and management system that delivers the Presence data anonymously and securely to vertical application providers. The company’s Network Orchestration System serves as the infrastructure management solution and also supports the GSMA’s OneAPI standard, which allows third parties to provide value-added services through web friendly message interfaces. The presenceCell was commercially deployed by Vodafone Turkey in 2015.\n\nAmong ip.access' major customers are AT&T, Bharti Airtel, Blue Ocean Wireless, Bouygues Telecom,Jersey Telecom Monaco Telecom, SFR, SPIE SA, T-Mobile, Tele2, Telefónica O2 Czech Republic,Telia Sonera, Vivacom and Vodafone\n\nThe company's technology partners include AeroMobile, Altobridge, Blue Ocean Wireless, Cisco Systems, Private Mobile Networks, Qualcomm, Quortus, Setcom, and TriaGnoSys.\n\nCorporate, product, and personnel awards won by ip.access include the following:\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "43674629", "url": "https://en.wikipedia.org/wiki?curid=43674629", "title": "List of cooking appliances", "text": "List of cooking appliances\n\nThis is a list of cooking appliances that are used for cooking foods.\n\n\n\n"}
{"id": "55502135", "url": "https://en.wikipedia.org/wiki?curid=55502135", "title": "List of cooking vessels", "text": "List of cooking vessels\n\nThis is a list of cooking vessels. A cooking vessel is a type of cookware or bakeware designed for cooking, baking, roasting, boiling or steaming. Cooking vessels are manufactured using materials such as steel, cast iron, aluminum, clay and various other ceramics. Some cooking vessels, such as ceramic ones, absorb and retain heat after cooking has finished.\n\n\n\n\n\n\n\n\n\n"}
{"id": "662340", "url": "https://en.wikipedia.org/wiki?curid=662340", "title": "List of duplicating processes", "text": "List of duplicating processes\n\nThis is a partial list of text and image duplicating processes used in business and government from the Industrial Revolution forward. Some are mechanical and some are chemical. There is naturally some overlap with printing processes and photographic processes, but the challenge of precisely duplicating business letters, forms, contracts, and other paperwork prompted some unique solutions as well. There were many short-lived inventions along the way.\n\n\"Within each type, the methods are arranged in very rough chronological order.\"\n\n\n\n"}
{"id": "13706125", "url": "https://en.wikipedia.org/wiki?curid=13706125", "title": "List of emerging technologies", "text": "List of emerging technologies\n\nEmerging technologies are those technical innovations which represent progressive developments within a field for competitive advantage.\n\n\n"}
{"id": "55980254", "url": "https://en.wikipedia.org/wiki?curid=55980254", "title": "List of shortest runways", "text": "List of shortest runways\n\nThis is a list of the shortest airport runways in the world. While most modern commercial aircraft require a paved runway of at least 6000 feet in length, many early aircraft were designed to operate from unprepared strips that could be improvised in small spaces. Los Angeles's Grand Central Airport, considered a landmark in aviation history, had a 1200 foot runway during its first six years of operation from 1923 to 1929. Such airstrips were used by heavy as well as light aircraft. During the Doolittle Raid in WW II, twin-engine B-25 bombers with a loaded weight of seventeen tons took off from the 827-foot flight deck of the carrier USS \"Hornet\". As late as 1977 a Lockheed Constellation demonstrated its ability to use the 2700 foot runway of the Greenwood Lake Airport in New Jersey, and in 1946, a lightened Constellation took off from a grass strip in 2000 feet on only three engines. Most general aviation aircraft retain this short-field performance; the Cessna 172, the most successful aircraft in history, will take off in as little as 720 feet when fully loaded. Many small airfields capable of accommodating these types remain in use, mostly in remote areas in the American West and French Alps, where space is limited.\n\n"}
{"id": "37630506", "url": "https://en.wikipedia.org/wiki?curid=37630506", "title": "List of smart TV platforms and middleware software", "text": "List of smart TV platforms and middleware software\n\nThe following list encompasses notable smart TV platforms and application software that are used as software framework and middleware platforms used by more than just one manufacturer.\n\nFor TV sets and companion boxes vendors, available under OEM license.\n\nIncludes first and third-party solutions.\n\n"}
{"id": "1721135", "url": "https://en.wikipedia.org/wiki?curid=1721135", "title": "Low technology", "text": "Low technology\n\nLow technology, often abbreviated low tech (adjective forms low-technology, low-tech, lo-tech) is simple technology, often of a traditional or non-mechanical kind, such as crafts and tools that pre-date the Industrial Revolution. It is the opposite of high technology.\n\nLow technology can typically be practised or fabricated with a minimum of capital investment by an individual or small group of individuals. Also, the knowledge of the practice can be completely comprehended by a single individual, free from increasing specialization and compartmentalization. Low-tech techniques and designs may fall into disuse due to changing socio-economic conditions or priorities.\n\nNote: almost all of the entries in this section should be prefixed by the word \"traditional\".\n\n\n\nNote: home canning is a counter example of a low technology since some of the supplies needed to pursue this skill rely on a global trade network and an existing manufacturing infrastructure.\n\n\nBy federal law in the United States, only those articles produced with little or no use of machinery or tools with complex mechanisms may be stamped with the designation \"hand-wrought\" or \"hand-made\". Lengthy court-battles are currently underway over the precise definition of the terms \"organic\" and \"natural\" as applied to foodstuffs.\n\n\n\n"}
{"id": "39903888", "url": "https://en.wikipedia.org/wiki?curid=39903888", "title": "Medio", "text": "Medio\n\nMedio is a business-to-business mobile analytics provider based in Seattle, WA. The company processes pre-existing data to provide historic and predictive analytics. Medio is built on a cloud-based Hadoop platform and is designed to interpret big data for mobile enterprise. Medio has had various partners including: IBM, Rovio, Verizon, T-Mobile, ABC, and Disney\n\nMedio was founded in 2004 by Brian Lent, Bill Bryant, David Bluhm, and Michael Libes and employed 40 people. Founded to be the 'Google' of mobile search engines, Medio was backed by $30 Million in initial venture funding from various tech companies including: Accel Partners, Mohr Davidow Ventures, and Frazier Technology Ventures.\n\nMedio received $11 Million more in 2006 to create a mobile analytics search engine capable of searching for ringtones, graphics, and internet-delivered information. This sparked employment to over 100 employees for some time, but in 2009 Google released their new mobile search engine. Rob Lilleness, who joined the company as President and COO in 2007 and was subsequently named CEO in 2009, took that as an opportunity to refocus as a predictive analytics and data science provider, using their recommendations engine as a key component of their newly focused company. The shift resulted in lay-offs of much of the staff, scaling back to nearly 60 employees.\n\nBy the end of 2010 the company became profitable, nearly tripling its sales from previous years. With the latest version of the Medio Platform and the release of products like K-Invite, Medio has grown to 70 employees with a total of $44 Million in venture funding.\n\nOn July 1, 2014, Medio was acquired by Nokia and the company plans to grow their presence in Seattle.\n\n"}
{"id": "45684490", "url": "https://en.wikipedia.org/wiki?curid=45684490", "title": "Ministry of Research, Technology and Higher Education (Indonesia)", "text": "Ministry of Research, Technology and Higher Education (Indonesia)\n\nMinistry of Research, Technology and Higher Education of the Republic of Indonesia is a government ministry that has the task of conducting affairs in the field of research, science and technology in the government to assist the President of Indonesia in carrying out state. The ministry was formerly known as the National Research Affairs Ministry of the Republic of Indonesia.\n\nFounded in 1962 under the name National Research Affairs Ministry of the Republic of Indonesia, and in 1973 changed its name to the Ministry of Research. Year 1986-2001 as Minister of State for Research and Technology, and in 2002 according Circular Minister of State for Administrative Reform concerning Naming Government Agencies, Office of the Secretary of State referred to the Ministry of Research and Technology. In 2005 pursuant to Presidential Decree No. 9 In 2005, this institution called the Ministry of Research and Technology (KNRT) or as the State Ministry of Research and Technology. In 2009 pursuant to Presidential Decree 47 of 2009 referred to the Ministry of Research and Technology.\n\n\nIn formulating the main directions and priorities of development of science and technology as well as the preparation of a strategic policy of national science and technology development, the Ministry of Research and Technology supported by the National Research Council (DRN).\n\n\nBased on Presidential Decree No. 4 of 2003 on the co-ordination of formulation, Strategic Policy Development and Implementation of National Science and Technology, Ministry of Research, and Technology co-ordinate government agencies non-ministry as follows;\n\nMinistry of Research and Technology also co-ordinate, and manage institutions as follows:\n"}
{"id": "1544319", "url": "https://en.wikipedia.org/wiki?curid=1544319", "title": "Nanosocialism", "text": "Nanosocialism\n\nNanosocialism refers generally to a set of economic theories of social organization advocating state or collective ownership and administration of the research, development and use of nanotechnology.\n\nNanosocialism is a stance that favors participatory politics to guide state intervention in the effort to manage the transition to a society revolutionized by molecular nanotechnology.\n\n\"Nanosocialism\" is a term coined by David M. Berube, the associate director of Nanoscience and Technology Studies at the USC NanoCenter, who argues that nanotechnological projections need to be tempered by technorealism about the implications of nanotechnology in a technocapitalist society, but that its applications also offer enormous opportunities for economic abundance and social progress.\n\nIn the role-playing game \"Transhuman Space\", nanosocialism is described as a descendant of infosocialism, in which intellectual property is nationalized and freely distributed by the state. It is adopted by some developing nations to counter the hold corporations from wealthier nations have on copyrights and patents. This fictional version of nanosocialism was coined by David L. Pulver, the game's creator, who was unaware that the term had already been used by Berube.\n\n"}
{"id": "1365774", "url": "https://en.wikipedia.org/wiki?curid=1365774", "title": "OPeNDAP", "text": "OPeNDAP\n\nOPeNDAP is an acronym for \"Open-source Project for a Network Data Access Protocol,\" an endeavor focused on enhancing the retrieval of remote, structured data through a Web-based architecture and a discipline-neutral Data Access Protocol (DAP). Widely used, especially in Earth science, the protocol is layered on HTTP, and its current specification is DAP4, though the previous DAP2 version remains broadly used. Developed and advanced (openly and collaboratively) by the non-profit OPeNDAP, Inc., DAP is intended to enable remote, selective data-retrieval as an easily invoked Web service. OPeNDAP, Inc. also develops and maintains zero-cost (reference) implementations of the DAP protocol in both server-side and client-side software. \n\n\"OPeNDAP\" often is used in place of \"DAP\" to denote the protocol but also may refer to an entire DAP-based data-retrieval architecture. Other DAP-centered architectures, such as THREDDS and ERDDAP, exhibit significant interoperability with one another as well as with systems employing OPeNDAP's own (open-source) servers and software.\n\nA DAP client can be an ordinary browser or even a spreadsheet, though with limited functionality (see OPeNDAP's Web page on Available Client Software). More typically, DAP clients are:\n\nRegardless of their types, and whether developed commercially or by an end-user, clients almost universally link to DAP servers through \"libraries\" that implement the DAP2 or DAP4 protocol in one language or another. OPeNDAP offers open-source libraries in C++ and Java, but many clients rely on community developed libraries such as PyDAP or, especially, the NetCDF suite. Developed and maintained by the Unidata Program at the UCAR in multiple programming languages, all NetCDF libraries include embedded capabilities for retrieving (array-style) data from DAP servers.\n\nA data-using client references a data set by its URL and requests metadata or content by issuing (usually through an embedded DAP library) an HTTP request to a DAP server. Content requests usually are \"preceded\" by requests for metadata describing the structure and other details about the referenced data set. With this information, the client may construct DAP constraint expressions to retrieve specific content (i.e., subsets) from the source. OPeNDAP servers offer various types of responses, depending on the specific form of the client's request, including XML, JSON, HTML and ASCII. In response to requests for \"content\", OPeNDAP servers can respond with multi-part mime documents that include a binary portion with NetCDF or DAP-native encoding. (These binary forms offer compact means to deliver large volumes of content, and the DAP-native form may even be streamed if desired.)\n\nOPeNDAP's software for building DAP servers (on top of Apache) is dubbed Hyrax and includes \"adapters\" that facilitate serving a wide variety of source data. DAP servers most frequently enable (remote) access to (large) HDF or NetCDF files, but the source data can exist in databases or other formats, including user-defined ones. When source data are organized as files, DAP retrievals enable, via subsetting, finer-grained access than does the FTP. Furthermore, OPeNDAP servers can aggregate subsets from multiple files for delivery in a single retrieval. Taken together, subsetting, aggregation and streaming can yield substantial data-access efficiencies, even in the presence of slow networks.\n\nOPeNDAP and other DAP servers are used operationally in government agencies, including NASA and NOAA, for providing access to Earth science data, including satellite imagery and other high-volume information sources. The DAP data model embraces a comprehensive set of data structures, including multidimensional arrays and nested sequences (i.e., records), complemented by a correspondingly rich set of constraint expressions. Hence the OPeNDAP data-retrieval architecture has demonstrated utility across a broad range of scientific data types, including data generated via simulations and data generated via observations (whether remotely sensed or measured in situ).\n\n"}
{"id": "5655064", "url": "https://en.wikipedia.org/wiki?curid=5655064", "title": "Owner's manual", "text": "Owner's manual\n\nAn owner's manual (also called an instruction manual or a user guide) is an instructional book or booklet that is supplied with almost all technologically advanced consumer products such as vehicles, home appliances and computer peripherals.\nInformation contained in the owner's manual typically includes:\n\nUntil the last decade or two of the twentieth century it was common for an owner's manual to include detailed repair information, such as a circuit diagram; however as products became more complex this information was gradually relegated to specialized service manuals, or dispensed with entirely, as devices became too inexpensive to be economically repaired.\n\nOwner's manuals for simpler devices are often multilingual so that the same boxed product can be sold in many different markets. Sometimes the same manual is shipped with a range of related products so the manual will contain a number of sections that apply only to some particular model in the product range.\n\nWith the increasing complexity of modern devices, many owner's manuals have become so large that a separate quickstart guide is provided. Some owner's manuals for computer equipment are supplied on CD-ROM to cut down on manufacturing costs, since the owner is assumed to have a computer able to read the CD-ROM. Another trend is to supply instructional video material with the product, such as a videotape or DVD, along with the owner's manual.\n\nMany businesses offer PDF copies of manuals that can be accessed or downloaded free of charge from their websites.\n\nAn installation manual or installation guide is a technical communication document intended to instruct people how to install a particular product. An installation manual is usually written by a technical writer or other technical staff. \n\nInstallation is the act of putting something in place so that it is ready for use. An installation manual most commonly describes the safe and correct installation of a product. The term product here relates to any consumer, non-consumer, hardware, software, electrical, electronic or mechanical product that requires installation. The installation of a computer program is also known as the setup.\n\nIn case of an installation manual, the installation instruction is a separate document that focuses solely on the person(s) that will perform the installation. However, the installation instruction can also be an integrated part of the overall owner's manual.\n\nThe size, structure and content of an installation manual depend heavily on the nature of the product and the needs and capabilities of the intended target group. Furthermore, various standards and directives are available that provide guidance and requirements for the design of instructions.\n\nThe international standard IEC 82079 prescribes the required installation topics for an installation instruction. Among these topics, are procedures, diagrams and conditions for installation activities, such as unpacking, mounting and connecting.\n\nFor machines the European Machinery Directive prescribes that an instruction manual must contain assembly, installation and connecting instructions, including drawings, diagrams and the means of attachment and the designation of the chassis or installation on which the machinery is to be mounted.  \n\nAll new cars come with an owner's manual from the manufacturer. Most owners leave them in the glove compartment for easy reference. This can make their frequent absence in rental cars frustrating because it violates the driver's user expectations, as well as makes it difficult to use controls that aren't understood, which is not good because understanding control operation of an unfamiliar car is one of the first steps recommended in defensive driving. Owner's manuals usually cover three main areas: a description of the location and operation of all controls; a schedule and descriptions of maintenance required, both by the owner and by a mechanic; and specifications such as oil and fuel capacity and part numbers of light bulbs used. Current car owner's manuals have become much bigger in part due to many safety warnings most likely designed to avoid product liability lawsuits, as well as from ever more complicated audio and navigational systems, which often have their own manual.\n\nIf owners lose their car manual, they can either order a replacement from a dealer, pick up a used one secondhand, or download a PDF version of the manual online.\n\nIn 2017 the next generation of digitized car manuals came online, which use IBM Watson Artificial Intelligence to understand and and answer questions in natural driver language. \"Ask Mercedes\" was the first in a wave of these vehicle assistants which can support both speech and text-based input.\n\nOfficial website\n\nThe noun phrase \"owner's manual\" has been used by analogy in the title of numerous instructional books about entities that are not manufactured products, such as pets, body parts and businesses.\n\nThe equivalent document for computer software is called a user guide since users are typically licensees rather than owners of the software.\n\nThe OPEN BOOK (📖) Unicode symbol equals \"read operator's manual\". OPEN BOOK has Unicode code point U+1F4D6.\n"}
{"id": "13634965", "url": "https://en.wikipedia.org/wiki?curid=13634965", "title": "Peer-to-peer video sharing", "text": "Peer-to-peer video sharing\n\nPeer-to-peer video sharing is a basic service on top of the IP Multimedia Subsystem (IMS).\nEarly proprietary implementations might also run a simple SIP infrastructure, too.\n\nThe GSM Association calls it \"Video Share\". The peer-to-peer video sharing functionality is defined by the Phase 1 of the GSMA Video Share service.\nFor a more detailed description of the full GSMA Video Share service, please see the Wikipedia entry for Video Share.\n\nThe most basic form is typically connected to a classical circuit-switched (CS) telephone call.\nWhile talking on the CS line the speaker can start in parallel a multimedia IMS session. The session is normally a video stream, with audio being optional (since there is an audio session already open on the CS domain). It is also possible to share photos or files.\n\nActually, P2P video sharing does not require a full IMS implementation. It could work with a pure IETF Session Initiation Protocol (SIP) infrastructure and simple HTTP Digest authentication.\nHowever, mobile operators may want to use it without username/password provisioning and the related frauds problems. One possible solution is the Early IMS Authentication method.\nIn the future USIM/ISIM based authentication could be introduced, too.\nSo the IMS adds up extra security and management features that are normally required by a mobile operator by default.\n\nThe early Nokia implementation requires the manual setting of an attribute in the phone book. When the video session is triggered (by simply pulling down the back-side camera cover on a 6680), the video sharing client looks up the destination URI based on the MSISDN number of the B party of the current open CS voice call. The video sharing is possible only if this number has a valid entry in the phone book and a valid URI for the SIP call.\n\nHowever, this method is not really scalable, since the user has to enter very complex strings into the phone book manually. Because this service does not involve any application server, it is difficult to make a good business model for it.\nUsually, the first commercial services were based on the idea that video sharing will increase the length of the voice sessions, and the resulting increased revenue would be enough to cover the costs of the video sharing service.\n\nThe P2P video sharing was introduced in 2004 by Nokia. Two major operators started commercial implementations: \"Turbo Call\" from Telecom Italia Mobile (TIM) in Italy and Telecomunicações Móveis Nacionais, SA (TMN) in Portugal.\n\nThe first handsets to support P2P video sharing were the Nokia 6630 and 6680. The 6680 is especially suited for turning on the video sharing by having a slider on top of the back-side camera.\nLater the Nokia N70 was added to the commercially supported handsets.\n\nTIM Italy reported about 10% penetration (based on the potentially available customers with appropriate handsets).\n\n\n"}
{"id": "10721277", "url": "https://en.wikipedia.org/wiki?curid=10721277", "title": "Redshift (theory)", "text": "Redshift (theory)\n\nRedshift is a techno-economic theory suggesting hypersegmentation of information technology markets based on whether individual computing needs are over or under-served by Moore's law, which predicts the doubling of computing transistors (and therefore roughly computing power) every two years. The theory,\nproposed and named by New Enterprise Associates partner and former Sun Microsystems CTO Greg Papadopoulos, categorized a series of high growth markets (redshifting) while predicting slower GDP-driven growth in traditional computing markets (blueshifting). Papadopoulos predicted the result will be a fundamental redesign of components comprising computing systems.\n\nAccording to the Redshift theory, applications \"redshift\" when they grow dramatically faster than Moore's Law allows, growing quickly in their absolute number of systems. In these markets, customers are running out of datacenter real-estate, power and cooling infrastructure. According to Dell Senior Vice President Brad Anderson, “Businesses requiring hyperscale computing environments – where infrastructure deployments are measured by up to millions of servers, storage and networking equipment – are changing the way they approach IT.”\n\nWhile various Redshift proponents offer minor alterations on the original presentation, “Redshifting” generally includes:\n\nThese are companies that drive heavy Internet traffic. This includes popular web-portals like Google, Yahoo, AOL and MSN. It also includes telecoms, multimedia, television over IP, online games like World of Warcraft and others. This segment has been enabled by widespread availability of high-bandwidth Internet connections to consumers through a DSL or cable modem. A simple way to understand this market is that for every byte of content served to a PC, mobile phone or other device over a network, there must exist computing systems to send it over the network.\n\nThese are companies that do complex simulations that involve (for example) weather, stock markets or drug-design simulations. This is a generally elastic market because businesses frequently spend every \"available\" dollar budgeted for IT. A common anecdote claims that cutting the cost of computing by half causes customers in this segment to buy at least twice as much, because each marginal IT dollar spent contributes to business advantage.\n\nThese are companies that aggregate traditional computing applications and offer them as services, typically in the form of Software as a Service (SaaS). For example, companies that deploy CRM are over-served by Moore's Law, but companies that aggregate CRM functions and offer them as a service, such as Salesforce.com, grow faster than Moore's Law.\n\nA prime example of redshift was a crisis at eBay. In 1999 eBay suffered a database crisis when a single Oracle Database running on the fastest Sun machine available (these tracking Moore's law in this period) was not enough to cope with eBay's growth. The solution was to massively parallelise their system architecture.\n\nRedshift theory suggests that traditional computing markets, such as those serving enterprise resource planning or customer relationship management applications, have reached relative saturation in industrialized nations. Thereafter, proponents argued further market growth will closely follow gross domestic product growth, which typically remains under 10% for most countries annually. Given that Moore's Law continues to predict accurately the rate of computing transistor growth, which roughly translates into computing power doubling every two years, the Redshift theory suggests that traditional computing markets will ultimately contract as a percentage of computing expenditures over time.\n\nFunctionally, this means “Blueshifting” customers can satisfy computing requirement growth by swapping in faster processors without increasing the absolute number of computing systems.\n\nPapadopoulos argued that while traditional computing markets remain the dominant source of revenue through the late 2000s, a shift to hypergrowth markets will inevitably occur. When that shift occurs, he argued computing (but not computers) will become a utility, and differentiation in\nthe IT market will be based upon a company's ability to deliver computing at massive scale, efficiently and with predictable service levels, much like electricity at that time.\n\nIf computing is to be delivered as a utility, Nicholas Carr suggested Papadopoulos' vision compares with Microsoft researcher Jim Hamilton, who both agree that computing is most efficiently generated in shipping containers. Industry analysts are also beginning to quantify Redshifting and Blueshifting markets. According to International Data Corporation vice president Matthew Eastwood, \"IDC believes that the IT market is in a period of hyper segmentation... This a class of customers that is Moore's law driven and as price performance gains continue, IDC believes that these organizations will accelerate their consumption of IT infrastructure.”\n\nKey portions of Papadopoulos' theory were first presented by Sun Microsystems CEO Jonathan Schwartz in late 2006. Papadopoulos later gave a full presentation on Redshift to Sun's annual Analyst Summit in February 2007. The term Redshift refers to what happens when electromagnetic radiation, usually visible light, moves away from an observer. Papadopoulos chose this term to reflect growth markets because redshift helped cosmologists explain the expansion of the universe.\n\nPapadopoulos originally depicted traditional IT markets as green to represent their revenue base, but later changed them to “blueshift,” which occurs when a light source moves toward an observer, similar to what would happen during a contraction of the universe.\n\n"}
{"id": "8434470", "url": "https://en.wikipedia.org/wiki?curid=8434470", "title": "Robot ethics", "text": "Robot ethics\n\nRobot ethics, sometimes known by the short expression \"roboethics\", concerns ethical problems that occur with robots, such as whether robots pose a threat to humans in the long or short run, whether some \"uses\" of robots are problematic (such as in healthcare or as 'killer robots' in war), and how robots should be designed such as they act 'ethically' (this last concern is also called machine ethics). Robot ethics is a sub-field of ethics of technology, specifically information technology, and it has close links to legal as well as socio-economic concerns. Researchers from diverse areas are beginning to tackle ethical questions about creating robotic technology and implementing it in societies, in a way that will still ensure the safety of the human race. \n\nWhile the issues are as old as the word \"robot\", serious academic discussions started around the year 2000. Robot ethics requires the combined commitment of experts of several disciplines, who have to adjust laws and regulations to the problems resulting from the scientific and technological achievements in Robotics and AI. The main fields involved in robot ethics are: robotics, computer science, artificial intelligence, philosophy, ethics, theology, biology, physiology, cognitive science, neurosciences, law, sociology, psychology, and industrial design.\n\nSince antiquity, the discussion of ethics in relation to the treatment of non-human and even non-living things and their potential \"spirituality\" have been discussed. With the development of machinery and eventually robots, this philosophy was also applied to robotics. The first publication directly addressing and setting the foundation for robot ethics was Runaround (story), a science fiction short story written by Isaac Asimov in 1942 which featured his well known Three Laws of Robotics. These three laws were continuously altered by Asimov, and a fourth, or zeroth law, was eventually added to precede the first three. in the context of his science fiction works. The short term \"roboethics\" was probably coined by Gianmarco Veruggio.\n\nAn important event that propelled the concern of roboethics was the First International Symposium on Roboethics in 2004 by the collaborative effort of Scuola di Robotica, the Arts Lab of Scuola Superiore Sant'Anna, Pisa, and the Theological Institute of Pontificia Accademia della Santa Croce, Rome. \"After two days of intense debating, anthropologist Daniela Cerqui identified three main ethical positions emerging from two days of intense debate:\n\nThese are some important events and projects in robot ethics. Further events in the field are announced by the euRobotics ELS topics group, and by RoboHub:\n\n\nRoboethics as a science or philosophical topic has not made any strong cultural impact, but is a common theme in science fiction literature and films. One of the most popular films depicting the potential misuse of robotic and AI technology is \"The Matrix\", depicting a future where the lack of roboethics brought about the destruction of the human race. An animated film based on \"The Matrix\", the \"Animatrix\", focused heavily on the potential ethical issues between humans and robots. Many of the Animatrix's animated shorts are also named after Isaac Asimov's fictional stories. \n\nAlthough not a part of roboethics \"per se\", the ethical behavior of robots themselves has also been a joining issue in roboethics in popular culture. The \"Terminator\" series focuses on robots run by an uncontrolled AI program with no restraint on the termination of its enemies. This series too has the same futuristic plot as \"The Matrix\" series, where robots have taken control. The most famous case of robots or computers without programmed ethics is HAL 9000 in the \"Space Odyssey\" series, where HAL (a computer with advance AI capabilities who monitors and assists humans on a space station) kills all the humans on board to ensure the success of the assigned mission after his own life is threatened. \n\n\n\nThe standard bibliography on roboethics is on PhilPapers \n\n\n\n\n"}
{"id": "56797234", "url": "https://en.wikipedia.org/wiki?curid=56797234", "title": "SS Australasia", "text": "SS Australasia\n\nThe Australasia was a wooden hulled steamship that sank on October 18, 1896 in Lake Michigan near the town of Sevastopol, Door County, Wisconsin, United States, after burning off Cana Island. On July 3, 2013 the wreck of the \"Australasia\" was added to the National Register of Historic Places.\n\nThe \"Australasia\" (Official number 106302) was built in 1884 in West Bay City, Michigan by the shipyard owned by Captain James Davidson. She was built for the Davidson Steamship Company which was also owned by Captain Davidson. At a length of the \"Australasia\" was one of the largest wooden ships ever built; her beam was wide and her cargo hold was deep. She was powered by a fore and aft compound engine which was fueled by two coal burning Scotch marine boilers. She had a gross register tonnage of 1829.32 tons and a net register tonnage of 1539.20 tons.\n\nOn September 17, 1884 the \"Australasia\" was launched as hull number #9. At the time of her launch the \"Australasia\" was the largest wooden hulled ship in the world. Because of her enormous size the \"Australasia\" needed iron cross bracing, an iron keelson, iron plates, and several iron arches to increase her strength.\n\nShe was used to haul bulk cargoes such as iron ore, coal, grain and sometimes salt. She could carry these cargoes so efficiently that she earned a fortune for her owners at a time when small, less versatile wooden vessels were quickly being replaced by larger, and stronger iron or steel vessels. Just like all ships owned by Captain Davidson, the \"Australasia\" used to tow a wooden schooner barge.\n\nOn October 17, 1896, the \"Australasia\" was bound from Lake Erie to Milwaukee, Wisconsin, carrying 2,200 tons of soft coal. At around 6:00 p.m. near Baileys Harbor, the crew of the \"Australasia\" discovered \"a fire beneath the texas on the main deck\". They attempted to fight the blaze but failed. The crew abandoned the \"Australasia\" before she reached Jacksonport, Wisconsin. At 10:30 p.m., the \"Australasia\" was about four hours off Jacksonport when the tugboat \"John Leathem\" came upon the struggling steamer. The \"Leathem\" began towing the \"Australasia\" to shore, but the hawser connecting them kept burning through. At 9:00 a.m. on October 18, 1896, the crew of the \"Leathem\" gave up trying to salvage her and instead dragged her onto the beach in of water south of Cave Point. Her crew decided to scuttle her; they did this by ramming a hole in the \"Australasia\"&apos;s side with the \"Leathem\"&apos;s stem. She was left heading north by northwest. She burned until the night of October 18, 1896.\n\nThe \"Australasia\" was declared a total loss. Much of her cargo of soft coal and machinery was salvaged, however her hull was beyond repair and was abandoned. Today her lower hull lies mostly buried in sand 15 to 20 feet of water off Whitefish Dunes State Park. Because most of her hull remains buried in sand, there is the possibility that different hull sections may be uncovered which may reveal more significant information about her construction. Not a trace of her cargo is visible on the site of her wreck, but traces of coal is visible on a beach nearby. The wreck of the \"Australasia\" is rarely visited by divers which means that very little site disturbance to the site has occurred. Close by are the wrecks of several other ships including the early steel freighter \"Lakeland\", the large wooden bulk carrier \"Frank O'Connor, the wooden steamer \"Louisiana\" which was lost during the Great Lakes Storm of 1913, the schooner \"Christina Nilsson\" and the steamboat \"Joys\".\n"}
{"id": "48466186", "url": "https://en.wikipedia.org/wiki?curid=48466186", "title": "Secure Islands", "text": "Secure Islands\n\nSecure Islands Technologies Ltd. was an Israeli privately held technology company headquartered in 5 Menachem Begin Ave., Beit Dagan, which was subsequently acquired by Microsoft. The company develops and markets Information Protection and Control (IPC) solutions.\n\nSecure Islands Technologies Ltd. was founded by two brothers, Aki and Yuval Eldar, in late 2006, to develop and sell advanced data security solutions. The then Jerusalem-based start-up company suggested a new solution for data protection: embedding security directly in data. Secure Islands builds software designed to classify sensitive information automatically based on policies outlined by an enterprise, and then to wrap it in the appropriate level of Digital rights management (DRM).\n\nMicrosoft acquired Israeli cyber-sec startup Secure Islands in 2015.\n\nSecure Islands Technologies Ltd. software is based on its active data immunization concept. Secure Islands’ Data Immunization technology uniquely embeds protection within information itself at the moment of creation or initial organizational access. This process is automatic and accompanies sensitive information throughout its lifecycle from creation, through usage and collaboration to storage and archival.\n\nThe company's \"IQProtector\" product, which is cloud-based, classifies unstructured data and automates IRM by classification at endpoints.\n\n"}
{"id": "28675208", "url": "https://en.wikipedia.org/wiki?curid=28675208", "title": "Silicon Taiga", "text": "Silicon Taiga\n\nSilicon Taiga is a nickname for Akademgorodok, a Russian research and development center that is located near Novosibirsk. The nickname is a reference to the Silicon Valley, a renowned IT region found in Northern California. The term was first introduced to the Western press by Newsweek magazine in 1999.\n\nThe town is situated partly on the River Ob, and partly on the shore of a Novosibirsk artificial reservoir that was created by a dam on the river. Informally, this reservoir is called the Ob Sea. The dam contains a large hydroelectric power plant that was constructed in the 1950s.\n\nThe town itself has no skyscrapers, and only one remote speedway connecting it to the city of Novosibirsk. Office buildings and residences are connected by many intertwined, footworn paths.\n\nIn the 1950s the former Academy of Sciences of the USSR founded its Siberian Division, today known as the Siberian Division of the Russian Academy of Sciences, with a center of scientific research in Akademgorodok, where they established a dozen research institutes. To keep institutes supplied with fresh minds, Novosibirsk State University (NSU) was founded by the resolution of the Council of Ministers of the USSR on January 9, 1958.\n\nThe distinctive feature of NSU is its system of competitive selection and its training of talented youth. NSU is the only university in Siberia to have developed a multilevel model of continuing education. The University was built and developed simultaneously with the Novosibirsk scientific center and is focused on training highly qualified specialists for scientific work and tutoring. Since its foundation in 1958, more than fifty thousand specialists graduated from Novosibirsk State University; more than six thousand have defended their PhD dissertations, and over one thousand five hundred have received doctoral degrees. In 2009, NSU achieved the status of a national research university. This high honor was granted by the Russian Government on a competitive basis for a period of ten years.\n\nThe first IT companies were established in Akademgorodok in the 1990s. After the collapse of the Soviet Union, the government's investments into scientific activity were greatly reduced, and many scientists left long established institutions on a quest for better conditions. Some of these scientists decided to leave Russia in search of jobs in foreign scientific organizations all over the world. Others established their own private businesses, which were software-related high-tech IT companies. Many of these companies grew up into large, internationally recommended providers of software products and services. Their strategy was simple: the new IT companies would adopt the tried and true principles of the already established, famous IT corporations.\n\nAll IT companies in the Silicon Taiga can be divided into the two categories according to the offshore programming business model they employ: The firms that provide Offshore Development Center (ODC), and mostly develop new custom products (NPD), and the firms that are oriented to the SAAS model. Meantime the global giants in the field of software and high-tech products, such as IBM, Intel Corporation, and Schlumberger, saw this growing trend and established branch offices in the Silicon Taiga.\n\nThe summer of 2010 saw the launch of an innovative technology park in Akademgorodok, which brought together economic and intellectual power in the area, thus expanding innovation in Russia. Today, the Silicon Taiga is not just a collection of IT companies; it is a beneficial environment, in which the Russian national system of innovations can continue to flourish.\n\nThe following is a partial list of past and present notable companies founded in the Silicon Taiga or which have a major subsidiary located there:\n\n\n"}
{"id": "2233721", "url": "https://en.wikipedia.org/wiki?curid=2233721", "title": "SpreadsheetML", "text": "SpreadsheetML\n\nSpreadsheetML is the XML schema for Microsoft Office Excel 2003.\n\nThe Office 2003 XML Reference Schemas are included in the Microsoft Open Specification Promise, a legal statement concerning unrestricted use of Microsoft intellectual property.\n\n\n"}
{"id": "50177657", "url": "https://en.wikipedia.org/wiki?curid=50177657", "title": "The Industries of the Future", "text": "The Industries of the Future\n\nThe Industries of the Future is a 2016 non-fiction book written by Alec Ross, an American technology policy expert and the former Senior Advisor for Innovation to Secretary of State Hillary Clinton during her time as Secretary of State. Ross is also a senior fellow at Columbia University, a former night-shift janitor, and a Baltimore teacher. Ross launched a campaign for the Governor of Maryland in 2017. The book explores the forces that will change the world in robotics, genetics, digital currency, coding and big data.\n\nThe Industries of the Future by Senior Policy Advisor Alec Ross explores the geopolitical, cultural and generational changes that will be driven by the key industries over the next twenty years. Ross is a Distinguished Visiting Fellow at Johns Hopkins University and was the Senior Advisor for Innovation to Secretary of State Hillary Clinton. During his time as Senior Advisor for Innovation he visited forty-one countries looking at the technological advances. He has been a guest lecturer at a number of institutions including the United Nations, University of Oxford, Harvard Law School, and Stanford Business School. Ross started his career as a teacher through Teach for America and in 2000 he co-founded a technology-focused nonprofit organization called One Economy.\n\nThe book explores several industries including robotics, genetics, coding and big data. Ross explores how advances in robotics and life sciences will change the way we live—robots, artificial intelligence and machine learning will have impact on our lives. According to Ross, dramatic advances in life sciences will increase our life expectancy—but not all will benefit from such changes. Ross spends time exploring \"Code\" and how the codefication of money and also weapons (computer security) will both benefit and potentially disrupt our international economies. Ross also looks at how data will be \"the raw material of the information age.\"\n\nRoss also focuses on globalization and geopolitical economics. He explores how competitiveness and how societies, families and individuals will need to thrive. Ross gives attention to the importance of women stating that \"the states and societies that do the most for women are those that will be best positioned to compete and succeed in the industries of the future.\" The book also touches on how to prepare children for \"success in a world of increasing change and competition.\"\n\nRoss discusses the shift of robotics from being manual and repetitive to cognitive and non-repetitive. He believes that breakthroughs in mathematical modeling and cloud robotics (machine learning and Artificial Intelligence) make robotics acceptable. In the book Ross describes how other cultures have different reactions to robotics and he uses Japan's use of robotics in elder-care as an example. He also expects that less developed countries may be able to leapfrog technologies in robotics much like they did with cell and mobile technologies.\n\nAccording to Ross, the last trillion dollar industry was created out of computer code; the next trillion dollar industry will be created out of genome code. In the book Ross describes how genome code is already being used to fix humans from curing cancer to hacking the brain to growing organs. He also describes the difference between the United States investment in genome research with that of China.\n\nRoss then turns to the \"code-ification\" of money, markets and trust. He describes the transition from cash to mobile and online banking. He also discusses the sharing economy from eBay to AirBnB and then gives an overview of BitCoin and blockchain technology. Ross also focuses on cybersecurity and the weaponization of code with a focus on a move from cold war to \"code war.\" Ross states that he expects the total market size of the cyberindustry to reach $175 billion by the end of 2017.\n\nAlec Ross has said that he intended to give a balanced point of view with the book that it is neither a Utopian or Dystopian vision of the future which is why he opened the book with the struggles he witnessed growing up in West Virginia. On writing the book Ross said that he knows his parents would have wanted a book like this in the sixties that would describe what globalization would do and he wished that he had a book like this when he graduated from college that would have explored the Internet and digitization on the economy.\n\nThe editors for the book were Jonathan Karp and Jonathan Cox of Simon & Schuster.\n\n\"The Industries of the Future\" has received mainly positive reviews from the likes of \"Forbes\", \"New York Journal of Books\", and \"Financial Times\". \"Forbes\" contributor Peter Decherney said the book \"reads like a portable TED conference at which you've been seated next to the smartest guy in the room.\" The book was also listed on the Forbes list—\"16 New Books for Leaders to Begin in 2016\". Tara D. Sonenshine in the \"New York Journal of Books\" called the book a good place to start \"if you want to know how to survive and thrive in the fast-paced world of today and how to anticipate the opportunities of tomorrow's information age.\" Sonenshine also called out the book for focusing on women and multiculturalism. In an article titled \"Is predicting the future futile or necessary?\" by Stephen Cave in the \"Financial Times\" is more critical, saying that Ross focuses on industries with already considerable coverage and investment but Cave points out that \"rarely can the future be predicted by extending current trajectories.\"\n\nThe following trends are covered in the book:\n"}
{"id": "1256791", "url": "https://en.wikipedia.org/wiki?curid=1256791", "title": "User guide", "text": "User guide\n\nA user guide or user's guide, also commonly known as a manual, is a technical communication document intended to give assistance to people using a particular system. It is usually written by a technical writer, although user guides are written by programmers, product or project managers, or other technical staff, particularly in smaller companies.\n\nUser guides are most commonly associated with electronic goods, computer hardware and software, although they can be written for any product.\n\nMost user guides contain both a written guide and the associated images. In the case of computer applications, it is usual to include screenshots of the human-machine interface(s), and hardware manuals often include clear, simplified diagrams. The language used is matched to the intended audience, with jargon kept to a minimum or explained thoroughly.\n\nThe sections of a user manual often include:\n\nUser guides have been found with ancient devices. One example is the Antikythera Mechanism, a 2,000 year old Greek analogue computer that was found off the coast of the Greek island Antikythera in the year 1900. On the cover of this device are passages of text which describe the features and operation of the mechanism.\n\nAs the software industry was developing, the question of how to best document software programs was undecided. This was a unique problem for software developers, since users often became frustrated with current help documents. Some considerations for writing a user guide that developed at this time include:\n\n\n\n\n\nUser manuals and user guides for most non-trivial software applications are book-like documents with contents similar to the above list. They may be distributed either in print or electronically. Some documents have a more fluid structure with many internal links. The \"Google Earth User Guide\" is an example of this format. The term \"guide\" is often applied to a document that addresses a specific aspect of a software product. Some usages are \"Installation Guide\", \"Getting Started Guide\", and various \"How to\" guides. An example is the \"Picasa Getting Started Guide\".\n\nIn some business software applications, where groups of users have access to only a sub-set of the application's full functionality, a user guide may be prepared for each group. An example of this approach is the \"Autodesk Topobase 2010 Help\" document, which contains separate \"Administrator Guides\", \"User Guides\", and a \"Developer's Guide\".\n\n"}
{"id": "23623196", "url": "https://en.wikipedia.org/wiki?curid=23623196", "title": "VMQ", "text": "VMQ\n\nThe Virtual Machine Queue (VMQ) is a hardware virtualization technology for the efficient transfer of network traffic (such as TCP/IP, iSCSI or FCoE) to a virtualized host OS. VMQ technology was patented in 2010 by Daniel Baumberger of Intel Corp. A VMQ capable NIC can use DMA to transfer all incoming frames that should be routed to a receive queue to the receive buffers that are allocated for that queue. The miniport driver can indicate all of the frames that are in a receive queue in one receive indication call.\n\nThe VMQ interface supports:\n\n\nThe NDIS virtual machine queue (VMQ) architecture provides advantages for virtualization such as:\n\n\nSome networks recommend disabling VMQ. They state this option is prone to misconfiguration and can cause reduced network performance when enabled.\n"}
{"id": "35554636", "url": "https://en.wikipedia.org/wiki?curid=35554636", "title": "Whiteboard animation", "text": "Whiteboard animation\n\nWhiteboard animation is the process of which an author physically draws and records an illustrated story using a whiteboard- or whiteboard like surface- and marker pens. The animations frequently are aided with narration by script. The authors commonly use stop motion animation to liven hand drawn illustrations, with YouTube used as a common platform. It is also used in television and internet advertisements to communicate to consumer's in a personal way. The earliest videos made using Whiteboard Animation were published in 2009 on YouTube, used mostly for experimental purposes until developing into a story telling device, focusing majority on narratives, though it has many other uses in modern day. \n\n\"Whiteboard animation\" refers to a specific type of presentation that uses the process of creating a series of draw pictures on a whiteboard that are recorded in sequence and then played back to create an animated presentation. The actual effect of whiteboard animation is time-lapse, or stop-motion. Actual sequential frame by frame animation is rarely used but has been incorporated. Other terms are \"video scribing\" and \"animated doodling\". These video animation styles are now seen in many variations, and have taken a turn into many other animation styles. With the introduction of software to create the whiteboard animations, the process has many different manifestations of varying quality. Those who use whiteboard animation are typically businesses and educators.\n\nThe whiteboard animation production procedure begins with creating a topic. Once the topic is chosen, script writing begins. After the content is created, it is time to create rough drafts of animations. These assist to set up the inventive bearing and timing for the movement. The rest of the process is as follows:\nThe steps listed above are not set in stone, they should be used as a guideline to create a whiteboard animation production.\n\nWhiteboard animation has been used in a few TV spots and on internet video sites such as YouTube and Vimeo. Early types were UPS Whiteboard Commercials. Many companies and firms of all sectors and sizes are incorporating this style into their modus operandi to teach company employees different company policies or demonstrate a new software or product to consumers.\n\nFor educational purposes, whiteboard animation videos have been used for learning online to teach languages, as chapter summaries for educational textbooks, and for the public communication of academic scholarship. A 2016 study of whiteboard animation found that, despite claims and high popularity, there is little to no compelling experimental evidence that they are more effective in learning, motivation, or persuasion than other forms of learning.\n\nStarting in 2010, the Royal Society of Arts converted selected speeches and books from its public events program into whiteboard animations. The first 14 RSA Animate videos gained 46 million views in 2011, making the RSA's YouTube channel the no.1 nonprofit channel worldwide.\n"}
