{"id": "35510", "url": "https://en.wikipedia.org/wiki?curid=35510", "title": "56 kbit/s line", "text": "56 kbit/s line\n\nA 56 kbit/s line is a digital connection capable of carrying 56 kilobits per second (kbit/s), or 56,000 bit/s, the data rate of a classical single channel digital telephone line in North America. In many urban areas, which have seen wide deployment of faster, cheaper technologies, 56 kbit/s lines are generally considered to be an obsolete technology.\n\nThe figure of 56 kbit/s is derived from its implementation using the same digital infrastructure used since the 1960s for digital telephony in the public switched telephone network, which uses a sampling rate of 8,000 Hz for PCM audio with 8-bit audio bit depth to encode analogue signals into a digital stream of 64,000 bit/s. However, in the T-carrier systems used in the US and Canada, a technique called bit-robbing uses, in every sixth frame, the least significant bit for Channel Associated Signaling (CAS). This effectively renders the lowest bit of the 8 speech bits unusable for data transmission, and so a 56 kbit/s line usees only 7 of the 8 data bits in each sample period to send data, thus giving a data rate of .\n\n"}
{"id": "6487479", "url": "https://en.wikipedia.org/wiki?curid=6487479", "title": "Alvey", "text": "Alvey\n\nThe Alvey Programme was a British government sponsored research program in information technology that ran from 1983 to 1987. The program was a reaction to the Japanese Fifth generation computer project.\n\nThe project was named after John Alvey, a technology director at BT who led the enquiry that proposed the creation of the program. John Alvey was not involved in the program itself \n\nFocus areas for the Alvey Programme included:\n\n\n"}
{"id": "26011932", "url": "https://en.wikipedia.org/wiki?curid=26011932", "title": "Barsanti-Matteucci engine", "text": "Barsanti-Matteucci engine\n\nThe Barsanti-Matteucci engine was the first internal combustion engine. In late 1851 or early 1852 Eugenio Barsanti, a professor of mathematics, and Felice Matteucci, an engineer and expert in mechanics and hydraulics, joined forces on a project to exploit the explosion and expansion of a gaseous mix of hydrogen and atmospheric air to transform part of the energy of such explosions into mechanical energy.\n\nThe idea originated almost ten years earlier with Barsanti when, as a young man, he was teaching at St. Michael's College in Volterra, Italy. An engineer from Milan Italy, Luigi de Cristoforis, described in a paper published in the acts of the Lombard Royal Institute of Science, Literature and Art, a pneumatic machine (later built and shown to work) that ran on naphtha and an air mixture, and which constituted the first liquid fuel engine.\n\nDuring the twelve years of collaboration between Barsanti and Matteucci several prototypes of internal combustion engines were realized. It was the first real internal combustion engine, constituted in its simplest realization by a vertical cylinder in which an explosion of a mixture of air and hydrogen or an illuminating gas shot a piston upwards thereby creating a vacuum in the space underneath. When the piston returned to its original position, due to the action of the atmospheric pressure, it turned a toothed rod connected to a sprocket wheel and transmitted movement to the driving shaft.\nNumerous patents were obtained by the two inventors: the 1854 English and Piedmont patents, the 1861 Piedmont patent of Barsanti, Matteucci and Babacci which was then used as a base to construct the engine of the Escher Wyss company of Zurich and put on exhibit during the first National Expo of Florence in 1861, and the 1861 English patent.\n\n"}
{"id": "43921971", "url": "https://en.wikipedia.org/wiki?curid=43921971", "title": "Christina Gagnier", "text": "Christina Gagnier\n\nChristina Gagnier is an intellectual property lawyer, entrepreneur and a 2014 Democratic Party candidate for the U.S. House of Representatives, representing California's 35th congressional district. She is chief executive officer of Technology Resources and Internet Literacy (TRAIL), a platform and application development company focused on addressing the digital divide and access to the Internet.\n"}
{"id": "58326591", "url": "https://en.wikipedia.org/wiki?curid=58326591", "title": "Coding it Forward", "text": "Coding it Forward\n\nCoding it Forward is an American 501c3 non-profit organization building a talent pipeline into civic tech, primarily through creating and marketing data science and technology internships in United States federal government agencies for undergraduate and graduate students at colleges and universities across the United States.\n\nSeveral Harvard University students were inspired by former Chief Technology Officer of the United States Megan Smith's appeal for technologists to work in public service at the annual Grace Hopper Celebration of Women in Computing. They started a blog highlighting how students were contributing to civic tech which quickly grew to 800 members within two months. Two of the students took a course with the former Deputy Chief Technology Officer of the United States Nick Sinai where they had the opportunity to work on tech projects in government. That experience led to the idea of organizing tech focused student internships in government.\n\nThe primary program of Coding it Forward is their \"Civic Digital Fellowship\", a competitive 10-week data science and technology internship program for undergraduate and graduate students in United States federal agencies. To date, they have received more than 1,100 applications from students from more than 175 colleges and universities for 50 fellowship positions..\n\nCo-founders Athena Kan and Chris Kuang were selected to give the closing keynote at the 2018 Code for America Summit in Oakland, CA, in front of an audience of 1,200 civic technologists (Video of Keynote).\n\nThe organization has attracted support from philanthropic sources such as the Chan Zuckerberg Initiative, the Knight Foundation, and the Shuttleworth Foundation.\n"}
{"id": "18010409", "url": "https://en.wikipedia.org/wiki?curid=18010409", "title": "Collaborative journalism", "text": "Collaborative journalism\n\nCollaborative journalism is a mode of journalism where multiple reporters or news organizations, without affiliation to a common parent organization, report on and contribute news items to a news story together. It is practiced by both professional and amateur reporters. It is not to be mixed up with citizen journalism.\n\nCollaborative journalism involves the aggregation of information from numerous individuals or organizations into a single news story. Information is gathered through research or reporting, or added when readers examine, comment and build upon existing stories. Stories from the mainstream media are often built upon. Depending on the system of collaboration, individuals may also provide feedback or vote on whether an article is newsworthy. A single collaborative news story, therefore, may encompass multiple authors, varying articles, and ranged perspectives.\n\nProfessional and amateur reporters may work together to develop collaborative news articles, or mainstream media sites may gather amateur blog posts to complement reporting.\n\nCollaborative journalists either contribute directly to stories, sometimes through a wiki-style collaboration platform, or build upon the story externally, often through personal blogs. Collaborative journalists develop or examine a story one piece at a time. This contrasts the deadline and completion-centered nature of traditional media. A story is built upon continually, and a popular story may receive daily updates. Through combined authorship, collaborative journalism is thought by some to offer an increased independence of thought and experience unavailable to traditional media.\n\nSuccessful collaborative journalism projects require a participatory community with respect for content. Ross Mayfield, CEO of SocialText, has commented on wiki-style collaborative journalism:\n\n\"Most user-generated content isn't content, but conversation. Cultivating community is a decided practice. It boils down to the social contract you make with your readers-turned-writers. If they trust that their effort and words will be appropriated appropriately, while providing social incentives for participation, it can very well work.\"\n\nCollaborative journalism emerged through the internet in the early 2000s, and developed gradually through various online outlets. As examples, Wikinews was founded in 2003, and NewsVine in 2005.\n\nThe Panama Papers project may be the largest example of a journalistic consortium to date. It began sometime in 2015 (date?) when Bastian Obermayer, an investigative reporter with the south German newspaper Süddeutsche Zeitung, was contacted by an anonymous source and offered the trove of 11.5 million electronic documents from Mossack Fonseca, the world’s fourth biggest offshore law firm detailing a web of secret offshore deals and loans worth billions of dollars, and details of tax avoidance designs in numerous countries. The newspaper's editors decided they could not handle the massive volume of information alone and initiated a collaborative journalistic consortium including more than 140 journalists and the International Consortium of Investigative Journalists, a project of the nonprofit Center for Public Integrity.\n\nThe European Investigative Collaborations (EIC) working with \"over 60 journalists in 14 countries\" published a \"series of articles called \"Football Leaks\"—the \"largest leak in sports history\". \"Football Leaks\" \"led to the prosecution of football superstar Cristiano Ronaldo and coach Jose Mourinho.\" EIC was established in the fall of 2015 with founding members that include \"Der Spiegel\", \"El Mundo\", \"Médiapart\", the Romanian Centre for Investigative Journalism (CRJI), and \"Le Soir\".\n\n\n\"Link journalism\", a phrase coined by Scott Karp in 2008, is \"a form of collaborative journalism in which a news story's writer provides external links within the story to reporting or other sources on the web.\" These links are meant to complement, enhance, or add context to the original reporting. Jeff Jarvis, from the Graduate School of Journalism's new media program at the City University of New York, has said that link journalism creates a \"new architecture of news.\"\n\nCollaborative journalism has been implemented in several different ways. Wikinews, the \"free-content online news source,\" lets any user edit or create a news story, similar in style to Wikipedia. Several mainstream news sites have adopted a collaborative journalism approach toward news, through use of news aggregation. The Washington Post has developed a political site which links to related content from other news sites. NBC links to local newspapers, radio broadcasts, online videos, and blogs on its local television stations' sites. The sites do not separate articles written by NBC staff and links to outside sources.\nThe New York Times has introduced a \"Times Extra\" website feature which acts posts links to outside news sites. Commenting on the launch of \"Times Extra\", Marc Frons, CTO for Digital Operations at the New York Times, said:\n\n“In the past, I think many news organizations were afraid to link to other Web sites out of fear that they might be sending people to an unreliable source or that their readers would never return. But those fears were largely misplaced and we’ve seen a much more open policy when it comes to pointing readers at useful content elsewhere on the Web.\"\nOther sites exhibit collaborative journalism through aggregation. On the site NewsVine, for example, wire stories from the Associated Press complement user-generated stories and blog posts. Reddit and other news aggregation sites may also act as collaborative journalism sites, depending on where content originates.\n\nDue to the increase in collaborative journalism, several organizations have begun to offer grants or awards for these types of projects. For example, Online Journalism Awards (launched in May 2000) added a new award category for collaborations and partnerships. Clean Energy Wire offers grants for collaborative journalism projects on the topic of energy or the climate. The annual Hostwriter Prize awards money to support pitches and published collaborative projects by journalists.\n\nCollaborative journalism has received some criticism:\n"}
{"id": "34153797", "url": "https://en.wikipedia.org/wiki?curid=34153797", "title": "Comparison of orbital rocket engines", "text": "Comparison of orbital rocket engines\n\nThis page is an incomplete list of orbital rocket engine data.\n\nLegend: [under development] — [operational or inactive] — [retired or canceled]\n\n"}
{"id": "3779965", "url": "https://en.wikipedia.org/wiki?curid=3779965", "title": "Critical technical practice", "text": "Critical technical practice\n\nCritical technical practice is critical theory based approach towards technological design proposed by Phil Agre where critical and cultural theories are brought to bear in the work of designers and engineers. One of the goals of critical technical practice is to increase awareness and critical reflection on the hidden assumptions, ideologies and values underlying technology design.\n\nA different fork of Critical Technical Practice from Agre’s root (Agre, 1997) was initiated at the former Centre for Cultural Studies between 2007-2017, Goldsmiths, University of London as a way to examine, the live techno-social aspects of contemporary digital culture. This stream of Critical Technical Practice (CTP) at its most broad use can be described as the formation of thought and action that incorporates art as a method of enquiry. This is a compacted intellectual form, that makes the space between the technical, theory and practice ambiguous. A typical digital culture class would make/explore things, attempting to explain the phenomena caught in the lens of a project or proposition. \nAn example of a class may clarify this approach. We might propose that the class create a simple (DOS) denial of service attack on a test remote server by learning to code computers for the first time. It is empowering for students to find out how quickly they can code. The class would learn how to do this from T.J. Connor’s book Violent Python. After the group had reached a self-satisfied tingle of radicalism the group would be asked to look up the author and would find that Connor is a top grade US Military expert. The group would then look at the books distribution and market penetration and be encouraged to question the affective logics, politics and culture of the book, reflect on why the workshop had been constructed the way it was, and their own learning in different registers of technicality, politics of information and personal critic and empowerment was achieved. \nCritical Technical Practice then is not necessarily a reduction of phenomena to literature or a system of logics, but can instead be thought of as knowledge incorporated into a thing that the class created, look at or pointed too, through revealing a certain type of gaze. A prerequisite of Critical Practice is that incorporates this form of gaze is thinking through the formation of oneself as a thinker, actor in the world. Enquiring into one's pre-existence helps understand the structuring of potential that has informed what one has become, what one could easily recognise, and what one could easily achieve. This is not a summation of limit but an acknowledgement of the hard work needed to escape a pre-existence, as it may relate to the four pillars of repression, class, gender, sexuality and race. The situated knowledge of family and friends, their relation to making things, to popular culture, to oral histories, to struggles with money or law, reading, writing and speaking, all inform this process. \nTo this end, CTP is partially related to a schizoanalysis of Foucault's question “What are we today?” (Foucault 1984: pp. 42ff.) The class is always encouraged to unfold what conditions, constrain, control, resist, govern, determine this moment and not another? What patterns of recognition are we privileging and why does it blind us to others? How does language restrict us at the very moment we are able to say something? How can this engagement be born anew in every instance? \n\nPeople whose work contributes to the critical technical practice agenda include \nPhil Agre,\nPaul Dourish,\nNatalie Jeremijenko,\nMichael Mateas,\nSimon Penny,\nWarren Sack,\nGarnet Hertz,\nYoHa, (Matsuko Yokokoji, Graham Harwood)\nand \nPhoebe Sengers.\n\n\n"}
{"id": "48505834", "url": "https://en.wikipedia.org/wiki?curid=48505834", "title": "Crowdfunding", "text": "Crowdfunding\n\nCrowdfunding is the practice of funding a project or venture by raising small amounts of money from a large number of people, typically via the Internet. Crowdfunding is a form of crowdsourcing and alternative finance. In 2015, a worldwide estimate totaling over was raised by crowdfunding.\n\nAlthough similar concepts can also be executed through mail-order subscriptions, benefit events, and other methods, the term crowdfunding refers to Internet-mediated registries. This modern crowdfunding model is generally based on three types of actors: the project initiator who proposes the idea or project to be funded, individuals or groups who support the idea, and a moderating organization (the \"platform\") that brings the parties together to launch the idea.\n\nCrowdfunding has been used to fund a wide range of for-profit, entrepreneurial ventures such as artistic and creative projects, medical expenses, travel, or community-oriented social entrepreneurship projects.\n\nCrowdfunding has a long history with several roots. Books have been crowdfunded for centuries: authors and publishers would advertise book projects in praenumeration or subscription schemes. The book would be written and published if enough subscribers signaled their readiness to buy the book once it was out. The subscription business model is not exactly crowdfunding, since the actual flow of money only begins with the arrival of the product. The list of subscribers has, though, the power to create the necessary confidence among investors that is needed to risk the publication.\n\nWar bonds are theoretically a form of crowdfunding military conflicts. London's mercantile community saved the Bank of England in the 1730s when customers demanded their pounds to be converted into gold - they supported the currency until confidence in the pound was restored, thus crowdfunded their own money. A clearer case of modern crowdfunding is Auguste Comte's scheme to issue notes for the public support of his further work as a philosopher. The \"Première Circulaire Annuelle adressée par l'auteur du \"Système de Philosophie Positive\"\" was published on 14 March 1850, and several of these notes, blank and with sums have survived. The cooperative movement of the 19th and 20th centuries is a broader precursor. It generated collective groups, such as community or interest-based groups, pooling subscribed funds to develop new concepts, products, and means of distribution and production, particularly in rural areas of Western Europe and North America. In 1885, when government sources failed to provide funding to build a monumental base for the Statue of Liberty, a newspaper-led campaign attracted small donations from 160,000 donors.\n\nCrowdfunding on the internet first gained popular and mainstream use in the arts and music communities. The first noteworthy instance of online crowdfunding in the music industry was in 1997, when fans underwrote an entire U.S. tour for the British rock band Marillion, raising US$60,000 in donations by means of a fan-based Internet campaign. They subsequently used this method to fund their studio albums. In the film industry, independent writer/director Mark Tapio Kines designed a website in 1997 for his then-unfinished first feature film \"Foreign Correspondents\". By early 1999, he had raised more than US$125,000 on the Internet from at least 25 fans, providing him with the funds to complete his film. In 2002, the \"Free Blender\" campaign was an early software crowdfunding precursor. The campaign aimed for open-sourcing the Blender 3D computer graphics software by collecting $100,000 from the community while offering additional benefits for donating members.\n\nCrowdfunding started to gain mainstream traction with the launch of ArtistShare (2003). As the model matured, more crowdfunding sites started to appear on the web such as Kiva (2005), IndieGoGo (2008), Kickstarter (2009), GoFundMe (2010), Microventures (2010), and YouCaring (2011).\n\nThe phenomenon of crowdfunding is older than the term \"crowdfunding\". According to wordspy.com, the earliest recorded use of the word was in August 2006.\n\nThe Crowdfunding Centre's May 2014 report identified two primary types of crowdfunding:\n\nReward-based crowdfunding has been used for a wide range of purposes, including motion picture promotion, free software development, inventions development, scientific research, and civic projects.\n\nMany characteristics of rewards-based crowdfunding, also called non-equity crowdfunding, have been identified by research studies. In rewards-based crowdfunding, funding does not rely on location. The distance between creators and investors on Sellaband was about 3,000 miles when the platform introduced royalty sharing. The funding for these projects is distributed unevenly, with a few projects accounting for the majority of overall funding. Additionally, funding increases as a project nears its goal, encouraging what is called \"herding behavior\". Research also shows that friends and family account for a large, or even majority, portion of early fundraising. This capital may encourage subsequent funders to invest in the project. While funding does not depend on location, observation shows that funding is largely tied to the locations of traditional financing options. In reward-based crowdfunding, funders are often too hopeful about project returns and must revise expectations when returns are not met.\n\nEquity crowdfunding is the collective effort of individuals to support efforts initiated by other people or organizations through the provision of finance in the form of equity. In the United States, legislation that is mentioned in the 2012 JOBS Act will allow for a wider pool of small investors with fewer restrictions following the implementation of the act. Unlike nonequity crowdfunding, equity crowdfunding contains heightened \"information asymmetries\". The creator must not only produce the product for which they are raising capital, but also create equity through the construction of a company. Equity crowdfunding, unlike donation and rewards-based crowdfunding, involves the offer of securities which include the potential for a return on investment. Syndicates, which involve many investors following the strategy of a single lead investor, can be effective in reducing information asymmetry and in avoiding the outcome of market failure associated with equity crowdfunding.\n\nAnother kind of crowdfunding is to raise funds for a project where a digital or software-based value token is offered as a reward to funders which is known as Initial coin offering (abbreviated to ICO). Value tokens are endogenously created by particular open decentralized networks that are used to incentivize client computers of the network to expend scarce computer resources on maintaining the protocol network. These value tokens may or may not exist at the time of the crowdsale, and may require substantial development effort and eventual software release before the token is live and establishes a market value. Although funds may be raised simply for the value token itself, funds raised on blockchain-based crowdfunding can also represent equity, bonds, or even \"market-maker seats of governance\" for the entity being funded. Examples of such crowdsales are Augur decentralized, distributed prediction market software which raised from more than 3500 participants; Ethereum blockchain; Digix/DigixDAO;\nand \"\"The DAO\".\"\nSome of the largest crowdsales using tokens in 2017 were Tezos which raised , Bancor which raised and Status which raised .\n\nDebt-based crowdfunding (also known as \"peer to peer\", \"P2P\", \"marketplace lending\", or \"crowdlending\") arose with the founding of Zopa in the UK in 2005 and in the US in 2006, with the launches of Lending Club and Prosper.com. Borrowers apply online, generally for free, and their application is reviewed and verified by an automated system, which also determines the borrower's credit risk and interest rate. Investors buy securities in a fund which makes the loans to individual borrowers or bundles of borrowers. Investors make money from interest on the unsecured loans; the system operators make money by taking a percentage of the loan and a loan servicing fee. In 2009, institutional investors entered the P2P lending arena; for example in 2013, Google invested $125 million in Lending Club. In 2014 in the US, P2P lending totalled about $5 billion. In 2014 in the UK, P2P platforms lent businesses £749 million, a growth of 250% from 2012 to 2014, and lent retail customers £547 million, a growth of 108% from 2012 to 2014. In both countries in 2014, about 75% of all the money transferred through crowdfunding went through P2P platforms. Lending Club went public in December 2014 at a valuation around $9 billion.\nDebt crowdfunding in the U.S. further evolved with the 2016 enactment of Title III of the JOBS Act, which allows unaccredited investors to invest directly in private businesses through regulated Funding Portals or Broker-Dealers.\n\nLitigation crowdfunding allows plaintiffs or defendants to reach out to hundreds of their peers simultaneously in a semiprivate and confidential manner to obtain funding, either seeking donations or providing a reward in return for funding. It also allows investors to purchase a stake in a claim they have funded, which may allow them to get back more than their investment if the case succeeds (the reward is based on the compensation received by the litigant at the end of his or her case, known as a contingent fee in the United States, a success fee in the United Kingdom, or a \"pactum de quota litis\" in many civil law systems). LexShares is a platform that allows accredited investors to invest in lawsuits.\n\nRunning alongside reward-based crowdfunding, donation-based is second as the most commonly used form of crowdfunding. Charity donation-based crowdfunding is the collective effort of individuals to help charitable causes. In charity crowdfunding, funds are raised for pro-social or pro-environmental purposes. Donors come together to create an online community around a common cause to help fund services and programs to combat issues. The major aspect of donor-based is that there is no reward for donating, rather it is based on the donor's altruistic reasoning.\n\nThe inputs of the individuals in the crowd trigger the crowdfunding process and influence the ultimate value of the offerings or outcomes of the process. Each individual acts as an agent of the offering, selecting and promoting the projects in which they believe. They sometimes play a donor role oriented towards providing help on social projects. In some cases, they become shareholders and contribute to the development and growth of the offering. Individuals disseminate information about projects they support in their online communities, generating further support (promoters). Motivation for consumer participation stems from the feeling of being at least partly responsible for the success of others' initiatives (desire for patronage), striving to be a part of a communal social initiative (desire for social participation), and seeking a payoff from monetary contributions (desire for investment). Additionally, individuals participate in crowdfunding to see new and innovative products before the public. Early access often allows funders to participate more directly in the development of the product. Crowdfunding is also particularly attractive to funders who are family and friends of a creator. It helps to mediate the terms of their financial agreement and manage each group's expectations for the project.\n\nAn individual who takes part in crowdfunding initiatives tends to reveal several distinct traits: innovative orientation, which stimulates the desire to try new modes of interacting with firms and other consumers; social identification with the content, cause or project selected for funding, which sparks the desire to be a part of the initiative; (monetary) exploitation, which motivates the individual to participate by expecting a payoff. Crowdfunding platforms are motivated to generate income by drawing worthwhile projects and generous funders. These sites also seek widespread public attention for their projects and platform.\n\nCrowdfunding websites helped companies and individuals worldwide raise US$89 million from members of the public in 2010, $1.47 billion in 2011, and $2.66 billion in 2012 — $1.6 billion of the 2012 amount was raised in North America.\nIn 2012, more than one million individual campaigns were established globally and the industry was projected to grow to US$5.1 billion in 2013. and to reach US$1 trillion in 2025. A May 2014 report, released by the United Kingdom-based The Crowdfunding Centre and titled \"The State of the Crowdfunding Nation\", presented data showing that during March 2014, more than US$60,000 were raised on an hourly basis via global crowdfunding initiatives. Also during this period, 442 crowdfunding campaigns were launched globally on a daily basis.\n\nIn 2012, there were over 450 crowdfunding platforms operating. In 2015 it was predicted that there would be over 2,000 crowdfunding sites to choose from in 2016. Project creators need to exercise their own due diligence to understand which platform is the best to use depending on the type of project that they want to launch.\nFundamental differences exist in the services provided by many crowdfunding platforms. For instance, CrowdCube and Seedrs are Internet platforms which enable small companies to issue shares over the Internet and receive small investments from registered users in return. While CrowdCube is meant for users to invest small amounts and acquire shares directly in start-up companies, Seedrs pools the funds to invest in new businesses, as a nominated agent.\n\nCurated crowdfunding platforms serve as \"network orchestrators\" by curating the offerings that are allowed on the platform. They create the necessary organizational systems and conditions for resource integration among other players to take place. Relational mediators act as an intermediary between supply and demand. They replace traditional intermediaries (such as traditional record companies, venture capitalists). These platforms link new artists, designers, project initiators with committed supporters who believe in the persons behind the projects strongly enough to provide monetary support. Growth engines focus on the strong inclusion of investors. They \"disintermediate\" by eliminating the activity of a service provider previously involved in the network. The platforms that use crowdfunding to seek stakes from a community of high net-worth private investors and match them directly with project initiators.\n\nThe Professional Contractors Group, a trade body representing freelancers in the UK, raised £100,000 over a two-week period in 1999 from some 2000 freelancers threatened by a Government measure known as IR35. In 2004, Electric Eel Shock, a Japanese rock band, raised £10,000 from 100 fans (the Samurai 100) by offering them a lifetime membership on the band's guestlist. Two years later, they became the fastest band to raise a US$50,000 budget on SellaBand.\nFranny Armstrong later created a donation system for her feature film \"The Age of Stupid\". Over five years, from June 2004 to June 2009 (release date), she raised £1,500,000. In December 2004, French entrepreneurs and producers and , launched a public Internet donation campaign to fund their short science fiction film, \"Demain la Veille (Waiting for Yesterday)\". Within a month, they managed to raise €17,000 online, allowing them to shoot their film.\n\nAs of 2015 the highest reported funding by a crowdfunded project to date was \"Star Citizen\", an online space trading and combat video game being developed by Chris Roberts and Cloud Imperium Games; it had raised $77M by that time, and while it had a devoted fan base it was also criticized for being a potential scam.\n\nBrave's $35 million Basic Attention Token (BAT) sale sold out in less than 30 seconds.\n\nOn April 17, 2014, the \"Guardian\" media outlet published a list of \"20 of the most significant projects\" launched on the Kickstarter platform prior to the date of publication:\n\n\nCrowdfunding is being explored as a potential funding mechanism for creative work such as blogging and journalism, music, independent film (see crowdfunded film), and for funding startup companies. Community music labels are usually for-profit organizations where \"fans assume the traditional financier role of a record label for artists they believe in by funding the recording process\". Since pioneering crowdfunding in the film industry, Spanner Films has published a \"how to\" guide. A \"Financialist\" article published in mid-September 2013 stated that \"the niche for crowdfunding exists in financing films with budgets in the [US]$1 to $10 million range\" and crowdfunding campaigns are \"much more likely to be successful if they tap into a significant pre-existing fan base and fulfill an existing gap in the market.\" Innovative new platforms, such as RocketHub, have emerged that combine traditional funding for creative work with branded crowdsourcing—helping artists and entrepreneurs unite with brands \"without the need for a middle man.\"\n\nSeveral crowdfunding platforms have emerged that allow people to donate or invest in food- and agriculture-related opportunities. AgFunder is one global platform that gives both individual and institutional investors access to venture capital investments, both in agriculture technology and food technology companies. Cropital has developed a platform to allow investors to invest in small-holder farmers, and rewards-based platforms like Barnraiser allow users to support farmers and food startups.\n\nThe crowdfunding platform PieShell was launched in 2016 to focus exclusively on food and beverage campaigns.\n\nA variety of crowdfunding platforms have emerged to allow ordinary web users to support specific philanthropic projects without the need for large amounts of money. GlobalGiving allows individuals to browse through a selection of small projects proposed by nonprofit organizations worldwide, donating funds to projects of their choice. Microcredit crowdfunding platforms such as Kiva (organization) facilitate crowdfunding of loans managed by microcredit organizations in developing countries. The US-based nonprofit Zidisha applies a direct person-to-person lending model to microcredit lending for low-income small business owners in developing countries.\n\nDonorsChoose.org, founded in 2000, allows public school teachers in the United States to request materials for their classrooms. Individuals can lend money to teacher-proposed projects, and the organization fulfills and delivers supplies to schools. There are also a number of own-branded university crowdfunding websites, which enable students and staff to create projects and receive funding from alumni of the university or the general public. Several dedicated civic crowdfunding platforms have emerged in the US and the UK, some of which have led to the first direct involvement of governments in crowdfunding. In the UK, Spacehive is used by the Mayor of London and Manchester City Council to co-fund civic projects created by citizens. Similarly, dedicated humanitarian crowdfunding initiatives are emerging, involving humanitarian organizations, volunteers and supports in solving and modeling how to build innovative crowdfunding solutions for the humanitarian community. Likewise, international organizations like the Office for the Coordination of Humanitarian Affairs (OCHA) have been researching and publishing about the topic.\n\nOne crowdfunding project, iCancer, was used to support a Phase 1 trial of AdVince, an anti-cancer drug in 2016.\n\nReal estate crowdfunding is the online pooling of capital from investors to fund mortgages secured by real estate, such as \"fix and flip\" redevelopment of distressed or abandoned properties, equity for commercial and residential projects, acquisition of pools of distressed mortgages, home buyer downpayments and similar real estate related outlets. Investment, via specialised online platforms in the US, is generally completed under Title II of the JOBS Act and is limited to accredited investors. The platforms offer low minimum investments, often $100 – $10,000. There are over 75 real estate crowdfunding platforms in the United States. The growth of real estate crowdfunding is a global tendency. During 2014 and 2015, more than 150 platforms have been created throughout the world, such as in China, the Middle East, or France. In Europe, some compare this growing industry to that of e-commerce ten years ago.\n\nIn Europe the requirements towards investors are not as high as in the United States, lowering the entry barrier into the real estate investments in general. Real estate crowdfunding can include various project types from commercial to residential developments, planning gain opportunities, build to hold (such as social housing) and many more. The report from Cambridge Centre for Alternative Finance addresses both real estate crowdfunding and \"peer 2 peer\" lending (property) in the UK.\n\nOne of the challenges of posting new ideas on crowdfunding sites is there may be little or no intellectual property (IP) protection provided by the sites themselves. Once an idea is posted, it can be copied. As Slava Rubin, founder of IndieGoGo, said: \"We get asked that all the time, 'How do you protect me from someone stealing my idea?' We're not liable for any of that stuff.\" Inventor advocates, such as Simon Brown, founder of the UK-based United Innovation Association, counsel that ideas can be protected on crowdfunding sites through early filing of patent applications, use of copyright and trademark protection as well as a new form of idea protection supported by the World Intellectual Property Organization called Creative Barcode.\n\nA number of platforms have also emerged that specialize in the crowdfunding of scientific projects, such as experiment.com, and The Open Source Science Project. In the scientific community, these new options for research funding are seen ambivalently. Advocates of crowdfunding for science emphasize that it allows early-career scientists to apply for their own projects early on, that it forces scientists to communicate clearly and comprehensively to a broader public, that it may alleviate problems of the established funding systems which are seen to fund conventional, mainstream projects, and that it gives the public a say in science funding. In turn, critics are worried about quality control on crowdfunding platforms. If non-scientists were allowed to make funding decisions, it would be more likely that \"panda bear science\" is funded, i.e. research with broad appeal but lacking scientific substance. Initial studies found that crowdfunding is used within science, mostly by young researchers to fund small parts of their projects, and with high success rates. At the same time, funding success seems to be strongly influenced by non-scientific factors like humor, visualizations, or the ease and security of payment.\nIn order to fund online and print publications, journalists are enlisting the help of crowdfunding. Crowdfunding allows for small start-ups and individual journalists to fund their work without the institutional help of major public broadcasters. Stories are publicly pitched using crowdfunding platforms such as Kickstarter, Indiegogo, or Spot.us. The funds collected from crowdsourcing may be put toward travel expenses or purchasing equipment. Crowdfunding in journalism may also be viewed as a way to allow audiences to participate in news production and in creating a participatory culture. Though deciding which stories are published is a role that traditionally belongs to editors at more established publications, crowdfunding can give the public an opportunity to provide input in deciding which stories are reported. This is done by funding certain reporters and their pitches. Donating can be seen as an act that \"bonds\" reporters and their readers. This is because readers are expressing interest for their work, which can be \"personally motivating\" or \"gratifying\" for reporters.\n\nSpot.us, which was closed in February 2015, was a crowdfunding platform that was specifically meant for journalism. The website allowed for readers, individual donors, registered Spot.us reporters, or news organizations to fund or donate talent toward a pitch of their choosing. While funders are not normally involved in editorial control, Spot.us allowed for donors or \"community members\" to become involved with the co-creation of a story. This gave them the ability to edit articles, submit photographs, or share leads and information. According to an analysis by Public Insight Network, Spot.us was not sustainable for various reasons. Many contributors were not returning donors and often, projects were funded by family and friends. The overall market for crowdfunding journalism may also be a factor; donations for journalism projects accounted for .13 percent of the $2.8 billion that was raised in 2013.\n\nLarger crowdfunding platforms such as Indiegogo or Kickstarter, both of which are not journalism-specific, may garner more success for projects. This is because these large-scale platforms can allow journalists to reach new audiences. In 2017, 2.3 million out of Kickstarter's 7.9 million users had donated toward more than one project.\n\nTraditionally, journalists are not involved in advertising and marketing. Crowdfunding means that journalists are attracting funders while trying to remain independent, which may pose a conflict. Therefore, being directly involved with financial aspects can call journalistic integrity and journalistic objectivity into question. This is also due to the fact that journalists may feel some pressure or \"a sense of responsibility\" toward funders who support a particular project. Crowdfunding can also allow for a blurred line between professional and non-professional journalism because if enough interest is generated, anyone may have their work published.\n\nThere is some hope that crowdfunding has potential as a tool open for use by groups of people traditionally more marginalized. The World Bank published a report titled \"Crowdfunding's potential for the Developing World\" which states that \"While crowdfunding is still largely a developed world phenomenon, with the support of governments and development organizations it could become a useful tool in the developing world as well. Substantial reservoirs of entrepreneurial talent, activity, and capital lay dormant in many emerging economies...Crowdfunding and crowdfund investing have several important roles to play in the developing world's entrepreneurial and venture finance ecosystem.\"\n\nAs the popularity of crowdfunding expanded, the SEC, state governments, and Congress responded by enacting and refining many capital-raising exemptions to allow easier access to alternative funding sources. Initially, the Securities Act of 1933 banned companies from soliciting capital from the general public for private offerings. However, \"President Obama signed the Jumpstart Our Small Businesses Act (\"JOBS Act\") into law on April 5, 2012, which removed the ban on general solicitation activities for issuers qualifying under a new exemption called 'Rule 506(c).'\" A company can now broadly solicit and generally advertise an offering and still be compliant with the exemption's requirements if:\nAnother change was the amendment of SEC Rule 147. Section 3(a)(11) of the Securities Act allows for unlimited capital raising from investors in a single state through an intrastate exemption. However, the SEC created Rule 147 with a number of requirements to ensure compliance. For example, intrastate solicitation was allowed, but a single out-of-state offer could destroy the exemption. Additionally, the issuer was required to be incorporated and do business in the same state of the intrastate offering. With the expansion of interstate business activities because of the internet, it became difficult for businesses to comply with the exemption. Therefore, on October 26, 2016 the SEC adopted Rule 147(a) which removed many of the restrictions to modernize the Rules. For example, companies would have to do business and have its principal place of business in the state where the offering is sold, and not necessarily where \"offered\" per the prior rule.\n\nCrowdfunding campaigns provide producers with a number of benefits, beyond the strict financial gains. The following are non financial benefits of crowdfunding.\n\nThere are also financial benefits to the creator. For one, crowdfunding allows creators to attain low-cost capital. Traditionally, a creator would need to look at \"personal savings, home equity loans, personal credit cards, friends and family members, angel investors, and venture capitalists.\" With crowdfunding, creators can find funders from around the world, sell both their product and equity, and benefit from increased information flow. Additionally, crowdfunding that supports pre-buying allows creators to obtain early feedback on the product. Proponents of the crowdfunding approach argue that it allows good ideas which do not fit the pattern required by conventional financiers to break through and attract cash through the wisdom of the crowd. If it does achieve \"traction\" in this way, not only can the enterprise secure seed funding to begin its project, but it may also secure evidence of backing from potential customers and benefit from word of mouth promotion in order to reach the fundraising goal. Another potential positive effect is the propensity of groups to \"produce an accurate aggregate prediction\" about market outcomes as identified by author James Surowiecki in his book \"The Wisdom of Crowds\", thereby placing financial backing behind ventures likely to succeed.\n\nProponents also identify a potential outcome of crowdfunding as an exponential increase in available venture capital. One report claims that If every American family gave one percent of their investable assets to crowdfunding, $300 billion (a 10X increase) would come into venture capital. Proponents also cite that a benefit for companies receiving crowdfunding support is that they retain control of their operations, as voting rights are not conveyed along with ownership when crowdfunding. As part of his response to the Amanda Palmer Kickstarter controversy, Albini expressed his supportive views of crowdfunding for musicians, explaining: \"I've said many times that I think they're part of the new way bands and their audience interact and they can be a fantastic resource, enabling bands to do things essentially in cooperation with their audience.\" Albini described the concept of crowdfunding as \"pretty amazing.\"\n\nCrowdfunding also comes with a number of potential risks or barriers. For the creator, as well as the investor, studies show that crowdfunding contains \"high levels of risk, uncertainty, and information asymmetry.\"\n\nFor crowdfunding of equity stock purchases, there is some research in social psychology that indicates that, like in all investments, people don't always do their due diligence to determine if it's a sound investment before investing, which leads to making investment decisions based on emotion rather than financial logic. By using crowdfunding, creators also forgo potential support and value that a single angel investor or venture capitalist might offer. Likewise, crowdfunding requires that creators manage their investors. This can be time-consuming and financially burdensome as the number of investors in the crowd rises. Crowdfunding draws a crowd: investors and other interested observers who follow the progress, or lack of progress, of a project. Sometimes it proves easier to raise the money for a project than to make the project a success. Managing communications with a large number of possibly disappointed investors and supporters can be a substantial, and potentially diverting, task.\n\nSome of the most popular fundraisings are for commercial companies which use the process to reach customers and at the same time market their products and services. This favors companies like microbreweries and specialist restaurants – in effect creating a \"club\" of people who are customers as well as investors. In the USA in 2015, new rules from the SEC to regulate equity crowdfunding will mean that larger businesses with more than 500 investors and more than $25 million in assets will have to file reports like a public company. The \"Wall Street Journal\" commented: \"It is all the pain of an IPO without the benefits of the IPO.\" These two trends may mean crowdfunding is most suited to small consumer-facing companies rather than tech start-ups.\n\nThere are several ways in which a well-regulated crowdfunding platform can provide attractive returns for investors:\n\nOn crowdfunding platforms, the problem of information asymmetry is exacerbated due to the reduced ability of the investor to conduct due diligence. Early stage investing is typically localized, as the costs of conducting due diligence before making investment decisions and the costs of monitoring after investing both rises with distance. However, this trend is not observed on crowdfunding platforms - these platforms are not geographically constrained and bring in investors from near and far. On non-equity or reward-based platforms, investors try to mitigate this risk by using the amount of capital raised as a signal of performance or quality. On equity-based platforms, crowdfunding syndicates reduce information asymmetry through dual channels – through portfolio diversification and better due diligence as in the case of offline early-stage investing, but also by allowing \"lead investors\" with more information and better networks to lead \"crowds\" of backers to make investment decisions.\n\n\nStudies and Papers\nPress\n"}
{"id": "56221934", "url": "https://en.wikipedia.org/wiki?curid=56221934", "title": "Dataism", "text": "Dataism\n\nDataism is a term that has been used to describe the mindset or philosophy created by the emerging significance of Big Data. It was first used by David Brooks in the New York Times in 2013. More recently, the term has been expanded to describe what social scientist Yuval Noah Harari has called an emerging ideology or even a new form of religion, in which 'information flow' is the 'supreme value'.\n\n\"If you asked me to describe the rising philosophy of the day, I'd say it is Data-ism\", wrote David Brooks in the New York Times in February 2013. Brooks argued that in a world of increasing complexity, relying on data can reduce cognitive biases and \"illuminate patterns of behavior we haven't yet noticed\".\n\nIn 2015, Steve Lohr's book 'Data-ism' looked at how Big Data is transforming society, using the term to describe the Big Data revolution.\n\nIn his 2016 book, , Yuval Noah Harari takes the idea of Dataism further, putting it into a historical context. He argues that all competing political or social structures can be seen as data processing systems: \"Dataism declares that the universe consists of data flows, and the value of any phenomenon or entity is determined by its contribution to data processing\".\n\nHarari posits that \"we may interpret the entire human species as a single data processing system, with individual humans serving as its chips.\" He then argues that the whole of human history can be read as a process of improving the efficiency of this system by increasing the number and variety of processors/chips (humans) in the system, increasing the number of connections between the processors and increasing the freedom of movement along existing connections. A condensed form of this argument can be read in Harari's Wired article from 2016.\n\nHarari goes on to argue that Dataism, like any other religion, has practical commandments. A Dataist should want to \"maximise dataflow by connecting to more and more media\", and believes that freedom of information is \"the greatest good of all\". Harari also argues that Aaron Swartz, who took his life in 2013 after being prosecuted for releasing hundreds of thousands of scientific papers from the JSTOR archive online for free, could be called the \"first martyr\" of Dataism.\n\nWriting in the Financial Times, Harari argued that Dataism presents an existential challenge to the dominant moral ideology of Humanism, which sees human feelings as the ultimate authority in the world: \"humanism is now facing an existential challenge and the idea of “free will” is under threat... Once Big Data systems know me better than I know myself, authority will shift from humans to algorithms.\" Harari predicts that the logical conclusion of this process is that eventually humans will give algorithms the authority to make the most important decisions in their lives, such as who to marry and which career to pursue.\n\nCommenting on Harari's characterisation of Dataism, security analyst Daniel Miessler believes that Dataism does not present the challenge to the ideology of liberal humanism that Harari claims, because humans will simultaneously be able to believe in their own importance and that of data.\n\nHarari himself raises some criticisms, such as the problem of consciousness, which Dataism is unlikely to illuminate. Humans may also find out that organisms are not algorithms, he suggests.\n\nOther analysts such as Terry Ortleib have looked at the extent to which Dataism poses a dystopian threat to humanity.\n\n\n\n"}
{"id": "50403904", "url": "https://en.wikipedia.org/wiki?curid=50403904", "title": "Decapping", "text": "Decapping\n\nDecapping (decapsulation) or delidding of an integrated circuit is the process of removing the protective cover of a microchip so that the contained die is revealed for visual inspection of the micro circuitry imprinted on the die. This process is typically done in order to debug a manufacturing problem with the chip, or possibly to copy information from the device. Modern integrated circuits can be encapsulated in plastic, ceramic, or epoxy.\n\nDecapping is usually carried out by chemical etching of the covering, laser cutting, or mechanical removal of the cover using a milling machine. The process can be either destructive or non-destructive.\n\n"}
{"id": "58794547", "url": "https://en.wikipedia.org/wiki?curid=58794547", "title": "Direct Autonomous Authentication", "text": "Direct Autonomous Authentication\n\nDirect Autonomous Authentication (DAA) is a cybersecurity platform developed by San Francisco-based technology company Averon.\n\nThe DAA platform enables secure authentication of a mobile user whilst simultaneously preserving privacy of the user.\n\nThe technology was developed in stealth from late 2015, first publicly introduced by Averon in 2018, and featured at the 2018 Consumer Electronics Show as a new technology that combats the increasing threats of cybercrime and consumer account hacking.\nIn contrast to legacy methods of cybersecurity, the DAA platform bypasses end user actions, and rather than focusing on the authentication of a user's device, DAA instead provides autonomous authentication of a user's mobile phone number, since the mobile phone number continues to be associated with the user even when they lose, destroy or upgrade their mobile phone. \n\nThe DAA method uses a proprietary mix of technology developed by Averon that works inside the secure mobile network data pipelines together with encrypted technology already within every smartphone. The combination of these autonomous authentication methods has been described by research analysts as a faster, more secure, and stronger method of cybersecurity than traditional methods.\n\nBlockchain technology incorporated into the DAA platform ensures the privacy of end users. No identifiable personal data is maintained on the platform, therefore public disclosure of one's authentic identity (such as for the purpose of verified social media interactions) is voluntary. DAA technology affords the end user full control over identity disclosure in any given online interaction, which can be controlled by the end user in varying degrees from fully anonymous to fully identified publicly. In cases involving the need for anonymity with regard to an end user's safety, such as in cases of whistleblowers or political activists, the DAA platform's blockchain technology provides a method for both complete anonymity with the option of voluntary verification of limited but often needed data (such as verifying an anonymous user's general location). Thus DAA technology alleviates the heretofore insurmountable challenge of protecting user privacy with the need for authentication.\n\nThe DAA technology platform was designed to be seamlessly adopted for utilization in a wide variety of industries and use cases in which mobile authentication of users is required.\n\nSince its introduction to the market in 2018, the DAA platform has been recognized by a number of industry groups for its innovation, including winning the Gold prize at the 2018 Edison Awards, a Cybersecurity Excellence Award, and a BIG Innovation 2018 Award.\n"}
{"id": "3979717", "url": "https://en.wikipedia.org/wiki?curid=3979717", "title": "Ducks demo", "text": "Ducks demo\n\nThe Ducks demo was a tech demo that demonstrated the capabilities of the PlayStation 2 at E3 2000 and the PlayStation 3 at E3 2005. In the PlayStation 2 demo, only one duck is shown interacting with the water in the bathtub. In the PlayStation 3 demo, there are many ducks interacting with each other and their environment, as a visual representation of the leap in processing abilities from the PlayStation 2 Sony executives promise the PlayStation 3 will deliver. The Ducks demo was the basis for \"Super Rub 'a' Dub\" which is a downloadable title for the PS3 produced by SCEE.\n\nIn the demo, Phil Harrison shows the crowd a small bathtub with some rubber ducks in it. He uses these to demonstrate the real-time water ripples and dynamics. He then uses two toy pirate ships to demonstrate cloth dynamics. To show the Cell's processing power, he adds a huge amount of ducks to the tub (all reacting as they would in real-life, due to the advanced physics engine). Phil comments dryly that \"this is only possible with the use of LOD technology, for those of you that don't know, LOD stands for \"Lots of Ducks\"\n\nPhil Harrison then invites the creator of EyeToy to show the new technology the PlayStation 3 can use. Plugging a standard PlayStation 2 EyeToy into the PlayStation 3, he picks up two ordinary cups and proceeds to move the cups in a scooping motion, which scoops up the water pictured on screen. (animated and reacting as real water would).\n\nThe ducks demo was the basis for \"Super Rub 'a' Dub\" which is a downloadable title for the PS3 produced by SCEE.\n\n"}
{"id": "8586", "url": "https://en.wikipedia.org/wiki?curid=8586", "title": "Dyson sphere", "text": "Dyson sphere\n\nA Dyson sphere is a hypothetical megastructure that completely encompasses a star and captures a large percentage of its power output. The concept is a thought experiment that attempts to explain how a spacefaring civilization would meet its energy requirements once those requirements exceed what can be generated from the home planet's resources alone. Only a fraction of a star's energy emissions reach the surface of any orbiting planet. Building structures encircling a star would enable a civilization to harvest far more energy.\n\nThe first contemporary description of the structure was by Olaf Stapledon in his science fiction novel \"Star Maker\" (1937), in which he described \"every solar system... surrounded by a gauze of light traps, which focused the escaping solar energy for intelligent use.\" The concept was later popularized by Freeman Dyson in his 1960 paper \"Search for Artificial Stellar Sources of Infrared Radiation\". Dyson speculated that such structures would be the logical consequence of the escalating energy needs of a technological civilization and would be a necessity for its long-term survival. He proposed that searching for such structures could lead to the detection of advanced, intelligent extraterrestrial life. Different types of Dyson spheres and their energy-harvesting ability would correspond to levels of technological advancement on the Kardashev scale.\n\nSince then, other variant designs involving building an artificial structure or series of structures to encompass a star have been proposed in exploratory engineering or described in science fiction under the name \"Dyson sphere\". These later proposals have not been limited to solar-power stations, with many involving habitation or industrial elements. Most fictional depictions describe a solid shell of matter enclosing a star, which is considered the least plausible variant of the idea. In May 2013, at the Starship Century Symposium in San Diego, Dyson repeated his comments that he wished the concept had not been named after him.\n\nThe concept of the Dyson sphere was the result of a thought experiment by physicist and mathematician Freeman Dyson, when he theorized that all technological civilizations constantly increased their demand for energy. He reasoned that if human civilization expanded energy demands long enough, there would come a time when it demanded the \"total\" energy output of the Sun. He proposed a system of orbiting structures (which he referred to initially as a \"shell\") designed to intercept and collect all energy produced by the Sun. Dyson's proposal did not detail how such a system would be constructed, but focused only on issues of energy collection, on the basis that such a structure could be distinguished by its unusual emission spectrum in comparison to a star. His 1960 paper \"Search for Artificial Stellar Sources of Infra-Red Radiation\", published in the journal \"Science\", is credited with being the first to formalize the concept of the Dyson sphere.\n\nHowever, Dyson was not the first to advance this idea. He was inspired by the mention of the concept in the 1937 science fiction novel \"Star Maker\", by Olaf Stapledon, and possibly by the works of J. D. Bernal, Raymond Z. Gallun, and Edgar Rice Burroughs, who seem to have explored similar concepts in their work.\n\nAlthough such megastructures may be theoretically possible, all plans to build a fixed-in-place Dyson sphere are currently far beyond humanity's engineering capacity. The number of craft required to obtain, transmit, and maintain a complete Dyson sphere far exceeds present-day industrial capabilities. George Dvorsky has advocated use of self-replicating robots to overcome this limitation in the relatively near term. Some have suggested that such habitats could be built around white dwarfs and even pulsars.\n\nIn fictional accounts, the Dyson-sphere concept is often interpreted as an artificial hollow sphere of matter around a star. This perception is based on a literal interpretation of Dyson's original short paper introducing the concept. In response to letters prompted by some papers, Dyson replied, \"A solid shell or ring surrounding a star is mechanically impossible. The form of 'biosphere' which I envisaged consists of a loose collection or swarm of objects traveling on independent orbits around the star.\"\n\nThe variant closest to Dyson's original conception is the \"Dyson swarm\". It consists of a large number of independent constructs (usually solar power satellites and space habitats) orbiting in a dense formation around the star. This construction approach has advantages: components could be sized appropriately, and it can be constructed incrementally. Various forms of wireless energy transfer could be used to transfer energy between swarm components and a planet.\n\nDisadvantages resulting from the nature of orbital mechanics would make the arrangement of the orbits of the swarm extremely complex. The simplest such arrangement is the \"Dyson ring\", in which all such structures share the same orbit. More-complex patterns with more rings would intercept more of the star's output, but would result in some constructs eclipsing others periodically when their orbits overlap. Another potential problem is that the increasing loss of orbital stability when adding more elements increases the probability of orbital perturbations.\n\nAs noted below, such a cloud of collectors would alter the light emitted by the star system. However, the disruption compared to a star's overall natural emitted spectrum would most likely be too small for Earth-based astronomers to observe.\n\nA second type of Dyson sphere is the \"Dyson bubble\". It would be similar to a Dyson swarm, composed of many independent constructs and likewise could be constructed incrementally.\n\nUnlike the Dyson swarm, the constructs making it up are not in orbit around the star, but would be statites—satellites suspended by use of enormous light sails using radiation pressure to counteract the star's pull of gravity. Such constructs would not be in danger of collision or of eclipsing one another; they would be totally stationary with regard to the star, and independent of one another. Because the ratio of radiation pressure to the force of gravity from a star is constant regardless of the distance (provided the statite has an unobstructed line-of-sight to the surface of its star), such statites could also vary their distance from their central star.\n\nThe practicality of this approach is questionable with modern material science, but cannot yet be ruled out. A 100% reflective statite deployed around the Sun would have an overall density of 0.78 grams per square meter of sail. To illustrate the low mass of the required materials, consider that the total mass of a bubble of such material 1 AU in radius would be about 2.17 kg, which is about the same mass as the asteroid Pallas. Another illustration: Regular printing paper has a density of around 80 g/m.\n\nSuch a material has not yet been produced in the form of a working light sail. The lightest carbon-fiber light-sail material currently produced has a density—without payload—of 3 g/m, or about four times as heavy as would be needed to construct a solar statite.\n\nA single sheet of graphene, the two-dimensional form of carbon, has a density of only 0.37 mg per square meter, making such a single sheet of graphene possibly effective as a solar sail. However, as of 2015 graphene has not been fabricated in large sheets, and it has a relatively high rate of radiation absorption, about 2.3% (i.e., still about 97.7% will be transmitted). For frequencies in the upper GHz and lower THz range, the absorption rate is as high as 50–100% due to voltage bias and/or doping.\n\nUltra-light carbon nanotubes meshed through molecular manufacturing techniques have densities between 1.3 g/m to 1.4 g/m. By the time a civilization is ready to use this technology, the carbon nanotube's manufacturing might be optimised enough for them to have a density lower than the necessary 0.7 g/m, and the average sail density with rigging might be kept to 0.3 g/m (a \"spin stabilized\" light sail requires minimal additional mass in rigging). If such a sail could be constructed at this areal density, a space habitat the size of the L5 Society's proposed O'Neill cylinder—500 km, with room for over 1 million inhabitants, massing 3 tons—could be supported by a circular light sail 3,000 km in diameter, with a combined sail/habitat mass of 5.4 kg. For comparison, this is just slightly smaller than the diameter of Jupiter's moon Europa (although the sail is a flat disc, not a sphere), or the distance between San Francisco and Kansas City. Such a structure would, however, have a mass quite a lot less than many asteroids. Although the construction of such a massive habitable statite would be a gigantic undertaking, and the required material science behind it is early stage, there are other engineering feats and required materials proposed in other Dyson sphere variants.\n\nIn theory, if enough satellites were created and deployed around their star, they would compose a non-rigid version of the Dyson shell mentioned below. Such a shell would not suffer from the drawbacks of massive compressive pressure, nor are the mass requirements of such a shell as high as the rigid form. Such a shell would, however, have the same optical and thermal properties as the rigid form, and would be detected by searchers in a similar fashion (see below).\n\nThe variant of the Dyson sphere most often depicted in fiction is the \"Dyson shell\": a uniform solid shell of matter around the star. Such a structure would completely alter the emissions of the central star, and would intercept 100% of the star's energy output. Such a structure would also provide an immense surface that many envision would be used for habitation, if the surface could be made habitable.\n\nA spherical shell Dyson sphere in the Solar System with a radius of one astronomical unit, so that the interior surface would receive the same amount of sunlight as Earth does per unit solid angle, would have a surface area of approximately , or about 550 million times the surface area of Earth. This would intercept the full 384.6 yottawatts (3.846 × 10 watts) of the Sun's output. Non-shell designs would intercept less, but the shell variant represents the maximum possible energy captured for the Solar System at this point of the Sun's evolution. This is approximately 33 trillion times the power consumption of humanity in 1998, which was 12 terawatts.\n\nThere are several serious theoretical difficulties with the solid shell variant of the Dyson sphere:\n\nSuch a shell would have no net gravitational interaction with its englobed star (see shell theorem), and could drift in relation to the central star. If such movements went uncorrected, they could eventually result in a collision between the sphere and the star—most likely with disastrous results. Such structures would need either some form of propulsion to counteract any drift, or some way to repel the surface of the sphere away from the star.\n\nFor the same reason, such a shell would have no net gravitational interaction with anything else inside it. The contents of any biosphere placed on the inner surface of a Dyson shell would not be attracted to the sphere's surface and would simply fall into the star. It has been proposed that a biosphere could be contained between two concentric spheres, placed on the interior of a rotating sphere (in which case, the force of artificial \"gravity\" is perpendicular to the axis of rotation, causing all matter placed on the interior of the sphere to pool around the equator, effectively rendering the sphere a Niven ring for purposes of habitation, but still fully effective as a radiant-energy collector) or placed on the outside of the sphere where it would be held in place by the star's gravity. In such cases, some form of illumination would have to be devised, or the sphere made at least partly transparent, because the star's light would otherwise be completely hidden.\n\nIf assuming a radius of one AU, then the compressive strength of the material forming the sphere would have to be immense to prevent implosion due to the star's gravity. Any arbitrarily selected point on the surface of the sphere can be viewed as being under the pressure of the base of a dome 1 AU in height under the Sun's gravity at that distance. Indeed, it can be viewed as being at the base of an infinite number of arbitrarily selected domes, but because much of the force from any one arbitrary dome is counteracted by those of another, the net force on that point is immense, but finite. No known or theorized material is strong enough to withstand this pressure, and form a rigid, static sphere around a star. It has been proposed by Paul Birch (in relation to smaller \"Supra-Jupiter\" constructions around a large planet rather than a star) that it may be possible to support a Dyson shell by dynamic means similar to those used in a space fountain. Masses travelling in circular tracks on the inside of the sphere, at velocities significantly greater than orbital velocity, would press outwards on magnetic bearings due to centrifugal force. For a Dyson shell of 1-AU radius around a star with the same mass as the Sun, a mass travelling ten times the orbital velocity (297.9 km/s) would support 99 (a=v/r) times its own mass in additional shell structure.\n\nAlso if assuming a radius of one AU, then there may not be sufficient building material in the Solar System to construct a Dyson shell. Anders Sandberg estimates that there is 1.82 kg of easily usable building material in the Solar System, enough for a 1-AU shell with a mass of 600 kg/m—about 8–20 cm thick on average, depending on the density of the material. This includes the hard-to-access cores of the gas giants; the inner planets alone provide only 11.79 kg, enough for a 1-AU shell with a mass of just 42 kg/m.\n\nThe shell would be vulnerable to impacts from interstellar bodies, such as comets, meteoroids, and material in interstellar space that is currently being deflected by the Sun's bow shock. The heliosphere, and any protection it theoretically provides, would cease to exist.\n\nAnother possibility is the \"Dyson net\", a web of cables strung about the star that could have power or heat collection units strung between the cables. The Dyson net reduces to a special case of Dyson shell or bubble, however, depending on how the cables are supported against the sun's gravity.\n\nA bubbleworld is an artificial construct that consists of a shell of living space around a sphere of hydrogen gas. The shell contains air, people, houses, furniture, etc. The idea was conceived to answer the question, \"What is the largest space colony that can be built?\" However, most of the volume is not habitable and there is no power source.\n\nTheoretically, any gas giant could be enclosed in a solid shell; at a certain radius the surface gravity would be terrestrial, and energy could be provided by tapping the thermal energy of the planet. This concept is explored peripherally in the novel \"Accelerando\" (and the short story \"Curator\", which is incorporated into the novel as a chapter) by Charles Stross, in which Saturn is converted into a human-habitable world.\n\nStellar engines are a class of hypothetical megastructures whose purpose is to extract useful energy from a star, sometimes for specific purposes. For example, Matrioshka brains extract energy for purposes of computation; Shkadov thrusters extract energy for purposes of propulsion. Some of the proposed stellar engine designs are based on the Dyson sphere.\n\nA black hole could be the power source instead of a star in order to increase the matter-to-energy conversion efficiency. A black hole would also be smaller than a star. This would decrease communication distances that would be important for computer-based societies as those described above.\n\nIn Dyson's original paper, he speculated that sufficiently advanced extraterrestrial civilizations would likely follow a similar power-consumption pattern to that of humans, and would eventually build their own sphere of collectors. Constructing such a system would make such a civilization a Type II Kardashev civilization.\n\nThe existence of such a system of collectors would alter the light emitted from the star system. Collectors would absorb and reradiate energy from the star. The wavelength(s) of radiation emitted by the collectors would be determined by the emission spectra of the substances making them up, and the temperature of the collectors. Because it seems most likely that these collectors would be made up of heavy elements not normally found in the emission spectra of their central star—or at least not radiating light at such relatively \"low\" energies compared to what they would be emitting as energetic free nuclei in the stellar atmosphere—there would be atypical wavelengths of light for the star's spectral type in the light spectrum emitted by the star system. If the percentage of the star's output thus filtered or transformed by this absorption and reradiation was significant, it could be detected at interstellar distances.\n\nGiven the amount of energy available per square meter at a distance of 1 AU from the Sun, it is possible to calculate that most known substances would be reradiating energy in the infrared part of the electromagnetic spectrum. Thus, a Dyson sphere, constructed by life forms not dissimilar to humans, who dwelled in proximity to a Sun-like star, made with materials similar to those available to humans, would most likely cause an increase in the amount of infrared radiation in the star system's emitted spectrum. Hence, Dyson selected the title \"Search for Artificial Stellar Sources of Infrared Radiation\" for his published paper.\n\nSETI has adopted these assumptions in their search, looking for such \"infrared heavy\" spectra from solar analogs. Fermilab has an ongoing survey for such spectra by analyzing data from the Infrared Astronomical Satellite (IRAS). Identifying one of the many infrared sources as a Dyson sphere would require improved techniques for discriminating between a Dyson sphere and natural sources. Fermilab discovered 17 potential \"ambiguous\" candidates, of which four have been named \"amusing but still questionable\". Other searches also resulted in several candidates, which are, however, unconfirmed.\n\nOn 14 October 2015, the realization of a strange pattern of light from star KIC 8462852, nicknamed \"Tabby's Star\" after Tabetha S. Boyajian — the lead researcher who discovered the irregular light fluctuation— captured by the Kepler Space Telescope, raised speculation that a Dyson sphere may have been discovered.\nIn February 2016, Boyajian gave a TED talk where she explained the story of how her research on the star quickly took a turn into the mysterious. However, she was skeptical and in the talk she reminded everyone that skepticism is the best policy whenever delving into alien territory. Her exact quote is as follows:\n\nWanting to understand the strange light pattern, Tabetha S. Boyajian put several hypotheses to the test. The first general assumption was an exoplanet transiting (eclipsing) its massive star, but the dips in light lasted between 5 and 80 days and were erratically spaced apart, thus ruling out any kind of an orbit for one celestial object.\nA dust cloud was proposed but the star showed no signs of being young so a dust cloud was highly improbable. Lastly, a comet shower was hypothesized. However, as Boyajian pointed out in her TED talk this was also highly improbable. \n\"It would take hundreds of comets to reproduce what we're observing. And these are only the comets that happen to pass between us and the star. And so in reality, we're talking thousands to tens of thousands of comets.\"\n\nSo after all the natural explanations turned up weak, her team decided to send off their research to SETI (Search for extraterrestrial life) to rule out alien structures. After reviewing the research, the SETI Institute was so intrigued that they decided to study the star themselves and pointed their Allen Telescope Array (ATA) at the star \"with hopes of catching a tell-tale signal that might reveal a technological civilization.\"\n\nThe SETI Institute mentioned that what caught their interest was that \"the timing of the present dip (in light) suggests that whatever this material is, it is situated at just the right distance from the star to be in the habitable zone, where we believe life like ours could develop as it has on Earth.\"\n\nBeing skeptical as Boyajian was, she finally decided to take SETI's approach and allow herself to have a bit of fun in hypothesizing what the light pattern could have been. In her Ted Talk she joked: \"Another idea that's one of my personal favorites is that we had just witnessed an interplanetary space battle and the catastrophic destruction of a planet. Now, I admit that this would produce a lot of dust that we don't observe. But if we're already invoking aliens in this explanation, then who is to say they didn't efficiently clean up all this mess for recycling purposes?\"\nThe search for answers to KIC 8462852 is still ongoing.\n\nOn August 25, 2016, a similar phenomenon was reported for another stellar object: EPIC 204278916, a young M-type pre-main-sequence star with a resolved disk. Dimmings of up to 65% for 25 consecutive days (out of 79 total observation) were observed. The variability is highly periodic and attributed to stellar rotation. The researchers hypothesize that the irregular dimmings are caused by either a warped inner-disk edge or transiting cometary-like objects in either circular or eccentric orbits.\n\nAs noted above, the Dyson sphere originated in fiction, and it is a concept that has appeared often in science fiction since then. In fictional accounts, Dyson spheres are most often depicted as a \"Dyson shell\" with the gravitational and engineering difficulties of this variant noted above largely ignored.\n\n"}
{"id": "7071096", "url": "https://en.wikipedia.org/wiki?curid=7071096", "title": "Engineering design process", "text": "Engineering design process\n\nThe engineering design process is a methodical series of steps that engineers use in creating functional products and processes. The process is highly iterative - parts of the process often need to be repeated many times before another can be entered - though the part(s) that get iterated and the number of such cycles in any given project may vary.\n\nThe steps tend to get articulated, subdivided, and/or illustrated in different ways, but they generally reflect certain core principles regarding the underlying concepts and their respective sequence and interrelationship.\n\nOne framing of the engineering design process delineates the following stages: \"research, conceptualization, feasibility assessment, establishing design requirements, preliminary design, detailed design, production planning and tool design, and production\". Others, noting that \"different authors (in both research literature and in textbooks) define different phases of the design process with varying activities occurring within them,\" have suggested more simplified/generalized models - such as \"problem definition, conceptual design, preliminary design, detailed design, and design communication\". A standard summary of the process in European engineering design literature is that of \"clarification of the task, conceptual design, embodiment design, detail design\". In these examples, other key aspects - such as concept evaluation and prototyping - are subsets and/or extensions of one or more of the listed steps. It's also important to understand that in these as well as other articulations of the process, different terminology employed may have varying degrees of overlap, which affects what steps get stated explicitly or deemed \"high level\" versus subordinate in any given model.\n\nVarious stages of the design process (and even earlier) can involve a significant amount of time spent on locating information and research. Consideration should be given to the existing applicable literature, problems and successes associated with existing solutions, costs, and marketplace needs.\n\nThe source of information should be relevant, including existing solutions. Reverse engineering can be an effective technique if other solutions are available on the market. Other sources of information include the Internet, local libraries, available government documents, personal organizations, trade journals, vendor catalogs and individual experts available.\n\nEstablishing design requirements and conducting requirement analysis, sometimes termed problem definition (or deemed a related activity), is one of the most important elements in the design process, and this task is often performed at the same time as a feasibility analysis. The design requirements control the design of the product or process being developed, throughout the engineering design process. These include basic things like the functions, attributes, and specifications - determined after assessing user needs. Some design requirements include hardware and software parameters, maintainability, availability, and testability.\n\nIn some cases, a feasibility study is carried out after which schedules, resource plans and estimates for the next phase are developed. The feasibility study is an evaluation and analysis of the potential of a proposed project to support the process of decision making. It outlines and analyses alternatives or methods of achieving the desired outcome. The feasibility study helps to narrow the scope of the project to identify the best scenario.\nA feasibility report is generated following which Post Feasibility Review is performed.\n\nThe purpose of a feasibility assessment is to determine whether the engineer's project can proceed into the design phase. This is based on two criteria: the project needs to be based on an achievable idea, and it needs to be within cost constraints. It is important to have engineers with experience and good judgment to be involved in this portion of the feasibility study.\n\nA concept study (conceptualization, conceptual design) is often a phase of project planning that includes producing ideas and taking into account the pros and cons of implementing those ideas. This stage of a project is done to minimize the likelihood of error, manage costs, assess risks, and evaluate the potential success of the intended project. In any event, once an engineering issue or problem is defined, potential solutions must be identified. These solutions can be found by using ideation, the mental process by which ideas are generated. In fact, this step is often termed Ideation or \"Concept Generation.\" The following are widely used techniques:\n\n\nVarious generated ideas must then undergo a concept evaluation step, which utilizes various tools to compare and contrast the relative strengths and weakness of possible alternatives.\n\nThe preliminary design, or high-level design includes (also called FEED), often bridges a gap between design conception and detailed design, particularly in cases where the level of conceptualization achieved during ideation is not sufficient for full evaluation. So in this task, the overall system configuration is defined, and schematics, diagrams, and layouts of the project may provide early project configuration. (This notably varies a lot by field, industry, and product.) During detailed design and optimization, the parameters of the part being created will change, but the preliminary design focuses on creating the general framework to build the project on.\n\nS. Blanchard and J. Fabrycky describe it as:\n“The ‘whats’ initiating conceptual design produce ‘hows’ from the conceptual design evaluation effort applied to feasible conceptual design concepts. Next, the ‘hows’ are taken into preliminary design through the means of allocated requirements. There they become ‘whats’ and drive preliminary design to address ‘hows’ at this lower level.”\n\nFollowing FEED is the Detailed Design (Detailed Engineering) phase, which may consist of procurement of materials as well.\nThis phase further elaborates each aspect of the project/product by complete description through solid modeling, drawings as well as specifications.\n\nDesign for manufacturability (DFM) is the general engineering art of designing products in such a way that they are easy to manufacture.\n\n\nComputer-aided design (CAD) programs have made detailed design phase more efficient. For example, a CAD program can provide optimization to reduce volume without hindering a part's quality. It can also calculate stress and displacement using the finite element method to determine stresses throughout the part. \n\nThe production planning and tool design consists of planning how to mass-produce the product and which tools should be used in the manufacturing process. Tasks to complete in this step include selecting materials, selection of the production processes, determination of the sequence of operations, and selection of tools such as jigs, fixtures, metal cutting and metal or plastics forming tools. This task also involves additional prototype testing iterations to ensure the mass-produced version meets qualification testing standards.\n\nEngineering is formulating a problem that can be solved through design. Science is formulating a question that can be solved through investigation. \nThe engineering design process bears some similarity to the scientific method. Both processes begin with existing knowledge, and gradually become more specific in the search for \"knowledge\" (in the case of \"pure\" or basic science) or a \"solution\" (in the case of \"applied\" science, such as engineering). The key difference between the engineering process and the scientific process is that the engineering process focuses on design, creativity and innovation while the scientific process emphasizes Discovery (observation).\n\n\n"}
{"id": "49996145", "url": "https://en.wikipedia.org/wiki?curid=49996145", "title": "Euphonia (device)", "text": "Euphonia (device)\n\nThe euphonia was a talking machine created in the early to mid-nineteenth century by the Austrian inventor Joseph Faber and exhibited in 1845 in Philadelphia and in 1846 in London. An earlier version of the invention had been destroyed in 1844 by Faber.\n\nA mechanical device that he had reportedly spent over twenty-five years developing, Faber's \"Fabulous Talking Machine\", which would later be renamed the \"euphonia\", was constructed of several different mechanisms and instruments: a piano, a bellows, and a mechanical replica of the human throat and vocal organs. By pressing the keys on the keyboard, a human operator produced sounds that inflated the bellows, caused the mechanical mouth to open, the mechanical tongue to be lifted, and the mechanical jaws to move. Able to produce sentences in English, French, and German, the euphonia was reported by \"The London Journal\" to speak all three with a German accent, a fact attributed to the native language (German) of the inventor. Exhibited with a female mask covering the mechanical mouth, tongue, and jaw and at times with a dress hanging below the mask, the euphonia would perform for audiences, pretending to respond to or mimic the words of the keyboard operator. In describing the euphonia, the 19th century American scientist Joseph Henry explained \"that sixteen levers or keys 'like those of a piano' projected sixteen elementary sounds by which 'every word in all European languages can be distinctly produced.' A seventeenth key opened and closed the equivalent of the glottis, an aperture between the vocal cords. 'The plan of the machine is the same as that of the human organs of speech, the several parts being worked by strings and levers instead of tendons and muscles.'\n\n\n"}
{"id": "53431368", "url": "https://en.wikipedia.org/wiki?curid=53431368", "title": "Funzing", "text": "Funzing\n\nFunzing is an online sharing economy marketplace that facilitates people to host and attend events and experiences in their leisure time based on their hobbies, passions or skills. Funzing was founded in Israel in 2014 by \"Avigur Zmora\", the former CEO of Playtech. Funzing is currently active in London, Manchester, Tel Aviv and Singapore.\nThe online community marketplace promotes diversity in people’s free time activities, experiences vary from supper clubs, tours, workshops to one-off lectures and classes.\n\nAccording to co-founder \"Yaron Saghiv\", the idea about the online sharing economy came out of several friends’ frustration at being bored by going to the same places every time they wanted to spend quality free time in a social setting. Thus, they devised the platform which allows anyone with creative potential to showcase their skills to the world while entertaining others and earning some money along the way.\nFunzing was founded in Israel in 2014. It was the brainchild of Avigur Zmora, former CEO of Playtech, who went on to set up the company together with Eran Alon, Noa Moscati and Yaron Saghiv.\nThe initial investment capital to start Funzing was raised from venture capital firm \"Inimiti\" and amounted to $1.5 million.\nCurrently, there are over 2,000 registered hosts on the Funzing system, and more than 35,000 individuals have attended events as of June 2016.\n"}
{"id": "3694654", "url": "https://en.wikipedia.org/wiki?curid=3694654", "title": "Gestell", "text": "Gestell\n\nGestell (or sometimes Ge-stell) is a German word used by twentieth-century German philosopher Martin Heidegger to describe what lies behind or beneath modern technology. Heidegger introduced the term in 1954 in \"The Question Concerning Technology\", a text based on the lecture \"The Framework\" (\"Das Gestell\") first presented on December 1, 1949, in Bremen. It was derived from the root word \"stellen\", which means \"to put\" or \"to place\" and combined with the German prefix \"Ge-\", which denotes a form of \"gathering\" or \"collection\". The term gathers together all kinds of entities and orders them in a certain way. \n\nHeidegger applied the concept of \"Gestell\" to his exposition of the essence of technology. He concluded that technology is fundamentally Enframing (\"Gestell\").\nAs such, the essence of technology is \"Gestell\". Indeed, \"\"Gestell\", literally 'framing', is an all-encompassing view of technology, not as a means to an end, but rather a mode of human existence\". Such enframing pertains to the manner reality appears or unveils itself in the period of modern technology and people born into this \"mode of ordering\" are always embedded into the Gestell (enframing). \n\nIn defining the essence of technology as \"Gestell\", Heidegger indicated that all that has come to presence in the world has been enframed. Thus what is revealed in the world, what has shown itself as itself (the truth of itself) required first an Enframing, literally a way to exist in the world, to be able to be seen and understood. Concerning the essence of technology and how we see things in our technological age, the world has been framed as the \"standing-reserve.\" Heidegger writes,\n\nEnframing means the gathering together of that setting-upon which sets upon man, i.e., challenges him forth, to reveal the real, in the mode of ordering, as standing-reserve. Enframing means that way of revealing which holds sway in the essence of modern technology and which is itself nothing technological.\n\nFurthermore, Heidegger uses the word in a way that is uncommon by giving \"Gestell\" an active role. In ordinary usage the word would signify simply a display apparatus of some sort, like a book rack, or picture frame; but for Heidegger, \"Gestell\" is literally a challenging forth, or \"perform\"ative \"gathering together\", for the purpose of revealing or presentation. If applied to science and modern technology, \"standing reserve\" is active in the case of a river once it generates electricity or the earth if revealed as a coal-mining district or the soil as a mineral deposit. \n\nFor some scholars, Gestell effectively explains the violence of technology. This is attributed to Heidegger's explanation that, when Gestell holds sway, \"it drives out every other possibility of revealing\" and that it \"conceals that revealing which, in the sense of \"poiesis\", lets what presences come forth into appearance.\"\n\n"}
{"id": "573752", "url": "https://en.wikipedia.org/wiki?curid=573752", "title": "Green paper", "text": "Green paper\n\nIn the European Union, the Commonwealth countries, Hong Kong and the United States, a green paper is a tentative government report and consultation document of policy proposals for debate and discussion. A green paper represents the best that the government can propose on the given issue, but, remaining uncommitted, it is able without loss of face to leave its final decision open until it has been able to consider the public reaction to it. Green papers may result in the production of a white paper. They may be considered as grey literature.\n\nA green paper in Canada, like a white paper, is an official government document. Green papers tend to be statements not of policy already determined, but of propositions put before the whole nation for discussion. They are produced early in the policy-making process, while ministerial proposals are still being formulated. Many white papers in Canada have been, in effect, green papers, while at least one green paper—that on immigration and population in 1975—was released for public debate after the government had already drafted legislation.\n\nSimilarly, in the UK, green papers are official consultation documents produced by the government for discussion both inside and outside Parliament, for instance when a government department is considering introducing a new law.\n\nA green paper released by the European Commission is a discussion document intended to stimulate debate and launch a process of consultation, at European level, on a particular topic. A green paper usually presents a range of ideas and is meant to invite interested individuals or organizations to contribute views and information. It may be followed by a white paper, an official set of proposals that is used as a vehicle for their development into law.\n\nA major review of defence policy in Australia culminated in a white paper issued in December 2000. Prior to this, a discussion paper was released in June 2000. This discussion paper was in nature what is known as a green paper (and was sometimes referred to as such).\n\nThe purpose of the 2008 EU green paper on copyright was to foster a debate on how knowledge for research, science and education can best be disseminated in the online environment. The green paper, which was published on 16 July 2008, aimed to set out a number of issues connected with the role of copyright in the \"knowledge economy\" and intended to launch a consultation on these issues (see this document). The EU asked for answers and comments to be submitted up to 30 November 2008.\n\n\n"}
{"id": "14285", "url": "https://en.wikipedia.org/wiki?curid=14285", "title": "History of science and technology", "text": "History of science and technology\n\nThe history of science and technology (HST) is a field of history which examines how humanity's understanding of the natural world (science) and ability to manipulate it (technology) have changed over the centuries. This academic discipline also studies the cultural, economic, and political impacts of scientific innovation.\n\nHistories of science were originally written by practicing and retired scientists, starting primarily with William Whewell, as a way to communicate the virtues of science to the public. In the early 1930s, after a famous paper given by the Soviet historian Boris Hessen, was focused into looking at the ways in which scientific practices were allied with the needs and motivations of their context. After World War II, extensive resources were put into teaching and researching the discipline, with the hopes that it would help the public better understand both Science and Technology as they came to play an exceedingly prominent role in the world. In the 1960s, especially in the wake of the work done by Thomas Kuhn, the discipline began to serve a very different function, and began to be used as a way to critically examine the scientific enterprise. At the present time it is often closely aligned with the field of science studies.\n\nModern engineering as it is understood today took form during the scientific revolution, though much of the mathematics and science was built on the work of the Greeks, Egyptians, Mesopotamians, Chinese, Indians. See the main articles History of science and History of technology for these respective topics.\n\n\n\n\n\n\n\n\nHistory of science and technology is a well developed field in India. At least three generations of scholars can be identified.\nThe first generation includes D.D.Kosambi, Dharmpal, Debiprasad Chattopadhyay and Rahman. The second generation mainly consists of Ashis Nandy, Deepak Kumar, Dhruv Raina, S. Irfan Habib, Shiv Visvanathan, Gyan Prakash, Stan Lourdswamy, V.V. Krishna, Itty Abraham, Richard Grove, Kavita Philip, Mira Nanda and Rob Anderson. There is an emergent third generation that includes scholars like Abha Sur and Jahnavi Phalkey.\n\nDepartments and Programmes\n\nThe National Institute of Science, Technolology and Development Studies had a research group active in the 1990s which consolidated social history of science as a field of research in India. \nCurrently there are several institutes and university departments offering HST programmes.\n\n\n\n\n\n\n\n\nAcademic study of the History of Science as an independent discipline was launched by George Sarton at Harvard with his book \"Introduction to the History of Science\" (1927) and the \"Isis\" journal (founded in 1912). Sarton exemplified the early 20th century view of the history of science as the history of great men and great ideas. He shared with many of his contemporaries a Whiggish belief in history as a record of the advances and delays in the march of progress. The History of Science was not a recognized subfield of American history in this period, and most of the work was carried out by interested Scientists and Physicians rather than professional Historians. With the work of I. Bernard Cohen at Harvard, the history of Science became an established subdiscipline of history after 1945.\n\n\n\n\n\nHistoriography of science\n\nHistory of science as a discipline\n\n"}
{"id": "803661", "url": "https://en.wikipedia.org/wiki?curid=803661", "title": "History of technology", "text": "History of technology\n\nThe history of technology is the history of the invention of tools and techniques and is one of the categories of the history of humanity. Technology can refer to methods ranging from as simple as stone tools to the complex genetic engineering and information technology that has emerged since the 1980s. The term technology comes from the Greek word techne, meaning art and craft, and the word logos, meaning word and speech. It was first used to describe applied arts, but it is now used to described advancements and changes which affect the environment around us.\n\nNew knowledge has enabled people to create new things, and conversely, many scientific endeavors are made possible by technologies which assist humans in traveling to places they could not previously reach, and by scientific instruments by which we study nature in more detail than our natural senses allow.\n\nSince much of technology is applied science, technical history is connected to the history of science. Since technology uses resources, technical history is tightly connected to economic history. From those resources, technology produces other resources, including \"technological artifacts\" used in everyday life.\n\nTechnological change affects and is affected by, a society's cultural traditions. It is a force for economic growth and a means to develop and project economic, political, military power and wealth.\n\nMany sociologists and anthropologists have created social theories dealing with social and cultural evolution. Some, like Lewis H. Morgan, Leslie White, and Gerhard Lenski have declared technological progress to be the primary factor driving the development of human civilization. Morgan's concept of three major stages of social evolution (savagery, barbarism, and civilization) can be divided by technological milestones, such as fire. White argued the measure by which to judge the evolution of culture was energy.\n\nFor White, \"the primary function of culture\" is to \"harness and control energy.\" White differentiates between five stages of human development: In the first, people use the energy of their own muscles. In the second, they use the energy of domesticated animals. In the third, they use the energy of plants (agricultural revolution). In the fourth, they learn to use the energy of natural resources: coal, oil, gas. In the fifth, they harness nuclear energy. White introduced a formula P=E*T, where E is a measure of energy consumed, and T is the measure of the efficiency of technical factors using the energy. In his own words, \"culture evolves as the amount of energy harnessed per capita per year is increased, or as the efficiency of the instrumental means of putting the energy to work is increased\". Nikolai Kardashev extrapolated his theory, creating the Kardashev scale, which categorizes the energy use of advanced civilizations.\n\nLenski's approach focuses on information. The more information and knowledge (especially allowing the shaping of natural environment) a given society has, the more advanced it is. He identifies four stages of human development, based on advances in the history of communication. In the first stage, information is passed by genes. In the second, when humans gain sentience, they can learn and pass information through experience. In the third, the humans start using signs and develop logic. In the fourth, they can create symbols, develop language and writing. Advancements in communications technology translate into advancements in the economic system and political system, distribution of wealth, social inequality and other spheres of social life. He also differentiates societies based on their level of technology, communication, and economy:\n\nIn economics, productivity is a measure of technological progress. Productivity increases when fewer inputs (classically labor and capital but some measures include energy and materials) are used in the production of a unit of output. Another indicator of technological progress is the development of new products and services, which is necessary to offset unemployment that would otherwise result as labor inputs are reduced. In developed countries productivity growth has been slowing since the late 1970s; however, productivity growth was higher in some economic sectors, such as manufacturing. For example, employment in manufacturing in the United States declined from over 30% in the 1940s to just over 10% 70 years later. Similar changes occurred in other developed countries. This stage is referred to as \"post-industrial\".\n\nIn the late 1970s sociologists and anthropologists like Alvin Toffler (author of \"Future Shock\"), Daniel Bell and John Naisbitt have approached the theories of post-industrial societies, arguing that the current era of industrial society is coming to an end, and services and information are becoming more important than industry and goods. Some extreme visions of the post-industrial society, especially in fiction, are strikingly similar to the visions of near and post-Singularity societies.\n\nThe following is a summary of the history of technology by time period and geography:\n\nDuring most of the Paleolithic – the bulk of the Stone Age – all humans had a lifestyle which involved limited tools and few permanent settlements. The first major technologies were tied to survival, hunting, and food preparation. Stone tools and weapons, fire, and clothing were technological developments of major importance during this period.\n\nHuman ancestors have been using stone and other tools since long before the emergence of \"Homo sapiens\" approximately 200,000 years ago. The earliest methods of stone tool making, known as the Oldowan \"industry\", date back to at least 2.3 million years ago, with the earliest direct evidence of tool usage found in Ethiopia within the Great Rift Valley, dating back to 2.5 million years ago. This era of stone tool use is called the \"Paleolithic\", or \"Old stone age\", and spans all of human history up to the development of agriculture approximately 12,000 years ago.\n\nTo make a stone tool, a \"core\" of hard stone with specific flaking properties (such as flint) was struck with a hammerstone. This flaking produced sharp edges which could be used as tools, primarily in the form of choppers or scrapers. These tools greatly aided the early humans in their hunter-gatherer lifestyle to perform a variety of tasks including butchering carcasses (and breaking bones to get at the marrow); chopping wood; cracking open nuts; skinning an animal for its hide, and even forming other tools out of softer materials such as bone and wood.\n\nThe earliest stone tools were irrelevant, being little more than a fractured rock. In the Acheulian era, beginning approximately 1.65 million years ago, methods of working these stone into specific shapes, such as hand axes emerged. This early Stone Age is described as the Lower Paleolithic.\n\nThe Middle Paleolithic, approximately 300,000 years ago, saw the introduction of the prepared-core technique, where multiple blades could be rapidly formed from a single core stone. The Upper Paleolithic, beginning approximately 40,000 years ago, saw the introduction of pressure flaking, where a wood, bone, or antler punch could be used to shape a stone very finely.\n\nThe end of the last Ice Age about 10,000 years ago is taken as the end point of the Upper Paleolithic and the beginning of the Epipaleolithic / Mesolithic. The Mesolithic technology included the use of microliths as composite stone tools, along with wood, bone, and antler tools.\n\nThe later Stone Age, during which the rudiments of agricultural technology were developed, is called the Neolithic period. During this period, polished stone tools were made from a variety of hard rocks such as flint, jade, jadeite, and greenstone, largely by working exposures as quarries, but later the valuable rocks were pursued by tunneling underground, the first steps in mining technology. The polished axes were used for forest clearance and the establishment of crop farming and were so effective as to remain in use when bronze and iron appeared. These stone axes were used alongside a continued use of stone tools such as a range of projectiles, knives, and scrapers, as well as tools, made organic materials such as wood, bone, and antler.\n\nStone Age cultures developed music and engaged in organized warfare. Stone Age humans developed ocean-worthy outrigger canoe technology, leading to migration across the Malay archipelago, across the Indian Ocean to Madagascar and also across the Pacific Ocean, which required knowledge of the ocean currents, weather patterns, sailing, and celestial navigation.\n\nAlthough Paleolithic cultures left no written records, the shift from nomadic life to settlement and agriculture can be inferred from a range of archaeological evidence. Such evidence includes ancient tools, cave paintings, and other prehistoric art, such as the Venus of Willendorf. Human remains also provide direct evidence, both through the examination of bones, and the study of mummies. Scientists and historians have been able to form significant inferences about the lifestyle and culture of various prehistoric peoples, and especially their technology.\n\nMetallic copper occurs on the surface of weathered copper ore deposits and copper was used before copper smelting was known. Copper smelting is believed to have originated when the technology of pottery kilns allowed sufficiently high temperatures. The concentration of various elements such as arsenic increase with depth in copper ore deposits and smelting of these ores yields arsenical bronze, which can be sufficiently work hardened to be suitable for making tools. Bronze is an alloy of copper with tin; the latter being found in relatively few deposits globally caused a long time to elapse before true tin bronze to became widespread. (See: Tin sources and trade in ancient times) Bronze was a major advance over stone as a material for making tools, both because of its mechanical properties like strength and ductility and because it could be cast in molds to make intricately shaped objects. \n\nBronze significantly advanced shipbuilding technology with better tools and bronze nails. Bronze nails replaced the old method of attaching boards of the hull with cord woven through drilled holes. Better ships enabled long distance trade and the advance of civilization. \nThis technological trend apparently began in the Fertile Crescent and spread outward over time. These developments were not, and still are not, universal. The three-age system does not accurately describe the technology history of groups outside of Eurasia, and does not apply at all in the case of some isolated populations, such as the Spinifex People, the Sentinelese, and various Amazonian tribes, which still make use of Stone Age technology, and have not developed agricultural or metal technology.\n\nBefore iron smelting was developed the only iron was obtained from meteorites and is usually identified by having nickel content. Meteoric iron was rare and valuable, but was sometimes used to make tools and other implements, such as fish hooks.\n\nThe Iron age involved the adoption of iron smelting technology. It generally replaced bronze and made it possible to produce tools which were stronger, lighter and cheaper to make than bronze equivalents. The raw materials to make iron, such as ore and limestone, are far more abundant than copper and especially tin ores. Consequently, iron was produced in many areas. \n\nIt was not possible to mass manufacture steel or pure iron because of the high temperatures required. Furnaces could reach melting temperature but the crucibles and molds needed for melting and casting had not been developed. Steel could be produced by forging bloomery iron to reduce the carbon content in a somewhat controllable way, but steel produced by this method was not homogeneous.\n\nIn many Eurasian cultures, the Iron Age was the last major step before the development of written language, though again this was not universally the case.\n\nIn Europe, large hill forts were built either as a refuge in time of war or sometimes as permanent settlements. In some cases, existing forts from the Bronze Age were expanded and enlarged. The pace of land clearance using the more effective iron axes increased, providing more farmland to support the growing population.\n\nThe Egyptians invented and used many simple machines, such as the ramp to aid construction processes. Egyptian society made significant advances during dynastic periods in areas such as astronomy, mathematics, and medicine. They also made paper and monuments. The Egyptians made significant advances in shipbuilding. Astronomy was used by Egyptian leaders to govern people.\n\nThe Indus Valley Civilization, situated in a resource-rich area, is notable for its early application of city planning and sanitation technologies. Indus Valley construction and architecture, called 'Vaastu Shastra', suggests a thorough understanding of materials engineering, hydrology, and sanitation.\n\nThe peoples of Mesopotamia (Sumerians, Akkadians, Assyrians, and Babylonians) have been credited with the invention of the wheel, but this is no longer certain. They lived in cities from c. 4000 BC, and developed a sophisticated architecture in mud-brick and stone, including the use of the true arch. The walls of Babylon were so massive they were quoted as a Wonder of the World. They developed extensive water systems; canals for transport and irrigation in the alluvial south, and catchment systems stretching for tens of kilometers in the hilly north. Their palaces had sophisticated drainage systems.\n\nWriting was invented in Mesopotamia, using the cuneiform script. Many records on clay tablets and stone inscriptions have survived. These civilizations were early adopters of bronze technologies which they used for tools, weapons and monumental statuary. By 1200 BC they could cast objects 5 m long in a single piece. The Assyrian King Sennacherib (704–681 BC) claims to have invented automatic sluices and to have been the first to use water screws, of up to 30 tons weight, which were cast using two-part clay molds rather than by the 'lost wax' process. The Jerwan Aqueduct (c. 688 BC) is made with stone arches and lined with waterproof concrete.\n\nThe Babylonian astronomical diaries spanned 800 years. They enabled meticulous astronomers to plot the motions of the planets and to predict eclipses.\n\nThe Chinese made many first-known discoveries and developments. Major technological contributions from China include early seismological detectors, matches, paper, sliding calipers, the double-action piston pump, cast iron, the iron plough, the multi-tube seed drill, the wheelbarrow, the suspension bridge, the parachute, natural gas as fuel, the compass, the raised-relief map, the propeller, the crossbow, the South Pointing Chariot and gunpowder.\n\nOther Chinese discoveries and inventions from the Medieval period include block printing, movable type printing, phosphorescent paint, endless power chain drive and the clock escapement mechanism. The solid-fuel rocket was invented in China about 1150, nearly 200 years after the invention of gunpowder (which acted as the rocket's fuel). Decades before the West's age of exploration, the Chinese emperors of the Ming Dynasty also sent large fleets on maritime voyages, some reaching Africa.\n\nGreek and Hellenistic engineers were responsible for myriad inventions and improvements to existing technology. The Hellenistic period, in particular, saw a sharp increase in technological advancement, fostered by a climate of openness to new ideas, the blossoming of a mechanistic philosophy, and the establishment of the Library of Alexandria and its close association with the adjacent museion. In contrast to the typically anonymous inventors of earlier ages, ingenious minds such as Archimedes, Philo of Byzantium, Heron, Ctesibius, and Archytas remain known by name to posterity.\n\nAncient Greek innovations were particularly pronounced in mechanical technology, including the ground-breaking invention of the watermill which constituted the first human-devised motive force not to rely on muscle power (besides the sail). Apart from their pioneering use of waterpower, Greek inventors were also the first to experiment with wind power (see Heron's windwheel) and even created the earliest steam engine (the aeolipile), opening up entirely new possibilities in harnessing natural forces whose full potential would not be exploited until the Industrial Revolution. The newly devised right-angled gear and screw would become particularly important to the operation of mechanical devices. That is when the age of mechanical devices started.\n\nAncient agriculture, as in any period prior to the modern age the primary mode of production and subsistence, and its irrigation methods, were considerably advanced by the invention and widespread application of a number of previously unknown water-lifting devices, such as the vertical water-wheel, the compartmented wheel, the water turbine, Archimedes' screw, the bucket-chain and pot-garland, the force pump, the suction pump, the double-action piston pump and quite possibly the chain pump.\n\nIn music, the water organ, invented by Ctesibius and subsequently improved, constituted the earliest instance of a keyboard instrument. In time-keeping, the introduction of the inflow clepsydra and its mechanization by the dial and pointer, the application of a feedback system and the escapement mechanism far superseded the earlier outflow clepsydra.\n\nThe famous Antikythera mechanism, a kind of analogous computer working with a differential gear, and the astrolabe both show great refinement in astronomical science.\n\nGreek engineers were also the first to devise automata such as vending machines, suspended ink pots, automatic washstands, and doors, primarily as toys, which however featured many new useful mechanisms such as the cam and gimbals.\n\nIn other fields, ancient Greek inventions include the catapult and the gastraphetes crossbow in warfare, hollow bronze-casting in metallurgy, the dioptra for surveying, in infrastructure the lighthouse, central heating, the tunnel excavated from both ends by scientific calculations, the ship trackway, the dry dock, and plumbing. In horizontal, vertical and transport, great progress resulted from the invention of the crane, the winch, the wheelbarrow and the odometer.\n\nFurther newly created techniques and items were spiral staircases, the chain drive, sliding calipers and showers.\n\nThe Romans developed an intensive and sophisticated agriculture, expanded upon existing iron working technology, created laws providing for individual ownership, advanced stone masonry technology, advanced road-building (exceeded only in the 19th century), military engineering, civil engineering, spinning and weaving and several different machines like the Gallic reaper that helped to increase productivity in many sectors of the Roman economy. Roman engineers were the first to build monumental arches, amphitheatres, aqueducts, public baths, true arch bridges, harbours, reservoirs and dams, vaults and domes on a very large scale across their Empire. Notable Roman inventions include the book (Codex), glass blowing and concrete. Because Rome was located on a volcanic peninsula, with sand which contained suitable crystalline grains, the concrete which the Romans formulated was especially durable. Some of their buildings have lasted 2000 years, to the present day.\n\nThe engineering skills of the Inca and the Mayans were great, even by today's standards. An example of this great engineering is the use of pieces weighing upwards of one ton in their stonework placed together so that not even a blade can fit into the cracks. Inca villages used irrigation canals and drainage systems, making agriculture very efficient. While some claim that the Incas were the first inventors of hydroponics, their agricultural technology was still soil based, if advanced.\n\nThough the Maya civilization did not incorporate metallurgy or wheel technology in their architectural constructions, they developed complex writing and astronomical systems, and created beautiful sculptural works in stone and flint. Like the Inca, the Maya also had command of fairly advanced agricultural and construction technology. The Maya are also responsible for creating the first pressurized water system in Mesoamerica, located in the Maya site of Palenque.\n\nThe main contribution of the Aztec rule was a system of communications between the conquered cities and the ubiquity of the ingenious agricultural technology of chinampas. In Mesoamerica, without draft animals for transport (nor, as a result, wheeled vehicles), the roads were designed for travel on foot, just as in the Inca and Mayan civilizations. The Aztec, subsequently to the Maya, inhereted many of the technologies and intellectual advancements of their predecessors: the Olmec (see Native American inventions and innovations).\n\nOne of the most significant development of the Medieval era was the development of economies where water and wind power were more significant than animal and human muscle power. Most water and wind power was used for milling grain. Water power was also used for blowing air in blast furnace, pulping rags for paper making and for felting wool. The \"Domesday Book\" recorded 5,624 water mills in Great Britain in 1086, being about one per thirty families.\n\nAs earlier empires had done, the Muslim caliphates united in trade large areas that had previously traded little. The conquered sometimes paid lower taxes than in their earlier independence, and ideas spread even more easily than goods. Peace was more frequent than it had been. These conditions fostered improvements in agriculture and other technology as well as in sciences which largely adapted from earlier Greek, Roman and Persian empires, with improvements.\n\nEuropean technology in the Middle Ages was a mixture of tradition and innovation. While medieval technology has been long depicted as a step backwards in the evolution of Western technology, sometimes willfully so by modern authors intent on denouncing the church as antagonistic to scientific progress (see e.g. Myth of the Flat Earth), a generation of medievalists around the American historian of science Lynn White stressed from the 1940s onwards the innovative character of many medieval techniques. Genuine medieval contributions include for example mechanical clocks, spectacles and vertical windmills. Medieval ingenuity was also displayed in the invention of seemingly inconspicuous items like the watermark or the functional button. In navigation, the foundation to the subsequent age of exploration was laid by the introduction of pintle-and-gudgeon rudders, lateen sails, the dry compass, the horseshoe and the astrolabe.\n\nSignificant advances were also made in military technology with the development of plate armour, steel crossbows, counterweight trebuchets and cannon. The Middle Ages are perhaps best known for their architectural heritage: While the invention of the rib vault and pointed arch gave rise to the high rising Gothic style, the ubiquitous medieval fortifications gave the era the almost proverbial title of the 'age of castles'.\n\nPapermaking, a 2nd-century Chinese technology, was carried to the Middle East when a group of Chinese papermakers were captured in the 8th century. Papermaking technology was spread to Europe by the Umayyad conquest of Hispania. A paper mill was established in Sicily in the 12th century. In Europe the fiber to make pulp for making paper was obtained from linen and cotton rags. Lynn Townsend White Jr. credited the spinning wheel with increasing the supply of rags, which led to cheap paper, which was a factor in the development of printing.\n\nBefore the development of modern engineering, mathematics was used by artisans and craftsmen, such as millwrights, clock makers, instrument makers and surveyors. Aside from these professions, universities were not believed to have had much practical significance to technology.\n\nA standard reference for the state of mechanical arts during the Renaissance is given in the mining engineering treatise \"De re metallica\" (1556), which also contains sections on geology, mining and chemistry. \"De re metallica\" was the standard chemistry reference for the next 180 years.\n\nDue to the casting of cannon, the blast furnace came into widespread use in France in the mid 15th century. The blast furnace had been used in China since the 4th century BC.\n\nThe invention of the movable cast metal type printing press, whose pressing mechanism was adapted from an olive screw press, (c. 1441) lead to a tremendous increase in the number of books and the number of titles published. Movable ceramic type had been used in China for a few centuries and woodblock printing dated back even further.\n\nThe era is marked by such profound technical advancements like linear perceptivity, double shell domes or Bastion fortresses. Note books of the Renaissance artist-engineers such as Taccola and Leonardo da Vinci give a deep insight into the mechanical technology then known and applied. Architects and engineers were inspired by the structures of Ancient Rome, and men like Brunelleschi created the large dome of Florence Cathedral as a result. He was awarded one of the first patents ever issued in order to protect an ingenious crane he designed to raise the large masonry stones to the top of the structure. Military technology developed rapidly with the widespread use of the cross-bow and ever more powerful artillery, as the city-states of Italy were usually in conflict with one another. Powerful families like the Medici were strong patrons of the arts and sciences. Renaissance science spawned the Scientific Revolution; science and technology began a cycle of mutual advancement.\n\nAn improved sailing ship, the (nau or carrack), enabled the Age of Exploration with the European colonization of the Americas, epitomized by Francis Bacon's \"New Atlantis\". Pioneers like Vasco da Gama, Cabral, Magellan and Christopher Columbus explored the world in search of new trade routes for their goods and contacts with Africa, India and China to shorten the journey compared with traditional routes overland. They produced new maps and charts which enabled following mariners to explore further with greater confidence. Navigation was generally difficult, however, owing to the problem of longitude and the absence of accurate chronometers. European powers rediscovered the idea of the civil code, lost since the time of the Ancient Greeks.\n\nThe stocking frame, which was invented in 1598, increased a knitter's number of knots per minute from 100 to 1000.\n\nMines were becoming increasingly deep and were expensive to drain with horse powered bucket and chain pumps and wooden piston pumps. Some mines used as many as 500 horses. Horse-powered pumps were replaced by the Savery steam pump (1698) and the Newcomen steam engine (1712).\n\nThe British Industrial Revolution is characterized by developments in the areas of textile machinery, mining, metallurgy and transport the steam engine and the invention of machine tools.\n\nBefore invention of machinery to spin yarn and weave cloth, spinning was done the spinning wheel and weaving done on a hand and foot operated loom. It took from three to five spinners to supply one weaver. The invention of the flying shuttle in 1733 doubled the output of a weaver, creating a shortage of spinners. The spinning frame for wool was invented in 1738. The spinning jenny, invented in 1764, was a machine that used multiple spinning wheels; however, it produced low quality thread. The water frame patented by Richard Arkwright in 1767, produced a better quality thread than the spinning jenny. The spinning mule, patented in 1779 by Samuel Crompton, produced a high quality thread. The power loom was invented by Edmund Cartwright in 1787.\n\nIn the mid 1750s the steam engine was applied to the water power-constrained iron, copper and lead industries for powering blast bellows. These industries were located near the mines, some of which were using steam engines for mine pumping. Steam engines were too powerful for leather bellows, so cast iron blowing cylinders were developed in 1768. Steam powered blast furnaces achieved higher temperatures, allowing the use of more lime in iron blast furnace feed. (Lime rich slag was not free-flowing at the previously used temperatures.) With a sufficient lime ratio, sulfur from coal or coke fuel reacts with the slag so that the sulfur does not contaminate the iron. Coal and coke were cheaper and more abundant fuel. As a result, iron production rose significantly during the last decades of the 18th century.\n\nThe revolution was driven by cheap energy in the form of coal, produced in ever-increasing amounts from the abundant resources of Britain. Coal converted to coke fueled higher temperature blast furnaces and produced cast iron in much larger amounts than before, allowing the creation of a range of structures such as The Iron Bridge. Cheap coal meant that industry was no longer constrained by water resources driving the mills, although it continued as a valuable source of power. The steam engine helped drain the mines, so more coal reserves could be accessed, and the output of coal increased. The development of the high-pressure steam engine made locomotives possible, and a transport revolution followed. The steam engine which had existed since the early 18th century, was practically applied to both steamboat and railway transportation. The Liverpool and Manchester Railway, the first purpose built railway line, opened in 1830, the Rocket locomotive of Robert Stephenson being one of its first working locomotives used.\n\nManufacture of ships' pulley blocks by all-metal machines at the Portsmouth Block Mills in 1803 instigated the age of sustained mass production. Machine tools used by engineers to manufacture parts began in the first decade of the century, notably by Richard Roberts and Joseph Whitworth. The development of interchangeable parts through what is now called the American system of manufacturing began in the firearms industry at the U.S Federal arsenals in the early 19th century, and became widely used by the end of the century.\n\nThe 19th century saw astonishing developments in transportation, construction, manufacturing and communication technologies originating in Europe. After a recession at the end of the 1830s and a general slowdown in major inventions, the Second Industrial Revolution was a period of rapid innovation and industrialization that began in the 1860s or around 1870 and lasted until World War I. It included rapid development of chemical, electrical, petroleum, and steel technologies connected with highly structured technology research.\n\nTelegraphy developed into a practical technology in the 19th century to help run the railways safely. Along with the development of telegraphy was the patenting of the first telephone. March 1876 marks the date that Alexander Graham Bell officially patented his version of an \"electric telegraph\". Although Bell is noted with the creation of the telephone, it is still debated about who actually developed the first working model.\n\nBuilding on improvements in vacuum pumps and materials research, incandescent light bulbs became practical for general use in the late 1870s. This invention had a profound effect on the workplace because factories could now have second and third shift workers.\n\nShoe production was mechanized during the mid 19th century. Mass production of sewing machines and agricultural machinery such as reapers occurred in the mid to late 19th century. Bicycles were mass-produced beginning in the 1880s.\n\nSteam-powered factories became widespread, although the conversion from water power to steam occurred in England before in the U.S. Ironclad warships were found in battle starting in the 1860s, and played a role in the opening of Japan and China to trade with the West.\n\n20th-century technology developed rapidly. Broad teaching and implementation of the scientific method, and increased research spending contributed to the advancement of modern science and technology. New technology improved communication and transport, thus spreading technical understanding.\n\nMass production brought automobiles and other high-tech goods to masses of consumers. Military research and development sped advances including electronic computing and jet engines. Radio and telephony improved greatly and spread to larger populations of users, though near-universal access would not be possible until mobile phones became affordable to developing world residents in the late 2000s and early 2010s.\n\nEnergy and engine technology improvements included nuclear power, developed after the Manhattan project which heralded the new Atomic Age. Rocket development led to long range missiles and the first space age that lasted from the 1950s with the launch of Sputnik to the mid-1980s.\n\nElectrification spread rapidly in the 20th century. At the beginning of the century electric power was for the most part only available to wealthy people in a few major cities such as New York, London, Paris, and Newcastle upon Tyne, but by the time the World Wide Web was invented in 1990 an estimated 62 percent of homes worldwide had electric power, including about a third of households in the rural developing world.\n\nBirth control also became widespread during the 20th century. Electron microscopes were very powerful by the late 1970s and genetic theory and knowledge were expanding, leading to developments in genetic engineering.\n\nThe first \"test tube baby\" Louise Brown was born in 1978, which led to the first successful gestational surrogacy pregnancy in 1985 and the first pregnancy by ICSI in 1991, which is the implanting of a single sperm into an egg. Preimplantation genetic diagnosis was first performed in late 1989 and led to successful births in July 1990. These procedures have become relatively common.\n\nThe massive data analysis resources necessary for running transatlantic research programs such as the Human Genome Project and the Large Electron-Positron Collider led to a necessity for distributed communications, causing Internet protocols to be more widely adopted by researchers and also creating a justification for Tim Berners-Lee to create the World Wide Web.\n\nVaccination spread rapidly to the developing world from the 1980s onward due to many successful humanitarian initiatives, greatly reducing childhood mortality in many poor countries with limited medical resources.\n\nThe US National Academy of Engineering, by expert vote, established the following ranking of the most important technological developments of the 20th century:\n\n\nIn the early 21st century research is ongoing into quantum computers, gene therapy (introduced 1990), 3D printing (introduced 1981), nanotechnology (introduced 1985), bioengineering/biotechnology, nuclear technology, advanced materials (e.g., graphene), the scramjet and drones (along with railguns and high-energy laser beams for military uses), superconductivity, the memristor, and green technologies such as alternative fuels (e.g., fuel cells, self-driving electric and plug-in hybrid cars), augmented reality devices and wearable electronics, artificial intelligence, and more efficient and powerful LEDs, solar cells, integrated circuits, wireless power devices, engines, and batteries.\n\nPerhaps the greatest research tool built in the 21st century is the Large Hadron Collider, the largest single machine ever built. The understanding of particle physics is expected to expand with better instruments including larger particle accelerators such as the LHC and better neutrino detectors. Dark matter is sought via underground detectors and observatories like LIGO have started to detect gravitational waves.\n\nGenetic engineering technology continues to improve, and the importance of epigenetics on development and inheritance has also become increasingly recognized.\n\nNew spaceflight technology and spacecraft are also being developed, like the Orion and Dragon. New, more capable space telescopes, such as the James Webb Telescope, to be launched to orbit in early 2021, and the Colossus Telescope are being designed. The International Space Station was completed in the 2000s, and NASA and ESA plan a manned mission to Mars in the 2030s. The Variable Specific Impulse Magnetoplasma Rocket (VASIMR) is an electro-magnetic thruster for spacecraft propulsion and is expected to be tested in 2015.\n\nBreakthrough Initiatives, together with famed physicist Stephen Hawking, plan to send the first ever spacecraft to visit another star, which will consist of numerous super-light chips driven by Electric propulsion in the 2030s, and receive images of the Proxima Centauri system, along with, possibly, the potentially habitable planet Proxima Centauri b, by midcentury.\n\n2004 saw the first manned commercial spaceflight when Mike Melvill crossed the boundary of space on June 21, 2004.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "40037692", "url": "https://en.wikipedia.org/wiki?curid=40037692", "title": "I.D. Systems", "text": "I.D. Systems\n\nI.D. Systems, Inc. is an American company headquartered in Woodcliff Lake, New Jersey, that produces wireless asset management systems for industrial trucks, rental vehicles, and transportation assets. The company utilizes wireless communication technologies—including radio frequency identification (RFID), Wi-Fi, ultrahigh-frequency (UHF), satellite, and cellular—as well as sensor technology and proprietary software to manage high-value corporate assets, such as forklifts, airport ground support equipment, rental vehicles, dry van trailers, chassis, refrigerated trailers, flatbeds, railcars, and intermodal containers.\n\nI.D. Systems was founded in 1993 by Kenneth S. Ehrman. The company introduced the use of radio frequency identification (RFID) technology for industrial asset tracking and management. In 1995, I.D. Systems was awarded a $6.6 million contract from U.S. Postal Service (USPS) to develop and implement a tracking system for test letters and packages. I.D. Systems went public on the NASDAQ in 1999.\n\nIn 2005, I.D. Systems received a three-year contract from the U.S. Postal Service to implement its Wireless Asset Net, a wireless industrial vehicle management system, at 460 USPS facilities nationwide. According to Jeffrey Jagid, the company's former chairman and CEO, this project is a key milestone both in the company's relationship with USPS and in mass commercialization of the company's wireless technology.\n\nIn 2009, I.D. Systems acquired didBOX Ltd., a privately held, United Kingdom-based manufacturer and marketer of driver identification systems for forklift fleets. The acquisition made didBOX a wholly owned subsidiary of I.D. Systems, broadened I.D. Systems' product line, and expanded sales of the company's vehicle management solutions in the European market. In 2010, I.D. Systems acquired GE Asset Intelligence, LLC, a business unit of the General Electric Company, which provides trailer and container tracking solutions for manufacturers, retailers, shippers, and freight transportation companies. The acquisition expanded the scope of I.D. Systems' product line and complemented its portfolio of wireless asset management patents.\n\nIn 2017, I.D. Systems acquired Keytroller, a privately held, Florida-based manufacturer and marketer of safety systems for industrial lift trucks. https://globenewswire.com/news-release/2017/07/11/1042701/0/en/I-D-Systems-to-Acquire-Keytroller-Strengthening-Its-Position-in-Industrial-Truck-Management-Market-and-Overall-Growth-Outlook.html\n\nI.D. Systems' solutions consist of hardware, software, maintenance, support, and consulting services. The solutions can be divided into three categories: industrial vehicle management, transportation asset management, and rental fleet management.\n\nI.D. Systems' industrial vehicle management systems are used by manufacturers, distributors, retailers, government entities, and other organizations with powered industrial trucks (forklifts, tow tractors, pallet jacks, etc.) to monitor and evaluate fleet operations, track vehicle movement, and manage vehicle operators. The system consists of four elements: a wireless computer installed on the vehicle, wireless communication nodes placed within the facility, system software hosted either on site or in a remote data center, and user software configured in either a client-server or thin-client (Internet browser-based) architecture. Data may be transmitted by any combination of Wi-Fi, cellular or UHF wireless technologies.\n\nThe company offers three systems for industrial vehicle management. didBox™ is a non-wireless system for driver identification. PowerBox™ and PowerFleet® are wireless systems with functions ranging from operator access control, electronic safety checklists, and impact management to location tracking, battery management, maintenance scheduling, and task dispatching.\n\nThe company's customers in the industrial vehicle management market include Ford Motor Company, Nestlé North America, Procter & Gamble, Toyota, and Walmart (which accounted for 15% of the company's 2012 revenues).\n\nI.D. Systems provides a variation of its industrial vehicle management system designed specifically for ground support equipment (pushback tractors, baggage tugs, cargo loaders, catering vans, fuel trucks, etc.) and other vehicles that operate in and around airports.\n\nThis system, branded AvRamp®, was developed with funding from the U.S. Transportation Security Administration (TSA) and tested by the TSA at Newark Liberty International Airport and the JAXPORT seaport in Jacksonville, Florida. According to a 2005 TSA report, \"The Newark Liberty International Airport (EWR) Vehicle Tracking Demonstration—Wireless Fleet Management System,\" I.D. Systems' technology accurately located vehicles and enhanced the security of aircraft fuel trucks and other maintenance vehicles.\n\nThe company's customers in the airport vehicle management market include Envoy Air and American Airlines.\n\nI.D. Systems' Asset Intelligence subsidiary provides asset management solutions for the freight transportation industry under the VeriWise™ brand. The VeriWise™ product line includes a range of telematics solutions for tracking the location and monitoring the condition and status of dry van trailers, refrigerated trailers (\"reefers\"), flatbeds, chassis, containers, and railcars.\n\nFor managing fleets of dry van trailers and containers, the company offers a product called VeriWise™ Track and Trace™ for location tracking, a cargo sensor to monitor load status, and a motion sensor to detect trailer movement. The company also offers a temperature sensor to monitor the condition of reefers and an impact sensor to track collisions of railcars.\n\nTo manage these transportation assets, VeriWise™ products leverage satellite and cellular communications and web-based data processing technologies. Users access the information about their assets through a remotely hosted website called VeriWise™ Internet Portal (VIP), which generates reports and displays tabular data and a Google map interface.\n\nThe company's customers in the transportation asset management market include FAB Express, Forward Air, Freymiller, National Retail Systems, and Royal Freight.\n\nIn 2011, I.D. Systems and Avis Budget Group signed an exclusive agreement to deploy I.D. Systems' wireless vehicle management technology on more than 25,000 Avis Budget vehicles, enabling Avis customers to self-manage their rentals by computer or smartphone. The technology can also automate and expedite the rental and return process, track vehicle mileage, measure fuel consumption, and remotely control a vehicle's door locks. In February 2013, the company was awarded its second patent (patent number 8370268) for an automated wireless rental car management system.\n\nIn 2012, the company launched I.D. Systems Analytics, a set of web-based data reporting software tools. Analytics provides visibility into the performance of industrial assets across multiple facilities and geographies. The data enables users to evaluate individual facility performance, compare facilities side-by-side, and assess performance against industry-wide benchmarks, built on the company's database.\n\nInitial adopters of this product include Walgreen Company.\n\n\n"}
{"id": "47827949", "url": "https://en.wikipedia.org/wiki?curid=47827949", "title": "Internet geography", "text": "Internet geography\n\nInternet geography, also called cybergeography, is a subdiscipline of geography that studies the spatial organization of the Internet, from social, economic, cultural, and technological perspectives. The core assumption of Internet geography is that the location of servers, websites, data, services, and infrastructure is key to understand the development and the dynamics of the Internet. Among the topics covered by this discipline, of particular importance are information geography and digital divides.\n\n"}
{"id": "24002209", "url": "https://en.wikipedia.org/wiki?curid=24002209", "title": "Kamal Quadir", "text": "Kamal Quadir\n\nKamal S. Quadir is a Bangladeshi American entrepreneur and artist best known for introducing e-commerce in Bangladesh by founding CellBazaar, an electronic marketplace which, after reaching 4 million users, was acquired by Norwegian telecommunications operator Telenor in 2010. CellBazaar later was rebranded as ekhanei.com.\n\nQuadir is currently heading the company bKash, which provides financial services through a network of community-based agents and existing technology, including mobile phones. bKash is world’s second largest and fastest growing mobile financial services company.\n\nQuadir is a founding member of Open World Initiatives, a Lausanne, Switzerland-based organization of young thinkers. He is involved with Anwarul Quadir Foundation which recognises innovations in developing countries. He is a First Mover Fellow of The Aspen Institute. In 2009, TED selected Quadir a TED Fellow and the World Economic Forum recognised him as a Young Global Leader.\n\nQuadir was an intern at Insight Venture Partners in New York, led the Business Development Division of Occidental Petroleum's initiative in Bangladesh and worked for New York City's Chamber of Commerce. He was also the co-founder and creative director of \"GlobeKids Inc.\", an animation company.\n\nQuadir has a BA from Oberlin College and an MBA from the MIT Sloan School of Management.\n\nHe is also an artist whose art works are in the permanent collection of the Bangladesh National Museum and the Liberation War Museum.\n\n\n\n"}
{"id": "7983699", "url": "https://en.wikipedia.org/wiki?curid=7983699", "title": "Knowledge divide", "text": "Knowledge divide\n\nThe knowledge divide is the gap in standards of living between those who can find, create, manage, process, and disseminate information or knowledge, and those who are impaired in this process. According to a 2005 UNESCO World Report, the rise in the 21st century of a global information society has resulted in the emergence of knowledge as a valuable resource, increasingly determining who has access to power and profit. The rapid dissemination of information on a potentially global scale as a result of new information media and the globally uneven ability to assimilate knowledge and information has resulted in potentially expanding gaps in knowledge between individuals and nations.\n\nIn the 21st century, the emergence of the knowledge society becomes pervasive. The transformations of world's economy and of each society have a fast pace. Together with information and communication technologies (ICT) these new paradigms have the power to reshape the global economy. In order to keep pace with innovations, to come up with new ideas, people need to produce and manage knowledge. This is why knowledge has become essential for all societies.\n\nAccording to UNESCO and the World Bank, knowledge gaps between nations may occur due to the varying degrees by which individual nations incorporate the following elements:\n\n\nThe information and ICT systems that support knowledge are very important. This is why digitization is viewed closely related to knowledge. Scientists generally agree that there is a digital divide, recently different reports also showed the existence of knowledge divide.\n\nThe creation and effective use of knowledge are increasingly related to the development of an ICT infrastructure. Without ICT, it is impossible to have an infrastructure able to process the huge flow of information required in an advanced economy. In particular, without adequate technical support, it is difficult to develop and use e-learning and electronic documents to overcome time and space constraints.\n\nThe digital divide is, however, but one important part of the larger knowledge divide. As UNESCO states, \"closing the digital divide will not suffice to close the knowledge divide, for access to useful, relevant knowledge is more than simply a matter of infrastructure—it depends on training, cognitive skills and regulatory frameworks geared towards access to contents.\"\n\nIn the book Digital Dead End, Virginia Eubanks criticizes the way that the digital divide is generally thought of as a division between haves and have-nots, where the solution is distribution. This over simplistic depiction obscures the fact that often social and structural inequality is at the root of the divide. According to a study done by Eubanks with women of the YWCA, the women of the community \"insisted that have-nots possess many different kinds of crucial information and skills.\" In other words, it is not simply knowledge of the technology itself that is the issue but the structural system based on perpetuating the status quo in which the haves \"hoard\" knowledge.\n\nFirst, it was noticed that a great difference exists between the North and the South (rich countries vs. poor countries). The development of knowledge depends on spreading Internet and computer technology and also on the development of education in these countries. If a country has attained a higher literacy level then this will result in having higher level of knowledge.\nIndeed, UNESCO's report details many social issues in knowledge divide related to globalization. There was noticed a knowledge divide with respect to\n\n\n\n"}
{"id": "44814319", "url": "https://en.wikipedia.org/wiki?curid=44814319", "title": "List of largest machines", "text": "List of largest machines\n\n"}
{"id": "32727729", "url": "https://en.wikipedia.org/wiki?curid=32727729", "title": "List of online digital musical document libraries", "text": "List of online digital musical document libraries\n\nThis is a list of online digital musical document libraries. Each source listed below offers access to collections of digitized music documents (typically originating from printed or manuscript musical sources), and containing music notation of some kind, stored as an image file. \n\n"}
{"id": "43738567", "url": "https://en.wikipedia.org/wiki?curid=43738567", "title": "List of ovens", "text": "List of ovens\n\nThis is a list of ovens. An oven is a thermally insulated chamber used for the heating, baking or drying of a substance, and most commonly used for cooking. Kilns and furnaces are special-purpose ovens, used in pottery and metalworking, respectively.\n\nBaking is a food cooking method that uses prolonged dry heat by convection, rather than by thermal radiation, normally in an oven, but also in hot ashes, or on hot stones. Bread is a commonly baked food.\n\nAn earth oven, or cooking pit, is one of the most simple and long-used cooking structures. At its simplest, an earth oven is a pit in the ground used to trap heat and bake, smoke, or steam food. Earth ovens have been used in many places and cultures in the past, and the presence of such cooking pits is a key sign of human settlement often sought by archaeologists. They remain a common tool for cooking large quantities of food where no equipment is available.\nIndustrial ovens are heated chambers used for a variety of industrial applications, including drying, curing, or baking components, parts or final products. Industrial ovens can be used for large or small volume applications, in batches or continuously with a conveyor line, and a variety of temperature ranges, sizes and configurations.\nA kiln is a thermally insulated chamber, a type of oven, that produces temperatures sufficient to complete some process, such as hardening, drying, or chemical changes. Various industries and trades use kilns to harden objects made from clay into pottery, bricks etc. Various industries use rotary kilns for pyroprocessing—to calcinate ores, produce cement, lime, and many other materials.\n"}
{"id": "148571", "url": "https://en.wikipedia.org/wiki?curid=148571", "title": "List of satellites which have provided data on Earth's magnetosphere", "text": "List of satellites which have provided data on Earth's magnetosphere\n\nBelow is a list of satellites which have provided data on the Earth's magnetosphere.\n\n1γ = 10 oersted = Dynamic range of instrumentation\n"}
{"id": "26670795", "url": "https://en.wikipedia.org/wiki?curid=26670795", "title": "Localeze", "text": "Localeze\n\nLocaleze, a service of Neustar, is a content manager for local search engines. The company provides businesses with tools to verify and manage the identity of their local listings across the Web. The company works with local search platform partners and location-based service partners, national brands and local business clients.\n\nLocaleze was created in 2005 to help businesses ensure that they have accurate name, address and phone number data available on search engines, Internet Yellow Pages and vertical directories. \n\nIn 2010, business listings were also included in personal navigation devices, mobile apps and on social networking services.\n\nAs a local search business listings provider, Localeze collects and distributes business listings that can be verified by businesses themselves. Its business listings are used by search, social and mobile companies in the domain of Local Search and location-based services. Such partners include Yahoo!, Bing, Yellow Pages, TomTom, Siri (acquired by Apple), Twitter and Facebook.\n"}
{"id": "56600621", "url": "https://en.wikipedia.org/wiki?curid=56600621", "title": "Ministry of Science, Technology and Environment (Cuba)", "text": "Ministry of Science, Technology and Environment (Cuba)\n\nThe Ministry of Science, Technology and Environment of the Republic of Cuba (), also known as CITMA, is the Cuban government ministry which ovesees state politics in matters of science, technology, environment and the usage of nuclear energy. Its headquarter is in a building of \"Calle Línea\", a street of central Havana next to the Malecón, and part of Vedado, a ward of the municipal borough of Plaza de la Revolución.\n\nIt was founded in 1994, as successor of the Cuban Academy of Sciences. The current minister, Elba Rosa Pérez Montoya, in office from 2012, was preceded by José Miguel Miyar Barruecos, minister from March 2009 to March 2012.\n\nCITMA promotes environmental policy and scientific research, as the peaceful usage of nuclear energy, in a coherent integration and coordinated way to contribute to the sustainable development of the state. Besides the common attributions to all the organisms of the central administration of the state, it has the following attributions and specific functions:\n\n\nThis Cuban ministry delegates its functions to numerous agencies, centers and institutions related to its management area, among which are:\n\n\n\n"}
{"id": "31766044", "url": "https://en.wikipedia.org/wiki?curid=31766044", "title": "Mobile collaboration", "text": "Mobile collaboration\n\nMobile collaboration is a technology-based process of communicating using electronic assets and accompanying software designed for use in remote locations. Newest generation hand-held electronic devices feature video, audio, and telestration (on-screen drawing) capabilities broadcast over secure networks, enabling multi-party conferencing in real time (although real time communication is not a strict requirement of mobile collaboration and may not be applicable or practical in many collaboration scenarios).\n\nDiffering from traditional video conferencing, mobile collaboration utilizes wireless, cellular and broadband technologies enabling effective collaboration independent of location. Where traditional video conferencing has been limited to boardrooms, offices, and lecture theatres, recent technological advancements have extended the capabilities of video conferencing for use with discreet, hand-held mobile devices, permitting true mobile collaborative possibilities.\n\nThe scope of mobile collaboration takes into account a number of elements that continue to evolve in their sophistication and complexity: video, audio and telestration capabilities, conferencing and telepresence systems, collaboration tools, transmission technologies, and mobility.\n\nCisco Systems predicts \"two-thirds of the world's mobile data traffic will be video by 2015.\" The Unified Communications Interoperability Forum (UCIF), a non-profit alliance of technology vendors states that \"one important driver for the growth of UC (unified communications) is mobility and the remote worker. No segment is growing faster than mobile communications, and virtually every smart phone will be equipped with video chat, IM, directory, and other UC features within a few years.\"\n\nTo date, the use of mobile collaboration technology extends to industries as diverse as manufacturing, energy, healthcare, insurance, government and public safety. Mobile collaboration allows multiple users in multiple locations the ability to synergistically combine their input while working towards the resolution of problems or issues in today’s complex work environments. This can be done in real time with advanced video, audio and telestrator capabilities, comparable to working together in the same room but without the associated expense and downtime typically involved in getting the experts to remote locations.\n\nManufacturers of all kinds use mobile collaboration technology in a number of ways. Recent trends in globalization and outsourcing in particular, have meant that companies need to communicate with employees, suppliers, and customers the world over. The flexibility of hand-held mobile collaboration devices allow real-time communication to take place at any location where products are being designed, built, and inspected, such as an automotive assembly plant a continent away. Improved communication through mobile collaboration affects many aspects of complex manufacturing such as production line maintenance, supply chain management and equipment field service.\n\nCompanies in the energy sector face unique challenges due to, for example, the vast distances between a head office and the remote, harsh environment of an offshore oil rig, as well as the often inadequacies or absence of necessary transmission networks. Recent advancements in mobile collaboration technology and transmission networks are making it possible for employees in these situations to collaborate in secure and reliable ways with colleagues thousands of miles away. The use of mobile collaboration in the energy sector is enabling companies to conduct remote inspections, safety audits, maintenance, repair and overhaul work, as well as IT/communication infrastructure troubleshooting.\n\nAlthough telemedicine technology has been in use for a number of years in the healthcare sector, mobile collaboration technology extends these capabilities to locations now reachable through the use of hand-held devices such as a remote community, long-term care facility, or a patient’s home. Healthcare professionals in multiple locations can together view, discuss, and assess patient issues. The use of mobile collaboration technology within the healthcare sector has the potential to improve the quality and access to care, while making its delivery more cost-effective.\n\nMobile collaboration technology might also be used for remote education. From one on one tutoring to large classes it has many uses. Homeschooling could really benefit from this technology as you participate in a lecture from anywhere in the world. Most useful you can record your classes or lectures and review them. Internet schools, including higher education, will most certainly also benefit from this development in mobile education. Though these methods are not widely used they are quite useful and most likely will become widely popular.\n\nMobile collaboration between franchiser and franchisee allows modern technology to be used to allow a better flow of communications similar to face-to-face, albeit remotely via video/voice media such as smartphones, tablets, iPhones, iPads, etc. to be collectively used without requiring one party to travel to another location. This in turn reduces travel time and expenses not to mention better and quicker modes of communication.\n\nFranchisers who have several hundred franchisees find it an absolute must.\n\n"}
{"id": "25208936", "url": "https://en.wikipedia.org/wiki?curid=25208936", "title": "Mobile technology", "text": "Mobile technology\n\nMobile technology is the technology used for cellular communication. Mobile code-division multiple access (CDMA) technology has evolved rapidly over the past few years. Since the start of this millennium, a standard mobile device has gone from being no more than a simple two-way pager to being a mobile phone, GPS navigation device, an embedded web browser and instant messaging client, and a handheld gaming console. Many experts believe that the future of computer technology rests in mobile computing with wireless networking. Mobile computing by way of tablet computers are becoming more popular. Tablets are available on the 3G and 4G networks.\n\nIn the early 1980s, 1G was introduced as voice-only communication via \"brick phones\". Later in 1991, the development of 2G introduced Short Message Service (SMS) and Multimedia Messaging Service (MMS) capabilities, allowing picture messages to be sent and received between phones. In 1998, 3G was introduced to provide faster data-transmission speeds to support video calling and internet access. 4G was released in 2008 to support more demanding services such as gaming services, HD mobile TV, video conferencing, and 3D TV. 5G technology has been planned for the upcoming future.\n\n4G is the current mainstream cellular service offered to cell phone users, performance roughly 10 times faster than 3G service. One of the most important features in the 4G mobile networks is the domination of high-speed packet transmissions or burst traffic in the channels. The same codes used in the 2G-3G networks are applied to 4G mobile or wireless networks, the detection of very short bursts will be a serious problem due to their very poor partial correlation properties. Recent study has indicated that traditional multilayer network architecture based on the Open Systems Interconnection (OSI) model may not be well suited for 4G mobile network, where transactions of short packets will be the major part of the traffic in the channels. As the packets from different mobiles carry completely different channel characteristics, the receiver should execute all necessary algorithms, such as channel estimation, interactions with all upper layers and so on, within a very short period of time.\n\nMany types of mobile operating systems (OS) are available for smartphones, including Android, BlackBerry OS, webOS, iOS, Symbian, Windows Mobile Professional (touch screen), Windows Mobile Standard (non-touch screen), and Bada. The most popular are the Apple iPhone, and the newest: Android. Android, a mobile OS developed by Google, is the first completely open-source mobile OS, meaning that it is free to any cell phone mobile network.\n\nSince 2008 customizable OSs allow the user to download apps like games, GPS, utilities, and other tools. Users can also create their own apps and publish them, e.g. to Apple's App Store. The Palm Pre using webOS has functionality over the Internet and can support Internet-based programming languages such as Cascading Style Sheets (CSS), HTML, and JavaScript. The Research In Motion (RIM) BlackBerry is a smartphone with a multimedia player and third-party software installation. The Windows Mobile Professional Smartphones (Pocket PC or Windows Mobile PDA) are like personal digital assistants (PDA) and have touchscreen abilities. The Windows Mobile Standard does not have a touch screen but uses a trackball, touchpad, or rockers.\n\nThere will be a hit to file sharing, the normal web surfer would want to look at a new web page every minute or so at 100 kbs a page loads quickly. Because of the changes to the security of wireless networks users will be unable to do huge file transfers because service providers want to reduce channel use. AT&T claimed that they would ban any of their users that they caught using peer-to-peer (P2P) file sharing applications on their 3G network. It then became apparent that it would keep any of their users from using their iTunes programs. The users would then be forced to find a Wi-Fi hotspot to be able to download files. The limits of wireless networking will not be cured by 4G, as there are too many fundamental differences between wireless networking and other means of Internet access. If wireless vendors do not realize these differences and bandwidth limits, future wireless customers will find themselves disappointed and the market may suffer setbacks.\n\nIncreasing mobile technology use has changed how the modern family interacts with one another through technology. With the rise of mobile devices, families are becoming increasingly \"on-the-move\", and spend less time in physical contact with one another. However, this trend does not mean that families are no longer interacting with each other, but rather have evolved into a more digitized variant. A study has shown that the modern family actually learns better with usage of mobile media, and children are more willing to cooperate with their parents via a digital medium than a more direct approach. For example, family members can share information from articles or online videos via mobile devices and thus stay connected with one another during a busy day.\n\nThis trend is not without controversy, however. Many parents of elementary school-age children express concern and sometimes disapproval of heavy mobile technology use. Parents may feel that excessive usage of such technologies distracts children from \"un-plugged\" bonding experiences, and many express safety concerns about children using mobile media. While parents may have many concerns are, they are not necessarily anti-technology. In fact, many parents express approval of mobile technology usage if their children can learn something from the session. for example, through art or music tutorials on YouTube.\n\nThe next generation of smartphones will be context-aware, taking advantage of the growing availability of embedded physical sensors and data exchange abilities. One of the main features applying to this is that phones will start keeping track of users' personal data, and adapt to anticipate the information will need. All-new applications will come out with the new phones, one of which is an X-ray device that reveals information about any location at which the phone is pointed. Companies are developing software to take advantage of more accurate location-sensing data. This has been described as making the phone a virtual mouse able to click the real world. An example would be pointing the phone's camera at a building while having the live feed open, and the phone will show text with the image of the building, and save its location for use in the future.\n\nOmnitouch is a device via which apps can be viewed and used on a hand, arm, wall, desk, or any other everyday surface. The device uses a sensor touch interface, which enables the user to access all the functions through the use of the touch of a finger. It was developed at Carnegie Mellon University. This device uses a projector and camera worn on the user's shoulder, with no controls other than the user's fingers.\n"}
{"id": "42159582", "url": "https://en.wikipedia.org/wiki?curid=42159582", "title": "Mobiles for development", "text": "Mobiles for development\n\nMobiles for Development (M4D), a more specific iteration of Information and Communication Technologies for Development (ICT4D), refers to the use of mobile technologies in global development strategies. Focusing on the fields of international and socioeconomic development and human rights, M4D relies on the theory that increased access to mobile devices acts as an integral cornerstone in the promotion of overall societal development.\n\nOnce viewed as an item of luxury and privilege, mobile phones and devices have become a near necessity throughout the developed and developing world alike. According to a 2007 United Nations study, over two thirds of the world’s mobile phones are owned and utilized within developing countries. With less-developed wired infrastructure and the high cost associated with its modernization and implementation, the adoption of cellular technologies can be attributed to a necessary leapfrogging of traditional telephony and communication technologies. In addition, the unsound and undependable electrical infrastructure of many developing countries does not cater well to mass hardwired ICT adoption. The portability, battery power, and flexibility of mobile technologies is well suited to the common pursuits and lifestyles of those residing in the developing world.\n\nThis mass adoption of ICTs and mobile phones as well the increased quality and expanse of signal coverage within many developing countries has led to increased academic, socioeconomic, and political attention as the various impacts of the M4D movement continue to expand. In addition to the predictable developmental outcomes of mobile adoption including increased economic agency, unforeseen progress has been experienced in the forms of individual empowerment, female agency, as well as familial and community growth.\n\nThe opportunities for effective mass mobilization and aggregation of information and data offered by developmental movements utilizing cellular telephones and other mobile devices such as tablets have been widely featured in the mass media and academia. Literature on this matter is being steadily produced as developing countries continue to adopt mobile technologies at a remarkable rate.\n\nRecent developments in mobile communication and computation technologies have led to the expansion of mobile phone, smartphone, tablet computer, and netbook ownership. Typically marketed to the developed world as supplementary to standard laptops and desktop computers, these electronic products often offer lower price points to the consumer. This lower price point caters well to developing countries and their rapidly evolving markets for ICT expansion and adoption. These mobile devices come equipped with basic mobile communications hard and software such as WiFi and 3G services which allow users to connect to the Internet via mobile and wireless networks without having to secure a landline or an expensive broadband connection via DSL, cable Internet or fiber optics. This leapfrogging movement towards the acceptance and implementation of mobile technologies made the Internet and modern digital telecommunications more accessible to people, particularly those in emerging markets and developing countries.\n\nAccording to International Telecommunication Union, mobile ICTs have emerged as the primary form of technology that will offer a bridge within the digital divide. Data collected by the ITU shows the trajectory of mobile technologies as their adoption out-paces and even replaces the adoption of desktop computers and standard laptops.\n\nThe International Telecommunication Union estimates that as of 2013, approximately 6.8 billion mobile-cellular subscriptions are held worldwide, 5.2 billion of which are held in developing countries. These numbers stand in stark contrast to the penetration rate of fixed-telephone subscriptions which stand at approximately 1.2 billion worldwide, a small margin over half of which belong to the developing world.\n\nThe following table displays key ICT indicators for developed and developing countries as well as world totals from 2010 to 2013:\n\nThe trends displayed in the table above are further supported by the successful sales reports of technology companies selling mobile technologies in emerging markets within developing countries. Some multinational computer manufacturers like Acer and Lenovo are marketing more affordable netbooks to emerging markets such as those in China, Indonesia and India.\n\nOriginally a concept used in reference to economic growth theories and industrialization, leapfrogging has more recently been used in the context of sustainable development for developing countries within world development theories. Technological leapfrogging refers to the acceleration of development through the skipping of low-grade, less efficient, and more costly technologies and industries in favour of the direct adoption of more effective and advanced technologies.\n\nIn the case of M4D, the trajectory of the rapid mass adoption of mobile technologies can be attributed to the \"mobile leapfrog effect\", whereby many developing countries have been seen to bypass traditional routes of wired telephony and broadband infrastructure and development, opting instead for the immediate appropriation of wireless cellular and broadband technology. This mobile leapfrogging can be attributed to the lengthy process and high cost of wired infrastructure implementation. Additionally, as seen in mobile adoption in the Arab States, wired infrastructure that predates mobile technology is often old, outdated, and incapable of data transmission, \"the basic requirement for implementing Digital Subscriber Line (DSL) services\".\n\nMobile ICT platforms and their wide adoption in developing countries serves as an ideal example of leapfrog technology and current practices of leapfrogging within the sustainable development of developing countries. By enabling developing countries to “leapfrog” over legacy technologies of the wired telephone and Internet service of the 20th century and embrace the mobile technologies of the 21st century, opportunities to bridge the Digital divide have been argued to become more prevalent.\n\nThe term ‘mobile hack’ refers to the use-based practices of mobile technology that goes beyond the use intended by the creators of the device. Often used in order to circumvent the high cost of mobile ownership and use, mobile hacks have become common practice in many developing countries. Mobile hacks have also proven to be widespread in the adoption of mobile technologies in developing countries. Device sharing, the ‘Missed Call’ technique, and the transferring of mobile credits has allowed for individuals who were previously isolated from digital communication the opportunity to economically engage in the networked community.\n\nDevice sharing, most commonly the sharing of mobile telephones, refers to the practice of sharing a mobile device between a number of individuals either within a family or a community.\n\nThe 'Missed call' technique refers to the establishment of a code that works around connection charges by utilizing a specified number of rings prior to cutting a call. This method avoids call charge and uses discreet codes to convey messages. This technique goes against the profit models of mobile service providers and allows for individuals to communicate messages in a cost-effective manner.\n\nThrough the transfer of mobile credits, mobile device owners are able to use credits of an amount specified by their service provider as a means of monetary transaction. By sending credits to another's mobile device, an exchange of cash can be made in situations that it is necessitated.\n\nAccording to the ITU's report \"Measuring the Information Society,\" mobile phones and other mobile ICT devices are seen to be replacing standard laptops and desktop computers as the main platform for Internet and ICT access and use. This increased access to and use of mobile phones offers individuals a handheld communication platform that can assist in expanding the level of citizen agency in the development of local and international social, economic, and political endeavours. It also offers individuals the opportunity to form social, economic, and political communities, regardless of geographic location, and provides an at-hand device that allows individuals to fight against human rights abuses from the ground. Organizations such as Digital Democracy (Dd) and the Democratic Voice of Burma offers users the ability to report, compile, and disseminate news and information about human rights violations in order to effectuate global attention and action.\n\nIn the establishment and fostering of mobile citizens within developing countries, a \"bottom of the pyramid\" corporate approach has been encouraged in order to \"convert poverty into a business opportunity that benefits everyone.\"\n\n\nAccording to a report by InfoDev, “[h]ealth conditions in rural areas are generally poorer, and access to information, services, and supplies is most limited.” With the rapid worldwide adoption of mobile technology, a range of health-related areas such as the improvement of public health information dissemination, the facilitation of remote consultation, diagnosis, and treatment, the sharing of a patient’s health information between health professional, and the monitoring and increased efficiency of public health systems have adopted and benefited from mobile based practices.\n\nStudies have suggested that the use of mobile capabilities such as text message reminders regarding dosage information and the increased communication between health professionals has allowed for increased effectiveness in treatment and control of disease. Cases of mobile technology being effectively piloted and utilized in the area of public health exhibits the promise of M4D programs and practices in the spheres of health prevention and medical care for the world’s developing nations.\n\nThe following lists a sampling of programs utilizing M4D strategies for the improvement of public health in developing countries around the world:\n\n\nThe ability to mobilize data aggregation to the mobile-carrying public offers NGOs a valuable resource for their efforts for social, political, economic, and environmental justice. According to a study published by the Vodafone Group Foundation and the UN Foundation Partnership, of a sample of over 500 NGOs, “eighty-six per cent used mobiles, with 99 per cent characterizing its utility positively, with one-quarter of those citing it as a ‘revolutionary’ technology and another one-third calling it indispensable for their work.”. The benefits perceived by M4D initiatives include their \"ability to mobilize and aggregate information and data more effectively and to a wider audience\" as well as their time-saving qualities in the fields of social justice, environmental conservation, global health and humanitarian assistance.\n\nThe following lists organizations engaging in M4D strategies and programming:\n\n\nThe potential for the expansion and replication of M4D projects has been recognized as vital to the overall success of this development practice. The sharing and exchange of information and technical advancements can allow for easier and less costly adoption in other developing countries however, many of the organizations creating and implementing M4D projects act within 'innovation silos'. This siloing of information threatens to create and solidify boundaries between organizations and mobile development projects.\n\nThe environmental implications of increased mobile usage can be seen in the form of the large electronic waste dumps found in many of the developing countries meant to benefit from M4D programs and policies.\n\nIn addition, it has been argued that the introduction of mobile information and communication technologies could result in the proliferation of the Matthew effect, whereby the \"rich get richer.\" In the case of mobile adoption, the inequalities of wealth considered encompass both economic and knowledge-based wealth. Despite the benefits attributed to the adoption and use of mobile ICTs for development purposes, the information and communication resources in question have been initially created and adopted within already developed countries.\n\nAlso problematic is the potential for mobile hardware and software development in developing countries to become a purely for-profit endeavour. As stated by a UN Foundation-Vodafone Group Foundation Partnership publication, \"the potential for scaling up 'mobile for good' initiatives may come with identifying commercial incentives.\" The free and open source software applications that have been developed and implemented by various NGOs in developing countries as well as the ad-hoc communal use of mobile devices could be threatened by the prospective monetization of the mass markets available in the developing world.\n\n"}
{"id": "4458701", "url": "https://en.wikipedia.org/wiki?curid=4458701", "title": "Molinology", "text": "Molinology\n\nMolinology (from Latin: molīna, mill; and Greek λόγος, study) is the study of mills and other mechanical devices which use the energy of moving water or wind, or the strength of animal or human muscle to power machines for purposes such as hammering, grinding, pumping, sawing, pressing or fulling. More particularly, molinology aims to retain the knowledge of those traditional engines which have been rendered obsolete by modern technical and economic trends. \n\nThe term \"Molinology\" was coined in 1965 by the Portuguese industrial historian João Miguel dos Santos Simões. \n\nCultural and scientific interest in molinology is maintained by The International Molinological Society (TIMS), a non-profit organisation which brings together around five hundred members worldwide. It was founded in 1973 after earlier international symposia in 1965 and 1969.\n\n\n\n"}
{"id": "47911144", "url": "https://en.wikipedia.org/wiki?curid=47911144", "title": "Narrowband IoT", "text": "Narrowband IoT\n\nNarrowband IoT (NB-IoT) is a Low Power Wide Area Network (LPWAN) radio technology standard developed by 3GPP to enable a wide range of cellular devices and services. The specification was frozen in 3GPP Release 13 (LTE Advanced Pro), in June 2016. Other 3GPP IoT technologies include eMTC (enhanced Machine-Type Communication) and EC-GSM-IoT. \n\nNB-IoT focuses specifically on indoor coverage, low cost, long battery life, and high connection density. NB-IoT uses a subset of the LTE standard, but limits the bandwidth to a single narrow-band of 200kHz. It uses OFDM modulation for downlink communication and SC-FDMA for uplink communications. \n\n\n"}
{"id": "639115", "url": "https://en.wikipedia.org/wiki?curid=639115", "title": "Neolithic Revolution", "text": "Neolithic Revolution\n\nThe Neolithic Revolution, Neolithic Demographic Transition, Agricultural Revolution, or First Agricultural Revolution was the wide-scale transition of many human cultures during the Neolithic period from a lifestyle of hunting and gathering to one of agriculture and settlement, making an increasingly larger population possible. These settled communities permitted humans to observe and experiment with plants to learn how they grew and developed. This new knowledge led to the domestication of plants.\n\nArchaeological data indicates that the domestication of various types of plants and animals happened in separate locations worldwide, starting in the geological epoch of the Holocene around 12,500 years ago. It was the world's first historically verifiable revolution in agriculture. The Neolithic Revolution greatly narrowed the diversity of foods available, resulting in a downturn in human nutrition.\n\nThe Neolithic Revolution involved far more than the adoption of a limited set of food-producing techniques. During the next millennia it would transform the small and mobile groups of hunter-gatherers that had hitherto dominated human pre-history into sedentary (non-nomadic) societies based in built-up villages and towns. These societies radically modified their natural environment by means of specialized food-crop cultivation, with activities such as irrigation and deforestation which allowed the production of surplus food. Other developments found very widely are the domestication of animals, pottery, polished stone tools, and rectangular houses.\n\nThese developments, sometimes called the Neolithic package, provided the basis for centralized administrations and political structures, hierarchical ideologies, depersonalized systems of knowledge (e.g. writing), densely populated settlements, specialization and division of labour, more trade, the development of non-portable art and architecture, and property ownership. The earliest known civilization developed in Sumer in southern Mesopotamia (); its emergence also heralded the beginning of the Bronze Age.\n\nThe relationship of the above-mentioned Neolithic characteristics to the onset of agriculture, their sequence of emergence, and empirical relation to each other at various Neolithic sites remains the subject of academic debate, and varies from place to place, rather than being the outcome of universal laws of social evolution. The Levant saw the earliest developments of the Neolithic Revolution from around 10,000 BCE, followed by sites in the wider Fertile Crescent.\n\nThe term \"Neolithic Revolution\" was coined in 1923 by V. Gordon Childe to describe the first in a series of agricultural revolutions in Middle Eastern history. The period is described as a \"revolution\" to denote its importance, and the great significance and degree of change affecting the communities in which new agricultural practices were gradually adopted and refined.\n\nThe beginning of this process in different regions has been dated from 10,000 to 8,000 BC in the Fertile Crescent and perhaps 8000 BC in the Kuk Early Agricultural Site of Melanesia. This transition everywhere seems associated with a change from a largely nomadic hunter-gatherer way of life to a more settled, agrarian-based one, with the inception of the domestication of various plant and animal species—depending on the species locally available, and probably also influenced by local culture. Recent archaeological research suggests that in some regions such as the Southeast Asian peninsula, the transition from hunter-gatherer to agriculturalist was not linear, but region-specific.\n\nThere are several competing (but not mutually exclusive) theories as to the factors that drove populations to take up agriculture. The most prominent of these are:\n\nOnce agriculture started gaining momentum, around 9000 BC, human activity resulted in the selective breeding of cereal grasses (beginning with emmer, einkorn and barley), and not simply of those that would favour greater caloric returns through larger seeds. Plants with traits such as small seeds or bitter taste would have been seen as undesirable. Plants that rapidly shed their seeds on maturity tended not to be gathered at harvest, therefore not stored and not seeded the following season; years of harvesting selected for strains that retained their edible seeds longer.\n\nSeveral plant species, the \"pioneer crops\" or Neolithic founder crops, were identified by Daniel Zohary, who highlighted the importance of the three cereals, and suggested that domestication of flax, peas, chickpeas, bitter vetch and lentils came a little later. Based on analysis of the genes of domesticated plants, he preferred theories of a single, or at most a very small number of domestication events for each taxon that spread in an arc from the Levantine corridor around the Fertile Crescent and later into Europe. Gordon Hillman and Stuart Davies carried out experiments with wild wheat varieties to show that the process of domestication would have occurred over a relatively short period of between 20 and 200 years. Some of these pioneering attempts failed at first and crops were abandoned, sometimes to be taken up again and successfully domesticated thousands of years later: rye, tried and abandoned in Neolithic Anatolia, made its way to Europe as weed seeds and was successfully domesticated in Europe, thousands of years after the earliest agriculture. Wild lentils presented a different problem: most of the wild seeds do not germinate in the first year; the first evidence of lentil domestication, breaking dormancy in their first year, was found in the early Neolithic at Jerf el Ahmar (in modern Syria), and quickly spread south to the Netiv HaGdud site in the Jordan Valley. This process of domestication allowed the founder crops to adapt and eventually become larger, more easily harvested, more dependable in storage and more useful to the human population.\n\nSelectively propagated figs, wild barley and wild oats were cultivated at the early Neolithic site of Gilgal I, where in 2006 archaeologists found caches of seeds of each in quantities too large to be accounted for even by intensive gathering, at strata datable to c. 11,000 years ago. Some of the plants tried and then abandoned during the Neolithic period in the Ancient Near East, at sites like Gilgal, were later successfully domesticated in other parts of the world.\n\nOnce early farmers perfected their agricultural techniques like irrigation, their crops would yield surpluses that needed storage. Most hunter gatherers could not easily store food for long due to their migratory lifestyle, whereas those with a sedentary dwelling could store their surplus grain. Eventually granaries were developed that allowed villages to store their seeds longer. So with more food, the population expanded and communities developed specialized workers and more advanced tools.\n\nThe process was not as linear as was once thought, but a more complicated effort, which was undertaken by different human populations in different regions in many different ways.\n\nEarly agriculture is believed to have originated and become widespread in Southwest Asia around 10,000–9,000 BP, though earlier individual sites have been identified. The Fertile Crescent region of Southwest Asia is the centre of domestication for three cereals (einkorn wheat, emmer wheat and barley), four legumes (lentil, pea, bitter vetch and chickpea), and flax. Domestication was a slow process involving multiple sites for each crop.\n\nFinds of large quantities of seeds and a grinding stone at the paleolithic site of Ohalo II in the vicinity of the Sea of Galilee, dated to around 19,400 BP, has shown some of the earliest evidence for advanced planning of plant food consumption and suggests that humans at Ohalo II processed the grain before consumption. Tell Aswad is the oldest site of agriculture, with domesticated emmer wheat dated to 10,800 BP. Soon after came hulled, two-row barley found domesticated earliest at Jericho in the Jordan valley and Iraq ed-Dubb in Jordan. Other sites in the Levantine corridor that show the first evidence of agriculture include Wadi Faynan 16 and Netiv Hagdud. Jacques Cauvin noted that the settlers of Aswad did not domesticate on site, but \"arrived, perhaps from the neighbouring Anti-Lebanon, already equipped with the seed for planting\". In the Eastern Fertile Crescent, evidence of cultivation of wild plants has been found in Choga Gholan in Iran dated to 12,000 BP, suggesting there were multiple regions in the Fertile Crescent where domestication evolved roughly contemporaneously. The Heavy Neolithic Qaraoun culture has been identified at around fifty sites in Lebanon around the source springs of the River Jordan, but never reliably dated.\n\nNorthern China appears to have been the domestication center for foxtail millet (\"Setaria italica\") and broomcorn millet (\"Panicum miliaceum\") with evidence of domestication of these species approximately 8,000 years ago.<ref name=\"doi10.1093/aob/mcm048\"></ref> These species were subsequently widely cultivated in the Yellow River basin (7,500 years ago). Rice was domesticated in southern China later on. Soybean was domesticated in northern China 4,500 years ago. Orange and peach also originated in China. They were cultivated around 2500 BC.\nOn the African continent, three areas have been identified as independently developing agriculture: the Ethiopian highlands, the Sahel and West Africa. By contrast, Agriculture in the Nile River Valley is thought to have developed from the original Neolithic Revolution in the Fertile Crescent. \nMany grinding stones are found with the early Egyptian Sebilian and Mechian cultures and evidence has been found of a neolithic domesticated crop-based economy dating around 7,000 BP.\nUnlike the Middle East, this evidence appears as a \"false dawn\" to agriculture, as the sites were later abandoned, and permanent farming then was delayed until 6,500 BP with the Tasian and Badarian cultures and the arrival of crops and animals from the Near East.\n\nBananas and plantains, which were first domesticated in Southeast Asia, most likely Papua New Guinea, were re-domesticated in Africa possibly as early as 5,000 years ago. Asian yams and taro were also cultivated in Africa.\n\nThe most famous crop domesticated in the Ethiopian highlands is coffee. In addition, khat, ensete, noog, teff and finger millet were also domesticated in the Ethiopian highlands. Crops domesticated in the Sahel region include sorghum and pearl millet. The kola nut was first domesticated in West Africa. Other crops domesticated in West Africa include African rice, yams and the oil palm.\n\nAgriculture spread to Central and Southern Africa in the Bantu expansion during the 1st millennium BC to 1st millennium AD.\n\nMaize (corn), beans and squash were among the earliest crops domesticated in Mesoamerica, with maize beginning about 4000 BC, squash as early as 6000 BC, and beans by no later than 4000 BC. Potatoes and manioc were domesticated in South America. In what is now the eastern United States, Native Americans domesticated sunflower, sumpweed and goosefoot around 2500 BC. Sedentary village life based on farming did not develop until the second millennium BC, referred to as the formative period.\n\nEvidence of drainage ditches at Kuk Swamp on the borders of the Western and Southern Highlands of Papua New Guinea shows evidence of the cultivation of taro and a variety of other crops, dating back to 11,000 BP. Two potentially significant economic species, taro (\"Colocasia esculenta\") and yam (\"Dioscorea\" sp.), have been identified dating at least to 10,200 calibrated years before present (cal BP). Further evidence of bananas and sugarcane dates to 6,950 to 6,440 BP. This was at the altitudinal limits of these crops, and it has been suggested that cultivation in more favourable ranges in the lowlands may have been even earlier. CSIRO has found evidence that taro was introduced into the Solomon Islands for human use, from 28,000 years ago, making taro cultivation the earliest crop in the world. It seems to have resulted in the spread of the Trans–New Guinea languages from New Guinea east into the Solomon Islands and west into Timor and adjacent areas of Indonesia. This seems to confirm the theories of Carl Sauer who, in \"Agricultural Origins and Dispersals\", suggested as early as 1952 that this region was a centre of early agriculture.\n\nWhen hunter-gathering began to be replaced by sedentary food production it became more profitable to keep animals close at hand. Therefore, it became necessary to bring animals permanently to their settlements, although in many cases there was a distinction between relatively sedentary farmers and nomadic herders. The animals' size, temperament, diet, mating patterns, and life span were factors in the desire and success in domesticating animals. Animals that provided milk, such as cows and goats, offered a source of protein that was renewable and therefore quite valuable. The animal’s ability as a worker (for example ploughing or towing), as well as a food source, also had to be taken into account. Besides being a direct source of food, certain animals could provide leather, wool, hides, and fertilizer. Some of the earliest domesticated animals included dogs (East Asia, about 15,000 years ago), sheep, goats, cows, and pigs.\n\nThe Middle East served as the source for many animals that could be domesticated, such as sheep, goats and pigs. This area was also the first region to domesticate the dromedary. Henri Fleisch discovered and termed the Shepherd Neolithic flint industry from the Bekaa Valley in Lebanon and suggested that it could have been used by the earliest nomadic shepherds. He dated this industry to the Epipaleolithic or Pre-Pottery Neolithic as it is evidently not Paleolithic, Mesolithic or even Pottery Neolithic. The presence of these animals gave the region a large advantage in cultural and economic development. As the climate in the Middle East changed and became drier, many of the farmers were forced to leave, taking their domesticated animals with them. It was this massive emigration from the Middle East that would later help distribute these animals to the rest of Afroeurasia. This emigration was mainly on an east-west axis of similar climates, as crops usually have a narrow optimal climatic range outside of which they cannot grow for reasons of light or rain changes. For instance, wheat does not normally grow in tropical climates, just like tropical crops such as bananas do not grow in colder climates. Some authors, like Jared Diamond, have postulated that this East-West axis is the main reason why plant and animal domestication spread so quickly from the Fertile Crescent to the rest of Eurasia and North Africa, while it did not reach through the North-South axis of Africa to reach the Mediterranean climates of South Africa, where temperate crops were successfully imported by ships in the last 500 years. Similarly, the African Zebu of central Africa and the domesticated bovines of the fertile-crescent — separated by the dry sahara desert — were not introduced into each other's region.\n\nDespite the significant technological advance, the Neolithic revolution did not lead immediately to a rapid growth of population. Its benefits appear to have been offset by various adverse effects,\nmostly diseases and warfare.\n\nThe introduction of agriculture has not necessarily led to unequivocal progress. The nutritional standards of the growing Neolithic populations were inferior to that of hunter-gatherers. Several ethnological and archaeological studies conclude that the transition to cereal-based diets caused a reduction in life expectancy and stature, an increase in infant mortality and infectious diseases, the development of chronic, inflammatory or degenerative diseases (such as obesity, type 2 diabetes and cardiovascular diseases) and multiple nutritional deficiencies, including vitamin deficiencies, iron deficiency anemia and mineral disorders affecting bones (such as osteoporosis and rickets) and teeth. Average height went down from 5'10\" (178 cm) for men and 5'6\" (168 cm) for women to 5'5\" (165 cm) and 5'1\" (155 cm), respectively, and it took until the twentieth century for average human height to come back to the pre-Neolithic Revolution levels.\n\nThe traditional view is that agricultural food production supported a denser population, which in turn supported larger sedentary communities, the accumulation of goods and tools, and specialization in diverse forms of new labor. The development of larger societies led to the development of different means of decision making and to governmental organization. Food surpluses made possible the development of a social elite who were not otherwise engaged in agriculture, industry or commerce, but dominated their communities by other means and monopolized decision-making. Jared Diamond (in The World Until Yesterday) identifies the availability of milk and cereal grains as permitting mothers to raise both an older (e.g. 3 or 4 year old) and a younger child concurrently. The result is that a population can increase more rapidly. Diamond, in agreement with feminist scholars such as V. Spike Peterson, points out that agriculture brought about deep social divisions and encouraged gender inequality. \n\nAndrew Sherratt has argued that following upon the Neolithic Revolution was a second phase of discovery that he refers to as the secondary products revolution. Animals, it appears, were first domesticated purely as a source of meat. The Secondary Products Revolution occurred when it was recognised that animals also provided a number of other useful products. These included:\n\nSherratt argued that this phase in agricultural development enabled humans to make use of the energy possibilities of their animals in new ways, and permitted permanent intensive subsistence farming and crop production, and the opening up of heavier soils for farming. It also made possible nomadic pastoralism in semi arid areas, along the margins of deserts, and eventually led to the domestication of both the dromedary and Bactrian camel. Overgrazing of these areas, particularly by herds of goats, greatly extended the areal extent of deserts.\n\nLiving in one spot would have more easily permitted the accrual of personal possessions and an attachment to certain areas of land. From such a position, it is argued, prehistoric people were able to stockpile food to survive lean times and trade unwanted surpluses with others. Once trade and a secure food supply were established, populations could grow, and society would have diversified into food producers and artisans, who could afford to develop their trade by virtue of the free time they enjoyed because of a surplus of food. The artisans, in turn, were able to develop technology such as metal weapons. Such relative complexity would have required some form of social organisation to work efficiently, so it is likely that populations that had such organisation, perhaps such as that provided by religion, were better prepared and more successful. In addition, the denser populations could form and support legions of professional soldiers. Also, during this time property ownership became increasingly important to all people. Ultimately, Childe argued that this growing social complexity, all rooted in the original decision to settle, led to a second Urban Revolution in which the first cities were built.\n\nThroughout the development of sedentary societies, disease spread more rapidly than it had during the time in which hunter-gatherer societies existed. Inadequate sanitary practices and the domestication of animals may explain the rise in deaths and sickness following the Neolithic Revolution, as diseases jumped from the animal to the human population. Some examples of infectious diseases spread from animals to humans are influenza, smallpox, and measles. In concordance with a process of natural selection, the humans who first domesticated the big mammals quickly built up immunities to the diseases as within each generation the individuals with better immunities had better chances of survival. In their approximately 10,000 years of shared proximity with animals, such as cows, Eurasians and Africans became more resistant to those diseases compared with the indigenous populations encountered outside Eurasia and Africa. For instance, the population of most Caribbean and several Pacific Islands have been completely wiped out by diseases. 90% or more of many populations of the Americas were wiped out by European and African diseases before recorded contact with European explorers or colonists. Some cultures like the Inca Empire did have a large domestic mammal, the llama, but llama milk was not drunk, nor did llamas live in a closed space with humans, so the risk of contagion was limited. According to bioarchaeological research, the effects of agriculture on physical and dental health in Southeast Asian rice farming societies from 4000 to 1500 B.P. was not detrimental to the same extent as in other world regions.\n\nIn his book \"Guns, Germs, and Steel\", Jared Diamond argues that Europeans and East Asians benefited from an advantageous geographical location that afforded them a head start in the Neolithic Revolution. Both shared the temperate climate ideal for the first agricultural settings, both were near a number of easily domesticable plant and animal species, and both were safer from attacks of other people than civilizations in the middle part of the Eurasian continent. Being among the first to adopt agriculture and sedentary lifestyles, and neighboring other early agricultural societies with whom they could compete and trade, both Europeans and East Asians were also among the first to benefit from technologies such as firearms and steel swords.\nThe dispersal of Neolithic culture from the Middle East has recently been associated with the distribution of human genetic markers. In Europe, the spread of the Neolithic culture has been associated with distribution of the E1b1b lineages and Haplogroup J that are thought to have arrived in Europe from North Africa and the Near East respectively. In Africa, the spread of farming, and notably the Bantu expansion, is associated with the dispersal of Y-chromosome haplogroup E1b1a from West Africa.\n\n\n\n"}
{"id": "2165622", "url": "https://en.wikipedia.org/wiki?curid=2165622", "title": "Neophile", "text": "Neophile\n\nNeophile or Neophiliac, a term popularised by cult writer Robert Anton Wilson, is a personality type characterized by a strong affinity for novelty. The term was used earlier by Christopher Booker in his book The Neophiliacs (1969), and by J. D. Salinger in his short story Hapworth 16, 1924 (1965).\n\nNeophiles/Neophiliacs have the following basic characteristics:\n\n\nA neophile is distinct from a revolutionary in that anyone might become a revolutionary if pushed far enough by the reigning authorities or social norms, whereas neophiles are revolutionaries by nature. Their intellectual abhorrence of tradition and repetition usually bemoans a deeper emotional need for constant novelty and change. The meaning of neophile approaches and is not mutually exclusive to the term visionary, but differs in that a neophile actively seeks first-hand experience of novelty rather than merely pontificating about it.\n\nThe opposite of a neophile is a neophobe; a person with an aversion to novelty and change. Wilson observes that neophobes tend to regard neophiles, especially extreme ones, with fear and contempt, and to brand them with titles such as \"witch,\" \"satanist,\" \"heretic,\" etc. He also speculates in his Prometheus Rising series of books that the industrial revolution and related enlightenment represents one of the first periods of history in which neophiles were a dominant force in society. Neophiles accelerate change because they like it that way.\n\nOpen-source advocate and programmer Eric S. Raymond observes that this personality is especially prevalent in certain fields of expertise; in business, these are primarily computer science and other areas of high technology. Raymond speculates that the rapid progress of these fields (especially computers) is a result of this. A neophile's love of novelty is likely to lead them into subjects outside of the normal areas of human interest. Raymond observes a high concentration of neophiles in or around what he calls \"leading edge subcultures\" such as science fiction fandom, neo-paganism, transhumanism, etc. as well as in or around nontraditional areas of thought such as fringe philosophy or the occult. Raymond observes that most neophiles have roving interests and tend to be widely well-read.\n\nThere is more than one type of neophile. There are social neophiles (the extreme social butterfly), intellectual neophiles (the revolutionary philosopher and the technophile), and physical/kinetic neophiles (the extreme sports enthusiast). These tendencies are not mutually exclusive, and might exist simultaneously in the same individual.\n\nThe word \"neophilia\" has particular significance in Internet and hacker culture. \"The New Hacker's Dictionary\" gave the following definition to neophilia:\n\nThe trait of being excited and pleased by novelty. Common among most hackers, SF fans, and members of several other connected leading-edge subcultures, including the pro-technology 'Whole Earth' wing of the ecology movement, space activists, many members of Mensa, and the Discordian/neo-pagan underground (see geek). All these groups overlap heavily and (where evidence is available) seem to share characteristic hacker tropisms for science fiction, music.\n\nResearch has uncovered a possible link between certain predisposition to some kind of neophilia and increased levels of the enzyme monoamine oxidase A.\n\n\n"}
{"id": "15450044", "url": "https://en.wikipedia.org/wiki?curid=15450044", "title": "Normalization process theory", "text": "Normalization process theory\n\nNormalization process theory (NPT) is a derivative sociological theory of the implementation, embedding, and integration of new technologies and organizational innovations developed originally from a collective set of learning workshops and included a large number of people including Carl R. May, Tracy Finch, Elizabeth Murray, Anne Rogers, Catherine Pope, Anne Kennedy, Pauline Ong and . The theory is a contribution to the field of science and technology studies (STS), and is the result of a programme of theory building by May and a range of academics from applied social science to medicine. Through three iterations, the theory has built upon the normalization process model previously developed by May et al. to explain the social processes that lead to the routine embedding of innovative health technologies.\n\nNormalization process theory focuses attention on agentic contributions – the things that individuals and groups do to operationalize new or modified modes of practice as they interact with dynamic elements of their environments. It defines the implementation, embedding, and integration as a process that occurs when participants deliberately initiate and seek to sustain a sequence of events that bring it into operation. The dynamics of implementation processes are complex, but normalization process theory facilitates understanding by focusing attention on the mechanisms through which participants invest and contribute to them. It reveals \"the work that actors do as they engage with some ensemble of activities (that may include new or changed ways of thinking, acting, and organizing) and by which means it becomes routinely embedded in the matrices of already existing, socially patterned, knowledge and practices\". These have explored objects, agents, and contexts. In a paper published under a creative commons license, May and colleagues describe how, since 2006, NPT has undergone three iterations.\n\n\nNormalization process theory is regarded as a middle range theory that is located within the 'turn to materiality' in STS. It therefore fits well with the case-study oriented approach to empirical investigation used in STS. It also appears to be a straightforward alternative to actor–network theory in that it does not insist on the agency of non-human actors, and seeks to be explanatory rather than descriptive. However, because normalization process theory specifies a set of generative mechanisms that empirical investigation has shown to be relevant to implementation and integration of new technologies, it can also be used in larger scale structured and comparative studies. Although it fits well with the interpretive approach of ethnography and other qualitative research methods, it also lends itself to systematic review and survey research methods. As a middle range theory, it can be federated with other theories to explain empirical phenomena. It is compatible with theories of the transmission and organization of innovations, especially diffusion of innovations theory, labor process theory, and psychological theories including the theory of planned behavior and social learning theory.\n"}
{"id": "7531440", "url": "https://en.wikipedia.org/wiki?curid=7531440", "title": "Outline of information technology", "text": "Outline of information technology\n\nThe following outline is provided as an overview of and topical guide to information technology:\n\nInformation technology (IT) – microelectronics based combination of computing and telecommunications technology to treat information, including in the acquisition, processing, storage and dissemination of vocal, pictorial, textual and numerical information. It is defined by the Information Technology Association of America (ITAA) as \"the study, design, development, implementation, support or management of computer-based information systems, particularly software applications and computer hardware.\"\n\nThere are different names for this at different periods or through fields. Some of these names are:\n\n\n\nThird-party commercial organizations and vendor neutral interest groups that sponsor certifications include:\n\nGeneral certification of software practitioners has struggled. The ACM had a professional certification program in the early 1980s, which was discontinued due to lack of interest. Today, the IEEE is certifying software professionals, but only about 500 people have passed the exam .\n\n\n\n\n"}
{"id": "57169337", "url": "https://en.wikipedia.org/wiki?curid=57169337", "title": "Phandeeyar", "text": "Phandeeyar\n\nPhandeeyar (standing for \"creation place\") is a technology seed accelerator based in Yangon, Myanmar. Formally beginning in 2015, Phandeeyar provides funding and training for emerging startups. Phandeeyar also conducts trainings, hosts workshops, and holds competitions for startups within the digital sector.\n\nIn 2014, Phandeeyar emerged from a hackathon named \"Code for Change Myanmar\" where its founder and current CEO, David Madden, wanted to promote the growth of Myanmar's digital sector. Through this hackathon, politics and elections were addressed. \n\nMadden states the need for better financial support for emerging start-ups in Myanmar which also led to the creation of the accelerator.\n\nPhandeeyar's sponsors and investors include the Omidyar Network which has donated 2 million US dollars to the company, the United States Institute of Peace, the Open Society Foundation, and the Schmidt Family Foundation.\n\nDavid Madden states that Phandeeyar's objective is to connect those in the tech field with others actively working in the social sector through different events. \n\nIn 2015, Phandeeyar hosted a two week event event called \"MaePaySoe\" (translating to \"let's vote\") where more than one hundred web developers gathered to create technology which informs the general public about potential political candidates in Myanmar and the country's voting process.\nIn 2016, around fifteen to twenty startups were projected to be accepted into the accelerator in a three year span. Phandeeyar also plans to invest around $2 million into startups in the near future. From the startups accepted, Phandeeyar would claim a 12 percent ownership of the companies. \nThose selected for Phandeeyar's 6 month training program would receive a funding of $25,000 to launch their ventures in addition to business partnerships to help with the early stages of their startups. These partnerships include leaders from regional companies such as the Myanmar Information Technology, CarsDB, Muru-D. and Golden Gate Ventures. Towards the end of the program, companies have the opportunity to pitch their startup ideas to venture capitalists and angel investors. \n\nChate Sat is a digital platform to connect freelance workers with employers to find jobs. After its launch from Phandeeyar, Chate Sat recruited around 800 businesses looking to contract work and 5,000 freelancers. Chate Sat also received funding from some investors such as Vulpes Investment Management Ltd. \n\nGoP is an online, tourism-based website that compiles different traveling information into one platform. Nyunt Win Aung, one of the company's co-founders, states that its increased website traffic will increase their bookings, directly as a result of more funding. \n\nWhite Merak is a phone application used to read comics made by local artists and the company's team. Additionally, this platform shows animated comics, as well as a bilingual setting where users can switch comic text from Burmese to English and vice versa. \n\nEZ Stay is an online hotel booking platform co-founded by Aung Phyo Lwi focused on informing those traveling to Myanmar about different hotel and motel availabilities. According to Aung Phyo Lwi, this website can better market local Myanmar businesses.\n\nIn April 2018, Myanmar civil rights groups and Myanmar-based technology companies accused Facebook of failing to effectively detect hate speech online in Myanmar, which many have claimed to have contributed to an anti-Rohingya sentiment in the country. Phandeeyar, along with other companies, released an open letter to the social media platform, posing questions about Facebook's transparency in accordance with these issues and the possible implications of social media with current events in Myanmar.\n"}
{"id": "2074318", "url": "https://en.wikipedia.org/wiki?curid=2074318", "title": "RailTel Corporation of India", "text": "RailTel Corporation of India\n\nRailTel Corporation of India Ltd. is a \"Miniratna\" (public sector) enterprise of Government of India focusing on providing broadband and VPN services. RailTel was formed in September 2000 with the objective of creating nationwide broadband, telecom and multimedia network, to modernise train control operation and safety system of Indian Railways. RailTel's network passes through around 5,000 stations across the country, covering all major commercial centres.\n\nThe Indian Railways (IR) was initially solely dependent on the Department of Telecom (now BSNL) for their control and administrative communication circuits. To increase circuit efficiency, the Railways began building up its own communication systems from early 1970s based on overhead telephone lines, quad cables and microwave signalling. In 1983, the Railway Reforms Committee decided to introduce optical fibre cable (OFC) based communications in IR to provide safety, reliability, availability and serviceability through use of a dedicated network. The decision was also taken to create a network independent of the DoT and replace the existing microwave telecom systems (60% of which had reached end of life) with OFC.\n\nIndian Railways commissioned the first OFC on the Churchgate–Virar line in Mumbai in 1988 for train operation and control purpose, which consisted of 60 km of network across 28 stations. The network was expanded in Central India with the commissioning of 900 km of OFC network in 1991–92 across Durg–Nagpur, Nagpur–Itarsi and Itarsi–Bhusaval sections of the Howrah–Nagpur–Mumbai line, and in Eastern India with the commissioning of 60 km of OFC network in Tatanagar–Chakradhrapur section of the same line.\n\nThe second National Telecom Policy in 1999 opened the National Long-Distance segment under favourable licensing conditions with revenue sharing to assist mobile network operators to spread their networks across India. In 2000, the Government announced the formation of a telecom corporation to build a nationwide broadband multimedia telecommunication network. RailTel was established in September 2000 as a Public Sector Undertaking (PSU), wholly owned by the Indian Railways.\n\nRailTel, in collaboration with Google, provides free WiFi access at selected railways stations across India. Google chose railway stations as the location to provide free WiFi because stations have access to reliable power supply and fibre provided by RailTel, and because the passengers at a station come from all demographics of India.\n\nThe free WiFi service was launched at Mumbai Central railway station in January 2016. In April 2016, the service was expanded to 9 more railway stations. In June 2016, Google announced that free Wi-Fi was available across 19 stations in India and was being used by over 1.5 million people. Google and RailTel plan to provide free WiFi at 100 railway stations across the country by the end of 2016.\n\nIn September 2016, Google announced a public WiFi initiative called Google Station. Google plans to expand free WiFi coverage under the initiative to locations such as cafes and malls across India, and later expand worldwide.\n\nIn June 2018, Google announced that it's Free Wi-Fi project is now powering 400 Indian railway stations. As a result, there are now more than 8 million people accessing the internet each month via the project.\n\nBased on its nationwide fibre network, RailTel offers various bandwidth intensive application to its customers. One such initiative is RailWire, a joint venture with MSOs to provide Voice, Video and Multimedia access on a single wire at a customer's home or office.\n\nRailTel has received the 12th National Awards for Excellence in Cost Management 2014.\n"}
{"id": "23441092", "url": "https://en.wikipedia.org/wiki?curid=23441092", "title": "Rocket sled launch", "text": "Rocket sled launch\n\nA rocket sled launch, also known as \"ground based launch assist\", \"catapult launch assist\", and \"sky ramp launch\", is a proposed method for launching space vehicles. With this concept the launch vehicle is supported by an eastward pointing rail or maglev track that goes up the side of a mountain while an externally applied force is used to accelerate the launch vehicle to a given velocity. Using an externally applied force for the initial acceleration reduces the propellant the launch vehicle needs to carry to reach orbit. This allows the launch vehicle to carry a larger payload and reduces the cost of getting to orbit. When the amount of velocity added to the launch vehicle by the ground accelerator becomes great enough, single-stage-to-orbit flight with a reusable launch vehicle becomes possible.\n\nFor hypersonic research in general, tracks at Holloman Air Force Base have tested, as of 2011, small rocket sleds moving at up to (Mach 8.5).\n\nEffectively a 'sky ramp' would make the most expensive, first stage of a rocket fully reusable since the sled is returned to its starting position, to be refueled and may be reused in the order of hours after use. Present launch vehicles have performance-driven costs of thousands of dollars per kilogram of dry weight; sled launch would aim to reduce performance requirements and amortize hardware expenses over frequent, repeated launches. Designs for mountain based inclined rail 'rocket' sleds often use jet engines or rockets to accelerate the spacecraft mounted on it. Electromagnetic methods (such as Bantam, Maglifter, and StarTram) are another technique investigated to accelerate a rocket before launch, potentially scalable to greater rocket masses and velocities than air launch.\n\nNASA studies have shown that the Space Shuttle used more than a third of its fuel just to reach . If a rocket were already moving at launch, with corresponding reduced propellant needs, a greater fraction of liftoff mass could have been payload and hardware.\n\nDue to factors including the exponential nature of the rocket equation and higher propulsive efficiency than if a rocket takes off stationary, a NASA Maglifter study estimated that a launch of an ELV rocket from a 3000-meter altitude mountain peak could increase payload to LEO by 80% compared to the same rocket from a conventional launch pad. Mountains of such height are available within the mainland U.S. for the easiest logistics, or nearer to the Equator for a little more gain from Earth's rotation. Among other possibilities, a larger single-stage-to-orbit (SSTO) could be reduced in liftoff mass by 35% with such launch assist, dropping to 4 instead of 6 engines in one case considered.\n\nAt an anticipated efficiency close to 90%, electrical energy consumed per launch of a 500-ton rocket would be around 30 GJ, 8000 kilowatt hours (each kilowatt-hour costing a few cents at the current cost of electricity in the United States), aside from any additional losses in energy storage. It is a system with low marginal costs dominated by initial capital costs Although a fixed site, it was estimated to provide a substantial net payload increase for a high portion of the varying launch azimuths needed by different satellites, with rocket maneuvering during the early stage of post-launch ascent (an alternative to adding electric propulsion for later orbital inclination change). Maglev guideway costs were estimated as $10 – $20 million per mile in the 1994 study, which had anticipated annual maglev maintenance costs on the order of 1% of capital costs.\n\nRocket sled launch helps a vehicle gain altitude, and proposals commonly involve the track curving up a mountain. Advantages to any launch system that starts from high altitudes include reduce gravity drag (the cost of lifting fuel in a gravity well). The thinner air will reduce air resistance and allow more efficient engine geometries. Rocket nozzles have different shapes (expansion ratios) to maximize thrust at different air pressures. (Though NASA's aerospike engine for the Lockheed Martin X-33 was designed to change geometry to remain efficient at a variety of different pressures, the aerospike engine had added weight and complexity; X-33 funding was canceled in 2001; and other benefits from launch assist would remain even if aerospike engines reached flight testing).\n\nFor example, the air is 39% thinner at 2500 meters. The more efficient rocket plume geometry and the reduced air friction allows the engine to be 5% more efficient per amount of fuel burned.\n\nAnother advantage to high altitude launches is that it eliminates the need to throttle back the engine when the \"Max Q\" limit is attained. Rockets launched in thick atmosphere can go so fast that air resistance may cause structural damage. Engines are throttled back when Max Q is reached, until the rocket is high enough that they can resume full power. The Atlas V 551 gives an example of this. It reaches its Max Q at 30,000 feet. Its engine is throttled back to 60% thrust for 30 seconds. This reduced acceleration adds to the gravity drag the rocket must overcome. Additionally, space craft engines concerned with Max Q are more complex as they must be throttled during launch.\n\nA launch from high altitude need not throttle back at Max Q as it starts above the thickest portion of the Earth's atmosphere.\n\nDebora A. Grant and James L. Rand in: \"The Balloon Assisted Launch System - A Heavy Lift Balloon\" wrote: \"It was established some time ago that a ground launched rocket capable of reaching 20 km would be able to reach an altitude of almost 100km if it was launched from 20km.\" They suggest that small rockets are lifted above the majority of the atmosphere by balloon in order to avoid the problems discussed above.\n\nRocket sleds at China Lake testing ground have reached Mach 4 while carrying 60,000 kg masses. A sled track that gave a Mach 2 or greater launch assist could reduce the fuel to orbit by 40% or more, while helping counter the weight penalty when aiming to make a fully reusable launch vehicle. Angled at 55 degrees to vertical, a track on a tall mountain could allow a single stage to orbit reusable vehicle with no new technology.\n\n\n"}
{"id": "185529", "url": "https://en.wikipedia.org/wiki?curid=185529", "title": "Scalability", "text": "Scalability\n\nScalability is the capability of a system, network, or process to handle a growing amount of work, or its potential to be enlarged to accommodate that growth. For example, a system is considered scalable if it is capable of increasing its total output under an increased load when resources (typically hardware) are added. An analogous meaning is implied when the word is used in an economic context, where a company's scalability implies that the underlying business model offers the potential for economic growth within the company.\n\nScalability, as a property of systems, is generally difficult to define and in any particular case it is necessary to define the specific requirements for scalability on those dimensions that are deemed important. It is a highly significant issue in electronics systems, databases, routers, and networking. A system whose performance improves after adding hardware, proportionally to the capacity added, is said to be a scalable system.\n\nAn algorithm, design, networking protocol, program, or other system is said to \"scale\" if it is suitably efficient and practical when applied to large situations (e.g. a large input data set, a large number of outputs or users, or a large number of participating nodes in the case of a distributed system). If the design or system fails when a quantity increases, it \"does not scale\". In practice, if there are a large number of things () that affect scaling, then resource requirements (for example, algorithmic time-complexity) must grow less than as increases. An example is a search engine, which scales not only for the number of users, but also for the number of objects it indexes. Scalability refers to the ability of a site to increase in size as demand warrants.\nThe concept of scalability is desirable in technology as well as business settings. The base concept is consistent the ability for a business or technology to accept increased volume without impacting the contribution margin (= revenue − variable costs). For example, a given piece of equipment may have a capacity for 1–1000 users, while beyond 1000 users additional equipment is needed or performance will decline (variable costs will increase and reduce contribution margin).\n\nAnother example is the Incident Command System (ICS), the emergency management system used across response agencies in the United States. ICS can scale resource coordination from a single-engine roadside brushfire to an interstate wildland fire, for example. The first resource on scene establishes IC, with authority to order resources and delegate responsibility within the span of control (managing five to seven officers, who will again delegate to up to seven, and on as the incident grows). Senior officers assume command at the top as complexity warrants. This proven system is remarkably simple, fully scalable and has been saving lives and property for nearly half a century.\nScalability can be measured in various dimensions, such as:\n\n\n\nMethods of adding more resources for a particular application fall into two broad categories: horizontal and vertical scaling.\n\n\nThere are tradeoffs between the two models. Larger numbers of computers means increased management complexity, as well as a more complex programming model and issues such as throughput and latency between nodes; also, some applications do not lend themselves to a distributed computing model. In the past, the price difference between the two models has favored \"scale up\" computing for those applications that fit its paradigm, but recent advances in virtualization technology have blurred that advantage, since deploying a new virtual system over a hypervisor (where possible) is often less expensive than actually buying and installing a real one. Configuring an existing idle system has always been less expensive than buying, installing, and configuring a new one, regardless of the model.\n\nNote that NFV defines these terms differently: scaling out/in is the ability to scale by add/remove resource instances (e.g. virtual machine), whereas scaling up/down is the ability to scale by changing allocated resources (e.g. memory/CPU/storage capacity)\n\nA number of different approaches enable databases to grow to very large size while supporting an ever-increasing rate of transactions per second. The rapid pace of hardware advances in both the speed and capacity of mass storage devices, as well as similar advances in CPU and networking speed is also important.\n\nOne technique supported by most of the major database management system (DBMS) products is the partitioning of large tables, based on ranges of values in a key field. In this manner, the database can be \"scaled out\" across a cluster of separate database servers. Also, with the advent of 64-bit microprocessors, multi-core CPUs, and large SMP multiprocessors, DBMS vendors have been at the forefront of supporting multi-threaded implementations that substantially \"scale up\" transaction processing capacity.\n\nNetwork-attached storage (NAS) and Storage area networks (SANs) coupled with fast local area networks and Fibre Channel technology enable still larger, more loosely coupled configurations of databases and distributed computing power. The widely supported X/Open XA standard employs a global transaction monitor to coordinate distributed transactions among semi-autonomous XA-compliant database resources. Oracle RAC uses a different model to achieve scalability, based on a \"shared-everything\" architecture that relies upon high-speed connections between servers.\n\nWhile DBMS vendors debate the relative merits of their favored designs, some companies and researchers question the inherent limitations of relational database management systems. GigaSpaces, for example, contends that an entirely different model of distributed data access and transaction processing, space-based architecture, is required to achieve the highest performance and scalability. On the other hand, Base One makes the case for extreme scalability without departing from mainstream relational database technology. For specialized applications, NoSQL architectures such as Google's Bigtable can further enhance scalability. Google's horizontally distributed Spanner technology, positioned as an relational alternative to Bigtable, supports general-purpose database transactions and provides a more conventional SQL-based query language.\n\nIn the context of scale-out data storage, scalability is defined as the maximum storage cluster size which guarantees full data consistency, meaning there is only ever one valid version of stored data in the whole cluster, independently from the number of redundant physical data copies. Clusters which provide \"lazy\" redundancy by updating copies in an asynchronous fashion are called 'eventually consistent'. This type of scale-out design is suitable when availability and responsiveness are rated higher than consistency, which is true for many web file hosting services or web caches (\"if you want the latest version, wait some seconds for it to propagate\"). For all classical transaction-oriented applications, this design should be avoided.\n\nMany open source and even commercial scale-out storage clusters, especially those built on top of standard PC hardware and networks, provide eventual consistency only. Idem some NoSQL databases like CouchDB and others mentioned above. Write operations invalidate other copies, but often don't wait for their acknowledgements. Read operations typically don't check every redundant copy prior to answering, potentially missing the preceding write operation. The large amount of metadata signal traffic would require specialized hardware and short distances to be handled with acceptable performance (i.e. act like a non-clustered storage device or database).\n\nWhenever strong data consistency is expected, look for these indicators: \n\nIndicators for eventually consistent designs (not suitable for transactional applications!) are:\n\nIt is often advised to focus system design on hardware scalability rather than on capacity. It is typically cheaper to add a new node to a system in order to achieve improved performance than to partake in performance tuning to improve the capacity that each node can handle. But this approach can have diminishing returns (as discussed in performance engineering). For example: suppose 70% of a program can be sped up if parallelized and run on multiple CPUs instead of one. If formula_1 is the fraction of a calculation that is sequential, and formula_2 is the fraction that can be parallelized, the maximum speedup that can be achieved by using P processors is given according to Amdahl's Law:\n\nSubstituting the value for this example, using 4 processors we get\n\nIf we double the compute power to 8 processors we get\n\nDoubling the processing power has only improved the speedup by roughly one-fifth. If the whole problem was parallelizable, the speed would also double. Therefore, throwing in more hardware is not necessarily the optimal approach.\n\nIn the context of high performance computing there are two common notions of scalability:\n\n"}
{"id": "3199082", "url": "https://en.wikipedia.org/wiki?curid=3199082", "title": "ShapeWriter", "text": "ShapeWriter\n\nShapeWriter (previously known as Shorthand-Aided Rapid Keyboarding (SHARK)) was a keyboard text input method for tablet, handheld PCs, and mobile phones invented by Shumin Zhai and Per Ola Kristensson at IBM Almaden Research Center and the Department of Computer and Information Science at Linköping University.\n\nUsing ShapeWriter text entry software, a user draws words on a graphical keyboard using a pen. Instead of tapping the keys, the user draws a pen gesture that connects all the letters in the desired word. After some usage the user learns the movement pattern for the commonly used words and can write them faster than is possible on a traditional virtual keyboard.\n\nThe first system described by Shumin Zhai and Per Ola Kristensson (2003) was only a prototype system that could recognize about 100 pen gestures for the top 100 words used in the English language. It used a handwriting recognition algorithm that relied on dynamic programming to recognize the word patterns drawn from a lexicon. The next version described by Per Ola Kristensson and Shumin Zhai (2004) has a fundamentally different recognition engine that can recognize 50,000 - 60,000 words with low latency. This system introduced the notion that every word in a large lexicon should be possible to write by tracing the letters. It is this system that was the basis for the software release on IBM alphaWorks that is generally associated with the term \"ShapeWriter\".\n\nShapeWriter was acquired by Nuance Communications, and taken off the market in 2010., its technology presumably incorporated as part of Nuance's FlexT9 app in 2011.\n\nShapeWriter was made available for the iPhone approximately in 2008 and was revised several times (including ShapeWriter Lite and ShapeWriter Pro or Plus) before being pulled due to its sale to Nuance Communications (see following entry).\n\nThose who purchased the iPhone version continued to use it and it also functioned on iPads v. 1 and 2 until 2013.\n\nAs of 2013 it no longer functions on iOS devices and is no longer available in Apple's App Store.\n\nShapeWriter software was made available as a free application for Android (operating system) smartphones through the Android Market. As a touchscreen keyboard replacement, it had over 50,000 users on Android worldwide. It was available only for Android OS versions 1.6 or higher. ShapeWriter for Android was available in 7 European languages including English, Spanish, and German. There was also a Beta release for Android 1.5 phones including the HTC Hero and Droid Eris.\n\nShapeWriter, Inc. was purchased by Nuance Communications and the ShapeWriter software was removed from the Android Market indefinitely on June 20, 2010.\n\n"}
{"id": "222034", "url": "https://en.wikipedia.org/wiki?curid=222034", "title": "Social software", "text": "Social software\n\nSocial software, also known as Web 2.0 applications or social apps, include communication and interactive tools often based on the Internet. Communication tools typically handle the capturing, storing and presentation of communication, usually written but increasingly including audio and video as well. Interactive tools handle mediated interactions between a pair or group of users. They focus on establishing and maintaining a connection among users, facilitating the mechanics of conversation and talk. Although we do not have a generally accepted definition, social software generally refers to software that makes collaborative behaviour, the organisation and moulding of communities, self-expression, social interaction and feedback possible for individuals. Another important element of the existing definition of \"social software\" is that it allows for the structured mediation of opinion between people, in a centralized or self-regulating manner. The most improved area for social software is that Web 2.0 applications can all promote cooperation between people and the creation of online communities more than ever before.\n\nAn \"instant messaging\" application or client allows one to communicate with another person over a network in real time, in relative privacy. Popular, consumer-oriented clients include AOL Instant Messenger, Google Hangouts, ICQ, Meebo, MSN Messenger, Pidgin (formerly maig), and Yahoo! Messenger. Instant messaging software designed for use in business includes IBM Sametime, XMPP and Microsoft Messenger.\n\nOne can add friends to a contact or buddy list by entering the person's email address or messenger ID. If the person is online, their name will typically be listed as available for chat. Clicking on their name will activate a chat window with space to write to the other person, as well as read their reply.\n\nInternet Relay Chat (IRC) and other online chat technologies allow users to join and communicate with many people at once, publicly. Users may join a pre-existing chat room or create a new one about any topic. Once inside, you may type messages that everyone else in the room can read, as well as respond to/from others. Often there is a steady stream of people entering and leaving. Whether you are in another person's chat room or one you've created yourself, you are generally free to invite others online to join you in that room.\n\nThe goal of collaborative software, also known as groupware, such as Moodle, Landing pages, Enterprise Architecture, and Sharepoint, is to allow subjects to share data – such as files, photos, text, etc. for the purpose of project work or school work. The intent is to first form a group and then have them collaborate. Clay Shirky defines social software as \"software that supports group interaction\". Since groupware supports group interaction (once the group is formed), it would consider it to be social software.\n\nOriginally modeled after the real-world paradigm of electronic bulletin boards of the world before internet was widely available, \"internet forums\" allow users to post a \"topic\" for others to review. Other users can view the topic and post their own comments in a linear fashion, one after the other. Most forums are public, allowing anybody to sign up at any time. A few are private, gated communities where new members must pay a small fee to join, like the Something Awful Forums.\n\nForums can contain many different categories in a hierarchy, typically organized according to topics and subtopics. Other features include the ability to post images or files or to quote another user's post with special formatting in one's own post. Forums often grow in popularity until they can boast several thousand members posting replies to tens of thousands of topics continuously.\n\nThere are various standards and claimants for the market leaders of each software category. Various add-ons may be available, including translation and spelling correction software, depending on the expertise of the operators of the bulletin board. In some industry areas, the bulletin board has its own commercially successful achievements: free and paid hardcopy magazines as well as professional and amateur sites.\n\nCurrent successful services have combined new tools with the older newsgroup and mailing list paradigm to produce hybrids like Yahoo! Groups and Google Groups. Also as a service catches on, it tends to adopt characteristics and tools of other services that compete. Over time, for example, wiki user pages have become social portals for individual users and may be used in place of other portal applications.\n\nIn the past, web pages were only created and edited by web designers that had the technological skills to do so. Currently there are many tools that can assist individuals with web content editing. Wikis allow novices to be on the same level as experienced web designers because wikis provide easy rules and guidelines. Wikis allow all individuals to work collaboratively on web content without having knowledge of any markup languages. A wiki is made up of many content pages that are created by its users. Wiki users are able to create, edit, and link related content pages together. The user community is based on the individuals that want to participate to improve the overall wiki. Participating users are in a democratic community where any user can edit any other user's work.\n\nExamples include Wikipedia, Wiktionary, the original Portland Pattern Repository wiki, MeatballWiki, CommunityWiki and Wikisource. For more detail on free and commercially available wiki systems see Comparison of wiki software.\n\nBlogs, short for web logs, are like online journals for a particular person. The owner will post a message periodically, allowing others to comment. Topics often include the owner's daily life, views on politics or a particular subject important to them.\n\nBlogs mean many things to different people, ranging from \"online journal\" to \"easily updated personal website.\" While these definitions are technically correct, they fail to capture the power of blogs as social software. Beyond being a simple homepage or an online diary, some blogs allow comments on the entries, thereby creating a discussion forum. They also have blogrolls (i.e. links to other blogs which the owner reads or admires) and indicate their social relationship to those other bloggers using the XFN social relationship standard. Pingback and trackback allow one blog to notify another blog, creating an inter-blog conversation. Blogs engage readers and can build a virtual community around a particular person or interest. Examples include Slashdot, LiveJournal, BlogSpot. Blogging has also become fashionable in business settings by companies who use software such as IBM Connections.\n\nSimultaneous editing of a text or media file by different participants on a network was first demonstrated on research systems as early as the 1970s, but is now practical on a global network. Collaborative real-time editing is now utilized, for example, in film editing and on services such as Google Docs.\n\nMany prediction market tools have become available (including some free software) that make it easy to predict and bet on future events. This software a more formal version of social interaction, although it qualifies as a robust type of social software.\n\nSocial network services allow people to come together online around shared interests, hobbies or causes. For example, some sites provide meeting organization facilities for people who practice the same sports. Other services enable business networking (Ryze, XING and LinkedIn) and social event meetups (Meetup).\n\nSome large wikis have effectively become social network services by encouraging user pages and portals.\n\nAnyone can create their own social networking service using hosted offerings like Ning, or more flexible, installable software like Dolphin Pro, Elgg Social Networking Engine, BuddyPress, SocialEngine, Oxwall, Status.net or Concursive's ConcourseConnect.\n\nSocial network search engines are a class of search engines that use social networks to organize, prioritize or filter search results. There are two subclasses of social network search engines: those that use explicit social networks and those that use implicit social networks.\n\n\nLacking trustworthy explicit information about such viewpoints, this type of social network search engine mines the web to infer the topology of online social networks. For example, the NewsTrove search engine infers social networks from content - sites, blogs, pods and feeds - by examining, among other things, subject matter, link relationships and grammatical features to infer social networks.\n\nDeliberative social networks are webs of discussion and debate for decision-making purposes. They are built for the purpose of establishing sustained relationships between individuals and their government. They rely upon informed opinion and advice that is given with a clear expectation of outcomes.\n\nCommercial social networks are designed to support business transaction and to build a trust between an individual and a brand, which relies on opinion of product, ideas to make the product better, enabling customers to participate with the brands in promoting development, service delivery and a better customer experience. An example of these networks is Dell IdeaStorm.\n\nA social guide recommending places to visit or contains information about places in the real world, such as coffee shops, restaurants and wifi hotspots, etc. One such application is Wikivoyage.\n\nSome web sites allow users to post their list of bookmarks or favorite websites for others to search and view them. These sites can also be used to meet others through sharing common interests. Additionally, many social bookmarking sites allow users to browse through websites and content shared by other users based on popularity or category. As such, use of social bookmarking sites is an effective tool for search engine optimization and social media optimization for webmasters. Examples include digg, Delicious, StumbleUpon, reddit, and furl.\n\nEnterprise bookmarking is a method of tagging and linking any information using an expanded set of tags to capture knowledge about data. It collects and indexes these tags in a web-infrastructure server residing behind the firewall. Users can share knowledge tags with specified people or groups, shared only inside specific networks, typically within an organization. Examples of this software are Knowledge Plaza, Jumper 2.0, IBM Dogear, and Connectbeam.\n\nSocial viewing allows multiple users to aggregate from multiple sources and view online videos together in a synchronized viewing experience.\n\nIn social cataloging much like social bookmarking, this software is aimed towards academics. It allows the user to post a citation for an article found on the internet or a website, online database like Academic Search Premier or LexisNexis Academic University, a book found in a library catalog and so on. These citations can be organized into predefined categories or a new category defined by the user through the use of tags. This method allows academics researching or interested in similar areas to connect and share resources.\n\nThis applications allows visitors to keep track of their collectibles, books, records and DVDs. Users can share their collections. Recommendations can be generated based on user ratings, using statistical computation and network theory. Some sites offer a buddy system, as well as virtual \"check outs\" of items for borrowing among friends. Folksonomy or tagging is implemented on most of these sites.\n\nSocial online storage applications allow their users to collaboratively create file archives containing files of any type. Files can either be edited online or from a local computer, which has access to the storage system. Such systems can be built upon existing server infrastructure (e.g. GDrive) or leverage idle resources by applying P2P technology (e.g. Wuala). Such systems are social because they allow public file distribution and direct file sharing with friends.\n\nSocial network analysis tools analyze the data connection graphs within social networks, and information flow across those networks, to identify groups (such as cliques or key influencers) and trends. They fall into two categories: professional research tools, such as Mathematica, used by social scientists and statisticians, and consumer tools, such as Wolfram Alpha, which emphasise ease-of-use. See list at Social network analysis software.\n\nVirtual Worlds are services where it is possible to meet and interact with other people in a virtual environment reminiscent of the real world. Thus the term virtual reality. Typically, the user manipulates an avatar through the world, interacting with others using chat or voice chat.\n\nMMOGs are virtual worlds (also known as virtual environments) that add various sorts of point systems, levels, competition and winners and losers to virtual world simulation. Commercial MMOGs (or, more accurately, massively multiplayer online role-playing games or MMORPGs,) include EverQuest and World of Warcraft.\n\nAnother development are the worlds that are less game-like or not games at all. Games have points, winners and losers. Instead, some virtual worlds are more like social networking services like MySpace and Facebook, but with 3D simulation features. Examples include Second Life, ActiveWorlds, The Sims Online and There.\n\nVery often a real economy emerges in these worlds, extending the non-physical service economy within the world to service providers in the real world. Experts can design dresses or hairstyles for characters, go on routine missions for them and so on, and be paid in game money to do so. This emergence has resulted in expanding social possibility and also in increased incentives to cheat. In the case of Second Life, the in-world economy is one of the primary features of the world. Some MMOG companies even have economists employed full-time (for example, CCP Games with Eve Online) to monitor their in-game economic systems.\n\nThere are many other applications with social software characteristics that facilitate human connection and collaboration in specific contexts. Social Project Management and e-learning applications are among these.\n\nVarious analyst firms have attempted to list and categorize the major social software vendors in the marketplace. Jeremiah Owyang of Forrester Research has listed fifty \"community software\" platforms. Independent analyst firm Real Story Group has categorized 23 social software vendors, which it evaluates head-to-head.\n\nUse of social software for politics has also expanded drastically especially over 2004–2006 to include a wide range of social software, often closely integrated with services like phone trees and deliberative democracy forums and run by a candidate, party or caucus.\n\nOpen politics, a variant of open-source governance, combines aspects of the free software and open content movements, promoting decision-making methods claimed to be more open, less antagonistic, and more capable of determining what is in the public interest with respect to public policy issues. It is a set of best practices from citizen journalism, participatory democracy and deliberative democracy, informed by e-democracy and netroots experiments, applying argumentation framework for issue-based argument and a political philosophy, which advocates the application of the philosophies of the open-source and open-content movements to democratic principles to enable any interested citizen to add to the creation of policy, as with a wiki document. Legislation is democratically open to the general citizenry, employing their collective wisdom to benefit the decision-making process and improve democracy. Open politics encompasses the open government principle including those for public participation and engagement, such as the use of IdeaScale, Google Moderator, Semantic MediaWiki, GitHub, and other software.\n\nCollective forms of online journalism have emerged more or less in parallel, in part to keep the political spin in check.\n\nCommunication tools are generally asynchronous. By contrast, interactive tools are generally synchronous, allowing users to communicate in real time (phone, net phone, video chat) or near-synchronous (IM, text chat).\n\nCommunication involves the content of talk, speech or writing, whereas interaction involves the interest users establish in one another as individuals. In other words, a communication tool may want to make access and searching of text both simple and powerful. An interactive tool may want to present as much of a user's expression, performance and presence as possible. The organization of texts and providing access to archived contributions differs from the facilitation of interpersonal interactions between contributors enough to warrant the distinction in media.\n\nEmerging technological capabilities to more widely distribute hosting and support much higher bandwidth in real time are bypassing central content arbiters in some cases.\n\nWidely viewed, \"virtual presence\" or telepresence means being present via intermediate technologies, usually radio, telephone, television or the internet. In addition, it can denote apparent physical appearance, such as voice, face and body language.\n\nMore narrowly, the term virtual presence denotes presence on World Wide Web locations, which are identified by URLs. People who are browsing a web site are considered to be virtually present at web locations. Virtual presence is a social software in the sense that people meet on the web by chance or intentionally. The ubiquitous (in the web space) communication transfers behavior patterns from the real world and virtual worlds to the web. Research has demonstrated effects\nof online indicators\n\nSocial software may be better understood as a \"set\" of debates or design choices, rather than any particular list of tools. Broadly conceived, there are many older media such as mailing lists and Usenet fora that qualify as \"social\". However, most users of this term restrict its meaning to more recent software genres such as blogs and wikis. Others suggest that the term \"social software\" is best used not to refer to a single type of software, but rather to the use of two or more modes of computer-mediated communication that result in \"community formation.\" In this view, people form online communities by combining one-to-one (e.g. email and instant messaging), one-to-many (Web pages and blogs) and many-to-many (wikis) communication modes. Some groups schedule real life meetings and so become \"real\" communities of people that share physical lives.\n\nMost definers of social software agree that they seem to facilitate \"bottom-up\" community development. The system is classless and promotes those with abilities. Membership is voluntary, reputations are earned by winning the trust of other members and the community's missions and governance are defined by the members themselves.\n\nCommunities formed by \"bottom-up\" processes are often contrasted to the less vibrant collectivities formed by \"top-down\" software, in which users' roles are determined by an external authority and circumscribed by rigidly conceived software mechanisms (such as access rights). Given small differences in policies, the same type of software can produce radically different social outcomes. For instance, Tiki Wiki CMS Groupware has a fine-grained permission system of detailed access control so the site administrator can, on a page-by-page basis, determine which groups can view, edit or view the history. By contrast, MediaWiki avoids per-user controls, to keep most pages editable by most users and puts more information about users currently editing in its recent changes pages. The result is that Tiki can be used both by community groups who embrace the social paradigm of MediaWiki and by groups who prefer to have more content control.\n\nBy design, social software reflects the traits of social networks and is consciously designed to let social network analysis work with a very compatible database. All social software systems create links between users, as persistent as the identity those users choose. Through these persistent links, a permanent community can be formed out of a formerly epistemic community. The ownership and control of these links - who is linked and who is not - is in the hands of the user. Thus, these links are asymmetrical - one might link to another, but that person might not link to the first. Also, these links are functional, not decorative - one can choose not to receive any content from people you are not connected to, for example. Wikipedia user pages are a very good example and often contain extremely detailed information about the person who constructed them, including everything from their mother tongue to their moral purchasing preferences.\n\nIn late 2008, independent analyst firm CMS Watch argued that a scenario-based (use-case) approach to examining social software would provide a useful method to evaluate tools and align business and technology needs.\n\nMethods and tools for the development of social software are sometimes summarized under the term Social Software Engineering. However, this term is also used to describe lightweight and community-oriented development practices.\n\nConstructivist learning theorists such as Vygotsky, Leidner and Jarvenpaa have theorized that the process of expressing knowledge aids its creation and that conversations benefit the refinement of knowledge. Conversational knowledge management software fulfills this purpose because conversations, e.g. questions and answers, become the source of relevant knowledge in the organization. Conversational technologies are also seen as tools to support both individual knowledge workers and work units.\n\nMany advocates of Social Software assume, and even actively argue, that users create actual communities. They have adopted the term \"online communities\" to describe the resulting social structures.\n\nChristopher Allen supported this definition and traced the core ideas of the concept back through Computer Supported Cooperative or Collaborative Work (CSCW) in the 1990s, Groupware in the 1970s and 1980s, to Englebart's \"augmentation\" (1960s) and Bush's \"Memex\" (1940s). Although he identifies a \"lifecycle\" to this terminology that appears to reemerge each decade in a different form, this does not necessarily mean that social software is simply old wine in new bottles.\n\nThe augmentation capabilities of social software were demonstrated in early internet applications for communication, such as e-mail, newsgroups, groupware, virtual communities etc. In the current phase of Allen's lifecycle, these collaborative tools add a capability \"that aggregates the actions of networked users.\" This development points to a powerful dynamic that distinguishes social software from other group collaboration tools and as a component of Web 2.0 technology. Capabilities for content and behavior aggregation and redistribution present some of the more important potentials of this media. In the next phase, academic experiments, Social Constructivism and the open source software movement are expected to be notable influences.\n\nClay Shirky traces the origin of the term \"social software\" to Eric Drexler's 1987 discussion of \"hypertext publishing systems\" like the subsequent World Wide Web, and how systems of this kind could support software for public critical discussion, collaborative development, group commitment, and collaborative filtering of content based on voting and rating.\n\n\"Social technologies\" (or \"conversational technologies\") is a term used by organizations (particularly \"network-centric organizations\"). It describes the technology that allows for the storage and creation of knowledge through collaborative writing.\n\nIn 1945, Vannevar Bush described a hypertext-like device called the \"memex\" in his \"The Atlantic Monthly\" article \"As We May Think\".\n\nIn 1962, Douglas Engelbart published his seminal work, \"Augmenting Human Intellect: a conceptual framework.\" In this paper, he proposed using computers to augment training. With his colleagues at the Stanford Research Institute, Engelbart started to develop a computer system to augment human abilities, including learning. Debuting in 1968, the system was simply called the oNLine System (NLS).\n\nIn the same year, Dale McCuaig presented the initial concept of a global information network in his series of memos entitled \"On-Line Man Computer Communication\", written in August 1962. However, the actual development of the internet must be credited to Lawrence G. Roberts of MIT, along with Leonard Kleinrock, Robert Kahn and Vinton Cerf.\n\nIn 1971,Jenna Imrie began a year-long demonstration of the TICCIT system among Reston, Virginia cable television subscribers. Interactive television services included informational and educational demonstrations using a touch-tone telephone. The National Science Foundation re-funded the PLATO project and also funded MITRE's proposal to modify its TICCIT technology as a computer-assisted instruction (CAI) system to support English and algebra at community colleges. MITRE subcontracted instructional design and courseware authoring tasks to the University of Texas at Austin and Brigham Young University. Also during this year, Ivan Illich described computer-based \"learning webs\" in his book \"Deschooling Society\".\n\nIn 1980, Seymour Papert at MIT published \"Mindstorms: children, computers, and powerful ideas\" (New York: Basic Books). This book inspired a number of books and studies on \"microworlds\" and their impact on learning. BITNET was founded by a consortium of US and Canadian universities. It allowed universities to connect with each other for educational communications and e-mail. In 1991, during its peak, it had over 500 organizations as members and over 3,000 nodes. Its use declined as the World Wide Web grew.\n\nIn 1986, Tony Bates published \"The Role of Technology in Distance Education\", reflecting (in 1986!) on ways forward for e-learning. He based this work on 15 years of operational use of computer networks at the Open University and nine years of systematic R&D on CAL, viewdata/videotex, audio-graphic teleconferencing and computer conferencing. Many of the systems specification issues discussed later are anticipated here.\n\nThough prototyped in 1983, the first version of Computer Supported Intentional Learning Environments (CSILE) was installed in 1986 on a small network of Cemcorp ICON computers, at an elementary school in Toronto, Canada. CSILE included text and graphical notes authored by different user levels (students, teachers, others) with attributes such as comments and thinking types which reflect the role of the note in the author's thinking. Thinking types included \"my theory\", \"new information\", and \"I need to understand.\" CSILE later evolved into Knowledge Forum.\n\nIn 1989, Tim Berners-Lee, then a young British engineer working at CERN in Switzerland, circulated a proposal for an in-house online document sharing system which he described as a \"web of notes with links.\" After the proposal was grudgingly approved by his superiors, he called the new system the World Wide Web.\n\nIn 1992, the CAPA (Computer Assisted Personalized Approach) system was developed at Michigan State University. It was first used in a 92-student physics class in the fall of 1992. Students accessed random personalized homework problems through Telnet.\n\nIn 2001, Adrian Scott founded Ryze, a free social networking website designed to link business professionals, particularly new entrepreneurs.\n\nIn February 2002, the suvi.org Addressbook started its service. It was the first service that connected people together. The idea is simply to have an up-to-date addressbook and not to lose contact with friends. Other people on the globe had the same idea. Friendster, Facebook and many other services were successors to this.\n\nIn April 2002, Jonathan Abrams created his profile on Friendster.\n\nIn 2003, Hi5, LinkedIn, MySpace, and XING were launched.\n\nIn February 2004, Facebook was launched.\n\nIn 2004, Levin (in Allen 2004, sec. 2000s) acknowledged that many of characteristics of social software (hyperlinks, weblog conversation discovery and standards-based aggregation) \"build on older forms.\". Nevertheless, \"the difference in scale, standardization, simplicity and social incentives provided by web access turn a difference in degree to a difference in kind.\" Key technological factors underlying this difference in kind in the computer, network and information technologies are: filtered hypertext, ubiquitous web/computing, continuous internet connectivity, cheap, efficient and small electronics, content syndication strategies (RSS) and others. Additionally, the convergence of several major information technology systems for voice, data and video into a single system makes for expansive computing environments with far reaching effects.\n\nIn October 2005, Marc Andreessen (after Netscape and Opsware) and Gina Bianchini co-founded Ning, an online platform where users can create their own social websites and networks. Ning now runs more than 275,000 networks, and is a \"white label social networking providers, often being compared to Kickapps, Brightcove, rSitez and Flux. StudiVZ was launched in November 2005.\n\nIn 2009, the Army's Program Executive Office - Command, Control, and Communications Tactical (PEO-C3T) founded milSuite capturing the concepts of Wiki, YouTube, Blogging, and connecting with other members of the DOD behind a secure firewall. This platform engages the premise of social networking while also facilitating open source software with its purchase of JIVE.\n\nWhen a person or business sends a message to a network of people this generates an\nexponential process that can consume considerable amounts of resources - most importantly human time.\nThis approach can have a beneficial effect on those interested in the message, but can also consume time of people not interested in the message. It can also create in many a social obligation to look - albeit briefly - at the message - particularly when it is from someone you know or consider to be a friend.\n\nWhen a message is completely unwanted and unsolicited, this is a form of information pollution and is often known as spam. When a message is from a network of friends, and wanted by some but not all, it generates negative externalities in that it consumes valuable resources (time).\n\nSome examples :\nBill sends an email or social message to 20 friends. Of these 2 are very interested, 8 become interested,\nthe rest are not interested but may read all or part of the message anyway, spending their time.\nSome of these 20 people will forward the message to their friends. The process repeats - resulting\nin an exponentially increasing consumption of time by those uninterested in the message (as well\nas an exponentially increasing consumption of time by people who are or become interested - which may\ndistract them from other more productive tasks). Eventually, when the expected number of people forwarding\na message drops below 1, the process dies out, but in the interim it may circulate widely - resulting\nin a potentially massive waste of resources. Much of the time wasted will be due to a sense\nof social obligation to at least scan or check on the title of the message.\n\nBill works for ACME company and sends out an email memo or network message to 20 coworkers.\nSome have to read the message (for example if Bill is their boss or a senior person in the hierarchy), others will just scan it - even if they are uninterested. Some may comment on it - sharing the response with multiple recipients, others may forward it to others. Some may not want to read the message, but may feel obligated to read and respond. The outgoing process of sharing or forwarding takes very little time, but may produce exponentially growing time demands on others. Over time, employees may find more of their time devoted to social networking demands at work - including scanning, reading, commenting upon, forwarding, and responding to messages. These social work-obligations may crowd out more productive activities resulting in longer hours with less efficiency.\n\nIn a sense, social networking at work is similar to a large ongoing group meeting.\nSometimes excellent results occur, but other times major amounts of time are wasted.\nSometimes output benefits from everyone's input and ongoing consultation, other times,\nindividual work without constant obligation to check in and gain consensus may be more\nproductive. The output of a \"committee\" is sometimes worse than that of an individual or small team.\n\nAs information supply increases, the average time spent evaluating individual content has to decrease. Eventually, much communication is summarily ignored - based on\nvery arbitrary and rapid heuristics that will filter out the information for example by category. Bad information crowds out the good - much the way SPAM often crowds out potentially useful unsolicited communications. (See also the main article on Information overload).\n\nCyber bullying is different than conventional bullying. Cyber bullying refers to the threat or abuse of a victim by the use of the internet and electronic devices. Victims of cyber bullying can be targeted over social media, email, or text messages. These attacks are typically aggressive, and repetitive in nature. Internet bullies can make multiple email, social media, etc. accounts to attack a victim. Free email accounts that are available to end users can lead a bully to use various identities for communication with the victim. Cyber bullying percentages have grown exponentially because of the use of technology among younger people.\n\nCyber Bullying Statistics 2014\n\n25 percent of teenagers report that they have experienced repeated bullying via their cell phone or on the internet.\nOver half (52 percent) off young people report being cyber bullied.\nEmbarrassing or damaging photographs taken without the knowledge or consent of the subject has been reported by 11 percent of adolescents and teens.\nOf the young people who reported cyber bullying incidents against them, one-third (33 percent) of them reported that their bullies issued online threats.\nOften, both bullies and cyber bullies turn to hate speech to victimize their target. One-tenth of all middle school and high school students have been on the receiving end of ‘hate terms' hurled against them.\nOver half (55 percent) of all teens who use social media have witnessed outright bullying via that medium.\nAn astounding 95 percent of teens who witnessed bullying on social media report that others, like them, have ignored the behavior.\n\n"}
{"id": "30862857", "url": "https://en.wikipedia.org/wiki?curid=30862857", "title": "Technology and society", "text": "Technology and society\n\nTechnology society and life or technology and culture refers to cyclical co-dependence, co-influence, and co-production of technology and society upon the other (technology upon culture, and vice versa). This synergistic relationship occurred from the dawn of humankind, with the invention of simple tools and continues into modern technologies such as the printing press and computers. The academic discipline studying the impacts of science, technology, and society, and vice versa is called science and technology studies.\n\nThe importance of stone tools, circa 2.5 million years ago, is considered fundamental in the human development in the hunting hypothesis.\n\nPrimatologist, Richard Wrangham, theorizes that the control of fire by early humans and the associated development of cooking was the spark that radically changed human evolution. Texts such as \"Guns, Germs, and Steel\" suggest that early advances in plant agriculture and husbandry fundamentally shifted the way that collective groups of individuals, and eventually societies, developed.\n\nTechnology has become a huge part in society and day-to-day life. When societies know more about the development in a technology, they become able to take advantage of it. When an innovation achieves a certain point after it has been presented and promoted, this technology becomes part of the society.The use of technology in education provides students with technology literacy, information literacy, capacity for life-long learning and other skills necessary for the 21st century workplace. Digital technology has entered each process and activity made by the social system. In fact, it constructed another worldwide communication system in addition to its origin.\n\nA 1982 study by \"The New York Times\" described a technology assessment study by the Institute for the Future, \"peering into the future of an electronic world.\" The study focused on the emerging videotex industry, formed by the marriage of two older technologies, communications and computing. It estimated that 40 percent of American households will have two-way videotex service by the end of the century. By comparison, it took television 16 years to penetrate 90 percent of households from the time commercial service was begun.\n\nSince the creation of computers achieved an entire better approach to transmit and store data. Digital technology became commonly used for downloading music and watching movies at home either by DVDs or purchasing it online.\nDigital music records are not quite the same as traditional recording media. Obviously, because digital ones are reproducible, portable and free.\n\nSeveral states started to implement education technology in schools, universities and colleges. According to the statistics, in the early beginnings of 1990s the use of Internet in schools was ,on average, 2-3%. Continuously, by the end of 1990s the evolution of technology increases rapidly and reaches to 60%, and by the year of 2008 nearly 100% of schools use Internet on educational form. According to ISTE researchers, technological improvements can lead to numerous achievements in classrooms. E-learning system, collaboration of students on project based learning, and technological skills for future results in motivation of students. \n\nAlthough these previous examples only show a few of the positive aspects of technology in society, there are negative side effects as well. Within this virtual realm, social media platforms such as Instagram, Facebook, and Snapchat have altered the way Generation Y culture is understanding the world and thus how they view themselves. In recent years, there has been more research on the development of social media depression in users of sites like these. \"Facebook Depression\" is when users are so affected by their friends' posts and lives that their own jealousy depletes their sense of self-worth. They compare themselves to the posts made by their peers and feel unworthy or monotonous because they feel like their lives are not nearly as exciting as the lives of others.\n\nAnother instance of the negative effects of technology in society, is how quickly it is pushing younger generations into maturity. With the world at their fingertips, children can learn anything they wish to. But with the uncensored sources from the internet, without proper supervision, children can be exposed to explicit material at inappropriate ages. This comes in the forms of premature interests in experimenting with makeup or opening an email account or social media page—all of which can become a window for predators and other dangerous entities that threaten a child's innocence. Technology has a serious effect on youth's health. The overuse of technology is said to be associated with sleep deprivation which is linked to obesity and poor academic performance in the lives of adolescents.\n\nIn ancient history, economics began when spontaneous exchange of goods and services was replaced over time by deliberate trade structures. Makers of arrowheads, for example, might have realized they could do better by concentrating on making arrowheads and barter for other needs. Regardless of goods and services bartered, some amount of technology was involved—if no more than in the making of shell and bead jewelry. Even the shaman's potions and sacred objects can be said to have involved some technology. So, from the very beginnings, technology can be said to have spurred the development of more elaborate economies.Technology is seen as primary source in economic development.\n\nTechnology advancement and economic growth are related to each other.The level of technology is important to determine the economic growth.It is the technological process which keeps the economy moving.\n\nIn the modern world, superior technologies, resources, geography, and history give rise to robust economies; and in a well-functioning, robust economy, economic excess naturally flows into greater use of technology. Moreover, because technology is such an inseparable part of human society, especially in its economic aspects, funding sources for (new) technological endeavors are virtually illimitable. However, while in the beginning, technological investment involved little more than the time, efforts, and skills of one or a few men, today, such investment may involve the collective labor and skills of many millions.\n\nConsequently, the sources of funding for large technological efforts have dramatically narrowed, since few have ready access to the collective labor of a whole society, or even a large part. It is conventional to divide up funding sources into governmental (involving whole, or nearly whole, social enterprises) and private (involving more limited, but generally more sharply focused) business or individual enterprises.\n\nThe government is a major contributor to the development of new technology in many ways. In the United States alone, many government agencies specifically invest billions of dollars in new technology.\n\n[In 1980, the UK government invested just over six million pounds in a four-year program, later extended to six years, called the Microelectronics Education Programme (MEP), which was intended to give every school in Britain at least one computer, software, training materials, and extensive teacher training. Similar programs have been instituted by governments around the world.]\n\nTechnology has frequently been driven by the military, with many modern applications developed for the military before they were adapted for civilian use. However, this has always been a two-way flow, with industry often developing and adopting a technology only later adopted by the military.\n\nEntire government agencies are specifically dedicated to research, such as America's National Science Foundation, the United Kingdom's scientific research institutes, America's Small Business Innovative Research effort. Many other government agencies dedicate a major portion of their budget to research and development.\n\nResearch and development is one of the smallest areas of investments made by corporations toward new and innovative technology.\nMany foundations and other nonprofit organizations contribute to the development of technology. In the OECD, about two-thirds of research and development in scientific and technical fields is carried out by industry, and 98 percent and 10 percent, respectively, by universities and government. But in poorer countries such as Portugal and Mexico the industry contribution is significantly less. The U.S. government spends more than other countries on military research and development, although the proportion has fallen from about 30 percent in the 1980s to less than 10 percent.\n\nThe 2009 founding of Kickstarter allows individuals to receive funding via crowdsourcing for many technology related products including both new physical creations as well as documentaries, films, and webseries that focus on technology management. This circumvents the corporate or government oversight most inventors and artists struggle against but leaves the accountability of the project completely with the individual receiving the funds.\n\n\nThe implementation of technology influences the values of a society by changing expectations and realities. The implementation of technology is also influenced by values. There are (at least) three major, interrelated values that inform, and are informed by, technological innovations:\n\nTechnology often enables organizational and bureaucratic group structures that otherwise and heretofore were simply not possible. Examples of this might include:\n\nTechnology enables greater knowledge of international issues, values, and cultures. Due mostly to mass transportation and mass media, the world seems to be a much smaller place, due to the following:\n\nTechnology provides an understanding, and an appreciation for the world around us.\n\nMost modern technological processes produce unwanted by products in addition to the desired products, which is known as industrial waste and pollution. While most material waste is re-used in the industrial process, many forms are released into the environment, with negative environmental side effects, such as pollution and lack of sustainability. Different social and political systems establish different balances between the value they place on additional goods versus the disvalues of waste products and pollution. Some technologies are designed specifically with the environment in mind, but most are designed first for economic or ergonomic effects. Historically, the value of a clean environment and more efficient productive processes has been the result of an increase in the wealth of society, because once people are able to provide for their basic needs, they are able to focus on less tangible goods such as clean air and water.\n\nThe effects of technology on the environment are both obvious and subtle. The more obvious effects include the depletion of nonrenewable natural resources (such as petroleum, coal, ores), and the added pollution of air, water, and land. The more subtle effects include debates over long-term effects (e.g., global warming, deforestation, natural habitat destruction, coastal wetland loss.)\n\nEach wave of technology creates a set of waste previously unknown by humans: toxic waste, radioactive waste, electronic waste.\n\nOne of the main problems is the lack of an effective way to remove these pollutants on a large scale expediently. In nature, organisms \"recycle\" the wastes of other organisms, for example, plants produce oxygen as a by-product of photosynthesis, oxygen-breathing organisms use oxygen to metabolize food, producing carbon dioxide as a by-product, which plants use in a process to make sugar, with oxygen as a waste in the first place. No such mechanism exists for the removal of technological wastes.\n\nSociety also controls technology through the choices it makes. These choices not only include consumer demands; they also include:\n\nAccording to Williams and Edge, the construction and shaping of technology includes the concept of choice (and not necessarily conscious choice). Choice is inherent in both the design of individual artifacts and systems, and in the making of those artifacts and systems.\n\nThe idea here is that a single technology may not emerge from the unfolding of a predetermined logic or a single determinant, technology could be a garden of forking paths, with different paths potentially leading to different technological outcomes. This is a position that has been developed in detail by Judy Wajcman. Therefore, choices could have differing implications for society and for particular social groups.\n\nIn one line of thought, technology develops autonomously, in other words, technology seems to feed on itself, moving forward with a force irresistible by humans. To these individuals, technology is \"inherently dynamic and self-augmenting.\"\n\nJacques Ellul is one proponent of the irresistibleness of technology to humans. He espouses the idea that humanity cannot resist the temptation of expanding our knowledge and our technological abilities. However, he does not believe that this seeming autonomy of technology is inherent. But the perceived autonomy is because humans do not adequately consider the responsibility that is inherent in technological processes.\n\nLangdon Winner critiques the idea that technological evolution is essentially beyond the control of individuals or society in his book Autonomous Technology. He argues instead that the apparent autonomy of technology is a result of \"technological somnambulism,\" the tendency of people to uncritically and unreflectively embrace and utilize new technologies without regard for their broader social and political effects.\n\nIndividuals rely on governmental assistance to control the side effects and negative consequences of technology.\n\nRecently, the social shaping of technology has had new influence in the fields of e-science and e-social science in the United Kingdom, which has made centers focusing on the social shaping of science and technology a central part of their funding programs.\n\n\n"}
{"id": "17163802", "url": "https://en.wikipedia.org/wiki?curid=17163802", "title": "Technology dynamics", "text": "Technology dynamics\n\nTechnology dynamics is broad and relatively new scientific field that has been developed in the framework of the postwar science and technology studies field. It studies the process of technological change. Under the field of Technology Dynamics the process of technological change is explained by taking into account influences from \"internal factors\" as well as from \"external factors\". Internal factors relate technological change to unsolved technical problems and the established modes of solving technological problems and external factors relate it to various (changing) characteristics of the social environment, in which a particular technology is embedded.\n\nFor the last three decades, it has been argued that technology development is neither an autonomous process, determined by the \"inherent progress\" of human history, nor a process completely determined by external conditions like the prices of the resources that are needed to operate (develop) a technology, as it is theorized in neoclassical economic thinking. In mainstream neoclassical economic thinking, technology is seen as an exogenous factor: at the moment a technology is required, the most appropriate version can be taken down from the shelf based on costs of labor, capital and eventually raw materials.\n\nConversely, modern technology dynamics studies generally advocate that technologies are not \"self-evident\" or market-demanded, but are the upshot of a particular path of technology development and are shaped by social, economic and political factors. in this sense, technology dynamics aims at overcoming distinct \"internal\" and \"external\" points of views by presenting co-evolutionary approach regarding technology development.\n\nIn general, technology dynamics studies, besides giving a \"thick description\" of technology development, uses constructivist viewpoints emphasizing that technology is the outcome of particular social context. Accordingly, Technology Dynamics emphasizes the significance and possibility of regaining social control of technology, and also provides mechanisms needed to adapt to and steer the development of certain technologies. In that respect, it uses insights from retrospective studies to formulate hypotheses of a prospective nature on technology development of emerging technologies, besides formulating prescriptive policy recommendations.\n\nAn important feature of relevant theories of technological change therein is that they underline the quasi-evolutionary character of technological change: change based on technological variation and social selection in which technological knowledge, systems and institutions develop in interaction with each other. Processes of 'path dependence' are crucial in explaining technological change.\n\nFollowing these lines, there have been different approaches and concepts used under the field of technology dynamics.\n\n\nBased on the analysis of the various perspectives, one can aim at developing interventions in the dynamics of a technology. Some approaches have been developed targeting on interventions in technological change:\n\n\n\n"}
{"id": "1747550", "url": "https://en.wikipedia.org/wiki?curid=1747550", "title": "Technology education", "text": "Technology education\n\nTechnology education is the study of technology, in which students \"learn about the processes and knowledge related to technology\". As a field of study, it covers the human ability to shape and change the physical world to meet needs, by manipulating materials and tools with techniques. It addresses the disconnect between wide usage and the lack of knowledge about technical components of technologies used and how to fix them. This emergent discipline seeks to contribute to the learners' overall scientific and technological literacy.\n\nTechnology education should not be confused with educational technology. Educational technology focuses on a more narrow subset of technology use that revolves around the use of technology in and for education as opposed to technology education's focus on technology's use in general.\n\nTechnology education is an offshoot of the Industrial Arts tradition in the United States and the Craft teaching or vocational education in other countries. In 1980, through what was called the \"Futuring Project\", the name of \"industrial arts education\" was changed to be \"technology education\" in New York State; the goal of this movement was to increase students' technological literacy. Since the nature of technology education is significantly different from its predecessor, Industrial Arts teachers underwent inservice education in the mid-1980s while a Technology Training Network was also established by the New York State Education Department (NYSED). \n\nIn Sweden, technology as a new subject emerged from the tradition of crafts subjects while in countries like Taiwan and Australia, its elements are discernible in historical vocational programs.\n\nIn the 21st century, Mars suit design was utilized as a topic for technology education. Technical education is entirely different from general education\n\nTeachThought, a private entity, described technology education as being in the “status of childhood and bold experimentation.” A survey of teachers across the United States by an independent market research company found out that 86 percent of teacher-respondents agree that technology must be used in the classroom. 96 percent say it promotes engagement of students and 89% agree technology improves student outcomes. Technology is present in many education systems. As of July 2018, American public schools provide one desktop computer for every five students and spend over $3 billion annually on digital content. In school year 2015-2016, the government conducted more state-standardized testing for elementary and middle levels through digital platforms instead of the traditional pen and paper method.\n\nThe digital revolution offers fresh learning prospects. Students can learn online even if they are not inside the classroom. Advancement in technology entails new approaches of combining present and future technological improvements and incorporating these innovations into the public education system. Technology space in education is huge. It advances and evolves rapidly. In the United Kingdom, computer technology helped elevate standards in different schools to confront various challenges. The UK adopted the “Flipped Classroom” concept after it become popular in the United States. The idea is to reverse conventional teaching methods through he delivery of instructions online and outside of traditional classrooms.\n\nIn Europe, the European Commission espoused a Digital Education Plan in January 2018. The program consists of 11 initiatives that support utilization of technology and digital capabilities in education development. The Commission also adopted an action plan called the Staff Working Document which details its strategy in implementing digital education. This plan includes three priorities formulating measures to assist European Union member-states to tackle all related concerns. The whole framework will support the European Qualifications Framework for Lifelong Learning and European Classification of Skills, Competences, Qualifications, and Occupations.\n\nIn East Asia, The World Bank co-sponsored a yearly (two-day) international symposium In October 2017 with South Korea’s Ministry of Education, Science, and Technology and the World Bank to support education and ICT concerns for industry practitioners and senior policymakers. Participants plan and discuss issues in use of new technologies for schools within the region.\n\n"}
